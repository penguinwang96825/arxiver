{"title": "TRACE Back from the Future: A Probabilistic Reasoning Approach to Controllable Language Generation", "abstract": "As large language models (LMs) advance, there is an increasing need to\ncontrol their outputs to align with human values (e.g., detoxification) or\ndesired attributes (e.g., personalization, topic). However, autoregressive\nmodels focus on next-token predictions and struggle with global properties that\nrequire looking ahead. Existing solutions either tune or post-train LMs for\neach new attribute - expensive and inflexible - or approximate the Expected\nAttribute Probability (EAP) of future sequences by sampling or training, which\nis slow and unreliable for rare attributes. We introduce TRACE (Tractable\nProbabilistic Reasoning for Adaptable Controllable gEneration), a novel\nframework that efficiently computes EAP and adapts to new attributes through\ntractable probabilistic reasoning and lightweight control. TRACE distills a\nHidden Markov Model (HMM) from an LM and pairs it with a small classifier to\nestimate attribute probabilities, enabling exact EAP computation over the HMM's\npredicted futures. This EAP is then used to reweigh the LM's next-token\nprobabilities for globally compliant continuations. Empirically, TRACE achieves\nstate-of-the-art results in detoxification with only 10% decoding overhead,\nadapts to 76 low-resource personalized LLMs within seconds, and seamlessly\nextends to composite attributes.", "published": "2025-04-25 17:59:13", "link": "http://arxiv.org/abs/2504.18535v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Co-Constructive Behavior of Large Language Models in Explanation Dialogues", "abstract": "The ability to generate explanations that are understood by explainees is the\nquintessence of explainable artificial intelligence. Since understanding\ndepends on the explainee's background and needs, recent research has focused on\nco-constructive explanation dialogues, where the explainer continuously\nmonitors the explainee's understanding and adapts explanations dynamically. We\ninvestigate the ability of large language models (LLMs) to engage as explainers\nin co-constructive explanation dialogues. In particular, we present a user\nstudy in which explainees interact with LLMs, of which some have been\ninstructed to explain a predefined topic co-constructively. We evaluate the\nexplainees' understanding before and after the dialogue, as well as their\nperception of the LLMs' co-constructive behavior. Our results indicate that\ncurrent LLMs show some co-constructive behaviors, such as asking verification\nquestions, that foster the explainees' engagement and can improve understanding\nof a topic. However, their ability to effectively monitor the current\nunderstanding and scaffold the explanations accordingly remains limited.", "published": "2025-04-25 16:47:44", "link": "http://arxiv.org/abs/2504.18483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Induction of Dialogue Task Schemas with Streaming Refinement and Simulated Interactions", "abstract": "In task-oriented dialogue (TOD) systems, Slot Schema Induction (SSI) is\nessential for automatically identifying key information slots from dialogue\ndata without manual intervention. This paper presents a novel state-of-the-art\n(SoTA) approach that formulates SSI as a text generation task, where a language\nmodel incrementally constructs and refines a slot schema over a stream of\ndialogue data. To develop this approach, we present a fully automatic LLM-based\nTOD simulation method that creates data with high-quality state labels for\nnovel task domains. Furthermore, we identify issues in SSI evaluation due to\ndata leakage and poor metric alignment with human judgment. We resolve these by\ncreating new evaluation data using our simulation method with human guidance\nand correction, as well as designing improved evaluation metrics. These\ncontributions establish a foundation for future SSI research and advance the\nSoTA in dialogue understanding and system development.", "published": "2025-04-25 16:29:45", "link": "http://arxiv.org/abs/2504.18474v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast-Slow Thinking for Large Vision-Language Model Reasoning", "abstract": "Recent advances in large vision-language models (LVLMs) have revealed an\n\\textit{overthinking} phenomenon, where models generate verbose reasoning\nacross all tasks regardless of questions. To address this issue, we present\n\\textbf{FAST}, a novel \\textbf{Fa}st-\\textbf{S}low \\textbf{T}hinking framework\nthat dynamically adapts reasoning depth based on question characteristics.\nThrough empirical analysis, we establish the feasibility of fast-slow thinking\nin LVLMs by investigating how response length and data distribution affect\nperformance. We develop FAST-GRPO with three components: model-based metrics\nfor question characterization, an adaptive thinking reward mechanism, and\ndifficulty-aware KL regularization. Experiments across seven reasoning\nbenchmarks demonstrate that FAST achieves state-of-the-art accuracy with over\n10\\% relative improvement compared to the base model, while reducing token\nusage by 32.7-67.3\\% compared to previous slow-thinking approaches, effectively\nbalancing reasoning length and accuracy.", "published": "2025-04-25 16:11:23", "link": "http://arxiv.org/abs/2504.18458v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation", "abstract": "Radiology report generation is critical for efficiency but current models\nlack the structured reasoning of experts, hindering clinical trust and\nexplainability by failing to link visual findings to precise anatomical\nlocations. This paper introduces BoxMed-RL, a groundbreaking unified training\nframework for generating spatially verifiable and explainable radiology\nreports. Built on a large vision-language model, BoxMed-RL revolutionizes\nreport generation through two integrated phases: (1) In the Pretraining Phase,\nwe refine the model via medical concept learning, using Chain-of-Thought\nsupervision to internalize the radiologist-like workflow, followed by spatially\nverifiable reinforcement, which applies reinforcement learning to align medical\nfindings with bounding boxes. (2) In the Downstream Adapter Phase, we freeze\nthe pretrained weights and train a downstream adapter to ensure fluent and\nclinically credible reports. This framework precisely mimics radiologists'\nworkflow, compelling the model to connect high-level medical concepts with\ndefinitive anatomical evidence. Extensive experiments on public datasets\ndemonstrate that BoxMed-RL achieves an average 7% improvement in both METEOR\nand ROUGE-L metrics compared to state-of-the-art methods. An average 5%\nimprovement in large language model-based metrics further underscores\nBoxMed-RL's robustness in generating high-quality radiology reports.", "published": "2025-04-25 16:05:06", "link": "http://arxiv.org/abs/2504.18453v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts", "abstract": "In this paper, we introduce PolyMath, a multilingual mathematical reasoning\nbenchmark covering 18 languages and 4 easy-to-hard difficulty levels. Our\nbenchmark ensures difficulty comprehensiveness, language diversity, and\nhigh-quality translation, making it a highly discriminative multilingual\nmathematical benchmark in the era of reasoning LLMs. We conduct a comprehensive\nevaluation for advanced LLMs and find that even Deepseek-R1-671B and\nQwen-QwQ-32B, achieve only 43.4 and 41.8 benchmark scores, with less than 30%\naccuracy under the highest level. From a language perspective, our benchmark\nreveals several key challenges of LLMs in multilingual reasoning: (1) Reasoning\nperformance varies widely across languages for current LLMs; (2) Input-output\nlanguage consistency is low in reasoning LLMs and may be correlated with\nperformance; (3) The thinking length differs significantly by language for\ncurrent LLMs. Additionally, we demonstrate that controlling the output language\nin the instructions has the potential to affect reasoning performance,\nespecially for some low-resource languages, suggesting a promising direction\nfor improving multilingual capabilities in LLMs.", "published": "2025-04-25 15:39:04", "link": "http://arxiv.org/abs/2504.18428v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kimi-Audio Technical Report", "abstract": "We present Kimi-Audio, an open-source audio foundation model that excels in\naudio understanding, generation, and conversation. We detail the practices in\nbuilding Kimi-Audio, including model architecture, data curation, training\nrecipe, inference deployment, and evaluation. Specifically, we leverage a\n12.5Hz audio tokenizer, design a novel LLM-based architecture with continuous\nfeatures as input and discrete tokens as output, and develop a chunk-wise\nstreaming detokenizer based on flow matching. We curate a pre-training dataset\nthat consists of more than 13 million hours of audio data covering a wide range\nof modalities including speech, sound, and music, and build a pipeline to\nconstruct high-quality and diverse post-training data. Initialized from a\npre-trained LLM, Kimi-Audio is continual pre-trained on both audio and text\ndata with several carefully designed tasks, and then fine-tuned to support a\ndiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audio\nachieves state-of-the-art performance on a range of audio benchmarks including\nspeech recognition, audio understanding, audio question answering, and speech\nconversation. We release the codes, model checkpoints, as well as the\nevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio.", "published": "2025-04-25 15:31:46", "link": "http://arxiv.org/abs/2504.18425v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs", "abstract": "Efficient deployment of 1-bit Large Language Models (LLMs) is hindered by\nactivation outliers, which complicate quantization to low bit-widths. We\nintroduce BitNet v2, a novel framework enabling native 4-bit activation\nquantization for 1-bit LLMs. To tackle outliers in attention and feed-forward\nnetwork activations, we propose H-BitLinear, a module applying an online\nHadamard transformation prior to activation quantization. This transformation\nsmooths sharp activation distributions into more Gaussian-like forms, suitable\nfor low-bit representation. Experiments show BitNet v2 trained from scratch\nwith 8-bit activations matches BitNet b1.58 performance. Crucially, BitNet v2\nachieves minimal performance degradation when trained with native 4-bit\nactivations, significantly reducing memory footprint and computational cost for\nbatched inference.", "published": "2025-04-25 15:17:52", "link": "http://arxiv.org/abs/2504.18415v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Expressing stigma and inappropriate responses prevents LLMs from safely replacing mental health providers", "abstract": "Should a large language model (LLM) be used as a therapist? In this paper, we\ninvestigate the use of LLMs to *replace* mental health providers, a use case\npromoted in the tech startup and research space. We conduct a mapping review of\ntherapy guides used by major medical institutions to identify crucial aspects\nof therapeutic relationships, such as the importance of a therapeutic alliance\nbetween therapist and client. We then assess the ability of LLMs to reproduce\nand adhere to these aspects of therapeutic relationships by conducting several\nexperiments investigating the responses of current LLMs, such as `gpt-4o`.\nContrary to best practices in the medical community, LLMs 1) express stigma\ntoward those with mental health conditions and 2) respond inappropriately to\ncertain common (and critical) conditions in naturalistic therapy settings --\ne.g., LLMs encourage clients' delusional thinking, likely due to their\nsycophancy. This occurs even with larger and newer LLMs, indicating that\ncurrent safety practices may not address these gaps. Furthermore, we note\nfoundational and practical barriers to the adoption of LLMs as therapists, such\nas that a therapeutic alliance requires human characteristics (e.g., identity\nand stakes). For these reasons, we conclude that LLMs should not replace\ntherapists, and we discuss alternative roles for LLMs in clinical therapy.", "published": "2025-04-25 15:14:21", "link": "http://arxiv.org/abs/2504.18412v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HRScene: How Far Are VLMs from Effective High-Resolution Image Understanding?", "abstract": "High-resolution image (HRI) understanding aims to process images with a large\nnumber of pixels, such as pathological images and agricultural aerial images,\nboth of which can exceed 1 million pixels. Vision Large Language Models (VLMs)\ncan allegedly handle HRIs, however, there is a lack of a comprehensive\nbenchmark for VLMs to evaluate HRI understanding. To address this gap, we\nintroduce HRScene, a novel unified benchmark for HRI understanding with rich\nscenes. HRScene incorporates 25 real-world datasets and 2 synthetic diagnostic\ndatasets with resolutions ranging from 1,024 $\\times$ 1,024 to 35,503 $\\times$\n26,627. HRScene is collected and re-annotated by 10 graduate-level annotators,\ncovering 25 scenarios, ranging from microscopic to radiology images, street\nviews, long-range pictures, and telescope images. It includes HRIs of\nreal-world objects, scanned documents, and composite multi-image. The two\ndiagnostic evaluation datasets are synthesized by combining the target image\nwith the gold answer and distracting images in different orders, assessing how\nwell models utilize regions in HRI. We conduct extensive experiments involving\n28 VLMs, including Gemini 2.0 Flash and GPT-4o. Experiments on HRScene show\nthat current VLMs achieve an average accuracy of around 50% on real-world\ntasks, revealing significant gaps in HRI understanding. Results on synthetic\ndatasets reveal that VLMs struggle to effectively utilize HRI regions, showing\nsignificant Regional Divergence and lost-in-middle, shedding light on future\nresearch.", "published": "2025-04-25 15:01:41", "link": "http://arxiv.org/abs/2504.18406v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A UD Treebank for Bohairic Coptic", "abstract": "Despite recent advances in digital resources for other Coptic dialects,\nespecially Sahidic, Bohairic Coptic, the main Coptic dialect for pre-Mamluk,\nlate Byzantine Egypt, and the contemporary language of the Coptic Church,\nremains critically under-resourced. This paper presents and evaluates the first\nsyntactically annotated corpus of Bohairic Coptic, sampling data from a range\nof works, including Biblical text, saints' lives and Christian ascetic writing.\nWe also explore some of the main differences we observe compared to the\nexisting UD treebank of Sahidic Coptic, the classical dialect of the language,\nand conduct joint and cross-dialect parsing experiments, revealing the unique\nnature of Bohairic as a related, but distinct variety from the more often\nstudied Sahidic.", "published": "2025-04-25 14:33:03", "link": "http://arxiv.org/abs/2504.18386v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pushing the boundary on Natural Language Inference", "abstract": "Natural Language Inference (NLI) is a central task in natural language\nunderstanding with applications in fact-checking, question answering, and\ninformation retrieval. Despite its importance, current NLI systems heavily rely\non supervised learning with datasets that often contain annotation artifacts\nand biases, limiting generalization and real-world applicability. In this work,\nwe apply a reinforcement learning-based approach using Group Relative Policy\nOptimization (GRPO) for Chain-of-Thought (CoT) learning in NLI, eliminating the\nneed for labeled rationales and enabling this type of training on more\nchallenging datasets such as ANLI. We fine-tune 7B, 14B, and 32B language\nmodels using parameter-efficient techniques (LoRA and QLoRA), demonstrating\nstrong performance across standard and adversarial NLI benchmarks. Our 32B\nAWQ-quantized model surpasses state-of-the-art results on 7 out of 11\nadversarial sets$\\unicode{x2013}$or on all of them considering our\nreplication$\\unicode{x2013}$within a 22GB memory footprint, showing that robust\nreasoning can be retained under aggressive quantization. This work provides a\nscalable and practical framework for building robust NLI systems without\nsacrificing inference quality.", "published": "2025-04-25 14:20:57", "link": "http://arxiv.org/abs/2504.18376v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant", "abstract": "In recent years, multi-agent frameworks powered by large language models\n(LLMs) have advanced rapidly. Despite this progress, there is still a notable\nabsence of benchmark datasets specifically tailored to evaluate their\nperformance. To bridge this gap, we introduce Auto-SLURP, a benchmark dataset\naimed at evaluating LLM-based multi-agent frameworks in the context of\nintelligent personal assistants. Auto-SLURP extends the original SLURP dataset\n-- initially developed for natural language understanding tasks -- by\nrelabeling the data and integrating simulated servers and external services.\nThis enhancement enables a comprehensive end-to-end evaluation pipeline,\ncovering language understanding, task execution, and response generation. Our\nexperiments demonstrate that Auto-SLURP presents a significant challenge for\ncurrent state-of-the-art frameworks, highlighting that truly reliable and\nintelligent multi-agent personal assistants remain a work in progress. The\ndataset and related code are available at\nhttps://github.com/lorashen/Auto-SLURP/.", "published": "2025-04-25 14:17:47", "link": "http://arxiv.org/abs/2504.18373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review", "abstract": "Large Language Models (LLMs) have been transformative across many domains.\nHowever, hallucination -- confidently outputting incorrect information --\nremains one of the leading challenges for LLMs. This raises the question of how\nto accurately assess and quantify the uncertainty of LLMs. Extensive literature\non traditional models has explored Uncertainty Quantification (UQ) to measure\nuncertainty and employed calibration techniques to address the misalignment\nbetween uncertainty and accuracy. While some of these methods have been adapted\nfor LLMs, the literature lacks an in-depth analysis of their effectiveness and\ndoes not offer a comprehensive benchmark to enable insightful comparison among\nexisting solutions. In this work, we fill this gap via a systematic survey of\nrepresentative prior works on UQ and calibration for LLMs and introduce a\nrigorous benchmark. Using two widely used reliability datasets, we empirically\nevaluate six related methods, which justify the significant findings of our\nreview. Finally, we provide outlooks for key future directions and outline open\nchallenges. To the best of our knowledge, this survey is the first dedicated\nstudy to review the calibration methods and relevant metrics for LLMs.", "published": "2025-04-25 13:34:40", "link": "http://arxiv.org/abs/2504.18346v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adversarial Attacks on LLM-as-a-Judge Systems: Insights from Prompt Injections", "abstract": "LLM as judge systems used to assess text quality code correctness and\nargument strength are vulnerable to prompt injection attacks. We introduce a\nframework that separates content author attacks from system prompt attacks and\nevaluate five models Gemma 3.27B Gemma 3.4B Llama 3.2 3B GPT 4 and Claude 3\nOpus on four tasks with various defenses using fifty prompts per condition.\nAttacks achieved up to seventy three point eight percent success smaller models\nproved more vulnerable and transferability ranged from fifty point five to\nsixty two point six percent. Our results contrast with Universal Prompt\nInjection and AdvPrompter We recommend multi model committees and comparative\nscoring and release all code and datasets", "published": "2025-04-25 13:18:42", "link": "http://arxiv.org/abs/2504.18333v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "TextTIGER: Text-based Intelligent Generation with Entity Prompt Refinement for Text-to-Image Generation", "abstract": "Generating images from prompts containing specific entities requires models\nto retain as much entity-specific knowledge as possible. However, fully\nmemorizing such knowledge is impractical due to the vast number of entities and\ntheir continuous emergence. To address this, we propose Text-based Intelligent\nGeneration with Entity prompt Refinement (TextTIGER), which augments knowledge\non entities included in the prompts and then summarizes the augmented\ndescriptions using Large Language Models (LLMs) to mitigate performance\ndegradation from longer inputs. To evaluate our method, we introduce WiT-Cub\n(WiT with Captions and Uncomplicated Background-explanations), a dataset\ncomprising captions, images, and an entity list. Experiments on four image\ngeneration models and five LLMs show that TextTIGER improves image generation\nperformance in standard metrics (IS, FID, and CLIPScore) compared to\ncaption-only prompts. Additionally, multiple annotators' evaluation confirms\nthat the summarized descriptions are more informative, validating LLMs' ability\nto generate concise yet rich descriptions. These findings demonstrate that\nrefining prompts with augmented and summarized entity-related descriptions\nenhances image generation capabilities. The code and dataset will be available\nupon acceptance.", "published": "2025-04-25 11:27:44", "link": "http://arxiv.org/abs/2504.18269v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "MAGI: Multi-Agent Guided Interview for Psychiatric Assessment", "abstract": "Automating structured clinical interviews could revolutionize mental\nhealthcare accessibility, yet existing large language models (LLMs) approaches\nfail to align with psychiatric diagnostic protocols. We present MAGI, the first\nframework that transforms the gold-standard Mini International Neuropsychiatric\nInterview (MINI) into automatic computational workflows through coordinated\nmulti-agent collaboration. MAGI dynamically navigates clinical logic via four\nspecialized agents: 1) an interview tree guided navigation agent adhering to\nthe MINI's branching structure, 2) an adaptive question agent blending\ndiagnostic probing, explaining, and empathy, 3) a judgment agent validating\nwhether the response from participants meet the node, and 4) a diagnosis Agent\ngenerating Psychometric Chain-of- Thought (PsyCoT) traces that explicitly map\nsymptoms to clinical criteria. Experimental results on 1,002 real-world\nparticipants covering depression, generalized anxiety, social anxiety and\nsuicide shows that MAGI advances LLM- assisted mental health assessment by\ncombining clinical rigor, conversational adaptability, and explainable\nreasoning.", "published": "2025-04-25 11:08:27", "link": "http://arxiv.org/abs/2504.18260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Single-Pass Training for Multi-Turn Reasoning", "abstract": "Training Large Language Models ( LLMs) to generate explicit reasoning before\nthey produce an answer has been shown to improve their performance across\nvarious tasks such as mathematics and coding. However, fine-tuning LLMs on\nmulti-turn reasoning datasets presents a unique challenge: LLMs must generate\nreasoning tokens that are excluded from subsequent inputs to the LLM. This\ndiscrepancy prevents us from processing an entire conversation in a single\nforward pass-an optimization readily available when we fine-tune on a\nmulti-turn non-reasoning dataset. This paper proposes a novel approach that\novercomes this limitation through response token duplication and a custom\nattention mask that enforces appropriate visibility constraints. Our approach\nsignificantly reduces the training time and allows efficient fine-tuning on\nmulti-turn reasoning datasets.", "published": "2025-04-25 10:46:56", "link": "http://arxiv.org/abs/2504.18246v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family", "abstract": "We introduce a new generation of small reasoning models for RAG, search, and\nsource summarization. Pleias-RAG-350m and Pleias-RAG-1B are mid-trained on a\nlarge synthetic dataset emulating the retrieval of a wide variety of\nmultilingual open sources from the Common Corpus. They provide native support\nfor citation and grounding with literal quotes and reintegrate multiple\nfeatures associated with RAG workflows, such as query routing, query\nreformulation, and source reranking. Pleias-RAG-350m and Pleias-RAG-1B\noutperform SLMs below 4 billion parameters on standardized RAG benchmarks\n(HotPotQA, 2wiki) and are competitive with popular larger models, including\nQwen-2.5-7B, Llama-3.1-8B, and Gemma-3-4B. They are the only SLMs to date\nmaintaining consistent RAG performance across leading European languages and\nensuring systematic reference grounding for statements. Due to their size and\nease of deployment on constrained infrastructure and higher factuality by\ndesign, the models unlock a range of new use cases for generative AI.", "published": "2025-04-25 10:17:04", "link": "http://arxiv.org/abs/2504.18225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimising ChatGPT for creativity in literary translation: A case study from English into Dutch, Chinese, Catalan and Spanish", "abstract": "This study examines the variability of Chat-GPT machine translation (MT)\noutputs across six different configurations in four languages,with a focus on\ncreativity in a literary text. We evaluate GPT translations in different text\ngranularity levels, temperature settings and prompting strategies with a\nCreativity Score formula. We found that prompting ChatGPT with a minimal\ninstruction yields the best creative translations, with \"Translate the\nfollowing text into [TG] creatively\" at the temperature of 1.0 outperforming\nother configurations and DeepL in Spanish, Dutch, and Chinese. Nonetheless,\nChatGPT consistently underperforms compared to human translation (HT).", "published": "2025-04-25 10:11:15", "link": "http://arxiv.org/abs/2504.18221v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning Language Models for Icelandic Legal Text Summarization", "abstract": "The integration of language models in the legal domain holds considerable\npromise for streamlining processes and improving efficiency in managing\nextensive workloads. However, the specialized terminology, nuanced language,\nand formal style of legal texts can present substantial challenges. This study\nexamines whether preference-based training techniques, specifically\nReinforcement Learning from Human Feedback and Direct Preference Optimization,\ncan enhance models' performance in generating Icelandic legal summaries that\nalign with domain-specific language standards and user preferences. We compare\nmodels fine-tuned with preference training to those using conventional\nsupervised learning. Results indicate that preference training improves the\nlegal accuracy of generated summaries over standard fine-tuning but does not\nsignificantly enhance the overall quality of Icelandic language usage.\nDiscrepancies between automated metrics and human evaluations further\nunderscore the importance of qualitative assessment in developing language\nmodels for the legal domain.", "published": "2025-04-25 08:55:15", "link": "http://arxiv.org/abs/2504.18180v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa with X (formerly Twitter)", "abstract": "Named Entity Recognition (NER) plays a pivotal role in various Natural\nLanguage Processing (NLP) tasks by identifying and classifying named entities\n(NEs) from unstructured data into predefined categories such as person,\norganization, location, date, and time. While extensive research exists for\nhigh-resource languages and general domains, NER in Urdu particularly within\ndomain-specific contexts like education remains significantly underexplored.\nThis is Due to lack of annotated datasets for educational content which limits\nthe ability of existing models to accurately identify entities such as academic\nroles, course names, and institutional terms, underscoring the urgent need for\ntargeted resources in this domain. To the best of our knowledge, no dataset\nexists in the domain of the Urdu language for this purpose. To achieve this\nobjective this study makes three key contributions. Firstly, we created a\nmanually annotated dataset in the education domain, named EDU-NER-2025, which\ncontains 13 unique most important entities related to education domain. Second,\nwe describe our annotation process and guidelines in detail and discuss the\nchallenges of labelling EDU-NER-2025 dataset. Third, we addressed and analyzed\nkey linguistic challenges, such as morphological complexity and ambiguity,\nwhich are prevalent in formal Urdu texts.", "published": "2025-04-25 07:50:58", "link": "http://arxiv.org/abs/2504.18142v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Temporal Entailment Pretraining for Clinical Language Models over EHR Data", "abstract": "Clinical language models have achieved strong performance on downstream tasks\nby pretraining on domain specific corpora such as discharge summaries and\nmedical notes. However, most approaches treat the electronic health record as a\nstatic document, neglecting the temporally-evolving and causally entwined\nnature of patient trajectories. In this paper, we introduce a novel temporal\nentailment pretraining objective for language models in the clinical domain.\nOur method formulates EHR segments as temporally ordered sentence pairs and\ntrains the model to determine whether a later state is entailed by,\ncontradictory to, or neutral with respect to an earlier state. Through this\ntemporally structured pretraining task, models learn to perform latent clinical\nreasoning over time, improving their ability to generalize across forecasting\nand diagnosis tasks. We pretrain on a large corpus derived from MIMIC IV and\ndemonstrate state of the art results on temporal clinical QA, early warning\nprediction, and disease progression modeling.", "published": "2025-04-25 07:30:38", "link": "http://arxiv.org/abs/2504.18128v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection", "abstract": "Hallucinations pose a significant obstacle to the reliability and widespread\nadoption of language models, yet their accurate measurement remains a\npersistent challenge. While many task- and domain-specific metrics have been\nproposed to assess faithfulness and factuality concerns, the robustness and\ngeneralization of these metrics are still untested. In this paper, we conduct a\nlarge-scale empirical evaluation of 6 diverse sets of hallucination detection\nmetrics across 4 datasets, 37 language models from 5 families, and 5 decoding\nmethods. Our extensive investigation reveals concerning gaps in current\nhallucination evaluation: metrics often fail to align with human judgments,\ntake an overtly myopic view of the problem, and show inconsistent gains with\nparameter scaling. Encouragingly, LLM-based evaluation, particularly with\nGPT-4, yields the best overall results, and mode-seeking decoding methods seem\nto reduce hallucinations, especially in knowledge-grounded settings. These\nfindings underscore the need for more robust metrics to understand and quantify\nhallucinations, and better strategies to mitigate them.", "published": "2025-04-25 06:37:29", "link": "http://arxiv.org/abs/2504.18114v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparative Study on the Discourse Meaning of Chinese and English Media in the Paris Olympics Based on LDA Topic Modeling Technology and LLM Prompt Engineering", "abstract": "This study analyzes Chinese and English media reports on the Paris Olympics\nusing topic modeling, Large Language Model (LLM) prompt engineering, and corpus\nphraseology methods to explore similarities and differences in discourse\nconstruction and attitudinal meanings. Common topics include the opening\nceremony, athlete performance, and sponsorship brands. Chinese media focus on\nspecific sports, sports spirit, doping controversies, and new technologies,\nwhile English media focus on female athletes, medal wins, and eligibility\ncontroversies. Chinese reports show more frequent prepositional co-occurrences\nand positive semantic prosody in describing the opening ceremony and sports\nspirit. English reports exhibit positive semantic prosody when covering female\nathletes but negative prosody in predicting opening ceremony reactions and\ndiscussing women's boxing controversies.", "published": "2025-04-25 06:23:55", "link": "http://arxiv.org/abs/2504.18106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation", "abstract": "In response to the growing problem of misinformation in the context of\nglobalization and informatization, this paper proposes a classification method\nfor fact-check-worthiness estimation based on prompt tuning. We construct a\nmodel for fact-check-worthiness estimation at the methodological level using\nprompt tuning. By applying designed prompt templates to large language models,\nwe establish in-context learning and leverage prompt tuning technology to\nimprove the accuracy of determining whether claims have fact-check-worthiness,\nparticularly when dealing with limited or unlabeled data. Through extensive\nexperiments on public datasets, we demonstrate that the proposed method\nsurpasses or matches multiple baseline methods in the classification task of\nfact-check-worthiness estimation assessment, including classical pre-trained\nmodels such as BERT, as well as recent popular large models like GPT-3.5 and\nGPT-4. Experiments show that the prompt tuning-based method proposed in this\nstudy exhibits certain advantages in evaluation metrics such as F1 score and\naccuracy, thereby effectively validating its effectiveness and advancement in\nthe task of fact-check-worthiness estimation.", "published": "2025-04-25 06:16:41", "link": "http://arxiv.org/abs/2504.18104v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tracking Articulatory Dynamics in Speech with a Fixed-Weight BiLSTM-CNN Architecture", "abstract": "Speech production is a complex sequential process which involve the\ncoordination of various articulatory features. Among them tongue being a highly\nversatile active articulator responsible for shaping airflow to produce\ntargeted speech sounds that are intellectual, clear, and distinct. This paper\npresents a novel approach for predicting tongue and lip articulatory features\ninvolved in a given speech acoustics using a stacked Bidirectional Long\nShort-Term Memory (BiLSTM) architecture, combined with a one-dimensional\nConvolutional Neural Network (CNN) for post-processing with fixed weights\ninitialization. The proposed network is trained with two datasets consisting of\nsimultaneously recorded speech and Electromagnetic Articulography (EMA)\ndatasets, each introducing variations in terms of geographical origin,\nlinguistic characteristics, phonetic diversity, and recording equipment. The\nperformance of the model is assessed in Speaker Dependent (SD), Speaker\nIndependent (SI), corpus dependent (CD) and cross corpus (CC) modes.\nExperimental results indicate that the proposed model with fixed weights\napproach outperformed the adaptive weights initialization with in relatively\nminimal number of training epochs. These findings contribute to the development\nof robust and efficient models for articulatory feature prediction, paving the\nway for advancements in speech production research and applications.", "published": "2025-04-25 05:57:22", "link": "http://arxiv.org/abs/2504.18099v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Random-Set Large Language Models", "abstract": "Large Language Models (LLMs) are known to produce very high-quality tests and\nresponses to our queries. But how much can we trust this generated text? In\nthis paper, we study the problem of uncertainty quantification in LLMs. We\npropose a novel Random-Set Large Language Model (RSLLM) approach which predicts\nfinite random sets (belief functions) over the token space, rather than\nprobability vectors as in classical LLMs. In order to allow so efficiently, we\nalso present a methodology based on hierarchical clustering to extract and use\na budget of \"focal\" subsets of tokens upon which the belief prediction is\ndefined, rather than using all possible collections of tokens, making the\nmethod scalable yet effective. RS-LLMs encode the epistemic uncertainty induced\nin their generation process by the size and diversity of its training set via\nthe size of the credal sets associated with the predicted belief functions. The\nproposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,\nMistral-7b and Phi-2 models and is shown to outperform the standard model in\nboth datasets in terms of correctness of answer while also showing potential in\nestimating the second level uncertainty in its predictions and providing the\ncapability to detect when its hallucinating.", "published": "2025-04-25 05:25:27", "link": "http://arxiv.org/abs/2504.18085v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization", "abstract": "Large Language Models (LLMs) show potential in medicine, yet clinical\nadoption is hindered by concerns over factual accuracy, language-specific\nlimitations (e.g., Japanese), and critically, their reliability when required\nto generate reasoning explanations -- a prerequisite for trust. This paper\nintroduces Preferred-MedLLM-Qwen-72B, a 72B-parameter model optimized for the\nJapanese medical domain to achieve both high accuracy and stable reasoning. We\nemploy a two-stage fine-tuning process on the Qwen2.5-72B base model: first,\nContinued Pretraining (CPT) on a comprehensive Japanese medical corpus instills\ndeep domain knowledge. Second, Reasoning Preference Optimization (RPO), a\npreference-based method, enhances the generation of reliable reasoning pathways\nwhile preserving high answer accuracy. Evaluations on the Japanese Medical\nLicensing Exam benchmark (IgakuQA) show Preferred-MedLLM-Qwen-72B achieves\nstate-of-the-art performance (0.868 accuracy), surpassing strong proprietary\nmodels like GPT-4o (0.866). Crucially, unlike baseline or CPT-only models which\nexhibit significant accuracy degradation (up to 11.5\\% and 3.8\\% respectively\non IgakuQA) when prompted for explanations, our model maintains its high\naccuracy (0.868) under such conditions. This highlights RPO's effectiveness in\nstabilizing reasoning generation. This work underscores the importance of\noptimizing for reliable explanations alongside accuracy. We release the\nPreferred-MedLLM-Qwen-72B model weights to foster research into trustworthy\nLLMs for specialized, high-stakes applications.", "published": "2025-04-25 05:15:31", "link": "http://arxiv.org/abs/2504.18080v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths", "abstract": "Retrieval Augmented Generation (RAG) has become the standard non-parametric\napproach for equipping Large Language Models (LLMs) with up-to-date knowledge\nand mitigating catastrophic forgetting common in continual learning. However,\nstandard RAG, relying on independent passage retrieval, fails to capture the\ninterconnected nature of human memory crucial for complex reasoning\n(associativity) and contextual understanding (sense-making). While structured\nRAG methods like HippoRAG utilize knowledge graphs (KGs) built from triples,\nthe inherent context loss limits fidelity. We introduce PropRAG, a framework\nleveraging contextually rich propositions and a novel beam search algorithm\nover proposition paths to explicitly discover multi-step reasoning chains.\nCrucially, PropRAG's online retrieval process operates entirely without\ninvoking generative LLMs, relying instead on efficient graph traversal and\npre-computed embeddings. This avoids online LLM inference costs and potential\ninconsistencies during evidence gathering. LLMs are used effectively offline\nfor high-quality proposition extraction and post-retrieval for answer\ngeneration. PropRAG achieves state-of-the-art zero-shot Recall@5 results on\nPopQA (55.3%), 2Wiki (93.7%), HotpotQA (97.0%), and MuSiQue (77.3%), alongside\ntop F1 scores (e.g., 52.4% on MuSiQue). By improving evidence retrieval through\nricher representation and explicit, LLM-free online path finding, PropRAG\nadvances non-parametric continual learning.", "published": "2025-04-25 04:47:34", "link": "http://arxiv.org/abs/2504.18070v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Personality-Aware Interactions in Salesperson Dialogue Agents", "abstract": "The integration of dialogue agents into the sales domain requires a deep\nunderstanding of how these systems interact with users possessing diverse\npersonas. This study explores the influence of user personas, defined using the\nMyers-Briggs Type Indicator (MBTI), on the interaction quality and performance\nof sales-oriented dialogue agents. Through large-scale testing and analysis, we\nassess the pre-trained agent's effectiveness, adaptability, and personalization\ncapabilities across a wide range of MBTI-defined user types. Our findings\nreveal significant patterns in interaction dynamics, task completion rates, and\ndialogue naturalness, underscoring the future potential for dialogue agents to\nrefine their strategies to better align with varying personality traits. This\nwork not only provides actionable insights for building more adaptive and\nuser-centric conversational systems in the sales domain but also contributes\nbroadly to the field by releasing persona-defined user simulators. These\nsimulators, unconstrained by domain, offer valuable tools for future research\nand demonstrate the potential for scaling personalized dialogue systems across\ndiverse applications.", "published": "2025-04-25 04:10:25", "link": "http://arxiv.org/abs/2504.18058v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DREAM: Disentangling Risks to Enhance Safety Alignment in Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) pose unique safety challenges due to\ntheir integration of visual and textual data, thereby introducing new\ndimensions of potential attacks and complex risk combinations. In this paper,\nwe begin with a detailed analysis aimed at disentangling risks through\nstep-by-step reasoning within multimodal inputs. We find that systematic\nmultimodal risk disentanglement substantially enhances the risk awareness of\nMLLMs. Via leveraging the strong discriminative abilities of multimodal risk\ndisentanglement, we further introduce \\textbf{DREAM}\n(\\textit{\\textbf{D}isentangling \\textbf{R}isks to \\textbf{E}nhance Safety\n\\textbf{A}lignment in \\textbf{M}LLMs}), a novel approach that enhances safety\nalignment in MLLMs through supervised fine-tuning and iterative Reinforcement\nLearning from AI Feedback (RLAIF). Experimental results show that DREAM\nsignificantly boosts safety during both inference and training phases without\ncompromising performance on normal tasks (namely oversafety), achieving a\n16.17\\% improvement in the SIUO safe\\&effective score compared to GPT-4V. The\ndata and code are available at https://github.com/Kizna1ver/DREAM.", "published": "2025-04-25 03:54:24", "link": "http://arxiv.org/abs/2504.18053v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models", "abstract": "Efforts to ensure the safety of large language models (LLMs) include safety\nfine-tuning, evaluation, and red teaming. However, despite the widespread use\nof the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses\non standard LLMs, which means we know little about how RAG use cases change a\nmodel's safety profile. We conduct a detailed comparative analysis of RAG and\nnon-RAG frameworks with eleven LLMs. We find that RAG can make models less safe\nand change their safety profile. We explore the causes of this change and find\nthat even combinations of safe models with safe documents can cause unsafe\ngenerations. In addition, we evaluate some existing red teaming methods for RAG\nsettings and show that they are less effective than when used for non-RAG\nsettings. Our work highlights the need for safety research and red-teaming\nmethods specifically tailored for RAG LLMs.", "published": "2025-04-25 03:25:18", "link": "http://arxiv.org/abs/2504.18041v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SMARTFinRAG: Interactive Modularized Financial RAG Benchmark", "abstract": "Financial sectors are rapidly adopting language model technologies, yet\nevaluating specialized RAG systems in this domain remains challenging. This\npaper introduces SMARTFinRAG, addressing three critical gaps in financial RAG\nassessment: (1) a fully modular architecture where components can be\ndynamically interchanged during runtime; (2) a document-centric evaluation\nparadigm generating domain-specific QA pairs from newly ingested financial\ndocuments; and (3) an intuitive interface bridging research-implementation\ndivides. Our evaluation quantifies both retrieval efficacy and response\nquality, revealing significant performance variations across configurations.\nThe platform's open-source architecture supports transparent, reproducible\nresearch while addressing practical deployment challenges faced by financial\ninstitutions implementing RAG systems.", "published": "2025-04-25 02:29:56", "link": "http://arxiv.org/abs/2504.18024v1", "categories": ["cs.CE", "cs.CL", "cs.IR"], "primary_category": "cs.CE"}
{"title": "Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation", "abstract": "Multimodal Machine Translation (MMT) aims to improve translation quality by\nleveraging auxiliary modalities such as images alongside textual input. While\nrecent advances in large-scale pre-trained language and vision models have\nsignificantly benefited unimodal natural language processing tasks, their\neffectiveness and role in MMT remain underexplored. In this work, we conduct a\nsystematic study on the impact of pre-trained encoders and decoders in\nmultimodal translation models. Specifically, we analyze how different training\nstrategies, from training from scratch to using pre-trained and partially\nfrozen components, affect translation performance under a unified MMT\nframework. Experiments are carried out on the Multi30K and CoMMuTE dataset\nacross English-German and English-French translation tasks. Our results reveal\nthat pre-training plays a crucial yet asymmetrical role in multimodal settings:\npre-trained decoders consistently yield more fluent and accurate outputs, while\npre-trained encoders show varied effects depending on the quality of\nvisual-text alignment. Furthermore, we provide insights into the interplay\nbetween modality fusion and pre-trained components, offering guidance for\nfuture architecture design in multimodal translation systems.", "published": "2025-04-25 01:44:04", "link": "http://arxiv.org/abs/2504.18012v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving LLM Personas via Rationalization with Psychological Scaffolds", "abstract": "Language models prompted with a user description or persona can predict a\nuser's preferences and opinions, but existing approaches to building personas\n-- based solely on a user's demographic attributes and/or prior judgments --\nfail to capture the underlying reasoning behind said user judgments. We\nintroduce PB&J (Psychology of Behavior and Judgments), a framework that\nimproves LLM personas by incorporating rationales of why a user might make\nspecific judgments. These rationales are LLM-generated, and aim to reason about\na user's behavior on the basis of their experiences, personality traits or\nbeliefs. This is done using psychological scaffolds -- structured frameworks\ngrounded in theories such as the Big 5 Personality Traits and Primal World\nBeliefs -- that help provide structure to the generated rationales. Experiments\non public opinion and movie preference prediction tasks demonstrate that LLM\npersonas augmented with PB&J rationales consistently outperform methods using\nonly a user's demographics and/or judgments. Additionally, LLM personas\nconstructed using scaffolds describing user beliefs perform competitively with\nthose using human-written rationales.", "published": "2025-04-25 00:36:39", "link": "http://arxiv.org/abs/2504.17993v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalization Capability for Imitation Learning", "abstract": "Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input.", "published": "2025-04-25 17:59:59", "link": "http://arxiv.org/abs/2504.18538v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Adapting Probabilistic Risk Assessment for AI", "abstract": "Modern general-purpose artificial intelligence (AI) systems present an urgent\nrisk management challenge, as their rapidly evolving capabilities and potential\nfor catastrophic harm outpace our ability to reliably assess their risks.\nCurrent methods often rely on selective testing and undocumented assumptions\nabout risk priorities, frequently failing to make a serious attempt at\nassessing the set of pathways through which Al systems pose direct or indirect\nrisks to society and the biosphere. This paper introduces the probabilistic\nrisk assessment (PRA) for AI framework, adapting established PRA techniques\nfrom high-reliability industries (e.g., nuclear power, aerospace) for the new\nchallenges of advanced AI. The framework guides assessors in identifying\npotential risks, estimating likelihood and severity, and explicitly documenting\nevidence, underlying assumptions, and analyses at appropriate granularities.\nThe framework's implementation tool synthesizes the results into a risk report\ncard with aggregated risk estimates from all assessed risks. This systematic\napproach integrates three advances: (1) Aspect-oriented hazard analysis\nprovides systematic hazard coverage guided by a first-principles taxonomy of AI\nsystem aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk\npathway modeling analyzes causal chains from system aspects to societal impacts\nusing bidirectional analysis and incorporating prospective techniques; and (3)\nUncertainty management employs scenario decomposition, reference scales, and\nexplicit tracing protocols to structure credible projections with novelty or\nlimited data. Additionally, the framework harmonizes diverse assessment methods\nby integrating evidence into comparable, quantified absolute risk estimates for\ncritical decisions. We have implemented this as a workbook tool for AI\ndevelopers, evaluators, and regulators, available on the project website.", "published": "2025-04-25 17:59:14", "link": "http://arxiv.org/abs/2504.18536v1", "categories": ["cs.AI", "cs.CY", "cs.LG", "cs.SY", "eess.SY", "stat.AP"], "primary_category": "cs.AI"}
{"title": "Scaling Laws For Scalable Oversight", "abstract": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific and\ndeception-specific Elo scores that are a piecewise-linear function of their\ngeneral intelligence, with two plateaus corresponding to task incompetence and\ntask saturation. We validate our framework with a modified version of the game\nNim and then apply it to four oversight games: \"Mafia\", \"Debate\", \"Backdoor\nCode\" and \"Wargames\". For each game, we find scaling laws that approximate how\ndomain performance depends on general AI system capability (using Chatbot Arena\nElo as a proxy for general capability). We then build on our findings in a\ntheoretical study of Nested Scalable Oversight (NSO), a process in which\ntrusted models oversee untrusted stronger models, which then become the trusted\nmodels in the next step. We identify conditions under which NSO succeeds and\nderive numerically (and in some cases analytically) the optimal number of\noversight levels to maximize the probability of oversight success. In our\nnumerical examples, the NSO success rate is below 52% when overseeing systems\nthat are 400 Elo points stronger than the baseline overseer, and it declines\nfurther for overseeing even stronger systems.", "published": "2025-04-25 17:54:27", "link": "http://arxiv.org/abs/2504.18530v1", "categories": ["cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate Statistics", "abstract": "Empirical inference attacks are a popular approach for evaluating the privacy\nrisk of data release mechanisms in practice. While an active attack literature\nexists to evaluate machine learning models or synthetic data release, we\ncurrently lack comparable methods for fixed aggregate statistics, in particular\nwhen only a limited number of statistics are released. We here propose an\ninference attack framework against fixed aggregate statistics and an attribute\ninference attack called DeSIA. We instantiate DeSIA against the U.S. Census\nPPMF dataset and show it to strongly outperform reconstruction-based attacks.\nIn particular, we show DeSIA to be highly effective at identifying vulnerable\nusers, achieving a true positive rate of 0.14 at a false positive rate of\n$10^{-3}$. We then show DeSIA to perform well against users whose attributes\ncannot be verified and when varying the number of aggregate statistics and\nlevel of noise addition. We also perform an extensive ablation study of DeSIA\nand show how DeSIA can be successfully adapted to the membership inference\ntask. Overall, our results show that aggregation alone is not sufficient to\nprotect privacy, even when a relatively small number of aggregates are being\nreleased, and emphasize the need for formal privacy mechanisms and testing\nbefore aggregate statistics are released.", "published": "2025-04-25 17:10:33", "link": "http://arxiv.org/abs/2504.18497v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Action Flow Matching for Continual Robot Learning", "abstract": "Continual learning in robotics seeks systems that can constantly adapt to\nchanging environments and tasks, mirroring human adaptability. A key challenge\nis refining dynamics models, essential for planning and control, while\naddressing issues such as safe adaptation, catastrophic forgetting, outlier\nmanagement, data efficiency, and balancing exploration with exploitation -- all\nwithin task and onboard resource constraints. Towards this goal, we introduce a\ngenerative framework leveraging flow matching for online robot dynamics model\nalignment. Rather than executing actions based on a misaligned model, our\napproach refines planned actions to better match with those the robot would\ntake if its model was well aligned. We find that by transforming the actions\nthemselves rather than exploring with a misaligned model -- as is traditionally\ndone -- the robot collects informative data more efficiently, thereby\naccelerating learning. Moreover, we validate that the method can handle an\nevolving and possibly imperfect model while reducing, if desired, the\ndependency on replay buffers or legacy model snapshots. We validate our\napproach using two platforms: an unmanned ground vehicle and a quadrotor. The\nresults highlight the method's adaptability and efficiency, with a record\n34.2\\% higher task success rate, demonstrating its potential towards enabling\ncontinual robot learning. Code:\nhttps://github.com/AlejandroMllo/action_flow_matching.", "published": "2025-04-25 16:26:15", "link": "http://arxiv.org/abs/2504.18471v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Iterative Event-based Motion Segmentation by Variational Contrast Maximization", "abstract": "Event cameras provide rich signals that are suitable for motion estimation\nsince they respond to changes in the scene. As any visual changes in the scene\nproduce event data, it is paramount to classify the data into different motions\n(i.e., motion segmentation), which is useful for various tasks such as object\ndetection and visual servoing. We propose an iterative motion segmentation\nmethod, by classifying events into background (e.g., dominant motion\nhypothesis) and foreground (independent motion residuals), thus extending the\nContrast Maximization framework. Experimental results demonstrate that the\nproposed method successfully classifies event clusters both for public and\nself-recorded datasets, producing sharp, motion-compensated edge-like images.\nThe proposed method achieves state-of-the-art accuracy on moving object\ndetection benchmarks with an improvement of over 30%, and demonstrates its\npossibility of applying to more complex and noisy real-world scenes. We hope\nthis work broadens the sensitivity of Contrast Maximization with respect to\nboth motion parameters and input events, thus contributing to theoretical\nadvancements in event-based motion segmentation estimation.\nhttps://github.com/aoki-media-lab/event_based_segmentation_vcmax", "published": "2025-04-25 16:00:23", "link": "http://arxiv.org/abs/2504.18447v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Pseudo-Boolean Proof Logging for Optimal Classical Planning", "abstract": "We introduce lower-bound certificates for classical planning tasks, which can\nbe used to prove the unsolvability of a task or the optimality of a plan in a\nway that can be verified by an independent third party. We describe a general\nframework for generating lower-bound certificates based on pseudo-Boolean\nconstraints, which is agnostic to the planning algorithm used.\n  As a case study, we show how to modify the $A^{*}$ algorithm to produce\nproofs of optimality with modest overhead, using pattern database heuristics\nand $h^\\textit{max}$ as concrete examples. The same proof logging approach\nworks for any heuristic whose inferences can be efficiently expressed as\nreasoning over pseudo-Boolean constraints.", "published": "2025-04-25 15:54:09", "link": "http://arxiv.org/abs/2504.18443v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing Pre-Trained Model-Based Class-Incremental Learning through Neural Collapse", "abstract": "Class-Incremental Learning (CIL) is a critical capability for real-world\napplications, enabling learning systems to adapt to new tasks while retaining\nknowledge from previous ones. Recent advancements in pre-trained models (PTMs)\nhave significantly advanced the field of CIL, demonstrating superior\nperformance over traditional methods. However, understanding how features\nevolve and are distributed across incremental tasks remains an open challenge.\nIn this paper, we propose a novel approach to modeling feature evolution in\nPTM-based CIL through the lens of neural collapse (NC), a striking phenomenon\nobserved in the final phase of training, which leads to a well-separated,\nequiangular feature space. We explore the connection between NC and CIL\neffectiveness, showing that aligning feature distributions with the NC geometry\nenhances the ability to capture the dynamic behavior of continual learning.\nBased on this insight, we introduce Neural Collapse-inspired Pre-Trained\nModel-based CIL (NCPTM-CIL), a method that dynamically adjusts the feature\nspace to conform to the elegant NC structure, thereby enhancing the continual\nlearning process. Extensive experiments demonstrate that NCPTM-CIL outperforms\nstate-of-the-art methods across four benchmark datasets. Notably, when\ninitialized with ViT-B/16-IN1K, NCPTM-CIL surpasses the runner-up method by\n6.73% on VTAB, 1.25% on CIFAR-100, and 2.5% on OmniBenchmark.", "published": "2025-04-25 15:48:41", "link": "http://arxiv.org/abs/2504.18437v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection", "abstract": "Despite the transformative impact of Artificial Intelligence (AI) across\nvarious sectors, cyber security continues to rely on traditional static and\ndynamic analysis tools, hampered by high false positive rates and superficial\ncode comprehension. While generative AI offers promising automation\ncapabilities for software development, leveraging Large Language Models (LLMs)\nfor vulnerability detection presents unique challenges. This paper explores the\npotential and limitations of LLMs in identifying vulnerabilities, acknowledging\ninherent weaknesses such as hallucinations, limited context length, and\nknowledge cut-offs. Previous attempts employing machine learning models for\nvulnerability detection have proven ineffective due to limited real-world\napplicability, feature engineering challenges, lack of contextual\nunderstanding, and the complexities of training models to keep pace with the\nevolving threat landscape. Therefore, we propose a robust AI-driven approach\nfocused on mitigating these limitations and ensuring the quality and\nreliability of LLM based vulnerability detection. Through innovative\nmethodologies combining Retrieval-Augmented Generation (RAG) and\nMixtureof-Agents (MoA), this research seeks to leverage the strengths of LLMs\nwhile addressing their weaknesses, ultimately paving the way for dependable and\nefficient AI-powered solutions in securing the ever-evolving software\nlandscape.", "published": "2025-04-25 15:30:40", "link": "http://arxiv.org/abs/2504.18423v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection", "abstract": "We present a new way to detect 3D objects from multimodal inputs, leveraging\nboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines an\nRGB detection network and a 3D LiDAR detector. We exploit late fusion\nprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGB\nones by projecting the LiDAR bounding boxes on the image. We rely on cascade\nfusion principles to recover LiDAR False Negatives leveraging epipolar\nconstraints and frustums generated by RGB detections of separate views. Our\nsolution can be plugged on top of any underlying single-modal detectors,\nenabling a flexible training process that can take advantage of pre-trained\nLiDAR and RGB detectors, or train the two branches separately. We evaluate our\nresults on the KITTI object detection benchmark, showing significant\nperformance improvements, especially for the detection of Pedestrians and\nCyclists.", "published": "2025-04-25 15:28:53", "link": "http://arxiv.org/abs/2504.18419v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Paradigm shift on Coding Productivity Using GenAI", "abstract": "Generative AI (GenAI) applications are transforming software engineering by\nenabling automated code co-creation. However, empirical evidence on GenAI's\nproductivity effects in industrial settings remains limited. This paper\ninvestigates the adoption of GenAI coding assistants (e.g., Codeium, Amazon Q)\nwithin telecommunications and FinTech domains. Through surveys and interviews\nwith industrial domain-experts, we identify primary productivity-influencing\nfactors, including task complexity, coding skills, domain knowledge, and GenAI\nintegration. Our findings indicate that GenAI tools enhance productivity in\nroutine coding tasks (e.g., refactoring and Javadoc generation) but face\nchallenges in complex, domain-specific activities due to limited\ncontext-awareness of codebases and insufficient support for customized design\nrules. We highlight new paradigms for coding transfer, emphasizing iterative\nprompt refinement, immersive development environment, and automated code\nevaluation as essential for effective GenAI usage.", "published": "2025-04-25 15:00:06", "link": "http://arxiv.org/abs/2504.18404v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography", "abstract": "Shape measures have emerged as promising descriptors of white matter\ntractography, offering complementary insights into anatomical variability and\nassociations with cognitive and clinical phenotypes. However, conventional\nmethods for computing shape measures are computationally expensive and\ntime-consuming for large-scale datasets due to reliance on voxel-based\nrepresentations. We propose Tract2Shape, a novel multimodal deep learning\nframework that leverages geometric (point cloud) and scalar (tabular) features\nto predict ten white matter tractography shape measures. To enhance model\nefficiency, we utilize a dimensionality reduction algorithm for the model to\npredict five primary shape components. The model is trained and evaluated on\ntwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.\nWe evaluate the performance of Tract2Shape by training and testing it on the\nHCP-YA dataset and comparing the results with state-of-the-art models. To\nfurther assess its robustness and generalization ability, we also test\nTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep\nlearning models across all ten shape measures, achieving the highest average\nPearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows\nthat both multimodal input and PCA contribute to performance gains. On the\nunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low\nnMSE, demonstrating strong generalizability in cross-dataset evaluation.\nTract2Shape enables fast, accurate, and generalizable prediction of white\nmatter shape measures from tractography data, supporting scalable analysis\nacross datasets. This framework lays a promising foundation for future\nlarge-scale white matter shape analysis.", "published": "2025-04-25 14:54:47", "link": "http://arxiv.org/abs/2504.18400v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation", "abstract": "Cross-domain Sequential Recommendation (CDSR) aims to extract the preference\nfrom the user's historical interactions across various domains. Despite some\nprogress in CDSR, two problems set the barrier for further advancements, i.e.,\noverlap dilemma and transition complexity. The former means existing CDSR\nmethods severely rely on users who own interactions on all domains to learn\ncross-domain item relationships, compromising the practicability. The latter\nrefers to the difficulties in learning the complex transition patterns from the\nmixed behavior sequences. With powerful representation and reasoning abilities,\nLarge Language Models (LLMs) are promising to address these two problems by\nbridging the items and capturing the user's preferences from a semantic view.\nTherefore, we propose an LLMs Enhanced Cross-domain Sequential Recommendation\nmodel (LLM4CDSR). To obtain the semantic item relationships, we first propose\nan LLM-based unified representation module to represent items. Then, a\ntrainable adapter with contrastive regularization is designed to adapt the CDSR\ntask. Besides, a hierarchical LLMs profiling module is designed to summarize\nuser cross-domain preferences. Finally, these two modules are integrated into\nthe proposed tri-thread framework to derive recommendations. We have conducted\nextensive experiments on three public cross-domain datasets, validating the\neffectiveness of LLM4CDSR. We have released the code online.", "published": "2025-04-25 14:30:25", "link": "http://arxiv.org/abs/2504.18383v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Spatial Reasoner: A 3D Inference Pipeline for XR Applications", "abstract": "Modern extended reality XR systems provide rich analysis of image data and\nfusion of sensor input and demand AR/VR applications that can reason about 3D\nscenes in a semantic manner. We present a spatial reasoning framework that\nbridges geometric facts with symbolic predicates and relations to handle key\ntasks such as determining how 3D objects are arranged among each other ('on',\n'behind', 'near', etc.). Its foundation relies on oriented 3D bounding box\nrepresentations, enhanced by a comprehensive set of spatial predicates, ranging\nfrom topology and connectivity to directionality and orientation, expressed in\na formalism related to natural language. The derived predicates form a spatial\nknowledge graph and, in combination with a pipeline-based inference model,\nenable spatial queries and dynamic rule evaluation. Implementations for client-\nand server-side processing demonstrate the framework's capability to\nefficiently translate geometric data into actionable knowledge, ensuring\nscalable and technology-independent spatial reasoning in complex 3D\nenvironments. The Spatial Reasoner framework is fostering the creation of\nspatial ontologies, and seamlessly integrates with and therefore enriches\nmachine learning, natural language processing, and rule systems in XR\napplications.", "published": "2025-04-25 14:27:27", "link": "http://arxiv.org/abs/2504.18380v1", "categories": ["cs.SE", "cs.AI", "cs.GR", "cs.HC", "spatial computing, extended reality, knowledge representation,\n  spatial reasoning"], "primary_category": "cs.SE"}
{"title": "COCO-Inpaint: A Benchmark for Image Inpainting Detection and Manipulation Localization", "abstract": "Recent advancements in image manipulation have achieved unprecedented\nprogress in generating photorealistic content, but also simultaneously\neliminating barriers to arbitrary manipulation and editing, raising concerns\nabout multimedia authenticity and cybersecurity. However, existing Image\nManipulation Detection and Localization (IMDL) methodologies predominantly\nfocus on splicing or copy-move forgeries, lacking dedicated benchmarks for\ninpainting-based manipulations. To bridge this gap, we present COCOInpaint, a\ncomprehensive benchmark specifically designed for inpainting detection, with\nthree key contributions: 1) High-quality inpainting samples generated by six\nstate-of-the-art inpainting models, 2) Diverse generation scenarios enabled by\nfour mask generation strategies with optional text guidance, and 3) Large-scale\ncoverage with 258,266 inpainted images with rich semantic diversity. Our\nbenchmark is constructed to emphasize intrinsic inconsistencies between\ninpainted and authentic regions, rather than superficial semantic artifacts\nsuch as object shapes. We establish a rigorous evaluation protocol using three\nstandard metrics to assess existing IMDL approaches. The dataset will be made\npublicly available to facilitate future research in this area.", "published": "2025-04-25 14:04:36", "link": "http://arxiv.org/abs/2504.18361v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Testing Individual Fairness in Graph Neural Networks", "abstract": "The biases in artificial intelligence (AI) models can lead to automated\ndecision-making processes that discriminate against groups and/or individuals\nbased on sensitive properties such as gender and race. While there are many\nstudies on diagnosing and mitigating biases in various AI models, there is\nlittle research on individual fairness in Graph Neural Networks (GNNs). Unlike\ntraditional models, which treat data features independently and overlook their\ninter-relationships, GNNs are designed to capture graph-based structure where\nnodes are interconnected. This relational approach enables GNNs to model\ncomplex dependencies, but it also means that biases can propagate through these\nconnections, complicating the detection and mitigation of individual fairness\nviolations. This PhD project aims to develop a testing framework to assess and\nensure individual fairness in GNNs. It first systematically reviews the\nliterature on individual fairness, categorizing existing approaches to define,\nmeasure, test, and mitigate model biases, creating a taxonomy of individual\nfairness. Next, the project will develop a framework for testing and ensuring\nfairness in GNNs by adapting and extending current fairness testing and\nmitigation techniques. The framework will be evaluated through industrial case\nstudies, focusing on graph-based large language models.", "published": "2025-04-25 13:45:24", "link": "http://arxiv.org/abs/2504.18353v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TSCL:Multi-party loss Balancing scheme for deep learning Image steganography based on Curriculum learning", "abstract": "For deep learning-based image steganography frameworks, in order to ensure\nthe invisibility and recoverability of the information embedding, the loss\nfunction usually contains several losses such as embedding loss, recovery loss\nand steganalysis loss. In previous research works, fixed loss weights are\nusually chosen for training optimization, and this setting is not linked to the\nimportance of the steganography task itself and the training process. In this\npaper, we propose a Two-stage Curriculum Learning loss scheduler (TSCL) for\nbalancing multinomial losses in deep learning image steganography algorithms.\nTSCL consists of two phases: a priori curriculum control and loss dynamics\ncontrol. The first phase firstly focuses the model on learning the information\nembedding of the original image by controlling the loss weights in the\nmulti-party adversarial training; secondly, it makes the model shift its\nlearning focus to improving the decoding accuracy; and finally, it makes the\nmodel learn to generate a steganographic image that is resistant to\nsteganalysis. In the second stage, the learning speed of each training task is\nevaluated by calculating the loss drop of the before and after iteration rounds\nto balance the learning of each task. Experimental results on three large\npublic datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed TSCL\nstrategy improves the quality of steganography, decoding accuracy and security.", "published": "2025-04-25 13:36:50", "link": "http://arxiv.org/abs/2504.18348v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "PHEATPRUNER: Interpretable Data-centric Feature Selection for Multivariate Time Series Classification through Persistent Homology", "abstract": "Balancing performance and interpretability in multivariate time series\nclassification is a significant challenge due to data complexity and high\ndimensionality. This paper introduces PHeatPruner, a method integrating\npersistent homology and sheaf theory to address these challenges. Persistent\nhomology facilitates the pruning of up to 45% of the applied variables while\nmaintaining or enhancing the accuracy of models such as Random Forest,\nCatBoost, XGBoost, and LightGBM, all without depending on posterior\nprobabilities or supervised optimization algorithms. Concurrently, sheaf theory\ncontributes explanatory vectors that provide deeper insights into the data's\nstructural nuances. The approach was validated using the UEA Archive and a\nmastitis detection dataset for dairy cows. The results demonstrate that\nPHeatPruner effectively preserves model accuracy. Furthermore, our results\nhighlight PHeatPruner's key features, i.e. simplifying complex data and\noffering actionable insights without increasing processing time or complexity.\nThis method bridges the gap between complexity reduction and interpretability,\nsuggesting promising applications in various fields.", "published": "2025-04-25 13:14:11", "link": "http://arxiv.org/abs/2504.18329v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Adaptive Software Agents for Debugging", "abstract": "Using multiple agents was found to improve the debugging capabilities of\nLarge Language Models. However, increasing the number of LLM-agents has several\ndrawbacks such as increasing the running costs and rising the risk for the\nagents to lose focus. In this work, we propose an adaptive agentic design,\nwhere the number of agents and their roles are determined dynamically based on\nthe characteristics of the task to be achieved. In this design, the agents\nroles are not predefined, but are generated after analyzing the problem to be\nsolved. Our initial evaluation shows that, with the adaptive design, the number\nof agents that are generated depends on the complexity of the buggy code. In\nfact, for simple code with mere syntax issues, the problem was usually fixed\nusing one agent only. However, for more complex problems, we noticed the\ncreation of a higher number of agents. Regarding the effectiveness of the fix,\nwe noticed an average improvement of 11% compared to the one-shot prompting.\nGiven these promising results, we outline future research directions to improve\nour design for adaptive software agents that can autonomously plan and conduct\ntheir software goals.", "published": "2025-04-25 12:48:08", "link": "http://arxiv.org/abs/2504.18316v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Artificial Intelligence health advice accuracy varies across languages and contexts", "abstract": "Using basic health statements authorized by UK and EU registers and 9,100\njournalist-vetted public-health assertions on topics such as abortion, COVID-19\nand politics from sources ranging from peer-reviewed journals and government\nadvisories to social media and news across the political spectrum, we benchmark\nsix leading large language models from in 21 languages, finding that, despite\nhigh accuracy on English-centric textbook claims, performance falls in multiple\nnon-European languages and fluctuates by topic and source, highlighting the\nurgency of comprehensive multilingual, domain-aware validation before deploying\nAI in global health communication.", "published": "2025-04-25 12:37:15", "link": "http://arxiv.org/abs/2504.18310v1", "categories": ["econ.GN", "cs.AI", "cs.CY", "cs.HC", "cs.LG", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Enhancing Long-Term Re-Identification Robustness Using Synthetic Data: A Comparative Analysis", "abstract": "This contribution explores the impact of synthetic training data usage and\nthe prediction of material wear and aging in the context of re-identification.\nDifferent experimental setups and gallery set expanding strategies are tested,\nanalyzing their impact on performance over time for aging re-identification\nsubjects. Using a continuously updating gallery, we were able to increase our\nmean Rank-1 accuracy by 24%, as material aging was taken into account step by\nstep. In addition, using models trained with 10% artificial training data,\nRank-1 accuracy could be increased by up to 13%, in comparison to a model\ntrained on only real-world data, significantly boosting generalized performance\non hold-out data. Finally, this work introduces a novel, open-source\nre-identification dataset, pallet-block-2696. This dataset contains 2,696\nimages of Euro pallets, taken over a period of 4 months. During this time,\nnatural aging processes occurred and some of the pallets were damaged during\ntheir usage. These wear and tear processes significantly changed the appearance\nof the pallets, providing a dataset that can be used to generate synthetically\naged pallets or other wooden materials.", "published": "2025-04-25 11:57:11", "link": "http://arxiv.org/abs/2504.18286v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.10; I.4.9"], "primary_category": "cs.CV"}
{"title": "Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator", "abstract": "Recent audio-visual generative models have made substantial progress in\ngenerating images from audio. However, existing approaches focus on generating\nimages from single-class audio and fail to generate images from mixed audio. To\naddress this, we propose an Audio-Visual Generation and Separation model\n(AV-GAS) for generating images from soundscapes (mixed audio containing\nmultiple classes). Our contribution is threefold: First, we propose a new\nchallenge in the audio-visual generation task, which is to generate an image\ngiven a multi-class audio input, and we propose a method that solves this task\nusing an audio-visual separator. Second, we introduce a new audio-visual\nseparation task, which involves generating separate images for each class\npresent in a mixed audio input. Lastly, we propose new evaluation metrics for\nthe audio-visual generation task: Class Representation Score (CRS) and a\nmodified R@K. Our model is trained and evaluated on the VGGSound dataset. We\nshow that our method outperforms the state-of-the-art, achieving 7% higher CRS\nand 4% higher R@2* in generating plausible images with mixed audio.", "published": "2025-04-25 11:51:04", "link": "http://arxiv.org/abs/2504.18283v1", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "LEAM: A Prompt-only Large Language Model-enabled Antenna Modeling Method", "abstract": "Antenna modeling is a time-consuming and complex process, decreasing the\nspeed of antenna analysis and design. In this paper, a large language model\n(LLM)- enabled antenna modeling method, called LEAM, is presented to address\nthis challenge. LEAM enables automatic antenna model generation based on\nlanguage descriptions via prompt input, images, descriptions from academic\npapers, patents, and technical reports (either one or multiple). The\neffectiveness of LEAM is demonstrated by three examples: a Vivaldi antenna\ngenerated from a complete user description, a slotted patch antenna generated\nfrom an incomplete user description and the operating frequency, and a monopole\nslotted antenna generated from images and descriptions scanned from the\nliterature. For all the examples, correct antenna models are generated in a few\nminutes. The code can be accessed via https://github.com/TaoWu974/LEAM.", "published": "2025-04-25 11:29:30", "link": "http://arxiv.org/abs/2504.18271v1", "categories": ["cs.AI", "cs.ET", "cs.HC", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Neural operators struggle to learn complex PDEs in pedestrian mobility: Hughes model case study", "abstract": "This paper investigates the limitations of neural operators in learning\nsolutions for a Hughes model, a first-order hyperbolic conservation law system\nfor crowd dynamics. The model couples a Fokker-Planck equation representing\npedestrian density with a Hamilton-Jacobi-type (eikonal) equation. This Hughes\nmodel belongs to the class of nonlinear hyperbolic systems that often exhibit\ncomplex solution structures, including shocks and discontinuities. In this\nstudy, we assess the performance of three state-of-the-art neural operators\n(Fourier Neural Operator, Wavelet Neural Operator, and Multiwavelet Neural\nOperator) in various challenging scenarios. Specifically, we consider (1)\ndiscontinuous and Gaussian initial conditions and (2) diverse boundary\nconditions, while also examining the impact of different numerical schemes.\n  Our results show that these neural operators perform well in easy scenarios\nwith fewer discontinuities in the initial condition, yet they struggle in\ncomplex scenarios with multiple initial discontinuities and dynamic boundary\nconditions, even when trained specifically on such complex samples. The\npredicted solutions often appear smoother, resulting in a reduction in total\nvariation and a loss of important physical features. This smoothing behavior is\nsimilar to issues discussed by Daganzo (1995), where models that introduce\nartificial diffusion were shown to miss essential features such as shock waves\nin hyperbolic systems. These results suggest that current neural operator\narchitectures may introduce unintended regularization effects that limit their\nability to capture transport dynamics governed by discontinuities. They also\nraise concerns about generalizing these methods to traffic applications where\nshock preservation is essential.", "published": "2025-04-25 11:26:41", "link": "http://arxiv.org/abs/2504.18267v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing", "abstract": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime\noperations, yet their navigation in shallow-water environments remains\nchallenging due to dynamic disturbances and depth constraints. Traditional\nnavigation strategies struggle with limited sensor information, making safe and\nefficient operation difficult. In this paper, we propose a reinforcement\nlearning (RL) framework for ASV navigation under depth constraints, where the\nvehicle must reach a target while avoiding unsafe areas with only a single\ndepth measurement per timestep from a downward-facing Single Beam Echosounder\n(SBES). To enhance environmental awareness, we integrate Gaussian Process (GP)\nregression into the RL framework, enabling the agent to progressively estimate\na bathymetric depth map from sparse sonar readings. This approach improves\ndecision-making by providing a richer representation of the environment.\nFurthermore, we demonstrate effective sim-to-real transfer, ensuring that\ntrained policies generalize well to real-world aquatic conditions. Experimental\nresults validate our method's capability to improve ASV navigation performance\nwhile maintaining safety in challenging shallow-water environments.", "published": "2025-04-25 10:56:56", "link": "http://arxiv.org/abs/2504.18253v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Event-Based Eye Tracking. 2025 Event-based Vision Workshop", "abstract": "This survey serves as a review for the 2025 Event-Based Eye Tracking\nChallenge organized as part of the 2025 CVPR event-based vision workshop. This\nchallenge focuses on the task of predicting the pupil center by processing\nevent camera recorded eye movement. We review and summarize the innovative\nmethods from teams rank the top in the challenge to advance future event-based\neye tracking research. In each method, accuracy, model size, and number of\noperations are reported. In this survey, we also discuss event-based eye\ntracking from the perspective of hardware design.", "published": "2025-04-25 10:50:14", "link": "http://arxiv.org/abs/2504.18249v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Time and Frequency Domain-based Anomaly Detection in Smart Meter Data for Distribution Network Studies", "abstract": "The widespread integration of new technologies in low-voltage distribution\nnetworks on the consumer side creates the need for distribution system\noperators to perform advanced real-time calculations to estimate network\nconditions. In recent years, data-driven models based on machine learning and\nbig data analysis have emerged for calculation purposes, leveraging the\ninformation available in large datasets obtained from smart meters and other\nadvanced measurement infrastructure. However, existing data-driven algorithms\ndo not take into account the quality of data collected from smart meters. They\nlack built-in anomaly detection mechanisms and fail to differentiate anomalies\nbased on whether the value or context of anomalous data instances deviates from\nthe norm. This paper focuses on methods for detecting and mitigating the impact\nof anomalies on the consumption of active and reactive power datasets. It\nproposes an anomaly detection framework based on the Isolation Forest machine\nlearning algorithm and Fast Fourier Transform filtering that works in both the\ntime and frequency domain and is unaffected by point anomalies or contextual\nanomalies of the power consumption data. The importance of integrating anomaly\ndetection methods is demonstrated in the analysis important for distribution\nnetworks with a high share of smart meters.", "published": "2025-04-25 10:26:30", "link": "http://arxiv.org/abs/2504.18231v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Learning to fuse: dynamic integration of multi-source data for accurate battery lifespan prediction", "abstract": "Accurate prediction of lithium-ion battery lifespan is vital for ensuring\noperational reliability and reducing maintenance costs in applications like\nelectric vehicles and smart grids. This study presents a hybrid learning\nframework for precise battery lifespan prediction, integrating dynamic\nmulti-source data fusion with a stacked ensemble (SE) modeling approach. By\nleveraging heterogeneous datasets from the National Aeronautics and Space\nAdministration (NASA), Center for Advanced Life Cycle Engineering (CALCE),\nMIT-Stanford-Toyota Research Institute (TRC), and nickel cobalt aluminum (NCA)\nchemistries, an entropy-based dynamic weighting mechanism mitigates variability\nacross heterogeneous datasets. The SE model combines Ridge regression, long\nshort-term memory (LSTM) networks, and eXtreme Gradient Boosting (XGBoost),\neffectively capturing temporal dependencies and nonlinear degradation patterns.\nIt achieves a mean absolute error (MAE) of 0.0058, root mean square error\n(RMSE) of 0.0092, and coefficient of determination (R2) of 0.9839,\noutperforming established baseline models with a 46.2% improvement in R2 and an\n83.2% reduction in RMSE. Shapley additive explanations (SHAP) analysis\nidentifies differential discharge capacity (Qdlin) and temperature of\nmeasurement (Temp_m) as critical aging indicators. This scalable, interpretable\nframework enhances battery health management, supporting optimized maintenance\nand safety across diverse energy storage systems, thereby contributing to\nimproved battery health management in energy storage systems.", "published": "2025-04-25 10:24:45", "link": "http://arxiv.org/abs/2504.18230v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multi-Grained Compositional Visual Clue Learning for Image Intent Recognition", "abstract": "In an era where social media platforms abound, individuals frequently share\nimages that offer insights into their intents and interests, impacting\nindividual life quality and societal stability. Traditional computer vision\ntasks, such as object detection and semantic segmentation, focus on concrete\nvisual representations, while intent recognition relies more on implicit visual\nclues. This poses challenges due to the wide variation and subjectivity of such\nclues, compounded by the problem of intra-class variety in conveying abstract\nconcepts, e.g. \"enjoy life\". Existing methods seek to solve the problem by\nmanually designing representative features or building prototypes for each\nclass from global features. However, these methods still struggle to deal with\nthe large visual diversity of each intent category. In this paper, we introduce\na novel approach named Multi-grained Compositional visual Clue Learning (MCCL)\nto address these challenges for image intent recognition. Our method leverages\nthe systematic compositionality of human cognition by breaking down intent\nrecognition into visual clue composition and integrating multi-grained\nfeatures. We adopt class-specific prototypes to alleviate data imbalance. We\ntreat intent recognition as a multi-label classification problem, using a graph\nconvolutional network to infuse prior knowledge through label embedding\ncorrelations. Demonstrated by a state-of-the-art performance on the Intentonomy\nand MDID datasets, our approach advances the accuracy of existing methods while\nalso possessing good interpretability. Our work provides an attempt for future\nexplorations in understanding complex and miscellaneous forms of human\nexpression.", "published": "2025-04-25 09:31:03", "link": "http://arxiv.org/abs/2504.18201v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models", "abstract": "We introduce PerfCam, an open source Proof-of-Concept (PoC) digital twinning\nframework that combines camera and sensory data with 3D Gaussian Splatting and\ncomputer vision models for digital twinning, object tracking, and Key\nPerformance Indicators (KPIs) extraction in industrial production lines. By\nutilizing 3D reconstruction and Convolutional Neural Networks (CNNs), PerfCam\noffers a semi-automated approach to object tracking and spatial mapping,\nenabling digital twins that capture real-time KPIs such as availability,\nperformance, Overall Equipment Effectiveness (OEE), and rate of conveyor belts\nin the production line. We validate the effectiveness of PerfCam through a\npractical deployment within realistic test production lines in the\npharmaceutical industry and contribute an openly published dataset to support\nfurther research and development in the field. The results demonstrate\nPerfCam's ability to deliver actionable insights through its precise digital\ntwin capabilities, underscoring its value as an effective tool for developing\nusable digital twins in smart manufacturing environments and extracting\noperational analytics.", "published": "2025-04-25 08:29:00", "link": "http://arxiv.org/abs/2504.18165v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Offline Learning of Controllable Diverse Behaviors", "abstract": "Imitation Learning (IL) techniques aim to replicate human behaviors in\nspecific tasks. While IL has gained prominence due to its effectiveness and\nefficiency, traditional methods often focus on datasets collected from experts\nto produce a single efficient policy. Recently, extensions have been proposed\nto handle datasets of diverse behaviors by mainly focusing on learning\ntransition-level diverse policies or on performing entropy maximization at the\ntrajectory level. While these methods may lead to diverse behaviors, they may\nnot be sufficient to reproduce the actual diversity of demonstrations or to\nallow controlled trajectory generation. To overcome these drawbacks, we propose\na different method based on two key features: a) Temporal Consistency that\nensures consistent behaviors across entire episodes and not just at the\ntransition level as well as b) Controllability obtained by constructing a\nlatent space of behaviors that allows users to selectively activate specific\nbehaviors based on their requirements. We compare our approach to\nstate-of-the-art methods over a diverse set of tasks and environments. Project\npage: https://mathieu-petitbois.github.io/projects/swr/", "published": "2025-04-25 08:16:56", "link": "http://arxiv.org/abs/2504.18160v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Learning from Less: SINDy Surrogates in RL", "abstract": "This paper introduces an approach for developing surrogate environments in\nreinforcement learning (RL) using the Sparse Identification of Nonlinear\nDynamics (SINDy) algorithm. We demonstrate the effectiveness of our approach\nthrough extensive experiments in OpenAI Gym environments, particularly Mountain\nCar and Lunar Lander. Our results show that SINDy-based surrogate models can\naccurately capture the underlying dynamics of these environments while reducing\ncomputational costs by 20-35%. With only 75 interactions for Mountain Car and\n1000 for Lunar Lander, we achieve state-wise correlations exceeding 0.997, with\nmean squared errors as low as 3.11e-06 for Mountain Car velocity and 1.42e-06\nfor LunarLander position. RL agents trained in these surrogate environments\nrequire fewer total steps (65,075 vs. 100,000 for Mountain Car and 801,000 vs.\n1,000,000 for Lunar Lander) while achieving comparable performance to those\ntrained in the original environments, exhibiting similar convergence patterns\nand final performance metrics. This work contributes to the field of\nmodel-based RL by providing an efficient method for generating accurate,\ninterpretable surrogate environments.", "published": "2025-04-25 06:34:19", "link": "http://arxiv.org/abs/2504.18113v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation", "abstract": "Medication recommendation is crucial in healthcare, offering effective\ntreatments based on patient's electronic health records (EHR). Previous studies\nshow that integrating more medication-related knowledge improves medication\nrepresentation accuracy. However, not all medications encompass multiple types\nof knowledge data simultaneously. For instance, some medications provide only\ntextual descriptions without structured data. This imbalance in data\navailability limits the performance of existing models, a challenge we term the\n\"bucket effect\" in medication recommendation. Our data analysis uncovers the\nseverity of the \"bucket effect\" in medication recommendation. To fill this gap,\nwe introduce a cross-modal medication encoder capable of seamlessly aligning\ndata from different modalities and propose a medication recommendation\nframework to integrate Multiple types of Knowledge, named MKMed. Specifically,\nwe first pre-train a cross-modal encoder with contrastive learning on five\nknowledge modalities, aligning them into a unified space. Then, we combine the\nmulti-knowledge medication representations with patient records for\nrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasets\ndemonstrate that MKMed mitigates the \"bucket effect\" in data, and significantly\noutperforms state-of-the-art baselines in recommendation accuracy and safety.", "published": "2025-04-25 05:47:15", "link": "http://arxiv.org/abs/2504.18096v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Efficient GNN Training Through Structure-Aware Randomized Mini-Batching", "abstract": "Graph Neural Networks (GNNs) enable learning on realworld graphs and\nmini-batch training has emerged as the de facto standard for training GNNs\nbecause it can scale to very large graphs and improve convergence. Current\nmini-batch construction policies largely ignore efficiency considerations of\nGNN training. Specifically, existing mini-batching techniques employ\nrandomization schemes to improve accuracy and convergence. However, these\nrandomization schemes are often agnostic to the structural properties of the\ngraph (for eg. community structure), resulting in highly irregular memory\naccess patterns during GNN training that make suboptimal use of on-chip GPU\ncaches. On the other hand, while deterministic mini-batching based solely on\ngraph structure delivers fast runtime performance, the lack of randomness\ncompromises both the final model accuracy and training convergence speed. In\nthis paper, we present Community-structure-aware Randomized Mini-batching\n(COMM-RAND), a novel methodology that bridges the gap between the above\nextremes. COMM-RAND allows practitioners to explore the space between pure\nrandomness and pure graph structural awareness during mini-batch construction,\nleading to significantly more efficient GNN training with similar accuracy. We\nevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RAND\ncuts down GNN training time by up to 2.76x (1.8x on average) while achieving an\naccuracy that is within 1.79% points (0.42% on average) compared to popular\nrandom mini-batching approaches.", "published": "2025-04-25 05:16:53", "link": "http://arxiv.org/abs/2504.18082v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity", "abstract": "The rapid expansion of distributed photovoltaic (PV) installations worldwide,\nmany being behind-the-meter systems, has significantly challenged energy\nmanagement and grid operations, as unobservable PV generation further\ncomplicates the supply-demand balance. Therefore, estimating this generation\nfrom net load, known as PV disaggregation, is critical. Given privacy concerns\nand the need for large training datasets, federated learning becomes a\npromising approach, but statistical heterogeneity, arising from geographical\nand behavioral variations among prosumers, poses new challenges to PV\ndisaggregation. To overcome these challenges, a privacy-preserving distributed\nPV disaggregation framework is proposed using Personalized Federated Learning\n(PFL). The proposed method employs a two-level framework that combines local\nand global modeling. At the local level, a transformer-based PV disaggregation\nmodel is designed to generate solar irradiance embeddings for representing\nlocal PV conditions. A novel adaptive local aggregation mechanism is adopted to\nmitigate the impact of statistical heterogeneity on the local model, extracting\na portion of global information that benefits the local model. At the global\nlevel, a central server aggregates information uploaded from multiple data\ncenters, preserving privacy while enabling cross-center knowledge sharing.\nExperiments on real-world data demonstrate the effectiveness of this proposed\nframework, showing improved accuracy and robustness compared to benchmark\nmethods.", "published": "2025-04-25 05:09:27", "link": "http://arxiv.org/abs/2504.18078v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "S3MOT: Monocular 3D Object Tracking with Selective State Space Model", "abstract": "Accurate and reliable multi-object tracking (MOT) in 3D space is essential\nfor advancing robotics and computer vision applications. However, it remains a\nsignificant challenge in monocular setups due to the difficulty of mining 3D\nspatiotemporal associations from 2D video streams. In this work, we present\nthree innovative techniques to enhance the fusion and exploitation of\nheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian State\nSpace Model (HSSM), a novel data association mechanism that compresses\ncontextual tracking cues across multiple paths, enabling efficient and\ncomprehensive assignment decisions with linear complexity. HSSM features a\nglobal receptive field and dynamic weights, in contrast to traditional linear\nassignment algorithms that rely on hand-crafted association costs. (2) We\npropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROI\npooling by directly using dense feature maps for contrastive learning, thus\nimproving object re-identification accuracy under challenging conditions such\nas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimation\nthrough VeloSSM, an encoder-decoder architecture that models temporal\ndependencies in velocity to capture motion dynamics, overcoming the limitations\nof frame-based 3D inference. Experiments on the KITTI public test benchmark\ndemonstrate the effectiveness of our method, achieving a new state-of-the-art\nperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous best\nby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustness\nand efficiency for monocular 3D MOT tasks. The code and models are available at\nhttps://github.com/bytepioneerX/s3mot.", "published": "2025-04-25 04:45:35", "link": "http://arxiv.org/abs/2504.18068v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLM-Guided Open RAN: Empowering Hierarchical RAN Intelligent Control", "abstract": "Recent advancements in large language models (LLMs) have led to a significant\ninterest in deploying LLMempowered algorithms for wireless communication\nnetworks. Meanwhile, open radio access network (O-RAN) techniques offer\nunprecedented flexibility, with the non-real-time (non-RT) radio access network\n(RAN) intelligent controller (RIC) (non-RT RIC) and near-real-time (near-RT)\nRIC (near-RT RIC) components enabling intelligent resource management across\ndifferent time scales. In this paper, we propose the LLM empowered hierarchical\nRIC (LLM-hRIC) framework to improve the collaboration between RICs. This\nframework integrates LLMs with reinforcement learning (RL) for efficient\nnetwork resource management. In this framework, LLMs-empowered non-RT RICs\nprovide strategic guidance and high-level policies based on environmental\ncontext. Concurrently, RL-empowered near-RT RICs perform low-latency tasks\nbased on strategic guidance and local near-RT observation. We evaluate the\nLLM-hRIC framework in an integrated access and backhaul (IAB) network setting.\nSimulation results demonstrate that the proposed framework achieves superior\nperformance. Finally, we discuss the key future challenges in applying LLMs to\nO-RAN.", "published": "2025-04-25 04:18:23", "link": "http://arxiv.org/abs/2504.18062v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "Opportunistic Collaborative Planning with Large Vision Model Guided Control and Joint Query-Service Optimization", "abstract": "Navigating autonomous vehicles in open scenarios is a challenge due to the\ndifficulties in handling unseen objects. Existing solutions either rely on\nsmall models that struggle with generalization or large models that are\nresource-intensive. While collaboration between the two offers a promising\nsolution, the key challenge is deciding when and how to engage the large model.\nTo address this issue, this paper proposes opportunistic collaborative planning\n(OCP), which seamlessly integrates efficient local models with powerful cloud\nmodels through two key innovations. First, we propose large vision model guided\nmodel predictive control (LVM-MPC), which leverages the cloud for LVM\nperception and decision making. The cloud output serves as a global guidance\nfor a local MPC, thereby forming a closed-loop perception-to-control system.\nSecond, to determine the best timing for large model query and service, we\npropose collaboration timing optimization (CTO), including object detection\nconfidence thresholding (ODCT) and cloud forward simulation (CFS), to decide\nwhen to seek cloud assistance and when to offer cloud service. Extensive\nexperiments show that the proposed OCP outperforms existing methods in terms of\nboth navigation time and success rate.", "published": "2025-04-25 04:07:21", "link": "http://arxiv.org/abs/2504.18057v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Validating Network Protocol Parsers with Traceable RFC Document Interpretation", "abstract": "Validating the correctness of network protocol implementations is highly\nchallenging due to the oracle and traceability problems. The former determines\nwhen a protocol implementation can be considered buggy, especially when the\nbugs do not cause any observable symptoms. The latter allows developers to\nunderstand how an implementation violates the protocol specification, thereby\nfacilitating bug fixes. Unlike existing works that rarely take both problems\ninto account, this work considers both and provides an effective solution using\nrecent advances in large language models (LLMs). Our key observation is that\nnetwork protocols are often released with structured specification documents,\na.k.a. RFC documents, which can be systematically translated to formal protocol\nmessage specifications via LLMs. Such specifications, which may contain errors\ndue to the hallucination of LLMs, are used as a quasi-oracle to validate\nprotocol parsers, while the validation results in return gradually refine the\noracle. Since the oracle is derived from the document, any bugs we find in a\nprotocol implementation can be traced back to the document, thus addressing the\ntraceability problem. We have extensively evaluated our approach using nine\nnetwork protocols and their implementations written in C, Python, and Go. The\nresults show that our approach outperforms the state-of-the-art and has\ndetected 69 bugs, with 36 confirmed. The project also demonstrates the\npotential for fully automating software validation based on natural language\nspecifications, a process previously considered predominantly manual due to the\nneed to understand specification documents and derive expected outputs for test\ninputs.", "published": "2025-04-25 03:39:19", "link": "http://arxiv.org/abs/2504.18050v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "A BERT-Style Self-Supervised Learning CNN for Disease Identification from Retinal Images", "abstract": "In the field of medical imaging, the advent of deep learning, especially the\napplication of convolutional neural networks (CNNs) has revolutionized the\nanalysis and interpretation of medical images. Nevertheless, deep learning\nmethods usually rely on large amounts of labeled data. In medical imaging\nresearch, the acquisition of high-quality labels is both expensive and\ndifficult. The introduction of Vision Transformers (ViT) and self-supervised\nlearning provides a pre-training strategy that utilizes abundant unlabeled\ndata, effectively alleviating the label acquisition challenge while broadening\nthe breadth of data utilization. However, ViT's high computational density and\nsubstantial demand for computing power, coupled with the lack of localization\ncharacteristics of its operations on image patches, limit its efficiency and\napplicability in many application scenarios. In this study, we employ\nnn-MobileNet, a lightweight CNN framework, to implement a BERT-style\nself-supervised learning approach. We pre-train the network on the unlabeled\nretinal fundus images from the UK Biobank to improve downstream application\nperformance. We validate the results of the pre-trained model on Alzheimer's\ndisease (AD), Parkinson's disease (PD), and various retinal diseases\nidentification. The results show that our approach can significantly improve\nperformance in the downstream tasks. In summary, this study combines the\nbenefits of CNNs with the capabilities of advanced self-supervised learning in\nhandling large-scale unlabeled data, demonstrating the potential of CNNs in the\npresence of label scarcity.", "published": "2025-04-25 03:38:55", "link": "http://arxiv.org/abs/2504.18049v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification", "abstract": "Ophthalmic diseases pose a significant global health challenge, yet\ntraditional diagnosis methods and existing single-eye deep learning approaches\noften fail to account for binocular pathological correlations. To address this,\nwe propose DMS-Net, a dual-modal multi-scale Siamese network for binocular\nfundus image classification. Our framework leverages weight-shared Siamese\nResNet-152 backbones to extract deep semantic features from paired fundus\nimages. To tackle challenges such as lesion boundary ambiguity and scattered\npathological distributions, we introduce a Multi-Scale Context-Aware Module\n(MSCAM) that integrates adaptive pooling and attention mechanisms for\nmulti-resolution feature aggregation. Additionally, a Dual-Modal Feature Fusion\n(DMFF) module enhances cross-modal interaction through spatial-semantic\nrecalibration and bidirectional attention, effectively combining global context\nand local edge features. Evaluated on the ODIR-5K dataset, DMS-Net achieves\nstate-of-the-art performance with 80.5% accuracy, 86.1% recall, and 83.8%\nCohen's kappa, demonstrating superior capability in detecting symmetric\npathologies and advancing clinical decision-making for ocular diseases.", "published": "2025-04-25 03:27:28", "link": "http://arxiv.org/abs/2504.18046v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI Ethics and Social Norms: Exploring ChatGPT's Capabilities From What to How", "abstract": "Using LLMs in healthcare, Computer-Supported Cooperative Work, and Social\nComputing requires the examination of ethical and social norms to ensure safe\nincorporation into human life. We conducted a mixed-method study, including an\nonline survey with 111 participants and an interview study with 38 experts, to\ninvestigate the AI ethics and social norms in ChatGPT as everyday life tools.\nThis study aims to evaluate whether ChatGPT in an empirical context operates\nfollowing ethics and social norms, which is critical for understanding actions\nin industrial and academic research and achieving machine ethics. The findings\nof this study provide initial insights into six important aspects of AI ethics,\nincluding bias, trustworthiness, security, toxicology, social norms, and\nethical data. Significant obstacles related to transparency and bias in\nunsupervised data collection methods are identified as ChatGPT's ethical\nconcerns.", "published": "2025-04-25 03:26:30", "link": "http://arxiv.org/abs/2504.18044v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.IT", "math.IT"], "primary_category": "cs.CY"}
{"title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities\nin social deduction games (SDGs) like Werewolf, where strategic reasoning and\nsocial deception are essential. However, current approaches remain limited to\ntextual information, ignoring crucial multimodal cues such as facial\nexpressions and tone of voice that humans naturally use to communicate.\nMoreover, existing SDG agents primarily focus on inferring other players'\nidentities without modeling how others perceive themselves or fellow players.\nTo address these limitations, we use One Night Ultimate Werewolf (ONUW) as a\ntestbed and present MultiMind, the first framework integrating multimodal\ninformation into SDG agents. MultiMind processes facial expressions and vocal\ntones alongside verbal content, while employing a Theory of Mind (ToM) model to\nrepresent each player's suspicion levels toward others. By combining this ToM\nmodel with Monte Carlo Tree Search (MCTS), our agent identifies communication\nstrategies that minimize suspicion directed at itself. Through comprehensive\nevaluation in both agent-versus-agent simulations and studies with human\nplayers, we demonstrate MultiMind's superior performance in gameplay. Our work\npresents a significant advancement toward LLM agents capable of human-like\nsocial reasoning across multimodal domains.", "published": "2025-04-25 03:12:43", "link": "http://arxiv.org/abs/2504.18039v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Large Vision-Language Model based Environment Perception System for Visually Impaired People", "abstract": "It is a challenging task for visually impaired people to perceive their\nsurrounding environment due to the complexity of the natural scenes. Their\npersonal and social activities are thus highly limited. This paper introduces a\nLarge Vision-Language Model(LVLM) based environment perception system which\nhelps them to better understand the surrounding environment, by capturing the\ncurrent scene they face with a wearable device, and then letting them retrieve\nthe analysis results through the device. The visually impaired people could\nacquire a global description of the scene by long pressing the screen to\nactivate the LVLM output, retrieve the categories of the objects in the scene\nresulting from a segmentation model by tapping or swiping the screen, and get a\ndetailed description of the objects they are interested in by double-tapping\nthe screen. To help visually impaired people more accurately perceive the\nworld, this paper proposes incorporating the segmentation result of the RGB\nimage as external knowledge into the input of LVLM to reduce the LVLM's\nhallucination. Technical experiments on POPE, MME and LLaVA-QA90 show that the\nsystem could provide a more accurate description of the scene compared to\nQwen-VL-Chat, exploratory experiments show that the system helps visually\nimpaired people to perceive the surrounding environment effectively.", "published": "2025-04-25 02:46:22", "link": "http://arxiv.org/abs/2504.18027v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization", "abstract": "Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI\nsystems by constraining their decisions on a set of human understandable\nconcepts. However, CBMs typically assume that datasets contains accurate\nconcept labels an assumption often violated in practice, which we show can\nsignificantly degrade performance (by 25% in some cases). To address this, we\nintroduce the Concept Preference Optimization (CPO) objective, a new loss\nfunction based on Direct Preference Optimization, which effectively mitigates\nthe negative impact of concept mislabeling on CBM performance. We provide an\nanalysis on some key properties of the CPO objective showing it directly\noptimizes for the concept's posterior distribution, and contrast it against\nBinary Cross Entropy (BCE) where we show CPO is inherently less sensitive to\nconcept noise. We empirically confirm our analysis finding that CPO\nconsistently outperforms BCE in three real world datasets with and without\nadded label noise.", "published": "2025-04-25 02:43:10", "link": "http://arxiv.org/abs/2504.18026v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation", "abstract": "Recent advances in autonomous system simulation platforms have significantly\nenhanced the safe and scalable testing of driving policies. However, existing\nsimulators do not yet fully meet the needs of future transportation research,\nparticularly in modeling socially-aware driving agents and enabling effective\nhuman-AI collaboration. This paper introduces Sky-Drive, a novel distributed\nmulti-agent simulation platform that addresses these limitations through four\nkey innovations: (a) a distributed architecture for synchronized simulation\nacross multiple terminals; (b) a multi-modal human-in-the-loop framework\nintegrating diverse sensors to collect rich behavioral data; (c) a human-AI\ncollaboration mechanism supporting continuous and adaptive knowledge exchange;\nand (d) a digital twin (DT) framework for constructing high-fidelity virtual\nreplicas of real-world transportation environments. Sky-Drive supports diverse\napplications such as autonomous vehicle (AV)-vulnerable road user (VRU)\ninteraction modeling, human-in-the-loop training, socially-aware reinforcement\nlearning, personalized driving policy, and customized scenario generation.\nFuture extensions will incorporate foundation models for context-aware decision\nsupport and hardware-in-the-loop (HIL) testing for real-world validation. By\nbridging scenario generation, data collection, algorithm training, and hardware\nintegration, Sky-Drive has the potential to become a foundational platform for\nthe next generation of socially-aware and human-centered autonomous\ntransportation research. The demo video and code are available\nat:https://sky-lab-uw.github.io/Sky-Drive-website/", "published": "2025-04-25 01:33:26", "link": "http://arxiv.org/abs/2504.18010v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Differential Privacy-Driven Framework for Enhancing Heart Disease Prediction", "abstract": "With the rapid digitalization of healthcare systems, there has been a\nsubstantial increase in the generation and sharing of private health data.\nSafeguarding patient information is essential for maintaining consumer trust\nand ensuring compliance with legal data protection regulations. Machine\nlearning is critical in healthcare, supporting personalized treatment, early\ndisease detection, predictive analytics, image interpretation, drug discovery,\nefficient operations, and patient monitoring. It enhances decision-making,\naccelerates research, reduces errors, and improves patient outcomes. In this\npaper, we utilize machine learning methodologies, including differential\nprivacy and federated learning, to develop privacy-preserving models that\nenable healthcare stakeholders to extract insights without compromising\nindividual privacy. Differential privacy introduces noise to data to guarantee\nstatistical privacy, while federated learning enables collaborative model\ntraining across decentralized datasets. We explore applying these technologies\nto Heart Disease Data, demonstrating how they preserve privacy while delivering\nvaluable insights and comprehensive analysis. Our results show that using a\nfederated learning model with differential privacy achieved a test accuracy of\n85%, ensuring patient data remained secure and private throughout the process.", "published": "2025-04-25 01:27:40", "link": "http://arxiv.org/abs/2504.18007v1", "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Augmenting Perceptual Super-Resolution via Image Quality Predictors", "abstract": "Super-resolution (SR), a classical inverse problem in computer vision, is\ninherently ill-posed, inducing a distribution of plausible solutions for every\ninput. However, the desired result is not simply the expectation of this\ndistribution, which is the blurry image obtained by minimizing pixelwise error,\nbut rather the sample with the highest image quality. A variety of techniques,\nfrom perceptual metrics to adversarial losses, are employed to this end. In\nthis work, we explore an alternative: utilizing powerful non-reference image\nquality assessment (NR-IQA) models in the SR context. We begin with a\ncomprehensive analysis of NR-IQA metrics on human-derived SR data, identifying\nboth the accuracy (human alignment) and complementarity of different metrics.\nThen, we explore two methods of applying NR-IQA models to SR learning: (i)\naltering data sampling, by building on an existing multi-ground-truth SR\nframework, and (ii) directly optimizing a differentiable quality score. Our\nresults demonstrate a more human-centric perception-distortion tradeoff,\nfocusing less on non-perceptual pixel-wise distortion, instead improving the\nbalance between perceptual fidelity and human-tuned NR-IQA measures.", "published": "2025-04-25 17:47:38", "link": "http://arxiv.org/abs/2504.18524v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "E-VLC: A Real-World Dataset for Event-based Visible Light Communication And Localization", "abstract": "Optical communication using modulated LEDs (e.g., visible light\ncommunication) is an emerging application for event cameras, thanks to their\nhigh spatio-temporal resolutions. Event cameras can be used simply to decode\nthe LED signals and also to localize the camera relative to the LED marker\npositions. However, there is no public dataset to benchmark the decoding and\nlocalization in various real-world settings. We present, to the best of our\nknowledge, the first public dataset that consists of an event camera, a frame\ncamera, and ground-truth poses that are precisely synchronized with hardware\ntriggers. It provides various camera motions with various sensitivities in\ndifferent scene brightness settings, both indoor and outdoor. Furthermore, we\npropose a novel method of localization that leverages the Contrast Maximization\nframework for motion estimation and compensation. The detailed analysis and\nexperimental results demonstrate the advantages of LED-based localization with\nevents over the conventional AR-marker--based one with frames, as well as the\nefficacy of the proposed method in localization. We hope that the proposed\ndataset serves as a future benchmark for both motion-related classical computer\nvision tasks and LED marker decoding tasks simultaneously, paving the way to\nbroadening applications of event cameras on mobile devices.\nhttps://woven-visionai.github.io/evlc-dataset", "published": "2025-04-25 17:43:20", "link": "http://arxiv.org/abs/2504.18521v1", "categories": ["cs.CV", "cs.RO", "eess.SP"], "primary_category": "cs.CV"}
{"title": "RSFR: A Coarse-to-Fine Reconstruction Framework for Diffusion Tensor Cardiac MRI with Semantic-Aware Refinement", "abstract": "Cardiac diffusion tensor imaging (DTI) offers unique insights into\ncardiomyocyte arrangements, bridging the gap between microscopic and\nmacroscopic cardiac function. However, its clinical utility is limited by\ntechnical challenges, including a low signal-to-noise ratio, aliasing\nartefacts, and the need for accurate quantitative fidelity. To address these\nlimitations, we introduce RSFR (Reconstruction, Segmentation, Fusion &\nRefinement), a novel framework for cardiac diffusion-weighted image\nreconstruction. RSFR employs a coarse-to-fine strategy, leveraging zero-shot\nsemantic priors via the Segment Anything Model and a robust Vision Mamba-based\nreconstruction backbone. Our framework integrates semantic features effectively\nto mitigate artefacts and enhance fidelity, achieving state-of-the-art\nreconstruction quality and accurate DT parameter estimation under high\nundersampling rates. Extensive experiments and ablation studies demonstrate the\nsuperior performance of RSFR compared to existing methods, highlighting its\nrobustness, scalability, and potential for clinical translation in quantitative\ncardiac DTI.", "published": "2025-04-25 17:41:14", "link": "http://arxiv.org/abs/2504.18520v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Examining the Impact of Optical Aberrations to Image Classification and Object Detection Models", "abstract": "Deep neural networks (DNNs) have proven to be successful in various computer\nvision applications such that models even infer in safety-critical situations.\nTherefore, vision models have to behave in a robust way to disturbances such as\nnoise or blur. While seminal benchmarks exist to evaluate model robustness to\ndiverse corruptions, blur is often approximated in an overly simplistic way to\nmodel defocus, while ignoring the different blur kernel shapes that result from\noptical systems. To study model robustness against realistic optical blur\neffects, this paper proposes two datasets of blur corruptions, which we denote\nOpticsBench and LensCorruptions. OpticsBench examines primary aberrations such\nas coma, defocus, and astigmatism, i.e. aberrations that can be represented by\nvarying a single parameter of Zernike polynomials. To go beyond the principled\nbut synthetic setting of primary aberrations, LensCorruptions samples linear\ncombinations in the vector space spanned by Zernike polynomials, corresponding\nto 100 real lenses. Evaluations for image classification and object detection\non ImageNet and MSCOCO show that for a variety of different pre-trained models,\nthe performance on OpticsBench and LensCorruptions varies significantly,\nindicating the need to consider realistic image corruptions to evaluate a\nmodel's robustness against blur.", "published": "2025-04-25 17:23:47", "link": "http://arxiv.org/abs/2504.18510v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation", "abstract": "Despite the unprecedented progress in the field of 3D generation, current\nsystems still often fail to produce high-quality 3D assets that are visually\nappealing and geometrically and semantically consistent across multiple\nviewpoints. To effectively assess the quality of the generated 3D data, there\nis a need for a reliable 3D evaluation tool. Unfortunately, existing 3D\nevaluation metrics often overlook the geometric quality of generated assets or\nmerely rely on black-box multimodal large language models for coarse\nassessment. In this paper, we introduce Eval3D, a fine-grained, interpretable\nevaluation tool that can faithfully evaluate the quality of generated 3D assets\nbased on various distinct yet complementary criteria. Our key observation is\nthat many desired properties of 3D generation, such as semantic and geometric\nconsistency, can be effectively captured by measuring the consistency among\nvarious foundation models and tools. We thus leverage a diverse set of models\nand tools as probes to evaluate the inconsistency of generated 3D assets across\ndifferent aspects. Compared to prior work, Eval3D provides pixel-wise\nmeasurement, enables accurate 3D spatial feedback, and aligns more closely with\nhuman judgments. We comprehensively evaluate existing 3D generation models\nusing Eval3D and highlight the limitations and challenges of current models.", "published": "2025-04-25 17:22:05", "link": "http://arxiv.org/abs/2504.18509v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Improved ResNet50 Model for Predicting Pavement Condition Index (PCI) Directly from Pavement Images", "abstract": "Accurately predicting the Pavement Condition Index (PCI), a measure of\nroadway conditions, from pavement images is crucial for infrastructure\nmaintenance. This study proposes an enhanced version of the Residual Network\n(ResNet50) architecture, integrated with a Convolutional Block Attention Module\n(CBAM), to predict PCI directly from pavement images without additional\nannotations. By incorporating CBAM, the model autonomously prioritizes critical\nfeatures within the images, improving prediction accuracy. Compared to the\noriginal baseline ResNet50 and DenseNet161 architectures, the enhanced\nResNet50-CBAM model achieved a significantly lower mean absolute percentage\nerror (MAPE) of 58.16%, compared to the baseline models that achieved 70.76%\nand 65.48% respectively. These results highlight the potential of using\nattention mechanisms to refine feature extraction, ultimately enabling more\naccurate and efficient assessments of pavement conditions. This study\nemphasizes the importance of targeted feature refinement in advancing automated\npavement analysis through attention mechanisms.", "published": "2025-04-25 17:00:50", "link": "http://arxiv.org/abs/2504.18490v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RGS-DR: Reflective Gaussian Surfels with Deferred Rendering for Shiny Objects", "abstract": "We introduce RGS-DR, a novel inverse rendering method for reconstructing and\nrendering glossy and reflective objects with support for flexible relighting\nand scene editing. Unlike existing methods (e.g., NeRF and 3D Gaussian\nSplatting), which struggle with view-dependent effects, RGS-DR utilizes a 2D\nGaussian surfel representation to accurately estimate geometry and surface\nnormals, an essential property for high-quality inverse rendering. Our approach\nexplicitly models geometric and material properties through learnable\nprimitives rasterized into a deferred shading pipeline, effectively reducing\nrendering artifacts and preserving sharp reflections. By employing a\nmulti-level cube mipmap, RGS-DR accurately approximates environment lighting\nintegrals, facilitating high-quality reconstruction and relighting. A residual\npass with spherical-mipmap-based directional encoding further refines the\nappearance modeling. Experiments demonstrate that RGS-DR achieves high-quality\nreconstruction and rendering quality for shiny objects, often outperforming\nreconstruction-exclusive state-of-the-art methods incapable of relighting.", "published": "2025-04-25 16:23:50", "link": "http://arxiv.org/abs/2504.18468v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NoiseController: Towards Consistent Multi-view Video Generation via Noise Decomposition and Collaboration", "abstract": "High-quality video generation is crucial for many fields, including the film\nindustry and autonomous driving. However, generating videos with spatiotemporal\nconsistencies remains challenging. Current methods typically utilize attention\nmechanisms or modify noise to achieve consistent videos, neglecting global\nspatiotemporal information that could help ensure spatial and temporal\nconsistency during video generation. In this paper, we propose the\nNoiseController, consisting of Multi-Level Noise Decomposition, Multi-Frame\nNoise Collaboration, and Joint Denoising, to enhance spatiotemporal\nconsistencies in video generation. In multi-level noise decomposition, we first\ndecompose initial noises into scene-level foreground/background noises,\ncapturing distinct motion properties to model multi-view foreground/background\nvariations. Furthermore, each scene-level noise is further decomposed into\nindividual-level shared and residual components. The shared noise preserves\nconsistency, while the residual component maintains diversity. In multi-frame\nnoise collaboration, we introduce an inter-view spatiotemporal collaboration\nmatrix and an intra-view impact collaboration matrix , which captures mutual\ncross-view effects and historical cross-frame impacts to enhance video quality.\nThe joint denoising contains two parallel denoising U-Nets to remove each\nscene-level noise, mutually enhancing video generation. We evaluate our\nNoiseController on public datasets focusing on video generation and downstream\ntasks, demonstrating its state-of-the-art performance.", "published": "2025-04-25 16:01:48", "link": "http://arxiv.org/abs/2504.18448v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Nearly isotropic segmentation for medial temporal lobe subregions in multi-modality MRI", "abstract": "Morphometry of medial temporal lobe (MTL) subregions in brain MRI is\nsensitive biomarker to Alzheimers Disease and other related conditions. While\nT2-weighted (T2w) MRI with high in-plane resolution is widely used to segment\nhippocampal subfields due to its higher contrast in hippocampus, its lower\nout-of-plane resolution reduces the accuracy of subregion thickness\nmeasurements. To address this issue, we developed a nearly isotropic\nsegmentation pipeline that incorporates image and label upsampling and\nhigh-resolution segmentation in T2w MRI. First, a high-resolution atlas was\ncreated based on an existing anisotropic atlas derived from 29 individuals.\nBoth T1-weighted and T2w images in the atlas were upsampled from their original\nresolution to a nearly isotropic resolution 0.4x0.4x0.52mm3 using a non-local\nmeans approach. Manual segmentations within the atlas were also upsampled to\nmatch this resolution using a UNet-based neural network, which was trained on a\ncohort consisting of both high-resolution ex vivo and low-resolution\nanisotropic in vivo MRI with manual segmentations. Second, a multi-modality\ndeep learning-based segmentation model was trained within this nearly isotropic\natlas. Finally, experiments showed the nearly isotropic subregion segmentation\nimproved the accuracy of cortical thickness as an imaging biomarker for\nneurodegeneration in T2w MRI.", "published": "2025-04-25 15:54:03", "link": "http://arxiv.org/abs/2504.18442v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "LaRI: Layered Ray Intersections for Single-view 3D Geometric Reasoning", "abstract": "We present layered ray intersections (LaRI), a new method for unseen geometry\nreasoning from a single image. Unlike conventional depth estimation that is\nlimited to the visible surface, LaRI models multiple surfaces intersected by\nthe camera rays using layered point maps. Benefiting from the compact and\nlayered representation, LaRI enables complete, efficient, and view-aligned\ngeometric reasoning to unify object- and scene-level tasks. We further propose\nto predict the ray stopping index, which identifies valid intersecting pixels\nand layers from LaRI's output. We build a complete training data generation\npipeline for synthetic and real-world data, including 3D objects and scenes,\nwith necessary data cleaning steps and coordination between rendering engines.\nAs a generic method, LaRI's performance is validated in two scenarios: It\nyields comparable object-level results to the recent large generative model\nusing 4% of its training data and 17% of its parameters. Meanwhile, it achieves\nscene-level occluded geometry reasoning in only one feed-forward.", "published": "2025-04-25 15:31:29", "link": "http://arxiv.org/abs/2504.18424v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HepatoGEN: Generating Hepatobiliary Phase MRI with Perceptual and Adversarial Models", "abstract": "Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) plays a\ncrucial role in the detection and characterization of focal liver lesions, with\nthe hepatobiliary phase (HBP) providing essential diagnostic information.\nHowever, acquiring HBP images requires prolonged scan times, which may\ncompromise patient comfort and scanner throughput. In this study, we propose a\ndeep learning based approach for synthesizing HBP images from earlier contrast\nphases (precontrast and transitional) and compare three generative models: a\nperceptual U-Net, a perceptual GAN (pGAN), and a denoising diffusion\nprobabilistic model (DDPM). We curated a multi-site DCE-MRI dataset from\ndiverse clinical settings and introduced a contrast evolution score (CES) to\nassess training data quality, enhancing model performance. Quantitative\nevaluation using pixel-wise and perceptual metrics, combined with qualitative\nassessment through blinded radiologist reviews, showed that pGAN achieved the\nbest quantitative performance but introduced heterogeneous contrast in\nout-of-distribution cases. In contrast, the U-Net produced consistent liver\nenhancement with fewer artifacts, while DDPM underperformed due to limited\npreservation of fine structural details. These findings demonstrate the\nfeasibility of synthetic HBP image generation as a means to reduce scan time\nwithout compromising diagnostic utility, highlighting the clinical potential of\ndeep learning for dynamic contrast enhancement in liver MRI. A project demo is\navailable at: https://jhooge.github.io/hepatogen", "published": "2025-04-25 15:01:09", "link": "http://arxiv.org/abs/2504.18405v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Partition Map-Based Fast Block Partitioning for VVC Inter Coding", "abstract": "Among the new techniques of Versatile Video Coding (VVC), the quadtree with\nnested multi-type tree (QT+MTT) block structure yields significant coding gains\nby providing more flexible block partitioning patterns. However, the recursive\npartition search in the VVC encoder increases the encoder complexity\nsubstantially. To address this issue, we propose a partition map-based\nalgorithm to pursue fast block partitioning in inter coding. Based on our\nprevious work on partition map-based methods for intra coding, we analyze the\ncharacteristics of VVC inter coding, and thus improve the partition map by\nincorporating an MTT mask for early termination. Next, we develop a neural\nnetwork that uses both spatial and temporal features to predict the partition\nmap. It consists of several special designs including stacked top-down and\nbottom-up processing, quantization parameter modulation layers, and\npartitioning-adaptive warping. Furthermore, we present a dual-threshold\ndecision scheme to achieve a fine-grained trade-off between complexity\nreduction and rate-distortion (RD) performance loss. The experimental results\ndemonstrate that the proposed method achieves an average 51.30% encoding time\nsaving with a 2.12% Bjontegaard Delta Bit Rate (BDBR) under the random access\nconfiguration.", "published": "2025-04-25 14:53:03", "link": "http://arxiv.org/abs/2504.18398v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Unsupervised Visual Chain-of-Thought Reasoning via Preference Optimization", "abstract": "Chain-of-thought (CoT) reasoning greatly improves the interpretability and\nproblem-solving abilities of multimodal large language models (MLLMs). However,\nexisting approaches are focused on text CoT, limiting their ability to leverage\nvisual cues. Visual CoT remains underexplored, and the only work is based on\nsupervised fine-tuning (SFT) that relies on extensive labeled bounding-box data\nand is hard to generalize to unseen cases. In this paper, we introduce\nUnsupervised Visual CoT (UV-CoT), a novel framework for image-level CoT\nreasoning via preference optimization. UV-CoT performs preference comparisons\nbetween model-generated bounding boxes (one is preferred and the other is\ndis-preferred), eliminating the need for bounding-box annotations. We get such\npreference data by introducing an automatic data generation pipeline. Given an\nimage, our target MLLM (e.g., LLaVA-1.5-7B) generates seed bounding boxes using\na template prompt and then answers the question using each bounded region as\ninput. An evaluator MLLM (e.g., OmniLLM-12B) ranks the responses, and these\nrankings serve as supervision to train the target MLLM with UV-CoT by\nminimizing negative log-likelihood losses. By emulating human\nperception--identifying key regions and reasoning based on them--UV-CoT can\nimprove visual comprehension, particularly in spatial reasoning tasks where\ntextual descriptions alone fall short. Our experiments on six datasets\ndemonstrate the superiority of UV-CoT, compared to the state-of-the-art textual\nand visual CoT methods. Our zero-shot testing on four unseen datasets shows the\nstrong generalization of UV-CoT. The code is available in\nhttps://github.com/kesenzhao/UV-CoT.", "published": "2025-04-25 14:48:18", "link": "http://arxiv.org/abs/2504.18397v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Interpretable Affordance Detection on 3D Point Clouds with Probabilistic Prototypes", "abstract": "Robotic agents need to understand how to interact with objects in their\nenvironment, both autonomously and during human-robot interactions. Affordance\ndetection on 3D point clouds, which identifies object regions that allow\nspecific interactions, has traditionally relied on deep learning models like\nPointNet++, DGCNN, or PointTransformerV3. However, these models operate as\nblack boxes, offering no insight into their decision-making processes.\nPrototypical Learning methods, such as ProtoPNet, provide an interpretable\nalternative to black-box models by employing a \"this looks like that\"\ncase-based reasoning approach. However, they have been primarily applied to\nimage-based tasks. In this work, we apply prototypical learning to models for\naffordance detection on 3D point clouds. Experiments on the 3D-AffordanceNet\nbenchmark dataset show that prototypical models achieve competitive performance\nwith state-of-the-art black-box models and offer inherent interpretability.\nThis makes prototypical models a promising candidate for human-robot\ninteraction scenarios that require increased trust and safety.", "published": "2025-04-25 13:52:39", "link": "http://arxiv.org/abs/2504.18355v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Revisiting Data Auditing in Large Vision-Language Models", "abstract": "With the surge of large language models (LLMs), Large Vision-Language Models\n(VLMs)--which integrate vision encoders with LLMs for accurate visual\ngrounding--have shown great potential in tasks like generalist agents and\nrobotic control. However, VLMs are typically trained on massive web-scraped\nimages, raising concerns over copyright infringement and privacy violations,\nand making data auditing increasingly urgent. Membership inference (MI), which\ndetermines whether a sample was used in training, has emerged as a key auditing\ntechnique, with promising results on open-source VLMs like LLaVA (AUC > 80%).\nIn this work, we revisit these advances and uncover a critical issue: current\nMI benchmarks suffer from distribution shifts between member and non-member\nimages, introducing shortcut cues that inflate MI performance. We further\nanalyze the nature of these shifts and propose a principled metric based on\noptimal transport to quantify the distribution discrepancy. To evaluate MI in\nrealistic settings, we construct new benchmarks with i.i.d. member and\nnon-member images. Existing MI methods fail under these unbiased conditions,\nperforming only marginally better than chance. Further, we explore the\ntheoretical upper bound of MI by probing the Bayes Optimality within the VLM's\nembedding space and find the irreducible error rate remains high. Despite this\npessimistic outlook, we analyze why MI for VLMs is particularly challenging and\nidentify three practical scenarios--fine-tuning, access to ground-truth texts,\nand set-based inference--where auditing becomes feasible. Our study presents a\nsystematic view of the limits and opportunities of MI for VLMs, providing\nguidance for future efforts in trustworthy data auditing.", "published": "2025-04-25 13:38:23", "link": "http://arxiv.org/abs/2504.18349v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "NUDF: Neural Unsigned Distance Fields for high resolution 3D medical image segmentation", "abstract": "Medical image segmentation is often considered as the task of labelling each\npixel or voxel as being inside or outside a given anatomy. Processing the\nimages at their original size and resolution often result in insuperable memory\nrequirements, but downsampling the images leads to a loss of important details.\nInstead of aiming to represent a smooth and continuous surface in a binary\nvoxel-grid, we propose to learn a Neural Unsigned Distance Field (NUDF)\ndirectly from the image. The small memory requirements of NUDF allow for high\nresolution processing, while the continuous nature of the distance field allows\nus to create high resolution 3D mesh models of shapes of any topology (i.e.\nopen surfaces). We evaluate our method on the task of left atrial appendage\n(LAA) segmentation from Computed Tomography (CT) images. The LAA is a complex\nand highly variable shape, being thus difficult to represent with traditional\nsegmentation methods using discrete labelmaps. With our proposed method, we are\nable to predict 3D mesh models that capture the details of the LAA and achieve\naccuracy in the order of the voxel spacing in the CT images.", "published": "2025-04-25 13:32:16", "link": "http://arxiv.org/abs/2504.18344v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations", "abstract": "The growing applications of AR/VR increase the demand for real-time full-body\npose estimation from Head-Mounted Displays (HMDs). Although HMDs provide joint\nsignals from the head and hands, reconstructing a full-body pose remains\nchallenging due to the unconstrained lower body. Recent advancements often rely\non conventional neural networks and generative models to improve performance in\nthis task, such as Transformers and diffusion models. However, these approaches\nstruggle to strike a balance between achieving precise pose reconstruction and\nmaintaining fast inference speed. To overcome these challenges, a lightweight\nand efficient model, SSD-Poser, is designed for robust full-body motion\nestimation from sparse observations. SSD-Poser incorporates a well-designed\nhybrid encoder, State Space Attention Encoders, to adapt the state space\nduality to complex motion poses and enable real-time realistic pose\nreconstruction. Moreover, a Frequency-Aware Decoder is introduced to mitigate\njitter caused by variable-frequency motion signals, remarkably enhancing the\nmotion smoothness. Comprehensive experiments on the AMASS dataset demonstrate\nthat SSD-Poser achieves exceptional accuracy and computational efficiency,\nshowing outstanding inference efficiency compared to state-of-the-art methods.", "published": "2025-04-25 13:18:06", "link": "http://arxiv.org/abs/2504.18332v1", "categories": ["cs.CV", "cs.HC", "68U05"], "primary_category": "cs.CV"}
{"title": "Depth3DLane: Monocular 3D Lane Detection via Depth Prior Distillation", "abstract": "Monocular 3D lane detection is challenging due to the difficulty in capturing\ndepth information from single-camera images. A common strategy involves\ntransforming front-view (FV) images into bird's-eye-view (BEV) space through\ninverse perspective mapping (IPM), facilitating lane detection using BEV\nfeatures. However, IPM's flat-ground assumption and loss of contextual\ninformation lead to inaccuracies in reconstructing 3D information, especially\nheight. In this paper, we introduce a BEV-based framework to address these\nlimitations and improve 3D lane detection accuracy. Our approach incorporates a\nHierarchical Depth-Aware Head that provides multi-scale depth features,\nmitigating the flat-ground assumption by enhancing spatial awareness across\nvarying depths. Additionally, we leverage Depth Prior Distillation to transfer\nsemantic depth knowledge from a teacher model, capturing richer structural and\ncontextual information for complex lane structures. To further refine lane\ncontinuity and ensure smooth lane reconstruction, we introduce a Conditional\nRandom Field module that enforces spatial coherence in lane predictions.\nExtensive experiments validate that our method achieves state-of-the-art\nperformance in terms of z-axis error and outperforms other methods in the field\nin overall performance. The code is released at:\nhttps://anonymous.4open.science/r/Depth3DLane-DCDD.", "published": "2025-04-25 13:08:41", "link": "http://arxiv.org/abs/2504.18325v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Outlier-aware Tensor Robust Principal Component Analysis with Self-guided Data Augmentation", "abstract": "Tensor Robust Principal Component Analysis (TRPCA) is a fundamental technique\nfor decomposing multi-dimensional data into a low-rank tensor and an outlier\ntensor, yet existing methods relying on sparse outlier assumptions often fail\nunder structured corruptions. In this paper, we propose a self-guided data\naugmentation approach that employs adaptive weighting to suppress outlier\ninfluence, reformulating the original TRPCA problem into a standard Tensor\nPrincipal Component Analysis (TPCA) problem. The proposed model involves an\noptimization-driven weighting scheme that dynamically identifies and\ndownweights outlier contributions during tensor augmentation. We develop an\nefficient proximal block coordinate descent algorithm with closed-form updates\nto solve the resulting optimization problem, ensuring computational efficiency.\nTheoretical convergence is guaranteed through a framework combining block\ncoordinate descent with majorization-minimization principles. Numerical\nexperiments on synthetic and real-world datasets, including face recovery,\nbackground subtraction, and hyperspectral denoising, demonstrate that our\nmethod effectively handles various corruption patterns. The results show the\nimprovements in both accuracy and computational efficiency compared to\nstate-of-the-art methods.", "published": "2025-04-25 13:03:35", "link": "http://arxiv.org/abs/2504.18323v1", "categories": ["math.NA", "cs.CV", "cs.LG", "cs.NA", "65K10, 15A69", "I.4.5; G.1.6"], "primary_category": "math.NA"}
{"title": "STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting", "abstract": "Text-to-4D generation is rapidly developing and widely applied in various\nscenarios. However, existing methods often fail to incorporate adequate\nspatio-temporal modeling and prompt alignment within a unified framework,\nresulting in temporal inconsistencies, geometric distortions, or low-quality 4D\ncontent that deviates from the provided texts. Therefore, we propose STP4D, a\nnovel approach that aims to integrate comprehensive spatio-temporal-prompt\nconsistency modeling for high-quality text-to-4D generation. Specifically,\nSTP4D employs three carefully designed modules: Time-varying Prompt Embedding,\nGeometric Information Enhancement, and Temporal Extension Deformation, which\ncollaborate to accomplish this goal. Furthermore, STP4D is among the first\nmethods to exploit the Diffusion model to generate 4D Gaussians, combining the\nfine-grained modeling capabilities and the real-time rendering process of 4DGS\nwith the rapid inference speed of the Diffusion model. Extensive experiments\ndemonstrate that STP4D excels in generating high-fidelity 4D content with\nexceptional efficiency (approximately 4.6s per asset), surpassing existing\nmethods in both quality and speed.", "published": "2025-04-25 12:53:15", "link": "http://arxiv.org/abs/2504.18318v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy", "abstract": "To support the Low Altitude Economy (LAE), precise unmanned aerial vehicles\n(UAVs) localization in urban areas where global positioning system (GPS)\nsignals are unavailable. Vision-based methods offer a viable alternative but\nface severe bandwidth, memory and processing constraints on lightweight UAVs.\nInspired by mammalian spatial cognition, we propose a task-oriented\ncommunication framework, where UAVs equipped with multi-camera systems extract\ncompact multi-view features and offload localization tasks to edge servers. We\nintroduce the Orthogonally-constrained Variational Information Bottleneck\nencoder (O-VIB), which incorporates automatic relevance determination (ARD) to\nprune non-informative features while enforcing orthogonality to minimize\nredundancy. This enables efficient and accurate localization with minimal\ntransmission cost. Extensive evaluation on a dedicated LAE UAV dataset shows\nthat O-VIB achieves high-precision localization under stringent bandwidth\nbudgets. Code and dataset will be made publicly available:\ngithub.com/fangzr/TOC-Edge-Aerial.", "published": "2025-04-25 12:49:14", "link": "http://arxiv.org/abs/2504.18317v1", "categories": ["cs.CV", "cs.NI"], "primary_category": "cs.CV"}
{"title": "Towards a deep learning approach for classifying treatment response in glioblastomas", "abstract": "Glioblastomas are the most aggressive type of glioma, having a 5-year\nsurvival rate of 6.9%. Treatment typically involves surgery, followed by\nradiotherapy and chemotherapy, and frequent magnetic resonance imaging (MRI)\nscans to monitor disease progression. To assess treatment response,\nradiologists use the Response Assessment in Neuro-Oncology (RANO) criteria to\ncategorize the tumor into one of four labels based on imaging and clinical\nfeatures: complete response, partial response, stable disease, and progressive\ndisease. This assessment is very complex and time-consuming. Since deep\nlearning (DL) has been widely used to tackle classification problems, this work\naimed to implement the first DL pipeline for the classification of RANO\ncriteria based on two consecutive MRI acquisitions. The models were trained and\ntested on the open dataset LUMIERE. Five approaches were tested: 1) subtraction\nof input images, 2) different combinations of modalities, 3) different model\narchitectures, 4) different pretraining tasks, and 5) adding clinical data. The\npipeline that achieved the best performance used a Densenet264 considering only\nT1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR)\nimages as input without any pretraining. A median Balanced Accuracy of 50.96%\nwas achieved. Additionally, explainability methods were applied. Using Saliency\nMaps, the tumor region was often successfully highlighted. In contrast,\nGrad-CAM typically failed to highlight the tumor region, with some exceptions\nobserved in the Complete Response and Progressive Disease classes, where it\neffectively identified the tumor region. These results set a benchmark for\nfuture studies on glioblastoma treatment response assessment based on the RANO\ncriteria while emphasizing the heterogeneity of factors that might play a role\nwhen assessing the tumor's response to treatment.", "published": "2025-04-25 11:27:05", "link": "http://arxiv.org/abs/2504.18268v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology", "abstract": "With the exacerbation of the biodiversity and climate crises, macroecological\npursuits such as global biodiversity mapping become more urgent. Remote sensing\noffers a wealth of Earth observation data for ecological studies, but the\nscarcity of labeled datasets remains a major challenge. Recently,\nself-supervised learning has enabled learning representations from unlabeled\ndata, triggering the development of pretrained geospatial models with\ngeneralizable features. However, these models are often trained on datasets\nbiased toward areas of high human activity, leaving entire ecological regions\nunderrepresented. Additionally, while some datasets attempt to address\nseasonality through multi-date imagery, they typically follow calendar seasons\nrather than local phenological cycles. To better capture vegetation seasonality\nat a global scale, we propose a simple phenology-informed sampling strategy and\nintroduce corresponding SSL4Eco, a multi-date Sentinel-2 dataset, on which we\ntrain an existing model with a season-contrastive objective. We compare\nrepresentations learned from SSL4Eco against other datasets on diverse\necological downstream tasks and demonstrate that our straightforward sampling\nmethod consistently improves representation quality, highlighting the\nimportance of dataset construction. The model pretrained on SSL4Eco reaches\nstate of the art performance on 7 out of 8 downstream tasks spanning\n(multi-label) classification and regression. We release our code, data, and\nmodel weights to support macroecological and computer vision research at\nhttps://github.com/PlekhanovaElena/ssl4eco.", "published": "2025-04-25 10:58:44", "link": "http://arxiv.org/abs/2504.18256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BiasBench: A reproducible benchmark for tuning the biases of event cameras", "abstract": "Event-based cameras are bio-inspired sensors that detect light changes\nasynchronously for each pixel. They are increasingly used in fields like\ncomputer vision and robotics because of several advantages over traditional\nframe-based cameras, such as high temporal resolution, low latency, and high\ndynamic range. As with any camera, the output's quality depends on how well the\ncamera's settings, called biases for event-based cameras, are configured. While\nframe-based cameras have advanced automatic configuration algorithms, there are\nvery few such tools for tuning these biases. A systematic testing framework\nwould require observing the same scene with different biases, which is tricky\nsince event cameras only generate events when there is movement. Event\nsimulators exist, but since biases heavily depend on the electrical circuit and\nthe pixel design, available simulators are not well suited for bias tuning. To\nallow reproducibility, we present BiasBench, a novel event dataset containing\nmultiple scenes with settings sampled in a grid-like pattern. We present three\ndifferent scenes, each with a quality metric of the downstream application.\nAdditionally, we present a novel, RL-based method to facilitate online bias\nadjustments.", "published": "2025-04-25 10:33:24", "link": "http://arxiv.org/abs/2504.18235v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Dense Geometry Supervision for Underwater Depth Estimation", "abstract": "The field of monocular depth estimation is continually evolving with the\nadvent of numerous innovative models and extensions. However, research on\nmonocular depth estimation methods specifically for underwater scenes remains\nlimited, compounded by a scarcity of relevant data and methodological support.\nThis paper proposes a novel approach to address the existing challenges in\ncurrent monocular depth estimation methods for underwater environments. We\nconstruct an economically efficient dataset suitable for underwater scenarios\nby employing multi-view depth estimation to generate supervisory signals and\ncorresponding enhanced underwater images. we introduces a texture-depth fusion\nmodule, designed according to the underwater optical imaging principles, which\naims to effectively exploit and integrate depth information from texture cues.\nExperimental results on the FLSea dataset demonstrate that our approach\nsignificantly improves the accuracy and adaptability of models in underwater\nsettings. This work offers a cost-effective solution for monocular underwater\ndepth estimation and holds considerable promise for practical applications.", "published": "2025-04-25 10:27:25", "link": "http://arxiv.org/abs/2504.18233v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unify3D: An Augmented Holistic End-to-end Monocular 3D Human Reconstruction via Anatomy Shaping and Twins Negotiating", "abstract": "Monocular 3D clothed human reconstruction aims to create a complete 3D avatar\nfrom a single image. To tackle the human geometry lacking in one RGB image,\ncurrent methods typically resort to a preceding model for an explicit geometric\nrepresentation. For the reconstruction itself, focus is on modeling both it and\nthe input image. This routine is constrained by the preceding model, and\noverlooks the integrity of the reconstruction task. To address this, this paper\nintroduces a novel paradigm that treats human reconstruction as a holistic\nprocess, utilizing an end-to-end network for direct prediction from 2D image to\n3D avatar, eliminating any explicit intermediate geometry display. Based on\nthis, we further propose a novel reconstruction framework consisting of two\ncore components: the Anatomy Shaping Extraction module, which captures implicit\nshape features taking into account the specialty of human anatomy, and the\nTwins Negotiating Reconstruction U-Net, which enhances reconstruction through\nfeature interaction between two U-Nets of different modalities. Moreover, we\npropose a Comic Data Augmentation strategy and construct 15k+ 3D human scans to\nbolster model performance in more complex case input. Extensive experiments on\ntwo test sets and many in-the-wild cases show the superiority of our method\nover SOTA methods. Our demos can be found in :\nhttps://e2e3dgsrecon.github.io/e2e3dgsrecon/.", "published": "2025-04-25 09:49:23", "link": "http://arxiv.org/abs/2504.18215v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Data-Centric Approach to 3D Semantic Segmentation of Railway Scenes", "abstract": "LiDAR-based semantic segmentation is critical for autonomous trains,\nrequiring accurate predictions across varying distances. This paper introduces\ntwo targeted data augmentation methods designed to improve segmentation\nperformance on the railway-specific OSDaR23 dataset. The person instance\npasting method enhances segmentation of pedestrians at distant ranges by\ninjecting realistic variations into the dataset. The track sparsification\nmethod redistributes point density in LiDAR scans, improving track segmentation\nat far distances with minimal impact on close-range accuracy. Both methods are\nevaluated using a state-of-the-art 3D semantic segmentation network,\ndemonstrating significant improvements in distant-range performance while\nmaintaining robustness in close-range predictions. We establish the first 3D\nsemantic segmentation benchmark for OSDaR23, demonstrating the potential of\ndata-centric approaches to address railway-specific challenges in autonomous\ntrain perception.", "published": "2025-04-25 09:46:31", "link": "http://arxiv.org/abs/2504.18213v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gradient Descent as a Shrinkage Operator for Spectral Bias", "abstract": "We generalize the connection between activation function and spline\nregression/smoothing and characterize how this choice may influence spectral\nbias within a 1D shallow network. We then demonstrate how gradient descent (GD)\ncan be reinterpreted as a shrinkage operator that masks the singular values of\na neural network's Jacobian. Viewed this way, GD implicitly selects the number\nof frequency components to retain, thereby controlling the spectral bias. An\nexplicit relationship is proposed between the choice of GD hyperparameters\n(learning rate & number of iterations) and bandwidth (the number of active\ncomponents). GD regularization is shown to be effective only with monotonic\nactivation functions. Finally, we highlight the utility of non-monotonic\nactivation functions (sinc, Gaussian) as iteration-efficient surrogates for\nspectral bias.", "published": "2025-04-25 09:36:17", "link": "http://arxiv.org/abs/2504.18207v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Optimizing Multi-Round Enhanced Training in Diffusion Models for Improved Preference Understanding", "abstract": "Generative AI has significantly changed industries by enabling text-driven\nimage generation, yet challenges remain in achieving high-resolution outputs\nthat align with fine-grained user preferences. Consequently, multi-round\ninteractions are necessary to ensure the generated images meet expectations.\nPrevious methods enhanced prompts via reward feedback but did not optimize over\na multi-round dialogue dataset. In this work, we present a Visual Co-Adaptation\n(VCA) framework incorporating human-in-the-loop feedback, leveraging a\nwell-trained reward model aligned with human preferences. Using a diverse\nmulti-turn dialogue dataset, our framework applies multiple reward functions,\nsuch as diversity, consistency, and preference feedback, while fine-tuning the\ndiffusion model through LoRA, thus optimizing image generation based on user\ninput. We also construct multi-round dialogue datasets of prompts and image\npairs aligned with user intent. Experiments demonstrate that our method\noutperforms state-of-the-art baselines, significantly improving image\nconsistency and alignment with user intent. Our approach consistently surpasses\ncompeting models in user satisfaction, especially in multi-turn dialogue\nscenarios.", "published": "2025-04-25 09:35:02", "link": "http://arxiv.org/abs/2504.18204v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LiDAR-Guided Monocular 3D Object Detection for Long-Range Railway Monitoring", "abstract": "Railway systems, particularly in Germany, require high levels of automation\nto address legacy infrastructure challenges and increase train traffic safely.\nA key component of automation is robust long-range perception, essential for\nearly hazard detection, such as obstacles at level crossings or pedestrians on\ntracks. Unlike automotive systems with braking distances of ~70 meters, trains\nrequire perception ranges exceeding 1 km. This paper presents an\ndeep-learning-based approach for long-range 3D object detection tailored for\nautonomous trains. The method relies solely on monocular images, inspired by\nthe Faraway-Frustum approach, and incorporates LiDAR data during training to\nimprove depth estimation. The proposed pipeline consists of four key modules:\n(1) a modified YOLOv9 for 2.5D object detection, (2) a depth estimation\nnetwork, and (3-4) dedicated short- and long-range 3D detection heads.\nEvaluations on the OSDaR23 dataset demonstrate the effectiveness of the\napproach in detecting objects up to 250 meters. Results highlight its potential\nfor railway automation and outline areas for future improvement.", "published": "2025-04-25 09:33:52", "link": "http://arxiv.org/abs/2504.18203v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "What is the Added Value of UDA in the VFM Era?", "abstract": "Unsupervised Domain Adaptation (UDA) can improve a perception model's\ngeneralization to an unlabeled target domain starting from a labeled source\ndomain. UDA using Vision Foundation Models (VFMs) with synthetic source data\ncan achieve generalization performance comparable to fully-supervised learning\nwith real target data. However, because VFMs have strong generalization from\ntheir pre-training, more straightforward, source-only fine-tuning can also\nperform well on the target. As data scenarios used in academic research are not\nnecessarily representative for real-world applications, it is currently unclear\n(a) how UDA behaves with more representative and diverse data and (b) if\nsource-only fine-tuning of VFMs can perform equally well in these scenarios.\nOur research aims to close these gaps and, similar to previous studies, we\nfocus on semantic segmentation as a representative perception task. We assess\nUDA for synth-to-real and real-to-real use cases with different source and\ntarget data combinations. We also investigate the effect of using a small\namount of labeled target data in UDA. We clarify that while these scenarios are\nmore realistic, they are not necessarily more challenging. Our results show\nthat, when using stronger synthetic source data, UDA's improvement over\nsource-only fine-tuning of VFMs reduces from +8 mIoU to +2 mIoU, and when using\nmore diverse real source data, UDA has no added value. However, UDA\ngeneralization is always higher in all synthetic data scenarios than\nsource-only fine-tuning and, when including only 1/16 of Cityscapes labels,\nsynthetic UDA obtains the same state-of-the-art segmentation quality of 85 mIoU\nas a fully-supervised model using all labels. Considering the mixed results, we\ndiscuss how UDA can best support robust autonomous driving at scale.", "published": "2025-04-25 09:10:10", "link": "http://arxiv.org/abs/2504.18190v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Label-independent hyperparameter-free self-supervised single-view deep subspace clustering", "abstract": "Deep subspace clustering (DSC) algorithms face several challenges that hinder\ntheir widespread adoption across variois application domains. First, clustering\nquality is typically assessed using only the encoder's output layer,\ndisregarding valuable information present in the intermediate layers. Second,\nmost DSC approaches treat representation learning and subspace clustering as\nindependent tasks, limiting their effectiveness. Third, they assume the\navailability of a held-out dataset for hyperparameter tuning, which is often\nimpractical in real-world scenarios. Fourth, learning termination is commonly\nbased on clustering error monitoring, requiring external labels. Finally, their\nperformance often depends on post-processing techniques that rely on labeled\ndata. To address this limitations, we introduce a novel single-view DSC\napproach that: (i) minimizes a layer-wise self expression loss using a joint\nrepresentation matrix; (ii) optimizes a subspace-structured norm to enhance\nclustering quality; (iii) employs a multi-stage sequential learning framework,\nconsisting of pre-training and fine-tuning, enabling the use of multiple\nregularization terms without hyperparameter tuning; (iv) incorporates a\nrelative error-based self-stopping mechanism to terminate training without\nlabels; and (v) retains a fixed number of leading coefficients in the learned\nrepresentation matrix based on prior knowledge. We evaluate the proposed method\non six datasets representing faces, digits, and objects. The results show that\nour method outperforms most linear SC algorithms with careffulyl tuned\nhyperparameters while maintaining competitive performance with the best\nperforming linear appoaches.", "published": "2025-04-25 08:54:34", "link": "http://arxiv.org/abs/2504.18179v1", "categories": ["cs.CV", "cs.LG", "68", "I.5.3; I.4.6; I.4.10"], "primary_category": "cs.CV"}
{"title": "E-InMeMo: Enhanced Prompting for Visual In-Context Learning", "abstract": "Large-scale models trained on extensive datasets have become the standard due\nto their strong generalizability across diverse tasks. In-context learning\n(ICL), widely used in natural language processing, leverages these models by\nproviding task-specific prompts without modifying their parameters. This\nparadigm is increasingly being adapted for computer vision, where models\nreceive an input-output image pair, known as an in-context pair, alongside a\nquery image to illustrate the desired output. However, the success of visual\nICL largely hinges on the quality of these prompts. To address this, we propose\nEnhanced Instruct Me More (E-InMeMo), a novel approach that incorporates\nlearnable perturbations into in-context pairs to optimize prompting. Through\nextensive experiments on standard vision tasks, E-InMeMo demonstrates superior\nperformance over existing state-of-the-art methods. Notably, it improves mIoU\nscores by 7.99 for foreground segmentation and by 17.04 for single object\ndetection when compared to the baseline without learnable prompts. These\nresults highlight E-InMeMo as a lightweight yet effective strategy for\nenhancing visual ICL. Code is publicly available at:\nhttps://github.com/Jackieam/E-InMeMo", "published": "2025-04-25 08:12:58", "link": "http://arxiv.org/abs/2504.18158v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding", "abstract": "Fine-grained understanding of human actions and poses in videos is essential\nfor human-centric AI applications. In this work, we introduce ActionArt, a\nfine-grained video-caption dataset designed to advance research in\nhuman-centric multimodal understanding. Our dataset comprises thousands of\nvideos capturing a broad spectrum of human actions, human-object interactions,\nand diverse scenarios, each accompanied by detailed annotations that\nmeticulously label every limb movement. We develop eight sub-tasks to evaluate\nthe fine-grained understanding capabilities of existing large multimodal models\nacross different dimensions. Experimental results indicate that, while current\nlarge multimodal models perform commendably on various tasks, they often fall\nshort in achieving fine-grained understanding. We attribute this limitation to\nthe scarcity of meticulously annotated data, which is both costly and difficult\nto scale manually. Since manual annotations are costly and hard to scale, we\npropose proxy tasks to enhance the model perception ability in both spatial and\ntemporal dimensions. These proxy tasks are carefully crafted to be driven by\ndata automatically generated from existing MLLMs, thereby reducing the reliance\non costly manual labels. Experimental results show that the proposed proxy\ntasks significantly narrow the gap toward the performance achieved with\nmanually annotated fine-grained data.", "published": "2025-04-25 08:05:32", "link": "http://arxiv.org/abs/2504.18152v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MASF-YOLO: An Improved YOLOv11 Network for Small Object Detection on Drone View", "abstract": "With the rapid advancement of Unmanned Aerial Vehicle (UAV) and computer\nvision technologies, object detection from UAV perspectives has emerged as a\nprominent research area. However, challenges for detection brought by the\nextremely small proportion of target pixels, significant scale variations of\nobjects, and complex background information in UAV images have greatly limited\nthe practical applications of UAV. To address these challenges, we propose a\nnovel object detection network Multi-scale Context Aggregation and\nScale-adaptive Fusion YOLO (MASF-YOLO), which is developed based on YOLOv11.\nFirstly, to tackle the difficulty of detecting small objects in UAV images, we\ndesign a Multi-scale Feature Aggregation Module (MFAM), which significantly\nimproves the detection accuracy of small objects through parallel multi-scale\nconvolutions and feature fusion. Secondly, to mitigate the interference of\nbackground noise, we propose an Improved Efficient Multi-scale Attention Module\n(IEMA), which enhances the focus on target regions through feature grouping,\nparallel sub-networks, and cross-spatial learning. Thirdly, we introduce a\nDimension-Aware Selective Integration Module (DASI), which further enhances\nmulti-scale feature fusion capabilities by adaptively weighting and fusing\nlow-dimensional features and high-dimensional features. Finally, we conducted\nextensive performance evaluations of our proposed method on the VisDrone2019\ndataset. Compared to YOLOv11-s, MASFYOLO-s achieves improvements of 4.6% in\nmAP@0.5 and 3.5% in mAP@0.5:0.95 on the VisDrone2019 validation set.\nRemarkably, MASF-YOLO-s outperforms YOLOv11-m while requiring only\napproximately 60% of its parameters and 65% of its computational cost.\nFurthermore, comparative experiments with state-of-the-art detectors confirm\nthat MASF-YOLO-s maintains a clear competitive advantage in both detection\naccuracy and model efficiency.", "published": "2025-04-25 07:43:33", "link": "http://arxiv.org/abs/2504.18136v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Salient Region-Guided Spacecraft Image Arbitrary-Scale Super-Resolution Network", "abstract": "Spacecraft image super-resolution seeks to enhance low-resolution spacecraft\nimages into high-resolution ones. Although existing arbitrary-scale\nsuper-resolution methods perform well on general images, they tend to overlook\nthe difference in features between the spacecraft core region and the large\nblack space background, introducing irrelevant noise. In this paper, we propose\na salient region-guided spacecraft image arbitrary-scale super-resolution\nnetwork (SGSASR), which uses features from the spacecraft core salient regions\nto guide latent modulation and achieve arbitrary-scale super-resolution.\nSpecifically, we design a spacecraft core region recognition block (SCRRB) that\nidentifies the core salient regions in spacecraft images using a pre-trained\nsaliency detection model. Furthermore, we present an adaptive-weighted feature\nfusion enhancement mechanism (AFFEM) to selectively aggregate the spacecraft\ncore region features with general image features by dynamic weight parameter to\nenhance the response of the core salient regions. Experimental results\ndemonstrate that the proposed SGSASR outperforms state-of-the-art approaches.", "published": "2025-04-25 07:23:13", "link": "http://arxiv.org/abs/2504.18127v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Study on Real-Time Road Surface Reconstruction Using Stereo Vision", "abstract": "Road surface reconstruction plays a crucial role in autonomous driving,\nproviding essential information for safe and smooth navigation. This paper\nenhances the RoadBEV [1] framework for real-time inference on edge devices by\noptimizing both efficiency and accuracy. To achieve this, we proposed to apply\nIsomorphic Global Structured Pruning to the stereo feature extraction backbone,\nreducing network complexity while maintaining performance. Additionally, the\nhead network is redesigned with an optimized hourglass structure, dynamic\nattention heads, reduced feature channels, mixed precision inference, and\nefficient probability volume computation. Our approach improves inference speed\nwhile achieving lower reconstruction error, making it well-suited for real-time\nroad surface reconstruction in autonomous driving.", "published": "2025-04-25 06:30:50", "link": "http://arxiv.org/abs/2504.18112v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Disentangle Identity, Cooperate Emotion: Correlation-Aware Emotional Talking Portrait Generation", "abstract": "Recent advances in Talking Head Generation (THG) have achieved impressive lip\nsynchronization and visual quality through diffusion models; yet existing\nmethods struggle to generate emotionally expressive portraits while preserving\nspeaker identity. We identify three critical limitations in current emotional\ntalking head generation: insufficient utilization of audio's inherent emotional\ncues, identity leakage in emotion representations, and isolated learning of\nemotion correlations. To address these challenges, we propose a novel framework\ndubbed as DICE-Talk, following the idea of disentangling identity with emotion,\nand then cooperating emotions with similar characteristics. First, we develop a\ndisentangled emotion embedder that jointly models audio-visual emotional cues\nthrough cross-modal attention, representing emotions as identity-agnostic\nGaussian distributions. Second, we introduce a correlation-enhanced emotion\nconditioning module with learnable Emotion Banks that explicitly capture\ninter-emotion relationships through vector quantization and attention-based\nfeature aggregation. Third, we design an emotion discrimination objective that\nenforces affective consistency during the diffusion process through\nlatent-space classification. Extensive experiments on MEAD and HDTF datasets\ndemonstrate our method's superiority, outperforming state-of-the-art approaches\nin emotion accuracy while maintaining competitive lip-sync performance.\nQualitative results and user studies further confirm our method's ability to\ngenerate identity-preserving portraits with rich, correlated emotional\nexpressions that naturally adapt to unseen identities.", "published": "2025-04-25 05:28:21", "link": "http://arxiv.org/abs/2504.18087v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physics-Driven Neural Compensation For Electrical Impedance Tomography", "abstract": "Electrical Impedance Tomography (EIT) provides a non-invasive, portable\nimaging modality with significant potential in medical and industrial\napplications. Despite its advantages, EIT encounters two primary challenges:\nthe ill-posed nature of its inverse problem and the spatially variable,\nlocation-dependent sensitivity distribution. Traditional model-based methods\nmitigate ill-posedness through regularization but overlook sensitivity\nvariability, while supervised deep learning approaches require extensive\ntraining data and lack generalization. Recent developments in neural fields\nhave introduced implicit regularization techniques for image reconstruction,\nbut these methods typically neglect the physical principles underlying EIT,\nthus limiting their effectiveness. In this study, we propose PhyNC\n(Physics-driven Neural Compensation), an unsupervised deep learning framework\nthat incorporates the physical principles of EIT. PhyNC addresses both the\nill-posed inverse problem and the sensitivity distribution by dynamically\nallocating neural representational capacity to regions with lower sensitivity,\nensuring accurate and balanced conductivity reconstructions. Extensive\nevaluations on both simulated and experimental data demonstrate that PhyNC\noutperforms existing methods in terms of detail preservation and artifact\nresistance, particularly in low-sensitivity regions. Our approach enhances the\nrobustness of EIT reconstructions and provides a flexible framework that can be\nadapted to other imaging modalities with similar challenges.", "published": "2025-04-25 04:44:00", "link": "http://arxiv.org/abs/2504.18067v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "POET: Prompt Offset Tuning for Continual Human Action Adaptation", "abstract": "As extended reality (XR) is redefining how users interact with computing\ndevices, research in human action recognition is gaining prominence. Typically,\nmodels deployed on immersive computing devices are static and limited to their\ndefault set of classes. The goal of our research is to provide users and\ndevelopers with the capability to personalize their experience by adding new\naction classes to their device models continually. Importantly, a user should\nbe able to add new classes in a low-shot and efficient manner, while this\nprocess should not require storing or replaying any of user's sensitive\ntraining data. We formalize this problem as privacy-aware few-shot continual\naction recognition. Towards this end, we propose POET: Prompt-Offset Tuning.\nWhile existing prompt tuning approaches have shown great promise for continual\nlearning of image, text, and video modalities; they demand access to\nextensively pretrained transformers. Breaking away from this assumption, POET\ndemonstrates the efficacy of prompt tuning a significantly lightweight\nbackbone, pretrained exclusively on the base class data. We propose a novel\nspatio-temporal learnable prompt offset tuning approach, and are the first to\napply such prompt tuning to Graph Neural Networks. We contribute two new\nbenchmarks for our new problem setting in human action recognition: (i) NTU\nRGB+D dataset for activity recognition, and (ii) SHREC-2017 dataset for hand\ngesture recognition. We find that POET consistently outperforms comprehensive\nbenchmarks. Source code at\nhttps://github.com/humansensinglab/POET-continual-action-recognition.", "published": "2025-04-25 04:11:24", "link": "http://arxiv.org/abs/2504.18059v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cabbage: A Differential Growth Framework for Open Surfaces", "abstract": "We propose Cabbage, a differential growth framework to model buckling\nbehavior in 3D open surfaces found in nature-like the curling of flower petals.\nCabbage creates high-quality triangular meshes free of self-intersection.\nCabbage-Shell is driven by edge subdivision which differentially increases\ndiscretization resolution. Shell forces expands the surface, generating\nbuckling over time. Feature-aware smoothing and remeshing ensures mesh quality.\nCorrective collision effectively prevents self-collision even in tight spaces.\nWe additionally provide Cabbage-Collision, and approximate alternative,\nfollowed by CAD-ready surface generation. Cabbage is the first open-source\neffort with this calibre and robustness, outperforming SOTA methods in its\nmorphological expressiveness, mesh quality, and stably generates large, complex\npatterns over hundreds of simulation steps. It is a source not only of\ncomputational modeling, digital fabrication, education, but also high-quality,\nannotated data for geometry processing and shape analysis.", "published": "2025-04-25 03:25:13", "link": "http://arxiv.org/abs/2504.18040v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Privacy-Utility Trade-offs to Mitigate Memorization in Diffusion Models", "abstract": "Text-to-image diffusion models have demonstrated remarkable capabilities in\ncreating images highly aligned with user prompts, yet their proclivity for\nmemorizing training set images has sparked concerns about the originality of\nthe generated images and privacy issues, potentially leading to legal\ncomplications for both model owners and users, particularly when the memorized\nimages contain proprietary content. Although methods to mitigate these issues\nhave been suggested, enhancing privacy often results in a significant decrease\nin the utility of the outputs, as indicated by text-alignment scores. To bridge\nthe research gap, we introduce a novel method, PRSS, which refines the\nclassifier-free guidance approach in diffusion models by integrating prompt\nre-anchoring (PR) to improve privacy and incorporating semantic prompt search\n(SS) to enhance utility. Extensive experiments across various privacy levels\ndemonstrate that our approach consistently improves the privacy-utility\ntrade-off, establishing a new state-of-the-art.", "published": "2025-04-25 02:51:23", "link": "http://arxiv.org/abs/2504.18032v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ShapeSpeak: Body Shape-Aware Textual Alignment for Visible-Infrared Person Re-Identification", "abstract": "Visible-Infrared Person Re-identification (VIReID) aims to match visible and\ninfrared pedestrian images, but the modality differences and the complexity of\nidentity features make it challenging. Existing methods rely solely on identity\nlabel supervision, which makes it difficult to fully extract high-level\nsemantic information. Recently, vision-language pre-trained models have been\nintroduced to VIReID, enhancing semantic information modeling by generating\ntextual descriptions. However, such methods do not explicitly model body shape\nfeatures, which are crucial for cross-modal matching. To address this, we\npropose an effective Body Shape-aware Textual Alignment (BSaTa) framework that\nexplicitly models and utilizes body shape information to improve VIReID\nperformance. Specifically, we design a Body Shape Textual Alignment (BSTA)\nmodule that extracts body shape information using a human parsing model and\nconverts it into structured text representations via CLIP. We also design a\nText-Visual Consistency Regularizer (TVCR) to ensure alignment between body\nshape textual representations and visual body shape features. Furthermore, we\nintroduce a Shape-aware Representation Learning (SRL) mechanism that combines\nMulti-text Supervision and Distribution Consistency Constraints to guide the\nvisual encoder to learn modality-invariant and discriminative identity\nfeatures, thus enhancing modality invariance. Experimental results demonstrate\nthat our method achieves superior performance on the SYSU-MM01 and RegDB\ndatasets, validating its effectiveness.", "published": "2025-04-25 02:37:47", "link": "http://arxiv.org/abs/2504.18025v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Federated Client-tailored Adapter for Medical Image Segmentation", "abstract": "Medical image segmentation in X-ray images is beneficial for computer-aided\ndiagnosis and lesion localization. Existing methods mainly fall into a\ncentralized learning paradigm, which is inapplicable in the practical medical\nscenario that only has access to distributed data islands. Federated Learning\nhas the potential to offer a distributed solution but struggles with heavy\ntraining instability due to client-wise domain heterogeneity (including\ndistribution diversity and class imbalance). In this paper, we propose a novel\nFederated Client-tailored Adapter (FCA) framework for medical image\nsegmentation, which achieves stable and client-tailored adaptive segmentation\nwithout sharing sensitive local data. Specifically, the federated adapter stirs\nuniversal knowledge in off-the-shelf medical foundation models to stabilize the\nfederated training process. In addition, we develop two client-tailored\nfederated updating strategies that adaptively decompose the adapter into common\nand individual components, then globally and independently update the parameter\ngroups associated with common client-invariant and individual client-specific\nunits, respectively. They further stabilize the heterogeneous federated\nlearning process and realize optimal client-tailored instead of sub-optimal\nglobal-compromised segmentation models. Extensive experiments on three\nlarge-scale datasets demonstrate the effectiveness and superiority of the\nproposed FCA framework for federated medical segmentation.", "published": "2025-04-25 02:20:25", "link": "http://arxiv.org/abs/2504.18020v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diffusion-Driven Universal Model Inversion Attack for Face Recognition", "abstract": "Facial recognition technology poses significant privacy risks, as it relies\non biometric data that is inherently sensitive and immutable if compromised. To\nmitigate these concerns, face recognition systems convert raw images into\nembeddings, traditionally considered privacy-preserving. However, model\ninversion attacks pose a significant privacy threat by reconstructing these\nprivate facial images, making them a crucial tool for evaluating the privacy\nrisks of face recognition systems. Existing methods usually require training\nindividual generators for each target model, a computationally expensive\nprocess. In this paper, we propose DiffUMI, a training-free diffusion-driven\nuniversal model inversion attack for face recognition systems. DiffUMI is the\nfirst approach to apply a diffusion model for unconditional image generation in\nmodel inversion. Unlike other methods, DiffUMI is universal, eliminating the\nneed for training target-specific generators. It operates within a fixed\nframework and pretrained diffusion model while seamlessly adapting to diverse\ntarget identities and models. DiffUMI breaches privacy-preserving face\nrecognition systems with state-of-the-art success, demonstrating that an\nunconditional diffusion model, coupled with optimized adversarial search,\nenables efficient and high-fidelity facial reconstruction. Additionally, we\nintroduce a novel application of out-of-domain detection (OODD), marking the\nfirst use of model inversion to distinguish non-face inputs from face inputs\nbased solely on embeddings.", "published": "2025-04-25 01:53:27", "link": "http://arxiv.org/abs/2504.18015v1", "categories": ["cs.CR", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Back to Fundamentals: Low-Level Visual Features Guided Progressive Token Pruning", "abstract": "Vision Transformers (ViTs) excel in semantic segmentation but demand\nsignificant computation, posing challenges for deployment on\nresource-constrained devices. Existing token pruning methods often overlook\nfundamental visual data characteristics. This study introduces 'LVTP', a\nprogressive token pruning framework guided by multi-scale Tsallis entropy and\nlow-level visual features with twice clustering. It integrates high-level\nsemantics and basic visual attributes for precise segmentation. A novel dynamic\nscoring mechanism using multi-scale Tsallis entropy weighting overcomes\nlimitations of traditional single-parameter entropy. The framework also\nincorporates low-level feature analysis to preserve critical edge information\nwhile optimizing computational cost. As a plug-and-play module, it requires no\narchitectural changes or additional training. Evaluations across multiple\ndatasets show 20%-45% computational reductions with negligible performance\nloss, outperforming existing methods in balancing cost and accuracy, especially\nin complex edge regions.", "published": "2025-04-25 00:43:20", "link": "http://arxiv.org/abs/2504.17996v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RSRNav: Reasoning Spatial Relationship for Image-Goal Navigation", "abstract": "Recent image-goal navigation (ImageNav) methods learn a perception-action\npolicy by separately capturing semantic features of the goal and egocentric\nimages, then passing them to a policy network. However, challenges remain: (1)\nSemantic features often fail to provide accurate directional information,\nleading to superfluous actions, and (2) performance drops significantly when\nviewpoint inconsistencies arise between training and application. To address\nthese challenges, we propose RSRNav, a simple yet effective method that reasons\nspatial relationships between the goal and current observations as navigation\nguidance. Specifically, we model the spatial relationship by constructing\ncorrelations between the goal and current observations, which are then passed\nto the policy network for action prediction. These correlations are\nprogressively refined using fine-grained cross-correlation and direction-aware\ncorrelation for more precise navigation. Extensive evaluation of RSRNav on\nthree benchmark datasets demonstrates superior navigation performance,\nparticularly in the \"user-matched goal\" setting, highlighting its potential for\nreal-world applications.", "published": "2025-04-25 00:22:17", "link": "http://arxiv.org/abs/2504.17991v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "From Mapping to Composing: A Two-Stage Framework for Zero-shot Composed Image Retrieval", "abstract": "Composed Image Retrieval (CIR) is a challenging multimodal task that\nretrieves a target image based on a reference image and accompanying\nmodification text. Due to the high cost of annotating CIR triplet datasets,\nzero-shot (ZS) CIR has gained traction as a promising alternative. Existing\nstudies mainly focus on projection-based methods, which map an image to a\nsingle pseudo-word token. However, these methods face three critical\nchallenges: (1) insufficient pseudo-word token representation capacity, (2)\ndiscrepancies between training and inference phases, and (3) reliance on\nlarge-scale synthetic data. To address these issues, we propose a two-stage\nframework where the training is accomplished from mapping to composing. In the\nfirst stage, we enhance image-to-pseudo-word token learning by introducing a\nvisual semantic injection module and a soft text alignment objective, enabling\nthe token to capture richer and fine-grained image information. In the second\nstage, we optimize the text encoder using a small amount of synthetic triplet\ndata, enabling it to effectively extract compositional semantics by combining\npseudo-word tokens with modification text for accurate target image retrieval.\nThe strong visual-to-pseudo mapping established in the first stage provides a\nsolid foundation for the second stage, making our approach compatible with both\nhigh- and low-quality synthetic data, and capable of achieving significant\nperformance gains with only a small amount of synthetic data. Extensive\nexperiments were conducted on three public datasets, achieving superior\nperformance compared to existing approaches.", "published": "2025-04-25 00:18:23", "link": "http://arxiv.org/abs/2504.17990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Tight Lower Bound for Multicolor Discrepancy", "abstract": "We prove the following asymptotically tight lower bound for $k$-color\ndiscrepancy: For any $k \\geq 2$, there exists a hypergraph with $n$ vertices\nsuch that its $k$-color discrepancy is at least $\\Omega(\\sqrt{n})$. This\nimproves on the previously known lower bound of $\\Omega(\\sqrt{n/\\log k})$ due\nto Caragiannis et al. (arXiv:2502.10516). As an application, we show that our\nresult implies improved lower bounds for group fair division.", "published": "2025-04-25 16:58:59", "link": "http://arxiv.org/abs/2504.18489v1", "categories": ["cs.DM", "cs.GT"], "primary_category": "cs.DM"}
{"title": "Subexponential and Parameterized Mixing Times of Glauber Dynamics on Independent Sets", "abstract": "Given a graph $G$, the hard-core model defines a probability distribution\nover its independent sets, assigning to each set of size $k$ a probability of\n$\\frac{\\lambda^k}{Z}$, where $\\lambda>0$ is a parameter known as the fugacity\nand $Z$ is a normalization constant. The Glauber dynamics is a simple Markov\nchain that converges to this distribution and enables efficient sampling. Its\nmixing time--the number of steps needed to approach the stationary\ndistribution--has been widely studied across various graph classes, with most\nprevious work emphasizing the dichotomy between polynomial and exponential\nmixing times, with a particular focus on sparse classes of graphs.\n  Inspired by the modern fine-grained approach to computational complexity, we\ninvestigate subexponential mixing times of the Glauber dynamics on geometric\nintersection graphs, such as disk graphs. We also study parameterized mixing\ntimes by focusing on two structural parameters that can remain small even in\ndense graphs: the tree independence number and the path independence number. We\nshow that Glauber dynamics mixes in polynomial time on graphs with bounded path\nindependence number and in quasi-polynomial time when the tree independence\nnumber is bounded. Moreover, we prove both bounds are tight, revealing a clear\nseparation between the two parameters.\n  This work provides a simple and efficient algorithm for sampling from the\nhard-core model. Unlike classical approaches that rely explicitly on geometric\nrepresentations or on constructing decompositions such as tree decompositions\nor separator trees, our analysis only requires their existence to establish\nmixing time bounds--these structures are not used directly by the algorithm\nitself.", "published": "2025-04-25 15:33:55", "link": "http://arxiv.org/abs/2504.18427v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "On constrained intersection representations of graphs and digraphs", "abstract": "We study the problem of determining optimal directed intersection\nrepresentations of DAGs in a model introduced by Kostochka, Liu, Machado, and\nMilenkovic [ISIT2019]: vertices are assigned color sets so that there is an arc\nfrom a vertex $u$ to a vertex $v$ if and only if their color sets have nonempty\nintersection and $v$ gets assigned strictly more colors than $u$, and the goal\nis to minimize the total number of colors. We show that the problem is\npolynomially solvable in the class of triangle-free and Hamiltonian DAGs and\nalso disclose the relationship of this problem with several other models of\nintersection representations of graphs and digraphs.", "published": "2025-04-25 14:07:56", "link": "http://arxiv.org/abs/2504.18365v1", "categories": ["cs.DM", "cs.DS", "cs.IT", "math.CO", "math.IT"], "primary_category": "cs.DM"}
{"title": "Computing Distances on Graph Associahedra is Fixed-parameter Tractable", "abstract": "An elimination tree of a connected graph $G$ is a rooted tree on the vertices\nof $G$ obtained by choosing a root $v$ and recursing on the connected\ncomponents of $G-v$ to obtain the subtrees of $v$. The graph associahedron of\n$G$ is a polytope whose vertices correspond to elimination trees of $G$ and\nwhose edges correspond to tree rotations, a natural operation between\nelimination trees. These objects generalize associahedra, which correspond to\nthe case where $G$ is a path. Ito et al. [ICALP 2023] recently proved that the\nproblem of computing distances on graph associahedra is NP-hard. In this paper\nwe prove that the problem, for a general graph $G$, is fixed-parameter\ntractable parameterized by the distance $k$. Prior to our work, only the case\nwhere $G$ is a path was known to be fixed-parameter tractable. To prove our\nresult, we use a novel approach based on a marking scheme that restricts the\nsearch to a set of vertices whose size is bounded by a (large) function of $k$.", "published": "2025-04-25 13:26:46", "link": "http://arxiv.org/abs/2504.18338v1", "categories": ["cs.DS", "cs.CG", "cs.DM", "math.CO", "05C85, 05C10, 0C05, 90C08, 90C27", "G.2.2; G.2.3; G.2.1"], "primary_category": "cs.DS"}
{"title": "Treewidth Parameterized by Feedback Vertex Number", "abstract": "We provide the first algorithm for computing an optimal tree decomposition\nfor a given graph $G$ that runs in single exponential time in the feedback\nvertex number of $G$, that is, in time $2^{O(\\text{fvn}(G))}\\cdot n^{O(1)}$,\nwhere $\\text{fvn}(G)$ is the feedback vertex number of $G$ and $n$ is the\nnumber of vertices of $G$. On a classification level, this improves the\npreviously known results by Chapelle et al. [Discrete Applied Mathematics '17]\nand Fomin et al. [Algorithmica '18], who independently showed that an optimal\ntree decomposition can be computed in single exponential time in the vertex\ncover number of $G$.\n  One of the biggest open problems in the area of parameterized complexity is\nwhether we can compute an optimal tree decomposition in single exponential time\nin the treewidth of the input graph. The currently best known algorithm by\nKorhonen and Lokshtanov [STOC '23] runs in $2^{O(\\text{tw}(G)^2)}\\cdot n^4$\ntime, where $\\text{tw}(G)$ is the treewidth of $G$. Our algorithm improves upon\nthis result on graphs $G$ where $\\text{fvn}(G)\\in o(\\text{tw}(G)^2)$. On a\ndifferent note, since $\\text{fvn}(G)$ is an upper bound on $\\text{tw}(G)$, our\nalgorithm can also be seen either as an important step towards a positive\nresolution of the above-mentioned open problem, or, if its answer is negative,\nthen a mark of the tractability border of single exponential time algorithms\nfor the computation of treewidth.", "published": "2025-04-25 12:20:51", "link": "http://arxiv.org/abs/2504.18302v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Clustering of return words in languages of interval exchanges", "abstract": "A word over an ordered alphabet is said to be clustering if identical letters\nappear adjacently in its Burrows-Wheeler transform. Such words are strictly\nrelated to (discrete) interval exchange transformations. We use an extended\nversion of the well-known Rauzy induction to show that every return word in the\nlanguage generated by a regular interval exchange transformation is clustering,\npartially answering a question of Lapointe (2021).", "published": "2025-04-25 11:45:17", "link": "http://arxiv.org/abs/2504.18280v1", "categories": ["cs.FL", "cs.DM", "68R15, 37E05"], "primary_category": "cs.FL"}
{"title": "Solving Partial Dominating Set and Related Problems Using Twin-Width", "abstract": "Partial vertex cover and partial dominating set are two well-investigated\noptimization problems. While they are $\\rm W[1]$-hard on general graphs, they\nhave been shown to be fixed-parameter tractable on many sparse graph classes,\nincluding nowhere-dense classes. In this paper, we demonstrate that these\nproblems are also fixed-parameter tractable with respect to the twin-width of a\ngraph. Indeed, we establish a more general result: every graph property that\ncan be expressed by a logical formula of the form $\\phi\\equiv\\exists x_1\\ldots\n\\exists x_k \\#y\\,\\psi(x_1,\\ldots,x_k,y)\\ge t$, where $\\psi$ is a\nquantifier-free formula, $t$ is an arbitrary number, and $\\#y$ is a counting\nquantifier, can be evaluated in time $f(d,k)n$, where $n$ is the number of\nvertices and $d$ is the width of a contraction sequence that is part of the\ninput. Notably, this includes problems such as connected partial dominating set\nand independent partial dominating set.", "published": "2025-04-25 09:59:11", "link": "http://arxiv.org/abs/2504.18218v1", "categories": ["cs.DS", "cs.DM", "cs.LO"], "primary_category": "cs.DS"}
{"title": "Music Tempo Estimation on Solo Instrumental Performance", "abstract": "Recently, automatic music transcription has made it possible to convert\nmusical audio into accurate MIDI. However, the resulting MIDI lacks music\nnotations such as tempo, which hinders its conversion into sheet music. In this\npaper, we investigate state-of-the-art tempo estimation techniques and evaluate\ntheir performance on solo instrumental music. These include temporal\nconvolutional network (TCN) and recurrent neural network (RNN) models that are\npretrained on massive of mixed vocals and instrumental music, as well as TCN\nmodels trained specifically with solo instrumental performances. Through\nevaluations on drum, guitar, and classical piano datasets, our TCN models with\nthe new training scheme achieved the best performance. Our newly trained TCN\nmodel increases the Acc1 metric by 38.6% for guitar tempo estimation, compared\nto the pretrained TCN model with an Acc1 of 61.1%. Although our trained TCN\nmodel is twice as accurate as the pretrained TCN model in estimating classical\npiano tempo, its Acc1 is only 50.9%. To improve the performance of deep\nlearning models, we investigate their combinations with various post-processing\nmethods. These post-processing techniques effectively enhance the performance\nof deep learning models when they struggle to estimate the tempo of specific\ninstruments.", "published": "2025-04-25 17:14:52", "link": "http://arxiv.org/abs/2504.18502v1", "categories": ["eess.AS", "cs.IR", "68T07", "H.5.5"], "primary_category": "eess.AS"}
{"title": "An Empirical Study of Evaluating Long-form Question Answering", "abstract": "\\Ac{LFQA} aims to generate lengthy answers to complex questions. This\nscenario presents great flexibility as well as significant challenges for\nevaluation. Most evaluations rely on deterministic metrics that depend on\nstring or n-gram matching, while the reliability of large language model-based\nevaluations for long-form answers remains relatively unexplored. We address\nthis gap by conducting an in-depth study of long-form answer evaluation with\nthe following research questions: (i) To what extent do existing automatic\nevaluation metrics serve as a substitute for human evaluations? (ii) What are\nthe limitations of existing evaluation metrics compared to human evaluations?\n(iii) How can the effectiveness and robustness of existing evaluation methods\nbe improved? We collect 5,236 factoid and non-factoid long-form answers\ngenerated by different large language models and conduct a human evaluation on\n2,079 of them, focusing on correctness and informativeness. Subsequently, we\ninvestigated the performance of automatic evaluation metrics by evaluating\nthese answers, analyzing the consistency between these metrics and human\nevaluations. We find that the style, length of the answers, and the category of\nquestions can bias the automatic evaluation metrics. However, fine-grained\nevaluation helps mitigate this issue on some metrics. Our findings have\nimportant implications for the use of large language models for evaluating\nlong-form question answering. All code and datasets are available at\nhttps://github.com/bugtig6351/lfqa_evaluation.", "published": "2025-04-25 15:14:25", "link": "http://arxiv.org/abs/2504.18413v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Leveraging Decoder Architectures for Learned Sparse Retrieval", "abstract": "Learned Sparse Retrieval (LSR) has traditionally focused on small-scale\nencoder-only transformer architectures. With the advent of large-scale\npre-trained language models, their capability to generate sparse\nrepresentations for retrieval tasks across different transformer-based\narchitectures, including encoder-only, decoder-only, and encoder-decoder\nmodels, remains largely unexplored. This study investigates the effectiveness\nof LSR across these architectures, exploring various sparse representation\nheads and model scales. Our results highlight the limitations of using large\nlanguage models to create effective sparse representations in zero-shot\nsettings, identifying challenges such as inappropriate term expansions and\nreduced performance due to the lack of expansion. We find that the\nencoder-decoder architecture with multi-tokens decoding approach achieves the\nbest performance among the three backbones. While the decoder-only model\nperforms worse than the encoder-only model, it demonstrates the potential to\noutperform when scaled to a high number of parameters.", "published": "2025-04-25 08:04:52", "link": "http://arxiv.org/abs/2504.18151v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Revisiting Algorithmic Audits of TikTok: Poor Reproducibility and Short-term Validity of Findings", "abstract": "Social media platforms are constantly shifting towards algorithmically\ncurated content based on implicit or explicit user feedback. Regulators, as\nwell as researchers, are calling for systematic social media algorithmic audits\nas this shift leads to enclosing users in filter bubbles and leading them to\nmore problematic content. An important aspect of such audits is the\nreproducibility and generalisability of their findings, as it allows to draw\nverifiable conclusions and audit potential changes in algorithms over time. In\nthis work, we study the reproducibility of the existing sockpuppeting audits of\nTikTok recommender systems, and the generalizability of their findings. In our\nefforts to reproduce the previous works, we find multiple challenges stemming\nfrom social media platform changes and content evolution, but also the research\nworks themselves. These drawbacks limit the audit reproducibility and require\nan extensive effort altogether with inevitable adjustments to the auditing\nmethodology. Our experiments also reveal that these one-shot audit findings\noften hold only in the short term, implying that the reproducibility and\ngeneralizability of the audits heavily depend on the methodological choices and\nthe state of algorithms and content on the platform. This highlights the\nimportance of reproducible audits that allow us to determine how the situation\nchanges in time.", "published": "2025-04-25 07:50:06", "link": "http://arxiv.org/abs/2504.18140v1", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "SoK: Timeline based event reconstruction for digital forensics: Terminology, methodology, and current challenges", "abstract": "Event reconstruction is a technique that examiners can use to attempt to\ninfer past activities by analyzing digital artifacts. Despite its significance,\nthe field suffers from fragmented research, with studies often focusing\nnarrowly on aspects like timeline creation or tampering detection. This paper\naddresses the lack of a unified perspective by proposing a comprehensive\nframework for timeline-based event reconstruction, adapted from traditional\nforensic science models. We begin by harmonizing existing terminology and\npresenting a cohesive diagram that clarifies the relationships between key\nelements of the reconstruction process. Through a comprehensive literature\nsurvey, we classify and organize the main challenges, extending the discussion\nbeyond common issues like data volume. Lastly, we highlight recent advancements\nand propose directions for future research, including specific research gaps.\nBy providing a structured approach, key findings, and a clearer understanding\nof the underlying challenges, this work aims to strengthen the foundation of\ndigital forensics.", "published": "2025-04-25 07:33:35", "link": "http://arxiv.org/abs/2504.18131v1", "categories": ["cs.CR", "cs.IR"], "primary_category": "cs.CR"}
{"title": "Information Freshness in Dynamic Gossip Networks", "abstract": "We consider a source that shares updates with a network of $n$ gossiping\nnodes. The network's topology switches between two arbitrary topologies, with\nswitching governed by a two-state continuous time Markov chain (CTMC) process.\nInformation freshness is well-understood for static networks. This work\nevaluates the impact of time-varying connections on information freshness. In\norder to quantify the freshness of information, we use the version age of\ninformation metric. If the two networks have static long-term average version\nages of $f_1(n)$ and $f_2(n)$ with $f_1(n) \\ll f_2(n)$, then the version age of\nthe varying-topologies network is related to $f_1(n)$, $f_2(n)$, and the\ntransition rates in the CTMC. If the transition rates in the CTMC are faster\nthan $f_1(n)$, the average version age of the varying-topologies network is\n$f_1(n)$. Further, we observe that the behavior of a vanishingly small fraction\nof nodes can severely impact the long-term average version age of a network in\na negative way. This motivates the definition of a typical set of nodes in the\nnetwork. We evaluate the impact of fast and slow CTMC transition rates on the\ntypical set of nodes.", "published": "2025-04-25 17:16:36", "link": "http://arxiv.org/abs/2504.18504v1", "categories": ["cs.IT", "cs.NI", "cs.SI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Probabilistic Shaping in MIMO: Going Beyond 1.53dB AWGN Gain With the Non-Linear Demapper", "abstract": "Constellation shaping is a well-established method to improve upon a regular\nquadrature amplitude modulation (QAM). It is known that the gain achieved by\nany shaping method for an additive white Gaussian noise (AWGN) channel is\nupper-bounded by 1.53dB. However, the situation becomes less clear in the\nmultiple-input and multiple-output (MIMO) setting.\n  In this paper, we study the application of probabilistic shaping for MIMO\nchannels. We utilize an efficient near-optimal demapper based on sphere\ndecoding (SD) and demonstrate that it is possible to achieve more than 2dB\ngains, breaking the AWGN limit. It becomes possible because both signal and\ninterference are shaped and the non-linear methods can capture this property\nand leverage on it to improve the demodulation performance.", "published": "2025-04-25 16:11:46", "link": "http://arxiv.org/abs/2504.18459v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Filtering of second order generalized stochastic processes corrupted by additive noise", "abstract": "We treat the optimal linear filtering problem for a sum of two second order\nuncorrelated generalized stochastic processes. This is an operator equation\ninvolving covariance operators. We study both the wide-sense stationary case\nand the non-stationary case. In the former case the equation simplifies into a\nconvolution equation. The solution is the Radon--Nikodym derivative between\nnon-negative tempered Radon measures, for signal and signal plus noise\nrespectively, in the frequency domain. In the non-stationary case we work with\npseudodifferential operators with symbols in Sj\\\"ostrand modulation spaces\nwhich admits the use of its spectral invariance properties.", "published": "2025-04-25 16:08:20", "link": "http://arxiv.org/abs/2504.18456v1", "categories": ["math.FA", "cs.IT", "math.IT", "math.PR"], "primary_category": "math.FA"}
{"title": "Generalization Guarantees for Multi-View Representation Learning and Application to Regularization via Gaussian Product Mixture Prior", "abstract": "We study the problem of distributed multi-view representation learning. In\nthis problem, $K$ agents observe each one distinct, possibly statistically\ncorrelated, view and independently extracts from it a suitable representation\nin a manner that a decoder that gets all $K$ representations estimates\ncorrectly the hidden label. In the absence of any explicit coordination between\nthe agents, a central question is: what should each agent extract from its view\nthat is necessary and sufficient for a correct estimation at the decoder? In\nthis paper, we investigate this question from a generalization error\nperspective. First, we establish several generalization bounds in terms of the\nrelative entropy between the distribution of the representations extracted from\ntraining and \"test\" datasets and a data-dependent symmetric prior, i.e., the\nMinimum Description Length (MDL) of the latent variables for all views and\ntraining and test datasets. Then, we use the obtained bounds to devise a\nregularizer; and investigate in depth the question of the selection of a\nsuitable prior. In particular, we show and conduct experiments that illustrate\nthat our data-dependent Gaussian mixture priors with judiciously chosen weights\nlead to good performance. For single-view settings (i.e., $K=1$), our\nexperimental results are shown to outperform existing prior art Variational\nInformation Bottleneck (VIB) and Category-Dependent VIB (CDVIB) approaches.\nInterestingly, we show that a weighted attention mechanism emerges naturally in\nthis setting. Finally, for the multi-view setting, we show that the selection\nof the joint prior as a Gaussians product mixture induces a Gaussian mixture\nmarginal prior for each marginal view and implicitly encourages the agents to\nextract and output redundant features, a finding which is somewhat\ncounter-intuitive.", "published": "2025-04-25 16:07:39", "link": "http://arxiv.org/abs/2504.18455v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Constructing Hamiltonian Decompositions of Complete $k$-Uniform Hypergraphs", "abstract": "Motivated by the wide-ranging applications of Hamiltonian decompositions in\ndistributed computing, coded caching, routing, resource allocation, load\nbalancing, and fault tolerance, our work presents a comprehensive design for\nHamiltonian decompositions of complete $k$-uniform hypergraphs $K_n^k$.\nBuilding upon the resolution of the long-standing conjecture of the existence\nof Hamiltonian decompositions of complete hypergraphs, a problem that was\nresolved using existence-based methods, our contribution goes beyond the\nprevious explicit designs, which were confined to the specific cases of $k=2$\nand $k=3$, by providing explicit designs for all $k$ and $n$ prime, allowing\nfor a broad applicability of Hamiltonian decompositions in various settings.", "published": "2025-04-25 15:45:36", "link": "http://arxiv.org/abs/2504.18434v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Achievable Rates and Error Probability Bounds of Frequency-based Channels of Unlimited Input Resolution", "abstract": "We consider a molecular channel, in which messages are encoded to the\nfrequency of objects in a pool, and whose output during reading time is a noisy\nversion of the input frequencies, as obtained by sampling with replacement from\nthe pool. Motivated by recent DNA storage techniques, we focus on the regime in\nwhich the input resolution is unlimited. We propose two error probability\nbounds for this channel; the first bound is based on random coding analysis of\nthe error probability of the maximum likelihood decoder and the second bound is\nderived by code expurgation techniques. We deduce an achievable bound on the\ncapacity of this channel, and compare it to both the achievable bounds under\nlimited input resolution, as well as to a converse bound.", "published": "2025-04-25 14:07:31", "link": "http://arxiv.org/abs/2504.18364v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Generalization of Kitaev Codes as Generalized Bicycle Codes", "abstract": "Surface codes have historically been the dominant choice for quantum error\ncorrection due to their superior error threshold performance. However,\nrecently, a new class of Generalized Bicycle (GB) codes, constructed from\nbinary circulant matrices with three non-zero elements per row, achieved\ncomparable performance with fewer physical qubits and higher encoding\nefficiency.\n  In this article, we focus on a subclass of GB codes, which are constructed\nfrom pairs of binary circulant matrices with two non-zero elements per row.\n  We introduce a family of codes that generalizes both standard and optimized\nKitaev codes for which we have a lower bound on their minimum distance,\nensuring performance better than standard Kitaev codes. These codes exhibit\nparameters of the form $ [| 2n , 2, \\geq \\sqrt{n} |] $ where $ n$ is a factor\nof $ 1 + d^2 $. For code lengths below 200, our analysis yields $21$ codes,\nincluding $7$ codes from Pryadko and Wang's database, and unveils $14$ new\ncodes with enhanced minimum distance compared to standard Kitaev codes. Among\nthese, $3$ surpass all previously known weight-4 GB codes for distances $4$,\n$8$, and $12$.", "published": "2025-04-25 14:04:08", "link": "http://arxiv.org/abs/2504.18360v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Rack-Aware Minimum Storage Partially Cooperative Regenerating Codes with Small Sub-Packetization", "abstract": "In the rack-aware model, there are $\\bar{n}$ racks each of which has $u$\nnodes with the same storage capacity. Assume that there are $h$ failed nodes\nuniformly distributed in $\\bar{h}$ host racks ( defined as racks containing\nfailed nodes), each rack containing $h/\\bar{h}$ failed nodes where $h$ is\ndivisible by $\\bar{h}$. Then together with its internal helper nodes, each host\nrack downloads recovery data from $\\bar{d}$ helper racks and repairs its failed\nnodes. The repair bandwidth is defined as the total inter-rack data transfer\nrequired for failures recovery, as the intra-rack communication does not\ncontribute to this cost. The full cooperative repair model requires that each\nhost rack must exchange the data with all the other $\\bar{h}$ host racks during\nthe cooperative repair phase. However, in the partial cooperative repair model,\neach host rack only needs to exchange data with $\\bar{h}-\\delta\\\n(1\\leq\\delta\\leq\\bar{h}-1)$ other host racks, during the cooperative repair\nphase. In this paper, we focus on the rack-aware minimum storage partially\ncooperative regenerating (MSPCR) codes for repairing the $h$ node failures. We\nfirst derive the lower bound on the repair bandwidth for rack-aware MSPCR codes\nusing extremal combinatorics, and then construct two classes of optimal repair\nschemes for rack-aware MSPCR codes with small sub-packetization level. In\nparticular, when $\\delta=1$, our second codes reduce to rack-aware\nminimum-storage cooperative regenerating (MSCR) codes, while achieving an\n$(\\bar{h}+1)$-fold reduction in sub-packetization level compared to known\nrack-aware MSCR codes.", "published": "2025-04-25 13:23:54", "link": "http://arxiv.org/abs/2504.18335v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Advanced Channel Decomposition Techniques in OTFS: A GSVD Approach for Multi-User Downlink", "abstract": "In this paper, we propose a multi-user downlink system for two users based on\nthe orthogonal time frequency space (OTFS) modulation scheme. The design\nleverages the generalized singular value decomposition (GSVD) of the channels\nbetween the base station and the two users, applying precoding and detection\nmatrices based on the right and left singular vectors, respectively. We derive\nthe analytical expressions for three scenarios and present the corresponding\nsimulation results. These results demonstrate that, in terms of bit error rate\n(BER), the proposed system outperforms the conventional multi-user OTFS system\nin two scenarios when using minimum mean square error (MMSE) equalizers or\nprecoder, both for perfect channel state information and for a scenario with\nchannel estimation errors. In the third scenario, the design is equivalent to\nzero-forcing (ZF) precoding at the transmitter.", "published": "2025-04-25 12:44:20", "link": "http://arxiv.org/abs/2504.18315v1", "categories": ["eess.SP", "cs.IT", "cs.SY", "eess.SY", "math.IT"], "primary_category": "eess.SP"}
{"title": "Secret Sharing in the Rank Metric", "abstract": "The connection between secret sharing and matroid theory is well established.\nIn this paper, we generalize the concepts of secret sharing and matroid ports\nto $q$-polymatroids. Specifically, we introduce the notion of an access\nstructure on a vector space, and consider properties related to duality,\nminors, and the relationship to $q$-polymatroids. Finally, we show how\nrank-metric codes give rise to secret sharing schemes within this framework.", "published": "2025-04-25 12:08:27", "link": "http://arxiv.org/abs/2504.18294v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Demand Private Coded Caching: Small Cache Size", "abstract": "We investigate the demand private coded caching problem, which is an $(N,K)$\ncoded caching problem with $N$ files, $K$ users, each equipped with a cache of\nsize $M$, and an additional privacy constraint on user demands, i.e., each user\ncan not gain any information about the demands of other users. We focus on\nscenarios where the size of users' caches is small, aiming to further\ncharacterize the fundamental limits of this problem. We first present a new\nvirtual-user-based achievable scheme for arbitrary number of users and files,\nand two MDS-code-based achievable schemes for the case $N \\le K$. With a newly\nderived converse bound for the case $N \\le K$, these proposed schemes lead to\nthe optimal memory-rate tradeoff of the demand private coded caching problem\nfor $M \\in \\big[0, \\frac{N}{(K+1)(N-1)} \\big] $ where $N \\le K \\le 2N-2$, and\nthe optimal memory-rate tradeoff for $M \\in \\big[0, \\frac{1}{K+1} \\big] $ where\n$ K > 2N-2$. Moreover, for the case of 2 files and arbitrary number of users,\nby deriving another new converse bound, the optimal memory-rate tradeoff is\ncharacterized for $M\\in \\big[0,\\frac{2}{K}\\big] \\cup\n\\big[\\frac{2(K-1)}{K+1},2\\big]$. Finally, we provide the optimal memory-rate\ntradeoff of the demand private coded caching problem for 2 files and 3 users.", "published": "2025-04-25 10:43:23", "link": "http://arxiv.org/abs/2504.18242v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Revolutionizing Symbiotic Radio: Exploiting Tradeoffs in Hybrid Active-Passive Communications", "abstract": "Symbiotic radio (SR), a novel energy- and spectrum-sharing paradigm of\nbackscatter communications (BC), has been deemed a promising solution for\nambient Internet of Things (A-IoT), enabling ultra-low power consumption and\nmassive connectivity. However, A-IoT nodes utilizing BC suffer from low\ntransmission rates, which may limit the applications of SR in A-IoT scenarios\nwith data transmission requirements. To address this issue, in this article, we\nintroduce hybrid active-passive communications (HAPC) into SR by exploiting\ntradeoffs between transmission rate and power consumption. We first present an\noverview of novel BC paradigms including ambient BC and SR. Then, a novel\nHAPC-enabled SR is proposed to enhance the transmission rate of A-IoT nodes.\nFurthermore, within this paradigm, we investigate the resource allocation\nscheme and present preliminary research results. Simulation results show that\nthe transmission rate of A-IoT nodes in the proposed HAPC-enabled SR surpasses\nthat in traditional SR. Finally, we discuss open issues related to HAPC-enabled\nSR.", "published": "2025-04-25 08:31:38", "link": "http://arxiv.org/abs/2504.18168v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Hierarchical Cell-Free Massive MIMO: A Simplified Design for Uniform Service Quality", "abstract": "In traditional cellular networks, users at the cell edge often suffer from\npoor quality of service (QoS) due to large distance-dependent path loss and\nsevere inter-cell interference. While cell-free (CF) massive multi-input\nmulti-out (MIMO) mitigates this issue by distributing access points (APs) to\nensure uniform QoS, the deployment of numerous distributed APs and a fronthaul\nnetwork incurs high infrastructure costs. To balance performance and cost\nefficiency, this article proposes a simplified design called hierarchical\ncell-free (HCF) massive MIMO. The key idea is to reduce the number of APs, thus\nminimizing the scale of the fronthaul network. The antennas from the\ndecommissioned APs are aggregated at a central base station (cBS), which also\nserves as the coordinator for distributed APs. We derive closed-form\nexpressions for uplink and downlink spectral efficiency (SE) for HCF, CF, and\ncellular massive MIMO under pilot contamination and correlated fading channels,\nconsidering the use of multi-antenna APs. Numerical results confirm that the\nhierarchical architecture achieves $95\\%$-likely per-user SE comparable to CF,\nenhancing cell-edge user rates in cellular systems by over 100 times, while\nsignificantly reducing the complexity and cost of the fronthaul network in CF.\nWe develop max-min fairness algorithms for joint power control of the cBS and\nAPs in the downlink, and the users in the uplink. These algorithms not only\nboost fairness and system capacity but also dramatically lower transmission\npower, e.g., achieving over $70\\%$ savings in uplink, particularly beneficial\nfor battery-powered mobile devices.", "published": "2025-04-25 08:07:42", "link": "http://arxiv.org/abs/2504.18155v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Spatiotemporal Analysis of Parallelized Computing at the Extreme Edge", "abstract": "Extreme Edge Computing (EEC) pushes computing even closer to end users than\ntraditional Multi-access Edge Computing (MEC), harnessing the idle resources of\nExtreme Edge Devices (EEDs) to enable low-latency, distributed processing.\nHowever, EEC faces key challenges, including spatial randomness in device\ndistribution, limited EED computational power necessitating parallel task\nexecution, vulnerability to failure, and temporal randomness due to variability\nin wireless communication and execution times. These challenges highlight the\nneed for a rigorous analytical framework to evaluate EEC performance. We\npresent the first spatiotemporal mathematical model for EEC over large-scale\nmillimeter-wave networks. Utilizing stochastic geometry and an Absorbing\nContinuous-Time Markov Chain (ACTMC), the framework captures the complex\ninteraction between communication and computation performance, including their\ntemporal overlap during parallel execution. We evaluate two key metrics:\naverage task response delay and task completion probability. Together, they\nprovide a holistic view of latency and reliability. The analysis considers\nfundamental offloading strategies, including randomized and location-aware\nschemes, while accounting for EED failures. Results show that there exists an\noptimal task segmentation that minimizes delay. Under limited EED availability,\nwe investigate a bias-based EEC and MEC collaboration that offloads excess\ndemand to MEC resources, effectively reducing congestion and improving system\nresponsiveness.", "published": "2025-04-25 03:30:30", "link": "http://arxiv.org/abs/2504.18047v1", "categories": ["cs.PF", "cs.IT", "math.IT"], "primary_category": "cs.PF"}
{"title": "Optimal Secure Coded Distributed Computation over all Fields", "abstract": "We construct optimal secure coded distributed schemes that extend the known\noptimal constructions over fields of characteristic 0 to all fields. A\nserendipitous result is that we can encode \\emph{all} functions over finite\nfields with a recovery threshold proportional to the complexity (tensor rank or\nmultiplicative); this is due to the well-known result that all functions over a\nfinite field can be represented as multivariate polynomials (or symmetric\ntensors). We get that a tensor of order $\\ell$ (or a multivariate polynomial of\ndegree $\\ell$) can be computed in the faulty network of $N$ nodes setting\nwithin a factor of $\\ell$ and an additive term depending on the genus of a code\nwith $N$ rational points and distance covering the number of faulty servers; in\nparticular, we present a coding scheme for general matrix multiplication of two\n$m \\times m $ matrices with a recovery threshold of $2 m^{\\omega } -1+g$ where\n$\\omega $ is the exponent of matrix multiplication which is optimal for coding\nschemes using AG codes. Moreover, we give sufficient conditions for which the\nHadamard-Shur product of general linear codes gives a similar recovery\nthreshold, which we call \\textit{log-additive codes}. Finally, we show that\nevaluation codes with a \\textit{curve degree} function (first defined in\n[Ben-Sasson et al. (STOC '13)]) that have well-behaved zero sets are\nlog-additive.", "published": "2025-04-25 03:11:04", "link": "http://arxiv.org/abs/2504.18038v1", "categories": ["cs.IT", "cs.DC", "cs.DS", "cs.SC", "math.AG", "math.IT", "E.4; I.1.2; E.1"], "primary_category": "cs.IT"}
{"title": "Iterative Joint Detection of Kalman Filter and Channel Decoder for Sensor-to-Controller Link in Wireless Networked Control Systems", "abstract": "In this letter, we propose an iterative joint detection algorithm of Kalman\nfilter (KF) and channel decoder for the sensor-to-controller link of wireless\nnetworked control systems, which utilizes the prior information of control\nsystem to improve the control and communication performance. In the algorithm,\nwe first use the KF to estimate the probability density of the control system\noutputs and calculate the prior probability of received signals to assist\ndecoding. Then, the possible outputs of the control system are traversed to\nupdate the prior probability in order to implement iterative detection. The\nsimulation results show that the prior information can reduce the block error\nrate performance of communications to improve the root mean square error\nperformance of controls.", "published": "2025-04-25 02:25:32", "link": "http://arxiv.org/abs/2504.18022v1", "categories": ["cs.IT", "cs.SY", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Representation Learning for Distributional Perturbation Extrapolation", "abstract": "We consider the problem of modelling the effects of unseen perturbations such\nas gene knockdowns or drug combinations on low-level measurements such as RNA\nsequencing data. Specifically, given data collected under some perturbations,\nwe aim to predict the distribution of measurements for new perturbations. To\naddress this challenging extrapolation task, we posit that perturbations act\nadditively in a suitable, unknown embedding space. More precisely, we formulate\nthe generative process underlying the observed data as a latent variable model,\nin which perturbations amount to mean shifts in latent space and can be\ncombined additively. Unlike previous work, we prove that, given sufficiently\ndiverse training perturbations, the representation and perturbation effects are\nidentifiable up to affine transformation, and use this to characterize the\nclass of unseen perturbations for which we obtain extrapolation guarantees. To\nestimate the model from data, we propose a new method, the perturbation\ndistribution autoencoder (PDAE), which is trained by maximising the\ndistributional similarity between true and predicted perturbation\ndistributions. The trained model can then be used to predict previously unseen\nperturbation distributions. Empirical evidence suggests that PDAE compares\nfavourably to existing methods and baselines at predicting the effects of\nunseen perturbations.", "published": "2025-04-25 17:44:04", "link": "http://arxiv.org/abs/2504.18522v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Intelligent Attacks and Defense Methods in Federated Learning-enabled Energy-Efficient Wireless Networks", "abstract": "Federated learning (FL) is a promising technique for learning-based functions\nin wireless networks, thanks to its distributed implementation capability. On\nthe other hand, distributed learning may increase the risk of exposure to\nmalicious attacks where attacks on a local model may spread to other models by\nparameter exchange. Meanwhile, such attacks can be hard to detect due to the\ndynamic wireless environment, especially considering local models can be\nheterogeneous with non-independent and identically distributed (non-IID) data.\nTherefore, it is critical to evaluate the effect of malicious attacks and\ndevelop advanced defense techniques for FL-enabled wireless networks. In this\nwork, we introduce a federated deep reinforcement learning-based cell sleep\ncontrol scenario that enhances the energy efficiency of the network. We propose\nmultiple intelligent attacks targeting the learning-based approach and we\npropose defense methods to mitigate such attacks. In particular, we have\ndesigned two attack models, generative adversarial network (GAN)-enhanced model\npoisoning attack and regularization-based model poisoning attack. As a\ncounteraction, we have proposed two defense schemes, autoencoder-based defense,\nand knowledge distillation (KD)-enabled defense. The autoencoder-based defense\nmethod leverages an autoencoder to identify the malicious participants and only\naggregate the parameters of benign local models during the global aggregation,\nwhile KD-based defense protects the model from attacks by controlling the\nknowledge transferred between the global model and local models.", "published": "2025-04-25 17:40:35", "link": "http://arxiv.org/abs/2504.18519v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PODNO: Proper Orthogonal Decomposition Neural Operators", "abstract": "In this paper, we introduce Proper Orthogonal Decomposition Neural Operators\n(PODNO) for solving partial differential equations (PDEs) dominated by\nhigh-frequency components. Building on the structure of Fourier Neural\nOperators (FNO), PODNO replaces the Fourier transform with (inverse)\northonormal transforms derived from the Proper Orthogonal Decomposition (POD)\nmethod to construct the integral kernel. Due to the optimality of POD basis,\nthe PODNO has potential to outperform FNO in both accuracy and computational\nefficiency for high-frequency problems. From analysis point of view, we\nestablished the universality of a generalization of PODNO, termed as\nGeneralized Spectral Operator (GSO). In addition, we evaluate PODNO's\nperformance numerically on dispersive equations such as the Nonlinear\nSchrodinger (NLS) equation and the Kadomtsev-Petviashvili (KP) equation.", "published": "2025-04-25 17:30:44", "link": "http://arxiv.org/abs/2504.18513v1", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph", "68T07, 65M12, 41A35, 65N99"], "primary_category": "math.NA"}
{"title": "Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional", "abstract": "Transition path sampling (TPS), which involves finding probable paths\nconnecting two points on an energy landscape, remains a challenge due to the\ncomplexity of real-world atomistic systems. Current machine learning approaches\nuse expensive, task-specific, and data-free training procedures, limiting their\nability to benefit from recent advances in atomistic machine learning, such as\nhigh-quality datasets and large-scale pre-trained models. In this work, we\naddress TPS by interpreting candidate paths as trajectories sampled from\nstochastic dynamics induced by the learned score function of pre-trained\ngenerative models, specifically denoising diffusion and flow matching. Under\nthese dynamics, finding high-likelihood transition paths becomes equivalent to\nminimizing the Onsager-Machlup (OM) action functional. This enables us to\nrepurpose pre-trained generative models for TPS in a zero-shot manner, in\ncontrast with bespoke, task-specific TPS models trained in previous work. We\ndemonstrate our approach on varied molecular systems, obtaining diverse,\nphysically realistic transition pathways and generalizing beyond the\npre-trained model's original training dataset. Our method can be easily\nincorporated into new generative models, making it practically relevant as\nmodels continue to scale and improve with increased data availability.", "published": "2025-04-25 17:17:17", "link": "http://arxiv.org/abs/2504.18506v1", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Enhancing Visual Interpretability and Explainability in Functional Survival Trees and Forests", "abstract": "Functional survival models are key tools for analyzing time-to-event data\nwith complex predictors, such as functional or high-dimensional inputs. Despite\ntheir predictive strength, these models often lack interpretability, which\nlimits their value in practical decision-making and risk analysis. This study\ninvestigates two key survival models: the Functional Survival Tree (FST) and\nthe Functional Random Survival Forest (FRSF). It introduces novel methods and\ntools to enhance the interpretability of FST models and improve the\nexplainability of FRSF ensembles. Using both real and simulated datasets, the\nresults demonstrate that the proposed approaches yield efficient,\neasy-to-understand decision trees that accurately capture the underlying\ndecision-making processes of the model ensemble.", "published": "2025-04-25 17:11:10", "link": "http://arxiv.org/abs/2504.18498v1", "categories": ["stat.ML", "cs.LG", "stat.ME", "62N02, 62P10, 62H30, 62G05, 62G08, 62J99", "G.3; I.5.1; I.5.2"], "primary_category": "stat.ML"}
{"title": "Discovering Governing Equations of Geomagnetic Storm Dynamics with Symbolic Regression", "abstract": "Geomagnetic storms are large-scale disturbances of the Earth's magnetosphere\ndriven by solar wind interactions, posing significant risks to space-based and\nground-based infrastructure. The Disturbance Storm Time (Dst) index quantifies\ngeomagnetic storm intensity by measuring global magnetic field variations. This\nstudy applies symbolic regression to derive data-driven equations describing\nthe temporal evolution of the Dst index. We use historical data from the NASA\nOMNIweb database, including solar wind density, bulk velocity, convective\nelectric field, dynamic pressure, and magnetic pressure. The PySR framework, an\nevolutionary algorithm-based symbolic regression library, is used to identify\nmathematical expressions linking dDst/dt to key solar wind. The resulting\nmodels include a hierarchy of complexity levels and enable a comparison with\nwell-established empirical models such as the Burton-McPherron-Russell and\nO'Brien-McPherron models. The best-performing symbolic regression models\ndemonstrate superior accuracy in most cases, particularly during moderate\ngeomagnetic storms, while maintaining physical interpretability. Performance\nevaluation on historical storm events includes the 2003 Halloween Storm, the\n2015 St. Patrick's Day Storm, and a 2017 moderate storm. The results provide\ninterpretable, closed-form expressions that capture nonlinear dependencies and\nthresholding effects in Dst evolution.", "published": "2025-04-25 16:14:54", "link": "http://arxiv.org/abs/2504.18461v1", "categories": ["cs.CE", "cs.LG"], "primary_category": "cs.CE"}
{"title": "Pseudo-Asynchronous Local SGD: Robust and Efficient Data-Parallel Training", "abstract": "Following AI scaling trends, frontier models continue to grow in size and\ncontinue to be trained on larger datasets. Training these models requires huge\ninvestments in exascale computational resources, which has in turn driven\ndevelopment of distributed deep learning methods. Data parallelism is an\nessential approach to speed up training, but it requires frequent global\ncommunication between workers, which can bottleneck training at the largest\nscales. In this work, we propose a method called Pseudo-Asynchronous Local SGD\n(PALSGD) to improve the efficiency of data-parallel training. PALSGD is an\nextension of Local SGD (Stich, 2018) and DiLoCo (Douillard et al., 2023),\ndesigned to further reduce communication frequency by introducing a\npseudo-synchronization mechanism. PALSGD allows the use of longer\nsynchronization intervals compared to standard Local SGD. Despite the reduced\ncommunication frequency, the pseudo-synchronization approach ensures that model\nconsistency is maintained, leading to performance results comparable to those\nachieved with more frequent synchronization. Furthermore, we provide a\ntheoretical analysis of PALSGD, establishing its convergence and deriving its\nconvergence rate. This analysis offers insights into the algorithm's behavior\nand performance guarantees. We evaluated PALSGD on image classification and\nlanguage modeling tasks. Our results show that PALSGD achieves better\nperformance in less time compared to existing methods like Distributed Data\nParallel (DDP), and DiLoCo. Notably, PALSGD trains 18.4% faster than DDP on\nImageNet-1K with ResNet-50, 24.4% faster than DDP on TinyStories with\nGPT-Neo125M, and 21.1% faster than DDP on TinyStories with GPT-Neo-8M.", "published": "2025-04-25 16:06:08", "link": "http://arxiv.org/abs/2504.18454v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enhancing Strawberry Yield Forecasting with Backcasted IoT Sensor Data and Machine Learning", "abstract": "Due to rapid population growth globally, digitally-enabled agricultural\nsectors are crucial for sustainable food production and making informed\ndecisions about resource management for farmers and various stakeholders. The\ndeployment of Internet of Things (IoT) technologies that collect real-time\nobservations of various environmental (e.g., temperature, humidity, etc.) and\noperational factors (e.g., irrigation) influencing production is often seen as\na critical step to enable additional novel downstream tasks, such as AI-based\nyield forecasting. However, since AI models require large amounts of data, this\ncreates practical challenges in a real-world dynamic farm setting where IoT\nobservations would need to be collected over a number of seasons. In this\nstudy, we deployed IoT sensors in strawberry production polytunnels for two\ngrowing seasons to collect environmental data, including water usage, external\nand internal temperature, external and internal humidity, soil moisture, soil\ntemperature, and photosynthetically active radiation. The sensor observations\nwere combined with manually provided yield records spanning a period of four\nseasons. To bridge the gap of missing IoT observations for two additional\nseasons, we propose an AI-based backcasting approach to generate synthetic\nsensor observations using historical weather data from a nearby weather station\nand the existing polytunnel observations. We built an AI-based yield\nforecasting model to evaluate our approach using the combination of real and\nsynthetic observations. Our results demonstrated that incorporating synthetic\ndata improved yield forecasting accuracy, with models incorporating synthetic\ndata outperforming those trained only on historical yield, weather records, and\nreal sensor data.", "published": "2025-04-25 16:02:50", "link": "http://arxiv.org/abs/2504.18451v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Boosting-Enabled Robust System Identification of Partially Observed LTI Systems Under Heavy-Tailed Noise", "abstract": "We consider the problem of system identification of partially observed linear\ntime-invariant (LTI) systems. Given input-output data, we provide\nnon-asymptotic guarantees for identifying the system parameters under general\nheavy-tailed noise processes. Unlike previous works that assume Gaussian or\nsub-Gaussian noise, we consider significantly broader noise distributions that\nare required to admit only up to the second moment. For this setting, we\nleverage tools from robust statistics to propose a novel system identification\nalgorithm that exploits the idea of boosting. Despite the much weaker noise\nassumptions, we show that our proposed algorithm achieves sample complexity\nbounds that nearly match those derived under sub-Gaussian noise. In particular,\nwe establish that our bounds retain a logarithmic dependence on the prescribed\nfailure probability. Interestingly, we show that such bounds can be achieved by\nrequiring just a finite fourth moment on the excitatory input process.", "published": "2025-04-25 15:57:13", "link": "http://arxiv.org/abs/2504.18444v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "An Axiomatic Assessment of Entropy- and Variance-based Uncertainty Quantification in Regression", "abstract": "Uncertainty quantification (UQ) is crucial in machine learning, yet most\n(axiomatic) studies of uncertainty measures focus on classification, leaving a\ngap in regression settings with limited formal justification and evaluations.\nIn this work, we introduce a set of axioms to rigorously assess measures of\naleatoric, epistemic, and total uncertainty in supervised regression. By\nutilizing a predictive exponential family, we can generalize commonly used\napproaches for uncertainty representation and corresponding uncertainty\nmeasures. More specifically, we analyze the widely used entropy- and\nvariance-based measures regarding limitations and challenges. Our findings\nprovide a principled foundation for UQ in regression, offering theoretical\ninsights and practical guidelines for reliable uncertainty assessment.", "published": "2025-04-25 15:44:46", "link": "http://arxiv.org/abs/2504.18433v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Online learning to accelerate nonlinear PDE solvers: applied to multiphase porous media flow", "abstract": "We propose a novel type of nonlinear solver acceleration for systems of\nnonlinear partial differential equations (PDEs) that is based on\nonline/adaptive learning. It is applied in the context of multiphase flow in\nporous media. The proposed method rely on four pillars: (i) dimensionless\nnumbers as input parameters for the machine learning model, (ii) simplified\nnumerical model (two-dimensional) for the offline training, (iii) dynamic\ncontrol of a nonlinear solver tuning parameter (numerical relaxation), (iv) and\nonline learning for real-time improvement of the machine learning model. This\nstrategy decreases the number of nonlinear iterations by dynamically modifying\na single global parameter, the relaxation factor, and by adaptively learning\nthe attributes of each numerical model on-the-run. Furthermore, this work\nperforms a sensitivity study in the dimensionless parameters (machine learning\nfeatures), assess the efficacy of various machine learning models, demonstrate\na decrease in nonlinear iterations using our method in more intricate,\nrealistic three-dimensional models, and fully couple a machine learning model\ninto an open-source multiphase flow simulator achieving up to 85\\% reduction in\ncomputational time.", "published": "2025-04-25 15:15:45", "link": "http://arxiv.org/abs/2504.18414v1", "categories": ["cs.LG", "physics.flu-dyn"], "primary_category": "cs.LG"}
{"title": "Three Types of Calibration with Properties and their Semantic and Formal Relationships", "abstract": "Fueled by discussions around \"trustworthiness\" and algorithmic fairness,\ncalibration of predictive systems has regained scholars attention. The vanilla\ndefinition and understanding of calibration is, simply put, on all days on\nwhich the rain probability has been predicted to be p, the actual frequency of\nrain days was p. However, the increased attention has led to an immense variety\nof new notions of \"calibration.\" Some of the notions are incomparable, serve\ndifferent purposes, or imply each other. In this work, we provide two accounts\nwhich motivate calibration: self-realization of forecasted properties and\nprecise estimation of incurred losses of the decision makers relying on\nforecasts. We substantiate the former via the reflection principle and the\nlatter by actuarial fairness. For both accounts we formulate prototypical\ndefinitions via properties $\\Gamma$ of outcome distributions, e.g., the mean or\nmedian. The prototypical definition for self-realization, which we call\n$\\Gamma$-calibration, is equivalent to a certain type of swap regret under\ncertain conditions. These implications are strongly connected to the\nomniprediction learning paradigm. The prototypical definition for precise loss\nestimation is a modification of decision calibration adopted from Zhao et al.\n[73]. For binary outcome sets both prototypical definitions coincide under\nappropriate choices of reference properties. For higher-dimensional outcome\nsets, both prototypical definitions can be subsumed by a natural extension of\nthe binary definition, called distribution calibration with respect to a\nproperty. We conclude by commenting on the role of groupings in both accounts\nof calibration often used to obtain multicalibration. In sum, this work\nprovides a semantic map of calibration in order to navigate a fragmented\nterrain of notions and definitions.", "published": "2025-04-25 14:46:10", "link": "http://arxiv.org/abs/2504.18395v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Machine Learning and Statistical Insights into Hospital Stay Durations: The Italian EHR Case", "abstract": "Length of hospital stay is a critical metric for assessing healthcare quality\nand optimizing hospital resource management. This study aims to identify\nfactors influencing LoS within the Italian healthcare context, using a dataset\nof hospitalization records from over 60 healthcare facilities in the Piedmont\nregion, spanning from 2020 to 2023. We explored a variety of features,\nincluding patient characteristics, comorbidities, admission details, and\nhospital-specific factors. Significant correlations were found between LoS and\nfeatures such as age group, comorbidity score, admission type, and the month of\nadmission. Machine learning models, specifically CatBoost and Random Forest,\nwere used to predict LoS. The highest R2 score, 0.49, was achieved with\nCatBoost, demonstrating good predictive performance.", "published": "2025-04-25 14:44:31", "link": "http://arxiv.org/abs/2504.18393v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Model Evaluation in the Dark: Robust Classifier Metrics with Missing Labels", "abstract": "Missing data in supervised learning is well-studied, but the specific issue\nof missing labels during model evaluation has been overlooked. Ignoring samples\nwith missing values, a common solution, can introduce bias, especially when\ndata is Missing Not At Random (MNAR). We propose a multiple imputation\ntechnique for evaluating classifiers using metrics such as precision, recall,\nand ROC-AUC. This method not only offers point estimates but also a predictive\ndistribution for these quantities when labels are missing. We empirically show\nthat the predictive distribution's location and shape are generally correct,\neven in the MNAR regime. Moreover, we establish that this distribution is\napproximately Gaussian and provide finite-sample convergence bounds.\nAdditionally, a robustness proof is presented, confirming the validity of the\napproximation under a realistic error model.", "published": "2025-04-25 14:31:42", "link": "http://arxiv.org/abs/2504.18385v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Explainable AI for UAV Mobility Management: A Deep Q-Network Approach for Handover Minimization", "abstract": "The integration of unmanned aerial vehicles (UAVs) into cellular networks\npresents significant mobility management challenges, primarily due to frequent\nhandovers caused by probabilistic line-of-sight conditions with multiple ground\nbase stations (BSs). To tackle these challenges, reinforcement learning\n(RL)-based methods, particularly deep Q-networks (DQN), have been employed to\noptimize handover decisions dynamically. However, a major drawback of these\nlearning-based approaches is their black-box nature, which limits\ninterpretability in the decision-making process. This paper introduces an\nexplainable AI (XAI) framework that incorporates Shapley Additive Explanations\n(SHAP) to provide deeper insights into how various state parameters influence\nhandover decisions in a DQN-based mobility management system. By quantifying\nthe impact of key features such as reference signal received power (RSRP),\nreference signal received quality (RSRQ), buffer status, and UAV position, our\napproach enhances the interpretability and reliability of RL-based handover\nsolutions. To validate and compare our framework, we utilize real-world network\nperformance data collected from UAV flight trials. Simulation results show that\nour method provides intuitive explanations for policy decisions, effectively\nbridging the gap between AI-driven models and human decision-makers.", "published": "2025-04-25 14:11:51", "link": "http://arxiv.org/abs/2504.18371v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Enhanced Sampling, Public Dataset and Generative Model for Drug-Protein Dissociation Dynamics", "abstract": "Drug-protein binding and dissociation dynamics are fundamental to\nunderstanding molecular interactions in biological systems. While many tools\nfor drug-protein interaction studies have emerged, especially artificial\nintelligence (AI)-based generative models, predictive tools on\nbinding/dissociation kinetics and dynamics are still limited. We propose a\nnovel research paradigm that combines molecular dynamics (MD) simulations,\nenhanced sampling, and AI generative models to address this issue. We propose\nan enhanced sampling strategy to efficiently implement the drug-protein\ndissociation process in MD simulations and estimate the free energy surface\n(FES). We constructed a program pipeline of MD simulations based on this\nsampling strategy, thus generating a dataset including 26,612 drug-protein\ndissociation trajectories containing about 13 million frames. We named this\ndissociation dynamics dataset DD-13M and used it to train a deep equivariant\ngenerative model UnbindingFlow, which can generate collision-free dissociation\ntrajectories. The DD-13M database and UnbindingFlow model represent a\nsignificant advancement in computational structural biology, and we anticipate\nits broad applicability in machine learning studies of drug-protein\ninteractions. Our ongoing efforts focus on expanding this methodology to\nencompass a broader spectrum of drug-protein complexes and exploring novel\napplications in pathway prediction.", "published": "2025-04-25 14:10:06", "link": "http://arxiv.org/abs/2504.18367v1", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph", "q-bio.BM"], "primary_category": "physics.comp-ph"}
{"title": "SSA-UNet: Advanced Precipitation Nowcasting via Channel Shuffling", "abstract": "Weather forecasting is essential for facilitating diverse socio-economic\nactivity and environmental conservation initiatives. Deep learning techniques\nare increasingly being explored as complementary approaches to Numerical\nWeather Prediction (NWP) models, offering potential benefits such as reduced\ncomplexity and enhanced adaptability in specific applications. This work\npresents a novel design, Small Shuffled Attention UNet (SSA-UNet), which\nenhances SmaAt-UNet's architecture by including a shuffle channeling mechanism\nto optimize performance and diminish complexity. To assess its efficacy, this\narchitecture and its reduced variant are examined and trained on two datasets:\na Dutch precipitation dataset from 2016 to 2019, and a French cloud cover\ndataset containing radar images from 2017 to 2018. Three output configurations\nof the proposed architecture are evaluated, yielding outputs of 1, 6, and 12\nprecipitation maps, respectively. To better understand how this model operates\nand produces its predictions, a gradient-based approach called Grad-CAM is used\nto analyze the outputs generated. The analysis of heatmaps generated by\nGrad-CAM facilitated the identification of regions within the input maps that\nthe model considers most informative for generating its predictions. The\nimplementation of SSA-UNet can be found on our\nGithub\\footnote{\\href{https://github.com/MarcoTurzi/SSA-UNet}{https://github.com/MarcoTurzi/SSA-UNet}}", "published": "2025-04-25 12:36:31", "link": "http://arxiv.org/abs/2504.18309v1", "categories": ["cs.LG", "I.2; I.5"], "primary_category": "cs.LG"}
{"title": "Deep Reinforcement Learning Based Navigation with Macro Actions and Topological Maps", "abstract": "This paper addresses the challenge of navigation in large, visually complex\nenvironments with sparse rewards. We propose a method that uses object-oriented\nmacro actions grounded in a topological map, allowing a simple Deep Q-Network\n(DQN) to learn effective navigation policies. The agent builds a map by\ndetecting objects from RGBD input and selecting discrete macro actions that\ncorrespond to navigating to these objects. This abstraction drastically reduces\nthe complexity of the underlying reinforcement learning problem and enables\ngeneralization to unseen environments. We evaluate our approach in a\nphotorealistic 3D simulation and show that it significantly outperforms a\nrandom baseline under both immediate and terminal reward conditions. Our\nresults demonstrate that topological structure and macro-level abstraction can\nenable sample-efficient learning even from pixel data.", "published": "2025-04-25 12:19:35", "link": "http://arxiv.org/abs/2504.18300v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A comprehensive review of classifier probability calibration metrics", "abstract": "Probabilities or confidence values produced by artificial intelligence (AI)\nand machine learning (ML) models often do not reflect their true accuracy, with\nsome models being under or over confident in their predictions. For example, if\na model is 80% sure of an outcome, is it correct 80% of the time? Probability\ncalibration metrics measure the discrepancy between confidence and accuracy,\nproviding an independent assessment of model calibration performance that\ncomplements traditional accuracy metrics. Understanding calibration is\nimportant when the outputs of multiple systems are combined, for assurance in\nsafety or business-critical contexts, and for building user trust in models.\nThis paper provides a comprehensive review of probability calibration metrics\nfor classifier and object detection models, organising them according to a\nnumber of different categorisations to highlight their relationships. We\nidentify 82 major metrics, which can be grouped into four classifier families\n(point-based, bin-based, kernel or curve-based, and cumulative) and an object\ndetection family. For each metric, we provide equations where available,\nfacilitating implementation and comparison by future researchers.", "published": "2025-04-25 11:44:44", "link": "http://arxiv.org/abs/2504.18278v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Studying Small Language Models with Susceptibilities", "abstract": "We develop a linear response framework for interpretability that treats a\nneural network as a Bayesian statistical mechanical system. A small, controlled\nperturbation of the data distribution, for example shifting the Pile toward\nGitHub or legal text, induces a first-order change in the posterior expectation\nof an observable localized on a chosen component of the network. The resulting\nsusceptibility can be estimated efficiently with local SGLD samples and\nfactorizes into signed, per-token contributions that serve as attribution\nscores. Building a set of perturbations (probes) yields a response matrix whose\nlow-rank structure separates functional modules such as multigram and induction\nheads in a 3M-parameter transformer. Susceptibilities link local learning\ncoefficients from singular learning theory with linear-response theory, and\nquantify how local loss landscape geometry deforms under shifts in the data\ndistribution.", "published": "2025-04-25 11:39:32", "link": "http://arxiv.org/abs/2504.18274v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Learning on Large Graphs using a Densifying Regularity Lemma", "abstract": "Learning on large graphs presents significant challenges, with traditional\nMessage Passing Neural Networks suffering from computational and memory costs\nscaling linearly with the number of edges. We introduce the Intersecting Block\nGraph (IBG), a low-rank factorization of large directed graphs based on\ncombinations of intersecting bipartite components, each consisting of a pair of\ncommunities, for source and target nodes. By giving less weight to non-edges,\nwe show how to efficiently approximate any graph, sparse or dense, by a dense\nIBG. Specifically, we prove a constructive version of the weak regularity\nlemma, showing that for any chosen accuracy, every graph, regardless of its\nsize or sparsity, can be approximated by a dense IBG whose rank depends only on\nthe accuracy. This dependence of the rank solely on the accuracy, and not on\nthe sparsity level, is in contrast to previous forms of the weak regularity\nlemma. We present a graph neural network architecture operating on the IBG\nrepresentation of the graph and demonstrating competitive performance on node\nclassification, spatio-temporal graph analysis, and knowledge graph completion,\nwhile having memory and computational complexity linear in the number of nodes\nrather than edges.", "published": "2025-04-25 11:34:44", "link": "http://arxiv.org/abs/2504.18273v1", "categories": ["cs.SI", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Local Statistical Parity for the Estimation of Fair Decision Trees", "abstract": "Given the high computational complexity of decision tree estimation,\nclassical methods construct a tree by adding one node at a time in a recursive\nway. To facilitate promoting fairness, we propose a fairness criterion local to\nthe tree nodes. We prove how it is related to the Statistical Parity criterion,\npopular in the Algorithmic Fairness literature, and show how to incorporate it\ninto standard recursive tree estimation algorithms.\n  We present a tree estimation algorithm called Constrained Logistic Regression\nTree (C-LRT), which is a modification of the standard CART algorithm using\nlocally linear classifiers and imposing restrictions as done in Constrained\nLogistic Regression.\n  Finally, we evaluate the performance of trees estimated with C-LRT on\ndatasets commonly used in the Algorithmic Fairness literature, using various\nclassification and fairness metrics. The results confirm that C-LRT\nsuccessfully allows to control and balance accuracy and fairness.", "published": "2025-04-25 11:15:55", "link": "http://arxiv.org/abs/2504.18262v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering", "abstract": "Multi-Hop Question Answering (MHQA) tasks permeate real-world applications,\nposing challenges in orchestrating multi-step reasoning across diverse\nknowledge domains. While existing approaches have been improved with iterative\nretrieval, they still struggle to identify and organize dynamic knowledge. To\naddress this, we propose DualRAG, a synergistic dual-process framework that\nseamlessly integrates reasoning and retrieval. DualRAG operates through two\ntightly coupled processes: Reasoning-augmented Querying (RaQ) and progressive\nKnowledge Aggregation (pKA). They work in concert: as RaQ navigates the\nreasoning path and generates targeted queries, pKA ensures that newly acquired\nknowledge is systematically integrated to support coherent reasoning. This\ncreates a virtuous cycle of knowledge enrichment and reasoning refinement.\nThrough targeted fine-tuning, DualRAG preserves its sophisticated reasoning and\nretrieval capabilities even in smaller-scale models, demonstrating its\nversatility and core advantages across different scales. Extensive experiments\ndemonstrate that this dual-process approach substantially improves answer\naccuracy and coherence, approaching, and in some cases surpassing, the\nperformance achieved with oracle knowledge access. These results establish\nDualRAG as a robust and efficient solution for complex multi-hop reasoning\ntasks.", "published": "2025-04-25 10:43:53", "link": "http://arxiv.org/abs/2504.18243v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Switch-Based Multi-Part Neural Network", "abstract": "This paper introduces decentralized and modular neural network framework\ndesigned to enhance the scalability, interpretability, and performance of\nartificial intelligence (AI) systems. At the heart of this framework is a\ndynamic switch mechanism that governs the selective activation and training of\nindividual neurons based on input characteristics, allowing neurons to\nspecialize in distinct segments of the data domain. This approach enables\nneurons to learn from disjoint subsets of data, mimicking biological brain\nfunction by promoting task specialization and improving the interpretability of\nneural network behavior. Furthermore, the paper explores the application of\nfederated learning and decentralized training for real-world AI deployments,\nparticularly in edge computing and distributed environments. By simulating\nlocalized training on non-overlapping data subsets, we demonstrate how modular\nnetworks can be efficiently trained and evaluated. The proposed framework also\naddresses scalability, enabling AI systems to handle large datasets and\ndistributed processing while preserving model transparency and\ninterpretability. Finally, we discuss the potential of this approach in\nadvancing the design of scalable, privacy-preserving, and efficient AI systems\nfor diverse applications.", "published": "2025-04-25 10:39:42", "link": "http://arxiv.org/abs/2504.18241v1", "categories": ["cs.NE", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Post-Transfer Learning Statistical Inference in High-Dimensional Regression", "abstract": "Transfer learning (TL) for high-dimensional regression (HDR) is an important\nproblem in machine learning, particularly when dealing with limited sample size\nin the target task. However, there currently lacks a method to quantify the\nstatistical significance of the relationship between features and the response\nin TL-HDR settings. In this paper, we introduce a novel statistical inference\nframework for assessing the reliability of feature selection in TL-HDR, called\nPTL-SI (Post-TL Statistical Inference). The core contribution of PTL-SI is its\nability to provide valid $p$-values to features selected in TL-HDR, thereby\nrigorously controlling the false positive rate (FPR) at desired significance\nlevel $\\alpha$ (e.g., 0.05). Furthermore, we enhance statistical power by\nincorporating a strategic divide-and-conquer approach into our framework. We\ndemonstrate the validity and effectiveness of the proposed PTL-SI through\nextensive experiments on both synthetic and real-world high-dimensional\ndatasets, confirming its theoretical properties and utility in testing the\nreliability of feature selection in TL scenarios.", "published": "2025-04-25 09:43:01", "link": "http://arxiv.org/abs/2504.18212v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Ultra-fast feature learning for the training of two-layer neural networks in the two-timescale regime", "abstract": "We study the convergence of gradient methods for the training of mean-field\nsingle hidden layer neural networks with square loss. Observing this is a\nseparable non-linear least-square problem which is linear w.r.t. the outer\nlayer's weights, we consider a Variable Projection (VarPro) or two-timescale\nlearning algorithm, thereby eliminating the linear variables and reducing the\nlearning problem to the training of the feature distribution. Whereas most\nconvergence rates or the training of neural networks rely on a neural tangent\nkernel analysis where features are fixed, we show such a strategy enables\nprovable convergence rates for the sampling of a teacher feature distribution.\nPrecisely, in the limit where the regularization strength vanishes, we show\nthat the dynamic of the feature distribution corresponds to a weighted\nultra-fast diffusion equation. Relying on recent results on the asymptotic\nbehavior of such PDEs, we obtain guarantees for the convergence of the trained\nfeature distribution towards the teacher feature distribution in a\nteacher-student setup.", "published": "2025-04-25 09:40:10", "link": "http://arxiv.org/abs/2504.18208v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "A Machine Learning Approach For Bitcoin Forecasting", "abstract": "Bitcoin is one of the cryptocurrencies that is gaining more popularity in\nrecent years. Previous studies have shown that closing price alone is not\nenough to forecast stock market series. We introduce a new set of time series\nand demonstrate that a subset is necessary to improve directional accuracy\nbased on a machine learning ensemble. In our experiments, we study which time\nseries and machine learning algorithms deliver the best results. We found that\nthe most relevant time series that contribute to improving directional accuracy\nare Open, High and Low, with the largest contribution of Low in combination\nwith an ensemble of Gated Recurrent Unit network and a baseline forecast. The\nrelevance of other Bitcoin-related features that are not price-related is\nnegligible. The proposed method delivers similar performance to the\nstate-of-the-art when observing directional accuracy.", "published": "2025-04-25 09:35:44", "link": "http://arxiv.org/abs/2504.18206v1", "categories": ["cs.LG", "cs.CE"], "primary_category": "cs.LG"}
{"title": "An Open-Source and Reproducible Implementation of LSTM and GRU Networks for Time Series Forecasting", "abstract": "This paper introduces an open-source and reproducible implementation of Long\nShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU) Networks for time\nseries forecasting. We evaluated LSTM and GRU networks because of their\nperformance reported in related work. We describe our method and its results on\ntwo datasets. The first dataset is the S&P BSE BANKEX, composed of stock time\nseries (closing prices) of ten financial institutions. The second dataset,\ncalled Activities, comprises ten synthetic time series resembling weekly\nactivities with five days of high activity and two days of low activity. We\nreport Root Mean Squared Error (RMSE) between actual and predicted values, as\nwell as Directional Accuracy (DA). We show that a single time series from a\ndataset can be used to adequately train the networks if the sequences in the\ndataset contain patterns that repeat, even with certain variation, and are\nproperly processed. For 1-step ahead and 20-step ahead forecasts, LSTM and GRU\nnetworks significantly outperform a baseline on the Activities dataset. The\nbaseline simply repeats the last available value. On the stock market dataset,\nthe networks perform just like the baseline, possibly due to the nature of\nthese series. We release the datasets used as well as the implementation with\nall experiments performed to enable future comparisons and to make our research\nreproducible.", "published": "2025-04-25 09:00:54", "link": "http://arxiv.org/abs/2504.18185v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning Operators by Regularized Stochastic Gradient Descent with Operator-valued Kernels", "abstract": "This paper investigates regularized stochastic gradient descent (SGD)\nalgorithms for estimating nonlinear operators from a Polish space to a\nseparable Hilbert space. We assume that the regression operator lies in a\nvector-valued reproducing kernel Hilbert space induced by an operator-valued\nkernel. Two significant settings are considered: an online setting with\npolynomially decaying step sizes and regularization parameters, and a\nfinite-horizon setting with constant step sizes and regularization parameters.\nWe introduce regularity conditions on the structure and smoothness of the\ntarget operator and the input random variables. Under these conditions, we\nprovide a dimension-free convergence analysis for the prediction and estimation\nerrors, deriving both expectation and high-probability error bounds. Our\nanalysis demonstrates that these convergence rates are nearly optimal.\nFurthermore, we present a new technique for deriving bounds with high\nprobability for general SGD schemes, which also ensures almost-sure\nconvergence. Finally, we discuss potential extensions to more general\noperator-valued kernels and the encoder-decoder framework.", "published": "2025-04-25 08:57:38", "link": "http://arxiv.org/abs/2504.18184v1", "categories": ["stat.ML", "cs.LG", "math.FA", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Unveiling 3D Ocean Biogeochemical Provinces: A Machine Learning Approach for Systematic Clustering and Validation", "abstract": "Defining ocean regions and water masses helps to understand marine processes\nand can serve downstream-tasks such as defining marine protected areas.\nHowever, such definitions are often a result of subjective decisions\npotentially producing misleading, unreproducible results. Here, the aim was to\nobjectively define regions of the North Atlantic. For this, a data-driven,\nsystematic machine learning approach was applied to generate and validate ocean\nclusters employing external, internal and relative validation techniques. About\n300 million measured salinity, temperature, and oxygen, nitrate, phosphate and\nsilicate concentration values served as input for various clustering methods\n(KMeans, agglomerative Ward, and Density-Based Spatial Clustering of\nApplications with Noise (DBSCAN)). Uniform Manifold Approximation and\nProjection (UMAP) emphasised (dis-)similarities in the data while reducing\ndimensionality. Based on a systematic validation of the considered clustering\nmethods and their hyperparameters, the results showed that UMAP-DBSCAN best\nrepresented the data. To address stochastic variability, 100 UMAP-DBSCAN\nclustering runs were conducted and aggregated using Native Emergent Manifold\nInterrogation (NEMI), producing a final set of 321 clusters. Reproducibility\nwas evaluated by calculating the ensemble overlap (88.81 +- 1.8%) and the mean\ngrid cell-wise uncertainty estimated by NEMI (15.49 +- 20%). The presented\nclustering results agreed very well with common water mass definitions. This\nstudy revealed a more detailed regionalization compared to previous concepts\nsuch as the Longhurst provinces. The applied method is objective, efficient and\nreproducible and will support future research focusing on biogeochemical\ndifferences and changes in oceanic regions.", "published": "2025-04-25 08:55:40", "link": "http://arxiv.org/abs/2504.18181v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Generative Graph Contrastive Learning Model with Global Signal", "abstract": "Graph contrastive learning (GCL) has garnered significant attention recently\nsince it learns complex structural information from graphs through\nself-supervised learning manner. However, prevalent GCL models may suffer from\nperformance degradation due to inappropriate contrastive signals. Concretely,\nthey commonly generate augmented views based on random perturbation, which\nleads to biased essential structures due to the introduction of noise. In\naddition, they assign equal weight to both hard and easy sample pairs, thereby\nignoring the difference in importance of the sample pairs. To address these\nissues, this study proposes a novel Contrastive Signal Generative Framework for\nAccurate Graph Learning (CSG2L) with the following two-fold ideas: a) building\na singular value decomposition (SVD)-directed augmented module (SVD-aug) to\nobtain the global interactions as well as avoiding the random noise\nperturbation; b) designing a local-global dependency learning module (LGDL)\nwith an adaptive reweighting strategy which can differentiate the effects of\nhard and easy sample pairs. Extensive experiments on benchmark datasets\ndemonstrate that the proposed CSG2L outperforms the state-of-art baselines.\nMoreover, CSG2L is compatible with a variety of GNNs.", "published": "2025-04-25 08:00:38", "link": "http://arxiv.org/abs/2504.18148v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "NoEsis: Differentially Private Knowledge Transfer in Modular LLM Adaptation", "abstract": "Large Language Models (LLM) are typically trained on vast amounts of data\nfrom various sources. Even when designed modularly (e.g., Mixture-of-Experts),\nLLMs can leak privacy on their sources. Conversely, training such models in\nisolation arguably prohibits generalization. To this end, we propose a\nframework, NoEsis, which builds upon the desired properties of modularity,\nprivacy, and knowledge transfer. NoEsis integrates differential privacy with a\nhybrid two-staged parameter-efficient fine-tuning that combines domain-specific\nlow-rank adapters, acting as experts, with common prompt tokens, acting as a\nknowledge-sharing backbone. Results from our evaluation on CodeXGLUE showcase\nthat NoEsis can achieve provable privacy guarantees with tangible knowledge\ntransfer across domains, and empirically show protection against Membership\nInference Attacks. Finally, on code completion tasks, NoEsis bridges at least\n77% of the accuracy gap between the non-shared and the non-private baseline.", "published": "2025-04-25 07:56:24", "link": "http://arxiv.org/abs/2504.18147v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Tree Boosting Methods for Balanced andImbalanced Classification and their Robustness Over Time in Risk Assessment", "abstract": "Most real-world classification problems deal with imbalanced datasets, posing\na challenge for Artificial Intelligence (AI), i.e., machine learning\nalgorithms, because the minority class, which is of extreme interest, often\nproves difficult to be detected. This paper empirically evaluates tree boosting\nmethods' performance given different dataset sizes and class distributions,\nfrom perfectly balanced to highly imbalanced. For tabular data, tree-based\nmethods such as XGBoost, stand out in several benchmarks due to detection\nperformance and speed. Therefore, XGBoost and Imbalance-XGBoost are evaluated.\nAfter introducing the motivation to address risk assessment with machine\nlearning, the paper reviews evaluation metrics for detection systems or binary\nclassifiers. It proposes a method for data preparation followed by tree\nboosting methods including hyper-parameter optimization. The method is\nevaluated on private datasets of 1 thousand (K), 10K and 100K samples on\ndistributions with 50, 45, 25, and 5 percent positive samples. As expected, the\ndeveloped method increases its recognition performance as more data is given\nfor training and the F1 score decreases as the data distribution becomes more\nimbalanced, but it is still significantly superior to the baseline of\nprecision-recall determined by the ratio of positives divided by positives and\nnegatives. Sampling to balance the training set does not provide consistent\nimprovement and deteriorates detection. In contrast, classifier hyper-parameter\noptimization improves recognition, but should be applied carefully depending on\ndata volume and distribution. Finally, the developed method is robust to data\nvariation over time up to some point. Retraining can be used when performance\nstarts deteriorating.", "published": "2025-04-25 07:35:38", "link": "http://arxiv.org/abs/2504.18133v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Score-Based Deterministic Density Sampling", "abstract": "We propose and analyze a deterministic sampling framework using Score-Based\nTransport Modeling (SBTM) for sampling an unnormalized target density $\\pi$.\nWhile diffusion generative modeling relies on pre-training the score function\n$\\nabla \\log f_t$ using samples from $\\pi$, SBTM addresses the more general and\nchallenging setting where only $\\nabla \\log\\pi$ is known. SBTM approximates the\nWasserstein gradient flow on KL$(f_t\\|\\pi)$ by learning the time-varying score\n$\\nabla \\log f_t$ on the fly using score matching. The learned score gives\nimmediate access to relative Fisher information, providing a built-in\nconvergence diagnostic. The deterministic trajectories are smooth,\ninterpretable, and free of Brownian-motion noise, while having the same\ndistribution as ULA. We prove that SBTM dissipates relative entropy at the same\nrate as the exact gradient flow, provided sufficient training. We further\nextend our framework to annealed dynamics, to handle non log-concave targets.\nNumerical experiments validate our theoretical findings: SBTM converges at the\noptimal rate, has smooth trajectories, and is easily integrated with annealed\ndynamics. We compare to the baselines of ULA and annealed ULA.", "published": "2025-04-25 07:33:16", "link": "http://arxiv.org/abs/2504.18130v1", "categories": ["cs.LG", "math.PR", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Lecture Notes on Normalizing Flows for Lattice Quantum Field Theories", "abstract": "Numerical simulations of quantum field theories on lattices serve as a\nfundamental tool for studying the non-perturbative regime of the theories,\nwhere analytic tools often fall short. Challenges arise when one takes the\ncontinuum limit or as the system approaches a critical point, especially in the\npresence of non-trivial topological structures in the theory. Rapid recent\nadvances in machine learning provide a promising avenue for progress in this\narea. These lecture notes aim to give a brief account of lattice field\ntheories, normalizing flows, and how the latter can be applied to study the\nformer. The notes are based on the lectures given by the first author in\nvarious recent research schools.", "published": "2025-04-25 07:22:11", "link": "http://arxiv.org/abs/2504.18126v1", "categories": ["hep-lat", "cs.LG", "hep-th"], "primary_category": "hep-lat"}
{"title": "Think, Prune, Train, Improve: Scaling Reasoning without Scaling Models", "abstract": "Large language models (LLMs) have demonstrated strong capabilities in\nprogramming and mathematical reasoning tasks, but are constrained by limited\nhigh-quality training data. Synthetic data can be leveraged to enhance\nfine-tuning outcomes, but several factors influence this process, including\nmodel size, synthetic data volume, pruning strategy, and number of fine-tuning\nrounds. We explore these axes and investigate which conditions enable model\nself-improvement. We introduce the Think, Prune, Train process, a scalable\nframework that iteratively fine-tunes models on their own reasoning traces,\nusing ground-truth pruning to ensure high-quality training data. This approach\nyields improved performance: on GSM8K, Gemma2-2B achieves a Pass@1 of 57.6%\n(from 41.9%), Gemma2-9B reaches 82%, matching LLaMA-3.1-70B, and LLaMA-3.1-70B\nattains 91%, even surpassing GPT-4o, demonstrating the effectiveness of\nself-generated reasoning and systematic data selection for improving LLM\ncapabilities.", "published": "2025-04-25 06:48:55", "link": "http://arxiv.org/abs/2504.18116v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Temperature Estimation in Induction Motors using Machine Learning", "abstract": "The number of electrified powertrains is ever increasing today towards a more\nsustainable future; thus, it is essential that unwanted failures are prevented,\nand a reliable operation is secured. Monitoring the internal temperatures of\nmotors and keeping them under their thresholds is an important first step.\nConventional modeling methods require expert knowledge and complicated\nmathematical approaches. With all the data a modern electric drive collects\nnowadays during the system operation, it is feasible to apply data-driven\napproaches for estimating thermal behaviors. In this paper, multiple\nmachine-learning methods are investigated on their capability to approximate\nthe temperatures of the stator winding and bearing in induction motors. The\nexplored algorithms vary from linear to neural networks. For this reason,\nexperimental lab data have been captured from a powertrain under predetermined\noperating conditions. For each approach, a hyperparameter search is then\nperformed to find the optimal configuration. All the models are evaluated by\nvarious metrics, and it has been found that neural networks perform\nsatisfactorily even under transient conditions.", "published": "2025-04-25 06:22:31", "link": "http://arxiv.org/abs/2504.18105v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bayesian Quantum Orthogonal Neural Networks for Anomaly Detection", "abstract": "Identification of defects or anomalies in 3D objects is a crucial task to\nensure correct functionality. In this work, we combine Bayesian learning with\nrecent developments in quantum and quantum-inspired machine learning,\nspecifically orthogonal neural networks, to tackle this anomaly detection\nproblem for an industrially relevant use case. Bayesian learning enables\nuncertainty quantification of predictions, while orthogonality in weight\nmatrices enables smooth training. We develop orthogonal (quantum) versions of\n3D convolutional neural networks and show that these models can successfully\ndetect anomalies in 3D objects. To test the feasibility of incorporating\nquantum computers into a quantum-enhanced anomaly detection pipeline, we\nperform hardware experiments with our models on IBM's 127-qubit Brisbane\ndevice, testing the effect of noise and limited measurement shots.", "published": "2025-04-25 06:16:13", "link": "http://arxiv.org/abs/2504.18103v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Subject-independent Classification of Meditative State from the Resting State using EEG", "abstract": "While it is beneficial to objectively determine whether a subject is\nmeditating, most research in the literature reports good results only in a\nsubject-dependent manner. This study aims to distinguish the modified state of\nconsciousness experienced during Rajyoga meditation from the resting state of\nthe brain in a subject-independent manner using EEG data. Three architectures\nhave been proposed and evaluated: The CSP-LDA Architecture utilizes common\nspatial pattern (CSP) for feature extraction and linear discriminant analysis\n(LDA) for classification. The CSP-LDA-LSTM Architecture employs CSP for feature\nextraction, LDA for dimensionality reduction, and long short-term memory (LSTM)\nnetworks for classification, modeling the binary classification problem as a\nsequence learning problem. The SVD-NN Architecture uses singular value\ndecomposition (SVD) to select the most relevant components of the EEG signals\nand a shallow neural network (NN) for classification. The CSP-LDA-LSTM\narchitecture gives the best performance with 98.2% accuracy for intra-subject\nclassification. The SVD-NN architecture provides significant performance with\n96.4\\% accuracy for inter-subject classification. This is comparable to the\nbest-reported accuracies in the literature for intra-subject classification.\nBoth architectures are capable of capturing subject-invariant EEG features for\neffectively classifying the meditative state from the resting state. The high\nintra-subject and inter-subject classification accuracies indicate these\nsystems' robustness and their ability to generalize across different subjects.", "published": "2025-04-25 05:44:51", "link": "http://arxiv.org/abs/2504.18095v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Reliable and Efficient Inverse Analysis using Physics-Informed Neural Networks with Distance Functions and Adaptive Weight Tuning", "abstract": "Physics-informed neural networks have attracted significant attention in\nscientific machine learning for their capability to solve forward and inverse\nproblems governed by partial differential equations. However, the accuracy of\nPINN solutions is often limited by the treatment of boundary conditions.\nConventional penalty-based methods, which incorporate boundary conditions as\npenalty terms in the loss function, cannot guarantee exact satisfaction of the\ngiven boundary conditions and are highly sensitive to the choice of penalty\nparameters. This paper demonstrates that distance functions, specifically\nR-functions, can be leveraged to enforce boundary conditions, overcoming these\nlimitations. R-functions provide normalized distance fields, enabling accurate\nrepresentation of boundary geometries, including non-convex domains, and\nfacilitating various types of boundary conditions. We extend this distance\nfunction-based boundary condition imposition method to inverse problems using\nPINNs and introduce an adaptive weight tuning technique to ensure reliable and\nefficient inverse analysis. We demonstrate the efficacy of the method through\nseveral numerical experiments. Numerical results show that the proposed method\nsolves inverse problems more accurately and efficiently than penalty-based\nmethods, even in the presence of complex non-convex geometries. This approach\noffers a reliable and efficient framework for inverse analysis using PINNs,\nwith potential applications across a wide range of engineering problems.", "published": "2025-04-25 05:39:09", "link": "http://arxiv.org/abs/2504.18091v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Model Zoo on Phase Transitions in Neural Networks", "abstract": "Using the weights of trained Neural Network (NN) models as data modality has\nrecently gained traction as a research field - dubbed Weight Space Learning\n(WSL). Multiple recent works propose WSL methods to analyze models, evaluate\nmethods, or synthesize weights. Weight space learning methods require\npopulations of trained models as datasets for development and evaluation.\nHowever, existing collections of models - called `model zoos' - are\nunstructured or follow a rudimentary definition of diversity. In parallel, work\nrooted in statistical physics has identified phases and phase transitions in NN\nmodels. Models are homogeneous within the same phase but qualitatively differ\nfrom one phase to another. We combine the idea of `model zoos' with phase\ninformation to create a controlled notion of diversity in populations. We\nintroduce 12 large-scale zoos that systematically cover known phases and vary\nover model architecture, size, and datasets. These datasets cover different\nmodalities, such as computer vision, natural language processing, and\nscientific ML. For every model, we compute loss landscape metrics and validate\nfull coverage of the phases. With this dataset, we provide the community with a\nresource with a wide range of potential applications for WSL and beyond.\nEvidence suggests the loss landscape phase plays a role in applications such as\nmodel training, analysis, or sparsification. We demonstrate this in an\nexploratory study of the downstream methods like transfer learning or model\nweights averaging.", "published": "2025-04-25 05:01:52", "link": "http://arxiv.org/abs/2504.18072v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Modes of Sequence Models and Learning Coefficients", "abstract": "We develop a geometric account of sequence modelling that links patterns in\nthe data to measurable properties of the loss landscape in transformer\nnetworks. First, we cast conditional sequence distributions into a\nHilbert-space framework and apply tensor decompositions to identify their\nprincipal modes. Truncating the small-amplitude modes yields an effective data\ndistribution that preserves dominant structure while discarding statistical\ndetail. Second, we show theoretically that Local Learning Coefficient (LLC)\nestimates are insensitive to modes below a data-dependent threshold.\nConsequently, the LLC calculated in practice characterises the geometry of the\neffective rather than the true distribution. This insight clarifies why\nreliable LLC estimates can be obtained even when a network parameter is not a\nstrict minimiser of the population loss, and it highlights how the inverse\ntemperature in SGLD acts as a resolution dial on the landscape structure.", "published": "2025-04-25 03:38:10", "link": "http://arxiv.org/abs/2504.18048v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Non-identifiability distinguishes Neural Networks among Parametric Models", "abstract": "One of the enduring problems surrounding neural networks is to identify the\nfactors that differentiate them from traditional statistical models. We prove a\npair of results which distinguish feedforward neural networks among parametric\nmodels at the population level, for regression tasks. Firstly, we prove that\nfor any pair of random variables $(X,Y)$, neural networks always learn a\nnontrivial relationship between $X$ and $Y$, if one exists. Secondly, we prove\nthat for reasonable smooth parametric models, under local and global\nidentifiability conditions, there exists a nontrivial $(X,Y)$ pair for which\nthe parametric model learns the constant predictor $\\mathbb{E}[Y]$. Together,\nour results suggest that a lack of identifiability distinguishes neural\nnetworks among the class of smooth parametric models.", "published": "2025-04-25 01:59:02", "link": "http://arxiv.org/abs/2504.18017v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "TGDT: A Temporal Graph-based Digital Twin for Urban Traffic Corridors", "abstract": "Urban congestion at signalized intersections leads to significant delays,\neconomic losses, and increased emissions. Existing deep learning models often\nlack spatial generalizability, rely on complex architectures, and struggle with\nreal-time deployment. To address these limitations, we propose the Temporal\nGraph-based Digital Twin (TGDT), a scalable framework that integrates Temporal\nConvolutional Networks and Attentional Graph Neural Networks for dynamic,\ndirection-aware traffic modeling and assessment at urban corridors. TGDT\nestimates key Measures of Effectiveness (MOEs) for traffic flow optimization at\nboth the intersection level (e.g., queue length, waiting time) and the corridor\nlevel (e.g., traffic volume, travel time). Its modular architecture and\nsequential optimization scheme enable easy extension to any number of\nintersections and MOEs. The model outperforms state-of-the-art baselines by\naccurately producing high-dimensional, concurrent multi-output estimates. It\nalso demonstrates high robustness and accuracy across diverse traffic\nconditions, including extreme scenarios, while relying on only a minimal set of\ntraffic features. Fully parallelized, TGDT can simulate over a thousand\nscenarios within a matter of seconds, offering a cost-effective, interpretable,\nand real-time solution for traffic signal optimization.", "published": "2025-04-25 01:28:32", "link": "http://arxiv.org/abs/2504.18008v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Self-Balancing, Memory Efficient, Dynamic Metric Space Data Maintenance, for Rapid Multi-Kernel Estimation", "abstract": "We present a dynamic self-balancing octree data structure that enables\nefficient neighborhood maintenance in evolving metric spaces, a key challenge\nin modern machine learning systems. Many learning and generative models operate\nas dynamical systems whose representations evolve during training, requiring\nfast, adaptive spatial organization. Our two-parameter octree supports\nlogarithmic-time updates and queries, eliminating the need for costly full\nrebuilds as data distributions shift. We demonstrate its effectiveness in four\nareas: (1) accelerating Stein variational gradient descent by supporting more\nparticles with lower overhead; (2) enabling real-time, incremental KNN\nclassification with logarithmic complexity; (3) facilitating efficient, dynamic\nindexing and retrieval for retrieval-augmented generation; and (4) improving\nsample efficiency by jointly optimizing input and latent spaces. Across all\napplications, our approach yields exponential speedups while preserving\naccuracy, particularly in high-dimensional spaces where maintaining adaptive\nspatial structure is critical.", "published": "2025-04-25 01:15:53", "link": "http://arxiv.org/abs/2504.18003v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving", "abstract": "Generative conversational interfaces powered by large language models (LLMs)\ntypically stream output token-by-token at a rate determined by computational\nbudget, often neglecting actual human reading speeds and the cognitive load\nassociated with the content. This mismatch frequently leads to inefficient use\nof computational resources. For example, in cloud-based services, streaming\ncontent faster than users can read appears unnecessary, resulting in wasted\ncomputational resources and potential delays for other users, particularly\nduring peak usage periods. To address this issue, we propose an adaptive\nstreaming method that dynamically adjusts the pacing of LLM streaming output in\nreal-time based on inferred cognitive load. Our approach estimates the\ncognitive load associated with streaming content and strategically slows down\nthe stream during complex or information-rich segments, thereby freeing\ncomputational resources for other users. Our statistical analysis of\ncomputational savings, combined with crowdsourced user studies, provides\ninsights into the trade-offs between service efficiency and user satisfaction,\ndemonstrating that our method can significantly reduce computational\nconsumption up to 16.8\\%. This context-aware computational resource management\nstrategy presents a practical framework for enhancing system efficiency in\ncloud-based conversational AI interfaces without compromising user experience.", "published": "2025-04-25 00:58:37", "link": "http://arxiv.org/abs/2504.17999v1", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Robust semi-implicit multilevel SDC methods for conservation laws", "abstract": "Semi-implicit multilevel spectral deferred correction (SI-MLSDC) methods\nprovide a promising approach for high-order time integration for nonlinear\nevolution equations including conservation laws. However, existing methods lack\nrobustness and often do not achieve the expected advantage over single-level\nSDC. This work adopts the novel SI time integrators from [44] for enhanced\nstability and extends the single-level SI-SDC method with a multilevel approach\nto increase computational efficiency. The favourable properties of the\nresulting SI-MLSDC method are shown by linear temporal stability analysis for a\nconvection-diffusion problem. The robustness and efficiency of the fully\ndiscrete method involving a high-order discontinuous Galerkin SEM\ndiscretization are demonstrated through numerical experiments for the\nconvection-diffusion, Burgers, Euler and Navier-Stokes equations. The method is\nshown to yield substantial reductions in fine-grid iterations compared to\nsingle-level SI-SDC across a broad range of test cases. Finally, current\nlimitations of the SI-MLSDC framework are identified and discussed, providing\nguidance for future improvements.", "published": "2025-04-25 17:50:36", "link": "http://arxiv.org/abs/2504.18526v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Generalized Chebyshev Acceleration", "abstract": "We use generalized Chebyshev polynomials, associated with the root system\n$A_2$, to provide a new semi-iterative method for accelerating simple iterative\nmethods for solving linear systems. We apply this semi-iterative method to the\nJacobi method, and give an example. There are certain restrictions but the\nresulting acceleration is rather high.", "published": "2025-04-25 16:20:51", "link": "http://arxiv.org/abs/2504.18465v1", "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "math.NA"}
{"title": "Convergence analysis of Lie and Strang splitting for operator-valued differential Riccati equations", "abstract": "Differential Riccati equations (DREs) are semilinear matrix- or\noperator-valued differential equations with quadratic non-linearities. They\narise in many different areas, and are particularly important in optimal\ncontrol of linear quadratic regulators, where they provide the optimal feedback\ncontrol laws. In the context of control of partial differential equations,\nthese Riccati equations are operator-valued. To approximate their solutions,\nboth spatial and temporal discretizations are needed. While the former have\nbeen well analyzed in the literature, there are very few rigorous convergence\nanalyses of time stepping methods applied to DREs, particularly in the\ninfinite-dimensional, operator-valued setting. In view of this, we analyze two\nnumerical time-stepping schemes, the Lie and Strang splitting methods, in such\na setting. The analysis relies on the assumption that the uncontrolled system\nevolves via an operator that generates an analytic semigroup, and that either\nthe initial condition is sufficiently smooth, or the nonlinearity in the DRE is\nsufficiently smoothing. These assumptions are mild, in the sense that they are\nnot enough to even guarantee continuity in operator-norm of the exact solution\nto the DRE. However, they imply certain regularity in a pointwise sense, which\ncan be leveraged to prove convergence in operator-norm with the classical\norders. The results are illustrated by four numerical experiments, where\nconvergence with the expected order is correlated with the relevant assumptions\nbeing fulfilled. The experiments also demonstrate that matrix-valued DREs which\narise as spatial discretizations of operator-valued DREs behave similarly,\nunless the discretization is coarse.", "published": "2025-04-25 13:59:38", "link": "http://arxiv.org/abs/2504.18358v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Numerical method for the inverse scattering by random periodic structures", "abstract": "Due to manufacturing defects or wear and tear, industrial components may have\nuncertainties. In order to evaluate the performance of machined components, it\nis crucial to quantify the uncertainty of the scattering surface. This brings\nup an important class of inverse scattering problems for random interface\nreconstruction. In this paper, we present an efficient numerical algorithm for\nthe inverse scattering problem of acoustic-elastic interaction with random\nperiodic interfaces. The proposed algorithm combines the Monte Carlo technique\nand the continuation method with respect to the wavenumber, which can\naccurately reconstruct the key statistics of random periodic interfaces from\nthe measured data of the acoustic scattered field. In the implementation of our\nalgorithm, a key two-step strategy is employed: Firstly, the elastic\ndisplacement field below the interface is determined by Tikhonov regularization\nbased on the dynamic interface condition; Secondly, the profile function is\niteratively updated and optimised using the Landweber method according to the\nkinematic interface condition. Such a algorithm does not require a priori\ninformation about the stochastic structures and performs well for both\nstationary Gaussian and non-Gaussian stochastic processes. Numerical\nexperiments demonstrate the reliability and effectiveness of our proposed\nmethod.", "published": "2025-04-25 13:53:51", "link": "http://arxiv.org/abs/2504.18356v1", "categories": ["math.NA", "cs.NA", "74J25, 35R30, 65N21"], "primary_category": "math.NA"}
{"title": "Stable localized orthogonal decomposition in Raviart-Thomas spaces", "abstract": "This work proposes a computational multiscale method for the mixed\nformulation of a second-order linear elliptic equation subject to a homogeneous\nNeumann boundary condition, based on a stable localized orthogonal\ndecomposition (LOD) in Raviart-Thomas finite element spaces. In the spirit of\nnumerical homogenization, the construction provides low-dimensional coarse\napproximation spaces that incorporate fine-scale information from the\nheterogeneous coefficients by solving local patch problems on a fine mesh. The\nresulting numerical scheme is accompanied by a rigorous error analysis, and it\nis applicable beyond periodicity and scale-separation in spatial dimensions two\nand three. In particular, this novel realization circumvents the presence of\npollution terms observed in a previous LOD construction for elliptic problems\nin mixed formulation. Finally, various numerical experiments are provided that\ndemonstrate the performance of the method.", "published": "2025-04-25 13:00:50", "link": "http://arxiv.org/abs/2504.18322v1", "categories": ["math.NA", "cs.NA", "35J15, 65N12, 65N30"], "primary_category": "math.NA"}
{"title": "A finite volume Simo-Reissner beam method for moored floating body dynamics", "abstract": "This paper presents a novel finite volume mooring line model based on the\ngeometrically exact Simo-Reissner beam model for analysing the interaction\nbetween a floating rigid body and its mooring lines. The coupled numerical\nmodel is implemented entirely within a finite volume-based discretisation\nframework using a popular computational fluid dynamics C++ toolbox, OpenFOAM.\nUnlike existing methods for modelling mooring lines, which rely on lumped mass\nmodels or finite element-based approaches, this work simulates the mooring\ncables using non-linear beam models implemented in a finite volume framework to\naccount for bending, tensile, and torsional loading. This advancement makes the\ncurrent work particularly valuable for simulating extreme sea conditions. The\ncoupled model developed in this study has been validated and verified using\nexperimental and numerical data for a floating box moored with four catenary\nmooring lines under regular wave conditions featuring different wave heights\nand periods. The results demonstrate strong agreement with both experimental\nand numerical data, highlighting the model's accuracy in capturing mooring\ndynamics and floating body motion.", "published": "2025-04-25 10:48:58", "link": "http://arxiv.org/abs/2504.18248v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A hybridizable discontinuous Galerkin method with transmission variables for time-harmonic acoustic problems in heterogeneous media", "abstract": "We consider the finite element solution of time-harmonic wave propagation\nproblems in heterogeneous media with hybridizable discontinuous Galerkin (HDG)\nmethods. In the case of homogeneous media, it has been observed that the\niterative solution of the linear system can be accelerated by hybridizing with\ntransmission variables instead of numerical traces, as performed in standard\napproaches. In this work, we extend the HDG method with transmission variables,\nwhich is called the CHDG method, to the heterogeneous case with piecewise\nconstant physical coefficients. In particular, we consider formulations with\nstandard upwind and general symmetric fluxes. The CHDG hybridized system can be\nwritten as a fixed-point problem, which can be solved with stationary iterative\nschemes for a class of symmetric fluxes. The standard HDG and CHDG methods are\nsystematically studied with the different numerical fluxes by considering a\nseries of 2D numerical benchmarks. The convergence of standard iterative\nschemes is always faster with the extended CHDG method than with the standard\nHDG methods, with upwind and scalar symmetric fluxes.", "published": "2025-04-25 09:41:27", "link": "http://arxiv.org/abs/2504.18209v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "On the approximation of the von Neumann equation in the semi-classical limit. Part II : numerical analysis", "abstract": "This paper is devoted to the numerical analysis of the Hermite spectral\nmethod proposed in [14], which provides, in the semi-classical limit, an\nasymptotic preserving approximation of the von Neumann equation. More\nprecisely, it relies on the use of so-called Weyl's variables to effectively\naddress the stiffness associated to the equation. Then by employing a truncated\nHermite expansion of the density operator, we successfully manage this\nstiffness and provide error estimates by leveraging the propagation of\nregularity in the exact solution.", "published": "2025-04-25 08:50:22", "link": "http://arxiv.org/abs/2504.18177v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Kalman-Langevin dynamics : exponential convergence, particle approximation and numerical approximation", "abstract": "Langevin dynamics has found a large number of applications in sampling,\noptimization and estimation. Preconditioning the gradient in the dynamics with\nthe covariance - an idea that originated in literature related to solving\nestimation and inverse problems using Kalman techniques - results in a\nmean-field (McKean-Vlasov) SDE. We demonstrate exponential convergence of the\ntime marginal law of the mean-field SDE to the Gibbs measure with non-Gaussian\npotentials. This extends previous results, obtained in the Gaussian setting, to\na broader class of potential functions. We also establish uniform in time\nbounds on all moments and convergence in $p$-Wasserstein distance. Furthermore,\nwe show convergence of a weak particle approximation, that avoids computing the\nsquare root of the empirical covariance matrix, to the mean-field limit.\nFinally, we prove that an explicit numerical scheme for approximating the\nparticle dynamics converges, uniformly in number of particles, to its\ncontinuous-time limit, addressing non-global Lipschitzness in the measure.", "published": "2025-04-25 07:46:15", "link": "http://arxiv.org/abs/2504.18139v1", "categories": ["math.PR", "cs.NA", "math.NA", "math.ST", "stat.TH", "65C30, 60H35, 60H10, 37H10, 35Q84"], "primary_category": "math.PR"}
{"title": "A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients", "abstract": "Achieving strongly symmetric stress approximations for linear elasticity\nproblems in high-contrast media poses a significant computational challenge.\nConventional methods often struggle with prohibitively high computational costs\ndue to excessive degrees of freedom, limiting their practical applicability. To\novercome this challenge, we introduce an efficient multiscale model reduction\nmethod and a computationally inexpensive coarse-grid simulation technique for\nlinear elasticity equations in highly heterogeneous, high-contrast media. We\nfirst utilize a stable stress-displacement mixed finite element method to\ndiscretize the linear elasticity problem and then present the construction of\nmultiscale basis functions for the displacement and the stress. The mixed\nformulation offers several advantages such as direct stress computation without\npost-processing, local momentum conservation (ensuring physical consistency),\nand robustness against locking effects, even for nearly incompressible\nmaterials. Theoretical analysis confirms that our method is inf-sup stable and\nlocking-free, with first-order convergence relative to the coarse mesh size.\nNotably, the convergence remains independent of contrast ratios as enlarging\noversampling regions. Numerical experiments validate the method's\neffectiveness, demonstrating its superior performance even under extreme\ncontrast conditions.", "published": "2025-04-25 03:55:16", "link": "http://arxiv.org/abs/2504.18054v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Direct sampling method to retrieve small objects from two-dimensional limited-aperture scattered field data", "abstract": "In this study, we investigated the application of the direct sampling method\n(DSM) to identify small dielectric objects in a limited-aperture inverse\nscattering problem. Unlike previous studies, we consider the bistatic\nmeasurement configuration corresponding to the transmitter location and design\nindicator functions for both a single source and multiple sources, and we\nconvert the unknown measurement data to a fixed nonzero constant. To explain\nthe applicability and limitation of object detection, we demonstrate that the\nindicator functions can be expressed by an infinite series of Bessel functions,\nthe material properties of the objects, the bistatic angle, and the converted\nconstant. Based on the theoretical results, we explain how the imaging\nperformance of the DSM is influenced by the bistatic angle and the converted\nconstant. In addition, the results of our analyses demonstrate that a smaller\nbistatic angle enhances the imaging accuracy and that optimal selection of the\nconverted constant is crucial to realize reliable object detection. The results\nof the numerical simulations obtained using a two-dimensional Fresnel dataset\nvalidated the theoretical findings and illustrate the effectiveness and\nlimitations of the designed indicator functions for small objects.", "published": "2025-04-25 03:02:44", "link": "http://arxiv.org/abs/2504.18036v1", "categories": ["math.NA", "cs.NA", "78A46"], "primary_category": "math.NA"}
{"title": "Real-time inversion of two-dimensional Fresnel experimental database using orthogonality sampling method with single and multiple sources: the case of transverse electric polarized waves", "abstract": "This paper concerns an application of the orthogonality sampling method (OSM)\nfor a real-time identification of small objects from two-dimensional Fresnel\nexperimental dataset in transverse electric polarization. First, we apply the\nOSM with a single source by designing an indicator function based on the\nasymptotic expansion formula for the scattered field in the presence of small\nobjects. We demonstrate that the indicator function can be expressed by an\ninfinite series of Bessel functions of integer order of the first kind, the\nrange of the signal receiver, and the location of the emitter. Based on this,\nwe then investigate the applicability and limitations of the designed OSM.\nSpecifically, we find that the imaging performance is strongly dependent on the\nsource and the applied frequency. We then apply the OSM with multiple sources\nto improve imaging performance. Based on the identified structure of the OSM\nwith a single source, we design an indicator function with multiple sources and\ndemonstrate that it can be expressed by an infinite series of the Bessel\nfunction of integer order of the first kind, and we explain that objects can be\nidentified uniquely using the designed OSM. Numerical simulation results\nobtained with the Fresnel experimental dataset demonstrate the advantages and\ndisadvantages of the OSM with a single source and confirm that the designed OSM\nwith multiple sources improves imaging performance.", "published": "2025-04-25 02:51:46", "link": "http://arxiv.org/abs/2504.18033v1", "categories": ["math.NA", "cs.NA", "78A46"], "primary_category": "math.NA"}
{"title": "Radner equilibrium with population growth", "abstract": "We prove the existence of a Radner equilibrium in a model with population\ngrowth and analyze the effects on asset prices. A finite population of agents\ngrows indefinitely at a Poisson rate, while receiving unspanned income and\nchoosing between consumption and investing into an annuity with\ninfinitely-lived exponential preferences. After establishing the existence of\nan equilibrium for a truncated number of agents, we prove that an equilibrium\nexists for the model with unlimited population growth. Our numerics show that\nincreasing the birth rate reduces oscillations in the equilibrium annuity\nprice, and when younger agents prioritize the present more than older agents,\nthe equilibrium annuity price rises compared to a uniform demographic.", "published": "2025-04-25 01:29:28", "link": "http://arxiv.org/abs/2504.18009v1", "categories": ["q-fin.MF", "91G30, 91B51, 60G55"], "primary_category": "q-fin.MF"}
{"title": "Numerical Generalized Randomized Hamiltonian Monte Carlo for piecewise smooth target densities", "abstract": "Traditional gradient-based sampling methods, like standard Hamiltonian Monte\nCarlo, require that the desired target distribution is continuous and\ndifferentiable. This limits the types of models one can define, although the\npresented models capture the reality in the observations better. In this\nproject, Generalized Randomized Hamiltonian Monte Carlo (GRHMC) processes for\nsampling continuous densities with discontinuous gradient and piecewise smooth\ntargets are proposed. The methods combine the advantages of Hamiltonian Monte\nCarlo methods with the nature of continuous time processes in the form of\npiecewise deterministic Markov processes to sample from such distributions. It\nis argued that the techniques lead to GRHMC processes that admit the desired\ntarget distribution as the invariant distribution in both scenarios. Simulation\nexperiments verifying this fact and several relevant real-life models are\npresented, including a new parameterization of the spike and slab prior for\nregularized linear regression that returns sparse coefficient estimates and a\nregime switching volatility model.", "published": "2025-04-25 09:41:57", "link": "http://arxiv.org/abs/2504.18210v1", "categories": ["stat.CO", "stat.ME", "stat.ML"], "primary_category": "stat.CO"}
{"title": "Fast approximative estimation of conditional Shapley values when using a linear regression model or a polynomial regression model", "abstract": "We develop a new approximative estimation method for conditional Shapley\nvalues obtained using a linear regression model. We develop a new estimation\nmethod and outperform existing methodology and implementations. Compared to the\nsequential method in the shapr-package (i.e fit one and one model), our method\nruns in minutes and not in hours. Compared to the iterative method in the\nshapr-package, we obtain better estimates in less than or almost the same\namount of time. When the number of covariates becomes too large, one can still\nfit thousands of regression models at once using our method. We focus on a\nlinear regression model, but one can easily extend the method to accommodate\nseveral types of splines that can be estimated using multivariate linear\nregression due to linearity in the parameters.", "published": "2025-04-25 08:29:18", "link": "http://arxiv.org/abs/2504.18167v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "DOSE : Drum One-Shot Extraction from Music Mixture", "abstract": "Drum one-shot samples are crucial for music production, particularly in sound\ndesign and electronic music. This paper introduces Drum One-Shot Extraction, a\ntask in which the goal is to extract drum one-shots that are present in the\nmusic mixture. To facilitate this, we propose the Random Mixture One-shot\nDataset (RMOD), comprising large-scale, randomly arranged music mixtures paired\nwith corresponding drum one-shot samples. Our proposed model, Drum One- Shot\nExtractor (DOSE), leverages neural audio codec language models for end-to-end\nextraction, bypassing traditional source separation steps. Additionally, we\nintroduce a novel onset loss, designed to encourage accurate prediction of the\ninitial transient of drum one-shots, which is essential for capturing timbral\ncharacteristics. We compare this approach against a source separation-based\nextraction method as a baseline. The results, evaluated using Frechet Audio\nDistance (FAD) and Multi-Scale Spectral loss (MSS), demonstrate that DOSE,\nenhanced with onset loss, outperforms the baseline, providing more accurate and\nhigher-quality drum one-shots from music mixtures. The code, model checkpoint,\nand audio examples are available at https://github.com/HSUNEH/DOSE", "published": "2025-04-25 08:12:35", "link": "http://arxiv.org/abs/2504.18157v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Assessing the Utility of Audio Foundation Models for Heart and Respiratory Sound Analysis", "abstract": "Pre-trained deep learning models, known as foundation models, have become\nessential building blocks in machine learning domains such as natural language\nprocessing and image domains. This trend has extended to respiratory and heart\nsound models, which have demonstrated effectiveness as off-the-shelf feature\nextractors. However, their evaluation benchmarking has been limited, resulting\nin incompatibility with state-of-the-art (SOTA) performance, thus hindering\nproof of their effectiveness. This study investigates the practical\neffectiveness of off-the-shelf audio foundation models by comparing their\nperformance across four respiratory and heart sound tasks with SOTA fine-tuning\nresults. Experiments show that models struggled on two tasks with noisy data\nbut achieved SOTA performance on the other tasks with clean data. Moreover,\ngeneral-purpose audio models outperformed a respiratory sound model,\nhighlighting their broader applicability. With gained insights and the released\ncode, we contribute to future research on developing and leveraging foundation\nmodels for respiratory and heart sounds.", "published": "2025-04-25 01:17:58", "link": "http://arxiv.org/abs/2504.18004v1", "categories": ["eess.AS", "cs.SD", "68T07", "J.3"], "primary_category": "eess.AS"}
{"title": "Improved Dwell-times for Switched Nonlinear Systems using Memory Regression Extension", "abstract": "This paper presents a switched systems approach for extending the dwell-time\nof an autonomous agent during GPS-denied operation by leveraging memory\nregressor extension (MRE) techniques. To maintain accurate trajectory tracking\ndespite unknown dynamics and environmental disturbances, the agent periodically\nacquires access to GPS, allowing it to correct accumulated state estimation\nerrors. The motivation for this work arises from the limitations of existing\nswitched system approaches, where increasing estimation errors during\nGPS-denied intervals and overly conservative dwell-time conditions restrict the\noperational efficiency of the agent. By leveraging MRE techniques during\nGPS-available intervals, the developed method refines the estimates of unknown\nsystem parameters, thereby enabling longer and more reliable operation in\nGPS-denied environments. A Lyapunov-based switched-system stability analysis\nestablishes that improved parameter estimates obtained through concurrent\nlearning allow extended operation in GPS-denied intervals without compromising\nclosed-loop system stability. Simulation results validate the theoretical\nfindings, demonstrating dwell-time extensions and enhanced trajectory tracking\nperformance.", "published": "2025-04-25 16:10:48", "link": "http://arxiv.org/abs/2504.18457v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "MROP: Modulated Rank-One Projections for compressive radio interferometric imaging", "abstract": "The emerging generation of radio-interferometric (RI) arrays are set to form\nimages of the sky with a new regime of sensitivity and resolution. This implies\na significant increase in visibility data volumes, scaling as\n$\\mathcal{O}(Q^{2}B)$ for $Q$ antennas and $B$ short-time integration intervals\n(or batches), calling for efficient data dimensionality reduction techniques.\nThis paper proposes a new approach to data compression during acquisition,\ncoined modulated rank-one projection (MROP). MROP compresses the $Q\\times Q$\nbatchwise covariance matrix into a smaller number $P$ of random rank-one\nprojections and compresses across time by trading $B$ for a smaller number $M$\nof random modulations of the ROP measurement vectors. Firstly, we introduce a\ndual perspective on the MROP acquisition, which can either be understood as\nrandom beamforming, or as a post-correlation compression. Secondly, we analyse\nthe noise statistics of MROPs and demonstrate that the random projections\ninduce a uniform noise level across measurements independently of the\nvisibility-weighting scheme used. Thirdly, we propose a detailed analysis of\nthe memory and computational cost requirements across the data acquisition and\nimage reconstruction stages, with comparison to state-of-the-art dimensionality\nreduction approaches. Finally, the MROP model is validated in simulation for\nmonochromatic intensity imaging, with comparison to the classical and\nbaseline-dependent averaging (BDA) models, and using the uSARA optimisation\nalgorithm for image formation. An extensive experimental setup is considered,\nwith ground-truth images containing diffuse and faint emission and spanning a\nwide variety of dynamic ranges, and for a range of $uv$-coverages corresponding\nto VLA and MeerKAT observation.", "published": "2025-04-25 16:00:11", "link": "http://arxiv.org/abs/2504.18446v1", "categories": ["astro-ph.IM", "eess.IV", "eess.SP"], "primary_category": "astro-ph.IM"}
{"title": "Multi-Sensor Fusion of Active and Passive Measurements for Extended Object Tracking", "abstract": "This paper addresses the challenge of achieving robust and reliable\npositioning of a radio device carried by an agent, in scenarios where direct\nline-of-sight (LOS) radio links are obstructed by the agent. We propose a\nBayesian estimation algorithm that integrates active measurements between the\nradio device and anchors with passive measurements in-between anchors\nreflecting off the agent. A geometry-based scattering measurement model is\nintroduced for multi-sensor structures, and multiple object-related\nmeasurements are incorporated to formulate an extended object probabilistic\ndata association (PDA) algorithm, where the agent that blocks, scatters and\nattenuates radio signals is modeled as an extended object (EO). The proposed\napproach significantly improves the accuracy during and after obstructed LOS\nconditions, outperforming the conventional PDA (which is based on the\npoint-target-assumption) and methods relying solely on active measurements.", "published": "2025-04-25 12:20:48", "link": "http://arxiv.org/abs/2504.18301v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generative AI for Physical-Layer Authentication", "abstract": "In recent years, Artificial Intelligence (AI)-driven Physical-Layer\nAuthentication (PLA), which focuses on achieving endogenous security and\nintelligent identity authentication, has attracted considerable interest. When\ncompared with Discriminative AI (DAI), Generative AI (GAI) offers several\nadvantages, such as fingerprint data augmentation, fingerprint denoising and\nreconstruction, and protection against adversarial attacks. Inspired by these\ninnovations, this paper provides a systematic exploration of GAI's integration\ninto PLA frameworks. We commence with a review of representative authentication\ntechniques, emphasizing PLA's inherent strengths. Following this, we revisit\nfour typical GAI models and contrast the limitations of DAI with the potential\nof GAI in addressing PLA challenges, including insufficient fingerprint data,\nenvironment noises and inferences, perturbations in fingerprint data, and\ncomplex tasks. Specifically, we delve into providing GAI-enhance methods for\nPLA across the data, model, and application layers in detail. Moreover, we\npresent a case study that combines fingerprint extrapolation, generative\ndiffusion models, and cooperative nodes to illustrate the superiority of GAI in\nbolstering the reliability of PLA compared to DAI. Additionally, we outline\npotential future research directions for GAI-based PLA.", "published": "2025-04-25 08:46:38", "link": "http://arxiv.org/abs/2504.18175v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Full-Duplex ISCC for Low-Altitude Networks: Resource Allocation and Coordinated Beamforming", "abstract": "This paper investigates an integrated sensing, communication, and computing\nsystem deployed over low-altitude networks for enabling applications within the\nlow-altitude economy. In the considered system, a full-duplex enabled unmanned\naerial vehicle (UAV) is dispatched in the airspace, functioning as a\nUAV-enabled low-altitude platform (ULAP). The ULAP is capable of achieving\nsimultaneous information transmission, target sensing, and mobile edge\ncomputing services. To reduce the overall energy consumption of the system\nwhile meeting the sensing beampattern threshold and user computation\nrequirements, we formulate an energy consumption minimization problem by\njointly optimizing the task allocation, computation resource allocation,\ntransmit beamforming, and receive beamforming. Since the problem is non-convex\nand involves highly coupled variables, we propose an efficient algorithm based\non alternation optimization, which decomposes the original problem into\ntractable convex subproblems. Moreover, we analyze the convergence and\ncomplexity of the proposed algorithm. Numerical results demonstrate that the\nproposed scheme saves up to 54.12\\% energy consumption performance compared to\nthe benchmark schemes.", "published": "2025-04-25 07:52:28", "link": "http://arxiv.org/abs/2504.18143v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physical Layer Security for Integrated Sensing and Communication: A Survey", "abstract": "Integrated sensing and communication (ISAC) has become a crucial technology\nin the development of next-generation wireless communication systems. The\nintegration of communication and sensing functionalities on a unified spectrum\nand infrastructure is expected to enable a variety of emerging use cases. The\nintroduction of ISAC has led to various new challenges and opportunities\nrelated to the security of wireless communications, resulting in significant\nresearch focused on ISAC system design in relation to physical layer security\n(PLS). The shared use of spectrum presents a risk where confidential messages\nembedded in probing ISAC signals may be exposed to potentially malicious\nsensing targets. This situation creates a tradeoff between sensing performance\nand security performance. The sensing functionality of ISAC offers a unique\nopportunity for PLS by utilizing sensing information regarding potential\neavesdroppers to design secure PLS schemes. This study examines PLS\nmethodologies to tackle the specified security challenge associated with ISAC.\nThe study begins with a brief overview of performance metrics related to PLS\nand sensing, as well as the optimization techniques commonly utilized in the\nexisting literature. A thorough examination of existing literature on PLS for\nISAC is subsequently presented, with the objective of emphasizing the current\nstate of research. The study concludes by outlining potential avenues for\nfuture research pertaining to secure ISAC systems.", "published": "2025-04-25 05:48:54", "link": "http://arxiv.org/abs/2504.18097v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Resource Estimation and Trajectory Optimization for eVTOL-involved CR network: A Monte Carlo Tree Search-based Approach", "abstract": "Electric Vertical Take-Off and Landing (eVTOL) aircraft, pivotal to Advanced\nAir Mobility (AAM), are emerging as a transformative transportation paradigm\nwith the potential to redefine urban and regional mobility. While these systems\noffer unprecedented efficiency in transporting people and goods, they rely\nheavily on computation capability, safety-critical operations such as real-time\nnavigation, environmental sensing, and trajectory tracking--necessitating\nrobust offboard computational support. A widely adopted solution involves\noffloading these tasks to terrestrial base stations (BSs) along the flight\npath. However, air-to-ground connectivity is often constrained by spectrum\nconflicts with terrestrial users, which poses a significant challenge to\nmaintaining reliable task execution. Cognitive radio (CR) techniques offer\npromising capabilities for dynamic spectrum access, making them a natural fit\nfor addressing this issue. Existing studies often overlook the time-varying\nnature of BS resources, such as spectrum availability and CPU cycles, which\nleads to inaccurate trajectory planning, suboptimal offloading success rates,\nexcessive energy consumption, and operational delays. To address these\nchallenges, we propose a trajectory optimization framework for eVTOL swarms\nthat maximizes task offloading success probability while minimizing both energy\nconsumption and resource competition (e.g., spectrum and CPU cycles) with\nprimary terrestrial users. The proposed algorithm integrates a Multi-Armed\nBandit (MAB) model to dynamically estimate BS resource availability and a Monte\nCarlo Tree Search (MCTS) algorithm to determine optimal offloading decisions,\nselecting both the BSs and access time windows that align with energy and\ntemporal constraints.", "published": "2025-04-25 02:48:48", "link": "http://arxiv.org/abs/2504.18031v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Optimal Power Allocation for OFDM-based Ranging Using Random Communication Signals", "abstract": "High-precision ranging plays a crucial role in future 6G Integrated Sensing\nand Communication (ISAC) systems. To improve the ranging performance while\nmaximizing the resource utilization efficiency, future 6G ISAC networks have to\nreuse data payload signals for both communication and sensing, whose inherent\nrandomness may deteriorate the ranging performance. To address this issue, this\npaper investigates the power allocation (PA) design for an OFDM-based ISAC\nsystem under random signaling, aiming to reduce the ranging sidelobe level of\nboth periodic and aperiodic auto-correlation functions (P-ACF and A-ACF) of the\nISAC signal. Towards that end, we first derive the closed-form expressions of\nthe average squared P-ACF and A-ACF, and then propose to minimize the\nexpectation of the integrated sidelobe level (EISL) under arbitrary\nconstellation mapping. We then rigorously prove that the uniform PA scheme\nachieves the global minimum of the EISL for both P-ACF and A-ACF. As a step\nfurther, we show that this scheme also minimizes the P-ACF sidelobe level at\nevery lag. Moreover, we extend our analysis to the P-ACF case with\nfrequency-domain zero-padding, which is a typical approach to improve the\nranging resolution. We reveal that there exists a tradeoff between sidelobe\nlevel and mainlobe width, and propose a project gradient descent algorithm to\nseek a locally optimal PA scheme that reduces the EISL. Finally, we validate\nour theoretical findings through extensive simulation results, confirming the\neffectiveness of the proposed PA methods in reducing the ranging sidelobe level\nfor random OFDM signals.", "published": "2025-04-25 01:54:03", "link": "http://arxiv.org/abs/2504.18016v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
