{"title": "Construction of a Japanese Word Similarity Dataset", "abstract": "An evaluation of distributed word representation is generally conducted using\na word similarity task and/or a word analogy task. There are many datasets\nreadily available for these tasks in English. However, evaluating distributed\nrepresentation in languages that do not have such resources (e.g., Japanese) is\ndifficult. Therefore, as a first step toward evaluating distributed\nrepresentations in Japanese, we constructed a Japanese word similarity dataset.\nTo the best of our knowledge, our dataset is the first resource that can be\nused to evaluate distributed representations in Japanese. Moreover, our dataset\ncontains various parts of speech and includes rare words in addition to common\nwords.", "published": "2017-03-17 07:53:03", "link": "http://arxiv.org/abs/1703.05916v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fostering User Engagement: Rhetorical Devices for Applause Generation\n  Learnt from TED Talks", "abstract": "One problem that every presenter faces when delivering a public discourse is\nhow to hold the listeners' attentions or to keep them involved. Therefore, many\nstudies in conversation analysis work on this issue and suggest qualitatively\ncon-structions that can effectively lead to audience's applause. To investigate\nthese proposals quantitatively, in this study we an-alyze the transcripts of\n2,135 TED Talks, with a particular fo-cus on the rhetorical devices that are\nused by the presenters for applause elicitation. Through conducting regression\nanal-ysis, we identify and interpret 24 rhetorical devices as triggers of\naudience applauding. We further build models that can rec-ognize\napplause-evoking sentences and conclude this work with potential implications.", "published": "2017-03-17 15:57:45", "link": "http://arxiv.org/abs/1704.02362v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal Information Extraction for Question Answering Using Syntactic\n  Dependencies in an LSTM-based Architecture", "abstract": "In this paper, we propose to use a set of simple, uniform in architecture\nLSTM-based models to recover different kinds of temporal relations from text.\nUsing the shortest dependency path between entities as input, the same\narchitecture is used to extract intra-sentence, cross-sentence, and document\ncreation time relations. A \"double-checking\" technique reverses entity pairs in\nclassification, boosting the recall of positive cases and reducing\nmisclassifications between opposite classes. An efficient pruning algorithm\nresolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our\nproposed technique outperforms state-of-the-art methods by a large margin.", "published": "2017-03-17 00:02:42", "link": "http://arxiv.org/abs/1703.05851v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Empirical Evaluation of Parallel Training Algorithms on Acoustic\n  Modeling", "abstract": "Deep learning models (DLMs) are state-of-the-art techniques in speech\nrecognition. However, training good DLMs can be time consuming especially for\nproduction-size models and corpora. Although several parallel training\nalgorithms have been proposed to improve training efficiency, there is no clear\nguidance on which one to choose for the task in hand due to lack of systematic\nand fair comparison among them. In this paper we aim at filling this gap by\ncomparing four popular parallel training algorithms in speech recognition,\nnamely asynchronous stochastic gradient descent (ASGD), blockwise model-update\nfiltering (BMUF), bulk synchronous parallel (BSP) and elastic averaging\nstochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using\nfeed-forward deep neural networks (DNNs) and convolutional, long short-term\nmemory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the\ntop choice to train acoustic models since it is most stable, scales well with\nnumber of GPUs, can achieve reproducible results, and in many cases even\noutperforms single-GPU SGD. ASGD can be used as a substitute in some cases.", "published": "2017-03-17 03:38:48", "link": "http://arxiv.org/abs/1703.05880v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning Robust Visual-Semantic Embeddings", "abstract": "Many of the existing methods for learning joint embedding of images and text\nuse only supervised information from paired images and its textual attributes.\nTaking advantage of the recent success of unsupervised learning in deep neural\nnetworks, we propose an end-to-end learning framework that is able to extract\nmore robust multi-modal representations across domains. The proposed method\ncombines representation learning models (i.e., auto-encoders) together with\ncross-domain learning criteria (i.e., Maximum Mean Discrepancy loss) to learn\njoint embeddings for semantic and visual features. A novel technique of\nunsupervised-data adaptation inference is introduced to construct more\ncomprehensive embeddings for both labeled and unlabeled data. We evaluate our\nmethod on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with\na wide range of applications, including zero and few-shot image recognition and\nretrieval, from inductive to transductive settings. Empirically, we show that\nour framework improves over the current state of the art on many of the\nconsidered tasks.", "published": "2017-03-17 06:59:51", "link": "http://arxiv.org/abs/1703.05908v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Global Entity Ranking Across Multiple Languages", "abstract": "We present work on building a global long-tailed ranking of entities across\nmultiple languages using Wikipedia and Freebase knowledge bases. We identify\nmultiple features and build a model to rank entities using a ground-truth\ndataset of more than 10 thousand labels. The final system ranks 27 million\nentities with 75% precision and 48% F1 score. We provide performance evaluation\nand empirical evidence of the quality of ranking across languages, and open the\nfinal ranked lists for future research.", "published": "2017-03-17 17:16:02", "link": "http://arxiv.org/abs/1703.06108v1", "categories": ["cs.IR", "cs.CL", "cs.SI", "H.3.1"], "primary_category": "cs.IR"}
