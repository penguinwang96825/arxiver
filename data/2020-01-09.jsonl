{"title": "Multiplex Word Embeddings for Selectional Preference Acquisition", "abstract": "Conventional word embeddings represent words with fixed vectors, which are\nusually trained based on co-occurrence patterns among words. In doing so,\nhowever, the power of such representations is limited, where the same word\nmight be functionalized separately under different syntactic relations. To\naddress this limitation, one solution is to incorporate relational dependencies\nof different words into their embeddings. Therefore, in this paper, we propose\na multiplex word embedding model, which can be easily extended according to\nvarious relations among words. As a result, each word has a center embedding to\nrepresent its overall semantics, and several relational embeddings to represent\nits relational dependencies. Compared to existing models, our model can\neffectively distinguish words with respect to different relations without\nintroducing unnecessary sparseness. Moreover, to accommodate various relations,\nwe use a small dimension for relational embeddings and our model is able to\nkeep their effectiveness. Experiments on selectional preference acquisition and\nword similarity demonstrate the effectiveness of the proposed model, and a\nfurther study of scalability also proves that our embeddings only need 1/20 of\nthe original embedding size to achieve better performance.", "published": "2020-01-09 04:47:14", "link": "http://arxiv.org/abs/2001.02836v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resolving the Scope of Speculation and Negation using Transformer-Based\n  Architectures", "abstract": "Speculation is a naturally occurring phenomena in textual data, forming an\nintegral component of many systems, especially in the biomedical information\nretrieval domain. Previous work addressing cue detection and scope resolution\n(the two subtasks of speculation detection) have ranged from rule-based systems\nto deep learning-based approaches. In this paper, we apply three popular\ntransformer-based architectures, BERT, XLNet and RoBERTa to this task, on two\npublicly available datasets, BioScope Corpus and SFU Review Corpus, reporting\nsubstantial improvements over previously reported results (by at least 0.29 F1\npoints on cue detection and 4.27 F1 points on scope resolution). We also\nexperiment with joint training of the model on multiple datasets, which\noutperforms the single dataset training approach by a good margin. We observe\nthat XLNet consistently outperforms BERT and RoBERTa, contrary to results on\nother benchmark datasets. To confirm this observation, we apply XLNet and\nRoBERTa to negation detection and scope resolution, reporting state-of-the-art\nresults on negation scope resolution for the BioScope Corpus (increase of 3.16\nF1 points on the BioScope Full Papers, 0.06 F1 points on the BioScope\nAbstracts) and the SFU Review Corpus (increase of 0.3 F1 points).", "published": "2020-01-09 08:43:30", "link": "http://arxiv.org/abs/2001.02885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Binary and Multitask Classification Model for Dutch Anaphora Resolution:\n  Die/Dat Prediction", "abstract": "The correct use of Dutch pronouns 'die' and 'dat' is a stumbling block for\nboth native and non-native speakers of Dutch due to the multiplicity of\nsyntactic functions and the dependency on the antecedent's gender and number.\nDrawing on previous research conducted on neural context-dependent dt-mistake\ncorrection models (Heyman et al. 2018), this study constructs the first neural\nnetwork model for Dutch demonstrative and relative pronoun resolution that\nspecifically focuses on the correction and part-of-speech prediction of these\ntwo pronouns. Two separate datasets are built with sentences obtained from,\nrespectively, the Dutch Europarl corpus (Koehn 2015) - which contains the\nproceedings of the European Parliament from 1996 to the present - and the SoNaR\ncorpus (Oostdijk et al. 2013) - which contains Dutch texts from a variety of\ndomains such as newspapers, blogs and legal texts. Firstly, a binary\nclassification model solely predicts the correct 'die' or 'dat'. The classifier\nwith a bidirectional long short-term memory architecture achieves 84.56%\naccuracy. Secondly, a multitask classification model simultaneously predicts\nthe correct 'die' or 'dat' and its part-of-speech tag. The model containing a\ncombination of a sentence and context encoder with both a bidirectional long\nshort-term memory architecture results in 88.63% accuracy for die/dat\nprediction and 87.73% accuracy for part-of-speech prediction. More\nevenly-balanced data, larger word embeddings, an extra bidirectional long\nshort-term memory layer and integrated part-of-speech knowledge positively\naffects die/dat prediction performance, while a context encoder architecture\nraises part-of-speech prediction performance. This study shows promising\nresults and can serve as a starting point for future research on machine\nlearning models for Dutch anaphora resolution.", "published": "2020-01-09 12:34:01", "link": "http://arxiv.org/abs/2001.02943v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Offensive Language Detection: A Comparative Analysis", "abstract": "Offensive behaviour has become pervasive in the Internet community.\nIndividuals take the advantage of anonymity in the cyber world and indulge in\noffensive communications which they may not consider in the real life.\nGovernments, online communities, companies etc are investing into prevention of\noffensive behaviour content in social media. One of the most effective solution\nfor tacking this enigmatic problem is the use of computational techniques to\nidentify offensive content and take action. The current work focuses on\ndetecting offensive language in English tweets. The dataset used for the\nexperiment is obtained from SemEval-2019 Task 6 on Identifying and Categorizing\nOffensive Language in Social Media (OffensEval). The dataset contains 14,460\nannotated English tweets. The present paper provides a comparative analysis and\nRandom kitchen sink (RKS) based approach for offensive language detection. We\nexplore the effectiveness of Google sentence encoder, Fasttext, Dynamic mode\ndecomposition (DMD) based features and Random kitchen sink (RKS) method for\noffensive language detection. From the experiments and evaluation we observed\nthat RKS with fastetxt achieved competing results. The evaluation measures used\nare accuracy, precision, recall, f1-score.", "published": "2020-01-09 17:48:44", "link": "http://arxiv.org/abs/2001.03131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simulating Lexical Semantic Change from Sense-Annotated Data", "abstract": "We present a novel procedure to simulate lexical semantic change from\nsynchronic sense-annotated data, and demonstrate its usefulness for assessing\nlexical semantic change detection models. The induced dataset represents a\nstronger correspondence to empirically observed lexical semantic change than\nprevious synthetic datasets, because it exploits the intimate relationship\nbetween synchronic polysemy and diachronic change. We publish the data and\nprovide the first large-scale evaluation gold standard for LSC detection\nmodels.", "published": "2020-01-09 20:37:49", "link": "http://arxiv.org/abs/2001.03216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The empirical structure of word frequency distributions", "abstract": "The frequencies at which individual words occur across languages follow power\nlaw distributions, a pattern of findings known as Zipf's law. A vast literature\nargues over whether this serves to optimize the efficiency of human\ncommunication, however this claim is necessarily post hoc, and it has been\nsuggested that Zipf's law may in fact describe mixtures of other distributions.\nFrom this perspective, recent findings that Sinosphere first (family) names are\ngeometrically distributed are notable, because this is actually consistent with\ninformation theoretic predictions regarding optimal coding. First names form\nnatural communicative distributions in most languages, and I show that when\nanalyzed in relation to the communities in which they are used, first name\ndistributions across a diverse set of languages are both geometric and,\nhistorically, remarkably similar, with power law distributions only emerging\nwhen empirical distributions are aggregated. I then show this pattern of\nfindings replicates in communicative distributions of English nouns and verbs.\nThese results indicate that if lexical distributions support efficient\ncommunication, they do so because their functional structures directly satisfy\nthe constraints described by information theory, and not because of Zipf's law.\nUnderstanding the function of these information structures is likely to be key\nto explaining humankind's remarkable communicative capacities.", "published": "2020-01-09 20:52:38", "link": "http://arxiv.org/abs/2001.05292v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Challenge for Correcting Errors of Speech Recognition Systems", "abstract": "The paper announces the new long-term challenge for improving the performance\nof automatic speech recognition systems. The goal of the challenge is to\ninvestigate methods of correcting the recognition results on the basis of\npreviously made errors by the speech processing system. The dataset prepared\nfor the task is described and evaluation criteria are presented.", "published": "2020-01-09 15:07:32", "link": "http://arxiv.org/abs/2001.03041v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "abstract": "We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.", "published": "2020-01-09 15:19:45", "link": "http://arxiv.org/abs/2001.03436v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Short-Range Audio Channels Security: Survey of Mechanisms, Applications,\n  and Research Challenges", "abstract": "Short-range audio channels have a few distinguishing characteristics: ease of\nuse, low deployment costs, and easy to tune frequencies, to cite a few.\nMoreover, thanks to their seamless adaptability to the security context, many\ntechniques and tools based on audio signals have been recently proposed.\nHowever, while the most promising solutions are turning into valuable\ncommercial products, acoustic channels are increasingly used also to launch\nattacks against systems and devices, leading to security concerns that could\nthwart their adoption. To provide a rigorous, scientific, security-oriented\nreview of the field, in this paper we survey and classify methods,\napplications, and use-cases rooted on short-range audio channels for the\nprovisioning of security services---including Two-Factor Authentication\ntechniques, pairing solutions, device authorization strategies, defense\nmethodologies, and attack schemes. Moreover, we also point out the strengths\nand weaknesses deriving from the use of short-range audio channels. Finally, we\nprovide open research issues in the context of short-range audio channels\nsecurity, calling for contributions from both academia and industry.", "published": "2020-01-09 08:07:55", "link": "http://arxiv.org/abs/2001.02877v2", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
