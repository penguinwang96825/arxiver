{"title": "Incorporating Semi-supervised Features into Discontinuous Easy-First\n  Constituent Parsing", "abstract": "This paper describes adaptations for EaFi, a parser for easy-first parsing of\ndiscontinuous constituents, to adapt it to multiple languages as well as make\nuse of the unlabeled data that was provided as part of the SPMRL shared task\n2014.", "published": "2014-09-12 18:37:35", "link": "http://arxiv.org/abs/1409.3813v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text mixing shapes the anatomy of rank-frequency distributions: A modern\n  Zipfian mechanics for natural language", "abstract": "Natural languages are full of rules and exceptions. One of the most famous\nquantitative rules is Zipf's law which states that the frequency of occurrence\nof a word is approximately inversely proportional to its rank. Though this\n`law' of ranks has been found to hold across disparate texts and forms of data,\nanalyses of increasingly large corpora over the last 15 years have revealed the\nexistence of two scaling regimes. These regimes have thus far been explained by\na hypothesis suggesting a separability of languages into core and non-core\nlexica. Here, we present and defend an alternative hypothesis, that the two\nscaling regimes result from the act of aggregating texts. We observe that text\nmixing leads to an effective decay of word introduction, which we show provides\naccurate predictions of the location and severity of breaks in scaling. Upon\nexamining large corpora from 10 languages in the Project Gutenberg eBooks\ncollection (eBooks), we find emphatic empirical support for the universality of\nour claim.", "published": "2014-09-12 21:34:28", "link": "http://arxiv.org/abs/1409.3870v3", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "An Approach to Reducing Annotation Costs for BioNLP", "abstract": "There is a broad range of BioNLP tasks for which active learning (AL) can\nsignificantly reduce annotation costs and a specific AL algorithm we have\ndeveloped is particularly effective in reducing annotation costs for these\ntasks. We have previously developed an AL algorithm called ClosestInitPA that\nworks best with tasks that have the following characteristics: redundancy in\ntraining material, burdensome annotation costs, Support Vector Machines (SVMs)\nwork well for the task, and imbalanced datasets (i.e. when set up as a binary\nclassification problem, one class is substantially rarer than the other). Many\nBioNLP tasks have these characteristics and thus our AL algorithm is a natural\napproach to apply to BioNLP tasks.", "published": "2014-09-12 22:40:38", "link": "http://arxiv.org/abs/1409.3881v1", "categories": ["cs.CL", "cs.LG", "stat.ML", "I.2.7; I.2.6; I.5.1; I.5.4"], "primary_category": "cs.CL"}
