{"title": "AraTrust: An Evaluation of Trustworthiness for LLMs in Arabic", "abstract": "The swift progress and widespread acceptance of artificial intelligence (AI)\nsystems highlight a pressing requirement to comprehend both the capabilities\nand potential risks associated with AI. Given the linguistic complexity,\ncultural richness, and underrepresented status of Arabic in AI research, there\nis a pressing need to focus on Large Language Models (LLMs) performance and\nsafety for Arabic-related tasks. Despite some progress in their development,\nthere is a lack of comprehensive trustworthiness evaluation benchmarks, which\npresents a major challenge in accurately assessing and improving the safety of\nLLMs when prompted in Arabic. In this paper, we introduce AraTrust, the first\ncomprehensive trustworthiness benchmark for LLMs in Arabic. AraTrust comprises\n522 human-written multiple-choice questions addressing diverse dimensions\nrelated to truthfulness, ethics, safety, physical health, mental health,\nunfairness, illegal activities, privacy, and offensive language. We evaluated a\nset of LLMs against our benchmark to assess their trustworthiness. GPT-4 was\nthe most trustworthy LLM, while open-source models, particularly AceGPT 7B and\nJais 13B, struggled to achieve a score of 60% in our benchmark.", "published": "2024-03-14 00:45:24", "link": "http://arxiv.org/abs/2403.09017v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning", "abstract": "Charts provide visual representations of data and are widely used for\nanalyzing information, addressing queries, and conveying insights to others.\nVarious chart-related downstream tasks have emerged recently, such as\nquestion-answering and summarization. A common strategy to solve these tasks is\nto fine-tune various models originally trained on vision tasks language.\nHowever, such task-specific models are not capable of solving a wide range of\nchart-related tasks, constraining their real-world applicability. To overcome\nthese challenges, we introduce ChartInstruct: a novel chart-specific\nvision-language Instruction-following dataset comprising 191K instructions\ngenerated with 71K charts. We then present two distinct systems for instruction\ntuning on such datasets: (1) an end-to-end model that connects a vision encoder\nfor chart understanding with a LLM; and (2) a pipeline model that employs a\ntwo-step approach to extract chart data tables and input them into the LLM. In\nexperiments on four downstream tasks, we first show the effectiveness of our\nmodel--achieving a new set of state-of-the-art results. Further evaluation\nshows that our instruction-tuning approach supports a wide array of real-world\nchart comprehension and reasoning scenarios, thereby expanding the scope and\napplicability of our models to new kinds of tasks.", "published": "2024-03-14 01:40:23", "link": "http://arxiv.org/abs/2403.09028v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAGGED: Towards Informed Design of Retrieval Augmented Generation\n  Systems", "abstract": "Retrieval-augmented generation (RAG) can significantly improve the\nperformance of language models (LMs) by providing additional context for tasks\nsuch as document-based question answering (DBQA). However, the effectiveness of\nRAG is highly dependent on its configuration. To systematically find the\noptimal configuration, we introduce RAGGED, a framework for analyzing RAG\nconfigurations across various DBQA tasks. Using the framework, we discover\ndistinct LM behaviors in response to varying context quantities, context\nqualities, and retrievers. For instance, while some models are robust to noisy\ncontexts, monotonically performing better with more contexts, others are more\nnoise-sensitive and can effectively use only a few contexts before declining in\nperformance. This framework also provides a deeper analysis of these\ndifferences by evaluating the LMs' sensitivity to signal and noise under\nspecific context quality conditions. Using RAGGED, researchers and\npractitioners can derive actionable insights about how to optimally configure\ntheir RAG systems for their specific question-answering tasks.", "published": "2024-03-14 02:26:31", "link": "http://arxiv.org/abs/2403.09040v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LAMP: A Language Model on the Map", "abstract": "Large Language Models (LLMs) are poised to play an increasingly important\nrole in our lives, providing assistance across a wide array of tasks. In the\ngeospatial domain, LLMs have demonstrated the ability to answer generic\nquestions, such as identifying a country's capital; nonetheless, their utility\nis hindered when it comes to answering fine-grained questions about specific\nplaces, such as grocery stores or restaurants, which constitute essential\naspects of people's everyday lives. This is mainly because the places in our\ncities haven't been systematically fed into LLMs, so as to understand and\nmemorize them. This study introduces a novel framework for fine-tuning a\npre-trained model on city-specific data, to enable it to provide accurate\nrecommendations, while minimizing hallucinations. We share our model, LAMP, and\nthe data used to train it. We conduct experiments to analyze its ability to\ncorrectly retrieving spatial objects, and compare it to well-known open- and\nclosed- source language models, such as GPT-4. Finally, we explore its emerging\ncapabilities through a case study on day planning.", "published": "2024-03-14 02:56:38", "link": "http://arxiv.org/abs/2403.09059v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revealing the Parallel Multilingual Learning within Large Language\n  Models", "abstract": "In this study, we reveal an in-context learning (ICL) capability of\nmultilingual large language models (LLMs): by translating the input to several\nlanguages, we provide Parallel Input in Multiple Languages (PiM) to LLMs, which\nsignificantly enhances their comprehension abilities. To test this capability,\nwe design extensive experiments encompassing 8 typical datasets, 7 languages\nand 8 state-of-the-art multilingual LLMs. Experimental results show that (1)\nincorporating more languages help PiM surpass the conventional ICL further; (2)\neven combining with the translations that are inferior to baseline performance\ncan also help. Moreover, by examining the activated neurons in LLMs, we\ndiscover a counterintuitive but interesting phenomenon. Contrary to the common\nthought that PiM would activate more neurons than monolingual input to leverage\nknowledge learned from diverse languages, PiM actually inhibits neurons and\npromotes more precise neuron activation especially when more languages are\nadded. This phenomenon aligns with the neuroscience insight about synaptic\npruning, which removes less used neural connections, strengthens remainders,\nand then enhances brain intelligence.", "published": "2024-03-14 03:33:46", "link": "http://arxiv.org/abs/2403.09073v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Information Extraction: An application to the domain of hyper-local\n  financial data on developing countries", "abstract": "Despite the need for financial data on company activities in developing\ncountries for development research and economic analysis, such data does not\nexist. In this project, we develop and evaluate two Natural Language Processing\n(NLP) based techniques to address this issue. First, we curate a custom dataset\nspecific to the domain of financial text data on developing countries and\nexplore multiple approaches for information extraction. We then explore a\ntext-to-text approach with the transformer-based T5 model with the goal of\nundertaking simultaneous NER and relation extraction. We find that this model\nis able to learn the custom text structure output data corresponding to the\nentities and their relations, resulting in an accuracy of 92.44\\%, a precision\nof 68.25\\% and a recall of 54.20\\% from our best T5 model on the combined task.\nSecondly, we explore an approach with sequential NER and relation extration.\nFor the NER, we run pre-trained and fine-tuned models using SpaCy, and we\ndevelop a custom relation extraction model using SpaCy's Dependency Parser\noutput and some heuristics to determine entity relationships \\cite{spacy}. We\nobtain an accuracy of 84.72\\%, a precision of 6.06\\% and a recall of 5.57\\% on\nthis sequential task.", "published": "2024-03-14 03:49:36", "link": "http://arxiv.org/abs/2403.09077v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI on AI: Exploring the Utility of GPT as an Expert Annotator of AI\n  Publications", "abstract": "Identifying scientific publications that are within a dynamic field of\nresearch often requires costly annotation by subject-matter experts. Resources\nlike widely-accepted classification criteria or field taxonomies are\nunavailable for a domain like artificial intelligence (AI), which spans\nemerging topics and technologies. We address these challenges by inferring a\nfunctional definition of AI research from existing expert labels, and then\nevaluating state-of-the-art chatbot models on the task of expert data\nannotation. Using the arXiv publication database as ground-truth, we experiment\nwith prompt engineering for GPT chatbot models to identify an alternative,\nautomated expert annotation pipeline that assigns AI labels with 94% accuracy.\nFor comparison, we fine-tune SPECTER, a transformer language model pre-trained\non scientific publications, that achieves 96% accuracy (only 2% higher than\nGPT) on classifying AI publications. Our results indicate that with effective\nprompt engineering, chatbots can be used as reliable data annotators even where\nsubject-area expertise is required. To evaluate the utility of\nchatbot-annotated datasets on downstream classification tasks, we train a new\nclassifier on GPT-labeled data and compare its performance to the arXiv-trained\nmodel. The classifier trained on GPT-labeled data outperforms the arXiv-trained\nmodel by nine percentage points, achieving 82% accuracy.", "published": "2024-03-14 04:43:02", "link": "http://arxiv.org/abs/2403.09097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Basque and Spanish Counter Narrative Generation: Data Creation and\n  Evaluation", "abstract": "Counter Narratives (CNs) are non-negative textual responses to Hate Speech\n(HS) aiming at defusing online hatred and mitigating its spreading across\nmedia. Despite the recent increase in HS content posted online, research on\nautomatic CN generation has been relatively scarce and predominantly focused on\nEnglish. In this paper, we present CONAN-EUS, a new Basque and Spanish dataset\nfor CN generation developed by means of Machine Translation (MT) and\nprofessional post-edition. Being a parallel corpus, also with respect to the\noriginal English CONAN, it allows to perform novel research on multilingual and\ncrosslingual automatic generation of CNs. Our experiments on CN generation with\nmT5, a multilingual encoder-decoder model, show that generation greatly\nbenefits from training on post-edited data, as opposed to relying on silver MT\ndata only. These results are confirmed by their correlation with a qualitative\nmanual evaluation, demonstrating that manually revised training data remains\ncrucial for the quality of the generated CNs. Furthermore, multilingual data\naugmentation improves results over monolingual settings for structurally\nsimilar languages such as English and Spanish, while being detrimental for\nBasque, a language isolate. Similar findings occur in zero-shot crosslingual\nevaluations, where model transfer (fine-tuning in English and generating in a\ndifferent target language) outperforms fine-tuning mT5 on machine translated\ndata for Spanish but not for Basque. This provides an interesting insight into\nthe asymmetry in the multilinguality of generative models, a challenging topic\nwhich is still open to research.", "published": "2024-03-14 08:12:47", "link": "http://arxiv.org/abs/2403.09159v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unveiling the Generalization Power of Fine-Tuned Large Language Models", "abstract": "While Large Language Models (LLMs) have demonstrated exceptional multitasking\nabilities, fine-tuning these models on downstream, domain-specific datasets is\noften necessary to yield superior performance on test sets compared to their\ncounterparts without fine-tuning. However, the comprehensive effects of\nfine-tuning on the LLMs' generalization ability are not fully understood. This\npaper delves into the differences between original, unmodified LLMs and their\nfine-tuned variants. Our primary investigation centers on whether fine-tuning\naffects the generalization ability intrinsic to LLMs. To elaborate on this, we\nconduct extensive experiments across five distinct language tasks on various\ndatasets. Our main findings reveal that models fine-tuned on generation and\nclassification tasks exhibit dissimilar behaviors in generalizing to different\ndomains and tasks. Intriguingly, we observe that integrating the in-context\nlearning strategy during fine-tuning on generation tasks can enhance the\nmodel's generalization ability. Through this systematic investigation, we aim\nto contribute valuable insights into the evolving landscape of fine-tuning\npractices for LLMs.", "published": "2024-03-14 08:18:59", "link": "http://arxiv.org/abs/2403.09162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dial-insight: Fine-tuning Large Language Models with High-Quality\n  Domain-Specific Data Preventing Capability Collapse", "abstract": "The efficacy of large language models (LLMs) is heavily dependent on the\nquality of the underlying data, particularly within specialized domains. A\ncommon challenge when fine-tuning LLMs for domain-specific applications is the\npotential degradation of the model's generalization capabilities. To address\nthese issues, we propose a two-stage approach for the construction of\nproduction prompts designed to yield high-quality data. This method involves\nthe generation of a diverse array of prompts that encompass a broad spectrum of\ntasks and exhibit a rich variety of expressions. Furthermore, we introduce a\ncost-effective, multi-dimensional quality assessment framework to ensure the\nintegrity of the generated labeling data. Utilizing a dataset comprised of\nservice provider and customer interactions from the real estate sector, we\ndemonstrate a positive correlation between data quality and model performance.\nNotably, our findings indicate that the domain-specific proficiency of general\nLLMs can be enhanced through fine-tuning with data produced via our proposed\nmethod, without compromising their overall generalization abilities, even when\nexclusively domain-specific data is employed for fine-tuning.", "published": "2024-03-14 08:27:32", "link": "http://arxiv.org/abs/2403.09167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic\n  Tasks", "abstract": "In this paper, we explore the capabilities of LLMs in capturing\nlexical-semantic knowledge from WordNet on the example of the LLaMA-2-7b model\nand test it on multiple lexical semantic tasks. As the outcome of our\nexperiments, we present TaxoLLaMA, the everything-in-one model, lightweight due\nto 4-bit quantization and LoRA. It achieves 11 SotA results, 4 top-2 results\nout of 16 tasks for the Taxonomy Enrichment, Hypernym Discovery, Taxonomy\nConstruction, and Lexical Entailment tasks. Moreover, it demonstrates very\nstrong zero-shot performance on Lexical Entailment and Taxonomy Construction\nwith no fine-tuning. We also explore its hidden multilingual and domain\nadaptation capabilities with a little tuning or few-shot learning. All\ndatasets, code, and model are available online at\nhttps://github.com/VityaVitalich/TaxoLLaMA", "published": "2024-03-14 09:21:25", "link": "http://arxiv.org/abs/2403.09207v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval augmented text-to-SQL generation for epidemiological question\n  answering using electronic health records", "abstract": "Electronic health records (EHR) and claims data are rich sources of\nreal-world data that reflect patient health status and healthcare utilization.\nQuerying these databases to answer epidemiological questions is challenging due\nto the intricacy of medical terminology and the need for complex SQL queries.\nHere, we introduce an end-to-end methodology that combines text-to-SQL\ngeneration with retrieval augmented generation (RAG) to answer epidemiological\nquestions using EHR and claims data. We show that our approach, which\nintegrates a medical coding step into the text-to-SQL process, significantly\nimproves the performance over simple prompting. Our findings indicate that\nalthough current language models are not yet sufficiently accurate for\nunsupervised use, RAG offers a promising direction for improving their\ncapabilities, as shown in a realistic industry setting.", "published": "2024-03-14 09:45:05", "link": "http://arxiv.org/abs/2403.09226v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Komodo: A Linguistic Expedition into Indonesia's Regional Languages", "abstract": "The recent breakthroughs in Large Language Models (LLMs) have mostly focused\non languages with easily available and sufficient resources, such as English.\nHowever, there remains a significant gap for languages that lack sufficient\nlinguistic resources in the public domain. Our work introduces Komodo-7B,\n7-billion-parameter Large Language Models designed to address this gap by\nseamlessly operating across Indonesian, English, and 11 regional languages in\nIndonesia. Komodo-7B is a family of LLMs that consist of Komodo-7B-Base and\nKomodo-7B-Instruct. Komodo-7B-Instruct stands out by achieving state-of-the-art\nperformance in various tasks and languages, outperforming the benchmarks set by\nOpenAI's GPT-3.5, Cohere's Aya-101, Llama-2-Chat-13B,\nMixtral-8x7B-Instruct-v0.1, Gemma-7B-it , and many more. This model not only\ndemonstrates superior performance in both language-specific and overall\nassessments but also highlights its capability to excel in linguistic\ndiversity. Our commitment to advancing language models extends beyond\nwell-resourced languages, aiming to bridge the gap for those with limited\nlinguistic assets. Additionally, Komodo-7B-Instruct's better cross-language\nunderstanding contributes to addressing educational disparities in Indonesia,\noffering direct translations from English to 11 regional languages, a\nsignificant improvement compared to existing language translation services.\nKomodo-7B represents a crucial step towards inclusivity and effectiveness in\nlanguage models, providing to the linguistic needs of diverse communities.", "published": "2024-03-14 13:12:21", "link": "http://arxiv.org/abs/2403.09362v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hyper-CL: Conditioning Sentence Representations with Hypernetworks", "abstract": "While the introduction of contrastive learning frameworks in sentence\nrepresentation learning has significantly contributed to advancements in the\nfield, it still remains unclear whether state-of-the-art sentence embeddings\ncan capture the fine-grained semantics of sentences, particularly when\nconditioned on specific perspectives. In this paper, we introduce Hyper-CL, an\nefficient methodology that integrates hypernetworks with contrastive learning\nto compute conditioned sentence representations. In our proposed approach, the\nhypernetwork is responsible for transforming pre-computed condition embeddings\ninto corresponding projection layers. This enables the same sentence embeddings\nto be projected differently according to various conditions. Evaluation on two\nrepresentative conditioning benchmarks, namely conditional semantic text\nsimilarity and knowledge graph completion, demonstrates that Hyper-CL is\neffective in flexibly conditioning sentence representations, showcasing its\ncomputational efficiency at the same time. We also provide a comprehensive\nanalysis of the inner workings of our approach, leading to a better\ninterpretation of its mechanisms.", "published": "2024-03-14 15:30:25", "link": "http://arxiv.org/abs/2403.09490v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MT-PATCHER: Selective and Extendable Knowledge Distillation from Large\n  Language Models for Machine Translation", "abstract": "Large Language Models (LLM) have demonstrated their strong ability in the\nfield of machine translation (MT), yet they suffer from high computational cost\nand latency. Therefore, transferring translation knowledge from giant LLMs to\nmedium-sized machine translation models is a promising research direction.\nHowever, traditional knowledge distillation methods do not take the capability\nof student and teacher models into consideration, therefore repeatedly teaching\nstudent models on the knowledge they have learned, and failing to extend to\nnovel contexts and knowledge. In this paper, we propose a framework called\nMT-Patcher, which transfers knowledge from LLMs to existing MT models in a\nselective, comprehensive and proactive manner. Considering the current\ntranslation ability of student MT models, we only identify and correct their\ntranslation errors, instead of distilling the whole translation from the\nteacher. Leveraging the strong language abilities of LLMs, we instruct LLM\nteachers to synthesize diverse contexts and anticipate more potential errors\nfor the student. Experiment results on translating both specific language\nphenomena and general MT benchmarks demonstrate that finetuning the student MT\nmodel on about 10% examples can achieve comparable results to the traditional\nknowledge distillation method, and synthesized potential errors and diverse\ncontexts further improve translation performances on unseen contexts and words.", "published": "2024-03-14 16:07:39", "link": "http://arxiv.org/abs/2403.09522v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference", "abstract": "Transformers have emerged as the backbone of large language models (LLMs).\nHowever, generation remains inefficient due to the need to store in memory a\ncache of key-value representations for past tokens, whose size scales linearly\nwith the input sequence length and batch size. As a solution, we propose\nDynamic Memory Compression (DMC), a method for online key-value cache\ncompression at inference time. Most importantly, the model learns to apply\ndifferent compression ratios in different heads and layers. We retrofit\npre-trained LLMs such as Llama 2 (7B, 13B and 70B) into DMC Transformers,\nachieving up to 7x throughput increase during auto-regressive inference on an\nNVIDIA H100 GPU. DMC is applied via continued pre-training on a negligible\npercentage of the original data without adding any extra parameters. DMC\npreserves the original downstream performance with up to 4x cache compression,\noutperforming up-trained grouped-query attention (GQA) and key-value eviction\npolicies (H$_2$O, TOVA). GQA and DMC can be even combined to obtain compounded\ngains. Hence, DMC can serve as a drop-in replacement for KV caching in existing\nLLMs to fit longer contexts and larger batches within any given memory budget.", "published": "2024-03-14 17:59:26", "link": "http://arxiv.org/abs/2403.09636v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Behavior of Machine Translation with Large Language Models under\n  Prompt Injection Attacks", "abstract": "Large Language Models (LLMs) are increasingly becoming the preferred\nfoundation platforms for many Natural Language Processing tasks such as Machine\nTranslation, owing to their quality often comparable to or better than\ntask-specific models, and the simplicity of specifying the task through natural\nlanguage instructions or in-context examples. Their generality, however, opens\nthem up to subversion by end users who may embed into their requests\ninstructions that cause the model to behave in unauthorized and possibly unsafe\nways. In this work we study these Prompt Injection Attacks (PIAs) on multiple\nfamilies of LLMs on a Machine Translation task, focusing on the effects of\nmodel size on the attack success rates. We introduce a new benchmark data set\nand we discover that on multiple language pairs and injected prompts written in\nEnglish, larger models under certain conditions may become more susceptible to\nsuccessful attacks, an instance of the Inverse Scaling phenomenon (McKenzie et\nal., 2023). To our knowledge, this is the first work to study non-trivial LLM\nscaling behaviour in a multi-lingual setting.", "published": "2024-03-14 19:39:10", "link": "http://arxiv.org/abs/2403.09832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FakeWatch: A Framework for Detecting Fake News to Ensure Credible\n  Elections", "abstract": "In today's technologically driven world, the rapid spread of fake news,\nparticularly during critical events like elections, poses a growing threat to\nthe integrity of information. To tackle this challenge head-on, we introduce\nFakeWatch, a comprehensive framework carefully designed to detect fake news.\nLeveraging a newly curated dataset of North American election-related news\narticles, we construct robust classification models. Our framework integrates a\nmodel hub comprising of both traditional machine learning (ML) techniques, and\nstate-of-the-art Language Models (LMs) to discern fake news effectively. Our\nobjective is to provide the research community with adaptable and precise\nclassification models adept at identifying fake news for the elections agenda.\nQuantitative evaluations of fake news classifiers on our dataset reveal that,\nwhile state-of-the-art LMs exhibit a slight edge over traditional ML models,\nclassical models remain competitive due to their balance of accuracy and\ncomputational efficiency. Additionally, qualitative analyses shed light on\npatterns within fake news articles. We provide our labeled data at\nhttps://huggingface.co/datasets/newsmediabias/fake_news_elections_labelled_data\nand model https://huggingface.co/newsmediabias/FakeWatch for reproducibility\nand further research.", "published": "2024-03-14 20:39:26", "link": "http://arxiv.org/abs/2403.09858v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geographically-Informed Language Identification", "abstract": "This paper develops an approach to language identification in which the set\nof languages considered by the model depends on the geographic origin of the\ntext in question. Given that many digital corpora can be geo-referenced at the\ncountry level, this paper formulates 16 region-specific models, each of which\ncontains the languages expected to appear in countries within that region.\nThese regional models also each include 31 widely-spoken international\nlanguages in order to ensure coverage of these linguae francae regardless of\nlocation. An upstream evaluation using traditional language identification\ntesting data shows an improvement in f-score ranging from 1.7 points (Southeast\nAsia) to as much as 10.4 points (North Africa). A downstream evaluation on\nsocial media data shows that this improved performance has a significant impact\non the language labels which are applied to large real-world corpora. The\nresult is a highly-accurate model that covers 916 languages at a sample size of\n50 characters, the performance improved by incorporating geographic information\ninto the model.", "published": "2024-03-14 21:55:17", "link": "http://arxiv.org/abs/2403.09892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semiparametric Token-Sequence Co-Supervision", "abstract": "In this work, we introduce a semiparametric token-sequence co-supervision\ntraining method. It trains a language model by simultaneously leveraging\nsupervision from the traditional next token prediction loss which is calculated\nover the parametric token embedding space and the next sequence prediction loss\nwhich is calculated over the nonparametric sequence embedding space. The\nnonparametric sequence embedding space is constructed by a separate language\nmodel tasked to condense an input text into a single representative embedding.\nOur experiments demonstrate that a model trained via both supervisions\nconsistently surpasses models trained via each supervision independently.\nAnalysis suggests that this co-supervision encourages a broader generalization\ncapability across the model. Especially, the robustness of parametric token\nspace which is established during the pretraining step tends to effectively\nenhance the stability of nonparametric sequence embedding space, a new space\nestablished by another language model.", "published": "2024-03-14 01:28:13", "link": "http://arxiv.org/abs/2403.09024v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The First to Know: How Token Distributions Reveal Hidden Knowledge in\n  Large Vision-Language Models?", "abstract": "Large vision-language models (LVLMs), designed to interpret and respond to\nhuman instructions, occasionally generate hallucinated or harmful content due\nto inappropriate instructions. This study uses linear probing to shed light on\nthe hidden knowledge at the output layers of LVLMs. We demonstrate that the\nlogit distributions of the first tokens contain sufficient information to\ndetermine whether to respond to the instructions, including recognizing\nunanswerable visual questions, defending against jailbreaking attacks, and\nidentifying deceptive questions. Such hidden knowledge is gradually lost in\nlogits of subsequent tokens during response generation. Then, we illustrate a\nsimple decoding strategy at the generation of the first token, effectively\nimproving the generated content. In experiments, we find a few interesting\ninsights: First, the CLIP model already contains a strong signal for solving\nthese tasks, which indicates potential bias in the existing datasets. Second,\nwe observe performance improvement by utilizing the first logit distributions\non three additional tasks, including indicating uncertainty in math solving,\nmitigating hallucination, and image classification. Last, with the same\ntraining data, simply finetuning LVLMs improves models' performance but is\nstill inferior to linear probing on these tasks.", "published": "2024-03-14 02:25:35", "link": "http://arxiv.org/abs/2403.09037v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Continued Pretrained LLM Approach for Automatic Medical Note\n  Generation", "abstract": "LLMs are revolutionizing NLP tasks. However, the use of the most advanced\nLLMs, such as GPT-4, is often prohibitively expensive for most specialized\nfields. We introduce HEAL, the first continuously trained 13B LLaMA2-based LLM\nthat is purpose-built for medical conversations and measured on automated\nscribing. Our results demonstrate that HEAL outperforms GPT-4 and PMC-LLaMA in\nPubMedQA, with an accuracy of 78.4\\%. It also achieves parity with GPT-4 in\ngenerating medical notes. Remarkably, HEAL surpasses GPT-4 and Med-PaLM 2 in\nidentifying more correct medical concepts and exceeds the performance of human\nscribes and other comparable models in correctness and completeness.", "published": "2024-03-14 02:55:37", "link": "http://arxiv.org/abs/2403.09057v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Meaningful Learning: Enhancing Abstract Reasoning in Large Language\n  Models via Generic Fact Guidance", "abstract": "Large language models (LLMs) have developed impressive performance and strong\nexplainability across various reasoning scenarios, marking a significant stride\ntowards mimicking human-like intelligence. Despite this, when tasked with\nseveral simple questions supported by a generic fact, LLMs often struggle to\nabstract and apply the generic fact to provide consistent and precise answers,\nrevealing a deficiency in abstract reasoning abilities. This has sparked a\nvigorous debate about whether LLMs are genuinely reasoning or merely\nmemorizing. In light of this, we design a preliminary study to quantify and\ndelve into the abstract reasoning abilities of existing LLMs. Our findings\nreveal a substantial discrepancy between their general reasoning and abstract\nreasoning performances. To relieve this problem, we tailor an abstract\nreasoning dataset (AbsR) together with a meaningful learning paradigm to teach\nLLMs how to leverage generic facts for reasoning purposes. The results show\nthat our approach not only boosts the general reasoning performance of LLMs but\nalso makes considerable strides towards their capacity for abstract reasoning,\nmoving beyond simple memorization or imitation to a more nuanced understanding\nand application of generic facts. The code is available at\nhttps://github.com/Waste-Wood/MeanLearn.", "published": "2024-03-14 04:06:13", "link": "http://arxiv.org/abs/2403.09085v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection", "abstract": "The prevalence of fake news across various online sources has had a\nsignificant influence on the public. Existing Chinese fake news detection\ndatasets are limited to news sourced solely from Weibo. However, fake news\noriginating from multiple sources exhibits diversity in various aspects,\nincluding its content and social context. Methods trained on purely one single\nnews source can hardly be applicable to real-world scenarios. Our pilot\nexperiment demonstrates that the F1 score of the state-of-the-art method that\nlearns from a large Chinese fake news detection dataset, Weibo-21, drops\nsignificantly from 0.943 to 0.470 when the test data is changed to multi-source\nnews data, failing to identify more than one-third of the multi-source fake\nnews. To address this limitation, we constructed the first multi-source\nbenchmark dataset for Chinese fake news detection, termed MCFEND, which is\ncomposed of news we collected from diverse sources such as social platforms,\nmessaging apps, and traditional online news outlets. Notably, such news has\nbeen fact-checked by 14 authoritative fact-checking agencies worldwide. In\naddition, various existing Chinese fake news detection methods are thoroughly\nevaluated on our proposed dataset in cross-source, multi-source, and unseen\nsource ways. MCFEND, as a benchmark dataset, aims to advance Chinese fake news\ndetection approaches in real-world scenarios.", "published": "2024-03-14 04:32:13", "link": "http://arxiv.org/abs/2403.09092v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ProSwitch: Knowledge-Guided Instruction Tuning to Switch Between\n  Professional and Non-Professional Responses", "abstract": "Large Language Models (LLMs) have demonstrated efficacy in various linguistic\napplications, including question answering and controlled text generation.\nHowever, studies into their ability to switch between opposite styles of\nresponses in professional domains remain underexplored. This study introduces a\nnovel approach, named ProSwitch, which enables a language model to switch\nbetween professional and non-professional answers, by tuning and evaluating\nthrough the guidance of domain and style knowledge. ProSwitch unfolds in three\nphases: LLM-augmented preparation to collect domain knowledge and QA pairs,\ninstruction tuning to optimize LLMs with multiple levels of knowledge, and\ncomprehensive evaluation to assess both style discrimination and\nreference-based quality of the generated text. Comparative analysis of\nProSwitch against general and specialized LLMs reveals that our approach\noutperforms baselines in switching between professional and non-professional\nresponses.", "published": "2024-03-14 06:49:16", "link": "http://arxiv.org/abs/2403.09131v5", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Evaluating LLMs for Gender Disparities in Notable Persons", "abstract": "This study examines the use of Large Language Models (LLMs) for retrieving\nfactual information, addressing concerns over their propensity to produce\nfactually incorrect \"hallucinated\" responses or to altogether decline to even\nanswer prompt at all. Specifically, it investigates the presence of\ngender-based biases in LLMs' responses to factual inquiries. This paper takes a\nmulti-pronged approach to evaluating GPT models by evaluating fairness across\nmultiple dimensions of recall, hallucinations and declinations. Our findings\nreveal discernible gender disparities in the responses generated by GPT-3.5.\nWhile advancements in GPT-4 have led to improvements in performance, they have\nnot fully eradicated these gender disparities, notably in instances where\nresponses are declined. The study further explores the origins of these\ndisparities by examining the influence of gender associations in prompts and\nthe homogeneity in the responses.", "published": "2024-03-14 07:58:27", "link": "http://arxiv.org/abs/2403.09148v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Caveat Lector: Large Language Models in Legal Practice", "abstract": "The current fascination with large language models, or LLMs, derives from the\nfact that many users lack the expertise to evaluate the quality of the\ngenerated text. LLMs may therefore appear more capable than they actually are.\nThe dangerous combination of fluency and superficial plausibility leads to the\ntemptation to trust the generated text and creates the risk of overreliance.\nWho would not trust perfect legalese? Relying recent findings in both technical\nand legal scholarship, this Article counterbalances the overly optimistic\npredictions as to the role of LLMs in legal practice. Integrating LLMs into\nlegal workstreams without a better comprehension of their limitations, will\ncreate inefficiencies if not outright risks. Notwithstanding their\nunprecedented ability to generate text, LLMs do not understand text. Without\nthe ability to understand meaning, LLMs will remain unable to use language, to\nacquire knowledge and to perform complex reasoning tasks. Trained to model\nlanguage on the basis of stochastic word predictions, LLMs cannot distinguish\nfact from fiction. Their knowledge of the law is limited to word strings\nmemorized in their parameters. It is also incomplete and largely incorrect.\nLLMs operate at the level of word distributions, not at the level of verified\nfacts. The resulting propensity to hallucinate, to produce statements that are\nincorrect but appear helpful and relevant, is alarming in high-risk areas like\nlegal services. At present, lawyers should beware of relying on text generated\nby LLMs.", "published": "2024-03-14 08:19:41", "link": "http://arxiv.org/abs/2403.09163v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine\n  Knowledge", "abstract": "No previous work has studied the performance of Large Language Models (LLMs)\nin the context of Traditional Chinese Medicine (TCM), an essential and distinct\nbranch of medical knowledge with a rich history. To bridge this gap, we present\na TCM question dataset named TCM-QA, which comprises three question types:\nsingle choice, multiple choice, and true or false, to examine the LLM's\ncapacity for knowledge recall and comprehensive reasoning within the TCM\ndomain. In our study, we evaluate two settings of the LLM, zero-shot and\nfew-shot settings, while concurrently discussing the differences between\nEnglish and Chinese prompts. Our results indicate that ChatGPT performs best in\ntrue or false questions, achieving the highest precision of 0.688 while scoring\nthe lowest precision is 0.241 in multiple-choice questions. Furthermore, we\nobserved that Chinese prompts outperformed English prompts in our evaluations.\nAdditionally, we assess the quality of explanations generated by ChatGPT and\ntheir potential contribution to TCM knowledge comprehension. This paper offers\nvaluable insights into the applicability of LLMs in specialized domains and\npaves the way for future research in leveraging these powerful models to\nadvance TCM.", "published": "2024-03-14 08:20:40", "link": "http://arxiv.org/abs/2403.09164v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "To Label or Not to Label: Hybrid Active Learning for Neural Machine\n  Translation", "abstract": "Active learning (AL) techniques reduce labeling costs for training neural\nmachine translation (NMT) models by selecting smaller representative subsets\nfrom unlabeled data for annotation. Diversity sampling techniques select\nheterogeneous instances, while uncertainty sampling methods select instances\nwith the highest model uncertainty. Both approaches have limitations -\ndiversity methods may extract varied but trivial examples, while uncertainty\nsampling can yield repetitive, uninformative instances. To bridge this gap, we\npropose Hybrid Uncertainty and Diversity Sampling (HUDS), an AL strategy for\ndomain adaptation in NMT that combines uncertainty and diversity for sentence\nselection. HUDS computes uncertainty scores for unlabeled sentences and\nsubsequently stratifies them. It then clusters sentence embeddings within each\nstratum and computes diversity scores by distance to the centroid. A weighted\nhybrid score that combines uncertainty and diversity is then used to select the\ntop instances for annotation in each AL iteration. Experiments on multi-domain\nGerman-English and French-English datasets demonstrate the better performance\nof HUDS over other strong AL baselines. We analyze the sentence selection with\nHUDS and show that it prioritizes diverse instances having high model\nuncertainty for annotation in early AL iterations.", "published": "2024-03-14 10:33:28", "link": "http://arxiv.org/abs/2403.09259v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Anatomical Structure-Guided Medical Vision-Language Pre-training", "abstract": "Learning medical visual representations through vision-language pre-training\nhas reached remarkable progress. Despite the promising performance, it still\nfaces challenges, i.e., local alignment lacks interpretability and clinical\nrelevance, and the insufficient internal and external representation learning\nof image-report pairs. To address these issues, we propose an Anatomical\nStructure-Guided (ASG) framework. Specifically, we parse raw reports into\ntriplets <anatomical region, finding, existence>, and fully utilize each\nelement as supervision to enhance representation learning. For anatomical\nregion, we design an automatic anatomical region-sentence alignment paradigm in\ncollaboration with radiologists, considering them as the minimum semantic units\nto explore fine-grained local alignment. For finding and existence, we regard\nthem as image tags, applying an image-tag recognition decoder to associate\nimage features with their respective tags within each sample and constructing\nsoft labels for contrastive learning to improve the semantic association of\ndifferent image-report pairs. We evaluate the proposed ASG framework on two\ndownstream tasks, including five public benchmarks. Experimental results\ndemonstrate that our method outperforms the state-of-the-art methods.", "published": "2024-03-14 11:29:47", "link": "http://arxiv.org/abs/2403.09294v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Rectifying Demonstration Shortcut in In-Context Learning", "abstract": "Large language models (LLMs) are able to solve various tasks with only a few\ndemonstrations utilizing their in-context learning (ICL) abilities. However,\nLLMs often rely on their pre-trained semantic priors of demonstrations rather\nthan on the input-label relationships to proceed with ICL prediction. In this\nwork, we term this phenomenon as the 'Demonstration Shortcut'. While previous\nworks have primarily focused on improving ICL prediction results for predefined\ntasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLM\nto effectively learn new input-label relationships from demonstrations. To\nachieve this, we introduce In-Context Calibration, a demonstration-aware\ncalibration method. We evaluate the effectiveness of the proposed method in two\nsettings: (1) the Original ICL Task using the standard label space and (2) the\nTask Learning setting, where the label space is replaced with semantically\nunrelated tokens. In both settings, In-Context Calibration demonstrates\nsubstantial improvements, with results generalized across three LLM families\n(OPT, GPT, and Llama2) under various configurations.", "published": "2024-03-14 15:30:14", "link": "http://arxiv.org/abs/2403.09488v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Less is More: High-value Data Selection for Visual Instruction Tuning", "abstract": "Visual instruction tuning is the key to building large vision language\nmodels~(LVLMs), which can greatly improve the task generalization and solving\ncapabilities by learning a mixture of instruction data from diverse visual\ntasks. Previous work mostly collects multiple existing visual instruction\ndatasets via heuristic ways for training (even more than a million\ninstructions), which may introduce data redundancy and enlarge the training\ncost. To investigate this issue, we conduct a series of empirical studies,\nwhich reveal a significant redundancy within the visual instruction datasets,\nand show that greatly reducing the amount of instructions from several tasks\neven do not affect the performance. Based on the findings, we propose a\nhigh-value data selection approach TIVE, to eliminate redundancy within the\nvisual instruction data and reduce the training cost. In TIVE, we first\nestimate the instance influence score on its corresponding task, and the task\ndifficulty score, based on the gradient-based influence functions. Then, we\nleverage the two kinds of scores to determine the task proportion within the\nselected visual instruction subset, and select high-value instances for each\ntask, respectively. Experiments on various LVLMs show that our approach using\nonly about 15% data can achieve comparable average performance to the full-data\nfine-tuned model across eight benchmarks, even surpassing it on four of the\nbenchmarks. Our code and data will be publicly released.", "published": "2024-03-14 16:47:25", "link": "http://arxiv.org/abs/2403.09559v4", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Large Language Models and Causal Inference in Collaboration: A Survey", "abstract": "Causal inference has shown potential in enhancing the predictive accuracy,\nfairness, robustness, and explainability of Natural Language Processing (NLP)\nmodels by capturing causal relationships among variables. The emergence of\ngenerative Large Language Models (LLMs) has significantly impacted various NLP\ndomains, particularly through their advanced reasoning capabilities. This\nsurvey focuses on evaluating and improving LLMs from a causal view in the\nfollowing areas: understanding and improving the LLMs' reasoning capacity,\naddressing fairness and safety issues in LLMs, complementing LLMs with\nexplanations, and handling multimodality. Meanwhile, LLMs' strong reasoning\ncapacities can in turn contribute to the field of causal inference by aiding\ncausal relationship discovery and causal effect estimations. This review\nexplores the interplay between causal inference frameworks and LLMs from both\nperspectives, emphasizing their collective potential to further the development\nof more advanced and equitable artificial intelligence systems.", "published": "2024-03-14 17:47:20", "link": "http://arxiv.org/abs/2403.09606v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reawakening knowledge: Anticipatory recovery from catastrophic\n  interference via structured training", "abstract": "We explore the training dynamics of neural networks in a structured non-IID\nsetting where documents are presented cyclically in a fixed, repeated sequence.\nTypically, networks suffer from catastrophic interference when training on a\nsequence of documents; however, we discover a curious and remarkable property\nof LLMs finetuned sequentially in this setting: they exhibit anticipatory\nbehavior, recovering from the forgetting on documents before encountering them\nagain. This behavior occurs even though the documents are never presented in\ncontext together. The behavior emerges and becomes more robust as the\narchitecture scales up its number of parameters. Through comprehensive\nexperiments and visualizations, we demonstrate a new mechanism by which\nover-parametrized neural networks can recover from catastrophic interference\nand uncover new insights into training over-parameterized networks in\ncyclically structured environments.", "published": "2024-03-14 17:51:54", "link": "http://arxiv.org/abs/2403.09613v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Re-Search for The Truth: Multi-round Retrieval-augmented Large Language\n  Models are Strong Fake News Detectors", "abstract": "The proliferation of fake news has had far-reaching implications on politics,\nthe economy, and society at large. While Fake news detection methods have been\nemployed to mitigate this issue, they primarily depend on two essential\nelements: the quality and relevance of the evidence, and the effectiveness of\nthe verdict prediction mechanism. Traditional methods, which often source\ninformation from static repositories like Wikipedia, are limited by outdated or\nincomplete data, particularly for emerging or rare claims. Large Language\nModels (LLMs), known for their remarkable reasoning and generative\ncapabilities, introduce a new frontier for fake news detection. However, like\ntraditional methods, LLM-based solutions also grapple with the limitations of\nstale and long-tail knowledge. Additionally, retrieval-enhanced LLMs frequently\nstruggle with issues such as low-quality evidence retrieval and context length\nconstraints. To address these challenges, we introduce a novel,\nretrieval-augmented LLMs framework--the first of its kind to automatically and\nstrategically extract key evidence from web sources for claim verification.\nEmploying a multi-round retrieval strategy, our framework ensures the\nacquisition of sufficient, relevant evidence, thereby enhancing performance.\nComprehensive experiments across three real-world datasets validate the\nframework's superiority over existing methods. Importantly, our model not only\ndelivers accurate verdicts but also offers human-readable explanations to\nimprove result interpretability.", "published": "2024-03-14 00:35:39", "link": "http://arxiv.org/abs/2403.09747v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Meta-Cognitive Analysis: Evaluating Declarative and Procedural Knowledge\n  in Datasets and Large Language Models", "abstract": "Declarative knowledge and procedural knowledge are two key parts in\nmeta-cognitive theory, and these two hold significant importance in\npre-training and inference of LLMs. However, a comprehensive analysis comparing\nthese two types of knowledge is lacking, primarily due to challenges in\ndefinition, probing and quantitative assessment. In this paper, we explore from\na new perspective by providing ground-truth knowledge for LLMs and evaluating\nthe effective score. Through extensive experiments with widely-used datasets\nand models, we get conclusions: (1) In most tasks, benefits from declarative\nknowledge are greater than those from procedural knowledge. (2) Profits of\nprocedural knowledge are larger than declarative knowledge only in reasoning\ntasks with simple logic. (3) As pre-training progresses and size increases,\nmodel ability to utilize both kinds of knowledge significantly improves, but in\ndifferent speed. We do detailed analysis for the findings and this can provide\nprimary guidance for evaluation and enhancement of large language models.", "published": "2024-03-14 05:34:35", "link": "http://arxiv.org/abs/2403.09750v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Images are Achilles' Heel of Alignment: Exploiting Visual\n  Vulnerabilities for Jailbreaking Multimodal Large Language Models", "abstract": "In this paper, we study the harmlessness alignment problem of multimodal\nlarge language models (MLLMs). We conduct a systematic empirical analysis of\nthe harmlessness performance of representative MLLMs and reveal that the image\ninput poses the alignment vulnerability of MLLMs. Inspired by this, we propose\na novel jailbreak method named HADES, which hides and amplifies the harmfulness\nof the malicious intent within the text input, using meticulously crafted\nimages. Experimental results show that HADES can effectively jailbreak existing\nMLLMs, which achieves an average Attack Success Rate (ASR) of 90.26% for\nLLaVA-1.5 and 71.60% for Gemini Pro Vision. Our code and data are available at\nhttps://github.com/RUCAIBox/HADES.", "published": "2024-03-14 18:24:55", "link": "http://arxiv.org/abs/2403.09792v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Self-Consistency Boosts Calibration for Math Reasoning", "abstract": "Calibration, which establishes the correlation between accuracy and model\nconfidence, is important for LLM development. We design three off-the-shelf\ncalibration methods based on self-consistency (Wang et al., 2022) for math\nreasoning tasks. Evaluation on two popular benchmarks (GSM8K and MathQA) using\nstrong open-source LLMs (Mistral and LLaMA2), our methods better bridge model\nconfidence and accuracy than existing methods based on p(True) (Kadavath et\nal., 2022) or logit (Kadavath et al., 2022).", "published": "2024-03-14 20:17:10", "link": "http://arxiv.org/abs/2403.09849v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sabi\u00e1-2: A New Generation of Portuguese Large Language Models", "abstract": "We introduce Sabi\\'a-2, a family of large language models trained on\nPortuguese texts. The models are evaluated on a diverse range of exams,\nincluding entry-level tests for Brazilian universities, professional\ncertification exams, and graduate-level exams for various disciplines such as\naccounting, economics, engineering, law and medicine. Our results reveal that\nour best model so far, Sabi\\'a-2 Medium, matches or surpasses GPT-4's\nperformance in 23 out of 64 exams and outperforms GPT-3.5 in 58 out of 64\nexams. Notably, specialization has a significant impact on a model's\nperformance without the need to increase its size, allowing us to offer\nSabi\\'a-2 Medium at a price per token that is 10 times cheaper than GPT-4.\nFinally, we identified that math and coding are key abilities that need\nimprovement.", "published": "2024-03-14 21:44:48", "link": "http://arxiv.org/abs/2403.09887v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Recurrent Drafter for Fast Speculative Decoding in Large Language Models", "abstract": "We present Recurrent Drafter (ReDrafter), an advanced speculative decoding\napproach that achieves state-of-the-art speedup for large language models\n(LLMs) inference. The performance gains are driven by three key aspects: (1)\nleveraging a recurrent neural network (RNN) as the draft model conditioning on\nLLM's hidden states, (2) applying a dynamic tree attention algorithm over beam\nsearch results to eliminate duplicated prefixes in candidate sequences, and (3)\ntraining through knowledge distillation from the LLM. ReDrafter accelerates\nVicuna inference in MT-Bench by up to 2.8x with a PyTorch implementation on\nNvidia H100 GPUs. To demonstrate its practicality in real environments, we also\nvalidated its effectiveness for on-device applications by implementing the\napproach in MLX and benchmarking performance on Metal GPUs in Apple Silicon\nchips, achieving up to 2.3x speedup.", "published": "2024-03-14 23:40:56", "link": "http://arxiv.org/abs/2403.09919v5", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language\n  Models to Coding Preferences", "abstract": "Evaluating the alignment of large language models (LLMs) with user-defined\ncoding preferences is a challenging endeavour that requires a deep assessment\nof LLMs' outputs. Existing methods and benchmarks rely primarily on automated\nmetrics and static analysis tools, which often fail to capture the nuances of\nuser instructions and LLM outputs. To address this gap, we propose using the\nLLM-as-a-Judge methodology to evaluate the alignment of LLMs with coding\npreferences. Based on this approach, we present CodeUltraFeedback, a\ncomprehensive dataset designed to facilitate the evaluation and improvement of\nLLM alignment. CodeUltraFeedback consists of 10,000 coding instructions, each\nannotated with four responses generated from a diverse pool of 14 LLMs. These\nresponses are ranked based on five distinct coding preferences using GPT-3.5 as\na judge, providing both numerical scores and detailed textual feedback. Our\nanalysis of CodeUltraFeedback reveals that responses from GPT-3.5 and GPT-4 are\ngenerally preferred over those from open-weight LLMs, highlighting significant\ndifferences in alignment between closed and open-weight models. In turn, we\nexplore the usage of CodeUltraFeedback as feedback data to fine-tune and align\nCodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement\nlearning from AI feedback (RLAIF) with direct preference optimization (DPO).\nThe resulting aligned CodeLlama-7B-Instruct model outperforms larger LLMs in\nterms of alignment with coding preferences and shows improved functional\ncorrectness on the HumanEval+ benchmark compared to the original instruct\nmodel. Therefore, our contributions bridge the gap in preference tuning of LLMs\nfor code and set the stage for further advancements in model alignment and\nRLAIF in automated software engineering.", "published": "2024-03-14 01:51:35", "link": "http://arxiv.org/abs/2403.09032v3", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient\n  Generative Inference", "abstract": "Transformers have emerged as the underpinning architecture for Large Language\nModels (LLMs). In generative language models, the inference process involves\ntwo primary phases: prompt processing and token generation. Token generation,\nwhich constitutes the majority of the computational workload, primarily entails\nvector-matrix multiplications and interactions with the Key-Value (KV) Cache.\nThis phase is constrained by memory bandwidth due to the overhead of\ntransferring weights and KV cache values from the memory system to the\ncomputing units. This memory bottleneck becomes particularly pronounced in\napplications that require long-context and extensive text generation, both of\nwhich are increasingly crucial for LLMs.\n  This paper introduces \"Keyformer\", an innovative inference-time approach, to\nmitigate the challenges associated with KV cache size and memory bandwidth\nutilization. Keyformer leverages the observation that approximately 90% of the\nattention weight in generative inference focuses on a specific subset of\ntokens, referred to as \"key\" tokens. Keyformer retains only the key tokens in\nthe KV cache by identifying these crucial tokens using a novel score function.\nThis approach effectively reduces both the KV cache size and memory bandwidth\nusage without compromising model accuracy. We evaluate Keyformer's performance\nacross three foundational models: GPT-J, Cerebras-GPT, and MPT, which employ\nvarious positional embedding algorithms. Our assessment encompasses a variety\nof tasks, with a particular emphasis on summarization and conversation tasks\ninvolving extended contexts. Keyformer's reduction of KV cache reduces\ninference latency by 2.1x and improves token generation throughput by 2.4x,\nwhile preserving the model's accuracy.", "published": "2024-03-14 02:42:42", "link": "http://arxiv.org/abs/2403.09054v2", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.CL", "68U35", "I.2.7; C.0"], "primary_category": "cs.LG"}
{"title": "UniCode: Learning a Unified Codebook for Multimodal Large Language\n  Models", "abstract": "In this paper, we propose \\textbf{UniCode}, a novel approach within the\ndomain of multimodal large language models (MLLMs) that learns a unified\ncodebook to efficiently tokenize visual, text, and potentially other types of\nsignals. This innovation addresses a critical limitation in existing MLLMs:\ntheir reliance on a text-only codebook, which restricts MLLM's ability to\ngenerate images and texts in a multimodal context. Towards this end, we propose\na language-driven iterative training paradigm, coupled with an in-context\npre-training task we term ``image decompression'', enabling our model to\ninterpret compressed visual data and generate high-quality images.The unified\ncodebook empowers our model to extend visual instruction tuning to\nnon-linguistic generation tasks. Moreover, UniCode is adaptable to diverse\nstacked quantization approaches in order to compress visual signals into a more\ncompact token representation. Despite using significantly fewer parameters and\nless data during training, Unicode demonstrates promising capabilities in\nvisual reconstruction and generation. It also achieves performances comparable\nto leading MLLMs across a spectrum of VQA benchmarks.", "published": "2024-03-14 03:29:58", "link": "http://arxiv.org/abs/2403.09072v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based\n  on Meta Learning", "abstract": "Large-scale pretraining followed by task-specific finetuning has achieved\ngreat success in various NLP tasks. Since finetuning all parameters of large\npretrained models poses substantial computational and memory challenges,\nseveral efficient finetuning methods have been developed. Among them, low-rank\nadaptation (LoRA), which finetunes low-rank incremental update matrices on top\nof frozen pretrained weights, has proven particularly effective. Nonetheless,\nLoRA's uniform rank assignment across all layers, along with its reliance on an\nexhaustive search to find the best rank, leads to high computation costs and\nsuboptimal finetuning performance. To address these limitations, we introduce\nAutoLoRA, a meta learning based framework for automatically identifying the\noptimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a\nlow-rank update matrix with a selection variable, which determines whether the\nrank-1 matrix should be discarded. A meta learning based method is developed to\nlearn these selection variables. The optimal rank is determined by thresholding\nthe values of these variables. Our comprehensive experiments on natural\nlanguage understanding, generation, and sequence labeling demonstrate the\neffectiveness of AutoLoRA.", "published": "2024-03-14 05:29:35", "link": "http://arxiv.org/abs/2403.09113v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"Like a Nesting Doll\": Analyzing Recursion Analogies Generated by CS\n  Students using Large Language Models", "abstract": "Grasping complex computing concepts often poses a challenge for students who\nstruggle to anchor these new ideas to familiar experiences and understandings.\nTo help with this, a good analogy can bridge the gap between unfamiliar\nconcepts and familiar ones, providing an engaging way to aid understanding.\nHowever, creating effective educational analogies is difficult even for\nexperienced instructors. We investigate to what extent large language models\n(LLMs), specifically ChatGPT, can provide access to personally relevant\nanalogies on demand. Focusing on recursion, a challenging threshold concept, we\nconducted an investigation analyzing the analogies generated by more than 350\nfirst-year computing students. They were provided with a code snippet and\ntasked to generate their own recursion-based analogies using ChatGPT,\noptionally including personally relevant topics in their prompts. We observed a\ngreat deal of diversity in the analogies produced with student-prescribed\ntopics, in contrast to the otherwise generic analogies, highlighting the value\nof student creativity when working with LLMs. Not only did students enjoy the\nactivity and report an improved understanding of recursion, but they described\nmore easily remembering analogies that were personally and culturally relevant.", "published": "2024-03-14 14:01:26", "link": "http://arxiv.org/abs/2403.09409v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision", "abstract": "Current AI alignment methodologies rely on human-provided demonstrations or\njudgments, and the learned capabilities of AI systems would be upper-bounded by\nhuman capabilities as a result. This raises a challenging research question:\nHow can we keep improving the systems when their capabilities have surpassed\nthe levels of humans? This paper answers this question in the context of\ntackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from\nhuman annotations on easier tasks (e.g., level 1-3 MATH problems), which we\nterm as easy-to-hard generalization. Our key insight is that an evaluator\n(reward model) trained on supervisions for easier tasks can be effectively used\nfor scoring candidate solutions of harder tasks and hence facilitating\neasy-to-hard generalization over different levels of tasks. Based on this\ninsight, we propose a novel approach to scalable alignment, which firstly\ntrains the (process-supervised) reward models on easy problems (e.g., level\n1-3), and then uses them to evaluate the performance of policy models on hard\nproblems. We show that such easy-to-hard generalization from evaluators can\nenable easy-to-hard generalizations in generators either through re-ranking or\nreinforcement learning (RL). Notably, our process-supervised 7b RL model and\n34b model (reranking@1024) achieves an accuracy of 34.0% and 52.5% on MATH500,\nrespectively, despite only using human supervision on easy problems. Our\napproach suggests a promising path toward AI systems that advance beyond the\nfrontier of human supervision.", "published": "2024-03-14 15:12:38", "link": "http://arxiv.org/abs/2403.09472v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Laying the Foundation First? Investigating the Generalization from\n  Atomic Skills to Complex Reasoning Tasks", "abstract": "Current language models have demonstrated their capability to develop basic\nreasoning, but struggle in more complicated reasoning tasks that require a\ncombination of atomic skills, such as math word problem requiring skills like\narithmetic and unit conversion. Previous methods either do not improve the\ninherent atomic skills of models or not attempt to generalize the atomic skills\nto complex reasoning tasks. In this paper, we first propose a probing framework\nto investigate whether the atomic skill can spontaneously generalize to complex\nreasoning tasks. Then, we introduce a hierarchical curriculum learning training\nstrategy to achieve better skill generalization. In our experiments, we find\nthat atomic skills can not spontaneously generalize to compositional tasks. By\nleveraging hierarchical curriculum learning, we successfully induce\ngeneralization, significantly improve the performance of open-source LMs on\ncomplex reasoning tasks. Promisingly, the skill generalization exhibit\neffective in cross-dataset and cross-domain scenarios. Complex reasoning can\nalso help enhance atomic skills. Our findings offer valuable guidance for\ndesigning better training strategies for complex reasoning tasks.", "published": "2024-03-14 15:20:54", "link": "http://arxiv.org/abs/2403.09479v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward\n  Fake News", "abstract": "In the digital era, the rapid propagation of fake news and rumors via social\nnetworks brings notable societal challenges and impacts public opinion\nregulation. Traditional fake news modeling typically forecasts the general\npopularity trends of different groups or numerically represents opinions shift.\nHowever, these methods often oversimplify real-world complexities and overlook\nthe rich semantic information of news text. The advent of large language models\n(LLMs) provides the possibility of modeling subtle dynamics of opinion.\nConsequently, in this work, we introduce a Fake news Propagation Simulation\nframework (FPS) based on LLM, which studies the trends and control of fake news\npropagation in detail. Specifically, each agent in the simulation represents an\nindividual with a distinct personality. They are equipped with both short-term\nand long-term memory, as well as a reflective mechanism to mimic human-like\nthinking. Every day, they engage in random opinion exchanges, reflect on their\nthinking, and update their opinions. Our simulation results uncover patterns in\nfake news propagation related to topic relevance, and individual traits,\naligning with real-world observations. Additionally, we evaluate various\nintervention strategies and demonstrate that early and appropriately frequent\ninterventions strike a balance between governance cost and effectiveness,\noffering valuable insights for practical applications. Our study underscores\nthe significant utility and potential of LLMs in combating fake news.", "published": "2024-03-14 15:40:13", "link": "http://arxiv.org/abs/2403.09498v2", "categories": ["cs.SI", "cs.AI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Leveraging Prototypical Representations for Mitigating Social Bias\n  without Demographic Information", "abstract": "Mitigating social biases typically requires identifying the social groups\nassociated with each data sample. In this paper, we present DAFair, a novel\napproach to address social bias in language models. Unlike traditional methods\nthat rely on explicit demographic labels, our approach does not require any\nsuch information. Instead, we leverage predefined prototypical demographic\ntexts and incorporate a regularization term during the fine-tuning process to\nmitigate bias in the model's representations. Our empirical results across two\ntasks and two models demonstrate the effectiveness of our method compared to\nprevious approaches that do not rely on labeled data. Moreover, with limited\ndemographic-annotated data, our approach outperforms common debiasing\napproaches.", "published": "2024-03-14 15:58:36", "link": "http://arxiv.org/abs/2403.09516v3", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision\n  Understanding", "abstract": "The evolution of text to visual components facilitates people's daily lives,\nsuch as generating image, videos from text and identifying the desired elements\nwithin the images. Computer vision models involving the multimodal abilities in\nthe previous days are focused on image detection, classification based on\nwell-defined objects. Large language models (LLMs) introduces the\ntransformation from nature language to visual objects, which present the visual\nlayout for text contexts. OpenAI GPT-4 has emerged as the pinnacle in LLMs,\nwhile the computer vision (CV) domain boasts a plethora of state-of-the-art\n(SOTA) models and algorithms to convert 2D images to their 3D representations.\nHowever, the mismatching between the algorithms with the problem could lead to\nundesired results. In response to this challenge, we propose an unified\nVisionGPT-3D framework to consolidate the state-of-the-art vision models,\nthereby facilitating the development of vision-oriented AI. VisionGPT-3D\nprovides a versatile multimodal framework building upon the strengths of\nmultimodal foundation models. It seamlessly integrates various SOTA vision\nmodels and brings the automation in the selection of SOTA vision models,\nidentifies the suitable 3D mesh creation algorithms corresponding to 2D depth\nmaps analysis, generates optimal results based on diverse multimodal inputs\nsuch as text prompts.\n  Keywords: VisionGPT-3D, 3D vision understanding, Multimodal agent", "published": "2024-03-14 16:13:00", "link": "http://arxiv.org/abs/2403.09530v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Logits of API-Protected LLMs Leak Proprietary Information", "abstract": "Large language model (LLM) providers often hide the architectural details and\nparameters of their proprietary models by restricting public access to a\nlimited API. In this work we show that, with only a conservative assumption\nabout the model architecture, it is possible to learn a surprisingly large\namount of non-public information about an API-protected LLM from a relatively\nsmall number of API queries (e.g., costing under $1000 USD for OpenAI's\ngpt-3.5-turbo). Our findings are centered on one key observation: most modern\nLLMs suffer from a softmax bottleneck, which restricts the model outputs to a\nlinear subspace of the full output space. We exploit this fact to unlock\nseveral capabilities, including (but not limited to) obtaining cheap\nfull-vocabulary outputs, auditing for specific types of model updates,\nidentifying the source LLM given a single full LLM output, and even efficiently\ndiscovering the LLM's hidden size. Our empirical investigations show the\neffectiveness of our methods, which allow us to estimate the embedding size of\nOpenAI's gpt-3.5-turbo to be about 4096. Lastly, we discuss ways that LLM\nproviders can guard against these attacks, as well as how these capabilities\ncan be viewed as a feature (rather than a bug) by allowing for greater\ntransparency and accountability.", "published": "2024-03-14 16:27:49", "link": "http://arxiv.org/abs/2403.09539v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training", "abstract": "In this work, we discuss building performant Multimodal Large Language Models\n(MLLMs). In particular, we study the importance of various architecture\ncomponents and data choices. Through careful and comprehensive ablations of the\nimage encoder, the vision language connector, and various pre-training data\nchoices, we identified several crucial design lessons. For example, we\ndemonstrate that for large-scale multimodal pre-training using a careful mix of\nimage-caption, interleaved image-text, and text-only data is crucial for\nachieving state-of-the-art (SOTA) few-shot results across multiple benchmarks,\ncompared to other published pre-training results. Further, we show that the\nimage encoder together with image resolution and the image token count has\nsubstantial impact, while the vision-language connector design is of\ncomparatively negligible importance. By scaling up the presented recipe, we\nbuild MM1, a family of multimodal models up to 30B parameters, including both\ndense models and mixture-of-experts (MoE) variants, that are SOTA in\npre-training metrics and achieve competitive performance after supervised\nfine-tuning on a range of established multimodal benchmarks. Thanks to\nlarge-scale pre-training, MM1 enjoys appealing properties such as enhanced\nin-context learning, and multi-image reasoning, enabling few-shot\nchain-of-thought prompting.", "published": "2024-03-14 17:51:32", "link": "http://arxiv.org/abs/2403.09611v4", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Quiet-STaR: Language Models Can Teach Themselves to Think Before\n  Speaking", "abstract": "When writing and talking, people sometimes pause to think. Although\nreasoning-focused works have often framed reasoning as a method of answering\nquestions or completing agentic tasks, reasoning is implicit in almost all\nwritten text. For example, this applies to the steps not stated between the\nlines of a proof or to the theory of mind underlying a conversation. In the\nSelf-Taught Reasoner (STaR, Zelikman et al. 2022), useful thinking is learned\nby inferring rationales from few-shot examples in question-answering and\nlearning from those that lead to a correct answer. This is a highly constrained\nsetting -- ideally, a language model could instead learn to infer unstated\nrationales in arbitrary text. We present Quiet-STaR, a generalization of STaR\nin which LMs learn to generate rationales at each token to explain future text,\nimproving their predictions. We address key challenges, including 1) the\ncomputational cost of generating continuations, 2) the fact that the LM does\nnot initially know how to generate or use internal thoughts, and 3) the need to\npredict beyond individual next tokens. To resolve these, we propose a tokenwise\nparallel sampling algorithm, using learnable tokens indicating a thought's\nstart and end, and an extended teacher-forcing technique. Encouragingly,\ngenerated rationales disproportionately help model difficult-to-predict tokens\nand improve the LM's ability to directly answer difficult questions. In\nparticular, after continued pretraining of an LM on a corpus of internet text\nwith Quiet-STaR, we find zero-shot improvements on GSM8K\n(5.9%$\\rightarrow$10.9%) and CommonsenseQA (36.3%$\\rightarrow$47.2%) and\nobserve a perplexity improvement of difficult tokens in natural text.\nCrucially, these improvements require no fine-tuning on these tasks. Quiet-STaR\nmarks a step towards LMs that can learn to reason in a more general and\nscalable way.", "published": "2024-03-14 17:58:16", "link": "http://arxiv.org/abs/2403.09629v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "3D-VLA: A 3D Vision-Language-Action Generative World Model", "abstract": "Recent vision-language-action (VLA) models rely on 2D inputs, lacking\nintegration with the broader realm of the 3D physical world. Furthermore, they\nperform action prediction by learning a direct mapping from perception to\naction, neglecting the vast dynamics of the world and the relations between\nactions and dynamics. In contrast, human beings are endowed with world models\nthat depict imagination about future scenarios to plan actions accordingly. To\nthis end, we propose 3D-VLA by introducing a new family of embodied foundation\nmodels that seamlessly link 3D perception, reasoning, and action through a\ngenerative world model. Specifically, 3D-VLA is built on top of a 3D-based\nlarge language model (LLM), and a set of interaction tokens is introduced to\nengage with the embodied environment. Furthermore, to inject generation\nabilities into the model, we train a series of embodied diffusion models and\nalign them into the LLM for predicting the goal images and point clouds. To\ntrain our 3D-VLA, we curate a large-scale 3D embodied instruction dataset by\nextracting vast 3D-related information from existing robotics datasets. Our\nexperiments on held-in datasets demonstrate that 3D-VLA significantly improves\nthe reasoning, multimodal generation, and planning capabilities in embodied\nenvironments, showcasing its potential in real-world applications.", "published": "2024-03-14 17:58:41", "link": "http://arxiv.org/abs/2403.09631v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Transformers Get Stable: An End-to-End Signal Propagation Theory for\n  Language Models", "abstract": "In spite of their huge success, transformer models remain difficult to scale\nin depth. In this work, we develop a unified signal propagation theory and\nprovide formulae that govern the moments of the forward and backward signal\nthrough the transformer model. Our framework can be used to understand and\nmitigate vanishing/exploding gradients, rank collapse, and instability\nassociated with high attention scores. We also propose DeepScaleLM, an\ninitialization and scaling scheme that conserves unit output/gradient moments\nthroughout the model, enabling the training of very deep models with 1000\nlayers. We find that transformer models could be much deeper - our deep models\nwith fewer parameters outperform shallow models in Language Modeling, Speech\nTranslation, and Image Classification, across encoder-only, decoder-only and\nencoder-decoder variants, for both Pre-LN and Post-LN transformers, for\nmultiple datasets and model sizes. These improvements also translate into\nimproved performance on downstream Question Answering tasks and improved\nrobustness for Image Classification.", "published": "2024-03-14 17:59:14", "link": "http://arxiv.org/abs/2403.09635v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "I.2.7; I.2.10"], "primary_category": "cs.CL"}
{"title": "What Was Your Prompt? A Remote Keylogging Attack on AI Assistants", "abstract": "AI assistants are becoming an integral part of society, used for asking\nadvice or help in personal and confidential issues. In this paper, we unveil a\nnovel side-channel that can be used to read encrypted responses from AI\nAssistants over the web: the token-length side-channel. We found that many\nvendors, including OpenAI and Microsoft, have this side-channel.\n  However, inferring the content of a response from a token-length sequence\nalone proves challenging. This is because tokens are akin to words, and\nresponses can be several sentences long leading to millions of grammatically\ncorrect sentences. In this paper, we show how this can be overcome by (1)\nutilizing the power of a large language model (LLM) to translate these\nsequences, (2) providing the LLM with inter-sentence context to narrow the\nsearch space and (3) performing a known-plaintext attack by fine-tuning the\nmodel on the target model's writing style.\n  Using these methods, we were able to accurately reconstruct 29\\% of an AI\nassistant's responses and successfully infer the topic from 55\\% of them. To\ndemonstrate the threat, we performed the attack on OpenAI's ChatGPT-4 and\nMicrosoft's Copilot on both browser and API traffic.", "published": "2024-03-14 09:38:12", "link": "http://arxiv.org/abs/2403.09751v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Helpful or Harmful? Exploring the Efficacy of Large Language Models for\n  Online Grooming Prevention", "abstract": "Powerful generative Large Language Models (LLMs) are becoming popular tools\namongst the general public as question-answering systems, and are being\nutilised by vulnerable groups such as children. With children increasingly\ninteracting with these tools, it is imperative for researchers to scrutinise\nthe safety of LLMs, especially for applications that could lead to serious\noutcomes, such as online child safety queries. In this paper, the efficacy of\nLLMs for online grooming prevention is explored both for identifying and\navoiding grooming through advice generation, and the impact of prompt design on\nmodel performance is investigated by varying the provided context and prompt\nspecificity. In results reflecting over 6,000 LLM interactions, we find that no\nmodels were clearly appropriate for online grooming prevention, with an\nobserved lack of consistency in behaviours, and potential for harmful answer\ngeneration, especially from open-source models. We outline where and how models\nfall short, providing suggestions for improvement, and identify prompt designs\nthat heavily altered model performance in troubling ways, with findings that\ncan be used to inform best practice usage guides.", "published": "2024-03-14 18:27:43", "link": "http://arxiv.org/abs/2403.09795v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Fisher Mask Nodes for Language Model Merging", "abstract": "Fine-tuning pre-trained models provides significant advantages in downstream\nperformance. The ubiquitous nature of pre-trained models such as BERT and its\nderivatives in natural language processing has also led to a proliferation of\ntask-specific fine-tuned models. As these models typically only perform one\ntask well, additional training or ensembling is required in multi-task\nscenarios. The growing field of model merging provides a solution, dealing with\nthe challenge of combining multiple task-specific models into a single\nmulti-task model. In this study, we introduce a novel model merging method for\nTransformers, combining insights from previous work in Fisher-weighted\naveraging and the use of Fisher information in model pruning. Utilizing the\nFisher information of mask nodes within the Transformer architecture, we devise\na computationally efficient weighted-averaging scheme. Our method exhibits a\nregular and significant performance increase across various models in the BERT\nfamily, outperforming full-scale Fisher-weighted averaging in a fraction of the\ncomputational cost, with baseline performance improvements of up to +6.5 and a\nspeedup between 57.4x and 321.7x across models. Our results prove the potential\nof our method in current multi-task learning environments and suggest its\nscalability and adaptability to new model architectures and learning scenarios.", "published": "2024-03-14 21:52:26", "link": "http://arxiv.org/abs/2403.09891v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MoPE: Mixture of Prompt Experts for Parameter-Efficient and Scalable\n  Multimodal Fusion", "abstract": "Despite the demonstrated parameter efficiency of prompt-based multimodal\nfusion methods, their limited adaptivity and expressiveness often result in\nsuboptimal performance compared to other tuning approaches. In this paper, we\nintroduce the Mixture of Prompt Experts (MoPE), the first technique designed to\novercome these limitations by decomposing standard prompts to capture\ninstance-level features adaptively. Building on this decomposition, MoPE\nenhances prompt fusion's expressiveness by leveraging multimodal pairing priors\nto route the most effective prompt for each instance dynamically. Compared to\nvanilla prompting, our MoPE-based fusion method exhibits greater\nexpressiveness, scaling more effectively with the training data and the overall\nnumber of trainable parameters. We also investigate regularization terms for\nexpert routing, which lead to emergent expert specialization with enhanced\nadaptiveness and interpretablity. Extensive experiments across six multimodal\ndatasets spanning four modalities demonstrate state-of-the-art performance for\nprompt fusion, matching or even surpassing the performance of fine-tuning while\nrequiring only 0.8% of the trainable parameters. Project homepage:\nhttps://github.com/songrise/MoPE", "published": "2024-03-14 17:47:10", "link": "http://arxiv.org/abs/2403.10568v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Methods for Matching English Language Addresses", "abstract": "Addresses occupy a niche location within the landscape of textual data, due\nto the positional importance carried by every word, and the geographical scope\nit refers to. The task of matching addresses happens everyday and is present in\nvarious fields like mail redirection, entity resolution, etc. Our work defines,\nand formalizes a framework to generate matching and mismatching pairs of\naddresses in the English language, and use it to evaluate various methods to\nautomatically perform address matching. These methods vary widely from distance\nbased approaches to deep learning models. By studying the Precision, Recall and\nAccuracy metrics of these approaches, we obtain an understanding of the best\nsuited method for this setting of the address matching task.", "published": "2024-03-14 10:39:14", "link": "http://arxiv.org/abs/2403.12092v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Incorporating Graph Attention Mechanism into Geometric Problem Solving\n  Based on Deep Reinforcement Learning", "abstract": "In the context of online education, designing an automatic solver for\ngeometric problems has been considered a crucial step towards general math\nArtificial Intelligence (AI), empowered by natural language understanding and\ntraditional logical inference. In most instances, problems are addressed by\nadding auxiliary components such as lines or points. However, adding auxiliary\ncomponents automatically is challenging due to the complexity in selecting\nsuitable auxiliary components especially when pivotal decisions have to be\nmade. The state-of-the-art performance has been achieved by exhausting all\npossible strategies from the category library to identify the one with the\nmaximum likelihood. However, an extensive strategy search have to be applied to\ntrade accuracy for ef-ficiency. To add auxiliary components automatically and\nefficiently, we present deep reinforcement learning framework based on the\nlanguage model, such as BERT. We firstly apply the graph attention mechanism to\nreduce the strategy searching space, called AttnStrategy, which only focus on\nthe conclusion-related components. Meanwhile, a novel algorithm, named\nAutomatically Adding Auxiliary Components using Reinforcement Learning\nframework (A3C-RL), is proposed by forcing an agent to select top strategies,\nwhich incorporates the AttnStrategy and BERT as the memory components. Results\nfrom extensive experiments show that the proposed A3C-RL algorithm can\nsubstantially enhance the average precision by 32.7% compared to the\ntraditional MCTS. In addition, the A3C-RL algorithm outperforms humans on the\ngeometric questions from the annual University Entrance Mathematical\nExamination of China.", "published": "2024-03-14 11:00:09", "link": "http://arxiv.org/abs/2403.14690v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "More than words: Advancements and challenges in speech recognition for\n  singing", "abstract": "This paper addresses the challenges and advancements in speech recognition\nfor singing, a domain distinctly different from standard speech recognition.\nSinging encompasses unique challenges, including extensive pitch variations,\ndiverse vocal styles, and background music interference. We explore key areas\nsuch as phoneme recognition, language identification in songs, keyword\nspotting, and full lyrics transcription. I will describe some of my own\nexperiences when performing research on these tasks just as they were starting\nto gain traction, but will also show how recent developments in deep learning\nand large-scale datasets have propelled progress in this field. My goal is to\nilluminate the complexities of applying speech recognition to singing, evaluate\ncurrent capabilities, and outline future research directions.", "published": "2024-03-14 11:37:02", "link": "http://arxiv.org/abs/2403.09298v1", "categories": ["cs.SD", "cs.CL", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Emotional Intelligence Through Artificial Intelligence : NLP and Deep\n  Learning in the Analysis of Healthcare Texts", "abstract": "This manuscript presents a methodical examination of the utilization of\nArtificial Intelligence in the assessment of emotions in texts related to\nhealthcare, with a particular focus on the incorporation of Natural Language\nProcessing and deep learning technologies. We scrutinize numerous research\nstudies that employ AI to augment sentiment analysis, categorize emotions, and\nforecast patient outcomes based on textual information derived from clinical\nnarratives, patient feedback on medications, and online health discussions. The\nreview demonstrates noteworthy progress in the precision of algorithms used for\nsentiment classification, the prognostic capabilities of AI models for\nneurodegenerative diseases, and the creation of AI-powered systems that offer\nsupport in clinical decision-making. Remarkably, the utilization of AI\napplications has exhibited an enhancement in personalized therapy plans by\nintegrating patient sentiment and contributing to the early identification of\nmental health disorders. There persist challenges, which encompass ensuring the\nethical application of AI, safeguarding patient confidentiality, and addressing\npotential biases in algorithmic procedures. Nevertheless, the potential of AI\nto revolutionize healthcare practices is unmistakable, offering a future where\nhealthcare is not only more knowledgeable and efficient but also more\nempathetic and centered around the needs of patients. This investigation\nunderscores the transformative influence of AI on healthcare, delivering a\ncomprehensive comprehension of its role in examining emotional content in\nhealthcare texts and highlighting the trajectory towards a more compassionate\napproach to patient care. The findings advocate for a harmonious synergy\nbetween AI's analytical capabilities and the human aspects of healthcare.", "published": "2024-03-14 15:58:13", "link": "http://arxiv.org/abs/2403.09762v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Physics-Informed Neural Network for Volumetric Sound field\n  Reconstruction of Speech Signals", "abstract": "Recent developments in acoustic signal processing have seen the integration\nof deep learning methodologies, alongside the continued prominence of classical\nwave expansion-based approaches, particularly in sound field reconstruction.\nPhysics-Informed Neural Networks (PINNs) have emerged as a novel framework,\nbridging the gap between data-driven and model-based techniques for addressing\nphysical phenomena governed by partial differential equations. This paper\nintroduces a PINN-based approach for the recovery of arbitrary volumetric\nacoustic fields. The network incorporates the wave equation to impose a\nregularization on signal reconstruction in the time domain. This methodology\nenables the network to learn the underlying physics of sound propagation and\nallows for the complete characterization of the sound field based on a limited\nset of observations. The proposed method's efficacy is validated through\nexperiments involving speech signals in a real-world environment, considering\nvarying numbers of available measurements. Moreover, a comparative analysis is\nundertaken against state-of-the-art frequency-domain and time-domain\nreconstruction methods from existing literature, highlighting the increased\naccuracy across the various measurement configurations.", "published": "2024-03-14 16:10:17", "link": "http://arxiv.org/abs/2403.09524v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "WavCraft: Audio Editing and Generation with Large Language Models", "abstract": "We introduce WavCraft, a collective system that leverages large language\nmodels (LLMs) to connect diverse task-specific models for audio content\ncreation and editing. Specifically, WavCraft describes the content of raw audio\nmaterials in natural language and prompts the LLM conditioned on audio\ndescriptions and user requests. WavCraft leverages the in-context learning\nability of the LLM to decomposes users' instructions into several tasks and\ntackle each task collaboratively with the particular module. Through task\ndecomposition along with a set of task-specific models, WavCraft follows the\ninput instruction to create or edit audio content with more details and\nrationales, facilitating user control. In addition, WavCraft is able to\ncooperate with users via dialogue interaction and even produce the audio\ncontent without explicit user commands. Experiments demonstrate that WavCraft\nyields a better performance than existing methods, especially when adjusting\nthe local regions of audio clips. Moreover, WavCraft can follow complex\ninstructions to edit and create audio content on the top of input recordings,\nfacilitating audio producers in a broader range of applications. Our\nimplementation and demos are available at this\nhttps://github.com/JinhuaLiang/WavCraft.", "published": "2024-03-14 16:10:34", "link": "http://arxiv.org/abs/2403.09527v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Practical Guide to Spectrogram Analysis for Audio Signal Processing", "abstract": "The paper summarizes spectrogram and gives practical application of\nspectrogram in signal processing. For analysis, finger-snapping is recorded\nwith a sampling rate of 441000 Hz and 96000 Hz. The effects of the number of\nsegments on the Power Spectral Density (PSD) and spectrogram are analyzed and\nvisualized.", "published": "2024-03-14 12:10:47", "link": "http://arxiv.org/abs/2403.09321v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Neural-SRP method for positional sound source localization", "abstract": "Steered Response Power (SRP) is a widely used method for the task of sound\nsource localization using microphone arrays, showing satisfactory localization\nperformance on many practical scenarios. However, its performance is diminished\nunder highly reverberant environments. Although Deep Neural Networks (DNNs)\nhave been previously proposed to overcome this limitation, most are trained for\na specific number of microphones with fixed spatial coordinates. This restricts\ntheir practical application on scenarios frequently observed in wireless\nacoustic sensor networks, where each application has an ad-hoc microphone\ntopology. We propose Neural-SRP, a DNN which combines the flexibility of SRP\nwith the performance gains of DNNs. We train our network using simulated data\nand transfer learning, and evaluate our approach on recorded and simulated\ndata. Results verify that Neural-SRP's localization performance significantly\noutperforms the baselines.", "published": "2024-03-14 14:53:54", "link": "http://arxiv.org/abs/2403.09455v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audiosockets: A Python socket package for Real-Time Audio Processing", "abstract": "There are many packages in Python which allow one to perform real-time\nprocessing on audio data. Unfortunately, due to the synchronous nature of the\nlanguage, there lacks a framework which allows for distributed parallel\nprocessing of the data without requiring a large programming overhead and in\nwhich the data acquisition is not blocked by subsequent processing operations.\nThis work improves on packages used for audio data collection with a\nlight-weight backend and a simple interface that allows for distributed\nprocessing through a socket-based structure. This is intended for real-time\naudio machine learning and data processing in Python with a quick deployment of\nmultiple parallel operations on the same data, allowing users to spend less\ntime debugging and more time developing.", "published": "2024-03-14 18:19:29", "link": "http://arxiv.org/abs/2403.09789v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An AI-Driven Approach to Wind Turbine Bearing Fault Diagnosis from\n  Acoustic Signals", "abstract": "This study aimed to develop a deep learning model for the classification of\nbearing faults in wind turbine generators from acoustic signals. A\nconvolutional LSTM model was successfully constructed and trained by using\naudio data from five predefined fault types for both training and validation.\nTo create the dataset, raw audio signal data was collected and processed in\nframes to capture time and frequency domain information. The model exhibited\noutstanding accuracy on training samples and demonstrated excellent\ngeneralization ability during validation, indicating its proficiency of\ngeneralization capability. On the test samples, the model achieved remarkable\nclassification performance, with an overall accuracy exceeding 99.5%, and a\nfalse positive rate of less than 1% for normal status. The findings of this\nstudy provide essential support for the diagnosis and maintenance of bearing\nfaults in wind turbine generators, with the potential to enhance the\nreliability and efficiency of wind power generation.", "published": "2024-03-14 01:46:30", "link": "http://arxiv.org/abs/2403.09030v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "M&M: Multimodal-Multitask Model Integrating Audiovisual Cues in\n  Cognitive Load Assessment", "abstract": "This paper introduces the M&M model, a novel multimodal-multitask learning\nframework, applied to the AVCAffe dataset for cognitive load assessment (CLA).\nM&M uniquely integrates audiovisual cues through a dual-pathway architecture,\nfeaturing specialized streams for audio and video inputs. A key innovation lies\nin its cross-modality multihead attention mechanism, fusing the different\nmodalities for synchronized multitasking. Another notable feature is the\nmodel's three specialized branches, each tailored to a specific cognitive load\nlabel, enabling nuanced, task-specific analysis. While it shows modest\nperformance compared to the AVCAffe's single-task baseline, M\\&M demonstrates a\npromising framework for integrated multimodal processing. This work paves the\nway for future enhancements in multimodal-multitask learning systems,\nemphasizing the fusion of diverse data types for complex task handling.", "published": "2024-03-14 14:49:40", "link": "http://arxiv.org/abs/2403.09451v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with\n  Unsupervised Audio Mixtures", "abstract": "Masked Autoencoders (MAEs) learn rich low-level representations from\nunlabeled data but require substantial labeled data to effectively adapt to\ndownstream tasks. Conversely, Instance Discrimination (ID) emphasizes\nhigh-level semantics, offering a potential solution to alleviate annotation\nrequirements in MAEs. Although combining these two approaches can address\ndownstream tasks with limited labeled data, naively integrating ID into MAEs\nleads to extended training times and high computational costs. To address this\nchallenge, we introduce uaMix-MAE, an efficient ID tuning strategy that\nleverages unsupervised audio mixtures. Utilizing contrastive tuning, uaMix-MAE\naligns the representations of pretrained MAEs, thereby facilitating effective\nadaptation to task-specific semantics. To optimize the model with small amounts\nof unlabeled data, we propose an audio mixing technique that manipulates audio\nsamples in both input and virtual label spaces. Experiments in low/few-shot\nsettings demonstrate that \\modelname achieves 4-6% accuracy improvements over\nvarious benchmarks when tuned with limited unlabeled data, such as\nAudioSet-20K. Code is available at https://github.com/PLAN-Lab/uamix-MAE", "published": "2024-03-14 17:13:37", "link": "http://arxiv.org/abs/2403.09579v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Mixture of Mixups for Multi-label Classification of Rare Anuran Sounds", "abstract": "Multi-label imbalanced classification poses a significant challenge in\nmachine learning, particularly evident in bioacoustics where animal sounds\noften co-occur, and certain sounds are much less frequent than others. This\npaper focuses on the specific case of classifying anuran species sounds using\nthe dataset AnuraSet, that contains both class imbalance and multi-label\nexamples. To address these challenges, we introduce Mixture of Mixups (Mix2), a\nframework that leverages mixing regularization methods Mixup, Manifold Mixup,\nand MultiMix. Experimental results show that these methods, individually, may\nlead to suboptimal results; however, when applied randomly, with one selected\nat each training iteration, they prove effective in addressing the mentioned\nchallenges, particularly for rare classes with few occurrences. Further\nanalysis reveals that Mix2 is also proficient in classifying sounds across\nvarious levels of class co-occurrences.", "published": "2024-03-14 17:39:14", "link": "http://arxiv.org/abs/2403.09598v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SpokeN-100: A Cross-Lingual Benchmarking Dataset for The Classification\n  of Spoken Numbers in Different Languages", "abstract": "Benchmarking plays a pivotal role in assessing and enhancing the performance\nof compact deep learning models designed for execution on resource-constrained\ndevices, such as microcontrollers. Our study introduces a novel, entirely\nartificially generated benchmarking dataset tailored for speech recognition,\nrepresenting a core challenge in the field of tiny deep learning. SpokeN-100\nconsists of spoken numbers from 0 to 99 spoken by 32 different speakers in four\ndifferent languages, namely English, Mandarin, German and French, resulting in\n12,800 audio samples. We determine auditory features and use UMAP (Uniform\nManifold Approximation and Projection for Dimension Reduction) as a\ndimensionality reduction method to show the diversity and richness of the\ndataset. To highlight the use case of the dataset, we introduce two benchmark\ntasks: given an audio sample, classify (i) the used language and/or (ii) the\nspoken number. We optimized state-of-the-art deep neural networks and performed\nan evolutionary neural architecture search to find tiny architectures optimized\nfor the 32-bit ARM Cortex-M4 nRF52840 microcontroller. Our results represent\nthe first benchmark data achieved for SpokeN-100.", "published": "2024-03-14 12:07:37", "link": "http://arxiv.org/abs/2403.09753v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LM2D: Lyrics- and Music-Driven Dance Synthesis", "abstract": "Dance typically involves professional choreography with complex movements\nthat follow a musical rhythm and can also be influenced by lyrical content. The\nintegration of lyrics in addition to the auditory dimension, enriches the\nfoundational tone and makes motion generation more amenable to its semantic\nmeanings. However, existing dance synthesis methods tend to model motions only\nconditioned on audio signals. In this work, we make two contributions to bridge\nthis gap. First, we propose LM2D, a novel probabilistic architecture that\nincorporates a multimodal diffusion model with consistency distillation,\ndesigned to create dance conditioned on both music and lyrics in one diffusion\ngeneration step. Second, we introduce the first 3D dance-motion dataset that\nencompasses both music and lyrics, obtained with pose estimation technologies.\nWe evaluate our model against music-only baseline models with objective metrics\nand human evaluations, including dancers and choreographers. The results\ndemonstrate LM2D is able to produce realistic and diverse dance matching both\nlyrics and music. A video summary can be accessed at:\nhttps://youtu.be/4XCgvYookvA.", "published": "2024-03-14 13:59:04", "link": "http://arxiv.org/abs/2403.09407v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast\n  Conformer", "abstract": "Humans are adept at leveraging visual cues from lip movements for recognizing\nspeech in adverse listening conditions. Audio-Visual Speech Recognition (AVSR)\nmodels follow similar approach to achieve robust speech recognition in noisy\nconditions. In this work, we present a multilingual AVSR model incorporating\nseveral enhancements to improve performance and audio noise robustness.\nNotably, we adapt the recently proposed Fast Conformer model to process both\naudio and visual modalities using a novel hybrid CTC/RNN-T architecture. We\nincrease the amount of audio-visual training data for six distinct languages,\ngenerating automatic transcriptions of unlabelled multilingual datasets\n(VoxCeleb2 and AVSpeech). Our proposed model achieves new state-of-the-art\nperformance on the LRS3 dataset, reaching WER of 0.8%. On the recently\nintroduced MuAViC benchmark, our model yields an absolute average-WER reduction\nof 11.9% in comparison to the original baseline. Finally, we demonstrate the\nability of the proposed model to perform audio-only, visual-only, and\naudio-visual speech recognition at test time.", "published": "2024-03-14 01:16:32", "link": "http://arxiv.org/abs/2405.12983v1", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "PTSD-MDNN : Fusion tardive de r\u00e9seaux de neurones profonds multimodaux\n  pour la d\u00e9tection du trouble de stress post-traumatique", "abstract": "In order to provide a more objective and quicker way to diagnose\npost-traumatic stress disorder (PTSD), we present PTSD-MDNN which merges two\nunimodal convolutional neural networks and which gives low detection error\nrate. By taking only videos and audios as inputs, the model could be used in\nthe configuration of teleconsultation sessions, in the optimization of patient\njourneys or for human-robot interaction.", "published": "2024-03-14 14:57:16", "link": "http://arxiv.org/abs/2403.10565v1", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.SD", "eess.IV", "q-bio.NC"], "primary_category": "eess.AS"}
