{"title": "Fusing Audio, Textual and Visual Features for Sentiment Analysis of News\n  Videos", "abstract": "This paper presents a novel approach to perform sentiment analysis of news\nvideos, based on the fusion of audio, textual and visual clues extracted from\ntheir contents. The proposed approach aims at contributing to the\nsemiodiscoursive study regarding the construction of the ethos (identity) of\nthis media universe, which has become a central part of the modern-day lives of\nmillions of people. To achieve this goal, we apply state-of-the-art\ncomputational methods for (1) automatic emotion recognition from facial\nexpressions, (2) extraction of modulations in the participants' speeches and\n(3) sentiment analysis from the closed caption associated to the videos of\ninterest. More specifically, we compute features, such as, visual intensities\nof recognized emotions, field sizes of participants, voicing probability, sound\nloudness, speech fundamental frequencies and the sentiment scores (polarities)\nfrom text sentences in the closed caption. Experimental results with a dataset\ncontaining 520 annotated news videos from three Brazilian and one American\npopular TV newscasts show that our approach achieves an accuracy of up to 84%\nin the sentiments (tension levels) classification task, thus demonstrating its\nhigh potential to be used by media analysts in several applications,\nespecially, in the journalistic domain.", "published": "2016-04-09 22:00:27", "link": "http://arxiv.org/abs/1604.02612v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word embeddings and recurrent neural networks based on Long-Short Term\n  Memory nodes in supervised biomedical word sense disambiguation", "abstract": "Word sense disambiguation helps identifying the proper sense of ambiguous\nwords in text. With large terminologies such as the UMLS Metathesaurus\nambiguities appear and highly effective disambiguation methods are required.\nSupervised learning algorithm methods are used as one of the approaches to\nperform disambiguation. Features extracted from the context of an ambiguous\nword are used to identify the proper sense of such a word. The type of features\nhave an impact on machine learning methods, thus affect disambiguation\nperformance. In this work, we have evaluated several types of features derived\nfrom the context of the ambiguous word and we have explored as well more global\nfeatures derived from MEDLINE using word embeddings. Results show that word\nembeddings improve the performance of more traditional features and allow as\nwell using recurrent neural network classifiers based on Long-Short Term Memory\n(LSTM) nodes. The combination of unigrams and word embeddings with an SVM sets\na new state of the art performance with a macro accuracy of 95.97 in the MSH\nWSD data set.", "published": "2016-04-09 01:14:05", "link": "http://arxiv.org/abs/1604.02506v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Compact Recurrent Neural Networks", "abstract": "Recurrent neural networks (RNNs), including long short-term memory (LSTM)\nRNNs, have produced state-of-the-art results on a variety of speech recognition\ntasks. However, these models are often too large in size for deployment on\nmobile devices with memory and latency constraints. In this work, we study\nmechanisms for learning compact RNNs and LSTMs via low-rank factorizations and\nparameter sharing schemes. Our goal is to investigate redundancies in recurrent\narchitectures where compression can be admitted without losing performance. A\nhybrid strategy of using structured matrices in the bottom layers and shared\nlow-rank factors on the top layers is found to be particularly effective,\nreducing the parameters of a standard LSTM by 75%, at a small cost of 0.3%\nincrease in WER, on a 2,000-hr English Voice Search task.", "published": "2016-04-09 19:09:22", "link": "http://arxiv.org/abs/1604.02594v1", "categories": ["cs.LG", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
