{"title": "Using reinforcement learning to learn how to play text-based games", "abstract": "The ability to learn optimal control policies in systems where action space\nis defined by sentences in natural language would allow many interesting\nreal-world applications such as automatic optimisation of dialogue systems.\nText-based games with multiple endings and rewards are a promising platform for\nthis task, since their feedback allows us to employ reinforcement learning\ntechniques to jointly learn text representations and control policies. We\npresent a general text game playing agent, testing its generalisation and\ntransfer learning performance and showing its ability to play multiple games at\nonce. We also present pyfiction, an open-source library for universal access to\ndifferent text games that could, together with our agent that implements its\ninterface, serve as a baseline for future research.", "published": "2018-01-06 10:38:51", "link": "http://arxiv.org/abs/1801.01999v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explorations in an English Poetry Corpus: A Neurocognitive Poetics\n  Perspective", "abstract": "This paper describes a corpus of about 3000 English literary texts with about\n250 million words extracted from the Gutenberg project that span a range of\ngenres from both fiction and non-fiction written by more than 130 authors\n(e.g., Darwin, Dickens, Shakespeare). Quantitative Narrative Analysis (QNA) is\nused to explore a cleaned subcorpus, the Gutenberg English Poetry Corpus (GEPC)\nwhich comprises over 100 poetic texts with around 2 million words from about 50\nauthors (e.g., Keats, Joyce, Wordsworth). Some exemplary QNA studies show\nauthor similarities based on latent semantic analysis, significant topics for\neach author or various text-analytic metrics for George Eliot's poem 'How Lisa\nLoved the King' and James Joyce's 'Chamber Music', concerning e.g. lexical\ndiversity or sentiment analysis. The GEPC is particularly suited for research\nin Digital Humanities, Natural Language Processing or Neurocognitive Poetics,\ne.g. as training and test corpus, or for stimulus development and control.", "published": "2018-01-06 17:28:21", "link": "http://arxiv.org/abs/1801.02054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis of Wikipedia-based Corpora for Question Answering", "abstract": "This paper gives comprehensive analyses of corpora based on Wikipedia for\nseveral tasks in question answering. Four recent corpora are collected,WikiQA,\nSelQA, SQuAD, and InfoQA, and first analyzed intrinsically by contextual\nsimilarities, question types, and answer categories. These corpora are then\nanalyzed extrinsically by three question answering tasks, answer retrieval,\nselection, and triggering. An indexing-based method for the creation of a\nsilver-standard dataset for answer retrieval using the entire Wikipedia is also\npresented. Our analysis shows the uniqueness of these corpora and suggests a\nbetter use of them for statistical question answering learning.", "published": "2018-01-06 19:28:15", "link": "http://arxiv.org/abs/1801.02073v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Text Correction", "abstract": "Videos, images, and sentences are mediums that can express the same\nsemantics. One can imagine a picture by reading a sentence or can describe a\nscene with some words. However, even small changes in a sentence can cause a\nsignificant semantic inconsistency with the corresponding video/image. For\nexample, by changing the verb of a sentence, the meaning may drastically\nchange. There have been many efforts to encode a video/sentence and decode it\nas a sentence/video. In this research, we study a new scenario in which both\nthe sentence and the video are given, but the sentence is inaccurate. A\nsemantic inconsistency between the sentence and the video or between the words\nof a sentence can result in an inaccurate description. This paper introduces a\nnew problem, called Visual Text Correction (VTC), i.e., finding and replacing\nan inaccurate word in the textual description of a video. We propose a deep\nnetwork that can simultaneously detect an inaccuracy in a sentence, and fix it\nby replacing the inaccurate word(s). Our method leverages the semantic\ninterdependence of videos and words, as well as the short-term and long-term\nrelations of the words in a sentence. In our formulation, part of a visual\nfeature vector for every single word is dynamically selected through a gating\nprocess. Furthermore, to train and evaluate our model, we propose an approach\nto automatically construct a large dataset for VTC problem. Our experiments and\nperformance analysis demonstrates that the proposed method provides very good\nresults and also highlights the general challenges in solving the VTC problem.\nTo the best of our knowledge, this work is the first of its kind for the Visual\nText Correction task.", "published": "2018-01-06 04:58:38", "link": "http://arxiv.org/abs/1801.01967v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
