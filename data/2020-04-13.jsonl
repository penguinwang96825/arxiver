{"title": "Integrated Eojeol Embedding for Erroneous Sentence Classification in\n  Korean Chatbots", "abstract": "This paper attempts to analyze the Korean sentence classification system for\na chatbot. Sentence classification is the task of classifying an input sentence\nbased on predefined categories. However, spelling or space error contained in\nthe input sentence causes problems in morphological analysis and tokenization.\nThis paper proposes a novel approach of Integrated Eojeol (Korean syntactic\nword separated by space) Embedding to reduce the effect that poorly analyzed\nmorphemes may make on sentence classification. It also proposes two noise\ninsertion methods that further improve classification performance. Our\nevaluation results indicate that the proposed system classifies erroneous\nsentences more accurately than the baseline system by 17%p.0", "published": "2020-04-13 02:11:19", "link": "http://arxiv.org/abs/2004.05744v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Multi-Criteria Chinese Word Segmentation with BERT", "abstract": "Multi-Criteria Chinese Word Segmentation (MCCWS) aims at finding word\nboundaries in a Chinese sentence composed of continuous characters while\nmultiple segmentation criteria exist. The unified framework has been widely\nused in MCCWS and shows its effectiveness. Besides, the pre-trained BERT\nlanguage model has been also introduced into the MCCWS task in a multi-task\nlearning framework. In this paper, we combine the superiority of the unified\nframework and pretrained language model, and propose a unified MCCWS model\nbased on BERT. Moreover, we augment the unified BERT-based MCCWS model with the\nbigram features and an auxiliary criterion classification task. Experiments on\neight datasets with diverse criteria demonstrate that our methods could achieve\nnew state-of-the-art results for MCCWS.", "published": "2020-04-13 07:50:04", "link": "http://arxiv.org/abs/2004.05808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation: Challenges, Progress and Future", "abstract": "Machine translation (MT) is a technique that leverages computers to translate\nhuman languages automatically. Nowadays, neural machine translation (NMT) which\nmodels direct mapping between source and target languages with deep neural\nnetworks has achieved a big breakthrough in translation performance and become\nthe de facto paradigm of MT. This article makes a review of NMT framework,\ndiscusses the challenges in NMT, introduces some exciting recent progresses and\nfinally looks forward to some potential future research trends. In addition, we\nmaintain the state-of-the-art methods for various NMT tasks at the website\nhttps://github.com/ZNLP/SOTA-MT.", "published": "2020-04-13 07:53:57", "link": "http://arxiv.org/abs/2004.05809v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Will I Sound Like Me? Improving Persona Consistency in Dialogues through\n  Pragmatic Self-Consciousness", "abstract": "We explore the task of improving persona consistency of dialogue agents.\nRecent models tackling consistency often train with additional Natural Language\nInference (NLI) labels or attach trained extra modules to the generative agent\nfor maintaining consistency. However, such additional labels and training can\nbe demanding. Also, we find even the best-performing persona-based agents are\ninsensitive to contradictory words. Inspired by social cognition and\npragmatics, we endow existing dialogue agents with public self-consciousness on\nthe fly through an imaginary listener. Our approach, based on the Rational\nSpeech Acts framework (Frank and Goodman, 2012), can enforce dialogue agents to\nrefrain from uttering contradiction. We further extend the framework by\nlearning the distractor selection, which has been usually done manually or\nrandomly. Results on Dialogue NLI (Welleck et al., 2019) and PersonaChat (Zhang\net al., 2018) dataset show that our approach reduces contradiction and improves\nconsistency of existing dialogue models. Moreover, we show that it can be\ngeneralized to improve context-consistency beyond persona in dialogues.", "published": "2020-04-13 08:16:16", "link": "http://arxiv.org/abs/2004.05816v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frequency-Guided Word Substitutions for Detecting Textual Adversarial\n  Examples", "abstract": "Recent efforts have shown that neural text processing models are vulnerable\nto adversarial examples, but the nature of these examples is poorly understood.\nIn this work, we show that adversarial attacks against CNN, LSTM and\nTransformer-based classification models perform word substitutions that are\nidentifiable through frequency differences between replaced words and their\ncorresponding substitutions. Based on these findings, we propose\nfrequency-guided word substitutions (FGWS), a simple algorithm exploiting the\nfrequency properties of adversarial word substitutions for the detection of\nadversarial examples. FGWS achieves strong performance by accurately detecting\nadversarial examples on the SST-2 and IMDb sentiment datasets, with F1\ndetection scores of up to 91.4% against RoBERTa-based classification models. We\ncompare our approach against a recently proposed perturbation discrimination\nframework and show that we outperform it by up to 13.0% F1.", "published": "2020-04-13 12:11:36", "link": "http://arxiv.org/abs/2004.05887v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Subgraph-Guided Knowledge Graph Question Generation with Graph\n  Neural Networks", "abstract": "Knowledge graph (KG) question generation (QG) aims to generate natural\nlanguage questions from KGs and target answers. Previous works mostly focus on\na simple setting which is to generate questions from a single KG triple. In\nthis work, we focus on a more realistic setting where we aim to generate\nquestions from a KG subgraph and target answers. In addition, most of previous\nworks built on either RNN-based or Transformer based models to encode a\nlinearized KG sugraph, which totally discards the explicit structure\ninformation of a KG subgraph. To address this issue, we propose to apply a\nbidirectional Graph2Seq model to encode the KG subgraph. Furthermore, we\nenhance our RNN decoder with node-level copying mechanism to allow directly\ncopying node attributes from the KG subgraph to the output question. Both\nautomatic and human evaluation results demonstrate that our model achieves new\nstate-of-the-art scores, outperforming existing methods by a significant margin\non two QG benchmarks. Experimental results also show that our QG model can\nconsistently benefit the Question Answering (QA) task as a mean of data\naugmentation.", "published": "2020-04-13 15:43:22", "link": "http://arxiv.org/abs/2004.06015v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AREDSUM: Adaptive Redundancy-Aware Iterative Sentence Ranking for\n  Extractive Document Summarization", "abstract": "Redundancy-aware extractive summarization systems score the redundancy of the\nsentences to be included in a summary either jointly with their salience\ninformation or separately as an additional sentence scoring step. Previous work\nshows the efficacy of jointly scoring and selecting sentences with neural\nsequence generation models. It is, however, not well-understood if the gain is\ndue to better encoding techniques or better redundancy reduction approaches.\nSimilarly, the contribution of salience versus diversity components on the\ncreated summary is not studied well. Building on the state-of-the-art encoding\nmethods for summarization, we present two adaptive learning models: AREDSUM-SEQ\nthat jointly considers salience and novelty during sentence selection; and a\ntwo-step AREDSUM-CTX that scores salience first, then learns to balance\nsalience and redundancy, enabling the measurement of the impact of each aspect.\nEmpirical results on CNN/DailyMail and NYT50 datasets show that by modeling\ndiversity explicitly in a separate step, AREDSUM-CTX achieves significantly\nbetter performance than AREDSUM-SEQ as well as state-of-the-art extractive\nsummarization baselines.", "published": "2020-04-13 20:02:03", "link": "http://arxiv.org/abs/2004.06176v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PoKi: A Large Dataset of Poems by Children", "abstract": "Child language studies are crucial in improving our understanding of child\nwell-being; especially in determining the factors that impact happiness, the\nsources of anxiety, techniques of emotion regulation, and the mechanisms to\ncope with stress. However, much of this research is stymied by the lack of\navailability of large child-written texts. We present a new corpus of\nchild-written text, PoKi, which includes about 62 thousand poems written by\nchildren from grades 1 to 12. PoKi is especially useful in studying child\nlanguage because it comes with information about the age of the child authors\n(their grade). We analyze the words in PoKi along several emotion dimensions\n(valence, arousal, dominance) and discrete emotions (anger, fear, sadness,\njoy). We use non-parametric regressions to model developmental differences from\nearly childhood to late-adolescence. Results show decreases in valence that are\nespecially pronounced during mid-adolescence, while arousal and dominance\npeaked during adolescence. Gender differences in the developmental trajectory\nof emotions are also observed. Our results support and extend the current state\nof emotion development research.", "published": "2020-04-13 20:36:57", "link": "http://arxiv.org/abs/2004.06188v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Divide-and-Conquer Approach to the Summarization of Long Documents", "abstract": "We present a novel divide-and-conquer method for the neural summarization of\nlong documents. Our method exploits the discourse structure of the document and\nuses sentence similarity to split the problem into an ensemble of smaller\nsummarization problems. In particular, we break a long document and its summary\ninto multiple source-target pairs, which are used for training a model that\nlearns to summarize each part of the document separately. These partial\nsummaries are then combined in order to produce a final complete summary. With\nthis approach we can decompose the problem of long document summarization into\nsmaller and simpler problems, reducing computational complexity and creating\nmore training examples, which at the same time contain less noise in the target\nsummaries compared to the standard approach. We demonstrate that this approach\npaired with different summarization models, including sequence-to-sequence RNNs\nand Transformers, can lead to improved summarization performance. Our best\nmodels achieve results that are on par with the state-of-the-art in two two\npublicly available datasets of academic articles.", "published": "2020-04-13 20:38:49", "link": "http://arxiv.org/abs/2004.06190v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforced Curriculum Learning on Pre-trained Neural Machine Translation\n  Models", "abstract": "The competitive performance of neural machine translation (NMT) critically\nrelies on large amounts of training data. However, acquiring high-quality\ntranslation pairs requires expert knowledge and is costly. Therefore, how to\nbest utilize a given dataset of samples with diverse quality and\ncharacteristics becomes an important yet understudied question in NMT.\nCurriculum learning methods have been introduced to NMT to optimize a model's\nperformance by prescribing the data input order, based on heuristics such as\nthe assessment of noise and difficulty levels. However, existing methods\nrequire training from scratch, while in practice most NMT models are\npre-trained on big data already. Moreover, as heuristics, they do not\ngeneralize well. In this paper, we aim to learn a curriculum for improving a\npre-trained NMT model by re-selecting influential data samples from the\noriginal training set and formulate this task as a reinforcement learning\nproblem. Specifically, we propose a data selection framework based on\nDeterministic Actor-Critic, in which a critic network predicts the expected\nchange of model performance due to a certain sample, while an actor network\nlearns to select the best sample out of a random batch of samples presented to\nit. Experiments on several translation datasets show that our method can\nfurther improve the performance of NMT when original batch training reaches its\nceiling, without using additional new training data, and significantly\noutperforms several strong baseline methods.", "published": "2020-04-13 03:40:44", "link": "http://arxiv.org/abs/2004.05757v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ProFormer: Towards On-Device LSH Projection Based Transformers", "abstract": "At the heart of text based neural models lay word representations, which are\npowerful but occupy a lot of memory making it challenging to deploy to devices\nwith memory constraints such as mobile phones, watches and IoT. To surmount\nthese challenges, we introduce ProFormer -- a projection based transformer\narchitecture that is faster and lighter making it suitable to deploy to memory\nconstraint devices and preserve user privacy. We use LSH projection layer to\ndynamically generate word representations on-the-fly without embedding lookup\ntables leading to significant memory footprint reduction from O(V.d) to O(T),\nwhere V is the vocabulary size, d is the embedding dimension size and T is the\ndimension of the LSH projection representation.\n  We also propose a local projection attention (LPA) layer, which uses\nself-attention to transform the input sequence of N LSH word projections into a\nsequence of N/K representations reducing the computations quadratically by\nO(K^2). We evaluate ProFormer on multiple text classification tasks and\nobserved improvements over prior state-of-the-art on-device approaches for\nshort text classification and comparable performance for long text\nclassification tasks. In comparison with a 2-layer BERT model, ProFormer\nreduced the embedding memory footprint from 92.16 MB to 1.3 KB and requires 16\ntimes less computation overhead, which is very impressive making it the fastest\nand smallest on-device model.", "published": "2020-04-13 07:31:31", "link": "http://arxiv.org/abs/2004.05801v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CLUE: A Chinese Language Understanding Evaluation Benchmark", "abstract": "The advent of natural language understanding (NLU) benchmarks for English,\nsuch as GLUE and SuperGLUE allows new NLU models to be evaluated across a\ndiverse set of tasks. These comprehensive benchmarks have facilitated a broad\nrange of research and applications in natural language processing (NLP). The\nproblem, however, is that most such benchmarks are limited to English, which\nhas made it difficult to replicate many of the successes in English NLU for\nother languages. To help remedy this issue, we introduce the first large-scale\nChinese Language Understanding Evaluation (CLUE) benchmark. CLUE is an\nopen-ended, community-driven project that brings together 9 tasks spanning\nseveral well-established single-sentence/sentence-pair classification tasks, as\nwell as machine reading comprehension, all on original Chinese text. To\nestablish results on these tasks, we report scores using an exhaustive set of\ncurrent state-of-the-art pre-trained Chinese models (9 in total). We also\nintroduce a number of supplementary datasets and additional tools to help\nfacilitate further progress on Chinese NLU. Our benchmark is released at\nhttps://www.CLUEbenchmarks.com", "published": "2020-04-13 15:02:29", "link": "http://arxiv.org/abs/2004.05986v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pretrained Transformers Improve Out-of-Distribution Robustness", "abstract": "Although pretrained Transformers such as BERT achieve high accuracy on\nin-distribution examples, do they generalize to new distributions? We\nsystematically measure out-of-distribution (OOD) generalization for seven NLP\ndatasets by constructing a new robustness benchmark with realistic distribution\nshifts. We measure the generalization of previous models including bag-of-words\nmodels, ConvNets, and LSTMs, and we show that pretrained Transformers'\nperformance declines are substantially smaller. Pretrained transformers are\nalso more effective at detecting anomalous or OOD examples, while many previous\nmodels are frequently worse than chance. We examine which factors affect\nrobustness, finding that larger models are not necessarily more robust,\ndistillation can be harmful, and more diverse pretraining data can enhance\nrobustness. Finally, we show where future work can improve OOD robustness.", "published": "2020-04-13 17:58:56", "link": "http://arxiv.org/abs/2004.06100v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Scholarly Knowledge Representation: Evaluating BERT-based\n  Models for Scientific Relation Classification", "abstract": "With the rapid growth of research publications, there is a vast amount of\nscholarly knowledge that needs to be organized in digital libraries. To deal\nwith this challenge, techniques relying on knowledge-graph structures are being\nadvocated. Within such graph-based pipelines, inferring relation types between\nrelated scientific concepts is a crucial step. Recently, advanced techniques\nrelying on language models pre-trained on the large corpus have been popularly\nexplored for automatic relation classification. Despite remarkable\ncontributions that have been made, many of these methods were evaluated under\ndifferent scenarios, which limits their comparability. To this end, we present\na thorough empirical evaluation on eight Bert-based classification models by\nfocusing on two key factors: 1) Bert model variants, and 2) classification\nstrategies. Experiments on three corpora show that domain-specific pre-training\ncorpus benefits the Bert-based classification model to identify the type of\nscientific relations. Although the strategy of predicting a single relation\neach time achieves a higher classification accuracy than the strategy of\nidentifying multiple relation types simultaneously in general, the latter\nstrategy demonstrates a more consistent performance in the corpus with either a\nlarge or small size of annotations. Our study aims to offer recommendations to\nthe stakeholders of digital libraries for selecting the appropriate technique\nto build knowledge-graph-based systems for enhanced scholarly information\norganization.", "published": "2020-04-13 18:46:55", "link": "http://arxiv.org/abs/2004.06153v2", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Robustly Pre-trained Neural Model for Direct Temporal Relation\n  Extraction", "abstract": "Background: Identifying relationships between clinical events and temporal\nexpressions is a key challenge in meaningfully analyzing clinical text for use\nin advanced AI applications. While previous studies exist, the state-of-the-art\nperformance has significant room for improvement.\n  Methods: We studied several variants of BERT (Bidirectional Encoder\nRepresentations using Transformers) some involving clinical domain\ncustomization and the others involving improved architecture and/or training\nstrategies. We evaluated these methods using a direct temporal relations\ndataset which is a semantically focused subset of the 2012 i2b2 temporal\nrelations challenge dataset.\n  Results: Our results show that RoBERTa, which employs better pre-training\nstrategies including using 10x larger corpus, has improved overall F measure by\n0.0864 absolute score (on the 1.00 scale) and thus reducing the error rate by\n24% relative to the previous state-of-the-art performance achieved with an SVM\n(support vector machine) model.\n  Conclusion: Modern contextual language modeling neural networks, pre-trained\non a large corpus, achieve impressive performance even on highly-nuanced\nclinical temporal relation tasks.", "published": "2020-04-13 22:01:38", "link": "http://arxiv.org/abs/2004.06216v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compass-aligned Distributional Embeddings for Studying Semantic\n  Differences across Corpora", "abstract": "Word2vec is one of the most used algorithms to generate word embeddings\nbecause of a good mix of efficiency, quality of the generated representations\nand cognitive grounding. However, word meaning is not static and depends on the\ncontext in which words are used. Differences in word meaning that depends on\ntime, location, topic, and other factors, can be studied by analyzing\nembeddings generated from different corpora in collections that are\nrepresentative of these factors. For example, language evolution can be studied\nusing a collection of news articles published in different time periods. In\nthis paper, we present a general framework to support cross-corpora language\nstudies with word embeddings, where embeddings generated from different corpora\ncan be compared to find correspondences and differences in meaning across the\ncorpora. CADE is the core component of our framework and solves the key problem\nof aligning the embeddings generated from different corpora. In particular, we\nfocus on providing solid evidence about the effectiveness, generality, and\nrobustness of CADE. To this end, we conduct quantitative and qualitative\nexperiments in different domains, from temporal word embeddings to language\nlocalization and topical analysis. The results of our experiments suggest that\nCADE achieves state-of-the-art or superior performance on tasks where several\ncompeting approaches are available, yet providing a general method that can be\nused in a variety of domains. Finally, our experiments shed light on the\nconditions under which the alignment is reliable, which substantially depends\non the degree of cross-corpora vocabulary overlap.", "published": "2020-04-13 15:46:47", "link": "http://arxiv.org/abs/2004.06519v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Aspect and Opinion Aware Abstractive Review Summarization with\n  Reinforced Hard Typed Decoder", "abstract": "In this paper, we study abstractive review summarization.Observing that\nreview summaries often consist of aspect words, opinion words and context\nwords, we propose a two-stage reinforcement learning approach, which first\npredicts the output word type from the three types, and then leverages the\npredicted word type to generate the final word distribution.Experimental\nresults on two Amazon product review datasets demonstrate that our method can\nconsistently outperform several strong baseline approaches based on ROUGE\nscores.", "published": "2020-04-13 03:35:29", "link": "http://arxiv.org/abs/2004.05755v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating Fact Checking Explanations", "abstract": "Most existing work on automated fact checking is concerned with predicting\nthe veracity of claims based on metadata, social network spread, language used\nin claims, and, more recently, evidence supporting or denying claims. A crucial\npiece of the puzzle that is still missing is to understand how to automate the\nmost elaborate part of the process -- generating justifications for verdicts on\nclaims. This paper provides the first study of how these explanations can be\ngenerated automatically based on available claim context, and how this task can\nbe modelled jointly with veracity prediction. Our results indicate that\noptimising both objectives at the same time, rather than training them\nseparately, improves the performance of a fact checking system. The results of\na manual evaluation further suggest that the informativeness, coverage and\noverall quality of the generated explanations are also improved in the\nmulti-task model.", "published": "2020-04-13 05:23:25", "link": "http://arxiv.org/abs/2004.05773v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MLR: A Two-stage Conversational Query Rewriting Model with Multi-task\n  Learning", "abstract": "Conversational context understanding aims to recognize the real intention of\nuser from the conversation history, which is critical for building the dialogue\nsystem. However, the multi-turn conversation understanding in open domain is\nstill quite challenging, which requires the system extracting the important\ninformation and resolving the dependencies in contexts among a variety of open\ntopics. In this paper, we propose the conversational query rewriting model -\nMLR, which is a Multi-task model on sequence Labeling and query Rewriting. MLR\nreformulates the multi-turn conversational queries into a single turn query,\nwhich conveys the true intention of users concisely and alleviates the\ndifficulty of the multi-turn dialogue modeling. In the model, we formulate the\nquery rewriting as a sequence generation problem and introduce word category\ninformation via the auxiliary word category label predicting task. To train our\nmodel, we construct a new Chinese query rewriting dataset and conduct\nexperiments on it. The experimental results show that our model outperforms\ncompared models, and prove the effectiveness of the word category information\nin improving the rewriting performance.", "published": "2020-04-13 08:04:49", "link": "http://arxiv.org/abs/2004.05812v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "From Machine Reading Comprehension to Dialogue State Tracking: Bridging\n  the Gap", "abstract": "Dialogue state tracking (DST) is at the heart of task-oriented dialogue\nsystems. However, the scarcity of labeled data is an obstacle to building\naccurate and robust state tracking systems that work across a variety of\ndomains. Existing approaches generally require some dialogue data with state\ninformation and their ability to generalize to unknown domains is limited. In\nthis paper, we propose using machine reading comprehension (RC) in state\ntracking from two perspectives: model architectures and datasets. We divide the\nslot types in dialogue state into categorical or extractive to borrow the\nadvantages from both multiple-choice and span-based reading comprehension\nmodels. Our method achieves near the current state-of-the-art in joint goal\naccuracy on MultiWOZ 2.1 given full training data. More importantly, by\nleveraging machine reading comprehension datasets, our method outperforms the\nexisting approaches by many a large margin in few-shot scenarios when the\navailability of in-domain data is limited. Lastly, even without any state\ntracking data, i.e., zero-shot scenario, our proposed approach achieves greater\nthan 90% average slot accuracy in 12 out of 30 slots in MultiWOZ 2.1.", "published": "2020-04-13 09:00:03", "link": "http://arxiv.org/abs/2004.05827v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ArCOV-19: The First Arabic COVID-19 Twitter Dataset with Propagation\n  Networks", "abstract": "In this paper, we present ArCOV-19, an Arabic COVID-19 Twitter dataset that\nspans one year, covering the period from 27th of January 2020 till 31st of\nJanuary 2021. ArCOV-19 is the first publicly-available Arabic Twitter dataset\ncovering COVID-19 pandemic that includes about 2.7M tweets alongside the\npropagation networks of the most-popular subset of them (i.e., most-retweeted\nand -liked). The propagation networks include both retweets and conversational\nthreads (i.e., threads of replies). ArCOV-19 is designed to enable research\nunder several domains including natural language processing, information\nretrieval, and social computing. Preliminary analysis shows that ArCOV-19\ncaptures rising discussions associated with the first reported cases of the\ndisease as they appeared in the Arab world. In addition to the source tweets\nand propagation networks, we also release the search queries and\nlanguage-independent crawler used to collect the tweets to encourage the\ncuration of similar datasets.", "published": "2020-04-13 10:49:53", "link": "http://arxiv.org/abs/2004.05861v4", "categories": ["cs.CL", "cs.IR", "cs.SI", "H.3; H.4; I.2; J.4"], "primary_category": "cs.CL"}
{"title": "Keyword Assisted Topic Models", "abstract": "In recent years, fully automated content analysis based on probabilistic\ntopic models has become popular among social scientists because of their\nscalability. The unsupervised nature of the models makes them suitable for\nexploring topics in a corpus without prior knowledge. However, researchers find\nthat these models often fail to measure specific concepts of substantive\ninterest by inadvertently creating multiple topics with similar content and\ncombining distinct themes into a single topic. In this paper, we empirically\ndemonstrate that providing a small number of keywords can substantially enhance\nthe measurement performance of topic models. An important advantage of the\nproposed keyword assisted topic model (keyATM) is that the specification of\nkeywords requires researchers to label topics prior to fitting a model to the\ndata. This contrasts with a widespread practice of post-hoc topic\ninterpretation and adjustments that compromises the objectivity of empirical\nfindings. In our application, we find that keyATM provides more interpretable\nresults, has better document classification performance, and is less sensitive\nto the number of topics than the standard topic models. Finally, we show that\nkeyATM can also incorporate covariates and model time trends. An open-source\nsoftware package is available for implementing the proposed methodology.", "published": "2020-04-13 14:35:28", "link": "http://arxiv.org/abs/2004.05964v3", "categories": ["cs.CL", "stat.AP", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Punctuation Prediction in Spontaneous Conversations: Can We Mitigate ASR\n  Errors with Retrofitted Word Embeddings?", "abstract": "Automatic Speech Recognition (ASR) systems introduce word errors, which often\nconfuse punctuation prediction models, turning punctuation restoration into a\nchallenging task. These errors usually take the form of homonyms. We show how\nretrofitting of the word embeddings on the domain-specific data can mitigate\nASR errors. Our main contribution is a method for better alignment of homonym\nembeddings and the validation of the presented method on the punctuation\nprediction task. We record the absolute improvement in punctuation prediction\naccuracy between 6.2% (for question marks) to 9% (for periods) when compared\nwith the state-of-the-art model.", "published": "2020-04-13 15:02:28", "link": "http://arxiv.org/abs/2004.05985v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Data augmentation using generative networks to identify dementia", "abstract": "Data limitation is one of the most common issues in training machine learning\nclassifiers for medical applications. Due to ethical concerns and data privacy,\nthe number of people that can be recruited to such experiments is generally\nsmaller than the number of participants contributing to non-healthcare\ndatasets. Recent research showed that generative models can be used as an\neffective approach for data augmentation, which can ultimately help to train\nmore robust classifiers sparse data domains. A number of studies proved that\nthis data augmentation technique works for image and audio data sets. In this\npaper, we investigate the application of a similar approach to different types\nof speech and audio-based features extracted from interactions recorded with\nour automatic dementia detection system. Using two generative models we show\nhow the generated synthesized samples can improve the performance of a DNN\nbased classifier. The variational autoencoder increased the F-score of a\nfour-way classifier distinguishing the typical patient groups seen in memory\nclinics from 58% to around 74%, a 16% improvement", "published": "2020-04-13 15:05:24", "link": "http://arxiv.org/abs/2004.05989v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learning from Rules Generalizing Labeled Exemplars", "abstract": "In many applications labeled data is not readily available, and needs to be\ncollected via pain-staking human supervision. We propose a rule-exemplar method\nfor collecting human supervision to combine the efficiency of rules with the\nquality of instance labels. The supervision is coupled such that it is both\nnatural for humans and synergistic for learning. We propose a training\nalgorithm that jointly denoises rules via latent coverage variables, and trains\nthe model through a soft implication loss over the coverage and label\nvariables. The denoised rules and trained model are used jointly for inference.\nEmpirical evaluation on five different tasks shows that (1) our algorithm is\nmore accurate than several existing methods of learning from a mix of clean and\nnoisy supervision, and (2) the coupled rule-exemplar supervision is effective\nin denoising rules.", "published": "2020-04-13 15:57:54", "link": "http://arxiv.org/abs/2004.06025v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "BLEU might be Guilty but References are not Innocent", "abstract": "The quality of automatic metrics for machine translation has been\nincreasingly called into question, especially for high-quality systems. This\npaper demonstrates that, while choice of metric is important, the nature of the\nreferences is also critical. We study different methods to collect references\nand compare their value in automated evaluation by reporting correlation with\nhuman evaluation for a variety of systems and metrics. Motivated by the finding\nthat typical references exhibit poor diversity, concentrating around\ntranslationese language, we develop a paraphrasing task for linguists to\nperform on existing reference translations, which counteracts this bias. Our\nmethod yields higher correlation with human judgment not only for the\nsubmissions of WMT 2019 English to German, but also for Back-translation and\nAPE augmented MT output, which have been shown to have low correlation with\nautomatic metrics using standard references. We demonstrate that our\nmethodology improves correlation with all modern evaluation metrics we look at,\nincluding embedding-based methods. To complete this picture, we reveal that\nmulti-reference BLEU does not improve the correlation for high quality output,\nand present an alternative multi-reference formulation that is more effective.", "published": "2020-04-13 16:49:09", "link": "http://arxiv.org/abs/2004.06063v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adversarial Augmentation Policy Search for Domain and Cross-Lingual\n  Generalization in Reading Comprehension", "abstract": "Reading comprehension models often overfit to nuances of training datasets\nand fail at adversarial evaluation. Training with adversarially augmented\ndataset improves robustness against those adversarial attacks but hurts\ngeneralization of the models. In this work, we present several effective\nadversaries and automated data augmentation policy search methods with the goal\nof making reading comprehension models more robust to adversarial evaluation,\nbut also improving generalization to the source domain as well as new domains\nand languages. We first propose three new methods for generating QA\nadversaries, that introduce multiple points of confusion within the context,\nshow dependence on insertion location of the distractor, and reveal the\ncompounding effect of mixing adversarial strategies with syntactic and semantic\nparaphrasing methods. Next, we find that augmenting the training datasets with\nuniformly sampled adversaries improves robustness to the adversarial attacks\nbut leads to decline in performance on the original unaugmented dataset. We\naddress this issue via RL and more efficient Bayesian policy search methods for\nautomatically learning the best augmentation policy combinations of the\ntransformation probability for each adversary in a large search space. Using\nthese learned policies, we show that adversarial training can lead to\nsignificant improvements in in-domain, out-of-domain, and cross-lingual\n(German, Russian, Turkish) generalization.", "published": "2020-04-13 17:20:08", "link": "http://arxiv.org/abs/2004.06076v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks", "abstract": "Large-scale pre-training methods of learning cross-modal representations on\nimage-text pairs are becoming popular for vision-language tasks. While existing\nmethods simply concatenate image region features and text features as input to\nthe model to be pre-trained and use self-attention to learn image-text semantic\nalignments in a brute force manner, in this paper, we propose a new learning\nmethod Oscar (Object-Semantics Aligned Pre-training), which uses object tags\ndetected in images as anchor points to significantly ease the learning of\nalignments. Our method is motivated by the observation that the salient objects\nin an image can be accurately detected, and are often mentioned in the paired\ntext. We pre-train an Oscar model on the public corpus of 6.5 million\ntext-image pairs, and fine-tune it on downstream tasks, creating new\nstate-of-the-arts on six well-established vision-language understanding and\ngeneration tasks.", "published": "2020-04-13 19:18:10", "link": "http://arxiv.org/abs/2004.06165v5", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Reverse Engineering Configurations of Neural Text Generation Models", "abstract": "This paper seeks to develop a deeper understanding of the fundamental\nproperties of neural text generations models. The study of artifacts that\nemerge in machine generated text as a result of modeling choices is a nascent\nresearch area. Previously, the extent and degree to which these artifacts\nsurface in generated text has not been well studied. In the spirit of better\nunderstanding generative text models and their artifacts, we propose the new\ntask of distinguishing which of several variants of a given model generated a\npiece of text, and we conduct an extensive suite of diagnostic tests to observe\nwhether modeling choices (e.g., sampling methods, top-$k$ probabilities, model\narchitectures, etc.) leave detectable artifacts in the text they generate. Our\nkey finding, which is backed by a rigorous set of experiments, is that such\nartifacts are present and that different modeling choices can be inferred by\nobserving the generated text alone. This suggests that neural text generators\nmay be more sensitive to various modeling choices than previously thought.", "published": "2020-04-13 21:02:44", "link": "http://arxiv.org/abs/2004.06201v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cascade Neural Ensemble for Identifying Scientifically Sound Articles", "abstract": "Background: A significant barrier to conducting systematic reviews and\nmeta-analysis is efficiently finding scientifically sound relevant articles.\nTypically, less than 1% of articles match this requirement which leads to a\nhighly imbalanced task. Although feature-engineered and early neural networks\nmodels were studied for this task, there is an opportunity to improve the\nresults.\n  Methods: We framed the problem of filtering articles as a classification\ntask, and trained and tested several ensemble architectures of SciBERT, a\nvariant of BERT pre-trained on scientific articles, on a manually annotated\ndataset of about 50K articles from MEDLINE. Since scientifically sound articles\nare identified through a multi-step process we proposed a novel cascade\nensemble analogous to the selection process. We compared the performance of the\ncascade ensemble with a single integrated model and other types of ensembles as\nwell as with results from previous studies.\n  Results: The cascade ensemble architecture achieved 0.7505 F measure, an\nimpressive 49.1% error rate reduction, compared to a CNN model that was\npreviously proposed and evaluated on a selected subset of the 50K articles. On\nthe full dataset, the cascade ensemble achieved 0.7639 F measure, resulting in\nan error rate reduction of 19.7% compared to the best performance reported in a\nprevious study that used the full dataset.\n  Conclusion: Pre-trained contextual encoder neural networks (e.g. SciBERT)\nperform better than the models studied previously and manually created search\nfilters in filtering for scientifically sound relevant articles. The superior\nperformance achieved by the cascade ensemble is a significant result that\ngeneralizes beyond this task and the dataset, and is analogous to query\noptimization in IR and databases.", "published": "2020-04-13 22:23:04", "link": "http://arxiv.org/abs/2004.06222v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speaker Diarization with Lexical Information", "abstract": "This work presents a novel approach for speaker diarization to leverage\nlexical information provided by automatic speech recognition. We propose a\nspeaker diarization system that can incorporate word-level speaker turn\nprobabilities with speaker embeddings into a speaker clustering process to\nimprove the overall diarization accuracy. To integrate lexical and acoustic\ninformation in a comprehensive way during clustering, we introduce an adjacency\nmatrix integration for spectral clustering. Since words and word boundary\ninformation for word-level speaker turn probability estimation are provided by\na speech recognition system, our proposed method works without any human\nintervention for manual transcriptions. We show that the proposed method\nimproves diarization performance on various evaluation datasets compared to the\nbaseline diarization system using acoustic information only in speaker\nembeddings.", "published": "2020-04-13 17:16:56", "link": "http://arxiv.org/abs/2004.06756v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Cross-lingual Zero- and Few-shot Hate Speech Detection Utilising Frozen\n  Transformer Language Models and AXEL", "abstract": "Detecting hate speech, especially in low-resource languages, is a non-trivial\nchallenge. To tackle this, we developed a tailored architecture based on\nfrozen, pre-trained Transformers to examine cross-lingual zero-shot and\nfew-shot learning, in addition to uni-lingual learning, on the HatEval\nchallenge data set. With our novel attention-based classification block AXEL,\nwe demonstrate highly competitive results on the English and Spanish subsets.\nWe also re-sample the English subset, enabling additional, meaningful\ncomparisons in the future.", "published": "2020-04-13 09:58:33", "link": "http://arxiv.org/abs/2004.13850v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Gender Detection on Social Networks using Ensemble Deep Learning", "abstract": "Analyzing the ever-increasing volume of posts on social media sites such as\nFacebook and Twitter requires improved information processing methods for\nprofiling authorship. Document classification is central to this task, but the\nperformance of traditional supervised classifiers has degraded as the volume of\nsocial media has increased. This paper addresses this problem in the context of\ngender detection through ensemble classification that employs multi-model deep\nlearning architectures to generate specialized understanding from different\nfeature spaces.", "published": "2020-04-13 15:08:49", "link": "http://arxiv.org/abs/2004.06518v3", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.SI"}
{"title": "From Inference to Generation: End-to-end Fully Self-supervised\n  Generation of Human Face from Speech", "abstract": "This work seeks the possibility of generating the human face from voice\nsolely based on the audio-visual data without any human-labeled annotations. To\nthis end, we propose a multi-modal learning framework that links the inference\nstage and generation stage. First, the inference networks are trained to match\nthe speaker identity between the two different modalities. Then the trained\ninference networks cooperate with the generation network by giving conditional\ninformation about the voice. The proposed method exploits the recent\ndevelopment of GANs techniques and generates the human face directly from the\nspeech waveform making our system fully end-to-end. We analyze the extent to\nwhich the network can naturally disentangle two latent factors that contribute\nto the generation of a face image - one that comes directly from a speech\nsignal and the other that is not related to it - and explore whether the\nnetwork can learn to generate natural human face image distribution by modeling\nthese factors. Experimental results show that the proposed network can not only\nmatch the relationship between the human face and speech, but can also generate\nthe high-quality human face sample conditioned on its speech. Finally, the\ncorrelation between the generated face and the corresponding speech is\nquantitatively measured to analyze the relationship between the two modalities.", "published": "2020-04-13 09:01:49", "link": "http://arxiv.org/abs/2004.05830v1", "categories": ["eess.AS", "cs.CV", "cs.LG", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
