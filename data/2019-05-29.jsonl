{"title": "Ensuring Readability and Data-fidelity using Head-modifier Templates in\n  Deep Type Description Generation", "abstract": "A type description is a succinct noun compound which helps human and machines\nto quickly grasp the informative and distinctive information of an entity.\nEntities in most knowledge graphs (KGs) still lack such descriptions, thus\ncalling for automatic methods to supplement such information. However, existing\ngenerative methods either overlook the grammatical structure or make factual\nmistakes in generated texts. To solve these problems, we propose a\nhead-modifier template-based method to ensure the readability and data fidelity\nof generated type descriptions. We also propose a new dataset and two automatic\nmetrics for this task. Experiments show that our method improves substantially\ncompared with baselines and achieves state-of-the-art performance on both\ndatasets.", "published": "2019-05-29 03:32:38", "link": "http://arxiv.org/abs/1905.12198v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Task-specific Representation for Novel Words in Sequence\n  Labeling", "abstract": "Word representation is a key component in neural-network-based sequence\nlabeling systems. However, representations of unseen or rare words trained on\nthe end task are usually poor for appreciable performance. This is commonly\nreferred to as the out-of-vocabulary (OOV) problem. In this work, we address\nthe OOV problem in sequence labeling using only training data of the task. To\nthis end, we propose a novel method to predict representations for OOV words\nfrom their surface-forms (e.g., character sequence) and contexts. The method is\nspecifically designed to avoid the error propagation problem suffered by\nexisting approaches in the same paradigm. To evaluate its effectiveness, we\nperformed extensive empirical studies on four part-of-speech tagging (POS)\ntasks and four named entity recognition (NER) tasks. Experimental results show\nthat the proposed method can achieve better or competitive performance on the\nOOV problem compared with existing state-of-the-art methods.", "published": "2019-05-29 08:58:52", "link": "http://arxiv.org/abs/1905.12277v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revision in Continuous Space: Unsupervised Text Style Transfer without\n  Adversarial Learning", "abstract": "Typical methods for unsupervised text style transfer often rely on two key\ningredients: 1) seeking the explicit disentanglement of the content and the\nattributes, and 2) troublesome adversarial learning. In this paper, we show\nthat neither of these components is indispensable. We propose a new framework\nthat utilizes the gradients to revise the sentence in a continuous space during\ninference to achieve text style transfer. Our method consists of three key\ncomponents: a variational auto-encoder (VAE), some attribute predictors (one\nfor each attribute), and a content predictor. The VAE and the two types of\npredictors enable us to perform gradient-based optimization in the continuous\nspace, which is mapped from sentences in a discrete space, to find the\nrepresentation of a target sentence with the desired attributes and preserved\ncontent. Moreover, the proposed method naturally has the ability to\nsimultaneously manipulate multiple fine-grained attributes, such as sentence\nlength and the presence of specific words, when performing text style transfer\ntasks. Compared with previous adversarial learning based methods, the proposed\nmethod is more interpretable, controllable and easier to train. Extensive\nexperimental studies on three popular text style transfer tasks show that the\nproposed method significantly outperforms five state-of-the-art methods.", "published": "2019-05-29 10:07:12", "link": "http://arxiv.org/abs/1905.12304v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TopExNet: Entity-Centric Network Topic Exploration in News Streams", "abstract": "The recent introduction of entity-centric implicit network representations of\nunstructured text offers novel ways for exploring entity relations in document\ncollections and streams efficiently and interactively. Here, we present\nTopExNet as a tool for exploring entity-centric network topics in streams of\nnews articles. The application is available as a web service at\nhttps://topexnet.ifi.uni-heidelberg.de/ .", "published": "2019-05-29 11:28:37", "link": "http://arxiv.org/abs/1905.12335v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards better substitution-based word sense induction", "abstract": "Word sense induction (WSI) is the task of unsupervised clustering of word\nusages within a sentence to distinguish senses. Recent work obtain strong\nresults by clustering lexical substitutes derived from pre-trained RNN language\nmodels (ELMo). Adapting the method to BERT improves the scores even further. We\nextend the previous method to support a dynamic rather than a fixed number of\nclusters as supported by other prominent methods, and propose a method for\ninterpreting the resulting clusters by associating them with their most\ninformative substitutes. We then perform extensive error analysis revealing the\nremaining sources of errors in the WSI task.\n  Our code is available at https://github.com/asafamr/bertwsi.", "published": "2019-05-29 17:20:11", "link": "http://arxiv.org/abs/1905.12598v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The (Non-)Utility of Structural Features in BiLSTM-based Dependency\n  Parsers", "abstract": "Classical non-neural dependency parsers put considerable effort on the design\nof feature functions. Especially, they benefit from information coming from\nstructural features, such as features drawn from neighboring tokens in the\ndependency tree. In contrast, their BiLSTM-based successors achieve\nstate-of-the-art performance without explicit information about the structural\ncontext. In this paper we aim to answer the question: How much structural\ncontext are the BiLSTM representations able to capture implicitly? We show that\nfeatures drawn from partial subtrees become redundant when the BiLSTMs are\nused. We provide a deep insight into information flow in transition- and\ngraph-based neural architectures to demonstrate where the implicit information\ncomes from when the parsers make their decisions. Finally, with model ablations\nwe demonstrate that the structural context is not only present in the models,\nbut it significantly influences their performance.", "published": "2019-05-29 18:49:03", "link": "http://arxiv.org/abs/1905.12676v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Choosing Transfer Languages for Cross-Lingual Learning", "abstract": "Cross-lingual transfer, where a high-resource transfer language is used to\nimprove the accuracy of a low-resource task language, is now an invaluable tool\nfor improving performance of natural language processing (NLP) on low-resource\nlanguages. However, given a particular task language, it is not clear which\nlanguage to transfer from, and the standard strategy is to select languages\nbased on ad hoc criteria, usually the intuition of the experimenter. Since a\nlarge number of features contribute to the success of cross-lingual transfer\n(including phylogenetic similarity, typological properties, lexical overlap, or\nsize of available data), even the most enlightened experimenter rarely\nconsiders all these factors for the particular task at hand. In this paper, we\nconsider this task of automatically selecting optimal transfer languages as a\nranking problem, and build models that consider the aforementioned features to\nperform this prediction. In experiments on representative NLP tasks, we\ndemonstrate that our model predicts good transfer languages much better than ad\nhoc baselines considering single features in isolation, and glean insights on\nwhat features are most informative for each different NLP tasks, which may\ninform future ad hoc selection even without use of our method. Code, data, and\npre-trained models are available at https://github.com/neulab/langrank", "published": "2019-05-29 19:19:47", "link": "http://arxiv.org/abs/1905.12688v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geolocating Political Events in Text", "abstract": "This work introduces a general method for automatically finding the locations\nwhere political events in text occurred. Using a novel set of 8,000 labeled\nsentences, I create a method to link automatically extracted events and\nlocations in text. The model achieves human level performance on the annotation\ntask and outperforms previous event geolocation systems. It can be applied to\nmost event extraction systems across geographic contexts. I formalize the\nevent--location linking task, describe the neural network model, describe the\npotential uses of such a system in political science, and demonstrate a\nworkflow to answer an open question on the role of conventional military\noffensives in causing civilian casualties in the Syrian civil war.", "published": "2019-05-29 20:40:24", "link": "http://arxiv.org/abs/1905.12713v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Persona Information for Diverse Generation of Conversational\n  Responses", "abstract": "In human conversations, due to their personalities in mind, people can easily\ncarry out and maintain the conversations. Giving conversational context with\npersona information to a chatbot, how to exploit the information to generate\ndiverse and sustainable conversations is still a non-trivial task. Previous\nwork on persona-based conversational models successfully make use of predefined\npersona information and have shown great promise in delivering more realistic\nresponses. And they all learn with the assumption that given a source input,\nthere is only one target response. However, in human conversations, there are\nmassive appropriate responses to a given input message. In this paper, we\npropose a memory-augmented architecture to exploit persona information from\ncontext and incorporate a conditional variational autoencoder model together to\ngenerate diverse and sustainable conversations. We evaluate the proposed model\non a benchmark persona-chat dataset. Both automatic and human evaluations show\nthat our model can deliver more diverse and more engaging persona-based\nresponses than baseline approaches.", "published": "2019-05-29 02:50:50", "link": "http://arxiv.org/abs/1905.12188v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation", "abstract": "Advances in learning and representations have reinvigorated work that\nconnects language to other modalities. A particularly exciting direction is\nVision-and-Language Navigation(VLN), in which agents interpret natural language\ninstructions and visual scenes to move through environments and reach goals.\nDespite recent progress, current research leaves unclear how much of a role\nlanguage understanding plays in this task, especially because dominant\nevaluation metrics have focused on goal completion rather than the sequence of\nactions corresponding to the instructions. Here, we highlight shortcomings of\ncurrent metrics for the Room-to-Room dataset (Anderson et al.,2018b) and\npropose a new metric, Coverage weighted by Length Score (CLS). We also show\nthat the existing paths in the dataset are not ideal for evaluating instruction\nfollowing because they are direct-to-goal shortest paths. We join existing\nshort paths to form more challenging extended paths to create a new data set,\nRoom-for-Room (R4R). Using R4R and CLS, we show that agents that receive\nrewards for instruction fidelity outperform agents that focus on goal\ncompletion.", "published": "2019-05-29 07:40:38", "link": "http://arxiv.org/abs/1905.12255v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Racial Bias in Hate Speech and Abusive Language Detection Datasets", "abstract": "Technologies for abusive language detection are being developed and applied\nwith little consideration of their potential biases. We examine racial bias in\nfive different sets of Twitter data annotated for hate speech and abusive\nlanguage. We train classifiers on these datasets and compare the predictions of\nthese classifiers on tweets written in African-American English with those\nwritten in Standard American English. The results show evidence of systematic\nracial bias in all datasets, as classifiers trained on them tend to predict\nthat tweets written in African-American English are abusive at substantially\nhigher rates. If these abusive language detection systems are used in the field\nthey will therefore have a disproportionate negative impact on African-American\nsocial media users. Consequently, these systems may discriminate against the\ngroups who are often the targets of the abuse we are trying to detect.", "published": "2019-05-29 15:12:58", "link": "http://arxiv.org/abs/1905.12516v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Predicting next shopping stage using Google Analytics data for\n  E-commerce applications", "abstract": "E-commerce web applications are almost ubiquitous in our day to day life,\nhowever as useful as they are, most of them have little to no adaptation to\nuser needs, which in turn can cause both lower conversion rates as well as\nunsatisfied customers. We propose a machine learning system which learns the\nuser behaviour from multiple previous sessions and predicts useful metrics for\nthe current session. In turn, these metrics can be used by the applications to\ncustomize and better target the customer, which can mean anything from offering\nbetter offers of specific products, targeted notifications or placing smart\nads. The data used for the learning algorithm is extracted from Google\nAnalytics Enhanced E-commerce, which is enabled by most e-commerce websites and\nthus the system can be used by any such merchant. In order to learn the user\npatterns, only its behaviour features were used, which don't include names,\ngender or any other personal information that could identify the user. The\nlearning model that was used is a double recurrent neural network which learns\nboth intra-session and inter-session features. The model predicts for each\nsession a probability score for each of the defined target classes.", "published": "2019-05-29 17:14:24", "link": "http://arxiv.org/abs/1905.12595v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Defending Against Neural Fake News", "abstract": "Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.", "published": "2019-05-29 17:58:52", "link": "http://arxiv.org/abs/1905.12616v3", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Neural Review Rating Prediction with Hierarchical Attentions and Latent\n  Factors", "abstract": "Text reviews can provide rich useful semantic information for modeling users\nand items, which can benefit rating prediction in recommendation. Different\nwords and reviews may have different informativeness for users or items.\nBesides, different users and items should be personalized. Most existing works\nregard all reviews equally or utilize a general attention mechanism. In this\npaper, we propose a hierarchical attention model fusing latent factor model for\nrating prediction with reviews, which can focus on important words and\ninformative reviews. Specially, we use the factor vectors of Latent Factor\nModel to guide the attention network and combine the factor vectors with\nfeature representation learned from reviews to predict the final ratings.\nExperiments on real-world datasets validate the effectiveness of our approach.", "published": "2019-05-29 14:16:28", "link": "http://arxiv.org/abs/1906.01511v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn\n  University Joint Investigation for Dinner Party ASR", "abstract": "In this paper, we present Hitachi and Paderborn University's joint effort for\nautomatic speech recognition (ASR) in a dinner party scenario. The main\nchallenges of ASR systems for dinner party recordings obtained by multiple\nmicrophone arrays are (1) heavy speech overlaps, (2) severe noise and\nreverberation, (3) very natural conversational content, and possibly (4)\ninsufficient training data. As an example of a dinner party scenario, we have\nchosen the data presented during the CHiME-5 speech recognition challenge,\nwhere the baseline ASR had a 73.3% word error rate (WER), and even the best\nperforming system at the CHiME-5 challenge had a 46.1% WER. We extensively\ninvestigated a combination of the guided source separation-based speech\nenhancement technique and an already proposed strong ASR backend and found that\na tight combination of these techniques provided substantial accuracy\nimprovements. Our final system achieved WERs of 39.94% and 41.64% for the\ndevelopment and evaluation data, respectively, both of which are the best\npublished results for the dataset. We also investigated with additional\ntraining data on the official small data in the CHiME-5 corpus to assess the\nintrinsic difficulty of this ASR task.", "published": "2019-05-29 05:50:35", "link": "http://arxiv.org/abs/1905.12230v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Learning Multilingual Word Embeddings Using Image-Text Data", "abstract": "There has been significant interest recently in learning multilingual word\nembeddings -- in which semantically similar words across languages have similar\nembeddings. State-of-the-art approaches have relied on expensive labeled data,\nwhich is unavailable for low-resource languages, or have involved post-hoc\nunification of monolingual embeddings. In the present paper, we investigate the\nefficacy of multilingual embeddings learned from weakly-supervised image-text\ndata. In particular, we propose methods for learning multilingual embeddings\nusing image-text data, by enforcing similarity between the representations of\nthe image and that of the text. Our experiments reveal that even without using\nany expensive labeled data, a bag-of-words-based embedding model trained on\nimage-text data achieves performance comparable to the state-of-the-art on\ncrosslingual semantic similarity tasks.", "published": "2019-05-29 07:55:17", "link": "http://arxiv.org/abs/1905.12260v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word-order biases in deep-agent emergent communication", "abstract": "Sequence-processing neural networks led to remarkable progress on many NLP\ntasks. As a consequence, there has been increasing interest in understanding to\nwhat extent they process language as humans do. We aim here to uncover which\nbiases such models display with respect to \"natural\" word-order constraints. We\ntrain models to communicate about paths in a simple gridworld, using miniature\nlanguages that reflect or violate various natural language trends, such as the\ntendency to avoid redundancy or to minimize long-distance dependencies. We\nstudy how the controlled characteristics of our miniature languages affect\nindividual learning and their stability across multiple network generations.\nThe results draw a mixed picture. On the one hand, neural networks show a\nstrong tendency to avoid long-distance dependencies. On the other hand, there\nis no clear preference for the efficient, non-redundant encoding of information\nthat is widely attested in natural language. We thus suggest inoculating a\nnotion of \"effort\" into neural networks, as a possible way to make their\nlinguistic behavior more human-like.", "published": "2019-05-29 11:17:59", "link": "http://arxiv.org/abs/1905.12330v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SECRET: Semantically Enhanced Classification of Real-world Tasks", "abstract": "Supervised machine learning (ML) algorithms are aimed at maximizing\nclassification performance under available energy and storage constraints. They\ntry to map the training data to the corresponding labels while ensuring\ngeneralizability to unseen data. However, they do not integrate meaning-based\nrelationships among labels in the decision process. On the other hand, natural\nlanguage processing (NLP) algorithms emphasize the importance of semantic\ninformation. In this paper, we synthesize the complementary advantages of\nsupervised ML and NLP algorithms into one method that we refer to as SECRET\n(Semantically Enhanced Classification of REal-world Tasks). SECRET performs\nclassifications by fusing the semantic information of the labels with the\navailable data: it combines the feature space of the supervised algorithms with\nthe semantic space of the NLP algorithms and predicts labels based on this\njoint space. Experimental results indicate that, compared to traditional\nsupervised learning, SECRET achieves up to 14.0% accuracy and 13.1% F1 score\nimprovements. Moreover, compared to ensemble methods, SECRET achieves up to\n12.7% accuracy and 13.3% F1 score improvements. This points to a new research\ndirection for supervised classification based on incorporation of semantic\ninformation.", "published": "2019-05-29 12:05:31", "link": "http://arxiv.org/abs/1905.12356v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "NRPA: Neural Recommendation with Personalized Attention", "abstract": "Existing review-based recommendation methods usually use the same model to\nlearn the representations of all users/items from reviews posted by users\ntowards items. However, different users have different preference and different\nitems have different characteristics. Thus, the same word or similar reviews\nmay have different informativeness for different users and items. In this paper\nwe propose a neural recommendation approach with personalized attention to\nlearn personalized representations of users and items from reviews. We use a\nreview encoder to learn representations of reviews from words, and a user/item\nencoder to learn representations of users or items from reviews. We propose a\npersonalized attention model, and apply it to both review and user/item\nencoders to select different important words and reviews for different\nusers/items. Experiments on five datasets validate our approach can effectively\nimprove the performance of neural recommendation.", "published": "2019-05-29 14:16:17", "link": "http://arxiv.org/abs/1905.12480v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Anti-efficient encoding in emergent communication", "abstract": "Despite renewed interest in emergent language simulations with neural\nnetworks, little is known about the basic properties of the induced code, and\nhow they compare to human language. One fundamental characteristic of the\nlatter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words\nare efficiently associated to shorter strings. We study whether the same\npattern emerges when two neural networks, a \"speaker\" and a \"listener\", are\ntrained to play a signaling game. Surprisingly, we find that networks develop\nan \\emph{anti-efficient} encoding scheme, in which the most frequent inputs are\nassociated to the longest messages, and messages in general are skewed towards\nthe maximum length threshold. This anti-efficient code appears easier to\ndiscriminate for the listener, and, unlike in human communication, the speaker\ndoes not impose a contrasting least-effort pressure towards brevity. Indeed,\nwhen the cost function includes a penalty for longer messages, the resulting\nmessage distribution starts respecting ZLA. Our analysis stresses the\nimportance of studying the basic features of emergent communication in a highly\ncontrolled setup, to ensure the latter will not strand too far from human\nlanguage. Moreover, we present a concrete illustration of how different\nfunctional pressures can lead to successful communication codes that lack basic\nproperties of human language, thus highlighting the role such pressures play in\nthe latter.", "published": "2019-05-29 16:14:24", "link": "http://arxiv.org/abs/1905.12561v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Recursive Sketches for Modular Deep Learning", "abstract": "We present a mechanism to compute a sketch (succinct summary) of how a\ncomplex modular deep network processes its inputs. The sketch summarizes\nessential information about the inputs and outputs of the network and can be\nused to quickly identify key components and summary statistics of the inputs.\nFurthermore, the sketch is recursive and can be unrolled to identify\nsub-components of these components and so forth, capturing a potentially\ncomplicated DAG structure. These sketches erase gracefully; even if we erase a\nfraction of the sketch at random, the remainder still retains the `high-weight'\ninformation present in the original sketch. The sketches can also be organized\nin a repository to implicitly form a `knowledge graph'; it is possible to\nquickly retrieve sketches in the repository that are related to a sketch of\ninterest; arranged in this fashion, the sketches can also be used to learn\nemerging concepts by looking for new clusters in sketch space. Finally, in the\nscenario where we want to learn a ground truth deep network, we show that\naugmenting input/output pairs with these sketches can theoretically make it\neasier to do so.", "published": "2019-05-29 21:10:58", "link": "http://arxiv.org/abs/1905.12730v2", "categories": ["cs.LG", "cs.CL", "cs.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adapting Text Embeddings for Causal Inference", "abstract": "Does adding a theorem to a paper affect its chance of acceptance? Does\nlabeling a post with the author's gender affect the post popularity? This paper\ndevelops a method to estimate such causal effects from observational text data,\nadjusting for confounding features of the text such as the subject or writing\nquality. We assume that the text suffices for causal adjustment but that, in\npractice, it is prohibitively high-dimensional. To address this challenge, we\ndevelop causally sufficient embeddings, low-dimensional document\nrepresentations that preserve sufficient information for causal identification\nand allow for efficient estimation of causal effects. Causally sufficient\nembeddings combine two ideas. The first is supervised dimensionality reduction:\ncausal adjustment requires only the aspects of text that are predictive of both\nthe treatment and outcome. The second is efficient language modeling:\nrepresentations of text are designed to dispose of linguistically irrelevant\ninformation, and this information is also causally irrelevant. Our method\nadapts language models (specifically, word embeddings and topic models) to\nlearn document embeddings that are able to predict both treatment and outcome.\nWe study causally sufficient embeddings with semi-synthetic datasets and find\nthat they improve causal estimation over related embedding methods. We\nillustrate the methods by answering the two motivating questions---the effect\nof a theorem on paper acceptance and the effect of a gender label on post\npopularity. Code and data available at\nhttps://github.com/vveitch/causal-text-embeddings-tf2}{github.com/vveitch/causal-text-embeddings-tf2", "published": "2019-05-29 21:29:37", "link": "http://arxiv.org/abs/1905.12741v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Unsupervised Paraphrasing without Translation", "abstract": "Paraphrasing exemplifies the ability to abstract semantic content from\nsurface forms. Recent work on automatic paraphrasing is dominated by methods\nleveraging Machine Translation (MT) as an intermediate step. This contrasts\nwith humans, who can paraphrase without being bilingual. This work proposes to\nlearn paraphrasing models from an unlabeled monolingual corpus only. To that\nend, we propose a residual variant of vector-quantized variational\nauto-encoder.\n  We compare with MT-based approaches on paraphrase identification, generation,\nand training augmentation. Monolingual paraphrasing outperforms unsupervised\ntranslation in all settings. Comparisons with supervised translation are more\nmixed: monolingual paraphrasing is interesting for identification and\naugmentation; supervised translation is superior for generation.", "published": "2019-05-29 22:15:38", "link": "http://arxiv.org/abs/1905.12752v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Educating Text Autoencoders: Latent Representation Guidance via\n  Denoising", "abstract": "Generative autoencoders offer a promising approach for controllable text\ngeneration by leveraging their latent sentence representations. However,\ncurrent models struggle to maintain coherent latent spaces required to perform\nmeaningful text manipulations via latent vector operations. Specifically, we\ndemonstrate by example that neural encoders do not necessarily map similar\nsentences to nearby latent vectors. A theoretical explanation for this\nphenomenon establishes that high capacity autoencoders can learn an arbitrary\nmapping between sequences and associated latent representations. To remedy this\nissue, we augment adversarial autoencoders with a denoising objective where\noriginal sentences are reconstructed from perturbed versions (referred to as\nDAAE). We prove that this simple modification guides the latent space geometry\nof the resulting model by encouraging the encoder to map similar texts to\nsimilar latent representations. In empirical comparisons with various types of\nautoencoders, our model provides the best trade-off between generation quality\nand reconstruction capacity. Moreover, the improved geometry of the DAAE latent\nspace enables zero-shot text style transfer via simple latent vector\narithmetic.", "published": "2019-05-29 23:22:56", "link": "http://arxiv.org/abs/1905.12777v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Large Scale Question Paraphrase Retrieval with Smoothed Deep Metric\n  Learning", "abstract": "The goal of a Question Paraphrase Retrieval (QPR) system is to retrieve\nequivalent questions that result in the same answer as the original question.\nSuch a system can be used to understand and answer rare and noisy\nreformulations of common questions by mapping them to a set of canonical forms.\nThis has large-scale applications for community Question Answering (cQA) and\nopen-domain spoken language question answering systems. In this paper we\ndescribe a new QPR system implemented as a Neural Information Retrieval (NIR)\nsystem consisting of a neural network sentence encoder and an approximate\nk-Nearest Neighbour index for efficient vector retrieval. We also describe our\nmechanism to generate an annotated dataset for question paraphrase retrieval\nexperiments automatically from question-answer logs via distant supervision. We\nshow that the standard loss function in NIR, triplet loss, does not perform\nwell with noisy labels. We propose smoothed deep metric loss (SDML) and with\nour experiments on two QPR datasets we show that it significantly outperforms\ntriplet loss in the noisy label setting.", "published": "2019-05-29 23:40:54", "link": "http://arxiv.org/abs/1905.12786v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Generalized Framework of Sequence Generation with Application to\n  Undirected Sequence Models", "abstract": "Undirected neural sequence models such as BERT (Devlin et al., 2019) have\nreceived renewed interest due to their success on discriminative natural\nlanguage understanding tasks such as question-answering and natural language\ninference. The problem of generating sequences directly from these models has\nreceived relatively little attention, in part because generating from\nundirected models departs significantly from conventional monotonic generation\nin directed sequence models. We investigate this problem by proposing a\ngeneralized model of sequence generation that unifies decoding in directed and\nundirected models. The proposed framework models the process of generation\nrather than the resulting sequence, and under this framework, we derive various\nneural sequence models as special cases, such as autoregressive,\nsemi-autoregressive, and refinement-based non-autoregressive models. This\nunification enables us to adapt decoding algorithms originally developed for\ndirected sequence models to undirected sequence models. We demonstrate this by\nevaluating various handcrafted and learned decoding strategies on a BERT-like\nmachine translation model (Lample & Conneau, 2019). The proposed approach\nachieves constant-time translation results on par with linear-time translation\nresults from the same undirected sequence model, while both are competitive\nwith the state-of-the-art on WMT'14 English-German translation.", "published": "2019-05-29 23:47:17", "link": "http://arxiv.org/abs/1905.12790v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Regularization Advantages of Multilingual Neural Language Models for Low\n  Resource Domains", "abstract": "Neural language modeling (LM) has led to significant improvements in several\napplications, including Automatic Speech Recognition. However, they typically\nrequire large amounts of training data, which is not available for many domains\nand languages. In this study, we propose a multilingual neural language model\narchitecture, trained jointly on the domain-specific data of several\nlow-resource languages. The proposed multilingual LM consists of language\nspecific word embeddings in the encoder and decoder, and one language specific\nLSTM layer, plus two LSTM layers with shared parameters across the languages.\nThis multilingual LM model facilitates transfer learning across the languages,\nacting as an extra regularizer in very low-resource scenarios. We integrate our\nproposed multilingual approach with a state-of-the-art highly-regularized\nneural LM, and evaluate on the conversational data domain for four languages\nover a range of training data sizes. Compared to monolingual LMs, the results\nshow significant improvements of our proposed multilingual LM when the amount\nof available training data is limited, indicating the advantages of\ncross-lingual parameter sharing in very low-resource language modeling.", "published": "2019-05-29 13:27:11", "link": "http://arxiv.org/abs/1906.01496v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "TMLab SRPOL at SemEval-2019 Task 8: Fact Checking in Community Question\n  Answering Forums", "abstract": "The article describes our submission to SemEval 2019 Task 8 on Fact-Checking\nin Community Forums. The systems under discussion participated in Subtask A:\ndecide whether a question asks for factual information, opinion/advice or is\njust socializing. Our primary submission was ranked as the second one among all\nparticipants in the official evaluation phase. The article presents our primary\nsolution: Deeply Regularized Residual Neural Network (DRR NN) with Universal\nSentence Encoder embeddings. This is followed by a description of two\ncontrastive solutions based on ensemble methods.", "published": "2019-05-29 09:31:26", "link": "http://arxiv.org/abs/1906.01515v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Measuring the Effectiveness of Voice Conversion on Speaker\n  Identification and Automatic Speech Recognition Systems", "abstract": "This paper evaluates the effectiveness of a Cycle-GAN based voice converter\n(VC) on four speaker identification (SID) systems and an automated speech\nrecognition (ASR) system for various purposes. Audio samples converted by the\nVC model are classified by the SID systems as the intended target at up to 46%\ntop-1 accuracy among more than 250 speakers. This encouraging result in\nimitating the target styles led us to investigate if converted (synthetic)\nsamples can be used to improve ASR training. Unfortunately, adding synthetic\ndata to the ASR training set only marginally improves word and character error\nrates. Our results indicate that even though VC models can successfully mimic\nthe style of target speakers as measured by SID systems, improving ASR training\nwith synthetic data from VC systems needs further research to establish its\nefficacy.", "published": "2019-05-29 15:28:35", "link": "http://arxiv.org/abs/1905.12531v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A new definition of the distortion matrix for an audio-to-score\n  alignment system", "abstract": "In this paper we present a new definition of the distortion matrix for a\nscore following framework based on DTW. The proposal consists of arranging the\nscore information in a sequence of note combinations and learning a spectral\npattern for each combination using instrument models. Then, the distortion\nmatrix is computed using these spectral patterns and a novel decomposition of\nthe input signal.", "published": "2019-05-29 11:02:02", "link": "http://arxiv.org/abs/1905.12324v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep-Learning-Based Audio-Visual Speech Enhancement in Presence of\n  Lombard Effect", "abstract": "When speaking in presence of background noise, humans reflexively change\ntheir way of speaking in order to improve the intelligibility of their speech.\nThis reflex is known as Lombard effect. Collecting speech in Lombard conditions\nis usually hard and costly. For this reason, speech enhancement systems are\ngenerally trained and evaluated on speech recorded in quiet to which noise is\nartificially added. Since these systems are often used in situations where\nLombard speech occurs, in this work we perform an analysis of the impact that\nLombard effect has on audio, visual and audio-visual speech enhancement,\nfocusing on deep-learning-based systems, since they represent the current state\nof the art in the field.\n  We conduct several experiments using an audio-visual Lombard speech corpus\nconsisting of utterances spoken by 54 different talkers. The results show that\ntraining deep-learning-based models with Lombard speech is beneficial in terms\nof both estimated speech quality and estimated speech intelligibility at low\nsignal to noise ratios, where the visual modality can play an important role in\nacoustically challenging situations. We also find that a performance difference\nbetween genders exists due to the distinct Lombard speech exhibited by males\nand females, and we analyse it in relation with acoustic and visual features.\nFurthermore, listening tests conducted with audio-visual stimuli show that the\nspeech quality of the signals processed with systems trained using Lombard\nspeech is statistically significantly better than the one obtained using\nsystems trained with non-Lombard speech at a signal to noise ratio of -5 dB.\nRegarding speech intelligibility, we find a general tendency of the benefit in\ntraining the systems with Lombard speech.", "published": "2019-05-29 17:37:41", "link": "http://arxiv.org/abs/1905.12605v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "A New Multilabel System for Automatic Music Emotion Recognition", "abstract": "Achieving advancements in automatic recognition of emotions that music can\ninduce require considering multiplicity and simultaneity of emotions.\nComparison of different machine learning algorithms performing multilabel and\nmulticlass classification is the core of our work. The study analyzes the\nimplementation of the Geneva Emotional Music Scale 9 in the Emotify music\ndataset and investigates its adoption from a machine-learning perspective. We\napproach the scenario of emotions expression/induction through music as a\nmultilabel and multiclass problem, where multiple emotion labels can be adopted\nfor the same music track by each annotator (multilabel), and each emotion can\nbe identified or not in the music (multiclass). The aim is the automatic\nrecognition of induced emotions through music.", "published": "2019-05-29 09:33:20", "link": "http://arxiv.org/abs/1905.12629v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
