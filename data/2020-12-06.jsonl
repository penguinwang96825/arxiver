{"title": "A Two-Systems Perspective for Computational Thinking", "abstract": "Computational Thinking (CT) has emerged as one of the vital thinking skills\nin recent times, especially for Science, Technology, Engineering and Management\n(STEM) graduates. Educators are in search of underlying cognitive models\nagainst which CT can be analyzed and evaluated. This paper suggests adopting\nKahneman's two-systems model as a framework to understand the computational\nthought process. Kahneman's two-systems model postulates that human thinking\nhappens at two levels, i.e. fast and slow thinking. This paper illustrates\nthrough examples that CT activities can be represented and analyzed using\nKahneman's two-systems model. The potential benefits of adopting Kahneman's\ntwo-systems perspective are that it helps us to fix the biases that cause\nerrors in our reasoning. Further, it also provides a set of heuristics to speed\nup reasoning activities.", "published": "2020-12-06 07:33:45", "link": "http://arxiv.org/abs/2012.03201v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Competition in Cross-situational Word Learning: A Computational Study", "abstract": "Children learn word meanings by tapping into the commonalities across\ndifferent situations in which words are used and overcome the high level of\nuncertainty involved in early word learning experiences. We propose a modeling\nframework to investigate the role of mutual exclusivity bias - asserting\none-to-one mappings between words and their meanings - in reducing uncertainty\nin word learning. In a set of computational studies, we show that to\nsuccessfully learn word meanings in the face of uncertainty, a learner needs to\nuse two types of competition: words competing for association to a referent\nwhen learning from an observation and referents competing for a word when the\nword is used. Our work highlights the importance of an algorithmic-level\nanalysis to shed light on the utility of different mechanisms that can\nimplement the same computational-level theory.", "published": "2020-12-06 20:32:56", "link": "http://arxiv.org/abs/2012.03370v2", "categories": ["cs.CL", "cs.LG", "68T50, 91F20, 68T05", "I.2.7; I.2.6; G.3; J.4"], "primary_category": "cs.CL"}
{"title": "Multi-task Learning Based Spoofing-Robust Automatic Speaker Verification\n  System", "abstract": "Spoofing attacks posed by generating artificial speech can severely degrade\nthe performance of a speaker verification system. Recently, many anti-spoofing\ncountermeasures have been proposed for detecting varying types of attacks from\nsynthetic speech to replay presentations. While there are numerous effective\ndefenses reported on standalone anti-spoofing solutions, the integration for\nspeaker verification and spoofing detection systems has obvious benefits. In\nthis paper, we propose a spoofing-robust automatic speaker verification\n(SR-ASV) system for diverse attacks based on a multi-task learning\narchitecture. This deep learning based model is jointly trained with\ntime-frequency representations from utterances to provide recognition decisions\nfor both tasks simultaneously. Compared with other state-of-the-art systems on\nthe ASVspoof 2017 and 2019 corpora, a substantial improvement of the combined\nsystem under different spoofing conditions can be obtained.", "published": "2020-12-06 01:03:35", "link": "http://arxiv.org/abs/2012.03154v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Guitar Effects Recognition and Parameter Estimation with Convolutional\n  Neural Networks", "abstract": "Despite the popularity of guitar effects, there is very little existing\nresearch on classification and parameter estimation of specific plugins or\neffect units from guitar recordings. In this paper, convolutional neural\nnetworks were used for classification and parameter estimation for 13\noverdrive, distortion and fuzz guitar effects. A novel dataset of processed\nelectric guitar samples was assembled, with four sub-datasets consisting of\nmonophonic or polyphonic samples and discrete or continuous settings values,\nfor a total of about 250 hours of processed samples. Results were compared for\nnetworks trained and tested on the same or on a different sub-dataset. We found\nthat discrete datasets could lead to equally high performance as continuous\nones, whilst being easier to design, analyse and modify. Classification\naccuracy was above 80\\%, with confusion matrices reflecting similarities in the\neffects timbre and circuits design. With parameter values between 0.0 and 1.0,\nthe mean absolute error is in most cases below 0.05, while the root mean square\nerror is below 0.1 in all cases but one.", "published": "2020-12-06 08:46:18", "link": "http://arxiv.org/abs/2012.03216v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Source Separation and Depthwise Separable Convolutions for Computer\n  Audition", "abstract": "Given recent advances in deep music source separation, we propose a feature\nrepresentation method that combines source separation with a state-of-the-art\nrepresentation learning technique that is suitably repurposed for computer\naudition (i.e. machine listening). We train a depthwise separable convolutional\nneural network on a challenging electronic dance music (EDM) data set and\ncompare its performance to convolutional neural networks operating on both\nsource separated and standard spectrograms. It is shown that source separation\nimproves classification performance in a limited-data setting compared to the\nstandard single spectrogram approach.", "published": "2020-12-06 19:30:26", "link": "http://arxiv.org/abs/2012.03359v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
