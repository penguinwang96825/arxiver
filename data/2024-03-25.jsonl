{"title": "Is There a One-Model-Fits-All Approach to Information Extraction?\n  Revisiting Task Definition Biases", "abstract": "Definition bias is a negative phenomenon that can mislead models. Definition\nbias in information extraction appears not only across datasets from different\ndomains but also within datasets sharing the same domain. We identify two types\nof definition bias in IE: bias among information extraction datasets and bias\nbetween information extraction datasets and instruction tuning datasets. To\nsystematically investigate definition bias, we conduct three probing\nexperiments to quantitatively analyze it and discover the limitations of\nunified information extraction and large language models in solving definition\nbias. To mitigate definition bias in information extraction, we propose a\nmulti-stage framework consisting of definition bias measurement, bias-aware\nfine-tuning, and task-specific bias mitigation. Experimental results\ndemonstrate the effectiveness of our framework in addressing definition bias.\nResources of this paper can be found at\nhttps://github.com/EZ-hwh/definition-bias", "published": "2024-03-25 03:19:20", "link": "http://arxiv.org/abs/2403.16396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KIT-19: A Comprehensive Korean Instruction Toolkit on 19 Tasks for\n  Fine-Tuning Korean Large Language Models", "abstract": "Instruction Tuning on Large Language Models is an essential process for model\nto function well and achieve high performance in specific tasks. Accordingly,\nin mainstream languages such as English, instruction-based datasets are being\nconstructed and made publicly available. In the case of Korean, publicly\navailable models and datasets all rely on using the output of ChatGPT or\ntranslating datasets built in English. In this paper, We introduce\n\\textit{KIT-19} as an instruction dataset for the development of LLM in Korean.\n\\textit{KIT-19} is a dataset created in an instruction format, comprising 19\nexisting open-source datasets for Korean NLP tasks. In this paper, we train a\nKorean Pretrained LLM using \\textit{KIT-19} to demonstrate its effectiveness.\nThe experimental results show that the model trained on \\textit{KIT-19}\nsignificantly outperforms existing Korean LLMs. Based on the its quality and\nempirical results, this paper proposes that \\textit{KIT-19} has the potential\nto make a substantial contribution to the future improvement of Korean LLMs'\nperformance.", "published": "2024-03-25 06:15:21", "link": "http://arxiv.org/abs/2403.16444v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric,\n  Data, and Algorithm", "abstract": "Large language models (LLMs) are gaining increasing interests to improve\nclinical efficiency for medical diagnosis, owing to their unprecedented\nperformance in modelling natural language. Ensuring the safe and reliable\nclinical applications, the evaluation of LLMs indeed becomes critical for\nbetter mitigating the potential risks, e.g., hallucinations. However, current\nevaluation methods heavily rely on labor-intensive human participation to\nachieve human-preferred judgements. To overcome this challenge, we propose an\nautomatic evaluation paradigm tailored to assess the LLMs' capabilities in\ndelivering clinical services, e.g., disease diagnosis and treatment. The\nevaluation paradigm contains three basic elements: metric, data, and algorithm.\nSpecifically, inspired by professional clinical practice pathways, we formulate\na LLM-specific clinical pathway (LCP) to define the clinical capabilities that\na doctor agent should possess. Then, Standardized Patients (SPs) from the\nmedical education are introduced as the guideline for collecting medical data\nfor evaluation, which can well ensure the completeness of the evaluation\nprocedure. Leveraging these steps, we develop a multi-agent framework to\nsimulate the interactive environment between SPs and a doctor agent, which is\nequipped with a Retrieval-Augmented Evaluation (RAE) to determine whether the\nbehaviors of a doctor agent are in accordance with LCP. The above paradigm can\nbe extended to any similar clinical scenarios to automatically evaluate the\nLLMs' medical capabilities. Applying such paradigm, we construct an evaluation\nbenchmark in the field of urology, including a LCP, a SPs dataset, and an\nautomated RAE. Extensive experiments are conducted to demonstrate the\neffectiveness of the proposed approach, providing more insights for LLMs' safe\nand reliable deployments in clinical practice.", "published": "2024-03-25 06:17:54", "link": "http://arxiv.org/abs/2403.16446v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Study on How Attention Scores in the BERT Model are Aware of Lexical\n  Categories in Syntactic and Semantic Tasks on the GLUE Benchmark", "abstract": "This study examines whether the attention scores between tokens in the BERT\nmodel significantly vary based on lexical categories during the fine-tuning\nprocess for downstream tasks. Drawing inspiration from the notion that in human\nlanguage processing, syntactic and semantic information is parsed differently,\nwe categorize tokens in sentences according to their lexical categories and\nfocus on changes in attention scores among these categories. Our hypothesis\nposits that in downstream tasks that prioritize semantic information, attention\nscores centered on content words are enhanced, while in cases emphasizing\nsyntactic information, attention scores centered on function words are\nintensified. Through experimentation conducted on six tasks from the GLUE\nbenchmark dataset, we substantiate our hypothesis regarding the fine-tuning\nprocess. Furthermore, our additional investigations reveal the presence of BERT\nlayers that consistently assign more bias to specific lexical categories,\nirrespective of the task, highlighting the existence of task-agnostic lexical\ncategory preferences.", "published": "2024-03-25 06:18:18", "link": "http://arxiv.org/abs/2403.16447v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Named Entity Recognition via Superposition Concept\n  Discrimination", "abstract": "Few-shot NER aims to identify entities of target types with only limited\nnumber of illustrative instances. Unfortunately, few-shot NER is severely\nchallenged by the intrinsic precise generalization problem, i.e., it is hard to\naccurately determine the desired target type due to the ambiguity stemming from\ninformation deficiency. In this paper, we propose Superposition Concept\nDiscriminator (SuperCD), which resolves the above challenge via an active\nlearning paradigm. Specifically, a concept extractor is first introduced to\nidentify superposition concepts from illustrative instances, with each concept\ncorresponding to a possible generalization boundary. Then a superposition\ninstance retriever is applied to retrieve corresponding instances of these\nsuperposition concepts from large-scale text corpus. Finally, annotators are\nasked to annotate the retrieved instances and these annotated instances\ntogether with original illustrative instances are used to learn FS-NER models.\nTo this end, we learn a universal concept extractor and superposition instance\nretriever using a large-scale openly available knowledge bases. Experiments\nshow that SuperCD can effectively identify superposition concepts from\nillustrative instances, retrieve superposition instances from large-scale\ncorpus, and significantly improve the few-shot NER performance with minimal\nadditional efforts.", "published": "2024-03-25 06:45:09", "link": "http://arxiv.org/abs/2403.16463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Construction of a Large-Scale Corpus for Geoparsing Using\n  Wikipedia Hyperlinks", "abstract": "Geoparsing is the task of estimating the latitude and longitude (coordinates)\nof location expressions in texts. Geoparsing must deal with the ambiguity of\nthe expressions that indicate multiple locations with the same notation. For\nevaluating geoparsing systems, several corpora have been proposed in previous\nwork. However, these corpora are small-scale and suffer from the coverage of\nlocation expressions on general domains. In this paper, we propose Wikipedia\nHyperlink-based Location Linking (WHLL), a novel method to construct a\nlarge-scale corpus for geoparsing from Wikipedia articles. WHLL leverages\nhyperlinks in Wikipedia to annotate multiple location expressions with\ncoordinates. With this method, we constructed the WHLL corpus, a new\nlarge-scale corpus for geoparsing. The WHLL corpus consists of 1.3M articles,\neach containing about 7.8 unique location expressions. 45.6% of location\nexpressions are ambiguous and refer to more than one location with the same\nnotation. In each article, location expressions of the article title and those\nhyperlinks to other articles are assigned with coordinates. By utilizing\nhyperlinks, we can accurately assign location expressions with coordinates even\nwith ambiguous location expressions in the texts. Experimental results show\nthat there remains room for improvement by disambiguating location expressions.", "published": "2024-03-25 07:08:13", "link": "http://arxiv.org/abs/2403.16483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models (or Humans) Disentangle Text?", "abstract": "We investigate the potential of large language models (LLMs) to disentangle\ntext variables--to remove the textual traces of an undesired forbidden variable\nin a task sometimes known as text distillation and closely related to the\nfairness in AI and causal inference literature. We employ a range of various\nLLM approaches in an attempt to disentangle text by identifying and removing\ninformation about a target variable while preserving other relevant signals. We\nshow that in the strong test of removing sentiment, the statistical association\nbetween the processed text and sentiment is still detectable to machine\nlearning classifiers post-LLM-disentanglement. Furthermore, we find that human\nannotators also struggle to disentangle sentiment while preserving other\nsemantic content. This suggests there may be limited separability between\nconcept variables in some text contexts, highlighting limitations of methods\nrelying on text-level transformations and also raising questions about the\nrobustness of disentanglement methods that achieve statistical independence in\nrepresentation space.", "published": "2024-03-25 09:51:54", "link": "http://arxiv.org/abs/2403.16584v2", "categories": ["cs.CL", "68T50", "I.2.7; H.1.2"], "primary_category": "cs.CL"}
{"title": "TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain\n  Machine Generated Text Detection Techniques", "abstract": "The Large Language Models (LLMs) exhibit remarkable ability to generate\nfluent content across a wide spectrum of user queries. However, this capability\nhas raised concerns regarding misinformation and personal information leakage.\nIn this paper, we present our methods for the SemEval2024 Task8, aiming to\ndetect machine-generated text across various domains in both mono-lingual and\nmulti-lingual contexts. Our study comprehensively analyzes various methods to\ndetect machine-generated text, including statistical, neural, and pre-trained\nmodel approaches. We also detail our experimental setup and perform a in-depth\nerror analysis to evaluate the effectiveness of these methods. Our methods\nobtain an accuracy of 86.9\\% on the test set of subtask-A mono and 83.7\\% for\nsubtask-B. Furthermore, we also highlight the challenges and essential factors\nfor consideration in future studies.", "published": "2024-03-25 10:09:03", "link": "http://arxiv.org/abs/2403.16592v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Conversational Grounding: Annotation and Analysis of Grounding Acts and\n  Grounding Units", "abstract": "Successful conversations often rest on common understanding, where all\nparties are on the same page about the information being shared. This process,\nknown as conversational grounding, is crucial for building trustworthy dialog\nsystems that can accurately keep track of and recall the shared information.\nThe proficiencies of an agent in grounding the conveyed information\nsignificantly contribute to building a reliable dialog system. Despite recent\nadvancements in dialog systems, there exists a noticeable deficit in their\ngrounding capabilities. Traum provided a framework for conversational grounding\nintroducing Grounding Acts and Grounding Units, but substantial progress,\nespecially in the realm of Large Language Models, remains lacking. To bridge\nthis gap, we present the annotation of two dialog corpora employing Grounding\nActs, Grounding Units, and a measure of their degree of grounding. We discuss\nour key findings during the annotation and also provide a baseline model to\ntest the performance of current Language Models in categorizing the grounding\nacts of the dialogs. Our work aims to provide a useful resource for further\nresearch in making conversations with machines better understood and more\nreliable in natural day-to-day collaborative dialogs.", "published": "2024-03-25 10:39:18", "link": "http://arxiv.org/abs/2403.16609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically Enriched Cross-Lingual Sentence Embeddings for\n  Crisis-related Social Media Texts", "abstract": "Tasks such as semantic search and clustering on crisis-related social media\ntexts enhance our comprehension of crisis discourse, aiding decision-making and\ntargeted interventions. Pre-trained language models have advanced performance\nin crisis informatics, but their contextual embeddings lack semantic\nmeaningfulness. Although the CrisisTransformers family includes a sentence\nencoder to address the semanticity issue, it remains monolingual, processing\nonly English texts. Furthermore, employing separate models for different\nlanguages leads to embeddings in distinct vector spaces, introducing challenges\nwhen comparing semantic similarities between multi-lingual texts. Therefore, we\npropose multi-lingual sentence encoders (CT-XLMR-SE and CT-mBERT-SE) that embed\ncrisis-related social media texts for over 50 languages, such that texts with\nsimilar meanings are in close proximity within the same vector space,\nirrespective of language diversity. Results in sentence encoding and sentence\nmatching tasks are promising, suggesting these models could serve as robust\nbaselines when embedding multi-lingual crisis-related social media texts. The\nmodels are publicly available at: https://huggingface.co/crisistransformers.", "published": "2024-03-25 10:44:38", "link": "http://arxiv.org/abs/2403.16614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grammatical vs Spelling Error Correction: An Investigation into the\n  Responsiveness of Transformer-based Language Models using BART and MarianMT", "abstract": "Text continues to remain a relevant form of representation for information.\nText documents are created either in digital native platforms or through the\nconversion of other media files such as images and speech. While the digital\nnative text is invariably obtained through physical or virtual keyboards,\ntechnologies such as OCR and speech recognition are utilized to transform the\nimages and speech signals into text content. All these variety of mechanisms of\ntext generation also introduce errors into the captured text.\n  This project aims at analyzing different kinds of error that occurs in text\ndocuments. The work employs two of the advanced deep neural network-based\nlanguage models, namely, BART and MarianMT, to rectify the anomalies present in\nthe text. Transfer learning of these models with available dataset is performed\nto finetune their capacity for error correction. A comparative study is\nconducted to investigate the effectiveness of these models in handling each of\nthe defined error categories. It is observed that while both models can bring\ndown the erroneous sentences by 20+%, BART can handle spelling errors far\nbetter (24.6%) than grammatical errors (8.8%).", "published": "2024-03-25 11:45:21", "link": "http://arxiv.org/abs/2403.16655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking\n  on Russia-Ukraine Conflict", "abstract": "Fact-checking is the task of verifying the factuality of a given claim by\nexamining the available evidence. High-quality evidence plays a vital role in\nenhancing fact-checking systems and facilitating the generation of explanations\nthat are understandable to humans. However, the provision of both sufficient\nand relevant evidence for explainable fact-checking systems poses a challenge.\nTo tackle this challenge, we propose a method based on a Large Language Model\nto automatically retrieve and summarize evidence from the Web. Furthermore, we\nconstruct RU22Fact, a novel multilingual explainable fact-checking dataset on\nthe Russia-Ukraine conflict in 2022 of 16K samples, each containing real-world\nclaims, optimized evidence, and referenced explanation. To establish a baseline\nfor our dataset, we also develop an end-to-end explainable fact-checking system\nto verify claims and generate explanations. Experimental results demonstrate\nthe prospect of optimized evidence in increasing fact-checking performance and\nalso indicate the possibility of further progress in the end-to-end claim\nverification and explanation generation tasks.", "published": "2024-03-25 11:56:29", "link": "http://arxiv.org/abs/2403.16662v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Machine Translation Bridge Multilingual Pretraining and\n  Cross-lingual Transfer Learning?", "abstract": "Multilingual pretraining and fine-tuning have remarkably succeeded in various\nnatural language processing tasks. Transferring representations from one\nlanguage to another is especially crucial for cross-lingual learning. One can\nexpect machine translation objectives to be well suited to fostering such\ncapabilities, as they involve the explicit alignment of semantically equivalent\nsentences from different languages. This paper investigates the potential\nbenefits of employing machine translation as a continued training objective to\nenhance language representation learning, bridging multilingual pretraining and\ncross-lingual applications. We study this question through two lenses: a\nquantitative evaluation of the performance of existing models and an analysis\nof their latent representations. Our results show that, contrary to\nexpectations, machine translation as the continued training fails to enhance\ncross-lingual representation learning in multiple cross-lingual natural\nlanguage understanding tasks. We conclude that explicit sentence-level\nalignment in the cross-lingual scenario is detrimental to cross-lingual\ntransfer pretraining, which has important implications for future cross-lingual\ntransfer studies. We furthermore provide evidence through similarity measures\nand investigation of parameters that this lack of positive influence is due to\noutput separability -- which we argue is of use for machine translation but\ndetrimental elsewhere.", "published": "2024-03-25 13:53:04", "link": "http://arxiv.org/abs/2403.16777v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TEI2GO: A Multilingual Approach for Fast Temporal Expression\n  Identification", "abstract": "Temporal expression identification is crucial for understanding texts written\nin natural language. Although highly effective systems such as HeidelTime\nexist, their limited runtime performance hampers adoption in large-scale\napplications and production environments. In this paper, we introduce the\nTEI2GO models, matching HeidelTime's effectiveness but with significantly\nimproved runtime, supporting six languages, and achieving state-of-the-art\nresults in four of them. To train the TEI2GO models, we used a combination of\nmanually annotated reference corpus and developed ``Professor HeidelTime'', a\ncomprehensive weakly labeled corpus of news texts annotated with HeidelTime.\nThis corpus comprises a total of $138,069$ documents (over six languages) with\n$1,050,921$ temporal expressions, the largest open-source annotated dataset for\ntemporal expression identification to date. By describing how the models were\nproduced, we aim to encourage the research community to further explore,\nrefine, and extend the set of models to additional languages and domains. Code,\nannotations, and models are openly available for community exploration and use.\nThe models are conveniently on HuggingFace for seamless integration and\napplication.", "published": "2024-03-25 14:23:03", "link": "http://arxiv.org/abs/2403.16804v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Contextualized Phrase Retrieval", "abstract": "Phrase-level dense retrieval has shown many appealing characteristics in\ndownstream NLP tasks by leveraging the fine-grained information that phrases\noffer. In our work, we propose a new task formulation of dense retrieval,\ncross-lingual contextualized phrase retrieval, which aims to augment\ncross-lingual applications by addressing polysemy using context information.\nHowever, the lack of specific training data and models are the primary\nchallenges to achieve our goal. As a result, we extract pairs of cross-lingual\nphrases using word alignment information automatically induced from parallel\nsentences. Subsequently, we train our Cross-lingual Contextualized Phrase\nRetriever (CCPR) using contrastive learning, which encourages the hidden\nrepresentations of phrases with similar contexts and semantics to align\nclosely. Comprehensive experiments on both the cross-lingual phrase retrieval\ntask and a downstream task, i.e, machine translation, demonstrate the\neffectiveness of CCPR. On the phrase retrieval task, CCPR surpasses baselines\nby a significant margin, achieving a top-1 accuracy that is at least 13 points\nhigher. When utilizing CCPR to augment the large-language-model-based\ntranslator, it achieves average gains of 0.7 and 1.5 in BERTScore for\ntranslations from X=>En and vice versa, respectively, on WMT16 dataset. Our\ncode and data are available at \\url{https://github.com/ghrua/ccpr_release}.", "published": "2024-03-25 14:46:51", "link": "http://arxiv.org/abs/2403.16820v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Intent Discovery with Attracting and Dispersing Prototype", "abstract": "New Intent Discovery (NID) aims to recognize known and infer new intent\ncategories with the help of limited labeled and large-scale unlabeled data. The\ntask is addressed as a feature-clustering problem and recent studies augment\ninstance representation. However, existing methods fail to capture\ncluster-friendly representations, since they show less capability to\neffectively control and coordinate within-cluster and between-cluster\ndistances. Tailored to the NID problem, we propose a Robust and Adaptive\nPrototypical learning (RAP) framework for globally distinct decision boundaries\nfor both known and new intent categories. Specifically, a robust prototypical\nattracting learning (RPAL) method is designed to compel instances to gravitate\ntoward their corresponding prototype, achieving greater within-cluster\ncompactness. To attain larger between-cluster separation, another adaptive\nprototypical dispersing learning (APDL) method is devised to maximize the\nbetween-cluster distance from the prototype-to-prototype perspective.\nExperimental results evaluated on three challenging benchmarks (CLINC, BANKING,\nand StackOverflow) of our method with better cluster-friendly representation\ndemonstrate that RAP brings in substantial improvements over the current\nstate-of-the-art methods (even large language model) by a large margin (average\n+5.5% improvement).", "published": "2024-03-25 16:31:55", "link": "http://arxiv.org/abs/2403.16913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Shortest Edit Script Methods for Contextual Lemmatization", "abstract": "Modern contextual lemmatizers often rely on automatically induced Shortest\nEdit Scripts (SES), namely, the number of edit operations to transform a word\nform into its lemma. In fact, different methods of computing SES have been\nproposed as an integral component in the architecture of several\nstate-of-the-art contextual lemmatizers currently available. However, previous\nwork has not investigated the direct impact of SES in the final lemmatization\nperformance. In this paper we address this issue by focusing on lemmatization\nas a token classification task where the only input that the model receives is\nthe word-label pairs in context, where the labels correspond to previously\ninduced SES. Thus, by modifying in our lemmatization system only the SES labels\nthat the model needs to learn, we may then objectively conclude which SES\nrepresentation produces the best lemmatization results. We experiment with\nseven languages of different morphological complexity, namely, English,\nSpanish, Basque, Russian, Czech, Turkish and Polish, using multilingual and\nlanguage-specific pre-trained masked language encoder-only models as a backbone\nto build our lemmatizers. Comprehensive experimental results, both in- and\nout-of-domain, indicate that computing the casing and edit operations\nseparately is beneficial overall, but much more clearly for languages with\nhigh-inflected morphology. Notably, multilingual pre-trained language models\nconsistently outperform their language-specific counterparts in every\nevaluation setting.", "published": "2024-03-25 17:28:24", "link": "http://arxiv.org/abs/2403.16968v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A comparison of Human, GPT-3.5, and GPT-4 Performance in a\n  University-Level Coding Course", "abstract": "This study evaluates the performance of ChatGPT variants, GPT-3.5 and GPT-4,\nboth with and without prompt engineering, against solely student work and a\nmixed category containing both student and GPT-4 contributions in\nuniversity-level physics coding assignments using the Python language.\nComparing 50 student submissions to 50 AI-generated submissions across\ndifferent categories, and marked blindly by three independent markers, we\namassed $n = 300$ data points. Students averaged 91.9% (SE:0.4), surpassing the\nhighest performing AI submission category, GPT-4 with prompt engineering, which\nscored 81.1% (SE:0.8) - a statistically significant difference (p = $2.482\n\\times 10^{-10}$). Prompt engineering significantly improved scores for both\nGPT-4 (p = $1.661 \\times 10^{-4}$) and GPT-3.5 (p = $4.967 \\times 10^{-9}$).\nAdditionally, the blinded markers were tasked with guessing the authorship of\nthe submissions on a four-point Likert scale from `Definitely AI' to\n`Definitely Human'. They accurately identified the authorship, with 92.1% of\nthe work categorized as 'Definitely Human' being human-authored. Simplifying\nthis to a binary `AI' or `Human' categorization resulted in an average accuracy\nrate of 85.3%. These findings suggest that while AI-generated work closely\napproaches the quality of university students' work, it often remains\ndetectable by human evaluators.", "published": "2024-03-25 17:41:02", "link": "http://arxiv.org/abs/2403.16977v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attribute First, then Generate: Locally-attributable Grounded Text\n  Generation", "abstract": "Recent efforts to address hallucinations in Large Language Models (LLMs) have\nfocused on attributed text generation, which supplements generated texts with\ncitations of supporting sources for post-generation fact-checking and\ncorrections. Yet, these citations often point to entire documents or\nparagraphs, burdening users with extensive verification work. In this paper, we\nintroduce a locally-attributable text generation approach, prioritizing concise\nattributions. Our method, named \"Attribute First, then Generate\", breaks down\nthe conventional end-to-end generation process into three intuitive steps:\ncontent selection, sentence planning, and sequential sentence generation. By\ninitially identifying relevant source segments (\"select first\") and then\nconditioning the generation process on them (\"then generate\"), we ensure these\nsegments also act as the output's fine-grained attributions (\"select\" becomes\n\"attribute\"). Tested on Multi-document Summarization and Long-form\nQuestion-answering, our method not only yields more concise citations than the\nbaselines but also maintains - and in some cases enhances - both generation\nquality and attribution accuracy. Furthermore, it significantly reduces the\ntime required for fact verification by human assessors.", "published": "2024-03-25 18:41:47", "link": "http://arxiv.org/abs/2403.17104v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Outcome-Constrained Large Language Models for Countering Hate Speech", "abstract": "Automatic counterspeech generation methods have been developed to assist\nefforts in combating hate speech. Existing research focuses on generating\ncounterspeech with linguistic attributes such as being polite, informative, and\nintent-driven. However, the real impact of counterspeech in online environments\nis seldom considered. This study aims to develop methods for generating\ncounterspeech constrained by conversation outcomes and evaluate their\neffectiveness. We experiment with large language models (LLMs) to incorporate\ninto the text generation process two desired conversation outcomes: low\nconversation incivility and non-hateful hater reentry. Specifically, we\nexperiment with instruction prompts, LLM finetuning, and LLM reinforcement\nlearning (RL). Evaluation results show that our methods effectively steer the\ngeneration of counterspeech toward the desired outcomes. Our analyses, however,\nshow that there are differences in the quality and style depending on the\nmodel.", "published": "2024-03-25 19:44:06", "link": "http://arxiv.org/abs/2403.17146v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reflecting the Male Gaze: Quantifying Female Objectification in 19th and\n  20th Century Novels", "abstract": "Inspired by the concept of the male gaze (Mulvey, 1975) in literature and\nmedia studies, this paper proposes a framework for analyzing gender bias in\nterms of female objectification: the extent to which a text portrays female\nindividuals as objects of visual pleasure. Our framework measures female\nobjectification along two axes. First, we compute an agency bias score that\nindicates whether male entities are more likely to appear in the text as\ngrammatical agents than female entities. Next, by analyzing the word embedding\nspace induced by a text (Caliskan et al., 2017), we compute an appearance bias\nscore that indicates whether female entities are more closely associated with\nappearance-related words than male entities. Applying our framework to 19th and\n20th century novels reveals evidence of female objectification in literature:\nwe find that novels written from a male perspective systematically objectify\nfemale characters, while novels written from a female perspective do not\nexhibit statistically significant objectification of any gender.", "published": "2024-03-25 20:16:14", "link": "http://arxiv.org/abs/2403.17158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Understanding in GPT-4 vs Humans", "abstract": "We examine whether a leading AI system GPT4 understands text as well as\nhumans do, first using a well-established standardized test of discourse\ncomprehension. On this test, GPT4 performs slightly, but not statistically\nsignificantly, better than humans given the very high level of human\nperformance. Both GPT4 and humans make correct inferences about information\nthat is not explicitly stated in the text, a critical test of understanding.\nNext, we use more difficult passages to determine whether that could allow\nlarger differences between GPT4 and humans. GPT4 does considerably better on\nthis more difficult text than do the high school and university students for\nwhom these the text passages are designed, as admission tests of student\nreading comprehension. Deeper exploration of GPT4 performance on material from\none of these admission tests reveals generally accepted signatures of genuine\nunderstanding, namely generalization and inference.", "published": "2024-03-25 21:17:14", "link": "http://arxiv.org/abs/2403.17196v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Social Support and Social Isolation Information from Clinical\n  Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language\n  Model", "abstract": "Background: Social support (SS) and social isolation (SI) are social\ndeterminants of health (SDOH) associated with psychiatric outcomes. In\nelectronic health records (EHRs), individual-level SS/SI is typically\ndocumented as narrative clinical notes rather than structured coded data.\nNatural language processing (NLP) algorithms can automate the otherwise\nlabor-intensive process of data extraction.\n  Data and Methods: Psychiatric encounter notes from Mount Sinai Health System\n(MSHS, n=300) and Weill Cornell Medicine (WCM, n=225) were annotated and\nestablished a gold standard corpus. A rule-based system (RBS) involving\nlexicons and a large language model (LLM) using FLAN-T5-XL were developed to\nidentify mentions of SS and SI and their subcategories (e.g., social network,\ninstrumental support, and loneliness).\n  Results: For extracting SS/SI, the RBS obtained higher macro-averaged\nf-scores than the LLM at both MSHS (0.89 vs. 0.65) and WCM (0.85 vs. 0.82). For\nextracting subcategories, the RBS also outperformed the LLM at both MSHS (0.90\nvs. 0.62) and WCM (0.82 vs. 0.81).\n  Discussion and Conclusion: Unexpectedly, the RBS outperformed the LLMs across\nall metrics. Intensive review demonstrates that this finding is due to the\ndivergent approach taken by the RBS and LLM. The RBS were designed and refined\nto follow the same specific rules as the gold standard annotations. Conversely,\nthe LLM were more inclusive with categorization and conformed to common\nEnglish-language understanding. Both approaches offer advantages and are made\navailable open-source for future testing.", "published": "2024-03-25 21:19:50", "link": "http://arxiv.org/abs/2403.17199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ontology Completion with Natural Language Inference and Concept\n  Embeddings: An Analysis", "abstract": "We consider the problem of finding plausible knowledge that is missing from a\ngiven ontology, as a generalisation of the well-studied taxonomy expansion\ntask. One line of work treats this task as a Natural Language Inference (NLI)\nproblem, thus relying on the knowledge captured by language models to identify\nthe missing knowledge. Another line of work uses concept embeddings to identify\nwhat different concepts have in common, taking inspiration from cognitive\nmodels for category based induction. These two approaches are intuitively\ncomplementary, but their effectiveness has not yet been compared. In this\npaper, we introduce a benchmark for evaluating ontology completion methods and\nthoroughly analyse the strengths and weaknesses of both approaches. We find\nthat both approaches are indeed complementary, with hybrid strategies achieving\nthe best overall results. We also find that the task is highly challenging for\nLarge Language Models, even after fine-tuning.", "published": "2024-03-25 21:46:35", "link": "http://arxiv.org/abs/2403.17216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making Sentence Embeddings Robust to User-Generated Content", "abstract": "NLP models have been known to perform poorly on user-generated content (UGC),\nmainly because it presents a lot of lexical variations and deviates from the\nstandard texts on which most of these models were trained. In this work, we\nfocus on the robustness of LASER, a sentence embedding model, to UGC data. We\nevaluate this robustness by LASER's ability to represent non-standard sentences\nand their standard counterparts close to each other in the embedding space.\nInspired by previous works extending LASER to other languages and modalities,\nwe propose RoLASER, a robust English encoder trained using a teacher-student\napproach to reduce the distances between the representations of standard and\nUGC sentences. We show that with training only on standard and synthetic\nUGC-like data, RoLASER significantly improves LASER's robustness to both\nnatural and artificial UGC data by achieving up to 2x and 11x better scores. We\nalso perform a fine-grained analysis on artificial UGC data and find that our\nmodel greatly outperforms LASER on its most challenging UGC phenomena such as\nkeyboard typos and social media abbreviations. Evaluation on downstream tasks\nshows that RoLASER performs comparably to or better than LASER on standard\ndata, while consistently outperforming it on UGC data.", "published": "2024-03-25 21:48:36", "link": "http://arxiv.org/abs/2403.17220v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Role of $n$-gram Smoothing in the Age of Neural Networks", "abstract": "For nearly three decades, language models derived from the $n$-gram\nassumption held the state of the art on the task. The key to their success lay\nin the application of various smoothing techniques that served to combat\noverfitting. However, when neural language models toppled $n$-gram models as\nthe best performers, $n$-gram smoothing techniques became less relevant.\nIndeed, it would hardly be an understatement to suggest that the line of\ninquiry into $n$-gram smoothing techniques became dormant. This paper re-opens\nthe role classical $n$-gram smoothing techniques may play in the age of neural\nlanguage models. First, we draw a formal equivalence between label smoothing, a\npopular regularization technique for neural language models, and add-$\\lambda$\nsmoothing. Second, we derive a generalized framework for converting any\n$n$-gram smoothing technique into a regularizer compatible with neural language\nmodels. Our empirical results find that our novel regularizers are comparable\nto and, indeed, sometimes outperform label smoothing on language modeling and\nmachine translation.", "published": "2024-03-25 22:42:19", "link": "http://arxiv.org/abs/2403.17240v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SPLICE: A Singleton-Enhanced PipeLIne for Coreference REsolution", "abstract": "Singleton mentions, i.e.~entities mentioned only once in a text, are\nimportant to how humans understand discourse from a theoretical perspective.\nHowever previous attempts to incorporate their detection in end-to-end neural\ncoreference resolution for English have been hampered by the lack of singleton\nmention spans in the OntoNotes benchmark. This paper addresses this limitation\nby combining predicted mentions from existing nested NER systems and features\nderived from OntoNotes syntax trees. With this approach, we create a near\napproximation of the OntoNotes dataset with all singleton mentions, achieving\n~94% recall on a sample of gold singletons. We then propose a two-step neural\nmention and coreference resolution system, named SPLICE, and compare its\nperformance to the end-to-end approach in two scenarios: the OntoNotes test set\nand the out-of-domain (OOD) OntoGUM corpus. Results indicate that reconstructed\nsingleton training yields results comparable to end-to-end systems for\nOntoNotes, while improving OOD stability (+1.1 avg. F1). We conduct error\nanalysis for mention detection and delve into its impact on coreference\nclustering, revealing that precision improvements deliver more substantial\nbenefits than increases in recall for resolving coreference chains.", "published": "2024-03-25 22:46:16", "link": "http://arxiv.org/abs/2403.17245v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hybrid Approach To Aspect Based Sentiment Analysis Using Transfer\n  Learning", "abstract": "Aspect-Based Sentiment Analysis (ABSA) aims to identify terms or multiword\nexpressions (MWEs) on which sentiments are expressed and the sentiment\npolarities associated with them. The development of supervised models has been\nat the forefront of research in this area. However, training these models\nrequires the availability of manually annotated datasets which is both\nexpensive and time-consuming. Furthermore, the available annotated datasets are\ntailored to a specific domain, language, and text type. In this work, we\naddress this notable challenge in current state-of-the-art ABSA research. We\npropose a hybrid approach for Aspect Based Sentiment Analysis using transfer\nlearning. The approach focuses on generating weakly-supervised annotations by\nexploiting the strengths of both large language models (LLM) and traditional\nsyntactic dependencies. We utilise syntactic dependency structures of sentences\nto complement the annotations generated by LLMs, as they may overlook\ndomain-specific aspect terms. Extensive experimentation on multiple datasets is\nperformed to demonstrate the efficacy of our hybrid method for the tasks of\naspect term extraction and aspect sentiment classification.\n  Keywords: Aspect Based Sentiment Analysis, Syntactic Parsing, large language\nmodel (LLM)", "published": "2024-03-25 23:02:33", "link": "http://arxiv.org/abs/2403.17254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators\n  for Reasoning-Based Chart VQA", "abstract": "Understanding data visualizations like charts and plots requires reasoning\nabout both visual elements and numerics. Although strong in extractive\nquestions, current chart visual question answering (chart VQA) models suffer on\ncomplex reasoning questions. In this work, we address the lack of reasoning\nability by data augmentation. We leverage Large Language Models (LLMs), which\nhave shown to have strong reasoning ability, as an automatic data annotator\nthat generates question-answer annotations for chart images. The key innovation\nin our method lies in the Synthesize Step-by-Step strategy: our LLM-based data\ngenerator learns to decompose the complex question into step-by-step\nsub-questions (rationales), which are then used to derive the final answer\nusing external tools, i.e. Python. This step-wise generation procedure is\ntrained on synthetic data generated using a template-based QA generation\npipeline. Experimental results highlight the significance of the proposed\nstep-by-step generation. By training with the LLM-augmented data (LAMENDA), we\nsignificantly enhance the chart VQA models, achieving the state-of-the-art\naccuracy on the ChartQA and PlotQA datasets. In particular, our approach\nimproves the accuracy of the previous state-of-the-art approach from 38% to 54%\non the human-written questions in the ChartQA dataset, which needs strong\nreasoning. We hope our work underscores the potential of synthetic data and\nencourages further exploration of data augmentation using LLMs for\nreasoning-heavy tasks.", "published": "2024-03-25 03:02:27", "link": "http://arxiv.org/abs/2403.16385v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on\n  Prompt-based Language Models", "abstract": "Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n$\\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo. The resource is available at\n$\\href{https://github.com/SavannahXu79/LinkPrompt}{https://github.com/SavannahXu79/LinkPrompt}$.", "published": "2024-03-25 05:27:35", "link": "http://arxiv.org/abs/2403.16432v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InstUPR : Instruction-based Unsupervised Passage Reranking with Large\n  Language Models", "abstract": "This paper introduces InstUPR, an unsupervised passage reranking method based\non large language models (LLMs). Different from existing approaches that rely\non extensive training with query-document pairs or retrieval-specific\ninstructions, our method leverages the instruction-following capabilities of\ninstruction-tuned LLMs for passage reranking without any additional\nfine-tuning. To achieve this, we introduce a soft score aggregation technique\nand employ pairwise reranking for unsupervised passage reranking. Experiments\non the BEIR benchmark demonstrate that InstUPR outperforms unsupervised\nbaselines as well as an instruction-tuned reranker, highlighting its\neffectiveness and superiority. Source code to reproduce all experiments is\nopen-sourced at https://github.com/MiuLab/InstUPR", "published": "2024-03-25 05:31:22", "link": "http://arxiv.org/abs/2403.16435v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Reasoning Runtime Behavior of a Program with LLM: How Far Are We?", "abstract": "Large language models for code (i.e., code LLMs) have shown strong code\nunderstanding and generation capabilities. To evaluate the capabilities of code\nLLMs in various aspects, many benchmarks have been proposed (e.g., HumanEval\nand ClassEval). Code reasoning is one of the most essential abilities of code\nLLMs, but existing benchmarks for code reasoning are not sufficient. Typically,\nthey focus on predicting the input and output of a program, ignoring the\nevaluation of the intermediate behavior during program execution, as well as\nthe logical consistency (e.g., the model should not give the correct output if\nthe prediction of execution path is wrong) when performing the reasoning. To\naddress these problems, in this paper, we propose a framework, namely REval,\nfor evaluating code reasoning abilities and consistency of code LLMs with\nprogram execution. We utilize existing code benchmarks and adapt them to new\nbenchmarks within our framework. A large-scale empirical study is conducted and\nmost LLMs show unsatisfactory performance on both Runtime Behavior Reasoning\n(i.e., an average accuracy of 44.4%) and Incremental Consistency Evaluation\n(i.e., an average IC score of 10.3). Evaluation results of current code LLMs\nreflect the urgent need for the community to strengthen the code reasoning\ncapability of code LLMs. Our code, data, and \\newname leaderboard are available\nat https://r-eval.github.io.", "published": "2024-03-25 05:37:16", "link": "http://arxiv.org/abs/2403.16437v3", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent\n  Classification", "abstract": "Multi-turn intent classification is notably challenging due to the complexity\nand evolving nature of conversational contexts. This paper introduces LARA, a\nLinguistic-Adaptive Retrieval-Augmentation framework to enhance accuracy in\nmulti-turn classification tasks across six languages, accommodating a large\nnumber of intents in chatbot interactions. LARA combines a fine-tuned smaller\nmodel with a retrieval-augmented mechanism, integrated within the architecture\nof LLMs. The integration allows LARA to dynamically utilize past dialogues and\nrelevant intents, thereby improving the understanding of the context.\nFurthermore, our adaptive retrieval techniques bolster the cross-lingual\ncapabilities of LLMs without extensive retraining and fine-tuning.\nComprehensive experiments demonstrate that LARA achieves state-of-the-art\nperformance on multi-turn intent classification tasks, enhancing the average\naccuracy by 3.67\\% from state-of-the-art single-turn intent classifiers.", "published": "2024-03-25 07:38:40", "link": "http://arxiv.org/abs/2403.16504v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "LLMs Are Few-Shot In-Context Low-Resource Language Learners", "abstract": "In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages. Our code is publicly\nreleased at https://github.com/SamuelCahyawijaya/in-context-alignment", "published": "2024-03-25 07:55:29", "link": "http://arxiv.org/abs/2403.16512v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visually Guided Generative Text-Layout Pre-training for Document\n  Intelligence", "abstract": "Prior study shows that pre-training techniques can boost the performance of\nvisual document understanding (VDU), which typically requires models to gain\nabilities to perceive and reason both document texts and layouts (e.g.,\nlocations of texts and table-cells). To this end, we propose visually guided\ngenerative text-layout pre-training, named ViTLP. Given a document image, the\nmodel optimizes hierarchical language and layout modeling objectives to\ngenerate the interleaved text and layout sequence. In addition, to address the\nlimitation of processing long documents by Transformers, we introduce a\nstraightforward yet effective multi-segment generative pre-training scheme,\nfacilitating ViTLP to process word-intensive documents of any length. ViTLP can\nfunction as a native OCR model to localize and recognize texts of document\nimages. Besides, ViTLP can be effectively applied to various downstream VDU\ntasks. Extensive experiments show that ViTLP achieves competitive performance\nover existing baselines on benchmark VDU tasks, including information\nextraction, document classification, and document question answering.", "published": "2024-03-25 08:00:43", "link": "http://arxiv.org/abs/2403.16516v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Efficient Information Extraction in Few-Shot Relation Classification\n  through Contrastive Representation Learning", "abstract": "Differentiating relationships between entity pairs with limited labeled\ninstances poses a significant challenge in few-shot relation classification.\nRepresentations of textual data extract rich information spanning the domain,\nentities, and relations. In this paper, we introduce a novel approach to\nenhance information extraction combining multiple sentence representations and\ncontrastive learning. While representations in relation classification are\ncommonly extracted using entity marker tokens, we argue that substantial\ninformation within the internal model representations remains untapped. To\naddress this, we propose aligning multiple sentence representations, such as\nthe [CLS] token, the [MASK] token used in prompting, and entity marker tokens.\nOur method employs contrastive learning to extract complementary discriminative\ninformation from these individual representations. This is particularly\nrelevant in low-resource settings where information is scarce. Leveraging\nmultiple sentence representations is especially effective in distilling\ndiscriminative information for relation classification when additional\ninformation, like relation descriptions, are not available. We validate the\nadaptability of our approach, maintaining robust performance in scenarios that\ninclude relation descriptions, and showcasing its flexibility to adapt to\ndifferent resource constraints.", "published": "2024-03-25 08:36:06", "link": "http://arxiv.org/abs/2403.16543v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PE: A Poincare Explanation Method for Fast Text Hierarchy Generation", "abstract": "The black-box nature of deep learning models in NLP hinders their widespread\napplication. The research focus has shifted to Hierarchical Attribution (HA)\nfor its ability to model feature interactions. Recent works model\nnon-contiguous combinations with a time-costly greedy search in Eculidean\nspaces, neglecting underlying linguistic information in feature\nrepresentations. In this work, we introduce a novel method, namely Poincare\nExplanation (PE), for modeling feature interactions with hyperbolic spaces in a\ntime efficient manner. Specifically, we take building text hierarchies as\nfinding spanning trees in hyperbolic spaces. First we project the embeddings\ninto hyperbolic spaces to elicit inherit semantic and syntax hierarchical\nstructures. Then we propose a simple yet effective strategy to calculate\nShapley score. Finally we build the the hierarchy with proving the constructing\nprocess in the projected space could be viewed as building a minimum spanning\ntree and introduce a time efficient building algorithm. Experimental results\ndemonstrate the effectiveness of our approach.", "published": "2024-03-25 09:04:14", "link": "http://arxiv.org/abs/2403.16554v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Who is bragging more online? A large scale analysis of bragging in\n  social media", "abstract": "Bragging is the act of uttering statements that are likely to be positively\nviewed by others and it is extensively employed in human communication with the\naim to build a positive self-image of oneself. Social media is a natural\nplatform for users to employ bragging in order to gain admiration, respect,\nattention and followers from their audiences. Yet, little is known about the\nscale of bragging online and its characteristics. This paper employs\ncomputational sociolinguistics methods to conduct the first large scale study\nof bragging behavior on Twitter (U.S.) by focusing on its overall prevalence,\ntemporal dynamics and impact of demographic factors. Our study shows that the\nprevalence of bragging decreases over time within the same population of users.\nIn addition, younger, more educated and popular users in the U.S. are more\nlikely to brag. Finally, we conduct an extensive linguistics analysis to unveil\nspecific bragging themes associated with different user traits.", "published": "2024-03-25 12:07:21", "link": "http://arxiv.org/abs/2403.16668v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "ToXCL: A Unified Framework for Toxic Speech Detection and Explanation", "abstract": "The proliferation of online toxic speech is a pertinent problem posing\nthreats to demographic groups. While explicit toxic speech contains offensive\nlexical signals, implicit one consists of coded or indirect language.\nTherefore, it is crucial for models not only to detect implicit toxic speech\nbut also to explain its toxicity. This draws a unique need for unified\nframeworks that can effectively detect and explain implicit toxic speech. Prior\nworks mainly formulated the task of toxic speech detection and explanation as a\ntext generation problem. Nonetheless, models trained using this strategy can be\nprone to suffer from the consequent error propagation problem. Moreover, our\nexperiments reveal that the detection results of such models are much lower\nthan those that focus only on the detection task. To bridge these gaps, we\nintroduce ToXCL, a unified framework for the detection and explanation of\nimplicit toxic speech. Our model consists of three modules: a (i) Target Group\nGenerator to generate the targeted demographic group(s) of a given post; an\n(ii) Encoder-Decoder Model in which the encoder focuses on detecting implicit\ntoxic speech and is boosted by a (iii) Teacher Classifier via knowledge\ndistillation, and the decoder generates the necessary explanation. ToXCL\nachieves new state-of-the-art effectiveness, and outperforms baselines\nsignificantly.", "published": "2024-03-25 12:21:38", "link": "http://arxiv.org/abs/2403.16685v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Synthetic Data Generation and Joint Learning for Robust Code-Mixed\n  Translation", "abstract": "The widespread online communication in a modern multilingual world has\nprovided opportunities to blend more than one language (aka code-mixed\nlanguage) in a single utterance. This has resulted a formidable challenge for\nthe computational models due to the scarcity of annotated data and presence of\nnoise. A potential solution to mitigate the data scarcity problem in\nlow-resource setup is to leverage existing data in resource-rich language\nthrough translation. In this paper, we tackle the problem of code-mixed\n(Hinglish and Bengalish) to English machine translation. First, we\nsynthetically develop HINMIX, a parallel corpus of Hinglish to English, with\n~4.2M sentence pairs. Subsequently, we propose RCMT, a robust perturbation\nbased joint-training model that learns to handle noise in the real-world\ncode-mixed text by parameter sharing across clean and noisy words. Further, we\nshow the adaptability of RCMT in a zero-shot setup for Bengalish to English\ntranslation. Our evaluation and comprehensive analyses qualitatively and\nquantitatively demonstrate the superiority of RCMT over state-of-the-art\ncode-mixed and robust translation methods.", "published": "2024-03-25 13:50:11", "link": "http://arxiv.org/abs/2403.16771v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Iterative Refinement of Project-Level Code Context for Precise Code\n  Generation with Compiler Feedback", "abstract": "Large Language Models (LLMs) have shown remarkable progress in automated code\ngeneration. Yet, LLM-generated code may contain errors in API usage, class,\ndata structure, or missing project-specific information. As much of this\nproject-specific context cannot fit into the prompts of LLMs, we must find ways\nto allow the model to explore the project-level code context. We present\nCoCoGen, a new code generation approach that uses compiler feedback to improve\nthe LLM-generated code. CoCoGen first leverages static analysis to identify\nmismatches between the generated code and the project's context. It then\niteratively aligns and fixes the identified errors using information extracted\nfrom the code repository. We integrate CoCoGen with two representative LLMs,\ni.e., GPT-3.5-Turbo and Code Llama (13B), and apply it to Python code\ngeneration. Experimental results show that CoCoGen significantly improves the\nvanilla LLMs by over 80% in generating code dependent on the project context\nand consistently outperforms the existing retrieval-based code generation\nbaselines.", "published": "2024-03-25 14:07:27", "link": "http://arxiv.org/abs/2403.16792v3", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Towards Explainability in Legal Outcome Prediction Models", "abstract": "Current legal outcome prediction models - a staple of legal NLP - do not\nexplain their reasoning. However, to employ these models in the real world,\nhuman legal actors need to be able to understand the model's decisions. In the\ncase of common law, legal practitioners reason towards the outcome of a case by\nreferring to past case law, known as precedent. We contend that precedent is,\ntherefore, a natural way of facilitating explainability for legal NLP models.\nIn this paper, we contribute a novel method for identifying the precedent\nemployed by legal outcome prediction models. Furthermore, by developing a\ntaxonomy of legal precedent, we are able to compare human judges and neural\nmodels with respect to the different types of precedent they rely on. We find\nthat while the models learn to predict outcomes reasonably well, their use of\nprecedent is unlike that of human judges.", "published": "2024-03-25 15:15:41", "link": "http://arxiv.org/abs/2403.16852v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Expert is Worth One Token: Synergizing Multiple Expert LLMs as\n  Generalist via Expert Token Routing", "abstract": "We present Expert-Token-Routing, a unified generalist framework that\nfacilitates seamless integration of multiple expert LLMs. Our framework\nrepresents expert LLMs as special expert tokens within the vocabulary of a meta\nLLM. The meta LLM can route to an expert LLM like generating new tokens.\nExpert-Token-Routing not only supports learning the implicit expertise of\nexpert LLMs from existing instruction dataset but also allows for dynamic\nextension of new expert LLMs in a plug-and-play manner. It also conceals the\ndetailed collaboration process from the user's perspective, facilitating\ninteraction as though it were a singular LLM. Our framework outperforms various\nexisting multi-LLM collaboration paradigms across benchmarks that incorporate\nsix diverse expert domains, demonstrating effectiveness and robustness in\nbuilding generalist LLM system via synergizing multiple expert LLMs.", "published": "2024-03-25 15:17:05", "link": "http://arxiv.org/abs/2403.16854v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Encoding of lexical tone in self-supervised models of spoken language", "abstract": "Interpretability research has shown that self-supervised Spoken Language\nModels (SLMs) encode a wide variety of features in human speech from the\nacoustic, phonetic, phonological, syntactic and semantic levels, to speaker\ncharacteristics. The bulk of prior research on representations of phonology has\nfocused on segmental features such as phonemes; the encoding of suprasegmental\nphonology (such as tone and stress patterns) in SLMs is not yet well\nunderstood. Tone is a suprasegmental feature that is present in more than half\nof the world's languages. This paper aims to analyze the tone encoding\ncapabilities of SLMs, using Mandarin and Vietnamese as case studies. We show\nthat SLMs encode lexical tone to a significant degree even when they are\ntrained on data from non-tonal languages. We further find that SLMs behave\nsimilarly to native and non-native human participants in tone and consonant\nperception studies, but they do not follow the same developmental trajectory.", "published": "2024-03-25 15:28:38", "link": "http://arxiv.org/abs/2403.16865v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings", "abstract": "Concept embeddings offer a practical and efficient mechanism for injecting\ncommonsense knowledge into downstream tasks. Their core purpose is often not to\npredict the commonsense properties of concepts themselves, but rather to\nidentify commonalities, i.e.\\ sets of concepts which share some property of\ninterest. Such commonalities are the basis for inductive generalisation, hence\nhigh-quality concept embeddings can make learning easier and more robust.\nUnfortunately, standard embeddings primarily reflect basic taxonomic\ncategories, making them unsuitable for finding commonalities that refer to more\nspecific aspects (e.g.\\ the colour of objects or the materials they are made\nof). In this paper, we address this limitation by explicitly modelling the\ndifferent facets of interest when learning concept embeddings. We show that\nthis leads to embeddings which capture a more diverse range of commonsense\nproperties, and consistently improves results in downstream tasks such as\nultra-fine entity typing and ontology completion.", "published": "2024-03-25 17:44:45", "link": "http://arxiv.org/abs/2403.16984v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Strong Pull of Prior Knowledge in Large Language Models and Its\n  Impact on Emotion Recognition", "abstract": "In-context Learning (ICL) has emerged as a powerful paradigm for performing\nnatural language tasks with Large Language Models (LLM) without updating the\nmodels' parameters, in contrast to the traditional gradient-based finetuning.\nThe promise of ICL is that the LLM can adapt to perform the present task at a\ncompetitive or state-of-the-art level at a fraction of the cost. The ability of\nLLMs to perform tasks in this few-shot manner relies on their background\nknowledge of the task (or task priors). However, recent work has found that,\nunlike traditional learning, LLMs are unable to fully integrate information\nfrom demonstrations that contrast task priors. This can lead to performance\nsaturation at suboptimal levels, especially for subjective tasks such as\nemotion recognition, where the mapping from text to emotions can differ widely\ndue to variability in human annotations. In this work, we design experiments\nand propose measurements to explicitly quantify the consistency of proxies of\nLLM priors and their pull on the posteriors. We show that LLMs have strong yet\ninconsistent priors in emotion recognition that ossify their predictions. We\nalso find that the larger the model, the stronger these effects become. Our\nresults suggest that caution is needed when using ICL with larger LLMs for\naffect-centered tasks outside their pre-training domain and when interpreting\nICL results.", "published": "2024-03-25 19:07:32", "link": "http://arxiv.org/abs/2403.17125v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaAligner: Towards Generalizable Multi-Objective Alignment of Language\n  Models", "abstract": "Recent advancements in large language models (LLMs) focus on aligning to\nheterogeneous human expectations and values via multi-objective preference\nalignment. However, existing methods are dependent on the policy model\nparameters, which require high-cost repetition of their alignment algorithms\nfor each new policy model, and they cannot expand to unseen objectives due to\ntheir static alignment objectives. In this work, we propose Meta-Objective\nAligner (MetaAligner), the first policy-agnostic and generalizable method for\nmulti-objective preference alignment. MetaAligner models multi-objective\nalignment into three stages: (1) dynamic objectives reformulation algorithm\nreorganizes traditional alignment datasets to supervise the model on performing\nflexible alignment across different objectives; (2) conditional weak-to-strong\ncorrection paradigm aligns the weak outputs of fixed policy models to approach\nstrong outputs with higher preferences in the corresponding alignment\nobjectives, enabling plug-and-play inferences on any policy models, which\nsignificantly reduces training costs and facilitates alignment on close-source\npolicy models; (3) generalizable inference method flexibly adjusts target\nobjectives by updating their text descriptions in the prompts, facilitating\ngeneralizable alignment to unseen objectives. Experimental results show that\nMetaAligner achieves significant and balanced improvements in multi-objective\nalignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU\ntraining hours compared to previous alignment methods. The model also\neffectively aligns unseen objectives, marking the first step towards\ngeneralizable multi-objective preference alignment.", "published": "2024-03-25 19:28:10", "link": "http://arxiv.org/abs/2403.17141v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Guided Distant Supervision for Multilingual Relation Extraction Data:\n  Adapting to a New Language", "abstract": "Relation extraction is essential for extracting and understanding\nbiographical information in the context of digital humanities and related\nsubjects. There is a growing interest in the community to build datasets\ncapable of training machine learning models to extract relationships. However,\nannotating such datasets can be expensive and time-consuming, in addition to\nbeing limited to English. This paper applies guided distant supervision to\ncreate a large biographical relationship extraction dataset for German. Our\ndataset, composed of more than 80,000 instances for nine relationship types, is\nthe largest biographical German relationship extraction dataset. We also create\na manually annotated dataset with 2000 instances to evaluate the models and\nrelease it together with the dataset compiled using guided distant supervision.\nWe train several state-of-the-art machine learning models on the automatically\ncreated dataset and release them as well. Furthermore, we experiment with\nmultilingual and cross-lingual experiments that could benefit many low-resource\nlanguages.", "published": "2024-03-25 19:40:26", "link": "http://arxiv.org/abs/2403.17143v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Task-Agnostic Detector for Insertion-Based Backdoor Attacks", "abstract": "Textual backdoor attacks pose significant security threats. Current detection\napproaches, typically relying on intermediate feature representation or\nreconstructing potential triggers, are task-specific and less effective beyond\nsentence classification, struggling with tasks like question answering and\nnamed entity recognition. We introduce TABDet (Task-Agnostic Backdoor\nDetector), a pioneering task-agnostic method for backdoor detection. TABDet\nleverages final layer logits combined with an efficient pooling technique,\nenabling unified logit representation across three prominent NLP tasks. TABDet\ncan jointly learn from diverse task-specific models, demonstrating superior\ndetection efficacy over traditional task-specific methods.", "published": "2024-03-25 20:12:02", "link": "http://arxiv.org/abs/2403.17155v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "QuanTemp: A real-world open-domain benchmark for fact-checking numerical\n  claims", "abstract": "Automated fact checking has gained immense interest to tackle the growing\nmisinformation in the digital era. Existing systems primarily focus on\nsynthetic claims on Wikipedia, and noteworthy progress has also been made on\nreal-world claims. In this work, we release QuanTemp, a diverse, multi-domain\ndataset focused exclusively on numerical claims, encompassing temporal,\nstatistical and diverse aspects with fine-grained metadata and an evidence\ncollection without leakage. This addresses the challenge of verifying\nreal-world numerical claims, which are complex and often lack precise\ninformation, not addressed by existing works that mainly focus on synthetic\nclaims. We evaluate and quantify the limitations of existing solutions for the\ntask of verifying numerical claims. We also evaluate claim decomposition based\nmethods, numerical understanding based models and our best baselines achieves a\nmacro-F1 of 58.32. This demonstrates that QuanTemp serves as a challenging\nevaluation set for numerical claim verification.", "published": "2024-03-25 20:36:03", "link": "http://arxiv.org/abs/2403.17169v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Linear Cross-document Event Coreference Resolution with X-AMR", "abstract": "Event Coreference Resolution (ECR) as a pairwise mention classification task\nis expensive both for automated systems and manual annotations. The task's\nquadratic difficulty is exacerbated when using Large Language Models (LLMs),\nmaking prompt engineering for ECR prohibitively costly. In this work, we\npropose a graphical representation of events, X-AMR, anchored around individual\nmentions using a \\textbf{cross}-document version of \\textbf{A}bstract\n\\textbf{M}eaning \\textbf{R}epresentation. We then linearize the ECR with a\nnovel multi-hop coreference algorithm over the event graphs. The event graphs\nsimplify ECR, making it a) LLM cost-effective, b) compositional and\ninterpretable, and c) easily annotated. For a fair assessment, we first enrich\nan existing ECR benchmark dataset with these event graphs using an\nannotator-friendly tool we introduce. Then, we employ GPT-4, the newest LLM by\nOpenAI, for these annotations. Finally, using the ECR algorithm, we assess\nGPT-4 against humans and analyze its limitations. Through this research, we aim\nto advance the state-of-the-art for efficient ECR and shed light on the\npotential shortcomings of current LLMs at this task. Code and annotations:\n\\url{https://github.com/ahmeshaf/gpt_coref}", "published": "2024-03-25 02:49:06", "link": "http://arxiv.org/abs/2404.08656v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhanced Facet Generation with LLM Editing", "abstract": "In information retrieval, facet identification of a user query is an\nimportant task. If a search service can recognize the facets of a user's query,\nit has the potential to offer users a much broader range of search results.\nPrevious studies can enhance facet prediction by leveraging retrieved documents\nand related queries obtained through a search engine. However, there are\nchallenges in extending it to other applications when a search engine operates\nas part of the model. First, search engines are constantly updated. Therefore,\nadditional information may change during training and test, which may reduce\nperformance. The second challenge is that public search engines cannot search\nfor internal documents. Therefore, a separate search system needs to be built\nto incorporate documents from private domains within the company. We propose\ntwo strategies that focus on a framework that can predict facets by taking only\nqueries as input without a search engine. The first strategy is multi-task\nlearning to predict SERP. By leveraging SERP as a target instead of a source,\nthe proposed model deeply understands queries without relying on external\nmodules. The second strategy is to enhance the facets by combining Large\nLanguage Model (LLM) and the small model. Overall performance improves when\nsmall model and LLM are combined rather than facet generation individually.", "published": "2024-03-25 00:43:44", "link": "http://arxiv.org/abs/2403.16345v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Concurrent Linguistic Error Detection (CLED) for Large Language Models", "abstract": "The wide adoption of Large language models (LLMs) makes their dependability a\npressing concern. Detection of errors is the first step to mitigating their\nimpact on a system and thus, efficient error detection for LLMs is an important\nissue. In many settings, the LLM is considered as a black box with no access to\nthe internal nodes; this prevents the use of many error detection schemes that\nneed access to the model's internal nodes. An interesting observation is that\nthe output of LLMs in error-free operation should be valid and normal text.\nTherefore, when the text is not valid or differs significantly from normal\ntext, it is likely that there is an error. Based on this observation we propose\nto perform Concurrent Linguistic Error Detection (CLED); this scheme extracts\nsome linguistic features of the text generated by the LLM and feeds them to a\nconcurrent classifier that detects errors. Since the proposed error detection\nmechanism only relies on the outputs of the model, then it can be used on LLMs\nin which there is no access to the internal nodes. The proposed CLED scheme has\nbeen evaluated on the T5 model when used for news summarization and on the\nOPUS-MT model when used for translation. In both cases, the same set of\nlinguistic features has been used for error detection to illustrate the\napplicability of the proposed scheme beyond a specific case. The results show\nthat CLED can detect most of the errors at a low overhead penalty. The use of\nthe concurrent classifier also enables a trade-off between error detection\neffectiveness and its associated overhead, so providing flexibility to a\ndesigner.", "published": "2024-03-25 03:17:27", "link": "http://arxiv.org/abs/2403.16393v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "If CLIP Could Talk: Understanding Vision-Language Model Representations\n  Through Their Preferred Concept Descriptions", "abstract": "Recent works often assume that Vision-Language Model (VLM) representations\nare based on visual attributes like shape. However, it is unclear to what\nextent VLMs prioritize this information to represent concepts. We propose\nExtract and Explore (EX2), a novel approach to characterize textual features\nthat are important for VLMs. EX2 uses reinforcement learning to align a large\nlanguage model with VLM preferences and generates descriptions that incorporate\nfeatures that are important for the VLM. Then, we inspect the descriptions to\nidentify features that contribute to VLM representations. Using EX2, we find\nthat spurious descriptions have a major role in VLM representations despite\nproviding no helpful information, e.g., Click to enlarge photo of CONCEPT. More\nimportantly, among informative descriptions, VLMs rely significantly on\nnon-visual attributes like habitat (e.g., North America) to represent visual\nconcepts. Also, our analysis reveals that different VLMs prioritize different\nattributes in their representations. Overall, we show that VLMs do not simply\nmatch images to scene descriptions and that non-visual or even spurious\ndescriptions significantly influence their representations.", "published": "2024-03-25 06:05:50", "link": "http://arxiv.org/abs/2403.16442v2", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CodeS: Natural Language to Code Repository via Multi-Layer Sketch", "abstract": "The impressive performance of large language models (LLMs) on code-related\ntasks has shown the potential of fully automated software development. In light\nof this, we introduce a new software engineering task, namely Natural Language\nto code Repository (NL2Repo). This task aims to generate an entire code\nrepository from its natural language requirements. To address this task, we\npropose a simple yet effective framework CodeS, which decomposes NL2Repo into\nmultiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three\nmodules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first\ngenerates a repository's directory structure for given requirements;\nFileSketcher then generates a file sketch for each file in the generated\nstructure; SketchFiller finally fills in the details for each function in the\ngenerated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry\nout evaluations through both automated benchmarking and manual feedback\nanalysis. For benchmark-based evaluation, we craft a repository-oriented\nbenchmark, SketchEval, and design an evaluation metric, SketchBLEU. For\nfeedback-based evaluation, we develop a VSCode plugin for CodeS and engage 30\nparticipants in conducting empirical studies. Extensive experiments prove the\neffectiveness and practicality of CodeS on the NL2Repo task.", "published": "2024-03-25 06:09:55", "link": "http://arxiv.org/abs/2403.16443v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Hallucination Detection in Foundation Models for Decision-Making: A\n  Flexible Definition and Review of the State of the Art", "abstract": "Autonomous systems are soon to be ubiquitous, spanning manufacturing,\nagriculture, healthcare, entertainment, and other industries. Most of these\nsystems are developed with modular sub-components for decision-making,\nplanning, and control that may be hand-engineered or learning-based. While\nthese approaches perform well under the situations they were specifically\ndesigned for, they can perform especially poorly in out-of-distribution\nscenarios that will undoubtedly arise at test-time. The rise of foundation\nmodels trained on multiple tasks with impressively large datasets has led\nresearchers to believe that these models may provide \"common sense\" reasoning\nthat existing planners are missing, bridging the gap between algorithm\ndevelopment and deployment. While researchers have shown promising results in\ndeploying foundation models to decision-making tasks, these models are known to\nhallucinate and generate decisions that may sound reasonable, but are in fact\npoor. We argue there is a need to step back and simultaneously design systems\nthat can quantify the certainty of a model's decision, and detect when it may\nbe hallucinating. In this work, we discuss the current use cases of foundation\nmodels for decision-making tasks, provide a general definition for\nhallucinations with examples, discuss existing approaches to hallucination\ndetection and mitigation with a focus on decision problems, present guidelines,\nand explore areas for further research in this exciting field.", "published": "2024-03-25 08:11:02", "link": "http://arxiv.org/abs/2403.16527v2", "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.AI"}
{"title": "NSINA: A News Corpus for Sinhala", "abstract": "The introduction of large language models (LLMs) has advanced natural\nlanguage processing (NLP), but their effectiveness is largely dependent on\npre-training resources. This is especially evident in low-resource languages,\nsuch as Sinhala, which face two primary challenges: the lack of substantial\ntraining data and limited benchmarking datasets. In response, this study\nintroduces NSINA, a comprehensive news corpus of over 500,000 articles from\npopular Sinhala news websites, along with three NLP tasks: news media\nidentification, news category prediction, and news headline generation. The\nrelease of NSINA aims to provide a solution to challenges in adapting LLMs to\nSinhala, offering valuable resources and benchmarks for improving NLP in the\nSinhala language. NSINA is the largest news corpus for Sinhala, available up to\ndate.", "published": "2024-03-25 09:36:51", "link": "http://arxiv.org/abs/2403.16571v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A comparative analysis of embedding models for patent similarity", "abstract": "This paper makes two contributions to the field of text-based patent\nsimilarity. First, it compares the performance of different kinds of\npatent-specific pretrained embedding models, namely static word embeddings\n(such as word2vec and doc2vec models) and contextual word embeddings (such as\ntransformers based models), on the task of patent similarity calculation.\nSecond, it compares specifically the performance of Sentence Transformers\n(SBERT) architectures with different training phases on the patent similarity\ntask. To assess the models' performance, we use information about patent\ninterferences, a phenomenon in which two or more patent claims belonging to\ndifferent patent applications are proven to be overlapping by patent examiners.\nTherefore, we use these interferences cases as a proxy for maximum similarity\nbetween two patents, treating them as ground-truth to evaluate the performance\nof the different embedding models. Our results point out that, first, Patent\nSBERT-adapt-ub, the domain adaptation of the pretrained Sentence Transformer\narchitecture proposed in this research, outperforms the current\nstate-of-the-art in patent similarity. Second, they show that, in some cases,\nlarge static models performances are still comparable to contextual ones when\ntrained on extensive data; thus, we believe that the superiority in the\nperformance of contextual embeddings may not be related to the actual\narchitecture but rather to the way the training phase is performed.", "published": "2024-03-25 11:20:23", "link": "http://arxiv.org/abs/2403.16630v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ProCQA: A Large-scale Community-based Programming Question Answering\n  Dataset for Code Search", "abstract": "Retrieval-based code question answering seeks to match user queries in\nnatural language to relevant code snippets. Previous approaches typically rely\non pretraining models using crafted bi-modal and uni-modal datasets to align\ntext and code representations. In this paper, we introduce ProCQA, a\nlarge-scale programming question answering dataset extracted from the\nStackOverflow community, offering naturally structured mixed-modal QA pairs. To\nvalidate its effectiveness, we propose a modality-agnostic contrastive\npre-training approach to improve the alignment of text and code representations\nof current code language models. Compared to previous models that primarily\nemploy bimodal and unimodal pairs extracted from CodeSearchNet for\npre-training, our model exhibits significant performance improvements across a\nwide range of code retrieval benchmarks.", "published": "2024-03-25 12:34:33", "link": "http://arxiv.org/abs/2403.16702v1", "categories": ["cs.CL", "cs.IR", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Can tweets predict article retractions? A comparison between human and\n  LLM labelling", "abstract": "Quickly detecting problematic research articles is crucial to safeguarding\nthe integrity of scientific research. This study explores whether Twitter\nmentions of retracted articles can signal potential problems with the articles\nprior to their retraction, potentially serving as an early warning system for\nscholars. To investigate this, we analysed a dataset of 4,354 Twitter mentions\nassociated with 504 retracted articles. The effectiveness of Twitter mentions\nin predicting article retractions was evaluated by both manual and Large\nLanguage Model (LLM) labelling. Manual labelling results indicated that 25.7%\nof tweets signalled problems before retraction. Using the manual labelling\nresults as the baseline, we found that LLMs (GPT-4o-mini, Gemini 1.5 Flash, and\nClaude-3.5-Haiku) outperformed lexicon-based sentiment analysis tools (e.g.,\nTextBlob) in detecting potential problems, suggesting that automatic detection\nof problematic articles from social media using LLMs is technically feasible.\nNevertheless, since only a small proportion of retracted articles (11.1%) were\ncriticised on Twitter prior to retraction, such automatic systems would detect\nonly a minority of problematic articles. Overall, this study offers insights\ninto how social media data, coupled with emerging generative AI techniques, can\nsupport research integrity.", "published": "2024-03-25 15:15:09", "link": "http://arxiv.org/abs/2403.16851v2", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DL"}
{"title": "State Space Models as Foundation Models: A Control Theoretic Overview", "abstract": "In recent years, there has been a growing interest in integrating linear\nstate-space models (SSM) in deep neural network architectures of foundation\nmodels. This is exemplified by the recent success of Mamba, showing better\nperformance than the state-of-the-art Transformer architectures in language\ntasks. Foundation models, like e.g. GPT-4, aim to encode sequential data into a\nlatent space in order to learn a compressed representation of the data. The\nsame goal has been pursued by control theorists using SSMs to efficiently model\ndynamical systems. Therefore, SSMs can be naturally connected to deep sequence\nmodeling, offering the opportunity to create synergies between the\ncorresponding research areas. This paper is intended as a gentle introduction\nto SSM-based architectures for control theorists and summarizes the latest\nresearch developments. It provides a systematic review of the most successful\nSSM proposals and highlights their main features from a control theoretic\nperspective. Additionally, we present a comparative analysis of these models,\nevaluating their performance on a standardized benchmark designed for assessing\na model's efficiency at learning long sequences.", "published": "2024-03-25 16:10:47", "link": "http://arxiv.org/abs/2403.16899v1", "categories": ["eess.SY", "cs.CL", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Towards Algorithmic Fidelity: Mental Health Representation across\n  Demographics in Synthetic vs. Human-generated Data", "abstract": "Synthetic data generation has the potential to impact applications and\ndomains with scarce data. However, before such data is used for sensitive tasks\nsuch as mental health, we need an understanding of how different demographics\nare represented in it. In our paper, we analyze the potential of producing\nsynthetic data using GPT-3 by exploring the various stressors it attributes to\ndifferent race and gender combinations, to provide insight for future\nresearchers looking into using LLMs for data generation. Using GPT-3, we\ndevelop HEADROOM, a synthetic dataset of 3,120 posts about\ndepression-triggering stressors, by controlling for race, gender, and time\nframe (before and after COVID-19). Using this dataset, we conduct semantic and\nlexical analyses to (1) identify the predominant stressors for each demographic\ngroup; and (2) compare our synthetic data to a human-generated dataset. We\npresent the procedures to generate queries to develop depression data using\nGPT-3, and conduct analyzes to uncover the types of stressors it assigns to\ndemographic groups, which could be used to test the limitations of LLMs for\nsynthetic data generation for depression data. Our findings show that synthetic\ndata mimics some of the human-generated data distribution for the predominant\ndepression stressors across diverse demographics.", "published": "2024-03-25 16:21:25", "link": "http://arxiv.org/abs/2403.16909v1", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language\n  Models", "abstract": "Fine-tuning in information retrieval systems using pre-trained language\nmodels (PLM-based IR) requires learning query representations and\nquery-document relations, in addition to downstream task-specific learning.\nThis study introduces coarse-tuning as an intermediate learning stage that\nbridges pre-training and fine-tuning. By learning query representations and\nquery-document relations in coarse-tuning, we aim to reduce the load of\nfine-tuning and improve the learning effect of downstream IR tasks. We propose\nQuery-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the\nappropriateness of query-document pairs. Evaluation experiments show that the\nproposed method significantly improves MRR and/or nDCG@5 in four ad-hoc\ndocument retrieval datasets. Furthermore, the results of the query prediction\ntask suggested that coarse-tuning facilitated learning of query representation\nand query-document relations.", "published": "2024-03-25 16:32:50", "link": "http://arxiv.org/abs/2403.16915v3", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "SPACE-IDEAS: A Dataset for Salient Information Detection in Space\n  Innovation", "abstract": "Detecting salient parts in text using natural language processing has been\nwidely used to mitigate the effects of information overflow. Nevertheless, most\nof the datasets available for this task are derived mainly from academic\npublications. We introduce SPACE-IDEAS, a dataset for salient information\ndetection from innovation ideas related to the Space domain. The text in\nSPACE-IDEAS varies greatly and includes informal, technical, academic and\nbusiness-oriented writing styles. In addition to a manually annotated dataset\nwe release an extended version that is annotated using a large generative\nlanguage model. We train different sentence and sequential sentence\nclassifiers, and show that the automatically annotated dataset can be leveraged\nusing multitask learning to train better classifiers.", "published": "2024-03-25 17:04:02", "link": "http://arxiv.org/abs/2403.16941v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Aligning with Human Judgement: The Role of Pairwise Preference in Large\n  Language Model Evaluators", "abstract": "Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\nevaluation, revealing that existing calibration methods aimed at mitigating\nbiases of LLMs are insufficient for effectively aligning LLM evaluators.\nInspired by the use of preference data in RLHF, we formulate the evaluation as\na ranking problem and introduce Pairwise-preference Search (PAIRS), an\nuncertainty-guided search-based rank aggregation method that employs LLMs to\nconduct pairwise comparisons locally and efficiently ranks candidate texts\nglobally. PAIRS achieves state-of-the-art performance on representative\nevaluation tasks in long-form generations and demonstrates significant\nimprovements over direct scoring. Furthermore, we provide insights into the\nrole of pairwise preference in quantifying the transitivity of LLMs and\ndemonstrate how PAIRS benefits from calibration using debiased pairwise\nevaluations.", "published": "2024-03-25 17:11:28", "link": "http://arxiv.org/abs/2403.16950v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language\n  Modeling Performance", "abstract": "Pretraining data of large language models composes multiple domains (e.g.,\nweb texts, academic papers, codes), whose mixture proportions crucially impact\nthe competence of outcome models. While existing endeavors rely on heuristics\nor qualitative strategies to tune the proportions, we discover the quantitative\npredictability of model performance regarding the mixture proportions in\nfunction forms, which we refer to as the data mixing laws. Fitting such\nfunctions on sample mixtures unveils model performance on unseen mixtures\nbefore actual runs, thus guiding the selection of an ideal data mixture.\nFurthermore, we propose nested use of the scaling laws of training steps, model\nsizes, and our data mixing law to enable predicting the performance of large\nmodels trained on massive data under various mixtures with only small-scale\ntraining. Moreover, experimental results verify that our method effectively\noptimizes the training mixture of a 1B model trained for 100B tokens in\nRedPajama, reaching a performance comparable to the one trained for 48% more\nsteps on the default mixture. Extending the application of data mixing laws to\ncontinual training accurately predicts the critical mixture proportion that\navoids catastrophic forgetting and outlooks the potential for dynamic data\nschedules", "published": "2024-03-25 17:14:00", "link": "http://arxiv.org/abs/2403.16952v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AIOS: LLM Agent Operating System", "abstract": "LLM-based intelligent agents face significant deployment challenges,\nparticularly related to resource management. Allowing unrestricted access to\nLLM or tool resources can lead to inefficient or even potentially harmful\nresource allocation and utilization for agents. Furthermore, the absence of\nproper scheduling and resource management mechanisms in current agent designs\nhinders concurrent processing and limits overall system efficiency. As the\ndiversity and complexity of agents continue to grow, addressing these resource\nmanagement issues becomes increasingly critical to LLM-based agent systems. To\naddress these challenges, this paper proposes the architecture of AIOS\n(LLM-based AI Agent Operating System) under the context of managing LLM-based\nagents. It introduces a novel architecture for serving LLM-based agents by\nisolating resources and LLM-specific services from agent applications into an\nAIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling,\ncontext management, memory management, storage management, access control) and\nefficient management of resources (e.g., LLM and external tools) for runtime\nagents. To enhance usability, AIOS also includes an AIOS-Agent SDK, a\ncomprehensive suite of APIs designed for utilizing functionalities provided by\nthe AIOS kernel. Experimental results demonstrate that using AIOS can achieve\nup to 2.1x faster execution for serving agents built by various agent\nframeworks. The source code is available at\nhttps://github.com/agiresearch/AIOS.", "published": "2024-03-25 17:32:23", "link": "http://arxiv.org/abs/2403.16971v3", "categories": ["cs.OS", "cs.AI", "cs.CL"], "primary_category": "cs.OS"}
{"title": "Language Rectified Flow: Advancing Diffusion Language Generation with\n  Probabilistic Flows", "abstract": "Recent works have demonstrated success in controlling sentence attributes\n($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the\ndiffusion language model. A key component that drives theimpressive performance\nfor generating high-quality samples from noise is iteratively denoise for\nthousands of steps. While beneficial, the complexity of starting from the noise\nand the learning steps has limited its implementation to many NLP real-world\napplications. This paper proposes Language Rectified Flow ({\\ours}). Our method\nis based on the reformulation of the standard probabilistic flow models.\nLanguage rectified flow learns (neural) ordinary differential equation models\nto transport between the source distribution and the target distribution, hence\nproviding a unified and effective solution to generative modeling and domain\ntransfer. From the source distribution, our language rectified flow yields fast\nsimulation and effectively decreases the inference time. Experiments on three\nchallenging fine-grained control tasks and multiple high-quality text editing\nshow that our method consistently outperforms its baselines. Extensive\nexperiments and ablation studies demonstrate that our method can be general,\neffective, and beneficial for many NLP tasks.", "published": "2024-03-25 17:58:22", "link": "http://arxiv.org/abs/2403.16995v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Grounding Language Plans in Demonstrations Through Counterfactual\n  Perturbations", "abstract": "Grounding the common-sense reasoning of Large Language Models (LLMs) in\nphysical domains remains a pivotal yet unsolved problem for embodied AI.\nWhereas prior works have focused on leveraging LLMs directly for planning in\nsymbolic spaces, this work uses LLMs to guide the search of task structures and\nconstraints implicit in multi-step demonstrations. Specifically, we borrow from\nmanipulation planning literature the concept of mode families, which group\nrobot configurations by specific motion constraints, to serve as an abstraction\nlayer between the high-level language representations of an LLM and the\nlow-level physical trajectories of a robot. By replaying a few human\ndemonstrations with synthetic perturbations, we generate coverage over the\ndemonstrations' state space with additional successful executions as well as\ncounterfactuals that fail the task. Our explanation-based learning framework\ntrains an end-to-end differentiable neural network to predict successful\ntrajectories from failures and as a by-product learns classifiers that ground\nlow-level states and images in mode families without dense labeling. The\nlearned grounding classifiers can further be used to translate language plans\ninto reactive policies in the physical domain in an interpretable manner. We\nshow our approach improves the interpretability and reactivity of imitation\nlearning through 2D navigation and simulated and real robot manipulation tasks.\nWebsite: https://yanweiw.github.io/glide", "published": "2024-03-25 19:04:59", "link": "http://arxiv.org/abs/2403.17124v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Exploring the Generalization of Cancer Clinical Trial Eligibility\n  Classifiers Across Diseases", "abstract": "Clinical trials are pivotal in medical research, and NLP can enhance their\nsuccess, with application in recruitment. This study aims to evaluate the\ngeneralizability of eligibility classification across a broad spectrum of\nclinical trials. Starting with phase 3 cancer trials, annotated with seven\neligibility exclusions, then to determine how well models can generalize to\nnon-cancer and non-phase 3 trials. To assess this, we have compiled eligibility\ncriteria data for five types of trials: (1) additional phase 3 cancer trials,\n(2) phase 1 and 2 cancer trials, (3) heart disease trials, (4) type 2 diabetes\ntrials, and (5) observational trials for any disease, comprising 2,490\nannotated eligibility criteria across seven exclusion types. Our results show\nthat models trained on the extensive cancer dataset can effectively handle\ncriteria commonly found in non-cancer trials, such as autoimmune diseases.\nHowever, they struggle with criteria disproportionately prevalent in cancer\ntrials, like prior malignancy. We also experiment with few-shot learning,\ndemonstrating that a limited number of disease-specific examples can partially\novercome this performance gap. We are releasing this new dataset of annotated\neligibility statements to promote the development of cross-disease\ngeneralization in clinical trial classification.", "published": "2024-03-25 19:17:59", "link": "http://arxiv.org/abs/2403.17135v1", "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large\n  Language Models", "abstract": "Classical planning formulations like the Planning Domain Definition Language\n(PDDL) admit action sequences guaranteed to achieve a goal state given an\ninitial state if any are possible. However, reasoning problems defined in PDDL\ndo not capture temporal aspects of action taking, such as concurrent actions\nbetween two agents when there are no conflicting conditions, without\nsignificant modification and definition to existing PDDL domains. A human\nexpert aware of such constraints can decompose a goal into subgoals, each\nreachable through single agent planning, to take advantage of simultaneous\nactions. In contrast to classical planning, large language models (LLMs)\ndirectly used for inferring plan steps rarely guarantee execution success, but\nare capable of leveraging commonsense reasoning to assemble action sequences.\nWe combine the strengths of both classical planning and LLMs by approximating\nhuman intuitions for multi-agent planning goal decomposition. We demonstrate\nthat LLM-based goal decomposition leads to faster planning times than solving\nmulti-agent PDDL problems directly while simultaneously achieving fewer plan\nexecution steps than a single agent plan alone, as well as most multiagent\nplans, while guaranteeing execution success. Additionally, we find that\nLLM-based approximations of subgoals result in similar multi-agent execution\nlengths to those specified by human experts. Website and resources at\nhttps://glamor-usc.github.io/twostep", "published": "2024-03-25 22:47:13", "link": "http://arxiv.org/abs/2403.17246v2", "categories": ["cs.AI", "cs.CL", "cs.MA", "cs.RO"], "primary_category": "cs.AI"}
{"title": "STRUM-LLM: Attributed and Structured Contrastive Summarization", "abstract": "Users often struggle with decision-making between two options (A vs B), as it\nusually requires time-consuming research across multiple web pages. We propose\nSTRUM-LLM that addresses this challenge by generating attributed, structured,\nand helpful contrastive summaries that highlight key differences between the\ntwo options. STRUM-LLM identifies helpful contrast: the specific attributes\nalong which the two options differ significantly and which are most likely to\ninfluence the user's decision. Our technique is domain-agnostic, and does not\nrequire any human-labeled data or fixed attribute list as supervision.\nSTRUM-LLM attributes all extractions back to the input sources along with\ntextual evidence, and it does not have a limit on the length of input sources\nthat it can process. STRUM-LLM Distilled has 100x more throughput than the\nmodels with comparable performance while being 10x smaller. In this paper, we\nprovide extensive evaluations for our method and lay out future directions for\nour currently deployed system.", "published": "2024-03-25 18:32:44", "link": "http://arxiv.org/abs/2403.19710v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal\n  Knowledge Graph Reasoning", "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing\nfacts for incomplete TKGs in complex scenarios (e.g., transductive and\ninductive settings), which has been gaining increasing attention. Recently, to\nmitigate dependence on structured connections in TKGs, text-based methods have\nbeen developed to utilize rich linguistic information from entity descriptions.\nHowever, suffering from the enormous parameters and inflexibility of\npre-trained language models, existing text-based methods struggle to balance\nthe textual knowledge and temporal information with computationally expensive\npurpose-built training strategies. To tap the potential of text-based models\nfor TKGR in various complex scenarios, we propose ChapTER, a Contrastive\nhistorical modeling framework with prefix-tuning for TEmporal Reasoning.\nChapTER feeds history-contextualized text into the pseudo-Siamese encoders to\nstrike a textual-temporal balance via contrastive estimation between queries\nand candidates. By introducing virtual time prefix tokens, it applies a\nprefix-based tuning method to facilitate the frozen PLM capable for TKGR tasks\nunder different settings. We evaluate ChapTER on four transductive and three\nfew-shot inductive TKGR benchmarks, and experimental results demonstrate that\nChapTER achieves superior performance compared to competitive baselines with\nonly 0.17% tuned parameters. We conduct thorough analysis to verify the\neffectiveness, flexibility and efficiency of ChapTER.", "published": "2024-03-25 17:25:40", "link": "http://arxiv.org/abs/2404.00051v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Advancing Speech Translation: A Corpus of Mandarin-English\n  Conversational Telephone Speech", "abstract": "This paper introduces a set of English translations for a 123-hour subset of\nthe CallHome Mandarin Chinese data and the HKUST Mandarin Telephone Speech data\nfor the task of speech translation. Paired source-language speech and\ntarget-language text is essential for training end-to-end speech translation\nsystems and can provide substantial performance improvements for cascaded\nsystems as well, relative to training on more widely available text data sets.\nWe demonstrate that fine-tuning a general-purpose translation model to our\nMandarin-English conversational telephone speech training set improves\ntarget-domain BLEU by more than 8 points, highlighting the importance of\nmatched training data.", "published": "2024-03-25 21:08:06", "link": "http://arxiv.org/abs/2404.11619v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild", "abstract": "We introduce VoiceCraft, a token infilling neural codec language model, that\nachieves state-of-the-art performance on both speech editing and zero-shot\ntext-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft\nemploys a Transformer decoder architecture and introduces a token rearrangement\nprocedure that combines causal masking and delayed stacking to enable\ngeneration within an existing sequence. On speech editing tasks, VoiceCraft\nproduces edited speech that is nearly indistinguishable from unedited\nrecordings in terms of naturalness, as evaluated by humans; for zero-shot TTS,\nour model outperforms prior SotA models including VALLE and the popular\ncommercial model XTTS-v2. Crucially, the models are evaluated on challenging\nand realistic datasets, that consist of diverse accents, speaking styles,\nrecording conditions, and background noise and music, and our model performs\nconsistently well compared to other models and real recordings. In particular,\nfor speech editing evaluation, we introduce a high quality, challenging, and\nrealistic dataset named RealEdit. We encourage readers to listen to the demos\nat https://jasonppy.github.io/VoiceCraft_web.", "published": "2024-03-25 17:38:32", "link": "http://arxiv.org/abs/2403.16973v3", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of\n  Large Speech Models", "abstract": "Parameter efficient adaptation methods have become a key mechanism to train\nlarge pre-trained models for downstream tasks. However, their per-task\nparameter overhead is considered still high when the number of downstream tasks\nto adapt for is large. We introduce an adapter module that has a better\nefficiency in large scale multi-task adaptation scenario. Our adapter is\nhierarchical in terms of how the adapter parameters are allocated. The adapter\nconsists of a single shared controller network and multiple task-level adapter\nheads to reduce the per-task parameter overhead without performance regression\non downstream tasks. The adapter is also recurrent so the entire adapter\nparameters are reused across different layers of the pre-trained model. Our\nHierarchical Recurrent Adapter (HRA) outperforms the previous adapter-based\napproaches as well as full model fine-tuning baseline in both single and\nmulti-task adaptation settings when evaluated on automatic speech recognition\ntasks.", "published": "2024-03-25 17:21:56", "link": "http://arxiv.org/abs/2403.19709v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "eess.AS"}
{"title": "Training Generative Adversarial Network-Based Vocoder with Limited Data\n  Using Augmentation-Conditional Discriminator", "abstract": "A generative adversarial network (GAN)-based vocoder trained with an\nadversarial discriminator is commonly used for speech synthesis because of its\nfast, lightweight, and high-quality characteristics. However, this data-driven\nmodel requires a large amount of training data incurring high data-collection\ncosts. This fact motivates us to train a GAN-based vocoder on limited data. A\npromising solution is to augment the training data to avoid overfitting.\nHowever, a standard discriminator is unconditional and insensitive to\ndistributional changes caused by data augmentation. Thus, augmented speech\n(which can be extraordinary) may be considered real speech. To address this\nissue, we propose an augmentation-conditional discriminator (AugCondD) that\nreceives the augmentation state as input in addition to speech, thereby\nassessing the input speech according to the augmentation state, without\ninhibiting the learning of the original non-augmented distribution.\nExperimental results indicate that AugCondD improves speech quality under\nlimited data conditions while achieving comparable speech quality under\nsufficient data conditions. Audio samples are available at\nhttps://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/augcondd/.", "published": "2024-03-25 06:46:27", "link": "http://arxiv.org/abs/2403.16464v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Distributed collaborative anomalous sound detection by embedding sharing", "abstract": "To develop a machine sound monitoring system, a method for detecting\nanomalous sound is proposed. In this paper, we explore a method for multiple\nclients to collaboratively learn an anomalous sound detection model while\nkeeping their raw data private from each other. In the context of industrial\nmachine anomalous sound detection, each client possesses data from different\nmachines or different operational states, making it challenging to learn\nthrough federated learning or split learning. In our proposed method, each\nclient calculates embeddings using a common pre-trained model developed for\nsound data classification, and these calculated embeddings are aggregated on\nthe server to perform anomalous sound detection through outlier exposure.\nExperiments showed that our proposed method improves the AUC of anomalous sound\ndetection by an average of 6.8%.", "published": "2024-03-25 10:40:04", "link": "http://arxiv.org/abs/2403.16610v1", "categories": ["eess.AS", "cs.CR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "As Good As A Coin Toss: Human detection of AI-generated images, videos,\n  audio, and audiovisual stimuli", "abstract": "Despite advancements in technology led synthetic media authentication and\nrecent government efforts to address the threats posed by maliciously employed\nsynthetic content via the mechanisms of law or through more public education,\none of the current principal defenses against weaponized synthetic media\ncontinues to be the ability of the targeted individual to visually or\nauditorily recognize AI-generated content when they encounter it. However, as\nthe realism of synthetic media continues to rapidly improve, it is vital to\nhave an accurate understanding of just how susceptible people currently are to\npotentially being misled by convincing but false AI generated content. We\nconducted a perceptual study with 1276 participants to assess how capable\npeople were at distinguishing between authentic and synthetic images, audio,\nvideo, and audiovisual media. We find that on average, people struggled to\ndistinguish between synthetic and authentic media, with the mean detection\nperformance close to a chance level performance of 50%. We also find that\naccuracy rates worsen when the stimuli contain any degree of synthetic content,\nfeatures foreign languages, and the media type is a single modality. People are\nalso less accurate at identifying synthetic images when they feature human\nfaces, and when audiovisual stimuli have heterogeneous authenticity. Finally,\nwe find that higher degrees of prior knowledgeability about synthetic media\ndoes not significantly impact detection accuracy rates, but age does, with\nolder individuals performing worse than their younger counterparts.\nCollectively, these results highlight that it is no longer feasible to rely on\nthe perceptual capabilities of people to protect themselves against the growing\nthreat of weaponized synthetic media, and that the need for alternative\ncountermeasures is more critical than ever before.", "published": "2024-03-25 13:39:33", "link": "http://arxiv.org/abs/2403.16760v4", "categories": ["cs.HC", "cs.AI", "cs.SD", "eess.AS", "68T01", "I.2"], "primary_category": "cs.HC"}
