{"title": "A Character-Word Compositional Neural Language Model for Finnish", "abstract": "Inspired by recent research, we explore ways to model the highly\nmorphological Finnish language at the level of characters while maintaining the\nperformance of word-level models. We propose a new\nCharacter-to-Word-to-Character (C2W2C) compositional language model that uses\ncharacters as input and output while still internally processing word level\nembeddings. Our preliminary experiments, using the Finnish Europarl V7 corpus,\nindicate that C2W2C can respond well to the challenges of morphologically rich\nlanguages such as high out of vocabulary rates, the prediction of novel words,\nand growing vocabulary size. Notably, the model is able to correctly score\ninflectional forms that are not present in the training data and sample\ngrammatically and semantically correct Finnish sentences character by\ncharacter.", "published": "2016-12-10 08:05:38", "link": "http://arxiv.org/abs/1612.03266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A natural language interface to a graph-based bibliographic information\n  retrieval system", "abstract": "With the ever-increasing scientific literature, there is a need on a natural\nlanguage interface to bibliographic information retrieval systems to retrieve\nrelated information effectively. In this paper, we propose a natural language\ninterface, NLI-GIBIR, to a graph-based bibliographic information retrieval\nsystem. In designing NLI-GIBIR, we developed a novel framework that can be\napplicable to graph-based bibliographic information retrieval systems. Our\nframework integrates algorithms/heuristics for interpreting and analyzing\nnatural language bibliographic queries. NLI-GIBIR allows users to search for a\nvariety of bibliographic data through natural language. A series of text- and\nlinguistic-based techniques are used to analyze and answer natural language\nqueries, including tokenization, named entity recognition, and syntactic\nanalysis. We find that our framework can effectively represents and addresses\ncomplex bibliographic information needs. Thus, the contributions of this paper\nare as follows: First, to our knowledge, it is the first attempt to propose a\nnatural language interface to graph-based bibliographic information retrieval.\nSecond, we propose a novel customized natural language processing framework\nthat integrates a few original algorithms/heuristics for interpreting and\nanalyzing natural language bibliographic queries. Third, we show that the\nproposed framework and natural language interface provide a practical solution\nin building real-world natural language interface-based bibliographic\ninformation retrieval systems. Our experimental results show that the presented\nsystem can correctly answer 39 out of 40 example natural language queries with\nvarying lengths and complexities.", "published": "2016-12-10 00:32:28", "link": "http://arxiv.org/abs/1612.03231v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Data Curation APIs", "abstract": "Understanding and analyzing big data is firmly recognized as a powerful and\nstrategic priority. For deeper interpretation of and better intelligence with\nbig data, it is important to transform raw data (unstructured, semi-structured\nand structured data sources, e.g., text, video, image data sets) into curated\ndata: contextualized data and knowledge that is maintained and made available\nfor use by end-users and applications. In particular, data curation acts as the\nglue between raw data and analytics, providing an abstraction layer that\nrelieves users from time consuming, tedious and error prone curation tasks. In\nthis context, the data curation process becomes a vital analytics asset for\nincreasing added value and insights.\n  In this paper, we identify and implement a set of curation APIs and make them\navailable (on GitHub) to researchers and developers to assist them transforming\ntheir raw data into curated data. The curation APIs enable developers to easily\nadd features - such as extracting keyword, part of speech, and named entities\nsuch as Persons, Locations, Organizations, Companies, Products, Diseases,\nDrugs, etc.; providing synonyms and stems for extracted information items\nleveraging lexical knowledge bases for the English language such as WordNet;\nlinking extracted entities to external knowledge bases such as Google Knowledge\nGraph and Wikidata; discovering similarity among the extracted information\nitems, such as calculating similarity between string, number, date and time\ndata; classifying, sorting and categorizing data into various types, forms or\nany other distinct class; and indexing structured and unstructured data - into\ntheir applications.", "published": "2016-12-10 10:54:45", "link": "http://arxiv.org/abs/1612.03277v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Active Learning for Speech Recognition: the Power of Gradients", "abstract": "In training speech recognition systems, labeling audio clips can be\nexpensive, and not all data is equally valuable. Active learning aims to label\nonly the most informative samples to reduce cost. For speech recognition,\nconfidence scores and other likelihood-based active learning methods have been\nshown to be effective. Gradient-based active learning methods, however, are\nstill not well-understood. This work investigates the Expected Gradient Length\n(EGL) approach in active learning for end-to-end speech recognition. We justify\nEGL from a variance reduction perspective, and observe that EGL's measure of\ninformativeness picks novel samples uncorrelated with confidence scores.\nExperimentally, we show that EGL can reduce word errors by 11\\%, or\nalternatively, reduce the number of samples to label by 50\\%, when compared to\nrandom sampling.", "published": "2016-12-10 00:09:45", "link": "http://arxiv.org/abs/1612.03226v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
