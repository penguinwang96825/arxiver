{"title": "RubyStar: A Non-Task-Oriented Mixture Model Dialog System", "abstract": "RubyStar is a dialog system designed to create \"human-like\" conversation by\ncombining different response generation strategies. RubyStar conducts a\nnon-task-oriented conversation on general topics by using an ensemble of\nrule-based, retrieval-based and generative methods. Topic detection, engagement\nmonitoring, and context tracking are used for managing interaction. Predictable\nelements of conversation, such as the bot's backstory and simple question\nanswering are handled by separate modules. We describe a rating scheme we\ndeveloped for evaluating response generation. We find that character-level RNN\nis an effective generation model for general responses, with proper parameter\nsettings; however other kinds of conversation topics might benefit from using\nother models.", "published": "2017-11-08 00:57:39", "link": "http://arxiv.org/abs/1711.02781v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Hypernymy Extraction with Distributional Semantic Classes", "abstract": "In this paper, we show how distributionally-induced semantic classes can be\nhelpful for extracting hypernyms. We present methods for inducing sense-aware\nsemantic classes using distributional semantics and using these induced\nsemantic classes for filtering noisy hypernymy relations. Denoising of\nhypernyms is performed by labeling each semantic class with its hypernyms. On\nthe one hand, this allows us to filter out wrong extractions using the global\nstructure of distributionally similar senses. On the other hand, we infer\nmissing hypernyms via label propagation to cluster terms. We conduct a\nlarge-scale crowdsourcing study showing that processing of automatically\nextracted hypernyms using our approach improves the quality of the hypernymy\nextraction in terms of both precision and recall. Furthermore, we show the\nutility of our method in the domain taxonomy induction task, achieving the\nstate-of-the-art results on a SemEval'16 task on taxonomy induction.", "published": "2017-11-08 12:29:18", "link": "http://arxiv.org/abs/1711.02918v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fidelity-Weighted Learning", "abstract": "Training deep neural networks requires many training samples, but in practice\ntraining labels are expensive to obtain and may be of varying quality, as some\nmay be from trusted expert labelers while others might be from heuristics or\nother sources of weak supervision such as crowd-sourcing. This creates a\nfundamental quality versus-quantity trade-off in the learning process. Do we\nlearn from the small amount of high-quality data or the potentially large\namount of weakly-labeled data? We argue that if the learner could somehow know\nand take the label-quality into account when learning the data representation,\nwe could get the best of both worlds. To this end, we propose\n\"fidelity-weighted learning\" (FWL), a semi-supervised student-teacher approach\nfor training deep neural networks using weakly-labeled data. FWL modulates the\nparameter updates to a student network (trained on the task we care about) on a\nper-sample basis according to the posterior confidence of its label-quality\nestimated by a teacher (who has access to the high-quality labels). Both\nstudent and teacher are learned from the data. We evaluate FWL on two tasks in\ninformation retrieval and natural language processing where we outperform\nstate-of-the-art alternative semi-supervised methods, indicating that our\napproach makes better use of strong and weak labels, and leads to better\ntask-dependent data representations.", "published": "2017-11-08 02:05:11", "link": "http://arxiv.org/abs/1711.02799v2", "categories": ["cs.LG", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "On the incorporation of interval-valued fuzzy sets into the Bousi-Prolog\n  system: declarative semantics, implementation and applications", "abstract": "In this paper we analyse the benefits of incorporating interval-valued fuzzy\nsets into the Bousi-Prolog system. A syntax, declarative semantics and im-\nplementation for this extension is presented and formalised. We show, by using\npotential applications, that fuzzy logic programming frameworks enhanced with\nthem can correctly work together with lexical resources and ontologies in order\nto improve their capabilities for knowledge representation and reasoning.", "published": "2017-11-08 20:25:43", "link": "http://arxiv.org/abs/1711.03147v1", "categories": ["cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.AI"}
{"title": "A joint separation-classification model for sound event detection of\n  weakly labelled data", "abstract": "Source separation (SS) aims to separate individual sources from an audio\nrecording. Sound event detection (SED) aims to detect sound events from an\naudio recording. We propose a joint separation-classification (JSC) model\ntrained only on weakly labelled audio data, that is, only the tags of an audio\nrecording are known but the time of the events are unknown. First, we propose a\nseparation mapping from the time-frequency (T-F) representation of an audio to\nthe T-F segmentation masks of the audio events. Second, a classification\nmapping is built from each T-F segmentation mask to the presence probability of\neach audio event. In the source separation stage, sources of audio events and\ntime of sound events can be obtained from the T-F segmentation masks. The\nproposed method achieves an equal error rate (EER) of 0.14 in SED,\noutperforming deep neural network baseline of 0.29. Source separation SDR of\n8.08 dB is obtained by using global weighted rank pooling (GWRP) as probability\nmapping, outperforming the global max pooling (GMP) based probability mapping\ngiving SDR at 0.03 dB. Source code of our work is published.", "published": "2017-11-08 16:28:17", "link": "http://arxiv.org/abs/1711.03037v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
