{"title": "SummQA at MEDIQA-Chat 2023:In-Context Learning with GPT-4 for Medical\n  Summarization", "abstract": "Medical dialogue summarization is challenging due to the unstructured nature\nof medical conversations, the use of medical terminology in gold summaries, and\nthe need to identify key information across multiple symptom sets. We present a\nnovel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA\n2023 Shared Task. Our approach for section-wise summarization (Task A) is a\ntwo-stage process of selecting semantically similar dialogues and using the\ntop-k similar dialogues as in-context examples for GPT-4. For full-note\nsummarization (Task B), we use a similar solution with k=1. We achieved 3rd\nplace in Task A (2nd among all teams), 4th place in Task B Division Wise\nSummarization (2nd among all teams), 15th place in Task A Section Header\nClassification (9th among all teams), and 8th place among all teams in Task B.\nOur results highlight the effectiveness of few-shot prompting for this task,\nthough we also identify several weaknesses of prompting-based approaches. We\ncompare GPT-4 performance with several finetuned baselines. We find that GPT-4\nsummaries are more abstractive and shorter. We make our code publicly\navailable.", "published": "2023-06-30 03:14:04", "link": "http://arxiv.org/abs/2306.17384v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Japanese Lexical Complexity for Non-Native Readers: A New Dataset", "abstract": "Lexical complexity prediction (LCP) is the task of predicting the complexity\nof words in a text on a continuous scale. It plays a vital role in simplifying\nor annotating complex words to assist readers. To study lexical complexity in\nJapanese, we construct the first Japanese LCP dataset. Our dataset provides\nseparate complexity scores for Chinese/Korean annotators and others to address\nthe readers' L1-specific needs. In the baseline experiment, we demonstrate the\neffectiveness of a BERT-based system for Japanese LCP.", "published": "2023-06-30 04:37:43", "link": "http://arxiv.org/abs/2306.17399v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Correct Like Humans: Progressive Learning Framework for Chinese Text\n  Error Correction", "abstract": "Chinese Text Error Correction (CTEC) aims to detect and correct errors in the\ninput text, which benefits human daily life and various downstream tasks.\nRecent approaches mainly employ Pre-trained Language Models (PLMs) to resolve\nCTEC. Although PLMs have achieved remarkable success in CTEC, we argue that\nprevious studies still overlook the importance of human thinking patterns. To\nenhance the development of PLMs for CTEC, inspired by humans' daily\nerror-correcting behavior, we propose a novel model-agnostic progressive\nlearning framework, named ProTEC, which guides PLMs-based CTEC models to learn\nto correct like humans. During the training process, ProTEC guides the model to\nlearn text error correction by incorporating these sub-tasks into a progressive\nparadigm. During the inference process, the model completes these sub-tasks in\nturn to generate the correction results. Extensive experiments and detailed\nanalyses demonstrate the effectiveness and efficiency of our proposed\nmodel-agnostic ProTEC framework.", "published": "2023-06-30 07:44:49", "link": "http://arxiv.org/abs/2306.17447v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Base Completion for Long-Tail Entities", "abstract": "Despite their impressive scale, knowledge bases (KBs), such as Wikidata,\nstill contain significant gaps. Language models (LMs) have been proposed as a\nsource for filling these gaps. However, prior works have focused on prominent\nentities with rich coverage by LMs, neglecting the crucial case of long-tail\nentities. In this paper, we present a novel method for LM-based-KB completion\nthat is specifically geared for facts about long-tail entities. The method\nleverages two different LMs in two stages: for candidate retrieval and for\ncandidate verification and disambiguation. To evaluate our method and various\nbaselines, we introduce a novel dataset, called MALT, rooted in Wikidata. Our\nmethod outperforms all baselines in F1, with major gains especially in recall.", "published": "2023-06-30 08:37:55", "link": "http://arxiv.org/abs/2306.17472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GPT-FinRE: In-context Learning for Financial Relation Extraction using\n  Large Language Models", "abstract": "Relation extraction (RE) is a crucial task in natural language processing\n(NLP) that aims to identify and classify relationships between entities\nmentioned in text. In the financial domain, relation extraction plays a vital\nrole in extracting valuable information from financial documents, such as news\narticles, earnings reports, and company filings. This paper describes our\nsolution to relation extraction on one such dataset REFinD. The dataset was\nreleased along with shared task as a part of the Fourth Workshop on Knowledge\nDiscovery from Unstructured Data in Financial Services, co-located with SIGIR\n2023. In this paper, we employed OpenAI models under the framework of\nin-context learning (ICL). We utilized two retrieval strategies to find top K\nrelevant in-context learning demonstrations / examples from training data for a\ngiven test example. The first retrieval mechanism, we employed, is a\nlearning-free dense retriever and the other system is a learning-based\nretriever. We were able to achieve 3rd rank overall. Our best F1-score is\n0.718.", "published": "2023-06-30 10:12:30", "link": "http://arxiv.org/abs/2306.17519v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Cost-aware Study of Depression Language on Social Media using Topic\n  and Affect Contextualization", "abstract": "Depression is a growing issue in society's mental health that affects all\nareas of life and can even lead to suicide. Fortunately, prevention programs\ncan be effective in its treatment. In this context, this work proposes an\nautomatic system for detecting depression on social media based on machine\nlearning and natural language processing methods. This paper presents the\nfollowing contributions: (i) an ensemble learning system that combines several\ntypes of text representations for depression detection, including recent\nadvances in the field; (ii) a contextualization schema through topic and\naffective information; (iii) an analysis of models' energy consumption,\nestablishing a trade-off between classification performance and overall\ncomputational costs. To assess the proposed models' effectiveness, a thorough\nevaluation is performed in two datasets that model depressive text. Experiments\nindicate that the proposed contextualization strategies can improve the\nclassification and that approaches that use Transformers can improve the\noverall F-score by 2% while augmenting the energy cost a hundred times.\nFinally, this work paves the way for future energy-wise systems by considering\nboth the performance classification and the energy consumption.", "published": "2023-06-30 11:34:48", "link": "http://arxiv.org/abs/2306.17564v1", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Feature Representation Learning for NL2SQL Generation Based on Coupling\n  and Decoupling", "abstract": "The NL2SQL task involves parsing natural language statements into SQL\nqueries. While most state-of-the-art methods treat NL2SQL as a slot-filling\ntask and use feature representation learning techniques, they overlook explicit\ncorrelation features between the SELECT and WHERE clauses and implicit\ncorrelation features between sub-tasks within a single clause. To address this\nissue, we propose the Clause Feature Correlation Decoupling and Coupling\n(CFCDC) model, which uses a feature representation decoupling method to\nseparate the SELECT and WHERE clauses at the parameter level. Next, we\nintroduce a multi-task learning architecture to decouple implicit correlation\nfeature representation between different SQL tasks in a specific clause.\nMoreover, we present an improved feature representation coupling module to\nintegrate the decoupled tasks in the SELECT and WHERE clauses and predict the\nfinal SQL query. Our proposed CFCDC model demonstrates excellent performance on\nthe WikiSQL dataset, with significant improvements in logic precision and\nexecution accuracy. The source code for the model will be publicly available on\nGitHub", "published": "2023-06-30 13:34:31", "link": "http://arxiv.org/abs/2306.17646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical Language Models are Robust to Sub-optimal Tokenization", "abstract": "As opposed to general English, many concepts in biomedical terminology have\nbeen designed in recent history by biomedical professionals with the goal of\nbeing precise and concise. This is often achieved by concatenating meaningful\nbiomedical morphemes to create new semantic units. Nevertheless, most modern\nbiomedical language models (LMs) are pre-trained using standard domain-specific\ntokenizers derived from large scale biomedical corpus statistics without\nexplicitly leveraging the agglutinating nature of biomedical language. In this\nwork, we first find that standard open-domain and biomedical tokenizers are\nlargely unable to segment biomedical terms into meaningful components.\nTherefore, we hypothesize that using a tokenizer which segments biomedical\nterminology more accurately would enable biomedical LMs to improve their\nperformance on downstream biomedical NLP tasks, especially ones which involve\nbiomedical terms directly such as named entity recognition (NER) and entity\nlinking. Surprisingly, we find that pre-training a biomedical LM using a more\naccurate biomedical tokenizer does not improve the entity representation\nquality of a language model as measured by several intrinsic and extrinsic\nmeasures such as masked language modeling prediction (MLM) accuracy as well as\nNER and entity linking performance. These quantitative findings, along with a\ncase study which explores entity representation quality more directly, suggest\nthat the biomedical pre-training process is quite robust to instances of\nsub-optimal tokenization.", "published": "2023-06-30 13:35:24", "link": "http://arxiv.org/abs/2306.17649v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and\n  Few-shot Agents", "abstract": "Task-oriented dialogue research has mainly focused on a few popular languages\nlike English and Chinese, due to the high dataset creation cost for a new\nlanguage. To reduce the cost, we apply manual editing to automatically\ntranslated data. We create a new multilingual benchmark, X-RiSAWOZ, by\ntranslating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean;\nand a code-mixed English-Hindi language. X-RiSAWOZ has more than 18,000\nhuman-verified dialogue utterances for each language, and unlike most\nmultilingual prior work, is an end-to-end dataset for building\nfully-functioning agents.\n  The many difficulties we encountered in creating X-RiSAWOZ led us to develop\na toolset to accelerate the post-editing of a new language dataset after\ntranslation. This toolset improves machine translation with a hybrid entity\nalignment technique that combines neural with dictionary-based methods, along\nwith many automated and semi-automated validation checks.\n  We establish strong baselines for X-RiSAWOZ by training dialogue agents in\nthe zero- and few-shot settings where limited gold data is available in the\ntarget language. Our results suggest that our translation and post-editing\nmethodology and toolset can be used to create new high-quality multilingual\ndialogue agents cost-effectively. Our dataset, code, and toolkit are released\nopen-source.", "published": "2023-06-30 14:03:30", "link": "http://arxiv.org/abs/2306.17674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Task and Dataset on Detecting Attacks on Human Rights Defenders", "abstract": "The ability to conduct retrospective analyses of attacks on human rights\ndefenders over time and by location is important for humanitarian organizations\nto better understand historical or ongoing human rights violations and thus\nbetter manage the global impact of such events. We hypothesize that NLP can\nsupport such efforts by quickly processing large collections of news articles\nto detect and summarize the characteristics of attacks on human rights\ndefenders. To that end, we propose a new dataset for detecting Attacks on Human\nRights Defenders (HRDsAttack) consisting of crowdsourced annotations on 500\nonline news articles. The annotations include fine-grained information about\nthe type and location of the attacks, as well as information about the\nvictim(s). We demonstrate the usefulness of the dataset by using it to train\nand evaluate baseline models on several sub-tasks to predict the annotated\ncharacteristics.", "published": "2023-06-30 14:20:06", "link": "http://arxiv.org/abs/2306.17695v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved NL2SQL based on Multi-layer Expert Network", "abstract": "The Natural Language to SQL (NL2SQL) technique is used to convert natural\nlanguage queries into executable SQL statements. Typically, slot-filling is\nemployed as a classification method for multi-task cases to achieve this goal.\nHowever, slot-filling can result in inaccurate SQL statement generation due to\nnegative migration issues arising from different classification tasks. To\novercome this limitation, this study introduces a new approach called\nMulti-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated\nmulti-task hierarchical network. The lower layer of the network extracts\nsemantic features of natural language statements, while the upper layer builds\na specialized expert system for handling specific classification tasks. This\nhierarchical approach mitigates performance degradation resulting from\ndifferent task conflicts. The proposed method was evaluated on the WiKSQL\ndataset and was found to be effective in generating accurate SQL statements.", "published": "2023-06-30 15:16:52", "link": "http://arxiv.org/abs/2306.17727v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Should you marginalize over possible tokenizations?", "abstract": "Autoregressive language models (LMs) map token sequences to probabilities.\nThe usual practice for computing the probability of any character string (e.g.\nEnglish sentences) is to first transform it into a sequence of tokens that is\nscored by the model. However, there are exponentially many token sequences that\nrepresent any given string. To truly compute the probability of a string one\nshould marginalize over all tokenizations, which is typically intractable.\nHere, we analyze whether the practice of ignoring the marginalization is\njustified. To this end, we devise an importance-sampling-based algorithm that\nallows us to compute estimates of the marginal probabilities and compare them\nto the default procedure in a range of state-of-the-art models and datasets.\nOur results show that the gap in log-likelihood is no larger than 0.5% in most\ncases, but that it becomes more pronounced for data with long complex words.", "published": "2023-06-30 16:09:01", "link": "http://arxiv.org/abs/2306.17757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language\n  Models", "abstract": "Neural-symbolic methods have demonstrated efficiency in enhancing the\nreasoning abilities of large language models (LLMs). However, existing methods\nmainly rely on syntactically mapping natural languages to complete formal\nlanguages like Python and SQL. Those methods require that reasoning tasks be\nconvertible into programs, which cater to the computer execution mindset and\ndeviate from human reasoning habits. To broaden symbolic methods' applicability\nand adaptability in the real world, we propose the Meta-Reasoning from a\nlinguistic perspective. This method empowers LLMs to deconstruct\nreasoning-independent semantic information into generic symbolic\nrepresentations, thereby efficiently capturing more generalized reasoning\nknowledge. We conduct extensive experiments on more than ten datasets\nencompassing conventional reasoning tasks like arithmetic, symbolic, and\nlogical reasoning, and the more complex interactive reasoning tasks like\ntheory-of-mind reasoning. Experimental results demonstrate that Meta-Reasoning\nsignificantly enhances in-context reasoning accuracy, learning efficiency,\nout-of-domain generalization, and output stability compared to the\nChain-of-Thought technique. Code and data are publicly available at\n\\url{https://github.com/Alsace08/Meta-Reasoning}.", "published": "2023-06-30 17:38:10", "link": "http://arxiv.org/abs/2306.17820v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meta-training with Demonstration Retrieval for Efficient Few-shot\n  Learning", "abstract": "Large language models show impressive results on few-shot NLP tasks. However,\nthese models are memory and computation-intensive. Meta-training allows one to\nleverage smaller models for few-shot generalization in a domain-general and\ntask-agnostic manner; however, these methods alone results in models that may\nnot have sufficient parameterization or knowledge to adapt quickly to a large\nvariety of tasks. To overcome this issue, we propose meta-training with\ndemonstration retrieval, where we use a dense passage retriever to retrieve\nsemantically similar labeled demonstrations to each example for more varied\nsupervision. By separating external knowledge from model parameters, we can use\nmeta-training to train parameter-efficient models that generalize well on a\nlarger variety of tasks. We construct a meta-training set from UnifiedQA and\nCrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our\nknowledge, our work is the first to combine retrieval with meta-training, to\nuse DPR models to retrieve demonstrations, and to leverage demonstrations from\nmany tasks simultaneously, rather than randomly sampling demonstrations from\nthe training set of the target task. Our approach outperforms a variety of\ntargeted parameter-efficient and retrieval-augmented few-shot methods on QA,\nNLI, and text classification tasks (including SQuAD, QNLI, and TREC). Our\napproach can be meta-trained and fine-tuned quickly on a single GPU.", "published": "2023-06-30 20:16:22", "link": "http://arxiv.org/abs/2307.00119v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Information Extraction in Domain and Generic Documents: Findings from\n  Heuristic-based and Data-driven Approaches", "abstract": "Information extraction (IE) plays very important role in natural language\nprocessing (NLP) and is fundamental to many NLP applications that used to\nextract structured information from unstructured text data. Heuristic-based\nsearching and data-driven learning are two main stream implementation\napproaches. However, no much attention has been paid to document genre and\nlength influence on IE tasks. To fill the gap, in this study, we investigated\nthe accuracy and generalization abilities of heuristic-based searching and\ndata-driven to perform two IE tasks: named entity recognition (NER) and\nsemantic role labeling (SRL) on domain-specific and generic documents with\ndifferent length. We posited two hypotheses: first, short documents may yield\nbetter accuracy results compared to long documents; second, generic documents\nmay exhibit superior extraction outcomes relative to domain-dependent documents\ndue to training document genre limitations. Our findings reveals that no single\nmethod demonstrated overwhelming performance in both tasks. For named entity\nextraction, data-driven approaches outperformed symbolic methods in terms of\naccuracy, particularly in short texts. In the case of semantic roles\nextraction, we observed that heuristic-based searching method and data-driven\nbased model with syntax representation surpassed the performance of pure\ndata-driven approach which only consider semantic information. Additionally, we\ndiscovered that different semantic roles exhibited varying accuracy levels with\nthe same method. This study offers valuable insights for downstream text mining\ntasks, such as NER and SRL, when addressing various document features and\ngenres.", "published": "2023-06-30 20:43:27", "link": "http://arxiv.org/abs/2307.00130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "iMETRE: Incorporating Markers of Entity Types for Relation Extraction", "abstract": "Sentence-level relation extraction (RE) aims to identify the relationship\nbetween 2 entities given a contextual sentence. While there have been many\nattempts to solve this problem, the current solutions have a lot of room to\nimprove. In this paper, we approach the task of relationship extraction in the\nfinancial dataset REFinD. Our approach incorporates typed entity markers\nrepresentations and various models finetuned on the dataset, which has allowed\nus to achieve an F1 score of 69.65% on the validation set. Through this paper,\nwe discuss various approaches and possible limitations.", "published": "2023-06-30 20:54:41", "link": "http://arxiv.org/abs/2307.00132v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SMILE: Evaluation and Domain Adaptation for Social Media Language\n  Understanding", "abstract": "We study the ability of transformer-based language models (LMs) to understand\nsocial media language. Social media (SM) language is distinct from standard\nwritten language, yet existing benchmarks fall short of capturing LM\nperformance in this socially, economically, and politically important domain.\nWe quantify the degree to which social media language differs from conventional\nlanguage and conclude that the difference is significant both in terms of token\ndistribution and rate of linguistic shift. Next, we introduce a new benchmark\nfor Social MedIa Language Evaluation (SMILE) that covers four SM platforms and\neleven tasks. Finally, we show that learning a tokenizer and pretraining on a\nmix of social media and conventional language yields an LM that outperforms the\nbest similar-sized alternative by 4.2 points on the overall SMILE score.", "published": "2023-06-30 21:04:59", "link": "http://arxiv.org/abs/2307.00135v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Provable Robust Watermarking for AI-Generated Text", "abstract": "We study the problem of watermarking large language models (LLMs) generated\ntext -- one of the most promising approaches for addressing the safety\nchallenges of LLM usage. In this paper, we propose a rigorous theoretical\nframework to quantify the effectiveness and robustness of LLM watermarks. We\npropose a robust and high-quality watermark method, Unigram-Watermark, by\nextending an existing approach with a simplified fixed grouping strategy. We\nprove that our watermark method enjoys guaranteed generation quality,\ncorrectness in watermark detection, and is robust against text editing and\nparaphrasing. Experiments on three varying LLMs and two datasets verify that\nour Unigram-Watermark achieves superior detection accuracy and comparable\ngeneration quality in perplexity, thus promoting the responsible use of LLMs.\nCode is available at https://github.com/XuandongZhao/Unigram-Watermark.", "published": "2023-06-30 07:24:32", "link": "http://arxiv.org/abs/2306.17439v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring\n  of Learning Objectives", "abstract": "We evaluated the capability of a generative pre-trained transformer (GPT-4)\nto automatically generate high-quality learning objectives (LOs) in the context\nof a practically oriented university course on Artificial Intelligence.\nDiscussions of opportunities (e.g., content generation, explanation) and risks\n(e.g., cheating) of this emerging technology in education have intensified, but\nto date there has not been a study of the models' capabilities in supporting\nthe course design and authoring of LOs. LOs articulate the knowledge and skills\nlearners are intended to acquire by engaging with a course. To be effective,\nLOs must focus on what students are intended to achieve, focus on specific\ncognitive processes, and be measurable. Thus, authoring high-quality LOs is a\nchallenging and time consuming (i.e., expensive) effort. We evaluated 127 LOs\nthat were automatically generated based on a carefully crafted prompt (detailed\nguidelines on high-quality LOs authoring) submitted to GPT-4 for conceptual\nmodules and projects of an AI Practitioner course. We analyzed the generated\nLOs if they follow certain best practices such as beginning with action verbs\nfrom Bloom's taxonomy in regards to the level of sophistication intended. Our\nanalysis showed that the generated LOs are sensible, properly expressed (e.g.,\nstarting with an action verb), and that they largely operate at the appropriate\nlevel of Bloom's taxonomy, respecting the different nature of the conceptual\nmodules (lower levels) and projects (higher levels). Our results can be\nleveraged by instructors and curricular designers wishing to take advantage of\nthe state-of-the-art generative models to support their curricular and course\ndesign efforts.", "published": "2023-06-30 08:15:18", "link": "http://arxiv.org/abs/2306.17459v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Preference Ranking Optimization for Human Alignment", "abstract": "Large language models (LLMs) often contain misleading content, emphasizing\nthe need to align them with human values to ensure secure AI systems.\nReinforcement learning from human feedback (RLHF) has been employed to achieve\nthis alignment. However, it encompasses two main drawbacks: (1) RLHF exhibits\ncomplexity, instability, and sensitivity to hyperparameters in contrast to SFT.\n(2) Despite massive trial-and-error, multiple sampling is reduced to pair-wise\ncontrast, thus lacking contrasts from a macro perspective. In this paper, we\npropose Preference Ranking Optimization (PRO) as an efficient SFT algorithm to\ndirectly fine-tune LLMs for human alignment. PRO extends the pair-wise contrast\nto accommodate preference rankings of any length. By iteratively contrasting\ncandidates, PRO instructs the LLM to prioritize the best response while\nprogressively ranking the rest responses. In this manner, PRO effectively\ntransforms human alignment into aligning the probability ranking of n responses\ngenerated by LLM with the preference ranking of humans towards these responses.\nExperiments have shown that PRO outperforms baseline algorithms, achieving\ncomparable results to ChatGPT and human responses through automatic-based,\nreward-based, GPT-4, and human evaluations.", "published": "2023-06-30 09:07:37", "link": "http://arxiv.org/abs/2306.17492v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards the extraction of robust sign embeddings for low resource sign\n  language recognition", "abstract": "Isolated Sign Language Recognition (SLR) has mostly been applied on datasets\ncontaining signs executed slowly and clearly by a limited group of signers. In\nreal-world scenarios, however, we are met with challenging visual conditions,\ncoarticulated signing, small datasets, and the need for signer independent\nmodels. To tackle this difficult problem, we require a robust feature extractor\nto process the sign language videos. One could expect human pose estimators to\nbe ideal candidates. However, due to a domain mismatch with their training sets\nand challenging poses in sign language, they lack robustness on sign language\ndata and image-based models often still outperform keypoint-based models.\nFurthermore, whereas the common practice of transfer learning with image-based\nmodels yields even higher accuracy, keypoint-based models are typically trained\nfrom scratch on every SLR dataset. These factors limit their usefulness for\nSLR. From the existing literature, it is also not clear which, if any, pose\nestimator performs best for SLR. We compare the three most popular pose\nestimators for SLR: OpenPose, MMPose and MediaPipe. We show that through\nkeypoint normalization, missing keypoint imputation, and learning a pose\nembedding, we can obtain significantly better results and enable transfer\nlearning. We show that keypoint-based embeddings contain cross-lingual\nfeatures: they can transfer between sign languages and achieve competitive\nperformance even when fine-tuning only the classifier layer of an SLR model on\na target sign language. We furthermore achieve better performance using\nfine-tuned transferred embeddings than models trained only on the target sign\nlanguage. The embeddings can also be learned in a multilingual fashion. The\napplication of these embeddings could prove particularly useful for low\nresource sign languages in the future.", "published": "2023-06-30 11:21:40", "link": "http://arxiv.org/abs/2306.17558v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Token-Event-Role Structure-based Multi-Channel Document-Level Event\n  Extraction", "abstract": "Document-level event extraction is a long-standing challenging information\nretrieval problem involving a sequence of sub-tasks: entity extraction, event\ntype judgment, and event type-specific multi-event extraction. However,\naddressing the problem as multiple learning tasks leads to increased model\ncomplexity. Also, existing methods insufficiently utilize the correlation of\nentities crossing different events, resulting in limited event extraction\nperformance. This paper introduces a novel framework for document-level event\nextraction, incorporating a new data structure called token-event-role and a\nmulti-channel argument role prediction module. The proposed data structure\nenables our model to uncover the primary role of tokens in multiple events,\nfacilitating a more comprehensive understanding of event relationships. By\nleveraging the multi-channel prediction module, we transform entity and\nmulti-event extraction into a single task of predicting token-event pairs,\nthereby reducing the overall parameter size and enhancing model efficiency. The\nresults demonstrate that our approach outperforms the state-of-the-art method\nby 9.5 percentage points in terms of the F1 score, highlighting its superior\nperformance in event extraction. Furthermore, an ablation study confirms the\nsignificant value of the proposed data structure in improving event extraction\ntasks, further validating its importance in enhancing the overall performance\nof the framework.", "published": "2023-06-30 15:22:57", "link": "http://arxiv.org/abs/2306.17733v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Statler: State-Maintaining Language Models for Embodied Reasoning", "abstract": "There has been a significant research interest in employing large language\nmodels to empower intelligent robots with complex reasoning. Existing work\nfocuses on harnessing their abilities to reason about the histories of their\nactions and observations. In this paper, we explore a new dimension in which\nlarge language models may benefit robotics planning. In particular, we propose\nStatler, a framework in which large language models are prompted to maintain an\nestimate of the world state, which are often unobservable, and track its\ntransition as new actions are taken. Our framework then conditions each action\non the estimate of the current world state. Despite being conceptually simple,\nour Statler framework significantly outperforms strong competing methods (e.g.,\nCode-as-Policies) on several robot planning tasks. Additionally, it has the\npotential advantage of scaling up to more challenging long-horizon planning\ntasks.", "published": "2023-06-30 17:58:02", "link": "http://arxiv.org/abs/2306.17840v4", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Queer People are People First: Deconstructing Sexual Identity\n  Stereotypes in Large Language Models", "abstract": "Large Language Models (LLMs) are trained primarily on minimally processed web\ntext, which exhibits the same wide range of social biases held by the humans\nwho created that content. Consequently, text generated by LLMs can\ninadvertently perpetuate stereotypes towards marginalized groups, like the\nLGBTQIA+ community. In this paper, we perform a comparative study of how LLMs\ngenerate text describing people with different sexual identities. Analyzing\nbias in the text generated by an LLM using regard score shows measurable bias\nagainst queer people. We then show that a post-hoc method based on\nchain-of-thought prompting using SHAP analysis can increase the regard of the\nsentence, representing a promising approach towards debiasing the output of\nLLMs in this setting.", "published": "2023-06-30 19:39:01", "link": "http://arxiv.org/abs/2307.00101v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Still No Lie Detector for Language Models: Probing Empirical and\n  Conceptual Roadblocks", "abstract": "We consider the questions of whether or not large language models (LLMs) have\nbeliefs, and, if they do, how we might measure them. First, we evaluate two\nexisting approaches, one due to Azaria and Mitchell (2023) and the other to\nBurns et al. (2022). We provide empirical results that show that these methods\nfail to generalize in very basic ways. We then argue that, even if LLMs have\nbeliefs, these methods are unlikely to be successful for conceptual reasons.\nThus, there is still no lie-detector for LLMs. After describing our empirical\nresults we take a step back and consider whether or not we should expect LLMs\nto have something like beliefs in the first place. We consider some recent\narguments aiming to show that LLMs cannot have beliefs. We show that these\narguments are misguided. We provide a more productive framing of questions\nsurrounding the status of beliefs in LLMs, and highlight the empirical nature\nof the problem. We conclude by suggesting some concrete paths for future work.", "published": "2023-06-30 23:44:51", "link": "http://arxiv.org/abs/2307.00175v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An automated method for the ontological representation of security\n  directives", "abstract": "Large documents written in juridical language are difficult to interpret,\nwith long sentences leading to intricate and intertwined relations between the\nnouns. The present paper frames this problem in the context of recent European\nsecurity directives. The complexity of their language is here thwarted by\nautomating the extraction of the relevant information, namely of the parts of\nspeech from each clause, through a specific tailoring of Natural Language\nProcessing (NLP) techniques. These contribute, in combination with ontology\ndevelopment principles, to the design of our automated method for the\nrepresentation of security directives as ontologies. The method is showcased on\na practical problem, namely to derive an ontology representing the NIS 2\ndirective, which is the peak of cybersecurity prescripts at the European level.\nAlthough the NLP techniques adopted showed some limitations and had to be\ncomplemented by manual analysis, the overall results provide valid support for\ndirective compliance in general and for ontology development in particular.", "published": "2023-06-30 09:04:47", "link": "http://arxiv.org/abs/2307.01211v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LMBot: Distilling Graph Knowledge into Language Model for Graph-less\n  Deployment in Twitter Bot Detection", "abstract": "As malicious actors employ increasingly advanced and widespread bots to\ndisseminate misinformation and manipulate public opinion, the detection of\nTwitter bots has become a crucial task. Though graph-based Twitter bot\ndetection methods achieve state-of-the-art performance, we find that their\ninference depends on the neighbor users multi-hop away from the targets, and\nfetching neighbors is time-consuming and may introduce bias. At the same time,\nwe find that after finetuning on Twitter bot detection, pretrained language\nmodels achieve competitive performance and do not require a graph structure\nduring deployment. Inspired by this finding, we propose a novel bot detection\nframework LMBot that distills the knowledge of graph neural networks (GNNs)\ninto language models (LMs) for graph-less deployment in Twitter bot detection\nto combat the challenge of data dependency. Moreover, LMBot is compatible with\ngraph-based and graph-less datasets. Specifically, we first represent each user\nas a textual sequence and feed them into the LM for domain adaptation. For\ngraph-based datasets, the output of LMs provides input features for the GNN,\nenabling it to optimize for bot detection and distill knowledge back to the LM\nin an iterative, mutually enhancing process. Armed with the LM, we can perform\ngraph-less inference, which resolves the graph data dependency and sampling\nbias issues. For datasets without graph structure, we simply replace the GNN\nwith an MLP, which has also shown strong performance. Our experiments\ndemonstrate that LMBot achieves state-of-the-art performance on four Twitter\nbot detection benchmarks. Extensive studies also show that LMBot is more\nrobust, versatile, and efficient compared to graph-based Twitter bot detection\nmethods.", "published": "2023-06-30 05:50:26", "link": "http://arxiv.org/abs/2306.17408v3", "categories": ["cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.AI"}
{"title": "Large Language Models are Effective Text Rankers with Pairwise Ranking\n  Prompting", "abstract": "Ranking documents using Large Language Models (LLMs) by directly feeding the\nquery and candidate documents into the prompt is an interesting and practical\nproblem. However, researchers have found it difficult to outperform fine-tuned\nbaseline rankers on benchmark datasets. We analyze pointwise and listwise\nranking prompts used by existing methods and argue that off-the-shelf LLMs do\nnot fully understand these challenging ranking formulations. In this paper, we\npropose to significantly reduce the burden on LLMs by using a new technique\ncalled Pairwise Ranking Prompting (PRP). Our results are the first in the\nliterature to achieve state-of-the-art ranking performance on standard\nbenchmarks using moderate-sized open-sourced LLMs. On TREC-DL 2019&2020, PRP\nbased on the Flan-UL2 model with 20B parameters performs favorably with the\nprevious best approach in the literature, which is based on the blackbox\ncommercial GPT-4 that has 50x (estimated) model size, while outperforming other\nLLM-based solutions, such as InstructGPT which has 175B parameters, by over 10%\nfor all ranking metrics. By using the same prompt template on seven BEIR tasks,\nPRP outperforms supervised baselines and outperforms the blackbox commercial\nChatGPT solution by 4.2% and pointwise LLM-based solutions by more than 10% on\naverage NDCG@10. Furthermore, we propose several variants of PRP to improve\nefficiency and show that it is possible to achieve competitive results even\nwith linear complexity.", "published": "2023-06-30 11:32:25", "link": "http://arxiv.org/abs/2306.17563v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Augmenting Holistic Review in University Admission using Natural\n  Language Processing for Essays and Recommendation Letters", "abstract": "University admission at many highly selective institutions uses a holistic\nreview process, where all aspects of the application, including protected\nattributes (e.g., race, gender), grades, essays, and recommendation letters are\nconsidered, to compose an excellent and diverse class. In this study, we\nempirically evaluate how influential protected attributes are for predicting\nadmission decisions using a machine learning (ML) model, and in how far textual\ninformation (e.g., personal essay, teacher recommendation) may substitute for\nthe loss of protected attributes in the model. Using data from 14,915\napplicants to an undergraduate admission office at a selective U.S. institution\nin the 2022-2023 cycle, we find that the exclusion of protected attributes from\nthe ML model leads to substantially reduced admission-prediction performance.\nThe inclusion of textual information via both a TF-IDF representation and a\nLatent Dirichlet allocation (LDA) model partially restores model performance,\nbut does not appear to provide a full substitute for admitting a similarly\ndiverse class. In particular, while the text helps with gender diversity, the\nproportion of URM applicants is severely impacted by the exclusion of protected\nattributes, and the inclusion of new attributes generated from the textual\ninformation does not recover this performance loss.", "published": "2023-06-30 11:51:08", "link": "http://arxiv.org/abs/2306.17575v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Improving the Performance of Pre-Trained Speech Models for\n  Low-Resource Languages Through Lateral Inhibition", "abstract": "With the rise of bidirectional encoder representations from Transformer\nmodels in natural language processing, the speech community has adopted some of\ntheir development methodologies. Therefore, the Wav2Vec models were introduced\nto reduce the data required to obtain state-of-the-art results. This work\nleverages this knowledge and improves the performance of the pre-trained speech\nmodels by simply replacing the fine-tuning dense layer with a lateral\ninhibition layer inspired by the biological process. Our experiments on\nRomanian, a low-resource language, show an average improvement of 12.5% word\nerror rate (WER) using the lateral inhibition layer. In addition, we obtain\nstate-of-the-art results on both the Romanian Speech Corpus and the Robin\nTechnical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.", "published": "2023-06-30 16:48:22", "link": "http://arxiv.org/abs/2306.17792v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Stay on topic with Classifier-Free Guidance", "abstract": "Classifier-Free Guidance (CFG) has recently emerged in text-to-image\ngeneration as a lightweight technique to encourage prompt-adherence in\ngenerations. In this work, we demonstrate that CFG can be used broadly as an\ninference-time technique in pure language modeling. We show that CFG (1)\nimproves the performance of Pythia, GPT-2 and LLaMA-family models across an\narray of tasks: Q\\&A, reasoning, code generation, and machine translation,\nachieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements\nequivalent to a model with twice the parameter-count; (3) can stack alongside\nother inference-time methods like Chain-of-Thought and Self-Consistency,\nyielding further improvements in difficult tasks; (4) can be used to increase\nthe faithfulness and coherence of assistants in challenging form-driven and\ncontent-driven prompts: in a human evaluation we show a 75\\% preference for\nGPT4All using CFG over baseline.", "published": "2023-06-30 17:07:02", "link": "http://arxiv.org/abs/2306.17806v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Massive Scale Semantic Similarity Dataset of Historical English", "abstract": "A diversity of tasks use language models trained on semantic similarity data.\nWhile there are a variety of datasets that capture semantic similarity, they\nare either constructed from modern web data or are relatively small datasets\ncreated in the past decade by human annotators. This study utilizes a novel\nsource, newly digitized articles from off-copyright, local U.S. newspapers, to\nassemble a massive-scale semantic similarity dataset spanning 70 years from\n1920 to 1989 and containing nearly 400M positive semantic similarity pairs.\nHistorically, around half of articles in U.S. local newspapers came from\nnewswires like the Associated Press. While local papers reproduced articles\nfrom the newswire, they wrote their own headlines, which form abstractive\nsummaries of the associated articles. We associate articles and their headlines\nby exploiting document layouts and language understanding. We then use deep\nneural methods to detect which articles are from the same underlying source, in\nthe presence of substantial noise and abridgement. The headlines of reproduced\narticles form positive semantic similarity pairs. The resulting publicly\navailable HEADLINES dataset is significantly larger than most existing semantic\nsimilarity datasets and covers a much longer span of time. It will facilitate\nthe application of contrastively trained semantic similarity models to a\nvariety of tasks, including the study of semantic change across space and time.", "published": "2023-06-30 17:16:04", "link": "http://arxiv.org/abs/2306.17810v2", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen\n  LLMs", "abstract": "In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling\nfrozen LLMs to perform both understanding and generation tasks involving\nnon-linguistic modalities such as images or videos. SPAE converts between raw\npixels and interpretable lexical tokens (or words) extracted from the LLM's\nvocabulary. The resulting tokens capture both the semantic meaning and the\nfine-grained details needed for visual reconstruction, effectively translating\nthe visual content into a language comprehensible to the LLM, and empowering it\nto perform a wide array of multimodal tasks. Our approach is validated through\nin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set\nof image understanding and generation tasks. Our method marks the first\nsuccessful attempt to enable a frozen LLM to generate image content while\nsurpassing state-of-the-art performance in image understanding tasks, under the\nsame setting, by over 25%.", "published": "2023-06-30 17:59:07", "link": "http://arxiv.org/abs/2306.17842v3", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Ticket-BERT: Labeling Incident Management Tickets with Language Models", "abstract": "An essential aspect of prioritizing incident tickets for resolution is\nefficiently labeling tickets with fine-grained categories. However, ticket data\nis often complex and poses several unique challenges for modern machine\nlearning methods: (1) tickets are created and updated either by machines with\npre-defined algorithms or by engineers with domain expertise that share\ndifferent protocols, (2) tickets receive frequent revisions that update ticket\nstatus by modifying all or parts of ticket descriptions, and (3) ticket\nlabeling is time-sensitive and requires knowledge updates and new labels per\nthe rapid software and hardware improvement lifecycle. To handle these issues,\nwe introduce Ticket- BERT which trains a simple yet robust language model for\nlabeling tickets using our proposed ticket datasets. Experiments demonstrate\nthe superiority of Ticket-BERT over baselines and state-of-the-art text\nclassifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT\nwith an active learning cycle and deploy it on the Microsoft IcM system, which\nenables the model to quickly finetune on newly-collected tickets with a few\nannotations.", "published": "2023-06-30 19:48:25", "link": "http://arxiv.org/abs/2307.00108v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Do Self-Supervised Speech Models Know About Words?", "abstract": "Many self-supervised speech models (S3Ms) have been introduced over the last\nfew years, improving performance and data efficiency on various speech tasks.\nHowever, these empirical successes alone do not give a complete picture of what\nis learned during pre-training. Recent work has begun analyzing how S3Ms encode\ncertain properties, such as phonetic and speaker information, but we still lack\na proper understanding of knowledge encoded at the word level and beyond. In\nthis work, we use lightweight analysis methods to study segment-level\nlinguistic properties -- word identity, boundaries, pronunciation, syntactic\nfeatures, and semantic features -- encoded in S3Ms. We present a comparative\nstudy of layer-wise representations from ten S3Ms and find that (i) the\nframe-level representations within each word segment are not all equally\ninformative, and (ii) the pre-training objective and model size heavily\ninfluence the accessibility and distribution of linguistic information across\nlayers. We also find that on several tasks -- word discrimination, word\nsegmentation, and semantic sentence similarity -- S3Ms trained with visual\ngrounding outperform their speech-only counterparts. Finally, our task-based\nanalyses demonstrate improved performance on word segmentation and acoustic\nword discrimination while using simpler methods than prior work.", "published": "2023-06-30 22:36:41", "link": "http://arxiv.org/abs/2307.00162v3", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Counterfactual Collaborative Reasoning", "abstract": "Causal reasoning and logical reasoning are two important types of reasoning\nabilities for human intelligence. However, their relationship has not been\nextensively explored under machine intelligence context. In this paper, we\nexplore how the two reasoning abilities can be jointly modeled to enhance both\naccuracy and explainability of machine learning models. More specifically, by\nintegrating two important types of reasoning ability -- counterfactual\nreasoning and (neural) logical reasoning -- we propose Counterfactual\nCollaborative Reasoning (CCR), which conducts counterfactual logic reasoning to\nimprove the performance. In particular, we use recommender system as an example\nto show how CCR alleviate data scarcity, improve accuracy and enhance\ntransparency. Technically, we leverage counterfactual reasoning to generate\n\"difficult\" counterfactual training examples for data augmentation, which --\ntogether with the original training examples -- can enhance the model\nperformance. Since the augmented data is model irrelevant, they can be used to\nenhance any model, enabling the wide applicability of the technique. Besides,\nmost of the existing data augmentation methods focus on \"implicit data\naugmentation\" over users' implicit feedback, while our framework conducts\n\"explicit data augmentation\" over users explicit feedback based on\ncounterfactual logic reasoning. Experiments on three real-world datasets show\nthat CCR achieves better performance than non-augmented models and implicitly\naugmented models, and also improves model transparency by generating\ncounterfactual explanations.", "published": "2023-06-30 23:01:10", "link": "http://arxiv.org/abs/2307.00165v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "The Integer Linear Programming Inference Cookbook", "abstract": "Over the years, integer linear programs have been employed to model inference\nin many natural language processing problems. This survey is meant to guide the\nreader through the process of framing a new inference problem as an instance of\nan integer linear program and is structured as a collection of recipes. At the\nend, we will see two worked examples to illustrate the use of these recipes.", "published": "2023-06-30 23:33:11", "link": "http://arxiv.org/abs/2307.00171v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Multi-Dialectal Representation Learning of Sinitic Phonology", "abstract": "Machine learning techniques have shown their competence for representing and\nreasoning in symbolic systems such as language and phonology. In Sinitic\nHistorical Phonology, notable tasks that could benefit from machine learning\ninclude the comparison of dialects and reconstruction of proto-languages\nsystems. Motivated by this, this paper provides an approach for obtaining\nmulti-dialectal representations of Sinitic syllables, by constructing a\nknowledge graph from structured phonological data, then applying the BoxE\ntechnique from knowledge base learning. We applied unsupervised clustering\ntechniques to the obtained representations to observe that the representations\ncapture phonemic contrast from the input dialects. Furthermore, we trained\nclassifiers to perform inference of unobserved Middle Chinese labels, showing\nthe representations' potential for indicating archaic, proto-language features.\nThe representations can be used for performing completion of fragmented Sinitic\nphonological knowledge bases, estimating divergences between different\ncharacters, or aiding the exploration and reconstruction of archaic features.", "published": "2023-06-30 02:37:25", "link": "http://arxiv.org/abs/2307.01209v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Voting-based Multimodal Automatic Deception Detection", "abstract": "Automatic Deception Detection has been a hot research topic for a long time,\nusing machine learning and deep learning to automatically detect deception,\nbrings new light to this old field. In this paper, we proposed a voting-based\nmethod for automatic deception detection from videos using audio, visual and\nlexical features. Experiments were done on two datasets, the Real-life trial\ndataset by Michigan University and the Miami University deception detection\ndataset. Video samples were split into frames of images, audio, and\nmanuscripts. Our Voting-based Multimodal proposed solution consists of three\nmodels. The first model is CNN for detecting deception from images, the second\nmodel is Support Vector Machine (SVM) on Mel spectrograms for detecting\ndeception from audio and the third model is Word2Vec on Support Vector Machine\n(SVM) for detecting deception from manuscripts. Our proposed solution\noutperforms state of the art. Best results achieved on images, audio and text\nwere 97%, 96%, 92% respectively on Real-Life Trial Dataset, and 97%, 82%, 73%\non video, audio and text respectively on Miami University Deception Detection.", "published": "2023-06-30 17:05:11", "link": "http://arxiv.org/abs/2307.07516v3", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Beyond Neural-on-Neural Approaches to Speaker Gender Protection", "abstract": "Recent research has proposed approaches that modify speech to defend against\ngender inference attacks. The goal of these protection algorithms is to control\nthe availability of information about a speaker's gender, a privacy-sensitive\nattribute. Currently, the common practice for developing and testing gender\nprotection algorithms is \"neural-on-neural\", i.e., perturbations are generated\nand tested with a neural network. In this paper, we propose to go beyond this\npractice to strengthen the study of gender protection. First, we demonstrate\nthe importance of testing gender inference attacks that are based on speech\nfeatures historically developed by speech scientists, alongside the\nconventionally used neural classifiers. Next, we argue that researchers should\nuse speech features to gain insight into how protective modifications change\nthe speech signal. Finally, we point out that gender-protection algorithms\nshould be compared with novel \"vocal adversaries\", human-executed voice\nadaptations, in order to improve interpretability and enable before-the-mic\nprotection.", "published": "2023-06-30 14:26:49", "link": "http://arxiv.org/abs/2306.17700v1", "categories": ["eess.AS", "cs.CL", "cs.CR", "cs.CY", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Audio Embeddings as Teachers for Music Classification", "abstract": "Music classification has been one of the most popular tasks in the field of\nmusic information retrieval. With the development of deep learning models, the\nlast decade has seen impressive improvements in a wide range of classification\ntasks. However, the increasing model complexity makes both training and\ninference computationally expensive. In this paper, we integrate the ideas of\ntransfer learning and feature-based knowledge distillation and systematically\ninvestigate using pre-trained audio embeddings as teachers to guide the\ntraining of low-complexity student networks. By regularizing the feature space\nof the student networks with the pre-trained embeddings, the knowledge in the\nteacher embeddings can be transferred to the students. We use various\npre-trained audio embeddings and test the effectiveness of the method on the\ntasks of musical instrument classification and music auto-tagging. Results show\nthat our method significantly improves the results in comparison to the\nidentical model trained without the teacher's knowledge. This technique can\nalso be combined with classical knowledge distillation approaches to further\nimprove the model's performance.", "published": "2023-06-30 06:38:33", "link": "http://arxiv.org/abs/2306.17424v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Beyond-Voice: Towards Continuous 3D Hand Pose Tracking on Commercial\n  Home Assistant Devices", "abstract": "The surging popularity of home assistants and their voice user interface\n(VUI) have made them an ideal central control hub for smart home devices.\nHowever, current form factors heavily rely on VUI, which poses accessibility\nand usability issues; some latest ones are equipped with additional cameras and\ndisplays, which are costly and raise privacy concerns. These concerns jointly\nmotivate Beyond-Voice, a novel high-fidelity acoustic sensing system that\nallows commodity home assistant devices to track and reconstruct hand poses\ncontinuously. It transforms the home assistant into an active sonar system\nusing its existing onboard microphones and speakers. We feed a high-resolution\nrange profile to the deep learning model that can analyze the motions of\nmultiple body parts and predict the 3D positions of 21 finger joints, bringing\nthe granularity for acoustic hand tracking to the next level. It operates\nacross different environments and users without the need for personalized\ntraining data. A user study with 11 participants in 3 different environments\nshows that Beyond-Voice can track joints with an average mean absolute error of\n16.47mm without any training data provided by the testing subject.", "published": "2023-06-30 08:49:41", "link": "http://arxiv.org/abs/2306.17477v2", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Empirical Interpretation of the Relationship Between Speech Acoustic\n  Context and Emotion Recognition", "abstract": "Speech emotion recognition (SER) is vital for obtaining emotional\nintelligence and understanding the contextual meaning of speech. Variations of\nconsonant-vowel (CV) phonemic boundaries can enrich acoustic context with\nlinguistic cues, which impacts SER. In practice, speech emotions are treated as\nsingle labels over an acoustic segment for a given time duration. However,\nphone boundaries within speech are not discrete events, therefore the perceived\nemotion state should also be distributed over potentially continuous\ntime-windows.\n  This research explores the implication of acoustic context and phone\nboundaries on local markers for SER using an attention-based approach. The\nbenefits of using a distributed approach to speech emotion understanding are\nsupported by the results of cross-corpora analysis experiments. Experiments\nwhere phones and words are mapped to the attention vectors along with the\nfundamental frequency to observe the overlapping distributions and thereby the\nrelationship between acoustic context and emotion. This work aims to bridge\npsycholinguistic theory research with computational modelling for SER.", "published": "2023-06-30 09:21:48", "link": "http://arxiv.org/abs/2306.17500v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Delays in Spiking Neural Networks using Dilated Convolutions\n  with Learnable Spacings", "abstract": "Spiking Neural Networks (SNNs) are a promising research direction for\nbuilding power-efficient information processing systems, especially for\ntemporal tasks such as speech recognition. In SNNs, delays refer to the time\nneeded for one spike to travel from one neuron to another. These delays matter\nbecause they influence the spike arrival times, and it is well-known that\nspiking neurons respond more strongly to coincident input spikes. More\nformally, it has been shown theoretically that plastic delays greatly increase\nthe expressivity in SNNs. Yet, efficient algorithms to learn these delays have\nbeen lacking. Here, we propose a new discrete-time algorithm that addresses\nthis issue in deep feedforward SNNs using backpropagation, in an offline\nmanner. To simulate delays between consecutive layers, we use 1D convolutions\nacross time. The kernels contain only a few non-zero weights - one per synapse\n- whose positions correspond to the delays. These positions are learned\ntogether with the weights using the recently proposed Dilated Convolution with\nLearnable Spacings (DCLS). We evaluated our method on three datasets: the\nSpiking Heidelberg Dataset (SHD), the Spiking Speech Commands (SSC) and its\nnon-spiking version Google Speech Commands v0.02 (GSC) benchmarks, which\nrequire detecting temporal patterns. We used feedforward SNNs with two or three\nhidden fully connected layers, and vanilla leaky integrate-and-fire neurons. We\nshowed that fixed random delays help and that learning them helps even more.\nFurthermore, our method outperformed the state-of-the-art in the three datasets\nwithout using recurrent connections and with substantially fewer parameters.\nOur work demonstrates the potential of delay learning in developing accurate\nand precise models for temporal data processing. Our code is based on PyTorch /\nSpikingJelly and available at: https://github.com/Thvnvtos/SNN-delays", "published": "2023-06-30 14:01:53", "link": "http://arxiv.org/abs/2306.17670v3", "categories": ["cs.NE", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.NE"}
{"title": "Dataset balancing can hurt model performance", "abstract": "Machine learning from training data with a skewed distribution of examples\nper class can lead to models that favor performance on common classes at the\nexpense of performance on rare ones. AudioSet has a very wide range of priors\nover its 527 sound event classes. Classification performance on AudioSet is\nusually evaluated by a simple average over per-class metrics, meaning that\nperformance on rare classes is equal in importance to the performance on common\nones. Several recent papers have used dataset balancing techniques to improve\nperformance on AudioSet. We find, however, that while balancing improves\nperformance on the public AudioSet evaluation data it simultaneously hurts\nperformance on an unpublished evaluation set collected under the same\nconditions. By varying the degree of balancing, we show that its benefits are\nfragile and depend on the evaluation set. We also do not find evidence\nindicating that balancing improves rare class performance relative to common\nclasses. We therefore caution against blind application of balancing, as well\nas against paying too much attention to small improvements on a public\nevaluation set.", "published": "2023-06-30 18:33:27", "link": "http://arxiv.org/abs/2307.00079v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "The Human Auditory System and Audio", "abstract": "This work reviews the human auditory system, elucidating some of the\nspecialized mechanisms and non-linear pathways along the chain of events\nbetween physical sound and its perception. Customary relationships between\nfrequency, time, and phase--such as the uncertainty principle--that hold for\nlinear systems, do not apply straightforwardly to the hearing process. Auditory\ntemporal resolution for certain processes can be a hundredth of the period of\nthe signal, and can extend down to the microseconds time scale. The\nastonishingly large number of variations that correspond to the neural\nexcitation pattern of 30000 auditory nerve fibers, originating from 3500 inner\nhair cells, explicates the vast capacity of the auditory system for the\nresolution of sonic detail. And the ear is sensitive enough to detect a\nbasilar-membrane amplitude at the level of a picometer, or about a hundred\ntimes smaller than an atom. This article surveys and provides new insights into\nsome of the impressive capabilities of the human auditory system and explores\ntheir relationship to fidelity in reproduced sound.", "published": "2023-06-30 18:41:49", "link": "http://arxiv.org/abs/2307.00084v2", "categories": ["q-bio.NC", "cs.SD", "eess.AS"], "primary_category": "q-bio.NC"}
{"title": "VoxWatch: An open-set speaker recognition benchmark on VoxCeleb", "abstract": "Despite its broad practical applications such as in fraud prevention,\nopen-set speaker identification (OSI) has received less attention in the\nspeaker recognition community compared to speaker verification (SV). OSI deals\nwith determining if a test speech sample belongs to a speaker from a set of\npre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In\naddition to the typical challenges associated with speech variability, OSI is\nprone to the \"false-alarm problem\"; as the size of the in-set speaker\npopulation (a.k.a watchlist) grows, the out-of-set scores become larger,\nleading to increased false alarm rates. This is in particular challenging for\napplications in financial institutions and border security where the watchlist\nsize is typically of the order of several thousand speakers. Therefore, it is\nimportant to systematically quantify the false-alarm problem, and develop\ntechniques that alleviate the impact of watchlist size on detection\nperformance. Prior studies on this problem are sparse, and lack a common\nbenchmark for systematic evaluations. In this paper, we present the first\npublic benchmark for OSI, developed using the VoxCeleb dataset. We quantify the\neffect of the watchlist size and speech duration on the watchlist-based speaker\ndetection task using three strong neural network based systems. In contrast to\nthe findings from prior research, we show that the commonly adopted adaptive\nscore normalization is not guaranteed to improve the performance for this task.\nOn the other hand, we show that score calibration and score fusion, two other\ncommonly used techniques in SV, result in significant improvements in OSI\nperformance.", "published": "2023-06-30 23:11:38", "link": "http://arxiv.org/abs/2307.00169v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Of Spiky SVDs and Music Recommendation", "abstract": "The truncated singular value decomposition is a widely used methodology in\nmusic recommendation for direct similar-item retrieval or embedding musical\nitems for downstream tasks. This paper investigates a curious effect that we\nshow naturally occurring on many recommendation datasets: spiking formations in\nthe embedding space. We first propose a metric to quantify this spiking\norganization's strength, then mathematically prove its origin tied to\nunderlying communities of items of varying internal popularity. With this\nnew-found theoretical understanding, we finally open the topic with an\nindustrial use case of estimating how music embeddings' top-k similar items\nwill change over time under the addition of data.", "published": "2023-06-30 15:19:33", "link": "http://arxiv.org/abs/2307.01212v1", "categories": ["cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
