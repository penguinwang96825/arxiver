{"title": "MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language\n  Models to Generalize to Novel Interpretations", "abstract": "Humans possess a remarkable ability to assign novel interpretations to\nlinguistic expressions, enabling them to learn new words and understand\ncommunity-specific connotations. However, Large Language Models (LLMs) have a\nknowledge cutoff and are costly to finetune repeatedly. Therefore, it is\ncrucial for LLMs to learn novel interpretations in-context. In this paper, we\nsystematically analyse the ability of LLMs to acquire novel interpretations\nusing in-context learning. To facilitate our study, we introduce MAGNIFICo, an\nevaluation suite implemented within a text-to-SQL semantic parsing framework\nthat incorporates diverse tokens and prompt settings to simulate real-world\ncomplexity. Experimental results on MAGNIFICo demonstrate that LLMs exhibit a\nsurprisingly robust capacity for comprehending novel interpretations from\nnatural language descriptions as well as from discussions within long\nconversations. Nevertheless, our findings also highlight the need for further\nimprovements, particularly when interpreting unfamiliar words or when composing\nmultiple novel interpretations simultaneously in the same example.\nAdditionally, our analysis uncovers the semantic predispositions in LLMs and\nreveals the impact of recency bias for information presented in long contexts.", "published": "2023-10-18 00:02:38", "link": "http://arxiv.org/abs/2310.11634v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Systematic Assessment of Factual Knowledge in Large Language Models", "abstract": "Previous studies have relied on existing question-answering benchmarks to\nevaluate the knowledge stored in large language models (LLMs). However, this\napproach has limitations regarding factual knowledge coverage, as it mostly\nfocuses on generic domains which may overlap with the pretraining data. This\npaper proposes a framework to systematically assess the factual knowledge of\nLLMs by leveraging knowledge graphs (KGs). Our framework automatically\ngenerates a set of questions and expected answers from the facts stored in a\ngiven KG, and then evaluates the accuracy of LLMs in answering these questions.\nWe systematically evaluate the state-of-the-art LLMs with KGs in generic and\nspecific domains. The experiment shows that ChatGPT is consistently the top\nperformer across all domains. We also find that LLMs performance depends on the\ninstruction finetuning, domain and question complexity and is prone to\nadversarial context.", "published": "2023-10-18 00:20:50", "link": "http://arxiv.org/abs/2310.11638v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot Faithfulness Evaluation for Text Summarization with Foundation\n  Language Model", "abstract": "Despite tremendous improvements in natural language generation, summarization\nmodels still suffer from the unfaithfulness issue. Previous work evaluates\nfaithfulness either using models trained on the other tasks or in-domain\nsynthetic data, or prompting a large model such as ChatGPT. This paper proposes\nto do zero-shot faithfulness evaluation simply with a moderately-sized\nfoundation language model. We introduce a new metric FFLM, which is a\ncombination of probability changes based on the intuition that prefixing a\npiece of text that is consistent with the output will increase the probability\nof predicting the output. Experiments show that FFLM performs competitively\nwith or even outperforms ChatGPT on both inconsistency detection and\nfaithfulness rating with 24x fewer parameters. FFLM also achieves improvements\nover other strong baselines.", "published": "2023-10-18 01:20:16", "link": "http://arxiv.org/abs/2310.11648v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Field-testing items using artificial intelligence: Natural language\n  processing with transformers", "abstract": "Five thousand variations of the RoBERTa model, an artificially intelligent\n\"transformer\" that can understand text language, completed an English literacy\nexam with 29 multiple-choice questions. Data were used to calculate the\npsychometric properties of the items, which showed some degree of agreement to\nthose obtained from human examinee data.", "published": "2023-10-18 01:56:16", "link": "http://arxiv.org/abs/2310.11655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error\n  Correction", "abstract": "Data Augmentation through generating pseudo data has been proven effective in\nmitigating the challenge of data scarcity in the field of Grammatical Error\nCorrection (GEC). Various augmentation strategies have been widely explored,\nmost of which are motivated by two heuristics, i.e., increasing the\ndistribution similarity and diversity of pseudo data. However, the underlying\nmechanism responsible for the effectiveness of these strategies remains poorly\nunderstood. In this paper, we aim to clarify how data augmentation improves GEC\nmodels. To this end, we introduce two interpretable and computationally\nefficient measures: Affinity and Diversity. Our findings indicate that an\nexcellent GEC data augmentation strategy characterized by high Affinity and\nappropriate Diversity can better improve the performance of GEC models. Based\non this observation, we propose MixEdit, a data augmentation approach that\nstrategically and dynamically augments realistic data, without requiring extra\nmonolingual corpora. To verify the correctness of our findings and the\neffectiveness of the proposed MixEdit, we conduct experiments on mainstream\nEnglish and Chinese GEC datasets. The results show that MixEdit substantially\nimproves GEC models and is complementary to traditional data augmentation\nmethods.", "published": "2023-10-18 02:45:51", "link": "http://arxiv.org/abs/2310.11671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open-ended Commonsense Reasoning with Unrestricted Answer Scope", "abstract": "Open-ended Commonsense Reasoning is defined as solving a commonsense question\nwithout providing 1) a short list of answer candidates and 2) a pre-defined\nanswer scope. Conventional ways of formulating the commonsense question into a\nquestion-answering form or utilizing external knowledge to learn\nretrieval-based methods are less applicable in the open-ended setting due to an\ninherent challenge. Without pre-defining an answer scope or a few candidates,\nopen-ended commonsense reasoning entails predicting answers by searching over\nan extremely large searching space. Moreover, most questions require implicit\nmulti-hop reasoning, which presents even more challenges to our problem. In\nthis work, we leverage pre-trained language models to iteratively retrieve\nreasoning paths on the external knowledge base, which does not require\ntask-specific supervision. The reasoning paths can help to identify the most\nprecise answer to the commonsense question. We conduct experiments on two\ncommonsense benchmark datasets. Compared to other approaches, our proposed\nmethod achieves better performance both quantitatively and qualitatively.", "published": "2023-10-18 02:45:54", "link": "http://arxiv.org/abs/2310.11672v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning", "abstract": "Recent advancements in Large Language Models (LLMs) have expanded the\nhorizons of natural language understanding and generation. Notably, the output\ncontrol and alignment with the input of LLMs can be refined through instruction\ntuning. However, as highlighted in several studies, low-quality data in the\ntraining set are usually detrimental to instruction tuning, resulting in\ninconsistent or even misleading LLM outputs. We propose a novel method, termed\n\"reflection-tuning,\" which addresses the problem by self-improvement and\njudging capabilities of LLMs. This approach utilizes an oracle LLM to recycle\nthe original training data by introspecting and enhancing the quality of\ninstructions and responses in the data. Extensive experiments on widely used\nevaluation benchmarks show that LLMs trained with our recycled data outperform\nthose trained with existing datasets in various benchmarks.", "published": "2023-10-18 05:13:47", "link": "http://arxiv.org/abs/2310.11716v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Evaluation of Large Language Models on Legal Judgment\n  Prediction", "abstract": "Large language models (LLMs) have demonstrated great potential for\ndomain-specific applications, such as the law domain. However, recent disputes\nover GPT-4's law evaluation raise questions concerning their performance in\nreal-world legal tasks. To systematically investigate their competency in the\nlaw, we design practical baseline solutions based on LLMs and test on the task\nof legal judgment prediction. In our solutions, LLMs can work alone to answer\nopen questions or coordinate with an information retrieval (IR) system to learn\nfrom similar cases or solve simplified multi-choice questions. We show that\nsimilar cases and multi-choice options, namely label candidates, included in\nprompts can help LLMs recall domain knowledge that is critical for expertise\nlegal reasoning. We additionally present an intriguing paradox wherein an IR\nsystem surpasses the performance of LLM+IR due to limited gains acquired by\nweaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes\nredundant. Our evaluation pipeline can be easily extended into other tasks to\nfacilitate evaluations in other domains. Code is available at\nhttps://github.com/srhthu/LM-CompEval-Legal", "published": "2023-10-18 07:38:04", "link": "http://arxiv.org/abs/2310.11761v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotated Job Ads with Named Entity Recognition", "abstract": "We have trained a named entity recognition (NER) model that screens Swedish\njob ads for different kinds of useful information (e.g. skills required from a\njob seeker). It was obtained by fine-tuning KB-BERT. The biggest challenge we\nfaced was the creation of a labelled dataset, which required manual annotation.\nThis paper gives an overview of the methods we employed to make the annotation\nprocess more efficient and to ensure high quality data. We also report on the\nperformance of the resulting model.", "published": "2023-10-18 07:55:53", "link": "http://arxiv.org/abs/2310.11769v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Long Document Topic Segmentation Models With Enhanced\n  Coherence Modeling", "abstract": "Topic segmentation is critical for obtaining structured documents and\nimproving downstream tasks such as information retrieval. Due to its ability of\nautomatically exploring clues of topic shift from abundant labeled data, recent\nsupervised neural models have greatly promoted the development of long document\ntopic segmentation, but leaving the deeper relationship between coherence and\ntopic segmentation underexplored. Therefore, this paper enhances the ability of\nsupervised models to capture coherence from both logical structure and semantic\nsimilarity perspectives to further improve the topic segmentation performance,\nproposing Topic-aware Sentence Structure Prediction (TSSP) and Contrastive\nSemantic Similarity Learning (CSSL). Specifically, the TSSP task is proposed to\nforce the model to comprehend structural information by learning the original\nrelations between adjacent sentences in a disarrayed document, which is\nconstructed by jointly disrupting the original document at topic and sentence\nlevels. Moreover, we utilize inter- and intra-topic information to construct\ncontrastive samples and design the CSSL objective to ensure that the sentences\nrepresentations in the same topic have higher similarity, while those in\ndifferent topics are less similar. Extensive experiments show that the\nLongformer with our approach significantly outperforms old state-of-the-art\n(SOTA) methods. Our approach improve $F_1$ of old SOTA by 3.42 (73.74 -> 77.16)\nand reduces $P_k$ by 1.11 points (15.0 -> 13.89) on WIKI-727K and achieves an\naverage relative reduction of 4.3% on $P_k$ on WikiSection. The average\nrelative $P_k$ drop of 8.38% on two out-of-domain datasets also demonstrates\nthe robustness of our approach.", "published": "2023-10-18 07:58:47", "link": "http://arxiv.org/abs/2310.11772v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Annotation Handbook: A Practical Guide for Machine Learning\n  Projects", "abstract": "This handbook is a hands-on guide on how to approach text annotation tasks.\nIt provides a gentle introduction to the topic, an overview of theoretical\nconcepts as well as practical advice. The topics covered are mostly technical,\nbut business, ethical and regulatory issues are also touched upon. The focus\nlies on readability and conciseness rather than completeness and scientific\nrigor. Experience with annotation and knowledge of machine learning are useful\nbut not required. The document may serve as a primer or reference book for a\nwide range of professions such as team leaders, project managers, IT\narchitects, software developers and machine learning engineers.", "published": "2023-10-18 08:19:53", "link": "http://arxiv.org/abs/2310.11780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Curious Case of Hallucinatory (Un)answerability: Finding Truths in\n  the Hidden States of Over-Confident Large Language Models", "abstract": "Large language models (LLMs) have been shown to possess impressive\ncapabilities, while also raising crucial concerns about the faithfulness of\ntheir responses. A primary issue arising in this context is the management of\n(un)answerable queries by LLMs, which often results in hallucinatory behavior\ndue to overconfidence. In this paper, we explore the behavior of LLMs when\npresented with (un)answerable queries. We ask: do models represent the fact\nthat the question is (un)answerable when generating a hallucinatory answer? Our\nresults show strong indications that such models encode the answerability of an\ninput query, with the representation of the first decoded token often being a\nstrong indicator. These findings shed new light on the spatial organization\nwithin the latent representations of LLMs, unveiling previously unexplored\nfacets of these models. Moreover, they pave the way for the development of\nimproved decoding techniques with better adherence to factual generation,\nparticularly in scenarios where query (un)answerability is a concern.", "published": "2023-10-18 11:01:09", "link": "http://arxiv.org/abs/2310.11877v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Dissonance to Insights: Dissecting Disagreements in Rationale\n  Construction for Case Outcome Classification", "abstract": "In legal NLP, Case Outcome Classification (COC) must not only be accurate but\nalso trustworthy and explainable. Existing work in explainable COC has been\nlimited to annotations by a single expert. However, it is well-known that\nlawyers may disagree in their assessment of case facts. We hence collect a\nnovel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two\nexperts in the domain of international human rights law, for whom we observe\nweak agreement. We study their disagreements and build a two-level\ntask-independent taxonomy, supplemented with COC-specific subcategories. To our\nknowledge, this is the first work in the legal NLP that focuses on human label\nvariation. We quantitatively assess different taxonomy categories and find that\ndisagreements mainly stem from underspecification of the legal context, which\nposes challenges given the typically limited granularity and noise in COC\nmetadata. We further assess the explainablility of SOTA COC models on RAVE and\nobserve limited agreement between models and experts. Overall, our case study\nreveals hitherto underappreciated complexities in creating benchmark datasets\nin legal NLP that revolve around identifying aspects of a case's facts\nsupposedly relevant to its outcome.", "published": "2023-10-18 11:04:31", "link": "http://arxiv.org/abs/2310.11878v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rather a Nurse than a Physician -- Contrastive Explanations under\n  Investigation", "abstract": "Contrastive explanations, where one decision is explained in contrast to\nanother, are supposed to be closer to how humans explain a decision than\nnon-contrastive explanations, where the decision is not necessarily referenced\nto an alternative. This claim has never been empirically validated. We analyze\nfour English text-classification datasets (SST2, DynaSent, BIOS and\nDBpedia-Animals). We fine-tune and extract explanations from three different\nmodels (RoBERTa, GTP-2, and T5), each in three different sizes and apply three\npost-hoc explainability methods (LRP, GradientxInput, GradNorm). We furthermore\ncollect and release human rationale annotations for a subset of 100 samples\nfrom the BIOS dataset for contrastive and non-contrastive settings. A\ncross-comparison between model-based rationales and human annotations, both in\ncontrastive and non-contrastive settings, yields a high agreement between the\ntwo settings for models as well as for humans. Moreover, model-based\nexplanations computed in both settings align equally well with human\nrationales. Thus, we empirically find that humans do not necessarily explain in\na contrastive manner.9 pages, long paper at ACL 2022 proceedings.", "published": "2023-10-18 11:54:38", "link": "http://arxiv.org/abs/2310.11906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating semantic subspaces of Transformer sentence embeddings\n  through linear structural probing", "abstract": "The question of what kinds of linguistic information are encoded in different\nlayers of Transformer-based language models is of considerable interest for the\nNLP community. Existing work, however, has overwhelmingly focused on word-level\nrepresentations and encoder-only language models with the masked-token training\nobjective. In this paper, we present experiments with semantic structural\nprobing, a method for studying sentence-level representations via finding a\nsubspace of the embedding space that provides suitable task-specific pairwise\ndistances between data-points. We apply our method to language models from\ndifferent families (encoder-only, decoder-only, encoder-decoder) and of\ndifferent sizes in the context of two tasks, semantic textual similarity and\nnatural-language inference. We find that model families differ substantially in\ntheir performance and layer dynamics, but that the results are largely\nmodel-size invariant.", "published": "2023-10-18 12:32:07", "link": "http://arxiv.org/abs/2310.11923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounded and Well-rounded: A Methodological Approach to the Study of\n  Cross-modal and Cross-lingual Grounding", "abstract": "Grounding has been argued to be a crucial component towards the development\nof more complete and truly semantically competent artificial intelligence\nsystems. Literature has divided into two camps: While some argue that grounding\nallows for qualitatively different generalizations, others believe it can be\ncompensated by mono-modal data quantity. Limited empirical evidence has emerged\nfor or against either position, which we argue is due to the methodological\nchallenges that come with studying grounding and its effects on NLP systems.\n  In this paper, we establish a methodological framework for studying what the\neffects are - if any - of providing models with richer input sources than\ntext-only. The crux of it lies in the construction of comparable samples of\npopulations of models trained on different input modalities, so that we can\ntease apart the qualitative effects of different input sources from\nquantifiable model performances. Experiments using this framework reveal\nqualitative differences in model behavior between cross-modally grounded,\ncross-lingually grounded, and ungrounded models, which we measure both at a\nglobal dataset level as well as for specific word representations, depending on\nhow concrete their semantics is.", "published": "2023-10-18 13:05:50", "link": "http://arxiv.org/abs/2310.11938v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMR Parsing with Causal Hierarchical Attention and Pointers", "abstract": "Translation-based AMR parsers have recently gained popularity due to their\nsimplicity and effectiveness. They predict linearized graphs as free texts,\navoiding explicit structure modeling. However, this simplicity neglects\nstructural locality in AMR graphs and introduces unnecessary tokens to\nrepresent coreferences. In this paper, we introduce new target forms of AMR\nparsing and a novel model, CHAP, which is equipped with causal hierarchical\nattention and the pointer mechanism, enabling the integration of structures\ninto the Transformer decoder. We empirically explore various alternative\nmodeling options. Experiments show that our model outperforms baseline models\non four out of five benchmarks in the setting of no additional data.", "published": "2023-10-18 13:44:26", "link": "http://arxiv.org/abs/2310.11964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filling in the Gaps: Efficient Event Coreference Resolution using Graph\n  Autoencoder Networks", "abstract": "We introduce a novel and efficient method for Event Coreference Resolution\n(ECR) applied to a lower-resourced language domain. By framing ECR as a graph\nreconstruction task, we are able to combine deep semantic embeddings with\nstructural coreference chain knowledge to create a parameter-efficient family\nof Graph Autoencoder models (GAE). Our method significantly outperforms\nclassical mention-pair methods on a large Dutch event coreference corpus in\nterms of overall score, efficiency and training speed. Additionally, we show\nthat our models are consistently able to classify more difficult coreference\nlinks and are far more robust in low-data settings when compared to\ntransformer-based mention-pair coreference algorithms.", "published": "2023-10-18 13:44:58", "link": "http://arxiv.org/abs/2310.11965v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gold: A Global and Local-aware Denoising Framework for Commonsense\n  Knowledge Graph Noise Detection", "abstract": "Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning,\nyet constructing them through human annotations can be costly. As a result,\nvarious automatic methods have been proposed to construct CSKG with larger\nsemantic coverage. However, these unsupervised approaches introduce spurious\nnoise that can lower the quality of the resulting CSKG, which cannot be tackled\neasily by existing denoising algorithms due to the unique characteristics of\nnodes and structures in CSKGs. To address this issue, we propose Gold (Global\nand Local-aware Denoising), a denoising framework for CSKGs that incorporates\nentity semantic information, global rules, and local structural information\nfrom the CSKG. Experiment results demonstrate that Gold outperforms all\nbaseline methods in noise detection tasks on synthetic noisy CSKG benchmarks.\nFurthermore, we show that denoising a real-world CSKG is effective and even\nbenefits the downstream zero-shot commonsense question-answering task.", "published": "2023-10-18 14:43:07", "link": "http://arxiv.org/abs/2310.12011v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CORE: A Few-Shot Company Relation Classification Dataset for Robust\n  Domain Adaptation", "abstract": "We introduce CORE, a dataset for few-shot relation classification (RC)\nfocused on company relations and business entities. CORE includes 4,708\ninstances of 12 relation types with corresponding textual evidence extracted\nfrom company Wikipedia pages. Company names and business entities pose a\nchallenge for few-shot RC models due to the rich and diverse information\nassociated with them. For example, a company name may represent the legal\nentity, products, people, or business divisions depending on the context.\nTherefore, deriving the relation type between entities is highly dependent on\ntextual context. To evaluate the performance of state-of-the-art RC models on\nthe CORE dataset, we conduct experiments in the few-shot domain adaptation\nsetting. Our results reveal substantial performance gaps, confirming that\nmodels trained on different domains struggle to adapt to CORE. Interestingly,\nwe find that models trained on CORE showcase improved out-of-domain\nperformance, which highlights the importance of high-quality data for robust\ndomain adaptation. Specifically, the information richness embedded in business\nentities allows models to focus on contextual nuances, reducing their reliance\non superficial clues such as relation-specific verbs. In addition to the\ndataset, we provide relevant code snippets to facilitate reproducibility and\nencourage further research in the field.", "published": "2023-10-18 14:58:13", "link": "http://arxiv.org/abs/2310.12024v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Symbol Binding Ability of Large Language Models for\n  Multiple-Choice Questions in Vietnamese General Education", "abstract": "In this paper, we evaluate the ability of large language models (LLMs) to\nperform multiple choice symbol binding (MCSB) for multiple choice question\nanswering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus\non Vietnamese, with fewer challenging MCQA datasets than in English. The two\nexisting datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent\nresearch in Vietnamese natural language processing (NLP) has focused on the\nVietnamese National High School Graduation Examination (VNHSGE) from 2019 to\n2023 to evaluate ChatGPT. However, these studies have mainly focused on how\nChatGPT solves the VNHSGE step by step. We aim to create a novel and\nhigh-quality dataset by providing structured guidelines for typing LaTeX\nformulas for mathematics, physics, chemistry, and biology. This dataset can be\nused to evaluate the MCSB ability of LLMs and smaller language models (LMs)\nbecause it is typed in a strict LaTeX style. We focus on predicting the\ncharacter (A, B, C, or D) that is the most likely answer to a question, given\nthe context of the question. Our evaluation of six well-known LLMs, namely\nBLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the\nViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising\nresults on the MCSB ability of LLMs for Vietnamese. The dataset is available\nfor research purposes only.", "published": "2023-10-18 15:48:07", "link": "http://arxiv.org/abs/2310.12059v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code Book for the Annotation of Diverse Cross-Document Coreference of\n  Entities in News Articles", "abstract": "This paper presents a scheme for annotating coreference across news articles,\nextending beyond traditional identity relations by also considering\nnear-identity and bridging relations. It includes a precise description of how\nto set up Inception, a respective annotation tool, how to annotate entities in\nnews articles, connect them with diverse coreferential relations, and link them\nacross documents to Wikidata's global knowledge graph. This multi-layered\nannotation approach is discussed in the context of the problem of media bias.\nOur main contribution lies in providing a methodology for creating a diverse\ncross-document coreference corpus which can be applied to the analysis of media\nbias by word-choice and labelling.", "published": "2023-10-18 15:53:45", "link": "http://arxiv.org/abs/2310.12064v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SPEED: Speculative Pipelined Execution for Efficient Decoding", "abstract": "Generative Large Language Models (LLMs) based on the Transformer architecture\nhave recently emerged as a dominant foundation model for a wide range of\nNatural Language Processing tasks. Nevertheless, their application in real-time\nscenarios has been highly restricted due to the significant inference latency\nassociated with these models. This is particularly pronounced due to the\nautoregressive nature of generative LLM inference, where tokens are generated\nsequentially since each token depends on all previous output tokens. It is\ntherefore challenging to achieve any token-level parallelism, making inference\nextremely memory-bound. In this work, we propose SPEED, which improves\ninference efficiency by speculatively executing multiple future tokens in\nparallel with the current token using predicted values based on early-layer\nhidden states. For Transformer decoders that employ parameter sharing, the\nmemory operations for the tokens executing in parallel can be amortized, which\nallows us to accelerate generative LLM inference. We demonstrate the efficiency\nof our method in terms of latency reduction relative to model accuracy and\ndemonstrate how speculation allows for training deeper decoders with parameter\nsharing with minimal runtime overhead.", "published": "2023-10-18 16:07:01", "link": "http://arxiv.org/abs/2310.12072v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Safer Operations: An Expert-involved Dataset of High-Pressure\n  Gas Incidents for Preventing Future Failures", "abstract": "This paper introduces a new IncidentAI dataset for safety prevention.\nDifferent from prior corpora that usually contain a single task, our dataset\ncomprises three tasks: named entity recognition, cause-effect extraction, and\ninformation retrieval. The dataset is annotated by domain experts who have at\nleast six years of practical experience as high-pressure gas conservation\nmanagers. We validate the contribution of the dataset in the scenario of safety\nprevention. Preliminary results on the three tasks show that NLP techniques are\nbeneficial for analyzing incident reports to prevent future failures. The\ndataset facilitates future research in NLP and incident management communities.\nThe access to the dataset is also provided (the IncidentAI dataset is available\nat: https://github.com/Cinnamon/incident-ai-dataset).", "published": "2023-10-18 16:07:13", "link": "http://arxiv.org/abs/2310.12074v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harnessing Dataset Cartography for Improved Compositional Generalization\n  in Transformers", "abstract": "Neural networks have revolutionized language modeling and excelled in various\ndownstream tasks. However, the extent to which these models achieve\ncompositional generalization comparable to human cognitive abilities remains a\ntopic of debate. While existing approaches in the field have mainly focused on\nnovel architectures and alternative learning paradigms, we introduce a\npioneering method harnessing the power of dataset cartography (Swayamdipta et\nal., 2020). By strategically identifying a subset of compositional\ngeneralization data using this approach, we achieve a remarkable improvement in\nmodel accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets.\nNotably, our technique incorporates dataset cartography as a curriculum\nlearning criterion, eliminating the need for hyperparameter tuning while\nconsistently achieving superior performance. Our findings highlight the\nuntapped potential of dataset cartography in unleashing the full capabilities\nof compositional generalization within Transformer models. Our code is\navailable at https://github.com/cyberiada/cartography-for-compositionality.", "published": "2023-10-18 17:14:41", "link": "http://arxiv.org/abs/2310.12118v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pseudointelligence: A Unifying Framework for Language Model Evaluation", "abstract": "With large language models surpassing human performance on an increasing\nnumber of benchmarks, we must take a principled approach for targeted\nevaluation of model capabilities. Inspired by pseudorandomness, we propose\npseudointelligence, which captures the maxim that \"(perceived) intelligence\nlies in the eye of the beholder\". That is, that claims of intelligence are\nmeaningful only when their evaluator is taken into account. Concretely, we\npropose a complexity-theoretic framework of model evaluation cast as a dynamic\ninteraction between a model and a learned evaluator. We demonstrate that this\nframework can be used to reason about two case studies in language model\nevaluation, as well as analyze existing evaluation methods.", "published": "2023-10-18 17:48:05", "link": "http://arxiv.org/abs/2310.12135v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Retrieval Augmentation for Long-Form Question Answering", "abstract": "We present a study of retrieval-augmented language models (LMs) on long-form\nquestion answering. We analyze how retrieval augmentation impacts different\nLMs, by comparing answers generated from models while using the same evidence\ndocuments, and how differing quality of retrieval document set impacts the\nanswers generated from the same LM. We study various attributes of generated\nanswers (e.g., fluency, length, variance) with an emphasis on the attribution\nof generated long-form answers to in-context evidence documents. We collect\nhuman annotations of answer attribution and evaluate methods for automatically\njudging attribution. Our study provides new insights on how retrieval\naugmentation impacts long, knowledge-rich text generation of LMs. We further\nidentify attribution patterns for long text generation and analyze the main\nculprits of attribution errors. Together, our analysis reveals how retrieval\naugmentation impacts long knowledge-rich text generation and provide directions\nfor future work.", "published": "2023-10-18 17:59:10", "link": "http://arxiv.org/abs/2310.12150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Direct Neural Machine Translation with Task-level Mixture of Experts\n  models", "abstract": "Direct neural machine translation (direct NMT) is a type of NMT system that\ntranslates text between two non-English languages. Direct NMT systems often\nface limitations due to the scarcity of parallel data between non-English\nlanguage pairs. Several approaches have been proposed to address this\nlimitation, such as multilingual NMT and pivot NMT (translation between two\nlanguages via English). Task-level Mixture of expert models (Task-level MoE),\nan inference-efficient variation of Transformer-based models, has shown\npromising NMT performance for a large number of language pairs. In Task-level\nMoE, different language groups can use different routing strategies to optimize\ncross-lingual learning and inference speed. In this work, we examine Task-level\nMoE's applicability in direct NMT and propose a series of high-performing\ntraining and evaluation configurations, through which Task-level MoE-based\ndirect NMT systems outperform bilingual and pivot-based models for a large\nnumber of low and high-resource direct pairs, and translation directions. Our\nTask-level MoE with 16 experts outperforms bilingual NMT, Pivot NMT models for\n7 language pairs, while pivot-based models still performed better in 9 pairs\nand directions.", "published": "2023-10-18 18:19:45", "link": "http://arxiv.org/abs/2310.12236v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Pointwise $\\mathcal{V}$-Usable Information In-Context-ly", "abstract": "In-context learning (ICL) is a new learning paradigm that has gained\npopularity along with the development of large language models. In this work,\nwe adapt a recently proposed hardness metric, pointwise $\\mathcal{V}$-usable\ninformation (PVI), to an in-context version (in-context PVI). Compared to the\noriginal PVI, in-context PVI is more efficient in that it requires only a few\nexemplars and does not require fine-tuning. We conducted a comprehensive\nempirical analysis to evaluate the reliability of in-context PVI. Our findings\nindicate that in-context PVI estimates exhibit similar characteristics to the\noriginal PVI. Specific to the in-context setting, we show that in-context PVI\nestimates remain consistent across different exemplar selections and numbers of\nshots. The variance of in-context PVI estimates across different exemplar\nselections is insignificant, which suggests that in-context PVI are stable.\nFurthermore, we demonstrate how in-context PVI can be employed to identify\nchallenging instances. Our work highlights the potential of in-context PVI and\nprovides new insights into the capabilities of ICL.", "published": "2023-10-18 20:07:41", "link": "http://arxiv.org/abs/2310.12300v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "knn-seq: Efficient, Extensible kNN-MT Framework", "abstract": "k-nearest-neighbor machine translation (kNN-MT) boosts the translation\nquality of a pre-trained neural machine translation (NMT) model by utilizing\ntranslation examples during decoding. Translation examples are stored in a\nvector database, called a datastore, which contains one entry for each target\ntoken from the parallel data it is made from. Due to its size, it is\ncomputationally expensive both to construct and to retrieve examples from the\ndatastore. In this paper, we present an efficient and extensible kNN-MT\nframework, knn-seq, for researchers and developers that is carefully designed\nto run efficiently, even with a billion-scale large datastore. knn-seq is\ndeveloped as a plug-in on fairseq and easy to switch models and kNN indexes.\nExperimental results show that our implemented kNN-MT achieves a comparable\ngain to the original kNN-MT, and the billion-scale datastore construction took\n2.21 hours in the WMT'19 German-to-English translation task. We publish our\nknn-seq as an MIT-licensed open-source project and the code is available on\nhttps://github.com/naist-nlp/knn-seq . The demo video is available on\nhttps://youtu.be/zTDzEOq80m0 .", "published": "2023-10-18 21:56:04", "link": "http://arxiv.org/abs/2310.12352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GRI: Graph-based Relative Isomorphism of Word Embedding Spaces", "abstract": "Automated construction of bilingual dictionaries using monolingual embedding\nspaces is a core challenge in machine translation. The end performance of these\ndictionaries relies upon the geometric similarity of individual spaces, i.e.,\ntheir degree of isomorphism. Existing attempts aimed at controlling the\nrelative isomorphism of different spaces fail to incorporate the impact of\nsemantically related words in the training objective. To address this, we\npropose GRI that combines the distributional training objectives with attentive\ngraph convolutions to unanimously consider the impact of semantically similar\nwords required to define/compute the relative isomorphism of multiple spaces.\nExperimental evaluation shows that GRI outperforms the existing research by\nimproving the average P@1 by a relative score of up to 63.6%. We release the\ncodes for GRI at https://github.com/asif6827/GRI.", "published": "2023-10-18 22:10:47", "link": "http://arxiv.org/abs/2310.12360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning", "abstract": "Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in\nadapting the pre-trained language models to downstream tasks while only\nupdating a small number of parameters. Despite the success, most existing\nmethods independently adapt to each task without considering knowledge transfer\nbetween tasks and are limited to low-data regimes. To overcome this issue, we\npropose Prototype-based HyperAdapter (PHA), a novel framework built on the\nadapter-tuning and hypernetwork. It introduces an instance-dense retriever and\na prototypical hypernetwork to generate the conditional modules in a\nsample-efficient manner. This leads to comparable performance improvements\nagainst existing PEFT methods on multi-task learning and few-shot transfer\nlearning. More importantly, when the available data size gets smaller, our\nmethod outperforms other strong baselines by a large margin. Based on our\nextensive empirical experiments across various datasets, we demonstrate that\nPHA strikes a better trade-off between trainable parameters, accuracy on stream\ntasks, and sample efficiency.", "published": "2023-10-18 02:42:17", "link": "http://arxiv.org/abs/2310.11670v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Descriptive Knowledge Graph in Biomedical Domain", "abstract": "We present a novel system that automatically extracts and generates\ninformative and descriptive sentences from the biomedical corpus and\nfacilitates the efficient search for relational knowledge. Unlike previous\nsearch engines or exploration systems that retrieve unconnected passages, our\nsystem organizes descriptive sentences as a relational graph, enabling\nresearchers to explore closely related biomedical entities (e.g., diseases\ntreated by a chemical) or indirectly connected entities (e.g., potential drugs\nfor treating a disease). Our system also uses ChatGPT and a fine-tuned relation\nsynthesis model to generate concise and reliable descriptive sentences from\nretrieved information, reducing the need for extensive human reading effort.\nWith our system, researchers can easily obtain both high-level knowledge and\ndetailed references and interactively steer to the information of interest. We\nspotlight the application of our system in COVID-19 research, illustrating its\nutility in areas such as drug repurposing and literature curation.", "published": "2023-10-18 03:10:25", "link": "http://arxiv.org/abs/2310.11681v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Superiority of Softmax: Unveiling the Performance Edge Over Linear\n  Attention", "abstract": "Large transformer models have achieved state-of-the-art results in numerous\nnatural language processing tasks. Among the pivotal components of the\ntransformer architecture, the attention mechanism plays a crucial role in\ncapturing token interactions within sequences through the utilization of\nsoftmax function.\n  Conversely, linear attention presents a more computationally efficient\nalternative by approximating the softmax operation with linear complexity.\nHowever, it exhibits substantial performance degradation when compared to the\ntraditional softmax attention mechanism.\n  In this paper, we bridge the gap in our theoretical understanding of the\nreasons behind the practical performance gap between softmax and linear\nattention. By conducting a comprehensive comparative analysis of these two\nattention mechanisms, we shed light on the underlying reasons for why softmax\nattention outperforms linear attention in most scenarios.", "published": "2023-10-18 03:17:57", "link": "http://arxiv.org/abs/2310.11685v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs", "abstract": "Large language models (LLMs) have recently shown great advances in a variety\nof tasks, including natural language understanding and generation. However,\ntheir use in high-stakes decision-making scenarios is still limited due to the\npotential for errors. Selective prediction is a technique that can be used to\nimprove the reliability of the LLMs by allowing them to abstain from making\npredictions when they are unsure of the answer. In this work, we propose a\nnovel framework for adaptation with self-evaluation to improve the selective\nprediction performance of LLMs. Our framework is based on the idea of using\nparameter-efficient tuning to adapt the LLM to the specific task at hand while\nimproving its ability to perform self-evaluation. We evaluate our method on a\nvariety of question-answering (QA) datasets and show that it outperforms\nstate-of-the-art selective prediction methods. For example, on the CoQA\nbenchmark, our method improves the AUACC from 91.23% to 92.63% and improves the\nAUROC from 74.61% to 80.25%.", "published": "2023-10-18 03:34:59", "link": "http://arxiv.org/abs/2310.11689v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MISAR: A Multimodal Instructional System with Augmented Reality", "abstract": "Augmented reality (AR) requires the seamless integration of visual, auditory,\nand linguistic channels for optimized human-computer interaction. While\nauditory and visual inputs facilitate real-time and contextual user guidance,\nthe potential of large language models (LLMs) in this landscape remains largely\nuntapped. Our study introduces an innovative method harnessing LLMs to\nassimilate information from visual, auditory, and contextual modalities.\nFocusing on the unique challenge of task performance quantification in AR, we\nutilize egocentric video, speech, and context analysis. The integration of LLMs\nfacilitates enhanced state estimation, marking a step towards more adaptive AR\nsystems. Code, dataset, and demo will be available at\nhttps://github.com/nguyennm1024/misar.", "published": "2023-10-18 04:15:12", "link": "http://arxiv.org/abs/2310.11699v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning Co-Speech Gesture for Multimodal Aphasia Type Detection", "abstract": "Aphasia, a language disorder resulting from brain damage, requires accurate\nidentification of specific aphasia types, such as Broca's and Wernicke's\naphasia, for effective treatment. However, little attention has been paid to\ndeveloping methods to detect different types of aphasia. Recognizing the\nimportance of analyzing co-speech gestures for distinguish aphasia types, we\npropose a multimodal graph neural network for aphasia type detection using\nspeech and corresponding gesture patterns. By learning the correlation between\nthe speech and gesture modalities for each aphasia type, our model can generate\ntextual representations sensitive to gesture information, leading to accurate\naphasia type detection. Extensive experiments demonstrate the superiority of\nour approach over existing methods, achieving state-of-the-art results (F1\n84.2\\%). We also show that gesture features outperform acoustic features,\nhighlighting the significance of gesture expression in detecting aphasia types.\nWe provide the codes for reproducibility purposes.", "published": "2023-10-18 04:54:32", "link": "http://arxiv.org/abs/2310.11710v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Low-resource Fine-grained Named Entity Recognition by\n  Leveraging Coarse-grained Datasets", "abstract": "Named Entity Recognition (NER) frequently suffers from the problem of\ninsufficient labeled data, particularly in fine-grained NER scenarios. Although\n$K$-shot learning techniques can be applied, their performance tends to\nsaturate when the number of annotations exceeds several tens of labels. To\novercome this problem, we utilize existing coarse-grained datasets that offer a\nlarge number of annotations. A straightforward approach to address this problem\nis pre-finetuning, which employs coarse-grained data for representation\nlearning. However, it cannot directly utilize the relationships between\nfine-grained and coarse-grained entities, although a fine-grained entity type\nis likely to be a subcategory of a coarse-grained entity type. We propose a\nfine-grained NER model with a Fine-to-Coarse(F2C) mapping matrix to leverage\nthe hierarchical structure explicitly. In addition, we present an inconsistency\nfiltering method to eliminate coarse-grained entities that are inconsistent\nwith fine-grained entity types to avoid performance degradation. Our\nexperimental results show that our method outperforms both $K$-shot learning\nand supervised learning methods when dealing with a small number of\nfine-grained annotations.", "published": "2023-10-18 05:13:34", "link": "http://arxiv.org/abs/2310.11715v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Chain-of-Thought Tuning: Masked Language Models can also Think Step By\n  Step in Natural Language Understanding", "abstract": "Chain-of-Thought (CoT) is a technique that guides Large Language Models\n(LLMs) to decompose complex tasks into multi-step reasoning through\nintermediate steps in natural language form. Briefly, CoT enables LLMs to think\nstep by step. However, although many Natural Language Understanding (NLU) tasks\nalso require thinking step by step, LLMs perform less well than small-scale\nMasked Language Models (MLMs). To migrate CoT from LLMs to MLMs, we propose\nChain-of-Thought Tuning (CoTT), a two-step reasoning framework based on prompt\ntuning, to implement step-by-step thinking for MLMs on NLU tasks. From the\nperspective of CoT, CoTT's two-step framework enables MLMs to implement task\ndecomposition; CoTT's prompt tuning allows intermediate steps to be used in\nnatural language form. Thereby, the success of CoT can be extended to NLU tasks\nthrough MLMs. To verify the effectiveness of CoTT, we conduct experiments on\ntwo NLU tasks: hierarchical classification and relation extraction, and the\nresults show that CoTT outperforms baselines and achieves state-of-the-art\nperformance.", "published": "2023-10-18 05:39:20", "link": "http://arxiv.org/abs/2310.11721v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quantifying Self-diagnostic Atomic Knowledge in Chinese Medical\n  Foundation Model: A Computational Analysis", "abstract": "Foundation Models (FMs) have the potential to revolutionize the way users\nself-diagnose through search engines by offering direct and efficient\nsuggestions. Recent studies primarily focused on the quality of FMs evaluated\nby GPT-4 or their ability to pass medical exams, no studies have quantified the\nextent of self-diagnostic atomic knowledge stored in FMs' memory, which is the\nbasis of foundation models to provide factual and reliable suggestions. In this\npaper, we first constructed a benchmark of Self-diagnostic Atomic Knowledge\n(SdAK), including the most common types of atomic knowledge involved in\nself-diagnostic queries, with 17 atomic types and a total of 14, 048 pieces of\natomic knowledge. Then, we evaluated both generic and open-source Chinese\nmedical FMs on the benchmark. The experimental results showcase that generic\nFMs perform better than medical FMs in terms of self-diagnostic atomic\nknowledge. Error analysis revealed that both generic and medical FMs are\nsycophantic, e.g., always catering to users' claims when it comes to unknown\nknowledge. We further explored different types of data commonly adopted for\nfine-tuning medical FMs, i.e., real-world, semi-distilled, and distilled data,\nand found that distilled data can benefit FMs most. The code and data are\navailable at https://github.com/FreedomIntelligence/SDAK.", "published": "2023-10-18 05:42:22", "link": "http://arxiv.org/abs/2310.11722v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating Uncertainty Calibration of Aligned Language Models under\n  the Multiple-Choice Setting", "abstract": "Despite the significant progress made in practical applications of aligned\nlanguage models (LMs), they tend to be overconfident in output answers compared\nto the corresponding pre-trained LMs. In this work, we systematically evaluate\nthe impact of the alignment process on logit-based uncertainty calibration of\nLMs under the multiple-choice setting. We first conduct a thoughtful empirical\nstudy on how aligned LMs differ in calibration from their pre-trained\ncounterparts. Experimental results reveal that there are two distinct\nuncertainties in LMs under the multiple-choice setting, which are responsible\nfor the answer decision and the format preference of the LMs, respectively.\nThen, we investigate the role of these two uncertainties on aligned LM's\ncalibration through fine-tuning in simple synthetic alignment schemes and\nconclude that one reason for aligned LMs' overconfidence is the conflation of\nthese two types of uncertainty. Furthermore, we examine the utility of common\npost-hoc calibration methods for aligned LMs and propose an easy-to-implement\nand sample-efficient method to calibrate aligned LMs. We hope our findings\ncould provide insights into the design of more reliable alignment processes for\nLMs.", "published": "2023-10-18 06:07:28", "link": "http://arxiv.org/abs/2310.11732v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Bias in Emotion Recognition with ChatGPT", "abstract": "This technical report explores the ability of ChatGPT in recognizing emotions\nfrom text, which can be the basis of various applications like interactive\nchatbots, data annotation, and mental health analysis. While prior research has\nshown ChatGPT's basic ability in sentiment analysis, its performance in more\nnuanced emotion recognition is not yet explored. Here, we conducted experiments\nto evaluate its performance of emotion recognition across different datasets\nand emotion labels. Our findings indicate a reasonable level of reproducibility\nin its performance, with noticeable improvement through fine-tuning. However,\nthe performance varies with different emotion labels and datasets, highlighting\nan inherent instability and possible bias. The choice of dataset and emotion\nlabels significantly impacts ChatGPT's emotion recognition performance. This\npaper sheds light on the importance of dataset and label selection, and the\npotential of fine-tuning in enhancing ChatGPT's emotion recognition\ncapabilities, providing a groundwork for better integration of emotion analysis\nin applications using ChatGPT.", "published": "2023-10-18 07:28:12", "link": "http://arxiv.org/abs/2310.11753v2", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Language Agents for Detecting Implicit Stereotypes in Text-to-image\n  Models at Scale", "abstract": "The recent surge in the research of diffusion models has accelerated the\nadoption of text-to-image models in various Artificial Intelligence Generated\nContent (AIGC) commercial products. While these exceptional AIGC products are\ngaining increasing recognition and sparking enthusiasm among consumers, the\nquestions regarding whether, when, and how these models might unintentionally\nreinforce existing societal stereotypes remain largely unaddressed. Motivated\nby recent advancements in language agents, here we introduce a novel agent\narchitecture tailored for stereotype detection in text-to-image models. This\nversatile agent architecture is capable of accommodating free-form detection\ntasks and can autonomously invoke various tools to facilitate the entire\nprocess, from generating corresponding instructions and images, to detecting\nstereotypes. We build the stereotype-relevant benchmark based on multiple\nopen-text datasets, and apply this architecture to commercial products and\npopular open source text-to-image models. We find that these models often\ndisplay serious stereotypes when it comes to certain prompts about personal\ncharacteristics, social cultural context and crime-related aspects. In summary,\nthese empirical findings underscore the pervasive existence of stereotypes\nacross social dimensions, including gender, race, and religion, which not only\nvalidate the effectiveness of our proposed approach, but also emphasize the\ncritical necessity of addressing potential ethical risks in the burgeoning\nrealm of AIGC. As AIGC continues its rapid expansion trajectory, with new\nmodels and plugins emerging daily in staggering numbers, the challenge lies in\nthe timely detection and mitigation of potential biases within these models.", "published": "2023-10-18 08:16:29", "link": "http://arxiv.org/abs/2310.11778v3", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "AI Nushu: An Exploration of Language Emergence in Sisterhood -Through\n  the Lens of Computational Linguistics", "abstract": "This paper presents \"AI Nushu,\" an emerging language system inspired by Nushu\n(women's scripts), the unique language created and used exclusively by ancient\nChinese women who were thought to be illiterate under a patriarchal society. In\nthis interactive installation, two artificial intelligence (AI) agents are\ntrained in the Chinese dictionary and the Nushu corpus. By continually\nobserving their environment and communicating, these agents collaborate towards\ncreating a standard writing system to encode Chinese. It offers an artistic\ninterpretation of the creation of a non-western script from a computational\nlinguistics perspective, integrating AI technology with Chinese cultural\nheritage and a feminist viewpoint.", "published": "2023-10-18 10:36:52", "link": "http://arxiv.org/abs/2310.11870v1", "categories": ["cs.CL", "cs.AI", "14J60 (Primary) 14F05, 14J26 (Secondary)", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Emptying the Ocean with a Spoon: Should We Edit Models?", "abstract": "We call into question the recently popularized method of direct model editing\nas a means of correcting factual errors in LLM generations. We contrast model\nediting with three similar but distinct approaches that pursue better defined\nobjectives: (1) retrieval-based architectures, which decouple factual memory\nfrom inference and linguistic capabilities embodied in LLMs; (2) concept\nerasure methods, which aim at preventing systemic bias in generated text; and\n(3) attribution methods, which aim at grounding generations into identified\ntextual sources. We argue that direct model editing cannot be trusted as a\nsystematic remedy for the disadvantages inherent to LLMs, and while it has\nproven potential in improving model explainability, it opens risks by\nreinforcing the notion that models can be trusted for factuality. We call for\ncautious promotion and application of model editing as part of the LLM\ndeployment process, and for responsibly limiting the use cases of LLMs to those\nnot relying on editing as a critical component.", "published": "2023-10-18 13:38:03", "link": "http://arxiv.org/abs/2310.11958v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for\n  Long Sequences", "abstract": "Transformer-based models have achieved state-of-the-art performance in many\nareas. However, the quadratic complexity of self-attention with respect to the\ninput length hinders the applicability of Transformer-based models to long\nsequences. To address this, we present Fast Multipole Attention, a new\nattention mechanism that uses a divide-and-conquer strategy to reduce the time\nand memory complexity of attention for sequences of length $n$ from\n$\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ or $O(n)$, while retaining a\nglobal receptive field. The hierarchical approach groups queries, keys, and\nvalues into $\\mathcal{O}( \\log n)$ levels of resolution, where groups at\ngreater distances are increasingly larger in size and the weights to compute\ngroup quantities are learned. As such, the interaction between tokens far from\neach other is considered in lower resolution in an efficient hierarchical\nmanner. The overall complexity of Fast Multipole Attention is $\\mathcal{O}(n)$\nor $\\mathcal{O}(n \\log n)$, depending on whether the queries are down-sampled\nor not. This multi-level divide-and-conquer strategy is inspired by fast\nsummation methods from $n$-body physics and the Fast Multipole Method. We\nperform evaluation on autoregressive and bidirectional language modeling tasks\nand compare our Fast Multipole Attention model with other efficient attention\nvariants on medium-size datasets. We find empirically that the Fast Multipole\nTransformer performs much better than other efficient transformers in terms of\nmemory size and accuracy. The Fast Multipole Attention mechanism has the\npotential to empower large language models with much greater sequence lengths,\ntaking the full context into account in an efficient, naturally hierarchical\nmanner during training and when generating long sequences.", "published": "2023-10-18 13:40:41", "link": "http://arxiv.org/abs/2310.11960v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "InfoDiffusion: Information Entropy Aware Diffusion Process for\n  Non-Autoregressive Text Generation", "abstract": "Diffusion models have garnered considerable interest in the field of text\ngeneration. Several studies have explored text diffusion models with different\nstructures and applied them to various tasks, including named entity\nrecognition and summarization. However, there exists a notable disparity\nbetween the \"easy-first\" text generation process of current diffusion models\nand the \"keyword-first\" natural text generation process of humans, which has\nreceived limited attention. To bridge this gap, we propose InfoDiffusion, a\nnon-autoregressive text diffusion model. Our approach introduces a\n\"keyinfo-first\" generation strategy and incorporates a noise schedule based on\nthe amount of text information. In addition, InfoDiffusion combines\nself-conditioning with a newly proposed partially noising model structure.\nExperimental results show that InfoDiffusion outperforms the baseline model in\nterms of generation quality and diversity, as well as exhibiting higher\nsampling efficiency.", "published": "2023-10-18 14:01:39", "link": "http://arxiv.org/abs/2310.11976v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Interpolation to Extrapolation: Complete Length Generalization for\n  Arithmetic Transformers", "abstract": "In this paper, we investigate the inherent capabilities of transformer models\nin learning arithmetic algorithms, such as addition and parity. Through\nexperiments and attention analysis, we identify a number of crucial factors for\nachieving optimal length generalization. We show that transformer models are\nable to generalize to long lengths with the help of targeted attention biasing.\nIn particular, our solution solves the Parity task, a well-known and\ntheoretically proven failure mode for Transformers. We then introduce Attention\nBias Calibration (ABC), a calibration stage that enables the model to\nautomatically learn the proper attention biases, which we show to be connected\nto mechanisms in relative position encoding. We demonstrate that using ABC, the\ntransformer model can achieve unprecedented near-perfect length generalization\non certain arithmetic tasks. In addition, we show that ABC bears remarkable\nsimilarities to RPE and LoRA, which may indicate the potential for applications\nto more complex tasks.", "published": "2023-10-18 14:10:47", "link": "http://arxiv.org/abs/2310.11984v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs", "abstract": "Knowledge graph entity typing (KGET) aims at inferring plausible types of\nentities in knowledge graphs. Existing approaches to KGET focus on how to\nbetter encode the knowledge provided by the neighbors and types of an entity\ninto its representation. However, they ignore the semantic knowledge provided\nby the way in which types can be clustered together. In this paper, we propose\na novel method called Multi-view Contrastive Learning for knowledge graph\nEntity Typing (MCLET), which effectively encodes the coarse-grained knowledge\nprovided by clusters into entity and type embeddings. MCLET is composed of\nthree modules: i) Multi-view Generation and Encoder module, which encodes\nstructured information from entity-type, entity-cluster and cluster-type views;\nii) Cross-view Contrastive Learning module, which encourages different views to\ncollaboratively improve view-specific representations of entities and types;\niii) Entity Typing Prediction module, which integrates multi-head attention and\na Mixture-of-Experts strategy to infer missing entity types. Extensive\nexperiments show the strong performance of MCLET compared to the\nstate-of-the-art", "published": "2023-10-18 14:41:09", "link": "http://arxiv.org/abs/2310.12008v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison\n  Scoring of Texts with Large Language Models", "abstract": "Existing text scoring methods require a large corpus, struggle with short\ntexts, or require hand-labeled data. We develop a text scoring framework that\nleverages generative large language models (LLMs) to (1) set texts against the\nbackdrop of information from the near-totality of the web and digitized media,\nand (2) effectively transform pairwise text comparisons from a reasoning\nproblem to a pattern recognition task. Our approach, concept-guided\nchain-of-thought (CGCoT), utilizes a chain of researcher-designed prompts with\nan LLM to generate a concept-specific breakdown for each text, akin to guidance\nprovided to human coders. We then pairwise compare breakdowns using an LLM and\naggregate answers into a score using a probability model. We apply this\napproach to better understand speech reflecting aversion to specific political\nparties on Twitter, a topic that has commanded increasing interest because of\nits potential contributions to democratic backsliding. We achieve stronger\ncorrelations with human judgments than widely used unsupervised text scoring\nmethods like Wordfish. In a supervised setting, besides a small pilot dataset\nto develop CGCoT prompts, our measures require no additional hand-labeled data\nand produce predictions on par with RoBERTa-Large fine-tuned on thousands of\nhand-labeled tweets. This project showcases the potential of combining human\nexpertise and LLMs for scoring tasks.", "published": "2023-10-18 15:34:37", "link": "http://arxiv.org/abs/2310.12049v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "On the Benefit of Generative Foundation Models for Human Activity\n  Recognition", "abstract": "In human activity recognition (HAR), the limited availability of annotated\ndata presents a significant challenge. Drawing inspiration from the latest\nadvancements in generative AI, including Large Language Models (LLMs) and\nmotion synthesis models, we believe that generative AI can address this data\nscarcity by autonomously generating virtual IMU data from text descriptions.\nBeyond this, we spotlight several promising research pathways that could\nbenefit from generative AI for the community, including the generating\nbenchmark datasets, the development of foundational models specific to HAR, the\nexploration of hierarchical structures within HAR, breaking down complex\nactivities, and applications in health sensing and activity summarization.", "published": "2023-10-18 16:27:06", "link": "http://arxiv.org/abs/2310.12085v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for\n  Fairer Instruction-Tuned Machine Translation", "abstract": "Recent instruction fine-tuned models can solve multiple NLP tasks when\nprompted to do so, with machine translation (MT) being a prominent use case.\nHowever, current research often focuses on standard performance benchmarks,\nleaving compelling fairness and ethical considerations behind. In MT, this\nmight lead to misgendered translations, resulting, among other harms, in the\nperpetuation of stereotypes and prejudices. In this work, we address this gap\nby investigating whether and to what extent such models exhibit gender bias in\nmachine translation and how we can mitigate it. Concretely, we compute\nestablished gender bias metrics on the WinoMT corpus from English to German and\nSpanish. We discover that IFT models default to male-inflected translations,\neven disregarding female occupational stereotypes. Next, using interpretability\nmethods, we unveil that models systematically overlook the pronoun indicating\nthe gender of a target occupation in misgendered translations. Finally, based\non this finding, we propose an easy-to-implement and effective bias mitigation\nsolution based on few-shot learning that leads to significantly fairer\ntranslations.", "published": "2023-10-18 17:36:55", "link": "http://arxiv.org/abs/2310.12127v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Eliminating Reasoning via Inferring with Planning: A New Framework to\n  Guide LLMs' Non-linear Thinking", "abstract": "Chain-of-Thought(CoT) prompting and its variants explore equipping large\nlanguage models (LLMs) with high-level reasoning abilities by emulating\nhuman-like linear cognition and logic. However, the human mind is complicated\nand mixed with both linear and nonlinear thinking. In this work, we propose\n\\textbf{I}nferential \\textbf{E}xclusion \\textbf{P}rompting (IEP), a novel\nprompting that combines the principles of elimination and inference in order to\nguide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize\nNatural Language Inference (NLI) to deduce each possible solution's entailment\nrelation with context, commonsense, or facts, therefore yielding a broader\nperspective by thinking back for inferring. This forward planning and backward\neliminating process allows IEP to better simulate the complex human thinking\nprocesses compared to other CoT-based methods, which only reflect linear\ncognitive processes. We conducted a series of empirical studies and have\ncorroborated that IEP consistently outperforms CoT across various tasks.\nAdditionally, we observe that integrating IEP and CoT further improves the\nLLMs' performance on certain tasks, highlighting the necessity of equipping\nLLMs with mixed logic processes. Moreover, to better evaluate comprehensive\nfeatures inherent in human logic, we introduce \\textbf{M}ental-\\textbf{A}bility\n\\textbf{R}easoning \\textbf{B}enchmark (MARB). The benchmark comprises six novel\nsubtasks with a total of 9,115 questions, among which 1,685 are developed with\nhand-crafted rationale references. We believe both \\textsc{IEP} and\n\\textsc{MARB} can serve as a promising direction for unveiling LLMs' logic and\nverbal reasoning abilities and drive further advancements. \\textsc{MARB} will\nbe available at ~\\texttt{anonymity link} soon.", "published": "2023-10-18 21:42:16", "link": "http://arxiv.org/abs/2310.12342v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LACMA: Language-Aligning Contrastive Learning with Meta-Actions for\n  Embodied Instruction Following", "abstract": "End-to-end Transformers have demonstrated an impressive success rate for\nEmbodied Instruction Following when the environment has been seen in training.\nHowever, they tend to struggle when deployed in an unseen environment. This\nlack of generalizability is due to the agent's insensitivity to subtle changes\nin natural language instructions. To mitigate this issue, we propose explicitly\naligning the agent's hidden states with the instructions via contrastive\nlearning. Nevertheless, the semantic gap between high-level language\ninstructions and the agent's low-level action space remains an obstacle.\nTherefore, we further introduce a novel concept of meta-actions to bridge the\ngap. Meta-actions are ubiquitous action patterns that can be parsed from the\noriginal action sequence. These patterns represent higher-level semantics that\nare intuitively aligned closer to the instructions. When meta-actions are\napplied as additional training signals, the agent generalizes better to unseen\nenvironments. Compared to a strong multi-modal Transformer baseline, we achieve\na significant 4.5% absolute gain in success rate in unseen environments of\nALFRED Embodied Instruction Following. Additional analysis shows that the\ncontrastive objective and meta-actions are complementary in achieving the best\nresults, and the resulting agent better aligns its states with corresponding\ninstructions, making it more suitable for real-world embodied agents. The code\nis available at: https://github.com/joeyy5588/LACMA.", "published": "2023-10-18 21:43:07", "link": "http://arxiv.org/abs/2310.12344v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative\n  Large Language Models", "abstract": "We present REMARK-LLM, a novel efficient, and robust watermarking framework\ndesigned for texts generated by large language models (LLMs). Synthesizing\nhuman-like content using LLMs necessitates vast computational resources and\nextensive datasets, encapsulating critical intellectual property (IP). However,\nthe generated content is prone to malicious exploitation, including spamming\nand plagiarism. To address the challenges, REMARK-LLM proposes three new\ncomponents: (i) a learning-based message encoding module to infuse binary\nsignatures into LLM-generated texts; (ii) a reparameterization module to\ntransform the dense distributions from the message encoding to the sparse\ndistribution of the watermarked textual tokens; (iii) a decoding module\ndedicated for signature extraction; Furthermore, we introduce an optimized beam\nsearch algorithm to guarantee the coherence and consistency of the generated\ncontent. REMARK-LLM is rigorously trained to encourage the preservation of\nsemantic integrity in watermarked content, while ensuring effective watermark\nretrieval. Extensive evaluations on multiple unseen datasets highlight\nREMARK-LLM proficiency and transferability in inserting 2 times more signature\nbits into the same texts when compared to prior art, all while maintaining\nsemantic integrity. Furthermore, REMARK-LLM exhibits better resilience against\na spectrum of watermark detection and removal attacks.", "published": "2023-10-18 22:14:37", "link": "http://arxiv.org/abs/2310.12362v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Solving Hard Analogy Questions with Relation Embedding Chains", "abstract": "Modelling how concepts are related is a central topic in Lexical Semantics. A\ncommon strategy is to rely on knowledge graphs (KGs) such as ConceptNet, and to\nmodel the relation between two concepts as a set of paths. However, KGs are\nlimited to a fixed set of relation types, and they are incomplete and often\nnoisy. Another strategy is to distill relation embeddings from a fine-tuned\nlanguage model. However, this is less suitable for words that are only\nindirectly related and it does not readily allow us to incorporate structured\ndomain knowledge. In this paper, we aim to combine the best of both worlds. We\nmodel relations as paths but associate their edges with relation embeddings.\nThe paths are obtained by first identifying suitable intermediate words and\nthen selecting those words for which informative relation embeddings can be\nobtained. We empirically show that our proposed representations are useful for\nsolving hard analogy questions.", "published": "2023-10-18 23:13:22", "link": "http://arxiv.org/abs/2310.12379v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language\n  Agents", "abstract": "Humans are social beings; we pursue social goals in our daily interactions,\nwhich is a crucial aspect of social intelligence. Yet, AI systems' abilities in\nthis realm remain elusive. We present SOTOPIA, an open-ended environment to\nsimulate complex social interactions between artificial agents and evaluate\ntheir social intelligence. In our environment, agents role-play and interact\nunder a wide variety of scenarios; they coordinate, collaborate, exchange, and\ncompete with each other to achieve complex social goals. We simulate the\nrole-play interaction between LLM-based agents and humans within this task\nspace and evaluate their performance with a holistic evaluation framework\ncalled SOTOPIA-Eval. With SOTOPIA, we find significant differences between\nthese models in terms of their social intelligence, and we identify a subset of\nSOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models.\nWe find that on this subset, GPT-4 achieves a significantly lower goal\ncompletion rate than humans and struggles to exhibit social commonsense\nreasoning and strategic communication skills. These findings demonstrate\nSOTOPIA's promise as a general platform for research on evaluating and\nimproving social intelligence in artificial agents.", "published": "2023-10-18 02:27:01", "link": "http://arxiv.org/abs/2310.11667v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs", "abstract": "Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of\npredicting facts for new, previously unseen entities based on context\ninformation. Although new entities can be integrated by retraining the model\nfrom scratch in principle, such an approach is infeasible for large-scale KGs,\nwhere retraining is expensive and new entities may arise frequently. In this\npaper, we propose and describe a large-scale benchmark to evaluate\nsemi-inductive LP models. The benchmark is based on and extends Wikidata5M: It\nprovides transductive, k-shot, and 0-shot LP tasks, each varying the available\ninformation from (i) only KG structure, to (ii) including textual mentions, and\n(iii) detailed descriptions of the entities. We report on a small study of\nrecent approaches and found that semi-inductive LP performance is far from\ntransductive performance on long-tail entities throughout all experiments. The\nbenchmark provides a test bed for further research into integrating context and\ntextual information in semi-inductive LP models.", "published": "2023-10-18 12:13:13", "link": "http://arxiv.org/abs/2310.11917v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MusicAgent: An AI Agent for Music Understanding and Generation with\n  Large Language Models", "abstract": "AI-empowered music processing is a diverse field that encompasses dozens of\ntasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension\ntasks (e.g., music classification). For developers and amateurs, it is very\ndifficult to grasp all of these task to satisfy their requirements in music\nprocessing, especially considering the huge differences in the representations\nof music data and the model applicability across platforms among various tasks.\nConsequently, it is necessary to build a system to organize and integrate these\ntasks, and thus help practitioners to automatically analyze their demand and\ncall suitable tools as solutions to fulfill their requirements. Inspired by the\nrecent success of large language models (LLMs) in task automation, we develop a\nsystem, named MusicAgent, which integrates numerous music-related tools and an\nautonomous workflow to address user requirements. More specifically, we build\n1) toolset that collects tools from diverse sources, including Hugging Face,\nGitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g.,\nChatGPT) to organize these tools and automatically decompose user requests into\nmultiple sub-tasks and invoke corresponding music tools. The primary goal of\nthis system is to free users from the intricacies of AI-music tools, enabling\nthem to concentrate on the creative aspect. By granting users the freedom to\neffortlessly combine tools, the system offers a seamless and enriching music\nexperience.", "published": "2023-10-18 13:31:10", "link": "http://arxiv.org/abs/2310.11954v2", "categories": ["cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Sociotechnical Safety Evaluation of Generative AI Systems", "abstract": "Generative AI systems produce a range of risks. To ensure the safety of\ngenerative AI systems, these risks must be evaluated. In this paper, we make\ntwo main contributions toward establishing such evaluations. First, we propose\na three-layered framework that takes a structured, sociotechnical approach to\nevaluating these risks. This framework encompasses capability evaluations,\nwhich are the main current approach to safety evaluation. It then reaches\nfurther by building on system safety principles, particularly the insight that\ncontext determines whether a given capability may cause harm. To account for\nrelevant context, our framework adds human interaction and systemic impacts as\nadditional layers of evaluation. Second, we survey the current state of safety\nevaluation of generative AI systems and create a repository of existing\nevaluations. Three salient evaluation gaps emerge from this analysis. We\npropose ways forward to closing these gaps, outlining practical steps as well\nas roles and responsibilities for different actors. Sociotechnical safety\nevaluation is a tractable approach to the robust and comprehensive safety\nevaluation of generative AI systems.", "published": "2023-10-18 14:13:58", "link": "http://arxiv.org/abs/2310.11986v2", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic\n  Tabletop Manipulation", "abstract": "The convergence of embodied agents and large language models (LLMs) has\nbrought significant advancements to embodied instruction following.\nParticularly, the strong reasoning capabilities of LLMs make it possible for\nrobots to perform long-horizon tasks without expensive annotated\ndemonstrations. However, public benchmarks for testing the long-horizon\nreasoning capabilities of language-conditioned robots in various scenarios are\nstill missing. To fill this gap, this work focuses on the tabletop manipulation\ntask and releases a simulation benchmark, \\textit{LoHoRavens}, which covers\nvarious long-horizon reasoning aspects spanning color, size, space, arithmetics\nand reference. Furthermore, there is a key modality bridging problem for\nlong-horizon manipulation tasks with LLMs: how to incorporate the observation\nfeedback during robot execution for the LLM's closed-loop planning, which is\nhowever less studied by prior work. We investigate two methods of bridging the\nmodality gap: caption generation and learnable interface for incorporating\nexplicit and implicit observation feedback to the LLM, respectively. These\nmethods serve as the two baselines for our proposed benchmark. Experiments show\nthat both methods struggle to solve some tasks, indicating long-horizon\nmanipulation tasks are still challenging for current popular models. We expect\nthe proposed public benchmark and baselines can help the community develop\nbetter models for long-horizon tabletop manipulation tasks.", "published": "2023-10-18 14:53:14", "link": "http://arxiv.org/abs/2310.12020v2", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "SHARCS: Efficient Transformers through Routing with Dynamic Width\n  Sub-networks", "abstract": "We introduce SHARCS for adaptive inference that takes into account the\nhardness of input samples. SHARCS can train a router on any transformer\nnetwork, enabling the model to direct different samples to sub-networks with\nvarying widths. Our experiments demonstrate that: (1) SHARCS outperforms or\ncomplements existing per-sample adaptive inference methods across various\nclassification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes\nacross different architectures and can be even applied to compressed and\nefficient transformer encoders to further improve their efficiency; (3) SHARCS\ncan provide a 2 times inference speed up at an insignificant drop in accuracy.", "published": "2023-10-18 17:35:15", "link": "http://arxiv.org/abs/2310.12126v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM\n  Planning", "abstract": "Text-to-image (T2I) generation has seen significant growth over the past few\nyears. Despite this, there has been little work on generating diagrams with T2I\nmodels. A diagram is a symbolic/schematic representation that explains\ninformation using structurally rich and spatially complex visualizations (e.g.,\na dense combination of related objects, text labels, directional arrows/lines,\netc.). Existing state-of-the-art T2I models often fail at diagram generation\nbecause they lack fine-grained object layout control when many objects are\ndensely connected via complex relations such as arrows/lines, and also often\nfail to render comprehensible text labels. To address this gap, we present\nDiagrammerGPT, a novel two-stage text-to-diagram generation framework\nleveraging the layout guidance capabilities of LLMs to generate more accurate\ndiagrams. In the first stage, we use LLMs to generate and iteratively refine\n'diagram plans' (in a planner-auditor feedback loop). In the second stage, we\nuse a diagram generator, DiagramGLIGEN, and a text label rendering module to\ngenerate diagrams (with clear text labels) following the diagram plans. To\nbenchmark the text-to-diagram generation task, we introduce AI2D-Caption, a\ndensely annotated diagram dataset built on top of the AI2D dataset. We show\nthat our DiagrammerGPT framework produces more accurate diagrams, outperforming\nexisting T2I models. We also provide comprehensive analysis, including\nopen-domain diagram generation, multi-platform vector graphic diagram\ngeneration, human-in-the-loop editing, and multimodal planner/auditor LLMs.", "published": "2023-10-18 17:37:10", "link": "http://arxiv.org/abs/2310.12128v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Simple Mechanisms for Representing, Indexing and Manipulating Concepts", "abstract": "Deep networks typically learn concepts via classifiers, which involves\nsetting up a model and training it via gradient descent to fit the\nconcept-labeled data. We will argue instead that learning a concept could be\ndone by looking at its moment statistics matrix to generate a concrete\nrepresentation or signature of that concept. These signatures can be used to\ndiscover structure across the set of concepts and could recursively produce\nhigher-level concepts by learning this structure from those signatures. When\nthe concepts are `intersected', signatures of the concepts can be used to find\na common theme across a number of related `intersected' concepts. This process\ncould be used to keep a dictionary of concepts so that inputs could correctly\nidentify and be routed to the set of concepts involved in the (latent)\ngeneration of the input.", "published": "2023-10-18 17:54:29", "link": "http://arxiv.org/abs/2310.12143v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Document-Level Language Models for Machine Translation", "abstract": "Despite the known limitations, most machine translation systems today still\noperate on the sentence-level. One reason for this is, that most parallel\ntraining data is only sentence-level aligned, without document-level meta\ninformation available. In this work, we set out to build context-aware\ntranslation systems utilizing document-level monolingual data instead. This can\nbe achieved by combining any existing sentence-level translation model with a\ndocument-level language model. We improve existing approaches by leveraging\nrecent advancements in model combination. Additionally, we propose novel\nweighting techniques that make the system combination more flexible and\nsignificantly reduce computational overhead. In a comprehensive evaluation on\nfour diverse translation tasks, we show that our extensions improve\ndocument-targeted scores substantially and are also computationally more\nefficient. However, we also find that in most scenarios, back-translation gives\neven better results, at the cost of having to re-train the translation system.\nFinally, we explore language model fusion in the light of recent advancements\nin large language models. Our findings suggest that there might be strong\npotential in utilizing large language models via model combination.", "published": "2023-10-18 20:10:07", "link": "http://arxiv.org/abs/2310.12303v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Sentiment Problem: A Critical Survey towards Deconstructing\n  Sentiment Analysis", "abstract": "We conduct an inquiry into the sociotechnical aspects of sentiment analysis\n(SA) by critically examining 189 peer-reviewed papers on their applications,\nmodels, and datasets. Our investigation stems from the recognition that SA has\nbecome an integral component of diverse sociotechnical systems, exerting\ninfluence on both social and technical users. By delving into sociological and\ntechnological literature on sentiment, we unveil distinct conceptualizations of\nthis term in domains such as finance, government, and medicine. Our study\nexposes a lack of explicit definitions and frameworks for characterizing\nsentiment, resulting in potential challenges and biases. To tackle this issue,\nwe propose an ethics sheet encompassing critical inquiries to guide\npractitioners in ensuring equitable utilization of SA. Our findings underscore\nthe significance of adopting an interdisciplinary approach to defining\nsentiment in SA and offer a pragmatic solution for its implementation.", "published": "2023-10-18 20:42:44", "link": "http://arxiv.org/abs/2310.12318v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Position Interpolation Improves ALiBi Extrapolation", "abstract": "Linear position interpolation helps pre-trained models using rotary position\nembeddings (RoPE) to extrapolate to longer sequence lengths. We propose using\nlinear position interpolation to extend the extrapolation range of models using\nAttention with Linear Biases (ALiBi). We find position interpolation\nsignificantly improves extrapolation capability on upstream language modelling\nand downstream summarization and retrieval tasks.", "published": "2023-10-18 16:41:47", "link": "http://arxiv.org/abs/2310.13017v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Neural Activations to Concepts: A Survey on Explaining Concepts in\n  Neural Networks", "abstract": "In this paper, we review recent approaches for explaining concepts in neural\nnetworks. Concepts can act as a natural link between learning and reasoning:\nonce the concepts are identified that a neural learning system uses, one can\nintegrate those concepts with a reasoning system for inference or use a\nreasoning system to act upon them to improve or enhance the learning system. On\nthe other hand, knowledge can not only be extracted from neural networks but\nconcept knowledge can also be inserted into neural network architectures. Since\nintegrating learning and reasoning is at the core of neuro-symbolic AI, the\ninsights gained from this survey can serve as an important step towards\nrealizing neuro-symbolic AI based on explainable concepts.", "published": "2023-10-18 11:08:02", "link": "http://arxiv.org/abs/2310.11884v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.NE"], "primary_category": "cs.AI"}
{"title": "FactCHD: Benchmarking Fact-Conflicting Hallucination Detection", "abstract": "Despite their impressive generative capabilities, LLMs are hindered by\nfact-conflicting hallucinations in real-world applications. The accurate\nidentification of hallucinations in texts generated by LLMs, especially in\ncomplex inferential scenarios, is a relatively unexplored area. To address this\ngap, we present FactCHD, a dedicated benchmark designed for the detection of\nfact-conflicting hallucinations from LLMs. FactCHD features a diverse dataset\nthat spans various factuality patterns, including vanilla, multi-hop,\ncomparison, and set operation. A distinctive element of FactCHD is its\nintegration of fact-based evidence chains, significantly enhancing the depth of\nevaluating the detectors' explanations. Experiments on different LLMs expose\nthe shortcomings of current approaches in detecting factual errors accurately.\nFurthermore, we introduce Truth-Triangulator that synthesizes reflective\nconsiderations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming\nto yield more credible detection through the amalgamation of predictive results\nand evidence. The benchmark dataset is available at\nhttps://github.com/zjunlp/FactCHD.", "published": "2023-10-18 16:27:49", "link": "http://arxiv.org/abs/2310.12086v3", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning\n  for Versatile Multimodal Modeling", "abstract": "Large language models (LLMs) and vision language models (VLMs) demonstrate\nexcellent performance on a wide range of tasks by scaling up parameter counts\nfrom O(10^9) to O(10^{12}) levels and further beyond. These large scales make\nit impossible to adapt and deploy fully specialized models given a task of\ninterest. Parameter-efficient fine-tuning (PEFT) emerges as a promising\ndirection to tackle the adaptation and serving challenges for such large\nmodels. We categorize PEFT techniques into two types: intrusive and\nnon-intrusive. Intrusive PEFT techniques directly change a model's internal\narchitecture. Though more flexible, they introduce significant complexities for\ntraining and serving. Non-intrusive PEFT techniques leave the internal\narchitecture unchanged and only adapt model-external parameters, such as\nembeddings for input. In this work, we describe AdaLink as a non-intrusive PEFT\ntechnique that achieves competitive performance compared to SoTA intrusive PEFT\n(LoRA) and full model fine-tuning (FT) on various tasks. We evaluate using both\ntext-only and multimodal tasks, with experiments that account for both\nparameter-count scaling and training regime (with and without instruction\ntuning).", "published": "2023-10-18 16:43:08", "link": "http://arxiv.org/abs/2310.12100v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "An Image is Worth Multiple Words: Discovering Object Level Concepts\n  using Multi-Concept Prompt Learning", "abstract": "Textural Inversion, a prompt learning method, learns a singular text\nembedding for a new \"word\" to represent image style and appearance, allowing it\nto be integrated into natural language sentences to generate novel synthesised\nimages. However, identifying multiple unknown object-level concepts within one\nscene remains a complex challenge. While recent methods have resorted to\ncropping or masking individual images to learn multiple concepts, these\ntechniques often require prior knowledge of new concepts and are\nlabour-intensive. To address this challenge, we introduce Multi-Concept Prompt\nLearning (MCPL), where multiple unknown \"words\" are simultaneously learned from\na single sentence-image pair, without any imagery annotations. To enhance the\naccuracy of word-concept correlation and refine attention mask boundaries, we\npropose three regularisation techniques: Attention Masking, Prompts Contrastive\nLoss, and Bind Adjective. Extensive quantitative comparisons with both\nreal-world categories and biomedical images demonstrate that our method can\nlearn new semantically disentangled concepts. Our approach emphasises learning\nsolely from textual embeddings, using less than 10% of the storage space\ncompared to others. The project page, code, and data are available at\nhttps://astrazeneca.github.io/mcpl.github.io.", "published": "2023-10-18 19:18:19", "link": "http://arxiv.org/abs/2310.12274v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enhancing Spoofing Speech Detection Using Rhythm Information", "abstract": "Current spoofing speech detection systems need more convincing evidence. In\nthis paper, the flaws of rhythm information inherent in the TTS-generated\nspeech are analyzed to increase the reliability of detection systems. TTS\nmodels take text as input and utilize acoustic models to predict rhythm\ninformation, which introduces artifacts in the rhythm information. By filtering\nout vocal tract response, the remaining glottal flow with rhythm information\nretains detection ability for TTS-generated speech. Based on these analyses, a\nrhythm perturbation module is proposed to enhance the copy-synthesis data\naugmentation method. Fake utterances generated by the proposed method force the\ndetecting model to pay attention to the artifacts in rhythm information and\neffectively improve the ability to detect TTS-generated speech of the\nanti-spoofing countermeasures.", "published": "2023-10-18 14:44:38", "link": "http://arxiv.org/abs/2310.12014v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Experimental Results of Underwater Sound Speed Profile Inversion by\n  Few-shot Multi-task Learning", "abstract": "Underwater Sound Speed Profile (SSP) distribution has great influence on the\npropagation mode of acoustic signal, thus the fast and accurate estimation of\nSSP is of great importance in building underwater observation systems. The\nstate-of-the-art SSP inversion methods include frameworks of matched field\nprocessing (MFP), compressive sensing (CS), and feedforeward neural networks\n(FNN), among which the FNN shows better real-time performance while maintain\nthe same level of accuracy. However, the training of FNN needs quite a lot\nhistorical SSP samples, which is diffcult to be satisfied in many ocean areas.\nThis situation is called few-shot learning. To tackle this issue, we propose a\nmulti-task learning (MTL) model with partial parameter sharing among different\ntraning tasks. By MTL, common features could be extracted, thus accelerating\nthe learning process on given tasks, and reducing the demand for reference\nsamples, so as to enhance the generalization ability in few-shot learning. To\nverify the feasibility and effectiveness of MTL, a deep-ocean experiment was\nheld in April 2023 at the South China Sea. Results shows that MTL outperforms\nthe state-of-the-art methods in terms of accuracy for SSP inversion, while\ninherits the real-time advantage of FNN during the inversion stage.", "published": "2023-10-18 04:53:01", "link": "http://arxiv.org/abs/2310.11708v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Blind estimation of audio effects using an auto-encoder approach and\n  differentiable digital signal processing", "abstract": "Blind Estimation of Audio Effects (BE-AFX) aims at estimating the Audio\nEffects (AFXs) applied to an original, unprocessed audio sample solely based on\nthe processed audio sample. To train such a system traditional approaches\noptimize a loss between ground truth and estimated AFX parameters. This\ninvolves knowing the exact implementation of the AFXs used for the process. In\nthis work, we propose an alternative solution that eliminates the requirement\nfor knowing this implementation. Instead, we introduce an auto-encoder\napproach, which optimizes an audio quality metric. We explore, suggest, and\ncompare various implementations of commonly used mastering AFXs, using\ndifferential signal processing or neural approximations. Our findings\ndemonstrate that our auto-encoder approach yields superior estimates of the\naudio quality produced by a chain of AFXs, compared to the traditional\nparameter-based approach, even if the latter provides a more accurate parameter\nestimation.", "published": "2023-10-18 08:20:54", "link": "http://arxiv.org/abs/2310.11781v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Physics-informed neural network for acoustic resonance analysis in a\n  one-dimensional acoustic tube", "abstract": "This study devised a physics-informed neural network (PINN) framework to\nsolve the wave equation for acoustic resonance analysis. The proposed\nanalytical model, ResoNet, minimizes the loss function for periodic solutions\nand conventional PINN loss functions, thereby effectively using the function\napproximation capability of neural networks while performing resonance\nanalysis. Additionally, it can be easily applied to inverse problems. The\nresonance in a one-dimensional acoustic tube, and the effectiveness of the\nproposed method was validated through the forward and inverse analyses of the\nwave equation with energy-loss terms. In the forward analysis, the\napplicability of PINN to the resonance problem was evaluated via comparison\nwith the finite-difference method. The inverse analysis, which included\nidentifying the energy loss term in the wave equation and design optimization\nof the acoustic tube, was performed with good accuracy.", "published": "2023-10-18 08:52:10", "link": "http://arxiv.org/abs/2310.11804v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BUT CHiME-7 system description", "abstract": "This paper describes the joint effort of Brno University of Technology (BUT),\nAGH University of Krakow and University of Buenos Aires on the development of\nAutomatic Speech Recognition systems for the CHiME-7 Challenge. We train and\nevaluate various end-to-end models with several toolkits. We heavily relied on\nGuided Source Separation (GSS) to convert multi-channel audio to single\nchannel. The ASR is leveraging speech representations from models pre-trained\nby self-supervised learning, and we do a fusion of several ASR systems. In\naddition, we modified external data from the LibriSpeech corpus to become a\nclose domain and added it to the training. Our efforts were focused on the\nfar-field acoustic robustness sub-track of Task 1 - Distant Automatic Speech\nRecognition (DASR), our systems use oracle segmentation.", "published": "2023-10-18 12:26:43", "link": "http://arxiv.org/abs/2310.11921v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification", "abstract": "Data augmentation is vital to the generalization ability and robustness of\ndeep neural networks (DNNs) models. Existing augmentation methods for speaker\nverification manipulate the raw signal, which are time-consuming and the\naugmented samples lack diversity. In this paper, we present a novel\ndifficulty-aware semantic augmentation (DASA) approach for speaker\nverification, which can generate diversified training samples in speaker\nembedding space with negligible extra computing cost. Firstly, we augment\ntraining samples by perturbing speaker embeddings along semantic directions,\nwhich are obtained from speaker-wise covariance matrices. Secondly, accurate\ncovariance matrices are estimated from robust speaker embeddings during\ntraining, so we introduce difficultyaware additive margin softmax\n(DAAM-Softmax) to obtain optimal speaker embeddings. Finally, we assume the\nnumber of augmented samples goes to infinity and derive a closed-form upper\nbound of the expected loss with DASA, which achieves compatibility and\nefficiency. Extensive experiments demonstrate the proposed approach can achieve\na remarkable performance improvement. The best result achieves a 14.6% relative\nreduction in EER metric on CN-Celeb evaluation set.", "published": "2023-10-18 17:07:05", "link": "http://arxiv.org/abs/2310.12111v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Property-Aware Multi-Speaker Data Simulation: A Probabilistic Modelling\n  Technique for Synthetic Data Generation", "abstract": "We introduce a sophisticated multi-speaker speech data simulator,\nspecifically engineered to generate multi-speaker speech recordings. A notable\nfeature of this simulator is its capacity to modulate the distribution of\nsilence and overlap via the adjustment of statistical parameters. This\ncapability offers a tailored training environment for developing neural models\nsuited for speaker diarization and voice activity detection. The acquisition of\nsubstantial datasets for speaker diarization often presents a significant\nchallenge, particularly in multi-speaker scenarios. Furthermore, the precise\ntime stamp annotation of speech data is a critical factor for training both\nspeaker diarization and voice activity detection. Our proposed multi-speaker\nsimulator tackles these problems by generating large-scale audio mixtures that\nmaintain statistical properties closely aligned with the input parameters. We\ndemonstrate that the proposed multi-speaker simulator generates audio mixtures\nwith statistical properties that closely align with the input parameters\nderived from real-world statistics. Additionally, we present the effectiveness\nof speaker diarization and voice activity detection models, which have been\ntrained exclusively on the generated simulated datasets.", "published": "2023-10-18 22:46:20", "link": "http://arxiv.org/abs/2310.12371v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The CHiME-7 Challenge: System Description and Performance of NeMo Team's\n  DASR System", "abstract": "We present the NVIDIA NeMo team's multi-channel speech recognition system for\nthe 7th CHiME Challenge Distant Automatic Speech Recognition (DASR) Task,\nfocusing on the development of a multi-channel, multi-speaker speech\nrecognition system tailored to transcribe speech from distributed microphones\nand microphone arrays. The system predominantly comprises of the following\nintegral modules: the Speaker Diarization Module, Multi-channel Audio Front-End\nProcessing Module, and the ASR Module. These components collectively establish\na cascading system, meticulously processing multi-channel and multi-speaker\naudio input. Moreover, this paper highlights the comprehensive optimization\nprocess that significantly enhanced our system's performance. Our team's\nsubmission is largely based on NeMo toolkits and will be publicly available.", "published": "2023-10-18 23:10:46", "link": "http://arxiv.org/abs/2310.12378v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Separating Invisible Sounds Toward Universal Audiovisual Scene-Aware\n  Sound Separation", "abstract": "The audio-visual sound separation field assumes visible sources in videos,\nbut this excludes invisible sounds beyond the camera's view. Current methods\nstruggle with such sounds lacking visible cues. This paper introduces a novel\n\"Audio-Visual Scene-Aware Separation\" (AVSA-Sep) framework. It includes a\nsemantic parser for visible and invisible sounds and a separator for\nscene-informed separation. AVSA-Sep successfully separates both sound types,\nwith joint training and cross-modal alignment enhancing effectiveness.", "published": "2023-10-18 05:03:57", "link": "http://arxiv.org/abs/2310.11713v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "EchoScan: Scanning Complex Room Geometries via Acoustic Echoes", "abstract": "Accurate estimation of indoor space geometries is vital for constructing\nprecise digital twins, whose broad industrial applications include navigation\nin unfamiliar environments and efficient evacuation planning, particularly in\nlow-light conditions. This study introduces EchoScan, a deep neural network\nmodel that utilizes acoustic echoes to perform room geometry inference.\nConventional sound-based techniques rely on estimating geometry-related room\nparameters such as wall position and room size, thereby limiting the diversity\nof inferable room geometries. Contrarily, EchoScan overcomes this limitation by\ndirectly inferring room floorplan maps and height maps, thereby enabling it to\nhandle rooms with complex shapes, including curved walls. The segmentation task\nfor predicting floorplan and height maps enables the model to leverage both\nlow- and high-order reflections. The use of high-order reflections further\nallows EchoScan to infer complex room shapes when some walls of the room are\nunobservable from the position of an audio device. Herein, EchoScan was trained\nand evaluated using RIRs synthesized from complex environments, including the\nManhattan and Atlanta layouts, employing a practical audio device configuration\ncompatible with commercial, off-the-shelf devices.", "published": "2023-10-18 05:56:53", "link": "http://arxiv.org/abs/2310.11728v4", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Unintended Memorization in Large ASR Models, and How to Mitigate It", "abstract": "It is well-known that neural networks can unintentionally memorize their\ntraining examples, causing privacy concerns. However, auditing memorization in\nlarge non-auto-regressive automatic speech recognition (ASR) models has been\nchallenging due to the high compute cost of existing methods such as hardness\ncalibration. In this work, we design a simple auditing method to measure\nmemorization in large ASR models without the extra compute overhead.\nConcretely, we speed up randomly-generated utterances to create a mapping\nbetween vocal and text information that is difficult to learn from typical\ntraining examples. Hence, accurate predictions only for sped-up training\nexamples can serve as clear evidence for memorization, and the corresponding\naccuracy can be used to measure memorization. Using the proposed method, we\nshowcase memorization in the state-of-the-art ASR models. To mitigate\nmemorization, we tried gradient clipping during training to bound the influence\nof any individual example on the final model. We empirically show that clipping\neach example's gradient can mitigate memorization for sped-up training examples\nwith up to 16 repetitions in the training set. Furthermore, we show that in\nlarge-scale distributed training, clipping the average gradient on each compute\ncore maintains neutral model quality and compute cost while providing strong\nprivacy protection.", "published": "2023-10-18 06:45:49", "link": "http://arxiv.org/abs/2310.11739v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "CLARA: Multilingual Contrastive Learning for Audio Representation\n  Acquisition", "abstract": "Multilingual speech processing requires understanding emotions, a task made\ndifficult by limited labelled data. CLARA, minimizes reliance on labelled data,\nenhancing generalization across languages. It excels at fostering shared\nrepresentations, aiding cross-lingual transfer of speech and emotions, even\nwith little data. Our approach adeptly captures emotional nuances in speech,\novercoming subjective assessment issues. Using a large multilingual audio\ncorpus and self-supervised learning, CLARA develops speech representations\nenriched with emotions, advancing emotion-aware multilingual speech processing.\n  Our method expands the data range using data augmentation, textual embedding\nfor visual understanding, and transfers knowledge from high- to low-resource\nlanguages. CLARA demonstrates excellent performance in emotion recognition,\nlanguage comprehension, and audio benchmarks, excelling in zero-shot and\nfew-shot learning. It adapts to low-resource languages, marking progress in\nmultilingual speech representation learning.", "published": "2023-10-18 09:31:56", "link": "http://arxiv.org/abs/2310.11830v2", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Take the aTrain. Introducing an Interface for the Accessible\n  Transcription of Interviews", "abstract": "aTrain is an open-source and offline tool for transcribing audio data in\nmultiple languages with CPU and NVIDIA GPU support. It is specifically designed\nfor researchers using qualitative data generated from various forms of speech\ninteractions with research participants. aTrain requires no programming skills,\nruns on most computers, does not require an internet connection, and was\nverified not to upload data to any server. aTrain combines OpenAI's Whisper\nmodel with speaker recognition to provide output that integrates with the\npopular qualitative data analysis software tools MAXQDA and ATLAS.ti. It has an\neasy-to-use graphical interface and is provided as a Windows-App through the\nMicrosoft Store allowing for simple installation by researchers. The source\ncode is freely available on GitHub. Having developed aTrain with a focus on\nspeed on local computers, we show that the transcription time on current mobile\nCPUs is around 2 to 3 times the duration of the audio file using the\nhighest-accuracy transcription models. If an entry-level graphics card is\navailable, the transcription speed increases to 20% of the audio duration.", "published": "2023-10-18 13:45:47", "link": "http://arxiv.org/abs/2310.11967v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
