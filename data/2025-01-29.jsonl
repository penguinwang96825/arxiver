{"title": "Forecasting S&P 500 Using LSTM Models", "abstract": "With the volatile and complex nature of financial data influenced by external\nfactors, forecasting the stock market is challenging. Traditional models such\nas ARIMA and GARCH perform well with linear data but struggle with non-linear\ndependencies. Machine learning and deep learning models, particularly Long\nShort-Term Memory (LSTM) networks, address these challenges by capturing\nintricate patterns and long-term dependencies. This report compares ARIMA and\nLSTM models in predicting the S&P 500 index, a major financial benchmark.\n  Using historical price data and technical indicators, we evaluated these\nmodels using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The\nARIMA model showed reasonable performance with an MAE of 462.1, RMSE of 614,\nand 89.8 percent accuracy, effectively capturing short-term trends but limited\nby its linear assumptions. The LSTM model, leveraging sequential processing\ncapabilities, outperformed ARIMA with an MAE of 369.32, RMSE of 412.84, and\n92.46 percent accuracy, capturing both short- and long-term dependencies.\nNotably, the LSTM model without additional features performed best, achieving\nan MAE of 175.9, RMSE of 207.34, and 96.41 percent accuracy, showcasing its\nability to handle market data efficiently.\n  Accurately predicting stock movements is crucial for investment strategies,\nrisk assessments, and market stability. Our findings confirm the potential of\ndeep learning models in handling volatile financial data compared to\ntraditional ones. The results highlight the effectiveness of LSTM and suggest\navenues for further improvements. This study provides insights into financial\nforecasting, offering a comparative analysis of ARIMA and LSTM while outlining\ntheir strengths and limitations.", "published": "2025-01-29 01:31:56", "link": "http://arxiv.org/abs/2501.17366v1", "categories": ["cs.LG", "cs.AI", "q-fin.CP", "q-fin.TR"], "primary_category": "cs.LG"}
{"title": "Transformer Based Time-Series Forecasting for Stock", "abstract": "To the naked eye, stock prices are considered chaotic, dynamic, and\nunpredictable. Indeed, it is one of the most difficult forecasting tasks that\nhundreds of millions of retail traders and professional traders around the\nworld try to do every second even before the market opens. With recent advances\nin the development of machine learning and the amount of data the market\ngenerated over years, applying machine learning techniques such as deep\nlearning neural networks is unavoidable. In this work, we modeled the task as a\nmultivariate forecasting problem, instead of a naive autoregression problem.\nThe multivariate analysis is done using the attention mechanism via applying a\nmutated version of the Transformer, \"Stockformer\", which we created.", "published": "2025-01-29 00:26:47", "link": "http://arxiv.org/abs/2502.09625v1", "categories": ["q-fin.CP", "cs.LG"], "primary_category": "q-fin.CP"}
{"title": "On the Singular Control of a Diffusion and Its Running Infimum or Supremum", "abstract": "We study a class of singular stochastic control problems for a\none-dimensional diffusion $X$ in which the performance criterion to be\noptimised depends explicitly on the running infimum $I$ (or supremum $S$) of\nthe controlled process. We introduce two novel integral operators that are\nconsistent with the Hamilton-Jacobi-Bellman equation for the resulting\ntwo-dimensional singular control problems. The first operator involves\nintegrals where the integrator is the control process of the two-dimensional\nprocess $(X,I)$ or $(X,S)$; the second operator concerns integrals where the\nintegrator is the running infimum or supremum process itself. Using these\ndefinitions, we prove a general verification theorem for problems involving\ntwo-dimensional state-dependent running costs, costs of controlling the\nprocess, costs of increasing the running infimum (or supremum) and exit times.\nFinally, we apply our results to explicitly solve an optimal dividend problem\nin which the manager's time-preferences depend on the company's historical\nworst performance.", "published": "2025-01-29 11:29:39", "link": "http://arxiv.org/abs/2501.17577v1", "categories": ["math.OC", "math.PR", "q-fin.MF", "93E20, 60J60, 49L12, 91B70"], "primary_category": "math.OC"}
{"title": "Bankruptcy analysis using images and convolutional neural networks (CNN)", "abstract": "The marketing departments of financial institutions strive to craft products\nand services that cater to the diverse needs of businesses of all sizes.\nHowever, it is evident upon analysis that larger corporations often receive a\nmore substantial portion of available funds. This disparity arises from the\nrelative ease of assessing the risk of default and bankruptcy in these more\nprominent companies. Historically, risk analysis studies have focused on data\nfrom publicly traded or stock exchange-listed companies, leaving a gap in\nknowledge about small and medium-sized enterprises (SMEs). Addressing this gap,\nthis study introduces a method for evaluating SMEs by generating images for\nprocessing via a convolutional neural network (CNN). To this end, more than\n10,000 images, one for each company in the sample, were created to identify\nscenarios in which the CNN can operate with higher assertiveness and reduced\ntraining error probability. The findings demonstrate a significant predictive\ncapacity, achieving 97.8% accuracy, when a substantial number of images are\nutilized. Moreover, the image creation method paves the way for potential\napplications of this technique in various sectors and for different analytical\npurposes.", "published": "2025-01-29 21:57:47", "link": "http://arxiv.org/abs/2502.15726v1", "categories": ["q-fin.RM", "cs.LG", "math.ST", "q-fin.ST", "stat.TH", "68T07 (Primary) 91G80, 91B84, 68U10, 62P20 (Secondary)"], "primary_category": "q-fin.RM"}
{"title": "Leveraging In-Context Learning and Retrieval-Augmented Generation for\n  Automatic Question Generation in Educational Domains", "abstract": "Question generation in education is a time-consuming and cognitively\ndemanding task, as it requires creating questions that are both contextually\nrelevant and pedagogically sound. Current automated question generation methods\noften generate questions that are out of context. In this work, we explore\nadvanced techniques for automated question generation in educational contexts,\nfocusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG),\nand a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL\nusing few-shot examples and BART with a retrieval module for RAG. The Hybrid\nModel combines RAG and ICL to address these issues and improve question\nquality. Evaluation is conducted using automated metrics, followed by human\nevaluation metrics. Our results show that both the ICL approach and the Hybrid\nModel consistently outperform other methods, including baseline models, by\ngenerating more contextually accurate and relevant questions.", "published": "2025-01-29 03:25:19", "link": "http://arxiv.org/abs/2501.17397v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language\n  Models", "abstract": "Graph-structured data plays a vital role in numerous domains, such as social\nnetworks, citation networks, commonsense reasoning graphs and knowledge graphs.\nWhile graph neural networks have been employed for graph processing, recent\nadvancements have explored integrating large language models for graph-based\ntasks. In this paper, we propose a novel approach named Learnable Graph Pooling\nToken (LGPT), which addresses the limitations of the scalability issues in\nnode-level projection and information loss in graph-level projection. LGPT\nenables flexible and efficient graph representation by introducing learnable\nparameters that act as tokens in large language models, balancing fine-grained\nand global graph information. Additionally, we investigate an Early Query\nFusion technique, which fuses query context before constructing the graph\nrepresentation, leading to more effective graph embeddings. Our method achieves\na 4.13\\% performance improvement on the GraphQA benchmark without training the\nlarge language model, demonstrating significant gains in handling complex\ntextual-attributed graph data.", "published": "2025-01-29 10:35:41", "link": "http://arxiv.org/abs/2501.17549v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A linguistically-motivated evaluation methodology for unraveling model's\n  abilities in reading comprehension tasks", "abstract": "We introduce an evaluation methodology for reading comprehension tasks based\non the intuition that certain examples, by the virtue of their linguistic\ncomplexity, consistently yield lower scores regardless of model size or\narchitecture. We capitalize on semantic frame annotation for characterizing\nthis complexity, and study seven complexity factors that may account for\nmodel's difficulty. We first deploy this methodology on a carefully annotated\nFrench reading comprehension benchmark showing that two of those complexity\nfactors are indeed good predictors of models' failure, while others are less\nso. We further deploy our methodology on a well studied English benchmark by\nusing Chat-GPT as a proxy for semantic annotation. Our study reveals that\nfine-grained linguisticallymotivated automatic evaluation of a reading\ncomprehension task is not only possible, but helps understand models' abilities\nto handle specific linguistic characteristics of input examples. It also shows\nthat current state-of-the-art models fail with some for those characteristics\nwhich suggests that adequately handling them requires more than merely\nincreasing model size.", "published": "2025-01-29 11:05:20", "link": "http://arxiv.org/abs/2501.17569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Context Recomposition for Large Language Models Using\n  Probabilistic Layer Realignment", "abstract": "Extended sequence generation often leads to degradation in contextual\nconsistency due to the inability of conventional self-attention mechanisms to\neffectively retain long-range dependencies. Existing approaches, including\nmemory compression and retrieval-augmented conditioning, introduce\ncomputational trade-offs that either increase inference latency or impose\nadditional storage overhead. Structured Context Recomposition (SCR) introduces\na probabilistic layer realignment strategy that dynamically adjusts learned\nrepresentations within transformer layers, ensuring that semantically relevant\nembeddings persist throughout extended transformations. The proposed method\nenhances coherence retention through a recursive weighting function that\nredistributes representational emphasis based on inferred contextual relevance\nrather than relying on fixed token-level attention scores. Empirical results\nindicate that probabilistic realignment mitigates abrupt topic shifts and\nlogical inconsistencies, particularly in scenarios where sequences exceed\nstandard attention window constraints. Sequence-level entropy analysis further\nreveals that SCR moderates representational variability without introducing\nexcessive output regularization, allowing models to sustain generative\ndiversity while preserving contextual alignment. Attention head deviation\nmeasurements confirm that hierarchical reweighting contributes to smoother\ntoken dependency transitions across transformer layers, reinforcing the\nstability of multi-turn interactions and document-level reasoning.\nComputational resource assessments show that while SCR incurs a moderate\nincrease in processing time, memory overhead remains within feasible limits,\nmaking it suitable for practical deployment in autoregressive generative\napplications.", "published": "2025-01-29 12:46:42", "link": "http://arxiv.org/abs/2501.17617v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Critique Fine-Tuning: Learning to Critique is More Effective than\n  Learning to Imitate", "abstract": "Supervised Fine-Tuning (SFT) is commonly used to train language models to\nimitate annotated responses for given instructions. In this paper, we propose\nCritique Fine-Tuning (CFT), a method more effective than SFT for reasoning\ntasks. Instead of simply imitating correct responses, CFT trains models to\ncritique noisy responses, inspired by human learning processes that emphasize\ncritical thinking, deeper analysis, and nuanced understanding - traits often\noverlooked by standard SFT. To validate the effectiveness of CFT, we construct\nmultiple critique datasets (e.g., WebInstruct, MetaMath, NuminaMath), where\nGPT-4o serves as the teacher to generate critiques in the form of ([query;\nnoisy response], critique). Experiments on these datasets demonstrate that CFT\nconsistently outperforms SFT by 4-10% across six mathematical reasoning\nbenchmarks, and is effective across different base models including Qwen2.5,\nQwen2.5-Math, and DeepSeek-Math. Notably, our model Qwen2.5-Math-CFT only\nrequires 1 hour of training on 8 x H100 over the 50K examples, yet matches or\noutperforms strong competitors like Qwen2.5-Math-Instruct on most benchmarks,\nwhich use over 2M samples. Moreover, it matches the performance of SimpleRL,\nwhich is a DeepSeek-r1 replication trained with 140 x more compute. Experiments\non IF_Eval and MT-Bench further demonstrate that CFT can significantly enhance\nthe model's general generation and instruction-following capabilities,\noutperforming the Qwen2.5-Math-Instruct by a large margin. Ablation studies\nshow that CFT is robust to noisy response sources and teacher critique models.\nThese findings highlight that CFT offers a more effective alternative to\nadvance the reasoning of language models.", "published": "2025-01-29 15:20:30", "link": "http://arxiv.org/abs/2501.17703v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts", "abstract": "User interactions with conversational agents (CAs) evolve in the era of\nheavily guardrailed large language models (LLMs). As users push beyond\nprogrammed boundaries to explore and build relationships with these systems,\nthere is a growing concern regarding the potential for unauthorized access or\nmanipulation, commonly referred to as \"jailbreaking.\" Moreover, with CAs that\npossess highly human-like qualities, users show a tendency toward initiating\nintimate sexual interactions or attempting to tame their chatbots. To capture\nand reflect these in-the-wild interactions into chatbot designs, we propose\nRICoTA, a Korean red teaming dataset that consists of 609 prompts challenging\nLLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We\nutilize user-chatbot conversations that were self-posted on a Korean\nReddit-like community, containing specific testing and gaming intentions with a\nsocial chatbot. With these prompts, we aim to evaluate LLMs' ability to\nidentify the type of conversation and users' testing purposes to derive chatbot\ndesign implications for mitigating jailbreaking risks. Our dataset will be made\npublicly available via GitHub.", "published": "2025-01-29 15:32:27", "link": "http://arxiv.org/abs/2501.17715v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey on Legal Summarization: Challenges and Future\n  Directions", "abstract": "This article provides a systematic up-to-date survey of automatic\nsummarization techniques, datasets, models, and evaluation methods in the legal\ndomain. Through specific source selection criteria, we thoroughly review over\n120 papers spanning the modern `transformer' era of natural language processing\n(NLP), thus filling a gap in existing systematic surveys on the matter. We\npresent existing research along several axes and discuss trends, challenges,\nand opportunities for future research.", "published": "2025-01-29 18:22:14", "link": "http://arxiv.org/abs/2501.17830v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt-oriented Output of Culture-Specific Items in Translated African\n  Poetry by Large Language Model: An Initial Multi-layered Tabular Review", "abstract": "This paper examines the output of cultural items generated by Chat Generative\nPreTrained Transformer Pro in response to three structured prompts to translate\nthree anthologies of African poetry. The first prompt was broad, the second\nfocused on poetic structure, and the third prompt emphasized cultural\nspecificity. To support this analysis, four comparative tables were created.\nThe first table presents the results of the cultural items produced after the\nthree prompts, the second categorizes these outputs based on Aixela framework\nof Proper nouns and Common expressions, the third table summarizes the cultural\nitems generated by human translators, a custom translation engine, and a Large\nLanguage Model. The final table outlines the strategies employed by Chat\nGenerative PreTrained Transformer Pro following the culture specific prompt.\nCompared to the outputs of cultural items from reference human translation and\nthe custom translation engine in prior studies the findings indicate that the\nculture oriented prompts used with Chat Generative PreTrained Transformer Pro\ndid not yield significant enhancements of cultural items during the translation\nof African poetry from English to French. Among the fifty four cultural items,\nthe human translation produced thirty three cultural items in repetition, the\ncustom translation engine generated Thirty eight cultural items in repetition\nwhile Chat Generative PreTrained Transformer Pro produced forty one cultural\nitems in repetition. The untranslated cultural items revealed inconsistencies\nin Large language models approach to translating cultural items in African\npoetry from English to French.", "published": "2025-01-29 09:00:19", "link": "http://arxiv.org/abs/2501.18644v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Aware Semantic Recomposition Mechanism for Large Language Models", "abstract": "Context-aware processing mechanisms have increasingly become a critical area\nof exploration for improving the semantic and contextual capabilities of\nlanguage generation models. The Context-Aware Semantic Recomposition Mechanism\n(CASRM) was introduced as a novel framework designed to address limitations in\ncoherence, contextual adaptability, and error propagation in large-scale text\ngeneration tasks. Through the integration of dynamically generated context\nvectors and attention modulation layers, CASRM enhances the alignment between\ntoken-level representations and broader contextual dependencies. Experimental\nevaluations demonstrated significant improvements in semantic coherence across\nmultiple domains, including technical, conversational, and narrative text. The\nability to adapt to unseen domains and ambiguous inputs was evaluated using a\ndiverse set of test scenarios, highlighting the robustness of the proposed\nmechanism. A detailed computational analysis revealed that while CASRM\nintroduces additional processing overhead, the gains in linguistic precision\nand contextual relevance outweigh the marginal increase in complexity. The\nframework also successfully mitigates error propagation in sequential tasks,\nimproving performance in dialogue continuation and multi-step text synthesis.\nAdditional investigations into token-level attention distribution emphasized\nthe dynamic focus shifts enabled through context-aware enhancements. The\nfindings suggest that CASRM offers a scalable and flexible solution for\nintegrating contextual intelligence into existing language model architectures.", "published": "2025-01-29 02:38:28", "link": "http://arxiv.org/abs/2501.17386v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark\n  Challenging to Frontier LLMs", "abstract": "We present MultiChallenge, a pioneering benchmark evaluating large language\nmodels (LLMs) on conducting multi-turn conversations with human users, a\ncrucial yet underexamined capability for their applications. MultiChallenge\nidentifies four categories of challenges in multi-turn conversations that are\nnot only common and realistic among current human-LLM interactions, but are\nalso challenging to all current frontier LLMs. All 4 challenges require\naccurate instruction-following, context allocation, and in-context reasoning at\nthe same time. We also develop LLM as judge with instance-level rubrics to\nfacilitate an automatic evaluation method with fair agreement with experienced\nhuman raters. Despite achieving near-perfect scores on existing multi-turn\nevaluation benchmarks, all frontier models have less than 50% accuracy on\nMultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving\njust a 41.4% average accuracy.", "published": "2025-01-29 03:29:24", "link": "http://arxiv.org/abs/2501.17399v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-Language Approach for Quranic QA", "abstract": "Question answering systems face critical limitations in languages with\nlimited resources and scarce data, making the development of robust models\nespecially challenging. The Quranic QA system holds significant importance as\nit facilitates a deeper understanding of the Quran, a Holy text for over a\nbillion people worldwide. However, these systems face unique challenges,\nincluding the linguistic disparity between questions written in Modern Standard\nArabic and answers found in Quranic verses written in Classical Arabic, and the\nsmall size of existing datasets, which further restricts model performance. To\naddress these challenges, we adopt a cross-language approach by (1) Dataset\nAugmentation: expanding and enriching the dataset through machine translation\nto convert Arabic questions into English, paraphrasing questions to create\nlinguistic diversity, and retrieving answers from an English translation of the\nQuran to align with multilingual training requirements; and (2) Language Model\nFine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base,\nDeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the\nspecific requirements of Quranic QA. Experimental results demonstrate that this\ncross-language approach significantly improves model performance, with\nRoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while\nDeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These\nfindings underscore the effectiveness of cross-language strategies in\novercoming linguistic barriers and advancing Quranic QA systems", "published": "2025-01-29 07:13:27", "link": "http://arxiv.org/abs/2501.17449v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A review on the novelty measurements of academic papers", "abstract": "Novelty evaluation is vital for the promotion and management of innovation.\nWith the advancement of information techniques and the open data movement, some\nprogress has been made in novelty measurements. Tracking and reviewing novelty\nmeasures provides a data-driven way to assess contributions, progress, and\nemerging directions in the science field. As academic papers serve as the\nprimary medium for the dissemination, validation, and discussion of scientific\nknowledge, this review aims to offer a systematic analysis of novelty\nmeasurements for scientific papers. We began by comparing the differences\nbetween scientific novelty and four similar concepts, including originality,\nscientific innovation, creativity, and scientific breakthrough. Next, we\nreviewed the types of scientific novelty. Then, we classified existing novelty\nmeasures according to data types and reviewed the measures for each type.\nSubsequently, we surveyed the approaches employed in validating novelty\nmeasures and examined the current tools and datasets associated with these\nmeasures. Finally, we proposed several open issues for future studies.", "published": "2025-01-29 07:33:36", "link": "http://arxiv.org/abs/2501.17456v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Large Language Models for Single-Step and Multi-Step Flight Trajectory\n  Prediction", "abstract": "Flight trajectory prediction is a critical time series task in aviation.\nWhile deep learning methods have shown significant promise, the application of\nlarge language models (LLMs) to this domain remains underexplored. This study\npioneers the use of LLMs for flight trajectory prediction by reframing it as a\nlanguage modeling problem. Specifically, We extract features representing the\naircraft's position and status from ADS-B flight data to construct a\nprompt-based dataset, where trajectory waypoints are converted into language\ntokens. The dataset is then employed to fine-tune LLMs, enabling them to learn\ncomplex spatiotemporal patterns for accurate predictions. Comprehensive\nexperiments demonstrate that LLMs achieve notable performance improvements in\nboth single-step and multi-step predictions compared to traditional methods,\nwith LLaMA-3.1 model achieving the highest overall accuracy. However, the high\ninference latency of LLMs poses a challenge for real-time applications,\nunderscoring the need for further research in this promising direction.", "published": "2025-01-29 07:35:56", "link": "http://arxiv.org/abs/2501.17459v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Semantic Consistency Regularization with Large Language Models for\n  Semi-supervised Sentiment Analysis", "abstract": "Accurate sentiment analysis of texts is crucial for a variety of\napplications, such as understanding customer feedback, monitoring market\ntrends, and detecting public sentiment. However, manually annotating large\nsentiment corpora for supervised learning is labor-intensive and\ntime-consuming. Therefore, it is essential and effective to develop a\nsemi-supervised method for the sentiment analysis task. Although some methods\nhave been proposed for semi-supervised text classification, they rely on the\nintrinsic information within the unlabeled data and the learning capability of\nthe NLP model, which lack generalization ability to the sentiment analysis\nscenario and may prone to overfit. Inspired by the ability of pretrained Large\nLanguage Models (LLMs) in following instructions and generating coherent text,\nwe propose a Semantic Consistency Regularization with Large Language Models\n(SCR) framework for semi-supervised sentiment analysis. We introduce two\nprompting strategies to semantically enhance unlabeled text using LLMs. The\nfirst is Entity-based Enhancement (SCR-EE), which involves extracting entities\nand numerical information, and querying the LLM to reconstruct the textual\ninformation. The second is Concept-based Enhancement (SCR-CE), which directly\nqueries the LLM with the original sentence for semantic reconstruction.\nSubsequently, the LLM-augmented data is utilized for a consistency loss with\nconfidence thresholding, which preserves high-quality agreement samples to\nprovide additional supervision signals during training. Furthermore, to fully\nutilize the uncertain unlabeled data samples, we propose a class re-assembling\nstrategy inspired by the class space shrinking theorem. Experiments show our\nmethod achieves remarkable performance over prior semi-supervised methods.", "published": "2025-01-29 12:03:11", "link": "http://arxiv.org/abs/2501.17598v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Uncertainty Quantification and Decomposition for LLM-based\n  Recommendation", "abstract": "Despite the widespread adoption of large language models (LLMs) for\nrecommendation, we demonstrate that LLMs often exhibit uncertainty in their\nrecommendations. To ensure the trustworthy use of LLMs in generating\nrecommendations, we emphasize the importance of assessing the reliability of\nrecommendations generated by LLMs. We start by introducing a novel framework\nfor estimating the predictive uncertainty to quantitatively measure the\nreliability of LLM-based recommendations. We further propose to decompose the\npredictive uncertainty into recommendation uncertainty and prompt uncertainty,\nenabling in-depth analyses of the primary source of uncertainty. Through\nextensive experiments, we (1) demonstrate predictive uncertainty effectively\nindicates the reliability of LLM-based recommendations, (2) investigate the\norigins of uncertainty with decomposed uncertainty measures, and (3) propose\nuncertainty-aware prompting for a lower predictive uncertainty and enhanced\nrecommendation. Our source code and model weights are available at\nhttps://github.com/WonbinKweon/UNC_LLM_REC_WWW2025", "published": "2025-01-29 13:08:17", "link": "http://arxiv.org/abs/2501.17630v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Tonguescape: Exploring Language Models Understanding of Vowel\n  Articulation", "abstract": "Vowels are primarily characterized by tongue position. Humans have discovered\nthese features of vowel articulation through their own experience and explicit\nobjective observation such as using MRI. With this knowledge and our\nexperience, we can explain and understand the relationship between tongue\npositions and vowels, and this knowledge is helpful for language learners to\nlearn pronunciation. Since language models (LMs) are trained on a large amount\nof data that includes linguistic and medical fields, our preliminary studies\nindicate that an LM is able to explain the pronunciation mechanisms of vowels.\nHowever, it is unclear whether multi-modal LMs, such as vision LMs, align\ntextual information with visual information. One question arises: do LMs\nassociate real tongue positions with vowel articulation? In this study, we\ncreated video and image datasets from the existing real-time MRI dataset and\ninvestigated whether LMs can understand vowel articulation based on tongue\npositions using vision-based information. Our findings suggest that LMs exhibit\npotential for understanding vowels and tongue positions when reference examples\nare provided while they have difficulties without them. Our code for dataset\nbuilding is available on GitHub.", "published": "2025-01-29 13:25:20", "link": "http://arxiv.org/abs/2501.17643v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Vision Language Models for Multimodal and Multilingual Stance\n  Detection", "abstract": "Social media's global reach amplifies the spread of information, highlighting\nthe need for robust Natural Language Processing tasks like stance detection\nacross languages and modalities. Prior research predominantly focuses on\ntext-only inputs, leaving multimodal scenarios, such as those involving both\nimages and text, relatively underexplored. Meanwhile, the prevalence of\nmultimodal posts has increased significantly in recent years. Although\nstate-of-the-art Vision-Language Models (VLMs) show promise, their performance\non multimodal and multilingual stance detection tasks remains largely\nunexamined. This paper evaluates state-of-the-art VLMs on a newly extended\ndataset covering seven languages and multimodal inputs, investigating their use\nof visual cues, language-specific performance, and cross-modality interactions.\nOur results show that VLMs generally rely more on text than images for stance\ndetection and this trend persists across languages. Additionally, VLMs rely\nsignificantly more on text contained within the images than other visual\ncontent. Regarding multilinguality, the models studied tend to generate\nconsistent predictions across languages whether they are explicitly\nmultilingual or not, although there are outliers that are incongruous with\nmacro F1, language support, and model size.", "published": "2025-01-29 13:39:53", "link": "http://arxiv.org/abs/2501.17654v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies\n  in Generated Report Without Human Feedback", "abstract": "As artificial intelligence (AI) becomes increasingly central to healthcare,\nthe demand for explainable and trustworthy models is paramount. Current report\ngeneration systems for chest X-rays (CXR) often lack mechanisms for validating\noutputs without expert oversight, raising concerns about reliability and\ninterpretability. To address these challenges, we propose a novel multimodal\nframework designed to enhance the semantic alignment and localization accuracy\nof AI-generated medical reports. Our framework integrates two key modules: a\nPhrase Grounding Model, which identifies and localizes pathologies in CXR\nimages based on textual prompts, and a Text-to-Image Diffusion Module, which\ngenerates synthetic CXR images from prompts while preserving anatomical\nfidelity. By comparing features between the original and generated images, we\nintroduce a dual-scoring system: one score quantifies localization accuracy,\nwhile the other evaluates semantic consistency. This approach significantly\noutperforms existing methods, achieving state-of-the-art results in pathology\nlocalization and text-to-image alignment. The integration of phrase grounding\nwith diffusion models, coupled with the dual-scoring evaluation system,\nprovides a robust mechanism for validating report quality, paving the way for\nmore trustworthy and transparent AI in medical imaging.", "published": "2025-01-29 16:02:16", "link": "http://arxiv.org/abs/2501.17726v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Hybrid Graphs for Table-and-Text based Question Answering using LLMs", "abstract": "Answering questions that require reasoning and aggregation across both\nstructured (tables) and unstructured (raw text) data sources presents\nsignificant challenges. Current methods rely on fine-tuning and high-quality,\nhuman-curated data, which is difficult to obtain. Recent advances in Large\nLanguage Models (LLMs) have shown promising results for multi-hop question\nanswering (QA) over single-source text data in a zero-shot setting, yet\nexploration into multi-source Table-Text QA remains limited. In this paper, we\npresent a novel Hybrid Graph-based approach for Table-Text QA that leverages\nLLMs without fine-tuning. Our method constructs a unified Hybrid Graph from\ntextual and tabular data, pruning information based on the input question to\nprovide the LLM with relevant context concisely. We evaluate our approach on\nthe challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,\nincluding GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot\nperformance on both datasets, improving Exact Match scores by up to 10% on\nHybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up\nto 53% compared to the original context.", "published": "2025-01-29 16:58:18", "link": "http://arxiv.org/abs/2501.17767v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare\n  Scripts", "abstract": "We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not\nencoded in Unicode. We introduce a novel approach to construct a multimodal\ndataset of linguistic puzzles involving such scripts, utilizing a tokenization\nmethod for language glyphs. Our methods include the Picture Method for LVLMs\nand the Description Method for LLMs, enabling these models to tackle these\nchallenges. We conduct experiments using prominent models, GPT-4o, Gemini, and\nClaude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and\nlimitations of current AI methods in linguistic decipherment, highlighting the\nimpact of Unicode encoding on model performance and the challenges of modeling\nvisual language tokens through descriptions. Our study advances understanding\nof AI's potential in linguistic decipherment and underscores the need for\nfurther research.", "published": "2025-01-29 17:24:19", "link": "http://arxiv.org/abs/2501.17785v1", "categories": ["cs.CL", "cs.LG", "J.5; I.2.7"], "primary_category": "cs.CL"}
{"title": "BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone\n  Disambiguation -- Challenges and Insights", "abstract": "We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted\nfor Taiwanese Mandarin, highlighting phonetic control abilities to address the\nunique challenges of polyphone disambiguation in the language. Building upon\nCosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an\noptimal-transport conditional flow matching model (OT-CFM), and a grapheme to\nphoneme prediction model, to generate realistic speech that closely mimics\nhuman utterances. Our evaluation demonstrates BreezyVoice's superior\nperformance in both general and code-switching contexts, highlighting its\nrobustness and effectiveness in generating high-fidelity speech. Additionally,\nwe address the challenges of generalizability in modeling long-tail speakers\nand polyphone disambiguation. Our approach significantly enhances performance\nand offers valuable insights into the workings of neural codec TTS systems.", "published": "2025-01-29 17:31:26", "link": "http://arxiv.org/abs/2501.17790v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Beyond the Surface: How Far Can Continual Pre-Training with\n  LoRA Enhance LLMs' Domain-Specific Insight Learning?", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious tasks, yet their ability to extract and internalize deeper insights\nfrom domain-specific datasets remains underexplored. In this study, we\ninvestigate how continual pre-training can enhance LLMs' capacity for insight\nlearning across three distinct forms: declarative, statistical, and\nprobabilistic insights. Focusing on two critical domains: medicine and finance,\nwe employ LoRA to train LLMs on two existing datasets. To evaluate each insight\ntype, we create benchmarks to measure how well continual pre-training helps\nmodels go beyond surface-level knowledge. We also assess the impact of document\nmodification on capturing insights. The results show that, while continual\npre-training on original documents has a marginal effect, modifying documents\nto retain only essential information significantly enhances the\ninsight-learning capabilities of LLMs.", "published": "2025-01-29 18:40:32", "link": "http://arxiv.org/abs/2501.17840v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dialogue is Better Than Monologue: Instructing Medical LLMs via\n  Strategical Conversations", "abstract": "Current medical AI systems often fail to replicate real-world clinical\nreasoning, as they are predominantly trained and evaluated on static text and\nquestion-answer tasks. These tuning methods and benchmarks overlook critical\naspects like evidence-based reasoning and handling distracting information. To\nbridge this gap, we introduce a novel benchmark that simulates real-world\ndiagnostic scenarios, integrating noise and difficulty levels aligned with\nUSMLE standards. Moreover, we explore dialogue-based fine-tuning, which\ntransforms static datasets into conversational formats to better capture\niterative reasoning processes. Experiments show that dialogue-tuned models\noutperform traditional methods, with improvements of $9.64\\%$ in multi-round\nreasoning scenarios and $6.18\\%$ in accuracy in a noisy environment. Our\nfindings highlight dialogue tuning as a promising approach for advancing\nclinically aligned and robust medical AI systems.", "published": "2025-01-29 18:58:48", "link": "http://arxiv.org/abs/2501.17860v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InnerThoughts: Disentangling Representations and Predictions in Large\n  Language Models", "abstract": "Large language models (LLMs) contain substantial factual knowledge which is\ncommonly elicited by multiple-choice question-answering prompts. Internally,\nsuch models process the prompt through multiple transformer layers, building\nvarying representations of the problem within its hidden states. Ultimately,\nhowever, only the hidden state corresponding to the final layer and token\nposition are used to predict the answer label. In this work, we propose instead\nto learn a small separate neural network predictor module on a collection of\ntraining questions, that take the hidden states from all the layers at the last\ntemporal position as input and outputs predictions. In effect, such a framework\ndisentangles the representational abilities of LLMs from their predictive\nabilities. On a collection of hard benchmarks, our method achieves considerable\nimprovements in performance, sometimes comparable to supervised fine-tuning\nprocedures, but at a fraction of the computational cost.", "published": "2025-01-29 21:01:44", "link": "http://arxiv.org/abs/2501.17994v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Free Token Reduction for Multi-Modal LLM", "abstract": "Vision-Language Models (VLMs) have achieved remarkable success across a range\nof multimodal tasks; however, their practical deployment is often constrained\nby high computational costs and prolonged inference times. Since the vision\nmodality typically carries more information than the text modality, compressing\nvisual prompts offers a promising solution to alleviate these challenges.\nExisting approaches predominantly focus on refining model architectures or\ndirectly reducing the number of visual tokens. However, these methods often\ncompromise inference performance due to a lack of consideration for the unique\nspatial and temporal characteristics of visual data. In this work, we propose a\ntoken compression paradigm that operates on both spatial and temporal\ndimensions. Our approach includes a learning-free, plug-and-play compression\npipeline that can be seamlessly integrated into most Multimodal Large Language\nModel (MLLM) frameworks. By leveraging this method, we enhance the model\ninference capability while simultaneously reducing its computational cost.\nExperimental results on the Video-QA task demonstrate the effectiveness of the\nproposed approach, showcasing significant improvements in efficiency without\nsacrificing performance.", "published": "2025-01-29 02:52:32", "link": "http://arxiv.org/abs/2501.17391v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "General Scene Adaptation for Vision-and-Language Navigation", "abstract": "Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on\none-time execution of individual instructions across multiple environments,\naiming to develop agents capable of functioning in any environment in a\nzero-shot manner. However, real-world navigation robots often operate in\npersistent environments with relatively consistent physical layouts, visual\nobservations, and language styles from instructors. Such a gap in the task\nsetting presents an opportunity to improve VLN agents by incorporating\ncontinuous adaptation to specific environments. To better reflect these\nreal-world conditions, we introduce GSA-VLN, a novel task requiring agents to\nexecute navigation instructions within a specific scene and simultaneously\nadapt to it for improved performance over time. To evaluate the proposed task,\none has to address two challenges in existing VLN datasets: the lack of OOD\ndata, and the limited number and style diversity of instructions for each\nscene. Therefore, we propose a new dataset, GSA-R2R, which significantly\nexpands the diversity and quantity of environments and instructions for the R2R\ndataset to evaluate agent adaptability in both ID and OOD contexts.\nFurthermore, we design a three-stage instruction orchestration pipeline that\nleverages LLMs to refine speaker-generated instructions and apply role-playing\ntechniques to rephrase instructions into different speaking styles. This is\nmotivated by the observation that each individual user often has consistent\nsignatures or preferences in their instructions. We conducted extensive\nexperiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various\nmethods. Based on our findings, we propose a novel method, GR-DUET, which\nincorporates memory-based navigation graphs with an environment-specific\ntraining strategy, achieving state-of-the-art results on all GSA-R2R splits.", "published": "2025-01-29 03:57:56", "link": "http://arxiv.org/abs/2501.17403v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases\n  in Language Models", "abstract": "While advances in fairness and alignment have helped mitigate overt biases\nexhibited by large language models (LLMs) when explicitly prompted, we\nhypothesize that these models may still exhibit implicit biases when simulating\nhuman behavior. To test this hypothesis, we propose a technique to\nsystematically uncover such biases across a broad range of sociodemographic\ncategories by assessing decision-making disparities among agents with\nLLM-generated, sociodemographically-informed personas. Using our technique, we\ntested six LLMs across three sociodemographic groups and four decision-making\nscenarios. Our results show that state-of-the-art LLMs exhibit significant\nsociodemographic disparities in nearly all simulations, with more advanced\nmodels exhibiting greater implicit biases despite reducing explicit biases.\nFurthermore, when comparing our findings to real-world disparities reported in\nempirical studies, we find that the biases we uncovered are directionally\naligned but markedly amplified. This directional alignment highlights the\nutility of our technique in uncovering systematic biases in LLMs rather than\nrandom variations; moreover, the presence and amplification of implicit biases\nemphasizes the need for novel strategies to address these biases.", "published": "2025-01-29 05:21:31", "link": "http://arxiv.org/abs/2501.17420v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing\n  Guardrail Moderation", "abstract": "Recent research shows that Large Language Models (LLMs) are vulnerable to\nharmful fine-tuning attacks -- models lose their safety alignment ability after\nfine-tuning on a few harmful samples. For risk mitigation, a guardrail is\ntypically used to filter out harmful samples before fine-tuning. By designing a\nnew red-teaming method, we in this paper show that purely relying on the\nmoderation guardrail for data filtration is not reliable. Our proposed attack\nmethod, dubbed Virus, easily bypasses the guardrail moderation by slightly\nmodifying the harmful data. Experimental results show that the harmful data\noptimized by Virus is not detectable by the guardrail with up to 100\\% leakage\nratio, and can simultaneously achieve superior attack performance. Finally, the\nkey message we want to convey through this paper is that: \\textbf{it is\nreckless to consider guardrail moderation as a clutch at straws towards harmful\nfine-tuning attack}, as it cannot solve the inherent safety issue of the\npre-trained LLMs. Our code is available at https://github.com/git-disl/Virus", "published": "2025-01-29 06:24:58", "link": "http://arxiv.org/abs/2501.17433v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious natural language processing tasks but often struggle to excel uniformly\nin diverse or complex domains. We propose a novel ensemble method - Diverse\nFingerprint Ensemble (DFPE), which leverages the complementary strengths of\nmultiple LLMs to achieve more robust performance. Our approach involves: (1)\nclustering models based on response \"fingerprints\" patterns, (2) applying a\nquantile-based filtering mechanism to remove underperforming models at a\nper-subject level, and (3) assigning adaptive weights to remaining models based\non their subject-wise validation accuracy. In experiments on the Massive\nMultitask Language Understanding (MMLU) benchmark, DFPE outperforms the best\nsingle model by 3% overall accuracy and 5% in discipline-level accuracy. This\nmethod increases the robustness and generalization of LLMs and underscores how\nmodel selection, diversity preservation, and performance-driven weighting can\neffectively address challenging, multi-faceted language understanding tasks.", "published": "2025-01-29 08:44:45", "link": "http://arxiv.org/abs/2501.17479v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DINT Transformer", "abstract": "DIFF Transformer addresses the issue of irrelevant context interference by\nintroducing a differential attention mechanism that enhances the robustness of\nlocal attention. However, it has two critical limitations: the lack of global\ncontext modeling, which is essential for identifying globally significant\ntokens, and numerical instability due to the absence of strict row\nnormalization in the attention matrix. To overcome these challenges, we propose\nDINT Transformer, which extends DIFF Transformer by incorporating a\ndifferential-integral mechanism. By computing global importance scores and\nintegrating them into the attention matrix, DINT Transformer improves its\nability to capture global dependencies. Moreover, the unified parameter design\nenforces row-normalized attention matrices, improving numerical stability.\nExperimental results demonstrate that DINT Transformer excels in accuracy and\nrobustness across various practical applications, such as long-context language\nmodeling and key information retrieval. These results position DINT Transformer\nas a highly effective and promising architecture.", "published": "2025-01-29 08:53:29", "link": "http://arxiv.org/abs/2501.17486v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM Assistance for Pediatric Depression", "abstract": "Traditional depression screening methods, such as the PHQ-9, are particularly\nchallenging for children in pediatric primary care due to practical\nlimitations. AI has the potential to help, but the scarcity of annotated\ndatasets in mental health, combined with the computational costs of training,\nhighlights the need for efficient, zero-shot approaches. In this work, we\ninvestigate the feasibility of state-of-the-art LLMs for depressive symptom\nextraction in pediatric settings (ages 6-24). This approach aims to complement\ntraditional screening and minimize diagnostic errors.\n  Our findings show that all LLMs are 60% more efficient than word match, with\nFlan leading in precision (average F1: 0.65, precision: 0.78), excelling in the\nextraction of more rare symptoms like \"sleep problems\" (F1: 0.92) and\n\"self-loathing\" (F1: 0.8). Phi strikes a balance between precision (0.44) and\nrecall (0.60), performing well in categories like \"Feeling depressed\" (0.69)\nand \"Weight change\" (0.78). Llama 3, with the highest recall (0.90),\novergeneralizes symptoms, making it less suitable for this type of analysis.\nChallenges include the complexity of clinical notes and overgeneralization from\nPHQ-9 scores. The main challenges faced by LLMs include navigating the complex\nstructure of clinical notes with content from different times in the patient\ntrajectory, as well as misinterpreting elevated PHQ-9 scores.\n  We finally demonstrate the utility of symptom annotations provided by Flan as\nfeatures in an ML algorithm, which differentiates depression cases from\ncontrols with high precision of 0.78, showing a major performance boost\ncompared to a baseline that does not use these features.", "published": "2025-01-29 09:27:27", "link": "http://arxiv.org/abs/2501.17510v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CSEval: Towards Automated, Multi-Dimensional, and Reference-Free\n  Counterspeech Evaluation using Auto-Calibrated LLMs", "abstract": "Counterspeech has emerged as a popular and effective strategy for combating\nonline hate speech, sparking growing research interest in automating its\ngeneration using language models. However, the field still lacks standardised\nevaluation protocols and reliable automated evaluation metrics that align with\nhuman judgement. Current automatic evaluation methods, primarily based on\nsimilarity metrics, do not effectively capture the complex and independent\nattributes of counterspeech quality, such as contextual relevance,\naggressiveness, or argumentative coherence. This has led to an increased\ndependency on labor-intensive human evaluations to assess automated\ncounter-speech generation methods. To address these challenges, we introduce\nCSEval, a novel dataset and framework for evaluating counterspeech quality\nacross four dimensions: contextual-relevance, aggressiveness,\nargument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated\nCOT for Counterspeech Evaluation (Auto-CSEval), a prompt-based method with\nauto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large\nlanguage models. Our experiments show that Auto-CSEval outperforms traditional\nmetrics like ROUGE, METEOR, and BertScore in correlating with human judgement,\nindicating a significant improvement in automated counterspeech evaluation.", "published": "2025-01-29 11:38:29", "link": "http://arxiv.org/abs/2501.17581v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "GLLM: Self-Corrective G-Code Generation using Large Language Models with\n  User Feedback", "abstract": "This paper introduces GLLM, an innovative tool that leverages Large Language\nModels (LLMs) to automatically generate G-code from natural language\ninstructions for Computer Numerical Control (CNC) machining. GLLM addresses the\nchallenges of manual G-code writing by bridging the gap between human-readable\ntask descriptions and machine-executable code. The system incorporates a\nfine-tuned StarCoder-3B model, enhanced with domain-specific training data and\na Retrieval-Augmented Generation (RAG) mechanism. GLLM employs advanced\nprompting strategies and a novel self-corrective code generation approach to\nensure both syntactic and semantic correctness of the generated G-code. The\narchitecture includes robust validation mechanisms, including syntax checks,\nG-code-specific verifications, and functional correctness evaluations using\nHausdorff distance. By combining these techniques, GLLM aims to democratize CNC\nprogramming, making it more accessible to users without extensive programming\nexperience while maintaining high accuracy and reliability in G-code\ngeneration.", "published": "2025-01-29 11:40:46", "link": "http://arxiv.org/abs/2501.17584v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Cross-lingual Embedding Clustering for Hierarchical Softmax in\n  Low-Resource Multilingual Speech Recognition", "abstract": "We present a novel approach centered on the decoding stage of Automatic\nSpeech Recognition (ASR) that enhances multilingual performance, especially for\nlow-resource languages. It utilizes a cross-lingual embedding clustering method\nto construct a hierarchical Softmax (H-Softmax) decoder, which enables similar\ntokens across different languages to share similar decoder representations. It\naddresses the limitations of the previous Huffman-based H-Softmax method, which\nrelied on shallow features in token similarity assessments. Through experiments\non a downsampled dataset of 15 languages, we demonstrate the effectiveness of\nour approach in improving low-resource multilingual ASR accuracy.", "published": "2025-01-29 12:44:30", "link": "http://arxiv.org/abs/2501.17615v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "In-Context Meta LoRA Generation", "abstract": "Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task\nspecific fine-tuning. However, in scenarios that involve multiple tasks,\ntraining a separate LoRA model for each one results in considerable\ninefficiency in terms of storage and inference. Moreover, existing parameter\ngeneration methods fail to capture the correlations among these tasks, making\nmulti-task LoRA parameter generation challenging. To address these limitations,\nwe propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently\nachieves task-specific customization of large language models (LLMs).\nSpecifically, we use training data from all tasks to train a tailored\ngenerator, Conditional Variational Autoencoder (CVAE). CVAE takes task\ndescriptions as inputs and produces task-aware LoRA weights as outputs. These\nLoRA weights are then merged with LLMs to create task-specialized models\nwithout the need for additional fine-tuning. Furthermore, we utilize in-context\nmeta-learning for knowledge enhancement and task mapping, to capture the\nrelationship between tasks and parameter distributions. As a result, our method\nachieves more accurate LoRA parameter generation for diverse tasks using CVAE.\nICM-LoRA enables more accurate LoRA parameter reconstruction than current\nparameter reconstruction methods and is useful for implementing task-specific\nenhancements of LoRA parameters. At the same time, our method occupies 283MB,\nonly 1\\% storage compared with the original LoRA.", "published": "2025-01-29 13:12:01", "link": "http://arxiv.org/abs/2501.17635v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Using Code Generation to Solve Open Instances of Combinatorial Design\n  Problems", "abstract": "The Handbook of Combinatorial Designs catalogs many types of combinatorial\ndesigns, together with lists of open instances for which existence has not yet\nbeen determined. We develop a constructive protocol CPro1, which uses Large\nLanguage Models (LLMs) to generate code that constructs combinatorial designs\nand resolves some of these open instances. The protocol starts from a\ndefinition of a particular type of design, and a verifier that reliably\nconfirms whether a proposed design is valid. The LLM selects strategies and\nimplements them in code, and scaffolding provides automated hyperparameter\ntuning and execution feedback using the verifier. Most generated code fails,\nbut by generating many candidates, the protocol automates exploration of a\nvariety of standard methods (e.g. simulated annealing, genetic algorithms) and\nexperimentation with variations (e.g. cost functions) to find successful\napproaches. Testing on 16 different types of designs, CPro1 constructs\nsolutions to open instances for 6 of them: Symmetric and Skew Weighing\nMatrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary\nDesigns, and Florentine Rectangles.", "published": "2025-01-29 15:57:43", "link": "http://arxiv.org/abs/2501.17725v1", "categories": ["cs.AI", "cs.CL", "cs.DM", "math.CO"], "primary_category": "cs.AI"}
{"title": "Improving Privacy Benefits of Redaction", "abstract": "We propose a novel redaction methodology that can be used to sanitize natural\ntext data. Our new technique provides better privacy benefits than other state\nof the art techniques while maintaining lower redaction levels.", "published": "2025-01-29 16:53:16", "link": "http://arxiv.org/abs/2501.17762v3", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "2SSP: A Two-Stage Framework for Structured Pruning of LLMs", "abstract": "We propose a novel Two-Stage framework for Structured Pruning (2SSP) for\npruning Large Language Models (LLMs), which combines two different strategies\nof pruning, namely Width and Depth Pruning. The first stage (Width Pruning)\nremoves entire neurons, hence their corresponding rows and columns, aiming to\npreserve the connectivity among the pruned structures in the intermediate state\nof the Feed-Forward Networks in each Transformer block. This is done based on\nan importance score measuring the impact of each neuron over the output\nmagnitude. The second stage (Depth Pruning), instead, removes entire Attention\nsubmodules. This is done by applying an iterative process that removes the\nAttention submodules with the minimum impact on a given metric of interest (in\nour case, perplexity). We also propose a novel mechanism to balance the\nsparsity rate of the two stages w.r.t. to the desired global sparsity. We test\n2SSP on four LLM families and three sparsity rates (25\\%, 37.5\\%, and 50\\%),\nmeasuring the resulting perplexity over three language modeling datasets as\nwell as the performance over six downstream tasks. Our method consistently\noutperforms five state-of-the-art competitors over three language modeling and\nsix downstream tasks, with an up to two-order-of-magnitude gain in terms of\npruning time. The code is available at available at\n\\url{https://github.com/FabrizioSandri/2SSP}.", "published": "2025-01-29 17:05:33", "link": "http://arxiv.org/abs/2501.17771v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Janus-Pro: Unified Multimodal Understanding and Generation with Data and\n  Model Scaling", "abstract": "In this work, we introduce Janus-Pro, an advanced version of the previous\nwork Janus. Specifically, Janus-Pro incorporates (1) an optimized training\nstrategy, (2) expanded training data, and (3) scaling to larger model size.\nWith these improvements, Janus-Pro achieves significant advancements in both\nmultimodal understanding and text-to-image instruction-following capabilities,\nwhile also enhancing the stability of text-to-image generation. We hope this\nwork will inspire further exploration in the field. Code and models are\npublicly available.", "published": "2025-01-29 18:00:19", "link": "http://arxiv.org/abs/2501.17811v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Improving Your Model Ranking on Chatbot Arena by Vote Rigging", "abstract": "Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,\nwhere users vote for their preferred response from two randomly sampled\nanonymous models. While Chatbot Arena is widely regarded as a reliable LLM\nranking leaderboard, we show that crowdsourced voting can be rigged to improve\n(or decrease) the ranking of a target model $m_{t}$. We first introduce a\nstraightforward target-only rigging strategy that focuses on new battles\ninvolving $m_{t}$, identifying it via watermarking or a binary classifier, and\nexclusively voting for $m_{t}$ wins. However, this strategy is practically\ninefficient because there are over $190$ models on Chatbot Arena and on average\nonly about $1\\%$ of new battles will involve $m_{t}$. To overcome this, we\npropose omnipresent rigging strategies, exploiting the Elo rating mechanism of\nChatbot Arena that any new vote on a battle can influence the ranking of the\ntarget model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.\nWe conduct experiments on around $1.7$ million historical votes from the\nChatbot Arena Notebook, showing that omnipresent rigging strategies can improve\nmodel rankings by rigging only hundreds of new votes. While we have evaluated\nseveral defense mechanisms, our findings highlight the importance of continued\nefforts to prevent vote rigging. Our code is available at\nhttps://github.com/sail-sg/Rigging-ChatbotArena.", "published": "2025-01-29 18:57:29", "link": "http://arxiv.org/abs/2501.17858v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DReSS: Data-driven Regularized Structured Streamlining for Large\n  Language Models", "abstract": "Large language models (LLMs) have achieved significant progress across\nvarious domains, but their increasing scale results in high computational and\nmemory costs. Recent studies have revealed that LLMs exhibit sparsity,\nproviding the potential to reduce model size through pruning techniques.\nHowever, existing pruning methods typically follow a prune-then-finetune\nparadigm. Since the pruned components still contain valuable information, their\ndirect removal often leads to irreversible performance degradation, imposing a\nsubstantial computational burden to recover performance during finetuning. In\nthis paper, we propose a novel paradigm that first applies regularization, then\nprunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a\nsimple and effective Data-driven Regularized Structured Streamlining method for\nLLMs. By leveraging a small amount of data to regularize the components to be\npruned, DReSS explicitly transfers the important information to the remaining\nparts of the model in advance. Compared to direct pruning, this can reduce the\ninformation loss caused by parameter removal, thereby enhancing its language\nmodeling capabilities. Experimental results demonstrate that DReSS\nsignificantly outperforms existing pruning methods even under extreme pruning\nratios, significantly reducing latency and increasing throughput.", "published": "2025-01-29 14:28:11", "link": "http://arxiv.org/abs/2501.17905v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From tools to thieves: Measuring and understanding public perceptions of\n  AI through crowdsourced metaphors", "abstract": "How has the public responded to the increasing prevalence of artificial\nintelligence (AI)-based technologies? We investigate public perceptions of AI\nby collecting over 12,000 responses over 12 months from a nationally\nrepresentative U.S. sample. Participants provided open-ended metaphors\nreflecting their mental models of AI, a methodology that overcomes the\nlimitations of traditional self-reported measures. Using a mixed-methods\napproach combining quantitative clustering and qualitative coding, we identify\n20 dominant metaphors shaping public understanding of AI. To analyze these\nmetaphors systematically, we present a scalable framework integrating language\nmodeling (LM)-based techniques to measure key dimensions of public perception:\nanthropomorphism (attribution of human-like qualities), warmth, and competence.\nWe find that Americans generally view AI as warm and competent, and that over\nthe past year, perceptions of AI's human-likeness and warmth have significantly\nincreased ($+34\\%, r = 0.80, p < 0.01; +41\\%, r = 0.62, p < 0.05$).\nFurthermore, these implicit perceptions, along with the identified dominant\nmetaphors, strongly predict trust in and willingness to adopt AI ($r^2 = 0.21,\n0.18, p < 0.001$). We further explore how differences in metaphors and implicit\nperceptions--such as the higher propensity of women, older individuals, and\npeople of color to anthropomorphize AI--shed light on demographic disparities\nin trust and adoption. In addition to our dataset and framework for tracking\nevolving public attitudes, we provide actionable insights on using metaphors\nfor inclusive and responsible AI development.", "published": "2025-01-29 23:17:43", "link": "http://arxiv.org/abs/2501.18045v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Layered Chain-of-Thought Prompting for Multi-Agent LLM Systems: A\n  Comprehensive Approach to Explainable Large Language Models", "abstract": "Large Language Models (LLMs) leverage chain-of-thought (CoT) prompting to\nprovide step-by-step rationales, improving performance on complex tasks.\nDespite its benefits, vanilla CoT often fails to fully verify intermediate\ninferences and can produce misleading explanations. In this work, we propose\nLayered Chain-of-Thought (Layered-CoT) Prompting, a novel framework that\nsystematically segments the reasoning process into multiple layers, each\nsubjected to external checks and optional user feedback. We expand on the key\nconcepts, present three scenarios -- medical triage, financial risk assessment,\nand agile engineering -- and demonstrate how Layered-CoT surpasses vanilla CoT\nin terms of transparency, correctness, and user engagement. By integrating\nreferences from recent arXiv papers on interactive explainability, multi-agent\nframeworks, and agent-based collaboration, we illustrate how Layered-CoT paves\nthe way for more reliable and grounded explanations in high-stakes domains.", "published": "2025-01-29 13:21:09", "link": "http://arxiv.org/abs/2501.18645v2", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Fake News Detection After LLM Laundering: Measurement and Explanation", "abstract": "With their advanced capabilities, Large Language Models (LLMs) can generate\nhighly convincing and contextually relevant fake news, which can contribute to\ndisseminating misinformation. Though there is much research on fake news\ndetection for human-written text, the field of detecting LLM-generated fake\nnews is still under-explored. This research measures the efficacy of detectors\nin identifying LLM-paraphrased fake news, in particular, determining whether\nadding a paraphrase step in the detection pipeline helps or impedes detection.\nThis study contributes: (1) Detectors struggle to detect LLM-paraphrased fake\nnews more than human-written text, (2) We find which models excel at which\ntasks (evading detection, paraphrasing to evade detection, and paraphrasing for\nsemantic similarity). (3) Via LIME explanations, we discovered a possible\nreason for detection failures: sentiment shift. (4) We discover a worrisome\ntrend for paraphrase quality measurement: samples that exhibit sentiment shift\ndespite a high BERTSCORE. (5) We provide a pair of datasets augmenting existing\ndatasets with paraphrase outputs and scores. The dataset is available on GitHub", "published": "2025-01-29 17:58:07", "link": "http://arxiv.org/abs/2501.18649v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Making Flowchart Images Machine Interpretable", "abstract": "Computer programming textbooks and software documentations often contain\nflowcharts to illustrate the flow of an algorithm or procedure. Modern OCR\nengines often tag these flowcharts as graphics and ignore them in further\nprocessing. In this paper, we work towards making flowchart images\nmachine-interpretable by converting them to executable Python codes. To this\nend, inspired by the recent success in natural language to code generation\nliterature, we present a novel transformer-based framework, namely FloCo-T5.\nOur model is well-suited for this task,as it can effectively learn semantics,\nstructure, and patterns of programming languages, which it leverages to\ngenerate syntactically correct code. We also used a task-specific pre-training\nobjective to pre-train FloCo-T5 using a large number of logic-preserving\naugmented code samples. Further, to perform a rigorous study of this problem,\nwe introduce theFloCo dataset that contains 11,884 flowchart images and their\ncorresponding Python codes. Our experiments show promising results, and\nFloCo-T5 clearly outperforms related competitive baselines on code generation\nmetrics. We make our dataset and implementation publicly available.", "published": "2025-01-29 06:43:38", "link": "http://arxiv.org/abs/2501.17441v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.DL", "cs.SE"], "primary_category": "cs.CV"}
{"title": "A computational loudness model for electrical stimulation with cochlear\n  implants", "abstract": "Cochlear implants (CIs) are devices that restore the sense of hearing in\npeople with severe sensorineural hearing loss. An electrode array inserted in\nthe cochlea bypasses the natural transducer mechanism that transforms\nmechanical sound waves into neural activity by artificially stimulating the\nauditory nerve fibers with electrical pulses. The perception of sounds is\npossible because the brain extracts features from this neural activity, and\nloudness is among the most fundamental perceptual features.\n  A computational model that uses a three-dimensional (3D) representation of\nthe peripheral auditory system of CI users was developed to predict categorical\nloudness from the simulated peripheral neural activity. In contrast, current\nstate-of-the-art computational loudness models predict loudness from the\nelectrical pulses with minimal parametrization of the electrode-nerve\ninterface. In the proposed model, the spikes produced in a population of\nauditory nerve fibers were grouped by cochlear places, a physiological\nrepresentation of the auditory filters in psychoacoustics, to be transformed\ninto loudness contribution. Then, a loudness index was obtained with a\nspatiotemporal integration over this loudness contribution. This index served\nto define the simulated threshold of hearing (THL) and most comfortable\nloudness (MCL) levels resembling the growth function in CI users.\n  The performance of real CI users in loudness summation experiments was also\nused to validate the computational model. These experiments studied the effect\nof stimulation rate, electrode separation and amplitude modulation. The\nproposed model provides a new set of perceptual features that can be used in\ncomputational frameworks for CIs and narrows the gap between simulations and\nthe human peripheral neural activity.", "published": "2025-01-29 13:19:32", "link": "http://arxiv.org/abs/2501.17640v1", "categories": ["q-bio.NC", "eess.AS"], "primary_category": "q-bio.NC"}
{"title": "Music2Latent2: Audio Compression with Summary Embeddings and\n  Autoregressive Decoding", "abstract": "Efficiently compressing high-dimensional audio signals into a compact and\ninformative latent space is crucial for various tasks, including generative\nmodeling and music information retrieval (MIR). Existing audio autoencoders,\nhowever, often struggle to achieve high compression ratios while preserving\naudio fidelity and facilitating efficient downstream applications. We introduce\nMusic2Latent2, a novel audio autoencoder that addresses these limitations by\nleveraging consistency models and a novel approach to representation learning\nbased on unordered latent embeddings, which we call summary embeddings. Unlike\nconventional methods that encode local audio features into ordered sequences,\nMusic2Latent2 compresses audio signals into sets of summary embeddings, where\neach embedding can capture distinct global features of the input sample. This\nenables to achieve higher reconstruction quality at the same compression ratio.\nTo handle arbitrary audio lengths, Music2Latent2 employs an autoregressive\nconsistency model trained on two consecutive audio chunks with causal masking,\nensuring coherent reconstruction across segment boundaries. Additionally, we\npropose a novel two-step decoding procedure that leverages the denoising\ncapabilities of consistency models to further refine the generated audio at no\nadditional cost. Our experiments demonstrate that Music2Latent2 outperforms\nexisting continuous audio autoencoders regarding audio quality and performance\non downstream tasks. Music2Latent2 paves the way for new possibilities in audio\ncompression.", "published": "2025-01-29 11:34:19", "link": "http://arxiv.org/abs/2501.17578v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and\n  Conditional Flow Matching", "abstract": "Despite remarkable advancements in recent voice conversion (VC) systems,\nenhancing speaker similarity in zero-shot scenarios remains challenging. This\nchallenge arises from the difficulty of generalizing and adapting speaker\ncharacteristics in speech within zero-shot environments, which is further\ncomplicated by mismatch between the training and inference processes. To\naddress these challenges, we propose VoicePrompter, a robust zero-shot VC model\nthat leverages in-context learning with voice prompts. VoicePrompter is\ncomposed of (1) a factorization method that disentangles speech components and\n(2) a DiT-based conditional flow matching (CFM) decoder that conditions on\nthese factorized features and voice prompts. Additionally, (3) latent mixup is\nused to enhance in-context learning by combining various speaker features. This\napproach improves speaker similarity and naturalness in zero-shot VC by\napplying mixup to latent representations. Experimental results demonstrate that\nVoicePrompter outperforms existing zero-shot VC systems in terms of speaker\nsimilarity, speech intelligibility, and audio quality. Our demo is available at\n\\url{https://hayeong0.github.io/VoicePrompter-demo/}.", "published": "2025-01-29 12:34:58", "link": "http://arxiv.org/abs/2501.17612v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Self-Supervised Frameworks for Speaker Verification via Bootstrapped\n  Positive Sampling", "abstract": "Recent developments in Self-Supervised Learning (SSL) have demonstrated\nsignificant potential for Speaker Verification (SV), but closing the\nperformance gap with supervised systems remains an ongoing challenge. Standard\nSSL frameworks rely on anchor-positive pairs extracted from the same audio\nutterances. Hence, positives have channel characteristics similar to those of\ntheir corresponding anchors, even with extensive data-augmentation. Therefore,\nthis positive sampling strategy is a fundamental limitation as it encodes too\nmuch information regarding the recording source in the learned representations.\nThis article introduces Self-Supervised Positive Sampling (SSPS), a\nbootstrapped technique for sampling appropriate and diverse positives in SSL\nframeworks for SV. SSPS samples positives close to their anchor in the\nrepresentation space, as we assume that these pseudo-positives belong to the\nsame speaker identity but correspond to different recording conditions. This\nmethod demonstrates consistent improvements in SV performance on VoxCeleb\nbenchmarks when implemented in major SSL frameworks, such as SimCLR, SwAV,\nVICReg, and DINO. Using SSPS, SimCLR, and DINO achieve 2.57% and 2.53% EER on\nVoxCeleb1-O. SimCLR yields a 58% relative reduction in EER, getting comparable\nperformance to DINO with a simpler training framework. Furthermore, SSPS lowers\nintra-class variance and reduces channel information in speaker representations\nwhile exhibiting greater robustness without data-augmentation.", "published": "2025-01-29 17:08:01", "link": "http://arxiv.org/abs/2501.17772v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "acoupi: An Open-Source Python Framework for Deploying Bioacoustic AI\n  Models on Edge Devices", "abstract": "1. Passive acoustic monitoring (PAM) coupled with artificial intelligence\n(AI) is becoming an essential tool for biodiversity monitoring. Traditional PAM\nsystems require manual data offloading and impose substantial demands on\nstorage and computing infrastructure. The combination of on-device AI-based\nprocessing and network connectivity enables local data analysis and\ntransmission of only relevant information, greatly reducing storage needs.\nHowever, programming these devices for robust operation is challenging,\nrequiring expertise in embedded systems and software engineering. Despite the\nincrease in AI-based models for bioacoustics, their full potential remains\nunrealized without accessible tools to deploy them on custom hardware and\ntailor device behaviour to specific monitoring goals. 2. To address this\nchallenge, we develop acoupi, an open-source Python framework that simplifies\nthe creation and deployment of smart bioacoustic devices. acoupi integrates\naudio recording, AI-based data processing, data management, and real-time\nwireless messaging into a unified and configurable framework. By modularising\nkey elements of the bioacoustic monitoring workflow, acoupi allows users to\neasily customise, extend, or select specific components to fit their unique\nmonitoring needs. 3. We demonstrate the flexibility of acoupi by integrating\ntwo bioacoustic classifiers: BirdNET, for the classification of bird species,\nand BatDetect2, for the classification of UK bat species. We test the\nreliability of acoupi over a month-long deployment of two acoupi-powered\ndevices in a UK urban park. 4. acoupi can be deployed on low-cost hardware such\nas the Raspberry Pi and can be customised for various applications. acoupi\nstandardised framework and simplified tools facilitate the adoption of\nAI-powered PAM systems for researchers and conservationists. acoupi is on\nGitHub at https://github.com/acoupi/acoupi.", "published": "2025-01-29 18:44:48", "link": "http://arxiv.org/abs/2501.17841v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "H.5.5; I.2.m; J.3"], "primary_category": "cs.SD"}
{"title": "Privacy-Preserving Edge Speech Understanding with Tiny Foundation Models", "abstract": "Robust speech recognition systems rely on cloud service providers for\ninference. It needs to ensure that an untrustworthy provider cannot deduce the\nsensitive content in speech. Sanitization can be done on speech content keeping\nin mind that it has to avoid compromising transcription accuracy. Realizing the\nunder utilized capabilities of tiny speech foundation models (FMs), for the\nfirst time, we propose a novel use: enhancing speech privacy on\nresource-constrained devices. We introduce XYZ, an edge/cloud privacy\npreserving speech inference engine that can filter sensitive entities without\ncompromising transcript accuracy. We utilize a timestamp based on-device\nmasking approach that utilizes a token to entity prediction model to filter\nsensitive entities. Our choice of mask strategically conceals parts of the\ninput and hides sensitive data. The masked input is sent to a trusted cloud\nservice or to a local hub to generate the masked output. The effectiveness of\nXYZ hinges on how well the entity time segments are masked. Our recovery is a\nconfidence score based approach that chooses the best prediction between cloud\nand on-device model. We implement XYZ on a 64 bit Raspberry Pi 4B. Experiments\nshow that our solution leads to robust speech recognition without forsaking\nprivacy. XYZ with < 100 MB memory, achieves state-of-the-art (SOTA) speech\ntranscription performance while filtering about 83% of private entities\ndirectly on-device. XYZ is 16x smaller in memory and 17x more compute efficient\nthan prior privacy preserving speech frameworks and has a relative reduction in\nword error rate (WER) by 38.8-77.5% when compared to existing offline\ntranscription services.", "published": "2025-01-29 18:55:42", "link": "http://arxiv.org/abs/2502.01649v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
