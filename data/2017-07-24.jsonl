{"title": "Analysing Errors of Open Information Extraction Systems", "abstract": "We report results on benchmarking Open Information Extraction (OIE) systems\nusing RelVis, a toolkit for benchmarking Open Information Extraction systems.\nOur comprehensive benchmark contains three data sets from the news domain and\none data set from Wikipedia with overall 4522 labeled sentences and 11243\nbinary or n-ary OIE relations. In our analysis on these data sets we compared\nthe performance of four popular OIE systems, ClausIE, OpenIE 4.2, Stanford\nOpenIE and PredPatt. In addition, we evaluated the impact of five common error\nclasses on a subset of 749 n-ary tuples. From our deep analysis we unreveal\nimportant research directions for a next generation of OIE systems.", "published": "2017-07-24 11:49:00", "link": "http://arxiv.org/abs/1707.07499v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAp 2017 challenge: Twitter Named Entity Recognition", "abstract": "The paper describes the CAp 2017 challenge. The challenge concerns the\nproblem of Named Entity Recognition (NER) for tweets written in French. We\nfirst present the data preparation steps we followed for constructing the\ndataset released in the framework of the challenge. We begin by demonstrating\nwhy NER for tweets is a challenging problem especially when the number of\nentities increases. We detail the annotation process and the necessary\ndecisions we made. We provide statistics on the inter-annotator agreement, and\nwe conclude the data description part with examples and statistics for the\ndata. We, then, describe the participation in the challenge, where 8 teams\nparticipated, with a focus on the methods employed by the challenge\nparticipants and the scores achieved in terms of F$_1$ measure. Importantly,\nthe constructed dataset comprising $\\sim$6,000 tweets annotated for 13 types of\nentities, which to the best of our knowledge is the first such dataset in\nFrench, is publicly available at \\url{http://cap2017.imag.fr/competition.html} .", "published": "2017-07-24 14:20:07", "link": "http://arxiv.org/abs/1707.07568v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transition-Based Generation from Abstract Meaning Representations", "abstract": "This work addresses the task of generating English sentences from Abstract\nMeaning Representation (AMR) graphs. To cope with this task, we transform each\ninput AMR graph into a structure similar to a dependency tree and annotate it\nwith syntactic information by applying various predefined actions to it.\nSubsequently, a sentence is obtained from this tree structure by visiting its\nnodes in a specific order. We train maximum entropy models to estimate the\nprobability of each individual action and devise an algorithm that efficiently\napproximates the best sequence of actions to be applied. Using a substandard\nlanguage model, our generator achieves a Bleu score of 27.4 on the LDC2014T12\ntest set, the best result reported so far without using silver standard\nannotations from another corpus as additional training data.", "published": "2017-07-24 14:52:32", "link": "http://arxiv.org/abs/1707.07591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improve Lexicon-based Word Embeddings By Word Sense Disambiguation", "abstract": "There have been some works that learn a lexicon together with the corpus to\nimprove the word embeddings. However, they either model the lexicon separately\nbut update the neural networks for both the corpus and the lexicon by the same\nlikelihood, or minimize the distance between all of the synonym pairs in the\nlexicon. Such methods do not consider the relatedness and difference of the\ncorpus and the lexicon, and may not be the best optimized. In this paper, we\npropose a novel method that considers the relatedness and difference of the\ncorpus and the lexicon. It trains word embeddings by learning the corpus to\npredicate a word and its corresponding synonym under the context at the same\ntime. For polysemous words, we use a word sense disambiguation filter to\neliminate the synonyms that have different meanings for the context. To\nevaluate the proposed method, we compare the performance of the word embeddings\ntrained by our proposed model, the control groups without the filter or the\nlexicon, and the prior works in the word similarity tasks and text\nclassification task. The experimental results show that the proposed model\nprovides better embeddings for polysemous words and improves the performance\nfor text classification.", "published": "2017-07-24 16:07:01", "link": "http://arxiv.org/abs/1707.07628v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Architectures for Neural Machine Translation", "abstract": "It has been shown that increasing model depth improves the quality of neural\nmachine translation. However, different architectural variants to increase\nmodel depth have been proposed, and so far, there has been no thorough\ncomparative study.\n  In this work, we describe and evaluate several existing approaches to\nintroduce depth in neural machine translation. Additionally, we explore novel\narchitectural variants, including deep transition RNNs, and we vary how\nattention is used in the deep decoder. We introduce a novel \"BiDeep\" RNN\narchitecture that combines deep transition RNNs and stacked RNNs.\n  Our evaluation is carried out on the English to German WMT news translation\ndataset, using a single-GPU machine for both training and inference. We find\nthat several of our proposed architectures improve upon existing approaches in\nterms of speed and translation quality. We obtain best improvements with a\nBiDeep RNN of combined depth 8, obtaining an average improvement of 1.5 BLEU\nover a strong shallow baseline.\n  We release our code for ease of adoption.", "published": "2017-07-24 16:19:59", "link": "http://arxiv.org/abs/1707.07631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Global Normalization of Convolutional Neural Networks for Joint Entity\n  and Relation Classification", "abstract": "We introduce globally normalized convolutional neural networks for joint\nentity classification and relation extraction. In particular, we propose a way\nto utilize a linear-chain conditional random field output layer for predicting\nentity types and relations between entities at the same time. Our experiments\nshow that global normalization outperforms a locally normalized softmax layer\non a benchmark dataset.", "published": "2017-07-24 19:39:22", "link": "http://arxiv.org/abs/1707.07719v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMR Parsing using Stack-LSTMs", "abstract": "We present a transition-based AMR parser that directly generates AMR parses\nfrom plain text. We use Stack-LSTMs to represent our parser state and make\ndecisions greedily. In our experiments, we show that our parser achieves very\ncompetitive scores on English using only AMR training data. Adding additional\ninformation, such as POS tags and dependency trees, improves the results\nfurther.", "published": "2017-07-24 21:33:21", "link": "http://arxiv.org/abs/1707.07755v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Neural Transducers for End-to-End Speech Recognition", "abstract": "In this work, we perform an empirical comparison among the CTC,\nRNN-Transducer, and attention-based Seq2Seq models for end-to-end speech\nrecognition. We show that, without any language model, Seq2Seq and\nRNN-Transducer models both outperform the best reported CTC models with a\nlanguage model, on the popular Hub5'00 benchmark. On our internal diverse\ndataset, these trends continue - RNNTransducer models rescored with a language\nmodel after beam search outperform our best CTC models. These results simplify\nthe speech recognition pipeline so that decoding can now be expressed purely as\nneural network operations. We also study how the choice of encoder architecture\naffects the performance of the three models - when all encoder layers are\nforward only, and when encoders downsample the input representation\naggressively.", "published": "2017-07-24 06:05:21", "link": "http://arxiv.org/abs/1707.07413v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Character-level Intra Attention Network for Natural Language Inference", "abstract": "Natural language inference (NLI) is a central problem in language\nunderstanding. End-to-end artificial neural networks have reached\nstate-of-the-art performance in NLI field recently.\n  In this paper, we propose Character-level Intra Attention Network (CIAN) for\nthe NLI task. In our model, we use the character-level convolutional network to\nreplace the standard word embedding layer, and we use the intra attention to\ncapture the intra-sentence semantics. The proposed CIAN model provides improved\nresults based on a newly published MNLI corpus.", "published": "2017-07-24 10:35:46", "link": "http://arxiv.org/abs/1707.07469v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Rare Word Representations using Semantic Bridging", "abstract": "We propose a methodology that adapts graph embedding techniques (DeepWalk\n(Perozzi et al., 2014) and node2vec (Grover and Leskovec, 2016)) as well as\ncross-lingual vector space mapping approaches (Least Squares and Canonical\nCorrelation Analysis) in order to merge the corpus and ontological sources of\nlexical knowledge. We also perform comparative analysis of the used algorithms\nin order to identify the best combination for the proposed system. We then\napply this to the task of enhancing the coverage of an existing word\nembedding's vocabulary with rare and unseen words. We show that our technique\ncan provide considerable extra coverage (over 99%), leading to consistent\nperformance gain (around 10% absolute gain is achieved with w2v-gn-500K cf.\\S\n3.3) on the Rare Word Similarity dataset.", "published": "2017-07-24 13:38:00", "link": "http://arxiv.org/abs/1707.07554v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Image Pivoting for Learning Multilingual Multimodal Representations", "abstract": "In this paper we propose a model to learn multimodal multilingual\nrepresentations for matching images and sentences in different languages, with\nthe aim of advancing multilingual versions of image search and image\nunderstanding. Our model learns a common representation for images and their\ndescriptions in two different languages (which need not be parallel) by\nconsidering the image as a pivot between two languages. We introduce a new\npairwise ranking loss function which can handle both symmetric and asymmetric\nsimilarity between the two modalities. We evaluate our models on\nimage-description ranking for German and English, and on semantic textual\nsimilarity of image descriptions in English. In both cases we achieve\nstate-of-the-art performance.", "published": "2017-07-24 15:08:13", "link": "http://arxiv.org/abs/1707.07601v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Thread Reconstruction in Conversational Data using Neural Coherence\n  Models", "abstract": "Discussion forums are an important source of information. They are often used\nto answer specific questions a user might have and to discover more about a\ntopic of interest. Discussions in these forums may evolve in intricate ways,\nmaking it difficult for users to follow the flow of ideas. We propose a novel\napproach for automatically identifying the underlying thread structure of a\nforum discussion. Our approach is based on a neural model that computes\ncoherence scores of possible reconstructions and then selects the highest\nscoring, i.e., the most coherent one. Preliminary experiments demonstrate\npromising results outperforming a number of strong baseline methods.", "published": "2017-07-24 17:42:32", "link": "http://arxiv.org/abs/1707.07660v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Reinforcement Learning for Bandit Neural Machine Translation with\n  Simulated Human Feedback", "abstract": "Machine translation is a natural candidate problem for reinforcement learning\nfrom human feedback: users provide quick, dirty ratings on candidate\ntranslations to guide a system to improve. Yet, current neural machine\ntranslation training focuses on expensive human-generated reference\ntranslations. We describe a reinforcement learning algorithm that improves\nneural machine translation systems from simulated human feedback. Our algorithm\ncombines the advantage actor-critic algorithm (Mnih et al., 2016) with the\nattention-based neural encoder-decoder architecture (Luong et al., 2015). This\nalgorithm (a) is well-designed for problems with a large action space and\ndelayed rewards, (b) effectively optimizes traditional corpus-level machine\ntranslation metrics, and (c) is robust to skewed, high-variance, granular\nfeedback modeled after actual human behaviors.", "published": "2017-07-24 04:35:19", "link": "http://arxiv.org/abs/1707.07402v4", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Share your Model instead of your Data: Privacy Preserving Mimic Learning\n  for Ranking", "abstract": "Deep neural networks have become a primary tool for solving problems in many\nfields. They are also used for addressing information retrieval problems and\nshow strong performance in several tasks. Training these models requires large,\nrepresentative datasets and for most IR tasks, such data contains sensitive\ninformation from users. Privacy and confidentiality concerns prevent many data\nowners from sharing the data, thus today the research community can only\nbenefit from research on large-scale datasets in a limited manner. In this\npaper, we discuss privacy preserving mimic learning, i.e., using predictions\nfrom a privacy preserving trained model instead of labels from the original\nsensitive training data as a supervision signal. We present the results of\npreliminary experiments in which we apply the idea of mimic learning and\nprivacy preserving mimic learning for the task of document re-ranking as one of\nthe core IR tasks. This research is a step toward laying the ground for\nenabling researchers from data-rich environments to share knowledge learned\nfrom actual users' data, which should facilitate research collaborations.", "published": "2017-07-24 15:23:41", "link": "http://arxiv.org/abs/1707.07605v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Extracting Core Claims from Scientific Articles", "abstract": "The number of scientific articles has grown rapidly over the years and there\nare no signs that this growth will slow down in the near future. Because of\nthis, it becomes increasingly difficult to keep up with the latest developments\nin a scientific field. To address this problem, we present here an approach to\nhelp researchers learn about the latest developments and findings by extracting\nin a normalized form core claims from scientific articles. This normalized\nrepresentation is a controlled natural language of English sentences called\nAIDA, which has been proposed in previous work as a method to formally\nstructure and organize scientific findings and discourse. We show how such AIDA\nsentences can be automatically extracted by detecting the core claim of an\narticle, checking for AIDA compliance, and - if necessary - transforming it\ninto a compliant sentence. While our algorithm is still far from perfect, our\nresults indicate that the different steps are feasible and they support the\nclaim that AIDA sentences might be a promising approach to improve scientific\ncommunication in the future.", "published": "2017-07-24 15:10:40", "link": "http://arxiv.org/abs/1707.07678v1", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Full-Network Embedding in a Multimodal Embedding Pipeline", "abstract": "The current state-of-the-art for image annotation and image retrieval tasks\nis obtained through deep neural networks, which combine an image representation\nand a text representation into a shared embedding space. In this paper we\nevaluate the impact of using the Full-Network embedding in this setting,\nreplacing the original image representation in a competitive multimodal\nembedding generation scheme. Unlike the one-layer image embeddings typically\nused by most approaches, the Full-Network embedding provides a multi-scale\nrepresentation of images, which results in richer characterizations. To measure\nthe influence of the Full-Network embedding, we evaluate its performance on\nthree different datasets, and compare the results with the original multimodal\nembedding generation scheme when using a one-layer image embedding, and with\nthe rest of the state-of-the-art. Results for image annotation and image\nretrieval tasks indicate that the Full-Network embedding is consistently\nsuperior to the one-layer embedding. These results motivate the integration of\nthe Full-Network embedding on any multimodal embedding generation scheme,\nsomething feasible thanks to the flexibility of the approach.", "published": "2017-07-24 10:27:33", "link": "http://arxiv.org/abs/1707.09872v2", "categories": ["cs.CV", "cs.CL", "cs.NE"], "primary_category": "cs.CV"}
