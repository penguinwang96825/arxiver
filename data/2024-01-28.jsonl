{"title": "Quantifying Stereotypes in Language", "abstract": "A stereotype is a generalized perception of a specific group of humans. It is\noften potentially encoded in human language, which is more common in texts on\nsocial issues. Previous works simply define a sentence as stereotypical and\nanti-stereotypical. However, the stereotype of a sentence may require\nfine-grained quantification. In this paper, to fill this gap, we quantify\nstereotypes in language by annotating a dataset. We use the pre-trained\nlanguage models (PLMs) to learn this dataset to predict stereotypes of\nsentences. Then, we discuss stereotypes about common social issues such as hate\nspeech, sexism, sentiments, and disadvantaged and advantaged groups. We\ndemonstrate the connections and differences between stereotypes and common\nsocial issues, and all four studies validate the general findings of the\ncurrent studies. In addition, our work suggests that fine-grained stereotype\nscores are a highly relevant and competitive dimension for research on social\nissues.", "published": "2024-01-28 01:07:21", "link": "http://arxiv.org/abs/2401.15535v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augment before You Try: Knowledge-Enhanced Table Question Answering via\n  Table Expansion", "abstract": "Table question answering is a popular task that assesses a model's ability to\nunderstand and interact with structured data. However, the given table often\ndoes not contain sufficient information for answering the question,\nnecessitating the integration of external knowledge. Existing methods either\nconvert both the table and external knowledge into text, which neglects the\nstructured nature of the table; or they embed queries for external sources in\nthe interaction with the table, which complicates the process. In this paper,\nwe propose a simple yet effective method to integrate external information in a\ngiven table. Our method first constructs an augmenting table containing the\nmissing information and then generates a SQL query over the two tables to\nanswer the question. Experiments show that our method outperforms strong\nbaselines on three table QA benchmarks. Our code is publicly available at\nhttps://github.com/UCSB-NLP-Chang/Augment_tableQA.", "published": "2024-01-28 03:37:11", "link": "http://arxiv.org/abs/2401.15555v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Tuning and Inference for Large Language Models on Textual\n  Graphs", "abstract": "Rich textual and topological information of textual graphs need to be modeled\nin real-world applications such as webpages, e-commerce, and academic articles.\nPractitioners have been long following the path of adopting a shallow text\nencoder and a subsequent graph neural network (GNN) to solve this problem. In\nlight of recent advancements in large language models (LLMs), it is apparent\nthat integrating LLMs for enhanced textual encoding can substantially improve\nthe performance of textual graphs. Nevertheless, the efficiency of these\nmethods poses a significant challenge. In this paper, we propose ENGINE, a\nparameter- and memory-efficient fine-tuning method for textual graphs with an\nLLM encoder. The key insight is to combine the LLMs and GNNs through a tunable\nside structure, which significantly reduces the training complexity without\nimpairing the joint model's capacity. Extensive experiments on textual graphs\ndemonstrate our method's effectiveness by achieving the best model performance,\nmeanwhile having the lowest training cost compared to previous methods.\nMoreover, we introduce two variants with caching and dynamic early exit to\nfurther enhance training and inference speed. Specifically, caching accelerates\nENGINE's training by 12x, and dynamic early exit achieves up to 5x faster\ninference with a negligible performance drop (at maximum 1.17% relevant drop\nacross 7 datasets). Our codes are available at:\nhttps://github.com/ZhuYun97/ENGINE", "published": "2024-01-28 05:12:09", "link": "http://arxiv.org/abs/2401.15569v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Gender Bias in Large Language Models via Chain-of-Thought\n  Prompting", "abstract": "There exist both scalable tasks, like reading comprehension and\nfact-checking, where model performance improves with model size, and unscalable\ntasks, like arithmetic reasoning and symbolic reasoning, where model\nperformance does not necessarily improve with model size. Large language models\n(LLMs) equipped with Chain-of-Thought (CoT) prompting are able to make accurate\nincremental predictions even on unscalable tasks. Unfortunately, despite their\nexceptional reasoning abilities, LLMs tend to internalize and reproduce\ndiscriminatory societal biases. Whether CoT can provide discriminatory or\negalitarian rationalizations for the implicit information in unscalable tasks\nremains an open question.\n  In this study, we examine the impact of LLMs' step-by-step predictions on\ngender bias in unscalable tasks. For this purpose, we construct a benchmark for\nan unscalable task where the LLM is given a list of words comprising feminine,\nmasculine, and gendered occupational words, and is required to count the number\nof feminine and masculine words. In our CoT prompts, we require the LLM to\nexplicitly indicate whether each word in the word list is a feminine or\nmasculine before making the final predictions. With counting and handling the\nmeaning of words, this benchmark has characteristics of both arithmetic\nreasoning and symbolic reasoning. Experimental results in English show that\nwithout step-by-step prediction, most LLMs make socially biased predictions,\ndespite the task being as simple as counting words. Interestingly, CoT\nprompting reduces this unconscious social bias in LLMs and encourages fair\npredictions.", "published": "2024-01-28 06:50:10", "link": "http://arxiv.org/abs/2401.15585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamically Allocated Interval-Based Generative Linguistic Steganography\n  with Roulette Wheel", "abstract": "Existing linguistic steganography schemes often overlook the conditional\nprobability (CP) of tokens in the candidate pool, allocating the one coding to\nall tokens, which results in identical selection likelihoods. This approach\nleads to the selection of low-CP tokens, degrading the quality of stegos and\nmaking them more detectable. This paper proposes a scheme based on the interval\nallocated, called DAIRstega. DAIRstega first uses a portion of the read secret\nto build the roulette area. Then, this scheme uses the idea of the roulette\nwheel and takes the CPs of tokens as the main basis for allocating the roulette\narea (i.e., the interval length). Thus, tokens with larger CPs are allocated\nmore area. The secret will have an increased likelihood of selecting a token\nwith a higher CP. During allocation, we designed some allocation functions and\nthree constraints to optimize the process. Additionally, DAIRstega supports\nprompt-based controllable generation of stegos. Rich experiments show that the\nproposed embedding way and DAIRstega perform better than the existing ways and\nbaselines, which shows strong perceptual, statistical, and semantic\nconcealment, as well as anti-steganalysis ability. It can also generate\nhigh-quality longer stegos, addressing the deficiencies in this task. DAIRstega\nis confirmed to have potential as a secure watermarking, offering insights for\nits development.", "published": "2024-01-28 13:21:44", "link": "http://arxiv.org/abs/2401.15656v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection", "abstract": "Many European citizens become targets of the Kremlin propaganda campaigns,\naiming to minimise public support for Ukraine, foster a climate of mistrust and\ndisunity, and shape elections (Meister, 2022). To address this challenge, we\ndeveloped ''Check News in 1 Click'', the first NLP-empowered pro-Kremlin\npropaganda detection application available in 7 languages, which provides the\nlay user with feedback on their news, and explains manipulative linguistic\nfeatures and keywords. We conducted a user study, analysed user entries and\nmodels' behaviour paired with questionnaire answers, and investigated the\nadvantages and disadvantages of the proposed interpretative solution.", "published": "2024-01-28 17:51:47", "link": "http://arxiv.org/abs/2401.15717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RE-GAINS & EnChAnT: Intelligent Tool Manipulation Systems For Enhanced\n  Query Responses", "abstract": "Large Language Models (LLMs) currently struggle with tool invocation and\nchaining, as they often hallucinate or miss essential steps in a sequence. We\npropose RE-GAINS and EnChAnT, two novel frameworks that empower LLMs to tackle\ncomplex user queries by making API calls to external tools based on tool\ndescriptions and argument lists. Tools are chained based on the expected\noutput, without receiving the actual results from each individual call.\nEnChAnT, an open-source solution, leverages an LLM format enforcer, OpenChat\n3.5 (an LLM), and ToolBench's API Retriever. RE-GAINS utilizes OpenAI models\nand embeddings with a specialized prompt based on the $\\underline{R}$easoning\nvi$\\underline{a}$ $\\underline{P}$lanning $(RAP)$ framework. Both frameworks are\nlow cost (0.01\\$ per query). Our key contribution is enabling LLMs for tool\ninvocation and chaining using modifiable, externally described tools.", "published": "2024-01-28 18:26:31", "link": "http://arxiv.org/abs/2401.15724v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PILOT: Legal Case Outcome Prediction with Case Law", "abstract": "Machine learning shows promise in predicting the outcome of legal cases, but\nmost research has concentrated on civil law cases rather than case law systems.\nWe identified two unique challenges in making legal case outcome predictions\nwith case law. First, it is crucial to identify relevant precedent cases that\nserve as fundamental evidence for judges during decision-making. Second, it is\nnecessary to consider the evolution of legal principles over time, as early\ncases may adhere to different legal contexts. In this paper, we proposed a new\nframework named PILOT (PredictIng Legal case OuTcome) for case outcome\nprediction. It comprises two modules for relevant case retrieval and temporal\npattern handling, respectively. To benchmark the performance of existing legal\ncase outcome prediction models, we curated a dataset from a large-scale case\nlaw database. We demonstrate the importance of accurately identifying precedent\ncases and mitigating the temporal shift when making predictions for case law,\nas our method shows a significant improvement over the prior methods that focus\non civil law case outcome predictions.", "published": "2024-01-28 21:18:05", "link": "http://arxiv.org/abs/2401.15770v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "cantnlp@LT-EDI-2024: Automatic Detection of Anti-LGBTQ+ Hate Speech in\n  Under-resourced Languages", "abstract": "This paper describes our homophobia/transphobia in social media comments\ndetection system developed as part of the shared task at LT-EDI-2024. We took a\ntransformer-based approach to develop our multiclass classification model for\nten language conditions (English, Spanish, Gujarati, Hindi, Kannada, Malayalam,\nMarathi, Tamil, Tulu, and Telugu). We introduced synthetic and organic\ninstances of script-switched language data during domain adaptation to mirror\nthe linguistic realities of social media language as seen in the labelled\ntraining data. Our system ranked second for Gujarati and Telugu with varying\nlevels of performance for other language conditions. The results suggest\nincorporating elements of paralinguistic behaviour such as script-switching may\nimprove the performance of language detection systems especially in the cases\nof under-resourced languages conditions.", "published": "2024-01-28 21:58:04", "link": "http://arxiv.org/abs/2401.15777v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UnMASKed: Quantifying Gender Biases in Masked Language Models through\n  Linguistically Informed Job Market Prompts", "abstract": "Language models (LMs) have become pivotal in the realm of technological\nadvancements. While their capabilities are vast and transformative, they often\ninclude societal biases encoded in the human-produced datasets used for their\ntraining. This research delves into the inherent biases present in masked\nlanguage models (MLMs), with a specific focus on gender biases. This study\nevaluated six prominent models: BERT, RoBERTa, DistilBERT, BERT-multilingual,\nXLM-RoBERTa, and DistilBERT-multilingual. The methodology employed a novel\ndataset, bifurcated into two subsets: one containing prompts that encouraged\nmodels to generate subject pronouns in English, and the other requiring models\nto return the probabilities of verbs, adverbs, and adjectives linked to the\nprompts' gender pronouns. The analysis reveals stereotypical gender alignment\nof all models, with multilingual variants showing comparatively reduced biases.", "published": "2024-01-28 23:00:40", "link": "http://arxiv.org/abs/2401.15798v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks\n  and Action-Tree Based Scheduled Sampling", "abstract": "Task-oriented dialog systems have witnessed substantial progress due to\nconversational pre-training techniques. Yet, two significant challenges\npersist. First, most systems primarily utilize the latest turn's state label\nfor the generator. This practice overlooks the comprehensive value of state\nlabels in boosting the model's understanding for future generations. Second, an\noverreliance on generated policy often leads to error accumulation, resulting\nin suboptimal responses when adhering to incorrect actions. To combat these\nchallenges, we propose turn-level multi-task objectives for the encoder. With\nthe guidance of essential information from labeled intermediate states, we\nestablish a more robust representation for both understanding and generation.\nFor the decoder, we introduce an action tree-based scheduled sampling\ntechnique. Specifically, we model the hierarchical policy as trees and utilize\nthe similarity between trees to sample negative policy based on scheduled\nsampling, hoping the model to generate invariant responses under perturbations.\nThis method simulates potential pitfalls by sampling similar negative policy,\nbridging the gap between task-oriented dialog training and inference. Among\nmethods without continual pre-training, our approach achieved state-of-the-art\n(SOTA) performance on the MultiWOZ dataset series and was also competitive with\npre-trained SOTA methods.", "published": "2024-01-28 11:02:23", "link": "http://arxiv.org/abs/2401.15626v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RecDCL: Dual Contrastive Learning for Recommendation", "abstract": "Self-supervised learning (SSL) has recently achieved great success in mining\nthe user-item interactions for collaborative filtering. As a major paradigm,\ncontrastive learning (CL) based SSL helps address data sparsity in Web\nplatforms by contrasting the embeddings between raw and augmented data.\nHowever, existing CL-based methods mostly focus on contrasting in a batch-wise\nway, failing to exploit potential regularity in the feature dimension. This\nleads to redundant solutions during the representation learning of users and\nitems. In this work, we investigate how to employ both batch-wise CL (BCL) and\nfeature-wise CL (FCL) for recommendation. We theoretically analyze the relation\nbetween BCL and FCL, and find that combining BCL and FCL helps eliminate\nredundant solutions but never misses an optimal solution. We propose a dual\ncontrastive learning recommendation framework -- RecDCL. In RecDCL, the FCL\nobjective is designed to eliminate redundant solutions on user-item positive\npairs and to optimize the uniform distributions within users and items using a\npolynomial kernel for driving the representations to be orthogonal; The BCL\nobjective is utilized to generate contrastive embeddings on output vectors for\nenhancing the robustness of the representations. Extensive experiments on four\nwidely-used benchmarks and one industry dataset demonstrate that RecDCL can\nconsistently outperform the state-of-the-art GNNs-based and SSL-based models\n(with an improvement of up to 5.65\\% in terms of Recall@20). The source code is\npublicly available (https://github.com/THUDM/RecDCL).", "published": "2024-01-28 11:51:09", "link": "http://arxiv.org/abs/2401.15635v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "PRE: A Peer Review Based Large Language Model Evaluator", "abstract": "The impressive performance of large language models (LLMs) has attracted\nconsiderable attention from the academic and industrial communities. Besides\nhow to construct and train LLMs, how to effectively evaluate and compare the\ncapacity of LLMs has also been well recognized as an important yet difficult\nproblem. Existing paradigms rely on either human annotators or model-based\nevaluators to evaluate the performance of LLMs on different tasks. However,\nthese paradigms often suffer from high cost, low generalizability, and\ninherited biases in practice, which make them incapable of supporting the\nsustainable development of LLMs in long term. In order to address these issues,\ninspired by the peer review systems widely used in academic publication\nprocess, we propose a novel framework that can automatically evaluate LLMs\nthrough a peer-review process. Specifically, for the evaluation of a specific\ntask, we first construct a small qualification exam to select \"reviewers\" from\na couple of powerful LLMs. Then, to actually evaluate the \"submissions\" written\nby different candidate LLMs, i.e., the evaluatees, we use the reviewer LLMs to\nrate or compare the submissions. The final ranking of evaluatee LLMs is\ngenerated based on the results provided by all reviewers. We conducted\nextensive experiments on text summarization tasks with eleven LLMs including\nGPT-4. The results demonstrate the existence of biasness when evaluating using\na single LLM. Also, our PRE model outperforms all the baselines, illustrating\nthe effectiveness of the peer review mechanism.", "published": "2024-01-28 12:33:14", "link": "http://arxiv.org/abs/2401.15641v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Fine-Tuned Large Language Models for Symptom Recognition from Spanish\n  Clinical Text", "abstract": "The accurate recognition of symptoms in clinical reports is significantly\nimportant in the fields of healthcare and biomedical natural language\nprocessing. These entities serve as essential building blocks for clinical\ninformation extraction, enabling retrieval of critical medical insights from\nvast amounts of textual data. Furthermore, the ability to identify and\ncategorize these entities is fundamental for developing advanced clinical\ndecision support systems, aiding healthcare professionals in diagnosis and\ntreatment planning. In this study, we participated in SympTEMIST, a shared task\non the detection of symptoms, signs and findings in Spanish medical documents.\nWe combine a set of large language models fine-tuned with the data released by\nthe organizers.", "published": "2024-01-28 22:11:25", "link": "http://arxiv.org/abs/2401.15780v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contextualization Distillation from Large Language Model for Knowledge\n  Graph Completion", "abstract": "While textual information significantly enhances the performance of\npre-trained language models (PLMs) in knowledge graph completion (KGC), the\nstatic and noisy nature of existing corpora collected from Wikipedia articles\nor synsets definitions often limits the potential of PLM-based KGC models. To\nsurmount these challenges, we introduce the Contextualization Distillation\nstrategy, a versatile plug-in-and-play approach compatible with both\ndiscriminative and generative KGC frameworks. Our method begins by instructing\nlarge language models (LLMs) to transform compact, structural triplets into\ncontext-rich segments. Subsequently, we introduce two tailored auxiliary tasks,\nreconstruction and contextualization, allowing smaller KGC models to assimilate\ninsights from these enriched triplets. Comprehensive evaluations across diverse\ndatasets and KGC techniques highlight the efficacy and adaptability of our\napproach, revealing consistent performance enhancements irrespective of\nunderlying pipelines or architectures. Moreover, our analysis makes our method\nmore explainable and provides insight into generating path selection, as well\nas the choosing of suitable distillation tasks. All the code and data in this\nwork will be released at\nhttps://github.com/David-Li0406/Contextulization-Distillation", "published": "2024-01-28 08:56:49", "link": "http://arxiv.org/abs/2402.01729v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "C Analyzer : A Static Program Analysis Tool for C Programs", "abstract": "In our times, when the world is increasingly becoming more dependent on\nsoftware programs, writing bug-free, correct programs is crucial. Program\nverification based on formal methods can guarantee this by detecting run-time\nerrors in safety-critical systems to avoid possible adverse impacts on human\nlife and save time and money.\n  This project work tries to leverage Abstract Interpretation techniques for\nstatic analysis of C programs. C Analyzer is a tool developed for static\nanalysis of C programs. This implementation of C Analyzer provides a\nplug-and-play domain architecture for multiple abstract domains to be used. C\nAnalyzer supports four abstract domains - Interval, Octagon, Polyhedra, and Bit\nVector. We use these different domains for required precision in program\nverification. C Analyzer tool uses LLVM C/C++ compiler frontend Clang API to\ngenerate and traverse the Control Flow Graph (CFG) of a given C program. This\ntool generates invariants in different abstract domains for statements in basic\nblocks of CFG during CFG traversal. Using these invariants, some properties of\na program, such as dividing by zero, modulus zero, arithmetic overflow, etc.,\ncan be analyzed. We also use a source-to-source transformation tool, CIL\n(Common Intermediate language), to transform some C constructs into simpler\nconstructs, such as transforming logical operators, switch statements, and\nconditional operators into if-else ladders and transforming do-while and for\nloops into while loops.\n  Using C Analyzer, C program constructs such as declarations, assignments,\nbinary operations (arithmetic, relational, bitwise shift, etc.), conditions\n(if-else), loops (while, do while, for loop), nested conditions, and nested\nloops can be analyzed. Currently, this tool does not support arrays,\nstructures, unions, pointers, or function calls.", "published": "2024-01-28 11:43:16", "link": "http://arxiv.org/abs/2403.12973v1", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Byte Pair Encoding Is All You Need For Automatic Bengali Speech\n  Recognition", "abstract": "Byte pair encoding (BPE) emerges as an effective tokenization method for\ntackling the out-of-vocabulary (OOV) challenge in various natural language and\nspeech processing tasks. Recent research highlights the dependency of BPE\nsubword tokenization's efficacy on the morphological nature of the language,\nparticularly in languages rich in inflectional morphology, where fewer BPE\nmerges suffice for generating highly productive tokens. Motivated by this, our\nstudy empirically identifies the optimal number of BPE tokens for Bengali, a\nlanguage known for its morphological complexity, thus enhancing\nout-of-distribution automatic speech recognition (ASR) performance.\nExperimental evaluation reveals that an excessively high number of BPE tokens\ncan lead to overfitting, while approximately 500-1000 tokens result in superior\nOOV performance. Furthermore, we conduct a comparative analysis of BPE with\ncharacter-based and unigram-based tokenization methods. By introducing BPE\ntokenization to Bengali ASR, we achieve a substantial reduction in the word\nerror rate (WER) from 66.44% in our character-based baseline system to 63.80%\non the LB-ASRTD eval set and from 46.34% to 42.80% on the SHRUTI eval set, both\nof which include out-of-distribution data.", "published": "2024-01-28 00:41:21", "link": "http://arxiv.org/abs/2401.15532v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PPM: Automated Generation of Diverse Programming Problems for\n  Benchmarking Code Generation Models", "abstract": "In recent times, a plethora of Large Code Generation Models (LCGMs) have been\nproposed, showcasing significant potential in assisting developers with complex\nprogramming tasks. Benchmarking LCGMs necessitates the creation of a set of\ndiverse programming problems, and each problem comprises the prompt (including\nthe task description), canonical solution, and test inputs. The existing\nmethods for constructing such a problem set can be categorized into two main\ntypes: manual methods and perturbation-based methods. However, manual methods\ndemand high effort and lack scalability, while also risking data integrity due\nto LCGMs' potentially contaminated data collection, and perturbation-based\napproaches mainly generate semantically homogeneous problems with the same\ncanonical solutions and introduce typos that can be easily auto-corrected by\nIDE, making them ineffective and unrealistic. In this work, we propose the idea\nof programming problem merging (PPM) and provide two implementation of this\nidea, we utilize our tool on two widely-used datasets and compare it against\nnine baseline methods using eight code generation models. The results\ndemonstrate the effectiveness of our tool in generating more challenging,\ndiverse, and natural programming problems, comparing to the baselines.", "published": "2024-01-28 02:27:38", "link": "http://arxiv.org/abs/2401.15545v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.PL"], "primary_category": "cs.SE"}
{"title": "An Analysis of Letter Dynamics in the English Alphabet", "abstract": "The frequency with which the letters of the English alphabet appear in\nwritings has been applied to the field of cryptography, the development of\nkeyboard mechanics, and the study of linguistics. We expanded on the\nstatistical analysis of the English alphabet by examining the average frequency\nwhich each letter appears in different categories of writings. We evaluated\nnews articles, novels, plays, scientific publications and calculated the\nfrequency of each letter of the alphabet, the information density of each\nletter, and the overall letter distribution. Furthermore, we developed a metric\nknown as distance, d that can be used to algorithmically recognize different\ncategories of writings. The results of our study can be applied to information\ntransmission, large data curation, and linguistics.", "published": "2024-01-28 03:54:41", "link": "http://arxiv.org/abs/2401.15560v1", "categories": ["cs.IT", "cs.CL", "math.IT", "94A15"], "primary_category": "cs.IT"}
{"title": "MunTTS: A Text-to-Speech System for Mundari", "abstract": "We present MunTTS, an end-to-end text-to-speech (TTS) system specifically for\nMundari, a low-resource Indian language of the Austo-Asiatic family. Our work\naddresses the gap in linguistic technology for underrepresented languages by\ncollecting and processing data to build a speech synthesis system. We begin our\nstudy by gathering a substantial dataset of Mundari text and speech and train\nend-to-end speech models. We also delve into the methods used for training our\nmodels, ensuring they are efficient and effective despite the data constraints.\nWe evaluate our system with native speakers and objective metrics,\ndemonstrating its potential as a tool for preserving and promoting the Mundari\nlanguage in the digital age.", "published": "2024-01-28 06:27:17", "link": "http://arxiv.org/abs/2401.15579v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "YODA: Teacher-Student Progressive Learning for Language Models", "abstract": "Although large language models (LLMs) have demonstrated adeptness in a range\nof tasks, they still lag behind human learning efficiency. This disparity is\noften linked to the inherent human capacity to learn from basic examples,\ngradually generalize and handle more complex problems, and refine their skills\nwith continuous feedback. Inspired by this, this paper introduces YODA, a novel\nteacher-student progressive learning framework that emulates the\nteacher-student education process to improve the efficacy of model fine-tuning.\nThe framework operates on an interactive \\textit{basic-generalized-harder}\nloop. The teacher agent provides tailored feedback on the student's answers,\nand systematically organizes the education process. This process unfolds by\nteaching the student basic examples, reinforcing understanding through\ngeneralized questions, and then enhancing learning by posing questions with\nprogressively enhanced complexity. With the teacher's guidance, the student\nlearns to iteratively refine its answer with feedback, and forms a robust and\ncomprehensive understanding of the posed questions. The systematic procedural\ndata, which reflects the progressive learning process of humans, is then\nutilized for model training. Taking math reasoning as a testbed, experiments\nshow that training LLaMA2 with data from YODA improves SFT with significant\nperformance gain (+17.01\\% on GSM8K and +9.98\\% on MATH). In addition, we find\nthat training with curriculum learning further improves learning robustness.", "published": "2024-01-28 14:32:15", "link": "http://arxiv.org/abs/2401.15670v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning and Mixture of Experts Enables Precise Vector\n  Embeddings", "abstract": "The advancement of transformer neural networks has significantly elevated the\ncapabilities of sentence similarity models, but they still struggle with highly\ndiscriminative tasks and may produce sub-optimal representations of important\ndocuments like scientific literature. With the increased reliance on retrieval\naugmentation and search, representing diverse documents as concise and\ndescriptive vectors is crucial. This paper improves upon the vectors embeddings\nof scientific text by assembling niche datasets using co-citations as a\nsimilarity metric, focusing on biomedical domains. We apply a novel Mixture of\nExperts (MoE) extension pipeline to pretrained BERT models, where every\nmulti-layer perceptron section is enlarged and copied into multiple distinct\nexperts. Our MoE variants perform well over $N$ scientific domains with $N$\ndedicated experts, whereas standard BERT models excel in only one domain at a\ntime. Notably, extending just a single transformer block to MoE captures 85% of\nthe benefit seen from full MoE extension at every layer. This holds promise for\nversatile and efficient One-Size-Fits-All transformer networks for numerically\nrepresenting diverse inputs. Our methodology marks advancements in\nrepresentation learning and holds promise for enhancing vector database search\nand compilation.", "published": "2024-01-28 17:34:42", "link": "http://arxiv.org/abs/2401.15713v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and\n  Symptom Analysis", "abstract": "Large language models (LLMs) constitute a breakthrough state-of-the-art\nArtificial Intelligence technology which is rapidly evolving and promises to\naid in medical diagnosis. However, the correctness and the accuracy of their\nreturns has not yet been properly evaluated. In this work, we propose an LLM\nevaluation paradigm that incorporates two independent steps of a novel\nmethodology, namely (1) multimodal LLM evaluation via structured interactions\nand (2) follow-up, domain-specific analysis based on data extracted via the\nprevious interactions. Using this paradigm, (1) we evaluate the correctness and\naccuracy of LLM-generated medical diagnosis with publicly available multimodal\nmultiple-choice questions(MCQs) in the domain of Pathology and (2) proceed to a\nsystemic and comprehensive analysis of extracted results. We used\nGPT-4-Vision-Preview as the LLM to respond to complex, medical questions\nconsisting of both images and text, and we explored a wide range of diseases,\nconditions, chemical compounds, and related entity types that are included in\nthe vast knowledge domain of Pathology. GPT-4-Vision-Preview performed quite\nwell, scoring approximately 84\\% of correct diagnoses. Next, we further\nanalyzed the findings of our work, following an analytical approach which\nincluded Image Metadata Analysis, Named Entity Recognition and Knowledge\nGraphs. Weaknesses of GPT-4-Vision-Preview were revealed on specific knowledge\npaths, leading to a further understanding of its shortcomings in specific\nareas. Our methodology and findings are not limited to the use of\nGPT-4-Vision-Preview, but a similar approach can be followed to evaluate the\nusefulness and accuracy of other LLMs and, thus, improve their use with further\noptimization.", "published": "2024-01-28 09:25:12", "link": "http://arxiv.org/abs/2402.01730v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "On Speaker Attribution with SURT", "abstract": "The Streaming Unmixing and Recognition Transducer (SURT) has recently become\na popular framework for continuous, streaming, multi-talker speech recognition\n(ASR). With advances in architecture, objectives, and mixture simulation\nmethods, it was demonstrated that SURT can be an efficient streaming method for\nspeaker-agnostic transcription of real meetings. In this work, we push this\nframework further by proposing methods to perform speaker-attributed\ntranscription with SURT, for both short mixtures and long recordings. We\nachieve this by adding an auxiliary speaker branch to SURT, and synchronizing\nits label prediction with ASR token prediction through HAT-style blank\nfactorization. In order to ensure consistency in relative speaker labels across\ndifferent utterance groups in a recording, we propose \"speaker prefixing\" --\nappending each chunk with high-confidence frames of speakers identified in\nprevious chunks, to establish the relative order. We perform extensive ablation\nexperiments on synthetic LibriSpeech mixtures to validate our design choices,\nand demonstrate the efficacy of our final model on the AMI corpus.", "published": "2024-01-28 14:56:34", "link": "http://arxiv.org/abs/2401.15676v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Evaluating Echo State Network for Parkinson's Disease Prediction using\n  Voice Features", "abstract": "Parkinson's disease (PD) is a debilitating neurological disorder that\nnecessitates precise and early diagnosis for effective patient care. This study\naims to develop a diagnostic model capable of achieving both high accuracy and\nminimizing false negatives, a critical factor in clinical practice. Given the\nlimited training data, a feature selection strategy utilizing ANOVA is employed\nto identify the most informative features. Subsequently, various machine\nlearning methods, including Echo State Networks (ESN), Random Forest, k-nearest\nNeighbors, Support Vector Classifier, Extreme Gradient Boosting, and Decision\nTree, are employed and thoroughly evaluated. The statistical analyses of the\nresults highlight ESN's exceptional performance, showcasing not only superior\naccuracy but also the lowest false negative rate among all methods.\nConsistently, statistical data indicates that the ESN method consistently\nmaintains a false negative rate of less than 8% in 83% of cases. ESN's capacity\nto strike a delicate balance between diagnostic precision and minimizing\nmisclassifications positions it as an exemplary choice for PD diagnosis,\nespecially in scenarios characterized by limited data. This research marks a\nsignificant step towards more efficient and reliable PD diagnosis, with\npotential implications for enhanced patient outcomes and healthcare dynamics.", "published": "2024-01-28 14:39:43", "link": "http://arxiv.org/abs/2401.15672v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Phoneme-Based Proactive Anti-Eavesdropping with Controlled Recording\n  Privilege", "abstract": "The widespread smart devices raise people's concerns of being eavesdropped\non. To enhance voice privacy, recent studies exploit the nonlinearity in\nmicrophone to jam audio recorders with inaudible ultrasound. However, existing\nsolutions solely rely on energetic masking. Their simple-form noise leads to\nseveral problems, such as high energy requirements and being easily removed by\nspeech enhancement techniques. Besides, most of these solutions do not support\nauthorized recording, which restricts their usage scenarios. In this paper, we\ndesign an efficient yet robust system that can jam microphones while preserving\nauthorized recording. Specifically, we propose a novel phoneme-based noise with\nthe idea of informational masking, which can distract both machines and humans\nand is resistant to denoising techniques. Besides, we optimize the noise\ntransmission strategy for broader coverage and implement a hardware prototype\nof our system. Experimental results show that our system can reduce the\nrecognition accuracy of recordings to below 50\\% under all tested speech\nrecognition systems, which is much better than existing solutions.", "published": "2024-01-28 16:56:56", "link": "http://arxiv.org/abs/2401.15704v1", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
