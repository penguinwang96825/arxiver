{"title": "Exploring the Sensitivity of LLMs' Decision-Making Capabilities:\n  Insights from Prompt Variation and Hyperparameters", "abstract": "The advancement of Large Language Models (LLMs) has led to their widespread\nuse across a broad spectrum of tasks including decision making. Prior studies\nhave compared the decision making abilities of LLMs with those of humans from a\npsychological perspective. However, these studies have not always properly\naccounted for the sensitivity of LLMs' behavior to hyperparameters and\nvariations in the prompt. In this study, we examine LLMs' performance on the\nHorizon decision making task studied by Binz and Schulz (2023) analyzing how\nLLMs respond to variations in prompts and hyperparameters. By experimenting on\nthree OpenAI language models possessing different capabilities, we observe that\nthe decision making abilities fluctuate based on the input prompts and\ntemperature settings. Contrary to previous findings language models display a\nhuman-like exploration exploitation tradeoff after simple adjustments to the\nprompt.", "published": "2023-12-29 05:19:11", "link": "http://arxiv.org/abs/2312.17476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in\n  the Avalon Game", "abstract": "Multi-agent collaboration with Large Language Models (LLMs) demonstrates\nproficiency in basic tasks, yet its efficiency in more complex scenarios\nremains unexplored. In gaming environments, these agents often face situations\nwithout established coordination protocols, requiring them to make intelligent\ninferences about teammates from limited data. This problem motivates the area\nof ad hoc teamwork, in which an agent may potentially cooperate with a variety\nof teammates to achieve a shared goal. Our study focuses on the ad hoc teamwork\nproblem where the agent operates in an environment driven by natural language.\nOur findings reveal the potential of LLM agents in team collaboration,\nhighlighting issues related to hallucinations in communication. To address this\nissue, we develop CodeAct, a general agent that equips LLM with enhanced memory\nand code-driven reasoning, enabling the repurposing of partial information for\nrapid adaptation to new teammates.", "published": "2023-12-29 08:26:54", "link": "http://arxiv.org/abs/2312.17515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of the PromptCBLUE Shared Task in CHIP2023", "abstract": "This paper presents an overview of the PromptCBLUE shared task\n(http://cips-chip.org.cn/2023/eval1) held in the CHIP-2023 Conference. This\nshared task reformualtes the CBLUE benchmark, and provide a good testbed for\nChinese open-domain or medical-domain large language models (LLMs) in general\nmedical natural language processing. Two different tracks are held: (a) prompt\ntuning track, investigating the multitask prompt tuning of LLMs, (b) probing\nthe in-context learning capabilities of open-sourced LLMs. Many teams from both\nthe industry and academia participated in the shared tasks, and the top teams\nachieved amazing test results. This paper describes the tasks, the datasets,\nevaluation metrics, and the top systems for both tasks. Finally, the paper\nsummarizes the techniques and results of the evaluation of the various\napproaches explored by the participating teams.", "published": "2023-12-29 09:05:00", "link": "http://arxiv.org/abs/2312.17522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Faithful Explanations for Text Classification with Robustness\n  Improvement and Explanation Guided Training", "abstract": "Feature attribution methods highlight the important input tokens as\nexplanations to model predictions, which have been widely applied to deep\nneural networks towards trustworthy AI. However, recent works show that\nexplanations provided by these methods face challenges of being faithful and\nrobust. In this paper, we propose a method with Robustness improvement and\nExplanation Guided training towards more faithful EXplanations (REGEX) for text\nclassification. First, we improve model robustness by input gradient\nregularization technique and virtual adversarial training. Secondly, we use\nsalient ranking to mask noisy tokens and maximize the similarity between model\nattention and feature attribution, which can be seen as a self-training\nprocedure without importing other external information. We conduct extensive\nexperiments on six datasets with five attribution methods, and also evaluate\nthe faithfulness in the out-of-domain setting. The results show that REGEX\nimproves fidelity metrics of explanations in all settings and further achieves\nconsistent gains based on two randomization tests. Moreover, we show that using\nhighlight explanations produced by REGEX to train select-then-predict models\nresults in comparable task performance to the end-to-end method.", "published": "2023-12-29 13:07:07", "link": "http://arxiv.org/abs/2312.17591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Generative Information Extraction: A Survey", "abstract": "Information extraction (IE) aims to extract structural knowledge from plain\nnatural language texts. Recently, generative Large Language Models (LLMs) have\ndemonstrated remarkable capabilities in text understanding and generation. As a\nresult, numerous works have been proposed to integrate LLMs for IE tasks based\non a generative paradigm. To conduct a comprehensive systematic review and\nexploration of LLM efforts for IE tasks, in this study, we survey the most\nrecent advancements in this field. We first present an extensive overview by\ncategorizing these works in terms of various IE subtasks and techniques, and\nthen we empirically analyze the most advanced methods and discover the emerging\ntrend of IE tasks with LLMs. Based on a thorough review conducted, we identify\nseveral insights in technique and promising research directions that deserve\nfurther exploration in future studies. We maintain a public repository and\nconsistently update related works and resources on GitHub\n(\\href{https://github.com/quqxui/Awesome-LLM4IE-Papers}{LLM4IE repository})", "published": "2023-12-29 14:25:22", "link": "http://arxiv.org/abs/2312.17617v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Normalization of Lithuanian Text Using Regular Expressions", "abstract": "Text Normalization is an integral part of any text-to-speech synthesis\nsystem. In a natural language text, there are elements such as numbers, dates,\nabbreviations, etc. that belong to other semiotic classes. They are called\nnon-standard words (NSW) and need to be expanded into ordinary words. For this\npurpose, it is necessary to identify the semiotic class of each NSW. The\ntaxonomy of semiotic classes adapted to the Lithuanian language is presented in\nthe work. Sets of rules are created for detecting and expanding NSWs based on\nregular expressions. Experiments with three completely different data sets were\nperformed and the accuracy was assessed. Causes of errors are explained and\nrecommendations are given for the development of text normalization rules.", "published": "2023-12-29 15:56:24", "link": "http://arxiv.org/abs/2312.17660v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "TuPy-E: detecting hate speech in Brazilian Portuguese social media with\n  a novel dataset and comprehensive analysis of models", "abstract": "Social media has become integral to human interaction, providing a platform\nfor communication and expression. However, the rise of hate speech on these\nplatforms poses significant risks to individuals and communities. Detecting and\naddressing hate speech is particularly challenging in languages like Portuguese\ndue to its rich vocabulary, complex grammar, and regional variations. To\naddress this, we introduce TuPy-E, the largest annotated Portuguese corpus for\nhate speech detection. TuPy-E leverages an open-source approach, fostering\ncollaboration within the research community. We conduct a detailed analysis\nusing advanced techniques like BERT models, contributing to both academic\nunderstanding and practical applications", "published": "2023-12-29 17:47:00", "link": "http://arxiv.org/abs/2312.17704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Essay Scoring in a Brazilian Scenario", "abstract": "This paper presents a novel Automatic Essay Scoring (AES) algorithm tailored\nfor the Portuguese-language essays of Brazil's Exame Nacional do Ensino M\\'edio\n(ENEM), addressing the challenges in traditional human grading systems. Our\napproach leverages advanced deep learning techniques to align closely with\nhuman grading criteria, targeting efficiency and scalability in evaluating\nlarge volumes of student essays. This research not only responds to the\nlogistical and financial constraints of manual grading in Brazilian educational\nassessments but also promises to enhance fairness and consistency in scoring,\nmarking a significant step forward in the application of AES in large-scale\nacademic settings.", "published": "2023-12-29 23:05:18", "link": "http://arxiv.org/abs/2401.00095v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Video Understanding with Large Language Models: A Survey", "abstract": "With the burgeoning growth of online video platforms and the escalating\nvolume of video content, the demand for proficient video understanding tools\nhas intensified markedly. Given the remarkable capabilities of large language\nmodels (LLMs) in language and multimodal tasks, this survey provides a detailed\noverview of recent advancements in video understanding that harness the power\nof LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly\nadvanced, particularly their ability for open-ended multi-granularity (general,\ntemporal, and spatiotemporal) reasoning combined with commonsense knowledge,\nsuggesting a promising path for future video understanding. We examine the\nunique characteristics and capabilities of Vid-LLMs, categorizing the\napproaches into three main types: Video Analyzer x LLM, Video Embedder x LLM,\nand (Analyzer + Embedder) x LLM. Furthermore, we identify five sub-types based\non the functions of LLMs in Vid-LLMs: LLM as Summarizer, LLM as Manager, LLM as\nText Decoder, LLM as Regressor, and LLM as Hidden Layer. Furthermore, this\nsurvey presents a comprehensive study of the tasks, datasets, benchmarks, and\nevaluation methodologies for Vid-LLMs. Additionally, it explores the expansive\napplications of Vid-LLMs across various domains, highlighting their remarkable\nscalability and versatility in real-world video understanding challenges.\nFinally, it summarizes the limitations of existing Vid-LLMs and outlines\ndirections for future research. For more information, readers are recommended\nto visit the repository at\nhttps://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.", "published": "2023-12-29 01:56:17", "link": "http://arxiv.org/abs/2312.17432v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction", "abstract": "With the rapid advancement of Large Language Models (LLMs) and their\noutstanding performance in semantic and contextual comprehension, the potential\nof LLMs in specialized domains warrants exploration. This paper introduces the\nNoteAid EHR Interaction Pipeline, an innovative approach developed using\ngenerative LLMs to assist in patient education, a task stemming from the need\nto aid patients in understanding Electronic Health Records (EHRs). Building\nupon the NoteAid work, we designed two novel tasks from the patient's\nperspective: providing explanations for EHR content that patients may not\nunderstand and answering questions posed by patients after reading their EHRs.\nWe extracted datasets containing 10,000 instances from MIMIC Discharge\nSummaries and 876 instances from the MADE medical notes collection,\nrespectively, executing the two tasks through the NoteAid EHR Interaction\nPipeline with these data. Performance data of LLMs on these tasks were\ncollected and constructed as the corresponding NoteAid EHR Interaction Dataset.\nThrough a comprehensive evaluation of the entire dataset using LLM assessment\nand a rigorous manual evaluation of 64 instances, we showcase the potential of\nLLMs in patient education. Besides, the results provide valuable data support\nfor future exploration and applications in this domain while also supplying\nhigh-quality synthetic datasets for in-house system training.", "published": "2023-12-29 05:13:40", "link": "http://arxiv.org/abs/2312.17475v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining", "abstract": "Although BERT-style encoder models are heavily used in NLP research, many\nresearchers do not pretrain their own BERTs from scratch due to the high cost\nof training. In the past half-decade since BERT first rose to prominence, many\nadvances have been made with other transformer architectures and training\nconfigurations that have yet to be systematically incorporated into BERT. Here,\nwe introduce MosaicBERT, a BERT-style encoder architecture and training recipe\nthat is empirically optimized for fast pretraining. This efficient architecture\nincorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear\nUnits (GLU), a module to dynamically remove padded tokens, and low precision\nLayerNorm into the classic transformer encoder block. The training recipe\nincludes a 30% masking ratio for the Masked Language Modeling (MLM) objective,\nbfloat16 precision, and vocabulary size optimized for GPU throughput, in\naddition to best-practices from RoBERTa and other encoder models. When\npretrained from scratch on the C4 dataset, this base model achieves a\ndownstream average GLUE (dev) score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs\nat a cost of roughly $20. We plot extensive accuracy vs. pretraining speed\nPareto curves and show that MosaicBERT base and large are consistently Pareto\noptimal when compared to a competitive BERT base and large. This empirical\nspeed up in pretraining enables researchers and engineers to pretrain custom\nBERT-style models at low cost instead of finetune on existing generic models.\nWe open source our model weights and code.", "published": "2023-12-29 06:05:19", "link": "http://arxiv.org/abs/2312.17482v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models\n  through Intervention without Tuning", "abstract": "Despite the great success of large language models (LLMs) in various tasks,\nthey suffer from generating hallucinations. We introduce Truth Forest, a method\nthat enhances truthfulness in LLMs by uncovering hidden truth representations\nusing multi-dimensional orthogonal probes. Specifically, it creates multiple\northogonal bases for modeling truth by incorporating orthogonal constraints\ninto the probes. Moreover, we introduce Random Peek, a systematic technique\nconsidering an extended range of positions within the sequence, reducing the\ngap between discerning and generating truth features in LLMs. By employing this\napproach, we improved the truthfulness of Llama-2-7B from 40.8\\% to 74.5\\% on\nTruthfulQA. Likewise, significant improvements are observed in fine-tuned\nmodels. We conducted a thorough analysis of truth features using probes. Our\nvisualization results show that orthogonal probes capture complementary\ntruth-related features, forming well-defined clusters that reveal the inherent\nstructure of the dataset.", "published": "2023-12-29 06:08:18", "link": "http://arxiv.org/abs/2312.17484v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Building Efficient Universal Classifiers with Natural Language Inference", "abstract": "Generative Large Language Models (LLMs) have become the mainstream choice for\nfewshot and zeroshot learning thanks to the universality of text generation.\nMany users, however, do not need the broad capabilities of generative LLMs when\nthey only want to automate a classification task. Smaller BERT-like models can\nalso learn universal tasks, which allow them to do any text classification task\nwithout requiring fine-tuning (zeroshot classification) or to learn new tasks\nwith only a few examples (fewshot), while being significantly more efficient\nthan generative LLMs. This paper (1) explains how Natural Language Inference\n(NLI) can be used as a universal classification task that follows similar\nprinciples as instruction fine-tuning of generative LLMs, (2) provides a\nstep-by-step guide with reusable Jupyter notebooks for building a universal\nclassifier, and (3) shares the resulting universal classifier that is trained\non 33 datasets with 389 diverse classes. Parts of the code we share has been\nused to train our older zeroshot classifiers that have been downloaded more\nthan 55 million times via the Hugging Face Hub as of December 2023. Our new\nclassifier improves zeroshot performance by 9.4%.", "published": "2023-12-29 10:18:36", "link": "http://arxiv.org/abs/2312.17543v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Action-Item-Driven Summarization of Long Meeting Transcripts", "abstract": "The increased prevalence of online meetings has significantly enhanced the\npracticality of a model that can automatically generate the summary of a given\nmeeting. This paper introduces a novel and effective approach to automate the\ngeneration of meeting summaries. Current approaches to this problem generate\ngeneral and basic summaries, considering the meeting simply as a long dialogue.\nHowever, our novel algorithms can generate abstractive meeting summaries that\nare driven by the action items contained in the meeting transcript. This is\ndone by recursively generating summaries and employing our action-item\nextraction algorithm for each section of the meeting in parallel. All of these\nsectional summaries are then combined and summarized together to create a\ncoherent and action-item-driven summary. In addition, this paper introduces\nthree novel methods for dividing up long transcripts into topic-based sections\nto improve the time efficiency of our algorithm, as well as to resolve the\nissue of large language models (LLMs) forgetting long-term dependencies. Our\npipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an\napproximately 4.98% increase from the current state-of-the-art result produced\nby a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.", "published": "2023-12-29 12:33:21", "link": "http://arxiv.org/abs/2312.17581v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Principled Gradient-based Markov Chain Monte Carlo for Text Generation", "abstract": "Recent papers have demonstrated the possibility of energy-based text\ngeneration by adapting gradient-based sampling algorithms, a paradigm of MCMC\nalgorithms that promises fast convergence. However, as we show in this paper,\nprevious attempts on this approach to text generation all fail to sample\ncorrectly from the target language model distributions. To address this\nlimitation, we consider the problem of designing text samplers that are\nfaithful, meaning that they have the target text distribution as its limiting\ndistribution. We propose several faithful gradient-based sampling algorithms to\nsample from the target energy-based text distribution correctly, and study\ntheir theoretical properties. Through experiments on various forms of text\ngeneration, we demonstrate that faithful samplers are able to generate more\nfluent text while adhering to the control objectives better.", "published": "2023-12-29 18:00:56", "link": "http://arxiv.org/abs/2312.17710v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience\n  in Higher Education", "abstract": "With the rapid evolution of Natural Language Processing (NLP), Large Language\nModels (LLMs) like ChatGPT have emerged as powerful tools capable of\ntransforming various sectors. Their vast knowledge base and dynamic interaction\ncapabilities represent significant potential in improving education by\noperating as a personalized assistant. However, the possibility of generating\nincorrect, biased, or unhelpful answers are a key challenge to resolve when\ndeploying LLMs in an education context. This work introduces an innovative\narchitecture that combines the strengths of ChatGPT with a traditional\ninformation retrieval based chatbot framework to offer enhanced student support\nin higher education. Our empirical evaluations underscore the high promise of\nthis approach.", "published": "2023-12-29 19:11:55", "link": "http://arxiv.org/abs/2401.00052v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Commonsense for Zero-Shot Natural Language Video Localization", "abstract": "Zero-shot Natural Language-Video Localization (NLVL) methods have exhibited\npromising results in training NLVL models exclusively with raw video data by\ndynamically generating video segments and pseudo-query annotations. However,\nexisting pseudo-queries often lack grounding in the source video, resulting in\nunstructured and disjointed content. In this paper, we investigate the\neffectiveness of commonsense reasoning in zero-shot NLVL. Specifically, we\npresent CORONET, a zero-shot NLVL framework that leverages commonsense to\nbridge the gap between videos and generated pseudo-queries via a commonsense\nenhancement module. CORONET employs Graph Convolution Networks (GCN) to encode\ncommonsense information extracted from a knowledge graph, conditioned on the\nvideo, and cross-attention mechanisms to enhance the encoded video and\npseudo-query representations prior to localization. Through empirical\nevaluations on two benchmark datasets, we demonstrate that CORONET surpasses\nboth zero-shot and weakly supervised baselines, achieving improvements up to\n32.13% across various recall thresholds and up to 6.33% in mIoU. These results\nunderscore the significance of leveraging commonsense reasoning for zero-shot\nNLVL.", "published": "2023-12-29 01:42:43", "link": "http://arxiv.org/abs/2312.17429v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Leveraging Open-Vocabulary Diffusion to Camouflaged Instance\n  Segmentation", "abstract": "Text-to-image diffusion techniques have shown exceptional capability of\nproducing high-quality images from text descriptions. This indicates that there\nexists a strong correlation between the visual and textual domains. In\naddition, text-image discriminative models such as CLIP excel in image\nlabelling from text prompts, thanks to the rich and diverse information\navailable from open concepts. In this paper, we leverage these technical\nadvances to solve a challenging problem in computer vision: camouflaged\ninstance segmentation. Specifically, we propose a method built upon a\nstate-of-the-art diffusion model, empowered by open-vocabulary to learn\nmulti-scale textual-visual features for camouflaged object representations.\nSuch cross-domain representations are desirable in segmenting camouflaged\nobjects where visual cues are subtle to distinguish the objects from the\nbackground, especially in segmenting novel objects which are not seen in\ntraining. We also develop technically supportive components to effectively fuse\ncross-domain features and engage relevant features towards respective\nforeground objects. We validate our method and compare it with existing ones on\nseveral benchmark datasets of camouflaged instance segmentation and generic\nopen-vocabulary instance segmentation. Experimental results confirm the\nadvances of our method over existing ones. We will publish our code and\npre-trained models to support future research.", "published": "2023-12-29 07:59:07", "link": "http://arxiv.org/abs/2312.17505v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing Quantitative Reasoning Skills of Large Language Models through\n  Dimension Perception", "abstract": "Quantities are distinct and critical components of texts that characterize\nthe magnitude properties of entities, providing a precise perspective for the\nunderstanding of natural language, especially for reasoning tasks. In recent\nyears, there has been a flurry of research on reasoning tasks based on large\nlanguage models (LLMs), most of which solely focus on numerical values,\nneglecting the dimensional concept of quantities with units despite its\nimportance. We argue that the concept of dimension is essential for precisely\nunderstanding quantities and of great significance for LLMs to perform\nquantitative reasoning. However, the lack of dimension knowledge and\nquantity-related benchmarks has resulted in low performance of LLMs. Hence, we\npresent a framework to enhance the quantitative reasoning ability of language\nmodels based on dimension perception. We first construct a dimensional unit\nknowledge base (DimUnitKB) to address the knowledge gap in this area. We\npropose a benchmark DimEval consisting of seven tasks of three categories to\nprobe and enhance the dimension perception skills of LLMs. To evaluate the\neffectiveness of our methods, we propose a quantitative reasoning task and\nconduct experiments. The experimental results show that our dimension\nperception method dramatically improves accuracy (43.55%->50.67%) on\nquantitative reasoning tasks compared to GPT-4.", "published": "2023-12-29 09:29:37", "link": "http://arxiv.org/abs/2312.17532v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of\n  LLMs", "abstract": "CoT (Chain-of-Thought) is a way to solve reasoning problems for LLMs .\nRecently, many researches appear for improving the CoT capability of LLMs. In\nthis work, we also proposed Olapa-MCoT, which is a LLMs based on llama2-13B PLM\nfor finetuning and alignment learning. During the alignment training, we\nproposed the SimRRHF algorithm and Incorrect Data Relearning and mainly focused\non optimizing the Chinese mathematical reasoning ability of Olapa-MCoT. The\nexperiment achieved significant results, with the accuracy of Chinese\nmathematical reasoning up to 50%, 36% rise compared to llama2-13B. In addition,\nthe accuracy of English reasoning ability also increased by nearly 4%.", "published": "2023-12-29 09:33:35", "link": "http://arxiv.org/abs/2312.17535v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Research on the Laws of Multimodal Perception and Cognition from a\n  Cross-cultural Perspective -- Taking Overseas Chinese Gardens as an Example", "abstract": "This study aims to explore the complex relationship between perceptual and\ncognitive interactions in multimodal data analysis,with a specific emphasis on\nspatial experience design in overseas Chinese gardens. It is found that\nevaluation content and images on social media can reflect individuals' concerns\nand sentiment responses, providing a rich data base for cognitive research that\ncontains both sentimental and image-based cognitive information. Leveraging\ndeep learning techniques, we analyze textual and visual data from social media,\nthereby unveiling the relationship between people's perceptions and sentiment\ncognition within the context of overseas Chinese gardens. In addition, our\nstudy introduces a multi-agent system (MAS)alongside AI agents. Each agent\nexplores the laws of aesthetic cognition through chat scene simulation combined\nwith web search. This study goes beyond the traditional approach of translating\nperceptions into sentiment scores, allowing for an extension of the research\nmethodology in terms of directly analyzing texts and digging deeper into\nopinion data. This study provides new perspectives for understanding aesthetic\nexperience and its impact on architecture and landscape design across diverse\ncultural contexts, which is an essential contribution to the field of cultural\ncommunication and aesthetic understanding.", "published": "2023-12-29 15:13:23", "link": "http://arxiv.org/abs/2312.17642v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.SI"], "primary_category": "cs.AI"}
{"title": "Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language\n  Models", "abstract": "The burgeoning interest in Multimodal Large Language Models (MLLMs), such as\nOpenAI's GPT-4V(ision), has significantly impacted both academic and industrial\nrealms. These models enhance Large Language Models (LLMs) with advanced visual\nunderstanding capabilities, facilitating their application in a variety of\nmultimodal tasks. Recently, Google introduced Gemini, a cutting-edge MLLM\ndesigned specifically for multimodal integration. Despite its advancements,\npreliminary benchmarks indicate that Gemini lags behind GPT models in\ncommonsense reasoning tasks. However, this assessment, based on a limited\ndataset (i.e., HellaSWAG), does not fully capture Gemini's authentic\ncommonsense reasoning potential. To address this gap, our study undertakes a\nthorough evaluation of Gemini's performance in complex reasoning tasks that\nnecessitate the integration of commonsense knowledge across modalities. We\ncarry out a comprehensive analysis of 12 commonsense reasoning datasets,\nranging from general to domain-specific tasks. This includes 11 datasets\nfocused solely on language, as well as one that incorporates multimodal\nelements. Our experiments across four LLMs and two MLLMs demonstrate Gemini's\ncompetitive commonsense reasoning capabilities. Additionally, we identify\ncommon challenges faced by current LLMs and MLLMs in addressing commonsense\nproblems, underscoring the need for further advancements in enhancing the\ncommonsense reasoning abilities of these models.", "published": "2023-12-29 15:57:49", "link": "http://arxiv.org/abs/2312.17661v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Jatmo: Prompt Injection Defense by Task-Specific Finetuning", "abstract": "Large Language Models (LLMs) are attracting significant research attention\ndue to their instruction-following abilities, allowing users and developers to\nleverage LLMs for a variety of tasks. However, LLMs are vulnerable to\nprompt-injection attacks: a class of attacks that hijack the model's\ninstruction-following abilities, changing responses to prompts to undesired,\npossibly malicious ones. In this work, we introduce Jatmo, a method for\ngenerating task-specific models resilient to prompt-injection attacks. Jatmo\nleverages the fact that LLMs can only follow instructions once they have\nundergone instruction tuning. It harnesses a teacher instruction-tuned model to\ngenerate a task-specific dataset, which is then used to fine-tune a base model\n(i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a\ndataset of inputs for the task: it uses the teacher model to generate outputs.\nFor situations with no pre-existing datasets, Jatmo can use a single example,\nor in some cases none at all, to produce a fully synthetic dataset. Our\nexperiments on seven tasks show that Jatmo models provide similar quality of\noutputs on their specific task as standard LLMs, while being resilient to\nprompt injections. The best attacks succeeded in less than 0.5% of cases\nagainst our models, versus 87% success rate against GPT-3.5-Turbo. We release\nJatmo at https://github.com/wagner-group/prompt-injection-defense.", "published": "2023-12-29 16:37:53", "link": "http://arxiv.org/abs/2312.17673v2", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Efficacy of Utilizing Large Language Models to Detect Public Threat\n  Posted Online", "abstract": "This paper examines the efficacy of utilizing large language models (LLMs) to\ndetect public threats posted online. Amid rising concerns over the spread of\nthreatening rhetoric and advance notices of violence, automated content\nanalysis techniques may aid in early identification and moderation. Custom data\ncollection tools were developed to amass post titles from a popular Korean\nonline community, comprising 500 non-threat examples and 20 threats. Various\nLLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as\neither \"threat\" or \"safe.\" Statistical analysis found all models demonstrated\nstrong accuracy, passing chi-square goodness of fit tests for both threat and\nnon-threat identification. GPT-4 performed best overall with 97.9% non-threat\nand 100% threat accuracy. Affordability analysis also showed PaLM API pricing\nas highly cost-efficient. The findings indicate LLMs can effectively augment\nhuman content moderation at scale to help mitigate emerging online risks.\nHowever, biases, transparency, and ethical oversight remain vital\nconsiderations before real-world implementation.", "published": "2023-12-29 16:42:02", "link": "http://arxiv.org/abs/2401.02974v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Generating Rhythm Game Music with Jukebox", "abstract": "Music has always been thought of as a \"human\" endeavor -- when praising a\npiece of music, we emphasize the composer's creativity and the emotions the\nmusic invokes. Because music also heavily relies on patterns and repetition in\nthe form of recurring melodic themes and chord progressions, artificial\nintelligence has increasingly been able to replicate music in a human-like\nfashion. This research investigated the capabilities of Jukebox, an open-source\ncommercially available neural network, to accurately replicate two genres of\nmusic often found in rhythm games, artcore and orchestral. A Google Colab\nnotebook provided the computational resources necessary to sample and extend a\ntotal of sixteen piano arrangements of both genres. A survey containing\nselected samples was distributed to a local youth orchestra to gauge people's\nperceptions of the musicality of AI and human-generated music. Even though\nhumans preferred human-generated music, Jukebox's slightly high rating showed\nthat it was somewhat capable at mimicking the styles of both genres. Despite\nlimitations of Jukebox only using raw audio and a relatively small sample size,\nit shows promise for the future of AI as a collaborative tool in music\nproduction.", "published": "2023-12-29 00:57:31", "link": "http://arxiv.org/abs/2401.01997v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attention-based Interactive Disentangling Network for Instance-level\n  Emotional Voice Conversion", "abstract": "Emotional Voice Conversion aims to manipulate a speech according to a given\nemotion while preserving non-emotion components. Existing approaches cannot\nwell express fine-grained emotional attributes. In this paper, we propose an\nAttention-based Interactive diseNtangling Network (AINN) that leverages\ninstance-wise emotional knowledge for voice conversion. We introduce a\ntwo-stage pipeline to effectively train our network: Stage I utilizes\ninter-speech contrastive learning to model fine-grained emotion and\nintra-speech disentanglement learning to better separate emotion and content.\nIn Stage II, we propose to regularize the conversion with a multi-view\nconsistency mechanism. This technique helps us transfer fine-grained emotion\nand maintain speech content. Extensive experiments show that our AINN\noutperforms state-of-the-arts in both objective and subjective metrics.", "published": "2023-12-29 08:06:45", "link": "http://arxiv.org/abs/2312.17508v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
