{"title": "Learning Interpretable Spatial Operations in a Rich 3D Blocks World", "abstract": "In this paper, we study the problem of mapping natural language instructions\nto complex spatial actions in a 3D blocks world. We first introduce a new\ndataset that pairs complex 3D spatial operations to rich natural language\ndescriptions that require complex spatial and pragmatic interpretations such as\n\"mirroring\", \"twisting\", and \"balancing\". This dataset, built on the simulation\nenvironment of Bisk, Yuret, and Marcu (2016), attains language that is\nsignificantly richer and more complex, while also doubling the size of the\noriginal dataset in the 2D environment with 100 new world configurations and\n250,000 tokens. In addition, we propose a new neural architecture that achieves\ncompetitive results while automatically discovering an inventory of\ninterpretable spatial operations (Figure 5)", "published": "2017-12-10 00:55:16", "link": "http://arxiv.org/abs/1712.03463v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Task Learning for Mental Health using Social Media Text", "abstract": "We introduce initial groundwork for estimating suicide risk and mental health\nin a deep learning framework. By modeling multiple conditions, the system\nlearns to make predictions about suicide risk and mental health at a low false\npositive rate. Conditions are modeled as tasks in a multi-task learning (MTL)\nframework, with gender prediction as an additional auxiliary task. We\ndemonstrate the effectiveness of multi-task learning by comparison to a\nwell-tuned single-task baseline with the same number of parameters. Our best\nMTL model predicts potential suicide attempt, as well as the presence of\natypical mental health, with AUC > 0.8. We also find additional large\nimprovements using multi-task learning on mental health tasks with limited\ntraining data.", "published": "2017-12-10 14:27:26", "link": "http://arxiv.org/abs/1712.03538v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Inducing Interpretability in Knowledge Graph Embeddings", "abstract": "We study the problem of inducing interpretability in KG embeddings.\nSpecifically, we explore the Universal Schema (Riedel et al., 2013) and propose\na method to induce interpretability. There have been many vector space models\nproposed for the problem, however, most of these methods don't address the\ninterpretability (semantics) of individual dimensions. In this work, we study\nthis problem and propose a method for inducing interpretability in KG\nembeddings using entity co-occurrence statistics. The proposed method\nsignificantly improves the interpretability, while maintaining comparable\nperformance in other KG tasks.", "published": "2017-12-10 15:02:05", "link": "http://arxiv.org/abs/1712.03547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stochastic Answer Networks for Machine Reading Comprehension", "abstract": "We propose a simple yet robust stochastic answer network (SAN) that simulates\nmulti-step reasoning in machine reading comprehension. Compared to previous\nwork such as ReasoNet which used reinforcement learning to determine the number\nof steps, the unique feature is the use of a kind of stochastic prediction\ndropout on the answer module (final layer) of the neural network during the\ntraining. We show that this simple trick improves robustness and achieves\nresults competitive to the state-of-the-art on the Stanford Question Answering\nDataset (SQuAD), the Adversarial SQuAD, and the Microsoft MAchine Reading\nCOmprehension Dataset (MS MARCO).", "published": "2017-12-10 16:28:33", "link": "http://arxiv.org/abs/1712.03556v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextualized Word Representations for Reading Comprehension", "abstract": "Reading a document and extracting an answer to a question about its content\nhas attracted substantial attention recently. While most work has focused on\nthe interaction between the question and the document, in this work we evaluate\nthe importance of context when the question and document are processed\nindependently. We take a standard neural architecture for this task, and show\nthat by providing rich contextualized word representations from a large\npre-trained language model as well as allowing the model to choose between\ncontext-dependent and context-independent word representations, we can obtain\ndramatic improvements and reach performance comparable to state-of-the-art on\nthe competitive SQuAD dataset.", "published": "2017-12-10 23:16:02", "link": "http://arxiv.org/abs/1712.03609v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative analysis of criteria for filtering time series of word usage\n  frequencies", "abstract": "This paper describes a method of nonlinear wavelet thresholding of time\nseries. The Ramachandran-Ranganathan runs test is used to assess the quality of\napproximation. To minimize the objective function, it is proposed to use\ngenetic algorithms - one of the stochastic optimization methods. The suggested\nmethod is tested both on the model series and on the word frequency series\nusing the Google Books Ngram data. It is shown that method of filtering which\nuses the runs criterion shows significantly better results compared with the\nstandard wavelet thresholding. The method can be used when quality of filtering\nis of primary importance but not the speed of calculations.", "published": "2017-12-10 12:04:19", "link": "http://arxiv.org/abs/1712.03512v1", "categories": ["stat.ME", "cs.CL", "stat.AP", "62M10, 91F20", "G.3; I.2.7"], "primary_category": "stat.ME"}
{"title": "The organization of a three-manual keyboard for 53-tone tempered and\n  other tempered systems", "abstract": "The aim is to explore new opportunities of the pitch organization of the\nmusical scale. Specifically, a numerical comparison of the different musical\ntemperaments among themselves in the degree of approximation of the Pythagorean\nscale is provided, and thus it numerically substantiates the thesis that the\n53-tone tempered system is the most advanced among possible others. We present\nnumerical data on the approximation of overtones from first twenty by steps of\nthe 53-tone temperament. Here were proposed some schemes of the three-manual\nkeyboard for the implementation of 53-tone temperament, which are also\nimplemented at the same time for 12 -, 17 -, 24 -, 29 - and 41-sounding system.\nIf there are technical means then these schemes can be used to play music in\nany temperaments, based on said number of steps.", "published": "2017-12-10 18:24:23", "link": "http://arxiv.org/abs/1712.03569v1", "categories": ["cs.SD", "eess.AS", "94A99", "H.5.5; H.5.1"], "primary_category": "cs.SD"}
{"title": "A Cascade Architecture for Keyword Spotting on Mobile Devices", "abstract": "We present a cascade architecture for keyword spotting with speaker\nverification on mobile devices. By pairing a small computational footprint with\nspecialized digital signal processing (DSP) chips, we are able to achieve low\npower consumption while continuously listening for a keyword.", "published": "2017-12-10 22:47:29", "link": "http://arxiv.org/abs/1712.03603v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Prodorshok I: A Bengali Isolated Speech Dataset for Voice-Based\n  Assistive Technologies - A comparative analysis of the effects of data\n  augmentation on HMM-GMM and DNN classifiers", "abstract": "Prodorshok I is a Bengali isolated word dataset tailored to help create\nspeaker-independent, voice-command driven automated speech recognition (ASR)\nbased assistive technologies to help improve human-computer interaction (HCI).\nThis paper presents the results of an objective analysis that was undertaken\nusing a subset of words from Prodorshok I to assess its reliability in ASR\nsystems that utilize Hidden Markov Models (HMM) with Gaussian emissions and\nDeep Neural Networks (DNN). The results show that simple data augmentation\ninvolving a small pitch shift can make surprisingly tangible improvements to\naccuracy levels in speech recognition.", "published": "2017-12-10 19:52:51", "link": "http://arxiv.org/abs/1712.03579v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
