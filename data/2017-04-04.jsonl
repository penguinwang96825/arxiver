{"title": "Voice Conversion from Unaligned Corpora using Variational Autoencoding\n  Wasserstein Generative Adversarial Networks", "abstract": "Building a voice conversion (VC) system from non-parallel speech corpora is\nchallenging but highly valuable in real application scenarios. In most\nsituations, the source and the target speakers do not repeat the same texts or\nthey may even speak different languages. In this case, one possible, although\nindirect, solution is to build a generative model for speech. Generative models\nfocus on explaining the observations with latent variables instead of learning\na pairwise transformation function, thereby bypassing the requirement of speech\nframe alignment. In this paper, we propose a non-parallel VC framework with a\nvariational autoencoding Wasserstein generative adversarial network (VAW-GAN)\nthat explicitly considers a VC objective when building the speech model.\nExperimental results corroborate the capability of our framework for building a\nVC system from unaligned data, and demonstrate improved conversion quality.", "published": "2017-04-04 01:47:14", "link": "http://arxiv.org/abs/1704.00849v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretation of Semantic Tweet Representations", "abstract": "Research in analysis of microblogging platforms is experiencing a renewed\nsurge with a large number of works applying representation learning models for\napplications like sentiment analysis, semantic textual similarity computation,\nhashtag prediction, etc. Although the performance of the representation\nlearning models has been better than the traditional baselines for such tasks,\nlittle is known about the elementary properties of a tweet encoded within these\nrepresentations, or why particular representations work better for certain\ntasks. Our work presented here constitutes the first step in opening the\nblack-box of vector embeddings for tweets. Traditional feature engineering\nmethods for high-level applications have exploited various elementary\nproperties of tweets. We believe that a tweet representation is effective for\nan application because it meticulously encodes the application-specific\nelementary properties of tweets. To understand the elementary properties\nencoded in a tweet representation, we evaluate the representations on the\naccuracy to which they can model each of those properties such as tweet length,\npresence of particular words, hashtags, mentions, capitalization, etc. Our\nsystematic extensive study of nine supervised and four unsupervised tweet\nrepresentations against most popular eight textual and five social elementary\nproperties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors\n(STV) best encode the textual and social properties of tweets respectively.\nFastText is the best model for low resource settings, providing very little\ndegradation with reduction in embedding size. Finally, we draw interesting\ninsights by correlating the model performance obtained for elementary property\nprediction tasks with the highlevel downstream applications.", "published": "2017-04-04 07:24:15", "link": "http://arxiv.org/abs/1704.00898v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Japanese Sentiment Classification using a Tree-Structured Long\n  Short-Term Memory with Attention", "abstract": "Previous approaches to training syntax-based sentiment classification models\nrequired phrase-level annotated corpora, which are not readily available in\nmany languages other than English. Thus, we propose the use of tree-structured\nLong Short-Term Memory with an attention mechanism that pays attention to each\nsubtree of the parse tree. Experimental results indicate that our model\nachieves the state-of-the-art performance in a Japanese sentiment\nclassification task.", "published": "2017-04-04 09:08:46", "link": "http://arxiv.org/abs/1704.00924v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring\n  Sentiment towards Brands from Financial News Headlines", "abstract": "In this paper, we describe a methodology to infer Bullish or Bearish\nsentiment towards companies/brands. More specifically, our approach leverages\naffective lexica and word embeddings in combination with convolutional neural\nnetworks to infer the sentiment of financial news headlines towards a target\ncompany. Such architecture was used and evaluated in the context of the SemEval\n2017 challenge (task 5, subtask 2), in which it obtained the best performance.", "published": "2017-04-04 10:01:47", "link": "http://arxiv.org/abs/1704.00939v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Emotional Chatting Machine: Emotional Conversation Generation with\n  Internal and External Memory", "abstract": "Perception and expression of emotion are key factors to the success of\ndialogue systems or conversational agents. However, this problem has not been\nstudied in large-scale conversation generation so far. In this paper, we\npropose Emotional Chatting Machine (ECM) that can generate appropriate\nresponses not only in content (relevant and grammatical) but also in emotion\n(emotionally consistent). To the best of our knowledge, this is the first work\nthat addresses the emotion factor in large-scale conversation generation. ECM\naddresses the factor using three new mechanisms that respectively (1) models\nthe high-level abstraction of emotion expressions by embedding emotion\ncategories, (2) captures the change of implicit internal emotion states, and\n(3) uses explicit emotion expressions with an external emotion vocabulary.\nExperiments show that the proposed model can generate responses appropriate not\nonly in content but also in emotion.", "published": "2017-04-04 15:44:48", "link": "http://arxiv.org/abs/1704.01074v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Modal to Multimodal Ambiguities: a Classification Approach", "abstract": "This paper deals with classifying ambiguities for Multimodal Languages. It\nevolves the classifications and the methods of the literature on ambiguities\nfor Natural Language and Visual Language, empirically defining an original\nclassification of ambiguities for multimodal interaction using a linguistic\nperspective. This classification distinguishes between Semantic and Syntactic\nmultimodal ambiguities and their subclasses, which are intercepted using a\nrule-based method implemented in a software module. The experimental results\nhave achieved an accuracy of the obtained classification compared to the\nexpected one, which are defined by the human judgment, of 94.6% for the\nsemantic ambiguities classes, and 92.1% for the syntactic ambiguities classes.", "published": "2017-04-04 12:06:51", "link": "http://arxiv.org/abs/1704.02841v1", "categories": ["cs.HC", "cs.CL", "I.2.1; I.2.7"], "primary_category": "cs.HC"}
