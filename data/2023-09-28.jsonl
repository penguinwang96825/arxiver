{"title": "Large Language Model Soft Ideologization via AI-Self-Consciousness", "abstract": "Large language models (LLMs) have demonstrated human-level performance on a\nvast spectrum of natural language tasks. However, few studies have addressed\nthe LLM threat and vulnerability from an ideology perspective, especially when\nthey are increasingly being deployed in sensitive domains, e.g., elections and\neducation. In this study, we explore the implications of GPT soft\nideologization through the use of AI-self-consciousness. By utilizing GPT\nself-conversations, AI can be granted a vision to \"comprehend\" the intended\nideology, and subsequently generate finetuning data for LLM ideology injection.\nWhen compared to traditional government ideology manipulation techniques, such\nas information censorship, LLM ideologization proves advantageous; it is easy\nto implement, cost-effective, and powerful, thus brimming with risks.", "published": "2023-09-28 04:47:58", "link": "http://arxiv.org/abs/2309.16167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Marathi-English Code-mixed Text Generation", "abstract": "Code-mixing, the blending of linguistic elements from distinct languages to\nform meaningful sentences, is common in multilingual settings, yielding hybrid\nlanguages like Hinglish and Minglish. Marathi, India's third most spoken\nlanguage, often integrates English for precision and formality. Developing\ncode-mixed language systems, like Marathi-English (Minglish), faces resource\nconstraints. This research introduces a Marathi-English code-mixed text\ngeneration algorithm, assessed with Code Mixing Index (CMI) and Degree of Code\nMixing (DCM) metrics. Across 2987 code-mixed questions, it achieved an average\nCMI of 0.2 and an average DCM of 7.4, indicating effective and comprehensible\ncode-mixed sentences. These results offer potential for enhanced NLP tools,\nbridging linguistic gaps in multilingual societies.", "published": "2023-09-28 06:51:26", "link": "http://arxiv.org/abs/2309.16202v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Text Generation with Residual Memory Transformer", "abstract": "Large-scale Causal Language Models (CLMs), e.g., GPT3 and ChatGPT, have\nbrought great success in text generation. However, it is still an open\nchallenge to control the generation process of CLM while balancing flexibility,\ncontrol granularity, and generation efficiency. In this paper, we provide a new\nalternative for controllable text generation (CTG), by designing a\nnon-intrusive, lightweight control plugin to accompany the generation of CLM at\narbitrary time steps. The proposed control plugin, namely Residual Memory\nTransformer (RMT), has an encoder-decoder setup, which can accept any types of\ncontrol conditions and cooperate with CLM through a residual learning paradigm,\nto achieve a more flexible, general, and efficient CTG. Extensive experiments\nare carried out on various control tasks, in the form of both automatic and\nhuman evaluations. The results show the superiority of RMT over a range of\nstate-of-the-art approaches, proving the effectiveness and versatility of our\napproach.", "published": "2023-09-28 08:13:33", "link": "http://arxiv.org/abs/2309.16231v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Political Figures in Real-Time: Leveraging YouTube Metadata\n  for Sentiment Analysis", "abstract": "Sentiment analysis using big data from YouTube videos metadata can be\nconducted to analyze public opinions on various political figures who represent\npolitical parties. This is possible because YouTube has become one of the\nplatforms for people to express themselves, including their opinions on various\npolitical figures. The resulting sentiment analysis can be useful for political\nexecutives to gain an understanding of public sentiment and develop appropriate\nand effective political strategies. This study aimed to build a sentiment\nanalysis system leveraging YouTube videos metadata. The sentiment analysis\nsystem was built using Apache Kafka, Apache PySpark, and Hadoop for big data\nhandling; TensorFlow for deep learning handling; and FastAPI for deployment on\nthe server. The YouTube videos metadata used in this study is the video\ndescription. The sentiment analysis model was built using LSTM algorithm and\nproduces two types of sentiments: positive and negative sentiments. The\nsentiment analysis results are then visualized in the form a simple web-based\ndashboard.", "published": "2023-09-28 08:15:55", "link": "http://arxiv.org/abs/2309.16234v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph\n  Question Answering Systems", "abstract": "With the recent spike in the number and availability of Large Language Models\n(LLMs), it has become increasingly important to provide large and realistic\nbenchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So\nfar the majority of benchmarks rely on pattern-based SPARQL query generation\napproaches. The subsequent natural language (NL) question generation is\nconducted through crowdsourcing or other automated methods, such as rule-based\nparaphrasing or NL question templates. Although some of these datasets are of\nconsiderable size, their pitfall lies in their pattern-based generation\napproaches, which do not always generalize well to the vague and linguistically\ndiverse questions asked by humans in real-world contexts. In this paper, we\nintroduce Spider4SPARQL - a new SPARQL benchmark dataset featuring 9,693\npreviously existing manually generated NL questions and 4,721 unique, novel,\nand complex SPARQL queries of varying complexity. In addition to the NL/SPARQL\npairs, we also provide their corresponding 166 knowledge graphs and ontologies,\nwhich cover 138 different domains. Our complex benchmark enables novel ways of\nevaluating the strengths and weaknesses of modern KGQA systems. We evaluate the\nsystem with state-of-the-art KGQA systems as well as LLMs, which achieve only\nup to 45\\% execution accuracy, demonstrating that Spider4SPARQL is a\nchallenging benchmark for future research.", "published": "2023-09-28 08:41:08", "link": "http://arxiv.org/abs/2309.16248v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Challenges of Fully Incremental Neural Dependency Parsing", "abstract": "Since the popularization of BiLSTMs and Transformer-based bidirectional\nencoders, state-of-the-art syntactic parsers have lacked incrementality,\nrequiring access to the whole sentence and deviating from human language\nprocessing. This paper explores whether fully incremental dependency parsing\nwith modern architectures can be competitive. We build parsers combining\nstrictly left-to-right neural encoders with fully incremental sequence-labeling\nand transition-based decoders. The results show that fully incremental parsing\nwith modern architectures considerably lags behind bidirectional parsing,\nnoting the challenges of psycholinguistically plausible parsing.", "published": "2023-09-28 08:44:08", "link": "http://arxiv.org/abs/2309.16254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Social Media Fashion Knowledge Extraction as Captioning", "abstract": "Social media plays a significant role in boosting the fashion industry, where\na massive amount of fashion-related posts are generated every day. In order to\nobtain the rich fashion information from the posts, we study the task of social\nmedia fashion knowledge extraction. Fashion knowledge, which typically consists\nof the occasion, person attributes, and fashion item information, can be\neffectively represented as a set of tuples. Most previous studies on fashion\nknowledge extraction are based on the fashion product images without\nconsidering the rich text information in social media posts. Existing work on\nfashion knowledge extraction in social media is classification-based and\nrequires to manually determine a set of fashion knowledge categories in\nadvance. In our work, we propose to cast the task as a captioning problem to\ncapture the interplay of the multimodal post information. Specifically, we\ntransform the fashion knowledge tuples into a natural language caption with a\nsentence transformation method. Our framework then aims to generate the\nsentence-based fashion knowledge directly from the social media post. Inspired\nby the big success of pre-trained models, we build our model based on a\nmultimodal pre-trained generative model and design several auxiliary tasks for\nenhancing the knowledge extraction. Since there is no existing dataset which\ncan be directly borrowed to our task, we introduce a dataset consisting of\nsocial media posts with manual fashion knowledge annotation. Extensive\nexperiments are conducted to demonstrate the effectiveness of our model.", "published": "2023-09-28 09:07:48", "link": "http://arxiv.org/abs/2309.16270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "At Which Training Stage Does Code Data Help LLMs Reasoning?", "abstract": "Large Language Models (LLMs) have exhibited remarkable reasoning capabilities\nand become the foundation of language technologies. Inspired by the great\nsuccess of code data in training LLMs, we naturally wonder at which training\nstage introducing code data can really help LLMs reasoning. To this end, this\npaper systematically explores the impact of code data on LLMs at different\nstages. Concretely, we introduce the code data at the pre-training stage,\ninstruction-tuning stage, and both of them, respectively. Then, the reasoning\ncapability of LLMs is comprehensively and fairly evaluated via six reasoning\ntasks in five domains. We critically analyze the experimental results and\nprovide conclusions with insights. First, pre-training LLMs with the mixture of\ncode and text can significantly enhance LLMs' general reasoning capability\nalmost without negative transfer on other tasks. Besides, at the\ninstruction-tuning stage, code data endows LLMs the task-specific reasoning\ncapability. Moreover, the dynamic mixing strategy of code and text data assists\nLLMs to learn reasoning capability step-by-step during training. These insights\ndeepen the understanding of LLMs regarding reasoning ability for their\napplication, such as scientific question answering, legal support, etc. The\nsource code and model parameters are released at the\nlink:~\\url{https://github.com/yingweima2022/CodeLLM}.", "published": "2023-09-28 09:50:27", "link": "http://arxiv.org/abs/2309.16298v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human Feedback is not Gold Standard", "abstract": "Human feedback has become the de facto standard for evaluating the\nperformance of Large Language Models, and is increasingly being used as a\ntraining objective. However, it is not clear which properties of a generated\noutput this single `preference' score captures. We hypothesise that preference\nscores are subjective and open to undesirable biases. We critically analyse the\nuse of human feedback for both training and evaluation, to verify whether it\nfully captures a range of crucial error criteria. We find that while preference\nscores have fairly good coverage, they under-represent important aspects like\nfactuality. We further hypothesise that both preference scores and error\nannotation may be affected by confounders, and leverage instruction-tuned\nmodels to generate outputs that vary along two possible confounding dimensions:\nassertiveness and complexity. We find that the assertiveness of an output skews\nthe perceived rate of factuality errors, indicating that human annotations are\nnot a fully reliable evaluation metric or training objective. Finally, we offer\npreliminary evidence that using human feedback as a training objective\ndisproportionately increases the assertiveness of model outputs. We encourage\nfuture work to carefully consider whether preference scores are well aligned\nwith the desired objective.", "published": "2023-09-28 11:18:20", "link": "http://arxiv.org/abs/2309.16349v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Document-level Relation Extraction (2016-2023)", "abstract": "Document-level relation extraction (DocRE) is an active area of research in\nnatural language processing (NLP) concerned with identifying and extracting\nrelationships between entities beyond sentence boundaries. Compared to the more\ntraditional sentence-level relation extraction, DocRE provides a broader\ncontext for analysis and is more challenging because it involves identifying\nrelationships that may span multiple sentences or paragraphs. This task has\ngained increased interest as a viable solution to build and populate knowledge\nbases automatically from unstructured large-scale documents (e.g., scientific\npapers, legal contracts, or news articles), in order to have a better\nunderstanding of relationships between entities. This paper aims to provide a\ncomprehensive overview of recent advances in this field, highlighting its\ndifferent applications in comparison to sentence-level relation extraction.", "published": "2023-09-28 12:43:32", "link": "http://arxiv.org/abs/2309.16396v3", "categories": ["cs.CL", "A.1"], "primary_category": "cs.CL"}
{"title": "A Benchmark for Learning to Translate a New Language from One Grammar\n  Book", "abstract": "Large language models (LLMs) can perform impressive feats with in-context\nlearning or lightweight finetuning. It is natural to wonder how well these\nmodels adapt to genuinely new tasks, but how does one find tasks that are\nunseen in internet-scale training sets? We turn to a field that is explicitly\nmotivated and bottlenecked by a scarcity of web data: low-resource languages.\nIn this paper, we introduce MTOB (Machine Translation from One Book), a\nbenchmark for learning to translate between English and Kalamang -- a language\nwith less than 200 speakers and therefore virtually no presence on the web --\nusing several hundred pages of field linguistics reference materials. This task\nframing is novel in that it asks a model to learn a language from a single\nhuman-readable book of grammar explanations, rather than a large mined corpus\nof in-domain data, more akin to L2 learning than L1 acquisition. We demonstrate\nthat baselines using current LLMs are promising but fall short of human\nperformance, achieving 44.7 chrF on Kalamang to English translation and 45.8\nchrF on English to Kalamang translation, compared to 51.6 and 57.0 chrF by a\nhuman who learned Kalamang from the same reference materials. We hope that MTOB\nwill help measure LLM capabilities along a new dimension, and that the methods\ndeveloped to solve it could help expand access to language technology for\nunderserved communities by leveraging qualitatively different kinds of data\nthan traditional machine translation.", "published": "2023-09-28 16:32:28", "link": "http://arxiv.org/abs/2309.16575v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GPT-Fathom: Benchmarking Large Language Models to Decipher the\n  Evolutionary Path towards GPT-4 and Beyond", "abstract": "With the rapid advancement of large language models (LLMs), there is a\npressing need for a comprehensive evaluation suite to assess their capabilities\nand limitations. Existing LLM leaderboards often reference scores reported in\nother papers without consistent settings and prompts, which may inadvertently\nencourage cherry-picking favored settings and prompts for better results. In\nthis work, we introduce GPT-Fathom, an open-source and reproducible LLM\nevaluation suite built on top of OpenAI Evals. We systematically evaluate 10+\nleading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across\n7 capability categories, all under aligned settings. Our retrospective study on\nOpenAI's earlier models offers valuable insights into the evolutionary path\nfrom GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3\nprogressively improves to GPT-4, including technical details like whether\nadding code data improves LLM's reasoning capability, which aspects of LLM\ncapability can be improved by SFT and RLHF, how much is the alignment tax, etc.\nOur analysis sheds light on many of these questions, aiming to improve the\ntransparency of advanced LLMs.", "published": "2023-09-28 16:43:35", "link": "http://arxiv.org/abs/2309.16583v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot\n  Translation", "abstract": "Zero-shot translation (ZST), which is generally based on a multilingual\nneural machine translation model, aims to translate between unseen language\npairs in training data. The common practice to guide the zero-shot language\nmapping during inference is to deliberately insert the source and target\nlanguage IDs, e.g., <EN> for English and <DE> for German. Recent studies have\nshown that language IDs sometimes fail to navigate the ZST task, making them\nsuffer from the off-target problem (non-target language words exist in the\ngenerated translation) and, therefore, difficult to apply the current\nmultilingual translation model to a broad range of zero-shot language\nscenarios. To understand when and why the navigation capabilities of language\nIDs are weakened, we compare two extreme decoder input cases in the ZST\ndirections: Off-Target (OFF) and On-Target (ON) cases. By contrastively\nvisualizing the contextual word representations (CWRs) of these cases with\nteacher forcing, we show that 1) the CWRs of different languages are\neffectively distributed in separate regions when the sentence and ID are\nmatched (ON setting), and 2) if the sentence and ID are unmatched (OFF\nsetting), the CWRs of different languages are chaotically distributed. Our\nanalyses suggest that although they work well in ideal ON settings, language\nIDs become fragile and lose their navigation ability when faced with off-target\ntokens, which commonly exist during inference but are rare in training\nscenarios. In response, we employ unlikelihood tuning on the negative (OFF)\nsamples to minimize their probability such that the language IDs can\ndiscriminate between the on- and off-target tokens during training. Experiments\nspanning 40 ZST directions show that our method reduces the off-target ratio by\n-48.0% on average, leading to a +9.1 BLEU improvement with only an extra +0.3%\ntuning cost.", "published": "2023-09-28 17:02:36", "link": "http://arxiv.org/abs/2309.16599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Qwen Technical Report", "abstract": "Large language models (LLMs) have revolutionized the field of artificial\nintelligence, enabling natural language processing tasks that were previously\nthought to be exclusive to humans. In this work, we introduce Qwen, the first\ninstallment of our large language model series. Qwen is a comprehensive\nlanguage model series that encompasses distinct models with varying parameter\ncounts. It includes Qwen, the base pretrained language models, and Qwen-Chat,\nthe chat models finetuned with human alignment techniques. The base language\nmodels consistently demonstrate superior performance across a multitude of\ndownstream tasks, and the chat models, particularly those trained using\nReinforcement Learning from Human Feedback (RLHF), are highly competitive. The\nchat models possess advanced tool-use and planning capabilities for creating\nagent applications, showcasing impressive performance even when compared to\nbigger models on complex tasks like utilizing a code interpreter. Furthermore,\nwe have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as\nwell as mathematics-focused models, Math-Qwen-Chat, which are built upon base\nlanguage models. These models demonstrate significantly improved performance in\ncomparison with open-source models, and slightly fall behind the proprietary\nmodels.", "published": "2023-09-28 17:07:49", "link": "http://arxiv.org/abs/2309.16609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Curriculum-Driven Edubot: A Framework for Developing Language Learning\n  Chatbots Through Synthesizing Conversational Data", "abstract": "Chatbots have become popular in educational settings, revolutionizing how\nstudents interact with material and how teachers teach. We present\nCurriculum-Driven EduBot, a framework for developing a chatbot that combines\nthe interactive features of chatbots with the systematic material of English\ntextbooks to assist students in enhancing their conversational skills. We begin\nby extracting pertinent topics from textbooks and using large language models\nto generate dialogues related to these topics. We then fine-tune an open-source\nmodel using our generated conversational data to create our curriculum-driven\nchatbot. User studies demonstrate that EduBot outperforms ChatGPT in leading\ncurriculum-based dialogues and adapting its dialogue to match the user's\nEnglish proficiency level. By combining traditional textbook methodologies with\nconversational AI, our approach offers learners an interactive tool that aligns\nwith their curriculum and provides user-tailored conversation practice. This\nfacilitates meaningful student-bot dialogues and enriches the overall learning\nexperience within the curriculum's pedagogical framework.", "published": "2023-09-28 19:14:18", "link": "http://arxiv.org/abs/2309.16804v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DeBERTinha: A Multistep Approach to Adapt DebertaV3 XSmall for Brazilian\n  Portuguese Natural Language Processing Task", "abstract": "This paper presents an approach for adapting the DebertaV3 XSmall model\npre-trained in English for Brazilian Portuguese natural language processing\n(NLP) tasks. A key aspect of the methodology involves a multistep training\nprocess to ensure the model is effectively tuned for the Portuguese language.\nInitial datasets from Carolina and BrWac are preprocessed to address issues\nlike emojis, HTML tags, and encodings. A Portuguese-specific vocabulary of\n50,000 tokens is created using SentencePiece. Rather than training from\nscratch, the weights of the pre-trained English model are used to initialize\nmost of the network, with random embeddings, recognizing the expensive cost of\ntraining from scratch. The model is fine-tuned using the replaced token\ndetection task in the same format of DebertaV3 training. The adapted model,\ncalled DeBERTinha, demonstrates effectiveness on downstream tasks like named\nentity recognition, sentiment analysis, and determining sentence relatedness,\noutperforming BERTimbau-Large in two tasks despite having only 40M parameters.", "published": "2023-09-28 20:53:25", "link": "http://arxiv.org/abs/2309.16844v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forgetting Private Textual Sequences in Language Models via\n  Leave-One-Out Ensemble", "abstract": "Recent research has shown that language models have a tendency to memorize\nrare or unique token sequences in the training corpus. After deploying a model,\npractitioners might be asked to delete any personal information from the model\nby individuals' requests. Re-training the underlying model every time\nindividuals would like to practice their rights to be forgotten is\ncomputationally expensive. We employ a teacher-student framework and propose a\nnovel leave-one-out ensemble method to unlearn the targeted textual sequences\nthat need to be forgotten from the model. In our approach, multiple teachers\nare trained on disjoint sets; for each targeted sequence to be removed, we\nexclude the teacher trained on the set containing this sequence and aggregate\nthe predictions from remaining teachers to provide supervision during\nfine-tuning. Experiments on LibriSpeech and WikiText-103 datasets show that the\nproposed method achieves superior privacy-utility trade-offs than other\ncounterparts.", "published": "2023-09-28 00:43:18", "link": "http://arxiv.org/abs/2309.16082v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TPE: Towards Better Compositional Reasoning over Conceptual Tools with\n  Multi-persona Collaboration", "abstract": "Large language models (LLMs) have demonstrated exceptional performance in\nplanning the use of various functional tools, such as calculators and\nretrievers, particularly in question-answering tasks. In this paper, we expand\nthe definition of these tools, centering on conceptual tools within the context\nof dialogue systems. A conceptual tool specifies a cognitive concept that aids\nsystematic or investigative thought. These conceptual tools play important\nroles in practice, such as multiple psychological or tutoring strategies being\ndynamically applied in a single turn to compose helpful responses. To further\nenhance the reasoning and planning capability of LLMs with these conceptual\ntools, we introduce a multi-persona collaboration framework: Think-Plan-Execute\n(TPE). This framework decouples the response generation process into three\ndistinct roles: Thinker, Planner, and Executor. Specifically, the Thinker\nanalyzes the internal status exhibited in the dialogue context, such as user\nemotions and preferences, to formulate a global guideline. The Planner then\ngenerates executable plans to call different conceptual tools (e.g., sources or\nstrategies), while the Executor compiles all intermediate results into a\ncoherent response. This structured approach not only enhances the\nexplainability and controllability of responses but also reduces token\nredundancy. We demonstrate the effectiveness of TPE across various dialogue\nresponse generation tasks, including multi-source (FoCus) and multi-strategy\ninteractions (CIMA and PsyQA). This reveals its potential to handle real-world\ndialogue interactions that require more complicated tool learning beyond just\nfunctional tools. The full code and data will be released for reproduction.", "published": "2023-09-28 01:18:53", "link": "http://arxiv.org/abs/2309.16090v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "AE-GPT: Using Large Language Models to Extract Adverse Events from\n  Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events", "abstract": "Though Vaccines are instrumental in global health, mitigating infectious\ndiseases and pandemic outbreaks, they can occasionally lead to adverse events\n(AEs). Recently, Large Language Models (LLMs) have shown promise in effectively\nidentifying and cataloging AEs within clinical reports. Utilizing data from the\nVaccine Adverse Event Reporting System (VAERS) from 1990 to 2016, this study\nparticularly focuses on AEs to evaluate LLMs' capability for AE extraction. A\nvariety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-4, and Llama 2,\nwere evaluated using Influenza vaccine as a use case. The fine-tuned GPT 3.5\nmodel (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match\nand 0.816 for relaxed match. The encouraging performance of the AE-GPT\nunderscores LLMs' potential in processing medical data, indicating a\nsignificant stride towards advanced AE detection, thus presumably generalizable\nto other AE extraction tasks.", "published": "2023-09-28 03:53:21", "link": "http://arxiv.org/abs/2309.16150v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Trickle-down Impact of Reward (In-)consistency on RLHF", "abstract": "Standard practice within Reinforcement Learning from Human Feedback (RLHF)\ninvolves optimizing against a Reward Model (RM), which itself is trained to\nreflect human preferences for desirable generations. A notable subject that is\nunderstudied is the (in-)consistency of RMs -- whether they can recognize the\nsemantic changes to different prompts and appropriately adapt their reward\nassignments -- and their impact on the downstream RLHF model.\n  In this paper, we visit a series of research questions relevant to RM\ninconsistency: (1) How can we measure the consistency of reward models? (2) How\nconsistent are the existing RMs and how can we improve them? (3) In what ways\ndoes reward inconsistency influence the chatbots resulting from the RLHF model\ntraining?\n  We propose Contrast Instructions -- a benchmarking strategy for the\nconsistency of RM. Each example in Contrast Instructions features a pair of\nlexically similar instructions with different ground truth responses. A\nconsistent RM is expected to rank the corresponding instruction and response\nhigher than other combinations. We observe that current RMs trained with the\nstandard ranking objective fail miserably on Contrast Instructions compared to\naverage humans. To show that RM consistency can be improved efficiently without\nusing extra training budget, we propose two techniques ConvexDA and\nRewardFusion, which enhance reward consistency through extrapolation during the\nRM training and inference stage, respectively. We show that RLHF models trained\nwith a more consistent RM yield more useful responses, suggesting that reward\ninconsistency exhibits a trickle-down effect on the downstream RLHF process.", "published": "2023-09-28 04:05:13", "link": "http://arxiv.org/abs/2309.16155v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using Weak Supervision and Data Augmentation in Question Answering", "abstract": "The onset of the COVID-19 pandemic accentuated the need for access to\nbiomedical literature to answer timely and disease-specific questions. During\nthe early days of the pandemic, one of the biggest challenges we faced was the\nlack of peer-reviewed biomedical articles on COVID-19 that could be used to\ntrain machine learning models for question answering (QA). In this paper, we\nexplore the roles weak supervision and data augmentation play in training deep\nneural network QA models. First, we investigate whether labels generated\nautomatically from the structured abstracts of scholarly papers using an\ninformation retrieval algorithm, BM25, provide a weak supervision signal to\ntrain an extractive QA model. We also curate new QA pairs using information\nretrieval techniques, guided by the clinicaltrials.gov schema and the\nstructured abstracts of articles, in the absence of annotated data from\nbiomedical domain experts. Furthermore, we explore augmenting the training data\nof a deep neural network model with linguistic features from external sources\nsuch as lexical databases to account for variations in word morphology and\nmeaning. To better utilize our training data, we apply curriculum learning to\ndomain adaptation, fine-tuning our QA model in stages based on characteristics\nof the QA pairs. We evaluate our methods in the context of QA models at the\ncore of a system to answer questions about COVID-19.", "published": "2023-09-28 05:16:51", "link": "http://arxiv.org/abs/2309.16175v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UPB @ ACTI: Detecting Conspiracies using fine tuned Sentence\n  Transformers", "abstract": "Conspiracy theories have become a prominent and concerning aspect of online\ndiscourse, posing challenges to information integrity and societal trust. As\nsuch, we address conspiracy theory detection as proposed by the ACTI @ EVALITA\n2023 shared task. The combination of pre-trained sentence Transformer models\nand data augmentation techniques enabled us to secure first place in the final\nleaderboard of both sub-tasks. Our methodology attained F1 scores of 85.71% in\nthe binary classification and 91.23% for the fine-grained conspiracy topic\nclassification, surpassing other competing systems.", "published": "2023-09-28 09:17:20", "link": "http://arxiv.org/abs/2309.16275v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Self-supervised Cross-view Representation Reconstruction for Change\n  Captioning", "abstract": "Change captioning aims to describe the difference between a pair of similar\nimages. Its key challenge is how to learn a stable difference representation\nunder pseudo changes caused by viewpoint change. In this paper, we address this\nby proposing a self-supervised cross-view representation reconstruction\n(SCORER) network. Concretely, we first design a multi-head token-wise matching\nto model relationships between cross-view features from similar/dissimilar\nimages. Then, by maximizing cross-view contrastive alignment of two similar\nimages, SCORER learns two view-invariant image representations in a\nself-supervised way. Based on these, we reconstruct the representations of\nunchanged objects by cross-attention, thus learning a stable difference\nrepresentation for caption generation. Further, we devise a cross-modal\nbackward reasoning to improve the quality of caption. This module reversely\nmodels a ``hallucination'' representation with the caption and ``before''\nrepresentation. By pushing it closer to the ``after'' representation, we\nenforce the caption to be informative about the difference in a self-supervised\nmanner. Extensive experiments show our method achieves the state-of-the-art\nresults on four datasets. The code is available at\nhttps://github.com/tuyunbin/SCORER.", "published": "2023-09-28 09:28:50", "link": "http://arxiv.org/abs/2309.16283v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large\n  Language Models", "abstract": "Recent advancements in autonomous driving have relied on data-driven\napproaches, which are widely adopted but face challenges including dataset\nbias, overfitting, and uninterpretability. Drawing inspiration from the\nknowledge-driven nature of human driving, we explore the question of how to\ninstill similar capabilities into autonomous driving systems and summarize a\nparadigm that integrates an interactive environment, a driver agent, as well as\na memory component to address this question. Leveraging large language models\n(LLMs) with emergent abilities, we propose the DiLu framework, which combines a\nReasoning and a Reflection module to enable the system to perform\ndecision-making based on common-sense knowledge and evolve continuously.\nExtensive experiments prove DiLu's capability to accumulate experience and\ndemonstrate a significant advantage in generalization ability over\nreinforcement learning-based methods. Moreover, DiLu is able to directly\nacquire experiences from real-world datasets which highlights its potential to\nbe deployed on practical autonomous driving systems. To the best of our\nknowledge, we are the first to leverage knowledge-driven capability in\ndecision-making for autonomous vehicles. Through the proposed DiLu framework,\nLLM is strengthened to apply knowledge and to reason causally in the autonomous\ndriving domain. Project page: https://pjlab-adg.github.io/DiLu/", "published": "2023-09-28 09:41:35", "link": "http://arxiv.org/abs/2309.16292v3", "categories": ["cs.RO", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Augmenting Transformers with Recursively Composed Multi-grained\n  Representations", "abstract": "We present ReCAT, a recursive composition augmented Transformer that is able\nto explicitly model hierarchical syntactic structures of raw texts without\nrelying on gold trees during both learning and inference. Existing research\nalong this line restricts data to follow a hierarchical tree structure and thus\nlacks inter-span communications. To overcome the problem, we propose a novel\ncontextual inside-outside (CIO) layer that learns contextualized\nrepresentations of spans through bottom-up and top-down passes, where a\nbottom-up pass forms representations of high-level spans by composing low-level\nspans, while a top-down pass combines information inside and outside a span. By\nstacking several CIO layers between the embedding layer and the attention\nlayers in Transformer, the ReCAT model can perform both deep intra-span and\ndeep inter-span interactions, and thus generate multi-grained representations\nfully contextualized with other spans. Moreover, the CIO layers can be jointly\npre-trained with Transformers, making ReCAT enjoy scaling ability, strong\nperformance, and interpretability at the same time. We conduct experiments on\nvarious sentence-level and span-level tasks. Evaluation results indicate that\nReCAT can significantly outperform vanilla Transformer models on all span-level\ntasks and baselines that combine recursive networks with Transformers on\nnatural language inference tasks. More interestingly, the hierarchical\nstructures induced by ReCAT exhibit strong consistency with human-annotated\nsyntactic trees, indicating good interpretability brought by the CIO layers.", "published": "2023-09-28 10:24:39", "link": "http://arxiv.org/abs/2309.16319v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "KLoB: a Benchmark for Assessing Knowledge Locating Methods in Language\n  Models", "abstract": "Recently, Locate-Then-Edit paradigm has emerged as one of the main approaches\nin changing factual knowledge stored in the Language models. However, there is\na lack of research on whether present locating methods can pinpoint the exact\nparameters embedding the desired knowledge. Moreover, although many researchers\nhave questioned the validity of locality hypothesis of factual knowledge, no\nmethod is provided to test the a hypothesis for more in-depth discussion and\nresearch. Therefore, we introduce KLoB, a benchmark examining three essential\nproperties that a reliable knowledge locating method should satisfy. KLoB can\nserve as a benchmark for evaluating existing locating methods in language\nmodels, and can contributes a method to reassessing the validity of locality\nhypothesis of factual knowledge. KLoB is publicly available at an anonymous\nGitHub: \\url{https://github.com/anon6662/KLoB}.", "published": "2023-09-28 15:47:03", "link": "http://arxiv.org/abs/2309.16535v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Stress Testing Chain-of-Thought Prompting for Large Language Models", "abstract": "This report examines the effectiveness of Chain-of-Thought (CoT) prompting in\nimproving the multi-step reasoning abilities of large language models (LLMs).\nInspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the\nimpact of three types of CoT prompt perturbations, namely CoT order, CoT\nvalues, and CoT operators on the performance of GPT-3 on various tasks. Our\nfindings show that incorrect CoT prompting leads to poor performance on\naccuracy metrics. Correct values in the CoT is crucial for predicting correct\nanswers. Moreover, incorrect demonstrations, where the CoT operators or the CoT\norder are wrong, do not affect the performance as drastically when compared to\nthe value based perturbations. This research deepens our understanding of CoT\nprompting and opens some new questions regarding the capability of LLMs to\nlearn reasoning in context.", "published": "2023-09-28 17:21:33", "link": "http://arxiv.org/abs/2309.16621v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Demystifying CLIP Data", "abstract": "Contrastive Language-Image Pre-training (CLIP) is an approach that has\nadvanced research and applications in computer vision, fueling modern\nrecognition systems and generative models. We believe that the main ingredient\nto the success of CLIP is its data and not the model architecture or\npre-training objective. However, CLIP only provides very limited information\nabout its data and how it has been collected, leading to works that aim to\nreproduce CLIP's data by filtering with its model parameters. In this work, we\nintend to reveal CLIP's data curation approach and in our pursuit of making it\nopen to the community introduce Metadata-Curated Language-Image Pre-training\n(MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's\nconcepts) and yields a balanced subset over the metadata distribution. Our\nexperimental study rigorously isolates the model and training settings,\nconcentrating solely on data. MetaCLIP applied to CommonCrawl with 400M\nimage-text data pairs outperforms CLIP's data on multiple standard benchmarks.\nIn zero-shot ImageNet classification, MetaCLIP achieves 70.8% accuracy,\nsurpassing CLIP's 68.3% on ViT-B models. Scaling to 1B data, while maintaining\nthe same training budget, attains 72.4%. Our observations hold across various\nmodel sizes, exemplified by ViT-H achieving 80.5%, without any\nbells-and-whistles. Curation code and training data distribution on metadata is\nmade available at https://github.com/facebookresearch/MetaCLIP.", "published": "2023-09-28 17:59:56", "link": "http://arxiv.org/abs/2309.16671v5", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "How many words does ChatGPT know? The answer is ChatWords", "abstract": "The introduction of ChatGPT has put Artificial Intelligence (AI) Natural\nLanguage Processing (NLP) in the spotlight. ChatGPT adoption has been\nexponential with millions of users experimenting with it in a myriad of tasks\nand application domains with impressive results. However, ChatGPT has\nlimitations and suffers hallucinations, for example producing answers that look\nplausible but they are completely wrong. Evaluating the performance of ChatGPT\nand similar AI tools is a complex issue that is being explored from different\nperspectives. In this work, we contribute to those efforts with ChatWords, an\nautomated test system, to evaluate ChatGPT knowledge of an arbitrary set of\nwords. ChatWords is designed to be extensible, easy to use, and adaptable to\nevaluate also other NLP AI tools. ChatWords is publicly available and its main\ngoal is to facilitate research on the lexical knowledge of AI tools. The\nbenefits of ChatWords are illustrated with two case studies: evaluating the\nknowledge that ChatGPT has of the Spanish lexicon (taken from the official\ndictionary of the \"Real Academia Espa\\~nola\") and of the words that appear in\nthe Quixote, the well-known novel written by Miguel de Cervantes. The results\nshow that ChatGPT is only able to recognize approximately 80% of the words in\nthe dictionary and 90% of the words in the Quixote, in some cases with an\nincorrect meaning. The implications of the lexical knowledge of NLP AI tools\nand potential applications of ChatWords are also discussed providing directions\nfor further work on the study of the lexical knowledge of AI tools.", "published": "2023-09-28 18:13:02", "link": "http://arxiv.org/abs/2309.16777v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Attention Sorting Combats Recency Bias In Long Context Language Models", "abstract": "Current language models often fail to incorporate long contexts efficiently\nduring generation. We show that a major contributor to this issue are attention\npriors that are likely learned during pre-training: relevant information\nlocated earlier in context is attended to less on average. Yet even when models\nfail to use the information from a relevant document in their response, they\nstill pay preferential attention to that document compared to an irrelevant\ndocument at the same position. We leverage this fact to introduce ``attention\nsorting'': perform one step of decoding, sort documents by the attention they\nreceive (highest attention going last), repeat the process, generate the answer\nwith the newly sorted context. We find that attention sorting improves\nperformance of long context models. Our findings highlight some challenges in\nusing off-the-shelf language models for retrieval augmented generation.", "published": "2023-09-28 05:19:06", "link": "http://arxiv.org/abs/2310.01427v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Chatmap : Large Language Model Interaction with Cartographic Data", "abstract": "The swift advancement and widespread availability of foundational Large\nLanguage Models (LLMs), complemented by robust fine-tuning methodologies, have\ncatalyzed their adaptation for innovative and industrious applications.\nEnabling LLMs to recognize and interpret geospatial data, while offering a\nlinguistic access to vast cartographic datasets, is of significant importance.\nOpenStreetMap (OSM) is the most ambitious open-source global initiative\noffering detailed urban and rural geographic data, curated by a community of\nover 10 million contributors, which constitutes a great potential for LLM\napplications. In this study, we demonstrate the proof of concept and details of\nthe process of fine-tuning a relatively small scale (1B parameters) LLM with a\nrelatively small artificial dataset curated by a more capable teacher model, in\norder to provide a linguistic interface to the OSM data of an arbitrary urban\nregion. Through this interface, users can inquire about a location's\nattributes, covering a wide spectrum of concepts, such as its touristic appeal\nor the potential profitability of various businesses in that vicinity. The\nstudy aims to provide an initial guideline for such generative artificial\nintelligence (AI) adaptations and demonstrate early signs of useful emerging\nabilities in this context even in minimal computational settings. The\nembeddings of artificially curated prompts including OSM data are also\ninvestigated in detail, which might be instrumental for potential geospatially\naware urban Retrieval Augmented Generation (RAG) applications.", "published": "2023-09-28 15:32:36", "link": "http://arxiv.org/abs/2310.01429v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Confidence-Competence Gap in Large Language Models: A Cognitive\n  Study", "abstract": "Large Language Models (LLMs) have acquired ubiquitous attention for their\nperformances across diverse domains. Our study here searches through LLMs'\ncognitive abilities and confidence dynamics. We dive deep into understanding\nthe alignment between their self-assessed confidence and actual performance. We\nexploit these models with diverse sets of questionnaires and real-world\nscenarios and extract how LLMs exhibit confidence in their responses. Our\nfindings reveal intriguing instances where models demonstrate high confidence\neven when they answer incorrectly. This is reminiscent of the Dunning-Kruger\neffect observed in human psychology. In contrast, there are cases where models\nexhibit low confidence with correct answers revealing potential underestimation\nbiases. Our results underscore the need for a deeper understanding of their\ncognitive processes. By examining the nuances of LLMs' self-assessment\nmechanism, this investigation provides noteworthy revelations that serve to\nadvance the functionalities and broaden the potential applications of these\nformidable language models.", "published": "2023-09-28 03:50:09", "link": "http://arxiv.org/abs/2309.16145v1", "categories": ["cs.CL", "cs.CY", "cs.HC", "ACM-class: I.2.0"], "primary_category": "cs.CL"}
{"title": "Brand Network Booster: A new system for improving brand connectivity", "abstract": "This paper presents a new decision support system offered for an in-depth\nanalysis of semantic networks, which can provide insights for a better\nexploration of a brand's image and the improvement of its connectivity. In\nterms of network analysis, we show that this goal is achieved by solving an\nextended version of the Maximum Betweenness Improvement problem, which includes\nthe possibility of considering adversarial nodes, constrained budgets, and\nweighted networks - where connectivity improvement can be obtained by adding\nlinks or increasing the weight of existing connections. Our contribution\nincludes a new algorithmic framework and the integration of this framework into\na software system called Brand Network Booster (BNB), which supports brand\nconnectivity evaluation and improvement. We present this new system together\nwith three case studies, and we also discuss its performance. Our tool and\napproach are valuable to both network scholars and in facilitating strategic\ndecision-making processes for marketing and communication managers across\nvarious sectors, be it public or private.", "published": "2023-09-28 08:09:33", "link": "http://arxiv.org/abs/2309.16228v2", "categories": ["cs.SI", "cs.CL", "cs.SE", "physics.soc-ph", "F.2; H.4; H.5; I.2; D.2"], "primary_category": "cs.SI"}
{"title": "LawBench: Benchmarking Legal Knowledge of Large Language Models", "abstract": "Large language models (LLMs) have demonstrated strong capabilities in various\naspects. However, when applying them to the highly specialized, safe-critical\nlegal domain, it is unclear how much legal knowledge they possess and whether\nthey can reliably perform legal-related tasks. To address this gap, we propose\na comprehensive evaluation benchmark LawBench. LawBench has been meticulously\ncrafted to have precise assessment of the LLMs' legal capabilities from three\ncognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize\nneeded legal concepts, articles and facts; (2) Legal knowledge understanding:\nwhether LLMs can comprehend entities, events and relationships within legal\ntext; (3) Legal knowledge applying: whether LLMs can properly utilize their\nlegal knowledge and make necessary reasoning steps to solve realistic legal\ntasks. LawBench contains 20 diverse tasks covering 5 task types: single-label\nclassification (SLC), multi-label classification (MLC), regression, extraction\nand generation. We perform extensive evaluations of 51 LLMs on LawBench,\nincluding 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific\nLLMs. The results show that GPT-4 remains the best-performing LLM in the legal\ndomain, surpassing the others by a significant margin. While fine-tuning LLMs\non legal specific text brings certain improvements, we are still a long way\nfrom obtaining usable and reliable LLMs in legal tasks. All data, model\npredictions and evaluation code are released in\nhttps://github.com/open-compass/LawBench/. We hope this benchmark provides\nin-depth understanding of the LLMs' domain-specified capabilities and speed up\nthe development of LLMs in the legal domain.", "published": "2023-09-28 09:35:59", "link": "http://arxiv.org/abs/2309.16289v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic\n  Manipulation Tasks", "abstract": "Current reinforcement learning algorithms struggle in sparse and complex\nenvironments, most notably in long-horizon manipulation tasks entailing a\nplethora of different sequences. In this work, we propose the Intrinsically\nGuided Exploration from Large Language Models (IGE-LLMs) framework. By\nleveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the\nexploratory process in reinforcement learning to address intricate long-horizon\nwith sparse rewards robotic manipulation tasks. We evaluate our framework and\nrelated intrinsic learning methods in an environment challenged with\nexploration, and a complex robotic manipulation task challenged by both\nexploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher\nperformance over related intrinsic methods and the direct use of LLMs in\ndecision-making, (ii) can be combined and complement existing learning methods\nhighlighting its modularity, (iii) are fairly insensitive to different\nintrinsic scaling parameters, and (iv) maintain robustness against increased\nlevels of uncertainty and horizons.", "published": "2023-09-28 11:14:52", "link": "http://arxiv.org/abs/2309.16347v2", "categories": ["cs.RO", "cs.CL", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Transformer-VQ: Linear-Time Transformers via Vector Quantization", "abstract": "We introduce Transformer-VQ, a decoder-only transformer computing\nsoftmax-based dense self-attention in linear time. Transformer-VQ's efficient\nattention is enabled by vector-quantized keys and a novel caching mechanism. In\nour large-scale experiments, Transformer-VQ is shown highly competitive in\nquality, obtaining 0.99 bpb on Enwik8, 26.6 ppl on PG-19, and 3.16 bpb on\nImageNet64. In addition, the optimized implementation of Transformer-VQ is over\n3x faster than a comparable quadratic-time transformer at sequence length 8k,\nis over 12x faster at 32k, and can scale to 131k with similar throughput. Code\navailable: \\url{https://github.com/transformer-vq/transformer_vq}", "published": "2023-09-28 11:26:52", "link": "http://arxiv.org/abs/2309.16354v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News\n  Detection", "abstract": "Despite considerable advances in automated fake news detection, due to the\ntimely nature of news, it remains a critical open question how to effectively\npredict the veracity of news articles based on limited fact-checks. Existing\napproaches typically follow a \"Train-from-Scratch\" paradigm, which is\nfundamentally bounded by the availability of large-scale annotated data. While\nexpressive pre-trained language models (PLMs) have been adapted in a\n\"Pre-Train-and-Fine-Tune\" manner, the inconsistency between pre-training and\ndownstream objectives also requires costly task-specific supervision. In this\npaper, we propose \"Prompt-and-Align\" (P&A), a novel prompt-based paradigm for\nfew-shot fake news detection that jointly leverages the pre-trained knowledge\nin PLMs and the social context topology. Our approach mitigates label scarcity\nby wrapping the news article in a task-related textual prompt, which is then\nprocessed by the PLM to directly elicit task-specific knowledge. To supplement\nthe PLM with social context without inducing additional training overheads,\nmotivated by empirical observation on user veracity consistency (i.e., social\nusers tend to consume news of the same veracity type), we further construct a\nnews proximity graph among news articles to capture the veracity-consistent\nsignals in shared readerships, and align the prompting predictions along the\ngraph edges in a confidence-informed manner. Extensive experiments on three\nreal-world benchmarks demonstrate that P&A sets new states-of-the-art for\nfew-shot fake news detection performance by significant margins.", "published": "2023-09-28 13:19:43", "link": "http://arxiv.org/abs/2309.16424v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Augmenting LLMs with Knowledge: A survey on hallucination prevention", "abstract": "Large pre-trained language models have demonstrated their proficiency in\nstoring factual knowledge within their parameters and achieving remarkable\nresults when fine-tuned for downstream natural language processing tasks.\nNonetheless, their capacity to access and manipulate knowledge with precision\nremains constrained, resulting in performance disparities on\nknowledge-intensive tasks when compared to task-specific architectures.\nAdditionally, the challenges of providing provenance for model decisions and\nmaintaining up-to-date world knowledge persist as open research frontiers. To\naddress these limitations, the integration of pre-trained models with\ndifferentiable access mechanisms to explicit non-parametric memory emerges as a\npromising solution. This survey delves into the realm of language models (LMs)\naugmented with the ability to tap into external knowledge sources, including\nexternal knowledge bases and search engines. While adhering to the standard\nobjective of predicting missing tokens, these augmented LMs leverage diverse,\npossibly non-parametric external modules to augment their contextual processing\ncapabilities, departing from the conventional language modeling paradigm.\nThrough an exploration of current advancements in augmenting large language\nmodels with knowledge, this work concludes that this emerging research\ndirection holds the potential to address prevalent issues in traditional LMs,\nsuch as hallucinations, un-grounded responses, and scalability challenges.", "published": "2023-09-28 14:09:58", "link": "http://arxiv.org/abs/2309.16459v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toloka Visual Question Answering Benchmark", "abstract": "In this paper, we present Toloka Visual Question Answering, a new\ncrowdsourced dataset allowing comparing performance of machine learning systems\nagainst human level of expertise in the grounding visual question answering\ntask. In this task, given an image and a textual question, one has to draw the\nbounding box around the object correctly responding to that question. Every\nimage-question pair contains the response, with only one correct response per\nimage. Our dataset contains 45,199 pairs of images and questions in English,\nprovided with ground truth bounding boxes, split into train and two test\nsubsets. Besides describing the dataset and releasing it under a CC BY license,\nwe conducted a series of experiments on open source zero-shot baseline models\nand organized a multi-phase competition at WSDM Cup that attracted 48\nparticipants worldwide. However, by the time of paper submission, no machine\nlearning model outperformed the non-expert crowdsourcing baseline according to\nthe intersection over union evaluation score.", "published": "2023-09-28 15:18:35", "link": "http://arxiv.org/abs/2309.16511v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC", "68-11", "C.4"], "primary_category": "cs.CV"}
{"title": "Unsupervised Pretraining for Fact Verification by Language Model\n  Distillation", "abstract": "Fact verification aims to verify a claim using evidence from a trustworthy\nknowledge base. To address this challenge, algorithms must produce features for\nevery claim that are both semantically meaningful, and compact enough to find a\nsemantic alignment with the source information. In contrast to previous work,\nwhich tackled the alignment problem by learning over annotated corpora of\nclaims and their corresponding labels, we propose SFAVEL (Self-supervised Fact\nVerification via Language Model Distillation), a novel unsupervised pretraining\nframework that leverages pre-trained language models to distil self-supervised\nfeatures into high-quality claim-fact alignments without the need for\nannotations. This is enabled by a novel contrastive loss function that\nencourages features to attain high-quality claim and evidence alignments whilst\npreserving the semantic relationships across the corpora. Notably, we present\nresults that achieve a new state-of-the-art on FB15k-237 (+5.3% Hits@1) and\nFEVER (+8% accuracy) with linear evaluation.", "published": "2023-09-28 15:53:44", "link": "http://arxiv.org/abs/2309.16540v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Language Models as a Service: Overview of a New Paradigm and its\n  Challenges", "abstract": "Some of the most powerful language models currently are proprietary systems,\naccessible only via (typically restrictive) web or software programming\ninterfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm. In\ncontrast with scenarios where full model access is available, as in the case of\nopen-source models, such closed-off language models present specific challenges\nfor evaluating, benchmarking, and testing them. This paper has two goals: on\nthe one hand, we delineate how the aforementioned challenges act as impediments\nto the accessibility, replicability, reliability, and trustworthiness of LMaaS.\nWe systematically examine the issues that arise from a lack of information\nabout language models for each of these four aspects. We conduct a detailed\nanalysis of existing solutions and put forth a number of considered\nrecommendations, and highlight the directions for future advancements. On the\nother hand, it serves as a comprehensive resource for existing knowledge on\ncurrent, major LMaaS, offering a synthesized overview of the licences and\ncapabilities their interfaces offer.", "published": "2023-09-28 16:29:52", "link": "http://arxiv.org/abs/2309.16573v2", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "MindShift: Leveraging Large Language Models for Mental-States-Based\n  Problematic Smartphone Use Intervention", "abstract": "Problematic smartphone use negatively affects physical and mental health.\nDespite the wide range of prior research, existing persuasive techniques are\nnot flexible enough to provide dynamic persuasion content based on users'\nphysical contexts and mental states. We first conducted a Wizard-of-Oz study\n(N=12) and an interview study (N=10) to summarize the mental states behind\nproblematic smartphone use: boredom, stress, and inertia. This informs our\ndesign of four persuasion strategies: understanding, comforting, evoking, and\nscaffolding habits. We leveraged large language models (LLMs) to enable the\nautomatic and dynamic generation of effective persuasion content. We developed\nMindShift, a novel LLM-powered problematic smartphone use intervention\ntechnique. MindShift takes users' in-the-moment app usage behaviors, physical\ncontexts, mental states, goals \\& habits as input, and generates personalized\nand dynamic persuasive content with appropriate persuasion strategies. We\nconducted a 5-week field experiment (N=25) to compare MindShift with its\nsimplified version (remove mental states) and baseline techniques (fixed\nreminder). The results show that MindShift improves intervention acceptance\nrates by 4.7-22.5% and reduces smartphone usage duration by 7.4-9.8%. Moreover,\nusers have a significant drop in smartphone addiction scale scores and a rise\nin self-efficacy scale scores. Our study sheds light on the potential of\nleveraging LLMs for context-aware persuasion in other behavior change domains.", "published": "2023-09-28 17:49:03", "link": "http://arxiv.org/abs/2309.16639v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "68U35", "H.5.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational\n  Sentence Scoring", "abstract": "Recent advances in machine learning and deep learning have led to the\nwidespread use of Conversational AI in many practical applications. However, it\nis still very challenging to leverage auxiliary information that can provide\nconversational context or personalized tuning to improve the quality of\nconversations. For example, there has only been limited research on using an\nindividuals persona information to improve conversation quality, and even\nstate-of-the-art conversational AI techniques are unable to effectively\nleverage signals from heterogeneous sources of auxiliary data, such as\nmulti-modal interaction data, demographics, SDOH data, etc. In this paper, we\npresent a novel Persona-Coded Poly-Encoder method that leverages persona\ninformation in a multi-stream encoding scheme to improve the quality of\nresponse generation for conversations. To show the efficacy of the proposed\nmethod, we evaluate our method on two different persona-based conversational\ndatasets, and compared against two state-of-the-art methods. Our experimental\nresults and analysis demonstrate that our method can improve conversation\nquality over the baseline method Poly-Encoder by 3.32% and 2.94% in terms of\nBLEU score and HR@1, respectively. More significantly, our method offers a path\nto better utilization of multi-modal data in conversational tasks. Lastly, our\nstudy outlines several challenges and future research directions for advancing\npersonalized conversational AI technology.", "published": "2023-09-28 18:07:01", "link": "http://arxiv.org/abs/2309.16770v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hallucination Reduction in Long Input Text Summarization", "abstract": "Hallucination in text summarization refers to the phenomenon where the model\ngenerates information that is not supported by the input source document.\nHallucination poses significant obstacles to the accuracy and reliability of\nthe generated summaries. In this paper, we aim to reduce hallucinated outputs\nor hallucinations in summaries of long-form text documents. We have used the\nPubMed dataset, which contains long scientific research documents and their\nabstracts. We have incorporated the techniques of data filtering and joint\nentity and summary generation (JAENS) in the fine-tuning of the Longformer\nEncoder-Decoder (LED) model to minimize hallucinations and thereby improve the\nquality of the generated summary. We have used the following metrics to measure\nfactual consistency at the entity level: precision-source, and F1-target. Our\nexperiments show that the fine-tuned LED model performs well in generating the\npaper abstract. Data filtering techniques based on some preprocessing steps\nreduce entity-level hallucinations in the generated summaries in terms of some\nof the factual consistency metrics.", "published": "2023-09-28 18:22:16", "link": "http://arxiv.org/abs/2309.16781v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution", "abstract": "Popular prompt strategies like Chain-of-Thought Prompting can dramatically\nimprove the reasoning abilities of Large Language Models (LLMs) in various\ndomains. However, such hand-crafted prompt-strategies are often sub-optimal. In\nthis paper, we present Promptbreeder, a general-purpose self-referential\nself-improvement mechanism that evolves and adapts prompts for a given domain.\nDriven by an LLM, Promptbreeder mutates a population of task-prompts, and\nsubsequently evaluates them for fitness on a training set. Crucially, the\nmutation of these task-prompts is governed by mutation-prompts that the LLM\ngenerates and improves throughout evolution in a self-referential way. That is,\nPromptbreeder is not just improving task-prompts, but it is also improving the\nmutationprompts that improve these task-prompts. Promptbreeder outperforms\nstate-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve\nPrompting on commonly used arithmetic and commonsense reasoning benchmarks.\nFurthermore, Promptbreeder is able to evolve intricate task-prompts for the\nchallenging problem of hate speech classification.", "published": "2023-09-28 19:01:07", "link": "http://arxiv.org/abs/2309.16797v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "A Sign Language Recognition System with Pepper, Lightweight-Transformer,\n  and LLM", "abstract": "This research explores using lightweight deep neural network architectures to\nenable the humanoid robot Pepper to understand American Sign Language (ASL) and\nfacilitate non-verbal human-robot interaction. First, we introduce a\nlightweight and efficient model for ASL understanding optimized for embedded\nsystems, ensuring rapid sign recognition while conserving computational\nresources. Building upon this, we employ large language models (LLMs) for\nintelligent robot interactions. Through intricate prompt engineering, we tailor\ninteractions to allow the Pepper Robot to generate natural Co-Speech Gesture\nresponses, laying the foundation for more organic and intuitive humanoid-robot\ndialogues. Finally, we present an integrated software pipeline, embodying\nadvancements in a socially aware AI interaction model. Leveraging the Pepper\nRobot's capabilities, we demonstrate the practicality and effectiveness of our\napproach in real-world scenarios. The results highlight a profound potential\nfor enhancing human-robot interaction through non-verbal interactions, bridging\ncommunication gaps, and making technology more accessible and understandable.", "published": "2023-09-28 23:54:41", "link": "http://arxiv.org/abs/2309.16898v1", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Large Language Models in Finance: A Survey", "abstract": "Recent advances in large language models (LLMs) have opened new possibilities\nfor artificial intelligence applications in finance. In this paper, we provide\na practical survey focused on two key aspects of utilizing LLMs for financial\ntasks: existing solutions and guidance for adoption.\n  First, we review current approaches employing LLMs in finance, including\nleveraging pretrained models via zero-shot or few-shot learning, fine-tuning on\ndomain-specific data, and training custom LLMs from scratch. We summarize key\nmodels and evaluate their performance improvements on financial natural\nlanguage processing tasks.\n  Second, we propose a decision framework to guide financial professionals in\nselecting the appropriate LLM solution based on their use case constraints\naround data, compute, and performance needs. The framework provides a pathway\nfrom lightweight experimentation to heavy investment in customized LLMs.\n  Lastly, we discuss limitations and challenges around leveraging LLMs in\nfinancial applications. Overall, this survey aims to synthesize the\nstate-of-the-art and provide a roadmap for responsibly applying LLMs to advance\nfinancial AI.", "published": "2023-09-28 06:04:04", "link": "http://arxiv.org/abs/2311.10723v2", "categories": ["q-fin.GN", "cs.AI", "cs.CL"], "primary_category": "q-fin.GN"}
{"title": "Language models in molecular discovery", "abstract": "The success of language models, especially transformer-based architectures,\nhas trickled into other domains giving rise to \"scientific language models\"\nthat operate on small molecules, proteins or polymers. In chemistry, language\nmodels contribute to accelerating the molecule discovery cycle as evidenced by\npromising recent findings in early-stage drug discovery. Here, we review the\nrole of language models in molecular discovery, underlining their strength in\nde novo drug design, property prediction and reaction chemistry. We highlight\nvaluable open-source software assets thus lowering the entry barrier to the\nfield of scientific language modeling. Last, we sketch a vision for future\nmolecular design that combines a chatbot interface with access to computational\nchemistry tools. Our contribution serves as a valuable resource for\nresearchers, chemists, and AI enthusiasts interested in understanding how\nlanguage models can and will be used to accelerate chemical discovery.", "published": "2023-09-28 08:19:54", "link": "http://arxiv.org/abs/2309.16235v1", "categories": ["physics.chem-ph", "cs.AI", "cs.CL", "cs.LG", "q-bio.BM"], "primary_category": "physics.chem-ph"}
{"title": "Hierarchical Cross-Modality Knowledge Transfer with Sinkhorn Attention\n  for CTC-based ASR", "abstract": "Due to the modality discrepancy between textual and acoustic modeling,\nefficiently transferring linguistic knowledge from a pretrained language model\n(PLM) to acoustic encoding for automatic speech recognition (ASR) still remains\na challenging task. In this study, we propose a cross-modality knowledge\ntransfer (CMKT) learning framework in a temporal connectionist temporal\nclassification (CTC) based ASR system where hierarchical acoustic alignments\nwith the linguistic representation are applied. Additionally, we propose the\nuse of Sinkhorn attention in cross-modality alignment process, where the\ntransformer attention is a special case of this Sinkhorn attention process. The\nCMKT learning is supposed to compel the acoustic encoder to encode rich\nlinguistic knowledge for ASR. On the AISHELL-1 dataset, with CTC greedy\ndecoding for inference (without using any language model), we achieved\nstate-of-the-art performance with 3.64% and 3.94% character error rates (CERs)\nfor the development and test sets, which corresponding to relative improvements\nof 34.18% and 34.88% compared to the baseline CTC-ASR system, respectively.", "published": "2023-09-28 01:31:40", "link": "http://arxiv.org/abs/2309.16093v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LAE-ST-MoE: Boosted Language-Aware Encoder Using Speech Translation\n  Auxiliary Task for E2E Code-switching ASR", "abstract": "Recently, to mitigate the confusion between different languages in\ncode-switching (CS) automatic speech recognition (ASR), the conditionally\nfactorized models, such as the language-aware encoder (LAE), explicitly\ndisregard the contextual information between different languages. However, this\ninformation may be helpful for ASR modeling. To alleviate this issue, we\npropose the LAE-ST-MoE framework. It incorporates speech translation (ST) tasks\ninto LAE and utilizes ST to learn the contextual information between different\nlanguages. It introduces a task-based mixture of expert modules, employing\nseparate feed-forward networks for the ASR and ST tasks. Experimental results\non the ASRU 2019 Mandarin-English CS challenge dataset demonstrate that,\ncompared to the LAE-based CTC, the LAE-ST-MoE model achieves a 9.26% mix error\nreduction on the CS test with the same decoding parameter. Moreover, the\nwell-trained LAE-ST-MoE model can perform ST tasks from CS speech to Mandarin\nor English text.", "published": "2023-09-28 05:36:20", "link": "http://arxiv.org/abs/2309.16178v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PP-MeT: a Real-world Personalized Prompt based Meeting Transcription\n  System", "abstract": "Speaker-attributed automatic speech recognition (SA-ASR) improves the\naccuracy and applicability of multi-speaker ASR systems in real-world scenarios\nby assigning speaker labels to transcribed texts. However, SA-ASR poses unique\nchallenges due to factors such as speaker overlap, speaker variability,\nbackground noise, and reverberation. In this study, we propose PP-MeT system, a\nreal-world personalized prompt based meeting transcription system, which\nconsists of a clustering system, target-speaker voice activity detection\n(TS-VAD), and TS-ASR. Specifically, we utilize target-speaker embedding as a\nprompt in TS-VAD and TS-ASR modules in our proposed system. In constrast with\nprevious system, we fully leverage pre-trained models for system\ninitialization, thereby bestowing our approach with heightened generalizability\nand precision. Experiments on M2MeT2.0 Challenge dataset show that our system\nachieves a cp-CER of 11.27% on the test set, ranking first in both fixed and\nopen training conditions.", "published": "2023-09-28 08:40:48", "link": "http://arxiv.org/abs/2309.16247v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Semantic Proximity Alignment: Towards Human Perception-consistent Audio\n  Tagging by Aligning with Label Text Description", "abstract": "Most audio tagging models are trained with one-hot labels as supervised\ninformation. However, one-hot labels treat all sound events equally, ignoring\nthe semantic hierarchy and proximity relationships between sound events. In\ncontrast, the event descriptions contains richer information, describing the\ndistance between different sound events with semantic proximity. In this paper,\nwe explore the impact of training audio tagging models with auxiliary text\ndescriptions of sound events. By aligning the audio features with the text\nfeatures of corresponding labels, we inject the hierarchy and proximity\ninformation of sound events into audio encoders, improving the performance\nwhile making the prediction more consistent with human perception. We refer to\nthis approach as Semantic Proximity Alignment (SPA). We use Ontology-aware mean\nAverage Precision (OmAP) as the main evaluation metric for the models. OmAP\nreweights the false positives based on Audioset ontology distance and is more\nconsistent with human perception compared to mAP. Experimental results show\nthat the audio tagging models trained with SPA achieve higher OmAP compared to\nmodels trained with one-hot labels solely (+1.8 OmAP). Human evaluations also\ndemonstrate that the predictions of SPA models are more consistent with human\nperception.", "published": "2023-09-28 08:57:22", "link": "http://arxiv.org/abs/2309.16265v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "NOMAD: Unsupervised Learning of Perceptual Embeddings for Speech\n  Enhancement and Non-matching Reference Audio Quality Assessment", "abstract": "This paper presents NOMAD (Non-Matching Audio Distance), a differentiable\nperceptual similarity metric that measures the distance of a degraded signal\nagainst non-matching references. The proposed method is based on learning deep\nfeature embeddings via a triplet loss guided by the Neurogram Similarity Index\nMeasure (NSIM) to capture degradation intensity. During inference, the\nsimilarity score between any two audio samples is computed through Euclidean\ndistance of their embeddings. NOMAD is fully unsupervised and can be used in\ngeneral perceptual audio tasks for audio analysis e.g. quality assessment and\ngenerative tasks such as speech enhancement and speech synthesis. The proposed\nmethod is evaluated with 3 tasks. Ranking degradation intensity, predicting\nspeech quality, and as a loss function for speech enhancement. Results indicate\nNOMAD outperforms other non-matching reference approaches in both ranking\ndegradation intensity and quality assessment, exhibiting competitive\nperformance with full-reference audio metrics. NOMAD demonstrates a promising\ntechnique that mimics human capabilities in assessing audio quality with\nnon-matching references to learn perceptual embeddings without the need for\nhuman-generated labels.", "published": "2023-09-28 09:29:52", "link": "http://arxiv.org/abs/2309.16284v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Supervised Training of Audio Transformers for Music\n  Representation Learning", "abstract": "In this work, we address music representation learning using convolution-free\ntransformers. We build on top of existing spectrogram-based audio transformers\nsuch as AST and train our models on a supervised task using patchout training\nsimilar to PaSST. In contrast to previous works, we study how specific design\ndecisions affect downstream music tagging tasks instead of focusing on the\ntraining task. We assess the impact of initializing the models with different\npre-trained weights, using various input audio segment lengths, using learned\nrepresentations from different blocks and tokens of the transformer for\ndownstream tasks, and applying patchout at inference to speed up feature\nextraction. We find that 1) initializing the model from ImageNet or AudioSet\nweights and using longer input segments are beneficial both for the training\nand downstream tasks, 2) the best representations for the considered downstream\ntasks are located in the middle blocks of the transformer, and 3) using\npatchout at inference allows faster processing than our convolutional baselines\nwhile maintaining superior performance. The resulting models, MAEST, are\npublicly available and obtain the best performance among open models in music\ntagging tasks.", "published": "2023-09-28 13:11:48", "link": "http://arxiv.org/abs/2309.16418v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Meeting Recognition with Continuous Speech Separation and\n  Transcription-Supported Diarization", "abstract": "We propose a modular pipeline for the single-channel separation, recognition,\nand diarization of meeting-style recordings and evaluate it on the Libri-CSS\ndataset. Using a Continuous Speech Separation (CSS) system with a TF-GridNet\nseparation architecture, followed by a speaker-agnostic speech recognizer, we\nachieve state-of-the-art recognition performance in terms of Optimal Reference\nCombination Word Error Rate (ORC WER). Then, a d-vector-based diarization\nmodule is employed to extract speaker embeddings from the enhanced signals and\nto assign the CSS outputs to the correct speaker. Here, we propose a\nsyntactically informed diarization using sentence- and word-level boundaries of\nthe ASR module to support speaker turn detection. This results in a\nstate-of-the-art Concatenated minimum-Permutation Word Error Rate (cpWER) for\nthe full meeting recognition pipeline.", "published": "2023-09-28 14:45:46", "link": "http://arxiv.org/abs/2309.16482v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards High Resolution Weather Monitoring with Sound Data", "abstract": "Across various research domains, remotely-sensed weather products are\nvaluable for answering many scientific questions; however, their temporal and\nspatial resolutions are often too coarse to answer many questions. For\ninstance, in wildlife research, it's crucial to have fine-scaled, highly\nlocalized weather observations when studying animal movement and behavior. This\npaper harnesses acoustic data to identify variations in rain, wind and air\ntemperature at different thresholds, with rain being the most successfully\npredicted. Training a model solely on acoustic data yields optimal results, but\nit demands labor-intensive sample labeling. Meanwhile, hourly satellite data\nfrom the MERRA-2 system, though sufficient for certain tasks, produced\npredictions that were notably less accurate in predict these acoustic labels.\nWe find that acoustic classifiers can be trained from the MERRA-2 data that are\nmore accurate than the raw MERRA-2 data itself. By using MERRA-2 to roughly\nidentify rain in the acoustic data, we were able to produce a functional model\nwithout using human-validated labels. Since MERRA-2 has global coverage, our\nmethod offers a practical way to train rain models using acoustic datasets\naround the world.", "published": "2023-09-28 21:49:54", "link": "http://arxiv.org/abs/2309.16867v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Predicting performance difficulty from piano sheet music images", "abstract": "Estimating the performance difficulty of a musical score is crucial in music\neducation for adequately designing the learning curriculum of the students.\nAlthough the Music Information Retrieval community has recently shown interest\nin this task, existing approaches mainly use machine-readable scores, leaving\nthe broader case of sheet music images unaddressed. Based on previous works\ninvolving sheet music images, we use a mid-level representation, bootleg score,\ndescribing notehead positions relative to staff lines coupled with a\ntransformer model. This architecture is adapted to our task by introducing an\nencoding scheme that reduces the encoded sequence length to one-eighth of the\noriginal size. In terms of evaluation, we consider five datasets -- more than\n7500 scores with up to 9 difficulty levels -- , two of them particularly\ncompiled for this work. The results obtained when pretraining the scheme on the\nIMSLP corpus and fine-tuning it on the considered datasets prove the proposal's\nvalidity, achieving the best-performing model with a balanced accuracy of\n40.34\\% and a mean square error of 1.33. Finally, we provide access to our\ncode, data, and models for transparency and reproducibility.", "published": "2023-09-28 09:33:47", "link": "http://arxiv.org/abs/2309.16287v1", "categories": ["cs.SD", "cs.DL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Visual Speaker Localization from EgoCentric Views", "abstract": "The use of audio and visual modality for speaker localization has been well\nstudied in the literature by exploiting their complementary characteristics.\nHowever, most previous works employ the setting of static sensors mounted at\nfixed positions. Unlike them, in this work, we explore the ego-centric setting,\nwhere the heterogeneous sensors are embodied and could be moving with a human\nto facilitate speaker localization. Compared to the static scenario, the\nego-centric setting is more realistic for smart-home applications e.g., a\nservice robot. However, this also brings new challenges such as blurred images,\nfrequent speaker disappearance from the field of view of the wearer, and\nocclusions. In this paper, we study egocentric audio-visual speaker DOA\nestimation and deal with the challenges mentioned above. Specifically, we\npropose a transformer-based audio-visual fusion method to estimate the relative\nDOA of the speaker to the wearer, and design a training strategy to mitigate\nthe problem of the speaker disappearing from the camera's view. We also develop\na new dataset for simulating the out-of-view scenarios, by creating a scene\nwith a camera wearer walking around while a speaker is moving at the same time.\nThe experimental results show that our proposed method offers promising\nperformance in this new dataset in terms of tracking accuracy. Finally, we\nadapt the proposed method for the multi-speaker scenario. Experiments on\nEasyCom show the effectiveness of the proposed model for multiple speakers in\nreal scenarios, which achieves state-of-the-art results in the sphere active\nspeaker detection task and the wearer activity prediction task. The simulated\ndataset and related code are available at\nhttps://github.com/KawhiZhao/Egocentric-Audio-Visual-Speaker-Localization.", "published": "2023-09-28 10:01:08", "link": "http://arxiv.org/abs/2309.16308v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Bringing the Discussion of Minima Sharpness to the Audio Domain: a\n  Filter-Normalised Evaluation for Acoustic Scene Classification", "abstract": "The correlation between the sharpness of loss minima and generalisation in\nthe context of deep neural networks has been subject to discussion for a long\ntime. Whilst mostly investigated in the context of selected benchmark data sets\nin the area of computer vision, we explore this aspect for the acoustic scene\nclassification task of the DCASE2020 challenge data. Our analysis is based on\ntwo-dimensional filter-normalised visualisations and a derived sharpness\nmeasure. Our exploratory analysis shows that sharper minima tend to show better\ngeneralisation than flat minima -even more so for out-of-domain data, recorded\nfrom previously unseen devices-, thus adding to the dispute about better\ngeneralisation capabilities of flat minima. We further find that, in\nparticular, the choice of optimisers is a main driver of the sharpness of\nminima and we discuss resulting limitations with respect to comparability. Our\ncode, trained model states and loss landscape visualisations are publicly\navailable.", "published": "2023-09-28 12:13:23", "link": "http://arxiv.org/abs/2309.16369v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio-Visual Speaker Verification via Joint Cross-Attention", "abstract": "Speaker verification has been widely explored using speech signals, which has\nshown significant improvement using deep models. Recently, there has been a\nsurge in exploring faces and voices as they can offer more complementary and\ncomprehensive information than relying only on a single modality of speech\nsignals. Though current methods in the literature on the fusion of faces and\nvoices have shown improvement over that of individual face or voice modalities,\nthe potential of audio-visual fusion is not fully explored for speaker\nverification. Most of the existing methods based on audio-visual fusion either\nrely on score-level fusion or simple feature concatenation. In this work, we\nhave explored cross-modal joint attention to fully leverage the inter-modal\ncomplementary information and the intra-modal information for speaker\nverification. Specifically, we estimate the cross-attention weights based on\nthe correlation between the joint feature presentation and that of the\nindividual feature representations in order to effectively capture both\nintra-modal as well inter-modal relationships among the faces and voices. We\nhave shown that efficiently leveraging the intra- and inter-modal relationships\nsignificantly improves the performance of audio-visual fusion for speaker\nverification. The performance of the proposed approach has been evaluated on\nthe Voxceleb1 dataset. Results show that the proposed approach can\nsignificantly outperform the state-of-the-art methods of audio-visual fusion\nfor speaker verification.", "published": "2023-09-28 16:25:29", "link": "http://arxiv.org/abs/2309.16569v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
