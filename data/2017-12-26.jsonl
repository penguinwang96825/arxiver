{"title": "Actionable Email Intent Modeling with Reparametrized RNNs", "abstract": "Emails in the workplace are often intentional calls to action for its\nrecipients. We propose to annotate these emails for what action its recipient\nwill take. We argue that our approach of action-based annotation is more\nscalable and theory-agnostic than traditional speech-act-based email intent\nannotation, while still carrying important semantic and pragmatic information.\nWe show that our action-based annotation scheme achieves good inter-annotator\nagreement. We also show that we can leverage threaded messages from other\ndomains, which exhibit comparable intents in their conversation, with domain\nadaptive RAINBOW (Recurrently AttentIve Neural Bag-Of-Words). On a collection\nof datasets consisting of IRC, Reddit, and email, our reparametrized RNNs\noutperform common multitask/multidomain approaches on several speech act\nrelated tasks. We also experiment with a minimally supervised scenario of email\nrecipient action classification, and find the reparametrized RNNs learn a\nuseful representation.", "published": "2017-12-26 06:02:36", "link": "http://arxiv.org/abs/1712.09185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mapping to Declarative Knowledge for Word Problem Solving", "abstract": "Math word problems form a natural abstraction to a range of quantitative\nreasoning problems, such as understanding financial news, sports results, and\ncasualties of war. Solving such problems requires the understanding of several\nmathematical concepts such as dimensional analysis, subset relationships, etc.\nIn this paper, we develop declarative rules which govern the translation of\nnatural language description of these concepts to math expressions. We then\npresent a framework for incorporating such declarative knowledge into word\nproblem solving. Our method learns to map arithmetic word problem text to math\nexpressions, by learning to select the relevant declarative knowledge for each\noperation of the solution expression. This provides a way to handle multiple\nconcepts in the same problem while, at the same time, support interpretability\nof the answer expression. Our method models the mapping to declarative\nknowledge as a latent variable, thus removing the need for expensive\nannotations. Experimental evaluation suggests that our domain knowledge based\nsolver outperforms all other systems, and that it generalizes better in the\nrealistic case where the training data it is exposed to is biased in a\ndifferent way than the test data.", "published": "2017-12-26 20:21:09", "link": "http://arxiv.org/abs/1712.09391v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advances in Pre-Training Distributed Word Representations", "abstract": "Many Natural Language Processing applications nowadays rely on pre-trained\nword representations estimated from large text corpora such as news\ncollections, Wikipedia and Web Crawl. In this paper, we show how to train\nhigh-quality word vector representations by using a combination of known tricks\nthat are however rarely used together. The main result of our work is the new\nset of publicly available pre-trained models that outperform the current state\nof the art by a large margin on a number of tasks.", "published": "2017-12-26 21:00:04", "link": "http://arxiv.org/abs/1712.09405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Basic concepts and tools for the Toki Pona minimal and constructed\n  language: description of the language and main issues; analysis of the\n  vocabulary; text synthesis and syntax highlighting; Wordnet synsets", "abstract": "A minimal constructed language (conlang) is useful for experiments and\ncomfortable for making tools. The Toki Pona (TP) conlang is minimal both in the\nvocabulary (with only 14 letters and 124 lemmas) and in the (about) 10 syntax\nrules. The language is useful for being a used and somewhat established minimal\nconlang with at least hundreds of fluent speakers. This article exposes current\nconcepts and resources for TP, and makes available Python (and Vim) scripted\nroutines for the analysis of the language, synthesis of texts, syntax\nhighlighting schemes, and the achievement of a preliminary TP Wordnet. Focus is\non the analysis of the basic vocabulary, as corpus analyses were found. The\nsynthesis is based on sentence templates, relates to context by keeping track\nof used words, and renders larger texts by using a fixed number of phonemes\n(e.g. for poems) and number of sentences, words and letters (e.g. for\nparagraphs). Syntax highlighting reflects morphosyntactic classes given in the\nofficial dictionary and different solutions are described and implemented in\nthe well-established Vim text editor. The tentative TP Wordnet is made\navailable in three patterns of relations between synsets and word lemmas. In\nsummary, this text holds potentially novel conceptualizations about, and tools\nand results in analyzing, synthesizing and syntax highlighting the TP language.", "published": "2017-12-26 18:43:32", "link": "http://arxiv.org/abs/1712.09359v3", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
