{"title": "DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and\n  Affective Labels", "abstract": "Nowadays, there are many applications of text mining over corpora from\ndifferent languages. However, most of them are based on texts in prose, lacking\napplications that work with poetry texts. An example of an application of text\nmining in poetry is the usage of features derived from their individual words\nin order to capture the lexical, sublexical and interlexical meaning, and infer\nthe General Affective Meaning (GAM) of the text. However, even though this\nproposal has been proved as useful for poetry in some languages, there is a\nlack of studies for both Spanish poetry and for highly-structured poetic\ncompositions such as sonnets. This article presents a study over an annotated\ncorpus of Spanish sonnets, in order to analyse if it is possible to build\nfeatures from their individual words for predicting their GAM. The purpose of\nthis is to model sonnets at an affective level. The article also analyses the\nrelationship between the GAM of the sonnets and the content itself. For this,\nwe consider the content from a psychological perspective, identifying with tags\nwhen a sonnet is related to a specific term. Then, we study how GAM changes\naccording to each of those psychological terms.\n  The corpus used contains 274 Spanish sonnets from authors of different\ncenturies, from 15th to 19th. This corpus was annotated by different domain\nexperts. The experts annotated the poems with affective and lexico-semantic\nfeatures, as well as with domain concepts that belong to psychology. Thanks to\nthis, the corpus of sonnets can be used in different applications, such as\npoetry recommender systems, personality text mining studies of the authors, or\nthe usage of poetry for therapeutic purposes.", "published": "2020-07-09 08:26:22", "link": "http://arxiv.org/abs/2007.04626v3", "categories": ["cs.CL", "68T50, 91F20", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Principal Word Vectors", "abstract": "We generalize principal component analysis for embedding words into a vector\nspace. The generalization is made in two major levels. The first is to\ngeneralize the concept of the corpus as a counting process which is defined by\nthree key elements vocabulary set, feature (annotation) set, and context. This\ngeneralization enables the principal word embedding method to generate word\nvectors with regard to different types of contexts and different types of\nannotations provided for a corpus. The second is to generalize the\ntransformation step used in most of the word embedding methods. To this end, we\ndefine two levels of transformations. The first is a quadratic transformation,\nwhich accounts for different types of weighting over the vocabulary units and\ncontextual features. Second is an adaptive non-linear transformation, which\nreshapes the data distribution to be meaningful to principal component\nanalysis. The effect of these generalizations on the word vectors is\nintrinsically studied with regard to the spread and the discriminability of the\nword vectors. We also provide an extrinsic evaluation of the contribution of\nthe principal word vectors on a word similarity benchmark and the task of\ndependency parsing. Our experiments are finalized by a comparison between the\nprincipal word vectors and other sets of word vectors generated with popular\nword embedding methods. The results obtained from our intrinsic evaluation\nmetrics show that the spread and the discriminability of the principal word\nvectors are higher than that of other word embedding methods. The results\nobtained from the extrinsic evaluation metrics show that the principal word\nvectors are better than some of the word embedding methods and on par with\npopular methods of word embedding.", "published": "2020-07-09 08:29:57", "link": "http://arxiv.org/abs/2007.04629v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Greedy Transition-Based Dependency Parsing with Discrete and Continuous\n  Supertag Features", "abstract": "We study the effect of rich supertag features in greedy transition-based\ndependency parsing. While previous studies have shown that sparse boolean\nfeatures representing the 1-best supertag of a word can improve parsing\naccuracy, we show that we can get further improvements by adding a continuous\nvector representation of the entire supertag distribution for a word. In this\nway, we achieve the best results for greedy transition-based parsing with\nsupertag features with $88.6\\%$ LAS and $90.9\\%$ UASon the English Penn\nTreebank converted to Stanford Dependencies.", "published": "2020-07-09 10:29:19", "link": "http://arxiv.org/abs/2007.04686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CompRes: A Dataset for Narrative Structure in News", "abstract": "This paper addresses the task of automatically detecting narrative structures\nin raw texts. Previous works have utilized the oral narrative theory by Labov\nand Waletzky to identify various narrative elements in personal stories texts.\nInstead, we direct our focus to news articles, motivated by their growing\nsocial impact as well as their role in creating and shaping public opinion.\n  We introduce CompRes -- the first dataset for narrative structure in news\nmedia. We describe the process in which the dataset was constructed: first, we\ndesigned a new narrative annotation scheme, better suited for news media, by\nadapting elements from the narrative theory of Labov and Waletzky (Complication\nand Resolution) and adding a new narrative element of our own (Success); then,\nwe used that scheme to annotate a set of 29 English news articles (containing\n1,099 sentences) collected from news and partisan websites. We use the\nannotated dataset to train several supervised models to identify the different\nnarrative elements, achieving an $F_1$ score of up to 0.7. We conclude by\nsuggesting several promising directions for future work.", "published": "2020-07-09 15:21:59", "link": "http://arxiv.org/abs/2007.04874v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advances of Transformer-Based Models for News Headline Generation", "abstract": "Pretrained language models based on Transformer architecture are the reason\nfor recent breakthroughs in many areas of NLP, including sentiment analysis,\nquestion answering, named entity recognition. Headline generation is a special\nkind of text summarization task. Models need to have strong natural language\nunderstanding that goes beyond the meaning of individual words and sentences\nand an ability to distinguish essential information to succeed in it. In this\npaper, we fine-tune two pretrained Transformer-based models (mBART and\nBertSumAbs) for that task and achieve new state-of-the-art results on the RIA\nand Lenta datasets of Russian news. BertSumAbs increases ROUGE on average by\n2.9 and 2.0 points respectively over previous best score achieved by\nPhrase-Based Attentional Transformer and CopyNet.", "published": "2020-07-09 19:34:18", "link": "http://arxiv.org/abs/2007.05044v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cultural Cartography with Word Embeddings", "abstract": "Using the frequency of keywords is a classic approach in the formal analysis\nof text, but has the drawback of glossing over the relationality of word\nmeanings. Word embedding models overcome this problem by constructing a\nstandardized and continuous \"meaning space\" where words are assigned a location\nbased on relations of similarity to other words based on how they are used in\nnatural language samples. We show how word embeddings are commensurate with\nprevailing theories of meaning in sociology and can be put to the task of\ninterpretation via two kinds of navigation. First, one can hold terms constant\nand measure how the embedding space moves around them--much like astronomers\nmeasured the changing of celestial bodies with the seasons. Second, one can\nalso hold the embedding space constant and see how documents or authors move\nrelative to it--just as ships use the stars on a given night to determine their\nlocation. Using the empirical case of immigration discourse in the United\nStates, we demonstrate the merits of these two broad strategies for advancing\nimportant topics in cultural theory, including social marking, media fields,\necho chambers, and cultural diffusion and change more broadly.", "published": "2020-07-09 01:58:28", "link": "http://arxiv.org/abs/2007.04508v4", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Less is More: Rejecting Unreliable Reviews for Product Question\n  Answering", "abstract": "Promptly and accurately answering questions on products is important for\ne-commerce applications. Manually answering product questions (e.g. on\ncommunity question answering platforms) results in slow response and does not\nscale. Recent studies show that product reviews are a good source for\nreal-time, automatic product question answering (PQA). In the literature, PQA\nis formulated as a retrieval problem with the goal to search for the most\nrelevant reviews to answer a given product question. In this paper, we focus on\nthe issue of answerability and answer reliability for PQA using reviews. Our\ninvestigation is based on the intuition that many questions may not be\nanswerable with a finite set of reviews. When a question is not answerable, a\nsystem should return nil answers rather than providing a list of irrelevant\nreviews, which can have significant negative impact on user experience.\nMoreover, for answerable questions, only the most relevant reviews that answer\nthe question should be included in the result. We propose a conformal\nprediction based framework to improve the reliability of PQA systems, where we\nreject unreliable answers so that the returned results are more concise and\naccurate at answering the product question, including returning nil answers for\nunanswerable questions. Experiments on a widely used Amazon dataset show\nencouraging results of our proposed framework. More broadly, our results\ndemonstrate a novel and effective application of conformal methods to a\nretrieval task.", "published": "2020-07-09 03:08:55", "link": "http://arxiv.org/abs/2007.04526v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Automatic Personality Prediction; an Enhanced Method Using Ensemble\n  Modeling", "abstract": "Human personality is significantly represented by those words which he/she\nuses in his/her speech or writing. As a consequence of spreading the\ninformation infrastructures (specifically the Internet and social media), human\ncommunications have reformed notably from face to face communication.\nGenerally, Automatic Personality Prediction (or Perception) (APP) is the\nautomated forecasting of the personality on different types of human\ngenerated/exchanged contents (like text, speech, image, video, etc.). The major\nobjective of this study is to enhance the accuracy of APP from the text. To\nthis end, we suggest five new APP methods including term frequency\nvector-based, ontology-based, enriched ontology-based, latent semantic analysis\n(LSA)-based, and deep learning-based (BiLSTM) methods. These methods as the\nbase ones, contribute to each other to enhance the APP accuracy through\nensemble modeling (stacking) based on a hierarchical attention network (HAN) as\nthe meta-model. The results show that ensemble modeling enhances the accuracy\nof APP.", "published": "2020-07-09 06:05:10", "link": "http://arxiv.org/abs/2007.04571v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepSinger: Singing Voice Synthesis with Data Mined From the Web", "abstract": "In this paper, we develop DeepSinger, a multi-lingual multi-singer singing\nvoice synthesis (SVS) system, which is built from scratch using singing\ntraining data mined from music websites. The pipeline of DeepSinger consists of\nseveral steps, including data crawling, singing and accompaniment separation,\nlyrics-to-singing alignment, data filtration, and singing modeling.\nSpecifically, we design a lyrics-to-singing alignment model to automatically\nextract the duration of each phoneme in lyrics starting from coarse-grained\nsentence level to fine-grained phoneme level, and further design a\nmulti-lingual multi-singer singing model based on a feed-forward Transformer to\ndirectly generate linear-spectrograms from lyrics, and synthesize voices using\nGriffin-Lim. DeepSinger has several advantages over previous SVS systems: 1) to\nthe best of our knowledge, it is the first SVS system that directly mines\ntraining data from music websites, 2) the lyrics-to-singing alignment model\nfurther avoids any human efforts for alignment labeling and greatly reduces\nlabeling cost, 3) the singing model based on a feed-forward Transformer is\nsimple and efficient, by removing the complicated acoustic feature modeling in\nparametric synthesis and leveraging a reference encoder to capture the timbre\nof a singer from noisy singing data, and 4) it can synthesize singing voices in\nmultiple languages and multiple singers. We evaluate DeepSinger on our mined\nsinging dataset that consists of about 92 hours data from 89 singers on three\nlanguages (Chinese, Cantonese and English). The results demonstrate that with\nthe singing data purely mined from the Web, DeepSinger can synthesize\nhigh-quality singing voices in terms of both pitch accuracy and voice\nnaturalness (footnote: Our audio samples are shown in\nhttps://speechresearch.github.io/deepsinger/.)", "published": "2020-07-09 07:00:48", "link": "http://arxiv.org/abs/2007.04590v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Unsupervised Text Generation by Learning from Search", "abstract": "In this work, we present TGLS, a novel framework to unsupervised Text\nGeneration by Learning from Search. We start by applying a strong search\nalgorithm (in particular, simulated annealing) towards a heuristically defined\nobjective that (roughly) estimates the quality of sentences. Then, a\nconditional generative model learns from the search results, and meanwhile\nsmooth out the noise of search. The alternation between search and learning can\nbe repeated for performance bootstrapping. We demonstrate the effectiveness of\nTGLS on two real-world natural language generation tasks, paraphrase generation\nand text formalization. Our model significantly outperforms unsupervised\nbaseline methods in both tasks. Especially, it achieves comparable performance\nwith the state-of-the-art supervised methods in paraphrase generation.", "published": "2020-07-09 04:34:48", "link": "http://arxiv.org/abs/2007.08557v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "RWCP-SSD-Onomatopoeia: Onomatopoeic Word Dataset for Environmental Sound\n  Synthesis", "abstract": "Environmental sound synthesis is a technique for generating a natural\nenvironmental sound. Conventional work on environmental sound synthesis using\nsound event labels cannot finely control synthesized sounds, for example, the\npitch and timbre. We consider that onomatopoeic words can be used for\nenvironmental sound synthesis. Onomatopoeic words are effective for explaining\nthe feature of sounds. We believe that using onomatopoeic words will enable us\nto control the fine time-frequency structure of synthesized sounds. However,\nthere is no dataset available for environmental sound synthesis using\nonomatopoeic words. In this paper, we thus present RWCP-SSD-Onomatopoeia, a\ndataset consisting of 155,568 onomatopoeic words paired with audio samples for\nenvironmental sound synthesis. We also collected self-reported confidence\nscores and others-reported acceptance scores of onomatopoeic words, to help us\ninvestigate the difficulty in the transcription and selection of a suitable\nword for environmental sound synthesis.", "published": "2020-07-09 11:41:40", "link": "http://arxiv.org/abs/2007.04719v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Capturing scattered discriminative information using a deep architecture\n  in acoustic scene classification", "abstract": "Frequently misclassified pairs of classes that share many common acoustic\nproperties exist in acoustic scene classification (ASC). To distinguish such\npairs of classes, trivial details scattered throughout the data could be vital\nclues. However, these details are less noticeable and are easily removed using\nconventional non-linear activations (e.g. ReLU). Furthermore, making design\nchoices to emphasize trivial details can easily lead to overfitting if the\nsystem is not sufficiently generalized. In this study, based on the analysis of\nthe ASC task's characteristics, we investigate various methods to capture\ndiscriminative information and simultaneously mitigate the overfitting problem.\nWe adopt a max feature map method to replace conventional non-linear\nactivations in a deep neural network, and therefore, we apply an element-wise\ncomparison between different filters of a convolution layer's output. Two data\naugment methods and two deep architecture modules are further explored to\nreduce overfitting and sustain the system's discriminative power. Various\nexperiments are conducted using the detection and classification of acoustic\nscenes and events 2020 task1-a dataset to validate the proposed methods. Our\nresults show that the proposed system consistently outperforms the baseline,\nwhere the single best performing system has an accuracy of 70.4% compared to\n65.1% of the baseline.", "published": "2020-07-09 08:32:06", "link": "http://arxiv.org/abs/2007.04631v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-task Regularization Based on Infrequent Classes for Audio\n  Captioning", "abstract": "Audio captioning is a multi-modal task, focusing on using natural language\nfor describing the contents of general audio. Most audio captioning methods are\nbased on deep neural networks, employing an encoder-decoder scheme and a\ndataset with audio clips and corresponding natural language descriptions (i.e.\ncaptions). A significant challenge for audio captioning is the distribution of\nwords in the captions: some words are very frequent but acoustically\nnon-informative, i.e. the function words (e.g. \"a\", \"the\"), and other words are\ninfrequent but informative, i.e. the content words (e.g. adjectives, nouns). In\nthis paper we propose two methods to mitigate this class imbalance problem.\nFirst, in an autoencoder setting for audio captioning, we weigh each word's\ncontribution to the training loss inversely proportional to its number of\noccurrences in the whole dataset. Secondly, in addition to multi-class,\nword-level audio captioning task, we define a multi-label side task based on\nclip-level content word detection by training a separate decoder. We use the\nloss from the second task to regularize the jointly trained encoder for the\naudio captioning task. We evaluate our method using Clotho, a recently\npublished, wide-scale audio captioning dataset, and our results show an\nincrease of 37\\% relative improvement with SPIDEr metric over the baseline\nmethod.", "published": "2020-07-09 09:38:54", "link": "http://arxiv.org/abs/2007.04660v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
