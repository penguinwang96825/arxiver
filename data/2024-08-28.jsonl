{"title": "Legilimens: Practical and Unified Content Moderation for Large Language\n  Model Services", "abstract": "Given the societal impact of unsafe content generated by large language\nmodels (LLMs), ensuring that LLM services comply with safety standards is a\ncrucial concern for LLM service providers. Common content moderation methods\nare limited by an effectiveness-and-efficiency dilemma, where simple models are\nfragile while sophisticated models consume excessive computational resources.\nIn this paper, we reveal for the first time that effective and efficient\ncontent moderation can be achieved by extracting conceptual features from\nchat-oriented LLMs, despite their initial fine-tuning for conversation rather\nthan content moderation. We propose a practical and unified content moderation\nframework for LLM services, named Legilimens, which features both effectiveness\nand efficiency. Our red-team model-based data augmentation enhances the\nrobustness of Legilimens against state-of-the-art jailbreaking. Additionally,\nwe develop a framework to theoretically analyze the cost-effectiveness of\nLegilimens compared to other methods. We have conducted extensive experiments\non five host LLMs, seventeen datasets, and nine jailbreaking methods to verify\nthe effectiveness, efficiency, and robustness of Legilimens against normal and\nadaptive adversaries. A comparison of Legilimens with both commercial and\nacademic baselines demonstrates the superior performance of Legilimens.\nFurthermore, we confirm that Legilimens can be applied to few-shot scenarios\nand extended to multi-label classification tasks.", "published": "2024-08-28 02:27:07", "link": "http://arxiv.org/abs/2408.15488v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing and Accelerating Large Language Models via Instruction-Aware\n  Contextual Compression", "abstract": "Large Language Models (LLMs) have garnered widespread attention due to their\nremarkable performance across various tasks. However, to mitigate the issue of\nhallucinations, LLMs often incorporate retrieval-augmented pipeline to provide\nthem with rich external knowledge and context. Nevertheless, challenges stem\nfrom inaccurate and coarse-grained context retrieved from the retriever.\nSupplying irrelevant context to the LLMs can result in poorer responses,\nincreased inference latency, and higher costs. This paper introduces a method\ncalled Instruction-Aware Contextual Compression, which filters out less\ninformative content, thereby accelerating and enhancing the use of LLMs. The\nexperimental results demonstrate that Instruction-Aware Contextual Compression\nnotably reduces memory consumption and minimizes generation latency while\nmaintaining performance levels comparable to those achieved with the use of the\nfull context. Specifically, we achieved a 50% reduction in context-related\ncosts, resulting in a 5% reduction in inference memory usage and a 2.2-fold\nincrease in inference speed, with only a minor drop of 0.047 in Rouge-1. These\nfindings suggest that our method strikes an effective balance between\nefficiency and performance.", "published": "2024-08-28 02:31:15", "link": "http://arxiv.org/abs/2408.15491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReMamba: Equip Mamba with Effective Long-Sequence Modeling", "abstract": "While the Mamba architecture demonstrates superior inference efficiency and\ncompetitive performance on short-context natural language processing (NLP)\ntasks, empirical evidence suggests its capacity to comprehend long contexts is\nlimited compared to transformer-based models. In this study, we investigate the\nlong-context efficiency issues of the Mamba models and propose ReMamba, which\nenhances Mamba's ability to comprehend long contexts. ReMamba incorporates\nselective compression and adaptation techniques within a two-stage re-forward\nprocess, incurring minimal additional inference costs overhead. Experimental\nresults on the LongBench and L-Eval benchmarks demonstrate ReMamba's efficacy,\nimproving over the baselines by 3.2 and 1.6 points, respectively, and attaining\nperformance almost on par with same-size transformer models.", "published": "2024-08-28 02:47:27", "link": "http://arxiv.org/abs/2408.15496v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Squid: Long Context as a New Modality for Energy-Efficient On-Device\n  Language Models", "abstract": "This paper presents Dolphin, a novel decoder-decoder architecture for\nenergy-efficient processing of long contexts in language models. Our approach\naddresses the significant energy consumption and latency challenges inherent in\non-device models. Dolphin employs a compact 0.5B parameter decoder to distill\nextensive contextual information into a memory embedding, substantially\nreducing the input length for the primary 7B parameter decoder model. Inspired\nby vision-language models, we repurpose the image embedding projector to encode\nlong textual contexts, effectively treating extended context as a distinct\nmodality. This innovative method enables processing of substantially longer\ncontexts without the typical computational overhead associated with extended\ninput sequences. Empirical evaluations demonstrate a 10-fold improvement in\nenergy efficiency and a 5-fold reduction in latency compared to conventional\nfull-length context processing methods without losing quality of the response.\nOur work contributes to the development of more sustainable and scalable\nlanguage models for on-device applications, addressing the critical need for\nenergy-efficient and responsive AI technologies in resource-constrained\nenvironments while maintaining the accuracy to understand long contexts. This\nresearch has implications for the broader field of natural language processing,\nparticularly in the domain of efficient model design for resource-limited\nsettings. By enabling more sophisticated AI capabilities on edge devices,\nDolphin paves the way for advanced language processing in a wide range of\napplications where computational resources are at a premium. The Dolphin model\nis publicly available at https://huggingface.co/NexaAIDev/Dolphin.", "published": "2024-08-28 04:06:14", "link": "http://arxiv.org/abs/2408.15518v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback", "abstract": "As large language models (LLMs) continue to advance, aligning these models\nwith human preferences has emerged as a critical challenge. Traditional\nalignment methods, relying on human or LLM annotated datasets, are limited by\ntheir resource-intensive nature, inherent subjectivity, misalignment with\nreal-world user preferences, and the risk of feedback loops that amplify model\nbiases. To overcome these limitations, we introduce WildFeedback, a novel\nframework that leverages in-situ user feedback during conversations with LLMs\nto create preference datasets automatically. Given a corpus of multi-turn\nuser-LLM conversation, WildFeedback identifies and classifies user feedback to\nLLM responses between conversation turns. The user feedback is then used to\ncreate examples of preferred and dispreferred responses according to users'\npreference. Our experiments demonstrate that LLMs fine-tuned on WildFeedback\ndataset exhibit significantly improved alignment with user preferences, as\nevidenced by both traditional benchmarks and our proposed checklist-guided\nevaluation. By incorporating in-situ feedback from actual users, WildFeedback\naddresses the scalability, subjectivity, and bias challenges that plague\nexisting approaches, marking a significant step toward developing LLMs that are\nmore responsive to the diverse and evolving needs of their users.", "published": "2024-08-28 05:53:46", "link": "http://arxiv.org/abs/2408.15549v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large\n  Language Models", "abstract": "There is a growing trend of teaching large language models (LLMs) to solve\nmathematical problems through coding. Existing studies primarily focus on\nprompting powerful, closed-source models to generate seed training data\nfollowed by in-domain data augmentation, equipping LLMs with considerable\ncapabilities for code-aided mathematical reasoning. However, continually\ntraining these models on augmented data derived from a few datasets such as\nGSM8K may impair their generalization abilities and restrict their\neffectiveness to a narrow range of question types. Conversely, the potential of\nimproving such LLMs by leveraging large-scale, expert-written, diverse math\nquestion-answer pairs remains unexplored. To utilize these resources and tackle\nunique challenges such as code response assessment, we propose a novel paradigm\nthat uses a code-based critic model to guide steps including question-code data\nconstruction, quality control, and complementary evaluation. We also explore\ndifferent alignment algorithms with self-generated instruction/preference data\nto foster continuous improvement. Experiments across both in-domain (up to\n+5.7%) and out-of-domain (+4.4%) benchmarks in English and Chinese demonstrate\nthe effectiveness of the proposed paradigm.", "published": "2024-08-28 06:33:03", "link": "http://arxiv.org/abs/2408.15565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StyleRemix: Interpretable Authorship Obfuscation via Distillation and\n  Perturbation of Style Elements", "abstract": "Authorship obfuscation, rewriting a text to intentionally obscure the\nidentity of the author, is an important but challenging task. Current methods\nusing large language models (LLMs) lack interpretability and controllability,\noften ignoring author-specific stylistic features, resulting in less robust\nperformance overall.\n  To address this, we develop StyleRemix, an adaptive and interpretable\nobfuscation method that perturbs specific, fine-grained style elements of the\noriginal input text. StyleRemix uses pre-trained Low Rank Adaptation (LoRA)\nmodules to rewrite an input specifically along various stylistic axes (e.g.,\nformality and length) while maintaining low computational cost. StyleRemix\noutperforms state-of-the-art baselines and much larger LLMs in a variety of\ndomains as assessed by both automatic and human evaluation.\n  Additionally, we release AuthorMix, a large set of 30K high-quality,\nlong-form texts from a diverse set of 14 authors and 4 domains, and DiSC, a\nparallel corpus of 1,500 texts spanning seven style axes in 16 unique\ndirections", "published": "2024-08-28 09:35:15", "link": "http://arxiv.org/abs/2408.15666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TempoFormer: A Transformer for Temporally-aware Representations in\n  Change Detection", "abstract": "Dynamic representation learning plays a pivotal role in understanding the\nevolution of linguistic content over time. On this front both context and time\ndynamics as well as their interplay are of prime importance. Current approaches\nmodel context via pre-trained representations, which are typically temporally\nagnostic. Previous work on modelling context and temporal dynamics has used\nrecurrent methods, which are slow and prone to overfitting. Here we introduce\nTempoFormer, the first task-agnostic transformer-based and temporally-aware\nmodel for dynamic representation learning. Our approach is jointly trained on\ninter and intra context dynamics and introduces a novel temporal variation of\nrotary positional embeddings. The architecture is flexible and can be used as\nthe temporal representation foundation of other models or applied to different\ntransformer-based architectures. We show new SOTA performance on three\ndifferent real-time change detection tasks.", "published": "2024-08-28 10:25:53", "link": "http://arxiv.org/abs/2408.15689v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conan-embedding: General Text Embedding with More and Better Negative\n  Samples", "abstract": "With the growing popularity of RAG, the capabilities of embedding models are\ngaining increasing attention. Embedding models are primarily trained through\ncontrastive loss learning, with negative examples being a key component.\nPrevious work has proposed various hard negative mining strategies, but these\nstrategies are typically employed as preprocessing steps. In this paper, we\npropose the conan-embedding model, which maximizes the utilization of more and\nhigher-quality negative examples. Specifically, since the model's ability to\nhandle preprocessed negative examples evolves during training, we propose\ndynamic hard negative mining method to expose the model to more challenging\nnegative examples throughout the training process. Secondly, contrastive\nlearning requires as many negative examples as possible but is limited by GPU\nmemory constraints. Therefore, we use a Cross-GPU balancing Loss to provide\nmore negative examples for embedding training and balance the batch size across\nmultiple tasks. Moreover, we also discovered that the prompt-response pairs\nfrom LLMs can be used for embedding training. Our approach effectively enhances\nthe capabilities of embedding models, currently ranking first on the Chinese\nleaderboard of Massive text embedding benchmark", "published": "2024-08-28 11:18:06", "link": "http://arxiv.org/abs/2408.15710v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Evaluation of Sindhi Word Embedding in Semantic Analogies and\n  Downstream Tasks", "abstract": "In this paper, we propose a new word embedding based corpus consisting of\nmore than 61 million words crawled from multiple web resources. We design a\npreprocessing pipeline for the filtration of unwanted text from crawled data.\nAfterwards, the cleaned vocabulary is fed to state-of-the-art\ncontinuous-bag-of-words, skip-gram, and GloVe word embedding algorithms. For\nthe evaluation of pretrained embeddings, we use popular intrinsic and extrinsic\nevaluation approaches. The evaluation results reveal that\ncontinuous-bag-of-words and skip-gram perform better than GloVe and existing\nSindhi fastText word embedding on both intrinsic and extrinsic evaluation\napproaches", "published": "2024-08-28 11:36:29", "link": "http://arxiv.org/abs/2408.15720v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of\n  Relational Knowledge in Language Models", "abstract": "Knowledge probing evaluates the extent to which a language model (LM) has\nacquired relational knowledge during its pre-training phase. It provides a\ncost-effective means of comparing LMs of different sizes and training setups\nand is useful for monitoring knowledge gained or lost during continual learning\n(CL). In prior work, we presented an improved knowledge probe called BEAR\n(Wiland et al., 2024), which enables the comparison of LMs trained with\ndifferent pre-training objectives (causal and masked LMs) and addresses issues\nof skewed distributions in previous probes to deliver a more unbiased reading\nof LM knowledge. With this paper, we present LM-PUB- QUIZ, a Python framework\nand leaderboard built around the BEAR probing mechanism that enables\nresearchers and practitioners to apply it in their work. It provides options\nfor standalone evaluation and direct integration into the widely-used training\npipeline of the Hugging Face TRANSFORMERS library. Further, it provides a\nfine-grained analysis of different knowledge types to assist users in better\nunderstanding the knowledge in each evaluated LM. We publicly release\nLM-PUB-QUIZ as an open-source project.", "published": "2024-08-28 11:44:52", "link": "http://arxiv.org/abs/2408.15729v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Form and meaning co-determine the realization of tone in Taiwan Mandarin\n  spontaneous speech: the case of Tone 3 sandhi", "abstract": "In Standard Chinese, Tone 3 (the dipping tone) becomes Tone 2 (rising tone)\nwhen followed by another Tone 3. Previous studies have noted that this sandhi\nprocess may be incomplete, in the sense that the assimilated Tone 3 is still\ndistinct from a true Tone 2. While Mandarin Tone 3 sandhi is widely studied\nusing carefully controlled laboratory speech (Xu, 1997) and more formal\nregisters of Beijing Mandarin (Yuan and Chen, 2014), less is known about its\nrealization in spontaneous speech, and about the effect of contextual factors\non tonal realization. The present study investigates the pitch contours of\ntwo-character words with T2-T3 and T3-T3 tone patterns in spontaneous Taiwan\nMandarin conversations. Our analysis makes use of the Generative Additive Mixed\nModel (GAMM, Wood, 2017) to examine fundamental frequency (f0) contours as a\nfunction of normalized time. We consider various factors known to influence\npitch contours, including gender, speaking rate, speaker, neighboring tones,\nword position, bigram probability, and also novel predictors, word and word\nsense (Chuang et al., 2024). Our analyses revealed that in spontaneous Taiwan\nMandarin, T3-T3 words become indistinguishable from T2-T3 words, indicating\ncomplete sandhi, once the strong effect of word (or word sense) is taken into\naccount. For our data, the shape of f0 contours is not co-determined by word\nfrequency. In contrast, the effect of word meaning on f0 contours is robust, as\nstrong as the effect of adjacent tones, and is present for both T2-T3 and T3-T3\nwords.", "published": "2024-08-28 12:25:45", "link": "http://arxiv.org/abs/2408.15747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Up Summarization: Leveraging Large Language Models for Long Text\n  Extractive Summarization", "abstract": "In an era where digital text is proliferating at an unprecedented rate,\nefficient summarization tools are becoming indispensable. While Large Language\nModels (LLMs) have been successfully applied in various NLP tasks, their role\nin extractive text summarization remains underexplored. This paper introduces\nEYEGLAXS (Easy Yet Efficient larGe LAnguage model for eXtractive\nSummarization), a framework that leverages LLMs, specifically LLAMA2-7B and\nChatGLM2-6B, for extractive summarization of lengthy text documents. Instead of\nabstractive methods, which often suffer from issues like factual inaccuracies\nand hallucinations, EYEGLAXS focuses on extractive summarization to ensure\nfactual and grammatical integrity. Utilizing state-of-the-art techniques such\nas Flash Attention and Parameter-Efficient Fine-Tuning (PEFT), EYEGLAXS\naddresses the computational and resource challenges typically associated with\nLLMs. The system sets new performance benchmarks on well-known datasets like\nPubMed and ArXiv. Furthermore, we extend our research through additional\nanalyses that explore the adaptability of LLMs in handling different sequence\nlengths and their efficiency in training on smaller datasets. These\ncontributions not only set a new standard in the field but also open up\npromising avenues for future research in extractive text summarization.", "published": "2024-08-28 13:52:19", "link": "http://arxiv.org/abs/2408.15801v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration\n  in Evolving Environments", "abstract": "The important challenge of keeping knowledge in Large Language Models (LLMs)\nup-to-date has led to the development of various methods for incorporating new\nfacts. However, existing methods for such knowledge editing still face\ndifficulties with multi-hop questions that require accurate fact identification\nand sequential logical reasoning, particularly among numerous fact updates. To\ntackle these challenges, this paper introduces Graph Memory-based Editing for\nLarge Language Models (GMeLLo), a straightforward and effective method that\nmerges the explicit knowledge representation of Knowledge Graphs (KGs) with the\nlinguistic flexibility of LLMs. Beyond merely leveraging LLMs for question\nanswering, GMeLLo employs these models to convert free-form language into\nstructured queries and fact triples, facilitating seamless interaction with KGs\nfor rapid updates and precise multi-hop reasoning. Our results show that GMeLLo\nsignificantly surpasses current state-of-the-art (SOTA) knowledge editing\nmethods in the multi-hop question answering benchmark, MQuAKE, especially in\nscenarios with extensive knowledge edits.", "published": "2024-08-28 16:15:45", "link": "http://arxiv.org/abs/2408.15903v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition\n  Capabilities of Language Models in Multi-Agent Systems", "abstract": "Large Language Models (LLMs) are becoming increasingly powerful and capable\nof handling complex tasks, e.g., building single agents and multi-agent\nsystems. Compared to single agents, multi-agent systems have higher\nrequirements for the collaboration capabilities of language models. Many\nbenchmarks are proposed to evaluate their collaborative abilities. However,\nthese benchmarks lack fine-grained evaluations of LLM collaborative\ncapabilities. Additionally, multi-agent collaborative and competitive scenarios\nare ignored in existing works. To address these two problems, we propose a\nbenchmark, called BattleAgentBench, which defines seven sub-stages of three\nvarying difficulty levels and conducts a fine-grained evaluation of language\nmodels in terms of single-agent scenario navigation capabilities, paired-agent\ntask execution abilities, and multi-agent collaboration and competition\ncapabilities. We conducted extensive evaluations on leading four closed-source\nand seven open-source models. Experimental results indicate that API-based\nmodels perform excellently on simple tasks but open-source small models\nstruggle with simple tasks. Regarding difficult tasks that require\ncollaborative and competitive abilities, although API-based models have\ndemonstrated some collaborative capabilities, there is still enormous room for\nimprovement.", "published": "2024-08-28 17:43:55", "link": "http://arxiv.org/abs/2408.15971v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Personality Prediction Possible Based on Reddit Comments?", "abstract": "In this assignment, we examine whether there is a correlation between the\npersonality type of a person and the texts they wrote. In order to do this, we\naggregated datasets of Reddit comments labeled with the Myers-Briggs Type\nIndicator (MBTI) of the author and built different supervised classifiers based\non BERT to try to predict the personality of an author given a text. Despite\nexperiencing issues with the unfiltered character of the dataset, we can\nobserve potential in the classification.", "published": "2024-08-28 18:43:07", "link": "http://arxiv.org/abs/2408.16089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Event Reasoning with Large Language Models", "abstract": "Reasoning about real-life events is a unifying challenge in AI and NLP that\nhas profound utility in a variety of domains, while fallacy in high-stake\napplications could be catastrophic. Able to work with diverse text in these\ndomains, large language models (LLMs) have proven capable of answering\nquestions and solving problems. However, I show that end-to-end LLMs still\nsystematically fail to reason about complex events, and they lack\ninterpretability due to their black-box nature. To address these issues, I\npropose three general approaches to use LLMs in conjunction with a structured\nrepresentation of events. The first is a language-based representation\ninvolving relations of sub-events that can be learned by LLMs via fine-tuning.\nThe second is a semi-symbolic representation involving states of entities that\ncan be predicted and leveraged by LLMs via few-shot prompting. The third is a\nfully symbolic representation that can be predicted by LLMs trained with\nstructured data and be executed by symbolic solvers. On a suite of event\nreasoning tasks spanning common-sense inference and planning, I show that each\napproach greatly outperforms end-to-end LLMs with more interpretability. These\nresults suggest manners of synergy between LLMs and structured representations\nfor event reasoning and beyond.", "published": "2024-08-28 19:03:41", "link": "http://arxiv.org/abs/2408.16098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Computational Representations of Character: An Austen\n  Character Similarity Benchmark", "abstract": "Several systems have been developed to extract information about characters\nto aid computational analysis of English literature. We propose character\nsimilarity grouping as a holistic evaluation task for these pipelines. We\npresent AustenAlike, a benchmark suite of character similarities in Jane\nAusten's novels. Our benchmark draws on three notions of character similarity:\na structurally defined notion of similarity; a socially defined notion of\nsimilarity; and an expert defined set extracted from literary criticism.\n  We use AustenAlike to evaluate character features extracted using two\npipelines, BookNLP and FanfictionNLP. We build character representations from\nfour kinds of features and compare them to the three AustenAlike benchmarks and\nto GPT-4 similarity rankings. We find that though computational representations\ncapture some broad similarities based on shared social and narrative roles, the\nexpert pairings in our third benchmark are challenging for all systems,\nhighlighting the subtler aspects of similarity noted by human readers.", "published": "2024-08-28 20:36:35", "link": "http://arxiv.org/abs/2408.16131v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via\n  Layer-wise Relevance Propagation", "abstract": "Retrieval-Augmented Generation (RAG) has become a primary technique for\nmitigating hallucinations in large language models (LLMs). However, incomplete\nknowledge extraction and insufficient understanding can still mislead LLMs to\nproduce irrelevant or even contradictory responses, which means hallucinations\npersist in RAG. In this paper, we propose LRP4RAG, a method based on the\nLayer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations\nin RAG. Specifically, we first utilize LRP to compute the relevance between the\ninput and output of the RAG generator. We then apply further extraction and\nresampling to the relevance matrix. The processed relevance data are input into\nmultiple classifiers to determine whether the output contains hallucinations.\nTo the best of our knowledge, this is the first time that LRP has been used for\ndetecting RAG hallucinations, and extensive experiments demonstrate that\nLRP4RAG outperforms existing baselines.", "published": "2024-08-28 04:44:43", "link": "http://arxiv.org/abs/2408.15533v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding", "abstract": "Scientific literature understanding is crucial for extracting targeted\ninformation and garnering insights, thereby significantly advancing scientific\ndiscovery. Despite the remarkable success of Large Language Models (LLMs), they\nface challenges in scientific literature understanding, primarily due to (1) a\nlack of scientific knowledge and (2) unfamiliarity with specialized scientific\ntasks.\n  To develop an LLM specialized in scientific literature understanding, we\npropose a hybrid strategy that integrates continual pre-training (CPT) and\nsupervised fine-tuning (SFT), to simultaneously infuse scientific domain\nknowledge and enhance instruction-following capabilities for domain-specific\ntasks.cIn this process, we identify two key challenges: (1) constructing\nhigh-quality CPT corpora, and (2) generating diverse SFT instructions. We\naddress these challenges through a meticulous pipeline, including PDF text\nextraction, parsing content error correction, quality filtering, and synthetic\ninstruction creation. Applying this strategy, we present a suite of LLMs:\nSciLitLLM, specialized in scientific literature understanding. These models\ndemonstrate promising performance on scientific literature understanding\nbenchmarks.\n  Our contributions are threefold: (1) We present an effective framework that\nintegrates CPT and SFT to adapt LLMs to scientific literature understanding,\nwhich can also be easily adapted to other domains. (2) We propose an LLM-based\nsynthesis method to generate diverse and high-quality scientific instructions,\nresulting in a new instruction set -- SciLitIns -- for supervised fine-tuning\nin less-represented scientific domains. (3) SciLitLLM achieves promising\nperformance improvements on scientific literature understanding benchmarks.", "published": "2024-08-28 05:41:52", "link": "http://arxiv.org/abs/2408.15545v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Boosting Lossless Speculative Decoding via Feature Sampling and Partial\n  Alignment Distillation", "abstract": "Lossless speculative decoding accelerates target large language model (LLM)\ninference by employing a lightweight draft model for generating tree-structured\ncandidates, which are subsequently verified in parallel by the target LLM.\nCurrently, effective approaches leverage feature-level rather than token-level\nautoregression within the draft model to facilitate more straightforward\npredictions and enhanced knowledge distillation. In this paper, we reassess\nthese approaches and propose FSPAD (Feature Sampling and Partial Alignment\nDistillation for Lossless Speculative Decoding), which introduces two\nstraightforward and effective components within the existing framework to boost\nlossless speculative decoding. Firstly, FSPAD utilizes token embeddings to\nsample features of the target LLM in high-dimensional space before feeding them\ninto the draft model, due to the inherent uncertainty of the features\npreventing the draft model from obtaining the specific token output by the\ntarget LLM. Secondly, FSPAD introduces partial alignment distillation to weaken\nthe draft model's connection between features and logits, aiming to reduce the\nconflict between feature alignment and logit confidence during training. Our\nexperiments include both greedy and non-greedy decoding on the largest and\nsmallest models from the Vicuna and LLaMA3-Instruct series, as well as tasks in\nmulti-turn conversation, translation, summarization, question answering,\nmathematical reasoning, and retrieval-augmented generation. The results show\nthat FSPAD outperforms the state-of-the-art method across all the\naforementioned tasks and target LLMs.", "published": "2024-08-28 06:28:01", "link": "http://arxiv.org/abs/2408.15562v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Harnessing the Intrinsic Knowledge of Pretrained Language Models for\n  Challenging Text Classification Settings", "abstract": "Text classification is crucial for applications such as sentiment analysis\nand toxic text filtering, but it still faces challenges due to the complexity\nand ambiguity of natural language. Recent advancements in deep learning,\nparticularly transformer architectures and large-scale pretraining, have\nachieved inspiring success in NLP fields. Building on these advancements, this\nthesis explores three challenging settings in text classification by leveraging\nthe intrinsic knowledge of pretrained language models (PLMs). Firstly, to\naddress the challenge of selecting misleading yet incorrect distractors for\ncloze questions, we develop models that utilize features based on\ncontextualized word representations from PLMs, achieving performance that\nrivals or surpasses human accuracy. Secondly, to enhance model generalization\nto unseen labels, we create small finetuning datasets with domain-independent\ntask label descriptions, improving model performance and robustness. Lastly, we\ntackle the sensitivity of large language models to in-context learning prompts\nby selecting effective demonstrations, focusing on misclassified examples and\nresolving model ambiguity regarding test example labels.", "published": "2024-08-28 09:07:30", "link": "http://arxiv.org/abs/2408.15650v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts", "abstract": "For Mixture-of-Experts (MoE) models, an unbalanced expert load will lead to\nrouting collapse or increased computational overhead. Existing methods commonly\nemploy an auxiliary loss to encourage load balance, but a large auxiliary loss\nwill introduce non-negligible interference gradients into training and thus\nimpair the model performance. In order to control load balance while not\nproducing undesired gradients during training, we propose Loss-Free Balancing,\nfeatured by an auxiliary-loss-free load balancing strategy. To be specific,\nbefore the top-K routing decision, Loss-Free Balancing will first apply an\nexpert-wise bias to the routing scores of each expert. By dynamically updating\nthe bias of each expert according to its recent load, Loss-Free Balancing can\nconsistently maintain a balanced distribution of expert load. In addition,\nsince Loss-Free Balancing does not produce any interference gradients, it also\nelevates the upper bound of model performance gained from MoE training. We\nvalidate the performance of Loss-Free Balancing on MoE models with up to 3B\nparameters trained on up to 200B tokens. Experimental results show that\nLoss-Free Balancing achieves both better performance and better load balance\ncompared with traditional auxiliary-loss-controlled load balancing strategies.", "published": "2024-08-28 09:31:09", "link": "http://arxiv.org/abs/2408.15664v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning Harmonized Representations for Speculative Sampling", "abstract": "Speculative sampling is a promising approach to accelerate the decoding stage\nfor Large Language Models (LLMs). Recent advancements that leverage target\nLLM's contextual information, such as hidden states and KV cache, have shown\nsignificant practical improvements. However, these approaches suffer from\ninconsistent context between training and decoding. We also observe another\ndiscrepancy between the training and decoding objectives in existing\nspeculative sampling methods. In this work, we propose a solution named\nHArmonized Speculative Sampling (HASS) that learns harmonized representations\nto address these issues. HASS accelerates the decoding stage without adding\ninference overhead through harmonized objective distillation and harmonized\ncontext alignment. Experiments on four LLaMA models demonstrate that HASS\nachieves 2.81x-4.05x wall-clock time speedup ratio averaging across three\ndatasets, surpassing EAGLE-2 by 8%-20%. The code is available at\nhttps://github.com/HArmonizedSS/HASS.", "published": "2024-08-28 12:59:12", "link": "http://arxiv.org/abs/2408.15766v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language\n  Models", "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across\nvarious tasks, showcasing complex problem-solving abilities. Understanding and\nexecuting complex rules, along with multi-step planning, are fundamental to\nlogical reasoning and critical for practical LLM agents and decision-making\nsystems. However, evaluating LLMs as effective rule-based executors and\nplanners remains underexplored. In this paper, we introduce LogicGame, a novel\nbenchmark designed to evaluate the comprehensive rule understanding, execution,\nand planning capabilities of LLMs. Unlike traditional benchmarks, LogicGame\nprovides diverse games that contain a series of rules with an initial state,\nrequiring models to comprehend and apply predefined regulations to solve\nproblems. We create simulated scenarios in which models execute or plan\noperations to achieve specific outcomes. These game scenarios are specifically\ndesigned to distinguish logical reasoning from mere knowledge by relying\nexclusively on predefined rules. This separation allows for a pure assessment\nof rule-based reasoning capabilities. The evaluation considers not only final\noutcomes but also intermediate steps, providing a comprehensive assessment of\nmodel performance. Moreover, these intermediate steps are deterministic and can\nbe automatically verified. LogicGame defines game scenarios with varying\ndifficulty levels, from simple rule applications to complex reasoning chains,\nin order to offer a precise evaluation of model performance on rule\nunderstanding and multi-step execution. Utilizing LogicGame, we test various\nLLMs and identify notable shortcomings in their rule-based logical reasoning\nabilities.", "published": "2024-08-28 13:16:41", "link": "http://arxiv.org/abs/2408.15778v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Interactive Agents: Simulating Counselor-Client Psychological Counseling\n  via Role-Playing LLM-to-LLM Interactions", "abstract": "Virtual counselors powered by large language models (LLMs) aim to create\ninteractive support systems that effectively assist clients struggling with\nmental health challenges. To replicate counselor-client conversations,\nresearchers have built an online mental health platform that allows\nprofessional counselors to provide clients with text-based counseling services\nfor about an hour per session. Notwithstanding its effectiveness, challenges\nexist as human annotation is time-consuming, cost-intensive, privacy-protected,\nand not scalable. To address this issue and investigate the applicability of\nLLMs in psychological counseling conversation simulation, we propose a\nframework that employs two LLMs via role-playing for simulating\ncounselor-client interactions. Our framework involves two LLMs, one acting as a\nclient equipped with a specific and real-life user profile and the other\nplaying the role of an experienced counselor, generating professional responses\nusing integrative therapy techniques. We implement both the counselor and the\nclient by zero-shot prompting the GPT-4 model. In order to assess the\neffectiveness of LLMs in simulating counselor-client interactions and\nunderstand the disparities between LLM- and human-generated conversations, we\nevaluate the synthetic data from various perspectives. We begin by assessing\nthe client's performance through automatic evaluations. Next, we analyze and\ncompare the disparities between dialogues generated by the LLM and those\ngenerated by professional counselors. Furthermore, we conduct extensive\nexperiments to thoroughly examine the performance of our LLM-based counselor\ntrained with synthetic interactive dialogues by benchmarking against\nstate-of-the-art models for mental health.", "published": "2024-08-28 13:29:59", "link": "http://arxiv.org/abs/2408.15787v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Language Adaptation on a Tight Academic Compute Budget: Tokenizer\n  Swapping Works and Pure bfloat16 Is Enough", "abstract": "We investigate continued pretraining of LLMs for language adaptation on a\ntight academic budget: a setting in which only a few GPUs can be used in\nparallel, for a heavily constrained duration. We focus on adapting Mistral-7B\nto German or Arabic and evaluate several techniques to improve efficiency and\neffectiveness in this setting. Our German models adapted on this tight compute\nbudget underperform compared to the base Mistral-7B, while our Arabic models\noutperform several baselines, showing that for sufficiently well-represented\nlanguages, continued pretraining for specialization is not always helpful. Our\nmain findings focus on training precision and tokenizer swapping. Our results\nshow that pure bfloat16 training is a viable alternative to mixed-precision\ntraining, while being much faster when only using a few GPUs. Swapping the\ntokenizer for a specialized one yields more efficient tokenization and is\ncompetitive with the original tokenizer, which already contains some German\ntokens, but did not significantly increase performance for German. Code and\nmodel weights are available at on GitHub.", "published": "2024-08-28 13:37:07", "link": "http://arxiv.org/abs/2408.15793v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Differential Diagnosis using Transformer-Based Multi-Label\n  Sequence Classification", "abstract": "As the field of artificial intelligence progresses, assistive technologies\nare becoming more widely used across all industries. The healthcare industry is\nno different, with numerous studies being done to develop assistive tools for\nhealthcare professionals. Automatic diagnostic systems are one such beneficial\ntool that can assist with a variety of tasks, including collecting patient\ninformation, analyzing test results, and diagnosing patients. However, the idea\nof developing systems that can provide a differential diagnosis has been\nlargely overlooked in most of these research studies. In this study, we propose\na transformer-based approach for providing differential diagnoses based on a\npatient's age, sex, medical history, and symptoms. We use the DDXPlus dataset,\nwhich provides differential diagnosis information for patients based on 49\ndisease types. Firstly, we propose a method to process the tabular patient data\nfrom the dataset and engineer them into patient reports to make them suitable\nfor our research. In addition, we introduce two data modification modules to\ndiversify the training data and consequently improve the robustness of the\nmodels. We approach the task as a multi-label classification problem and\nconduct extensive experiments using four transformer models. All the models\ndisplayed promising results by achieving over 97% F1 score on the held-out test\nset. Moreover, we design additional behavioral tests to get a broader\nunderstanding of the models. In particular, for one of our test cases, we\nprepared a custom test set of 100 samples with the assistance of a doctor. The\nresults on the custom set showed that our proposed data modification modules\nimproved the model's generalization capabilities. We hope our findings will\nprovide future researchers with valuable insights and inspire them to develop\nreliable systems for automatic differential diagnosis.", "published": "2024-08-28 14:40:15", "link": "http://arxiv.org/abs/2408.15827v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Persuasion Games using Large Language Models", "abstract": "Large Language Models (LLMs) have emerged as formidable instruments capable\nof comprehending and producing human-like text. This paper explores the\npotential of LLMs, to shape user perspectives and subsequently influence their\ndecisions on particular tasks. This capability finds applications in diverse\ndomains such as Investment, Credit cards and Insurance, wherein they assist\nusers in selecting appropriate insurance policies, investment plans, Credit\ncards, Retail, as well as in Behavioral Change Support Systems (BCSS).\n  We present a sophisticated multi-agent framework wherein a consortium of\nagents operate in collaborative manner. The primary agent engages directly with\nuser agents through persuasive dialogue, while the auxiliary agents perform\ntasks such as information retrieval, response analysis, development of\npersuasion strategies, and validation of facts. Empirical evidence from our\nexperiments demonstrates that this collaborative methodology significantly\nenhances the persuasive efficacy of the LLM. We continuously analyze the\nresistance of the user agent to persuasive efforts and counteract it by\nemploying a combination of rule-based and LLM-based resistance-persuasion\nmapping techniques.\n  We employ simulated personas and generate conversations in insurance,\nbanking, and retail domains to evaluate the proficiency of large language\nmodels (LLMs) in recognizing, adjusting to, and influencing various personality\ntypes. Concurrently, we examine the resistance mechanisms employed by LLM\nsimulated personas. Persuasion is quantified via measurable surveys before and\nafter interaction, LLM-generated scores on conversation, and user decisions\n(purchase or non-purchase).", "published": "2024-08-28 15:50:41", "link": "http://arxiv.org/abs/2408.15879v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Bias in LLMs as Annotators: The Effect of Party Cues on Labelling\n  Decision by Large Language Models", "abstract": "Human coders are biased. We test similar biases in Large Language Models\n(LLMs) as annotators. By replicating an experiment run by Ennser-Jedenastik and\nMeyer (2018), we find evidence that LLMs use political information, and\nspecifically party cues, to judge political statements. Not only do LLMs use\nrelevant information to contextualize whether a statement is positive,\nnegative, or neutral based on the party cue, they also reflect the biases of\nthe human-generated data upon which they have been trained. We also find that\nunlike humans, who are only biased when faced with statements from extreme\nparties, LLMs exhibit significant bias even when prompted with statements from\ncenter-left and center-right parties. The implications of our findings are\ndiscussed in the conclusion.", "published": "2024-08-28 16:05:20", "link": "http://arxiv.org/abs/2408.15895v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using Large Language Models to Create AI Personas for Replication and\n  Prediction of Media Effects: An Empirical Test of 133 Published Experimental\n  Research Findings", "abstract": "This report analyzes the potential for large language models (LLMs) to\nexpedite accurate replication of published message effects studies. We tested\nLLM-powered participants (personas) by replicating 133 experimental findings\nfrom 14 papers containing 45 recent studies in the Journal of Marketing\n(January 2023-May 2024). We used a new software tool, Viewpoints AI\n(https://viewpoints.ai/), that takes study designs, stimuli, and measures as\ninput, automatically generates prompts for LLMs to act as a specified sample of\nunique personas, and collects their responses to produce a final output in the\nform of a complete dataset and statistical analysis. The underlying LLM used\nwas Anthropic's Claude Sonnet 3.5. We generated 19,447 AI personas to replicate\nthese studies with the exact same sample attributes, study designs, stimuli,\nand measures reported in the original human research. Our LLM replications\nsuccessfully reproduced 76% of the original main effects (84 out of 111),\ndemonstrating strong potential for AI-assisted replication of studies in which\npeople respond to media stimuli. When including interaction effects, the\noverall replication rate was 68% (90 out of 133). The use of LLMs to replicate\nand accelerate marketing research on media effects is discussed with respect to\nthe replication crisis in social science, potential solutions to\ngeneralizability problems in sampling subjects and experimental conditions, and\nthe ability to rapidly test consumer responses to various media stimuli. We\nalso address the limitations of this approach, particularly in replicating\ncomplex interaction effects in media response studies, and suggest areas for\nfuture research and improvement in AI-assisted experimental replication of\nmedia effects.", "published": "2024-08-28 18:14:39", "link": "http://arxiv.org/abs/2408.16073v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational\n  Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench (Automated\n  Multi-shot Jailbreaks)", "abstract": "This paper introduces FRACTURED-SORRY-Bench, a framework for evaluating the\nsafety of Large Language Models (LLMs) against multi-turn conversational\nattacks. Building upon the SORRY-Bench dataset, we propose a simple yet\neffective method for generating adversarial prompts by breaking down harmful\nqueries into seemingly innocuous sub-questions. Our approach achieves a maximum\nincrease of +46.22\\% in Attack Success Rates (ASRs) across GPT-4, GPT-4o,\nGPT-4o-mini, and GPT-3.5-Turbo models compared to baseline methods. We\ndemonstrate that this technique poses a challenge to current LLM safety\nmeasures and highlights the need for more robust defenses against subtle,\nmulti-turn attacks.", "published": "2024-08-28 22:51:29", "link": "http://arxiv.org/abs/2408.16163v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FedMCP: Parameter-Efficient Federated Learning with Model-Contrastive\n  Personalization", "abstract": "With increasing concerns and regulations on data privacy, fine-tuning\npretrained language models (PLMs) in federated learning (FL) has become a\ncommon paradigm for NLP tasks. Despite being extensively studied, the existing\nmethods for this problem still face two primary challenges. First, the huge\nnumber of parameters in large-scale PLMs leads to excessive communication and\ncomputational overhead. Second, the heterogeneity of data and tasks across\nclients poses a significant obstacle to achieving the desired fine-tuning\nperformance. To address the above problems, we propose FedMCP, a novel\nparameter-efficient fine-tuning method with model-contrastive personalization\nfor FL. Specifically, FedMCP adds two lightweight adapter modules, i.e., the\nglobal adapter and the private adapter, to the frozen PLMs within clients. In a\ncommunication round, each client sends only the global adapter to the server\nfor federated aggregation. Furthermore, FedMCP introduces a model-contrastive\nregularization term between the two adapters. This, on the one hand, encourages\nthe global adapter to assimilate universal knowledge and, on the other hand,\nthe private adapter to capture client-specific knowledge. By leveraging both\nadapters, FedMCP can effectively provide fine-tuned personalized models\ntailored to individual clients. Extensive experiments on highly heterogeneous\ncross-task, cross-silo datasets show that FedMCP achieves substantial\nperformance improvements over state-of-the-art FL fine-tuning approaches for\nPLMs.", "published": "2024-08-28 04:19:47", "link": "http://arxiv.org/abs/2409.00116v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ConCSE: Unified Contrastive Learning and Augmentation for Code-Switched\n  Embeddings", "abstract": "This paper examines the Code-Switching (CS) phenomenon where two languages\nintertwine within a single utterance. There exists a noticeable need for\nresearch on the CS between English and Korean. We highlight that the current\nEquivalence Constraint (EC) theory for CS in other languages may only partially\ncapture English-Korean CS complexities due to the intrinsic grammatical\ndifferences between the languages. We introduce a novel Koglish dataset\ntailored for English-Korean CS scenarios to mitigate such challenges. First, we\nconstructed the Koglish-GLUE dataset to demonstrate the importance and need for\nCS datasets in various tasks. We found the differential outcomes of various\nfoundation multilingual language models when trained on a monolingual versus a\nCS dataset. Motivated by this, we hypothesized that SimCSE, which has shown\nstrengths in monolingual sentence embedding, would have limitations in CS\nscenarios. We construct a novel Koglish-NLI (Natural Language Inference)\ndataset using a CS augmentation-based approach to verify this. From this\nCS-augmented dataset Koglish-NLI, we propose a unified contrastive learning and\naugmentation method for code-switched embeddings, ConCSE, highlighting the\nsemantics of CS sentences. Experimental results validate the proposed ConCSE\nwith an average performance enhancement of 1.77\\% on the Koglish-STS(Semantic\nTextual Similarity) tasks.", "published": "2024-08-28 11:27:21", "link": "http://arxiv.org/abs/2409.00120v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Reliable are Causal Probing Interventions?", "abstract": "Causal probing aims to analyze foundation models by examining how intervening\non their representation of various latent properties impacts their outputs.\nRecent works have cast doubt on the theoretical basis of several leading causal\nprobing methods, but it has been unclear how to systematically evaluate the\neffectiveness of these methods in practice. To address this, we define two key\ncausal probing desiderata: completeness (how thoroughly the representation of\nthe target property has been transformed) and selectivity (how little\nnon-targeted properties have been impacted). We find that there is an inherent\ntradeoff between the two, which we define as reliability, their harmonic mean.\nWe introduce an empirical analysis framework to measure and evaluate these\nquantities, allowing us to make the first direct comparisons between different\nfamilies of leading causal probing methods (e.g., linear vs. nonlinear, or\nconcept removal vs. counterfactual interventions). We find that: (1) no method\nis reliable across all layers; (2) more reliable methods have a greater impact\non LLM behavior; (3) nonlinear interventions are more reliable in early and\nintermediate layers, and linear interventions are more reliable in later\nlayers; and (4) concept removal methods are far less reliable than\ncounterfactual interventions, suggesting that they may not be an effective\napproach to causal probing.", "published": "2024-08-28 03:45:49", "link": "http://arxiv.org/abs/2408.15510v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Toward Automated Simulation Research Workflow through LLM Prompt\n  Engineering Design", "abstract": "The advent of Large Language Models (LLMs) has created new opportunities for\nthe automation of scientific research spanning both experimental processes and\ncomputational simulations. This study explores the feasibility of constructing\nan autonomous simulation agent (ASA) powered by LLMs through prompt engineering\nand automated program design to automate the entire simulation research process\naccording to a human-provided research plan. This process includes experimental\ndesign, remote upload and simulation execution, data analysis, and report\ncompilation. Using a well-studied simulation problem of polymer chain\nconformations as a test case, we assessed the long-task completion and\nreliability of ASAs powered by different LLMs, including GPT-4o, Claude-3.5,\netc. Our findings revealed that ASA-GPT-4o achieved near-flawless execution on\ndesignated research missions, underscoring the potential of methods like ASA to\nachieve automation in simulation research processes to enhance research\nefficiency. The outlined automation can be iteratively performed for up to 20\ncycles without human intervention, illustrating the potential of ASA for\nlong-task workflow automation. Additionally, we discussed the intrinsic traits\nof ASA in managing extensive tasks, focusing on self-validation mechanisms, and\nthe balance between local attention and global oversight.", "published": "2024-08-28 03:48:05", "link": "http://arxiv.org/abs/2408.15512v3", "categories": ["cs.AI", "cs.CL", "physics.chem-ph"], "primary_category": "cs.AI"}
{"title": "An Investigation of Warning Erroneous Chat Translations in Cross-lingual\n  Communication", "abstract": "Machine translation models are still inappropriate for translating chats,\ndespite the popularity of translation software and plug-in applications. The\ncomplexity of dialogues poses significant challenges and can hinder\ncrosslingual communication. Instead of pursuing a flawless translation system,\na more practical approach would be to issue warning messages about potential\nmistranslations to reduce confusion. However, it is still unclear how\nindividuals perceive these warning messages and whether they benefit the crowd.\nThis paper tackles to investigate this question and demonstrates the warning\nmessages' contribution to making chat translation systems effective.", "published": "2024-08-28 05:36:25", "link": "http://arxiv.org/abs/2408.15543v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Beyond Levenshtein: Leveraging Multiple Algorithms for Robust Word Error\n  Rate Computations And Granular Error Classifications", "abstract": "The Word Error Rate (WER) is the common measure of accuracy for Automatic\nSpeech Recognition (ASR). Transcripts are usually pre-processed by substituting\nspecific characters to account for non-semantic differences. As a result of\nthis normalisation, information on the accuracy of punctuation or\ncapitalisation is lost. We present a non-destructive, token-based approach\nusing an extended Levenshtein distance algorithm to compute a robust WER and\nadditional orthographic metrics. Transcription errors are also classified more\ngranularly by existing string similarity and phonetic algorithms. An evaluation\non several datasets demonstrates the practical equivalence of our approach\ncompared to common WER computations. We also provide an exemplary analysis of\nderived use cases, such as a punctuation error rate, and a web application for\ninteractive use and visualisation of our implementation. The code is available\nopen-source.", "published": "2024-08-28 08:14:51", "link": "http://arxiv.org/abs/2408.15616v1", "categories": ["cs.CL", "cs.SD", "eess.AS", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CBF-LLM: Safe Control for LLM Alignment", "abstract": "This paper proposes a control-based framework for aligning large language\nmodels (LLMs) by leveraging a control barrier function (CBF) to ensure\nuser-desirable text generation. The presented framework applies the safety\nfilter, designed based on the CBF, to the output generation of the baseline\nLLM, i.e., the sequence of the token, with the aim of intervening in the\ngenerated text. The overall text-generation system is implemented with Llama 3\nand a RoBERTa model, and the source code is available at\nhttps://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control\nability and effectiveness in reducing the number of interventions needed for\nuser-specified alignment tasks.", "published": "2024-08-28 08:25:22", "link": "http://arxiv.org/abs/2408.15625v2", "categories": ["eess.SY", "cs.AI", "cs.CL", "cs.SY"], "primary_category": "eess.SY"}
{"title": "A Survey on Evaluation of Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) mimic human perception and reasoning\nsystem by integrating powerful Large Language Models (LLMs) with various\nmodality encoders (e.g., vision, audio), positioning LLMs as the \"brain\" and\nvarious modality encoders as sensory organs. This framework endows MLLMs with\nhuman-like capabilities, and suggests a potential pathway towards achieving\nartificial general intelligence (AGI). With the emergence of all-round MLLMs\nlike GPT-4V and Gemini, a multitude of evaluation methods have been developed\nto assess their capabilities across different dimensions. This paper presents a\nsystematic and comprehensive review of MLLM evaluation methods, covering the\nfollowing key aspects: (1) the background of MLLMs and their evaluation; (2)\n\"what to evaluate\" that reviews and categorizes existing MLLM evaluation tasks\nbased on the capabilities assessed, including general multimodal recognition,\nperception, reasoning and trustworthiness, and domain-specific applications\nsuch as socioeconomic, natural sciences and engineering, medical usage, AI\nagent, remote sensing, video and audio processing, 3D point cloud analysis, and\nothers; (3) \"where to evaluate\" that summarizes MLLM evaluation benchmarks into\ngeneral and specific benchmarks; (4) \"how to evaluate\" that reviews and\nillustrates MLLM evaluation steps and metrics; Our overarching goal is to\nprovide valuable insights for researchers in the field of MLLM evaluation,\nthereby facilitating the development of more capable and reliable MLLMs. We\nemphasize that evaluation should be regarded as a critical discipline,\nessential for advancing the field of MLLMs.", "published": "2024-08-28 13:05:55", "link": "http://arxiv.org/abs/2408.15769v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Knowledge Navigator: LLM-guided Browsing Framework for Exploratory\n  Search in Scientific Literature", "abstract": "The exponential growth of scientific literature necessitates advanced tools\nfor effective knowledge exploration. We present Knowledge Navigator, a system\ndesigned to enhance exploratory search abilities by organizing and structuring\nthe retrieved documents from broad topical queries into a navigable, two-level\nhierarchy of named and descriptive scientific topics and subtopics. This\nstructured organization provides an overall view of the research themes in a\ndomain, while also enabling iterative search and deeper knowledge discovery\nwithin specific subtopics by allowing users to refine their focus and retrieve\nadditional relevant documents. Knowledge Navigator combines LLM capabilities\nwith cluster-based methods to enable an effective browsing method. We\ndemonstrate our approach's effectiveness through automatic and manual\nevaluations on two novel benchmarks, CLUSTREC-COVID and SCITOC. Our code,\nprompts, and benchmarks are made publicly available.", "published": "2024-08-28 14:48:37", "link": "http://arxiv.org/abs/2408.15836v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A New Method for Cross-Lingual-based Semantic Role Labeling", "abstract": "Semantic role labeling is a crucial task in natural language processing,\nenabling better comprehension of natural language. However, the lack of\nannotated data in multiple languages has posed a challenge for researchers. To\naddress this, a deep learning algorithm based on model transfer has been\nproposed. The algorithm utilizes a dataset consisting of the English portion of\nCoNLL2009 and a corpus of semantic roles in Persian. To optimize the efficiency\nof training, only ten percent of the educational data from each language is\nused. The results of the proposed model demonstrate significant improvements\ncompared to Niksirt et al.'s model. In monolingual mode, the proposed model\nachieved a 2.05 percent improvement on F1-score, while in cross-lingual mode,\nthe improvement was even more substantial, reaching 6.23 percent. Worth noting\nis that the compared model only trained two of the four stages of semantic role\nlabeling and employed golden data for the remaining two stages. This suggests\nthat the actual superiority of the proposed model surpasses the reported\nnumbers by a significant margin. The development of cross-lingual methods for\nsemantic role labeling holds promise, particularly in addressing the scarcity\nof annotated data for various languages. These advancements pave the way for\nfurther research in understanding and processing natural language across\ndifferent linguistic contexts.", "published": "2024-08-28 16:06:12", "link": "http://arxiv.org/abs/2408.15896v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Nexus: Specialization meets Adaptability for Efficiently Training\n  Mixture of Experts", "abstract": "Efficiency, specialization, and adaptability to new data distributions are\nqualities that are hard to combine in current Large Language Models. The\nMixture of Experts (MoE) architecture has been the focus of significant\nresearch because its inherent conditional computation enables such desirable\nproperties. In this work, we focus on \"upcycling\" dense expert models into an\nMoE, aiming to improve specialization while also adding the ability to adapt to\nnew tasks easily. We introduce Nexus, an enhanced MoE architecture with\nadaptive routing where the model learns to project expert embeddings from\ndomain representations. This approach allows Nexus to flexibly add new experts\nafter the initial upcycling through separately trained dense models, without\nrequiring large-scale MoE training for unseen data domains. Our experiments\nshow that Nexus achieves a relative gain of up to 2.1% over the baseline for\ninitial upcycling, and a 18.8% relative gain for extending the MoE with a new\nexpert by using limited finetuning data. This flexibility of Nexus is crucial\nto enable an open-source ecosystem where every user continuously assembles\ntheir own MoE-mix according to their needs.", "published": "2024-08-28 16:12:55", "link": "http://arxiv.org/abs/2408.15901v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Open Knowledge for Advancing Task Expertise in Large Language\n  Models", "abstract": "The cultivation of expertise for large language models (LLMs) to solve tasks\nof specific areas often requires special-purpose tuning with calibrated\nbehaviors on the expected stable outputs. To avoid huge cost brought by manual\npreparation of instruction datasets and training resources up to hundreds of\nhours, the exploitation of open knowledge including a wealth of low rank\nadaptation (LoRA) models and instruction datasets serves as a good starting\npoint. However, existing methods on model and data selection focus on the\nperformance of general-purpose capabilities while neglecting the knowledge gap\nexposed in domain-specific deployment. In the present study, we propose to\nbridge such gap by introducing few human-annotated samples (i.e., K-shot) for\nadvancing task expertise of LLMs with open knowledge. Specifically, we develop\nan efficient and scalable pipeline to cost-efficiently produce task experts\nwhere K-shot data intervene in selecting the most promising expert candidates\nand the task-relevant instructions. A mixture-of-expert (MoE) system is built\nto make the best use of individual-yet-complementary knowledge between multiple\nexperts. We unveil the two keys to the success of a MoE system, 1) the abidance\nby K-shot, and 2) the insistence on diversity. For the former, we ensure that\nmodels that truly possess problem-solving abilities on K-shot are selected\nrather than those blind guessers. Besides, during data selection, instructions\nthat share task-relevant contexts with K-shot are prioritized. For the latter,\nwe highlight the diversity of constituting experts and that of the fine-tuning\ninstructions throughout the model and data selection process. Extensive\nexperimental results confirm the superiority of our approach over existing\nmethods on utilization of open knowledge across various tasks. Our codes will\nbe available at https://github.com/Yaphabates/Rocket.", "published": "2024-08-28 16:28:07", "link": "http://arxiv.org/abs/2408.15915v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "More Text, Less Point: Towards 3D Data-Efficient Point-Language\n  Understanding", "abstract": "Enabling Large Language Models (LLMs) to comprehend the 3D physical world\nremains a significant challenge. Due to the lack of large-scale 3D-text pair\ndatasets, the success of LLMs has yet to be replicated in 3D understanding. In\nthis paper, we rethink this issue and propose a new task: 3D Data-Efficient\nPoint-Language Understanding. The goal is to enable LLMs to achieve robust 3D\nobject understanding with minimal 3D point cloud and text data pairs. To\naddress this task, we introduce GreenPLM, which leverages more text data to\ncompensate for the lack of 3D data. First, inspired by using CLIP to align\nimages and text, we utilize a pre-trained point cloud-text encoder to map the\n3D point cloud space to the text space. This mapping leaves us to seamlessly\nconnect the text space with LLMs. Once the point-text-LLM connection is\nestablished, we further enhance text-LLM alignment by expanding the\nintermediate text space, thereby reducing the reliance on 3D point cloud data.\nSpecifically, we generate 6M free-text descriptions of 3D objects, and design a\nthree-stage training strategy to help LLMs better explore the intrinsic\nconnections between different modalities. To achieve efficient modality\nalignment, we design a zero-parameter cross-attention module for token pooling.\nExtensive experimental results show that GreenPLM requires only 12% of the 3D\ntraining data used by existing state-of-the-art models to achieve superior 3D\nunderstanding. Remarkably, GreenPLM also achieves competitive performance using\ntext-only data. The code and weights are available at:\nhttps://github.com/TangYuan96/GreenPLM.", "published": "2024-08-28 17:38:44", "link": "http://arxiv.org/abs/2408.15966v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "CoGen: Learning from Feedback with Coupled Comprehension and Generation", "abstract": "Systems with both language comprehension and generation capabilities can\nbenefit from the tight connection between the two. This work studies coupling\ncomprehension and generation with focus on continually learning from\ninteraction with users. We propose techniques to tightly integrate the two\ncapabilities for both learning and inference. We situate our studies in\ntwo-player reference games, and deploy various models for thousands of\ninteractions with human users, while learning from interaction feedback\nsignals. We show dramatic improvements in performance over time, with\ncomprehension-generation coupling leading to performance improvements up to 26%\nin absolute terms and up to 17% higher accuracies compared to a non-coupled\nsystem. Our analysis also shows coupling has substantial qualitative impact on\nthe system's language, making it significantly more human-like.", "published": "2024-08-28 17:58:39", "link": "http://arxiv.org/abs/2408.15992v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Logic-Enhanced Language Model Agents for Trustworthy Social Simulations", "abstract": "We introduce the Logic-Enhanced Language Model Agents (LELMA) framework, a\nnovel approach to enhance the trustworthiness of social simulations that\nutilize large language models (LLMs). While LLMs have gained attention as\nagents for simulating human behaviour, their applicability in this role is\nlimited by issues such as inherent hallucinations and logical inconsistencies.\nLELMA addresses these challenges by integrating LLMs with symbolic AI, enabling\nlogical verification of the reasoning generated by LLMs. This verification\nprocess provides corrective feedback, refining the reasoning output. The\nframework consists of three main components: an LLM-Reasoner for producing\nstrategic reasoning, an LLM-Translator for mapping natural language reasoning\nto logic queries, and a Solver for evaluating these queries. This study focuses\non decision-making in game-theoretic scenarios as a model of human interaction.\nExperiments involving the Hawk-Dove game, Prisoner's Dilemma, and Stag Hunt\nhighlight the limitations of state-of-the-art LLMs, GPT-4 Omni and Gemini 1.0\nPro, in producing correct reasoning in these contexts. LELMA demonstrates high\naccuracy in error detection and improves the reasoning correctness of LLMs via\nself-refinement, particularly in GPT-4 Omni.", "published": "2024-08-28 18:25:35", "link": "http://arxiv.org/abs/2408.16081v1", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LO"], "primary_category": "cs.AI"}
{"title": "3-in-1: 2D Rotary Adaptation for Efficient Finetuning, Efficient\n  Batching and Composability", "abstract": "Parameter-efficient finetuning (PEFT) methods effectively adapt large\nlanguage models (LLMs) to diverse downstream tasks, reducing storage and GPU\nmemory demands. Despite these advantages, several applications pose new\nchallenges to PEFT beyond mere parameter efficiency. One notable challenge\ninvolves the efficient deployment of LLMs equipped with multiple task- or\nuser-specific adapters, particularly when different adapters are needed for\ndistinct requests within the same batch. Another challenge is the\ninterpretability of LLMs, which is crucial for understanding how LLMs function.\nPrevious studies introduced various approaches to address different challenges.\nIn this paper, we introduce a novel method, RoAd, which employs a\nstraightforward 2D rotation to adapt LLMs and addresses all the above\nchallenges: (1) RoAd is remarkably parameter-efficient, delivering optimal\nperformance on GLUE, eight commonsense reasoning tasks and four arithmetic\nreasoning tasks with $<0.1\\%$ trainable parameters; (2) RoAd facilitates the\nefficient serving of requests requiring different adapters within a batch, with\nan overhead comparable to element-wise multiplication instead of batch matrix\nmultiplication; (3) RoAd enhances LLM's interpretability through integration\nwithin a framework of distributed interchange intervention, demonstrated via\ncomposition experiments.", "published": "2024-08-28 08:45:29", "link": "http://arxiv.org/abs/2409.00119v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Leveraging Large Language Models for Wireless Symbol Detection via\n  In-Context Learning", "abstract": "Deep neural networks (DNNs) have made significant strides in tackling\nchallenging tasks in wireless systems, especially when an accurate wireless\nmodel is not available. However, when available data is limited, traditional\nDNNs often yield subpar results due to underfitting. At the same time, large\nlanguage models (LLMs) exemplified by GPT-3, have remarkably showcased their\ncapabilities across a broad range of natural language processing tasks. But\nwhether and how LLMs can benefit challenging non-language tasks in wireless\nsystems is unexplored. In this work, we propose to leverage the in-context\nlearning ability (a.k.a. prompting) of LLMs to solve wireless tasks in the low\ndata regime without any training or fine-tuning, unlike DNNs which require\ntraining. We further demonstrate that the performance of LLMs varies\nsignificantly when employed with different prompt templates. To solve this\nissue, we employ the latest LLM calibration methods. Our results reveal that\nusing LLMs via ICL methods generally outperforms traditional DNNs on the symbol\ndemodulation task and yields highly confident predictions when coupled with\ncalibration techniques.", "published": "2024-08-28 17:19:20", "link": "http://arxiv.org/abs/2409.00124v2", "categories": ["eess.SP", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Responsible AI for Test Equity and Quality: The Duolingo English Test as\n  a Case Study", "abstract": "Artificial intelligence (AI) creates opportunities for assessments, such as\nefficiencies for item generation and scoring of spoken and written responses.\nAt the same time, it poses risks (such as bias in AI-generated item content).\nResponsible AI (RAI) practices aim to mitigate risks associated with AI. This\nchapter addresses the critical role of RAI practices in achieving test quality\n(appropriateness of test score inferences), and test equity (fairness to all\ntest takers). To illustrate, the chapter presents a case study using the\nDuolingo English Test (DET), an AI-powered, high-stakes English language\nassessment. The chapter discusses the DET RAI standards, their development and\ntheir relationship to domain-agnostic RAI principles. Further, it provides\nexamples of specific RAI practices, showing how these practices meaningfully\naddress the ethical principles of validity and reliability, fairness, privacy\nand security, and transparency and accountability standards to ensure test\nequity and quality.", "published": "2024-08-28 11:39:20", "link": "http://arxiv.org/abs/2409.07476v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Drop the beat! Freestyler for Accompaniment Conditioned Rapping Voice\n  Generation", "abstract": "Rap, a prominent genre of vocal performance, remains underexplored in vocal\ngeneration. General vocal synthesis depends on precise note and duration\ninputs, requiring users to have related musical knowledge, which limits\nflexibility. In contrast, rap typically features simpler melodies, with a core\nfocus on a strong rhythmic sense that harmonizes with accompanying beats. In\nthis paper, we propose Freestyler, the first system that generates rapping\nvocals directly from lyrics and accompaniment inputs. Freestyler utilizes\nlanguage model-based token generation, followed by a conditional flow matching\nmodel to produce spectrograms and a neural vocoder to restore audio. It allows\na 3-second prompt to enable zero-shot timbre control. Due to the scarcity of\npublicly available rap datasets, we also present RapBank, a rap song dataset\ncollected from the internet, alongside a meticulously designed processing\npipeline. Experimental results show that Freestyler produces high-quality\nrapping voice generation with enhanced naturalness and strong alignment with\naccompanying beats, both stylistically and rhythmically.", "published": "2024-08-28 01:44:08", "link": "http://arxiv.org/abs/2408.15474v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Noise-to-mask Ratio Loss for Deep Neural Network based Audio\n  Watermarking", "abstract": "Digital audio watermarking consists in inserting a message into audio signals\nin a transparent way and can be used to allow automatic recognition of audio\nmaterial and management of the copyrights. We propose a perceptual loss\nfunction to be used in deep neural network based audio watermarking systems.\nThe loss is based on the noise-to-mask ratio (NMR), which is a model of the\npsychoacoustic masking effect characteristic of the human ear. We use the NMR\nloss between marked and host signals to train the deep neural models and we\nevaluate the objective quality with PEAQ and the subjective quality with a\nMUSHRA test. Both objective and subjective tests show that models trained with\nNMR loss generate more transparent watermarks than models trained with the\nconventionally used MSE loss", "published": "2024-08-28 06:06:59", "link": "http://arxiv.org/abs/2408.15553v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spectral Masking with Explicit Time-Context Windowing for Neural\n  Network-Based Monaural Speech Enhancement", "abstract": "We propose and analyze the use of an explicit time-context window for neural\nnetwork-based spectral masking speech enhancement to leverage signal context\ndependencies between neighboring frames. In particular, we concentrate on soft\nmasking and loss computed on the time-frequency representation of the\nreconstructed speech. We show that the application of a time-context windowing\nfunction at both input and output of the neural network model improves the soft\nmask estimation process by combining multiple estimates taken from different\ncontexts. The proposed approach is only applied as post-optimization in\ninference mode, not requiring additional layers or special training for the\nneural network model. Our results show that the method consistently increases\nboth intelligibility and signal quality of the denoised speech, as demonstrated\nfor two classes of convolutional-based speech enhancement models. Importantly,\nthe proposed method requires only a negligible ($\\leq1\\%$) increase in the\nnumber of model parameters, making it suitable for hardware-constrained\napplications.", "published": "2024-08-28 07:08:09", "link": "http://arxiv.org/abs/2408.15582v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Whisper-PMFA: Partial Multi-Scale Feature Aggregation for Speaker\n  Verification using Whisper Models", "abstract": "In this paper, Whisper, a large-scale pre-trained model for automatic speech\nrecognition, is proposed to apply to speaker verification. A partial\nmulti-scale feature aggregation (PMFA) approach is proposed based on a subset\nof Whisper encoder blocks to derive highly discriminative speaker\nembeddings.Experimental results demonstrate that using the middle to later\nblocks of the Whisper encoder keeps more speaker information. On the VoxCeleb1\nand CN-Celeb1 datasets, our system achieves 1.42% and 8.23% equal error rates\n(EERs) respectively, receiving 0.58% and 1.81% absolute EER reductions over the\nECAPA-TDNN baseline, and 0.46% and 0.97% over the ResNet34 baseline.\nFurthermore, our results indicate that using Whisper models trained on\nmultilingual data can effectively enhance the model's robustness across\nlanguages. Finally, the low-rank adaptation approach is evaluated, which\nreduces the trainable model parameters by approximately 45 times while only\nslightly increasing EER by 0.2%.", "published": "2024-08-28 07:21:36", "link": "http://arxiv.org/abs/2408.15585v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VoxInstruct: Expressive Human Instruction-to-Speech Generation with\n  Unified Multilingual Codec Language Modelling", "abstract": "Recent AIGC systems possess the capability to generate digital multimedia\ncontent based on human language instructions, such as text, image and video.\nHowever, when it comes to speech, existing methods related to human\ninstruction-to-speech generation exhibit two limitations. Firstly, they require\nthe division of inputs into content prompt (transcript) and description prompt\n(style and speaker), instead of directly supporting human instruction. This\ndivision is less natural in form and does not align with other AIGC models.\nSecondly, the practice of utilizing an independent description prompt to model\nspeech style, without considering the transcript content, restricts the ability\nto control speech at a fine-grained level. To address these limitations, we\npropose VoxInstruct, a novel unified multilingual codec language modeling\nframework that extends traditional text-to-speech tasks into a general human\ninstruction-to-speech task. Our approach enhances the expressiveness of human\ninstruction-guided speech generation and aligns the speech generation paradigm\nwith other modalities. To enable the model to automatically extract the content\nof synthesized speech from raw text instructions, we introduce speech semantic\ntokens as an intermediate representation for instruction-to-content guidance.\nWe also incorporate multiple Classifier-Free Guidance (CFG) strategies into our\ncodec language model, which strengthens the generated speech following human\ninstructions. Furthermore, our model architecture and training strategies allow\nfor the simultaneous support of combining speech prompt and descriptive human\ninstruction for expressive speech synthesis, which is a first-of-its-kind\nattempt. Codes, models and demos are at:\nhttps://github.com/thuhcsi/VoxInstruct.", "published": "2024-08-28 09:57:17", "link": "http://arxiv.org/abs/2408.15676v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Hybrid Approach for Low-Complexity Joint Acoustic Echo and Noise\n  Reduction", "abstract": "Deep learning-based methods that jointly perform the task of acoustic echo\nand noise reduction (AENR) often require high memory and computational\nresources, making them unsuitable for real-time deployment on low-resource\nplatforms such as embedded devices. We propose a low-complexity hybrid approach\nfor joint AENR by employing a single model to suppress both residual echo and\nnoise components. Specifically, we integrate the state-of-the-art (SOTA) ULCNet\nmodel, which was originally proposed to achieve ultra-low complexity noise\nsuppression, in a hybrid system and train it for joint AENR. We show that the\nproposed approach achieves better echo reduction and comparable noise reduction\nperformance with much lower computational complexity and memory requirements\nthan all considered SOTA methods, at the cost of slight degradation in speech\nquality.", "published": "2024-08-28 12:24:54", "link": "http://arxiv.org/abs/2408.15746v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spoofing-Robust Speaker Verification Using Parallel Embedding Fusion:\n  BTU Speech Group's Approach for ASVspoof5 Challenge", "abstract": "This paper introduces the parallel network-based spoofing-aware speaker\nverification (SASV) system developed by BTU Speech Group for the ASVspoof5\nChallenge. The SASV system integrates ASV and CM systems to enhance security\nagainst spoofing attacks. Our approach employs score and embedding fusion from\nASV models (ECAPA-TDNN, WavLM) and CM models (AASIST). The fused embeddings are\nprocessed using a simple DNN structure, optimizing model performance with a\ncombination of recently proposed a-DCF and BCE losses. We introduce a novel\nparallel network structure where two identical DNNs, fed with different inputs,\nindependently process embeddings and produce SASV scores. The final SASV\nprobability is derived by averaging these scores, enhancing robustness and\naccuracy. Experimental results demonstrate that the proposed parallel DNN\nstructure outperforms traditional single DNN methods, offering a more reliable\nand secure speaker verification system against spoofing attacks.", "published": "2024-08-28 15:48:03", "link": "http://arxiv.org/abs/2408.15877v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor\n  Attacks on Deep Speech Classification Models", "abstract": "Deep speech classification tasks, mainly including keyword spotting and\nspeaker verification, play a crucial role in speech-based human-computer\ninteraction. Recently, the security of these technologies has been demonstrated\nto be vulnerable to backdoor attacks. Specifically speaking, speech samples are\nattacked by noisy disruption and component modification in present triggers. We\nsuggest that speech backdoor attacks can strategically focus on emotion, a\nhigher-level subjective perceptual attribute inherent in speech. Furthermore,\nwe proposed that emotional voice conversion technology can serve as the speech\nbackdoor attack trigger, and the method is called EmoAttack. Based on this, we\nconducted attack experiments on two speech classification tasks, showcasing\nthat EmoAttack method owns impactful trigger effectiveness and its remarkable\nattack success rate and accuracy variance. Additionally, the ablation\nexperiments found that speech with intensive emotion is more suitable to be\ntargeted for attacks.", "published": "2024-08-28 03:36:43", "link": "http://arxiv.org/abs/2408.15508v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards reliable respiratory disease diagnosis based on cough sounds and\n  vision transformers", "abstract": "Recent advancements in deep learning techniques have sparked performance\nboosts in various real-world applications including disease diagnosis based on\nmulti-modal medical data. Cough sound data-based respiratory disease (e.g.,\nCOVID-19 and Chronic Obstructive Pulmonary Disease) diagnosis has also\nattracted much attention. However, existing works usually utilise traditional\nmachine learning or deep models of moderate scales. On the other hand, the\ndeveloped approaches are trained and evaluated on small-scale data due to the\ndifficulty of curating and annotating clinical data on scale. To address these\nissues in prior works, we create a unified framework to evaluate various deep\nmodels from lightweight Convolutional Neural Networks (e.g., ResNet18) to\nmodern vision transformers and compare their performance in respiratory disease\nclassification. Based on the observations from such an extensive empirical\nstudy, we propose a novel approach to cough-based disease classification based\non both self-supervised and supervised learning on a large-scale cough data\nset. Experimental results demonstrate our proposed approach outperforms prior\narts consistently on two benchmark datasets for COVID-19 diagnosis and a\nproprietary dataset for COPD/non-COPD classification with an AUROC of 92.5%.", "published": "2024-08-28 09:40:40", "link": "http://arxiv.org/abs/2408.15667v2", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "wav2pos: Sound Source Localization using Masked Autoencoders", "abstract": "We present a novel approach to the 3D sound source localization task for\ndistributed ad-hoc microphone arrays by formulating it as a set-to-set\nregression problem. By training a multi-modal masked autoencoder model that\noperates on audio recordings and microphone coordinates, we show that such a\nformulation allows for accurate localization of the sound source, by\nreconstructing coordinates masked in the input. Our approach is flexible in the\nsense that a single model can be used with an arbitrary number of microphones,\neven when a subset of audio recordings and microphone coordinates are missing.\nWe test our method on simulated and real-world recordings of music and speech\nin indoor environments, and demonstrate competitive performance compared to\nboth classical and other learning based localization methods.", "published": "2024-08-28 13:09:20", "link": "http://arxiv.org/abs/2408.15771v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Easy, Interpretable, Effective: openSMILE for voice deepfake detection", "abstract": "In this paper, we demonstrate that attacks in the latest ASVspoof5 dataset --\na de facto standard in the field of voice authenticity and deepfake detection\n-- can be identified with surprising accuracy using a small subset of very\nsimplistic features. These are derived from the openSMILE library, and are\nscalar-valued, easy to compute, and human interpretable. For example, attack\nA10`s unvoiced segments have a mean length of 0.09 +- 0.02, while bona fide\ninstances have a mean length of 0.18 +- 0.07. Using this feature alone, a\nthreshold classifier achieves an Equal Error Rate (EER) of 10.3% for attack\nA10. Similarly, across all attacks, we achieve up to 0.8% EER, with an overall\nEER of 15.7 +- 6.0%. We explore the generalization capabilities of these\nfeatures and find that some of them transfer effectively between attacks,\nprimarily when the attacks originate from similar Text-to-Speech (TTS)\narchitectures. This finding may indicate that voice anti-spoofing is, in part,\na problem of identifying and remembering signatures or fingerprints of\nindividual TTS systems. This allows to better understand anti-spoofing models\nand their challenges in real-world application.", "published": "2024-08-28 13:14:18", "link": "http://arxiv.org/abs/2408.15775v2", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ModalityMirror: Improving Audio Classification in Modality Heterogeneity\n  Federated Learning with Multimodal Distillation", "abstract": "Multimodal Federated Learning frequently encounters challenges of client\nmodality heterogeneity, leading to undesired performances for secondary\nmodality in multimodal learning. It is particularly prevalent in audiovisual\nlearning, with audio is often assumed to be the weaker modality in recognition\ntasks. To address this challenge, we introduce ModalityMirror to improve audio\nmodel performance by leveraging knowledge distillation from an audiovisual\nfederated learning model. ModalityMirror involves two phases: a modality-wise\nFL stage to aggregate uni-modal encoders; and a federated knowledge\ndistillation stage on multi-modality clients to train an unimodal student\nmodel. Our results demonstrate that ModalityMirror significantly improves the\naudio classification compared to the state-of-the-art FL methods such as\nHarmony, particularly in audiovisual FL facing video missing. Our approach\nunlocks the potential for exploiting the diverse modality spectrum inherent in\nmulti-modal FL.", "published": "2024-08-28 13:56:22", "link": "http://arxiv.org/abs/2408.15803v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-modal Adversarial Training for Zero-Shot Voice Cloning", "abstract": "A text-to-speech (TTS) model trained to reconstruct speech given text tends\ntowards predictions that are close to the average characteristics of a dataset,\nfailing to model the variations that make human speech sound natural. This\nproblem is magnified for zero-shot voice cloning, a task that requires training\ndata with high variance in speaking styles. We build off of recent works which\nhave used Generative Advsarial Networks (GAN) by proposing a Transformer\nencoder-decoder architecture to conditionally discriminates between real and\ngenerated speech features. The discriminator is used in a training pipeline\nthat improves both the acoustic and prosodic features of a TTS model. We\nintroduce our novel adversarial training technique by applying it to a\nFastSpeech2 acoustic model and training on Libriheavy, a large multi-speaker\ndataset, for the task of zero-shot voice cloning. Our model achieves\nimprovements over the baseline in terms of speech quality and speaker\nsimilarity. Audio examples from our system are available online.", "published": "2024-08-28 16:30:41", "link": "http://arxiv.org/abs/2408.15916v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Learning-Based Automatic Multi-Level Airway Collapse Monitoring on\n  Obstructive Sleep Apnea Patients", "abstract": "This study investigated the use of deep learning to identify multi-level\nupper airway collapses in obstructive sleep apnea (OSA) patients based on\nsnoring sounds. We fi-ne-tuned ResNet-50 and Audio Spectrogram Transformer\n(AST) models using snoring recordings from 37 subjects undergoing drug-induced\nsleep endoscopy (DISE) between 2020 and 2021. Snoring sounds were labeled\naccording to the VOTE (Velum, Orophar-ynx, Tongue Base, Epiglottis)\nclassification, resulting in 259 V, 403 O, 77 T, 13 E, 1016 VO, 46 VT, 140 OT,\n39 OE, 30 VOT, and 3150 non-snoring (N) 0.5-second clips. The models were\ntrained for two multi-label classification tasks: identifying obstructions at\nV, O, T, and E levels, and identifying retropalatal (RP) and retroglossal (RG)\nobstruc-tions. Results showed AST slightly outperformed ResNet-50,\ndemonstrating good abil-ity to identify V (F1-score: 0.71, MCC: 0.61, AUC:\n0.89), O (F1-score: 0.80, MCC: 0.72, AUC: 0.94), and RP obstructions (F1-score:\n0.86, MCC: 0.77, AUC: 0.97). However, both models struggled with T, E, and RG\nclassifications due to limited data. Retrospective analysis of a full-night\nrecording showed the potential to profile airway obstruction dynamics. We\nexpect this information, combined with polysomnography and other clinical\nparameters, can aid clinical triage and treatment planning for OSA patients.", "published": "2024-08-28 09:30:20", "link": "http://arxiv.org/abs/2408.16030v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Generalization of Speech Separation in Real-World Scenarios:\n  Strategies in Simulation, Optimization, and Evaluation", "abstract": "Achieving robust speech separation for overlapping speakers in various\nacoustic environments with noise and reverberation remains an open challenge.\nAlthough existing datasets are available to train separators for specific\nscenarios, they do not effectively generalize across diverse real-world\nscenarios. In this paper, we present a novel data simulation pipeline that\nproduces diverse training data from a range of acoustic environments and\ncontent, and propose new training paradigms to improve quality of a general\nspeech separation model. Specifically, we first introduce AC-SIM, a data\nsimulation pipeline that incorporates broad variations in both content and\nacoustics. Then we integrate multiple training objectives into the permutation\ninvariant training (PIT) to enhance separation quality and generalization of\nthe trained model. Finally, we conduct comprehensive objective and human\nlistening experiments across separation architectures and benchmarks to\nvalidate our methods, demonstrating substantial improvement of generalization\non both non-homologous and real-world test sets.", "published": "2024-08-28 20:26:34", "link": "http://arxiv.org/abs/2408.16126v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SVDD 2024: The Inaugural Singing Voice Deepfake Detection Challenge", "abstract": "With the advancements in singing voice generation and the growing presence of\nAI singers on media platforms, the inaugural Singing Voice Deepfake Detection\n(SVDD) Challenge aims to advance research in identifying AI-generated singing\nvoices from authentic singers. This challenge features two tracks: a controlled\nsetting track (CtrSVDD) and an in-the-wild scenario track (WildSVDD). The\nCtrSVDD track utilizes publicly available singing vocal data to generate\ndeepfakes using state-of-the-art singing voice synthesis and conversion\nsystems. Meanwhile, the WildSVDD track expands upon the existing SingFake\ndataset, which includes data sourced from popular user-generated content\nwebsites. For the CtrSVDD track, we received submissions from 47 teams, with 37\nsurpassing our baselines and the top team achieving a 1.65% equal error rate.\nFor the WildSVDD track, we benchmarked the baselines. This paper reviews these\nresults, discusses key findings, and outlines future directions for SVDD\nresearch.", "published": "2024-08-28 20:48:04", "link": "http://arxiv.org/abs/2408.16132v2", "categories": ["eess.AS", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "BELT-2: Bootstrapping EEG-to-Language representation alignment for\n  multi-task brain decoding", "abstract": "The remarkable success of large language models (LLMs) across various\nmulti-modality applications is well established. However, integrating large\nlanguage models with humans, or brain dynamics, remains relatively unexplored.\nIn this paper, we introduce BELT-2, a pioneering multi-task model designed to\nenhance both encoding and decoding performance from EEG signals. To bolster the\nquality of the EEG encoder, BELT-2 is the first work to innovatively 1) adopt\nbyte-pair encoding (BPE)-level EEG-language alignment and 2) integrate\nmulti-task training and decoding in the EEG domain. Inspired by the idea of\n\\textbf{\\textit{Bridging the Brain with GPT}}, we further connect the\nmulti-task EEG encoder with LLMs by utilizing prefix-tuning on intermediary\noutput from the EEG encoder. These innovative efforts make BELT-2 a pioneering\nbreakthrough, making it the first work in the field capable of decoding\ncoherent and readable sentences from non-invasive brain signals. Our\nexperiments highlight significant advancements over prior techniques in both\nquantitative and qualitative measures, achieving a decoding performance with a\nBLEU-1 score of 52.2\\% on the ZuCo dataset. Furthermore, BELT-2 shows a\nremarkable improvement ranging from 31\\% to 162\\% on other translation\nbenchmarks. Codes can be accessed via the provided anonymous\nlink~\\footnote{https://anonymous.4open.science/r/BELT-2-0048}.", "published": "2024-08-28 12:30:22", "link": "http://arxiv.org/abs/2409.00121v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Flexible Control in Symbolic Music Generation via Musical Metadata", "abstract": "In this work, we introduce the demonstration of symbolic music generation,\nfocusing on providing short musical motifs that serve as the central theme of\nthe narrative. For the generation, we adopt an autoregressive model which takes\nmusical metadata as inputs and generates 4 bars of multitrack MIDI sequences.\nDuring training, we randomly drop tokens from the musical metadata to guarantee\nflexible control. It provides users with the freedom to select input types\nwhile maintaining generative performance, enabling greater flexibility in music\ncomposition. We validate the effectiveness of the strategy through experiments\nin terms of model capacity, musical fidelity, diversity, and controllability.\nAdditionally, we scale up the model and compare it with other music generation\nmodel through a subjective test. Our results indicate its superiority in both\ncontrol and music quality. We provide a URL link\nhttps://www.youtube.com/watch?v=-0drPrFJdMQ to our demonstration video.", "published": "2024-08-28 04:35:08", "link": "http://arxiv.org/abs/2409.07467v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
