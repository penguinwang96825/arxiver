{"title": "Privacy Preserving Prompt Engineering: A Survey", "abstract": "Pre-trained language models (PLMs) have demonstrated significant proficiency\nin solving a wide range of general natural language processing (NLP) tasks.\nResearchers have observed a direct correlation between the performance of these\nmodels and their sizes. As a result, the sizes of these models have notably\nexpanded in recent years, persuading researchers to adopt the term large\nlanguage models (LLMs) to characterize the larger-sized PLMs. The size\nexpansion comes with a distinct capability called in-context learning (ICL),\nwhich represents a special form of prompting and allows the models to be\nutilized through the presentation of demonstration examples without\nmodifications to the model parameters. Although interesting, privacy concerns\nhave become a major obstacle in its widespread usage. Multiple studies have\nexamined the privacy risks linked to ICL and prompting in general, and have\ndevised techniques to alleviate these risks. Thus, there is a necessity to\norganize these mitigation techniques for the benefit of the community. This\nsurvey provides a systematic overview of the privacy protection methods\nemployed during ICL and prompting in general. We review, analyze, and compare\ndifferent methods under this paradigm. Furthermore, we provide a summary of the\nresources accessible for the development of these frameworks. Finally, we\ndiscuss the limitations of these frameworks and offer a detailed examination of\nthe promising areas that necessitate further exploration.", "published": "2024-04-09 04:11:25", "link": "http://arxiv.org/abs/2404.06001v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Shopping Intent in Product QA for Proactive Recommendations", "abstract": "Voice assistants have become ubiquitous in smart devices allowing users to\ninstantly access information via voice questions. While extensive research has\nbeen conducted in question answering for voice search, little attention has\nbeen paid on how to enable proactive recommendations from a voice assistant to\nits users. This is a highly challenging problem that often leads to user\nfriction, mainly due to recommendations provided to the users at the wrong\ntime. We focus on the domain of e-commerce, namely in identifying Shopping\nProduct Questions (SPQs), where the user asking a product-related question may\nhave an underlying shopping need. Identifying a user's shopping need allows\nvoice assistants to enhance shopping experience by determining when to provide\nrecommendations, such as product or deal recommendations, or proactive shopping\nactions recommendation. Identifying SPQs is a challenging problem and cannot be\ndone from question text alone, and thus requires to infer latent user behavior\npatterns inferred from user's past shopping history. We propose features that\ncapture the user's latent shopping behavior from their purchase history, and\ncombine them using a novel Mixture-of-Experts (MoE) model. Our evaluation shows\nthat the proposed approach is able to identify SPQs with a high score of\nF1=0.91. Furthermore, based on an online evaluation with real voice assistant\nusers, we identify SPQs in real-time and recommend shopping actions to users to\nadd the queried product into their shopping list. We demonstrate that we are\nable to accurately identify SPQs, as indicated by the significantly higher rate\nof added products to users' shopping lists when being prompted after SPQs vs\nrandom PQs.", "published": "2024-04-09 04:55:24", "link": "http://arxiv.org/abs/2404.06017v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Making Old Kurdish Publications Processable by Augmenting Available\n  Optical Character Recognition Engines", "abstract": "Kurdish libraries have many historical publications that were printed back in\nthe early days when printing devices were brought to Kurdistan. Having a good\nOptical Character Recognition (OCR) to help process these publications and\ncontribute to the Kurdish languages resources which is crucial as Kurdish is\nconsidered a low-resource language. Current OCR systems are unable to extract\ntext from historical documents as they have many issues, including being\ndamaged, very fragile, having many marks left on them, and often written in\nnon-standard fonts and more. This is a massive obstacle in processing these\ndocuments as currently processing them requires manual typing which is very\ntime-consuming. In this study, we adopt an open-source OCR framework by Google,\nTesseract version 5.0, that has been used to extract text for various\nlanguages. Currently, there is no public dataset, and we developed our own by\ncollecting historical documents from Zheen Center for Documentation and\nResearch, which were printed before 1950 and resulted in a dataset of 1233\nimages of lines with transcription of each. Then we used the Arabic model as\nour base model and trained the model using the dataset. We used different\nmethods to evaluate our model, Tesseracts built-in evaluator lstmeval indicated\na Character Error Rate (CER) of 0.755%. Additionally, Ocreval demonstrated an\naverage character accuracy of 84.02%. Finally, we developed a web application\nto provide an easy- to-use interface for end-users, allowing them to interact\nwith the model by inputting an image of a page and extracting the text. Having\nan extensive dataset is crucial to develop OCR systems with reasonable\naccuracy, as currently, no public datasets are available for historical Kurdish\ndocuments; this posed a significant challenge in our work. Additionally, the\nunaligned spaces between characters and words proved another challenge with our\nwork.", "published": "2024-04-09 08:08:03", "link": "http://arxiv.org/abs/2404.06101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Necessity of Visual Modality in Multimodal Machine\n  Translation using Authentic Datasets", "abstract": "Recent research in the field of multimodal machine translation (MMT) has\nindicated that the visual modality is either dispensable or offers only\nmarginal advantages. However, most of these conclusions are drawn from the\nanalysis of experimental results based on a limited set of bilingual\nsentence-image pairs, such as Multi30k. In these kinds of datasets, the content\nof one bilingual parallel sentence pair must be well represented by a manually\nannotated image, which is different from the real-world translation scenario.\nIn this work, we adhere to the universal multimodal machine translation\nframework proposed by Tang et al. (2022). This approach allows us to delve into\nthe impact of the visual modality on translation efficacy by leveraging\nreal-world translation datasets. Through a comprehensive exploration via\nprobing tasks, we find that the visual modality proves advantageous for the\nmajority of authentic translation datasets. Notably, the translation\nperformance primarily hinges on the alignment and coherence between textual and\nvisual contents. Furthermore, our results suggest that visual information\nserves a supplementary role in multimodal translation and can be substituted.", "published": "2024-04-09 08:19:10", "link": "http://arxiv.org/abs/2404.06107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection of fields of applications in biomedical abstracts with the\n  support of argumentation elements", "abstract": "Focusing on particular facts, instead of the complete text, can potentially\nimprove searching for specific information in the scientific literature. In\nparticular, argumentative elements allow focusing on specific parts of a\npublication, e.g., the background section or the claims from the authors. We\nevaluated some tools for the extraction of argumentation elements for a\nspecific task in biomedicine, namely, for detecting the fields of the\napplication in a biomedical publication, e.g, whether it addresses the problem\nof disease diagnosis or drug development. We performed experiments with the\nPubMedBERT pre-trained model, which was fine-tuned on a specific corpus for the\ntask. We compared the use of title and abstract to restricting to only some\nargumentative elements. The top F1 scores ranged from 0.22 to 0.84, depending\non the field of application. The best argumentative labels were the ones\nrelated the conclusion and background sections of an abstract.", "published": "2024-04-09 08:44:02", "link": "http://arxiv.org/abs/2404.06121v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cendol: Open Instruction-tuned Generative Large Language Models for\n  Indonesian Languages", "abstract": "Large language models (LLMs) show remarkable human-like capability in various\ndomains and languages. However, a notable quality gap arises in low-resource\nlanguages, e.g., Indonesian indigenous languages, rendering them ineffective\nand inefficient in such linguistic contexts. To bridge this quality gap, we\nintroduce Cendol, a collection of Indonesian LLMs encompassing both\ndecoder-only and encoder-decoder architectures across a range of model sizes.\nWe highlight Cendol's effectiveness across a diverse array of tasks, attaining\n20% improvement, and demonstrate its capability to generalize to unseen tasks\nand indigenous languages of Indonesia. Furthermore, Cendol models showcase\nimproved human favorability despite their limitations in capturing indigenous\nknowledge and cultural values in Indonesia. In addition, we discuss the\nshortcomings of parameter-efficient tunings, such as LoRA, for language\nadaptation. Alternatively, we propose the usage of vocabulary adaptation to\nenhance efficiency. Lastly, we evaluate the safety of Cendol and showcase that\nsafety in pre-training in one language such as English is transferable to\nlow-resource languages, such as Indonesian, even without RLHF and safety\nfine-tuning.", "published": "2024-04-09 09:04:30", "link": "http://arxiv.org/abs/2404.06138v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "(Not) Understanding Latin Poetic Style with Deep Learning", "abstract": "This article summarizes some mostly unsuccessful attempts to understand\nauthorial style by examining the attention of various neural networks (LSTMs\nand CNNs) trained on a corpus of classical Latin verse that has been encoded to\ninclude sonic and metrical features. Carefully configured neural networks are\nshown to be extremely strong authorship classifiers, so it is hoped that they\nmight therefore teach `traditional' readers something about how the authors\ndiffer in style. Sadly their reasoning is, so far, inscrutable. While the\noverall goal has not yet been reached, this work reports some useful findings\nin terms of effective ways to encode and embed verse, the relative strengths\nand weaknesses of the neural network families, and useful (and not so useful)\ntechniques for designing and inspecting NN models in this domain. This article\nsuggests that, for poetry, CNNs are better choices than LSTMs -- they train\nmore quickly, have equivalent accuracy, and (potentially) offer better\ninterpretability. Based on a great deal of experimentation, it also suggests\nthat simple, trainable embeddings are more effective than domain-specific\nschemes, and stresses the importance of techniques to reduce overfitting, like\ndropout and batch normalization.", "published": "2024-04-09 09:21:56", "link": "http://arxiv.org/abs/2404.06150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "[Call for Papers] The 2nd BabyLM Challenge: Sample-efficient pretraining\n  on a developmentally plausible corpus", "abstract": "After last year's successful BabyLM Challenge, the competition will be hosted\nagain in 2024/2025. The overarching goals of the challenge remain the same;\nhowever, some of the competition rules will be different. The big changes for\nthis year's competition are as follows: First, we replace the loose track with\na paper track, which allows (for example) non-model-based submissions, novel\ncognitively-inspired benchmarks, or analysis techniques. Second, we are\nrelaxing the rules around pretraining data, and will now allow participants to\nconstruct their own datasets provided they stay within the 100M-word or\n10M-word budget. Third, we introduce a multimodal vision-and-language track,\nand will release a corpus of 50% text-only and 50% image-text multimodal data\nas a starting point for LM model training. The purpose of this CfP is to\nprovide rules for this year's challenge, explain these rule changes and their\nrationale in greater detail, give a timeline of this year's competition, and\nprovide answers to frequently asked questions from last year's challenge.", "published": "2024-04-09 11:04:50", "link": "http://arxiv.org/abs/2404.06214v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VI-OOD: A Unified Representation Learning Framework for Textual\n  Out-of-distribution Detection", "abstract": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the\nsafety and reliability of deep neural networks in various applications. While\nthere has been a growing focus on OOD detection in visual data, the field of\ntextual OOD detection has received less attention. Only a few attempts have\nbeen made to directly apply general OOD detection methods to natural language\nprocessing (NLP) tasks, without adequately considering the characteristics of\ntextual data. In this paper, we delve into textual OOD detection with\nTransformers. We first identify a key problem prevalent in existing OOD\ndetection methods: the biased representation learned through the maximization\nof the conditional likelihood $p(y\\mid x)$ can potentially result in subpar\nperformance. We then propose a novel variational inference framework for OOD\ndetection (VI-OOD), which maximizes the likelihood of the joint distribution\n$p(x, y)$ instead of $p(y\\mid x)$. VI-OOD is tailored for textual OOD detection\nby efficiently exploiting the representations of pre-trained Transformers.\nThrough comprehensive experiments on various text classification tasks, VI-OOD\ndemonstrates its effectiveness and wide applicability. Our code has been\nreleased at \\url{https://github.com/liam0949/LLM-OOD}.", "published": "2024-04-09 11:10:00", "link": "http://arxiv.org/abs/2404.06217v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Cross-Lingual Alignment -- A Survey", "abstract": "Cross-lingual alignment, the meaningful similarity of representations across\nlanguages in multilingual language models, has been an active field of research\nin recent years. We survey the literature of techniques to improve\ncross-lingual alignment, providing a taxonomy of methods and summarising\ninsights from throughout the field. We present different understandings of\ncross-lingual alignment and their limitations. We provide a qualitative summary\nof results from a large number of surveyed papers. Finally, we discuss how\nthese insights may be applied not only to encoder models, where this topic has\nbeen heavily studied, but also to encoder-decoder or even decoder-only models,\nand argue that an effective trade-off between language-neutral and\nlanguage-specific information is key.", "published": "2024-04-09 11:39:53", "link": "http://arxiv.org/abs/2404.06228v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs' Reading Comprehension Is Affected by Parametric Knowledge and\n  Struggles with Hypothetical Statements", "abstract": "The task of reading comprehension (RC), often implemented as context-based\nquestion answering (QA), provides a primary means to assess language models'\nnatural language understanding (NLU) capabilities. Yet, when applied to large\nlanguage models (LLMs) with extensive built-in world knowledge, this method can\nbe deceptive. If the context aligns with the LLMs' internal knowledge, it is\nhard to discern whether the models' answers stem from context comprehension or\nfrom LLMs' internal information. Conversely, using data that conflicts with the\nmodels' knowledge creates erroneous trends which distort the results. To\naddress this issue, we suggest to use RC on imaginary data, based on fictitious\nfacts and entities. This task is entirely independent of the models' world\nknowledge, enabling us to evaluate LLMs' linguistic abilities without the\ninterference of parametric knowledge. Testing ChatGPT, GPT-4, LLaMA 2 and\nMixtral on such imaginary data, we uncover a class of linguistic phenomena\nposing a challenge to current LLMs, involving thinking in terms of alternative,\nhypothetical scenarios. While all the models handle simple affirmative and\nnegative contexts with high accuracy, they are much more prone to error when\ndealing with modal and conditional contexts. Crucially, these phenomena also\ntrigger the LLMs' vulnerability to knowledge-conflicts again. In particular,\nwhile some models prove virtually unaffected by knowledge conflicts in\naffirmative and negative contexts, when faced with more semantically involved\nmodal and conditional environments, they often fail to separate the text from\ntheir internal knowledge.", "published": "2024-04-09 13:08:56", "link": "http://arxiv.org/abs/2404.06283v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalizable Sarcasm Detection Is Just Around The Corner, Of Course!", "abstract": "We tested the robustness of sarcasm detection models by examining their\nbehavior when fine-tuned on four sarcasm datasets containing varying\ncharacteristics of sarcasm: label source (authors vs. third-party), domain\n(social media/online vs. offline conversations/dialogues), style (aggressive\nvs. humorous mocking). We tested their prediction performance on the same\ndataset (intra-dataset) and across different datasets (cross-dataset). For\nintra-dataset predictions, models consistently performed better when fine-tuned\nwith third-party labels rather than with author labels. For cross-dataset\npredictions, most models failed to generalize well to the other datasets,\nimplying that one type of dataset cannot represent all sorts of sarcasm with\ndifferent styles and domains. Compared to the existing datasets, models\nfine-tuned on the new dataset we release in this work showed the highest\ngeneralizability to other datasets. With a manual inspection of the datasets\nand post-hoc analysis, we attributed the difficulty in generalization to the\nfact that sarcasm actually comes in different domains and styles. We argue that\nfuture sarcasm research should take the broad scope of sarcasm into account.", "published": "2024-04-09 14:48:32", "link": "http://arxiv.org/abs/2404.06357v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SurveyAgent: A Conversational System for Personalized and Efficient\n  Research Survey", "abstract": "In the rapidly advancing research fields such as AI, managing and staying\nabreast of the latest scientific literature has become a significant challenge\nfor researchers. Although previous efforts have leveraged AI to assist with\nliterature searches, paper recommendations, and question-answering, a\ncomprehensive support system that addresses the holistic needs of researchers\nhas been lacking. This paper introduces SurveyAgent, a novel conversational\nsystem designed to provide personalized and efficient research survey\nassistance to researchers. SurveyAgent integrates three key modules: Knowledge\nManagement for organizing papers, Recommendation for discovering relevant\nliterature, and Query Answering for engaging with content on a deeper level.\nThis system stands out by offering a unified platform that supports researchers\nthrough various stages of their literature review process, facilitated by a\nconversational interface that prioritizes user interaction and personalization.\nOur evaluation demonstrates SurveyAgent's effectiveness in streamlining\nresearch activities, showcasing its capability to facilitate how researchers\ninteract with scientific literature.", "published": "2024-04-09 15:01:51", "link": "http://arxiv.org/abs/2404.06364v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ClinLinker: Medical Entity Linking of Clinical Concept Mentions in\n  Spanish", "abstract": "Advances in natural language processing techniques, such as named entity\nrecognition and normalization to widely used standardized terminologies like\nUMLS or SNOMED-CT, along with the digitalization of electronic health records,\nhave significantly advanced clinical text analysis. This study presents\nClinLinker, a novel approach employing a two-phase pipeline for medical entity\nlinking that leverages the potential of in-domain adapted language models for\nbiomedical text mining: initial candidate retrieval using a SapBERT-based\nbi-encoder and subsequent re-ranking with a cross-encoder, trained by following\na contrastive-learning strategy to be tailored to medical concepts in Spanish.\nThis methodology, focused initially on content in Spanish, substantially\noutperforming multilingual language models designed for the same purpose. This\nis true even for complex scenarios involving heterogeneous medical\nterminologies and being trained on a subset of the original data. Our results,\nevaluated using top-k accuracy at 25 and other top-k metrics, demonstrate our\napproach's performance on two distinct clinical entity linking Gold Standard\ncorpora, DisTEMIST (diseases) and MedProcNER (clinical procedures),\noutperforming previous benchmarks by 40 points in DisTEMIST and 43 points in\nMedProcNER, both normalized to SNOMED-CT codes. These findings highlight our\napproach's ability to address language-specific nuances and set a new benchmark\nin entity linking, offering a potent tool for enhancing the utility of digital\nmedical records. The resulting system is of practical value, both for large\nscale automatic generation of structured data derived from clinical records, as\nwell as for exhaustive extraction and harmonization of predefined clinical\nvariables of interest.", "published": "2024-04-09 15:04:27", "link": "http://arxiv.org/abs/2404.06367v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Distance Guided Alignment Training for Large Language Models", "abstract": "Ensuring alignment with human preferences is a crucial characteristic of\nlarge language models (LLMs). Presently, the primary alignment methods, RLHF\nand DPO, require extensive human annotation, which is expensive despite their\nefficacy. The significant expenses associated with current alignment techniques\nmotivate researchers to investigate the development of annotation-free\nalignment training methods. In pursuit of improved alignment without relying on\nexternal annotation, we introduce Latent Distance Guided Alignment Training\n(LD-Align). This approach seeks to align the model with a high-quality\nsupervised fine-tune dataset using guidance from a latent space. The latent\nspace is generated through sample reconstruction, akin to auto-encoding.\nConsequently, we utilize the distance between sample pairs in the latent space\nto guide DPO-based alignment training. Extensive experimentation and evaluation\nshow the efficacy of our proposed method in achieving notable alignment.", "published": "2024-04-09 15:33:09", "link": "http://arxiv.org/abs/2404.06390v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Two Model Designs for Clinical Note Generation; Is an LLM a\n  Useful Evaluator of Consistency?", "abstract": "Following an interaction with a patient, physicians are responsible for the\nsubmission of clinical documentation, often organized as a SOAP note. A\nclinical note is not simply a summary of the conversation but requires the use\nof appropriate medical terminology. The relevant information can then be\nextracted and organized according to the structure of the SOAP note. In this\npaper we analyze two different approaches to generate the different sections of\na SOAP note based on the audio recording of the conversation, and specifically\nexamine them in terms of note consistency. The first approach generates the\nsections independently, while the second method generates them all together. In\nthis work we make use of PEGASUS-X Transformer models and observe that both\nmethods lead to similar ROUGE values (less than 1% difference) and have no\ndifference in terms of the Factuality metric. We perform a human evaluation to\nmeasure aspects of consistency and demonstrate that LLMs like Llama2 can be\nused to perform the same tasks with roughly the same agreement as the human\nannotators. Between the Llama2 analysis and the human reviewers we observe a\nCohen Kappa inter-rater reliability of 0.79, 1.00, and 0.32 for consistency of\nage, gender, and body part injury, respectively. With this we demonstrate the\nusefulness of leveraging an LLM to measure quality indicators that can be\nidentified by humans but are not currently captured by automatic metrics. This\nallows scaling evaluation to larger data sets, and we find that clinical note\nconsistency improves by generating each new section conditioned on the output\nof all previously generated sections.", "published": "2024-04-09 17:54:10", "link": "http://arxiv.org/abs/2404.06503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What is Your Favorite Gender, MLM? Gender Bias Evaluation in\n  Multilingual Masked Language Models", "abstract": "Bias is a disproportionate prejudice in favor of one side against another.\nDue to the success of transformer-based Masked Language Models (MLMs) and their\nimpact on many NLP tasks, a systematic evaluation of bias in these models is\nneeded more than ever. While many studies have evaluated gender bias in English\nMLMs, only a few works have been conducted for the task in other languages.\nThis paper proposes a multilingual approach to estimate gender bias in MLMs\nfrom 5 languages: Chinese, English, German, Portuguese, and Spanish. Unlike\nprevious work, our approach does not depend on parallel corpora coupled with\nEnglish to detect gender bias in other languages using multilingual lexicons.\nMoreover, a novel model-based method is presented to generate sentence pairs\nfor a more robust analysis of gender bias, compared to the traditional\nlexicon-based method. For each language, both the lexicon-based and model-based\nmethods are applied to create two datasets respectively, which are used to\nevaluate gender bias in an MLM specifically trained for that language using one\nexisting and 3 new scoring metrics. Our results show that the previous approach\nis data-sensitive and not stable as it does not remove contextual dependencies\nirrelevant to gender. In fact, the results often flip when different scoring\nmetrics are used on the same dataset, suggesting that gender bias should be\nstudied on a large dataset using multiple evaluation metrics for best practice.", "published": "2024-04-09 21:12:08", "link": "http://arxiv.org/abs/2404.06621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RULER: What's the Real Context Size of Your Long-Context Language\n  Models?", "abstract": "The needle-in-a-haystack (NIAH) test, which examines the ability to retrieve\na piece of information (the \"needle\") from long distractor texts (the\n\"haystack\"), has been widely adopted to evaluate long-context language models\n(LMs). However, this simple retrieval-based test is indicative of only a\nsuperficial form of long-context understanding. To provide a more comprehensive\nevaluation of long-context LMs, we create a new synthetic benchmark RULER with\nflexible configurations for customized sequence length and task complexity.\nRULER expands upon the vanilla NIAH test to encompass variations with diverse\ntypes and quantities of needles. Moreover, RULER introduces new task categories\nmulti-hop tracing and aggregation to test behaviors beyond searching from\ncontext. We evaluate 17 long-context LMs with 13 representative tasks in RULER.\nDespite achieving nearly perfect accuracy in the vanilla NIAH test, almost all\nmodels exhibit large performance drops as the context length increases. While\nthese models all claim context sizes of 32K tokens or greater, only half of\nthem can maintain satisfactory performance at the length of 32K. Our analysis\nof Yi-34B, which supports context length of 200K, reveals large room for\nimprovement as we increase input length and task complexity. We open source\nRULER to spur comprehensive evaluation of long-context LMs.", "published": "2024-04-09 23:41:27", "link": "http://arxiv.org/abs/2404.06654v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Interesting Facts to Enhance User Engagement with\n  Conversational Interfaces", "abstract": "Conversational Task Assistants (CTAs) guide users in performing a multitude\nof activities, such as making recipes. However, ensuring that interactions\nremain engaging, interesting, and enjoyable for CTA users is not trivial,\nespecially for time-consuming or challenging tasks. Grounded in psychological\ntheories of human interest, we propose to engage users with contextual and\ninteresting statements or facts during interactions with a multi-modal CTA, to\nreduce fatigue and task abandonment before a task is complete. To\noperationalize this idea, we train a high-performing classifier (82% F1-score)\nto automatically identify relevant and interesting facts for users. We use it\nto create an annotated dataset of task-specific interesting facts for the\ndomain of cooking. Finally, we design and validate a dialogue policy to\nincorporate the identified relevant and interesting facts into a conversation,\nto improve user engagement and task completion. Live testing on a leading\nmulti-modal voice assistant shows that 66% of the presented facts were received\npositively, leading to a 40% gain in the user satisfaction rating, and a 37%\nincrease in conversation length. These findings emphasize that strategically\nincorporating interesting facts into the CTA experience can promote real-world\nuser participation for guided task interactions.", "published": "2024-04-09 23:51:29", "link": "http://arxiv.org/abs/2404.06659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Hey..! This medicine made me sick\": Sentiment Analysis of\n  User-Generated Drug Reviews using Machine Learning Techniques", "abstract": "Sentiment analysis has become increasingly important in healthcare,\nespecially in the biomedical and pharmaceutical fields. The data generated by\nthe general public on the effectiveness, side effects, and adverse drug\nreactions are goldmines for different agencies and medicine producers to\nunderstand the concerns and reactions of people. Despite the challenge of\nobtaining datasets on drug-related problems, sentiment analysis on this topic\nwould be a significant boon to the field. This project proposes a drug review\nclassification system that classifies user reviews on a particular drug into\ndifferent classes, such as positive, negative, and neutral. This approach uses\na dataset that is collected from publicly available sources containing drug\nreviews, such as drugs.com. The collected data is manually labeled and verified\nmanually to ensure that the labels are correct. Three pre-trained language\nmodels, such as BERT, SciBERT, and BioBERT, are used to obtain embeddings,\nwhich were later used as features to different machine learning classifiers\nsuch as decision trees, support vector machines, random forests, and also deep\nlearning algorithms such as recurrent neural networks. The performance of these\nclassifiers is quantified using precision, recall, and f1-score, and the\nresults show that the proposed approaches are useful in analyzing the\nsentiments of people on different drugs.", "published": "2024-04-09 08:42:34", "link": "http://arxiv.org/abs/2404.13057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Traitement quantique des langues : {\u00e9}tat de l'art", "abstract": "This article presents a review of quantum computing research works for\nNatural Language Processing (NLP). Their goal is to improve the performance of\ncurrent models, and to provide a better representation of several linguistic\nphenomena, such as ambiguity and long range dependencies. Several families of\napproaches are presented, including symbolic diagrammatic approaches, and\nhybrid neural networks. These works show that experimental studies are already\nfeasible, and open research perspectives on the conception of new models and\ntheir evaluation.", "published": "2024-04-09 08:05:15", "link": "http://arxiv.org/abs/2406.15370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interplay of Machine Translation, Diacritics, and Diacritization", "abstract": "We investigate two research questions: (1) how do machine translation (MT)\nand diacritization influence the performance of each other in a multi-task\nlearning setting (2) the effect of keeping (vs. removing) diacritics on MT\nperformance. We examine these two questions in both high-resource (HR) and\nlow-resource (LR) settings across 55 different languages (36 African languages\nand 19 European languages). For (1), results show that diacritization\nsignificantly benefits MT in the LR scenario, doubling or even tripling\nperformance for some languages, but harms MT in the HR scenario. We find that\nMT harms diacritization in LR but benefits significantly in HR for some\nlanguages. For (2), MT performance is similar regardless of diacritics being\nkept or removed. In addition, we propose two classes of metrics to measure the\ncomplexity of a diacritical system, finding these metrics to correlate\npositively with the performance of our diacritization models. Overall, our work\nprovides insights for developing MT and diacritization systems under different\ndata size conditions and may have implications that generalize beyond the 55\nlanguages we investigate.", "published": "2024-04-09 01:55:05", "link": "http://arxiv.org/abs/2404.05943v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page\n  Understanding and Grounding?", "abstract": "Multimodal Large Language models (MLLMs) have shown promise in web-related\ntasks, but evaluating their performance in the web domain remains a challenge\ndue to the lack of comprehensive benchmarks. Existing benchmarks are either\ndesigned for general multimodal tasks, failing to capture the unique\ncharacteristics of web pages, or focus on end-to-end web agent tasks, unable to\nmeasure fine-grained abilities such as OCR, understanding, and grounding. In\nthis paper, we introduce \\bench{}, a multimodal benchmark designed to assess\nthe capabilities of MLLMs across a variety of web tasks. \\bench{} consists of\nseven tasks, and comprises 1.5K human-curated instances from 139 real websites,\ncovering 87 sub-domains. We evaluate 14 open-source MLLMs, Gemini Pro, Claude-3\nseries, and GPT-4V(ision) on \\bench{}, revealing significant challenges and\nperformance gaps. Further analysis highlights the limitations of current MLLMs,\nincluding inadequate grounding in text-rich environments and subpar performance\nwith low-resolution image inputs. We believe \\bench{} will serve as a valuable\nresource for the research community and contribute to the creation of more\npowerful and versatile MLLMs for web-related applications.", "published": "2024-04-09 02:29:39", "link": "http://arxiv.org/abs/2404.05955v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders", "abstract": "Large decoder-only language models (LLMs) are the state-of-the-art models on\nmost of today's NLP tasks and benchmarks. Yet, the community is only slowly\nadopting these models for text embedding tasks, which require rich\ncontextualized representations. In this work, we introduce LLM2Vec, a simple\nunsupervised approach that can transform any decoder-only LLM into a strong\ntext encoder. LLM2Vec consists of three simple steps: 1) enabling bidirectional\nattention, 2) masked next token prediction, and 3) unsupervised contrastive\nlearning. We demonstrate the effectiveness of LLM2Vec by applying it to 4\npopular LLMs ranging from 1.3B to 8B parameters and evaluate the transformed\nmodels on English word- and sequence-level tasks. We outperform encoder-only\nmodels by a large margin on word-level tasks and reach a new unsupervised\nstate-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB).\nMoreover, when combining LLM2Vec with supervised contrastive learning, we\nachieve state-of-the-art performance on MTEB among models that train only on\npublicly available data (as of May 24, 2024). Our strong empirical results and\nextensive analysis demonstrate that LLMs can be effectively transformed into\nuniversal text encoders in a parameter-efficient manner without the need for\nexpensive adaptation or synthetic GPT-4 generated data.", "published": "2024-04-09 02:51:05", "link": "http://arxiv.org/abs/2404.05961v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "THOUGHTSCULPT: Reasoning with Intermediate Revision and Search", "abstract": "We present THOUGHTSCULPT, a general reasoning and search method for tasks\nwith outputs that can be decomposed into components. THOUGHTSCULPT explores a\nsearch tree of potential solutions using Monte Carlo Tree Search (MCTS),\nbuilding solutions one action at a time and evaluating according to any\ndomain-specific heuristic, which in practice is often simply an LLM evaluator.\nCritically, our action space includes revision actions: THOUGHTSCULPT may\nchoose to revise part of its previous output rather than continuing to build\nthe rest of its output. Empirically, THOUGHTSCULPT outperforms state-of-the-art\nreasoning methods across three challenging tasks: Story Outline Improvement (up\nto +30% interestingness), Mini-Crosswords Solving (up to +16% word success\nrate), and Constrained Generation (up to +10% concept coverage).", "published": "2024-04-09 02:53:14", "link": "http://arxiv.org/abs/2404.05966v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimization Methods for Personalizing Large Language Models through\n  Retrieval Augmentation", "abstract": "This paper studies retrieval-augmented approaches for personalizing large\nlanguage models (LLMs), which potentially have a substantial impact on various\napplications and domains. We propose the first attempt to optimize the\nretrieval models that deliver a limited number of personal documents to large\nlanguage models for the purpose of personalized generation. We develop two\noptimization algorithms that solicit feedback from the downstream personalized\ngeneration tasks for retrieval optimization -- one based on reinforcement\nlearning whose reward function is defined using any arbitrary metric for\npersonalized generation and another based on knowledge distillation from the\ndownstream LLM to the retrieval model. This paper also introduces a pre- and\npost-generation retriever selection model that decides what retriever to choose\nfor each LLM input. Extensive experiments on diverse tasks from the language\nmodel personalization (LaMP) benchmark reveal statistically significant\nimprovements in six out of seven datasets.", "published": "2024-04-09 02:58:05", "link": "http://arxiv.org/abs/2404.05970v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Event-enhanced Retrieval in Real-time Search", "abstract": "The embedding-based retrieval (EBR) approach is widely used in mainstream\nsearch engine retrieval systems and is crucial in recent retrieval-augmented\nmethods for eliminating LLM illusions. However, existing EBR models often face\nthe \"semantic drift\" problem and insufficient focus on key information, leading\nto a low adoption rate of retrieval results in subsequent steps. This issue is\nespecially noticeable in real-time search scenarios, where the various\nexpressions of popular events on the Internet make real-time retrieval heavily\nreliant on crucial event information. To tackle this problem, this paper\nproposes a novel approach called EER, which enhances real-time retrieval\nperformance by improving the dual-encoder model of traditional EBR. We\nincorporate contrastive learning to accompany pairwise learning for encoder\noptimization. Furthermore, to strengthen the focus on critical event\ninformation in events, we include a decoder module after the document encoder,\nintroduce a generative event triplet extraction scheme based on prompt-tuning,\nand correlate the events with query encoder optimization through comparative\nlearning. This decoder module can be removed during inference. Extensive\nexperiments demonstrate that EER can significantly improve the real-time search\nretrieval performance. We believe that this approach will provide new\nperspectives in the field of information retrieval. The codes and dataset are\navailable at https://github.com/open-event-hub/Event-enhanced_Retrieval .", "published": "2024-04-09 03:47:48", "link": "http://arxiv.org/abs/2404.05989v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation\n  of Large Language Models", "abstract": "The rapid development of large language model (LLM) evaluation methodologies\nand datasets has led to a profound challenge: integrating state-of-the-art\nevaluation techniques cost-effectively while ensuring reliability,\nreproducibility, and efficiency. Currently, there is a notable absence of a\nunified and adaptable framework that seamlessly integrates various evaluation\napproaches. Moreover, the reliability of evaluation findings is often\nquestionable due to potential data contamination, with the evaluation\nefficiency commonly overlooked when facing the substantial costs associated\nwith LLM inference. In response to these challenges, we introduce FreeEval, a\nmodular and scalable framework crafted to enable trustworthy and efficient\nautomatic evaluations of LLMs. Firstly, FreeEval's unified abstractions\nsimplify the integration and improve the transparency of diverse evaluation\nmethodologies, encompassing dynamic evaluation that demand sophisticated LLM\ninteractions. Secondly, the framework integrates meta-evaluation techniques\nlike human evaluation and data contamination detection, which, along with\ndynamic evaluation modules in the platform, enhance the fairness of the\nevaluation outcomes. Lastly, FreeEval is designed with a high-performance\ninfrastructure, including distributed computation and caching strategies,\nenabling extensive evaluations across multi-node, multi-GPU clusters for\nopen-source and proprietary LLMs.", "published": "2024-04-09 04:17:51", "link": "http://arxiv.org/abs/2404.06003v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for\n  Hallucination Detection", "abstract": "In this paper, we present our novel systems developed for the SemEval-2024\nhallucination detection task. Our investigation spans a range of strategies to\ncompare model predictions with reference standards, encompassing diverse\nbaselines, the refinement of pre-trained encoders through supervised learning,\nand an ensemble approaches utilizing several high-performing models. Through\nthese explorations, we introduce three distinct methods that exhibit strong\nperformance metrics. To amplify our training data, we generate additional\ntraining samples from unlabelled training subset. Furthermore, we provide a\ndetailed comparative analysis of our approaches. Notably, our premier method\nachieved a commendable 9th place in the competition's model-agnostic track and\n17th place in model-aware track, highlighting its effectiveness and potential.", "published": "2024-04-09 09:03:44", "link": "http://arxiv.org/abs/2404.06137v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Clue-Instruct: Text-Based Clue Generation for Educational Crossword\n  Puzzles", "abstract": "Crossword puzzles are popular linguistic games often used as tools to engage\nstudents in learning. Educational crosswords are characterized by less cryptic\nand more factual clues that distinguish them from traditional crossword\npuzzles. Despite there exist several publicly available clue-answer pair\ndatabases for traditional crosswords, educational clue-answer pairs datasets\nare missing. In this article, we propose a methodology to build educational\nclue generation datasets that can be used to instruct Large Language Models\n(LLMs). By gathering from Wikipedia pages informative content associated with\nrelevant keywords, we use Large Language Models to automatically generate\npedagogical clues related to the given input keyword and its context. With such\nan approach, we created clue-instruct, a dataset containing 44,075 unique\nexamples with text-keyword pairs associated with three distinct crossword\nclues. We used clue-instruct to instruct different LLMs to generate educational\nclues from a given input content and keyword. Both human and automatic\nevaluations confirmed the quality of the generated clues, thus validating the\neffectiveness of our approach.", "published": "2024-04-09 10:12:34", "link": "http://arxiv.org/abs/2404.06186v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Finding fake reviews in e-commerce platforms by using hybrid algorithms", "abstract": "Sentiment analysis, a vital component in natural language processing, plays a\ncrucial role in understanding the underlying emotions and opinions expressed in\ntextual data. In this paper, we propose an innovative ensemble approach for\nsentiment analysis for finding fake reviews that amalgamate the predictive\ncapabilities of Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and\nDecision Tree classifiers. Our ensemble architecture strategically combines\nthese diverse models to capitalize on their strengths while mitigating inherent\nweaknesses, thereby achieving superior accuracy and robustness in fake review\nprediction. By combining all the models of our classifiers, the predictive\nperformance is boosted and it also fosters adaptability to varied linguistic\npatterns and nuances present in real-world datasets. The metrics accounted for\non fake reviews demonstrate the efficacy and competitiveness of the proposed\nensemble method against traditional single-model approaches. Our findings\nunderscore the potential of ensemble techniques in advancing the\nstate-of-the-art in finding fake reviews using hybrid algorithms, with\nimplications for various applications in different social media and e-platforms\nto find the best reviews and neglect the fake ones, eliminating puffery and\nbluffs.", "published": "2024-04-09 14:25:27", "link": "http://arxiv.org/abs/2404.06339v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RAR-b: Reasoning as Retrieval Benchmark", "abstract": "Semantic textual similartiy (STS) and information retrieval tasks (IR) tasks\nhave been the two major avenues to record the progress of embedding models in\nthe past few years. Under the emerging Retrieval-augmented Generation (RAG)\nparadigm, we envision the need to evaluate next-level language understanding\nabilities of embedding models, and take a conscious look at the reasoning\nabilities stored in them. Addressing this, we pose the question: Can retrievers\nsolve reasoning problems? By transforming reasoning tasks into retrieval tasks,\nwe find that without specifically trained for reasoning-level language\nunderstanding, current state-of-the-art retriever models may still be far from\nbeing competent for playing the role of assisting LLMs, especially in\nreasoning-intensive tasks. Moreover, albeit trained to be aware of\ninstructions, instruction-aware IR models are often better off without\ninstructions in inference time for reasoning tasks, posing an overlooked\nretriever-LLM behavioral gap for the research community to align. However,\nrecent decoder-based embedding models show great promise in narrowing the gap,\nhighlighting the pathway for embedding models to achieve reasoning-level\nlanguage understanding. We also show that, although current off-the-shelf\nre-ranker models fail on these tasks, injecting reasoning abilities into them\nthrough fine-tuning still appears easier than doing so to bi-encoders, and we\nare able to achieve state-of-the-art performance across all tasks by\nfine-tuning a reranking model. We release Reasoning as Retrieval Benchmark\n(RAR-b), a holistic suite of tasks and settings to evaluate the reasoning\nabilities stored in retriever models. RAR-b is available at\nhttps://github.com/gowitheflow-1998/RAR-b.", "published": "2024-04-09 14:34:48", "link": "http://arxiv.org/abs/2404.06347v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Event Extraction in Basque: Typologically motivated Cross-Lingual\n  Transfer-Learning Analysis", "abstract": "Cross-lingual transfer-learning is widely used in Event Extraction for\nlow-resource languages and involves a Multilingual Language Model that is\ntrained in a source language and applied to the target language. This paper\nstudies whether the typological similarity between source and target languages\nimpacts the performance of cross-lingual transfer, an under-explored topic. We\nfirst focus on Basque as the target language, which is an ideal target language\nbecause it is typologically different from surrounding languages. Our\nexperiments on three Event Extraction tasks show that the shared linguistic\ncharacteristic between source and target languages does have an impact on\ntransfer quality. Further analysis of 72 language pairs reveals that for tasks\nthat involve token classification such as entity and event trigger\nidentification, common writing script and morphological features produce higher\nquality cross-lingual transfer. In contrast, for tasks involving structural\nprediction like argument extraction, common word order is the most relevant\nfeature. In addition, we show that when increasing the training size, not all\nthe languages scale in the same way in the cross-lingual setting. To perform\nthe experiments we introduce EusIE, an event extraction dataset for Basque,\nwhich follows the Multilingual Event Extraction dataset (MEE). The dataset and\ncode are publicly available.", "published": "2024-04-09 15:35:41", "link": "http://arxiv.org/abs/2404.06392v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MiniCPM: Unveiling the Potential of Small Language Models with Scalable\n  Training Strategies", "abstract": "The burgeoning interest in developing Large Language Models (LLMs) with up to\ntrillion parameters has been met with concerns regarding resource efficiency\nand practical expense, particularly given the immense cost of experimentation.\nThis scenario underscores the importance of exploring the potential of Small\nLanguage Models (SLMs) as a resource-efficient alternative. In this context, we\nintroduce MiniCPM, specifically the 1.2B and 2.4B non-embedding parameter\nvariants, not only excel in their respective categories but also demonstrate\ncapabilities on par with 7B-13B LLMs. While focusing on SLMs, our approach\nexhibits scalability in both model and data dimensions for future LLM research.\nRegarding model scaling, we employ extensive model wind tunnel experiments for\nstable and optimal scaling. For data scaling, we introduce a\nWarmup-Stable-Decay (WSD) learning rate scheduler (LRS), conducive to\ncontinuous training and domain adaptation. We present an in-depth analysis of\nthe intriguing training dynamics that occurred in the WSD LRS. With WSD LRS, we\nare now able to efficiently study data-model scaling law without extensive\nretraining experiments on both axes of model and data, from which we derive the\nmuch higher compute optimal data-model ratio than Chinchilla Optimal.\nAdditionally, we introduce MiniCPM family, including MiniCPM-DPO, MiniCPM-MoE\nand MiniCPM-128K, whose excellent performance further cementing MiniCPM's\nfoundation in diverse SLM applications. MiniCPM models are available publicly\nat https://github.com/OpenBMB/MiniCPM .", "published": "2024-04-09 15:36:50", "link": "http://arxiv.org/abs/2404.06395v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and\n  Improve LLM Agents", "abstract": "The advances made by Large Language Models (LLMs) have led to the pursuit of\nLLM agents that can solve intricate, multi-step reasoning tasks. As with any\nresearch pursuit, benchmarking and evaluation are key corner stones to\nefficient and reliable progress. However, existing benchmarks are often narrow\nand simply compute overall task success. To face these issues, we propose\nAgentQuest -- a framework where (i) both benchmarks and metrics are modular and\neasily extensible through well documented and easy-to-use APIs; (ii) we offer\ntwo new evaluation metrics that can reliably track LLM agent progress while\nsolving a task. We exemplify the utility of the metrics on two use cases\nwherein we identify common failure points and refine the agent architecture to\nobtain a significant performance increase. Together with the research\ncommunity, we hope to extend AgentQuest further and therefore we make it\navailable under https://github.com/nec-research/agentquest.", "published": "2024-04-09 16:01:24", "link": "http://arxiv.org/abs/2404.06411v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks", "abstract": "Recently, the large language model (LLM) community has shown increasing\ninterest in enhancing LLMs' capability to handle extremely long documents. As\nvarious long-text techniques and model architectures emerge, the precise and\ndetailed evaluation of models' long-text capabilities has become increasingly\nimportant. Existing long-text evaluation benchmarks, such as L-Eval and\nLongBench, construct long-text test sets based on open-source datasets,\nfocusing mainly on QA and summarization tasks. These datasets include test\nsamples of varying lengths (from 2k to 32k+) entangled together, making it\nchallenging to assess model capabilities across different length ranges.\nMoreover, they do not cover the ultralong settings (100k+ tokens) that the\nlatest LLMs claim to achieve. In this paper, we introduce Ada-LEval, a\nlength-adaptable benchmark for evaluating the long-context understanding of\nLLMs. Ada-LEval includes two challenging subsets, TSort and BestAnswer, which\nenable a more reliable evaluation of LLMs' long context capabilities. These\nbenchmarks support intricate manipulation of the length of test cases, and can\neasily produce text samples up to 128k tokens. We evaluate 4 state-of-the-art\nclosed-source API models and 6 open-source models with Ada-LEval. The\nevaluation results demonstrate the limitations of current LLMs, especially in\nultra-long-context settings. Our code is available at\nhttps://github.com/open-compass/Ada-LEval.", "published": "2024-04-09 17:30:48", "link": "http://arxiv.org/abs/2404.06480v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Pitfalls of Conversational LLMs on News Debiasing", "abstract": "This paper addresses debiasing in news editing and evaluates the\neffectiveness of conversational Large Language Models in this task. We designed\nan evaluation checklist tailored to news editors' perspectives, obtained\ngenerated texts from three popular conversational models using a subset of a\npublicly available dataset in media bias, and evaluated the texts according to\nthe designed checklist. Furthermore, we examined the models as evaluator for\nchecking the quality of debiased model outputs. Our findings indicate that none\nof the LLMs are perfect in debiasing. Notably, some models, including ChatGPT,\nintroduced unnecessary changes that may impact the author's style and create\nmisinformation. Lastly, we show that the models do not perform as proficiently\nas domain experts in evaluating the quality of debiased outputs.", "published": "2024-04-09 17:42:59", "link": "http://arxiv.org/abs/2404.06488v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Effect of (Near) Duplicate Subwords in Language Modelling", "abstract": "Tokenisation is a core part of language models (LMs). It involves splitting a\ncharacter sequence into subwords which are assigned arbitrary indices before\nbeing served to the LM. While typically lossless, however, this process may\nlead to less sample efficient LM training: as it removes character-level\ninformation, it could make it harder for LMs to generalise across similar\nsubwords, such as now and Now. We refer to such subwords as near duplicates. In\nthis paper, we study the impact of near duplicate subwords on LM training\nefficiency. First, we design an experiment that gives us an upper bound to how\nmuch we should expect a model to improve if we could perfectly generalise\nacross near duplicates. We do this by duplicating each subword in our LM's\nvocabulary, creating perfectly equivalent classes of subwords. Experimentally,\nwe find that LMs need roughly 17% more data when trained in a fully duplicated\nsetting. Second, we investigate the impact of naturally occurring near\nduplicates on LMs. Here, we see that merging them considerably hurts LM\nperformance. Therefore, although subword duplication negatively impacts LM\ntraining efficiency, naturally occurring near duplicates may not be as similar\nas anticipated, limiting the potential for performance improvements.", "published": "2024-04-09 17:57:29", "link": "http://arxiv.org/abs/2404.06508v3", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model\n  Handling Resolutions from 336 Pixels to 4K HD", "abstract": "The Large Vision-Language Model (LVLM) field has seen significant\nadvancements, yet its progression has been hindered by challenges in\ncomprehending fine-grained visual content due to limited resolution. Recent\nefforts have aimed to enhance the high-resolution understanding capabilities of\nLVLMs, yet they remain capped at approximately 1500 x 1500 pixels and\nconstrained to a relatively narrow resolution range. This paper represents\nInternLM-XComposer2-4KHD, a groundbreaking exploration into elevating LVLM\nresolution capabilities up to 4K HD (3840 x 1600) and beyond. Concurrently,\nconsidering the ultra-high resolution may not be necessary in all scenarios, it\nsupports a wide range of diverse resolutions from 336 pixels to 4K standard,\nsignificantly broadening its scope of applicability. Specifically, this\nresearch advances the patch division paradigm by introducing a novel extension:\ndynamic resolution with automatic patch configuration. It maintains the\ntraining image aspect ratios while automatically varying patch counts and\nconfiguring layouts based on a pre-trained Vision Transformer (ViT) (336 x\n336), leading to dynamic training resolution from 336 pixels to 4K standard.\nOur research demonstrates that scaling training resolution up to 4K HD leads to\nconsistent performance enhancements without hitting the ceiling of potential\nimprovements. InternLM-XComposer2-4KHD shows superb capability that matches or\neven surpasses GPT-4V and Gemini Pro in 10 of the 16 benchmarks. The\nInternLM-XComposer2-4KHD model series with 7B parameters are publicly available\nat https://github.com/InternLM/InternLM-XComposer.", "published": "2024-04-09 17:59:32", "link": "http://arxiv.org/abs/2404.06512v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian\n  Language?", "abstract": "Evaluating Large Language Models (LLMs) is challenging due to their\ngenerative nature, necessitating precise evaluation methodologies.\nAdditionally, non-English LLM evaluation lags behind English, resulting in the\nabsence or weakness of LLMs for many languages. In response to this necessity,\nwe introduce Khayyam Challenge (also known as PersianMMLU), a meticulously\ncurated collection comprising 20,192 four-choice questions sourced from 38\ndiverse tasks extracted from Persian examinations, spanning a wide spectrum of\nsubjects, complexities, and ages. The primary objective of the Khayyam\nChallenge is to facilitate the rigorous evaluation of LLMs that support the\nPersian language. Distinctive features of the Khayyam Challenge are (i) its\ncomprehensive coverage of various topics, including literary comprehension,\nmathematics, sciences, logic, intelligence testing, etc., aimed at assessing\ndifferent facets of LLMs such as language comprehension, reasoning, and\ninformation retrieval across various educational stages, from lower primary\nschool to upper secondary school (ii) its inclusion of rich metadata such as\nhuman response rates, difficulty levels, and descriptive answers (iii) its\nutilization of new data to avoid data contamination issues prevalent in\nexisting frameworks (iv) its use of original, non-translated data tailored for\nPersian speakers, ensuring the framework is free from translation challenges\nand errors while encompassing cultural nuances (v) its inherent scalability for\nfuture data updates and evaluations without requiring special human effort.\nPrevious works lacked an evaluation framework that combined all of these\nfeatures into a single comprehensive benchmark. Furthermore, we evaluate a wide\nrange of existing LLMs that support the Persian language, with statistical\nanalyses and interpretations of their outputs.", "published": "2024-04-09 22:38:13", "link": "http://arxiv.org/abs/2404.06644v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Extractive text summarisation of Privacy Policy documents using machine\n  learning approaches", "abstract": "This work demonstrates two Privacy Policy (PP) summarisation models based on\ntwo different clustering algorithms: K-means clustering and Pre-determined\nCentroid (PDC) clustering. K-means is decided to be used for the first model\nafter an extensive evaluation of ten commonly used clustering algorithms. The\nsummariser model based on the PDC-clustering algorithm summarises PP documents\nby segregating individual sentences by Euclidean distance from each sentence to\nthe pre-defined cluster centres. The cluster centres are defined according to\nGeneral Data Protection Regulation (GDPR)'s 14 essential topics that must be\nincluded in any privacy notices. The PDC model outperformed the K-means model\nfor two evaluation methods, Sum of Squared Distance (SSD) and ROUGE by some\nmargin (27% and 24% respectively). This result contrasts the K-means model's\nbetter performance in the general clustering of sentence vectors before running\nthe task-specific evaluation. This indicates the effectiveness of operating\ntask-specific fine-tuning measures on unsupervised machine-learning models. The\nsummarisation mechanisms implemented in this paper demonstrates an idea of how\nto efficiently extract essential sentences that should be included in any PP\ndocuments. The summariser models could be further developed to an application\nthat tests the GDPR-compliance (or any data privacy legislation) of PP\ndocuments.", "published": "2024-04-09 04:54:08", "link": "http://arxiv.org/abs/2404.08686v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "JSTR: Judgment Improves Scene Text Recognition", "abstract": "In this paper, we present a method for enhancing the accuracy of scene text\nrecognition tasks by judging whether the image and text match each other. While\nprevious studies focused on generating the recognition results from input\nimages, our approach also considers the model's misrecognition results to\nunderstand its error tendencies, thus improving the text recognition pipeline.\nThis method boosts text recognition accuracy by providing explicit feedback on\nthe data that the model is likely to misrecognize by predicting correct or\nincorrect between the image and text. The experimental results on publicly\navailable datasets demonstrate that our proposed method outperforms the\nbaseline and state-of-the-art methods in scene text recognition.", "published": "2024-04-09 02:55:12", "link": "http://arxiv.org/abs/2404.05967v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Does Transformer Interpretability Transfer to RNNs?", "abstract": "Recent advances in recurrent neural network architectures, such as Mamba and\nRWKV, have enabled RNNs to match or exceed the performance of equal-size\ntransformers in terms of language modeling perplexity and downstream\nevaluations, suggesting that future systems may be built on completely new\narchitectures. In this paper, we examine if selected interpretability methods\noriginally designed for transformer language models will transfer to these\nup-and-coming recurrent architectures. Specifically, we focus on steering model\noutputs via contrastive activation addition, on eliciting latent predictions\nvia the tuned lens, and eliciting latent knowledge from models fine-tuned to\nproduce false outputs under certain conditions. Our results show that most of\nthese techniques are effective when applied to RNNs, and we show that it is\npossible to improve some of them by taking advantage of RNNs' compressed state.", "published": "2024-04-09 02:59:17", "link": "http://arxiv.org/abs/2404.05971v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM\n  Experts", "abstract": "As Large Language Models (LLMs) and generative AI become more widespread, the\ncontent safety risks associated with their use also increase. We find a notable\ndeficiency in high-quality content safety datasets and benchmarks that\ncomprehensively cover a wide range of critical safety areas. To address this,\nwe define a broad content safety risk taxonomy, comprising 13 critical risk and\n9 sparse risk categories. Additionally, we curate AEGISSAFETYDATASET, a new\ndataset of approximately 26, 000 human-LLM interaction instances, complete with\nhuman annotations adhering to the taxonomy. We plan to release this dataset to\nthe community to further research and to help benchmark LLM models for safety.\nTo demonstrate the effectiveness of the dataset, we instruction-tune multiple\nLLM-based safety models. We show that our models (named AEGISSAFETYEXPERTS),\nnot only surpass or perform competitively with the state-of-the-art LLM-based\nsafety models and general purpose LLMs, but also exhibit robustness across\nmultiple jail-break attack categories. We also show how using\nAEGISSAFETYDATASET during the LLM alignment phase does not negatively impact\nthe performance of the aligned models on MT Bench scores. Furthermore, we\npropose AEGIS, a novel application of a no-regret online adaptation framework\nwith strong theoretical guarantees, to perform content moderation with an\nensemble of LLM content safety experts in deployment", "published": "2024-04-09 03:54:28", "link": "http://arxiv.org/abs/2404.05993v2", "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free\n  Information Retrieval", "abstract": "Graph-based approximate nearest neighbor search (ANNS) algorithms work\neffectively against large-scale vector retrieval. Among such methods, DiskANN\nachieves good recall-speed tradeoffs using both DRAM and storage. DiskANN\nadopts product quantization (PQ) to reduce memory usage, which is still\nproportional to the scale of datasets. In this paper, we propose All-in-Storage\nANNS with Product Quantization (AiSAQ), which offloads compressed vectors to\nthe SSD index. Our method achieves $\\sim$10 MB memory usage in query search\nwith billion-scale datasets without critical latency degradation. AiSAQ also\nreduces the index load time for query search preparation, which enables fast\nswitch between muitiple billion-scale indices.This method can be applied to\nretrievers of retrieval-augmented generation (RAG) and be scaled out with\nmultiple-server systems for emerging datasets. Our DiskANN-based implementation\nis available on GitHub.", "published": "2024-04-09 04:20:27", "link": "http://arxiv.org/abs/2404.06004v2", "categories": ["cs.IR", "cs.CL", "cs.DS"], "primary_category": "cs.IR"}
{"title": "Heuristic-enhanced Candidates Selection strategy for GPTs tackle\n  Few-Shot Aspect-Based Sentiment Analysis", "abstract": "Few-Shot Aspect-Based Sentiment Analysis (FSABSA) is an indispensable and\nhighly challenging task in natural language processing. However, methods based\non Pre-trained Language Models (PLMs) struggle to accommodate multiple\nsub-tasks, and methods based on Generative Pre-trained Transformers (GPTs)\nperform poorly. To address the above issues, the paper designs a\nHeuristic-enhanced Candidates Selection (HCS) strategy and further proposes All\nin One (AiO) model based on it. The model works in a two-stage, which\nsimultaneously accommodates the accuracy of PLMs and the generalization\ncapability of GPTs. Specifically, in the first stage, a backbone model based on\nPLMs generates rough heuristic candidates for the input sentence. In the second\nstage, AiO leverages LLMs' contextual learning capabilities to generate precise\npredictions. The study conducted comprehensive comparative and ablation\nexperiments on five benchmark datasets. The experimental results demonstrate\nthat the proposed model can better adapt to multiple sub-tasks, and also\noutperforms the methods that directly utilize GPTs.", "published": "2024-04-09 07:02:14", "link": "http://arxiv.org/abs/2404.06063v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Characterizing Multimodal Long-form Summarization: A Case Study on\n  Financial Reports", "abstract": "As large language models (LLMs) expand the power of natural language\nprocessing to handle long inputs, rigorous and systematic analyses are\nnecessary to understand their abilities and behavior. A salient application is\nsummarization, due to its ubiquity and controversy (e.g., researchers have\ndeclared the death of summarization). In this paper, we use financial report\nsummarization as a case study because financial reports are not only long but\nalso use numbers and tables extensively. We propose a computational framework\nfor characterizing multimodal long-form summarization and investigate the\nbehavior of Claude 2.0/2.1, GPT-4/3.5, and Cohere. We find that GPT-3.5 and\nCohere fail to perform this summarization task meaningfully. For Claude 2 and\nGPT-4, we analyze the extractiveness of the summary and identify a position\nbias in LLMs. This position bias disappears after shuffling the input for\nClaude, which suggests that Claude seems to recognize important information. We\nalso conduct a comprehensive investigation on the use of numeric data in\nLLM-generated summaries and offer a taxonomy of numeric hallucination. We\nemploy prompt engineering to improve GPT-4's use of numbers with limited\nsuccess. Overall, our analyses highlight the strong capability of Claude 2 in\nhandling long multimodal inputs compared to GPT-4. The generated summaries and\nevaluation code are available at\nhttps://github.com/ChicagoHAI/characterizing-multimodal-long-form-summarization.", "published": "2024-04-09 09:34:25", "link": "http://arxiv.org/abs/2404.06162v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Elephants Never Forget: Memorization and Learning of Tabular Data in\n  Large Language Models", "abstract": "While many have shown how Large Language Models (LLMs) can be applied to a\ndiverse set of tasks, the critical issues of data contamination and\nmemorization are often glossed over. In this work, we address this concern for\ntabular data. Specifically, we introduce a variety of different techniques to\nassess whether a language model has seen a tabular dataset during training.\nThis investigation reveals that LLMs have memorized many popular tabular\ndatasets verbatim. We then compare the few-shot learning performance of LLMs on\ndatasets that were seen during training to the performance on datasets released\nafter training. We find that LLMs perform better on datasets seen during\ntraining, indicating that memorization leads to overfitting. At the same time,\nLLMs show non-trivial performance on novel datasets and are surprisingly robust\nto data transformations. We then investigate the in-context statistical\nlearning abilities of LLMs. While LLMs are significantly better than random at\nsolving statistical classification problems, the sample efficiency of few-shot\nlearning lags behind traditional statistical learning algorithms, especially as\nthe dimension of the problem increases. This suggests that much of the observed\nfew-shot performance on novel real-world datasets is due to the LLM's world\nknowledge. Overall, our results highlight the importance of testing whether an\nLLM has seen an evaluation dataset during pre-training. We release the\nhttps://github.com/interpretml/LLM-Tabular-Memorization-Checker Python package\nto test LLMs for memorization of tabular datasets.", "published": "2024-04-09 10:58:21", "link": "http://arxiv.org/abs/2404.06209v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Low-Cost Generation and Evaluation of Dictionary Example Sentences", "abstract": "Dictionary example sentences play an important role in illustrating word\ndefinitions and usage, but manually creating quality sentences is challenging.\nPrior works have demonstrated that language models can be trained to generate\nexample sentences. However, they relied on costly customized models and word\nsense datasets for generation and evaluation of their work. Rapid advancements\nin foundational models present the opportunity to create low-cost, zero-shot\nmethods for the generation and evaluation of dictionary example sentences. We\nintroduce a new automatic evaluation metric called OxfordEval that measures the\nwin-rate of generated sentences against existing Oxford Dictionary sentences.\nOxfordEval shows high alignment with human judgments, enabling large-scale\nautomated quality evaluation. We experiment with various LLMs and\nconfigurations to generate dictionary sentences across word classes. We\ncomplement this with a novel approach of using masked language models to\nidentify and select sentences that best exemplify word meaning. The eventual\nmodel, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentences\naccording to OxfordEval, compared to 39.8% win rate for prior model-generated\nsentences.", "published": "2024-04-09 11:26:59", "link": "http://arxiv.org/abs/2404.06224v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dimensionality Reduction in Sentence Transformer Vector Databases with\n  Fast Fourier Transform", "abstract": "Dimensionality reduction in vector databases is pivotal for streamlining AI\ndata management, enabling efficient storage, faster computation, and improved\nmodel performance. This paper explores the benefits of reducing vector database\ndimensions, with a focus on computational efficiency and overcoming the curse\nof dimensionality. We introduce a novel application of Fast Fourier Transform\n(FFT) to dimensionality reduction, a method previously underexploited in this\ncontext. By demonstrating its utility across various AI domains, including\nRetrieval-Augmented Generation (RAG) models and image processing, this\nFFT-based approach promises to improve data retrieval processes and enhance the\nefficiency and scalability of AI solutions. The incorporation of FFT may not\nonly optimize operations in real-time processing and recommendation systems but\nalso extend to advanced image processing techniques, where dimensionality\nreduction can significantly improve performance and analysis efficiency. This\npaper advocates for the broader adoption of FFT in vector database management,\nmarking a significant stride towards addressing the challenges of data volume\nand complexity in AI research and applications. Unlike many existing\napproaches, we directly handle the embedding vectors produced by the model\nafter processing a test input.", "published": "2024-04-09 13:02:22", "link": "http://arxiv.org/abs/2404.06278v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "nEMO: Dataset of Emotional Speech in Polish", "abstract": "Speech emotion recognition has become increasingly important in recent years\ndue to its potential applications in healthcare, customer service, and\npersonalization of dialogue systems. However, a major issue in this field is\nthe lack of datasets that adequately represent basic emotional states across\nvarious language families. As datasets covering Slavic languages are rare,\nthere is a need to address this research gap. This paper presents the\ndevelopment of nEMO, a novel corpus of emotional speech in Polish. The dataset\ncomprises over 3 hours of samples recorded with the participation of nine\nactors portraying six emotional states: anger, fear, happiness, sadness,\nsurprise, and a neutral state. The text material used was carefully selected to\nrepresent the phonetics of the Polish language adequately. The corpus is freely\navailable under the terms of a Creative Commons license (CC BY-NC-SA 4.0).", "published": "2024-04-09 13:18:52", "link": "http://arxiv.org/abs/2404.06292v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Model Generation with LLMs: From Requirements to UML Sequence Diagrams", "abstract": "Complementing natural language (NL) requirements with graphical models can\nimprove stakeholders' communication and provide directions for system design.\nHowever, creating models from requirements involves manual effort. The advent\nof generative large language models (LLMs), ChatGPT being a notable example,\noffers promising avenues for automated assistance in model generation. This\npaper investigates the capability of ChatGPT to generate a specific type of\nmodel, i.e., UML sequence diagrams, from NL requirements. We conduct a\nqualitative study in which we examine the sequence diagrams generated by\nChatGPT for 28 requirements documents of various types and from different\ndomains. Observations from the analysis of the generated diagrams have\nsystematically been captured through evaluation logs, and categorized through\nthematic analysis. Our results indicate that, although the models generally\nconform to the standard and exhibit a reasonable level of understandability,\ntheir completeness and correctness with respect to the specified requirements\noften present challenges. This issue is particularly pronounced in the presence\nof requirements smells, such as ambiguity and inconsistency. The insights\nderived from this study can influence the practical utilization of LLMs in the\nRE process, and open the door to novel RE-specific prompting strategies\ntargeting effective model generation.", "published": "2024-04-09 15:07:25", "link": "http://arxiv.org/abs/2404.06371v2", "categories": ["cs.SE", "cs.CL", "cs.LG", "D.2; K.6.3; D.2.1; D.3.1; D.2.2; D.2.10; D.2.2; I.2; I.2.7"], "primary_category": "cs.SE"}
{"title": "Wu's Method can Boost Symbolic AI to Rival Silver Medalists and\n  AlphaGeometry to Outperform Gold Medalists at IMO Geometry", "abstract": "Proving geometric theorems constitutes a hallmark of visual reasoning\ncombining both intuitive and logical skills. Therefore, automated theorem\nproving of Olympiad-level geometry problems is considered a notable milestone\nin human-level automated reasoning. The introduction of AlphaGeometry, a\nneuro-symbolic model trained with 100 million synthetic samples, marked a major\nbreakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO)\nproblems whereas the reported baseline based on Wu's method solved only ten. In\nthis note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry,\nand find that Wu's method is surprisingly strong. Wu's method alone can solve\n15 problems, and some of them are not solved by any of the other methods. This\nleads to two key findings: (i) Combining Wu's method with the classic synthetic\nmethods of deductive databases and angle, ratio, and distance chasing solves 21\nout of 30 methods by just using a CPU-only laptop with a time limit of 5\nminutes per problem. Essentially, this classic method solves just 4 problems\nless than AlphaGeometry and establishes the first fully symbolic baseline\nstrong enough to rival the performance of an IMO silver medalist. (ii) Wu's\nmethod even solves 2 of the 5 problems that AlphaGeometry failed to solve.\nThus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art\nfor automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the\nfirst AI method which outperforms an IMO gold medalist.", "published": "2024-04-09 15:54:00", "link": "http://arxiv.org/abs/2404.06405v2", "categories": ["cs.AI", "cs.CG", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Rethinking How to Evaluate Language Model Jailbreak", "abstract": "Large language models (LLMs) have become increasingly integrated with various\napplications. To ensure that LLMs do not generate unsafe responses, they are\naligned with safeguards that specify what content is restricted. However, such\nalignment can be bypassed to produce prohibited content using a technique\ncommonly referred to as jailbreak. Different systems have been proposed to\nperform the jailbreak automatically. These systems rely on evaluation methods\nto determine whether a jailbreak attempt is successful. However, our analysis\nreveals that current jailbreak evaluation methods have two limitations. (1)\nTheir objectives lack clarity and do not align with the goal of identifying\nunsafe responses. (2) They oversimplify the jailbreak result as a binary\noutcome, successful or not. In this paper, we propose three metrics, safeguard\nviolation, informativeness, and relative truthfulness, to evaluate language\nmodel jailbreak. Additionally, we demonstrate how these metrics correlate with\nthe goal of different malicious actors. To compute these metrics, we introduce\na multifaceted approach that extends the natural language generation evaluation\nmethod after preprocessing the response. We evaluate our metrics on a benchmark\ndataset produced from three malicious intent datasets and three jailbreak\nsystems. The benchmark dataset is labeled by three annotators. We compare our\nmultifaceted approach with three existing jailbreak evaluation methods.\nExperiments demonstrate that our multifaceted evaluation outperforms existing\nmethods, with F1 scores improving on average by 17% compared to existing\nbaselines. Our findings motivate the need to move away from the binary view of\nthe jailbreak problem and incorporate a more comprehensive evaluation to ensure\nthe safety of the language model.", "published": "2024-04-09 15:54:16", "link": "http://arxiv.org/abs/2404.06407v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Foundation Models to the Rescue: Deadlock Resolution in Connected\n  Multi-Robot Systems", "abstract": "Connected multi-agent robotic systems (MRS) are prone to deadlocks in an\nobstacle environment where the robots can get stuck away from their desired\nlocations under a smooth low-level control policy. Without an external\nintervention, often in terms of a high-level command, a low-level control\npolicy cannot resolve such deadlocks. Utilizing the generalizability and low\ndata requirements of foundation models, this paper explores the possibility of\nusing text-based models, i.e., large language models (LLMs), and\ntext-and-image-based models, i.e., vision-language models (VLMs), as high-level\nplanners for deadlock resolution. We propose a hierarchical control framework\nwhere a foundation model-based high-level planner helps to resolve deadlocks by\nassigning a leader to the MRS along with a set of waypoints for the MRS leader.\nThen, a low-level distributed control policy based on graph neural networks is\nexecuted to safely follow these waypoints, thereby evading the deadlock. We\nconduct extensive experiments on various MRS environments using the best\navailable pre-trained LLMs and VLMs. We compare their performance with a\ngraph-based planner in terms of effectiveness in helping the MRS reach their\ntarget locations and computational time. Our results illustrate that, compared\nto grid-based planners, the foundation models perform better in terms of the\ngoal-reaching rate and computational time for complex environments, which helps\nus conclude that foundation models can assist MRS operating in complex\nobstacle-cluttered environments to resolve deadlocks efficiently.", "published": "2024-04-09 16:03:26", "link": "http://arxiv.org/abs/2404.06413v2", "categories": ["cs.RO", "cs.CL", "math.OC"], "primary_category": "cs.RO"}
{"title": "Visually Descriptive Language Model for Vector Graphics Reasoning", "abstract": "Despite significant advancements, large multimodal models (LMMs) still\nstruggle to bridge the gap between low-level visual perception -- focusing on\nshapes, sizes, and layouts -- and high-level language reasoning, such as\nsemantics and logic. This limitation is evident in tasks that require precise\nvisual perception, like comparing geometric properties or solving visual\nreasoning problems. To study this failure mode, we focus on vector graphics --\nimages composed of 2D objects and shapes, prevalent in LMM-based tasks in web,\ndesign, and OS environments. We identify two key research questions: how can we\nenable precise visual perception, and how can we facilitate high-level\nreasoning based on such low-level perceptions? To capture fine visual details,\nwe use Scalable Vector Graphics (SVG) for accurate encoding of visual scenes.\nHowever, SVGs are not readily interpretable by LMMs in a zero-shot manner. To\ntackle this, we propose the Visually Descriptive Language Model (VDLM), which\nintroduces a Primal Visual Description (PVD) as an intermediate textual\nrepresentation. PVD translates SVGs into a text-based abstraction consisting of\nprimitive attributes (e.g., shape, position, measurement) and their\ncorresponding values. PVD can be learned using task-agnostic synthesized data\nand represents visual primitives that are universal across vector graphics.\nThis abstraction is more structured, allowing for direct interpretation by\nfoundation models for zero-shot generalization. Without human-annotated data,\nempirical results show that VDLM significantly improves state-of-the-art LMMs\nlike GPT-4o on various multimodal perception and reasoning tasks. Extensive\nanalyses of VDLM show improved interpretability due to its disentangled\nperception and reasoning. We also demonstrate a positive correlation between\nPVD quality and task performance. Project page:\nhttps://mikewangwzhl.github.io/VDLM/", "published": "2024-04-09 17:30:18", "link": "http://arxiv.org/abs/2404.06479v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Less is More for Improving Automatic Evaluation of Factual Consistency", "abstract": "Assessing the factual consistency of automatically generated texts in\nrelation to source context is crucial for developing reliable natural language\ngeneration applications. Recent literature proposes AlignScore which uses a\nunified alignment model to evaluate factual consistency and substantially\noutperforms previous methods across many benchmark tasks. In this paper, we\ntake a closer look of datasets used in AlignScore and uncover an unexpected\nfinding: utilizing a smaller number of data points can actually improve\nperformance. We process the original AlignScore training dataset to remove\nnoise, augment with robustness-enhanced samples, and utilize a subset\ncomprising 10\\% of the data to train an improved factual consistency evaluation\nmodel, we call LIM-RA (Less Is More for Robust AlignScore). LIM-RA demonstrates\nsuperior performance, consistently outperforming AlignScore and other strong\nbaselines like ChatGPT across four benchmarks (two utilizing traditional\nnatural language generation datasets and two focused on large language model\noutputs). Our experiments show that LIM-RA achieves the highest score on 24 of\nthe 33 test datasets, while staying competitive on the rest, establishing the\nnew state-of-the-art benchmarks.", "published": "2024-04-09 19:02:12", "link": "http://arxiv.org/abs/2404.06579v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FairPair: A Robust Evaluation of Biases in Language Models through\n  Paired Perturbations", "abstract": "The accurate evaluation of differential treatment in language models to\nspecific groups is critical to ensuring a positive and safe user experience. An\nideal evaluation should have the properties of being robust, extendable to new\ngroups or attributes, and being able to capture biases that appear in typical\nusage (rather than just extreme, rare cases). Relatedly, bias evaluation should\nsurface not only egregious biases but also ones that are subtle and\ncommonplace, such as a likelihood for talking about appearances with regard to\nwomen. We present FairPair, an evaluation framework for assessing differential\ntreatment that occurs during ordinary usage. FairPair operates through\ncounterfactual pairs, but crucially, the paired continuations are grounded in\nthe same demographic group, which ensures equivalent comparison. Additionally,\nunlike prior work, our method factors in the inherent variability that comes\nfrom the generation process itself by measuring the sampling variability. We\npresent an evaluation of several commonly used generative models and a\nqualitative analysis that indicates a preference for discussing family and\nhobbies with regard to women.", "published": "2024-04-09 21:09:22", "link": "http://arxiv.org/abs/2404.06619v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs", "abstract": "Large Language Models (LLMs) are increasingly being developed and applied,\nbut their widespread use faces challenges. These include aligning LLMs'\nresponses with human values to prevent harmful outputs, which is addressed\nthrough safety training methods. Even so, bad actors and malicious users have\nsucceeded in attempts to manipulate the LLMs to generate misaligned responses\nfor harmful questions such as methods to create a bomb in school labs, recipes\nfor harmful drugs, and ways to evade privacy rights. Another challenge is the\nmultilingual capabilities of LLMs, which enable the model to understand and\nrespond in multiple languages. Consequently, attackers exploit the unbalanced\npre-training datasets of LLMs in different languages and the comparatively\nlower model performance in low-resource languages than high-resource ones. As a\nresult, attackers use a low-resource languages to intentionally manipulate the\nmodel to create harmful responses. Many of the similar attack vectors have been\npatched by model providers, making the LLMs more robust against language-based\nmanipulation. In this paper, we introduce a new black-box attack vector called\nthe \\emph{Sandwich attack}: a multi-language mixture attack, which manipulates\nstate-of-the-art LLMs into generating harmful and misaligned responses. Our\nexperiments with five different models, namely Google's Bard, Gemini Pro,\nLLaMA-2-70-B-Chat, GPT-3.5-Turbo, GPT-4, and Claude-3-OPUS, show that this\nattack vector can be used by adversaries to generate harmful responses and\nelicit misaligned responses from these models. By detailing both the mechanism\nand impact of the Sandwich attack, this paper aims to guide future research and\ndevelopment towards more secure and resilient LLMs, ensuring they serve the\npublic good while minimizing potential for misuse.", "published": "2024-04-09 18:29:42", "link": "http://arxiv.org/abs/2404.07242v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Towards Building a Robust Toxicity Predictor", "abstract": "Recent NLP literature pays little attention to the robustness of toxicity\nlanguage predictors, while these systems are most likely to be used in\nadversarial contexts. This paper presents a novel adversarial attack,\n\\texttt{ToxicTrap}, introducing small word-level perturbations to fool SOTA\ntext classifiers to predict toxic text samples as benign. ToxicTrap exploits\ngreedy based search strategies to enable fast and effective generation of toxic\nadversarial examples. Two novel goal function designs allow ToxicTrap to\nidentify weaknesses in both multiclass and multilabel toxic language detectors.\nOur empirical results show that SOTA toxicity text classifiers are indeed\nvulnerable to the proposed attacks, attaining over 98\\% attack success rates in\nmultilabel cases. We also show how a vanilla adversarial training and its\nimproved version can help increase robustness of a toxicity detector even\nagainst unseen attacks.", "published": "2024-04-09 22:56:05", "link": "http://arxiv.org/abs/2404.08690v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The X-LANCE Technical Report for Interspeech 2024 Speech Processing\n  Using Discrete Speech Unit Challenge", "abstract": "Discrete speech tokens have been more and more popular in multiple speech\nprocessing fields, including automatic speech recognition (ASR), text-to-speech\n(TTS) and singing voice synthesis (SVS). In this paper, we describe the systems\ndeveloped by the SJTU X-LANCE group for the TTS (acoustic + vocoder), SVS, and\nASR tracks in the Interspeech 2024 Speech Processing Using Discrete Speech Unit\nChallenge. Notably, we achieved 1st rank on the leaderboard in the TTS track\nboth with the whole training set and only 1h training data, with the highest\nUTMOS score and lowest bitrate among all submissions.", "published": "2024-04-09 07:37:41", "link": "http://arxiv.org/abs/2404.06079v2", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Masked Modeling Duo: Towards a Universal Audio Pre-training Framework", "abstract": "Self-supervised learning (SSL) using masked prediction has made great strides\nin general-purpose audio representation. This study proposes Masked Modeling\nDuo (M2D), an improved masked prediction SSL, which learns by predicting\nrepresentations of masked input signals that serve as training signals. Unlike\nconventional methods, M2D obtains a training signal by encoding only the masked\npart, encouraging the two networks in M2D to model the input. While M2D\nimproves general-purpose audio representations, a specialized representation is\nessential for real-world applications, such as in industrial and medical\ndomains. The often confidential and proprietary data in such domains is\ntypically limited in size and has a different distribution from that in\npre-training datasets. Therefore, we propose M2D for X (M2D-X), which extends\nM2D to enable the pre-training of specialized representations for an\napplication X. M2D-X learns from M2D and an additional task and inputs\nbackground noise. We make the additional task configurable to serve diverse\napplications, while the background noise helps learn on small data and forms a\ndenoising task that makes representation robust. With these design choices,\nM2D-X should learn a representation specialized to serve various application\nneeds. Our experiments confirmed that the representations for general-purpose\naudio, specialized for the highly competitive AudioSet and speech domain, and a\nsmall-data medical task achieve top-level performance, demonstrating the\npotential of using our models as a universal audio pre-training framework. Our\ncode is available online for future studies at https://github.com/nttcslab/m2d", "published": "2024-04-09 07:57:08", "link": "http://arxiv.org/abs/2404.06095v1", "categories": ["eess.AS", "cs.SD", "68T07"], "primary_category": "eess.AS"}
{"title": "Exploring Diverse Sounds: Identifying Outliers in a Music Corpus", "abstract": "Existing research on music recommendation systems primarily focuses on\nrecommending similar music, thereby often neglecting diverse and distinctive\nmusical recordings. Musical outliers can provide valuable insights due to the\ninherent diversity of music itself. In this paper, we explore music outliers,\ninvestigating their potential usefulness for music discovery and recommendation\nsystems. We argue that not all outliers should be treated as noise, as they can\noffer interesting perspectives and contribute to a richer understanding of an\nartist's work. We introduce the concept of 'Genuine' music outliers and provide\na definition for them. These genuine outliers can reveal unique aspects of an\nartist's repertoire and hold the potential to enhance music discovery by\nexposing listeners to novel and diverse musical experiences.", "published": "2024-04-09 08:10:04", "link": "http://arxiv.org/abs/2404.06103v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MuPT: A Generative Symbolic Music Pretrained Transformer", "abstract": "In this paper, we explore the application of Large Language Models (LLMs) to\nthe pre-training of music. While the prevalent use of MIDI in music modeling is\nwell-established, our findings suggest that LLMs are inherently more compatible\nwith ABC Notation, which aligns more closely with their design and strengths,\nthereby enhancing the model's performance in musical composition. To address\nthe challenges associated with misaligned measures from different tracks during\ngeneration, we propose the development of a Synchronized Multi-Track ABC\nNotation (SMT-ABC Notation), which aims to preserve coherence across multiple\nmusical tracks. Our contributions include a series of models capable of\nhandling up to 8192 tokens, covering 90% of the symbolic music data in our\ntraining set. Furthermore, we explore the implications of the Symbolic Music\nScaling Law (SMS Law) on model performance. The results indicate a promising\ndirection for future research in music generation, offering extensive resources\nfor community-led research through our open-source contributions.", "published": "2024-04-09 15:35:52", "link": "http://arxiv.org/abs/2404.06393v4", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
