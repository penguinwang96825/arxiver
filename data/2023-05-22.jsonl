{"title": "PrOnto: Language Model Evaluations for 859 Languages", "abstract": "Evaluation datasets are critical resources for measuring the quality of\npretrained language models. However, due to the high cost of dataset\nannotation, these resources are scarce for most languages other than English,\nmaking it difficult to assess the quality of language models. In this work, we\npresent a new method for evaluation dataset construction which enables any\nlanguage with a New Testament translation to receive a suite of evaluation\ndatasets suitable for pretrained language model evaluation. The method\ncritically involves aligning verses with those in the New Testament portion of\nEnglish OntoNotes, and then projecting annotations from English to the target\nlanguage, with no manual annotation required. We apply this method to 1051 New\nTestament translations in 859 and make them publicly available. Additionally,\nwe conduct experiments which demonstrate the efficacy of our method for\ncreating evaluation tasks which can assess language model quality.", "published": "2023-05-22 00:33:52", "link": "http://arxiv.org/abs/2305.12612v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keeping Up with the Language Models: Systematic Benchmark Extension for\n  Bias Auditing", "abstract": "Bias auditing of language models (LMs) has received considerable attention as\nLMs are becoming widespread. As such, several benchmarks for bias auditing have\nbeen proposed. At the same time, the rapid evolution of LMs can make these\nbenchmarks irrelevant in no time. Bias auditing is further complicated by LM\nbrittleness: when a presumably biased outcome is observed, is it due to model\nbias or model brittleness? We propose enlisting the models themselves to help\nconstruct bias auditing datasets that remain challenging, and introduce bias\nmeasures that distinguish between different types of model errors. First, we\nextend an existing bias benchmark for NLI (BBNLI) using a combination of\nLM-generated lexical variations, adversarial filtering, and human validation.\nWe demonstrate that the newly created dataset BBNLI-next is more challenging\nthan BBNLI: on average, BBNLI-next reduces the accuracy of state-of-the-art NLI\nmodels from 95.3%, as observed by BBNLI, to a strikingly low 57.5%. Second, we\nemploy BBNLI-next to showcase the interplay between robustness and bias: we\npoint out shortcomings in current bias scores and propose bias measures that\ntake into account both bias and model brittleness. Third, despite the fact that\nBBNLI-next was designed with non-generative models in mind, we show that the\nnew dataset is also able to uncover bias in state-of-the-art open-source\ngenerative LMs.\n  Note: All datasets included in this work are in English and they address\nUS-centered social biases. In the spirit of efficient NLP research, no model\ntraining or fine-tuning was performed to conduct this research.\n  Warning: This paper contains offensive text examples.", "published": "2023-05-22 01:02:45", "link": "http://arxiv.org/abs/2305.12620v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data-efficient Active Learning for Structured Prediction with Partial\n  Annotation and Self-Training", "abstract": "In this work we propose a pragmatic method that reduces the annotation cost\nfor structured label spaces using active learning. Our approach leverages\npartial annotation, which reduces labeling costs for structured outputs by\nselecting only the most informative sub-structures for annotation. We also\nutilize self-training to incorporate the current model's automatic predictions\nas pseudo-labels for un-annotated sub-structures. A key challenge in\neffectively combining partial annotation with self-training to reduce\nannotation cost is determining which sub-structures to select to label. To\naddress this challenge, we adopt an error estimator to adaptively decide the\npartial selection ratio according to the current model's capability. In\nevaluations spanning four structured prediction tasks, we show that our\ncombination of partial annotation and self-training using an adaptive selection\nratio reduces annotation cost over strong full annotation baselines under a\nfair comparison scheme that takes reading time into consideration.", "published": "2023-05-22 01:58:42", "link": "http://arxiv.org/abs/2305.12634v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Sentence Representations: From the BERT Epoch\n  to the ChatGPT Era and Beyond", "abstract": "Sentence representations are a critical component in NLP applications such as\nretrieval, question answering, and text classification. They capture the\nmeaning of a sentence, enabling machines to understand and reason over human\nlanguage. In recent years, significant progress has been made in developing\nmethods for learning sentence representations, including unsupervised,\nsupervised, and transfer learning approaches. However there is no literature\nreview on sentence representations till now. In this paper, we provide an\noverview of the different methods for sentence representation learning,\nfocusing mostly on deep learning models. We provide a systematic organization\nof the literature, highlighting the key contributions and challenges in this\narea. Overall, our review highlights the importance of this area in natural\nlanguage processing, the progress made in sentence representation learning, and\nthe challenges that remain. We conclude with directions for future research,\nsuggesting potential avenues for improving the quality and efficiency of\nsentence representations.", "published": "2023-05-22 02:31:15", "link": "http://arxiv.org/abs/2305.12641v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Frustratingly Simple Decoding Method for Neural Text Generation", "abstract": "We introduce a frustratingly simple, super efficient and surprisingly\neffective decoding method, which we call Frustratingly Simple Decoding (FSD),\nfor neural text generation. The idea behind FSD is straightforward: we build an\nanti-LM based on previously generated text and use this anti-LM to penalize\nfuture generation of what has been generated. The anti-LM can be implemented as\nsimple as an n-gram language model or a vectorized variant. In this way, FSD\nintroduces no extra model parameters and negligible computational overhead (FSD\ncan be as fast as greedy search). Despite the simplicity, FSD is surprisingly\neffective; Experiments show that FSD can outperform the canonical methods to\ndate (i.e., nucleus sampling) as well as several strong baselines that were\nproposed recently.", "published": "2023-05-22 03:28:47", "link": "http://arxiv.org/abs/2305.12675v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Energy-based Language Models with Different Architectures and\n  Training Methods for Speech Recognition", "abstract": "Energy-based language models (ELMs) parameterize an unnormalized distribution\nfor natural sentences and are radically different from popular autoregressive\nlanguage models (ALMs). As an important application, ELMs have been\nsuccessfully used as a means for calculating sentence scores in speech\nrecognition, but they all use less-modern CNN or LSTM networks. The recent\nprogress in Transformer networks and large pretrained models such as BERT and\nGPT2 opens new possibility to further advancing ELMs. In this paper, we explore\ndifferent architectures of energy functions and different training methods to\ninvestigate the capabilities of ELMs in rescoring for speech recognition, all\nusing large pretrained models as backbones.", "published": "2023-05-22 03:28:48", "link": "http://arxiv.org/abs/2305.12676v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal\n  Review Helpfulness Prediction", "abstract": "Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews\nbased on predicted helpfulness scores and has been widely applied in e-commerce\nvia presenting customers with useful reviews. Previous studies commonly employ\nfully-connected neural networks (FCNNs) as the final score predictor and\npairwise loss as the training objective. However, FCNNs have been shown to\nperform inefficient splitting for review features, making the model difficult\nto clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise\nobjective, which works on review pairs, may not completely capture the MRHP\ngoal to produce the ranking for the entire review list, and possibly induces\nlow generalization during testing. To address these issues, we propose a\nlistwise attention network that clearly captures the MRHP ranking context and a\nlistwise optimization objective that enhances model generalization. We further\npropose gradient-boosted decision tree as the score predictor to efficaciously\npartition product reviews' representations. Extensive experiments demonstrate\nthat our method achieves state-of-the-art results and polished generalization\nperformance on two large-scale MRHP benchmark datasets.", "published": "2023-05-22 03:31:00", "link": "http://arxiv.org/abs/2305.12678v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "G3Detector: General GPT-Generated Text Detector", "abstract": "The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.", "published": "2023-05-22 03:35:00", "link": "http://arxiv.org/abs/2305.12680v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Interpretable Style Embeddings via Prompting LLMs", "abstract": "Style representation learning builds content-independent representations of\nauthor style in text. Stylometry, the analysis of style in text, is often\nperformed by expert forensic linguists and no large dataset of stylometric\nannotations exists for training. Current style representation learning uses\nneural methods to disentangle style from content to create style vectors,\nhowever, these approaches result in uninterpretable representations,\ncomplicating their usage in downstream applications like authorship attribution\nwhere auditing and explainability is critical. In this work, we use prompting\nto perform stylometry on a large number of texts to create a synthetic dataset\nand train human-interpretable style representations we call LISA embeddings. We\nrelease our synthetic stylometry dataset and our interpretable style models as\nresources.", "published": "2023-05-22 04:07:54", "link": "http://arxiv.org/abs/2305.12696v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis", "abstract": "Sentiment analysis (SA) systems are widely deployed in many of the world's\nlanguages, and there is well-documented evidence of demographic bias in these\nsystems. In languages beyond English, scarcer training data is often\nsupplemented with transfer learning using pre-trained models, including\nmultilingual models trained on other languages. In some cases, even supervision\ndata comes from other languages. Does cross-lingual transfer also import new\nbiases? To answer this question, we use counterfactual evaluation to test\nwhether gender or racial biases are imported when using cross-lingual transfer,\ncompared to a monolingual transfer setting. Across five languages, we find that\nsystems using cross-lingual transfer usually become more biased than their\nmonolingual counterparts. We also find racial biases to be much more prevalent\nthan gender biases. To spur further research on this topic, we release the\nsentiment models we used for this study, and the intermediate checkpoints\nthroughout training, yielding 1,525 distinct models; we also release our\nevaluation code.", "published": "2023-05-22 04:37:49", "link": "http://arxiv.org/abs/2305.12709v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Labels: Empowering Human Annotators with Natural Language\n  Explanations through a Novel Active-Learning Architecture", "abstract": "Real-world domain experts (e.g., doctors) rarely annotate only a decision\nlabel in their day-to-day workflow without providing explanations. Yet,\nexisting low-resource learning techniques, such as Active Learning (AL), that\naim to support human annotators mostly focus on the label while neglecting the\nnatural language explanation of a data point. This work proposes a novel AL\narchitecture to support experts' real-world need for label and explanation\nannotations in low-resource scenarios. Our AL architecture leverages an\nexplanation-generation model to produce explanations guided by human\nexplanations, a prediction model that utilizes generated explanations toward\nprediction faithfully, and a novel data diversity-based AL sampling strategy\nthat benefits from the explanation annotations. Automated and human evaluations\ndemonstrate the effectiveness of incorporating explanations into AL sampling\nand the improved human annotation efficiency and trustworthiness with our AL\narchitecture. Additional ablation studies illustrate the potential of our AL\narchitecture for transfer learning, generalizability, and integration with\nlarge language models (LLMs). While LLMs exhibit exceptional\nexplanation-generation capabilities for relatively simple tasks, their\neffectiveness in complex real-world tasks warrants further in-depth study.", "published": "2023-05-22 04:38:10", "link": "http://arxiv.org/abs/2305.12710v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MADNet: Maximizing Addressee Deduction Expectation for Multi-Party\n  Conversation Generation", "abstract": "Modeling multi-party conversations (MPCs) with graph neural networks has been\nproven effective at capturing complicated and graphical information flows.\nHowever, existing methods rely heavily on the necessary addressee labels and\ncan only be applied to an ideal setting where each utterance must be tagged\nwith an addressee label. To study the scarcity of addressee labels which is a\ncommon issue in MPCs, we propose MADNet that maximizes addressee deduction\nexpectation in heterogeneous graph neural networks for MPC generation. Given an\nMPC with a few addressee labels missing, existing methods fail to build a\nconsecutively connected conversation graph, but only a few separate\nconversation fragments instead. To ensure message passing between these\nconversation fragments, four additional types of latent edges are designed to\ncomplete a fully-connected graph. Besides, to optimize the edge-type-dependent\nmessage passing for those utterances without addressee labels, an\nExpectation-Maximization-based method that iteratively generates silver\naddressee labels (E step), and optimizes the quality of generated responses (M\nstep), is designed. Experimental results on two Ubuntu IRC channel benchmarks\nshow that MADNet outperforms various baseline models on the task of MPC\ngeneration, especially under the more common and challenging setting where part\nof addressee labels are missing.", "published": "2023-05-22 05:50:11", "link": "http://arxiv.org/abs/2305.12733v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can We Edit Factual Knowledge by In-Context Learning?", "abstract": "Previous studies have shown that large language models (LLMs) like GPTs store\nmassive factual knowledge in their parameters. However, the stored knowledge\ncould be false or out-dated. Traditional knowledge editing methods refine LLMs\nvia fine-tuning on texts containing specific knowledge. However, with the\nincreasing scales of LLMs, these gradient-based approaches bring large\ncomputation costs. The trend of model-as-a-service also makes it impossible to\nmodify knowledge in black-box LMs. Inspired by in-context learning (ICL), a new\nparadigm based on demonstration contexts without parameter updating, we explore\nwhether ICL can edit factual knowledge. To answer this question, we give a\ncomprehensive empirical study of ICL strategies. Experiments show that\nin-context knowledge editing (IKE), without any gradient and parameter\nupdating, achieves a competitive success rate compared to gradient-based\nmethods on GPT-J (6B) but with much fewer side effects, including less\nover-editing on similar but unrelated facts and less knowledge forgetting on\npreviously stored knowledge. We also apply the method to larger LMs with tens\nor hundreds of parameters like OPT-175B, which shows the scalability of our\nmethod. The code is available at https://github.com/Zce1112zslx/IKE.", "published": "2023-05-22 06:07:58", "link": "http://arxiv.org/abs/2305.12740v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Benchmark on Extremely Weakly Supervised Text Classification:\n  Reconcile Seed Matching and Prompting Approaches", "abstract": "Etremely Weakly Supervised Text Classification (XWS-TC) refers to text\nclassification based on minimal high-level human guidance, such as a few\nlabel-indicative seed words or classification instructions. There are two\nmainstream approaches for XWS-TC, however, never being rigorously compared: (1)\ntraining classifiers based on pseudo-labels generated by (softly) matching seed\nwords (SEED) and (2) prompting (and calibrating) language models using\nclassification instruction (and raw texts) to decode label words (PROMPT). This\npaper presents the first XWS-TC benchmark to compare the two approaches on fair\ngrounds, where the datasets, supervisions, and hyperparameter choices are\nstandardized across methods. Our benchmarking results suggest that (1) Both\nSEED and PROMPT approaches are competitive and there is no clear winner; (2)\nSEED is empirically more tolerant than PROMPT to human guidance (e.g., seed\nwords, classification instructions, and label words) changes; (3) SEED is\nempirically more selective than PROMPT to the pre-trained language models; (4)\nRecent SEED and PROMPT methods have close connections and a clustering\npost-processing step based on raw in-domain texts is a strong performance\nbooster to both. We hope this benchmark serves as a guideline in selecting\nXWS-TC methods in different scenarios and stimulate interest in developing\nguidance- and model-robust XWS-TC methods. We release the repo at\nhttps://github.com/ZihanWangKi/x-TC.", "published": "2023-05-22 06:18:23", "link": "http://arxiv.org/abs/2305.12749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language\n  Models", "abstract": "Bias research in NLP seeks to analyse models for social biases, thus helping\nNLP practitioners uncover, measure, and mitigate social harms. We analyse the\nbody of work that uses prompts and templates to assess bias in language models.\nWe draw on a measurement modelling framework to create a taxonomy of attributes\nthat capture what a bias test aims to measure and how that measurement is\ncarried out. By applying this taxonomy to 90 bias tests, we illustrate\nqualitatively and quantitatively that core aspects of bias test\nconceptualisations and operationalisations are frequently unstated or\nambiguous, carry implicit assumptions, or be mismatched. Our analysis\nilluminates the scope of possible bias types the field is able to measure, and\nreveals types that are as yet under-researched. We offer guidance to enable the\ncommunity to explore a wider section of the possible bias space, and to better\nclose the gap between desired outcomes and experimental design, both for bias\nand for evaluating language models more broadly.", "published": "2023-05-22 06:28:48", "link": "http://arxiv.org/abs/2305.12757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Kanbun-LM: Reading and Translating Classical Chinese in Japanese Methods\n  by Language Models", "abstract": "Recent studies in natural language processing (NLP) have focused on modern\nlanguages and achieved state-of-the-art results in many tasks. Meanwhile,\nlittle attention has been paid to ancient texts and related tasks. Classical\nChinese first came to Japan approximately 2,000 years ago. It was gradually\nadapted to a Japanese form called Kanbun-Kundoku (Kanbun) in Japanese reading\nand translating methods, which has significantly impacted Japanese literature.\nHowever, compared to the rich resources for ancient texts in mainland China,\nKanbun resources remain scarce in Japan. To solve this problem, we construct\nthe first Classical-Chinese-to-Kanbun dataset in the world. Furthermore, we\nintroduce two tasks, character reordering and machine translation, both of\nwhich play a significant role in Kanbun comprehension. We also test the current\nlanguage models on these tasks and discuss the best evaluation method by\ncomparing the results with human scores. We release our code and dataset on\nGitHub.", "published": "2023-05-22 06:30:02", "link": "http://arxiv.org/abs/2305.12759v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Optimal Policy for Simultaneous Machine Translation via Binary\n  Search", "abstract": "Simultaneous machine translation (SiMT) starts to output translation while\nreading the source sentence and needs a precise policy to decide when to output\nthe generated translation. Therefore, the policy determines the number of\nsource tokens read during the translation of each target token. However, it is\ndifficult to learn a precise translation policy to achieve good latency-quality\ntrade-offs, because there is no golden policy corresponding to parallel\nsentences as explicit supervision. In this paper, we present a new method for\nconstructing the optimal policy online via binary search. By employing explicit\nsupervision, our approach enables the SiMT model to learn the optimal policy,\nwhich can guide the model in completing the translation during inference.\nExperiments on four translation tasks show that our method can exceed strong\nbaselines across all latency scenarios.", "published": "2023-05-22 07:03:06", "link": "http://arxiv.org/abs/2305.12774v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Pragmatic Abilities of Image Captioners on A3DS", "abstract": "Evaluating grounded neural language model performance with respect to\npragmatic qualities like the trade off between truthfulness, contrastivity and\noverinformativity of generated utterances remains a challenge in absence of\ndata collected from humans. To enable such evaluation, we present a novel open\nsource image-text dataset \"Annotated 3D Shapes\" (A3DS) comprising over nine\nmillion exhaustive natural language annotations and over 12 million\nvariable-granularity captions for the 480,000 images provided by Burges & Kim\n(2018). We showcase the evaluation of pragmatic abilities developed by a\ntask-neutral image captioner fine-tuned in a multi-agent communication setting\nto produce contrastive captions. The evaluation is enabled by the dataset\nbecause the exhaustive annotations allow to quantify the presence of\ncontrastive features in the model's generations. We show that the model\ndevelops human-like patterns (informativity, brevity, over-informativity for\nspecific features (e.g., shape, color biases)).", "published": "2023-05-22 07:15:33", "link": "http://arxiv.org/abs/2305.12777v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MacLaSa: Multi-Aspect Controllable Text Generation via Efficient\n  Sampling from Compact Latent Space", "abstract": "Multi-aspect controllable text generation aims to generate fluent sentences\nthat possess multiple desired attributes simultaneously. Traditional methods\neither combine many operators in the decoding stage, often with costly\niteration or search in the discrete text space, or train separate controllers\nfor each aspect, resulting in a degeneration of text quality due to the\ndiscrepancy between different aspects. To address these limitations, we\nintroduce a novel approach for multi-aspect control, namely MacLaSa, that\nestimates compact latent space for multiple aspects and performs efficient\nsampling with a robust sampler based on ordinary differential equations (ODEs).\nTo eliminate the domain gaps between different aspects, we utilize a\nVariational Autoencoder (VAE) network to map text sequences from varying data\nsources into close latent representations. The estimated latent space enables\nthe formulation of joint energy-based models (EBMs) and the plugging in of\narbitrary attribute discriminators to achieve multi-aspect control. Afterwards,\nwe draw latent vector samples with an ODE-based sampler and feed sampled\nexamples to the VAE decoder to produce target text sequences. Experimental\nresults demonstrate that MacLaSa outperforms several strong baselines on\nattribute relevance and textual quality while maintaining a high inference\nspeed.", "published": "2023-05-22 07:30:35", "link": "http://arxiv.org/abs/2305.12785v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Data Imbalance and Representation Degeneration in\n  Multilingual Machine Translation", "abstract": "Despite advances in multilingual neural machine translation (MNMT), we argue\nthat there are still two major challenges in this area: data imbalance and\nrepresentation degeneration. The data imbalance problem refers to the imbalance\nin the amount of parallel corpora for all language pairs, especially for\nlong-tail languages (i.e., very low-resource languages). The representation\ndegeneration problem refers to the problem of encoded tokens tending to appear\nonly in a small subspace of the full space available to the MNMT model. To\nsolve these two issues, we propose Bi-ACL, a framework that uses only\ntarget-side monolingual data and a bilingual dictionary to improve the\nperformance of the MNMT model. We define two modules, named bidirectional\nautoencoder and bidirectional contrastive learning, which we combine with an\nonline constrained beam search and a curriculum learning sampling strategy.\nExtensive experiments show that our proposed method is more effective both in\nlong-tail languages and in high-resource languages. We also demonstrate that\nour approach is capable of transferring knowledge between domains and languages\nin zero-shot scenarios.", "published": "2023-05-22 07:31:08", "link": "http://arxiv.org/abs/2305.12786v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Agency of LLMs in Human-AI Collaboration Tasks", "abstract": "Agency, the capacity to proactively shape events, is central to how humans\ninteract and collaborate. While LLMs are being developed to simulate human\nbehavior and serve as human-like agents, little attention has been given to the\nAgency that these models should possess in order to proactively manage the\ndirection of interaction and collaboration. In this paper, we investigate\nAgency as a desirable function of LLMs, and how it can be measured and managed.\nWe build on social-cognitive theory to develop a framework of features through\nwhich Agency is expressed in dialogue - indicating what you intend to do\n(Intentionality), motivating your intentions (Motivation), having self-belief\nin intentions (Self-Efficacy), and being able to self-adjust (Self-Regulation).\nWe collect a new dataset of 83 human-human collaborative interior design\nconversations containing 908 conversational snippets annotated for Agency\nfeatures. Using this dataset, we develop methods for measuring Agency of LLMs.\nAutomatic and human evaluations show that models that manifest features\nassociated with high Intentionality, Motivation, Self-Efficacy, and\nSelf-Regulation are more likely to be perceived as strongly agentive.", "published": "2023-05-22 08:17:14", "link": "http://arxiv.org/abs/2305.12815v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Farewell to Aimless Large-scale Pretraining: Influential Subset\n  Selection for Language Model", "abstract": "Pretrained language models have achieved remarkable success in various\nnatural language processing tasks. However, pretraining has recently shifted\ntoward larger models and larger data, and this has resulted in significant\ncomputational and energy costs. In this paper, we propose Influence Subset\nSelection (ISS) for language model, which explicitly utilizes end-task\nknowledge to select a tiny subset of the pretraining corpus. Specifically, the\nISS selects the samples that will provide the most positive influence on the\nperformance of the end-task. Furthermore, we design a gradient matching based\ninfluence estimation method, which can drastically reduce the computation time\nof influence. With only 0.45% of the data and a three-orders-of-magnitude lower\ncomputational cost, ISS outperformed pretrained models (e.g., RoBERTa) on eight\ndatasets covering four domains.", "published": "2023-05-22 08:18:58", "link": "http://arxiv.org/abs/2305.12816v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Bias and Fairness in NLP: Investigating the Impact of Bias and\n  Debiasing in Language Models on the Fairness of Toxicity Detection", "abstract": "Language models are the new state-of-the-art natural language processing\n(NLP) models and they are being increasingly used in many NLP tasks. Even\nthough there is evidence that language models are biased, the impact of that\nbias on the fairness of downstream NLP tasks is still understudied.\nFurthermore, despite that numerous debiasing methods have been proposed in the\nliterature, the impact of bias removal methods on the fairness of NLP tasks is\nalso understudied. In this work, we investigate three different sources of bias\nin NLP models, i.e. representation bias, selection bias and overamplification\nbias, and examine how they impact the fairness of the downstream task of\ntoxicity detection. Moreover, we investigate the impact of removing these\nbiases using different bias removal techniques on the fairness of toxicity\ndetection. Results show strong evidence that downstream sources of bias,\nespecially overamplification bias, are the most impactful types of bias on the\nfairness of the task of toxicity detection. We also found strong evidence that\nremoving overamplification bias by fine-tuning the language models on a dataset\nwith balanced contextual representations and ratios of positive examples\nbetween different identity groups can improve the fairness of the task of\ntoxicity detection. Finally, we build on our findings and introduce a list of\nguidelines to ensure the fairness of the task of toxicity detection.", "published": "2023-05-22 08:44:00", "link": "http://arxiv.org/abs/2305.12829v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CopyNE: Better Contextual ASR by Copying Named Entities", "abstract": "End-to-end automatic speech recognition (ASR) systems have made significant\nprogress in general scenarios. However, it remains challenging to transcribe\ncontextual named entities (NEs) in the contextual ASR scenario. Previous\napproaches have attempted to address this by utilizing the NE dictionary. These\napproaches treat entities as individual tokens and generate them\ntoken-by-token, which may result in incomplete transcriptions of entities. In\nthis paper, we treat entities as indivisible wholes and introduce the idea of\ncopying into ASR. We design a systematic mechanism called CopyNE, which can\ncopy entities from the NE dictionary. By copying all tokens of an entity at\nonce, we can reduce errors during entity transcription, ensuring the\ncompleteness of the entity. Experiments demonstrate that CopyNE consistently\nimproves the accuracy of transcribing entities compared to previous approaches.\nEven when based on the strong Whisper, CopyNE still achieves notable\nimprovements.", "published": "2023-05-22 09:03:11", "link": "http://arxiv.org/abs/2305.12839v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lion: Adversarial Distillation of Proprietary Large Language Models", "abstract": "The practice of transferring knowledge from a sophisticated, proprietary\nlarge language model (LLM) to a compact, open-source LLM has garnered\nconsiderable attention. Previous works have focused on a unidirectional\nknowledge distillation way by aligning the responses of the student model with\nthose of the teacher model to a set of instructions. Nevertheless, they\noverlooked the possibility of incorporating any reciprocal\n\"feedback\"--identifying challenging instructions where the student model's\nperformance falls short--to boost the student model's proficiency iteratively.\nTo this end, we propose a novel adversarial distillation framework for a more\nefficient knowledge transfer. Leveraging the versatile role adaptability of\nLLMs, we prompt the teacher model to identify \"hard\" instructions and generate\nnew \"hard\" instructions for the student model, creating a three-stage\nadversarial loop of imitation, discrimination, and generation. By applying this\nadversarial framework, we successfully transfer knowledge from ChatGPT to a\nstudent model (named Lion), using a mere 70k training data. Our results show\nthat Lion-13B not only achieves comparable open-ended generation capabilities\nto ChatGPT but surpasses conventional state-of-the-art (SOTA) instruction-tuned\nmodels like Vicuna-13B by 55.4% in challenging zero-shot reasoning benchmarks\nsuch as BIG-Bench Hard (BBH) and 16.7% on AGIEval. Code and model can be found\nat https://github.com/YJiangcm/Lion.", "published": "2023-05-22 09:49:16", "link": "http://arxiv.org/abs/2305.12870v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-Autoregressive Document-Level Machine Translation", "abstract": "Non-autoregressive translation (NAT) models achieve comparable performance\nand superior speed compared to auto-regressive translation (AT) models in the\ncontext of sentence-level machine translation (MT). However, their abilities\nare unexplored in document-level MT, hindering their usage in real scenarios.\nIn this paper, we conduct a comprehensive examination of typical NAT models in\nthe context of document-level MT and further propose a simple but effective\ndesign of sentence alignment between source and target. Experiments show that\nNAT models achieve high acceleration on documents, and sentence alignment\nsignificantly enhances their performance.\n  However, current NAT models still have a significant performance gap compared\nto their AT counterparts. Further investigation reveals that NAT models suffer\nmore from the multi-modality and misalignment issues in the context of\ndocument-level MT, and current NAT models struggle with exploiting document\ncontext and handling discourse phenomena. We delve into these challenges and\nprovide our code at \\url{https://github.com/baoguangsheng/nat-on-doc}.", "published": "2023-05-22 09:59:59", "link": "http://arxiv.org/abs/2305.12878v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Human Feedback to Scale Educational Datasets: Combining\n  Crowdworkers and Comparative Judgement", "abstract": "Machine Learning models have many potentially beneficial applications in\neducation settings, but a key barrier to their development is securing enough\ndata to train these models. Labelling educational data has traditionally relied\non highly skilled raters using complex, multi-class rubrics, making the process\nexpensive and difficult to scale. An alternative, more scalable approach could\nbe to use non-expert crowdworkers to evaluate student work, however,\nmaintaining sufficiently high levels of accuracy and inter-rater reliability\nwhen using non-expert workers is challenging. This paper reports on two\nexperiments investigating using non-expert crowdworkers and comparative\njudgement to evaluate complex student data. Crowdworkers were hired to evaluate\nstudent responses to open-ended reading comprehension questions. Crowdworkers\nwere randomly assigned to one of two conditions: the control, where they were\nasked to decide whether answers were correct or incorrect (i.e., a categorical\njudgement), or the treatment, where they were shown the same question and\nanswers, but were instead asked to decide which of two candidate answers was\nmore correct (i.e., a comparative/preference-based judgement). We found that\nusing comparative judgement substantially improved inter-rater reliability on\nboth tasks. These results are in-line with well-established literature on the\nbenefits of comparative judgement in the field of educational assessment, as\nwell as with recent trends in artificial intelligence research, where\ncomparative judgement is becoming the preferred method for providing human\nfeedback on model outputs when working with non-expert crowdworkers. However,\nto our knowledge, these results are novel and important in demonstrating the\nbeneficial effects of using the combination of comparative judgement and\ncrowdworkers to evaluate educational data.", "published": "2023-05-22 10:22:14", "link": "http://arxiv.org/abs/2305.12894v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models for German Text Simplification: Overcoming Parallel Data\n  Scarcity through Style-specific Pre-training", "abstract": "Automatic text simplification systems help to reduce textual information\nbarriers on the internet. However, for languages other than English, only few\nparallel data to train these systems exists. We propose a two-step approach to\novercome this data scarcity issue. First, we fine-tuned language models on a\ncorpus of German Easy Language, a specific style of German. Then, we used these\nmodels as decoders in a sequence-to-sequence simplification task. We show that\nthe language models adapt to the style characteristics of Easy Language and\noutput more accessible texts. Moreover, with the style-specific pre-training,\nwe reduced the number of trainable parameters in text simplification models.\nHence, less parallel data is sufficient for training. Our results indicate that\npre-training on unaligned data can reduce the required parallel data while\nimproving the performance on downstream tasks.", "published": "2023-05-22 10:41:30", "link": "http://arxiv.org/abs/2305.12908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and\n  Why?", "abstract": "Understanding the fundamental concepts and trends in a scientific field is\ncrucial for keeping abreast of its continuous advancement. In this study, we\npropose a systematic framework for analyzing the evolution of research topics\nin a scientific field using causal discovery and inference techniques. We\ndefine three variables to encompass diverse facets of the evolution of research\ntopics within NLP and utilize a causal discovery algorithm to unveil the causal\nconnections among these variables using observational data. Subsequently, we\nleverage this structure to measure the intensity of these relationships. By\nconducting extensive experiments on the ACL Anthology corpus, we demonstrate\nthat our framework effectively uncovers evolutionary trends and the underlying\ncauses for a wide range of NLP research topics. Specifically, we show that\ntasks and methods are primary drivers of research in NLP, with datasets\nfollowing, while metrics have minimal impact.", "published": "2023-05-22 11:08:00", "link": "http://arxiv.org/abs/2305.12920v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EnCore: Fine-Grained Entity Typing by Pre-Training Entity Encoders on\n  Coreference Chains", "abstract": "Entity typing is the task of assigning semantic types to the entities that\nare mentioned in a text. In the case of fine-grained entity typing (FET), a\nlarge set of candidate type labels is considered. Since obtaining sufficient\namounts of manual annotations is then prohibitively expensive, FET models are\ntypically trained using distant supervision. In this paper, we propose to\nimprove on this process by pre-training an entity encoder such that embeddings\nof coreferring entities are more similar to each other than to the embeddings\nof other entities. The main problem with this strategy, which helps to explain\nwhy it has not previously been considered, is that predicted coreference links\nare often too noisy. We show that this problem can be addressed by using a\nsimple trick: we only consider coreference links that are predicted by two\ndifferent off-the-shelf systems. With this prudent use of coreference links,\nour pre-training strategy allows us to improve the state-of-the-art in\nbenchmarks on fine-grained entity typing, as well as traditional entity\nextraction.", "published": "2023-05-22 11:11:59", "link": "http://arxiv.org/abs/2305.12924v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GEST: the Graph of Events in Space and Time as a Common Representation\n  between Vision and Language", "abstract": "One of the essential human skills is the ability to seamlessly build an inner\nrepresentation of the world. By exploiting this representation, humans are\ncapable of easily finding consensus between visual, auditory and linguistic\nperspectives. In this work, we set out to understand and emulate this ability\nthrough an explicit representation for both vision and language - Graphs of\nEvents in Space and Time (GEST). GEST alows us to measure the similarity\nbetween texts and videos in a semantic and fully explainable way, through graph\nmatching. It also allows us to generate text and videos from a common\nrepresentation that provides a well understood content. In this work we show\nthat the graph matching similarity metrics based on GEST outperform classical\ntext generation metrics and can also boost the performance of state of art,\nheavily trained metrics.", "published": "2023-05-22 11:38:27", "link": "http://arxiv.org/abs/2305.12940v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist\n  Examination", "abstract": "As ChatGPT and GPT-4 spearhead the development of Large Language Models\n(LLMs), more researchers are investigating their performance across various\ntasks. But more research needs to be done on the interpretability capabilities\nof LLMs, that is, the ability to generate reasons after an answer has been\ngiven. Existing explanation datasets are mostly English-language general\nknowledge questions, which leads to insufficient thematic and linguistic\ndiversity. To address the language bias and lack of medical resources in\ngenerating rationales QA datasets, we present ExplainCPE (over 7k instances), a\nchallenging medical benchmark in Simplified Chinese. We analyzed the errors of\nChatGPT and GPT-4, pointing out the limitations of current LLMs in\nunderstanding text and computational reasoning. During the experiment, we also\nfound that different LLMs have different preferences for in-context learning.\nExplainCPE presents a significant challenge, but its potential for further\ninvestigation is promising, and it can be used to evaluate the ability of a\nmodel to generate explanations. AI safety and trustworthiness need more\nattention, and this work makes the first step to explore the medical\ninterpretability of LLMs.The dataset is available at\nhttps://github.com/HITsz-TMG/ExplainCPE.", "published": "2023-05-22 11:45:42", "link": "http://arxiv.org/abs/2305.12945v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatGPT to Replace Crowdsourcing of Paraphrases for Intent\n  Classification: Higher Diversity and Comparable Model Robustness", "abstract": "The emergence of generative large language models (LLMs) raises the question:\nwhat will be its impact on crowdsourcing? Traditionally, crowdsourcing has been\nused for acquiring solutions to a wide variety of human-intelligence tasks,\nincluding ones involving text generation, modification or evaluation. For some\nof these tasks, models like ChatGPT can potentially substitute human workers.\nIn this study, we investigate whether this is the case for the task of\nparaphrase generation for intent classification. We apply data collection\nmethodology of an existing crowdsourcing study (similar scale, prompts and seed\ndata) using ChatGPT and Falcon-40B. We show that ChatGPT-created paraphrases\nare more diverse and lead to at least as robust models.", "published": "2023-05-22 11:46:32", "link": "http://arxiv.org/abs/2305.12947v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distilling ChatGPT for Explainable Automated Student Answer Assessment", "abstract": "Providing explainable and faithful feedback is crucial for automated student\nanswer assessment. In this paper, we introduce a novel framework that explores\nusing ChatGPT, a cutting-edge large language model, for the concurrent tasks of\nstudent answer scoring and rationale generation. We identify the appropriate\ninstructions by prompting ChatGPT with different templates to collect the\nrationales, where inconsistent rationales are refined to align with marking\nstandards. The refined ChatGPT outputs enable us to fine-tune a smaller\nlanguage model that simultaneously assesses student answers and provides\nrationales. Extensive experiments on the benchmark dataset show that the\nproposed method improves the overall QWK score by 11% compared to ChatGPT.\nFurthermore, our thorough analysis and human evaluation demonstrate that the\nrationales generated by our proposed method are comparable to those of ChatGPT.\nOur approach provides a viable solution to achieve explainable automated\nassessment in education. Code available at\nhttps://github.com/lijiazheng99/aera.", "published": "2023-05-22 12:11:39", "link": "http://arxiv.org/abs/2305.12962v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Representations via Gaussian Embedding", "abstract": "Recent progress in sentence embedding, which represents the meaning of a\nsentence as a point in a vector space, has achieved high performance on tasks\nsuch as a semantic textual similarity (STS) task. However, sentence\nrepresentations as a point in a vector space can express only a part of the\ndiverse information that sentences have, such as asymmetrical relationships\nbetween sentences. This paper proposes GaussCSE, a Gaussian distribution-based\ncontrastive learning framework for sentence embedding that can handle\nasymmetric relationships between sentences, along with a similarity measure for\nidentifying inclusion relations. Our experiments show that GaussCSE achieves\nthe same performance as previous methods in natural language inference tasks,\nand is able to estimate the direction of entailment relations, which is\ndifficult with point representations.", "published": "2023-05-22 12:51:38", "link": "http://arxiv.org/abs/2305.12990v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bidirectional Transformer Reranker for Grammatical Error Correction", "abstract": "Pre-trained seq2seq models have achieved state-of-the-art results in the\ngrammatical error correction task. However, these models still suffer from a\nprediction bias due to their unidirectional decoding. Thus, we propose a\nbidirectional Transformer reranker (BTR), that re-estimates the probability of\neach candidate sentence generated by the pre-trained seq2seq model. The BTR\npreserves the seq2seq-style Transformer architecture but utilizes a BERT-style\nself-attention mechanism in the decoder to compute the probability of each\ntarget token by using masked language modeling to capture bidirectional\nrepresentations from the target context. For guiding the reranking, the BTR\nadopts negative sampling in the objective function to minimize the\nunlikelihood. During inference, the BTR gives final results after comparing the\nreranked top-1 results with the original ones by an acceptance threshold.\nExperimental results show that, in reranking candidates from a pre-trained\nseq2seq model, T5-base, the BTR on top of T5-base could yield 65.47 and 71.27\nF0.5 scores on the CoNLL-14 and BEA test sets, respectively, and yield 59.52\nGLEU score on the JFLEG corpus, with improvements of 0.36, 0.76 and 0.48 points\ncompared with the original T5-base. Furthermore, when reranking candidates from\nT5-large, the BTR on top of T5-base improved the original T5-large by 0.26\npoints on the BEA test set.", "published": "2023-05-22 13:04:48", "link": "http://arxiv.org/abs/2305.13000v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models emulate an inductive Thematic Analysis of\n  semi-structured interviews? An exploration and provocation on the limits of\n  the approach and the model", "abstract": "Large Language Models (LLMs) have emerged as powerful generative Artificial\nIntelligence solutions which can be applied to several fields and areas of\nwork. This paper presents results and reflection of an experiment done to use\nthe model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic\nAnalysis. Previous research on this subject has largely worked on conducting\ndeductive analysis. Thematic Analysis is a qualitative method for analysis\ncommonly used in social sciences and it is based on interpretations made by the\nhuman analyst(s) and the identification of explicit and latent meanings in\nqualitative data. Attempting an analysis based on human interpretation with an\nLLM clearly is a provocation but also a way to learn something about how these\nsystems can or cannot be used in qualitative research. The paper presents the\nmotivations for attempting this emulation, it reflects on how the six steps to\na Thematic Analysis proposed by Braun and Clarke can at least partially be\nreproduced with the LLM and it also reflects on what are the outputs produced\nby the model. The paper used two existing datasets of open access\nsemi-structured interviews, previously analysed with Thematic Analysis by other\nresearchers. It used the previously produced analysis (and the related themes)\nto compare with the results produced by the LLM. The results show that the\nmodel can infer at least partially some of the main Themes. The objective of\nthe paper is not to replace human analysts in qualitative analysis but to learn\nif some elements of LLM data manipulation can to an extent be of support for\nqualitative research.", "published": "2023-05-22 13:16:07", "link": "http://arxiv.org/abs/2305.13014v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding", "abstract": "The main objective of Knowledge Graph (KG) embeddings is to learn\nlow-dimensional representations of entities and relations, enabling the\nprediction of missing facts. A significant challenge in achieving better KG\nembeddings lies in capturing relation patterns, including symmetry,\nantisymmetry, inversion, commutative composition, non-commutative composition,\nhierarchy, and multiplicity. This study introduces a novel model called 3H-TH\n(3D Rotation and Translation in Hyperbolic space) that captures these relation\npatterns simultaneously. In contrast, previous attempts have not achieved\nsatisfactory performance across all the mentioned properties at the same time.\nThe experimental results demonstrate that the new model outperforms existing\nstate-of-the-art models in terms of accuracy, hierarchy property, and other\nrelation patterns in low-dimensional space, meanwhile performing similarly in\nhigh-dimensional space.", "published": "2023-05-22 13:17:23", "link": "http://arxiv.org/abs/2305.13015v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Iterative Forward Tuning Boosts In-Context Learning in Language Models", "abstract": "Despite the advancements in in-context learning (ICL) for large language\nmodels (LLMs), current research centers on specific prompt engineering, such as\ndemonstration selection, with the expectation that a single iteration of\ndemonstrations processing can generalize effectively to a given test sample.\nHowever, this perspective overlooks the potential benefits derived from\nmultiple iterations involving demonstrations, a practice aligning more closely\nwith the iterative decision-making process exhibited by humans, who often learn\nthrough analogy. In this study, we introduce a novel two-stage framework to\nboost ICL in LLMs. Specifically, our framework delineates the ICL process into\ntwo distinct stages: Deep-Thinking and test stages. The Deep-Thinking stage\nincorporates a unique attention mechanism, i.e., iterative enhanced attention,\nwhich enables multiple rounds of information accumulation. This mechanism\noperates by manipulating the Key-Value matrices without training, fostering\nenhanced understanding capabilities in LLMs by thinking demonstrations multiple\ntimes. We evaluated Deep-Thinking across a range of benchmarks and LLMs,\nshowing its superior performance over vanilla ICL methods and its effectiveness\nin challenging tasks where demonstration selection is infeasible.", "published": "2023-05-22 13:18:17", "link": "http://arxiv.org/abs/2305.13016v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DUMB: A Benchmark for Smart Evaluation of Dutch Models", "abstract": "We introduce the Dutch Model Benchmark: DUMB. The benchmark includes a\ndiverse set of datasets for low-, medium- and high-resource tasks. The total\nset of nine tasks includes four tasks that were previously not available in\nDutch. Instead of relying on a mean score across tasks, we propose Relative\nError Reduction (RER), which compares the DUMB performance of language models\nto a strong baseline which can be referred to in the future even when assessing\ndifferent sets of language models. Through a comparison of 14 pre-trained\nlanguage models (mono- and multi-lingual, of varying sizes), we assess the\ninternal consistency of the benchmark tasks, as well as the factors that likely\nenable high performance. Our results indicate that current Dutch monolingual\nmodels under-perform and suggest training larger Dutch models with other\narchitectures and pre-training objectives. At present, the highest performance\nis achieved by DeBERTaV3 (large), XLM-R (large) and mDeBERTaV3 (base). In\naddition to highlighting best strategies for training larger Dutch models, DUMB\nwill foster further research on Dutch. A public leaderboard is available at\nhttps://dumbench.nl.", "published": "2023-05-22 13:27:37", "link": "http://arxiv.org/abs/2305.13026v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nearest Neighbor Machine Translation is Meta-Optimizer on Output\n  Projection Layer", "abstract": "Nearest Neighbor Machine Translation ($k$NN-MT) has achieved great success in\ndomain adaptation tasks by integrating pre-trained Neural Machine Translation\n(NMT) models with domain-specific token-level retrieval. However, the reasons\nunderlying its success have not been thoroughly investigated. In this paper, we\ncomprehensively analyze $k$NN-MT through theoretical and empirical studies.\nInitially, we provide new insights into the working mechanism of $k$NN-MT as an\nefficient technique to implicitly execute gradient descent on the output\nprojection layer of NMT, indicating that it is a specific case of model\nfine-tuning. Subsequently, we conduct multi-domain experiments and word-level\nanalysis to examine the differences in performance between $k$NN-MT and\nentire-model fine-tuning. Our findings suggest that: (1) Incorporating $k$NN-MT\nwith adapters yields comparable translation performance to fine-tuning on\nin-domain test sets, while achieving better performance on out-of-domain test\nsets; (2) Fine-tuning significantly outperforms $k$NN-MT on the recall of\nin-domain low-frequency words, but this gap could be bridged by optimizing the\ncontext representations with additional adapter layers.", "published": "2023-05-22 13:38:53", "link": "http://arxiv.org/abs/2305.13034v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated stance detection in complex topics and small languages: the\n  challenging case of immigration in polarizing news media", "abstract": "Automated stance detection and related machine learning methods can provide\nuseful insights for media monitoring and academic research. Many of these\napproaches require annotated training datasets, which limits their\napplicability for languages where these may not be readily available. This\npaper explores the applicability of large language models for automated stance\ndetection in a challenging scenario, involving a morphologically complex,\nlower-resource language, and a socio-culturally complex topic, immigration. If\nthe approach works in this case, it can be expected to perform as well or\nbetter in less demanding scenarios. We annotate a large set of pro and\nanti-immigration examples, and compare the performance of multiple language\nmodels as supervised learners. We also probe the usability of ChatGPT as an\ninstructable zero-shot classifier for the same task. Supervised achieves\nacceptable performance, and ChatGPT yields similar accuracy. This is promising\nas a potentially simpler and cheaper alternative for text classification tasks,\nincluding in lower-resource languages. We further use the best-performing model\nto investigate diachronic trends over seven years in two corpora of Estonian\nmainstream and right-wing populist news sources, demonstrating the\napplicability of the approach for news analytics and media monitoring settings,\nand discuss correspondences between stance changes and real-world events.", "published": "2023-05-22 13:56:35", "link": "http://arxiv.org/abs/2305.13047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieval-augmented Multi-label Text Classification", "abstract": "Multi-label text classification (MLC) is a challenging task in settings of\nlarge label sets, where label support follows a Zipfian distribution. In this\npaper, we address this problem through retrieval augmentation, aiming to\nimprove the sample efficiency of classification models. Our approach closely\nfollows the standard MLC architecture of a Transformer-based encoder paired\nwith a set of classification heads. In our case, however, the input document\nrepresentation is augmented through cross-attention to similar documents\nretrieved from the training set and represented in a task-specific manner. We\nevaluate this approach on four datasets from the legal and biomedical domains,\nall of which feature highly skewed label distributions. Our experiments show\nthat retrieval augmentation substantially improves model performance on the\nlong tail of infrequent labels especially so for lower-resource training\nscenarios and more challenging long-document data scenarios.", "published": "2023-05-22 14:16:23", "link": "http://arxiv.org/abs/2305.13058v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine-Created Universal Language for Cross-lingual Transfer", "abstract": "There are two primary approaches to addressing cross-lingual transfer:\nmultilingual pre-training, which implicitly aligns the hidden representations\nof various languages, and translate-test, which explicitly translates different\nlanguages into an intermediate language, such as English. Translate-test offers\nbetter interpretability compared to multilingual pre-training. However, it has\nlower performance than multilingual pre-training(Conneau and Lample, 2019;\nConneau et al, 2020) and struggles with word-level tasks due to translation\naltering word order. As a result, we propose a new Machine-created Universal\nLanguage (MUL) as an alternative intermediate language. MUL comprises a set of\ndiscrete symbols forming a universal vocabulary and a natural language to MUL\ntranslator for converting multiple natural languages to MUL. MUL unifies shared\nconcepts from various languages into a single universal word, enhancing\ncross-language transfer. Additionally, MUL retains language-specific words and\nword order, allowing the model to be easily applied to word-level tasks. Our\nexperiments demonstrate that translating into MUL yields improved performance\ncompared to multilingual pre-training, and our analysis indicates that MUL\npossesses strong interpretability. The code is at:\nhttps://github.com/microsoft/Unicoder/tree/master/MCUL.", "published": "2023-05-22 14:41:09", "link": "http://arxiv.org/abs/2305.13071v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Abstract Specification of VoxML as an Annotation Language", "abstract": "VoxML is a modeling language used to map natural language expressions into\nreal-time visualizations using commonsense semantic knowledge of objects and\nevents. Its utility has been demonstrated in embodied simulation environments\nand in agent-object interactions in situated multimodal human-agent\ncollaboration and communication. It introduces the notion of object affordance\n(both Gibsonian and Telic) from HRI and robotics, as well as the concept of\nhabitat (an object's context of use) for interactions between a rational agent\nand an object. This paper aims to specify VoxML as an annotation language in\ngeneral abstract terms. It then shows how it works on annotating linguistic\ndata that express visually perceptible human-object interactions. The\nannotation structures thus generated will be interpreted against the enriched\nminimal model created by VoxML as a modeling language while supporting the\nmodeling purposes of VoxML linguistically.", "published": "2023-05-22 14:47:59", "link": "http://arxiv.org/abs/2305.13076v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InheritSumm: A General, Versatile and Compact Summarizer by Distilling\n  from GPT", "abstract": "While large models such as GPT-3 demonstrate exceptional performance in\nzeroshot and fewshot summarization tasks, their extensive serving and\nfine-tuning costs hinder their utilization in various applications. Conversely,\nprevious studies have found that although automatic metrics tend to favor\nsmaller fine-tuned models, the quality of the summaries they generate is\ninferior to that of larger models like GPT-3 when assessed by human evaluators.\nTo address this issue, we propose InheritSumm, a versatile and compact\nsummarization model derived from GPT-3.5 through distillation. InheritSumm not\nonly exhibits comparable zeroshot and fewshot summarization capabilities to\nGPT-3.5 but is also sufficiently compact for fine-tuning purposes. Experimental\nresults demonstrate that InheritSumm achieves similar or superior performance\nto GPT-3.5 in zeroshot and fewshot settings. Furthermore, it outperforms the\npreviously established best small models in both prefix-tuning and full-data\nfine-tuning scenarios.", "published": "2023-05-22 14:52:32", "link": "http://arxiv.org/abs/2305.13083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models", "abstract": "This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.", "published": "2023-05-22 14:52:47", "link": "http://arxiv.org/abs/2305.13085v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LMGQS: A Large-scale Dataset for Query-focused Summarization", "abstract": "Query-focused summarization (QFS) aims to extract or generate a summary of an\ninput document that directly answers or is relevant to a given query. The lack\nof large-scale datasets in the form of documents, queries, and summaries has\nhindered model development in this area. In contrast, multiple large-scale\nhigh-quality datasets for generic summarization exist. We hypothesize that\nthere is a hidden query for each summary sentence in a generic summarization\nannotation, and we utilize a large-scale pretrained language model to recover\nit. In this way, we convert four generic summarization benchmarks into a new\nQFS benchmark dataset, LMGQS, which consists of over 1 million\ndocument-query-summary samples. We thoroughly investigate the properties of our\nproposed dataset and establish baselines with state-of-the-art summarization\nmodels. By fine-tuning a language model on LMGQS, we achieve state-of-the-art\nzero-shot and supervised performance on multiple existing QFS benchmarks,\ndemonstrating the high quality and diversity of LMGQS.", "published": "2023-05-22 14:53:45", "link": "http://arxiv.org/abs/2305.13086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Not Yet Human-Level Evaluators for Abstractive\n  Summarization", "abstract": "With the recent undeniable advancement in reasoning abilities in large\nlanguage models (LLMs) like ChatGPT and GPT-4, there is a growing trend for\nusing LLMs on various tasks. One area where LLMs can be employed is as an\nalternative evaluation metric for complex generative tasks, which generally\ndemands expensive human judges to complement the traditional automatic metrics\nfor various evaluation dimensions such as fluency and consistency. In this\nwork, we conduct extensive analysis to investigate the stability and\nreliability of LLMs as automatic evaluators for abstractive summarization. We\nfound that while ChatGPT and GPT-4 outperform the commonly used automatic\nmetrics, they are not ready as human replacements due to significant\nlimitations. That is, LLM evaluators rate each candidate system inconsistently\nand are dimension-dependent. They also struggle to compare candidates with\nclose performance and become more unreliable with higher-quality summaries by\nobtaining a lower correlation with humans. In other words, with better\nabstractive summarization systems being introduced at a fast pace, LLMs may\nresult in misleading and unreliable evaluations.", "published": "2023-05-22 14:58:13", "link": "http://arxiv.org/abs/2305.13091v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Compositional Generalization by Generating Demonstrations for\n  Meta-Learning", "abstract": "Meta-learning and few-shot prompting are viable methods to induce certain\ntypes of compositional behaviour. However, these methods can be very sensitive\nto the choice of support examples used. Choosing good supports from the\ntraining data for a given test query is already a difficult problem, but in\nsome cases solving this may not even be enough. We consider a grounded language\nlearning problem (gSCAN) where good support examples for certain test splits\nmight not even exist in the training data, or would be infeasible to search\nfor. We design an agent which instead generates possible supports which are\nrelevant to the test query and current state of the world, then uses these\nsupports via meta-learning to solve the test query. We show substantially\nimproved performance on a previously unsolved compositional behaviour split\nwithout a loss of performance on other splits. Further experiments show that in\nthis case, searching for relevant demonstrations even with an oracle function\nis not sufficient to attain good performance when using meta-learning.", "published": "2023-05-22 14:58:54", "link": "http://arxiv.org/abs/2305.13092v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AVeriTeC: A Dataset for Real-world Claim Verification with Evidence from\n  the Web", "abstract": "Existing datasets for automated fact-checking have substantial limitations,\nsuch as relying on artificial claims, lacking annotations for evidence and\nintermediate reasoning, or including evidence published after the claim. In\nthis paper we introduce AVeriTeC, a new dataset of 4,568 real-world claims\ncovering fact-checks by 50 different organizations. Each claim is annotated\nwith question-answer pairs supported by evidence available online, as well as\ntextual justifications explaining how the evidence combines to produce a\nverdict. Through a multi-round annotation process, we avoid common pitfalls\nincluding context dependence, evidence insufficiency, and temporal leakage, and\nreach a substantial inter-annotator agreement of $\\kappa=0.619$ on verdicts. We\ndevelop a baseline as well as an evaluation scheme for verifying claims through\nseveral question-answering steps against the open web.", "published": "2023-05-22 15:17:18", "link": "http://arxiv.org/abs/2305.13117v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ambiguity Meets Uncertainty: Investigating Uncertainty Estimation for\n  Word Sense Disambiguation", "abstract": "Word sense disambiguation (WSD), which aims to determine an appropriate sense\nfor a target word given its context, is crucial for natural language\nunderstanding. Existing supervised methods treat WSD as a classification task\nand have achieved remarkable performance. However, they ignore uncertainty\nestimation (UE) in the real-world setting, where the data is always noisy and\nout of distribution. This paper extensively studies UE on the benchmark\ndesigned for WSD. Specifically, we first compare four uncertainty scores for a\nstate-of-the-art WSD model and verify that the conventional predictive\nprobabilities obtained at the end of the model are inadequate to quantify\nuncertainty. Then, we examine the capability of capturing data and model\nuncertainties by the model with the selected UE score on well-designed test\nscenarios and discover that the model reflects data uncertainty satisfactorily\nbut underestimates model uncertainty. Furthermore, we explore numerous lexical\nproperties that intrinsically affect data uncertainty and provide a detailed\nanalysis of four critical aspects: the syntactic category, morphology, sense\ngranularity, and semantic relations. The code is available at\nhttps://github.com/RyanLiut/WSD-UE.", "published": "2023-05-22 15:18:15", "link": "http://arxiv.org/abs/2305.13119v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extrapolating Multilingual Understanding Models as Multilingual\n  Generators", "abstract": "Multilingual understanding models (or encoder-based), pre-trained via masked\nlanguage modeling, have achieved promising results on many language\nunderstanding tasks (e.g., mBERT). However, these non-autoregressive (NAR)\nmodels still struggle to generate high-quality texts compared with\nautoregressive (AR) models. Considering that encoder-based models have the\nadvantage of efficient generation and self-correction abilities, this paper\nexplores methods to empower multilingual understanding models the generation\nabilities to get a unified model. Specifically, we start from a multilingual\nencoder (XLM-R) and propose a \\textbf{S}emantic-\\textbf{G}uided\n\\textbf{A}lignment-then-Denoising (SGA) approach to adapt an encoder to a\nmultilingual generator with a small number of new parameters. Experiments show\nthat the proposed approach is an effective adaption method, outperforming\nwidely-used initialization-based methods with gains of 9.4 BLEU on machine\ntranslation, 8.1 Rouge-L on question generation, and 5.5 METEOR on story\ngeneration on XLM-R$_{large}$. On the other hand, we observe that XLM-R is\nstill inferior to mBART in supervised settings despite better results on\nzero-shot settings, indicating that more exploration is required to make\nunderstanding models strong generators.", "published": "2023-05-22 15:33:21", "link": "http://arxiv.org/abs/2305.13140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Sampling of Negatives for Distantly Supervised Named Entity\n  Recognition", "abstract": "Distantly supervised named entity recognition (DS-NER) has been proposed to\nexploit the automatically labeled training data instead of human annotations.\nThe distantly annotated datasets are often noisy and contain a considerable\nnumber of false negatives. The recent approach uses a weighted sampling\napproach to select a subset of negative samples for training. However, it\nrequires a good classifier to assign weights to the negative samples. In this\npaper, we propose a simple and straightforward approach for selecting the top\nnegative samples that have high similarities with all the positive samples for\ntraining. Our method achieves consistent performance improvements on four\ndistantly supervised NER datasets. Our analysis also shows that it is critical\nto differentiate the true negatives from the false negatives.", "published": "2023-05-22 15:35:39", "link": "http://arxiv.org/abs/2305.13142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM\n  Inference Pipeline", "abstract": "Large language models (LLMs) have revolutionized the field of AI,\ndemonstrating unprecedented capacity across various tasks. However, the\ninference process for LLMs comes with significant computational costs. In this\npaper, we propose an efficient LLM inference pipeline that harnesses the power\nof LLMs. Our approach begins by tapping into the potential of LLMs to\naccurately perceive and predict the response length with minimal overhead. By\nleveraging this information, we introduce an efficient sequence scheduling\ntechnique that groups queries with similar response lengths into micro-batches.\nWe evaluate our approach on real-world instruction datasets using the\nLLaMA-based model, and our results demonstrate an impressive 86% improvement in\ninference throughput without compromising effectiveness. Notably, our method is\northogonal to other inference acceleration techniques, making it a valuable\naddition to many existing toolkits (e.g., FlashAttention, Quantization) for LLM\ninference.", "published": "2023-05-22 15:36:06", "link": "http://arxiv.org/abs/2305.13144v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via\n  Debate", "abstract": "Large language models (LLMs) such as ChatGPT and GPT-4 have shown impressive\nperformance in complex reasoning tasks. However, it is difficult to know\nwhether the models are reasoning based on deep understandings of truth and\nlogic, or leveraging their memorized patterns in a relatively superficial way.\nIn this work, we explore testing LLMs' reasoning by engaging with them in a\ndebate-like conversation, where given a question, the LLM and the user need to\ndiscuss to make the correct decision starting from opposing arguments. Upon\nmitigating the Clever Hans effect, our task requires the LLM to not only\nachieve the correct answer on its own, but also be able to hold and defend its\nbelief instead of blindly believing or getting misled by the user's (invalid)\narguments and critiques, thus testing in greater depth whether the LLM grasps\nthe essence of the reasoning required to solve the problem. Across a range of\ncomplex reasoning benchmarks spanning math, commonsense, logic and BIG-Bench\ntasks, we find that despite their impressive performance as reported in\nexisting work on generating correct step-by-step solutions in the beginning,\nLLMs like ChatGPT cannot maintain their beliefs in truth for a significant\nportion of examples when challenged by oftentimes absurdly invalid arguments.\nOur work points to danger zones of model alignment, and also suggests more\ncareful treatments and interpretations of the recent findings that LLMs can\nimprove their responses based on feedback.", "published": "2023-05-22 15:47:31", "link": "http://arxiv.org/abs/2305.13160v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discovering Universal Geometry in Embeddings with ICA", "abstract": "This study utilizes Independent Component Analysis (ICA) to unveil a\nconsistent semantic structure within embeddings of words or images. Our\napproach extracts independent semantic components from the embeddings of a\npre-trained model by leveraging anisotropic information that remains after the\nwhitening process in Principal Component Analysis (PCA). We demonstrate that\neach embedding can be expressed as a composition of a few intrinsic\ninterpretable axes and that these semantic axes remain consistent across\ndifferent languages, algorithms, and modalities. The discovery of a universal\nsemantic structure in the geometric patterns of embeddings enhances our\nunderstanding of the representations in embeddings.", "published": "2023-05-22 16:04:44", "link": "http://arxiv.org/abs/2305.13175v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimCSE++: Improving Contrastive Learning for Sentence Embeddings from\n  Two Perspectives", "abstract": "This paper improves contrastive learning for sentence embeddings from two\nperspectives: handling dropout noise and addressing feature corruption.\nSpecifically, for the first perspective, we identify that the dropout noise\nfrom negative pairs affects the model's performance. Therefore, we propose a\nsimple yet effective method to deal with such type of noise. Secondly, we\npinpoint the rank bottleneck of current solutions to feature corruption and\npropose a dimension-wise contrastive learning objective to address this issue.\nBoth proposed methods are generic and can be applied to any contrastive\nlearning based models for sentence embeddings. Experimental results on standard\nbenchmarks demonstrate that combining both proposed methods leads to a gain of\n1.8 points compared to the strong baseline SimCSE configured with BERT base.\nFurthermore, applying the proposed method to DiffCSE, another strong\ncontrastive learning based baseline, results in a gain of 1.4 points.", "published": "2023-05-22 16:24:46", "link": "http://arxiv.org/abs/2305.13192v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization\n  Evaluation", "abstract": "Reliable automatic evaluation of summarization systems is challenging due to\nthe multifaceted and subjective nature of the task. This is especially the case\nfor languages other than English, where human evaluations are scarce. In this\nwork, we introduce SEAHORSE, a dataset for multilingual, multifaceted\nsummarization evaluation. SEAHORSE consists of 96K summaries with human ratings\nalong 6 dimensions of text quality: comprehensibility, repetition, grammar,\nattribution, main ideas, and conciseness, covering 6 languages, 9 systems and 4\ndatasets. As a result of its size and scope, SEAHORSE can serve both as a\nbenchmark to evaluate learnt metrics, as well as a large-scale resource for\ntraining such metrics. We show that metrics trained with SEAHORSE achieve\nstrong performance on the out-of-domain meta-evaluation benchmarks TRUE\n(Honovich et al., 2022) and mFACE (Aharoni et al., 2022). We make the SEAHORSE\ndataset and metrics publicly available for future research on multilingual and\nmultifaceted summarization evaluation.", "published": "2023-05-22 16:25:07", "link": "http://arxiv.org/abs/2305.13194v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil\n  Demographic Biases in Languages at Scale", "abstract": "We introduce a multilingual extension of the HOLISTICBIAS dataset, the\nlargest English template-based taxonomy of textual people references:\nMULTILINGUALHOLISTICBIAS. This extension consists of 20,459 sentences in 50\nlanguages distributed across all 13 demographic axes. Source sentences are\nbuilt from combinations of 118 demographic descriptors and three patterns,\nexcluding nonsensical combinations. Multilingual translations include\nalternatives for gendered languages that cover gendered translations when there\nis ambiguity in English. Our benchmark is intended to uncover demographic\nimbalances and be the tool to quantify mitigations towards them.\n  Our initial findings show that translation quality for EN-to-XX translations\nis an average of 8 spBLEU better when evaluating with the masculine human\nreference compared to feminine. In the opposite direction, XX-to-EN, we compare\nthe robustness of the model when the source input only differs in gender\n(masculine or feminine) and masculine translations are an average of almost 4\nspBLEU better than feminine. When embedding sentences to a joint multilingual\nsentence representations space, we find that for most languages masculine\ntranslations are significantly closer to the English neutral sentences when\nembedded.", "published": "2023-05-22 16:29:04", "link": "http://arxiv.org/abs/2305.13198v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision", "abstract": "Most existing task-oriented dialog (TOD) systems track dialog states in terms\nof slots and values and use them to query a database to get relevant knowledge\nto generate responses. In real-life applications, user utterances are noisier,\nand thus it is more difficult to accurately track dialog states and correctly\nsecure relevant knowledge. Recently, a progress in question answering and\ndocument-grounded dialog systems is retrieval-augmented methods with a\nknowledge retriever. Inspired by such progress, we propose a retrieval-based\nmethod to enhance knowledge selection in TOD systems, which significantly\noutperforms the traditional database query method for real-life dialogs.\nFurther, we develop latent variable model based semi-supervised learning, which\ncan work with the knowledge retriever to leverage both labeled and unlabeled\ndialog data. Joint Stochastic Approximation (JSA) algorithm is employed for\nsemi-supervised model training, and the whole system is referred to as that\nJSA-KRTOD. Experiments are conducted on a real-life dataset from China Mobile\nCustom-Service, called MobileCS, and show that JSA-KRTOD achieves superior\nperformances in both labeled-only and semi-supervised settings.", "published": "2023-05-22 16:29:20", "link": "http://arxiv.org/abs/2305.13199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Atomic Inference for NLI with Generated Facts as Atoms", "abstract": "With recent advances, neural models can achieve human-level performance on\nvarious natural language tasks. However, there are no guarantees that any\nexplanations from these models are faithful, i.e. that they reflect the inner\nworkings of the model. Atomic inference overcomes this issue, providing\ninterpretable and faithful model decisions. This approach involves making\npredictions for different components (or atoms) of an instance, before using\ninterpretable and deterministic rules to derive the overall prediction based on\nthe individual atom-level predictions. We investigate the effectiveness of\nusing LLM-generated facts as atoms, decomposing Natural Language Inference\npremises into lists of facts. While directly using generated facts in atomic\ninference systems can result in worse performance, with 1) a multi-stage fact\ngeneration process, and 2) a training regime that incorporates the facts, our\nfact-based method outperforms other approaches.", "published": "2023-05-22 16:45:50", "link": "http://arxiv.org/abs/2305.13214v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A\n  Preliminary Study on Writing Assistance", "abstract": "Proprietary Large Language Models (LLMs), such as ChatGPT, have garnered\nsignificant attention due to their exceptional capabilities in handling a\ndiverse range of tasks. Recent studies demonstrate that open-sourced smaller\nfoundational models, such as 7B-size LLaMA, can also display remarkable\nproficiency in tackling diverse tasks when fine-tuned using instruction-driven\ndata. In this work, we investigate a practical problem setting where the\nprimary focus is on one or a few particular tasks rather than general-purpose\ninstruction following, and explore whether LLMs can be beneficial and further\nimproved for such targeted scenarios. We choose the writing-assistant scenario\nas the testbed, which includes seven writing tasks. We collect training data\nfor these tasks, reframe them in an instruction-following format, and\nsubsequently refine the LLM, specifically LLaMA, via instruction tuning.\nExperimental results show that fine-tuning LLaMA on writing instruction data\nsignificantly improves its ability on writing tasks. We also conduct more\nexperiments and analyses to offer insights for future work on effectively\nfine-tuning LLaMA for specific scenarios. Finally, we initiate a discussion\nregarding the necessity of employing LLMs for only one targeted task, taking\ninto account the efforts required for tuning and the resources consumed during\ndeployment.", "published": "2023-05-22 16:56:44", "link": "http://arxiv.org/abs/2305.13225v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAGE: Machine-generated Text Detection in the Wild", "abstract": "Large language models (LLMs) have achieved human-level text generation,\nemphasizing the need for effective AI-generated text detection to mitigate\nrisks like the spread of fake news and plagiarism. Existing research has been\nconstrained by evaluating detection methods on specific domains or particular\nlanguage models. In practical scenarios, however, the detector faces texts from\nvarious domains or LLMs without knowing their sources. To this end, we build a\ncomprehensive testbed by gathering texts from diverse human writings and texts\ngenerated by different LLMs. Empirical results show challenges in\ndistinguishing machine-generated texts from human-authored ones across various\nscenarios, especially out-of-distribution. These challenges are due to the\ndecreasing linguistic distinctions between the two sources. Despite challenges,\nthe top-performing detector can identify 86.54% out-of-domain texts generated\nby a new LLM, indicating the feasibility for application scenarios. We release\nour resources at https://github.com/yafuly/MAGE.", "published": "2023-05-22 17:13:29", "link": "http://arxiv.org/abs/2305.13242v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Knowledge: Grounding Large Language Models via Dynamic\n  Knowledge Adapting over Heterogeneous Sources", "abstract": "We present chain-of-knowledge (CoK), a novel framework that augments large\nlanguage models (LLMs) by dynamically incorporating grounding information from\nheterogeneous sources. It results in more factual rationales and reduced\nhallucination in generation. Specifically, CoK consists of three stages:\nreasoning preparation, dynamic knowledge adapting, and answer consolidation.\nGiven a knowledge-intensive question, CoK first prepares several preliminary\nrationales and answers while identifying the relevant knowledge domains. If\nthere is no majority consensus among the answers from samples, CoK corrects the\nrationales step by step by adapting knowledge from the identified domains.\nThese corrected rationales can plausibly serve as a better foundation for the\nfinal answer consolidation. Unlike prior studies that primarily use\nunstructured data, CoK also leverages structured knowledge sources such as\nWikidata and tables that provide more reliable factual information. To access\nboth unstructured and structured knowledge sources in the dynamic knowledge\nadapting stage, we propose an adaptive query generator that allows the\ngeneration of queries for various types of query languages, including SPARQL,\nSQL, and natural sentences. Moreover, to minimize error propagation between\nrationales, CoK corrects the rationales progressively using preceding corrected\nrationales to generate and correct subsequent rationales. Extensive experiments\nshow that CoK consistently improves the performance of LLMs on\nknowledge-intensive tasks across different domains.", "published": "2023-05-22 17:34:23", "link": "http://arxiv.org/abs/2305.13269v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLASS: A Design Framework for building Intelligent Tutoring Systems\n  based on Learning Science principles", "abstract": "We present a design framework called Conversational Learning with Analytical\nStep-by-Step Strategies (CLASS) for building advanced Intelligent Tutoring\nSystems (ITS) powered by high-performance Large Language Models (LLMs). The\nCLASS framework empowers ITS with two key capabilities. First, through a\ncarefully curated scaffolding dataset, CLASS equips ITS with essential\nproblem-solving strategies, enabling it to provide tutor-like, step-by-step\nguidance to students. Second, by using a dynamic conversational dataset, CLASS\nassists ITS in facilitating natural language interactions, fostering engaging\nstudent-tutor conversations. The CLASS framework also provides valuable\ninsights into ITS' internal decision-making process which allows seamless\nintegration of user feedback, thus enabling continuous refinement and\nimprovement. We also present a proof-of-concept ITS, referred to as SPOCK,\nwhich is trained using the CLASS framework with a focus on introductory\ncollege-level biology content. A carefully constructed protocol was developed\nfor SPOCK's preliminary evaluation, examining aspects such as the factual\naccuracy and relevance of its responses. Experts in the field of biology\noffered favorable remarks, particularly highlighting SPOCK's capability to\nbreak down questions into manageable subproblems and provide encouraging\nresponses to students. Code and models are available at\nhttps://github.com/luffycodes/Tutorbot-Spock.", "published": "2023-05-22 17:35:05", "link": "http://arxiv.org/abs/2305.13272v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LM vs LM: Detecting Factual Errors via Cross Examination", "abstract": "A prominent weakness of modern language models (LMs) is their tendency to\ngenerate factually incorrect text, which hinders their usability. A natural\nquestion is whether such factual errors can be detected automatically. Inspired\nby truth-seeking mechanisms in law, we propose a factuality evaluation\nframework for LMs that is based on cross-examination. Our key idea is that an\nincorrect claim is likely to result in inconsistency with other claims that the\nmodel generates. To discover such inconsistencies, we facilitate a multi-turn\ninteraction between the LM that generated the claim and another LM (acting as\nan examiner) which introduces questions to discover inconsistencies. We\nempirically evaluate our method on factual claims made by multiple recent LMs\non four benchmarks, finding that it outperforms existing methods and baselines,\noften by a large gap. Our results demonstrate the potential of using\ninteracting LMs for capturing factual errors.", "published": "2023-05-22 17:42:14", "link": "http://arxiv.org/abs/2305.13281v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How do languages influence each other? Studying cross-lingual data\n  sharing during LM fine-tuning", "abstract": "Multilingual large language models (MLLMs) are jointly trained on data from\nmany different languages such that representation of individual languages can\nbenefit from other languages' data. Impressive performance on zero-shot\ncross-lingual transfer shows that these models are capable of exploiting data\nfrom other languages. Yet, it remains unclear to what extent, and under which\nconditions, languages rely on each other's data. In this study, we use TracIn\n(Pruthi et al., 2020), a training data attribution (TDA) method, to retrieve\nthe most influential training samples seen during multilingual fine-tuning for\na particular test language. This allows us to analyse cross-lingual sharing\nmechanisms of MLLMs from a new perspective. While previous work studied\ncross-lingual sharing at the level of model parameters, we present the first\napproach to study cross-lingual sharing at the data level. We find that MLLMs\nrely on data from multiple languages from the early stages of fine-tuning and\nthat this reliance gradually increases as fine-tuning progresses. We further\nstudy how different fine-tuning languages influence model performance on a\ngiven test language and find that they can both reinforce and complement the\nknowledge acquired from data of the test language itself.", "published": "2023-05-22 17:47:41", "link": "http://arxiv.org/abs/2305.13286v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the Role of Feed-Forward Networks in Transformers Using\n  Parallel Attention and Feed-Forward Net Design", "abstract": "This paper investigates the key role of Feed-Forward Networks (FFNs) in\ntransformer models by utilizing the Parallel Attention and Feed-Forward Net\nDesign (PAF) architecture, and comparing it to their Series Attention and\nFeed-Forward Net Design (SAF) counterparts. Central to the effectiveness of PAF\nare two main assumptions regarding the FFN block and the attention block within\na layer: 1) the primary function of the FFN block is to maintain isotropy among\ntoken embeddings and prevent their degeneration, and 2) the residual norm\ncomputed in the attention block is substantially smaller than the input token\nembedding norm. To empirically validate these assumptions, we train PAF\nvariants of two large language models (RoBERTa-large and bert-large-uncased).\nOur results demonstrate that both assumptions hold true in the PAF design. This\nstudy contributes to a deeper understanding of the roles and interactions\nbetween FFNs and self-attention mechanisms in transformer architectures.", "published": "2023-05-22 17:56:09", "link": "http://arxiv.org/abs/2305.13297v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiffusionNER: Boundary Diffusion for Named Entity Recognition", "abstract": "In this paper, we propose DiffusionNER, which formulates the named entity\nrecognition task as a boundary-denoising diffusion process and thus generates\nnamed entities from noisy spans. During training, DiffusionNER gradually adds\nnoises to the golden entity boundaries by a fixed forward diffusion process and\nlearns a reverse diffusion process to recover the entity boundaries. In\ninference, DiffusionNER first randomly samples some noisy spans from a standard\nGaussian distribution and then generates the named entities by denoising them\nwith the learned reverse diffusion process. The proposed boundary-denoising\ndiffusion process allows progressive refinement and dynamic sampling of\nentities, empowering DiffusionNER with efficient and flexible entity generation\ncapability. Experiments on multiple flat and nested NER datasets demonstrate\nthat DiffusionNER achieves comparable or even better performance than previous\nstate-of-the-art models.", "published": "2023-05-22 17:56:12", "link": "http://arxiv.org/abs/2305.13298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language-Agnostic Bias Detection in Language Models with Bias Probing", "abstract": "Pretrained language models (PLMs) are key components in NLP, but they contain\nstrong social biases. Quantifying these biases is challenging because current\nmethods focusing on fill-the-mask objectives are sensitive to slight changes in\ninput. To address this, we propose a bias probing technique called LABDet, for\nevaluating social bias in PLMs with a robust and language-agnostic method. For\nnationality as a case study, we show that LABDet `surfaces' nationality bias by\ntraining a classifier on top of a frozen PLM on non-nationality sentiment\ndetection. We find consistent patterns of nationality bias across monolingual\nPLMs in six languages that align with historical and political context. We also\nshow for English BERT that bias surfaced by LABDet correlates well with bias in\nthe pretraining data; thus, our work is one of the few studies that directly\nlinks pretraining data to PLM behavior. Finally, we verify LABDet's reliability\nand applicability to different templates and languages through an extensive set\nof robustness checks. We publicly share our code and dataset in\nhttps://github.com/akoksal/LABDet.", "published": "2023-05-22 17:58:01", "link": "http://arxiv.org/abs/2305.13302v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Unsupervised Recognition of Token-level Semantic Differences in\n  Related Documents", "abstract": "Automatically highlighting words that cause semantic differences between two\ndocuments could be useful for a wide range of applications. We formulate\nrecognizing semantic differences (RSD) as a token-level regression task and\nstudy three unsupervised approaches that rely on a masked language model. To\nassess the approaches, we begin with basic English sentences and gradually move\nto more complex, cross-lingual document pairs. Our results show that an\napproach based on word alignment and sentence-level contrastive learning has a\nrobust correlation to gold labels. However, all unsupervised approaches still\nleave a large margin of improvement. Code to reproduce our experiments is\navailable at https://github.com/ZurichNLP/recognizing-semantic-differences", "published": "2023-05-22 17:58:04", "link": "http://arxiv.org/abs/2305.13303v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Factual Consistency of Texts with Semantic Role Labeling", "abstract": "Automated evaluation of text generation systems has recently seen increasing\nattention, particularly checking whether generated text stays truthful to input\nsources. Existing methods frequently rely on an evaluation using task-specific\nlanguage models, which in turn allows for little interpretability of generated\nscores. We introduce SRLScore, a reference-free evaluation metric designed with\ntext summarization in mind. Our approach generates fact tuples constructed from\nSemantic Role Labels, applied to both input and summary texts. A final\nfactuality score is computed by an adjustable scoring mechanism, which allows\nfor easy adaption of the method across domains. Correlation with human\njudgments on English summarization datasets shows that SRLScore is competitive\nwith state-of-the-art methods and exhibits stable generalization across\ndatasets without requiring further training or hyperparameter tuning. We\nexperiment with an optional co-reference resolution step, but find that the\nperformance boost is mostly outweighed by the additional compute required. Our\nmetric is available online at https://github.com/heyjing/SRLScore.", "published": "2023-05-22 17:59:42", "link": "http://arxiv.org/abs/2305.13309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs facilitate interpretation of pre-trained language models?", "abstract": "Work done to uncover the knowledge encoded within pre-trained language models\nrely on annotated corpora or human-in-the-loop methods. However, these\napproaches are limited in terms of scalability and the scope of interpretation.\nWe propose using a large language model, ChatGPT, as an annotator to enable\nfine-grained interpretation analysis of pre-trained language models. We\ndiscover latent concepts within pre-trained language models by applying\nagglomerative hierarchical clustering over contextualized representations and\nthen annotate these concepts using ChatGPT. Our findings demonstrate that\nChatGPT produces accurate and semantically richer annotations compared to\nhuman-annotated concepts. Additionally, we showcase how GPT-based annotations\nempower interpretation analysis methodologies of which we demonstrate two:\nprobing frameworks and neuron interpretation. To facilitate further exploration\nand experimentation in the field, we make available a substantial ConceptNet\ndataset (TCN) comprising 39,000 annotated concepts.", "published": "2023-05-22 18:03:13", "link": "http://arxiv.org/abs/2305.13386v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for\n  Real-World Pharmacovigilance", "abstract": "Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical\nliterature is paramount for public safety, but involves slow and costly manual\nlabor. We set out to improve drug safety monitoring (pharmacovigilance, PV)\nthrough the use of Natural Language Processing (NLP). We introduce BioDEX, a\nlarge-scale resource for Biomedical adverse Drug Event Extraction, rooted in\nthe historical output of drug safety reporting in the U.S. BioDEX consists of\n65k abstracts and 19k full-text biomedical papers with 256k associated\ndocument-level safety reports created by medical experts. The core features of\nthese reports include the reported weight, age, and biological sex of a\npatient, a set of drugs taken by the patient, the drug dosages, the reactions\nexperienced, and whether the reaction was life threatening. In this work, we\nconsider the task of predicting the core information of the report given its\noriginating paper. We estimate human performance to be 72.0% F1, whereas our\nbest model achieves 62.3% F1, indicating significant headroom on this task. We\nalso begin to explore ways in which these models could help professional PV\nreviewers. Our code and data are available: https://github.com/KarelDO/BioDEX.", "published": "2023-05-22 18:15:57", "link": "http://arxiv.org/abs/2305.13395v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A study of conceptual language similarity: comparison and evaluation", "abstract": "An interesting line of research in natural language processing (NLP) aims to\nincorporate linguistic typology to bridge linguistic diversity and assist the\nresearch of low-resource languages. While most works construct linguistic\nsimilarity measures based on lexical or typological features, such as word\norder and verbal inflection, recent work has introduced a novel approach to\ndefining language similarity based on how they represent basic concepts, which\nis complementary to existing similarity measures. In this work, we study the\nconceptual similarity in detail and evaluate it extensively on a binary\nclassification task.", "published": "2023-05-22 18:28:02", "link": "http://arxiv.org/abs/2305.13401v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GATology for Linguistics: What Syntactic Dependencies It Knows", "abstract": "Graph Attention Network (GAT) is a graph neural network which is one of the\nstrategies for modeling and representing explicit syntactic knowledge and can\nwork with pre-trained models, such as BERT, in downstream tasks. Currently,\nthere is still a lack of investigation into how GAT learns syntactic knowledge\nfrom the perspective of model structure. As one of the strategies for modeling\nexplicit syntactic knowledge, GAT and BERT have never been applied and\ndiscussed in Machine Translation (MT) scenarios. We design a dependency\nrelation prediction task to study how GAT learns syntactic knowledge of three\nlanguages as a function of the number of attention heads and layers. We also\nuse a paired t-test and F1-score to clarify the differences in syntactic\ndependency prediction between GAT and BERT fine-tuned by the MT task (MT-B).\nThe experiments show that better performance can be achieved by appropriately\nincreasing the number of attention heads with two GAT layers. With more than\ntwo layers, learning suffers. Moreover, GAT is more competitive in training\nspeed and syntactic dependency prediction than MT-B, which may reveal a better\nincorporation of modeling explicit syntactic knowledge and the possibility of\ncombining GAT and BERT in the MT tasks.", "published": "2023-05-22 18:34:12", "link": "http://arxiv.org/abs/2305.13403v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules", "abstract": "Existing large language models (LLMs) that mainly focus on Standard American\nEnglish (SAE) often lead to significantly worse performance when being applied\nto other English dialects. While existing mitigations tackle discrepancies for\nindividual target dialects, they assume access to high-accuracy dialect\nidentification systems. The boundaries between dialects are inherently\nflexible, making it difficult to categorize language into discrete predefined\ncategories. In this paper, we propose DADA (Dialect Adaptation via Dynamic\nAggregation), a modular approach to imbue SAE-trained models with\nmulti-dialectal robustness by composing adapters which handle specific\nlinguistic features. The compositional architecture of DADA allows for both\ntargeted adaptation to specific dialect variants and simultaneous adaptation to\nvarious dialects. We show that DADA is effective for both single task and\ninstruction finetuned language models, offering an extensible and interpretable\nframework for adapting existing LLMs to different English dialects.", "published": "2023-05-22 18:43:31", "link": "http://arxiv.org/abs/2305.13406v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Element-aware Summarization with Large Language Models: Expert-aligned\n  Evaluation and Chain-of-Thought Method", "abstract": "Automatic summarization generates concise summaries that contain key ideas of\nsource documents. As the most mainstream datasets for the news sub-domain,\nCNN/DailyMail and BBC XSum have been widely used for performance benchmarking.\nHowever, the reference summaries of those datasets turn out to be noisy, mainly\nin terms of factual hallucination and information redundancy. To address this\nchallenge, we first annotate new expert-writing Element-aware test sets\nfollowing the \"Lasswell Communication Model\" proposed by Lasswell (1948),\nallowing reference summaries to focus on more fine-grained news elements\nobjectively and comprehensively. Utilizing the new test sets, we observe the\nsurprising zero-shot summary ability of LLMs, which addresses the issue of the\ninconsistent results between human preference and automatic evaluation metrics\nof LLMs' zero-shot summaries in prior work. Further, we propose a Summary\nChain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step\nby step, which helps them integrate more fine-grained details of source\ndocuments into the final summaries that correlate with the human writing\nmindset. Experimental results show our method outperforms state-of-the-art\nfine-tuned PLMs and zero-shot LLMs by +4.33/+4.77 in ROUGE-L on the two\ndatasets, respectively. Dataset and code are publicly available at\nhttps://github.com/Alsace08/SumCoT.", "published": "2023-05-22 18:54:35", "link": "http://arxiv.org/abs/2305.13412v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Knowledge via Graph Attention with BERT in Machine Translation", "abstract": "Although the Transformer model can effectively acquire context features via a\nself-attention mechanism, deeper syntactic knowledge is still not effectively\nmodeled. To alleviate the above problem, we propose Syntactic knowledge via\nGraph attention with BERT (SGB) in Machine Translation (MT) scenarios. Graph\nAttention Network (GAT) and BERT jointly represent syntactic dependency feature\nas explicit knowledge of the source language to enrich source language\nrepresentations and guide target language generation. Our experiments use gold\nsyntax-annotation sentences and Quality Estimation (QE) model to obtain\ninterpretability of translation quality improvement regarding syntactic\nknowledge without being limited to a BLEU score. Experiments show that the\nproposed SGB engines improve translation quality across the three MT tasks\nwithout sacrificing BLEU scores. We investigate what length of source sentences\nbenefits the most and what dependencies are better identified by the SGB\nengines. We also find that learning of specific dependency relations by GAT can\nbe reflected in the translation quality containing such relations and that\nsyntax on the graph leads to new modeling of syntactic aspects of source\nsentences in the middle and bottom layers of BERT.", "published": "2023-05-22 18:56:14", "link": "http://arxiv.org/abs/2305.13413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VISIT: Visualizing and Interpreting the Semantic Information Flow of\n  Transformers", "abstract": "Recent advances in interpretability suggest we can project weights and hidden\nstates of transformer-based language models (LMs) to their vocabulary, a\ntransformation that makes them more human interpretable. In this paper, we\ninvestigate LM attention heads and memory values, the vectors the models\ndynamically create and recall while processing a given input. By analyzing the\ntokens they represent through this projection, we identify patterns in the\ninformation flow inside the attention mechanism. Based on our discoveries, we\ncreate a tool to visualize a forward pass of Generative Pre-trained\nTransformers (GPTs) as an interactive flow graph, with nodes representing\nneurons or hidden states and edges representing the interactions between them.\nOur visualization simplifies huge amounts of data into easy-to-read plots that\ncan reflect the models' internal processing, uncovering the contribution of\neach component to the models' final prediction. Our visualization also unveils\nnew insights about the role of layer norms as semantic filters that influence\nthe models' output, and about neurons that are always activated during forward\npasses and act as regularization vectors.", "published": "2023-05-22 19:04:56", "link": "http://arxiv.org/abs/2305.13417v2", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Clembench: Using Game Play to Evaluate Chat-Optimized Language Models as\n  Conversational Agents", "abstract": "Recent work has proposed a methodology for the systematic evaluation of\n\"Situated Language Understanding Agents\"-agents that operate in rich linguistic\nand non-linguistic contexts-through testing them in carefully constructed\ninteractive settings. Other recent work has argued that Large Language Models\n(LLMs), if suitably set up, can be understood as (simulators of) such agents. A\nconnection suggests itself, which this paper explores: Can LLMs be evaluated\nmeaningfully by exposing them to constrained game-like settings that are built\nto challenge specific capabilities? As a proof of concept, this paper\ninvestigates five interaction settings, showing that current chat-optimised\nLLMs are, to an extent, capable to follow game-play instructions. Both this\ncapability and the quality of the game play, measured by how well the\nobjectives of the different games are met, follows the development cycle, with\nnewer models performing better. The metrics even for the comparatively simple\nexample games are far from being saturated, suggesting that the proposed\ninstrument will remain to have diagnostic value. Our general framework for\nimplementing and evaluating games with LLMs is available at\nhttps://github.com/clembench .", "published": "2023-05-22 19:56:10", "link": "http://arxiv.org/abs/2305.13455v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Look-back Decoding for Open-Ended Text Generation", "abstract": "Given a prefix (context), open-ended generation aims to decode texts that are\ncoherent, which do not abruptly drift from previous topics, and informative,\nwhich do not suffer from undesired repetitions. In this paper, we propose\nLook-back, an improved decoding algorithm that leverages the Kullback-Leibler\ndivergence to track the distribution distance between current and historical\ndecoding steps. Thus Look-back can automatically predict potential repetitive\nphrase and topic drift, and remove tokens that may cause the failure modes,\nrestricting the next token probability distribution within a plausible distance\nto the history. We perform decoding experiments on document continuation and\nstory generation, and demonstrate that Look-back is able to generate more\nfluent and coherent text, outperforming other strong decoding methods\nsignificantly in both automatic and human evaluations.", "published": "2023-05-22 20:42:37", "link": "http://arxiv.org/abs/2305.13477v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Readability Assessment for Closely Related Languages", "abstract": "In recent years, the main focus of research on automatic readability\nassessment (ARA) has shifted towards using expensive deep learning-based\nmethods with the primary goal of increasing models' accuracy. This, however, is\nrarely applicable for low-resource languages where traditional handcrafted\nfeatures are still widely used due to the lack of existing NLP tools to extract\ndeeper linguistic representations. In this work, we take a step back from the\ntechnical component and focus on how linguistic aspects such as mutual\nintelligibility or degree of language relatedness can improve ARA in a\nlow-resource setting. We collect short stories written in three languages in\nthe Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment\nmodels and explore the interaction of data and features in various\ncross-lingual setups. Our results show that the inclusion of CrossNGO, a novel\nspecialized feature exploiting n-gram overlap applied to languages with high\nmutual intelligibility, significantly improves the performance of ARA models\ncompared to the use of off-the-shelf large multilingual language models alone.\nConsequently, when both linguistic representations are combined, we achieve\nstate-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA\nin Bikol.", "published": "2023-05-22 20:42:53", "link": "http://arxiv.org/abs/2305.13478v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Easily Updated General Purpose Text Representations with\n  Adaptable Task-Specific Prefixes", "abstract": "Many real-world applications require making multiple predictions from the\nsame text. Fine-tuning a large pre-trained language model for each downstream\ntask causes computational burdens in the inference time due to several times of\nforward passes. To amortize the computational cost, freezing the language model\nand building lightweight models for downstream tasks based on fixed text\nrepresentations are common solutions. Accordingly, how to learn fixed but\ngeneral text representations that can generalize well to unseen downstream\ntasks becomes a challenge. Previous works have shown that the generalizability\nof representations can be improved by fine-tuning the pre-trained language\nmodel with some source tasks in a multi-tasking way. In this work, we propose a\nprefix-based method to learn the fixed text representations with source tasks.\nWe learn a task-specific prefix for each source task independently and combine\nthem to get the final representations. Our experimental results show that\nprefix-based training performs better than multi-tasking training and can\nupdate the text representations at a smaller computational cost than\nmulti-tasking training.", "published": "2023-05-22 21:31:03", "link": "http://arxiv.org/abs/2305.13499v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CEO: Corpus-based Open-Domain Event Ontology Induction", "abstract": "Existing event-centric NLP models often only apply to the pre-defined\nontology, which significantly restricts their generalization capabilities. This\npaper presents CEO, a novel Corpus-based Event Ontology induction model to\nrelax the restriction imposed by pre-defined event ontologies. Without direct\nsupervision, CEO leverages distant supervision from available summary datasets\nto detect corpus-wise salient events and exploits external event knowledge to\nforce events within a short distance to have close embeddings. Experiments on\nthree popular event datasets show that the schema induced by CEO has better\ncoverage and higher accuracy than previous methods. Moreover, CEO is the first\nevent ontology induction model that can induce a hierarchical event ontology\nwith meaningful names on eleven open-domain corpora, making the induced schema\nmore trustworthy and easier to be further curated.", "published": "2023-05-22 22:26:47", "link": "http://arxiv.org/abs/2305.13521v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Study of Generative Large Language Model for Medical Research and\n  Healthcare", "abstract": "There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.", "published": "2023-05-22 22:37:24", "link": "http://arxiv.org/abs/2305.13523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning the Norwegian UD Treebank with Entity and Coreference\n  Information", "abstract": "This paper presents a merged collection of entity and coreference annotated\ndata grounded in the Universal Dependencies (UD) treebanks for the two written\nforms of Norwegian: Bokm{\\aa}l and Nynorsk. The aligned and converted corpora\nare the Norwegian Named Entities (NorNE) and Norwegian Anaphora Resolution\nCorpus (NARC). While NorNE is aligned with an older version of the treebank,\nNARC is misaligned and requires extensive transformation from the original\nannotations to the UD structure and CoNLL-U format. We here demonstrate the\nconversion and alignment processes, along with an analysis of discovered issues\nand errors in the data - some of which include data split overlaps in the\noriginal treebank. These procedures and the developed system may prove helpful\nfor future corpus alignment and coreference annotation endeavors. The merged\ncorpora comprise the first Norwegian UD treebank enriched with named entities\nand coreference information.", "published": "2023-05-22 22:44:53", "link": "http://arxiv.org/abs/2305.13527v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Transfer-Free Data-Efficient Multilingual Slot Labeling", "abstract": "Slot labeling (SL) is a core component of task-oriented dialogue (ToD)\nsystems, where slots and corresponding values are usually language-, task- and\ndomain-specific. Therefore, extending the system to any new\nlanguage-domain-task configuration requires (re)running an expensive and\nresource-intensive data annotation process. To mitigate the inherent data\nscarcity issue, current research on multilingual ToD assumes that sufficient\nEnglish-language annotated data are always available for particular tasks and\ndomains, and thus operates in a standard cross-lingual transfer setup. In this\nwork, we depart from this often unrealistic assumption. We examine challenging\nscenarios where such transfer-enabling English annotated data cannot be\nguaranteed, and focus on bootstrapping multilingual data-efficient slot\nlabelers in transfer-free scenarios directly in the target languages without\nany English-ready data. We propose a two-stage slot labeling approach (termed\nTWOSL) which transforms standard multilingual sentence encoders into effective\nslot labelers. In Stage 1, relying on SL-adapted contrastive learning with only\na handful of SL-annotated examples, we turn sentence encoders into\ntask-specific span encoders. In Stage 2, we recast SL from a token\nclassification into a simpler, less data-intensive span classification task.\nOur results on two standard multilingual TOD datasets and across diverse\nlanguages confirm the effectiveness and robustness of TWOSL. It is especially\neffective for the most challenging transfer-free few-shot setups, paving the\nway for quick and data-efficient bootstrapping of multilingual slot labelers\nfor ToD.", "published": "2023-05-22 22:47:32", "link": "http://arxiv.org/abs/2305.13528v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open-world Semi-supervised Generalized Relation Discovery Aligned in a\n  Real-world Setting", "abstract": "Open-world Relation Extraction (OpenRE) has recently garnered significant\nattention. However, existing approaches tend to oversimplify the problem by\nassuming that all unlabeled texts belong to novel classes, thereby limiting the\npracticality of these methods. We argue that the OpenRE setting should be more\naligned with the characteristics of real-world data. Specifically, we propose\ntwo key improvements: (a) unlabeled data should encompass known and novel\nclasses, including hard-negative instances; and (b) the set of novel classes\nshould represent long-tail relation types. Furthermore, we observe that popular\nrelations such as titles and locations can often be implicitly inferred through\nspecific patterns, while long-tail relations tend to be explicitly expressed in\nsentences. Motivated by these insights, we present a novel method called KNoRD\n(Known and Novel Relation Discovery), which effectively classifies explicitly\nand implicitly expressed relations from known and novel classes within\nunlabeled data. Experimental evaluations on several Open-world RE benchmarks\ndemonstrate that KNoRD consistently outperforms other existing methods,\nachieving significant performance gains.", "published": "2023-05-22 23:12:57", "link": "http://arxiv.org/abs/2305.13533v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "How Language Model Hallucinations Can Snowball", "abstract": "A major risk of using language models in practical applications is their\ntendency to hallucinate incorrect statements. Hallucinations are often\nattributed to knowledge gaps in LMs, but we hypothesize that in some cases,\nwhen justifying previously generated hallucinations, LMs output false claims\nthat they can separately recognize as incorrect. We construct three\nquestion-answering datasets where ChatGPT and GPT-4 often state an incorrect\nanswer and offer an explanation with at least one incorrect claim. Crucially,\nwe find that ChatGPT and GPT-4 can identify 67% and 87% of their own mistakes,\nrespectively. We refer to this phenomenon as hallucination snowballing: an LM\nover-commits to early mistakes, leading to more mistakes that it otherwise\nwould not make.", "published": "2023-05-22 23:14:28", "link": "http://arxiv.org/abs/2305.13534v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction", "abstract": "Generative methods greatly promote aspect-based sentiment analysis via\ngenerating a sequence of sentiment elements in a specified format. However,\nexisting studies usually predict sentiment elements in a fixed order, which\nignores the effect of the interdependence of the elements in a sentiment tuple\nand the diversity of language expression on the results. In this work, we\npropose Multi-view Prompting (MvP) that aggregates sentiment elements generated\nin different orders, leveraging the intuition of human-like problem-solving\nprocesses from different views. Specifically, MvP introduces element order\nprompts to guide the language model to generate multiple sentiment tuples, each\nwith a different element order, and then selects the most reasonable tuples by\nvoting. MvP can naturally model multi-view and multi-task as permutations and\ncombinations of elements, respectively, outperforming previous task-specific\ndesigned methods on multiple ABSA tasks with a single model. Extensive\nexperiments show that MvP significantly advances the state-of-the-art\nperformance on 10 datasets of 4 benchmark tasks, and performs quite effectively\nin low-resource settings. Detailed evaluation verified the effectiveness,\nflexibility, and cross-task transferability of MvP.", "published": "2023-05-22 01:32:50", "link": "http://arxiv.org/abs/2305.12627v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beneath Surface Similarity: Large Language Models Make Reasonable\n  Scientific Analogies after Structure Abduction", "abstract": "The vital role of analogical reasoning in human cognition allows us to grasp\nnovel concepts by linking them with familiar ones through shared relational\nstructures. Despite the attention previous research has given to word\nanalogies, this work suggests that Large Language Models (LLMs) often overlook\nthe structures that underpin these analogies, raising questions about the\nefficacy of word analogies as a measure of analogical reasoning skills akin to\nhuman cognition. In response to this, our paper introduces a task of analogical\nstructure abduction, grounded in cognitive psychology, designed to abduce\nstructures that form an analogy between two systems. In support of this task,\nwe establish a benchmark called SCAR, containing 400 scientific analogies from\n13 distinct fields, tailored for evaluating analogical reasoning with structure\nabduction. The empirical evidence underlines the continued challenges faced by\nLLMs, including ChatGPT and GPT-4, in mastering this task, signifying the need\nfor future exploration to enhance their abilities.", "published": "2023-05-22 03:04:06", "link": "http://arxiv.org/abs/2305.12660v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta\n  Learning", "abstract": "With emerging topics (e.g., COVID-19) on social media as a source for the\nspreading misinformation, overcoming the distributional shifts between the\noriginal training domain (i.e., source domain) and such target domains remains\na non-trivial task for misinformation detection. This presents an elusive\nchallenge for early-stage misinformation detection, where a good amount of data\nand annotations from the target domain is not available for training. To\naddress the data scarcity issue, we propose MetaAdapt, a meta learning based\napproach for domain adaptive few-shot misinformation detection. MetaAdapt\nleverages limited target examples to provide feedback and guide the knowledge\ntransfer from the source to the target domain (i.e., learn to adapt). In\nparticular, we train the initial model with multiple source tasks and compute\ntheir similarity scores to the meta task. Based on the similarity scores, we\nrescale the meta gradients to adaptively learn from the source tasks. As such,\nMetaAdapt can learn how to adapt the misinformation detection model and exploit\nthe source data for improved performance in the target domain. To demonstrate\nthe efficiency and effectiveness of our method, we perform extensive\nexperiments to compare MetaAdapt with state-of-the-art baselines and large\nlanguage models (LLMs) such as LLaMA, where MetaAdapt achieves better\nperformance in domain adaptive few-shot misinformation detection with\nsubstantially reduced parameters on real-world datasets.", "published": "2023-05-22 04:00:38", "link": "http://arxiv.org/abs/2305.12692v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Spell Checker and Correction for Under-represented Spoken\n  Languages: Case Study on Wolof", "abstract": "This paper presents a spell checker and correction tool specifically designed\nfor Wolof, an under-represented spoken language in Africa. The proposed spell\nchecker leverages a combination of a trie data structure, dynamic programming,\nand the weighted Levenshtein distance to generate suggestions for misspelled\nwords. We created novel linguistic resources for Wolof, such as a lexicon and a\ncorpus of misspelled words, using a semi-automatic approach that combines\nmanual and automatic annotation methods. Despite the limited data available for\nthe Wolof language, the spell checker's performance showed a predictive\naccuracy of 98.31% and a suggestion accuracy of 93.33%. Our primary focus\nremains the revitalization and preservation of Wolof as an Indigenous and\nspoken language in Africa, providing our efforts to develop novel linguistic\nresources. This work represents a valuable contribution to the growth of\ncomputational tools and resources for the Wolof language and provides a strong\nfoundation for future studies in the automatic spell checking and correction\nfield.", "published": "2023-05-22 04:03:20", "link": "http://arxiv.org/abs/2305.12694v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TADA: Efficient Task-Agnostic Domain Adaptation for Transformers", "abstract": "Intermediate training of pre-trained transformer-based language models on\ndomain-specific data leads to substantial gains for downstream tasks. To\nincrease efficiency and prevent catastrophic forgetting alleviated from full\ndomain-adaptive pre-training, approaches such as adapters have been developed.\nHowever, these require additional parameters for each layer, and are criticized\nfor their limited expressiveness. In this work, we introduce TADA, a novel\ntask-agnostic domain adaptation method which is modular, parameter-efficient,\nand thus, data-efficient. Within TADA, we retrain the embeddings to learn\ndomain-aware input representations and tokenizers for the transformer encoder,\nwhile freezing all other parameters of the model. Then, task-specific\nfine-tuning is performed. We further conduct experiments with meta-embeddings\nand newly introduced meta-tokenizers, resulting in one model per task in\nmulti-domain use cases. Our broad evaluation in 4 downstream tasks for 14\ndomains across single- and multi-domain setups and high- and low-resource\nscenarios reveals that TADA is an effective and efficient alternative to full\ndomain-adaptive pre-training and adapters for domain adaptation, while not\nintroducing additional parameters or complex training steps.", "published": "2023-05-22 04:53:59", "link": "http://arxiv.org/abs/2305.12717v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "llm-japanese-dataset v0: Construction of Japanese Chat Dataset for Large\n  Language Models and its Methodology", "abstract": "This study constructed a Japanese chat dataset for tuning large language\nmodels (LLMs), which consist of about 8.4 million records. Recently, LLMs have\nbeen developed and gaining popularity. However, high-performing LLMs are\nusually mainly for English. There are two ways to support languages other than\nEnglish by those LLMs: constructing LLMs from scratch or tuning existing\nmodels. However, in both ways, datasets are necessary parts. In this study, we\nfocused on supporting Japanese in those LLMs and making a dataset for training\nor tuning LLMs in Japanese. The dataset we constructed consisted of various\ntasks, such as translation and knowledge tasks. In our experiment, we tuned an\nexisting LLM using our dataset and evaluated the performance qualitatively. The\nresults suggest that our dataset is possibly beneficial for LLMs. However, we\nalso revealed some difficulties in constructing LLMs in languages other than\nEnglish.", "published": "2023-05-22 04:59:33", "link": "http://arxiv.org/abs/2305.12720v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Small Medical Learners with Privacy-preserving Contextual\n  Prompting", "abstract": "Large language models (LLMs) demonstrate remarkable medical expertise, but\ndata privacy concerns impede their direct use in healthcare environments.\nAlthough offering improved data privacy protection, domain-specific small\nlanguage models (SLMs) often underperform LLMs, emphasizing the need for\nmethods that reduce this performance gap while alleviating privacy concerns. In\nthis paper, we present a simple yet effective method that harnesses LLMs'\nmedical proficiency to boost SLM performance in medical tasks under\nprivacy-restricted scenarios. Specifically, we mitigate patient privacy issues\nby extracting keywords from medical data and prompting the LLM to generate a\nmedical knowledge-intensive context by simulating clinicians' thought\nprocesses. This context serves as additional input for SLMs, augmenting their\ndecision-making capabilities. Our method significantly enhances performance in\nboth few-shot and full training settings across three medical\nknowledge-intensive tasks, achieving up to a 22.57% increase in absolute\naccuracy compared to SLM fine-tuning without context, and sets new\nstate-of-the-art results in two medical tasks within privacy-restricted\nscenarios. Further out-of-domain testing and experiments in two general domain\ndatasets showcase its generalizability and broad applicability. Our code can be\nfound at https://github.com/XZhang97666/PrivacyBoost-SLM.", "published": "2023-05-22 05:14:38", "link": "http://arxiv.org/abs/2305.12723v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Best of Both Worlds: Combining Human and Machine Translations for\n  Multilingual Semantic Parsing with Active Learning", "abstract": "Multilingual semantic parsing aims to leverage the knowledge from the\nhigh-resource languages to improve low-resource semantic parsing, yet commonly\nsuffers from the data imbalance problem. Prior works propose to utilize the\ntranslations by either humans or machines to alleviate such issues. However,\nhuman translations are expensive, while machine translations are cheap but\nprone to error and bias. In this work, we propose an active learning approach\nthat exploits the strengths of both human and machine translations by\niteratively adding small batches of human translations into the\nmachine-translated training set. Besides, we propose novel aggregated\nacquisition criteria that help our active learning method select utterances to\nbe manually translated. Our experiments demonstrate that an ideal utterance\nselection can significantly reduce the error and bias in the translated data,\nresulting in higher parser accuracies than the parsers merely trained on the\nmachine-translated data.", "published": "2023-05-22 05:57:47", "link": "http://arxiv.org/abs/2305.12737v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fact-Checking Complex Claims with Program-Guided Reasoning", "abstract": "Fact-checking real-world claims often requires collecting multiple pieces of\nevidence and applying complex multi-step reasoning. In this paper, we present\nProgram-Guided Fact-Checking (ProgramFC), a novel fact-checking model that\ndecomposes complex claims into simpler sub-tasks that can be solved using a\nshared library of specialized functions. We first leverage the in-context\nlearning ability of large language models to generate reasoning programs to\nguide the verification process. Afterward, we execute the program by delegating\neach sub-task to the corresponding sub-task handler. This process makes our\nmodel both explanatory and data-efficient, providing clear explanations of its\nreasoning process and requiring minimal training data. We evaluate ProgramFC on\ntwo challenging fact-checking datasets and show that it outperforms seven\nfact-checking baselines across different settings of evidence availability,\nwith explicit output programs that benefit human debugging. Our codes and data\nare publicly available at https://github.com/mbzuai-nlp/ProgramFC.", "published": "2023-05-22 06:11:15", "link": "http://arxiv.org/abs/2305.12744v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Rank Utterances for Query-Focused Meeting Summarization", "abstract": "Query-focused meeting summarization(QFMS) aims to generate a specific summary\nfor the given query according to the meeting transcripts. Due to the conflict\nbetween long meetings and limited input size, previous works mainly adopt\nextract-then-summarize methods, which use extractors to simulate binary labels\nor ROUGE scores to extract utterances related to the query and then generate a\nsummary. However, the previous approach fails to fully use the comparison\nbetween utterances. To the extractor, comparison orders are more important than\nspecific scores. In this paper, we propose a Ranker-Generator framework. It\nlearns to rank the utterances by comparing them in pairs and learning from the\nglobal orders, then uses top utterances as the generator's input. We show that\nlearning to rank utterances helps to select utterances related to the query\neffectively, and the summarizer can benefit from it. Experimental results on\nQMSum show that the proposed model outperforms all existing multi-stage models\nwith fewer parameters.", "published": "2023-05-22 06:25:09", "link": "http://arxiv.org/abs/2305.12753v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Cross-lingual Natural Language Inference by Soft Prompting\n  with Multilingual Verbalizer", "abstract": "Cross-lingual natural language inference is a fundamental problem in\ncross-lingual language understanding. Many recent works have used prompt\nlearning to address the lack of annotated parallel corpora in XNLI. However,\nthese methods adopt discrete prompting by simply translating the templates to\nthe target language and need external expert knowledge to design the templates.\nBesides, discrete prompts of human-designed template words are not trainable\nvectors and can not be migrated to target languages in the inference stage\nflexibly. In this paper, we propose a novel Soft prompt learning framework with\nthe Multilingual Verbalizer (SoftMV) for XNLI. SoftMV first constructs\ncloze-style question with soft prompts for the input sample. Then we leverage\nbilingual dictionaries to generate an augmented multilingual question for the\noriginal question. SoftMV adopts a multilingual verbalizer to align the\nrepresentations of original and augmented multilingual questions into the same\nsemantic space with consistency regularization. Experimental results on XNLI\ndemonstrate that SoftMV can achieve state-of-the-art performance and\nsignificantly outperform the previous methods under the few-shot and full-shot\ncross-lingual transfer settings.", "published": "2023-05-22 06:31:29", "link": "http://arxiv.org/abs/2305.12761v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Robust Personalized Dialogue Generation via Order-Insensitive\n  Representation Regularization", "abstract": "Generating persona consistent dialogue response is important for developing\nan intelligent conversational agent. Recent works typically fine-tune\nlarge-scale pre-trained models on this task by concatenating persona texts and\ndialogue history as a single input sequence to generate the target response.\nWhile simple and effective, our analysis shows that this popular practice is\nseriously affected by order sensitivity where different input orders of persona\nsentences significantly impact the quality and consistency of generated\nresponse, resulting in severe performance fluctuations (i.e., 29.4% on GPT2 and\n83.2% on BART). To mitigate the order sensitivity problem, we propose a\nmodel-agnostic framework, ORder Insensitive Generation (ORIG), which enables\ndialogue models to learn robust representation under different persona orders\nand improve the consistency of response generation. Experiments on the\nPersona-Chat dataset justify the effectiveness and superiority of our method\nwith two dominant pre-trained models (GPT2 and BART).", "published": "2023-05-22 07:24:29", "link": "http://arxiv.org/abs/2305.12782v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Semantic Structure Enhanced Event Causality Identification", "abstract": "Event Causality Identification (ECI) aims to identify causal relations\nbetween events in unstructured texts. This is a very challenging task, because\ncausal relations are usually expressed by implicit associations between events.\nExisting methods usually capture such associations by directly modeling the\ntexts with pre-trained language models, which underestimate two kinds of\nsemantic structures vital to the ECI task, namely, event-centric structure and\nevent-associated structure. The former includes important semantic elements\nrelated to the events to describe them more precisely, while the latter\ncontains semantic paths between two events to provide possible supports for\nECI. In this paper, we study the implicit associations between events by\nmodeling the above explicit semantic structures, and propose a Semantic\nStructure Integration model (SemSIn). It utilizes a GNN-based event aggregator\nto integrate the event-centric structure information, and employs an LSTM-based\npath aggregator to capture the event-associated structure information between\ntwo events. Experimental results on three widely used datasets show that SemSIn\nachieves significant improvements over baseline methods.", "published": "2023-05-22 07:42:35", "link": "http://arxiv.org/abs/2305.12792v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple\n  Clustering Based Strategy", "abstract": "Ultra-fine entity typing (UFET) is the task of inferring the semantic types,\nfrom a large set of fine-grained candidates, that apply to a given entity\nmention. This task is especially challenging because we only have a small\nnumber of training examples for many of the types, even with distant\nsupervision strategies. State-of-the-art models, therefore, have to rely on\nprior knowledge about the type labels in some way. In this paper, we show that\nthe performance of existing methods can be improved using a simple technique:\nwe use pre-trained label embeddings to cluster the labels into semantic domains\nand then treat these domains as additional types. We show that this strategy\nconsistently leads to improved results, as long as high-quality label\nembeddings are used. We furthermore use the label clusters as part of a simple\npost-processing technique, which results in further performance gains. Both\nstrategies treat the UFET model as a black box and can thus straightforwardly\nbe used to improve a wide range of existing models.", "published": "2023-05-22 08:00:56", "link": "http://arxiv.org/abs/2305.12802v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Crosslingual Transfer Learning for Low-Resource Languages Based on\n  Multilingual Colexification Graphs", "abstract": "In comparative linguistics, colexification refers to the phenomenon of a\nlexical form conveying two or more distinct meanings. Existing work on\ncolexification patterns relies on annotated word lists, limiting scalability\nand usefulness in NLP. In contrast, we identify colexification patterns of more\nthan 2,000 concepts across 1,335 languages directly from an unannotated\nparallel corpus. We then propose simple and effective methods to build\nmultilingual graphs from the colexification patterns: ColexNet and ColexNet+.\nColexNet's nodes are concepts and its edges are colexifications. In ColexNet+,\nconcept nodes are additionally linked through intermediate nodes, each\nrepresenting an ngram in one of 1,334 languages. We use ColexNet+ to train\n$\\overrightarrow{\\mbox{ColexNet+}}$, high-quality multilingual embeddings that\nare well-suited for transfer learning. In our experiments, we first show that\nColexNet achieves high recall on CLICS, a dataset of crosslingual\ncolexifications. We then evaluate $\\overrightarrow{\\mbox{ColexNet+}}$ on\nroundtrip translation, sentence retrieval and sentence classification and show\nthat our embeddings surpass several transfer learning baselines. This\ndemonstrates the benefits of using colexification as a source of information in\nmultilingual NLP.", "published": "2023-05-22 08:20:23", "link": "http://arxiv.org/abs/2305.12818v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MultiTabQA: Generating Tabular Answers for Multi-Table Question\n  Answering", "abstract": "Recent advances in tabular question answering (QA) with large language models\nare constrained in their coverage and only answer questions over a single\ntable. However, real-world queries are complex in nature, often over multiple\ntables in a relational database or web page. Single table questions do not\ninvolve common table operations such as set operations, Cartesian products\n(joins), or nested queries. Furthermore, multi-table operations often result in\na tabular output, which necessitates table generation capabilities of tabular\nQA models. To fill this gap, we propose a new task of answering questions over\nmultiple tables. Our model, MultiTabQA, not only answers questions over\nmultiple tables, but also generalizes to generate tabular answers. To enable\neffective training, we build a pre-training dataset comprising of 132,645 SQL\nqueries and tabular answers. Further, we evaluate the generated tables by\nintroducing table-specific metrics of varying strictness assessing various\nlevels of granularity of the table structure. MultiTabQA outperforms\nstate-of-the-art single table QA models adapted to a multi-table QA setting by\nfinetuning on three datasets: Spider, Atis and GeoQuery.", "published": "2023-05-22 08:25:15", "link": "http://arxiv.org/abs/2305.12820v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open-Domain Event Graph Induction for Mitigating Framing Bias", "abstract": "Researchers have proposed various information extraction (IE) techniques to\nconvert news articles into structured knowledge for news understanding.\nHowever, none of the existing methods have explicitly addressed the issue of\nframing bias that is inherent in news articles. We argue that studying and\nidentifying framing bias is a crucial step towards trustworthy event\nunderstanding. We propose a novel task, neutral event graph induction, to\naddress this problem. An event graph is a network of events and their temporal\nrelations. Our task aims to induce such structural knowledge with minimal\nframing bias in an open domain. We propose a three-step framework to induce a\nneutral event graph from multiple input sources. The process starts by inducing\nan event graph from each input source, then merging them into one merged event\ngraph, and lastly using a Graph Convolutional Network to remove event nodes\nwith biased connotations. We demonstrate the effectiveness of our framework\nthrough the use of graph prediction metrics and bias-focused metrics.", "published": "2023-05-22 08:57:42", "link": "http://arxiv.org/abs/2305.12835v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Coherence of Extractive Summarization with Multitask Learning", "abstract": "This study proposes a multitask learning architecture for extractive\nsummarization with coherence boosting. The architecture contains an extractive\nsummarizer and coherent discriminator module. The coherent discriminator is\ntrained online on the sentence vectors of the augmented textual input, thus\nimproving its general ability of judging whether the input sentences are\ncoherent. Meanwhile, we maximize the coherent scores from the coherent\ndiscriminator by updating the parameters of the summarizer. To make the\nextractive sentences trainable in a differentiable manner, we introduce two\nstrategies, including pre-trained converting model (model-based) and converting\nmatrix (MAT-based) that merge sentence representations. Experiments show that\nour proposed method significantly improves the proportion of consecutive\nsentences in the extracted summaries based on their positions in the original\narticle (i.e., automatic sentence-level coherence metric), while the goodness\nin terms of other automatic metrics (i.e., Rouge scores and BertScores) are\npreserved. Human evaluation also evidences the improvement of coherence and\nconsistency of the extracted summaries given by our method.", "published": "2023-05-22 09:20:58", "link": "http://arxiv.org/abs/2305.12851v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gloss-Free End-to-End Sign Language Translation", "abstract": "In this paper, we tackle the problem of sign language translation (SLT)\nwithout gloss annotations. Although intermediate representation like gloss has\nbeen proven effective, gloss annotations are hard to acquire, especially in\nlarge quantities. This limits the domain coverage of translation datasets, thus\nhandicapping real-world applications. To mitigate this problem, we design the\nGloss-Free End-to-end sign language translation framework (GloFE). Our method\nimproves the performance of SLT in the gloss-free setting by exploiting the\nshared underlying semantics of signs and the corresponding spoken translation.\nCommon concepts are extracted from the text and used as a weak form of\nintermediate representation. The global embedding of these concepts is used as\na query for cross-attention to find the corresponding information within the\nlearned visual features. In a contrastive manner, we encourage the similarity\nof query results between samples containing such concepts and decrease those\nthat do not. We obtained state-of-the-art results on large-scale datasets,\nincluding OpenASL and How2Sign. The code and model will be available at\nhttps://github.com/HenryLittle/GloFE.", "published": "2023-05-22 09:57:43", "link": "http://arxiv.org/abs/2305.12876v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Yes, this Way! Learning to Ground Referring Expressions into Actions\n  with Intra-episodic Feedback from Supportive Teachers", "abstract": "The ability to pick up on language signals in an ongoing interaction is\ncrucial for future machine learning models to collaborate and interact with\nhumans naturally. In this paper, we present an initial study that evaluates\nintra-episodic feedback given in a collaborative setting. We use a referential\nlanguage game as a controllable example of a task-oriented collaborative joint\nactivity. A teacher utters a referring expression generated by a well-known\nsymbolic algorithm (the \"Incremental Algorithm\") as an initial instruction and\nthen monitors the follower's actions to possibly intervene with intra-episodic\nfeedback (which does not explicitly have to be requested). We frame this task\nas a reinforcement learning problem with sparse rewards and learn a follower\npolicy for a heuristic teacher. Our results show that intra-episodic feedback\nallows the follower to generalize on aspects of scene complexity and performs\nbetter than providing only the initial statement.", "published": "2023-05-22 10:01:15", "link": "http://arxiv.org/abs/2305.12880v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Improving Metrics for Speech Translation", "abstract": "We introduce Parallel Paraphrasing ($\\text{Para}_\\text{both}$), an\naugmentation method for translation metrics making use of automatic\nparaphrasing of both the reference and hypothesis. This method counteracts the\ntypically misleading results of speech translation metrics such as WER, CER,\nand BLEU if only a single reference is available. We introduce two new datasets\nexplicitly created to measure the quality of metrics intended to be applied to\nSwiss German speech-to-text systems. Based on these datasets, we show that we\nare able to significantly improve the correlation with human quality perception\nif our method is applied to commonly used metrics.", "published": "2023-05-22 11:01:38", "link": "http://arxiv.org/abs/2305.12918v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Correspondence between Compositionality and Imitation in Emergent\n  Neural Communication", "abstract": "Compositionality is a hallmark of human language that not only enables\nlinguistic generalization, but also potentially facilitates acquisition. When\nsimulating language emergence with neural networks, compositionality has been\nshown to improve communication performance; however, its impact on imitation\nlearning has yet to be investigated. Our work explores the link between\ncompositionality and imitation in a Lewis game played by deep neural agents.\nOur contributions are twofold: first, we show that the learning algorithm used\nto imitate is crucial: supervised learning tends to produce more average\nlanguages, while reinforcement learning introduces a selection pressure toward\nmore compositional languages. Second, our study reveals that compositional\nlanguages are easier to imitate, which may induce the pressure toward\ncompositional languages in RL imitation settings.", "published": "2023-05-22 11:41:29", "link": "http://arxiv.org/abs/2305.12941v1", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Cross-functional Analysis of Generalisation in Behavioural Learning", "abstract": "In behavioural testing, system functionalities underrepresented in the\nstandard evaluation setting (with a held-out test set) are validated through\ncontrolled input-output pairs. Optimising performance on the behavioural tests\nduring training (behavioural learning) would improve coverage of phenomena not\nsufficiently represented in the i.i.d. data and could lead to seemingly more\nrobust models. However, there is the risk that the model narrowly captures\nspurious correlations from the behavioural test suite, leading to\noverestimation and misrepresentation of model performance -- one of the\noriginal pitfalls of traditional evaluation. In this work, we introduce BeLUGA,\nan analysis method for evaluating behavioural learning considering\ngeneralisation across dimensions of different granularity levels. We optimise\nbehaviour-specific loss functions and evaluate models on several partitions of\nthe behavioural test suite controlled to leave out specific phenomena. An\naggregate score measures generalisation to unseen functionalities (or\noverfitting). We use BeLUGA to examine three representative NLP tasks\n(sentiment analysis, paraphrase identification and reading comprehension) and\ncompare the impact of a diverse set of regularisation and domain generalisation\nmethods on generalisation performance.", "published": "2023-05-22 11:54:19", "link": "http://arxiv.org/abs/2305.12951v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GPT-SW3: An Autoregressive Language Model for the Nordic Languages", "abstract": "This paper details the process of developing the first native large\ngenerative language model for the Nordic languages, GPT-SW3. We cover all parts\nof the development process, from data collection and processing, training\nconfiguration and instruction finetuning, to evaluation and considerations for\nrelease strategies. We hope that this paper can serve as a guide and reference\nfor other researchers that undertake the development of large generative models\nfor smaller languages.", "published": "2023-05-22 12:47:48", "link": "http://arxiv.org/abs/2305.12987v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SpokenWOZ: A Large-Scale Speech-Text Benchmark for Spoken Task-Oriented\n  Dialogue Agents", "abstract": "Task-oriented dialogue (TOD) models have made significant progress in recent\nyears. However, previous studies primarily focus on datasets written by\nannotators, which has resulted in a gap between academic research and\nreal-world spoken conversation scenarios. While several small-scale spoken TOD\ndatasets are proposed to address robustness issues such as ASR errors, they\nignore the unique challenges in spoken conversation. To tackle the limitations,\nwe introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD,\ncontaining 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from\nhuman-to-human spoken conversations. SpokenWOZ further incorporates common\nspoken characteristics such as word-by-word processing and reasoning in spoken\nlanguage. Based on these characteristics, we present cross-turn slot and\nreasoning slot detection as new challenges. We conduct experiments on various\nbaselines, including text-modal models, newly proposed dual-modal models, and\nLLMs, e.g., ChatGPT. The results show that the current models still have\nsubstantial room for improvement in spoken conversation, where the most\nadvanced dialogue state tracker only achieves 25.65% in joint goal accuracy and\nthe SOTA end-to-end model only correctly completes the user request in 52.1% of\ndialogues. The dataset, code, and leaderboard are available:\nhttps://spokenwoz.github.io/.", "published": "2023-05-22 13:47:51", "link": "http://arxiv.org/abs/2305.13040v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RWKV: Reinventing RNNs for the Transformer Era", "abstract": "Transformers have revolutionized almost all natural language processing (NLP)\ntasks but suffer from memory and computational complexity that scales\nquadratically with sequence length. In contrast, recurrent neural networks\n(RNNs) exhibit linear scaling in memory and computational requirements but\nstruggle to match the same performance as Transformers due to limitations in\nparallelization and scalability. We propose a novel model architecture,\nReceptance Weighted Key Value (RWKV), that combines the efficient\nparallelizable training of transformers with the efficient inference of RNNs.\n  Our approach leverages a linear attention mechanism and allows us to\nformulate the model as either a Transformer or an RNN, thus parallelizing\ncomputations during training and maintains constant computational and memory\ncomplexity during inference. We scale our models as large as 14 billion\nparameters, by far the largest dense RNN ever trained, and find RWKV performs\non par with similarly sized Transformers, suggesting future work can leverage\nthis architecture to create more efficient models. This work presents a\nsignificant step towards reconciling trade-offs between computational\nefficiency and model performance in sequence processing tasks.", "published": "2023-05-22 13:57:41", "link": "http://arxiv.org/abs/2305.13048v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Biomedical Named Entity Recognition via Dictionary-based Synonym\n  Generalization", "abstract": "Biomedical named entity recognition is one of the core tasks in biomedical\nnatural language processing (BioNLP). To tackle this task, numerous\nsupervised/distantly supervised approaches have been proposed. Despite their\nremarkable success, these approaches inescapably demand laborious human effort.\nTo alleviate the need of human effort, dictionary-based approaches have been\nproposed to extract named entities simply based on a given dictionary. However,\none downside of existing dictionary-based approaches is that they are\nchallenged to identify concept synonyms that are not listed in the given\ndictionary, which we refer as the synonym generalization problem. In this\nstudy, we propose a novel Synonym Generalization (SynGen) framework that\nrecognizes the biomedical concepts contained in the input text using span-based\npredictions. In particular, SynGen introduces two regularization terms, namely,\n(1) a synonym distance regularizer; and (2) a noise perturbation regularizer,\nto minimize the synonym generalization error. To demonstrate the effectiveness\nof our approach, we provide a theoretical analysis of the bound of synonym\ngeneralization error. We extensively evaluate our approach on a wide range of\nbenchmarks and the results verify that SynGen outperforms previous\ndictionary-based models by notable margins. Lastly, we provide a detailed\nanalysis to further reveal the merits and inner-workings of our approach.", "published": "2023-05-22 14:36:32", "link": "http://arxiv.org/abs/2305.13066v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Distilling Robustness into Natural Language Inference Models with\n  Domain-Targeted Augmentation", "abstract": "Knowledge distillation optimises a smaller student model to behave similarly\nto a larger teacher model, retaining some of the performance benefits. While\nthis method can improve results on in-distribution examples, it does not\nnecessarily generalise to out-of-distribution (OOD) settings. We investigate\ntwo complementary methods for improving the robustness of the resulting student\nmodels on OOD domains. The first approach augments the distillation with\ngenerated unlabelled examples that match the target distribution. The second\nmethod upsamples data points among the training set that are similar to the\ntarget distribution. When applied on the task of natural language inference\n(NLI), our experiments on MNLI show that distillation with these modifications\noutperforms previous robustness solutions. We also find that these methods\nimprove performance on OOD domains even beyond the target domain.", "published": "2023-05-22 14:37:05", "link": "http://arxiv.org/abs/2305.13067v3", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Rethinking the Evaluation for Conversational Recommendation in the Era\n  of Large Language Models", "abstract": "The recent success of large language models (LLMs) has shown great potential\nto develop more powerful conversational recommender systems (CRSs), which rely\non natural language conversations to satisfy user needs. In this paper, we\nembark on an investigation into the utilization of ChatGPT for conversational\nrecommendation, revealing the inadequacy of the existing evaluation protocol.\nIt might over-emphasize the matching with the ground-truth items or utterances\ngenerated by human annotators, while neglecting the interactive nature of being\na capable CRS. To overcome the limitation, we further propose an interactive\nEvaluation approach based on LLMs named iEvaLM that harnesses LLM-based user\nsimulators. Our evaluation approach can simulate various interaction scenarios\nbetween users and systems. Through the experiments on two publicly available\nCRS datasets, we demonstrate notable improvements compared to the prevailing\nevaluation protocol. Furthermore, we emphasize the evaluation of\nexplainability, and ChatGPT showcases persuasive explanation generation for its\nrecommendations. Our study contributes to a deeper comprehension of the\nuntapped potential of LLMs for CRSs and provides a more flexible and\neasy-to-use evaluation framework for future research endeavors. The codes and\ndata are publicly available at https://github.com/RUCAIBox/iEvaLM-CRS.", "published": "2023-05-22 15:12:43", "link": "http://arxiv.org/abs/2305.13112v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Partial Annotation Learning for Biomedical Entity Recognition", "abstract": "Motivation: Named Entity Recognition (NER) is a key task to support\nbiomedical research. In Biomedical Named Entity Recognition (BioNER), obtaining\nhigh-quality expert annotated data is laborious and expensive, leading to the\ndevelopment of automatic approaches such as distant supervision. However,\nmanually and automatically generated data often suffer from the unlabeled\nentity problem, whereby many entity annotations are missing, degrading the\nperformance of full annotation NER models. Results: To address this problem, we\nsystematically study the effectiveness of partial annotation learning methods\nfor biomedical entity recognition over different simulated scenarios of missing\nentity annotations. Furthermore, we propose a TS-PubMedBERT-Partial-CRF partial\nannotation learning model. We harmonize 15 biomedical NER corpora encompassing\nfive entity types to serve as a gold standard and compare against two commonly\nused partial annotation learning models, BiLSTM-Partial-CRF and EER-PubMedBERT,\nand the state-of-the-art full annotation learning BioNER model PubMedBERT\ntagger. Results show that partial annotation learning-based methods can\neffectively learn from biomedical corpora with missing entity annotations. Our\nproposed model outperforms alternatives and, specifically, the PubMedBERT\ntagger by 38% in F1-score under high missing entity rates. The recall of entity\nmentions in our model is also competitive with the upper bound on the fully\nannotated dataset.", "published": "2023-05-22 15:18:38", "link": "http://arxiv.org/abs/2305.13120v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Pretrainer's Guide to Training Data: Measuring the Effects of Data\n  Age, Domain Coverage, Quality, & Toxicity", "abstract": "Pretraining is the preliminary and fundamental step in developing capable\nlanguage models (LM). Despite this, pretraining data design is critically\nunder-documented and often guided by empirically unsupported intuitions. To\naddress this, we pretrain 28 1.5B parameter decoder-only models, training on\ndata curated (1) at different times, (2) with varying toxicity and quality\nfilters, and (3) with different domain compositions. First, we quantify the\neffect of pretraining data age. A temporal shift between evaluation data and\npretraining data leads to performance degradation, which is not overcome by\nfinetuning. Second, we explore the effect of quality and toxicity filters,\nshowing a trade-off between performance on standard benchmarks and risk of\ntoxic generations. Our findings indicate there does not exist a\none-size-fits-all solution to filtering training data. We also find that the\neffects of different types of filtering are not predictable from text domain\ncharacteristics. Lastly, we empirically validate that the inclusion of\nheterogeneous data sources, like books and web, is broadly beneficial and\nwarrants greater prioritization. These findings constitute the largest set of\nexperiments to validate, quantify, and expose many undocumented intuitions\nabout text pretraining, which we hope will help support more informed\ndata-centric decisions in LM development.", "published": "2023-05-22 15:57:53", "link": "http://arxiv.org/abs/2305.13169v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Teaching Probabilistic Logical Reasoning to Transformers", "abstract": "In this paper, we evaluate the capability of transformer-based language\nmodels in making inferences over uncertain text that includes uncertain rules\nof reasoning. We cover both Pre-trained Language Models (PLMs) and generative\nLarge Language Models (LLMs). Our evaluation results show that both generations\nof language models struggle with reasoning over uncertain text. We propose a\nnovel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT),\nthat utilizes probabilistic logical rules as constraints in the fine-tuning\nphase without relying on these rules in the inference stage. To assess the\neffectiveness of PCT, we utilize the related corpora and, additionally, create\na new and more challenging benchmark that, unlike the previous ones, uses\ninstance-specific rules. Our study demonstrates that PCT improves the\ntransformer-based language model's intrinsic reasoning and makes their\nprobabilistic logical reasoning process more explicit and explainable.\nFurthermore, PCT equips these models to effectively handle novel situations,\nincluding higher reasoning depth, new domains, and complex probabilistic\nstructures.", "published": "2023-05-22 16:08:20", "link": "http://arxiv.org/abs/2305.13179v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim\n  Verification on Scientific Tables", "abstract": "Current scientific fact-checking benchmarks exhibit several shortcomings,\nsuch as biases arising from crowd-sourced claims and an over-reliance on\ntext-based evidence. We present SCITAB, a challenging evaluation dataset\nconsisting of 1.2K expert-verified scientific claims that 1) originate from\nauthentic scientific publications and 2) require compositional reasoning for\nverification. The claims are paired with evidence-containing scientific tables\nannotated with labels. Through extensive evaluations, we demonstrate that\nSCITAB poses a significant challenge to state-of-the-art models, including\ntable-based pretraining models and large language models. All models except\nGPT-4 achieved performance barely above random guessing. Popular prompting\ntechniques, such as Chain-of-Thought, do not achieve much performance gains on\nSCITAB. Our analysis uncovers several unique challenges posed by SCITAB,\nincluding table grounding, claim ambiguity, and compositional reasoning. Our\ncodes and data are publicly available at https://github.com/XinyuanLu00/SciTab.", "published": "2023-05-22 16:13:50", "link": "http://arxiv.org/abs/2305.13186v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Challenging Decoder helps in Masked Auto-Encoder Pre-training for Dense\n  Passage Retrieval", "abstract": "Recently, various studies have been directed towards exploring dense passage\nretrieval techniques employing pre-trained language models, among which the\nmasked auto-encoder (MAE) pre-training architecture has emerged as the most\npromising. The conventional MAE framework relies on leveraging the passage\nreconstruction of decoder to bolster the text representation ability of\nencoder, thereby enhancing the performance of resulting dense retrieval\nsystems. Within the context of building the representation ability of the\nencoder through passage reconstruction of decoder, it is reasonable to\npostulate that a ``more demanding'' decoder will necessitate a corresponding\nincrease in the encoder's ability. To this end, we propose a novel token\nimportance aware masking strategy based on pointwise mutual information to\nintensify the challenge of the decoder. Importantly, our approach can be\nimplemented in an unsupervised manner, without adding additional expenses to\nthe pre-training phase. Our experiments verify that the proposed method is both\neffective and robust on large-scale supervised passage retrieval datasets and\nout-of-domain zero-shot retrieval benchmarks.", "published": "2023-05-22 16:27:10", "link": "http://arxiv.org/abs/2305.13197v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly\n  Generating Predictions and Natural Language Explanations", "abstract": "Models that generate natural language explanations (NLEs) for their\npredictions have recently gained increasing interest. However, this approach\nusually demands large datasets of human-written NLEs for the ground-truth\nanswers at training time, which can be expensive and potentially infeasible for\nsome applications. When only a few NLEs are available (a few-shot setup),\nfine-tuning pre-trained language models (PLMs) in conjunction with prompt-based\nlearning has recently shown promising results. However, PLMs typically have\nbillions of parameters, making full fine-tuning expensive. We propose\nSparseFit, a sparse few-shot fine-tuning strategy that leverages discrete\nprompts to jointly generate predictions and NLEs. We experiment with SparseFit\non three sizes of the T5 language model and four datasets and compare it\nagainst existing state-of-the-art Parameter-Efficient Fine-Tuning (PEFT)\ntechniques. We find that fine-tuning only 6.8% of the model parameters leads to\ncompetitive results for both the task performance and the quality of the\ngenerated NLEs compared to full fine-tuning of the model and produces better\nresults on average than other PEFT methods in terms of predictive accuracy and\nNLE quality.", "published": "2023-05-22 17:06:41", "link": "http://arxiv.org/abs/2305.13235v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head\n  Checkpoints", "abstract": "Multi-query attention (MQA), which only uses a single key-value head,\ndrastically speeds up decoder inference. However, MQA can lead to quality\ndegradation, and moreover it may not be desirable to train a separate model\njust for faster inference. We (1) propose a recipe for uptraining existing\nmulti-head language model checkpoints into models with MQA using 5% of original\npre-training compute, and (2) introduce grouped-query attention (GQA), a\ngeneralization of multi-query attention which uses an intermediate (more than\none, less than number of query heads) number of key-value heads. We show that\nuptrained GQA achieves quality close to multi-head attention with comparable\nspeed to MQA.", "published": "2023-05-22 17:16:38", "link": "http://arxiv.org/abs/2305.13245v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interactive Natural Language Processing", "abstract": "Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.", "published": "2023-05-22 17:18:29", "link": "http://arxiv.org/abs/2305.13246v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"According to ...\": Prompting Language Models Improves Quoting from\n  Pre-Training Data", "abstract": "Large Language Models (LLMs) may hallucinate and generate fake information,\ndespite pre-training on factual data. Inspired by the journalistic device of\n\"according to sources\", we propose according-to prompting: directing LLMs to\nground responses against previously observed text. To quantify this grounding,\nwe propose a novel evaluation metric (QUIP-Score) that measures the extent to\nwhich model-produced answers are directly found in underlying text corpora. We\nillustrate with experiments on three corpora (Wikipedia, PubMed, and the U.S.\nlegal tax code) that these prompts improve grounding under our metrics, with\nthe additional benefit of often improving end-task performance. Furthermore,\nprompts that ask the model to decrease grounding (or to ground to other\ncorpora) indeed decrease QUIP-Score, indicating the ability of LLMs to increase\nor decrease grounded generations on request.", "published": "2023-05-22 17:25:24", "link": "http://arxiv.org/abs/2305.13252v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TaskWeb: Selecting Better Source Tasks for Multi-task NLP", "abstract": "Recent work in NLP has shown promising results in training models on large\namounts of tasks to achieve better generalization. However, it is not\nwell-understood how tasks are related, and how helpful training tasks can be\nchosen for a new task. In this work, we investigate whether knowing task\nrelationships via pairwise task transfer improves choosing one or more source\ntasks that help to learn a new target task. We provide TaskWeb, a large-scale\nbenchmark of pairwise task transfers for 22 NLP tasks using three different\nmodel types, sizes, and adaptation methods, spanning about 25,000 experiments.\nThen, we design a new method TaskShop based on our analysis of TaskWeb.\nTaskShop uses TaskWeb to estimate the benefit of using a source task for\nlearning a new target task, and to choose a subset of helpful training tasks\nfor multi-task training. Our method improves overall rankings and top-k\nprecision of source tasks by 10% and 38%, respectively. We also use TaskShop to\nbuild much smaller multi-task training sets that improve zero-shot performances\nacross 11 different target tasks by at least 4.3%.", "published": "2023-05-22 17:27:57", "link": "http://arxiv.org/abs/2305.13256v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompting is not a substitute for probability measurements in large\n  language models", "abstract": "Prompting is now a dominant method for evaluating the linguistic knowledge of\nlarge language models (LLMs). While other methods directly read out models'\nprobability distributions over strings, prompting requires models to access\nthis internal information by processing linguistic input, thereby implicitly\ntesting a new type of emergent ability: metalinguistic judgment. In this study,\nwe compare metalinguistic prompting and direct probability measurements as ways\nof measuring models' linguistic knowledge. Broadly, we find that LLMs'\nmetalinguistic judgments are inferior to quantities directly derived from\nrepresentations. Furthermore, consistency gets worse as the prompt query\ndiverges from direct measurements of next-word probabilities. Our findings\nsuggest that negative results relying on metalinguistic prompts cannot be taken\nas conclusive evidence that an LLM lacks a particular linguistic\ngeneralization. Our results also highlight the value that is lost with the move\nto closed APIs where access to probability distributions is limited.", "published": "2023-05-22 17:33:17", "link": "http://arxiv.org/abs/2305.13264v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models", "abstract": "Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.", "published": "2023-05-22 17:33:44", "link": "http://arxiv.org/abs/2305.13267v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate\n  Speech Detection", "abstract": "Hate speech is a severe issue that affects many online platforms. So far,\nseveral studies have been performed to develop robust hate speech detection\nsystems. Large language models like ChatGPT have recently shown a great promise\nin performing several tasks, including hate speech detection. However, it is\ncrucial to comprehend the limitations of these models to build robust hate\nspeech detection systems. To bridge this gap, our study aims to evaluate the\nstrengths and weaknesses of the ChatGPT model in detecting hate speech at a\ngranular level across 11 languages. Our evaluation employs a series of\nfunctionality tests that reveals various intricate failures of the model which\nthe aggregate metrics like macro F1 or accuracy are not able to unfold. In\naddition, we investigate the influence of complex emotions, such as the use of\nemojis in hate speech, on the performance of the ChatGPT model. Our analysis\nhighlights the shortcomings of the generative models in detecting certain types\nof hate speech and highlighting the need for further research and improvements\nin the workings of these models.", "published": "2023-05-22 17:36:58", "link": "http://arxiv.org/abs/2305.13276v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for\n  Out-of-Domain Detection", "abstract": "Out-of-distribution (OOD) detection is a critical task for reliable\npredictions over text. Fine-tuning with pre-trained language models has been a\nde facto procedure to derive OOD detectors with respect to in-distribution (ID)\ndata. Despite its common use, the understanding of the role of fine-tuning and\nits necessity for OOD detection is largely unexplored. In this paper, we raise\nthe question: is fine-tuning necessary for OOD detection? We present a study\ninvestigating the efficacy of directly leveraging pre-trained language models\nfor OOD detection, without any model fine-tuning on the ID data. We compare the\napproach with several competitive fine-tuning objectives, and offer new\ninsights under various types of distributional shifts. Extensive evaluations on\n8 diverse ID-OOD dataset pairs demonstrate near-perfect OOD detection\nperformance (with 0% FPR95 in many cases), strongly outperforming its\nfine-tuned counterparts. We show that using distance-based detection methods,\npre-trained language models are near-perfect OOD detectors when the\ndistribution shift involves a domain change. Furthermore, we study the effect\nof fine-tuning on OOD detection and identify how to balance ID accuracy with\nOOD detection performance. Our code is publically available at\nhttps://github.com/Uppaal/lm-ood.", "published": "2023-05-22 17:42:44", "link": "http://arxiv.org/abs/2305.13282v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive Chameleon or Stubborn Sloth: Revealing the Behavior of Large\n  Language Models in Knowledge Conflicts", "abstract": "By providing external information to large language models (LLMs), tool\naugmentation (including retrieval augmentation) has emerged as a promising\nsolution for addressing the limitations of LLMs' static parametric memory.\nHowever, how receptive are LLMs to such external evidence, especially when the\nevidence conflicts with their parametric memory? We present the first\ncomprehensive and controlled investigation into the behavior of LLMs when\nencountering knowledge conflicts. We propose a systematic framework to elicit\nhigh-quality parametric memory from LLMs and construct the corresponding\ncounter-memory, which enables us to conduct a series of controlled experiments.\nOur investigation reveals seemingly contradicting behaviors of LLMs. On the one\nhand, different from prior wisdom, we find that LLMs can be highly receptive to\nexternal evidence even when that conflicts with their parametric memory, given\nthat the external evidence is coherent and convincing. On the other hand, LLMs\nalso demonstrate a strong confirmation bias when the external evidence contains\nsome information that is consistent with their parametric memory, despite being\npresented with conflicting evidence at the same time. These results pose\nimportant implications that are worth careful consideration for the further\ndevelopment and deployment of tool- and retrieval-augmented LLMs. Resources are\navailable at https://github.com/OSU-NLP-Group/LLM-Knowledge-Conflict.", "published": "2023-05-22 17:57:41", "link": "http://arxiv.org/abs/2305.13300v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text", "abstract": "The fixed-size context of Transformer makes GPT models incapable of\ngenerating arbitrarily long text. In this paper, we introduce RecurrentGPT, a\nlanguage-based simulacrum of the recurrence mechanism in RNNs. RecurrentGPT is\nbuilt upon a large language model (LLM) such as ChatGPT and uses natural\nlanguage to simulate the Long Short-Term Memory mechanism in an LSTM. At each\ntimestep, RecurrentGPT generates a paragraph of text and updates its\nlanguage-based long-short term memory stored on the hard drive and the prompt,\nrespectively. This recurrence mechanism enables RecurrentGPT to generate texts\nof arbitrary length without forgetting. Since human users can easily observe\nand edit the natural language memories, RecurrentGPT is interpretable and\nenables interactive generation of long text. RecurrentGPT is an initial step\ntowards next-generation computer-assisted writing systems beyond local editing\nsuggestions. In addition to producing AI-generated content (AIGC), we also\ndemonstrate the possibility of using RecurrentGPT as an interactive fiction\nthat directly interacts with consumers. We call this usage of generative models\nby ``AI As Contents'' (AIAC), which we believe is the next form of conventional\nAIGC. We further demonstrate the possibility of using RecurrentGPT to create\npersonalized interactive fiction that directly interacts with readers instead\nof interacting with writers. More broadly, RecurrentGPT demonstrates the\nutility of borrowing ideas from popular model designs in cognitive science and\ndeep learning for prompting LLMs. Our code is available at\nhttps://github.com/aiwaves-cn/RecurrentGPT and an online demo is available at\nhttps://www.aiwaves.org/recurrentgpt.", "published": "2023-05-22 17:58:10", "link": "http://arxiv.org/abs/2305.13304v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The neural dynamics of auditory word recognition and integration", "abstract": "Listeners recognize and integrate words in rapid and noisy everyday speech by\ncombining expectations about upcoming content with incremental sensory\nevidence. We present a computational model of word recognition which formalizes\nthis perceptual process in Bayesian decision theory. We fit this model to\nexplain scalp EEG signals recorded as subjects passively listened to a\nfictional story, revealing both the dynamics of the online auditory word\nrecognition process and the neural correlates of the recognition and\nintegration of words.\n  The model reveals distinct neural processing of words depending on whether or\nnot they can be quickly recognized. While all words trigger a neural response\ncharacteristic of probabilistic integration -- voltage modulations predicted by\na word's surprisal in context -- these modulations are amplified for words\nwhich require more than roughly 150 ms of input to be recognized. We observe no\ndifference in the latency of these neural responses according to words'\nrecognition times. Our results are consistent with a two-part model of speech\ncomprehension, combining an eager and rapid process of word recognition with a\ntemporally independent process of word integration. However, we also developed\nalternative models of the scalp EEG signal not incorporating word recognition\ndynamics which showed similar performance improvements. We discuss potential\nfuture modeling steps which may help to separate these hypotheses.", "published": "2023-05-22 18:06:32", "link": "http://arxiv.org/abs/2305.13388v2", "categories": ["cs.CL", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "MAILEX: Email Event and Argument Extraction", "abstract": "In this work, we present the first dataset, MailEx, for performing event\nextraction from conversational email threads. To this end, we first proposed a\nnew taxonomy covering 10 event types and 76 arguments in the email domain. Our\nfinal dataset includes 1.5K email threads and ~4K emails, which are annotated\nwith totally ~8K event instances. To understand the task challenges, we\nconducted a series of experiments comparing three types of approaches, i.e.,\nfine-tuned sequence labeling, fine-tuned generative extraction, and few-shot\nin-context learning. Our results showed that the task of email event extraction\nis far from being addressed, due to challenges lying in, e.g., extracting\nnon-continuous, shared trigger spans, extracting non-named entity arguments,\nand modeling the email conversational history. Our work thus suggests more\nfuture investigations in this domain-specific event extraction task.", "published": "2023-05-22 20:28:23", "link": "http://arxiv.org/abs/2305.13469v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation for Code Generation", "abstract": "Neural machine translation (NMT) methods developed for natural language\nprocessing have been shown to be highly successful in automating translation\nfrom one natural language to another. Recently, these NMT methods have been\nadapted to the generation of program code. In NMT for code generation, the task\nis to generate output source code that satisfies constraints expressed in the\ninput. In the literature, a variety of different input scenarios have been\nexplored, including generating code based on natural language description,\nlower-level representations such as binary or assembly (neural decompilation),\npartial representations of source code (code completion and repair), and source\ncode in another language (code translation). In this paper we survey the NMT\nfor code generation literature, cataloging the variety of methods that have\nbeen explored according to input and output representations, model\narchitectures, optimization techniques used, data sets, and evaluation methods.\nWe discuss the limitations of existing methods and future research directions", "published": "2023-05-22 21:43:12", "link": "http://arxiv.org/abs/2305.13504v1", "categories": ["cs.CL", "cs.LG", "A.1"], "primary_category": "cs.CL"}
{"title": "Small Language Models Improve Giants by Rewriting Their Outputs", "abstract": "Despite the impressive performance of large language models (LLMs), they\noften lag behind specialized models in various tasks. LLMs only use a fraction\nof the existing training data for in-context learning, while task-specific\nmodels harness the full dataset for fine-tuning. In this work, we tackle the\nproblem of leveraging training data to improve the performance of LLMs without\nfine-tuning. Our approach directly targets LLM predictions without requiring\naccess to their weights. We create a pool of candidates from the LLM through\nfew-shot prompting and we employ a compact model, the LM-corrector (LMCor),\nspecifically trained to merge these candidates to produce an enhanced output.\nOur experiments on four natural language generation tasks demonstrate that even\na small LMCor model (250M) substantially improves the few-shot performance of\nLLMs (62B), matching and even outperforming standard fine-tuning. Furthermore,\nwe illustrate the robustness of LMCor against different prompts, thereby\nminimizing the need for extensive prompt engineering. Finally, we show that\nLMCor can be seamlessly integrated with different LLMs at inference, serving as\na plug-and-play module to improve their performance.", "published": "2023-05-22 22:07:50", "link": "http://arxiv.org/abs/2305.13514v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian\n  Language", "abstract": "This paper provides an overview of a text mining tool the StyloMetrix\ndeveloped initially for the Polish language and further extended for English\nand recently for Ukrainian. The StyloMetrix is built upon various metrics\ncrafted manually by computational linguists and researchers from literary\nstudies to analyze grammatical, stylistic, and syntactic patterns. The idea of\nconstructing the statistical evaluation of syntactic and grammar features is\nstraightforward and familiar for the languages like English, Spanish, German,\nand others; it is yet to be developed for low-resource languages like\nUkrainian. We describe the StyloMetrix pipeline and provide some experiments\nwith this tool for the text classification task. We also describe our package's\nmain limitations and the metrics' evaluation procedure.", "published": "2023-05-22 22:52:47", "link": "http://arxiv.org/abs/2305.13530v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Classifier Robustness through Active Generation of Pairwise\n  Counterfactuals", "abstract": "Counterfactual Data Augmentation (CDA) is a commonly used technique for\nimproving robustness in natural language classifiers. However, one fundamental\nchallenge is how to discover meaningful counterfactuals and efficiently label\nthem, with minimal human labeling cost. Most existing methods either completely\nrely on human-annotated labels, an expensive process which limits the scale of\ncounterfactual data, or implicitly assume label invariance, which may mislead\nthe model with incorrect labels. In this paper, we present a novel framework\nthat utilizes counterfactual generative models to generate a large number of\ndiverse counterfactuals by actively sampling from regions of uncertainty, and\nthen automatically label them with a learned pairwise classifier. Our key\ninsight is that we can more correctly label the generated counterfactuals by\ntraining a pairwise classifier that interpolates the relationship between the\noriginal example and the counterfactual. We demonstrate that with a small\namount of human-annotated counterfactual data (10%), we can generate a\ncounterfactual augmentation dataset with learned labels, that provides an\n18-20% improvement in robustness and a 14-21% reduction in errors on 6\nout-of-domain datasets, comparable to that of a fully human-annotated\ncounterfactual dataset for both sentiment classification and question\nparaphrase tasks.", "published": "2023-05-22 23:19:01", "link": "http://arxiv.org/abs/2305.13535v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot\n  Text Classification Tasks", "abstract": "Text classification tasks often encounter few shot scenarios with limited\nlabeled data, and addressing data scarcity is crucial. Data augmentation with\nmixup has shown to be effective on various text classification tasks. However,\nmost of the mixup methods do not consider the varying degree of learning\ndifficulty in different stages of training and generate new samples with one\nhot labels, resulting in the model over confidence. In this paper, we propose a\nself evolution learning (SE) based mixup approach for data augmentation in text\nclassification, which can generate more adaptive and model friendly pesudo\nsamples for the model training. SE focuses on the variation of the model's\nlearning ability. To alleviate the model confidence, we introduce a novel\ninstance specific label smoothing approach, which linearly interpolates the\nmodel's output and one hot labels of the original samples to generate new soft\nfor label mixing up. Through experimental analysis, in addition to improving\nclassification accuracy, we demonstrate that SE also enhances the model's\ngeneralize ability.", "published": "2023-05-22 23:43:23", "link": "http://arxiv.org/abs/2305.13547v3", "categories": ["cs.CL", "cs.NI"], "primary_category": "cs.CL"}
{"title": "How Fragile is Relation Extraction under Entity Replacements?", "abstract": "Relation extraction (RE) aims to extract the relations between entity names\nfrom the textual context. In principle, textual context determines the\nground-truth relation and the RE models should be able to correctly identify\nthe relations reflected by the textual context. However, existing work has\nfound that the RE models memorize the entity name patterns to make RE\npredictions while ignoring the textual context. This motivates us to raise the\nquestion: ``are RE models robust to the entity replacements?'' In this work, we\noperate the random and type-constrained entity replacements over the RE\ninstances in TACRED and evaluate the state-of-the-art RE models under the\nentity replacements. We observe the 30\\% - 50\\% F1 score drops on the\nstate-of-the-art RE models under entity replacements. These results suggest\nthat we need more efforts to develop effective RE models robust to entity\nreplacements. We release the source code at\nhttps://github.com/wangywUST/RobustRE.", "published": "2023-05-22 23:53:32", "link": "http://arxiv.org/abs/2305.13551v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Finding the Pillars of Strength for Multi-Head Attention", "abstract": "Recent studies have revealed some issues of Multi-Head Attention (MHA), e.g.,\nredundancy and over-parameterization. Specifically, the heads of MHA were\noriginally designed to attend to information from different representation\nsubspaces, whereas prior studies found that some attention heads likely learn\nsimilar features and can be pruned without harming performance. Inspired by the\nminimum-redundancy feature selection, we assume that focusing on the most\nrepresentative and distinctive features with minimum resources can mitigate the\nabove issues and lead to more effective and efficient MHAs. In particular, we\npropose Grouped Head Attention, trained with a self-supervised group constraint\nthat group attention heads, where each group focuses on an essential but\ndistinctive feature subset. We additionally propose a Voting-to-Stay procedure\nto remove redundant heads, thus achieving a transformer with lighter weights.\nMoreover, our method achieves significant performance gains on three\nwell-established tasks while considerably compressing parameters.", "published": "2023-05-22 03:44:44", "link": "http://arxiv.org/abs/2305.14380v2", "categories": ["cs.LG", "cs.CL", "I.2.0; I.2.7"], "primary_category": "cs.LG"}
{"title": "REFinD: Relation Extraction Financial Dataset", "abstract": "A number of datasets for Relation Extraction (RE) have been created to aide\ndownstream tasks such as information retrieval, semantic search, question\nanswering and textual entailment. However, these datasets fail to capture\nfinancial-domain specific challenges since most of these datasets are compiled\nusing general knowledge sources such as Wikipedia, web-based text and news\narticles, hindering real-life progress and adoption within the financial world.\nTo address this limitation, we propose REFinD, the first large-scale annotated\ndataset of relations, with $\\sim$29K instances and 22 relations amongst 8 types\nof entity pairs, generated entirely over financial documents. We also provide\nan empirical evaluation with various state-of-the-art models as benchmarks for\nthe RE task and highlight the challenges posed by our dataset. We observed that\nvarious state-of-the-art deep learning models struggle with numeric inference,\nrelational and directional ambiguity.", "published": "2023-05-22 22:40:11", "link": "http://arxiv.org/abs/2305.18322v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Duplex Diffusion Models Improve Speech-to-Speech Translation", "abstract": "Speech-to-speech translation is a typical sequence-to-sequence learning task\nthat naturally has two directions. How to effectively leverage bidirectional\nsupervision signals to produce high-fidelity audio for both directions?\nExisting approaches either train two separate models or a multitask-learned\nmodel with low efficiency and inferior performance. In this paper, we propose a\nduplex diffusion model that applies diffusion probabilistic models to both\nsides of a reversible duplex Conformer, so that either end can simultaneously\ninput and output a distinct language's speech. Our model enables reversible\nspeech translation by simply flipping the input and output ends. Experiments\nshow that our model achieves the first success of reversible speech translation\nwith significant improvements of ASR-BLEU scores compared with a list of\nstate-of-the-art baselines.", "published": "2023-05-22 01:39:40", "link": "http://arxiv.org/abs/2305.12628v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Reflective Linguistic Programming (RLP): A Stepping Stone in\n  Socially-Aware AGI (SocialAGI)", "abstract": "This paper presents Reflective Linguistic Programming (RLP), a unique\napproach to conversational AI that emphasizes self-awareness and strategic\nplanning. RLP encourages models to introspect on their own predefined\npersonality traits, emotional responses to incoming messages, and planned\nstrategies, enabling contextually rich, coherent, and engaging interactions. A\nstriking illustration of RLP's potential involves a toy example, an AI persona\nwith an adversarial orientation, a demon named `Bogus' inspired by the\nchildren's fairy tale Hansel & Gretel. Bogus exhibits sophisticated behaviors,\nsuch as strategic deception and sensitivity to user discomfort, that\nspontaneously arise from the model's introspection and strategic planning.\nThese behaviors are not pre-programmed or prompted, but emerge as a result of\nthe model's advanced cognitive modeling. The potential applications of RLP in\nsocially-aware AGI (Social AGI) are vast, from nuanced negotiations and mental\nhealth support systems to the creation of diverse and dynamic AI personas. Our\nexploration of deception serves as a stepping stone towards a new frontier in\nAGI, one filled with opportunities for advanced cognitive modeling and the\ncreation of truly human `digital souls'.", "published": "2023-05-22 02:43:15", "link": "http://arxiv.org/abs/2305.12647v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "FIT: Far-reaching Interleaved Transformers", "abstract": "We present FIT: a transformer-based architecture with efficient\nself-attention and adaptive computation. Unlike original transformers, which\noperate on a single sequence of data tokens, we divide the data tokens into\ngroups, with each group being a shorter sequence of tokens. We employ two types\nof transformer layers: local layers operate on data tokens within each group,\nwhile global layers operate on a smaller set of introduced latent tokens. These\nlayers, comprising the same set of self-attention and feed-forward layers as\nstandard transformers, are interleaved, and cross-attention is used to\nfacilitate information exchange between data and latent tokens within the same\ngroup. The attention complexity is $O(n^2)$ locally within each group of size\n$n$, but can reach $O(L^{{4}/{3}})$ globally for sequence length of $L$. The\nefficiency can be further enhanced by relying more on global layers that\nperform adaptive computation using a smaller set of latent tokens. FIT is a\nversatile architecture and can function as an encoder, diffusion decoder, or\nautoregressive decoder. We provide initial evidence demonstrating its\neffectiveness in high-resolution image understanding and generation tasks.\nNotably, FIT exhibits potential in performing end-to-end training on\ngigabit-scale data, such as 6400$\\times$6400 images, or 160K tokens (after\npatch tokenization), within a memory capacity of 16GB, without requiring\nspecific optimizations or model parallelism.", "published": "2023-05-22 03:56:44", "link": "http://arxiv.org/abs/2305.12689v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Quantifying Association Capabilities of Large Language Models and Its\n  Implications on Privacy Leakage", "abstract": "The advancement of large language models (LLMs) brings notable improvements\nacross various applications, while simultaneously raising concerns about\npotential private data exposure. One notable capability of LLMs is their\nability to form associations between different pieces of information, but this\nraises concerns when it comes to personally identifiable information (PII).\nThis paper delves into the association capabilities of language models, aiming\nto uncover the factors that influence their proficiency in associating\ninformation. Our study reveals that as models scale up, their capacity to\nassociate entities/information intensifies, particularly when target pairs\ndemonstrate shorter co-occurrence distances or higher co-occurrence\nfrequencies. However, there is a distinct performance gap when associating\ncommonsense knowledge versus PII, with the latter showing lower accuracy.\nDespite the proportion of accurately predicted PII being relatively small, LLMs\nstill demonstrate the capability to predict specific instances of email\naddresses and phone numbers when provided with appropriate prompts. These\nfindings underscore the potential risk to PII confidentiality posed by the\nevolving capabilities of LLMs, especially as they continue to expand in scale\nand power.", "published": "2023-05-22 04:30:35", "link": "http://arxiv.org/abs/2305.12707v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Towards Explainable In-the-Wild Video Quality Assessment: A Database and\n  a Language-Prompted Approach", "abstract": "The proliferation of in-the-wild videos has greatly expanded the Video\nQuality Assessment (VQA) problem. Unlike early definitions that usually focus\non limited distortion types, VQA on in-the-wild videos is especially\nchallenging as it could be affected by complicated factors, including various\ndistortions and diverse contents. Though subjective studies have collected\noverall quality scores for these videos, how the abstract quality scores relate\nwith specific factors is still obscure, hindering VQA methods from more\nconcrete quality evaluations (e.g. sharpness of a video). To solve this\nproblem, we collect over two million opinions on 4,543 in-the-wild videos on 13\ndimensions of quality-related factors, including in-capture authentic\ndistortions (e.g. motion blur, noise, flicker), errors introduced by\ncompression and transmission, and higher-level experiences on semantic contents\nand aesthetic issues (e.g. composition, camera trajectory), to establish the\nmulti-dimensional Maxwell database. Specifically, we ask the subjects to label\namong a positive, a negative, and a neutral choice for each dimension. These\nexplanation-level opinions allow us to measure the relationships between\nspecific quality factors and abstract subjective quality ratings, and to\nbenchmark different categories of VQA algorithms on each dimension, so as to\nmore comprehensively analyze their strengths and weaknesses. Furthermore, we\npropose the MaxVQA, a language-prompted VQA approach that modifies\nvision-language foundation model CLIP to better capture important quality\nissues as observed in our analyses. The MaxVQA can jointly evaluate various\nspecific quality factors and final quality scores with state-of-the-art\naccuracy on all dimensions, and superb generalization ability on existing\ndatasets. Code and data available at https://github.com/VQAssessment/MaxVQA.", "published": "2023-05-22 05:20:23", "link": "http://arxiv.org/abs/2305.12726v2", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "GNCformer Enhanced Self-attention for Automatic Speech Recognition", "abstract": "In this paper,an Enhanced Self-Attention (ESA) mechanism has been put forward\nfor robust feature extraction.The proposed ESA is integrated with the recursive\ngated convolution and self-attention mechanism.In particular, the former is\nused to capture multi-order feature interaction and the latter is for global\nfeature extraction.In addition, the location of interest that is suitable for\ninserting the ESA is also worth being explored.In this paper, the ESA is\nembedded into the encoder layer of the Transformer network for automatic speech\nrecognition (ASR) tasks, and this newly proposed model is named GNCformer. The\neffectiveness of the GNCformer has been validated using two datasets, that are\nAishell-1 and HKUST.Experimental results show that, compared with the\nTransformer network,0.8%CER,and 1.2%CER improvement for these two mentioned\ndatasets, respectively, can be achieved.It is worth mentioning that only 1.4M\nadditional parameters have been involved in our proposed GNCformer.", "published": "2023-05-22 06:26:05", "link": "http://arxiv.org/abs/2305.12755v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Explaining Emergent In-Context Learning as Kernel Regression", "abstract": "Large language models (LLMs) have initiated a paradigm shift in transfer\nlearning. In contrast to the classic pretraining-then-finetuning procedure, in\norder to use LLMs for downstream prediction tasks, one only needs to provide a\nfew demonstrations, known as in-context examples, without adding more or\nupdating existing model parameters. This in-context learning (ICL) capability\nof LLMs is intriguing, and it is not yet fully understood how pretrained LLMs\nacquire such capabilities. In this paper, we investigate the reason why a\ntransformer-based language model can accomplish in-context learning after\npre-training on a general language corpus by proposing one hypothesis that LLMs\ncan simulate kernel regression with internal representations when faced with\nin-context examples. More concretely, we first prove that Bayesian inference on\nin-context prompts can be asymptotically understood as kernel regression $\\hat\ny = \\sum_i y_i K(x, x_i)/\\sum_i K(x, x_i)$ as the number of in-context\ndemonstrations grows. Then, we empirically investigate the in-context behaviors\nof language models. We find that during ICL, the attention and hidden features\nin LLMs match the behaviors of a kernel regression. Finally, our theory\nprovides insights into multiple phenomena observed in the ICL field: why\nretrieving demonstrative samples similar to test samples can help, why ICL\nperformance is sensitive to the output formats, and why ICL accuracy benefits\nfrom selecting in-distribution and representative samples.", "published": "2023-05-22 06:45:02", "link": "http://arxiv.org/abs/2305.12766v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling\n  for Many-to-Many Multimodal Summarization", "abstract": "Many-to-many multimodal summarization (M$^3$S) task aims to generate\nsummaries in any language with document inputs in any language and the\ncorresponding image sequence, which essentially comprises multimodal\nmonolingual summarization (MMS) and multimodal cross-lingual summarization\n(MXLS) tasks. Although much work has been devoted to either MMS or MXLS and has\nobtained increasing attention in recent years, little research pays attention\nto the M$^3$S task. Besides, existing studies mainly focus on 1) utilizing MMS\nto enhance MXLS via knowledge distillation without considering the performance\nof MMS or 2) improving MMS models by filtering summary-unrelated visual\nfeatures with implicit learning or explicitly complex training objectives. In\nthis paper, we first introduce a general and practical task, i.e., M$^3$S.\nFurther, we propose a dual knowledge distillation and target-oriented vision\nmodeling framework for the M$^3$S task. Specifically, the dual knowledge\ndistillation method guarantees that the knowledge of MMS and MXLS can be\ntransferred to each other and thus mutually prompt both of them. To offer\ntarget-oriented visual features, a simple yet effective target-oriented\ncontrastive objective is designed and responsible for discarding needless\nvisual information. Extensive experiments on the many-to-many setting show the\neffectiveness of the proposed approach. Additionally, we will contribute a\nmany-to-many multimodal summarization (M$^3$Sum) dataset.", "published": "2023-05-22 06:47:35", "link": "http://arxiv.org/abs/2305.12767v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Zero-Shot End-to-End Spoken Language Understanding via Cross-Modal\n  Selective Self-Training", "abstract": "End-to-end (E2E) spoken language understanding (SLU) is constrained by the\ncost of collecting speech-semantics pairs, especially when label domains\nchange. Hence, we explore \\textit{zero-shot} E2E SLU, which learns E2E SLU\nwithout speech-semantics pairs, instead using only speech-text and\ntext-semantics pairs. Previous work achieved zero-shot by pseudolabeling all\nspeech-text transcripts with a natural language understanding (NLU) model\nlearned on text-semantics corpora. However, this method requires the domains of\nspeech-text and text-semantics to match, which often mismatch due to separate\ncollections. Furthermore, using the entire collected speech-text corpus from\nany domains leads to \\textit{imbalance} and \\textit{noise} issues. To address\nthese, we propose \\textit{cross-modal selective self-training} (CMSST). CMSST\ntackles imbalance by clustering in a joint space of the three modalities\n(speech, text, and semantics) and handles label noise with a selection network.\nWe also introduce two benchmarks for zero-shot E2E SLU, covering matched and\nfound speech (mismatched) settings. Experiments show that CMSST improves\nperformance in both two settings, with significantly reduced sample sizes and\ntraining time. Our code and data are released in\nhttps://github.com/amazon-science/zero-shot-E2E-slu.", "published": "2023-05-22 07:42:52", "link": "http://arxiv.org/abs/2305.12793v2", "categories": ["eess.AS", "cs.CL", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Word Embeddings Are Steers for Language Models", "abstract": "Language models (LMs) automatically learn word embeddings during pre-training\non language corpora. Although word embeddings are usually interpreted as\nfeature vectors for individual words, their roles in language model generation\nremain underexplored. In this work, we theoretically and empirically revisit\noutput word embeddings and find that their linear transformations are\nequivalent to steering language model generation styles. We name such steers\nLM-Steers and find them existing in LMs of all sizes. It requires learning\nparameters equal to 0.2% of the original LMs' size for steering each style. On\ntasks such as language model detoxification and sentiment control, LM-Steers\ncan achieve comparable or superior performance compared with state-of-the-art\ncontrolled generation methods while maintaining a better balance with\ngeneration quality. The learned LM-Steer serves as a lens in text styles: it\nreveals that word embeddings are interpretable when associated with language\nmodel generations and can highlight text spans that most indicate the style\ndifferences. An LM-Steer is transferrable between different language models by\nan explicit form calculation. One can also continuously steer LMs simply by\nscaling the LM-Steer or compose multiple LM-Steers by adding their\ntransformations. Our codes are publicly available at\n\\url{https://github.com/Glaciohound/LM-Steer}.", "published": "2023-05-22 07:52:04", "link": "http://arxiv.org/abs/2305.12798v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Meta-in-context learning in large language models", "abstract": "Large language models have shown tremendous performance in a variety of\ntasks. In-context learning -- the ability to improve at a task after being\nprovided with a number of demonstrations -- is seen as one of the main\ncontributors to their success. In the present paper, we demonstrate that the\nin-context learning abilities of large language models can be recursively\nimproved via in-context learning itself. We coin this phenomenon\nmeta-in-context learning. Looking at two idealized domains, a one-dimensional\nregression task and a two-armed bandit task, we show that meta-in-context\nlearning adaptively reshapes a large language model's priors over expected\ntasks. Furthermore, we find that meta-in-context learning modifies the\nin-context learning strategies of such models. Finally, we extend our approach\nto a benchmark of real-world regression problems where we observe competitive\nperformance to traditional learning algorithms. Taken together, our work\nimproves our understanding of in-context learning and paves the way toward\nadapting large language models to the environment they are applied purely\nthrough meta-in-context learning rather than traditional finetuning.", "published": "2023-05-22 10:40:36", "link": "http://arxiv.org/abs/2305.12907v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Speaker-Related Information in Spoken Language Understanding\n  for Better Speaker Diarization", "abstract": "Speaker diarization(SD) is a classic task in speech processing and is crucial\nin multi-party scenarios such as meetings and conversations. Current mainstream\nspeaker diarization approaches consider acoustic information only, which result\nin performance degradation when encountering adverse acoustic conditions. In\nthis paper, we propose methods to extract speaker-related information from\nsemantic content in multi-party meetings, which, as we will show, can further\nbenefit speaker diarization. We introduce two sub-tasks, Dialogue Detection and\nSpeaker-Turn Detection, in which we effectively extract speaker information\nfrom conversational semantics. We also propose a simple yet effective algorithm\nto jointly model acoustic and semantic information and obtain\nspeaker-identified texts. Experiments on both AISHELL-4 and AliMeeting datasets\nshow that our method achieves consistent improvements over acoustic-only\nspeaker diarization systems.", "published": "2023-05-22 11:14:19", "link": "http://arxiv.org/abs/2305.12927v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MaNtLE: Model-agnostic Natural Language Explainer", "abstract": "Understanding the internal reasoning behind the predictions of machine\nlearning systems is increasingly vital, given their rising adoption and\nacceptance. While previous approaches, such as LIME, generate algorithmic\nexplanations by attributing importance to input features for individual\nexamples, recent research indicates that practitioners prefer examining\nlanguage explanations that explain sub-groups of examples. In this paper, we\nintroduce MaNtLE, a model-agnostic natural language explainer that analyzes\nmultiple classifier predictions and generates faithful natural language\nexplanations of classifier rationale for structured classification tasks.\nMaNtLE uses multi-task training on thousands of synthetic classification tasks\nto generate faithful explanations. Simulated user studies indicate that, on\naverage, MaNtLE-generated explanations are at least 11% more faithful compared\nto LIME and Anchors explanations across three tasks. Human evaluations\ndemonstrate that users can better predict model behavior using explanations\nfrom MaNtLE compared to other techniques", "published": "2023-05-22 12:58:06", "link": "http://arxiv.org/abs/2305.12995v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Semi-supervised Learning with Language Models", "abstract": "Semi-supervised learning (SSL) is a popular setting aiming to effectively\nutilize unlabelled data to improve model performance in downstream natural\nlanguage processing (NLP) tasks. Currently, there are two popular approaches to\nmake use of unlabelled data: Self-training (ST) and Task-adaptive pre-training\n(TAPT). ST uses a teacher model to assign pseudo-labels to the unlabelled data,\nwhile TAPT continues pre-training on the unlabelled data before fine-tuning. To\nthe best of our knowledge, the effectiveness of TAPT in SSL tasks has not been\nsystematically studied, and no previous work has directly compared TAPT and ST\nin terms of their ability to utilize the pool of unlabelled data. In this\npaper, we provide an extensive empirical study comparing five state-of-the-art\nST approaches and TAPT across various NLP tasks and data sizes, including in-\nand out-of-domain settings. Surprisingly, we find that TAPT is a strong and\nmore robust SSL learner, even when using just a few hundred unlabelled samples\nor in the presence of domain shifts, compared to more sophisticated ST\napproaches, and tends to bring greater improvements in SSL than in\nfully-supervised settings. Our further analysis demonstrates the risks of using\nST approaches when the size of labelled or unlabelled data is small or when\ndomain shifts exist. We offer a fresh perspective for future SSL research,\nsuggesting the use of unsupervised pre-training objectives over dependency on\npseudo labels.", "published": "2023-05-22 13:07:35", "link": "http://arxiv.org/abs/2305.13002v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Textually Pretrained Speech Language Models", "abstract": "Speech language models (SpeechLMs) process and generate acoustic data only,\nwithout textual supervision. In this work, we propose TWIST, a method for\ntraining SpeechLMs using a warm-start from a pretrained textual language\nmodels. We show using both automatic and human evaluations that TWIST\noutperforms a cold-start SpeechLM across the board. We empirically analyze the\neffect of different model design choices such as the speech tokenizer, the\npretrained textual model, and the dataset size. We find that model and dataset\nscale both play an important role in constructing better-performing SpeechLMs.\nBased on our observations, we present the largest (to the best of our\nknowledge) SpeechLM both in terms of number of parameters and training data. We\nadditionally introduce two spoken versions of the StoryCloze textual benchmark\nto further improve model evaluation and advance future research in the field.\nWe make speech samples, code and models publicly available:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/twist/ .", "published": "2023-05-22 13:12:16", "link": "http://arxiv.org/abs/2305.13009v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Federated Learning of Medical Concepts Embedding using BEHRT", "abstract": "Electronic Health Records (EHR) data contains medical records such as\ndiagnoses, medications, procedures, and treatments of patients. This data is\noften considered sensitive medical information. Therefore, the EHR data from\nthe medical centers often cannot be shared, making it difficult to create\nprediction models using multi-center EHR data, which is essential for such\nmodels' robustness and generalizability. Federated Learning (FL) is an\nalgorithmic approach that allows learning a shared model using data in multiple\nlocations without the need to store all data in a central place. An example of\na prediction model's task is to predict future diseases. More specifically, the\nmodel needs to predict patient's next visit diagnoses, based on current and\nprevious clinical data. Such a prediction model can support care providers in\nmaking clinical decisions and even provide preventive treatment. We propose a\nfederated learning approach for learning medical concepts embedding. This\npre-trained model can be used for fine-tuning for specific downstream tasks.\nOur approach is based on an embedding model like BEHRT, a deep neural sequence\ntransduction model for EHR. We train using federated learning, both the Masked\nLanguage Modeling (MLM) and the next visit downstream model. We demonstrate our\napproach on the MIMIC-IV dataset. We compare the performance of a model trained\nwith FL against a model trained on centralized data. We find that our federated\nlearning approach reaches very close to the performance of a centralized model,\nand it outperforms local models in terms of average precision. We also show\nthat pre-trained MLM improves the model's average precision performance in the\nnext visit prediction task, compared to an MLM model without pre-training. Our\ncode is available at https://github.com/nadavlab/FederatedBEHRT.", "published": "2023-05-22 14:05:39", "link": "http://arxiv.org/abs/2305.13052v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Table Meets LLM: Can Large Language Models Understand Structured Table\n  Data? A Benchmark and Empirical Study", "abstract": "Large language models (LLMs) are becoming attractive as few-shot reasoners to\nsolve Natural Language (NL)-related tasks. However, the understanding of their\ncapability to process structured data like tables remains an under-explored\narea. While tables can be serialized as input for LLMs, there is a lack of\ncomprehensive studies on whether LLMs genuinely comprehend this data. In this\npaper, we try to understand this by designing a benchmark to evaluate the\nstructural understanding capabilities of LLMs through seven distinct tasks,\ne.g., cell lookup, row retrieval and size detection. Specially, we perform a\nseries of evaluations on the recent most advanced LLM models, GPT-3.5 and GPT-4\nand observe that performance varied with different input choices, including\ntable input format, content order, role prompting, and partition marks. Drawing\nfrom the insights gained through the benchmark evaluations, we propose\n$\\textit{self-augmentation}$ for effective structural prompting, such as\ncritical value / range identification using internal knowledge of LLMs. When\ncombined with carefully chosen input choices, these structural prompting\nmethods lead to promising improvements in LLM performance on a variety of\ntabular tasks, e.g., TabFact($\\uparrow2.31\\%$), HybridQA($\\uparrow2.13\\%$),\nSQA($\\uparrow2.72\\%$), Feverous($\\uparrow0.84\\%$), and ToTTo($\\uparrow5.68\\%$).\nWe believe that our open source benchmark and proposed prompting methods can\nserve as a simple yet generic selection for future research. The code and data\nof this paper will be temporality released at\nhttps://anonymous.4open.science/r/StructuredLLM-76F3/README.md and will be\nreplaced with an official one at https://github.com/microsoft/TableProvider\nlater.", "published": "2023-05-22 14:23:46", "link": "http://arxiv.org/abs/2305.13062v5", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Text-to-SQL Error Correction with Language Models of Code", "abstract": "Despite recent progress in text-to-SQL parsing, current semantic parsers are\nstill not accurate enough for practical use. In this paper, we investigate how\nto build automatic text-to-SQL error correction models. Noticing that\ntoken-level edits are out of context and sometimes ambiguous, we propose\nbuilding clause-level edit models instead. Besides, while most language models\nof code are not specifically pre-trained for SQL, they know common data\nstructures and their operations in programming languages such as Python. Thus,\nwe propose a novel representation for SQL queries and their edits that adheres\nmore closely to the pre-training corpora of language models of code. Our error\ncorrection model improves the exact set match accuracy of different parsers by\n2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong\nbaselines. Our code and data are available at\nhttps://github.com/OSU-NLP-Group/Auto-SQL-Correction.", "published": "2023-05-22 14:42:39", "link": "http://arxiv.org/abs/2305.13073v2", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mitigating Catastrophic Forgetting for Few-Shot Spoken Word\n  Classification Through Meta-Learning", "abstract": "We consider the problem of few-shot spoken word classification in a setting\nwhere a model is incrementally introduced to new word classes. This would occur\nin a user-defined keyword system where new words can be added as the system is\nused. In such a continual learning scenario, a model might start to misclassify\nearlier words as newer classes are added, i.e. catastrophic forgetting. To\naddress this, we propose an extension to model-agnostic meta-learning (MAML):\neach inner learning loop, where a model \"learns how to learn'' new classes,\nends with a single gradient update using stored templates from all the classes\nthat the model has already seen (one template per class). We compare this\nmethod to OML (another extension of MAML) in few-shot isolated-word\nclassification experiments on Google Commands and FACC. Our method consistently\noutperforms OML in experiments where the number of shots and the final number\nof classes are varied.", "published": "2023-05-22 14:51:15", "link": "http://arxiv.org/abs/2305.13080v1", "categories": ["cs.CL", "cs.AI", "eess.AS", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Should We Attend More or Less? Modulating Attention for Fairness", "abstract": "The advances in natural language processing (NLP) pose both opportunities and\nchallenges. While recent progress enables the development of high-performing\nmodels for a variety of tasks, it also poses the risk of models learning\nharmful biases from the data, such as gender stereotypes. In this work, we\ninvestigate the role of attention, a widely-used technique in current\nstate-of-the-art NLP models, in the propagation of social biases. Specifically,\nwe study the relationship between the entropy of the attention distribution and\nthe model's performance and fairness. We then propose a novel method for\nmodulating attention weights to improve model fairness after training. Since\nour method is only applied post-training and pre-inference, it is an\nintra-processing method and is, therefore, less computationally expensive than\nexisting in-processing and pre-processing approaches. Our results show an\nincrease in fairness and minimal performance loss on different text\nclassification and generation tasks using language models of varying sizes.\nWARNING: This work uses language that is offensive.", "published": "2023-05-22 14:54:21", "link": "http://arxiv.org/abs/2305.13088v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Debiased Automatic Speech Recognition for Dysarthric Speech via Sample\n  Reweighting with Sample Affinity Test", "abstract": "Automatic speech recognition systems based on deep learning are mainly\ntrained under empirical risk minimization (ERM). Since ERM utilizes the\naveraged performance on the data samples regardless of a group such as healthy\nor dysarthric speakers, ASR systems are unaware of the performance disparities\nacross the groups. This results in biased ASR systems whose performance\ndifferences among groups are severe. In this study, we aim to improve the ASR\nsystem in terms of group robustness for dysarthric speakers. To achieve our\ngoal, we present a novel approach, sample reweighting with sample affinity test\n(Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given\ndata sample and then mitigates the bias by debiasing helpfulness-based sample\nreweighting. Experimental results demonstrate that Re-SAT contributes to\nimproved ASR performance on dysarthric speech without performance degradation\non healthy speech.", "published": "2023-05-22 15:09:27", "link": "http://arxiv.org/abs/2305.13108v3", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EMNS /Imz/ Corpus: An emotive single-speaker dataset for narrative\n  storytelling in games, television and graphic novels", "abstract": "The increasing adoption of text-to-speech technologies has led to a growing\ndemand for natural and emotive voices that adapt to a conversation's context\nand emotional tone. The Emotive Narrative Storytelling (EMNS) corpus is a\nunique speech dataset created to enhance conversations' expressiveness and\nemotive quality in interactive narrative-driven systems. The corpus consists of\na 2.3-hour recording featuring a female speaker delivering labelled utterances.\nIt encompasses eight acted emotional states, evenly distributed with a variance\nof 0.68%, along with expressiveness levels and natural language descriptions\nwith word emphasis labels. The evaluation of audio samples from different\ndatasets revealed that the EMNS corpus achieved the highest average scores in\naccurately conveying emotions and demonstrating expressiveness. It outperformed\nother datasets in conveying shared emotions and achieved comparable levels of\ngenuineness. A classification task confirmed the accurate representation of\nintended emotions in the corpus, with participants recognising the recordings\nas genuine and expressive. Additionally, the availability of the dataset\ncollection tool under the Apache 2.0 License simplifies remote speech data\ncollection for researchers.", "published": "2023-05-22 15:32:32", "link": "http://arxiv.org/abs/2305.13137v2", "categories": ["cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Taxonomy Expansion for Named Entity Recognition", "abstract": "Training a Named Entity Recognition (NER) model often involves fixing a\ntaxonomy of entity types. However, requirements evolve and we might need the\nNER model to recognize additional entity types. A simple approach is to\nre-annotate entire dataset with both existing and additional entity types and\nthen train the model on the re-annotated dataset. However, this is an extremely\nlaborious task. To remedy this, we propose a novel approach called Partial\nLabel Model (PLM) that uses only partially annotated datasets. We experiment\nwith 6 diverse datasets and show that PLM consistently performs better than\nmost other approaches (0.5 - 2.5 F1), including in novel settings for taxonomy\nexpansion not considered in prior work. The gap between PLM and all other\napproaches is especially large in settings where there is limited data\navailable for the additional entity types (as much as 11 F1), thus suggesting a\nmore cost effective approaches to taxonomy expansion.", "published": "2023-05-22 16:23:46", "link": "http://arxiv.org/abs/2305.13191v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Isochronous Machine Translation with Target Factors and\n  Auxiliary Counters", "abstract": "To translate speech for automatic dubbing, machine translation needs to be\nisochronous, i.e. translated speech needs to be aligned with the source in\nterms of speech durations. We introduce target factors in a transformer model\nto predict durations jointly with target language phoneme sequences. We also\nintroduce auxiliary counters to help the decoder to keep track of the timing\ninformation while generating target phonemes. We show that our model improves\ntranslation quality and isochrony compared to previous work where the\ntranslation model is instead trained to predict interleaved sequences of\nphonemes and durations.", "published": "2023-05-22 16:36:04", "link": "http://arxiv.org/abs/2305.13204v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis", "abstract": "Recent research has highlighted the importance of dataset size in scaling\nlanguage models. However, large language models (LLMs) are notoriously\ntoken-hungry during pre-training, and high-quality text data on the web is\napproaching its scaling limit for LLMs. To further enhance LLMs, a\nstraightforward approach is to repeat the pre-training data for additional\nepochs. In this study, we empirically investigate three key aspects under this\napproach. First, we explore the consequences of repeating pre-training data,\nrevealing that the model is susceptible to overfitting, leading to multi-epoch\ndegradation. Second, we examine the key factors contributing to multi-epoch\ndegradation, finding that significant factors include dataset size, model\nparameters, and training objectives, while less influential factors consist of\ndataset quality and model FLOPs. Finally, we explore whether widely used\nregularization can alleviate multi-epoch degradation. Most regularization\ntechniques do not yield significant improvements, except for dropout, which\ndemonstrates remarkable effectiveness but requires careful tuning when scaling\nup the model size. Additionally, we discover that leveraging mixture-of-experts\n(MoE) enables cost-effective and efficient hyper-parameter tuning for\ncomputationally intensive dense LLMs with comparable trainable parameters,\npotentially impacting efficient LLM development on a broader scale.", "published": "2023-05-22 17:02:15", "link": "http://arxiv.org/abs/2305.13230v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Measuring Inductive Biases of In-Context Learning with Underspecified\n  Demonstrations", "abstract": "In-context learning (ICL) is an important paradigm for adapting large\nlanguage models (LLMs) to new tasks, but the generalization behavior of ICL\nremains poorly understood. We investigate the inductive biases of ICL from the\nperspective of feature bias: which feature ICL is more likely to use given a\nset of underspecified demonstrations in which two features are equally\npredictive of the labels. First, we characterize the feature biases of GPT-3\nmodels by constructing underspecified demonstrations from a range of NLP\ndatasets and feature combinations. We find that LLMs exhibit clear feature\nbiases - for example, demonstrating a strong bias to predict labels according\nto sentiment rather than shallow lexical features, like punctuation. Second, we\nevaluate the effect of different interventions that are designed to impose an\ninductive bias in favor of a particular feature, such as adding a natural\nlanguage instruction or using semantically relevant label words. We find that,\nwhile many interventions can influence the learner to prefer a particular\nfeature, it can be difficult to overcome strong prior biases. Overall, our\nresults provide a broader picture of the types of features that ICL may be more\nlikely to exploit and how to impose inductive biases that are better aligned\nwith the intended task.", "published": "2023-05-22 17:56:31", "link": "http://arxiv.org/abs/2305.13299v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modular Domain Adaptation for Conformer-Based Streaming ASR", "abstract": "Speech data from different domains has distinct acoustic and linguistic\ncharacteristics. It is common to train a single multidomain model such as a\nConformer transducer for speech recognition on a mixture of data from all\ndomains. However, changing data in one domain or adding a new domain would\nrequire the multidomain model to be retrained. To this end, we propose a\nframework called modular domain adaptation (MDA) that enables a single model to\nprocess multidomain data while keeping all parameters domain-specific, i.e.,\neach parameter is only trained by data from one domain. On a streaming\nConformer transducer trained only on video caption data, experimental results\nshow that an MDA-based model can reach similar performance as the multidomain\nmodel on other domains such as voice search and dictation by adding per-domain\nadapters and per-domain feed-forward networks in the Conformer encoder.", "published": "2023-05-22 18:49:35", "link": "http://arxiv.org/abs/2305.13408v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multimodal Automated Fact-Checking: A Survey", "abstract": "Misinformation is often conveyed in multiple modalities, e.g. a miscaptioned\nimage. Multimodal misinformation is perceived as more credible by humans, and\nspreads faster than its text-only counterparts. While an increasing body of\nresearch investigates automated fact-checking (AFC), previous surveys mostly\nfocus on text. In this survey, we conceptualise a framework for AFC including\nsubtasks unique to multimodal misinformation. Furthermore, we discuss related\nterms used in different communities and map them to our framework. We focus on\nfour modalities prevalent in real-world fact-checking: text, image, audio, and\nvideo. We survey benchmarks and models, and discuss limitations and promising\ndirections for future research", "published": "2023-05-22 21:52:24", "link": "http://arxiv.org/abs/2305.13507v3", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken\n  Language Understanding", "abstract": "Recently, large pretrained language models have demonstrated strong language\nunderstanding capabilities. This is particularly reflected in their zero-shot\nand in-context learning abilities on downstream tasks through prompting. To\nassess their impact on spoken language understanding (SLU), we evaluate several\nsuch models like ChatGPT and OPT of different sizes on multiple benchmarks. We\nverify the emergent ability unique to the largest models as they can reach\nintent classification accuracy close to that of supervised models with zero or\nfew shots on various languages given oracle transcripts. By contrast, the\nresults for smaller models fitting a single GPU fall far behind. We note that\nthe error cases often arise from the annotation scheme of the dataset;\nresponses from ChatGPT are still reasonable. We show, however, that the model\nis worse at slot filling, and its performance is sensitive to ASR errors,\nsuggesting serious challenges for the application of those textual models on\nSLU.", "published": "2023-05-22 21:59:26", "link": "http://arxiv.org/abs/2305.13512v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Scaling Speech Technology to 1,000+ Languages", "abstract": "Expanding the language coverage of speech technology has the potential to\nimprove access to information for many more people. However, current speech\ntechnology is restricted to about one hundred languages which is a small\nfraction of the over 7,000 languages spoken around the world. The Massively\nMultilingual Speech (MMS) project increases the number of supported languages\nby 10-40x, depending on the task. The main ingredients are a new dataset based\non readings of publicly available religious texts and effectively leveraging\nself-supervised learning. We built pre-trained wav2vec 2.0 models covering\n1,406 languages, a single multilingual automatic speech recognition model for\n1,107 languages, speech synthesis models for the same number of languages, as\nwell as a language identification model for 4,017 languages. Experiments show\nthat our multilingual speech recognition model more than halves the word error\nrate of Whisper on 54 languages of the FLEURS benchmark while being trained on\na small fraction of the labeled data.", "published": "2023-05-22 22:09:41", "link": "http://arxiv.org/abs/2305.13516v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation", "abstract": "In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.", "published": "2023-05-22 17:36:14", "link": "http://arxiv.org/abs/2305.14386v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AlpacaFarm: A Simulation Framework for Methods that Learn from Human\n  Feedback", "abstract": "Large language models (LLMs) such as ChatGPT have seen widespread adoption\ndue to their strong instruction-following abilities. Developing these LLMs\ninvolves a complex yet poorly understood workflow requiring training with human\nfeedback. Replicating and understanding this instruction-following requires\ntackling three major challenges: the high cost of data collection, the lack of\ntrustworthy evaluation, and the absence of reference method implementations. We\naddress these challenges with AlpacaFarm, a simulator that enables research and\ndevelopment for learning from feedback at a low cost. First, we design LLM\nprompts to simulate human feedback that are 50x cheaper than crowdworkers and\ndisplay high agreement with humans. Second, we propose an automatic evaluation\nand validate it against human instructions obtained on real-world interactions.\nThird, we contribute reference implementations for several methods (PPO, DPO,\nbest-of-n, expert iteration, and more) that learn from pairwise feedback.\nFinally, as an end-to-end validation of AlpacaFarm, we train and evaluate\neleven models on 10k pairs of real human feedback and show that rankings of\nmodels trained in AlpacaFarm match rankings of models trained on human data. As\na demonstration of the research possible in AlpacaFarm, we find that methods\nthat use a reward model can substantially improve over supervised fine-tuning\nand that our reference PPO implementation leads to a +10% improvement in\nwin-rate against Davinci003. We release all components of AlpacaFarm at\nhttps://github.com/tatsu-lab/alpaca_farm.", "published": "2023-05-22 17:55:50", "link": "http://arxiv.org/abs/2305.14387v4", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Text Generation with Speech Synthesis for ASR Data Augmentation", "abstract": "Aiming at reducing the reliance on expensive human annotations, data\nsynthesis for Automatic Speech Recognition (ASR) has remained an active area of\nresearch. While prior work mainly focuses on synthetic speech generation for\nASR data augmentation, its combination with text generation methods is\nconsiderably less explored. In this work, we explore text augmentation for ASR\nusing large-scale pre-trained neural networks, and systematically compare those\nto traditional text augmentation methods. The generated synthetic texts are\nthen converted to synthetic speech using a text-to-speech (TTS) system and\nadded to the ASR training data. In experiments conducted on three datasets, we\nfind that neural models achieve 9%-15% relative WER improvement and outperform\ntraditional methods. We conclude that text augmentation, particularly through\nmodern neural approaches, is a viable tool for improving the accuracy of ASR\nsystems.", "published": "2023-05-22 18:45:20", "link": "http://arxiv.org/abs/2305.16333v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Automated Feedback Generation for a Chemistry Database and Abstracting\n  Exercise", "abstract": "Timely feedback is an important part of teaching and learning. Here we\ndescribe how a readily available neural network transformer (machine-learning)\nmodel (BERT) can be used to give feedback on the structure of the response to\nan abstracting exercise where students are asked to summarise the contents of a\npublished article after finding it from a publication database. The dataset\ncontained 207 submissions from two consecutive years of the course, summarising\na total of 21 different papers from the primary literature. The model was\npre-trained using an available dataset (approx. 15,000 samples) and then\nfine-tuned on 80% of the submitted dataset. This fine tuning was seen to be\nimportant. The sentences in the student submissions are characterised into\nthree classes - background, technique and observation - which allows a\ncomparison of how each submission is structured. Comparing the structure of the\nstudents' abstract a large collection of those from the PubMed database shows\nthat students in this exercise concentrate more on the background to the paper\nand less on the techniques and results than the abstracts to papers themselves.\nThe results allowed feedback for each submitted assignment to be automatically\ngenerated.", "published": "2023-05-22 15:04:26", "link": "http://arxiv.org/abs/2305.18319v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cognitive network science reveals bias in GPT-3, ChatGPT, and GPT-4\n  mirroring math anxiety in high-school students", "abstract": "Large language models are becoming increasingly integrated into our lives.\nHence, it is important to understand the biases present in their outputs in\norder to avoid perpetuating harmful stereotypes, which originate in our own\nflawed ways of thinking. This challenge requires developing new benchmarks and\nmethods for quantifying affective and semantic bias, keeping in mind that LLMs\nact as psycho-social mirrors that reflect the views and tendencies that are\nprevalent in society. One such tendency that has harmful negative effects is\nthe global phenomenon of anxiety toward math and STEM subjects. Here, we\ninvestigate perceptions of math and STEM fields provided by cutting-edge\nlanguage models, namely GPT-3, Chat-GPT, and GPT-4, by applying an approach\nfrom network science and cognitive psychology. Specifically, we use behavioral\nforma mentis networks (BFMNs) to understand how these LLMs frame math and STEM\ndisciplines in relation to other concepts. We use data obtained by probing the\nthree LLMs in a language generation task that has previously been applied to\nhumans. Our findings indicate that LLMs have an overall negative perception of\nmath and STEM fields, with math being perceived most negatively. We observe\nsignificant differences across the three LLMs. We observe that newer versions\n(i.e. GPT-4) produce richer, more complex perceptions as well as less negative\nperceptions compared to older versions and N=159 high-school students. These\nfindings suggest that advances in the architecture of LLMs may lead to\nincreasingly less biased models that could even perhaps someday aid in reducing\nharmful stereotypes in society rather than perpetuating them.", "published": "2023-05-22 15:06:51", "link": "http://arxiv.org/abs/2305.18320v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Fairness of ChatGPT", "abstract": "Understanding and addressing unfairness in LLMs are crucial for responsible\nAI deployment. However, there is a limited number of quantitative analyses and\nin-depth studies regarding fairness evaluations in LLMs, especially when\napplying LLMs to high-stakes fields. This work aims to fill this gap by\nproviding a systematic evaluation of the effectiveness and fairness of LLMs\nusing ChatGPT as a study case. We focus on assessing ChatGPT's performance in\nhigh-takes fields including education, criminology, finance and healthcare. To\nconduct a thorough evaluation, we consider both group fairness and individual\nfairness metrics. We also observe the disparities in ChatGPT's outputs under a\nset of biased or unbiased prompts. This work contributes to a deeper\nunderstanding of LLMs' fairness performance, facilitates bias mitigation and\nfosters the development of responsible AI systems.", "published": "2023-05-22 17:51:56", "link": "http://arxiv.org/abs/2305.18569v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Preconditioned Visual Language Inference with Weak Supervision", "abstract": "Humans can infer the affordance of objects by extracting related contextual\npreconditions for each scenario. For example, upon seeing an image of a broken\ncup, we can infer that this precondition prevents the cup from being used for\ndrinking. Reasoning with preconditions of commonsense is studied in NLP where\nthe model explicitly gets the contextual precondition. However, it is unclear\nif SOTA visual language models (VLMs) can extract such preconditions and infer\nthe affordance of objects with them. In this work, we introduce the task of\npreconditioned visual language inference and rationalization (PVLIR). We\npropose a learning resource based on three strategies to retrieve weak\nsupervision signals for the task and develop a human-verified test set for\nevaluation. Our results reveal the shortcomings of SOTA VLM models in the task\nand draw a road map to address the challenges ahead in improving them.", "published": "2023-05-22 16:57:52", "link": "http://arxiv.org/abs/2306.01753v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "FACTIFY3M: A Benchmark for Multimodal Fact Verification with\n  Explainability through 5W Question-Answering", "abstract": "Combating disinformation is one of the burning societal crises -- about 67%\nof the American population believes that disinformation produces a lot of\nuncertainty, and 10% of them knowingly propagate disinformation. Evidence shows\nthat disinformation can manipulate democratic processes and public opinion,\ncausing disruption in the share market, panic and anxiety in society, and even\ndeath during crises. Therefore, disinformation should be identified promptly\nand, if possible, mitigated. With approximately 3.2 billion images and 720,000\nhours of video shared online daily on social media platforms, scalable\ndetection of multimodal disinformation requires efficient fact verification.\nDespite progress in automatic text-based fact verification (e.g., FEVER, LIAR),\nthe research community lacks substantial effort in multimodal fact\nverification. To address this gap, we introduce FACTIFY 3M, a dataset of 3\nmillion samples that pushes the boundaries of the domain of fact verification\nvia a multimodal fake news dataset, in addition to offering explainability\nthrough the concept of 5W question-answering. Salient features of the dataset\ninclude: (i) textual claims, (ii) ChatGPT-generated paraphrased claims, (iii)\nassociated images, (iv) stable diffusion-generated additional images (i.e.,\nvisual paraphrases), (v) pixel-level image heatmap to foster image-text\nexplainability of the claim, (vi) 5W QA pairs, and (vii) adversarial fake news\nstories.", "published": "2023-05-22 08:29:47", "link": "http://arxiv.org/abs/2306.05523v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Evaluating Prompt-based Question Answering for Object Prediction in the\n  Open Research Knowledge Graph", "abstract": "There have been many recent investigations into prompt-based training of\ntransformer language models for new text genres in low-resource settings. The\nprompt-based training approach has been found to be effective in generalizing\npre-trained or fine-tuned models for transfer to resource-scarce settings. This\nwork, for the first time, reports results on adopting prompt-based training of\ntransformers for \\textit{scholarly knowledge graph object prediction}. The work\nis unique in the following two main aspects. 1) It deviates from the other\nworks proposing entity and relation extraction pipelines for predicting objects\nof a scholarly knowledge graph. 2) While other works have tested the method on\ntext genera relatively close to the general knowledge domain, we test the\nmethod for a significantly different domain, i.e. scholarly knowledge, in turn\ntesting the linguistic, probabilistic, and factual generalizability of these\nlarge-scale transformer models. We find that (i) per expectations, transformer\nmodels when tested out-of-the-box underperform on a new domain of data, (ii)\nprompt-based training of the models achieve performance boosts of up to 40\\% in\na relaxed evaluation setting, and (iii) testing the models on a starkly\ndifferent domain even with a clever training objective in a low resource\nsetting makes evident the domain knowledge capture gap offering an\nempirically-verified incentive for investing more attention and resources to\nthe scholarly domain in the context of transformer models.", "published": "2023-05-22 10:35:18", "link": "http://arxiv.org/abs/2305.12900v2", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Making Language Models Better Tool Learners with Execution Feedback", "abstract": "Tools serve as pivotal interfaces that enable humans to understand and\nreshape the environment. With the advent of foundation models, AI systems can\nutilize tools to expand their capabilities and interact with the real world.\nExisting tool learning methodologies, encompassing supervised fine-tuning and\nprompt engineering approaches, often induce large language models to utilize\ntools indiscriminately, as complex tasks often exceed their own competencies.\nHowever, introducing tools for simple tasks, which the models themselves can\nreadily resolve, can inadvertently propagate errors rather than enhance\nperformance. This leads to the research question: can we teach language models\nwhen and how to use tools? To meet this need, we propose Tool leaRning wIth\nexeCution fEedback (TRICE), a two-stage end-to-end framework that enables the\nmodel to continually learn through feedback derived from tool execution,\nthereby learning when and how to use tools effectively. Experimental results,\nbacked by further analysis, show that TRICE can make the large language model\nselectively use tools by improving the accuracy of tool usage while enhancing\ninsufficient tool learning and mitigating excessive reliance on tools. Code is\navailable at https://github.com/zjunlp/TRICE.", "published": "2023-05-22 14:37:05", "link": "http://arxiv.org/abs/2305.13068v3", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Observations on LLMs for Telecom Domain: Capabilities and Limitations", "abstract": "The landscape for building conversational interfaces (chatbots) has witnessed\na paradigm shift with recent developments in generative Artificial Intelligence\n(AI) based Large Language Models (LLMs), such as ChatGPT by OpenAI (GPT3.5 and\nGPT4), Google's Bard, Large Language Model Meta AI (LLaMA), among others. In\nthis paper, we analyze capabilities and limitations of incorporating such\nmodels in conversational interfaces for the telecommunication domain,\nspecifically for enterprise wireless products and services. Using Cradlepoint's\npublicly available data for our experiments, we present a comparative analysis\nof the responses from such models for multiple use-cases including domain\nadaptation for terminology and product taxonomy, context continuity, robustness\nto input perturbations and errors. We believe this evaluation would provide\nuseful insights to data scientists engaged in building customized\nconversational interfaces for domain-specific requirements.", "published": "2023-05-22 15:04:16", "link": "http://arxiv.org/abs/2305.13102v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.IR", "cs.LG", "68T50"], "primary_category": "cs.HC"}
{"title": "LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities\n  and Future Opportunities", "abstract": "This paper presents an exhaustive quantitative and qualitative evaluation of\nLarge Language Models (LLMs) for Knowledge Graph (KG) construction and\nreasoning. We engage in experiments across eight diverse datasets, focusing on\nfour representative tasks encompassing entity and relation extraction, event\nextraction, link prediction, and question-answering, thereby thoroughly\nexploring LLMs' performance in the domain of construction and inference.\nEmpirically, our findings suggest that LLMs, represented by GPT-4, are more\nsuited as inference assistants rather than few-shot information extractors.\nSpecifically, while GPT-4 exhibits good performance in tasks related to KG\nconstruction, it excels further in reasoning tasks, surpassing fine-tuned\nmodels in certain cases. Moreover, our investigation extends to the potential\ngeneralization ability of LLMs for information extraction, leading to the\nproposition of a Virtual Knowledge Extraction task and the development of the\ncorresponding VINE dataset. Based on these empirical findings, we further\npropose AutoKG, a multi-agent-based approach employing LLMs and external\nsources for KG construction and reasoning. We anticipate that this research can\nprovide invaluable insights for future undertakings in the field of knowledge\ngraphs. The code and datasets are in https://github.com/zjunlp/AutoKG.", "published": "2023-05-22 15:56:44", "link": "http://arxiv.org/abs/2305.13168v4", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Editing Large Language Models: Problems, Methods, and Opportunities", "abstract": "Despite the ability to train capable LLMs, the methodology for maintaining\ntheir relevancy and rectifying errors remains elusive. To this end, the past\nfew years have witnessed a surge in techniques for editing LLMs, the objective\nof which is to efficiently alter the behavior of LLMs within a specific domain\nwithout negatively impacting performance across other inputs. This paper\nembarks on a deep exploration of the problems, methods, and opportunities\nrelated to model editing for LLMs. In particular, we provide an exhaustive\noverview of the task definition and challenges associated with model editing,\nalong with an in-depth empirical analysis of the most progressive methods\ncurrently at our disposal. We also build a new benchmark dataset to facilitate\na more robust evaluation and pinpoint enduring issues intrinsic to existing\ntechniques. Our objective is to provide valuable insights into the\neffectiveness and feasibility of each editing technique, thereby assisting the\ncommunity in making informed decisions on the selection of the most appropriate\nmethod for a specific task or context. Code and datasets are available at\nhttps://github.com/zjunlp/EasyEdit.", "published": "2023-05-22 16:00:00", "link": "http://arxiv.org/abs/2305.13172v3", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Flover: A Temporal Fusion Framework for Efficient Autoregressive Model\n  Parallel Inference", "abstract": "Autoregressive models, despite their commendable performance in a myriad of\ngenerative tasks, face challenges stemming from their inherently sequential\nstructure. Inference on these models, by design, harnesses a temporal\ndependency, where the current token's probability distribution is conditioned\non preceding tokens. This inherent characteristic severely impedes\ncomputational efficiency during inference as a typical inference request can\nrequire more than thousands of tokens, where generating each token requires a\nload of entire model weights, making the inference more memory-bound. The large\noverhead becomes profound in real deployment where requests arrive randomly,\nnecessitating various generation lengths. Existing solutions, such as dynamic\nbatching and concurrent instances, introduce significant response delays and\nbandwidth contention, falling short of achieving optimal latency and\nthroughput. To address these shortcomings, we propose Flover -- a temporal\nfusion framework for efficiently inferring multiple requests in parallel. We\ndeconstruct the general generation pipeline into pre-processing and token\ngeneration, and equip the framework with a dedicated work scheduler for fusing\nthe generation process temporally across all requests. By orchestrating the\ntoken-level parallelism, Flover exhibits optimal hardware efficiency and\nsignificantly spares the system resources. By further employing a fast buffer\nreordering algorithm that allows memory eviction of finished tasks, it brings\nover 11x inference speedup on GPT and 16x on LLAMA compared to the cutting-edge\nsolutions provided by NVIDIA FasterTransformer. Crucially, by leveraging the\nadvanced tensor parallel technique, Flover proves efficacious across diverse\ncomputational landscapes, from single-GPU setups to distributed scenarios,\nthereby offering robust performance optimization that adapts to variable use\ncases.", "published": "2023-05-22 20:58:09", "link": "http://arxiv.org/abs/2305.13484v3", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.DC"}
{"title": "NAS-FM: Neural Architecture Search for Tunable and Interpretable Sound\n  Synthesis based on Frequency Modulation", "abstract": "Developing digital sound synthesizers is crucial to the music industry as it\nprovides a low-cost way to produce high-quality sounds with rich timbres.\nExisting traditional synthesizers often require substantial expertise to\ndetermine the overall framework of a synthesizer and the parameters of\nsubmodules. Since expert knowledge is hard to acquire, it hinders the\nflexibility to quickly design and tune digital synthesizers for diverse sounds.\nIn this paper, we propose ``NAS-FM'', which adopts neural architecture search\n(NAS) to build a differentiable frequency modulation (FM) synthesizer. Tunable\nsynthesizers with interpretable controls can be developed automatically from\nsounds without any prior expert knowledge and manual operating costs. In\ndetail, we train a supernet with a specifically designed search space,\nincluding predicting the envelopes of carriers and modulators with different\nfrequency ratios. An evolutionary search algorithm with adaptive oscillator\nsize is then developed to find the optimal relationship between oscillators and\nthe frequency ratio of FM. Extensive experiments on recordings of different\ninstrument sounds show that our algorithm can build a synthesizer fully\nautomatically, achieving better results than handcrafted synthesizers. Audio\nsamples are available at https://nas-fm.github.io/.", "published": "2023-05-22 09:46:10", "link": "http://arxiv.org/abs/2305.12868v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The HCCL system for VoxCeleb Speaker Recognition Challenge 2022", "abstract": "This report describes our submission to track1 and track3 for VoxCeleb\nSpeaker Recognition Challenge 2022(VoxSRC2022). Our best system achieves minDCF\n0.1397 and EER 2.414 in track1, minDCF 0.388 and EER 7.030 in track3.", "published": "2023-05-22 02:32:34", "link": "http://arxiv.org/abs/2305.12642v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer", "abstract": "Text-to-speech(TTS) has undergone remarkable improvements in performance,\nparticularly with the advent of Denoising Diffusion Probabilistic Models\n(DDPMs). However, the perceived quality of audio depends not solely on its\ncontent, pitch, rhythm, and energy, but also on the physical environment. In\nthis work, we propose ViT-TTS, the first visual TTS model with scalable\ndiffusion transformers. ViT-TTS complement the phoneme sequence with the visual\ninformation to generate high-perceived audio, opening up new avenues for\npractical applications of AR and VR to allow a more immersive and realistic\naudio experience. To mitigate the data scarcity in learning visual acoustic\ninformation, we 1) introduce a self-supervised learning framework to enhance\nboth the visual-text encoder and denoiser decoder; 2) leverage the diffusion\ntransformer scalable in terms of parameters and capacity to learn visual scene\ninformation. Experimental results demonstrate that ViT-TTS achieves new\nstate-of-the-art results, outperforming cascaded systems and other baselines\nregardless of the visibility of the scene. With low-resource data (1h, 2h, 5h),\nViT-TTS achieves comparative results with rich-resource\nbaselines.~\\footnote{Audio samples are available at\n\\url{https://ViT-TTS.github.io/.}}", "published": "2023-05-22 04:37:41", "link": "http://arxiv.org/abs/2305.12708v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Target Active Speaker Detection with Audio-visual Cues", "abstract": "In active speaker detection (ASD), we would like to detect whether an\non-screen person is speaking based on audio-visual cues. Previous studies have\nprimarily focused on modeling audio-visual synchronization cue, which depends\non the video quality of the lip region of a speaker. In real-world\napplications, it is possible that we can also have the reference speech of the\non-screen speaker. To benefit from both facial cue and reference speech, we\npropose the Target Speaker TalkNet (TS-TalkNet), which leverages a pre-enrolled\nspeaker embedding to complement the audio-visual synchronization cue in\ndetecting whether the target speaker is speaking. Our framework outperforms the\npopular model, TalkNet on two datasets, achieving absolute improvements of 1.6%\nin mAP on the AVA-ActiveSpeaker validation set, and 0.8%, 0.4%, and 0.8% in\nterms of AP, AUC and EER on the ASW test set, respectively. Code is available\nat https://github.com/Jiang-Yidi/TS-TalkNet/.", "published": "2023-05-22 08:52:42", "link": "http://arxiv.org/abs/2305.12831v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Enhanced Res2Net with Local and Global Feature Fusion for Speaker\n  Verification", "abstract": "Effective fusion of multi-scale features is crucial for improving speaker\nverification performance. While most existing methods aggregate multi-scale\nfeatures in a layer-wise manner via simple operations, such as summation or\nconcatenation. This paper proposes a novel architecture called Enhanced Res2Net\n(ERes2Net), which incorporates both local and global feature fusion techniques\nto improve the performance. The local feature fusion (LFF) fuses the features\nwithin one single residual block to extract the local signal. The global\nfeature fusion (GFF) takes acoustic features of different scales as input to\naggregate global signal. To facilitate effective feature fusion in both LFF and\nGFF, an attentional feature fusion module is employed in the ERes2Net\narchitecture, replacing summation or concatenation operations. A range of\nexperiments conducted on the VoxCeleb datasets demonstrate the superiority of\nthe ERes2Net in speaker verification. Code has been made publicly available at\nhttps://github.com/alibaba-damo-academy/3D-Speaker.", "published": "2023-05-22 09:01:23", "link": "http://arxiv.org/abs/2305.12838v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech", "abstract": "Deep learning has led to considerable advances in text-to-speech synthesis.\nMost recently, the adoption of Score-based Generative Models (SGMs), also known\nas Diffusion Probabilistic Models (DPMs), has gained traction due to their\nability to produce high-quality synthesized neural speech in neural speech\nsynthesis systems. In SGMs, the U-Net architecture and its variants have long\ndominated as the backbone since its first successful adoption. In this\nresearch, we mainly focus on the neural network in diffusion-model-based\nText-to-Speech (TTS) systems and propose the U-DiT architecture, exploring the\npotential of vision transformer architecture as the core component of the\ndiffusion models in a TTS system. The modular design of the U-DiT architecture,\ninherited from the best parts of U-Net and ViT, allows for great scalability\nand versatility across different data scales. The proposed U-DiT TTS system is\na mel spectrogram-based acoustic model and utilizes a pretrained HiFi-GAN as\nthe vocoder. The objective (ie Frechet distance) and MOS results show that our\nDiT-TTS system achieves state-of-art performance on the single speaker dataset\nLJSpeech. Our demos are publicly available at:\nhttps://eihw.github.io/u-dit-tts/", "published": "2023-05-22 16:25:19", "link": "http://arxiv.org/abs/2305.13195v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "More Perspectives Mean Better: Underwater Target Recognition and\n  Localization with Multimodal Data via Symbiotic Transformer and Multiview\n  Regression", "abstract": "Underwater acoustic target recognition (UATR) and localization (UATL) play\nimportant roles in marine exploration. The highly noisy acoustic signal and\ntime-frequency interference among various sources pose big challenges to this\ntask. To tackle these issues, we propose a multimodal approach to extract and\nfuse audio-visual-textual information to recognize and localize underwater\ntargets through the designed Symbiotic Transformer (Symb-Trans) and Multi-View\nRegression (MVR) method. The multimodal data were first preprocessed by a\ncustom-designed HetNorm module to normalize the multi-source data in a common\nfeature space. The Symb-Trans module embeds audiovisual features by co-training\nthe preprocessed multimodal features through parallel branches and a content\nencoder with cross-attention. The audiovisual features are then used for\nunderwater target recognition. Meanwhile, the text embedding combined with the\naudiovisual features is fed to an MVR module to predict the localization of the\nunderwater targets through multi-view clustering and multiple regression. Since\nno off-the-shell multimodal dataset is available for UATR and UATL, we combined\nmultiple public datasets, consisting of acoustic, and/or visual, and/or\ntextural data, to obtain audio-visual-textual triplets for model training and\nvalidation. Experiments show that our model outperforms comparative methods in\n91.7% (11 out of 12 metrics) and 100% (4 metrics) of the quantitative metrics\nfor the recognition and localization tasks, respectively. In a case study, we\ndemonstrate the advantages of multi-view models in establishing sample\ndiscriminability through visualization methods. For UATL, the proposed MVR\nmethod produces the relation graphs, which allow predictions based on records\nof underwater targets with similar conditions.", "published": "2023-05-22 04:16:28", "link": "http://arxiv.org/abs/2305.12701v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Progressive Sub-Graph Clustering Algorithm for Semi-Supervised Domain\n  Adaptation Speaker Verification", "abstract": "Utilizing the large-scale unlabeled data from the target domain via\npseudo-label clustering algorithms is an important approach for addressing\ndomain adaptation problems in speaker verification tasks. In this paper, we\npropose a novel progressive subgraph clustering algorithm based on multi-model\nvoting and double-Gaussian based assessment (PGMVG clustering). To fully\nexploit the relationships among utterances and the complementarity among\nmultiple models, our method constructs multiple k-nearest neighbors graphs\nbased on diverse models and generates high-confidence edges using a voting\nmechanism. Further, to maximize the intra-class diversity, the connected\nsubgraph is utilized to obtain the initial pseudo-labels. Finally, to prevent\ndisastrous clustering results, we adopt an iterative approach that\nprogressively increases k and employs a double-Gaussian based assessment\nalgorithm to decide whether merging sub-classes.", "published": "2023-05-22 04:26:18", "link": "http://arxiv.org/abs/2305.12703v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LEAN: Light and Efficient Audio Classification Network", "abstract": "Over the past few years, audio classification task on large-scale dataset\nsuch as AudioSet has been an important research area. Several deeper\nConvolution-based Neural networks have shown compelling performance notably\nVggish, YAMNet, and Pretrained Audio Neural Network (PANN). These models are\navailable as pretrained architecture for transfer learning as well as specific\naudio task adoption. In this paper, we propose a lightweight on-device deep\nlearning-based model for audio classification, LEAN. LEAN consists of a raw\nwaveform-based temporal feature extractor called as Wave Encoder and\nlogmel-based Pretrained YAMNet. We show that using a combination of trainable\nwave encoder, Pretrained YAMNet along with cross attention-based temporal\nrealignment, results in competitive performance on downstream audio\nclassification tasks with lesser memory footprints and hence making it suitable\nfor resource constraints devices such as mobile, edge devices, etc . Our\nproposed system achieves on-device mean average precision(mAP) of .445 with a\nmemory footprint of a mere 4.5MB on the FSD50K dataset which is an improvement\nof 22% over baseline on-device mAP on same dataset.", "published": "2023-05-22 04:45:04", "link": "http://arxiv.org/abs/2305.12712v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Coswara: A respiratory sounds and symptoms dataset for remote screening\n  of SARS-CoV-2 infection", "abstract": "This paper presents the Coswara dataset, a dataset containing diverse set of\nrespiratory sounds and rich meta-data, recorded between April-2020 and\nFebruary-2022 from 2635 individuals (1819 SARS-CoV-2 negative, 674 positive,\nand 142 recovered subjects). The respiratory sounds contained nine sound\ncategories associated with variants of breathing, cough and speech. The rich\nmetadata contained demographic information associated with age, gender and\ngeographic location, as well as the health information relating to the\nsymptoms, pre-existing respiratory ailments, comorbidity and SARS-CoV-2 test\nstatus. Our study is the first of its kind to manually annotate the audio\nquality of the entire dataset (amounting to 65~hours) through manual listening.\nThe paper summarizes the data collection procedure, demographic, symptoms and\naudio data information. A COVID-19 classifier based on bi-directional long\nshort-term (BLSTM) architecture, is trained and evaluated on the different\npopulation sub-groups contained in the dataset to understand the bias/fairness\nof the model. This enabled the analysis of the impact of gender, geographic\nlocation, date of recording, and language proficiency on the COVID-19 detection\nperformance.", "published": "2023-05-22 06:09:10", "link": "http://arxiv.org/abs/2305.12741v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "q-bio.QM"], "primary_category": "eess.AS"}
{"title": "The defender's perspective on automatic speaker verification: An\n  overview", "abstract": "Automatic speaker verification (ASV) plays a critical role in\nsecurity-sensitive environments. Regrettably, the reliability of ASV has been\nundermined by the emergence of spoofing attacks, such as replay and synthetic\nspeech, as well as adversarial attacks and the relatively new partially fake\nspeech. While there are several review papers that cover replay and synthetic\nspeech, and adversarial attacks, there is a notable gap in a comprehensive\nreview that addresses defense against adversarial attacks and the recently\nemerged partially fake speech. Thus, the aim of this paper is to provide a\nthorough and systematic overview of the defense methods used against these\ntypes of attacks.", "published": "2023-05-22 08:01:59", "link": "http://arxiv.org/abs/2305.12804v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ZS-MSTM: Zero-Shot Style Transfer for Gesture Animation driven by Text\n  and Speech using Adversarial Disentanglement of Multimodal Style Encoding", "abstract": "In this study, we address the importance of modeling behavior style in\nvirtual agents for personalized human-agent interaction. We propose a machine\nlearning approach to synthesize gestures, driven by prosodic features and text,\nin the style of different speakers, even those unseen during training. Our\nmodel incorporates zero-shot multimodal style transfer using multimodal data\nfrom the PATS database, which contains videos of diverse speakers. We recognize\nstyle as a pervasive element during speech, influencing the expressivity of\ncommunicative behaviors, while content is conveyed through multimodal signals\nand text. By disentangling content and style, we directly infer the style\nembedding, even for speakers not included in the training phase, without the\nneed for additional training or fine-tuning. Objective and subjective\nevaluations are conducted to validate our approach and compare it against two\nbaseline methods.", "published": "2023-05-22 10:10:35", "link": "http://arxiv.org/abs/2305.12887v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards generalizing deep-audio fake detection networks", "abstract": "Today's generative neural networks allow the creation of high-quality\nsynthetic speech at scale. While we welcome the creative use of this new\ntechnology, we must also recognize the risks. As synthetic speech is abused for\nmonetary and identity theft, we require a broad set of deepfake identification\ntools. Furthermore, previous work reported a limited ability of deep\nclassifiers to generalize to unseen audio generators. We study the frequency\ndomain fingerprints of current audio generators. Building on top of the\ndiscovered frequency footprints, we train excellent lightweight detectors that\ngeneralize. We report improved results on the WaveFake dataset and an extended\nversion. To account for the rapid progress in the field, we extend the WaveFake\ndataset by additionally considering samples drawn from the novel Avocodo and\nBigVGAN networks. For illustration purposes, the supplementary material\ncontains audio samples of generator artifacts.", "published": "2023-05-22 13:37:52", "link": "http://arxiv.org/abs/2305.13033v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AudioToken: Adaptation of Text-Conditioned Diffusion Models for\n  Audio-to-Image Generation", "abstract": "In recent years, image generation has shown a great leap in performance,\nwhere diffusion models play a central role. Although generating high-quality\nimages, such models are mainly conditioned on textual descriptions. This begs\nthe question: \"how can we adopt such models to be conditioned on other\nmodalities?\". In this paper, we propose a novel method utilizing latent\ndiffusion models trained for text-to-image-generation to generate images\nconditioned on audio recordings. Using a pre-trained audio encoding model, the\nproposed method encodes audio into a new token, which can be considered as an\nadaptation layer between the audio and text representations. Such a modeling\nparadigm requires a small number of trainable parameters, making the proposed\napproach appealing for lightweight optimization. Results suggest the proposed\nmethod is superior to the evaluated baseline methods, considering objective and\nsubjective metrics. Code and samples are available at:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/AudioToken.", "published": "2023-05-22 14:02:44", "link": "http://arxiv.org/abs/2305.13050v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning to detect an animal sound from five examples", "abstract": "Automatic detection and classification of animal sounds has many applications\nin biodiversity monitoring and animal behaviour. In the past twenty years, the\nvolume of digitised wildlife sound available has massively increased, and\nautomatic classification through deep learning now shows strong results.\nHowever, bioacoustics is not a single task but a vast range of small-scale\ntasks (such as individual ID, call type, emotional indication) with wide\nvariety in data characteristics, and most bioacoustic tasks do not come with\nstrongly-labelled training data. The standard paradigm of supervised learning,\nfocussed on a single large-scale dataset and/or a generic pre-trained\nalgorithm, is insufficient. In this work we recast bioacoustic sound event\ndetection within the AI framework of few-shot learning. We adapt this framework\nto sound event detection, such that a system can be given the annotated\nstart/end times of as few as 5 events, and can then detect events in\nlong-duration audio -- even when the sound category was not known at the time\nof algorithm training. We introduce a collection of open datasets designed to\nstrongly test a system's ability to perform few-shot sound event detections,\nand we present the results of a public contest to address the task. We show\nthat prototypical networks are a strong-performing method, when enhanced with\nadaptations for general characteristics of animal sounds. We demonstrate that\nwidely-varying sound event durations are an important factor in performance, as\nwell as non-stationarity, i.e. gradual changes in conditions throughout the\nduration of a recording. For fine-grained bioacoustic recognition tasks without\nmassive annotated training data, our results demonstrate that few-shot sound\nevent detection is a powerful new method, strongly outperforming traditional\nsignal-processing detection methods in the fully automated scenario.", "published": "2023-05-22 16:43:39", "link": "http://arxiv.org/abs/2305.13210v1", "categories": ["cs.SD", "eess.AS", "q-bio.QM"], "primary_category": "cs.SD"}
{"title": "Modulation Extraction for LFO-driven Audio Effects", "abstract": "Low frequency oscillator (LFO) driven audio effects such as phaser, flanger,\nand chorus, modify an input signal using time-varying filters and delays,\nresulting in characteristic sweeping or widening effects. It has been shown\nthat these effects can be modeled using neural networks when conditioned with\nthe ground truth LFO signal. However, in most cases, the LFO signal is not\naccessible and measurement from the audio signal is nontrivial, hindering the\nmodeling process. To address this, we propose a framework capable of extracting\narbitrary LFO signals from processed audio across multiple digital audio\neffects, parameter settings, and instrument configurations. Since our system\nimposes no restrictions on the LFO signal shape, we demonstrate its ability to\nextract quasiperiodic, combined, and distorted modulation signals that are\nrelevant to effect modeling. Furthermore, we show how coupling the extraction\nmodel with a simple processing network enables training of end-to-end black-box\nmodels of unseen analog or digital LFO-driven audio effects using only dry and\nwet audio pairs, overcoming the need to access the audio effect or internal LFO\nsignal. We make our code available and provide the trained audio effect models\nin a real-time VST plugin.", "published": "2023-05-22 17:33:07", "link": "http://arxiv.org/abs/2305.13262v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Ultrasound Tongue Image prediction from EEG during speech\n  production", "abstract": "Previous initial research has already been carried out to propose\nspeech-based BCI using brain signals (e.g. non-invasive EEG and invasive sEEG /\nECoG), but there is a lack of combined methods that investigate non-invasive\nbrain, articulation, and speech signals together and analyze the cognitive\nprocesses in the brain, the kinematics of the articulatory movement and the\nresulting speech signal. In this paper, we describe our multimodal\n(electroencephalography, ultrasound tongue imaging, and speech) analysis and\nsynthesis experiments, as a feasibility study. We extend the analysis of brain\nsignals recorded during speech production with ultrasound-based articulation\ndata. From the brain signal measured with EEG, we predict ultrasound images of\nthe tongue with a fully connected deep neural network. The results show that\nthere is a weak but noticeable relationship between EEG and ultrasound tongue\nimages, i.e. the network can differentiate articulated speech and neutral\ntongue position.", "published": "2023-05-22 08:23:51", "link": "http://arxiv.org/abs/2306.05374v2", "categories": ["physics.med-ph", "cs.SD", "eess.AS", "eess.IV"], "primary_category": "physics.med-ph"}
{"title": "Connecting Multi-modal Contrastive Representations", "abstract": "Multi-modal Contrastive Representation learning aims to encode different\nmodalities into a semantically aligned shared space. This paradigm shows\nremarkable generalization ability on numerous downstream tasks across various\nmodalities. However, the reliance on massive high-quality data pairs limits its\nfurther development on more modalities. This paper proposes a novel\ntraining-efficient method for learning MCR without paired data called\nConnecting Multi-modal Contrastive Representations (C-MCR). Specifically, given\ntwo existing MCRs pre-trained on (A, B) and (B, C) modality pairs, we project\nthem to a new space and use the data from the overlapping modality B to\naligning the two MCRs in the new space. Meanwhile, since the modality pairs (A,\nB) and (B, C) are already aligned within each MCR, the connection learned by\noverlapping modality can also be transferred to non-overlapping modality pair\n(A, C). To unleash the potential of C-MCR, we further introduce a\nsemantic-enhanced inter- and intra-MCR connection method. We first enhance the\nsemantic consistency and completion of embeddings across different modalities\nfor more robust alignment. Then we utilize the inter-MCR alignment to establish\nthe connection, and employ the intra-MCR alignment to better maintain the\nconnection for inputs from non-overlapping modalities. To demonstrate the\neffectiveness of C-MCR, we connect CLIP and CLAP via texts to derive\naudio-visual representations, and integrate CLIP and ULIP via images for\n3D-language representations. Remarkably, without using any paired data, C-MCR\nfor audio-visual achieves state-of-the-art performance on audio-image\nretrieval, audio-visual source localization, and counterfactual audio-image\nrecognition tasks. Furthermore, C-MCR for 3D-language also attains advanced\nzero-shot 3D point cloud classification accuracy on ModelNet40.", "published": "2023-05-22 09:44:39", "link": "http://arxiv.org/abs/2305.14381v2", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
