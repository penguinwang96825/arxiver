{"title": "ThinkEdit: Interpretable Weight Editing to Mitigate Overly Short Thinking in Reasoning Models", "abstract": "Recent studies have shown that Large Language Models (LLMs) augmented with\nchain-of-thought (CoT) reasoning demonstrate impressive problem-solving\nabilities. However, in this work, we identify a recurring issue where these\nmodels occasionally generate overly short reasoning, leading to degraded\nperformance on even simple mathematical problems. Specifically, we investigate\nhow reasoning length is embedded in the hidden representations of reasoning\nmodels and its impact on accuracy. Our analysis reveals that reasoning length\nis governed by a linear direction in the representation space, allowing us to\ninduce overly short reasoning by steering the model along this direction.\nBuilding on this insight, we introduce ThinkEdit, a simple yet effective\nweight-editing approach to mitigate the issue of overly short reasoning. We\nfirst identify a small subset of attention heads (approximately 2%) that\npredominantly drive short reasoning behavior. We then edit the output\nprojection weights of these heads to suppress the short reasoning direction.\nWith changes to only 0.1% of the model's parameters, ThinkEdit effectively\nreduces overly short reasoning and yields notable accuracy gains for short\nreasoning outputs (+5.44%), along with an overall improvement across multiple\nmath benchmarks (+2.43%). Our findings provide new mechanistic insights into\nhow reasoning length is controlled within LLMs and highlight the potential of\nfine-grained model interventions to improve reasoning quality. Our code is\navailable at https://github.com/Trustworthy-ML-Lab/ThinkEdit", "published": "2025-03-27 23:53:45", "link": "http://arxiv.org/abs/2503.22048v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Risks of Using Large Language Models for Text Annotation in Social Science Research", "abstract": "Generative artificial intelligence (GenAI) or large language models (LLMs)\nhave the potential to revolutionize computational social science, particularly\nin automated textual analysis. In this paper, we conduct a systematic\nevaluation of the promises and risks of using LLMs for diverse coding tasks,\nwith social movement studies serving as a case example. We propose a framework\nfor social scientists to incorporate LLMs into text annotation, either as the\nprimary coding decision-maker or as a coding assistant. This framework provides\ntools for researchers to develop the optimal prompt, and to examine and report\nthe validity and reliability of LLMs as a methodological tool. Additionally, we\ndiscuss the associated epistemic risks related to validity, reliability,\nreplicability, and transparency. We conclude with several practical guidelines\nfor using LLMs in text annotation tasks, and how we can better communicate the\nepistemic risks in research.", "published": "2025-03-27 23:33:36", "link": "http://arxiv.org/abs/2503.22040v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Debate-Driven Multi-Agent LLMs for Phishing Email Detection", "abstract": "Phishing attacks remain a critical cybersecurity threat. Attackers constantly\nrefine their methods, making phishing emails harder to detect. Traditional\ndetection methods, including rule-based systems and supervised machine learning\nmodels, either rely on predefined patterns like blacklists, which can be\nbypassed with slight modifications, or require large datasets for training and\nstill can generate false positives and false negatives. In this work, we\npropose a multi-agent large language model (LLM) prompting technique that\nsimulates debates among agents to detect whether the content presented on an\nemail is phishing. Our approach uses two LLM agents to present arguments for or\nagainst the classification task, with a judge agent adjudicating the final\nverdict based on the quality of reasoning provided. This debate mechanism\nenables the models to critically analyze contextual cue and deceptive patterns\nin text, which leads to improved classification accuracy. The proposed\nframework is evaluated on multiple phishing email datasets and demonstrate that\nmixed-agent configurations consistently outperform homogeneous configurations.\nResults also show that the debate structure itself is sufficient to yield\naccurate decisions without extra prompting strategies.", "published": "2025-03-27 23:18:14", "link": "http://arxiv.org/abs/2503.22038v1", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "ObscuraCoder: Powering Efficient Code LM Pre-Training Via Obfuscation Grounding", "abstract": "Language models (LMs) have become a staple of the code-writing toolbox. Their\npre-training recipe has, however, remained stagnant over recent years, barring\nthe occasional changes in data sourcing and filtering strategies. In\nparticular, research exploring modifications to Code-LMs' pre-training\nobjectives, geared towards improving data efficiency and better disentangling\nbetween syntax and semantics, has been noticeably sparse, especially compared\nwith corresponding efforts in natural language LMs. In this work, we examine\ngrounding on obfuscated code as a means of helping Code-LMs look beyond the\nsurface-form syntax and enhance their pre-training sample efficiency. To this\nend, we compile ObscuraX, a dataset of approximately 55M source and obfuscated\ncode pairs in seven languages. Subsequently, we pre-train ObscuraCoder models,\nranging in size from 255M to 2.8B parameters, on a 272B-token corpus that\nincludes ObscuraX and demonstrate that our obfuscation-based pre-training\nrecipe leads to consistent improvements in Code-LMs' abilities compared to both\nvanilla autoregressive pre-training as well as existing de-obfuscation (DOBF)\nobjectives. ObscuraCoder demonstrates sizeable gains across multiple tests of\nsyntactic and semantic code understanding, along with improved capabilities in\nmultilingual code completion, multilingual code commit summarization, and\nmulti-purpose library-oriented code generation.", "published": "2025-03-27 23:08:53", "link": "http://arxiv.org/abs/2504.00019v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Cognitive Prompts Using Guilford's Structure of Intellect Model", "abstract": "Large language models (LLMs) demonstrate strong language generation\ncapabilities but often struggle with structured reasoning, leading to\ninconsistent or suboptimal problem-solving. To mitigate this limitation,\nGuilford's Structure of Intellect (SOI) model - a foundational framework from\nintelligence theory - is leveraged as the basis for cognitive prompt\nengineering. The SOI model categorizes cognitive operations such as pattern\nrecognition, memory retrieval, and evaluation, offering a systematic approach\nto enhancing LLM reasoning and decision-making. This position paper presents a\nnovel cognitive prompting approach for enforcing SOI-inspired reasoning for\nimproving clarity, coherence, and adaptability in model responses.", "published": "2025-03-27 23:06:30", "link": "http://arxiv.org/abs/2503.22036v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them", "abstract": "We investigate the use of LLM-generated data for continual pretraining of\nencoder models in specialized domains with limited training data, using the\nscientific domain of invasion biology as a case study. To this end, we leverage\ndomain-specific ontologies by enriching them with LLM-generated data and\npretraining the encoder model as an ontology-informed embedding model for\nconcept definitions. To evaluate the effectiveness of this method, we compile a\nbenchmark specifically designed for assessing model performance in invasion\nbiology. After demonstrating substantial improvements over standard LLM\npretraining, we investigate the feasibility of applying the proposed approach\nto domains without comprehensive ontologies by substituting ontological\nconcepts with concepts automatically extracted from a small corpus of\nscientific abstracts and establishing relationships between concepts through\ndistributional statistics. Our results demonstrate that this automated approach\nachieves comparable performance using only a small set of scientific abstracts,\nresulting in a fully automated pipeline for enhancing domain-specific\nunderstanding of small encoder models that is especially suited for application\nin low-resource settings and achieves performance comparable to masked language\nmodeling pretraining on much larger datasets.", "published": "2025-03-27 21:51:24", "link": "http://arxiv.org/abs/2503.22006v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Monte Carlo Sampling for Analyzing In-Context Examples", "abstract": "Prior works have shown that in-context learning is brittle to presentation\nfactors such as the order, number, and choice of selected examples. However,\nablation-based guidance on selecting the number of examples may ignore the\ninterplay between different presentation factors. In this work we develop a\nMonte Carlo sampling-based method to study the impact of number of examples\nwhile explicitly accounting for effects from order and selected examples. We\nfind that previous guidance on how many in-context examples to select does not\nalways generalize across different sets of selected examples and orderings, and\nwhether one-shot settings outperform zero-shot settings is highly dependent on\nthe selected example. Additionally, inspired by data valuation, we apply our\nsampling method to in-context example selection to select examples that perform\nwell across different orderings. We find a negative result, that while\nperformance is robust to ordering and number of examples, there is an\nunexpected performance degradation compared to random sampling.", "published": "2025-03-27 21:37:40", "link": "http://arxiv.org/abs/2503.22002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cluster automata", "abstract": "We introduce a new class of clustered Moore automata (CMA), investigate their\ntemporal behavior, and describe some applications.", "published": "2025-03-27 21:36:55", "link": "http://arxiv.org/abs/2503.22000v1", "categories": ["cs.CL", "cs.FL"], "primary_category": "cs.CL"}
{"title": "Socially Constructed Treatment Plans: Analyzing Online Peer Interactions to Understand How Patients Navigate Complex Medical Conditions", "abstract": "When faced with complex and uncertain medical conditions (e.g., cancer,\nmental health conditions, recovery from substance dependency), millions of\npatients seek online peer support. In this study, we leverage content analysis\nof online discourse and ethnographic studies with clinicians and patient\nrepresentatives to characterize how treatment plans for complex conditions are\n\"socially constructed.\" Specifically, we ground online conversation on\nmedication-assisted recovery treatment to medication guidelines and\nsubsequently surface when and why people deviate from the clinical guidelines.\nWe characterize the implications and effectiveness of socially constructed\ntreatment plans through in-depth interviews with clinical experts. Finally,\ngiven the enthusiasm around AI-powered solutions for patient communication, we\ninvestigate whether and how socially constructed treatment-related knowledge is\nreflected in a state-of-the-art large language model (LLM). Leveraging a novel\nmixed-method approach, this study highlights critical research directions for\npatient-centered communication in online health communities.", "published": "2025-03-27 21:06:07", "link": "http://arxiv.org/abs/2503.21986v1", "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Entropy-Aware Branching for Improved Mathematical Reasoning", "abstract": "While Large Language Models (LLMs) are effectively aligned through extensive\npre-training and fine-tuning, they still struggle with varying levels of\nuncertainty during token generation. In our investigation of mathematical\nreasoning, we observe that errors are more likely to arise at tokens exhibiting\nhigh entropy and variance of entropy in the model's output distribution. Based\non the observation, we propose a novel approach that dynamically branches the\ngeneration process on demand instead of defaulting to the single most probable\ntoken. By exploring in parallel multiple branches stemming from high\nprobability tokens of critical decision points, the model can discover diverse\nreasoning paths that might otherwise be missed. We further harness external\nfeedback from larger models to rank and select the most coherent and accurate\nreasoning branch. Our experimental results on mathematical word problems and\ncalculation questions show that this branching strategy boosts the reasoning\ncapabilities of small LLMs up to 4.6% compared to conventional argmax decoding.", "published": "2025-03-27 20:18:22", "link": "http://arxiv.org/abs/2503.21961v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Boosting Large Language Models with Mask Fine-Tuning", "abstract": "The model is usually kept integral in the mainstream large language model\n(LLM) fine-tuning protocols. No works have questioned whether maintaining the\nintegrity of the model is indispensable for performance. In this work, we\nintroduce Mask Fine-Tuning (MFT), a brand-new LLM fine-tuning paradigm to show\nthat properly breaking the integrity of the model can surprisingly lead to\nimproved performance. Specifically, MFT learns a set of binary masks supervised\nby the typical LLM fine-tuning objective. Extensive experiments show that MFT\ngains a consistent performance boost across various domains and backbones\n(e.g., 1.95%/1.88% average gain in coding with LLaMA2-7B/3.1-8B). Detailed\nprocedures are provided to study the proposed MFT from different hyperparameter\nperspectives for better insight. In particular, MFT naturally updates the\ncurrent LLM training protocol by deploying it on a complete well-trained model.\nThis study extends the functionality of mask learning from its conventional\nnetwork pruning context for model compression to a more general scope.", "published": "2025-03-27 20:17:57", "link": "http://arxiv.org/abs/2503.22764v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad", "abstract": "Recent math benchmarks for large language models (LLMs) such as MathArena\nindicate that state-of-the-art reasoning models achieve impressive performance\non mathematical competitions like AIME, with the leading model, Gemini-2.5-Pro,\nachieving scores comparable to top human competitors. However, these benchmarks\nevaluate models solely based on final numerical answers, neglecting rigorous\nreasoning and proof generation which are essential for real-world mathematical\ntasks. To address this, we introduce the first comprehensive evaluation of\nfull-solution reasoning for challenging mathematical problems. Using expert\nhuman annotators, we evaluated several state-of-the-art reasoning models on the\nsix problems from the 2025 USAMO within hours of their release. Our results\nreveal that all tested models struggled significantly: only Gemini-2.5-Pro\nachieves a non-trivial score of 25%, while all other models achieve less than\n5%. Through detailed analysis of reasoning traces, we identify the most common\nfailure modes and find several unwanted artifacts arising from the optimization\nstrategies employed during model training. Overall, our results suggest that\ncurrent LLMs are inadequate for rigorous mathematical reasoning tasks,\nhighlighting the need for substantial improvements in reasoning and proof\ngeneration capabilities.", "published": "2025-03-27 19:21:05", "link": "http://arxiv.org/abs/2503.21934v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Local Normalization Distortion and the Thermodynamic Formalism of Decoding Strategies for Large Language Models", "abstract": "Advances in hardware and language model architecture have spurred a\nrevolution in natural language generation. However, autoregressive models\ncompute probability distributions over next-token choices, and sampling from\nthese distributions, known as decoding, has received significantly less\nattention than other design choices. Existing decoding strategies are largely\nbased on heuristics, resulting in methods that are hard to apply or improve in\na principled manner. We develop the theory of decoding strategies for language\nmodels by expressing popular decoding algorithms as equilibrium states in the\nlanguage of ergodic theory and stating the functions they optimize. Using this,\nwe analyze the effect of the local normalization step of top-k, nucleus, and\ntemperature sampling, used to make probabilities sum to one. We argue that\nlocal normalization distortion is a fundamental defect of decoding strategies\nand quantify the size of this distortion and its effect on mathematical proxies\nfor the quality and diversity of generated text. Contrary to the prevailing\nexplanation, we argue that the major cause of the under-performance of top-k\nsampling relative to nucleus sampling is local normalization distortion. This\nyields conclusions for the future design of decoding algorithms and the\ndetection of machine-generated text.", "published": "2025-03-27 19:15:43", "link": "http://arxiv.org/abs/2503.21929v1", "categories": ["cs.CL", "cs.LG", "math.DS"], "primary_category": "cs.CL"}
{"title": "Hybrid Emotion Recognition: Enhancing Customer Interactions Through Acoustic and Textual Analysis", "abstract": "This research presents a hybrid emotion recognition system integrating\nadvanced Deep Learning, Natural Language Processing (NLP), and Large Language\nModels (LLMs) to analyze audio and textual data for enhancing customer\ninteractions in contact centers. By combining acoustic features with textual\nsentiment analysis, the system achieves nuanced emotion detection, addressing\nthe limitations of traditional approaches in understanding complex emotional\nstates. Leveraging LSTM and CNN models for audio analysis and DistilBERT for\ntextual evaluation, the methodology accommodates linguistic and cultural\nvariations while ensuring real-time processing. Rigorous testing on diverse\ndatasets demonstrates the system's robustness and accuracy, highlighting its\npotential to transform customer service by enabling personalized, empathetic\ninteractions and improving operational efficiency. This research establishes a\nfoundation for more intelligent and human-centric digital communication,\nredefining customer service standards.", "published": "2025-03-27 19:13:37", "link": "http://arxiv.org/abs/2503.21927v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoPsyC: Automatic Recognition of Psychodynamic Conflicts from Semi-structured Interviews with Large Language Models", "abstract": "Psychodynamic conflicts are persistent, often unconscious themes that shape a\nperson's behaviour and experiences. Accurate diagnosis of psychodynamic\nconflicts is crucial for effective patient treatment and is commonly done via\nlong, manually scored semi-structured interviews. Existing automated solutions\nfor psychiatric diagnosis tend to focus on the recognition of broad disorder\ncategories such as depression, and it is unclear to what extent psychodynamic\nconflicts which even the patient themselves may not have conscious access to\ncould be automatically recognised from conversation. In this paper, we propose\nAutoPsyC, the first method for recognising the presence and significance of\npsychodynamic conflicts from full-length Operationalized Psychodynamic\nDiagnostics (OPD) interviews using Large Language Models (LLMs). Our approach\ncombines recent advances in parameter-efficient fine-tuning and\nRetrieval-Augmented Generation (RAG) with a summarisation strategy to\neffectively process entire 90 minute long conversations. In evaluations on a\ndataset of 141 diagnostic interviews we show that AutoPsyC consistently\noutperforms all baselines and ablation conditions on the recognition of four\nhighly relevant psychodynamic conflicts.", "published": "2025-03-27 18:41:35", "link": "http://arxiv.org/abs/2503.21911v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "JEEM: Vision-Language Understanding in Four Arabic Dialects", "abstract": "We introduce JEEM, a benchmark designed to evaluate Vision-Language Models\n(VLMs) on visual understanding across four Arabic-speaking countries: Jordan,\nThe Emirates, Egypt, and Morocco. JEEM includes the tasks of image captioning\nand visual question answering, and features culturally rich and regionally\ndiverse content. This dataset aims to assess the ability of VLMs to generalize\nacross dialects and accurately interpret cultural elements in visual contexts.\nIn an evaluation of five prominent open-source Arabic VLMs and GPT-4V, we find\nthat the Arabic VLMs consistently underperform, struggling with both visual\nunderstanding and dialect-specific generation. While GPT-4V ranks best in this\ncomparison, the model's linguistic competence varies across dialects, and its\nvisual understanding capabilities lag behind. This underscores the need for\nmore inclusive models and the value of culturally-diverse evaluation paradigms.", "published": "2025-03-27 18:41:21", "link": "http://arxiv.org/abs/2503.21910v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "OntoAligner: A Comprehensive Modular and Robust Python Toolkit for Ontology Alignment", "abstract": "Ontology Alignment (OA) is fundamental for achieving semantic\ninteroperability across diverse knowledge systems. We present OntoAligner, a\ncomprehensive, modular, and robust Python toolkit for ontology alignment,\ndesigned to address current limitations with existing tools faced by\npractitioners. Existing tools are limited in scalability, modularity, and ease\nof integration with recent AI advances. OntoAligner provides a flexible\narchitecture integrating existing lightweight OA techniques such as fuzzy\nmatching but goes beyond by supporting contemporary methods with\nretrieval-augmented generation and large language models for OA. The framework\nprioritizes extensibility, enabling researchers to integrate custom alignment\nalgorithms and datasets. This paper details the design principles,\narchitecture, and implementation of the OntoAligner, demonstrating its utility\nthrough benchmarks on standard OA tasks. Our evaluation highlights\nOntoAligner's ability to handle large-scale ontologies efficiently with few\nlines of code while delivering high alignment quality. By making OntoAligner\nopen-source, we aim to provide a resource that fosters innovation and\ncollaboration within the OA community, empowering researchers and practitioners\nwith a toolkit for reproducible OA research and real-world applications.", "published": "2025-03-27 18:28:11", "link": "http://arxiv.org/abs/2503.21902v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "RedditESS: A Mental Health Social Support Interaction Dataset -- Understanding Effective Social Support to Refine AI-Driven Support Tools", "abstract": "Effective mental health support is crucial for alleviating psychological\ndistress. While large language model (LLM)-based assistants have shown promise\nin mental health interventions, existing research often defines \"effective\"\nsupport primarily in terms of empathetic acknowledgments, overlooking other\nessential dimensions such as informational guidance, community validation, and\ntangible coping strategies. To address this limitation and better understand\nwhat constitutes effective support, we introduce RedditESS, a novel real-world\ndataset derived from Reddit posts, including supportive comments and original\nposters' follow-up responses. Grounded in established social science theories,\nwe develop an ensemble labeling mechanism to annotate supportive comments as\neffective or not and perform qualitative assessments to ensure the reliability\nof the annotations. Additionally, we demonstrate the practical utility of\nRedditESS by using it to guide LLM alignment toward generating more\ncontext-sensitive and genuinely helpful supportive responses. By broadening the\nunderstanding of effective support, our study paves the way for advanced\nAI-driven mental health interventions.", "published": "2025-03-27 18:03:11", "link": "http://arxiv.org/abs/2503.21888v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross Fusion", "abstract": "We present StyleMotif, a novel Stylized Motion Latent Diffusion model,\ngenerating motion conditioned on both content and style from multiple\nmodalities. Unlike existing approaches that either focus on generating diverse\nmotion content or transferring style from sequences, StyleMotif seamlessly\nsynthesizes motion across a wide range of content while incorporating stylistic\ncues from multi-modal inputs, including motion, text, image, video, and audio.\nTo achieve this, we introduce a style-content cross fusion mechanism and align\na style encoder with a pre-trained multi-modal model, ensuring that the\ngenerated motion accurately captures the reference style while preserving\nrealism. Extensive experiments demonstrate that our framework surpasses\nexisting methods in stylized motion generation and exhibits emergent\ncapabilities for multi-modal motion stylization, enabling more nuanced motion\nsynthesis. Source code and pre-trained models will be released upon acceptance.\nProject Page: https://stylemotif.github.io", "published": "2025-03-27 17:59:46", "link": "http://arxiv.org/abs/2503.21775v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MemInsight: Autonomous Memory Augmentation for LLM Agents", "abstract": "Large language model (LLM) agents have evolved to intelligently process\ninformation, make decisions, and interact with users or tools. A key capability\nis the integration of long-term memory capabilities, enabling these agents to\ndraw upon historical interactions and knowledge. However, the growing memory\nsize and need for semantic structuring pose significant challenges. In this\nwork, we propose an autonomous memory augmentation approach, MemInsight, to\nenhance semantic data representation and retrieval mechanisms. By leveraging\nautonomous augmentation to historical interactions, LLM agents are shown to\ndeliver more accurate and contextualized responses. We empirically validate the\nefficacy of our proposed approach in three task scenarios; conversational\nrecommendation, question answering and event summarization. On the LLM-REDIAL\ndataset, MemInsight boosts persuasiveness of recommendations by up to 14%.\nMoreover, it outperforms a RAG baseline by 34% in recall for LoCoMo retrieval.\nOur empirical results show the potential of MemInsight to enhance the\ncontextual performance of LLM agents across multiple tasks.", "published": "2025-03-27 17:57:28", "link": "http://arxiv.org/abs/2503.21760v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics", "abstract": "Ensuring the reliability and effectiveness of software release decisions is\ncritical, particularly in safety-critical domains like automotive systems.\nPrecise analysis of release validation data, often presented in tabular form,\nplays a pivotal role in this process. However, traditional methods that rely on\nmanual analysis of extensive test datasets and validation metrics are prone to\ndelays and high costs. Large Language Models (LLMs) offer a promising\nalternative but face challenges in analytical reasoning, contextual\nunderstanding, handling out-of-scope queries, and processing structured test\ndata consistently; limitations that hinder their direct application in\nsafety-critical scenarios. This paper introduces GateLens, an LLM-based tool\nfor analyzing tabular data in the automotive domain. GateLens translates\nnatural language queries into Relational Algebra (RA) expressions and then\ngenerates optimized Python code. It outperforms the baseline system on\nbenchmarking datasets, achieving higher F1 scores and handling complex and\nambiguous queries with greater robustness. Ablation studies confirm the\ncritical role of the RA module, with performance dropping sharply when omitted.\nIndustrial evaluations reveal that GateLens reduces analysis time by over 80%\nwhile maintaining high accuracy and reliability. As demonstrated by presented\nresults, GateLens achieved high performance without relying on few-shot\nexamples, showcasing strong generalization across various query types from\ndiverse company roles. Insights from deploying GateLens with a partner\nautomotive company offer practical guidance for integrating AI into critical\nworkflows such as release validation. Results show that by automating test\nresult analysis, GateLens enables faster, more informed, and dependable release\ndecisions, and can thus advance software scalability and reliability in\nautomotive systems.", "published": "2025-03-27 17:48:32", "link": "http://arxiv.org/abs/2503.21735v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.SE"}
{"title": "Effective Skill Unlearning through Intervention and Abstention", "abstract": "Large language Models (LLMs) have demonstrated remarkable skills across\nvarious domains. Understanding the mechanisms behind their abilities and\nimplementing controls over them is becoming increasingly important for\ndeveloping better models. In this paper, we focus on skill unlearning in LLMs,\nspecifically unlearning a particular skill while retaining their overall\ncapabilities. We introduce two lightweight, training-free machine skill\nunlearning techniques for LLMs. First, we observe that the pre-activation\ndistribution of neurons in each Feed-Forward Layer (FFL) differs when the model\ndemonstrates different skills. Additionally, we find that queries triggering\nthe same skill cluster within the FFL key space and can be separated from other\nqueries using a hypercube. Based on these observations, we propose two\nlightweight, training-free skill unlearning methods via \\textit{intervention}\nand \\textit{abstention} respectively: \\texttt{Neuron Adjust} and \\texttt{Key\nSpace Detection}. We evaluate our methods on unlearning math-solving,\nPython-coding, and comprehension skills across seven different languages. The\nresults demonstrate their strong unlearning capabilities for the designated\nskills. Specifically, \\texttt{Key Space Detection} achieves over 80\\% relative\nperformance drop on the forgetting skill and less than 10\\% relative\nperformance drop on other skills and the model's general knowledge (MMLU) for\nmost unlearning tasks. Our code is available at\nhttps://github.com/Trustworthy-ML-Lab/effective_skill_unlearning", "published": "2025-03-27 17:45:06", "link": "http://arxiv.org/abs/2503.21730v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation", "abstract": "Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely\nprimarily on parametric knowledge, limiting factual accuracy. While recent\nworks equip reinforcement learning (RL)-based LRMs with retrieval capabilities,\nthey suffer from overthinking and lack robustness in reasoning, reducing their\neffectiveness in question answering (QA) tasks. To address this, we propose\nReaRAG, a factuality-enhanced reasoning model that explores diverse queries\nwithout excessive iterations. Our solution includes a novel data construction\nframework with an upper bound on the reasoning chain length. Specifically, we\nfirst leverage an LRM to generate deliberate thinking, then select an action\nfrom a predefined action space (Search and Finish). For Search action, a query\nis executed against the RAG engine, where the result is returned as observation\nto guide reasoning steps later. This process iterates until a Finish action is\nchosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach\noutperforms existing baselines on multi-hop QA. Further analysis highlights its\nstrong reflective ability to recognize errors and refine its reasoning\ntrajectory. Our study enhances LRMs' factuality while effectively integrating\nrobust reasoning for Retrieval-Augmented Generation (RAG).", "published": "2025-03-27 17:44:18", "link": "http://arxiv.org/abs/2503.21729v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Collab: Controlled Decoding using Mixture of Agents for LLM Alignment", "abstract": "Alignment of Large Language models (LLMs) is crucial for safe and trustworthy\ndeployment in applications. Reinforcement learning from human feedback (RLHF)\nhas emerged as an effective technique to align LLMs to human preferences and\nbroader utilities, but it requires updating billions of model parameters, which\nis computationally expensive. Controlled Decoding, by contrast, provides a\nmechanism for aligning a model at inference time without retraining. However,\nsingle-agent decoding approaches often struggle to adapt to diverse tasks due\nto the complexity and variability inherent in these tasks. To strengthen the\ntest-time performance w.r.t the target task, we propose a mixture of\nagent-based decoding strategies leveraging the existing off-the-shelf aligned\nLLM policies. Treating each prior policy as an agent in the spirit of mixture\nof agent collaboration, we develop a decoding method that allows for\ninference-time alignment through a token-level selection strategy among\nmultiple agents. For each token, the most suitable LLM is dynamically chosen\nfrom a pool of models based on a long-term utility metric. This\npolicy-switching mechanism ensures optimal model selection at each step,\nenabling efficient collaboration and alignment among LLMs during decoding.\nTheoretical analysis of our proposed algorithm establishes optimal performance\nwith respect to the target task represented via a target reward for the given\noff-the-shelf models. We conduct comprehensive empirical evaluations with\nopen-source aligned models on diverse tasks and preferences, which demonstrates\nthe merits of this approach over single-agent decoding baselines. Notably,\nCollab surpasses the current SoTA decoding strategy, achieving an improvement\nof up to 1.56x in average reward and 71.89% in GPT-4 based win-tie rate.", "published": "2025-03-27 17:34:25", "link": "http://arxiv.org/abs/2503.21720v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Outlier dimensions favor frequent tokens in language models", "abstract": "We study last-layer outlier dimensions, i.e. dimensions that display extreme\nactivations for the majority of inputs. We show that outlier dimensions arise\nin many different modern language models, and trace their function back to the\nheuristic of constantly predicting frequent words. We further show how a model\ncan block this heuristic when it is not contextually appropriate, by assigning\na counterbalancing weight mass to the remaining dimensions, and we investigate\nwhich model parameters boost outlier dimensions and when they arise during\ntraining. We conclude that outlier dimensions are a specialized mechanism\ndiscovered by many distinct models to implement a useful token prediction\nheuristic.", "published": "2025-03-27 17:30:50", "link": "http://arxiv.org/abs/2503.21718v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CLAIMCHECK: How Grounded are LLM Critiques of Scientific Papers?", "abstract": "A core part of scientific peer review involves providing expert critiques\nthat directly assess the scientific claims a paper makes. While it is now\npossible to automatically generate plausible (if generic) reviews, ensuring\nthat these reviews are sound and grounded in the papers' claims remains\nchallenging. To facilitate LLM benchmarking on these challenges, we introduce\nCLAIMCHECK, an annotated dataset of NeurIPS 2023 and 2024 submissions and\nreviews mined from OpenReview. CLAIMCHECK is richly annotated by ML experts for\nweakness statements in the reviews and the paper claims that they dispute, as\nwell as fine-grained labels of the validity, objectivity, and type of the\nidentified weaknesses. We benchmark several LLMs on three claim-centric tasks\nsupported by CLAIMCHECK, requiring models to (1) associate weaknesses with the\nclaims they dispute, (2) predict fine-grained labels for weaknesses and rewrite\nthe weaknesses to enhance their specificity, and (3) verify a paper's claims\nwith grounded reasoning. Our experiments reveal that cutting-edge LLMs, while\ncapable of predicting weakness labels in (2), continue to underperform relative\nto human experts on all other tasks.", "published": "2025-03-27 17:29:45", "link": "http://arxiv.org/abs/2503.21717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "As easy as PIE: understanding when pruning causes language models to disagree", "abstract": "Language Model (LM) pruning compresses the model by removing weights, nodes,\nor other parts of its architecture. Typically, pruning focuses on the resulting\nefficiency gains at the cost of effectiveness. However, when looking at how\nindividual data points are affected by pruning, it turns out that a particular\nsubset of data points always bears most of the brunt (in terms of reduced\naccuracy) when pruning, but this effect goes unnoticed when reporting the mean\naccuracy of all data points. These data points are called PIEs and have been\nstudied in image processing, but not in NLP. In a study of various NLP\ndatasets, pruning methods, and levels of compression, we find that PIEs impact\ninference quality considerably, regardless of class frequency, and that BERT is\nmore prone to this than BiLSTM. We also find that PIEs contain a high amount of\ndata points that have the largest influence on how well the model generalises\nto unseen data. This means that when pruning, with seemingly moderate loss to\naccuracy across all data points, we in fact hurt tremendously those data points\nthat matter the most. We trace what makes PIEs both hard and impactful to\ninference to their overall longer and more semantically complex text. These\nfindings are novel and contribute to understanding how LMs are affected by\npruning. The code is available at: https://github.com/pietrotrope/AsEasyAsPIE", "published": "2025-03-27 17:26:32", "link": "http://arxiv.org/abs/2503.21714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Mathematical Relationship Between Layer Normalization and Dynamic Activation Functions", "abstract": "A recent paper proposes Dynamic Tanh (DyT) as a drop-in replacement for layer\nnormalization (LN). Although the method is empirically well-motivated and\nappealing from a practical point of view, it lacks a theoretical foundation. In\nthis work, we shed light on the mathematical relationship between layer\nnormalization and dynamic activation functions. In particular, we derive DyT\nfrom LN and show that a well-defined approximation is needed to do so. By\ndropping said approximation, an alternative activation function is obtained,\nwhich we call Dynamic Inverse Square Root Unit (DyISRU). DyISRU is the exact\ncounterpart of layer normalization, and we demonstrate numerically that it\nindeed resembles LN more accurately than DyT does.", "published": "2025-03-27 17:20:44", "link": "http://arxiv.org/abs/2503.21708v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning to Represent Individual Differences for Choice Decision Making", "abstract": "Human decision making can be challenging to predict because decisions are\naffected by a number of complex factors. Adding to this complexity,\ndecision-making processes can differ considerably between individuals, and\nmethods aimed at predicting human decisions need to take individual differences\ninto account. Behavioral science offers methods by which to measure individual\ndifferences (e.g., questionnaires, behavioral models), but these are often\nnarrowed down to low dimensions and not tailored to specific prediction tasks.\nThis paper investigates the use of representation learning to measure\nindividual differences from behavioral experiment data. Representation learning\noffers a flexible approach to create individual embeddings from data that are\nboth structured (e.g., demographic information) and unstructured (e.g., free\ntext), where the flexibility provides more options for individual difference\nmeasures for personalization, e.g., free text responses may allow for\nopen-ended questions that are less privacy-sensitive. In the current paper we\nuse representation learning to characterize individual differences in human\nperformance on an economic decision-making task. We demonstrate that models\nusing representation learning to capture individual differences consistently\nimprove decision predictions over models without representation learning, and\neven outperform well-known theory-based behavioral models used in these\nenvironments. Our results propose that representation learning offers a useful\nand flexible tool to capture individual differences.", "published": "2025-03-27 17:10:05", "link": "http://arxiv.org/abs/2503.21704v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks", "abstract": "Recent advances in deep thinking models have demonstrated remarkable\nreasoning capabilities on mathematical and coding tasks. However, their\neffectiveness in embodied domains which require continuous interaction with\nenvironments through image action interleaved trajectories remains largely\n-unexplored. We present Embodied Reasoner, a model that extends o1 style\nreasoning to interactive embodied search tasks. Unlike mathematical reasoning\nthat relies primarily on logical deduction, embodied scenarios demand spatial\nunderstanding, temporal reasoning, and ongoing self-reflection based on\ninteraction history. To address these challenges, we synthesize 9.3k coherent\nObservation-Thought-Action trajectories containing 64k interactive images and\n90k diverse thinking processes (analysis, spatial reasoning, reflection,\nplanning, and verification). We develop a three-stage training pipeline that\nprogressively enhances the model's capabilities through imitation learning,\nself-exploration via rejection sampling, and self-correction through reflection\ntuning. The evaluation shows that our model significantly outperforms those\nadvanced visual reasoning models, e.g., it exceeds OpenAI o1, o3-mini, and\nClaude-3.7 by +9\\%, 24\\%, and +13\\%. Analysis reveals our model exhibits fewer\nrepeated searches and logical inconsistencies, with particular advantages in\ncomplex long-horizon tasks. Real-world environments also show our superiority\nwhile exhibiting fewer repeated searches and logical inconsistency cases.", "published": "2025-03-27 17:00:51", "link": "http://arxiv.org/abs/2503.21696v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku with Self-Play and Reinforcement Learning", "abstract": "In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced.", "published": "2025-03-27 16:52:25", "link": "http://arxiv.org/abs/2503.21683v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "JiraiBench: A Bilingual Benchmark for Evaluating Large Language Models' Detection of Human Self-Destructive Behavior Content in Jirai Community", "abstract": "This paper introduces JiraiBench, the first bilingual benchmark for\nevaluating large language models' effectiveness in detecting self-destructive\ncontent across Chinese and Japanese social media communities. Focusing on the\ntransnational \"Jirai\" (landmine) online subculture that encompasses multiple\nforms of self-destructive behaviors including drug overdose, eating disorders,\nand self-harm, we present a comprehensive evaluation framework incorporating\nboth linguistic and cultural dimensions. Our dataset comprises 10,419 Chinese\nposts and 5,000 Japanese posts with multidimensional annotation along three\nbehavioral categories, achieving substantial inter-annotator agreement.\nExperimental evaluations across four state-of-the-art models reveal significant\nperformance variations based on instructional language, with Japanese prompts\nunexpectedly outperforming Chinese prompts when processing Chinese content.\nThis emergent cross-cultural transfer suggests that cultural proximity can\nsometimes outweigh linguistic similarity in detection tasks. Cross-lingual\ntransfer experiments with fine-tuned models further demonstrate the potential\nfor knowledge transfer between these language systems without explicit target\nlanguage training. These findings highlight the need for culturally-informed\napproaches to multilingual content moderation and provide empirical evidence\nfor the importance of cultural context in developing more effective detection\nsystems for vulnerable online communities.", "published": "2025-03-27 16:48:58", "link": "http://arxiv.org/abs/2503.21679v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "How do language models learn facts? Dynamics, curricula and hallucinations", "abstract": "Large language models accumulate vast knowledge during pre-training, yet the\ndynamics governing this acquisition remain poorly understood. This work\ninvestigates the learning dynamics of language models on a synthetic factual\nrecall task, uncovering three key findings: First, language models learn in\nthree phases, exhibiting a performance plateau before acquiring precise factual\nknowledge. Mechanistically, this plateau coincides with the formation of\nattention-based circuits that support recall. Second, the training data\ndistribution significantly impacts learning dynamics, as imbalanced\ndistributions lead to shorter plateaus. Finally, hallucinations emerge\nsimultaneously with knowledge, and integrating new knowledge into the model\nthrough fine-tuning is challenging, as it quickly corrupts its existing\nparametric memories. Our results emphasize the importance of data distribution\nin knowledge acquisition and suggest novel data scheduling strategies to\naccelerate neural network training.", "published": "2025-03-27 16:43:45", "link": "http://arxiv.org/abs/2503.21676v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in Hindi-English Code-Mixing", "abstract": "The rapid growth of digital communication has driven the widespread use of\ncode-mixing, particularly Hindi-English, in multilingual communities. Existing\ndatasets often focus on romanized text, have limited scope, or rely on\nsynthetic data, which fails to capture realworld language nuances. Human\nannotations are crucial for assessing the naturalness and acceptability of\ncode-mixed text. To address these challenges, We introduce COMI-LINGUA, the\nlargest manually annotated dataset for code-mixed text, comprising 100,970\ninstances evaluated by three expert annotators in both Devanagari and Roman\nscripts. The dataset supports five fundamental NLP tasks: Language\nIdentification, Matrix Language Identification, Part-of-Speech Tagging, Named\nEntity Recognition, and Translation. We evaluate LLMs on these tasks using\nCOMILINGUA, revealing limitations in current multilingual modeling strategies\nand emphasizing the need for improved code-mixed text processing capabilities.\nCOMI-LINGUA is publically availabe at:\nhttps://huggingface.co/datasets/LingoIITGN/COMI-LINGUA.", "published": "2025-03-27 16:36:39", "link": "http://arxiv.org/abs/2503.21670v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Model Assembly Learning with Heterogeneous Layer Weight Merging", "abstract": "Model merging acquires general capabilities without extra data or training by\ncombining multiple models' parameters. Previous approaches achieve linear mode\nconnectivity by aligning parameters into the same loss basin using permutation\ninvariance. In this paper, we introduce Model Assembly Learning (MAL), a novel\nparadigm for model merging that iteratively integrates parameters from diverse\nmodels in an open-ended model zoo to enhance the base model's capabilities.\nUnlike previous works that require identical architectures, MAL allows the\nmerging of heterogeneous architectures and selective parameters across layers.\nSpecifically, the base model can incorporate parameters from different layers\nof multiple pre-trained models. We systematically investigate the conditions\nand fundamental settings of heterogeneous parameter merging, addressing all\npossible mismatches in layer widths between the base and target models.\nFurthermore, we establish key laws and provide practical guidelines for\neffectively implementing MAL.", "published": "2025-03-27 16:21:53", "link": "http://arxiv.org/abs/2503.21657v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond", "abstract": "Recent Large Reasoning Models (LRMs), such as DeepSeek-R1 and OpenAI o1, have\ndemonstrated strong performance gains by scaling up the length of\nChain-of-Thought (CoT) reasoning during inference. However, a growing concern\nlies in their tendency to produce excessively long reasoning traces, which are\noften filled with redundant content (e.g., repeated definitions), over-analysis\nof simple problems, and superficial exploration of multiple reasoning paths for\nharder tasks. This inefficiency introduces significant challenges for training,\ninference, and real-world deployment (e.g., in agent-based systems), where\ntoken economy is critical. In this survey, we provide a comprehensive overview\nof recent efforts aimed at improving reasoning efficiency in LRMs, with a\nparticular focus on the unique challenges that arise in this new paradigm. We\nidentify common patterns of inefficiency, examine methods proposed across the\nLRM lifecycle, i.e., from pretraining to inference, and discuss promising\nfuture directions for research. To support ongoing development, we also\nmaintain a real-time GitHub repository tracking recent progress in the field.\nWe hope this survey serves as a foundation for further exploration and inspires\ninnovation in this rapidly evolving area.", "published": "2025-03-27 15:36:30", "link": "http://arxiv.org/abs/2503.21614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating book summaries from internal knowledge in Large Language Models: a cross-model and semantic consistency approach", "abstract": "We study the ability of large language models (LLMs) to generate\ncomprehensive and accurate book summaries solely from their internal knowledge,\nwithout recourse to the original text. Employing a diverse set of books and\nmultiple LLM architectures, we examine whether these models can synthesize\nmeaningful narratives that align with established human interpretations.\nEvaluation is performed with a LLM-as-a-judge paradigm: each AI-generated\nsummary is compared against a high-quality, human-written summary via a\ncross-model assessment, where all participating LLMs evaluate not only their\nown outputs but also those produced by others. This methodology enables the\nidentification of potential biases, such as the proclivity for models to favor\ntheir own summarization style over others. In addition, alignment between the\nhuman-crafted and LLM-generated summaries is quantified using ROUGE and\nBERTScore metrics, assessing the depth of grammatical and semantic\ncorrespondence. The results reveal nuanced variations in content representation\nand stylistic preferences among the models, highlighting both strengths and\nlimitations inherent in relying on internal knowledge for summarization tasks.\nThese findings contribute to a deeper understanding of LLM internal encodings\nof factual information and the dynamics of cross-model evaluation, with\nimplications for the development of more robust natural language generative\nsystems.", "published": "2025-03-27 15:36:24", "link": "http://arxiv.org/abs/2503.21613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "debug-gym: A Text-Based Environment for Interactive Debugging", "abstract": "Large Language Models (LLMs) are increasingly relied upon for coding tasks,\nyet in most scenarios it is assumed that all relevant information can be either\naccessed in context or matches their training data. We posit that LLMs can\nbenefit from the ability to interactively explore a codebase to gather the\ninformation relevant to their task. To achieve this, we present a textual\nenvironment, namely debug-gym, for developing LLM-based agents in an\ninteractive coding setting. Our environment is lightweight and provides a\npreset of useful tools, such as a Python debugger (pdb), designed to facilitate\nan LLM-based agent's interactive debugging. Beyond coding and debugging tasks,\nthis approach can be generalized to other tasks that would benefit from\ninformation-seeking behavior by an LLM agent.", "published": "2025-03-27 14:43:28", "link": "http://arxiv.org/abs/2503.21557v1", "categories": ["cs.AI", "cs.CL", "cs.PL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "SWI: Speaking with Intent in Large Language Models", "abstract": "Intent, typically clearly formulated and planned, functions as a cognitive\nframework for reasoning and problem-solving. This paper introduces the concept\nof Speaking with Intent (SWI) in large language models (LLMs), where the\nexplicitly generated intent encapsulates the model's underlying intention and\nprovides high-level planning to guide subsequent analysis and communication. By\nemulating deliberate and purposeful thoughts in the human mind, SWI is\nhypothesized to enhance the reasoning capabilities and generation quality of\nLLMs. Extensive experiments on mathematical reasoning benchmarks consistently\ndemonstrate the superiority of Speaking with Intent over Baseline (i.e.,\ngeneration without explicit intent). Moreover, SWI outperforms answer-trigger\nprompting methods Chain-of-Thought and Plan-and-Solve and maintains competitive\nperformance with the strong method ARR (Analyzing, Retrieving, and Reasoning).\nAdditionally, the effectiveness and generalizability of SWI are solidified on\nreasoning-intensive question answering (QA) and text summarization benchmarks,\nwhere SWI brings consistent improvement to the Baseline generation. In text\nsummarization, SWI-generated summaries exhibit greater accuracy, conciseness,\nand factual correctness, with fewer hallucinations. Furthermore, human\nevaluations verify the coherence, effectiveness, and interpretability of the\nintent produced by SWI. This proof-of-concept study creates a novel avenue for\nenhancing LLMs' reasoning abilities with cognitive notions.", "published": "2025-03-27 14:34:28", "link": "http://arxiv.org/abs/2503.21544v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Low-Resource Transliteration for Roman-Urdu and Urdu Using Transformer-Based Models", "abstract": "As the Information Retrieval (IR) field increasingly recognizes the\nimportance of inclusivity, addressing the needs of low-resource languages\nremains a significant challenge. Transliteration between Urdu and its Romanized\nform, Roman Urdu, remains underexplored despite the widespread use of both\nscripts in South Asia. Prior work using RNNs on the Roman-Urdu-Parl dataset\nshowed promising results but suffered from poor domain adaptability and limited\nevaluation. We propose a transformer-based approach using the m2m100\nmultilingual translation model, enhanced with masked language modeling (MLM)\npretraining and fine-tuning on both Roman-Urdu-Parl and the domain-diverse\nDakshina dataset. To address previous evaluation flaws, we introduce rigorous\ndataset splits and assess performance using BLEU, character-level BLEU, and\nCHRF. Our model achieves strong transliteration performance, with Char-BLEU\nscores of 96.37 for Urdu->Roman-Urdu and 97.44 for Roman-Urdu->Urdu. These\nresults outperform both RNN baselines and GPT-4o Mini and demonstrate the\neffectiveness of multilingual transfer learning for low-resource\ntransliteration tasks.", "published": "2025-03-27 14:18:50", "link": "http://arxiv.org/abs/2503.21530v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Datasets for Depression Modeling in Social Media: An Overview", "abstract": "Depression is the most common mental health disorder, and its prevalence\nincreased during the COVID-19 pandemic. As one of the most extensively\nresearched psychological conditions, recent research has increasingly focused\non leveraging social media data to enhance traditional methods of depression\nscreening. This paper addresses the growing interest in interdisciplinary\nresearch on depression, and aims to support early-career researchers by\nproviding a comprehensive and up-to-date list of datasets for analyzing and\npredicting depression through social media data. We present an overview of\ndatasets published between 2019 and 2024. We also make the comprehensive list\nof datasets available online as a continuously updated resource, with the hope\nthat it will facilitate further interdisciplinary research into the linguistic\nexpressions of depression on social media.", "published": "2025-03-27 14:03:25", "link": "http://arxiv.org/abs/2503.21513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Evaluation of Large Vision-Language Models in Autonomous Driving", "abstract": "Existing benchmarks for Vision-Language Model (VLM) on autonomous driving\n(AD) primarily assess interpretability through open-form visual question\nanswering (QA) within coarse-grained tasks, which remain insufficient to assess\ncapabilities in complex driving scenarios. To this end, we introduce\n$\\textbf{VLADBench}$, a challenging and fine-grained dataset featuring\nclose-form QAs that progress from static foundational knowledge and elements to\nadvanced reasoning for dynamic on-road situations. The elaborate\n$\\textbf{VLADBench}$ spans 5 key domains: Traffic Knowledge Understanding,\nGeneral Element Recognition, Traffic Graph Generation, Target Attribute\nComprehension, and Ego Decision-Making and Planning. These domains are further\nbroken down into 11 secondary aspects and 29 tertiary tasks for a granular\nevaluation. A thorough assessment of general and domain-specific (DS) VLMs on\nthis benchmark reveals both their strengths and critical limitations in AD\ncontexts. To further exploit the cognitive and reasoning interactions among the\n5 domains for AD understanding, we start from a small-scale VLM and train the\nDS models on individual domain datasets (collected from 1.4M DS QAs across\npublic sources). The experimental results demonstrate that the proposed\nbenchmark provides a crucial step toward a more comprehensive assessment of\nVLMs in AD, paving the way for the development of more cognitively\nsophisticated and reasoning-capable AD systems.", "published": "2025-03-27 13:45:47", "link": "http://arxiv.org/abs/2503.21505v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Keyword-Oriented Multimodal Modeling for Euphemism Identification", "abstract": "Euphemism identification deciphers the true meaning of euphemisms, such as\nlinking \"weed\" (euphemism) to \"marijuana\" (target keyword) in illicit texts,\naiding content moderation and combating underground markets. While existing\nmethods are primarily text-based, the rise of social media highlights the need\nfor multimodal analysis, incorporating text, images, and audio. However, the\nlack of multimodal datasets for euphemisms limits further research. To address\nthis, we regard euphemisms and their corresponding target keywords as keywords\nand first introduce a keyword-oriented multimodal corpus of euphemisms\n(KOM-Euph), involving three datasets (Drug, Weapon, and Sexuality), including\ntext, images, and speech. We further propose a keyword-oriented multimodal\neuphemism identification method (KOM-EI), which uses cross-modal feature\nalignment and dynamic fusion modules to explicitly utilize the visual and audio\nfeatures of the keywords for efficient euphemism identification. Extensive\nexperiments demonstrate that KOM-EI outperforms state-of-the-art models and\nlarge language models, and show the importance of our multimodal datasets.", "published": "2025-03-27 13:45:35", "link": "http://arxiv.org/abs/2503.21504v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "OpenHuEval: Evaluating Large Language Model on Hungarian Specifics", "abstract": "We introduce OpenHuEval, the first benchmark for LLMs focusing on the\nHungarian language and specifics. OpenHuEval is constructed from a vast\ncollection of Hungarian-specific materials sourced from multiple origins. In\nthe construction, we incorporated the latest design principles for evaluating\nLLMs, such as using real user queries from the internet, emphasizing the\nassessment of LLMs' generative capabilities, and employing LLM-as-judge to\nenhance the multidimensionality and accuracy of evaluations. Ultimately,\nOpenHuEval encompasses eight Hungarian-specific dimensions, featuring five\ntasks and 3953 questions. Consequently, OpenHuEval provides the comprehensive,\nin-depth, and scientifically accurate assessment of LLM performance in the\ncontext of the Hungarian language and its specifics. We evaluated current\nmainstream LLMs, including both traditional LLMs and recently developed Large\nReasoning Models. The results demonstrate the significant necessity for\nevaluation and model optimization tailored to the Hungarian language and\nspecifics. We also established the framework for analyzing the thinking\nprocesses of LRMs with OpenHuEval, revealing intrinsic patterns and mechanisms\nof these models in non-English languages, with Hungarian serving as a\nrepresentative example. We will release OpenHuEval at\nhttps://github.com/opendatalab/OpenHuEval .", "published": "2025-03-27 13:40:06", "link": "http://arxiv.org/abs/2503.21500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OmniVox: Zero-Shot Emotion Recognition with Omni-LLMs", "abstract": "The use of omni-LLMs (large language models that accept any modality as\ninput), particularly for multimodal cognitive state tasks involving speech, is\nunderstudied. We present OmniVox, the first systematic evaluation of four\nomni-LLMs on the zero-shot emotion recognition task. We evaluate on two widely\nused multimodal emotion benchmarks: IEMOCAP and MELD, and find zero-shot\nomni-LLMs outperform or are competitive with fine-tuned audio models. Alongside\nour audio-only evaluation, we also evaluate omni-LLMs on text only and text and\naudio. We present acoustic prompting, an audio-specific prompting strategy for\nomni-LLMs which focuses on acoustic feature analysis, conversation context\nanalysis, and step-by-step reasoning. We compare our acoustic prompting to\nminimal prompting and full chain-of-thought prompting techniques. We perform a\ncontext window analysis on IEMOCAP and MELD, and find that using context helps,\nespecially on IEMOCAP. We conclude with an error analysis on the generated\nacoustic reasoning outputs from the omni-LLMs.", "published": "2025-03-27 13:12:49", "link": "http://arxiv.org/abs/2503.21480v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt Detection", "abstract": "In this work, we propose a metric called Number of Thoughts (NofT) to\ndetermine the difficulty of tasks pre-prompting and support Large Language\nModels (LLMs) in production contexts. By setting thresholds based on the number\nof thoughts, this metric can discern the difficulty of prompts and support more\neffective prompt routing. A 2% decrease in latency is achieved when routing\nprompts from the MathInstruct dataset through quantized, distilled versions of\nDeepseek with 1.7 billion, 7 billion, and 14 billion parameters. Moreover, this\nmetric can be used to detect adversarial prompts used in prompt injection\nattacks with high efficacy. The Number of Thoughts can inform a classifier that\nachieves 95% accuracy in adversarial prompt detection. Our experiments ad\ndatasets used are available on our GitHub page:\nhttps://github.com/rymarinelli/Number_Of_Thoughts/tree/main.", "published": "2025-03-27 12:54:00", "link": "http://arxiv.org/abs/2503.21464v1", "categories": ["cs.CL", "cs.AI", "cs.PF"], "primary_category": "cs.CL"}
{"title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges", "abstract": "The era of intelligent agents is upon us, driven by revolutionary\nadvancements in large language models. Large Language Model (LLM) agents, with\ngoal-driven behaviors and dynamic adaptation capabilities, potentially\nrepresent a critical pathway toward artificial general intelligence. This\nsurvey systematically deconstructs LLM agent systems through a\nmethodology-centered taxonomy, linking architectural foundations, collaboration\nmechanisms, and evolutionary pathways. We unify fragmented research threads by\nrevealing fundamental connections between agent design principles and their\nemergent behaviors in complex environments. Our work provides a unified\narchitectural perspective, examining how agents are constructed, how they\ncollaborate, and how they evolve over time, while also addressing evaluation\nmethodologies, tool applications, practical challenges, and diverse application\ndomains. By surveying the latest developments in this rapidly evolving field,\nwe offer researchers a structured taxonomy for understanding LLM agents and\nidentify promising directions for future research. The collection is available\nat https://github.com/luo-junyu/Awesome-Agent-Papers.", "published": "2025-03-27 12:50:17", "link": "http://arxiv.org/abs/2503.21460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Composable Prompting Workspaces for Creative Writing: Exploration and Iteration Using Dynamic Widgets", "abstract": "Generative AI models offer many possibilities for text creation and\ntransformation. Current graphical user interfaces (GUIs) for prompting them\nlack support for iterative exploration, as they do not represent prompts as\nactionable interface objects. We propose the concept of a composable prompting\ncanvas for text exploration and iteration using dynamic widgets. Users generate\nwidgets through system suggestions, prompting, or manually to capture\ntask-relevant facets that affect the generated text. In a comparative study\nwith a baseline (conversational UI), 18 participants worked on two writing\ntasks, creating diverse prompting environments with custom widgets and spatial\nlayouts. They reported having more control over the generated text and\npreferred our system over the baseline. Our design significantly outperformed\nthe baseline on the Creativity Support Index, and participants felt the results\nwere worth the effort. This work highlights the need for GUIs that support\nuser-driven customization and (re-)structuring to increase both the flexibility\nand efficiency of prompting.", "published": "2025-03-27 11:36:47", "link": "http://arxiv.org/abs/2503.21394v1", "categories": ["cs.HC", "cs.CL", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "An evaluation of LLMs and Google Translate for translation of selected Indian languages via sentiment and semantic analyses", "abstract": "Large Language models (LLMs) have been prominent for language translation,\nincluding low-resource languages. There has been limited study about the\nassessment of the quality of translations generated by LLMs, including Gemini,\nGPT and Google Translate. In this study, we address this limitation by using\nsemantic and sentiment analysis of selected LLMs for Indian languages,\nincluding Sanskrit, Telugu and Hindi. We select prominent texts that have been\nwell translated by experts and use LLMs to generate their translations to\nEnglish, and then we provide a comparison with selected expert (human)\ntranslations. Our findings suggest that while LLMs have made significant\nprogress in translation accuracy, challenges remain in preserving sentiment and\nsemantic integrity, especially in figurative and philosophical contexts. The\nsentiment analysis revealed that GPT-4o and GPT-3.5 are better at preserving\nthe sentiments for the Bhagavad Gita (Sanskrit-English) translations when\ncompared to Google Translate. We observed a similar trend for the case of Tamas\n(Hindi-English) and Maha P (Telugu-English) translations. GPT-4o performs\nsimilarly to GPT-3.5 in the translation in terms of sentiments for the three\nlanguages. We found that LLMs are generally better at translation for capturing\nsentiments when compared to Google Translate.", "published": "2025-03-27 11:35:40", "link": "http://arxiv.org/abs/2503.21393v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Controlling Large Language Model with Latent Actions", "abstract": "Adapting Large Language Models (LLMs) to downstream tasks using Reinforcement\nLearning (RL) has proven to be an effective approach. However, LLMs do not\ninherently define the structure of an agent for RL training, particularly in\nterms of defining the action space. This paper studies learning a compact\nlatent action space to enhance the controllability and exploration of RL for\nLLMs. We propose Controlling Large Language Models with Latent Actions (CoLA),\na framework that integrates a latent action space into pre-trained LLMs. We\napply CoLA to the Llama-3.1-8B model. Our experiments demonstrate that,\ncompared to RL with token-level actions, CoLA's latent action enables greater\nsemantic diversity in text generation. For enhancing downstream tasks, we show\nthat CoLA with RL achieves a score of 42.4 on the math500 benchmark, surpassing\nthe baseline score of 38.2, and reaches 68.2 when augmented with a Monte Carlo\nTree Search variant. Furthermore, CoLA with RL consistently improves\nperformance on agent-based tasks without degrading the pre-trained LLM's\ncapabilities, unlike the baseline. Finally, CoLA reduces computation time by\nhalf in tasks involving enhanced thinking prompts for LLMs by RL. These results\nhighlight CoLA's potential to advance RL-based adaptation of LLMs for\ndownstream applications.", "published": "2025-03-27 11:25:22", "link": "http://arxiv.org/abs/2503.21383v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Challenging the Boundaries of Reasoning: An Olympiad-Level Math Benchmark for Large Language Models", "abstract": "In recent years, the rapid development of large reasoning models has resulted\nin the saturation of existing benchmarks for evaluating mathematical reasoning,\nhighlighting the urgent need for more challenging and rigorous evaluation\nframeworks. To address this gap, we introduce OlymMATH, a novel Olympiad-level\nmathematical benchmark, designed to rigorously test the complex reasoning\ncapabilities of LLMs. OlymMATH features 200 meticulously curated problems, each\nmanually verified and available in parallel English and Chinese versions. The\nproblems are systematically organized into two distinct difficulty tiers: (1)\nAIME-level problems (easy) that establish a baseline for mathematical reasoning\nassessment, and (2) significantly more challenging problems (hard) designed to\npush the boundaries of current state-of-the-art models. In our benchmark, these\nproblems span four core mathematical fields, each including a verifiable\nnumerical solution to enable objective, rule-based evaluation. Empirical\nresults underscore the significant challenge presented by OlymMATH, with\nstate-of-the-art models including DeepSeek-R1 and OpenAI's o3-mini\ndemonstrating notably limited accuracy on the hard subset. Furthermore, the\nbenchmark facilitates comprehensive bilingual assessment of mathematical\nreasoning abilities-a critical dimension that remains largely unaddressed in\nmainstream mathematical reasoning benchmarks. We release the OlymMATH benchmark\nat the STILL project: https://github.com/RUCAIBox/Slow_Thinking_with_LLMs.", "published": "2025-03-27 11:20:17", "link": "http://arxiv.org/abs/2503.21380v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieving Time-Series Differences Using Natural Language Queries", "abstract": "Effectively searching time-series data is essential for system analysis;\nhowever, traditional methods often require domain expertise to define search\ncriteria. Recent advancements have enabled natural language-based search, but\nthese methods struggle to handle differences between time-series data. To\naddress this limitation, we propose a natural language query-based approach for\nretrieving pairs of time-series data based on differences specified in the\nquery. Specifically, we define six key characteristics of differences,\nconstruct a corresponding dataset, and develop a contrastive learning-based\nmodel to align differences between time-series data with query texts.\nExperimental results demonstrate that our model achieves an overall mAP score\nof 0.994 in retrieving time-series pairs.", "published": "2025-03-27 11:15:17", "link": "http://arxiv.org/abs/2503.21378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From User Preferences to Optimization Constraints Using Large Language Models", "abstract": "This work explores using Large Language Models (LLMs) to translate user\npreferences into energy optimization constraints for home appliances. We\ndescribe a task where natural language user utterances are converted into\nformal constraints for smart appliances, within the broader context of a\nrenewable energy community (REC) and in the Italian scenario. We evaluate the\neffectiveness of various LLMs currently available for Italian in translating\nthese preferences resorting to classical zero-shot, one-shot, and few-shot\nlearning settings, using a pilot dataset of Italian user requests paired with\ncorresponding formal constraint representation. Our contributions include\nestablishing a baseline performance for this task, publicly releasing the\ndataset and code for further research, and providing insights on observed best\npractices and limitations of LLMs in this particular domain", "published": "2025-03-27 10:52:10", "link": "http://arxiv.org/abs/2503.21360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning LLMs on Small Medical Datasets: Text Classification and Normalization Effectiveness on Cardiology reports and Discharge records", "abstract": "We investigate the effectiveness of fine-tuning large language models (LLMs)\non small medical datasets for text classification and named entity recognition\ntasks. Using a German cardiology report dataset and the i2b2 Smoking Challenge\ndataset, we demonstrate that fine-tuning small LLMs locally on limited training\ndata can improve performance achieving comparable results to larger models. Our\nexperiments show that fine-tuning improves performance on both tasks, with\nnotable gains observed with as few as 200-300 training examples. Overall, the\nstudy highlights the potential of task-specific fine-tuning of LLMs for\nautomating clinical workflows and efficiently extracting structured data from\nunstructured medical text.", "published": "2025-03-27 10:35:56", "link": "http://arxiv.org/abs/2503.21349v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.6; I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback", "abstract": "Summarization refinement faces challenges when extending to multi-dimension.\nIn this paper, we introduce ReFeed, a powerful summarization refinement\npipeline that enhances multiple dimensions through reflective reasoning on\nfeedback. To achieve this, we release SumFeed-CoT, a large-scale Long-CoT-based\ndataset optimized for training a lightweight model with reflective reasoning.\nOur experiments reveal how the number of dimensions, feedback exposure, and\nreasoning policy influence refinement performance, highlighting reflective\nreasoning and simultaneously addressing multiple feedback is crucial to\nmitigate trade-off between dimensions. Furthermore, ReFeed is robust to noisy\nfeedback and feedback order. Lastly, our finding emphasizes that creating data\nwith a proper goal and guideline constitutes a fundamental pillar of effective\nreasoning. The dataset and model will be released.", "published": "2025-03-27 10:11:41", "link": "http://arxiv.org/abs/2503.21332v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "R-PRM: Reasoning-Driven Process Reward Modeling", "abstract": "Large language models (LLMs) inevitably make mistakes when performing\nstep-by-step mathematical reasoning. Process Reward Models (PRMs) have emerged\nas a promising solution by evaluating each reasoning step. However, existing\nPRMs typically output evaluation scores directly, limiting both learning\nefficiency and evaluation accuracy, which is further exacerbated by the\nscarcity of annotated data. To address these issues, we propose\nReasoning-Driven Process Reward Modeling (R-PRM). First, we leverage stronger\nLLMs to generate seed data from limited annotations, effectively bootstrapping\nour model's reasoning capabilities and enabling comprehensive step-by-step\nevaluation. Second, we further enhance performance through preference\noptimization, without requiring additional annotated data. Third, we introduce\ninference-time scaling to fully harness the model's reasoning potential.\nExtensive experiments demonstrate R-PRM's effectiveness: on ProcessBench and\nPRMBench, it surpasses strong baselines by 11.9 and 8.5 points in F1 scores,\nrespectively. When applied to guide mathematical reasoning, R-PRM achieves\nconsistent accuracy improvements of over 8.5 points across six challenging\ndatasets. Further analysis reveals that R-PRM exhibits more comprehensive\nevaluation and stronger generalization capabilities, thereby highlighting its\nsignificant potential.", "published": "2025-03-27 09:23:08", "link": "http://arxiv.org/abs/2503.21295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Medical Reasoning in LLMs: An In-Depth Analysis of DeepSeek R1", "abstract": "Integrating large language models (LLMs) like DeepSeek R1 into healthcare\nrequires rigorous evaluation of their reasoning alignment with clinical\nexpertise. This study assesses DeepSeek R1's medical reasoning against expert\npatterns using 100 MedQA clinical cases. The model achieved 93% diagnostic\naccuracy, demonstrating systematic clinical judgment through differential\ndiagnosis, guideline-based treatment selection, and integration of\npatient-specific factors. However, error analysis of seven incorrect cases\nrevealed persistent limitations: anchoring bias, challenges reconciling\nconflicting data, insufficient exploration of alternatives, overthinking,\nknowledge gaps, and premature prioritization of definitive treatment over\nintermediate care. Crucially, reasoning length correlated with accuracy -\nshorter responses (<5,000 characters) were more reliable, suggesting extended\nexplanations may signal uncertainty or rationalization of errors. While\nDeepSeek R1 exhibits foundational clinical reasoning capabilities, recurring\nflaws highlight critical areas for refinement, including bias mitigation,\nknowledge updates, and structured reasoning frameworks. These findings\nunderscore LLMs' potential to augment medical decision-making through\nartificial reasoning but emphasize the need for domain-specific validation,\ninterpretability safeguards, and confidence metrics (e.g., response length\nthresholds) to ensure reliability in real-world applications.", "published": "2025-03-27 09:18:08", "link": "http://arxiv.org/abs/2504.00016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cultivating Game Sense for Yourself: Making VLMs Gaming Experts", "abstract": "Developing agents capable of fluid gameplay in first/third-person games\nwithout API access remains a critical challenge in Artificial General\nIntelligence (AGI). Recent efforts leverage Vision Language Models (VLMs) as\ndirect controllers, frequently pausing the game to analyze screens and plan\naction through language reasoning. However, this inefficient paradigm\nfundamentally restricts agents to basic and non-fluent interactions: relying on\nisolated VLM reasoning for each action makes it impossible to handle tasks\nrequiring high reactivity (e.g., FPS shooting) or dynamic adaptability (e.g.,\nACT combat). To handle this, we propose a paradigm shift in gameplay agent\ndesign: instead of directly controlling gameplay, VLM develops specialized\nexecution modules tailored for tasks like shooting and combat. These modules\nhandle real-time game interactions, elevating VLM to a high-level developer.\nBuilding upon this paradigm, we introduce GameSense, a gameplay agent framework\nwhere VLM develops task-specific game sense modules by observing task execution\nand leveraging vision tools and neural network training pipelines. These\nmodules encapsulate action-feedback logic, ranging from direct action rules to\nneural network-based decisions. Experiments demonstrate that our framework is\nthe first to achieve fluent gameplay in diverse genres, including ACT, FPS, and\nFlappy Bird, setting a new benchmark for game-playing agents.", "published": "2025-03-27 08:40:47", "link": "http://arxiv.org/abs/2503.21263v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ResearchBench: Benchmarking LLMs in Scientific Discovery via Inspiration-Based Task Decomposition", "abstract": "Large language models (LLMs) have demonstrated potential in assisting\nscientific research, yet their ability to discover high-quality research\nhypotheses remains unexamined due to the lack of a dedicated benchmark. To\naddress this gap, we introduce the first large-scale benchmark for evaluating\nLLMs with a near-sufficient set of sub-tasks of scientific discovery:\ninspiration retrieval, hypothesis composition, and hypothesis ranking. We\ndevelop an automated framework that extracts critical components - research\nquestions, background surveys, inspirations, and hypotheses - from scientific\npapers across 12 disciplines, with expert validation confirming its accuracy.\nTo prevent data contamination, we focus exclusively on papers published in\n2024, ensuring minimal overlap with LLM pretraining data. Our evaluation\nreveals that LLMs perform well in retrieving inspirations, an\nout-of-distribution task, suggesting their ability to surface novel knowledge\nassociations. This positions LLMs as \"research hypothesis mines\", capable of\nfacilitating automated scientific discovery by generating innovative hypotheses\nat scale with minimal human intervention.", "published": "2025-03-27 08:09:15", "link": "http://arxiv.org/abs/2503.21248v1", "categories": ["cs.CL", "cs.AI", "cs.CE"], "primary_category": "cs.CL"}
{"title": "Bias-Aware Agent: Enhancing Fairness in AI-Driven Knowledge Retrieval", "abstract": "Advancements in retrieving accessible information have evolved faster in the\nlast few years compared to the decades since the internet's creation. Search\nengines, like Google, have been the number one way to find relevant data. They\nhave always relied on the user's abilities to find the best information in its\nbillions of links and sources at everybody's fingertips. The advent of large\nlanguage models (LLMs) has completely transformed the field of information\nretrieval. The LLMs excel not only at retrieving relevant knowledge but also at\nsummarizing it effectively, making information more accessible and consumable\nfor users. On top of it, the rise of AI Agents has introduced another aspect to\ninformation retrieval i.e. dynamic information retrieval which enables the\nintegration of real-time data such as weather forecasts, and financial data\nwith the knowledge base to curate context-aware knowledge. However, despite\nthese advancements the agents remain susceptible to issues of bias and\nfairness, challenges deeply rooted within the knowledge base and training of\nLLMs. This study introduces a novel approach to bias-aware knowledge retrieval\nby leveraging agentic framework and the innovative use of bias detectors as\ntools to identify and highlight inherent biases in the retrieved content. By\nempowering users with transparency and awareness, this approach aims to foster\nmore equitable information systems and promote the development of responsible\nAI.", "published": "2025-03-27 07:54:39", "link": "http://arxiv.org/abs/2503.21237v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "LLaVA-CMoE: Towards Continual Mixture of Experts for Large Vision-Language Models", "abstract": "Although applying Mixture of Experts to large language models for learning\nnew tasks is widely regarded as an effective strategy for continuous learning,\nthere still remain two major challenges: (1) As the number of tasks grows,\nsimple parameter expansion strategies can lead to excessively large models. (2)\nModifying the parameters of the existing router results in the erosion of\npreviously acquired knowledge. In this paper, we present an innovative\nframework named LLaVA-CMoE, which is a continuous Mixture of Experts (MoE)\narchitecture without any replay data. Specifically, we have developed a method\ncalled Probe-Guided Knowledge Extension (PGKE), which employs probe experts to\nassess whether additional knowledge is required for a specific layer. This\napproach enables the model to adaptively expand its network parameters based on\ntask distribution, thereby significantly improving the efficiency of parameter\nexpansion. Additionally, we introduce a hierarchical routing algorithm called\nProbabilistic Task Locator (PTL), where high-level routing captures inter-task\ninformation and low-level routing focuses on intra-task details, ensuring that\nnew task experts do not interfere with existing ones. Our experiments shows\nthat our efficient architecture has substantially improved model performance on\nthe Coin benchmark while maintaining a reasonable parameter count.", "published": "2025-03-27 07:36:11", "link": "http://arxiv.org/abs/2503.21227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VoxRep: Enhancing 3D Spatial Understanding in 2D Vision-Language Models via Voxel Representation", "abstract": "Comprehending 3D environments is vital for intelligent systems in domains\nlike robotics and autonomous navigation. Voxel grids offer a structured\nrepresentation of 3D space, but extracting high-level semantic meaning remains\nchallenging. This paper proposes a novel approach utilizing a Vision-Language\nModel (VLM) to extract \"voxel semantics\"-object identity, color, and\nlocation-from voxel data. Critically, instead of employing complex 3D networks,\nour method processes the voxel space by systematically slicing it along a\nprimary axis (e.g., the Z-axis, analogous to CT scan slices). These 2D slices\nare then formatted and sequentially fed into the image encoder of a standard\nVLM. The model learns to aggregate information across slices and correlate\nspatial patterns with semantic concepts provided by the language component.\nThis slice-based strategy aims to leverage the power of pre-trained 2D VLMs for\nefficient 3D semantic understanding directly from voxel representations.", "published": "2025-03-27 07:07:11", "link": "http://arxiv.org/abs/2503.21214v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MSPLoRA: A Multi-Scale Pyramid Low-Rank Adaptation for Efficient Model Fine-Tuning", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has become an essential approach for\nadapting large-scale pre-trained models while reducing computational costs.\nAmong PEFT methods, LoRA significantly reduces trainable parameters by\ndecomposing weight updates into low-rank matrices. However, traditional LoRA\napplies a fixed rank across all layers, failing to account for the varying\ncomplexity of hierarchical information, which leads to inefficient adaptation\nand redundancy. To address this, we propose MSPLoRA (Multi-Scale Pyramid LoRA),\nwhich introduces Global Shared LoRA, Mid-Level Shared LoRA, and Layer-Specific\nLoRA to capture global patterns, mid-level features, and fine-grained\ninformation, respectively. This hierarchical structure reduces inter-layer\nredundancy while maintaining strong adaptation capability. Experiments on\nvarious NLP tasks demonstrate that MSPLoRA achieves more efficient adaptation\nand better performance while significantly reducing the number of trainable\nparameters. Furthermore, additional analyses based on Singular Value\nDecomposition validate its information decoupling ability, highlighting MSPLoRA\nas a scalable and effective optimization strategy for parameter-efficient\nfine-tuning in large language models. Our code is available at\nhttps://github.com/Oblivioniss/MSPLoRA.", "published": "2025-03-27 07:01:50", "link": "http://arxiv.org/abs/2503.21838v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UGen: Unified Autoregressive Multimodal Model with Progressive Vocabulary Learning", "abstract": "We introduce UGen, a unified autoregressive multimodal model that\ndemonstrates strong performance across text processing, image understanding,\nand image generation tasks simultaneously. UGen converts both texts and images\ninto discrete token sequences and utilizes a single transformer to generate\nthem uniformly in an autoregressive manner. To address the challenges\nassociated with unified multimodal learning, UGen is trained using a novel\nmechanism, namely progressive vocabulary learning. In this process, visual\ntoken IDs are incrementally activated and integrated into the training phase,\nultimately enhancing the effectiveness of unified multimodal learning.\nExperiments on comprehensive text and image tasks show that UGen achieves a\nsignificant overall performance improvement of 13.3% compared to the vanilla\nunified autoregressive method, and it also delivers competitive results across\nall tasks against several task-specific models.", "published": "2025-03-27 06:19:29", "link": "http://arxiv.org/abs/2503.21193v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection", "abstract": "The proliferation of fake news on social media platforms has exerted a\nsubstantial influence on society, leading to discernible impacts and\ndeleterious consequences. Conventional deep learning methodologies employing\nsmall language models (SLMs) suffer from the necessity for extensive supervised\ntraining and the challenge of adapting to rapidly evolving circumstances. Large\nlanguage models (LLMs), despite their robust zero-shot capabilities, have\nfallen short in effectively identifying fake news due to a lack of pertinent\ndemonstrations and the dynamic nature of knowledge. In this paper, a novel\nframework Multi-Round Collaboration Detection (MRCD) is proposed to address\nthese aforementioned limitations. The MRCD framework is capable of enjoying the\nmerits from both LLMs and SLMs by integrating their generalization abilities\nand specialized functionalities, respectively. Our approach features a\ntwo-stage retrieval module that selects relevant and up-to-date demonstrations\nand knowledge, enhancing in-context learning for better detection of emerging\nnews events. We further design a multi-round learning framework to ensure more\nreliable detection results. Our framework MRCD achieves SOTA results on two\nreal-world datasets Pheme and Twitter16, with accuracy improvements of 7.4\\%\nand 12.8\\% compared to using only SLMs, which effectively addresses the\nlimitations of current models and improves the detection of emergent fake news.", "published": "2025-03-27 03:39:26", "link": "http://arxiv.org/abs/2503.21127v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Risk Assessment in Hyperconnected Logistic Hub Network Deployment", "abstract": "The growing emphasis on energy efficiency and environmental sustainability in\nglobal supply chains introduces new challenges in the deployment of\nhyperconnected logistic hub networks. In current volatile, uncertain, complex,\nand ambiguous (VUCA) environments, dynamic risk assessment becomes essential to\nensure successful hub deployment. However, traditional methods often struggle\nto effectively capture and analyze unstructured information. In this paper, we\ndesign an Large Language Model (LLM)-driven risk assessment pipeline integrated\nwith multiple analytical tools to evaluate logistic hub deployment. This\nframework enables LLMs to systematically identify potential risks by analyzing\nunstructured data, such as geopolitical instability, financial trends,\nhistorical storm events, traffic conditions, and emerging risks from news\nsources. These data are processed through a suite of analytical tools, which\nare automatically called by LLMs to support a structured and data-driven\ndecision-making process for logistic hub selection. In addition, we design\nprompts that instruct LLMs to leverage these tools for assessing the\nfeasibility of hub selection by evaluating various risk types and levels.\nThrough risk-based similarity analysis, LLMs cluster logistic hubs with\ncomparable risk profiles, enabling a structured approach to risk assessment. In\nconclusion, the framework incorporates scalability with long-term memory and\nenhances decision-making through explanation and interpretation, enabling\ncomprehensive risk assessments for logistic hub deployment in hyperconnected\nsupply chain networks.", "published": "2025-03-27 03:13:22", "link": "http://arxiv.org/abs/2503.21115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring and Analyzing Subjective Uncertainty in Scientific Communications", "abstract": "Uncertainty of scientific findings are typically reported through statistical\nmetrics such as $p$-values, confidence intervals, etc. The magnitude of this\nobjective uncertainty is reflected in the language used by the authors to\nreport their findings primarily through expressions carrying\nuncertainty-inducing terms or phrases. This language uncertainty is a\nsubjective concept and is highly dependent on the writing style of the authors.\nThere is evidence that such subjective uncertainty influences the impact of\nscience on public audience. In this work, we turned our focus to scientists\nthemselves, and measured/analyzed the subjective uncertainty and its impact\nwithin scientific communities across different disciplines. We showed that the\nlevel of this type of uncertainty varies significantly across different fields,\nyears of publication and geographical locations. We also studied the\ncorrelation between subjective uncertainty and several bibliographical metrics,\nsuch as number/gender of authors, centrality of the field's community, citation\ncount, etc. The underlying patterns identified in this work are useful in\nidentification and documentation of linguistic norms in scientific\ncommunication in different communities/societies.", "published": "2025-03-27 03:12:50", "link": "http://arxiv.org/abs/2503.21114v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Function Alignment: A New Theory of Mind and Intelligence, Part I: Foundations", "abstract": "This paper introduces function alignment, a novel theory of mind and\nintelligence that is both intuitively compelling and structurally grounded. It\nexplicitly models how meaning, interpretation, and analogy emerge from\ninteractions among layered representations, forming a coherent framework\ncapable not only of modeling minds but also of serving as a blueprint for\nbuilding them. One of the key theoretical insights derived from function\nalignment is bounded interpretability, which provides a unified explanation for\npreviously fragmented ideas in cognitive science, such as bounded rationality,\nsymbol grounding, and analogy-making. Beyond modeling, the function alignment\nframework bridges disciplines often kept apart, linking computational\narchitecture, psychological theory, and even contemplative traditions such as\nZen. Rather than building on any philosophical systems, it offers a structural\nfoundation upon which multiple ways of understanding the mind may be\nreconstructed.", "published": "2025-03-27 02:59:01", "link": "http://arxiv.org/abs/2503.21106v3", "categories": ["cs.CL", "68T27, 91E45", "I.2.0; I.2.4; F.4.1"], "primary_category": "cs.CL"}
{"title": "ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging", "abstract": "This paper presents the ZJUKLAB team's submission for SemEval-2025 Task 4:\nUnlearning Sensitive Content from Large Language Models. This task aims to\nselectively erase sensitive knowledge from large language models, avoiding both\nover-forgetting and under-forgetting issues. We propose an unlearning system\nthat leverages Model Merging (specifically TIES-Merging), combining two\nspecialized models into a more balanced unlearned model. Our system achieves\ncompetitive results, ranking second among 26 teams, with an online score of\n0.944 for Task Aggregate and 0.487 for overall Aggregate. In this paper, we\nalso conduct local experiments and perform a comprehensive analysis of the\nunlearning process, examining performance trajectories, loss dynamics, and\nweight perspectives, along with several supplementary experiments, to\nunderstand the effectiveness of our method. Furthermore, we analyze the\nshortcomings of our method and evaluation metrics, emphasizing that MIA scores\nand ROUGE-based metrics alone are insufficient to fully evaluate successful\nunlearning. Finally, we emphasize the need for more comprehensive evaluation\nmethodologies and rethinking of unlearning objectives in future research. Code\nis available at https://github.com/zjunlp/unlearn/tree/main/semeval25.", "published": "2025-03-27 02:03:25", "link": "http://arxiv.org/abs/2503.21088v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "EQ-Negotiator: An Emotion-Reasoning LLM Agent in Credit Dialogues", "abstract": "While large language model (LLM)-based chatbots have been applied for\neffective engagement in credit dialogues, their capacity for dynamic emotional\nexpression remains limited. Current agents primarily rely on passive empathy\nrather than affective reasoning. For instance, when faced with persistent\nclient negativity, the agent should employ strategic emotional adaptation by\nexpressing measured anger to discourage counterproductive behavior and guide\nthe conversation toward resolution. This context-aware emotional modulation is\nessential for imitating the nuanced decision-making of human negotiators. This\npaper introduces an EQ-negotiator that combines emotion sensing from\npre-trained language models (PLMs) with emotional reasoning based on Game\nTheory and Hidden Markov Models. It takes into account both the current and\nhistorical emotions of the client to better manage and address negative\nemotions during interactions. By fine-tuning pre-trained language models (PLMs)\non public emotion datasets and validating them on the credit dialogue datasets,\nour approach enables LLM-based agents to effectively capture shifts in client\nemotions and dynamically adjust their response tone based on our emotion\ndecision policies in real-world financial negotiations. This EQ-negotiator can\nalso help credit agencies foster positive client relationships, enhancing\nsatisfaction in credit services.", "published": "2025-03-27 01:41:34", "link": "http://arxiv.org/abs/2503.21080v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rerouting Connection: Hybrid Computer Vision Analysis Reveals Visual Similarity Between Indus and Tibetan-Yi Corridor Writing Systems", "abstract": "This thesis employs a hybrid CNN-Transformer architecture, in conjunction\nwith a detailed anthropological framework, to investigate potential historical\nconnections between the visual morphology of the Indus Valley script and\npictographic systems of the Tibetan-Yi Corridor. Through an ensemble\nmethodology of three target scripts across 15 independently trained models, we\ndemonstrate that Tibetan-Yi Corridor scripts exhibit approximately six-fold\nhigher visual similarity to the Indus script (61.7%-63.5%) than to the Bronze\nAge Proto-Cuneiform (10.2%-10.9%) or Proto-Elamite (7.6%-8.7%) systems.\nAdditionally and contrarily to our current understanding of the networks of the\nIndus Valley Civilization, the Indus script unexpectedly maps closer to\nTibetan-Yi Corridor scripts, with a mean cosine similarity of 0.629, than to\nthe aforementioned contemporaneous West Asian signaries, both of which recorded\nmean cosine similarities of 0.104 and 0.080 despite their close geographic\nproximity and evident trade relations. Across various dimensionality reduction\npractices and clustering methodologies, the Indus script consistently clusters\nclosest to Tibetan-Yi Corridor scripts. Our computational results align with\nqualitative observations of specific pictorial parallels in numeral systems,\ngender markers, and key iconographic elements; this is further supported by\narchaeological evidence of sustained contact networks along the ancient\nShu-Shendu road in tandem with the Indus Valley Civilization's decline,\nproviding a plausible transmission pathway. While alternative explanations\ncannot be ruled out, the specificity and consistency of observed similarities\nchallenge conventional narratives of isolated script development and suggest\nmore complex ancient cultural transmission networks between South and East Asia\nthan previously recognized.", "published": "2025-03-27 01:19:47", "link": "http://arxiv.org/abs/2503.21074v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Shared Global and Local Geometry of Language Model Embeddings", "abstract": "Researchers have recently suggested that models share common representations.\nIn this work, we find that the token embeddings of language models exhibit\ncommon geometric structure. First, we find ``global'' similarities: token\nembeddings often share similar relative orientations. Next, we characterize\nlocal geometry in two ways: (1) by using Locally Linear Embeddings, and (2) by\ndefining a simple measure for the intrinsic dimension of each token embedding.\nOur intrinsic dimension measure demonstrates that token embeddings lie on a\nlower dimensional manifold. We qualitatively show that tokens with lower\nintrinsic dimensions often have semantically coherent clusters, while those\nwith higher intrinsic dimensions do not. Both characterizations allow us to\nfind similarities in the local geometry of token embeddings. Perhaps most\nsurprisingly, we find that alignment in token embeddings persists through the\nhidden states of language models, allowing us to develop an application for\ninterpretability. Namely, we empirically demonstrate that steering vectors from\none language model can be transferred to another, despite the two models having\ndifferent dimensions.", "published": "2025-03-27 01:17:06", "link": "http://arxiv.org/abs/2503.21073v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AskSport: Web Application for Sports Question-Answering", "abstract": "This paper introduces AskSport, a question-answering web application about\nsports. It allows users to ask questions using natural language and retrieve\nthe three most relevant answers, including related information and documents.\nThe paper describes the characteristics and functionalities of the application,\nincluding use cases demonstrating its ability to return names and numerical\nvalues. AskSport and its implementation are available for public access on\nHuggingFace.", "published": "2025-03-27 00:57:27", "link": "http://arxiv.org/abs/2503.21067v1", "categories": ["cs.AI", "cs.CL", "I.2.1; I.2.7"], "primary_category": "cs.AI"}
{"title": "Safeguarding Autonomy: a Focus on Machine Learning Decision Systems", "abstract": "As global discourse on AI regulation gains momentum, this paper focuses on\ndelineating the impact of ML on autonomy and fostering awareness. Respect for\nautonomy is a basic principle in bioethics that establishes persons as\ndecision-makers. While the concept of autonomy in the context of ML appears in\nseveral European normative publications, it remains a theoretical concept that\nhas yet to be widely accepted in ML practice. Our contribution is to bridge the\ntheoretical and practical gap by encouraging the practical application of\nautonomy in decision-making within ML practice by identifying the conditioning\nfactors that currently prevent it. Consequently, we focus on the different\nstages of the ML pipeline to identify the potential effects on ML end-users'\nautonomy. To improve its practical utility, we propose a related question for\neach detected impact, offering guidance for identifying possible focus points\nto respect ML end-users autonomy in decision-making.", "published": "2025-03-27 22:31:16", "link": "http://arxiv.org/abs/2503.22023v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models", "abstract": "Vision-language-action models (VLAs) have shown potential in leveraging\npretrained vision-language models and diverse robot demonstrations for learning\ngeneralizable sensorimotor control. While this paradigm effectively utilizes\nlarge-scale data from both robotic and non-robotic sources, current VLAs\nprimarily focus on direct input--output mappings, lacking the intermediate\nreasoning steps crucial for complex manipulation tasks. As a result, existing\nVLAs lack temporal planning or reasoning capabilities. In this paper, we\nintroduce a method that incorporates explicit visual chain-of-thought (CoT)\nreasoning into vision-language-action models (VLAs) by predicting future image\nframes autoregressively as visual goals before generating a short action\nsequence to achieve these goals. We introduce CoT-VLA, a state-of-the-art 7B\nVLA that can understand and generate visual and action tokens. Our experimental\nresults demonstrate that CoT-VLA achieves strong performance, outperforming the\nstate-of-the-art VLA model by 17% in real-world manipulation tasks and 6% in\nsimulation benchmarks. Project website: https://cot-vla.github.io/", "published": "2025-03-27 22:23:04", "link": "http://arxiv.org/abs/2503.22020v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "BOOTPLACE: Bootstrapped Object Placement with Detection Transformers", "abstract": "In this paper, we tackle the copy-paste image-to-image composition problem\nwith a focus on object placement learning. Prior methods have leveraged\ngenerative models to reduce the reliance for dense supervision. However, this\noften limits their capacity to model complex data distributions. Alternatively,\ntransformer networks with a sparse contrastive loss have been explored, but\ntheir over-relaxed regularization often leads to imprecise object placement. We\nintroduce BOOTPLACE, a novel paradigm that formulates object placement as a\nplacement-by-detection problem. Our approach begins by identifying suitable\nregions of interest for object placement. This is achieved by training a\nspecialized detection transformer on object-subtracted backgrounds, enhanced\nwith multi-object supervisions. It then semantically associates each target\ncompositing object with detected regions based on their complementary\ncharacteristics. Through a boostrapped training approach applied to randomly\nobject-subtracted images, our model enforces meaningful placements through\nextensive paired data augmentation. Experimental results on established\nbenchmarks demonstrate BOOTPLACE's superior performance in object\nrepositioning, markedly surpassing state-of-the-art baselines on Cityscapes and\nOPA datasets with notable improvements in IOU scores. Additional ablation\nstudies further showcase the compositionality and generalizability of our\napproach, supported by user study evaluations.", "published": "2025-03-27 21:21:20", "link": "http://arxiv.org/abs/2503.21991v1", "categories": ["cs.CV", "cs.AI", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Pretrained Bayesian Non-parametric Knowledge Prior in Robotic Long-Horizon Reinforcement Learning", "abstract": "Reinforcement learning (RL) methods typically learn new tasks from scratch,\noften disregarding prior knowledge that could accelerate the learning process.\nWhile some methods incorporate previously learned skills, they usually rely on\na fixed structure, such as a single Gaussian distribution, to define skill\npriors. This rigid assumption can restrict the diversity and flexibility of\nskills, particularly in complex, long-horizon tasks. In this work, we introduce\na method that models potential primitive skill motions as having non-parametric\nproperties with an unknown number of underlying features. We utilize a Bayesian\nnon-parametric model, specifically Dirichlet Process Mixtures, enhanced with\nbirth and merge heuristics, to pre-train a skill prior that effectively\ncaptures the diverse nature of skills. Additionally, the learned skills are\nexplicitly trackable within the prior space, enhancing interpretability and\ncontrol. By integrating this flexible skill prior into an RL framework, our\napproach surpasses existing methods in long-horizon manipulation tasks,\nenabling more efficient skill transfer and task success in complex\nenvironments. Our findings show that a richer, non-parametric representation of\nskill priors significantly improves both the learning and execution of\nchallenging robotic tasks. All data, code, and videos are available at\nhttps://ghiara.github.io/HELIOS/.", "published": "2025-03-27 20:43:36", "link": "http://arxiv.org/abs/2503.21975v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Data-Agnostic Robotic Long-Horizon Manipulation with Vision-Language-Guided Closed-Loop Feedback", "abstract": "Recent advances in language-conditioned robotic manipulation have leveraged\nimitation and reinforcement learning to enable robots to execute tasks from\nhuman commands. However, these methods often suffer from limited\ngeneralization, adaptability, and the lack of large-scale specialized datasets,\nunlike data-rich domains such as computer vision, making long-horizon task\nexecution challenging. To address these gaps, we introduce DAHLIA, a\ndata-agnostic framework for language-conditioned long-horizon robotic\nmanipulation, leveraging large language models (LLMs) for real-time task\nplanning and execution. DAHLIA employs a dual-tunnel architecture, where an\nLLM-powered planner collaborates with co-planners to decompose tasks and\ngenerate executable plans, while a reporter LLM provides closed-loop feedback,\nenabling adaptive re-planning and ensuring task recovery from potential\nfailures. Moreover, DAHLIA integrates chain-of-thought (CoT) in task reasoning\nand temporal abstraction for efficient action execution, enhancing traceability\nand robustness. Our framework demonstrates state-of-the-art performance across\ndiverse long-horizon tasks, achieving strong generalization in both simulated\nand real-world scenarios. Videos and code are available at\nhttps://ghiara.github.io/DAHLIA/.", "published": "2025-03-27 20:32:58", "link": "http://arxiv.org/abs/2503.21969v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Parametric Shadow Control for Portrait Generation in Text-to-Image Diffusion Models", "abstract": "Text-to-image diffusion models excel at generating diverse portraits, but\nlack intuitive shadow control. Existing editing approaches, as post-processing,\nstruggle to offer effective manipulation across diverse styles. Additionally,\nthese methods either rely on expensive real-world light-stage data collection\nor require extensive computational resources for training. To address these\nlimitations, we introduce Shadow Director, a method that extracts and\nmanipulates hidden shadow attributes within well-trained diffusion models. Our\napproach uses a small estimation network that requires only a few thousand\nsynthetic images and hours of training-no costly real-world light-stage data\nneeded. Shadow Director enables parametric and intuitive control over shadow\nshape, placement, and intensity during portrait generation while preserving\nartistic integrity and identity across diverse styles. Despite training only on\nsynthetic data built on real-world identities, it generalizes effectively to\ngenerated portraits with diverse styles, making it a more accessible and\nresource-friendly solution.", "published": "2025-03-27 19:42:52", "link": "http://arxiv.org/abs/2503.21943v2", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Lobster: A GPU-Accelerated Framework for Neurosymbolic Programming", "abstract": "Neurosymbolic programs combine deep learning with symbolic reasoning to\nachieve better data efficiency, interpretability, and generalizability compared\nto standalone deep learning approaches. However, existing neurosymbolic\nlearning frameworks implement an uneasy marriage between a highly scalable,\nGPU-accelerated neural component with a slower symbolic component that runs on\nCPUs. We propose Lobster, a unified framework for harnessing GPUs in an\nend-to-end manner for neurosymbolic learning. Lobster maps a general\nneurosymbolic language based on Datalog to the GPU programming paradigm. This\nmapping is implemented via compilation to a new intermediate language called\nAPM. The extra abstraction provided by APM allows Lobster to be both flexible,\nsupporting discrete, probabilistic, and differentiable modes of reasoning on\nGPU hardware with a library of provenance semirings, and performant,\nimplementing new optimization passes. We demonstrate that Lobster programs can\nsolve interesting problems spanning the domains of natural language processing,\nimage processing, program reasoning, bioinformatics, and planning. On a suite\nof 8 applications, Lobster achieves an average speedup of 5.3x over Scallop, a\nstate-of-the-art neurosymbolic framework, and enables scaling of neurosymbolic\nsolutions to previously infeasible tasks.", "published": "2025-03-27 19:32:58", "link": "http://arxiv.org/abs/2503.21937v1", "categories": ["cs.PL", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.PL"}
{"title": "An Efficient Training Algorithm for Models with Block-wise Sparsity", "abstract": "Large-scale machine learning (ML) models are increasingly being used in\ncritical domains like education, lending, recruitment, healthcare, criminal\njustice, etc. However, the training, deployment, and utilization of these\nmodels demand substantial computational resources. To decrease computation and\nmemory costs, machine learning models with sparse weight matrices are widely\nused in the literature. Among sparse models, those with special sparse\nstructures (e.g., models with block-wise sparse weight matrices) fit better\nwith the hardware accelerators and can decrease the memory and computation\ncosts during the inference. Unfortunately, while there are several efficient\ntraining methods, none of them are designed to train a block-wise sparse model\nefficiently. As a result, the current methods for training block-wise sparse\nmodels start with full and dense models leading to inefficient training. In\nthis work, we focus on training models with \\textit{block-wise sparse matrices}\nand propose an efficient training algorithm to decrease both computation and\nmemory costs during training and inference. In addition, we will show that our\nproposed method enables us to efficiently find the right block size for the\nsparsity pattern during the training process. Our extensive empirical and\ntheoretical analyses show that our algorithms can decrease the computation and\nmemory costs significantly without a performance drop compared to baselines.", "published": "2025-03-27 19:14:27", "link": "http://arxiv.org/abs/2503.21928v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Cost of Local and Global Fairness in Federated Learning", "abstract": "With the emerging application of Federated Learning (FL) in finance, hiring\nand healthcare, FL models are regulated to be fair, preventing disparities with\nrespect to legally protected attributes such as race or gender. Two concepts of\nfairness are important in FL: global and local fairness. Global fairness\naddresses the disparity across the entire population and local fairness is\nconcerned with the disparity within each client. Prior fair FL frameworks have\nimproved either global or local fairness without considering both. Furthermore,\nwhile the majority of studies on fair FL focuses on binary settings, many\nreal-world applications are multi-class problems. This paper proposes a\nframework that investigates the minimum accuracy lost for enforcing a specified\nlevel of global and local fairness in multi-class FL settings. Our framework\nleads to a simple post-processing algorithm that derives fair outcome\npredictors from the Bayesian optimal score functions. Experimental results show\nthat our algorithm outperforms the current state of the art (SOTA) with regard\nto the accuracy-fairness tradoffs, computational and communication costs. Codes\nare available at:\nhttps://github.com/papersubmission678/The-cost-of-local-and-global-fairness-in-FL .", "published": "2025-03-27 18:37:54", "link": "http://arxiv.org/abs/2503.22762v1", "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Exponentially Weighted Instance-Aware Repeat Factor Sampling for Long-Tailed Object Detection Model Training in Unmanned Aerial Vehicles Surveillance Scenarios", "abstract": "Object detection models often struggle with class imbalance, where rare\ncategories appear significantly less frequently than common ones. Existing\nsampling-based rebalancing strategies, such as Repeat Factor Sampling (RFS) and\nInstance-Aware Repeat Factor Sampling (IRFS), mitigate this issue by adjusting\nsample frequencies based on image and instance counts. However, these methods\nare based on linear adjustments, which limit their effectiveness in long-tailed\ndistributions. This work introduces Exponentially Weighted Instance-Aware\nRepeat Factor Sampling (E-IRFS), an extension of IRFS that applies exponential\nscaling to better differentiate between rare and frequent classes. E-IRFS\nadjusts sampling probabilities using an exponential function applied to the\ngeometric mean of image and instance frequencies, ensuring a more adaptive\nrebalancing strategy. We evaluate E-IRFS on a dataset derived from the\nFireman-UAV-RGBT Dataset and four additional public datasets, using YOLOv11\nobject detection models to identify fire, smoke, people and lakes in emergency\nscenarios. The results show that E-IRFS improves detection performance by 22\\%\nover the baseline and outperforms RFS and IRFS, particularly for rare\ncategories. The analysis also highlights that E-IRFS has a stronger effect on\nlightweight models with limited capacity, as these models rely more on data\nsampling strategies to address class imbalance. The findings demonstrate that\nE-IRFS improves rare object detection in resource-constrained environments,\nmaking it a suitable solution for real-time applications such as UAV-based\nemergency monitoring.", "published": "2025-03-27 18:09:37", "link": "http://arxiv.org/abs/2503.21893v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "StarFlow: Generating Structured Workflow Outputs From Sketch Images", "abstract": "Workflows are a fundamental component of automation in enterprise platforms,\nenabling the orchestration of tasks, data processing, and system integrations.\nDespite being widely used, building workflows can be complex, often requiring\nmanual configuration through low-code platforms or visual programming tools. To\nsimplify this process, we explore the use of generative foundation models,\nparticularly vision-language models (VLMs), to automatically generate\nstructured workflows from visual inputs. Translating hand-drawn sketches or\ncomputer-generated diagrams into executable workflows is challenging due to the\nambiguity of free-form drawings, variations in diagram styles, and the\ndifficulty of inferring execution logic from visual elements. To address this,\nwe introduce StarFlow, a framework for generating structured workflow outputs\nfrom sketches using vision-language models. We curate a diverse dataset of\nworkflow diagrams -- including synthetic, manually annotated, and real-world\nsamples -- to enable robust training and evaluation. We finetune and benchmark\nmultiple vision-language models, conducting a series of ablation studies to\nanalyze the strengths and limitations of our approach. Our results show that\nfinetuning significantly enhances structured workflow generation, outperforming\nlarge vision-language models on this task.", "published": "2025-03-27 18:04:05", "link": "http://arxiv.org/abs/2503.21889v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Is Best-of-N the Best of Them? Coverage, Scaling, and Optimality in Inference-Time Alignment", "abstract": "Inference-time computation provides an important axis for scaling language\nmodel performance, but naively scaling compute through techniques like\nBest-of-$N$ sampling can cause performance to degrade due to reward hacking.\nToward a theoretical understanding of how to best leverage additional\ncomputation, we focus on inference-time alignment which we formalize as the\nproblem of improving a pre-trained policy's responses for a prompt of interest,\ngiven access to an imperfect reward model. We analyze the performance of\ninference-time alignment algorithms in terms of (i) response quality, and (ii)\ncompute, and provide new results that highlight the importance of the\npre-trained policy's coverage over high-quality responses for performance and\ncompute scaling:\n  1. We show that Best-of-$N$ alignment with an ideal choice for $N$ can\nachieve optimal performance under stringent notions of coverage, but provably\nsuffers from reward hacking when $N$ is large, and fails to achieve tight\nguarantees under more realistic coverage conditions.\n  2. We introduce $\\texttt{InferenceTimePessimism}$, a new algorithm which\nmitigates reward hacking through deliberate use of inference-time compute,\nimplementing the principle of pessimism in the face of uncertainty via\nrejection sampling; we prove that its performance is optimal and does not\ndegrade with $N$, meaning it is scaling-monotonic.\n  We complement our theoretical results with an experimental evaluation that\ndemonstrate the benefits of $\\texttt{InferenceTimePessimism}$ across a variety\nof tasks and models.", "published": "2025-03-27 18:00:08", "link": "http://arxiv.org/abs/2503.21878v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Stable-SCore: A Stable Registration-based Framework for 3D Shape Correspondence", "abstract": "Establishing character shape correspondence is a critical and fundamental\ntask in computer vision and graphics, with diverse applications including\nre-topology, attribute transfer, and shape interpolation. Current dominant\nfunctional map methods, while effective in controlled scenarios, struggle in\nreal situations with more complex challenges such as non-isometric shape\ndiscrepancies. In response, we revisit registration-for-correspondence methods\nand tap their potential for more stable shape correspondence estimation. To\novercome their common issues including unstable deformations and the necessity\nfor careful pre-alignment or high-quality initial 3D correspondences, we\nintroduce Stable-SCore: A Stable Registration-based Framework for 3D Shape\nCorrespondence. We first re-purpose a foundation model for 2D character\ncorrespondence that ensures reliable and stable 2D mappings. Crucially, we\npropose a novel Semantic Flow Guided Registration approach that leverages 2D\ncorrespondence to guide mesh deformations. Our framework significantly\nsurpasses existing methods in challenging scenarios, and brings possibilities\nfor a wide array of real applications, as demonstrated in our results.", "published": "2025-03-27 17:59:02", "link": "http://arxiv.org/abs/2503.21766v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single Video", "abstract": "This paper presents a unified approach to understanding dynamic scenes from\ncasual videos. Large pretrained vision foundation models, such as\nvision-language, video depth prediction, motion tracking, and segmentation\nmodels, offer promising capabilities. However, training a single model for\ncomprehensive 4D understanding remains challenging. We introduce Uni4D, a\nmulti-stage optimization framework that harnesses multiple pretrained models to\nadvance dynamic 3D modeling, including static/dynamic reconstruction, camera\npose estimation, and dense 3D motion tracking. Our results show\nstate-of-the-art performance in dynamic 4D modeling with superior visual\nquality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the\neffectiveness of repurposing visual foundation models for 4D understanding.", "published": "2025-03-27 17:57:32", "link": "http://arxiv.org/abs/2503.21761v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck", "abstract": "In this work, we aim to compress the vision tokens of a Large Vision Language\nModel (LVLM) into a representation that is simultaneously suitable for (a)\ngenerative and (b) discriminative tasks, (c) is nearly lossless, and (d) is\nstorage-efficient. We propose a novel compression approach, called Fwd2Bot,\nthat uses the LVLM itself to compress the visual information in a task-agnostic\nmanner. At the core of Fwd2bot there exists a \"double-forward pass\" training\nstrategy, whereby, during the first forward pass, the LLM (of the LVLM) creates\na bottleneck by condensing the visual information into a small number of\nsummary tokens. Then, using the same LLM, the second forward pass processes the\nlanguage instruction(s) alongside the summary tokens, used as a direct\nreplacement for the image ones. The training signal is provided by two losses:\nan autoregressive one applied after the second pass that provides a direct\noptimization objective for compression, and a contrastive loss, applied after\nthe first pass, that further boosts the representation strength, especially for\ndiscriminative tasks. The training is further enhanced by stage-specific\nadapters. We accompany the proposed method by an in-depth ablation study.\nOverall, Fwd2Bot results in highly-informative compressed representations\nsuitable for both generative and discriminative tasks. For generative tasks, we\noffer a 2x higher compression rate without compromising the generative\ncapabilities, setting a new state-of-the-art result. For discriminative tasks,\nwe set a new state-of-the-art on image retrieval and compositionality.", "published": "2025-03-27 17:57:07", "link": "http://arxiv.org/abs/2503.21757v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CTRL-O: Language-Controllable Object-Centric Visual Representation Learning", "abstract": "Object-centric representation learning aims to decompose visual scenes into\nfixed-size vectors called \"slots\" or \"object files\", where each slot captures a\ndistinct object. Current state-of-the-art object-centric models have shown\nremarkable success in object discovery in diverse domains, including complex\nreal-world scenes. However, these models suffer from a key limitation: they\nlack controllability. Specifically, current object-centric models learn\nrepresentations based on their preconceived understanding of objects, without\nallowing user input to guide which objects are represented. Introducing\ncontrollability into object-centric models could unlock a range of useful\ncapabilities, such as the ability to extract instance-specific representations\nfrom a scene. In this work, we propose a novel approach for user-directed\ncontrol over slot representations by conditioning slots on language\ndescriptions. The proposed ConTRoLlable Object-centric representation learning\napproach, which we term CTRL-O, achieves targeted object-language binding in\ncomplex real-world scenes without requiring mask supervision. Next, we apply\nthese controllable slot representations on two downstream vision language\ntasks: text-to-image generation and visual question answering. The proposed\napproach enables instance-specific text-to-image generation and also achieves\nstrong performance on visual question answering.", "published": "2025-03-27 17:53:50", "link": "http://arxiv.org/abs/2503.21747v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enhance Vision-based Tactile Sensors via Dynamic Illumination and Image Fusion", "abstract": "Vision-based tactile sensors use structured light to measure deformation in\ntheir elastomeric interface. Until now, vision-based tactile sensors such as\nDIGIT and GelSight have been using a single, static pattern of structured light\ntuned to the specific form factor of the sensor. In this work, we investigate\nthe effectiveness of dynamic illumination patterns, in conjunction with image\nfusion techniques, to improve the quality of sensing of vision-based tactile\nsensors. Specifically, we propose to capture multiple measurements, each with a\ndifferent illumination pattern, and then fuse them together to obtain a single,\nhigher-quality measurement. Experimental results demonstrate that this type of\ndynamic illumination yields significant improvements in image contrast,\nsharpness, and background difference. This discovery opens the possibility of\nretroactively improving the sensing quality of existing vision-based tactile\nsensors with a simple software update, and for new hardware designs capable of\nfully exploiting dynamic illumination.", "published": "2025-03-27 17:19:57", "link": "http://arxiv.org/abs/2504.00017v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Foveated Instance Segmentation", "abstract": "Instance segmentation is essential for augmented reality and virtual reality\n(AR/VR) as it enables precise object recognition and interaction, enhancing the\nintegration of virtual and real-world elements for an immersive experience.\nHowever, the high computational overhead of segmentation limits its application\non resource-constrained AR/VR devices, causing large processing latency and\ndegrading user experience. In contrast to conventional scenarios, AR/VR users\ntypically focus on only a few regions within their field of view before\nshifting perspective, allowing segmentation to be concentrated on gaze-specific\nareas. This insight drives the need for efficient segmentation methods that\nprioritize processing instance of interest, reducing computational load and\nenhancing real-time performance. In this paper, we present a foveated instance\nsegmentation (FovealSeg) framework that leverages real-time user gaze data to\nperform instance segmentation exclusively on instance of interest, resulting in\nsubstantial computational savings. Evaluation results show that FSNet achieves\nan IoU of 0.56 on ADE20K and 0.54 on LVIS, notably outperforming the baseline.\nThe code is available at https://github.com/SAI-", "published": "2025-03-27 17:08:44", "link": "http://arxiv.org/abs/2503.21854v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX", "abstract": "Frontier models have either been language-only or have primarily focused on\nvision and language modalities. Although recent advancements in models with\nvision and audio understanding capabilities have shown substantial progress,\nthe field lacks a standardized evaluation framework for thoroughly assessing\ntheir cross-modality perception performance. We introduce MAVERIX~(Multimodal\nAudio-Visual Evaluation Reasoning IndeX), a novel benchmark with 700 videos and\n2,556 questions explicitly designed to evaluate multimodal models through tasks\nthat necessitate close integration of video and audio information. MAVERIX\nuniquely provides models with audiovisual tasks, closely mimicking the\nmultimodal perceptual experiences available to humans during inference and\ndecision-making processes. To our knowledge, MAVERIX is the first benchmark\naimed explicitly at assessing comprehensive audiovisual integration.\nExperiments with state-of-the-art models, including Gemini 1.5 Pro and o1, show\nperformance approaching human levels (around 70% accuracy), while human experts\nreach near-ceiling performance (95.1%). With standardized evaluation protocols,\na rigorously annotated pipeline, and a public toolkit, MAVERIX establishes a\nchallenging testbed for advancing audiovisual multimodal intelligence.", "published": "2025-03-27 17:04:33", "link": "http://arxiv.org/abs/2503.21699v1", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "AMA-SAM: Adversarial Multi-Domain Alignment of Segment Anything Model for High-Fidelity Histology Nuclei Segmentation", "abstract": "Accurate segmentation of cell nuclei in histopathology images is essential\nfor numerous biomedical research and clinical applications. However, existing\ncell nucleus segmentation methods only consider a single dataset (i.e., primary\ndomain), while neglecting to leverage supplementary data from diverse sources\n(i.e., auxiliary domains) to reduce overfitting and enhance the performance.\nAlthough incorporating multiple datasets could alleviate overfitting, it often\nexacerbates performance drops caused by domain shifts. In this work, we\nintroduce Adversarial Multi-domain Alignment of Segment Anything Model\n(AMA-SAM) that extends the Segment Anything Model (SAM) to overcome these\nobstacles through two key innovations. First, we propose a Conditional Gradient\nReversal Layer (CGRL), a multi-domain alignment module that harmonizes features\nfrom diverse domains to promote domain-invariant representation learning while\npreserving crucial discriminative features for the primary dataset. Second, we\naddress SAM's inherent low-resolution output by designing a High-Resolution\nDecoder (HR-Decoder), which directly produces fine-grained segmentation maps in\norder to capture intricate nuclei boundaries in high-resolution histology\nimages. To the best of our knowledge, this is the first attempt to adapt SAM\nfor multi-dataset learning with application to histology nuclei segmentation.\nWe validate our method on several publicly available datasets, demonstrating\nconsistent and significant improvements over state-of-the-art approaches.", "published": "2025-03-27 16:59:39", "link": "http://arxiv.org/abs/2503.21695v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data", "abstract": "It is highly desirable to obtain a model that can generate high-quality 3D\nmeshes from text prompts in just seconds. While recent attempts have adapted\npre-trained text-to-image diffusion models, such as Stable Diffusion (SD), into\ngenerators of 3D representations (e.g., Triplane), they often suffer from poor\nquality due to the lack of sufficient high-quality 3D training data. Aiming at\novercoming the data shortage, we propose a novel training scheme, termed as\nProgressive Rendering Distillation (PRD), eliminating the need for 3D\nground-truths by distilling multi-view diffusion models and adapting SD into a\nnative 3D generator. In each iteration of training, PRD uses the U-Net to\nprogressively denoise the latent from random noise for a few steps, and in each\nstep it decodes the denoised latent into 3D output. Multi-view diffusion\nmodels, including MVDream and RichDreamer, are used in joint with SD to distill\ntext-consistent textures and geometries into the 3D outputs through score\ndistillation. Since PRD supports training without 3D ground-truths, we can\neasily scale up the training data and improve generation quality for\nchallenging text prompts with creative concepts. Meanwhile, PRD can accelerate\nthe inference speed of the generation model in just a few steps. With PRD, we\ntrain a Triplane generator, namely TriplaneTurbo, which adds only $2.5\\%$\ntrainable parameters to adapt SD for Triplane generation. TriplaneTurbo\noutperforms previous text-to-3D generators in both efficiency and quality.\nSpecifically, it can produce high-quality 3D meshes in 1.2 seconds and\ngeneralize well for challenging text input. The code is available at\nhttps://github.com/theEricMa/TriplaneTurbo.", "published": "2025-03-27 16:59:15", "link": "http://arxiv.org/abs/2503.21694v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "A tale of two goals: leveraging sequentiality in multi-goal scenarios", "abstract": "Several hierarchical reinforcement learning methods leverage planning to\ncreate a graph or sequences of intermediate goals, guiding a lower-level\ngoal-conditioned (GC) policy to reach some final goals. The low-level policy is\ntypically conditioned on the current goal, with the aim of reaching it as\nquickly as possible. However, this approach can fail when an intermediate goal\ncan be reached in multiple ways, some of which may make it impossible to\ncontinue toward subsequent goals. To address this issue, we introduce two\ninstances of Markov Decision Process (MDP) where the optimization objective\nfavors policies that not only reach the current goal but also subsequent ones.\nIn the first, the agent is conditioned on both the current and final goals,\nwhile in the second, it is conditioned on the next two goals in the sequence.\nWe conduct a series of experiments on navigation and pole-balancing tasks in\nwhich sequences of intermediate goals are given. By evaluating policies trained\nwith TD3+HER on both the standard GC-MDP and our proposed MDPs, we show that,\nin most cases, conditioning on the next two goals improves stability and sample\nefficiency over other approaches.", "published": "2025-03-27 16:47:46", "link": "http://arxiv.org/abs/2503.21677v1", "categories": ["cs.LG", "cs.AI", "68T40"], "primary_category": "cs.LG"}
{"title": "Comparative Analysis of Image, Video, and Audio Classifiers for Automated News Video Segmentation", "abstract": "News videos require efficient content organisation and retrieval systems, but\ntheir unstructured nature poses significant challenges for automated\nprocessing. This paper presents a comprehensive comparative analysis of image,\nvideo, and audio classifiers for automated news video segmentation. This work\npresents the development and evaluation of multiple deep learning approaches,\nincluding ResNet, ViViT, AST, and multimodal architectures, to classify five\ndistinct segment types: advertisements, stories, studio scenes, transitions,\nand visualisations. Using a custom-annotated dataset of 41 news videos\ncomprising 1,832 scene clips, our experiments demonstrate that image-based\nclassifiers achieve superior performance (84.34\\% accuracy) compared to more\ncomplex temporal models. Notably, the ResNet architecture outperformed\nstate-of-the-art video classifiers while requiring significantly fewer\ncomputational resources. Binary classification models achieved high accuracy\nfor transitions (94.23\\%) and advertisements (92.74\\%). These findings advance\nthe understanding of effective architectures for news video segmentation and\nprovide practical insights for implementing automated content organisation\nsystems in media applications. These include media archiving, personalised\ncontent delivery, and intelligent video search.", "published": "2025-03-27 16:42:50", "link": "http://arxiv.org/abs/2503.21848v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Intelligent IoT Attack Detection Design via ODLLM with Feature Ranking-based Knowledge Base", "abstract": "The widespread adoption of Internet of Things (IoT) devices has introduced\nsignificant cybersecurity challenges, particularly with the increasing\nfrequency and sophistication of Distributed Denial of Service (DDoS) attacks.\nTraditional machine learning (ML) techniques often fall short in detecting such\nattacks due to the complexity of blended and evolving patterns. To address\nthis, we propose a novel framework leveraging On-Device Large Language Models\n(ODLLMs) augmented with fine-tuning and knowledge base (KB) integration for\nintelligent IoT network attack detection. By implementing feature ranking\ntechniques and constructing both long and short KBs tailored to model\ncapacities, the proposed framework ensures efficient and accurate detection of\nDDoS attacks while overcoming computational and privacy limitations. Simulation\nresults demonstrate that the optimized framework achieves superior accuracy\nacross diverse attack types, especially when using compact models in edge\ncomputing environments. This work provides a scalable and secure solution for\nreal-time IoT security, advancing the applicability of edge intelligence in\ncybersecurity.", "published": "2025-03-27 16:41:57", "link": "http://arxiv.org/abs/2503.21674v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "ReCoM: Realistic Co-Speech Motion Generation with Recurrent Embedded Transformer", "abstract": "We present ReCoM, an efficient framework for generating high-fidelity and\ngeneralizable human body motions synchronized with speech. The core innovation\nlies in the Recurrent Embedded Transformer (RET), which integrates Dynamic\nEmbedding Regularization (DER) into a Vision Transformer (ViT) core\narchitecture to explicitly model co-speech motion dynamics. This architecture\nenables joint spatial-temporal dependency modeling, thereby enhancing gesture\nnaturalness and fidelity through coherent motion synthesis. To enhance model\nrobustness, we incorporate the proposed DER strategy, which equips the model\nwith dual capabilities of noise resistance and cross-domain generalization,\nthereby improving the naturalness and fluency of zero-shot motion generation\nfor unseen speech inputs. To mitigate inherent limitations of autoregressive\ninference, including error accumulation and limited self-correction, we propose\nan iterative reconstruction inference (IRI) strategy. IRI refines motion\nsequences via cyclic pose reconstruction, driven by two key components: (1)\nclassifier-free guidance improves distribution alignment between generated and\nreal gestures without auxiliary supervision, and (2) a temporal smoothing\nprocess eliminates abrupt inter-frame transitions while ensuring kinematic\ncontinuity. Extensive experiments on benchmark datasets validate ReCoM's\neffectiveness, achieving state-of-the-art performance across metrics. Notably,\nit reduces the Fr\\'echet Gesture Distance (FGD) from 18.70 to 2.48,\ndemonstrating an 86.7% improvement in motion realism. Our project page is\nhttps://yong-xie-xy.github.io/ReCoM/.", "published": "2025-03-27 16:39:40", "link": "http://arxiv.org/abs/2503.21847v1", "categories": ["cs.GR", "cs.AI"], "primary_category": "cs.GR"}
{"title": "LightSNN: Lightweight Architecture Search for Sparse and Accurate Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) are highly regarded for their energy\nefficiency, inherent activation sparsity, and suitability for real-time\nprocessing in edge devices. However, most current SNN methods adopt\narchitectures resembling traditional artificial neural networks (ANNs), leading\nto suboptimal performance when applied to SNNs. While SNNs excel in energy\nefficiency, they have been associated with lower accuracy levels than\ntraditional ANNs when utilizing conventional architectures. In response, in\nthis work we present LightSNN, a rapid and efficient Neural Network\nArchitecture Search (NAS) technique specifically tailored for SNNs that\nautonomously leverages the most suitable architecture, striking a good balance\nbetween accuracy and efficiency by enforcing sparsity. Based on the spiking NAS\nnetwork (SNASNet) framework, a cell-based search space including backward\nconnections is utilized to build our training-free pruning-based NAS mechanism.\nOur technique assesses diverse spike activation patterns across different data\nsamples using a sparsity-aware Hamming distance fitness evaluation. Thorough\nexperiments are conducted on both static (CIFAR10 and CIFAR100) and\nneuromorphic datasets (DVS128-Gesture). Our LightSNN model achieves\nstate-of-the-art results on CIFAR10 and CIFAR100, improves performance on\nDVS128Gesture by 4.49%, and significantly reduces search time, most notably\noffering a 98x speedup over SNASNet and running 30% faster than the best\nexisting method on DVS128Gesture.", "published": "2025-03-27 16:38:13", "link": "http://arxiv.org/abs/2503.21846v1", "categories": ["cs.NE", "cs.AI", "eess.SP"], "primary_category": "cs.NE"}
{"title": "Cognitive Science-Inspired Evaluation of Core Capabilities for Object Understanding in AI", "abstract": "One of the core components of our world models is 'intuitive physics' - an\nunderstanding of objects, space, and causality. This capability enables us to\npredict events, plan action and navigate environments, all of which rely on a\ncomposite sense of objecthood. Despite its importance, there is no single,\nunified account of objecthood, though multiple theoretical frameworks provide\ninsights. In the first part of this paper, we present a comprehensive overview\nof the main theoretical frameworks in objecthood research - Gestalt psychology,\nenactive cognition, and developmental psychology - and identify the core\ncapabilities each framework attributes to object understanding, as well as what\nfunctional roles they play in shaping world models in biological agents. Given\nthe foundational role of objecthood in world modelling, understanding\nobjecthood is also essential in AI. In the second part of the paper, we\nevaluate how current AI paradigms approach and test objecthood capabilities\ncompared to those in cognitive science. We define an AI paradigm as a\ncombination of how objecthood is conceptualised, the methods used for studying\nobjecthood, the data utilised, and the evaluation techniques. We find that,\nwhilst benchmarks can detect that AI systems model isolated aspects of\nobjecthood, the benchmarks cannot detect when AI systems lack functional\nintegration across these capabilities, not solving the objecthood challenge\nfully. Finally, we explore novel evaluation approaches that align with the\nintegrated vision of objecthood outlined in this paper. These methods are\npromising candidates for advancing from isolated object capabilities toward\ngeneral-purpose AI with genuine object understanding in real-world contexts.", "published": "2025-03-27 16:35:02", "link": "http://arxiv.org/abs/2503.21668v2", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Unlocking the Potential of Past Research: Using Generative AI to Reconstruct Healthcare Simulation Models", "abstract": "Discrete-event simulation (DES) is widely used in healthcare Operations\nResearch, but the models themselves are rarely shared. This limits their\npotential for reuse and long-term impact in the modelling and healthcare\ncommunities. This study explores the feasibility of using generative artificial\nintelligence (AI) to recreate published models using Free and Open Source\nSoftware (FOSS), based on the descriptions provided in an academic journal.\nUsing a structured methodology, we successfully generated, tested and\ninternally reproduced two DES models, including user interfaces. The reported\nresults were replicated for one model, but not the other, likely due to missing\ninformation on distributions. These models are substantially more complex than\nAI-generated DES models published to date. Given the challenges we faced in\nprompt engineering, code generation, and model testing, we conclude that our\niterative approach to model development, systematic comparison and testing, and\nthe expertise of our team were necessary to the success of our recreated\nsimulation models.", "published": "2025-03-27 16:10:02", "link": "http://arxiv.org/abs/2503.21646v1", "categories": ["cs.AI", "stat.AP"], "primary_category": "cs.AI"}
{"title": "Towards Fully Automated Decision-Making Systems for Greenhouse Control: Challenges and Opportunities", "abstract": "Machine learning has been successful in building control policies to drive a\ncomplex system to desired states in various applications (e.g. games, robotics,\netc.). To be specific, a number of parameters of policy can be automatically\noptimized from the observations of environment to be able to generate a\nsequence of decisions leading to the best performance. In this survey paper, we\nparticularly explore such policy-learning techniques for another unique,\npractical use-case scenario--farming, in which critical decisions (e.g., water\nsupply, heating, etc.) must be made in a timely manner to minimize risks (e.g.,\ndamage to plants) while maximizing the revenue (e.g., healthy crops) in the\nend. We first provide a broad overview of latest studies on it to identify not\nonly domain-specific challenges but opportunities with potential solutions,\nsome of which are suggested as promising directions for future research. Also,\nwe then introduce our successful approach to being ranked second among 46 teams\nat the ''3rd Autonomous Greenhouse Challenge'' to use this specific example to\ndiscuss the lessons learned about important considerations for design to create\nautonomous farm-management systems.", "published": "2025-03-27 16:06:59", "link": "http://arxiv.org/abs/2503.21640v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "When Astronomy Meets AI: Manazel For Crescent Visibility Prediction in Morocco", "abstract": "The accurate determination of the beginning of each Hijri month is essential\nfor religious, cultural, and administrative purposes. Manazel (The code and\ndatasets are available at https://github.com/lairgiyassir/manazel) addresses\nthis challenge in Morocco by leveraging 13 years of crescent visibility data to\nrefine the ODEH criterion, a widely used standard for lunar crescent visibility\nprediction. The study integrates two key features, the Arc of Vision (ARCV) and\nthe total width of the crescent (W), to enhance the accuracy of lunar\nvisibility assessments. A machine learning approach utilizing the Logistic\nRegression algorithm is employed to classify crescent visibility conditions,\nachieving a predictive accuracy of 98.83%. This data-driven methodology offers\na robust and reliable framework for determining the start of the Hijri month,\ncomparing different data classification tools, and improving the consistency of\nlunar calendar calculations in Morocco. The findings demonstrate the\neffectiveness of machine learning in astronomical applications and highlight\nthe potential for further enhancements in the modeling of crescent visibility.", "published": "2025-03-27 15:56:55", "link": "http://arxiv.org/abs/2503.21634v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning", "abstract": "The recent DeepSeek-R1 has showcased the emergence of reasoning capabilities\nin LLMs through reinforcement learning (RL) with rule-based rewards. Building\non this idea, we are the first to explore how rule-based RL can enhance the\nreasoning capabilities of multimodal large language models (MLLMs) for graphic\nuser interface (GUI) action prediction tasks. To this end, we curate a small\nyet high-quality dataset of 136 challenging tasks, encompassing five common\naction types on mobile devices. We also introduce a unified rule-based action\nreward, enabling model optimization via policy-based algorithms such as Group\nRelative Policy Optimization (GRPO). Experimental results demonstrate that our\nproposed data-efficient model, UI-R1-3B, achieves substantial improvements on\nboth in-domain (ID) and out-of-domain (OOD) tasks. Specifically, on the ID\nbenchmark AndroidControl, the action type accuracy improves by 15%, while\ngrounding accuracy increases by 10.3%, compared with the base model (i.e.\nQwen2.5-VL-3B). On the OOD GUI grounding benchmark ScreenSpot-Pro, our model\nsurpasses the base model by 6.0% and achieves competitive performance with\nlarger models (e.g., OS-Atlas-7B), which are trained via supervised fine-tuning\n(SFT) on 76K data. These results underscore the potential of rule-based\nreinforcement learning to advance GUI understanding and control, paving the way\nfor future research in this domain.", "published": "2025-03-27 15:39:30", "link": "http://arxiv.org/abs/2503.21620v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Measure Based Generalizable Approach to Understandability", "abstract": "Successful agent-human partnerships require that any agent generated\ninformation is understandable to the human, and that the human can easily steer\nthe agent towards a goal. Such effective communication requires the agent to\ndevelop a finer-level notion of what is understandable to the human.\nState-of-the-art agents, including LLMs, lack this detailed notion of\nunderstandability because they only capture average human sensibilities from\nthe training data, and therefore afford limited steerability (e.g., requiring\nnon-trivial prompt engineering).\n  In this paper, instead of only relying on data, we argue for developing\ngeneralizable, domain-agnostic measures of understandability that can be used\nas directives for these agents. Existing research on understandability measures\nis fragmented, we survey various such efforts across domains, and lay a\ncognitive-science-rooted groundwork for more coherent and domain-agnostic\nresearch investigations in future.", "published": "2025-03-27 15:36:49", "link": "http://arxiv.org/abs/2503.21615v1", "categories": ["cs.HC", "cs.AI", "cs.SE"], "primary_category": "cs.HC"}
{"title": "Gaze-Guided 3D Hand Motion Prediction for Detecting Intent in Egocentric Grasping Tasks", "abstract": "Human intention detection with hand motion prediction is critical to drive\nthe upper-extremity assistive robots in neurorehabilitation applications.\nHowever, the traditional methods relying on physiological signal measurement\nare restrictive and often lack environmental context. We propose a novel\napproach that predicts future sequences of both hand poses and joint positions.\nThis method integrates gaze information, historical hand motion sequences, and\nenvironmental object data, adapting dynamically to the assistive needs of the\npatient without prior knowledge of the intended object for grasping.\nSpecifically, we use a vector-quantized variational autoencoder for robust hand\npose encoding with an autoregressive generative transformer for effective hand\nmotion sequence prediction. We demonstrate the usability of these novel\ntechniques in a pilot study with healthy subjects. To train and evaluate the\nproposed method, we collect a dataset consisting of various types of grasp\nactions on different objects from multiple subjects. Through extensive\nexperiments, we demonstrate that the proposed method can successfully predict\nsequential hand movement. Especially, the gaze information shows significant\nenhancements in prediction capabilities, particularly with fewer input frames,\nhighlighting the potential of the proposed method for real-world applications.", "published": "2025-03-27 15:26:41", "link": "http://arxiv.org/abs/2504.01024v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "GenEdit: Compounding Operators and Continuous Improvement to Tackle Text-to-SQL in the Enterprise", "abstract": "Recent advancements in Text-to-SQL, driven by large language models, are\ndemocratizing data access. Despite these advancements, enterprise deployments\nremain challenging due to the need to capture business-specific knowledge,\nhandle complex queries, and meet expectations of continuous improvements. To\naddress these issues, we designed and implemented GenEdit: our Text-to-SQL\ngeneration system that improves with user feedback. GenEdit builds and\nmaintains a company-specific knowledge set, employs a pipeline of operators\ndecomposing SQL generation, and uses feedback to update its knowledge set to\nimprove future SQL generations.\n  We describe GenEdit's architecture made of two core modules: (i) decomposed\nSQL generation; and (ii) knowledge set edits based on user feedback. For\ngeneration, GenEdit leverages compounding operators to improve knowledge\nretrieval and to create a plan as chain-of-thought steps that guides\ngeneration. GenEdit first retrieves relevant examples in an initial retrieval\nstage where original SQL queries are decomposed into sub-statements, clauses or\nsub-queries. It then also retrieves instructions and schema elements. Using the\nretrieved contextual information, GenEdit then generates step-by-step plan in\nnatural language on how to produce the query. Finally, GenEdit uses the plan to\ngenerate SQL, minimizing the need for model reasoning, which enhances complex\nSQL generation. If necessary, GenEdit regenerates the query based on syntactic\nand semantic errors. The knowledge set edits are recommended through an\ninteractive copilot, allowing users to iterate on their feedback and to\nregenerate SQL queries as needed. Each generation uses staged edits which\nupdate the generation prompt. Once the feedback is submitted, it gets merged\nafter passing regression testing and obtaining an approval, improving future\ngenerations.", "published": "2025-03-27 15:22:02", "link": "http://arxiv.org/abs/2503.21602v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition", "abstract": "Human Activity Recognition (HAR) is a fundamental technology for numerous\nhuman - centered intelligent applications. Although deep learning methods have\nbeen utilized to accelerate feature extraction, issues such as multimodal data\nmixing, activity heterogeneity, and complex model deployment remain largely\nunresolved. The aim of this paper is to address issues such as multimodal data\nmixing, activity heterogeneity, and complex model deployment in sensor-based\nhuman activity recognition. We propose a spatiotemporal attention modal\ndecomposition alignment fusion strategy to tackle the problem of the mixed\ndistribution of sensor data. Key discriminative features of activities are\ncaptured through cross-modal spatio-temporal disentangled representation, and\ngradient modulation is combined to alleviate data heterogeneity. In addition, a\nwearable deployment simulation system is constructed. We conducted experiments\non a large number of public datasets, demonstrating the effectiveness of the\nmodel.", "published": "2025-03-27 15:21:49", "link": "http://arxiv.org/abs/2503.21843v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Prompt, Divide, and Conquer: Bypassing Large Language Model Safety Filters via Segmented and Distributed Prompt Processing", "abstract": "Large Language Models (LLMs) have transformed task automation and content\ngeneration across various domains while incorporating safety filters to prevent\nmisuse. We introduce a novel jailbreaking framework that employs distributed\nprompt processing combined with iterative refinements to bypass these safety\nmeasures, particularly in generating malicious code. Our architecture consists\nof four key modules: prompt segmentation, parallel processing, response\naggregation, and LLM-based jury evaluation. Tested on 500 malicious prompts\nacross 10 cybersecurity categories, the framework achieves a 73.2% Success Rate\n(SR) in generating malicious code. Notably, our comparative analysis reveals\nthat traditional single-LLM judge evaluation overestimates SRs (93.8%) compared\nto our LLM jury system (73.2%), with manual verification confirming that\nsingle-judge assessments often accept incomplete implementations. Moreover, we\ndemonstrate that our distributed architecture improves SRs by 12% over the\nnon-distributed approach in an ablation study, highlighting both the\neffectiveness of distributed prompt processing and the importance of robust\nevaluation methodologies in assessing jailbreak attempts.", "published": "2025-03-27 15:19:55", "link": "http://arxiv.org/abs/2503.21598v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Data Poisoning in Deep Learning: A Survey", "abstract": "Deep learning has become a cornerstone of modern artificial intelligence,\nenabling transformative applications across a wide range of domains. As the\ncore element of deep learning, the quality and security of training data\ncritically influence model performance and reliability. However, during the\ntraining process, deep learning models face the significant threat of data\npoisoning, where attackers introduce maliciously manipulated training data to\ndegrade model accuracy or lead to anomalous behavior. While existing surveys\nprovide valuable insights into data poisoning, they generally adopt a broad\nperspective, encompassing both attacks and defenses, but lack a dedicated,\nin-depth analysis of poisoning attacks specifically in deep learning. In this\nsurvey, we bridge this gap by presenting a comprehensive and targeted review of\ndata poisoning in deep learning. First, this survey categorizes data poisoning\nattacks across multiple perspectives, providing an in-depth analysis of their\ncharacteristics and underlying design princinples. Second, the discussion is\nextended to the emerging area of data poisoning in large language models(LLMs).\nFinally, we explore critical open challenges in the field and propose potential\nresearch directions to advance the field further. To support further\nexploration, an up-to-date repository of resources on data poisoning in deep\nlearning is available at https://github.com/Pinlong-Zhao/Data-Poisoning.", "published": "2025-03-27 15:16:57", "link": "http://arxiv.org/abs/2503.22759v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Critical Iterative Denoising: A Discrete Generative Model Applied to Graphs", "abstract": "Discrete Diffusion and Flow Matching models have significantly advanced\ngenerative modeling for discrete structures, including graphs. However, the\ntime dependencies in the noising process of these models lead to error\naccumulation and propagation during the backward process. This issue,\nparticularly pronounced in mask diffusion, is a known limitation in sequence\nmodeling and, as we demonstrate, also impacts discrete diffusion models for\ngraphs.\n  To address this problem, we propose a novel framework called Iterative\nDenoising, which simplifies discrete diffusion and circumvents the issue by\nassuming conditional independence across time. Additionally, we enhance our\nmodel by incorporating a Critic, which during generation selectively retains or\ncorrupts elements in an instance based on their likelihood under the data\ndistribution. Our empirical evaluations demonstrate that the proposed method\nsignificantly outperforms existing discrete diffusion baselines in graph\ngeneration tasks.", "published": "2025-03-27 15:08:58", "link": "http://arxiv.org/abs/2503.21592v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AlignDiff: Learning Physically-Grounded Camera Alignment via Diffusion", "abstract": "Accurate camera calibration is a fundamental task for 3D perception,\nespecially when dealing with real-world, in-the-wild environments where complex\noptical distortions are common. Existing methods often rely on pre-rectified\nimages or calibration patterns, which limits their applicability and\nflexibility. In this work, we introduce a novel framework that addresses these\nchallenges by jointly modeling camera intrinsic and extrinsic parameters using\na generic ray camera model. Unlike previous approaches, AlignDiff shifts focus\nfrom semantic to geometric features, enabling more accurate modeling of local\ndistortions. We propose AlignDiff, a diffusion model conditioned on geometric\npriors, enabling the simultaneous estimation of camera distortions and scene\ngeometry. To enhance distortion prediction, we incorporate edge-aware\nattention, focusing the model on geometric features around image edges, rather\nthan semantic content. Furthermore, to enhance generalizability to real-world\ncaptures, we incorporate a large database of ray-traced lenses containing over\nthree thousand samples. This database characterizes the distortion inherent in\na diverse variety of lens forms. Our experiments demonstrate that the proposed\nmethod significantly reduces the angular error of estimated ray bundles by ~8.2\ndegrees and overall calibration accuracy, outperforming existing approaches on\nchallenging, real-world datasets.", "published": "2025-03-27 14:59:59", "link": "http://arxiv.org/abs/2503.21581v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Magnitude-Phase Dual-Path Speech Enhancement Network based on Self-Supervised Embedding and Perceptual Contrast Stretch Boosting", "abstract": "Speech self-supervised learning (SSL) has made great progress in various\nspeech processing tasks, but there is still room for improvement in speech\nenhancement (SE). This paper presents BSP-MPNet, a dual-path framework that\ncombines self-supervised features with magnitude-phase information for SE. The\napproach starts by applying the perceptual contrast stretching (PCS) algorithm\nto enhance the magnitude-phase spectrum. A magnitude-phase 2D coarse (MP-2DC)\nencoder then extracts coarse features from the enhanced spectrum. Next, a\nfeature-separating self-supervised learning (FS-SSL) model generates\nself-supervised embeddings for the magnitude and phase components separately.\nThese embeddings are fused to create cross-domain feature representations.\nFinally, two parallel RNN-enhanced multi-attention (REMA) mask decoders refine\nthe features, apply them to the mask, and reconstruct the speech signal. We\nevaluate BSP-MPNet on the VoiceBank+DEMAND and WHAMR! datasets. Experimental\nresults show that BSP-MPNet outperforms existing methods under various noise\nconditions, providing new directions for self-supervised speech enhancement\nresearch. The implementation of the BSP-MPNet code is available\nonline\\footnote[2]{https://github.com/AlimMat/BSP-MPNet. \\label{s1}}", "published": "2025-03-27 14:52:06", "link": "http://arxiv.org/abs/2503.21571v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Local Perspective-based Model for Overlapping Community Detection", "abstract": "Community detection, which identifies densely connected node clusters with\nsparse between-group links, is vital for analyzing network structure and\nfunction in real-world systems. Most existing community detection methods based\non GCNs primarily focus on node-level information while overlooking\ncommunity-level features, leading to performance limitations on large-scale\nnetworks. To address this issue, we propose LQ-GCN, an overlapping community\ndetection model from a local community perspective. LQ-GCN employs a\nBernoulli-Poisson model to construct a community affiliation matrix and form an\nend-to-end detection framework. By adopting local modularity as the objective\nfunction, the model incorporates local community information to enhance the\nquality and accuracy of clustering results. Additionally, the conventional GCNs\narchitecture is optimized to improve the model capability in identifying\noverlapping communities in large-scale networks. Experimental results\ndemonstrate that LQ-GCN achieves up to a 33% improvement in Normalized Mutual\nInformation (NMI) and a 26.3% improvement in Recall compared to baseline models\nacross multiple real-world benchmark datasets.", "published": "2025-03-27 14:43:42", "link": "http://arxiv.org/abs/2503.21558v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "LOCATEdit: Graph Laplacian Optimized Cross Attention for Localized Text-Guided Image Editing", "abstract": "Text-guided image editing aims to modify specific regions of an image\naccording to natural language instructions while maintaining the general\nstructure and the background fidelity. Existing methods utilize masks derived\nfrom cross-attention maps generated from diffusion models to identify the\ntarget regions for modification. However, since cross-attention mechanisms\nfocus on semantic relevance, they struggle to maintain the image integrity. As\na result, these methods often lack spatial consistency, leading to editing\nartifacts and distortions. In this work, we address these limitations and\nintroduce LOCATEdit, which enhances cross-attention maps through a graph-based\napproach utilizing self-attention-derived patch relationships to maintain\nsmooth, coherent attention across image regions, ensuring that alterations are\nlimited to the designated items while retaining the surrounding structure.\nLOCATEdit consistently and substantially outperforms existing baselines on\nPIE-Bench, demonstrating its state-of-the-art performance and effectiveness on\nvarious editing tasks. Code can be found on\nhttps://github.com/LOCATEdit/LOCATEdit/", "published": "2025-03-27 14:32:17", "link": "http://arxiv.org/abs/2503.21541v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MONO2REST: Identifying and Exposing Microservices: a Reusable RESTification Approach", "abstract": "The microservices architectural style has become the de facto standard for\nlarge-scale cloud applications, offering numerous benefits in scalability,\nmaintainability, and deployment flexibility. Many organizations are pursuing\nthe migration of legacy monolithic systems to a microservices architecture.\nHowever, this process is challenging, risky, time-intensive, and\nprone-to-failure while several organizations lack necessary financial\nresources, time, or expertise to set up this migration process. So, rather than\ntrying to migrate a legacy system where migration is risky or not feasible, we\nsuggest exposing it as a microservice application without without having to\nmigrate it. In this paper, we present a reusable, automated, two-phase approach\nthat combines evolutionary algorithms with machine learning techniques. In the\nfirst phase, we identify microservices at the method level using a\nmulti-objective genetic algorithm that considers both structural and semantic\ndependencies between methods. In the second phase, we generate REST APIs for\neach identified microservice using a classification algorithm to assign HTTP\nmethods and endpoints. We evaluated our approach with a case study on the\nSpring PetClinic application, which has both monolithic and microservices\nimplementations that serve as ground truth for comparison. Results demonstrate\nthat our approach successfully aligns identified microservices with those in\nthe reference microservices implementation, highlighting its effectiveness in\nservice identification and API generation.", "published": "2025-03-27 14:10:33", "link": "http://arxiv.org/abs/2503.21522v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Quantitative Evaluation of Quantum/Classical Neural Network Using a Game Solver Metric", "abstract": "To evaluate the performance of quantum computing systems relative to\nclassical counterparts and explore the potential for quantum advantage, we\npropose a game-solving benchmark based on Elo ratings in the game of\ntic-tac-toe. We compare classical convolutional neural networks (CNNs), quantum\nconvolutional neural networks (QCNNs), and hybrid classical-quantum models by\nassessing their performance against a random-move agent in automated matches.\nAdditionally, we implement a QCNN integrated with quantum communication and\nevaluate its performance to quantify the overhead introduced by noisy quantum\nchannels. Our results show that the classical-quantum hybrid model achieves Elo\nratings comparable to those of classical CNNs, while the standalone QCNN\nunderperforms under current hardware constraints. The communication overhead\nwas found to be modest. These findings demonstrate the viability of using\ngame-based benchmarks for evaluating quantum computing systems and suggest that\nquantum communication can be incorporated with limited impact on performance,\nproviding a foundation for future hybrid quantum applications.", "published": "2025-03-27 14:05:16", "link": "http://arxiv.org/abs/2503.21514v1", "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Towards an intelligent assessment system for evaluating the development of algorithmic thinking skills: An exploratory study in Swiss compulsory schools", "abstract": "The rapid digitalisation of contemporary society has profoundly impacted\nvarious facets of our lives, including healthcare, communication, business, and\neducation. The ability to engage with new technologies and solve problems has\nbecome crucial, making CT skills, such as pattern recognition, decomposition,\nand algorithm design, essential competencies. In response, Switzerland is\nconducting research and initiatives to integrate CT into its educational\nsystem. This study aims to develop a comprehensive framework for large-scale\nassessment of CT skills, particularly focusing on AT, the ability to design\nalgorithms. To achieve this, we first developed a competence model capturing\nthe situated and developmental nature of CT, guiding the design of activities\ntailored to cognitive abilities, age, and context. This framework clarifies how\nactivity characteristics influence CT development and how to assess these\ncompetencies. Additionally, we developed an activity for large-scale assessment\nof AT skills, offered in two variants: one based on non-digital artefacts\n(unplugged) and manual expert assessment, and the other based on digital\nartefacts (virtual) and automatic assessment. To provide a more comprehensive\nevaluation of students' competencies, we developed an IAS based on BNs with\nnoisy gates, which offers real-time probabilistic assessment for each skill\nrather than a single overall score. The results indicate that the proposed\ninstrument can measure AT competencies across different age groups and\neducational contexts in Switzerland, demonstrating its applicability for\nlarge-scale use. AT competencies exhibit a progressive development, with no\noverall gender differences, though variations are observed at the school level,\nsignificantly influenced by the artefact-based environment and its context,\nunderscoring the importance of creating accessible and adaptable assessment\ntools.", "published": "2025-03-27 13:34:36", "link": "http://arxiv.org/abs/2503.22756v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Adaptive Resampling with Bootstrap for Noisy Multi-Objective Optimization Problems", "abstract": "The challenge of noisy multi-objective optimization lies in the constant\ntrade-off between exploring new decision points and improving the precision of\nknown points through resampling. This decision should take into account both\nthe variability of the objective functions and the current estimate of a point\nin relation to the Pareto front. Since the amount and distribution of noise are\ngenerally unknown, it is desirable for a decision function to be highly\nadaptive to the properties of the optimization problem. This paper presents a\nresampling decision function that incorporates the stochastic nature of the\noptimization problem by using bootstrapping and the probability of dominance.\nThe distribution-free estimation of the probability of dominance is achieved\nusing bootstrap estimates of the means. To make the procedure applicable even\nwith very few observations, we transfer the distribution observed at other\ndecision points. The efficiency of this resampling approach is demonstrated by\napplying it in the NSGA-II algorithm with a sequential resampling procedure\nunder multiple noise variations.", "published": "2025-03-27 13:32:42", "link": "http://arxiv.org/abs/2503.21495v1", "categories": ["cs.LG", "cs.AI", "stat.ML", "90C29", "G.1.6"], "primary_category": "cs.LG"}
{"title": "The Procedural Content Generation Benchmark: An Open-source Testbed for Generative Challenges in Games", "abstract": "This paper introduces the Procedural Content Generation Benchmark for\nevaluating generative algorithms on different game content creation tasks. The\nbenchmark comes with 12 game-related problems with multiple variants on each\nproblem. Problems vary from creating levels of different kinds to creating rule\nsets for simple arcade games. Each problem has its own content representation,\ncontrol parameters, and evaluation metrics for quality, diversity, and\ncontrollability. This benchmark is intended as a first step towards a\nstandardized way of comparing generative algorithms. We use the benchmark to\nscore three baseline algorithms: a random generator, an evolution strategy, and\na genetic algorithm. Results show that some problems are easier to solve than\nothers, as well as the impact the chosen objective has on quality, diversity,\nand controllability of the generated artifacts.", "published": "2025-03-27 13:05:40", "link": "http://arxiv.org/abs/2503.21474v2", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Retinal Fundus Multi-Disease Image Classification using Hybrid CNN-Transformer-Ensemble Architectures", "abstract": "Our research is motivated by the urgent global issue of a large population\naffected by retinal diseases, which are evenly distributed but underserved by\nspecialized medical expertise, particularly in non-urban areas. Our primary\nobjective is to bridge this healthcare gap by developing a comprehensive\ndiagnostic system capable of accurately predicting retinal diseases solely from\nfundus images. However, we faced significant challenges due to limited, diverse\ndatasets and imbalanced class distributions. To overcome these issues, we have\ndevised innovative strategies. Our research introduces novel approaches,\nutilizing hybrid models combining deeper Convolutional Neural Networks (CNNs),\nTransformer encoders, and ensemble architectures sequentially and in parallel\nto classify retinal fundus images into 20 disease labels. Our overarching goal\nis to assess these advanced models' potential in practical applications, with a\nstrong focus on enhancing retinal disease diagnosis accuracy across a broader\nspectrum of conditions. Importantly, our efforts have surpassed baseline model\nresults, with the C-Tran ensemble model emerging as the leader, achieving a\nremarkable model score of 0.9166, surpassing the baseline score of 0.9.\nAdditionally, experiments with the IEViT model showcased equally promising\noutcomes with improved computational efficiency. We've also demonstrated the\neffectiveness of dynamic patch extraction and the integration of domain\nknowledge in computer vision tasks. In summary, our research strives to\ncontribute significantly to retinal disease diagnosis, addressing the critical\nneed for accessible healthcare solutions in underserved regions while aiming\nfor comprehensive and accurate disease prediction.", "published": "2025-03-27 12:55:07", "link": "http://arxiv.org/abs/2503.21465v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T10, 68T45, 92C55", "I.2.10; I.5.4; J.3"], "primary_category": "cs.CV"}
{"title": "Unveiling Latent Information in Transaction Hashes: Hypergraph Learning for Ethereum Ponzi Scheme Detection", "abstract": "With the widespread adoption of Ethereum, financial frauds such as Ponzi\nschemes have become increasingly rampant in the blockchain ecosystem, posing\nsignificant threats to the security of account assets. Existing Ethereum fraud\ndetection methods typically model account transactions as graphs, but this\napproach primarily focuses on binary transactional relationships between\naccounts, failing to adequately capture the complex multi-party interaction\npatterns inherent in Ethereum. To address this, we propose a hypergraph\nmodeling method for the Ponzi scheme detection method in Ethereum, called\nHyperDet. Specifically, we treat transaction hashes as hyperedges that connect\nall the relevant accounts involved in a transaction. Additionally, we design a\ntwo-step hypergraph sampling strategy to significantly reduce computational\ncomplexity. Furthermore, we introduce a dual-channel detection module,\nincluding the hypergraph detection channel and the hyper-homo graph detection\nchannel, to be compatible with existing detection methods. Experimental results\nshow that, compared to traditional homogeneous graph-based methods, the\nhyper-homo graph detection channel achieves significant performance\nimprovements, demonstrating the superiority of hypergraph in Ponzi scheme\ndetection. This research offers innovations for modeling complex relationships\nin blockchain data.", "published": "2025-03-27 12:52:47", "link": "http://arxiv.org/abs/2503.21463v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Graph-to-Vision: Multi-graph Understanding and Reasoning using Vision-Language Models", "abstract": "Graph Neural Networks (GNNs), as the dominant paradigm for graph-structured\nlearning, have long faced dual challenges of exponentially escalating\ncomputational complexity and inadequate cross-scenario generalization\ncapability. With the rapid advancement of multimodal learning, Vision-Language\nModels (VLMs) have demonstrated exceptional cross-modal relational reasoning\ncapabilities and generalization capacities, thereby opening up novel pathways\nfor overcoming the inherent limitations of conventional graph learning\nparadigms. However, current research predominantly concentrates on\ninvestigating the single-graph reasoning capabilities of VLMs, which\nfundamentally fails to address the critical requirement for coordinated\nreasoning across multiple heterogeneous graph data in real-world application\nscenarios. To address these limitations, we propose the first multi-graph joint\nreasoning benchmark for VLMs. Our benchmark encompasses four graph categories:\nknowledge graphs, flowcharts, mind maps, and route maps,with each graph group\naccompanied by three progressively challenging instruction-response pairs.\nLeveraging this benchmark, we conducted comprehensive capability assessments of\nstate-of-the-art VLMs and performed fine-tuning on open-source models. This\nstudy not only addresses the underexplored evaluation gap in multi-graph\nreasoning for VLMs but also empirically validates their generalization\nsuperiority in graph-structured learning.", "published": "2025-03-27 12:20:37", "link": "http://arxiv.org/abs/2503.21435v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From Deep Learning to LLMs: A survey of AI in Quantitative Investment", "abstract": "Quantitative investment (quant) is an emerging, technology-driven approach in\nasset management, increasingy shaped by advancements in artificial\nintelligence. Recent advances in deep learning and large language models (LLMs)\nfor quant finance have improved predictive modeling and enabled agent-based\nautomation, suggesting a potential paradigm shift in this field. In this\nsurvey, taking alpha strategy as a representative example, we explore how AI\ncontributes to the quantitative investment pipeline. We first examine the early\nstage of quant research, centered on human-crafted features and traditional\nstatistical models with an established alpha pipeline. We then discuss the rise\nof deep learning, which enabled scalable modeling across the entire pipeline\nfrom data processing to order execution. Building on this, we highlight the\nemerging role of LLMs in extending AI beyond prediction, empowering autonomous\nagents to process unstructured data, generate alphas, and support\nself-iterative workflows.", "published": "2025-03-27 12:10:15", "link": "http://arxiv.org/abs/2503.21422v1", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "q-fin.ST", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Neuroplasticity in Artificial Intelligence -- An Overview and Inspirations on Drop In & Out Learning", "abstract": "Artificial Intelligence (AI) has achieved new levels of performance and\nspread in public usage with the rise of deep neural networks (DNNs). Initially\ninspired by human neurons and their connections, NNs have become the foundation\nof AI models for many advanced architectures. However, some of the most\nintegral processes in the human brain, particularly neurogenesis and\nneuroplasticity in addition to the more spread neuroapoptosis have largely been\nignored in DNN architecture design. Instead, contemporary AI development\npredominantly focuses on constructing advanced frameworks, such as large\nlanguage models, which retain a static structure of neural connections during\ntraining and inference. In this light, we explore how neurogenesis,\nneuroapoptosis, and neuroplasticity can inspire future AI advances.\nSpecifically, we examine analogous activities in artificial NNs, introducing\nthe concepts of ``dropin'' for neurogenesis and revisiting ``dropout'' and\nstructural pruning for neuroapoptosis. We additionally suggest neuroplasticity\ncombining the two for future large NNs in ``life-long learning'' settings\nfollowing the biological inspiration. We conclude by advocating for greater\nresearch efforts in this interdisciplinary domain and identifying promising\ndirections for future exploration.", "published": "2025-03-27 12:09:04", "link": "http://arxiv.org/abs/2503.21419v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Federated Intelligence: When Large AI Models Meet Federated Fine-Tuning and Collaborative Reasoning at the Network Edge", "abstract": "Large artificial intelligence (AI) models exhibit remarkable capabilities in\nvarious application scenarios, but deploying them at the network edge poses\nsignificant challenges due to issues such as data privacy, computational\nresources, and latency. In this paper, we explore federated fine-tuning and\ncollaborative reasoning techniques to facilitate the implementation of large AI\nmodels in resource-constrained wireless networks. Firstly, promising\napplications of large AI models within specific domains are discussed.\nSubsequently, federated fine-tuning methods are proposed to adapt large AI\nmodels to specific tasks or environments at the network edge, effectively\naddressing the challenges associated with communication overhead and enhancing\ncommunication efficiency. These methodologies follow clustered, hierarchical,\nand asynchronous paradigms to effectively tackle privacy issues and eliminate\ndata silos. Furthermore, to enhance operational efficiency and reduce latency,\nefficient frameworks for model collaborative reasoning are developed, which\ninclude decentralized horizontal collaboration, cloud-edge-end vertical\ncollaboration, and multi-access collaboration. Next, simulation results\ndemonstrate the effectiveness of our proposed methods in reducing the\nfine-tuning loss of large AI models across various downstream tasks. Finally,\nseveral open challenges and research opportunities are outlined.", "published": "2025-03-27 11:56:36", "link": "http://arxiv.org/abs/2503.21412v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring the Roles of Large Language Models in Reshaping Transportation Systems: A Survey, Framework, and Roadmap", "abstract": "Modern transportation systems face pressing challenges due to increasing\ndemand, dynamic environments, and heterogeneous information integration. The\nrapid evolution of Large Language Models (LLMs) offers transformative potential\nto address these challenges. Extensive knowledge and high-level capabilities\nderived from pretraining evolve the default role of LLMs as text generators to\nbecome versatile, knowledge-driven task solvers for intelligent transportation\nsystems. This survey first presents LLM4TR, a novel conceptual framework that\nsystematically categorizes the roles of LLMs in transportation into four\nsynergetic dimensions: information processors, knowledge encoders, component\ngenerators, and decision facilitators. Through a unified taxonomy, we\nsystematically elucidate how LLMs bridge fragmented data pipelines, enhance\npredictive analytics, simulate human-like reasoning, and enable closed-loop\ninteractions across sensing, learning, modeling, and managing tasks in\ntransportation systems. For each role, our review spans diverse applications,\nfrom traffic prediction and autonomous driving to safety analytics and urban\nmobility optimization, highlighting how emergent capabilities of LLMs such as\nin-context learning and step-by-step reasoning can enhance the operation and\nmanagement of transportation systems. We further curate practical guidance,\nincluding available resources and computational guidelines, to support\nreal-world deployment. By identifying challenges in existing LLM-based\nsolutions, this survey charts a roadmap for advancing LLM-driven transportation\nresearch, positioning LLMs as central actors in the next generation of\ncyber-physical-social mobility ecosystems. Online resources can be found in the\nproject page: https://github.com/tongnie/awesome-llm4tr.", "published": "2025-03-27 11:56:27", "link": "http://arxiv.org/abs/2503.21411v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Neuro-Symbolic Imitation Learning: Discovering Symbolic Abstractions for Skill Learning", "abstract": "Imitation learning is a popular method for teaching robots new behaviors.\nHowever, most existing methods focus on teaching short, isolated skills rather\nthan long, multi-step tasks. To bridge this gap, imitation learning algorithms\nmust not only learn individual skills but also an abstract understanding of how\nto sequence these skills to perform extended tasks effectively. This paper\naddresses this challenge by proposing a neuro-symbolic imitation learning\nframework. Using task demonstrations, the system first learns a symbolic\nrepresentation that abstracts the low-level state-action space. The learned\nrepresentation decomposes a task into easier subtasks and allows the system to\nleverage symbolic planning to generate abstract plans. Subsequently, the system\nutilizes this task decomposition to learn a set of neural skills capable of\nrefining abstract plans into actionable robot commands. Experimental results in\nthree simulated robotic environments demonstrate that, compared to baselines,\nour neuro-symbolic approach increases data efficiency, improves generalization\ncapabilities, and facilitates interpretability.", "published": "2025-03-27 11:50:29", "link": "http://arxiv.org/abs/2503.21406v1", "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Reasoning Under Threat: Symbolic and Neural Techniques for Cybersecurity Verification", "abstract": "Cybersecurity demands rigorous and scalable techniques to ensure system\ncorrectness, robustness, and resilience against evolving threats. Automated\nreasoning, encompassing formal logic, theorem proving, model checking, and\nsymbolic analysis, provides a foundational framework for verifying security\nproperties across diverse domains such as access control, protocol design,\nvulnerability detection, and adversarial modeling. This survey presents a\ncomprehensive overview of the role of automated reasoning in cybersecurity,\nanalyzing how logical systems, including temporal, deontic, and epistemic\nlogics are employed to formalize and verify security guarantees. We examine\nSOTA tools and frameworks, explore integrations with AI for neural-symbolic\nreasoning, and highlight critical research gaps, particularly in scalability,\ncompositionality, and multi-layered security modeling. The paper concludes with\na set of well-grounded future research directions, aiming to foster the\ndevelopment of secure systems through formal, automated, and explainable\nreasoning techniques.", "published": "2025-03-27 11:41:53", "link": "http://arxiv.org/abs/2503.22755v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "HybridoNet-Adapt: A Domain-Adapted Framework for Accurate Lithium-Ion Battery RUL Prediction", "abstract": "Accurate prediction of the remaining useful life (RUL) in Lithium-ion battery\n(LIB) health management systems is crucial for ensuring reliability and safety.\nCurrent methods typically assume that training and testing data share the same\ndistribution, overlooking the benefits of incorporating diverse data sources to\nenhance model performance. To address this limitation, we introduce a\ndata-independent RUL prediction framework along with its domain adaptation (DA)\napproach, which leverages heterogeneous data sources for improved target\npredictions. Our approach integrates comprehensive data preprocessing,\nincluding feature extraction, denoising, and normalization, with a\ndata-independent prediction model that combines Long Short-Term Memory (LSTM),\nMultihead Attention, and a Neural Ordinary Differential Equation (NODE) block,\ntermed HybridoNet. The domain-adapted version, HybridoNet Adapt, is trained\nusing a novel technique inspired by the Domain-Adversarial Neural Network\n(DANN) framework, a regression ensemble method, and Maximum Mean Discrepancy\n(MMD) to learn domain-invariant features from labeled cycling data in the\nsource and target domains. Experimental results demonstrate that our approach\noutperforms state-of-the-art techniques, providing reliable RUL predictions for\nreal-world applications.", "published": "2025-03-27 11:35:25", "link": "http://arxiv.org/abs/2503.21392v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Investigating the Duality of Interpretability and Explainability in Machine Learning", "abstract": "The rapid evolution of machine learning (ML) has led to the widespread\nadoption of complex \"black box\" models, such as deep neural networks and\nensemble methods. These models exhibit exceptional predictive performance,\nmaking them invaluable for critical decision-making across diverse domains\nwithin society. However, their inherently opaque nature raises concerns about\ntransparency and interpretability, making them untrustworthy decision support\nsystems. To alleviate such a barrier to high-stakes adoption, research\ncommunity focus has been on developing methods to explain black box models as a\nmeans to address the challenges they pose. Efforts are focused on explaining\nthese models instead of developing ones that are inherently interpretable.\nDesigning inherently interpretable models from the outset, however, can pave\nthe path towards responsible and beneficial applications in the field of ML. In\nthis position paper, we clarify the chasm between explaining black boxes and\nadopting inherently interpretable models. We emphasize the imperative need for\nmodel interpretability and, following the purpose of attaining better (i.e.,\nmore effective or efficient w.r.t. predictive performance) and trustworthy\npredictors, provide an experimental evaluation of latest hybrid learning\nmethods that integrates symbolic knowledge into neural network predictors. We\ndemonstrate how interpretable hybrid models could potentially supplant black\nbox ones in different domains.", "published": "2025-03-27 10:48:40", "link": "http://arxiv.org/abs/2503.21356v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Using large language models to produce literature reviews: Usages and systematic biases of microphysics parametrizations in 2699 publications", "abstract": "Large language models afford opportunities for using computers for intensive\ntasks, realizing research opportunities that have not been considered before.\nOne such opportunity could be a systematic interrogation of the scientific\nliterature. Here, we show how a large language model can be used to construct a\nliterature review of 2699 publications associated with microphysics\nparametrizations in the Weather and Research Forecasting (WRF) model, with the\ngoal of learning how they were used and their systematic biases, when\nsimulating precipitation. The database was constructed of publications\nidentified from Web of Science and Scopus searches. The large language model\nGPT-4 Turbo was used to extract information about model configurations and\nperformance from the text of 2699 publications. Our results reveal the\nlandscape of how nine of the most popular microphysics parameterizations have\nbeen used around the world: Lin, Ferrier, WRF Single-Moment, Goddard Cumulus\nEnsemble, Morrison, Thompson, and WRF Double-Moment. More studies used\none-moment parameterizations before 2020 and two-moment parameterizations after\n2020. Seven out of nine parameterizations tended to overestimate precipitation.\nHowever, systematic biases of parameterizations differed in various regions.\nExcept simulations using the Lin, Ferrier, and Goddard parameterizations that\ntended to underestimate precipitation over almost all locations, the remaining\nsix parameterizations tended to overestimate, particularly over China,\nsoutheast Asia, western United States, and central Africa. This method could be\nused by other researchers to help understand how the increasingly massive body\nof scientific literature can be harnessed through the power of artificial\nintelligence to solve their research problems.", "published": "2025-03-27 10:42:19", "link": "http://arxiv.org/abs/2503.21352v1", "categories": ["cs.AI", "stat.AP"], "primary_category": "cs.AI"}
{"title": "Model Lake: a New Alternative for Machine Learning Models Management and Governance", "abstract": "The rise of artificial intelligence and data science across industries\nunderscores the pressing need for effective management and governance of\nmachine learning (ML) models. Traditional approaches to ML models management\noften involve disparate storage systems and lack standardized methodologies for\nversioning, audit, and re-use. Inspired by data lake concepts, this paper\ndevelops the concept of ML Model Lake as a centralized management framework for\ndatasets, codes, and models within organizations environments. We provide an\nin-depth exploration of the Model Lake concept, delineating its architectural\nfoundations, key components, operational benefits, and practical challenges. We\ndiscuss the transformative potential of adopting a Model Lake approach, such as\nenhanced model lifecycle management, discovery, audit, and reusability.\nFurthermore, we illustrate a real-world application of Model Lake and its\ntransformative impact on data, code and model management practices.", "published": "2025-03-27 10:35:51", "link": "http://arxiv.org/abs/2503.22754v1", "categories": ["cs.LG", "cs.AI", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Residual Learning Inspired Crossover Operator and Strategy Enhancements for Evolutionary Multitasking", "abstract": "In evolutionary multitasking, strategies such as crossover operators and\nskill factor assignment are critical for effective knowledge transfer. Existing\nimprovements to crossover operators primarily focus on low-dimensional variable\ncombinations, such as arithmetic crossover or partially mapped crossover, which\nare insufficient for modeling complex high-dimensional interactions.Moreover,\nstatic or semi-dynamic crossover strategies fail to adapt to the dynamic\ndependencies among tasks. In addition, current Multifactorial Evolutionary\nAlgorithm frameworks often rely on fixed skill factor assignment strategies,\nlacking flexibility. To address these limitations, this paper proposes the\nMultifactorial Evolutionary Algorithm-Residual Learning (MFEA-RL) method based\non residual learning. The method employs a Very Deep Super-Resolution (VDSR)\nmodel to generate high-dimensional residual representations of individuals,\nenhancing the modeling of complex relationships within dimensions. A\nResNet-based mechanism dynamically assigns skill factors to improve task\nadaptability, while a random mapping mechanism efficiently performs crossover\noperations and mitigates the risk of negative transfer. Theoretical analysis\nand experimental results show that MFEA-RL outperforms state-of-the-art\nmultitasking algorithms. It excels in both convergence and adaptability on\nstandard evolutionary multitasking benchmarks, including CEC2017-MTSO and\nWCCI2020-MTSO. Additionally, its effectiveness is validated through a\nreal-world application scenario.", "published": "2025-03-27 10:27:17", "link": "http://arxiv.org/abs/2503.21347v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "A 71.2-$\u03bc$W Speech Recognition Accelerator with Recurrent Spiking Neural Network", "abstract": "This paper introduces a 71.2-$\\mu$W speech recognition accelerator designed\nfor edge devices' real-time applications, emphasizing an ultra low power\ndesign. Achieved through algorithm and hardware co-optimizations, we propose a\ncompact recurrent spiking neural network with two recurrent layers, one fully\nconnected layer, and a low time step (1 or 2). The 2.79-MB model undergoes\npruning and 4-bit fixed-point quantization, shrinking it by 96.42\\% to 0.1 MB.\nOn the hardware front, we take advantage of \\textit{mixed-level pruning},\n\\textit{zero-skipping} and \\textit{merged spike} techniques, reducing\ncomplexity by 90.49\\% to 13.86 MMAC/S. The \\textit{parallel time-step\nexecution} addresses inter-time-step data dependencies and enables weight\nbuffer power savings through weight sharing. Capitalizing on the sparse spike\nactivity, an input broadcasting scheme eliminates zero computations, further\nsaving power. Implemented on the TSMC 28-nm process, the design operates in\nreal time at 100 kHz, consuming 71.2 $\\mu$W, surpassing state-of-the-art\ndesigns. At 500 MHz, it has 28.41 TOPS/W and 1903.11 GOPS/mm$^2$ in energy and\narea efficiency, respectively.", "published": "2025-03-27 10:14:00", "link": "http://arxiv.org/abs/2503.21337v1", "categories": ["cs.AR", "cs.AI", "eess.AS"], "primary_category": "cs.AR"}
{"title": "A Low-Power Streaming Speech Enhancement Accelerator For Edge Devices", "abstract": "Transformer-based speech enhancement models yield impressive results.\nHowever, their heterogeneous and complex structure restricts model compression\npotential, resulting in greater complexity and reduced hardware efficiency.\nAdditionally, these models are not tailored for streaming and low-power\napplications. Addressing these challenges, this paper proposes a low-power\nstreaming speech enhancement accelerator through model and hardware\noptimization. The proposed high performance model is optimized for hardware\nexecution with the co-design of model compression and target application, which\nreduces 93.9\\% of model size by the proposed domain-aware and streaming-aware\npruning techniques. The required latency is further reduced with batch\nnormalization-based transformers. Additionally, we employed softmax-free\nattention, complemented by an extra batch normalization, facilitating simpler\nhardware design. The tailored hardware accommodates these diverse computing\npatterns by breaking them down into element-wise multiplication and\naccumulation (MAC). This is achieved through a 1-D processing array, utilizing\nconfigurable SRAM addressing, thereby minimizing hardware complexities and\nsimplifying zero skipping. Using the TSMC 40nm CMOS process, the final\nimplementation requires merely 207.8K gates and 53.75KB SRAM. It consumes only\n8.08 mW for real-time inference at a 62.5MHz frequency.", "published": "2025-03-27 10:13:41", "link": "http://arxiv.org/abs/2503.21335v1", "categories": ["cs.AR", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.AR"}
{"title": "HyperGraphRAG: Retrieval-Augmented Generation with Hypergraph-Structured Knowledge Representation", "abstract": "While standard Retrieval-Augmented Generation (RAG) based on chunks, GraphRAG\nstructures knowledge as graphs to leverage the relations among entities.\nHowever, previous GraphRAG methods are limited by binary relations: one edge in\nthe graph only connects two entities, which cannot well model the n-ary\nrelations among more than two entities that widely exist in reality. To address\nthis limitation, we propose HyperGraphRAG, a novel hypergraph-based RAG method\nthat represents n-ary relational facts via hyperedges, modeling the complicated\nn-ary relations in the real world. To retrieve and generate over hypergraphs,\nwe introduce a complete pipeline with a hypergraph construction method, a\nhypergraph retrieval strategy, and a hypergraph-guided generation mechanism.\nExperiments across medicine, agriculture, computer science, and law demonstrate\nthat HyperGraphRAG outperforms standard RAG and GraphRAG in accuracy and\ngeneration quality.", "published": "2025-03-27 10:01:16", "link": "http://arxiv.org/abs/2503.21322v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FineCIR: Explicit Parsing of Fine-Grained Modification Semantics for Composed Image Retrieval", "abstract": "Composed Image Retrieval (CIR) facilitates image retrieval through a\nmultimodal query consisting of a reference image and modification text. The\nreference image defines the retrieval context, while the modification text\nspecifies desired alterations. However, existing CIR datasets predominantly\nemploy coarse-grained modification text (CoarseMT), which inadequately captures\nfine-grained retrieval intents. This limitation introduces two key challenges:\n(1) ignoring detailed differences leads to imprecise positive samples, and (2)\ngreater ambiguity arises when retrieving visually similar images. These issues\ndegrade retrieval accuracy, necessitating manual result filtering or repeated\nqueries. To address these limitations, we develop a robust fine-grained CIR\ndata annotation pipeline that minimizes imprecise positive samples and enhances\nCIR systems' ability to discern modification intents accurately. Using this\npipeline, we refine the FashionIQ and CIRR datasets to create two fine-grained\nCIR datasets: Fine-FashionIQ and Fine-CIRR. Furthermore, we introduce FineCIR,\nthe first CIR framework explicitly designed to parse the modification text.\nFineCIR effectively captures fine-grained modification semantics and aligns\nthem with ambiguous visual entities, enhancing retrieval precision. Extensive\nexperiments demonstrate that FineCIR consistently outperforms state-of-the-art\nCIR baselines on both fine-grained and traditional CIR benchmark datasets. Our\nFineCIR code and fine-grained CIR datasets are available at\nhttps://github.com/SDU-L/FineCIR.git.", "published": "2025-03-27 09:34:21", "link": "http://arxiv.org/abs/2503.21309v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "InternVL-X: Advancing and Accelerating InternVL Series with Efficient Visual Token Compression", "abstract": "Most multimodal large language models (MLLMs) treat visual tokens as \"a\nsequence of text\", integrating them with text tokens into a large language\nmodel (LLM). However, a great quantity of visual tokens significantly increases\nthe demand for computational resources and time. In this paper, we propose\nInternVL-X, which outperforms the InternVL model in both performance and\nefficiency by incorporating three visual token compression methods. First, we\npropose a novel vision-language projector, PVTC. This component integrates\nadjacent visual embeddings to form a local query and utilizes the transformed\nCLS token as a global query, then performs point-to-region cross-attention\nthrough these local and global queries to more effectively convert visual\nfeatures. Second, we present a layer-wise visual token compression module,\nLVTC, which compresses tokens in the LLM shallow layers and then expands them\nthrough upsampling and residual connections in the deeper layers. This\nsignificantly enhances the model computational efficiency. Futhermore, we\npropose an efficient high resolution slicing method, RVTC, which dynamically\nadjusts the number of visual tokens based on image area or length filtering.\nRVTC greatly enhances training efficiency with only a slight reduction in\nperformance. By utilizing 20% or fewer visual tokens, InternVL-X achieves\nstate-of-the-art performance on 7 public MLLM benchmarks, and improves the\naverage metric by 2.34% across 12 tasks.", "published": "2025-03-27 09:31:35", "link": "http://arxiv.org/abs/2503.21307v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DeBackdoor: A Deductive Framework for Detecting Backdoor Attacks on Deep Models with Limited Data", "abstract": "Backdoor attacks are among the most effective, practical, and stealthy\nattacks in deep learning. In this paper, we consider a practical scenario where\na developer obtains a deep model from a third party and uses it as part of a\nsafety-critical system. The developer wants to inspect the model for potential\nbackdoors prior to system deployment. We find that most existing detection\ntechniques make assumptions that are not applicable to this scenario. In this\npaper, we present a novel framework for detecting backdoors under realistic\nrestrictions. We generate candidate triggers by deductively searching over the\nspace of possible triggers. We construct and optimize a smoothed version of\nAttack Success Rate as our search objective. Starting from a broad class of\ntemplate attacks and just using the forward pass of a deep model, we reverse\nengineer the backdoor attack. We conduct extensive evaluation on a wide range\nof attacks, models, and datasets, with our technique performing almost\nperfectly across these settings.", "published": "2025-03-27 09:31:10", "link": "http://arxiv.org/abs/2503.21305v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Multi-Scale Invertible Neural Network for Wide-Range Variable-Rate Learned Image Compression", "abstract": "Autoencoder-based structures have dominated recent learned image compression\nmethods. However, the inherent information loss associated with autoencoders\nlimits their rate-distortion performance at high bit rates and restricts their\nflexibility of rate adaptation. In this paper, we present a variable-rate image\ncompression model based on invertible transform to overcome these limitations.\nSpecifically, we design a lightweight multi-scale invertible neural network,\nwhich bijectively maps the input image into multi-scale latent representations.\nTo improve the compression efficiency, a multi-scale spatial-channel context\nmodel with extended gain units is devised to estimate the entropy of the latent\nrepresentation from high to low levels. Experimental results demonstrate that\nthe proposed method achieves state-of-the-art performance compared to existing\nvariable-rate methods, and remains competitive with recent multi-model\napproaches. Notably, our method is the first learned image compression solution\nthat outperforms VVC across a very wide range of bit rates using a single\nmodel, especially at high bit rates. The source code is available at\nhttps://github.com/hytu99/MSINN-VRLIC.", "published": "2025-03-27 09:08:39", "link": "http://arxiv.org/abs/2503.21284v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Individual to Group: Developing a Context-Aware Multi-Criteria Group Recommender System", "abstract": "Group decision-making is becoming increasingly common in areas such as\neducation, dining, travel, and finance, where collaborative choices must\nbalance diverse individual preferences. While conventional recommender systems\nare effective in personalization, they fall short in group settings due to\ntheir inability to manage conflicting preferences, contextual factors, and\nmultiple evaluation criteria. This study presents the development of a\nContext-Aware Multi-Criteria Group Recommender System (CA-MCGRS) designed to\naddress these challenges by integrating contextual factors and multiple\ncriteria to enhance recommendation accuracy. By leveraging a Multi-Head\nAttention mechanism, our model dynamically weighs the importance of different\nfeatures. Experiments conducted on an educational dataset with varied ratings\nand contextual variables demonstrate that CA-MCGRS consistently outperforms\nother approaches across four scenarios. Our findings underscore the importance\nof incorporating context and multi-criteria evaluations to improve group\nrecommendations, offering valuable insights for developing more effective group\nrecommender systems.", "published": "2025-03-27 09:01:45", "link": "http://arxiv.org/abs/2503.22752v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Reinforced Model Merging", "abstract": "The success of large language models has garnered widespread attention for\nmodel merging techniques, especially training-free methods which combine model\ncapabilities within the parameter space. However, two challenges remain: (1)\nuniform treatment of all parameters leads to performance degradation; (2)\nsearch-based algorithms are often inefficient. In this paper, we present an\ninnovative framework termed Reinforced Model Merging (RMM), which encompasses\nan environment and agent tailored for merging tasks. These components interact\nto execute layer-wise merging actions, aiming to search the optimal merging\narchitecture. Notably, RMM operates without any gradient computations on the\noriginal models, rendering it feasible for edge devices. Furthermore, by\nutilizing data subsets during the evaluation process, we addressed the\nbottleneck in the reward feedback phase, thereby accelerating RMM by up to 100\ntimes. Extensive experiments demonstrate that RMM achieves state-of-the-art\nperformance across various vision and NLP datasets and effectively overcomes\nthe limitations of the existing baseline methods. Our code is available at\nhttps://github.com/WuDiHJQ/Reinforced-Model-Merging.", "published": "2025-03-27 08:52:41", "link": "http://arxiv.org/abs/2503.21272v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Learn by Reasoning: Analogical Weight Generation for Few-Shot Class-Incremental Learning", "abstract": "Few-shot class-incremental Learning (FSCIL) enables models to learn new\nclasses from limited data while retaining performance on previously learned\nclasses. Traditional FSCIL methods often require fine-tuning parameters with\nlimited new class data and suffer from a separation between learning new\nclasses and utilizing old knowledge. Inspired by the analogical learning\nmechanisms of the human brain, we propose a novel analogical generative method.\nOur approach includes the Brain-Inspired Analogical Generator (BiAG), which\nderives new class weights from existing classes without parameter fine-tuning\nduring incremental stages. BiAG consists of three components: Weight\nSelf-Attention Module (WSA), Weight & Prototype Analogical Attention Module\n(WPAA), and Semantic Conversion Module (SCM). SCM uses Neural Collapse theory\nfor semantic conversion, WSA supplements new class weights, and WPAA computes\nanalogies to generate new class weights. Experiments on miniImageNet, CUB-200,\nand CIFAR-100 datasets demonstrate that our method achieves higher final and\naverage accuracy compared to SOTA methods.", "published": "2025-03-27 08:31:46", "link": "http://arxiv.org/abs/2503.21258v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "OminiAdapt: Learning Cross-Task Invariance for Robust and Environment-Aware Robotic Manipulation", "abstract": "With the rapid development of embodied intelligence, leveraging large-scale\nhuman data for high-level imitation learning on humanoid robots has become a\nfocal point of interest in both academia and industry. However, applying\nhumanoid robots to precision operation domains remains challenging due to the\ncomplexities they face in perception and control processes, the long-standing\nphysical differences in morphology and actuation mechanisms between humanoid\nrobots and humans, and the lack of task-relevant features obtained from\negocentric vision. To address the issue of covariate shift in imitation\nlearning, this paper proposes an imitation learning algorithm tailored for\nhumanoid robots. By focusing on the primary task objectives, filtering out\nbackground information, and incorporating channel feature fusion with spatial\nattention mechanisms, the proposed algorithm suppresses environmental\ndisturbances and utilizes a dynamic weight update strategy to significantly\nimprove the success rate of humanoid robots in accomplishing target tasks.\nExperimental results demonstrate that the proposed method exhibits robustness\nand scalability across various typical task scenarios, providing new ideas and\napproaches for autonomous learning and control in humanoid robots. The project\nwill be open-sourced on GitHub.", "published": "2025-03-27 08:28:22", "link": "http://arxiv.org/abs/2503.21257v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Vision-to-Music Generation: A Survey", "abstract": "Vision-to-music Generation, including video-to-music and image-to-music\ntasks, is a significant branch of multimodal artificial intelligence\ndemonstrating vast application prospects in fields such as film scoring, short\nvideo creation, and dance music synthesis. However, compared to the rapid\ndevelopment of modalities like text and images, research in vision-to-music is\nstill in its preliminary stage due to its complex internal structure and the\ndifficulty of modeling dynamic relationships with video. Existing surveys focus\non general music generation without comprehensive discussion on\nvision-to-music. In this paper, we systematically review the research progress\nin the field of vision-to-music generation. We first analyze the technical\ncharacteristics and core challenges for three input types: general videos,\nhuman movement videos, and images, as well as two output types of symbolic\nmusic and audio music. We then summarize the existing methodologies on\nvision-to-music generation from the architecture perspective. A detailed review\nof common datasets and evaluation metrics is provided. Finally, we discuss\ncurrent challenges and promising directions for future research. We hope our\nsurvey can inspire further innovation in vision-to-music generation and the\nbroader field of multimodal generation in academic research and industrial\napplications. To follow latest works and foster further innovation in this\nfield, we are continuously maintaining a GitHub repository at\nhttps://github.com/wzk1015/Awesome-Vision-to-Music-Generation.", "published": "2025-03-27 08:21:54", "link": "http://arxiv.org/abs/2503.21254v1", "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Dual-Splitting Conformal Prediction for Multi-Step Time Series Forecasting", "abstract": "Time series forecasting is crucial for applications like resource scheduling\nand risk management, where multi-step predictions provide a comprehensive view\nof future trends. Uncertainty Quantification (UQ) is a mainstream approach for\naddressing forecasting uncertainties, with Conformal Prediction (CP) gaining\nattention due to its model-agnostic nature and statistical guarantees. However,\nmost variants of CP are designed for single-step predictions and face\nchallenges in multi-step scenarios, such as reliance on real-time data and\nlimited scalability. This highlights the need for CP methods specifically\ntailored to multi-step forecasting. We propose the Dual-Splitting Conformal\nPrediction (DSCP) method, a novel CP approach designed to capture inherent\ndependencies within time-series data for multi-step forecasting. Experimental\nresults on real-world datasets from four different domains demonstrate that the\nproposed DSCP significantly outperforms existing CP variants in terms of the\nWinkler Score, achieving a performance improvement of up to 23.59% compared to\nstate-of-the-art methods. Furthermore, we deployed the DSCP approach for\nrenewable energy generation and IT load forecasting in power management of a\nreal-world trajectory-based application, achieving an 11.25% reduction in\ncarbon emissions through predictive optimization of data center operations and\ncontrols.", "published": "2025-03-27 08:17:18", "link": "http://arxiv.org/abs/2503.21251v1", "categories": ["cs.LG", "cs.AI", "68T37", "I.2.8"], "primary_category": "cs.LG"}
{"title": "Improving $(\u03b1, f)$-Byzantine Resilience in Federated Learning via layerwise aggregation and cosine distance", "abstract": "The rapid development of artificial intelligence systems has amplified\nsocietal concerns regarding their usage, necessitating regulatory frameworks\nthat encompass data privacy. Federated Learning (FL) is posed as potential\nsolution to data privacy challenges in distributed machine learning by enabling\ncollaborative model training {without data sharing}. However, FL systems remain\nvulnerable to Byzantine attacks, where malicious nodes contribute corrupted\nmodel updates. While Byzantine Resilient operators have emerged as a widely\nadopted robust aggregation algorithm to mitigate these attacks, its efficacy\ndiminishes significantly in high-dimensional parameter spaces, sometimes\nleading to poor performing models. This paper introduces Layerwise Cosine\nAggregation, a novel aggregation scheme designed to enhance robustness of these\nrules in such high-dimensional settings while preserving computational\nefficiency. A theoretical analysis is presented, demonstrating the superior\nrobustness of the proposed Layerwise Cosine Aggregation compared to original\nrobust aggregation operators. Empirical evaluation across diverse image\nclassification datasets, under varying data distributions and Byzantine attack\nscenarios, consistently demonstrates the improved performance of Layerwise\nCosine Aggregation, achieving up to a 16% increase in model accuracy.", "published": "2025-03-27 08:07:39", "link": "http://arxiv.org/abs/2503.21244v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Feature-Enhanced Machine Learning for All-Cause Mortality Prediction in Healthcare Data", "abstract": "Accurate patient mortality prediction enables effective risk stratification,\nleading to personalized treatment plans and improved patient outcomes. However,\npredicting mortality in healthcare remains a significant challenge, with\nexisting studies often focusing on specific diseases or limited predictor sets.\nThis study evaluates machine learning models for all-cause in-hospital\nmortality prediction using the MIMIC-III database, employing a comprehensive\nfeature engineering approach. Guided by clinical expertise and literature, we\nextracted key features such as vital signs (e.g., heart rate, blood pressure),\nlaboratory results (e.g., creatinine, glucose), and demographic information.\nThe Random Forest model achieved the highest performance with an AUC of 0.94,\nsignificantly outperforming other machine learning and deep learning\napproaches. This demonstrates Random Forest's robustness in handling\nhigh-dimensional, noisy clinical data and its potential for developing\neffective clinical decision support tools. Our findings highlight the\nimportance of careful feature engineering for accurate mortality prediction. We\nconclude by discussing implications for clinical adoption and propose future\ndirections, including enhancing model robustness and tailoring prediction\nmodels for specific diseases.", "published": "2025-03-27 08:04:42", "link": "http://arxiv.org/abs/2503.21241v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Knowledge Graphs as World Models for Semantic Material-Aware Obstacle Handling in Autonomous Vehicles", "abstract": "The inability of autonomous vehicles (AVs) to infer the material properties\nof obstacles limits their decision-making capacity. While AVs rely on sensor\nsystems such as cameras, LiDAR, and radar to detect obstacles, this study\nsuggests combining sensors with a knowledge graph (KG)-based world model to\nimprove AVs' comprehension of physical material qualities. Beyond sensor data,\nAVs can infer qualities such as malleability, density, and elasticity using a\nsemantic KG that depicts the relationships between obstacles and their\nattributes. Using the CARLA autonomous driving simulator, we evaluated AV\nperformance with and without KG integration. The findings demonstrate that the\nKG-based method improves obstacle management, which allows AVs to use material\nqualities to make better decisions about when to change lanes or apply\nemergency braking. For example, the KG-integrated AV changed lanes for hard\nimpediments like traffic cones and successfully avoided collisions with\nflexible items such as plastic bags by passing over them. Compared to the\ncontrol system, the KG framework demonstrated improved responsiveness to\nobstacles by resolving conflicting sensor data, causing emergency stops for\n13.3% more cases. In addition, our method exhibits a 6.6% higher success rate\nin lane-changing maneuvers in experimental scenarios, particularly for larger,\nhigh-impact obstacles. While we focus particularly on autonomous driving, our\nwork demonstrates the potential of KG-based world models to improve\ndecision-making in embodied AI systems and scale to other domains, including\nrobotics, healthcare, and environmental simulation.", "published": "2025-03-27 07:46:45", "link": "http://arxiv.org/abs/2503.21232v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "M-DocSum: Do LVLMs Genuinely Comprehend Interleaved Image-Text in Document Summarization?", "abstract": "We investigate a critical yet under-explored question in Large\nVision-Language Models (LVLMs): Do LVLMs genuinely comprehend interleaved\nimage-text in the document? Existing document understanding benchmarks often\nassess LVLMs using question-answer formats, which are information-sparse and\ndifficult to guarantee the coverage of long-range dependencies. To address this\nissue, we introduce a novel and challenging Multimodal Document Summarization\nBenchmark (M-DocSum-Bench), which comprises 500 high-quality arXiv papers,\nalong with interleaved multimodal summaries aligned with human preferences.\nM-DocSum-Bench is a reference-based generation task and necessitates the\ngeneration of interleaved image-text summaries using provided reference images,\nthereby simultaneously evaluating capabilities in understanding, reasoning,\nlocalization, and summarization within complex multimodal document scenarios.\nTo facilitate this benchmark, we develop an automated framework to construct\nsummaries and propose a fine-grained evaluation method called M-DocEval.\nMoreover, we further develop a robust summarization baseline, i.e.,\nM-DocSum-7B, by progressive two-stage training with diverse instruction and\npreference data. The extensive results on our M-DocSum-Bench reveal that the\nleading LVLMs struggle to maintain coherence and accurately integrate\ninformation within long and interleaved contexts, often exhibiting confusion\nbetween similar images and a lack of robustness. Notably, M-DocSum-7B achieves\nstate-of-the-art performance compared to larger and closed-source models\n(including GPT-4o, Gemini Pro, Claude-3.5-Sonnet and Qwen2.5-VL-72B, etc.),\ndemonstrating the potential of LVLMs for improved interleaved image-text\nunderstanding. The code, data, and models are available at\nhttps://github.com/stepfun-ai/M-DocSum-Bench.", "published": "2025-03-27 07:28:32", "link": "http://arxiv.org/abs/2503.21839v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GenFusion: Closing the Loop between Reconstruction and Generation via Videos", "abstract": "Recently, 3D reconstruction and generation have demonstrated impressive novel\nview synthesis results, achieving high fidelity and efficiency. However, a\nnotable conditioning gap can be observed between these two fields, e.g.,\nscalable 3D scene reconstruction often requires densely captured views, whereas\n3D generation typically relies on a single or no input view, which\nsignificantly limits their applications. We found that the source of this\nphenomenon lies in the misalignment between 3D constraints and generative\npriors. To address this problem, we propose a reconstruction-driven video\ndiffusion model that learns to condition video frames on artifact-prone RGB-D\nrenderings. Moreover, we propose a cyclical fusion pipeline that iteratively\nadds restoration frames from the generative model to the training set, enabling\nprogressive expansion and addressing the viewpoint saturation limitations seen\nin previous reconstruction and generation pipelines. Our evaluation, including\nview synthesis from sparse view and masked input, validates the effectiveness\nof our approach. More details at https://genfusion.sibowu.com.", "published": "2025-03-27 07:16:24", "link": "http://arxiv.org/abs/2503.21219v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Advancing Spatiotemporal Prediction using Artificial Intelligence: Extending the Framework of Geographically and Temporally Weighted Neural Network (GTWNN) for Differing Geographical and Temporal Contexts", "abstract": "This paper aims at improving predictive crime models by extending the\nmathematical framework of Artificial Neural Networks (ANNs) tailored to general\nspatiotemporal problems and appropriately applying them. Recent advancements in\nthe geospatial-temporal modelling field have focused on the inclusion of\ngeographical weighting in their deep learning models to account for nonspatial\nstationarity, which is often apparent in spatial data. We formulate a novel\nsemi-analytical approach to solving Geographically and Temporally Weighted\nRegression (GTWR), and applying it to London crime data. The results produce\nhigh-accuracy predictive evaluation scores that affirm the validity of the\nassumptions and approximations in the approach. This paper presents\nmathematical advances to the Geographically and Temporally Weighted Neural\nNetwork (GTWNN) framework, which offers a novel contribution to the field.\nInsights from past literature are harmoniously employed with the assumptions\nand approximations to generate three mathematical extensions to GTWNN's\nframework. Combinations of these extensions produce five novel ANNs, applied to\nthe London and Detroit datasets. The results suggest that one of the extensions\nis redundant and is generally surpassed by another extension, which we term the\nhistory-dependent module. The remaining extensions form three novel ANN designs\nthat pose potential GTWNN improvements. We evaluated the efficacy of various\nmodels in both the London and Detroit crime datasets, highlighting the\nimportance of accounting for specific geographic and temporal characteristics\nwhen selecting modelling strategies to improve model suitability. In general,\nthe proposed methods provide the foundations for a more context-aware,\naccurate, and robust ANN approach in spatio-temporal modelling.", "published": "2025-03-27 06:45:59", "link": "http://arxiv.org/abs/2503.22751v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Learning Generalizable Skills from Offline Multi-Task Data for Multi-Agent Cooperation", "abstract": "Learning cooperative multi-agent policy from offline multi-task data that can\ngeneralize to unseen tasks with varying numbers of agents and targets is an\nattractive problem in many scenarios. Although aggregating general behavior\npatterns among multiple tasks as skills to improve policy transfer is a\npromising approach, two primary challenges hinder the further advancement of\nskill learning in offline multi-task MARL. Firstly, extracting general\ncooperative behaviors from various action sequences as common skills lacks\nbringing cooperative temporal knowledge into them. Secondly, existing works\nonly involve common skills and can not adaptively choose independent knowledge\nas task-specific skills in each task for fine-grained action execution. To\ntackle these challenges, we propose Hierarchical and Separate Skill Discovery\n(HiSSD), a novel approach for generalizable offline multi-task MARL through\nskill learning. HiSSD leverages a hierarchical framework that jointly learns\ncommon and task-specific skills. The common skills learn cooperative temporal\nknowledge and enable in-sample exploitation for offline multi-task MARL. The\ntask-specific skills represent the priors of each task and achieve a\ntask-guided fine-grained action execution. To verify the advancement of our\nmethod, we conduct experiments on multi-agent MuJoCo and SMAC benchmarks. After\ntraining the policy using HiSSD on offline multi-task data, the empirical\nresults show that HiSSD assigns effective cooperative behaviors and obtains\nsuperior performance in unseen tasks.", "published": "2025-03-27 06:35:59", "link": "http://arxiv.org/abs/2503.21200v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Integrating Large Language Models For Monte Carlo Simulation of Chemical Reaction Networks", "abstract": "Chemical reaction network is an important method for modeling and exploring\ncomplex biological processes, bio-chemical interactions and the behavior of\ndifferent dynamics in system biology. But, formulating such reaction kinetics\ntakes considerable time. In this paper, we leverage the efficiency of modern\nlarge language models to automate the stochastic monte carlo simulation of\nchemical reaction networks and enable the simulation through the reaction\ndescription provided in the form of natural languages. We also integrate this\nprocess into widely used simulation tool Copasi to further give the edge and\nease to the modelers and researchers. In this work, we show the efficacy and\nlimitations of the modern large language models to parse and create reaction\nkinetics for modelling complex chemical reaction processes.", "published": "2025-03-27 06:01:50", "link": "http://arxiv.org/abs/2503.21178v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Adversarial Wear and Tear: Exploiting Natural Damage for Generating Physical-World Adversarial Examples", "abstract": "The presence of adversarial examples in the physical world poses significant\nchallenges to the deployment of Deep Neural Networks in safety-critical\napplications such as autonomous driving. Most existing methods for crafting\nphysical-world adversarial examples are ad-hoc, relying on temporary\nmodifications like shadows, laser beams, or stickers that are tailored to\nspecific scenarios. In this paper, we introduce a new class of physical-world\nadversarial examples, AdvWT, which draws inspiration from the naturally\noccurring phenomenon of `wear and tear', an inherent property of physical\nobjects. Unlike manually crafted perturbations, `wear and tear' emerges\norganically over time due to environmental degradation, as seen in the gradual\ndeterioration of outdoor signboards. To achieve this, AdvWT follows a two-step\napproach. First, a GAN-based, unsupervised image-to-image translation network\nis employed to model these naturally occurring damages, particularly in the\ncontext of outdoor signboards. The translation network encodes the\ncharacteristics of damaged signs into a latent `damage style code'. In the\nsecond step, we introduce adversarial perturbations into the style code,\nstrategically optimizing its transformation process. This manipulation subtly\nalters the damage style representation, guiding the network to generate\nadversarial images where the appearance of damages remains perceptually\nrealistic, while simultaneously ensuring their effectiveness in misleading\nneural networks. Through comprehensive experiments on two traffic sign\ndatasets, we show that AdvWT effectively misleads DNNs in both digital and\nphysical domains. AdvWT achieves an effective attack success rate, greater\nrobustness, and a more natural appearance compared to existing physical-world\nadversarial examples. Additionally, integrating AdvWT into training enhances a\nmodel's generalizability to real-world damaged signs.", "published": "2025-03-27 05:19:41", "link": "http://arxiv.org/abs/2503.21164v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Adaptive Clipping for Privacy-Preserving Few-Shot Learning: Enhancing Generalization with Limited Data", "abstract": "In the era of data-driven machine-learning applications, privacy concerns and\nthe scarcity of labeled data have become paramount challenges. These challenges\nare particularly pronounced in the domain of few-shot learning, where the\nability to learn from limited labeled data is crucial. Privacy-preserving\nfew-shot learning algorithms have emerged as a promising solution to address\nsuch pronounced challenges. However, it is well-known that privacy-preserving\ntechniques often lead to a drop in utility due to the fundamental trade-off\nbetween data privacy and model performance. To enhance the utility of\nprivacy-preserving few-shot learning methods, we introduce a novel approach\ncalled Meta-Clip. This technique is specifically designed for meta-learning\nalgorithms, including Differentially Private (DP) model-agnostic meta-learning,\nDP-Reptile, and DP-MetaSGD algorithms, with the objective of balancing data\nprivacy preservation with learning capacity maximization. By dynamically\nadjusting clipping thresholds during the training process, our Adaptive\nClipping method provides fine-grained control over the disclosure of sensitive\ninformation, mitigating overfitting on small datasets and significantly\nimproving the generalization performance of meta-learning models. Through\ncomprehensive experiments on diverse benchmark datasets, we demonstrate the\neffectiveness of our approach in minimizing utility degradation, showcasing a\nsuperior privacy-utility trade-off compared to existing privacy-preserving\ntechniques. The adoption of Adaptive Clipping represents a substantial step\nforward in the field of privacy-preserving few-shot learning, empowering the\ndevelopment of secure and accurate models for real-world applications,\nespecially in scenarios where there are limited data availability.", "published": "2025-03-27 05:14:18", "link": "http://arxiv.org/abs/2503.22749v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multi-Objective Optimization for Privacy-Utility Balance in Differentially Private Federated Learning", "abstract": "Federated learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, making it a promising approach\nfor privacy-preserving machine learning. However, ensuring differential privacy\n(DP) in FL presents challenges due to the trade-off between model utility and\nprivacy protection. Clipping gradients before aggregation is a common strategy\nto limit privacy loss, but selecting an optimal clipping norm is non-trivial,\nas excessively high values compromise privacy, while overly restrictive\nclipping degrades model performance. In this work, we propose an adaptive\nclipping mechanism that dynamically adjusts the clipping norm using a\nmulti-objective optimization framework. By integrating privacy and utility\nconsiderations into the optimization objective, our approach balances privacy\npreservation with model accuracy. We theoretically analyze the convergence\nproperties of our method and demonstrate its effectiveness through extensive\nexperiments on MNIST, Fashion-MNIST, and CIFAR-10 datasets. Our results show\nthat adaptive clipping consistently outperforms fixed-clipping baselines,\nachieving improved accuracy under the same privacy constraints. This work\nhighlights the potential of dynamic clipping strategies to enhance\nprivacy-utility trade-offs in differentially private federated learning.", "published": "2025-03-27 04:57:05", "link": "http://arxiv.org/abs/2503.21159v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Federated Learning with Differential Privacy: An Utility-Enhanced Approach", "abstract": "Federated learning has emerged as an attractive approach to protect data\nprivacy by eliminating the need for sharing clients' data while reducing\ncommunication costs compared with centralized machine learning algorithms.\nHowever, recent studies have shown that federated learning alone does not\nguarantee privacy, as private data may still be inferred from the uploaded\nparameters to the central server. In order to successfully avoid data leakage,\nadopting differential privacy (DP) in the local optimization process or in the\nlocal update aggregation process has emerged as two feasible ways for achieving\nsample-level or user-level privacy guarantees respectively, in federated\nlearning models. However, compared to their non-private equivalents, these\napproaches suffer from a poor utility. To improve the privacy-utility\ntrade-off, we present a modification to these vanilla differentially private\nalgorithms based on a Haar wavelet transformation step and a novel noise\ninjection scheme that significantly lowers the asymptotic bound of the noise\nvariance. We also present a holistic convergence analysis of our proposed\nalgorithm, showing that our method yields better convergence performance than\nthe vanilla DP algorithms. Numerical experiments on real-world datasets\ndemonstrate that our method outperforms existing approaches in model utility\nwhile maintaining the same privacy guarantees.", "published": "2025-03-27 04:48:29", "link": "http://arxiv.org/abs/2503.21154v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Devil is in Low-Level Features for Cross-Domain Few-Shot Segmentation", "abstract": "Cross-Domain Few-Shot Segmentation (CDFSS) is proposed to transfer the\npixel-level segmentation capabilities learned from large-scale source-domain\ndatasets to downstream target-domain datasets, with only a few annotated images\nper class. In this paper, we focus on a well-observed but unresolved phenomenon\nin CDFSS: for target domains, particularly those distant from the source\ndomain, segmentation performance peaks at the very early epochs, and declines\nsharply as the source-domain training proceeds. We delve into this phenomenon\nfor an interpretation: low-level features are vulnerable to domain shifts,\nleading to sharper loss landscapes during the source-domain training, which is\nthe devil of CDFSS. Based on this phenomenon and interpretation, we further\npropose a method that includes two plug-and-play modules: one to flatten the\nloss landscapes for low-level features during source-domain training as a novel\nsharpness-aware minimization method, and the other to directly supplement\ntarget-domain information to the model during target-domain testing by\nlow-level-based calibration. Extensive experiments on four target datasets\nvalidate our rationale and demonstrate that our method surpasses the\nstate-of-the-art method in CDFSS signifcantly by 3.71% and 5.34% average MIoU\nin 1-shot and 5-shot scenarios, respectively.", "published": "2025-03-27 04:37:52", "link": "http://arxiv.org/abs/2503.21150v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A computational theory of evaluation for parameterisable subject", "abstract": "Evaluation is critical to advance decision making across domains, yet\nexisting methodologies often struggle to balance theoretical rigor and\npractical scalability. In order to reduce the cost of experimental evaluation,\nwe introduce a computational theory of evaluation for parameterisable subjects.\nWe prove upper bounds of generalized evaluation error and generalized causal\neffect error of evaluation metric on subject. We also prove efficiency, and\nconsistency to estimated causal effect of subject on metric by prediction. To\noptimize evaluation models, we propose a meta-learner to handle heterogeneous\nevaluation subjects space. Comparing with other computational approaches, our\n(conditional) evaluation model reduced 24.1%-99.0% evaluation errors across 12\nscenes, including individual medicine, scientific simulation, business\nactivities, and quantum trade. The evaluation time is reduced 3-7 order of\nmagnitude comparing with experiments or simulations.", "published": "2025-03-27 04:00:49", "link": "http://arxiv.org/abs/2503.21138v1", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.AI"}
{"title": "Optimizing Multi-DNN Inference on Mobile Devices through Heterogeneous Processor Co-Execution", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed across diverse\nindustries, driving demand for mobile device support. However, existing mobile\ninference frameworks often rely on a single processor per model, limiting\nhardware utilization and causing suboptimal performance and energy efficiency.\nExpanding DNN accessibility on mobile platforms requires adaptive,\nresource-efficient solutions to meet rising computational needs without\ncompromising functionality. Parallel inference of multiple DNNs on\nheterogeneous processors remains challenging. Some works partition DNN\noperations into subgraphs for parallel execution across processors, but these\noften create excessive subgraphs based only on hardware compatibility,\nincreasing scheduling complexity and memory overhead.\n  To address this, we propose an Advanced Multi-DNN Model Scheduling (ADMS)\nstrategy for optimizing multi-DNN inference on mobile heterogeneous processors.\nADMS constructs an optimal subgraph partitioning strategy offline, balancing\nhardware operation support and scheduling granularity, and uses a\nprocessor-state-aware algorithm to dynamically adjust workloads based on\nreal-time conditions. This ensures efficient workload distribution and\nmaximizes processor utilization. Experiments show ADMS reduces multi-DNN\ninference latency by 4.04 times compared to vanilla frameworks.", "published": "2025-03-27 03:03:09", "link": "http://arxiv.org/abs/2503.21109v1", "categories": ["cs.DC", "cs.AI", "68T07, 68W40", "I.2.6; C.1.4; D.4.8"], "primary_category": "cs.DC"}
{"title": "Ignite Forecasting with SPARK: An Efficient Generative Framework for Refining LLMs in Temporal Knowledge Graph Forecasting", "abstract": "Temporal Knowledge Graph (TKG) forecasting is crucial for predicting future\nevents using historical data. With the surge of Large Language Models (LLMs),\nrecent studies have begun exploring their integration into TKG forecasting and\nachieved some success. However, they still face limitations such as limited\ninput length, inefficient output generation, and resource-intensive refinement,\nwhich undermine their performance and practical applicability. To address these\nlimitations, we introduce SPARK, a Sequence-level Proxy-Adapting framework for\nRefining LLMs in TKG forecasting. Inspired by inference-time algorithms adopted\nin controlling generation, SPARK offers a cost-effective, plug-and-play\nsolution through two key innovations: (1) Beam Sequence-Level Generation, which\nreframes TKG forecasting as a top-K sequence-level generation task, using beam\nsearch for efficiently generating next-entity distribution in a single forward\npass. (2) TKG Adapter for Refinement, which employs traditional TKG models as\ntrainable proxy adapters to leverage global graph information and refine LLM\noutputs, overcoming both the input length and the resource-intensive\nfine-tuning problems. Experiments across diverse datasets validate SPARK's\nforecasting performance, robust generalization capabilities, and high\nefficiency. We release source codes at https://github.com/yin-gz/SPARK.", "published": "2025-03-27 03:02:02", "link": "http://arxiv.org/abs/2503.22748v1", "categories": ["cs.LG", "cs.AI", "I.2.4"], "primary_category": "cs.LG"}
{"title": "LeForecast: Enterprise Hybrid Forecast by Time Series Intelligence", "abstract": "Demand is spiking in industrial fields for multidisciplinary forecasting,\nwhere a broad spectrum of sectors needs planning and forecasts to streamline\nintelligent business management, such as demand forecasting, product planning,\ninventory optimization, etc. Specifically, these tasks expecting intelligent\napproaches to learn from sequentially collected historical data and then\nforesee most possible trend, i.e. time series forecasting. Challenge of it lies\nin interpreting complex business contexts and the efficiency and generalisation\nof modelling. With aspirations of pre-trained foundational models for such\npurpose, given their remarkable success of large foundation model across\nlegions of tasks, we disseminate \\leforecast{}, an enterprise intelligence\nplatform tailored for time series tasks. It integrates advanced interpretations\nof time series data and multi-source information, and a three-pillar modelling\nengine combining a large foundation model (Le-TSFM), multimodal model and\nhybrid model to derive insights, predict or infer futures, and then drive\noptimisation across multiple sectors in enterprise operations. The framework is\ncomposed by a model pool, model profiling module, and two different fusion\napproaches regarding original model architectures. Experimental results verify\nthe efficiency of our trail fusion concepts: router-based fusion network and\ncoordination of large and small models, resulting in high costs for redundant\ndevelopment and maintenance of models. This work reviews deployment of\nLeForecast and its performance in three industrial use cases. Our comprehensive\nexperiments indicate that LeForecast is a profound and practical platform for\nefficient and competitive performance. And we do hope that this work can\nenlighten the research and grounding of time series techniques in accelerating\nenterprise.", "published": "2025-03-27 02:58:06", "link": "http://arxiv.org/abs/2503.22747v1", "categories": ["cs.LG", "cs.AI", "cs.ET"], "primary_category": "cs.LG"}
{"title": "Alleviating LLM-based Generative Retrieval Hallucination in Alipay Search", "abstract": "Generative retrieval (GR) has revolutionized document retrieval with the\nadvent of large language models (LLMs), and LLM-based GR is gradually being\nadopted by the industry. Despite its remarkable advantages and potential,\nLLM-based GR suffers from hallucination and generates documents that are\nirrelevant to the query in some instances, severely challenging its credibility\nin practical applications. We thereby propose an optimized GR framework\ndesigned to alleviate retrieval hallucination, which integrates knowledge\ndistillation reasoning in model training and incorporate decision agent to\nfurther improve retrieval precision. Specifically, we employ LLMs to assess and\nreason GR retrieved query-document (q-d) pairs, and then distill the reasoning\ndata as transferred knowledge to the GR model. Moreover, we utilize a decision\nagent as post-processing to extend the GR retrieved documents through retrieval\nmodel and select the most relevant ones from multi perspectives as the final\ngenerative retrieval result. Extensive offline experiments on real-world\ndatasets and online A/B tests on Fund Search and Insurance Search in Alipay\ndemonstrate our framework's superiority and effectiveness in improving search\nquality and conversion gains.", "published": "2025-03-27 02:36:48", "link": "http://arxiv.org/abs/2503.21098v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Confidence Adjusted Surprise Measure for Active Resourceful Trials (CA-SMART): A Data-driven Active Learning Framework for Accelerating Material Discovery under Resource Constraints", "abstract": "Accelerating the discovery and manufacturing of advanced materials with\nspecific properties is a critical yet formidable challenge due to vast search\nspace, high costs of experiments, and time-intensive nature of material\ncharacterization. In recent years, active learning, where a surrogate machine\nlearning (ML) model mimics the scientific discovery process of a human\nscientist, has emerged as a promising approach to address these challenges by\nguiding experimentation toward high-value outcomes with a limited budget. Among\nthe diverse active learning philosophies, the concept of surprise (capturing\nthe divergence between expected and observed outcomes) has demonstrated\nsignificant potential to drive experimental trials and refine predictive\nmodels. Scientific discovery often stems from surprise thereby making it a\nnatural driver to guide the search process. Despite its promise, prior studies\nleveraging surprise metrics such as Shannon and Bayesian surprise lack\nmechanisms to account for prior confidence, leading to excessive exploration of\nuncertain regions that may not yield useful information. To address this, we\npropose the Confidence-Adjusted Surprise Measure for Active Resourceful Trials\n(CA-SMART), a novel Bayesian active learning framework tailored for optimizing\ndata-driven experimentation. On a high level, CA-SMART incorporates\nConfidence-Adjusted Surprise (CAS) to dynamically balance exploration and\nexploitation by amplifying surprises in regions where the model is more certain\nwhile discounting them in highly uncertain areas. We evaluated CA-SMART on two\nbenchmark functions (Six-Hump Camelback and Griewank) and in predicting the\nfatigue strength of steel. The results demonstrate superior accuracy and\nefficiency compared to traditional surprise metrics, standard Bayesian\nOptimization (BO) acquisition functions and conventional ML methods.", "published": "2025-03-27 02:21:42", "link": "http://arxiv.org/abs/2503.21095v1", "categories": ["cs.LG", "cs.AI", "stat.AP"], "primary_category": "cs.LG"}
{"title": "A Multi-Modal Knowledge-Enhanced Framework for Vessel Trajectory Prediction", "abstract": "Accurate vessel trajectory prediction facilitates improved navigational\nsafety, routing, and environmental protection. However, existing prediction\nmethods are challenged by the irregular sampling time intervals of the vessel\ntracking data from the global AIS system and the complexity of vessel movement.\nThese aspects render model learning and generalization difficult. To address\nthese challenges and improve vessel trajectory prediction, we propose the\nmulti-modal knowledge-enhanced framework (MAKER) for vessel trajectory\nprediction. To contend better with the irregular sampling time intervals, MAKER\nfeatures a Large language model-guided Knowledge Transfer (LKT) module that\nleverages pre-trained language models to transfer trajectory-specific\ncontextual knowledge effectively. To enhance the ability to learn complex\ntrajectory patterns, MAKER incorporates a Knowledge-based Self-paced Learning\n(KSL) module. This module employs kinematic knowledge to progressively\nintegrate complex patterns during training, allowing for adaptive learning and\nenhanced generalization. Experimental results on two vessel trajectory datasets\nshow that MAKER can improve the prediction accuracy of state-of-the-art methods\nby 12.08%-17.86%.", "published": "2025-03-27 00:01:35", "link": "http://arxiv.org/abs/2503.21834v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The commutativity problem for effective varieties of formal series, and applications", "abstract": "A formal series in noncommuting variables $\\Sigma$ over the rationals is a\nmapping $\\Sigma^* \\to \\mathbb Q$. We say that a series is commutative if the\nvalue in the output does not depend on the order of the symbols in the input.\nThe commutativity problem for a class of series takes as input a (finite\npresentation of) a series from the class and amounts to establishing whether it\nis commutative. This is a very natural, albeit nontrivial problem, which has\nnot been considered before from an algorithmic perspective.\n  We show that commutativity is decidable for all classes of series that\nconstitute a so-called effective prevariety, a notion generalising Reutenauer's\nvarieties of formal series. For example, the class of rational series,\nintroduced by Sch\\\"utzenberger in the 1960's, is well-known to be an effective\n(pre)variety, and thus commutativity is decidable for it.\n  In order to showcase the applicability of our result, we consider classes of\nformal series generalising the rational ones. We consider polynomial automata,\nshuffle automata, and infiltration automata, and we show that each of these\nmodels recognises an effective prevariety of formal series. Consequently, their\ncommutativity problem is decidable, which is a novel result. We find it\nremarkable that commutativity can be decided in a uniform way for such\ndisparate computation models.\n  Finally, we present applications of commutativity outside the theory of\nformal series. We show that we can decide solvability in sequences and in power\nseries for restricted classes of algebraic difference and differential\nequations, for which such problems are undecidable in full generality. Thanks\nto this, we can prove that the syntaxes of multivariate polynomial recursive\nsequences and of constructible differentially algebraic power series are\neffective, which are new results which were left open in previous work.", "published": "2025-03-27 17:01:19", "link": "http://arxiv.org/abs/2503.21697v1", "categories": ["cs.FL", "cs.DM", "cs.LO"], "primary_category": "cs.FL"}
{"title": "The Avoider-Enforcer game on hypergraphs of rank 3", "abstract": "In the Avoider-Enforcer convention of positional games, two players, Avoider\nand Enforcer, take turns selecting vertices from a hypergraph H. Enforcer wins\nif, by the time all vertices of H have been selected, Avoider has completely\nfilled an edge of H with her vertices; otherwise, Avoider wins. In this paper,\nwe first give some general results, in particular regarding the outcome of the\ngame and disjoint unions of hypergraphs. We then determine which player has a\nwinning strategy for all hypergraphs of rank 2, and for linear hypergraphs of\nrank 3 when Avoider plays the last move. The structural characterisations we\nobtain yield polynomial-time algorithms.", "published": "2025-03-27 16:40:37", "link": "http://arxiv.org/abs/2503.21672v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "On the Maiorana-McFarland Class Extensions", "abstract": "The closure $\\mathcal{M}_{m}^{\\#}$ and the extension\n$\\widehat{\\mathcal{M}}_{m}$ of the Maiorana--McFarland class $\\mathcal{M}_{m}$\nin $m = 2n$ variables relative to the extended-affine equivalence and the bent\nfunction construction $f \\oplus \\mathrm{Ind}_{U}$ are considered, where $U$ is\nan affine subspace of $\\mathbb{F}_{2}^{m}$ of dimension $m/2$. We obtain an\nexplicit formula for $|\\widehat{\\mathcal{M}}_{m}|$ and an upper bound for\n$|\\widehat{\\mathcal{M}}_{m}^{\\#}|$. Asymptotically tight bounds for\n$|\\mathcal{M}_{m}^{\\#}|$ are proved as well, for instance,\n$|\\mathcal{M}_{8}^{\\#}| \\approx 2^{77.865}$. Metric properties of\n$\\mathcal{M}_{m}$ and $\\mathcal{M}_{m}^{\\#}$ are also investigated. We find the\nnumber of all closest bent functions to the set $\\mathcal{M}_{m}$ and provide\nan upper bound of the same number for $\\mathcal{M}_{m}^{\\#}$. The average\nnumber $E(\\mathcal{M}_{m})$ of $m/2$-dimensional affine subspaces of\n$\\mathbb{F}_{2}^{m}$ such that a function from $\\mathcal{M}_{m}$ is affine on\neach of them is calculated. We obtain that similarly defined\n$E(\\mathcal{M}_{m}^{\\#})$ satisfies $E(\\mathcal{M}_{m}^{\\#}) <\nE(\\mathcal{M}_{m})$ and $E(\\mathcal{M}_{m}^{\\#}) = E(\\mathcal{M}_{m}) - o(1)$.", "published": "2025-03-27 12:34:05", "link": "http://arxiv.org/abs/2503.21440v1", "categories": ["cs.CR", "cs.DM", "math.CO", "06E30, 94A60"], "primary_category": "cs.CR"}
{"title": "Efficient Algorithms for Minimizing the Kirchhoff Index via Adding Edges", "abstract": "The Kirchhoff index, which is the sum of the resistance distance between\nevery pair of nodes in a network, is a key metric for gauging network\nperformance, where lower values signify enhanced performance. In this paper, we\nstudy the problem of minimizing the Kirchhoff index by adding edges. We first\nprovide a greedy algorithm for solving this problem and give an analysis of its\nquality based on the bounds of the submodularity ratio and the curvature. Then,\nwe introduce a gradient-based greedy algorithm as a new paradigm to solve this\nproblem. To accelerate the computation cost, we leverage geometric properties,\nconvex hull approximation, and approximation of the projected coordinate of\neach point. To further improve this algorithm, we use pre-pruning and fast\nupdate techniques, making it particularly suitable for large networks. Our\nproposed algorithms have nearly-linear time complexity. We provide extensive\nexperiments on ten real networks to evaluate the quality of our algorithms. The\nresults demonstrate that our proposed algorithms outperform the\nstate-of-the-art methods in terms of efficiency and effectiveness. Moreover,\nour algorithms are scalable to large graphs with over 5 million nodes and 12\nmillion edges.", "published": "2025-03-27 11:52:24", "link": "http://arxiv.org/abs/2503.21409v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "On Supports for graphs of bounded genus", "abstract": "Let $(X,\\mathcal{E})$ be a hypergraph. A support is a graph $Q$ on $X$ such\nthat for each $E\\in\\mathcal{E}$, the subgraph of $Q$ induced on the elements in\n$E$ is connected. We consider the problem of constructing a support for\nhypergraphs defined by connected subgraphs of a host graph. For a graph\n$G=(V,E)$, let $\\mathcal{H}$ be a set of connected subgraphs of $G$. Let the\nvertices of $G$ be partitioned into two sets the \\emph{terminals}\n$\\mathbf{b}(V)$ and the \\emph{non-terminals} $\\mathbf{r}(V)$. We define a\nhypergraph on $\\mathbf{b}(V)$, where each $H\\in\\mathcal{H}$ defines a hyperedge\nconsisting of the vertices of $\\mathbf{b}(V)$ in $H$.\n  We also consider the problem of constructing a support for the \\emph{dual\nhypergraph} - a hypergraph on $\\mathcal{H}$ where each $v\\in \\mathbf{b}(V)$\ndefines a hyperedge consisting of the subgraphs in $\\mathcal{H}$ containing\n$v$. In fact, we construct supports for a common generalization of the primal\nand dual settings called the \\emph{intersection hypergraph}.\n  As our main result, we show that if the host graph $G$ has bounded genus and\nthe subgraphs in $\\mathcal{H}$ satisfy a condition of being \\emph{cross-free},\nthen there exists a support that also has bounded genus. Our results are a\ngeneralization of the results of Raman and Ray (Rajiv Raman, Saurabh Ray:\nConstructing Planar Support for Non-Piercing Regions. Discret. Comput. Geom.\n64(3): 1098-1122 (2020)).\n  Our techniques imply a unified analysis for packing and covering problems for\nhypergraphs defined on surfaces of bounded genus. We also describe applications\nof our results for hypergraph colorings.", "published": "2025-03-27 09:11:24", "link": "http://arxiv.org/abs/2503.21287v1", "categories": ["math.CO", "cs.DM", "05C65, 05C10"], "primary_category": "math.CO"}
{"title": "HyperMAN: Hypergraph-enhanced Meta-learning Adaptive Network for Next POI Recommendation", "abstract": "Next Point-of-Interest (POI) recommendation aims to predict users' next\nlocations by leveraging historical check-in sequences. Although existing\nmethods have shown promising results, they often struggle to capture complex\nhigh-order relationships and effectively adapt to diverse user behaviors,\nparticularly when addressing the cold-start issue. To address these challenges,\nwe propose Hypergraph-enhanced Meta-learning Adaptive Network (HyperMAN), a\nnovel framework that integrates heterogeneous hypergraph modeling with a\ndifficulty-aware meta-learning mechanism for next POI recommendation.\nSpecifically, three types of heterogeneous hyperedges are designed to capture\nhigh-order relationships: user visit behaviors at specific times (Temporal\nbehavioral hyperedge), spatial correlations among POIs (spatial functional\nhyperedge), and user long-term preferences (user preference hyperedge).\nFurthermore, a diversity-aware meta-learning mechanism is introduced to\ndynamically adjust learning strategies, considering users behavioral diversity.\nExtensive experiments on real-world datasets demonstrate that HyperMAN achieves\nsuperior performance, effectively addressing cold start challenges and\nsignificantly enhancing recommendation accuracy.", "published": "2025-03-27 23:58:57", "link": "http://arxiv.org/abs/2503.22049v1", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Empowering Retrieval-based Conversational Recommendation with Contrasting User Preferences", "abstract": "Conversational recommender systems (CRSs) are designed to suggest the target\nitem that the user is likely to prefer through multi-turn conversations. Recent\nstudies stress that capturing sentiments in user conversations improves\nrecommendation accuracy. However, they employ a single user representation,\nwhich may fail to distinguish between contrasting user intentions, such as\nlikes and dislikes, potentially leading to suboptimal performance. To this end,\nwe propose a novel conversational recommender model, called COntrasting user\npReference expAnsion and Learning (CORAL). Firstly, CORAL extracts the user's\nhidden preferences through contrasting preference expansion using the reasoning\ncapacity of the LLMs. Based on the potential preference, CORAL explicitly\ndifferentiates the contrasting preferences and leverages them into the\nrecommendation process via preference-aware learning. Extensive experiments\nshow that CORAL significantly outperforms existing methods in three benchmark\ndatasets, improving up to 99.72% in Recall@10. The code and datasets are\navailable at https://github.com/kookeej/CORAL", "published": "2025-03-27 21:45:49", "link": "http://arxiv.org/abs/2503.22005v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CombiGCN: An effective GCN model for Recommender System", "abstract": "Graph Neural Networks (GNNs) have opened up a potential line of research for\ncollaborative filtering (CF). The key power of GNNs is based on injecting\ncollaborative signal into user and item embeddings which will contain\ninformation about user-item interactions after that. However, there are still\nsome unsatisfactory points for a CF model that GNNs could have done better. The\nway in which the collaborative signal are extracted through an implicit\nfeedback matrix that is essentially built on top of the message-passing\narchitecture of GNNs, and it only helps to update the embedding based on the\nvalue of the items (or users) embeddings neighboring. By identifying the\nsimilarity weight of users through their interaction history, a key concept of\nCF, we endeavor to build a user-user weighted connection graph based on their\nsimilarity weight.\n  In this study, we propose a recommendation framework, CombiGCN, in which item\nembeddings are only linearly propagated on the user-item interaction graph,\nwhile user embeddings are propagated simultaneously on both the user-user\nweighted connection graph and user-item interaction graph graphs with Light\nGraph Convolution (LGC) and combined in a simpler method by using the weighted\nsum of the embeddings for each layer. We also conducted experiments comparing\nCombiGCN with several state-of-the-art models on three real-world datasets.", "published": "2025-03-27 13:03:27", "link": "http://arxiv.org/abs/2503.21471v1", "categories": ["cs.IR", "H.m"], "primary_category": "cs.IR"}
{"title": "Improvement Graph Convolution Collaborative Filtering with Weighted addition input", "abstract": "Graph Neural Networks have been extensively applied in the field of machine\nlearning to find features of graphs, and recommendation systems are no\nexception. The ratings of users on considered items can be represented by\ngraphs which are input for many efficient models to find out the\ncharacteristics of the users and the items. From these insights, relevant items\nare recommended to users. However, user's decisions on the items have varying\ndegrees of effects on different users, and this information should be learned\nso as not to be lost in the process of information mining.\n  In this publication, we propose to build an additional graph showing the\nrecommended weight of an item to a target user to improve the accuracy of GNN\nmodels. Although the users' friendships were not recorded, their correlation\nwas still evident through the commonalities in consumption behavior. We build a\nmodel WiGCN (Weighted input GCN) to describe and experiment on well-known\ndatasets. Conclusions will be stated after comparing our results with\nstate-of-the-art such as GCMC, NGCF and LightGCN. The source code is also\nincluded at https://github.com/trantin84/WiGCN.", "published": "2025-03-27 12:57:33", "link": "http://arxiv.org/abs/2503.21468v1", "categories": ["cs.IR", "H.m"], "primary_category": "cs.IR"}
{"title": "Are We Solving a Well-Defined Problem? A Task-Centric Perspective on Recommendation Tasks", "abstract": "Recommender systems (RecSys) leverage user interaction history to predict and\nsuggest relevant items, shaping user experiences across various domains. While\nmany studies adopt a general problem definition, i.e., to recommend preferred\nitems to users based on past interactions, such abstraction often lacks the\ndomain-specific nuances necessary for practical deployment. However, models are\nfrequently evaluated using datasets from online recommender platforms, which\ninherently reflect these specificities. In this paper, we analyze RecSys task\nformulations, emphasizing key components such as input-output structures,\ntemporal dynamics, and candidate item selection. All these factors directly\nimpact offline evaluation. We further examine the complexities of user-item\ninteractions, including decision-making costs, multi-step engagements, and\nunobservable interactions, which may influence model design and loss functions.\nAdditionally, we explore the balance between task specificity and model\ngeneralizability, highlighting how well-defined task formulations serve as the\nfoundation for robust evaluation and effective solution development. By\nclarifying task definitions and their implications, this work provides a\nstructured perspective on RecSys research. The goal is to help researchers\nbetter navigate the field, particularly in understanding specificities of the\nRecSys tasks and ensuring fair and meaningful evaluations.", "published": "2025-03-27 06:10:22", "link": "http://arxiv.org/abs/2503.21188v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Network Density Analysis of Health Seeking Behavior in Metro Manila: A Retrospective Analysis on COVID-19 Google Trends Data", "abstract": "This study examined the temporal aspect of COVID-19-related health-seeking\nbehavior in Metro Manila, National Capital Region, Philippines through a\nnetwork density analysis of Google Trends data. A total of 15 keywords across\nfive categories (English symptoms, Filipino symptoms, face wearing, quarantine,\nand new normal) were examined using both 15-day and 30-day rolling windows from\nMarch 2020 to March 2021. The methodology involved constructing network graphs\nusing distance correlation coefficients at varying thresholds (0.4, 0.5, 0.6,\nand 0.8) and analyzing the time-series data of network density and clustering\ncoefficients. Results revealed three key findings: (1) an inverse relationship\nbetween the threshold values and network metrics, indicating that higher\nthresholds provide more meaningful keyword relationships; (2) exceptionally\nhigh network connectivity during the initial pandemic months followed by\ngradual decline; and (3) distinct patterns in keyword relationships,\ntransitioning from policy-focused searches to more symptom-specific queries as\nthe pandemic temporally progressed. The 30-day window analysis showed more\nstable, but less search activities compared to the 15-day windows, suggesting\nstronger correlations in immediate search behaviors. These insights are helpful\nfor health communication because it emphasizes the need of a strategic and\nconscientious information dissemination from the government or the private\nsector based on the networked search behavior (e.g. prioritizing to inform\nselect symptoms rather than an overview of what the coronavirus is).", "published": "2025-03-27 05:11:57", "link": "http://arxiv.org/abs/2503.21162v2", "categories": ["cs.CY", "cs.IR", "I.6.3; J.3"], "primary_category": "cs.CY"}
{"title": "FAIR-QR: Enhancing Fairness-aware Information Retrieval through Query Refinement", "abstract": "Information retrieval systems such as open web search and recommendation\nsystems are ubiquitous and significantly impact how people receive and consume\nonline information. Previous research has shown the importance of fairness in\ninformation retrieval systems to combat the issue of echo chambers and mitigate\nthe rich-get-richer effect. Therefore, various fairness-aware information\nretrieval methods have been proposed. Score-based fairness-aware information\nretrieval algorithms, focusing on statistical parity, are interpretable but\ncould be mathematically infeasible and lack generalizability. In contrast,\nlearning-to-rank-based fairness-aware information retrieval algorithms using\nfairness-aware loss functions demonstrate strong performance but lack\ninterpretability. In this study, we proposed a novel and interpretable\nframework that recursively refines query keywords to retrieve documents from\nunderrepresented groups and achieve group fairness. Retrieved documents using\nrefined queries will be re-ranked to ensure relevance. Our method not only\nshows promising retrieval results regarding relevance and fairness but also\npreserves interpretability by showing refined keywords used at each iteration.", "published": "2025-03-27 02:10:19", "link": "http://arxiv.org/abs/2503.21092v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Information Theoretic One-Time Programs from Geometrically Local $\\text{QNC}_0$ Adversaries", "abstract": "We show how to construct simulation secure one-time memories, and thus\none-time programs, without computational assumptions in the presence of\nconstraints on quantum hardware. Specifically, we build one-time memories from\nrandom linear codes and quantum random access codes (QRACs) when constrained to\nnon-adaptive, constant depth, and $D$-dimensional geometrically-local quantum\ncircuit for some constant $D$. We place no restrictions on the adversary's\nclassical computational power, number of qubits it can use, or the coherence\ntime of its qubits. Notably, our construction can still be secure even in the\npresence of fault tolerant quantum computation as long as the input qubits are\nencoded in a non-fault tolerant manner (e.g. encoded as high energy states in\nnon-ideal hardware). Unfortunately though, our construction requires decoding\nrandom linear codes and thus does not run in polynomial time. We leave open the\nquestion of whether one can construct a polynomial time information\ntheoretically secure one-time memory from geometrically local quantum circuits.\n  Of potentially independent interest, we develop a progress bound for\ninformation leakage via collision entropy (Renyi entropy of order $2$) along\nwith a few key technical lemmas for a \"mutual information\" for collision\nentropies. We also develop new bounds on how much information a specific $2\n\\mapsto 1$ QRAC can leak about its input, which may be of independent interest\nas well.", "published": "2025-03-27 22:10:42", "link": "http://arxiv.org/abs/2503.22016v2", "categories": ["quant-ph", "cs.CR", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "DeCompress: Denoising via Neural Compression", "abstract": "Learning-based denoising algorithms achieve state-of-the-art performance\nacross various denoising tasks. However, training such models relies on access\nto large training datasets consisting of clean and noisy image pairs. On the\nother hand, in many imaging applications, such as microscopy, collecting ground\ntruth images is often infeasible. To address this challenge, researchers have\nrecently developed algorithms that can be trained without requiring access to\nground truth data. However, training such models remains computationally\nchallenging and still requires access to large noisy training samples. In this\nwork, inspired by compression-based denoising and recent advances in neural\ncompression, we propose a new compression-based denoising algorithm, which we\nname DeCompress, that i) does not require access to ground truth images, ii)\ndoes not require access to large training dataset - only a single noisy image\nis sufficient, iii) is robust to overfitting, and iv) achieves superior\nperformance compared with zero-shot or unsupervised learning-based denoisers.", "published": "2025-03-27 22:05:30", "link": "http://arxiv.org/abs/2503.22015v1", "categories": ["eess.IV", "cs.CV", "cs.IT", "math.IT"], "primary_category": "eess.IV"}
{"title": "Quantum umlaut information", "abstract": "We study the quantum umlaut information, a correlation measure defined for\nbipartite quantum states $\\rho_{AB}$ as a reversed variant of the quantum\nmutual information: $U(A;B)_\\rho = \\min_{\\sigma_B} D(\\rho_A\\otimes\n\\sigma_B\\|\\rho_{AB})$ in terms of the quantum relative entropy $D$. As in the\nclassical case [Girardi et al., arXiv:2503.18910], this definition allows for a\nclosed-form expression and has an operational interpretation as the asymptotic\nerror exponent in the hypothesis testing task of deciding whether a given\nbipartite state is product or not. We generalise the umlaut information to\nquantum channels, where it also extends the notion of `oveloh information'\n[Nuradha et al., arXiv:2404.16101]. We prove that channel umlaut information is\nadditive for classical-quantum channels, while we observe additivity violations\nfor fully quantum channels. Inspired by recent results in entanglement theory,\nwe then show as our main result that the regularised umlaut information\nconstitutes a fundamental measure of the quality of classical information\ntransmission over a quantum channel -- as opposed to the capacity, which\nquantifies the quantity of information that can be sent. This interpretation\napplies to coding assisted by activated non-signalling correlations, and the\nchannel umlaut information is in general larger than the corresponding\nexpression for unassisted communication as obtained by Dalai for the\nclassical-quantum case [IEEE Trans. Inf. Theory 59, 8027 (2013)]. Combined with\nprior works on non-signalling--assisted zero-error channel capacities, our\nfindings imply a dichotomy between the settings of zero-rate error exponents\nand zero-error communication. While our results are single-letter only for\nclassical-quantum channels, we also give a single-letter bound for fully\nquantum channels in terms of the `geometric' version of umlaut information.", "published": "2025-03-27 13:11:49", "link": "http://arxiv.org/abs/2503.21479v1", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Robust DNN Partitioning and Resource Allocation Under Uncertain Inference Time", "abstract": "In edge intelligence systems, deep neural network (DNN) partitioning and data\noffloading can provide real-time task inference for resource-constrained mobile\ndevices. However, the inference time of DNNs is typically uncertain and cannot\nbe precisely determined in advance, presenting significant challenges in\nensuring timely task processing within deadlines. To address the uncertain\ninference time, we propose a robust optimization scheme to minimize the total\nenergy consumption of mobile devices while meeting task probabilistic\ndeadlines. The scheme only requires the mean and variance information of the\ninference time, without any prediction methods or distribution functions. The\nproblem is formulated as a mixed-integer nonlinear programming (MINLP) that\ninvolves jointly optimizing the DNN model partitioning and the allocation of\nlocal CPU/GPU frequencies and uplink bandwidth. To tackle the problem, we first\ndecompose the original problem into two subproblems: resource allocation and\nDNN model partitioning. Subsequently, the two subproblems with probability\nconstraints are equivalently transformed into deterministic optimization\nproblems using the chance-constrained programming (CCP) method. Finally, the\nconvex optimization technique and the penalty convex-concave procedure (PCCP)\ntechnique are employed to obtain the optimal solution of the resource\nallocation subproblem and a stationary point of the DNN model partitioning\nsubproblem, respectively. The proposed algorithm leverages real-world data from\npopular hardware platforms and is evaluated on widely used DNN models.\nExtensive simulations show that our proposed algorithm effectively addresses\nthe inference time uncertainty with probabilistic deadline guarantees while\nminimizing the energy consumption of mobile devices.", "published": "2025-03-27 13:06:26", "link": "http://arxiv.org/abs/2503.21476v1", "categories": ["cs.DC", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.DC"}
{"title": "Age of Information in Short Packet Multi-Connectivity Links", "abstract": "In this paper, we investigate multi-connectivity (MC) schemes in the context\nof status update systems with short payloads. As a performance metric, we use\nthe age of information (AoI). Due to short payloads, transmission errors must\nbe taken into account. In addition to the well-known schemes of packet\nduplication, message splitting, and multiplexing, we propose a codeword\nsplitting scheme, where each status update is jointly encoded across multiple\nchannels. We derive closed-form expressions of the average AoI for the\ndifferent schemes and optimize their corresponding parameters, such as\nblocklengths, message splits, and the cyclic schedule for the multiplexing\nscheme. Analytical comparisons and numerical evaluations show that the codeword\nsplitting scheme achieves the lowest average AoI when joint encoding and\ndecoding are possible. In scenarios where joint encoding is not feasible,\nwhether message splitting or multiplexing results in a lower average AoI\ndepends on the specific parameters.", "published": "2025-03-27 11:50:46", "link": "http://arxiv.org/abs/2503.21407v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Distributed Nonlinear Transform Source-Channel Coding for Wireless Correlated Image Transmission", "abstract": "This paper investigates distributed joint source-channel coding (JSCC) for\ncorrelated image semantic transmission over wireless channels. In this setup,\ncorrelated images at different transmitters are separately encoded and\ntransmitted through dedicated channels for joint recovery at the receiver. We\npropose a novel distributed nonlinear transform source-channel coding (D-NTSCC)\nframework. Unlike existing learning-based approaches that implicitly learn\nsource correlation in a purely data-driven manner, our method explicitly models\nthe source correlation through joint distribution. Specifically, the correlated\nimages are separately encoded into latent representations via an encoding\ntransform function, followed by a JSCC encoder to produce channel input\nsymbols. A learned joint entropy model is introduced to determine the\ntransmission rates, which more accurately approximates the joint distribution\nof the latent representations and captures source dependencies, thereby\nimproving rate-distortion performance. At the receiver, a JSCC decoder and a\ndecoding transform function reconstruct the images from the received signals,\neach serving as side information for recovering the other image. Therein, a\ntransformation module is designed to align the latent representations for\nmaximal correlation learning. Furthermore, a loss function is derived to\njointly optimize encoding, decoding, and the joint entropy model, ensuring that\nthe learned joint entropy model approximates the true joint distribution.\nExperiments on multi-view datasets show that D-NTSCC outperforms\nstate-of-the-art distributed schemes, demonstrating its effectiveness in\nexploiting source correlation.", "published": "2025-03-27 08:09:55", "link": "http://arxiv.org/abs/2503.21249v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Utility of Quantum Entanglement for Joint Communication and Instantaneous Detection", "abstract": "Entanglement is known to significantly improve the performance (separately)\nof communication and detection schemes that utilize quantum resources. This\nwork explores the simultaneous utility of quantum entanglement for (joint)\ncommunication and detection schemes, over channels that are convex combinations\nof identity, depolarization and erasure operators, both with perfect and\nimperfect entanglement assistance. The channel state is binary, rapidly\ntime-varying and unknown to the transmitter. While the communication is\ndelay-tolerant, allowing the use of arbitrarily long codewords to ensure\nreliable decoding, the channel state detection is required to be instantaneous.\nThe detector is neither co-located with the transmitter, nor able to wait for\nthe decoding in order to learn the transmitted waveform. The results of this\nwork appear in the form of communication-rate vs instantaneous-detection-error\ntradeoffs, with and without quantum entanglement. Despite the challenges that\nplace the two tasks at odds with each other, the results indicate that quantum\nentanglement can indeed be simultaneously and significantly beneficial for\njoint communication and instantaneous detection.", "published": "2025-03-27 03:51:59", "link": "http://arxiv.org/abs/2503.21134v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "DBRAA: Sub-6 GHz and Millimeter Wave Dual-Band Reconfigurable Antenna Array for ISAC", "abstract": "This paper proposes a dual-band reconfigurable antenna array (DBRAA),\nenabling wireless capabilities in both sub-6 GHz (sub-6G) and millimeter wave\n(mmWave) bands using a single array. For the sub-6G band, we propose a\nreconfigurable antenna selection structure, where each sub-6G antenna is formed\nby multiplexing several mmWave antennas, with its position dynamically adjusted\nusing PIN diodes. For the mmWave band, we develop a reconfigurable hybrid\nbeamforming structure that connects radio frequency chains to the antennas via\nphase shifters and a reconfigurable switch network. We then investigate\nintegrated sensing and communications (ISAC) in sub-6G and mmWave bands using\nthe proposed DBRAA and formulate a dual-band ISAC beamforming design problem.\nThis problem aims at maximizing the mmWave communication sum-rate subject to\nthe constraints of sub-6G communication quality of service and sensing\nbeamforming gain requirements. The dual-band ISAC beamforming design is\ndecoupled into sub-6G beamforming design and mmWave beamforming design. For the\nsub-6G beamforming design, we develop a fast search-based joint beamforming and\nantenna selection algorithm. For the mmWave beamforming design, we develop an\nalternating direction method of multipliers-based reconfigurable hybrid\nbeamforming algorithm. Simulation results demonstrate the effectiveness of the\nproposed methods.", "published": "2025-03-27 00:22:41", "link": "http://arxiv.org/abs/2503.21062v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Monitoring Spatially Distributed Cyber-Physical Systems with Alternating Finite Automata", "abstract": "Modern cyber-physical systems (CPS) can consist of various networked\ncomponents and agents interacting and communicating with each other. In the\ncontext of spatially distributed CPS, these connections can be dynamically\ndependent on the spatial configuration of the various components and agents. In\nthese settings, robust monitoring of the distributed components is vital to\nensuring complex behaviors are achieved, and safety properties are maintained.\nTo this end, we look at defining the automaton semantics for the\nSpatio-Temporal Reach and Escape Logic (STREL), a formal logic designed to\nexpress and monitor spatio-temporal requirements over mobile, spatially\ndistributed CPS. Specifically, STREL reasons about spatio-temporal behavior\nover dynamic weighted graphs. While STREL is endowed with well defined\nqualitative and quantitative semantics, in this paper, we propose a novel\nconstruction of (weighted) alternating finite automata from STREL\nspecifications that efficiently encodes these semantics. Moreover, we\ndemonstrate how this automaton semantics can be used to perform both, offline\nand online monitoring for STREL specifications using a simulated drone swarm\nenvironment.", "published": "2025-03-27 18:35:44", "link": "http://arxiv.org/abs/2503.21906v1", "categories": ["cs.LO", "cs.FL", "cs.MA"], "primary_category": "cs.LO"}
{"title": "Energy Minimization for Participatory Federated Learning in IoT Analyzed via Game Theory", "abstract": "The Internet of Things requires intelligent decision making in many\nscenarios. To this end, resources available at the individual nodes for sensing\nor computing, or both, can be leveraged. This results in approaches known as\nparticipatory sensing and federated learning, respectively. We investigate the\nsimultaneous implementation of both, through a distributed approach based on\nempowering local nodes with game theoretic decision making. A global objective\nof energy minimization is combined with the individual node's optimization of\nlocal expenditure for sensing and transmitting data over multiple learning\nrounds. We present extensive evaluations of this technique, based on both a\ntheoretical framework and experiments in a simulated network scenario with real\ndata. Such a distributed approach can reach a desired level of accuracy for\nfederated learning without a centralized supervision of the data collector.\nHowever, depending on the weight attributed to the local costs of the single\nnode, it may also result in a significantly high Price of Anarchy (from 1.28\nonwards). Thus, we argue for the need of incentive mechanisms, possibly based\non Age of Information of the single nodes.", "published": "2025-03-27 17:35:38", "link": "http://arxiv.org/abs/2503.21722v1", "categories": ["cs.LG", "cs.GT", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Static and Repeated Cooperative Games for the Optimization of the AoI in IoT Networks", "abstract": "Wireless sensing and the internet of things (IoT) are nowadays pervasive in\n5G and beyond networks, and they are expected to play a crucial role in 6G.\nHowever, a centralized optimization of a distributed system is not always\npossible and cost-efficient. In this paper, we analyze a setting in which two\nsensors collaboratively update a common server seeking to minimize the age of\ninformation (AoI) of the latest sample of a common physical process. We\nconsider a distributed and uncoordinated setting where each sensor lacks\ninformation about whether the other decides to update the server. This\nstrategic setting is modeled through game theory (GT) and two games are\ndefined: i) a static game of complete information with an incentive mechanism\nfor cooperation, and ii) a repeated game over a finite horizon where the static\ngame is played at each stage. We perform a mathematical analysis of the static\ngame finding three Nash Equilibria (NEs) in pure strategies and one in mixed\nstrategies. A numerical simulation of the repeated game is also presented and\nnovel and valuable insight into the setting is given thanks to the definition\nof a new metric, the price of delayed updates (PoDU), which shows that the\ndecentralized solution provides results close to the centralized optimum.", "published": "2025-03-27 15:55:52", "link": "http://arxiv.org/abs/2503.21633v1", "categories": ["cs.NI", "cs.GT", "cs.MA"], "primary_category": "cs.NI"}
{"title": "Formation Shape Control using the Gromov-Wasserstein Metric", "abstract": "This article introduces a formation shape control algorithm, in the optimal\ncontrol framework, for steering an initial population of agents to a desired\nconfiguration via employing the Gromov-Wasserstein distance. The underlying\ndynamical system is assumed to be a constrained linear system and the objective\nfunction is a sum of quadratic control-dependent stage cost and a\nGromov-Wasserstein terminal cost. The inclusion of the Gromov-Wasserstein cost\ntransforms the resulting optimal control problem into a well-known NP-hard\nproblem, making it both numerically demanding and difficult to solve with high\naccuracy. Towards that end, we employ a recent semi-definite relaxation-driven\ntechnique to tackle the Gromov-Wasserstein distance. A numerical example is\nprovided to illustrate our results.", "published": "2025-03-27 14:29:31", "link": "http://arxiv.org/abs/2503.21538v1", "categories": ["math.OC", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "Safe Human Robot Navigation in Warehouse Scenario", "abstract": "The integration of autonomous mobile robots (AMRs) in industrial\nenvironments, particularly warehouses, has revolutionized logistics and\noperational efficiency. However, ensuring the safety of human workers in\ndynamic, shared spaces remains a critical challenge. This work proposes a novel\nmethodology that leverages control barrier functions (CBFs) to enhance safety\nin warehouse navigation. By integrating learning-based CBFs with the Open\nRobotics Middleware Framework (OpenRMF), the system achieves adaptive and\nsafety-enhanced controls in multi-robot, multi-agent scenarios. Experiments\nconducted using various robot platforms demonstrate the efficacy of the\nproposed approach in avoiding static and dynamic obstacles, including human\npedestrians. Our experiments evaluate different scenarios in which the number\nof robots, robot platforms, speed, and number of obstacles are varied, from\nwhich we achieve promising performance.", "published": "2025-03-27 04:12:27", "link": "http://arxiv.org/abs/2503.21141v1", "categories": ["cs.RO", "cs.LG", "cs.MA"], "primary_category": "cs.RO"}
{"title": "High order integration of stochastic dynamics on Riemannian manifolds with frozen flow methods", "abstract": "We present a new class of numerical methods for solving stochastic\ndifferential equations with additive noise on general Riemannian manifolds with\nhigh weak order of accuracy. In opposition to the popular approach with\nprojection methods, the proposed methods are intrinsic: they only rely on\ngeometric operations and avoid coordinates and embeddings. We provide a robust\nand general convergence analysis and an algebraic formalism of exotic planar\nButcher series for the computation of order conditions at any high order. To\nillustrate the methodology, an explicit method of second weak order is\nintroduced, and several numerical experiments confirm the theoretical findings\nand extend the approach for the sampling of the invariant measure of Riemannian\nLangevin dynamics.", "published": "2025-03-27 17:20:10", "link": "http://arxiv.org/abs/2503.21855v1", "categories": ["math.NA", "cs.NA", "math.CO", "math.PR", "16T05, 41A58, 60H35, 37M25, 65L06, 70H45"], "primary_category": "math.NA"}
{"title": "Strong convergence and stability of stochastic theta method for time-changed stochastic differential equations with local Lipschitz coefficients", "abstract": "In this paper, the stochastic theta (ST) method is investigated for a class\nof stochastic differential equations driven by a time-changed Brownian motion,\nwhose coefficients are time-space-dependent and satisfy the local Lipschitz\ncondition. It is proved that under the local Lipschitz and some additional\nassumptions, the ST method with $\\theta\\in[1/2,1]$ is strongly convergent. It\nis also obtained that, for all positive stepsizes, the ST method with\n$\\theta\\in[1/2,1]$ is asymptotically mean square stable under a coercivity\ncondition. With some restrictions on the stepsize, the ST method with\n$\\theta\\in[0,1/2)$ is asymptotically mean square stable under a stronger\nassumption. Some numerical simulations are presented to illustrate the\ntheoretical results.", "published": "2025-03-27 16:17:14", "link": "http://arxiv.org/abs/2503.21653v1", "categories": ["math.PR", "cs.NA", "math.NA", "65C30, 60H10"], "primary_category": "math.PR"}
{"title": "Inverse Lax-Wendroff boundary treatment for solving conservation laws with finite difference HWENO methods", "abstract": "This paper presents a novel inverse Lax-Wendroff (ILW) boundary treatment for\nfinite difference Hermite weighted essentially non-oscillatory (HWENO) schemes\nto solve hyperbolic conservation laws on arbitrary geometries. The complex\ngeometric domain is divided by a uniform Cartesian grid, resulting in challenge\nin boundary treatment. The proposed ILW boundary treatment could provide high\norder approximations of both solution values and spatial derivatives at ghost\npoints outside the computational domain. Distinct from existing ILW approaches,\nour boundary treatment constructs the extrapolation via optimized through a\nleast squares formulation, coupled with the spatial derivatives at the boundary\nobtained via the ILW procedure. Theoretical analysis indicates that compared\nwith other ILW methods, our proposed one would require fewer terms by using the\nrelatively complicated ILW procedure and thus improve computational efficiency\nwhile preserving accuracy and stability. The effectiveness and robustness of\nthe method are validated through numerical experiments.", "published": "2025-03-27 15:44:58", "link": "http://arxiv.org/abs/2503.21626v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A shifted Laplace rational filter for large-scale eigenvalue problems", "abstract": "We present a rational filter for computing all eigenvalues of a symmetric\ndefinite eigenvalue problem lying in an interval on the real axis. The linear\nsystems arising from the filter embedded in the subspace iteration framework,\nare solved via a preconditioned Krylov method.\n  The choice of the poles of the filter is based on two criteria. On the one\nhand, the filter should enhance the eigenvalues in the interval of interest,\nwhich suggests that the poles should be chosen close to or in the interval. On\nthe other hand, the choice of poles has an important impact on the convergence\nspeed of the iterative method. For the solution of problems arising from\nvibrations, the two criteria contradict each other, since fast convergence of\nthe eigensolver requires poles to be in or close to the interval, whereas the\niterative linear system solver becomes cheaper when the poles lie further away\nfrom the eigenvalues. In the paper, we propose a selection of poles inspired by\nthe shifted Laplace preconditioner for the Helmholtz equation.\n  We show numerical experiments from finite element models of vibrations. We\ncompare the shifted Laplace rational filter with rational filters based on\nquadrature rules for contour integration.", "published": "2025-03-27 15:38:05", "link": "http://arxiv.org/abs/2503.21618v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical solution of locally loaded Volterra integral equations", "abstract": "Volterra's integral equations with local and nonlocal loads represent the\nnovel class of integral equations that have attracted considerable attention in\nrecent years. These equations are a generalisation of the classic Volterra\nintegral equations, which were first introduced by Vito Volterra in the late\n19th century. The loaded Volterra integral equations are characterised by the\npresence of a load which complicates the process of their theoretical and\nnumerical study. Sometimes these equation are called the equations with\n``frozen'' argument. The present work is devoted to the study of Volterra\nequations with locally loaded integral operators. The existence and uniquness\ntheorems are proved. Among the main contributions is the collocation method for\napproximate solution of such equations based on the piecewise linear\napproximation. To confirm the convergence of the method, a number of numerical\nresults for solving model problems are provided.", "published": "2025-03-27 12:42:51", "link": "http://arxiv.org/abs/2503.21452v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "45D05 65R20"], "primary_category": "math.NA"}
{"title": "Computing adjoint mismatch of linear maps", "abstract": "This paper considers the problem of detecting adjoint mismatch for two linear\nmaps. To clarify, this means that we aim to calculate the operator norm for the\ndifference of two linear maps, where for one we only have a black-box\nimplementation for the evaluation of the map, and for the other we only have a\nblack-box for the evaluation of the adjoint map. We give two stochastic\nalgorithms for which we prove the almost sure convergence to the operator norm.\nThe algorithm is a random search method for a generalization of the Rayleigh\nquotient and uses optimal step sizes. Additionally, a convergence analysis is\ndone for the corresponding singular vector and the respective eigenvalue\nequation.", "published": "2025-03-27 10:52:12", "link": "http://arxiv.org/abs/2503.21361v1", "categories": ["math.NA", "cs.NA", "math.OC", "65F35, 15A60, 68W20"], "primary_category": "math.NA"}
{"title": "Explicit error bounds and guaranteed convergence of the Koopman-Hill projection stability method for linear time-periodic dynamics", "abstract": "The Koopman-Hill projection method is used to approximate the fundamental\nsolution matrix of linear time-periodic ordinary differential equations,\npossibly stemming from linearization around a periodic solution of a nonlinear\ndynamical system. By expressing both the true fundamental solution and its\napproximation as series, we derive an upper bound for the approximation error\nthat decays exponentially with the size of the Hill matrix. Exponential decay\nof the Fourier coefficients of the system dynamics is key to guarantee\nconvergence. The paper also analyzes a subharmonic formulation that improves\nthe convergence rate. Two numerical examples, including a Duffing oscillator,\nillustrate the theoretical findings.", "published": "2025-03-27 09:57:26", "link": "http://arxiv.org/abs/2503.21318v1", "categories": ["math.NA", "cs.NA", "math.DS", "35L70 (Primary), 37M20 (Secondary)"], "primary_category": "math.NA"}
{"title": "Multi-fidelity Learning of Reduced Order Models for Parabolic PDE Constrained Optimization", "abstract": "This article builds on the recently proposed RB-ML-ROM approach for\nparameterized parabolic PDEs and proposes a novel hierarchical Trust Region\nalgorithm for solving parabolic PDE constrained optimization problems. Instead\nof using a traditional offline/online splitting approach for model order\nreduction, we adopt an active learning or enrichment strategy to construct a\nmulti-fidelity hierarchy of reduced order models on-the-fly during the outer\noptimization loop. The multi-fidelity surrogate model consists of a full order\nmodel, a reduced order model and a machine learning model. The proposed\nhierarchical framework adaptively updates its hierarchy when querying\nparameters, utilizing a rigorous a posteriori error estimator in an error aware\ntrust region framework. Numerical experiments are given to demonstrate the\nefficiency of the proposed approach.", "published": "2025-03-27 08:18:00", "link": "http://arxiv.org/abs/2503.21252v1", "categories": ["math.OC", "cs.NA", "math.NA", "49M20, 49K20, 35J20, 65N30, 90C06"], "primary_category": "math.OC"}
{"title": "Continuous Data Assimilation for the Navier-Stokes Equations with Nonlinear Slip Boundary Conditions", "abstract": "This paper focuses on continuous data assimilation (CDA) for the\nNavier-Stokes equations with nonlinear slip boundary conditions. CDA methods\nare typically employed to recover the original system when initial data or\nviscosity coefficients are unknown, by incorporating a feedback control term\ngenerated by observational data over a time period. In this study, based on a\nregularized form derived from the variational inequalities of the Navier-Stokes\nequations with nonlinear slip boundary conditions, we first investigate the\nclassical CDA problem when initial data is absent. After establishing the\nexistence, uniqueness and regularity of the solution, we prove its exponential\nconvergence with respect to the time. Additionally, we extend the CDA to\naddress the problem of missing viscosity coefficients and analyze its\nconvergence order, too. Furthermore, utilizing the predictive capabilities of\npartial evolutionary tensor neural networks (pETNNs) for time-dependent\nproblems, we propose a novel CDA by replacing observational data with\npredictions got by pETNNs. Compared with the classical CDA, the new one can\nachieve similar approximation accuracy but need much less computational cost.\nSome numerical experiments are presented, which not only validate the\ntheoretical results, but also demonstrate the efficiency of the CDA.", "published": "2025-03-27 07:49:44", "link": "http://arxiv.org/abs/2503.21234v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Optimal Transportation for the Far-field Reflector Problem", "abstract": "The inverse reflector problem aims to design a freeform reflecting surface\nthat can direct the light from a specified source to produce the desired\nillumination in the target area, which is significant in the field of\ngeometrical non-imaging optics. Mathematically, it can be formulated as an\noptimization problem, which is exactly the optimal transportation problem (OT)\nwhen the target is in the far field. The gradient of OT is governed by the\ngeneralized Monge-Amp`ere equation that models the far-field reflector system.\nBased on the gradient, this work presents a Sobolev gradient descent method\nimplemented within a finite element framework to solve the corresponding OT.\nConvergence of the method is established and numerical examples are provided to\ndemonstrate the effectiveness of the method.", "published": "2025-03-27 06:05:01", "link": "http://arxiv.org/abs/2503.21182v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Low Stein Discrepancy via Message-Passing Monte Carlo", "abstract": "Message-Passing Monte Carlo (MPMC) was recently introduced as a novel\nlow-discrepancy sampling approach leveraging tools from geometric deep\nlearning. While originally designed for generating uniform point sets, we\nextend this framework to sample from general multivariate probability\ndistributions with known probability density function. Our proposed method,\nStein-Message-Passing Monte Carlo (Stein-MPMC), minimizes a kernelized Stein\ndiscrepancy, ensuring improved sample quality. Finally, we show that Stein-MPMC\noutperforms competing methods, such as Stein Variational Gradient Descent and\n(greedy) Stein Points, by achieving a lower Stein discrepancy.", "published": "2025-03-27 02:49:31", "link": "http://arxiv.org/abs/2503.21103v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Sub-ODEs Simplify Taylor Series Algorithms for Ordinary Differential Equations", "abstract": "A Taylor method for solving an ordinary differential equation initial-value\nproblem $\\dot x = f(t,x)$, $x(t_0) = x_0$, computes the Taylor series (TS) of\nthe solution at the current point, truncated to some order, and then advances\nto the next point by summing the TS with a suitable step size.\n  A standard ODE method (e.g. Runge-Kutta) treats function $f$ as a black box,\nbut a Taylor solver requires $f$ to be preprocessed into a code-list of\nelementary operations that it interprets as operations on (truncated) TS.\n  The trade-off for this extra work includes arbitrary order, typically\nenabling much larger step sizes.\n  For a standard function, such as $\\exp$, this means evaluating\n$v(t)=\\exp(u(t))$, where $u(t),v(t)$ are TS.\n  The sub-ODE method applies the ODE $d v/d u=v$, obeyed by $v=\\exp(u)$, to\nin-line this operation as $\\dot v=v\\dot u$.\n  This gives economy of implementation: each function that satisfies a simple\nODE goes into the \"Taylor library\" with a few lines of code--not needing a\nseparate recurrence relation, which is the typical approach.\n  Mathematically, however, the use of sub-ODEs generally transforms the\noriginal ODE into a differential-algebraic system, making it nontrivial to\nensure a sound system of recurrences for Taylor coefficients.\n  We prove that, regardless of how many sub-ODEs are incorporated into $f$,\nthis approach guarantees a sound system.\n  We introduce our sub-ODE-based Matlab ODE solver and show that its\nperformance compares favorably with solvers from the Matlab ODE suite.", "published": "2025-03-27 01:35:32", "link": "http://arxiv.org/abs/2503.21078v1", "categories": ["math.NA", "cs.MS", "cs.NA", "65L05, 65L80, 41A58"], "primary_category": "math.NA"}
{"title": "Pool Value Replication (CPM) and Impermanent Loss Hedging", "abstract": "This work analytically characterizes impermanent loss for automated market\nmakers (AMMs) in decentralized markets such as Uniswap or Balancer (CPMM). We\nderive a static replication formula for the pool's value using a combination of\nEuropean calls and puts. Furthermore, we establish a result guaranteeing\nhedging coverage for all final prices within a predefined interval. These\ntheoretical results motivate a numerical example where we illustrate the\nstrangle strategy using real cryptocurrency options data from Deribit, one of\nthe most liquid markets available.", "published": "2025-03-27 20:31:33", "link": "http://arxiv.org/abs/2503.21967v1", "categories": ["q-fin.RM", "q-fin.MF"], "primary_category": "q-fin.RM"}
{"title": "Dynamic Asset Pricing Theory for Life Contingent Risks", "abstract": "Although the valuation of life contingent assets has been thoroughly\ninvestigated under the framework of mathematical statistics, little financial\neconomics research pays attention to the pricing of these assets in a\nnon-arbitrage, complete market. In this paper, we first revisit the Fundamental\nTheorem of Asset Pricing (FTAP) and the short proof of it. Then we point out\nthat discounted asset price is a martingale only when dividends are zero under\nall random states of the world, using a simple proof based on pricing kernel.\nNext, we apply Fundamental Theorem of Asset Pricing (FTAP) to find valuation\nformula for life contingent assets including life insurance policies and life\ncontingent annuities. Last but not least, we state the assumption of static\nportfolio in a dynamic economy, and clarify the FTAP that accommodates the\nvaluation of a portfolio of life contingent policies.", "published": "2025-03-27 08:24:05", "link": "http://arxiv.org/abs/2503.21256v1", "categories": ["q-fin.PR", "math.PR", "q-fin.MF", "q-fin.ST"], "primary_category": "q-fin.PR"}
{"title": "Improving Equivariant Networks with Probabilistic Symmetry Breaking", "abstract": "Equivariance encodes known symmetries into neural networks, often enhancing\ngeneralization. However, equivariant networks cannot break symmetries: the\noutput of an equivariant network must, by definition, have at least the same\nself-symmetries as the input. This poses an important problem, both (1) for\nprediction tasks on domains where self-symmetries are common, and (2) for\ngenerative models, which must break symmetries in order to reconstruct from\nhighly symmetric latent spaces. This fundamental limitation can be addressed by\nconsidering equivariant conditional distributions, instead of equivariant\nfunctions. We present novel theoretical results that establish necessary and\nsufficient conditions for representing such distributions. Concretely, this\nrepresentation provides a practical framework for breaking symmetries in any\nequivariant network via randomized canonicalization. Our method, SymPE\n(Symmetry-breaking Positional Encodings), admits a simple interpretation in\nterms of positional encodings. This approach expands the representational power\nof equivariant networks while retaining the inductive bias of symmetry, which\nwe justify through generalization bounds. Experimental results demonstrate that\nSymPE significantly improves performance of group-equivariant and graph neural\nnetworks across diffusion models for graphs, graph autoencoders, and lattice\nspin system modeling.", "published": "2025-03-27 21:04:49", "link": "http://arxiv.org/abs/2503.21985v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Artificial Trend Index for Private Consumption Using Google Trends", "abstract": "In recent years, the use of databases that analyze trends, sentiments or news\nto make economic projections or create indicators has gained significant\npopularity, particularly with the Google Trends platform. This article explores\nthe potential of Google search data to develop a new index that improves\neconomic forecasts, with a particular focus on one of the key components of\neconomic activity: private consumption (64\\% of GDP in Peru). By selecting and\nestimating categorized variables, machine learning techniques are applied,\ndemonstrating that Google data can identify patterns to generate a leading\nindicator in real time and improve the accuracy of forecasts. Finally, the\nresults show that Google's \"Food\" and \"Tourism\" categories significantly reduce\nprojection errors, highlighting the importance of using this information in a\nsegmented manner to improve macroeconomic forecasts.", "published": "2025-03-27 20:58:01", "link": "http://arxiv.org/abs/2503.21981v1", "categories": ["econ.EM", "stat.ML"], "primary_category": "econ.EM"}
{"title": "Rolled Gaussian process models for curves on manifolds", "abstract": "Given a planar curve, imagine rolling a sphere along that curve without\nslipping or twisting, and by this means tracing out a curve on the sphere. It\nis well known that such a rolling operation induces a local isometry between\nthe sphere and the plane so that the two curves uniquely determine each other,\nand moreover, the operation extends to a general class of manifolds in any\ndimension. We use rolling to construct an analogue of a Gaussian process on a\nmanifold starting from a Euclidean Gaussian process. The resulting model is\ngenerative, and is amenable to statistical inference given data as curves on a\nmanifold. We illustrate with examples on the unit sphere, symmetric\npositive-definite matrices, and with a robotics application involving 3D\norientations.", "published": "2025-03-27 20:52:18", "link": "http://arxiv.org/abs/2503.21980v1", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "A Comprehensive Benchmark for RNA 3D Structure-Function Modeling", "abstract": "The RNA structure-function relationship has recently garnered significant\nattention within the deep learning community, promising to grow in importance\nas nucleic acid structure models advance. However, the absence of standardized\nand accessible benchmarks for deep learning on RNA 3D structures has impeded\nthe development of models for RNA functional characteristics.\n  In this work, we introduce a set of seven benchmarking datasets for RNA\nstructure-function prediction, designed to address this gap. Our library builds\non the established Python library rnaglib, and offers easy data distribution\nand encoding, splitters and evaluation methods, providing a convenient\nall-in-one framework for comparing models. Datasets are implemented in a fully\nmodular and reproducible manner, facilitating for community contributions and\ncustomization. Finally, we provide initial baseline results for all tasks using\na graph neural network.\n  Source code: https://github.com/cgoliver/rnaglib\n  Documentation: https://rnaglib.org", "published": "2025-03-27 16:49:31", "link": "http://arxiv.org/abs/2503.21681v1", "categories": ["q-bio.BM", "cs.LG", "stat.ML"], "primary_category": "q-bio.BM"}
{"title": "A friendly introduction to triangular transport", "abstract": "Decision making under uncertainty is a cross-cutting challenge in science and\nengineering. Most approaches to this challenge employ probabilistic\nrepresentations of uncertainty. In complicated systems accessible only via data\nor black-box models, however, these representations are rarely known. We\ndiscuss how to characterize and manipulate such representations using\ntriangular transport maps, which approximate any complex probability\ndistribution as a transformation of a simple, well-understood distribution. The\nparticular structure of triangular transport guarantees many desirable\nmathematical and computational properties that translate well into solving\npractical problems. Triangular maps are actively used for density estimation,\n(conditional) generative modelling, Bayesian inference, data assimilation,\noptimal experimental design, and related tasks. While there is ample literature\non the development and theory of triangular transport methods, this manuscript\nprovides a detailed introduction for scientists interested in employing measure\ntransport without assuming a formal mathematical background. We build intuition\nfor the key foundations of triangular transport, discuss many aspects of its\npractical implementation, and outline the frontiers of this field.", "published": "2025-03-27 16:41:14", "link": "http://arxiv.org/abs/2503.21673v1", "categories": ["stat.CO", "physics.ao-ph", "stat.ME", "stat.ML", "62-01, 62-02, 60-08, 65C05, 62F15, 65C20"], "primary_category": "stat.CO"}
{"title": "Locally minimax optimal and dimension-agnostic discrete argmin inference", "abstract": "We revisit the discrete argmin inference problem in high-dimensional\nsettings. Given $n$ observations from a $d$ dimensional vector, the goal is to\ntest whether the $r$th component of the mean vector is the smallest among all\ncomponents. We propose dimension-agnostic tests that maintain validity\nregardless of how $d$ scales with $n$, and regardless of arbitrary ties in the\nmean vector. Notably, our validity holds under mild moment conditions,\nrequiring little more than finiteness of a second moment, and permitting\npossibly strong dependence between coordinates. In addition, we establish the\nlocal minimax separation rate for this problem, which adapts to the cardinality\nof a confusion set, and show that the proposed tests attain this rate. Our\nmethod uses the sample splitting and self-normalization approach of Kim and\nRamdas (2024). Our tests can be easily inverted to yield confidence sets for\nthe argmin index. Empirical results illustrate the strong performance of our\napproach in terms of type I error control and power compared to existing\nmethods.", "published": "2025-03-27 16:06:07", "link": "http://arxiv.org/abs/2503.21639v1", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "ClusterSC: Advancing Synthetic Control with Donor Selection", "abstract": "In causal inference with observational studies, synthetic control (SC) has\nemerged as a prominent tool. SC has traditionally been applied to\naggregate-level datasets, but more recent work has extended its use to\nindividual-level data. As they contain a greater number of observed units, this\nshift introduces the curse of dimensionality to SC. To address this, we propose\nCluster Synthetic Control (ClusterSC), based on the idea that groups of\nindividuals may exist where behavior aligns internally but diverges between\ngroups. ClusterSC incorporates a clustering step to select only the relevant\ndonors for the target. We provide theoretical guarantees on the improvements\ninduced by ClusterSC, supported by empirical demonstrations on synthetic and\nreal-world datasets. The results indicate that ClusterSC consistently\noutperforms classical SC approaches.", "published": "2025-03-27 15:50:32", "link": "http://arxiv.org/abs/2503.21629v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Nonlinear Multiple Response Regression and Learning of Latent Spaces", "abstract": "Identifying low-dimensional latent structures within high-dimensional data\nhas long been a central topic in the machine learning community, driven by the\nneed for data compression, storage, transmission, and deeper data\nunderstanding. Traditional methods, such as principal component analysis (PCA)\nand autoencoders (AE), operate in an unsupervised manner, ignoring label\ninformation even when it is available. In this work, we introduce a unified\nmethod capable of learning latent spaces in both unsupervised and supervised\nsettings. We formulate the problem as a nonlinear multiple-response regression\nwithin an index model context. By applying the generalized Stein's lemma, the\nlatent space can be estimated without knowing the nonlinear link functions. Our\nmethod can be viewed as a nonlinear generalization of PCA. Moreover, unlike AE\nand other neural network methods that operate as \"black boxes\", our approach\nnot only offers better interpretability but also reduces computational\ncomplexity while providing strong theoretical guarantees. Comprehensive\nnumerical experiments and real data analyses demonstrate the superior\nperformance of our method.", "published": "2025-03-27 15:28:06", "link": "http://arxiv.org/abs/2503.21608v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Probabilistic Functional Neural Networks", "abstract": "High-dimensional functional time series (HDFTS) are often characterized by\nnonlinear trends and high spatial dimensions. Such data poses unique challenges\nfor modeling and forecasting due to the nonlinearity, nonstationarity, and high\ndimensionality. We propose a novel probabilistic functional neural network\n(ProFnet) to address these challenges. ProFnet integrates the strengths of\nfeedforward and deep neural networks with probabilistic modeling. The model\ngenerates probabilistic forecasts using Monte Carlo sampling and also enables\nthe quantification of uncertainty in predictions. While capturing both temporal\nand spatial dependencies across multiple regions, ProFnet offers a scalable and\nunified solution for large datasets. Applications to Japan's mortality rates\ndemonstrate superior performance. This approach enhances predictive accuracy\nand provides interpretable uncertainty estimates, making it a valuable tool for\nforecasting complex high-dimensional functional data and HDFTS.", "published": "2025-03-27 15:01:37", "link": "http://arxiv.org/abs/2503.21585v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Consistent Multigroup Low-Rank Approximation", "abstract": "We consider the problem of consistent low-rank approximation for multigroup\ndata: we ask for a sequence of $k$ basis vectors such that projecting the data\nonto their spanned subspace treats all groups as equally as possible, by\nminimizing the maximum error among the groups. Additionally, we require that\nthe sequence of basis vectors satisfies the natural consistency property: when\nlooking for the best $k$ vectors, the first $d<k$ vectors are the best possible\nsolution to the problem of finding $d$ basis vectors. Thus, this multigroup\nlow-rank approximation method naturally generalizes \\svd and reduces to \\svd\nfor data with a single group. We give an iterative algorithm for this task that\nsequentially adds to the basis the vector that gives the best rank$-1$\nprojection according to the min-max criterion, and then projects the data onto\nthe orthogonal complement of that vector. For finding the best rank$-1$\nprojection, we use primal-dual approaches or semidefinite programming. We\nanalyze the theoretical properties of the algorithms and demonstrate\nempirically that the proposed methods compare favorably to existing methods for\nmultigroup (or fair) PCA.", "published": "2025-03-27 14:47:27", "link": "http://arxiv.org/abs/2503.21563v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SyncSDE: A Probabilistic Framework for Diffusion Synchronization", "abstract": "There have been many attempts to leverage multiple diffusion models for\ncollaborative generation, extending beyond the original domain. A prominent\napproach involves synchronizing multiple diffusion trajectories by mixing the\nestimated scores to artificially correlate the generation processes. However,\nexisting methods rely on naive heuristics, such as averaging, without\nconsidering task specificity. These approaches do not clarify why such methods\nwork and often fail when a heuristic suitable for one task is blindly applied\nto others. In this paper, we present a probabilistic framework for analyzing\nwhy diffusion synchronization works and reveal where heuristics should be\nfocused - modeling correlations between multiple trajectories and adapting them\nto each specific task. We further identify optimal correlation models per task,\nachieving better results than previous approaches that apply a single heuristic\nacross all tasks without justification.", "published": "2025-03-27 14:40:53", "link": "http://arxiv.org/abs/2503.21555v1", "categories": ["cs.LG", "cs.CV", "cs.GR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Exploring the Energy Landscape of RBMs: Reciprocal Space Insights into Bosons, Hierarchical Learning and Symmetry Breaking", "abstract": "Deep generative models have become ubiquitous due to their ability to learn\nand sample from complex distributions. Despite the proliferation of various\nframeworks, the relationships among these models remain largely unexplored, a\ngap that hinders the development of a unified theory of AI learning. We address\ntwo central challenges: clarifying the connections between different deep\ngenerative models and deepening our understanding of their learning mechanisms.\nWe focus on Restricted Boltzmann Machines (RBMs), known for their universal\napproximation capabilities for discrete distributions. By introducing a\nreciprocal space formulation, we reveal a connection between RBMs, diffusion\nprocesses, and coupled Bosons. We show that at initialization, the RBM operates\nat a saddle point, where the local curvature is determined by the singular\nvalues, whose distribution follows the Marcenko-Pastur law and exhibits\nrotational symmetry. During training, this rotational symmetry is broken due to\nhierarchical learning, where different degrees of freedom progressively capture\nfeatures at multiple levels of abstraction. This leads to a symmetry breaking\nin the energy landscape, reminiscent of Landau theory. This symmetry breaking\nin the energy landscape is characterized by the singular values and the weight\nmatrix eigenvector matrix. We derive the corresponding free energy in a\nmean-field approximation. We show that in the limit of infinite size RBM, the\nreciprocal variables are Gaussian distributed. Our findings indicate that in\nthis regime, there will be some modes for which the diffusion process will not\nconverge to the Boltzmann distribution. To illustrate our results, we trained\nreplicas of RBMs with different hidden layer sizes using the MNIST dataset. Our\nfindings bridge the gap between disparate generative frameworks and also shed\nlight on the processes underpinning learning in generative models.", "published": "2025-03-27 14:28:37", "link": "http://arxiv.org/abs/2503.21536v1", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Bayesian Pseudo Posterior Mechanism for Differentially Private Machine Learning", "abstract": "Differential privacy (DP) is becoming increasingly important for deployed\nmachine learning applications because it provides strong guarantees for\nprotecting the privacy of individuals whose data is used to train models.\nHowever, DP mechanisms commonly used in machine learning tend to struggle on\nmany real world distributions, including highly imbalanced or small labeled\ntraining sets. In this work, we propose a new scalable DP mechanism for deep\nlearning models, SWAG-PPM, by using a pseudo posterior distribution that\ndownweights by-record likelihood contributions proportionally to their\ndisclosure risks as the randomized mechanism. As a motivating example from\nofficial statistics, we demonstrate SWAG-PPM on a workplace injury text\nclassification task using a highly imbalanced public dataset published by the\nU.S. Occupational Safety and Health Administration (OSHA). We find that\nSWAG-PPM exhibits only modest utility degradation against a non-private\ncomparator while greatly outperforming the industry standard DP-SGD for a\nsimilar privacy budget.", "published": "2025-03-27 14:17:05", "link": "http://arxiv.org/abs/2503.21528v1", "categories": ["stat.ML", "cs.CR", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Constraint-based causal discovery with tiered background knowledge and latent variables in single or overlapping datasets", "abstract": "In this paper we consider the use of tiered background knowledge within\nconstraint based causal discovery. Our focus is on settings relaxing causal\nsufficiency, i.e. allowing for latent variables which may arise because\nrelevant information could not be measured at all, or not jointly, as in the\ncase of multiple overlapping datasets. We first present novel insights into the\nproperties of the 'tiered FCI' (tFCI) algorithm. Building on this, we introduce\na new extension of the IOD (integrating overlapping datasets) algorithm\nincorporating tiered background knowledge, the 'tiered IOD' (tIOD) algorithm.\nWe show that under full usage of the tiered background knowledge tFCI and tIOD\nare sound, while simple versions of the tIOD and tFCI are sound and complete.\nWe further show that the tIOD algorithm can often be expected to be\nconsiderably more efficient and informative than the IOD algorithm even beyond\nthe obvious restriction of the Markov equivalence classes. We provide a formal\nresult on the conditions for this gain in efficiency and informativeness. Our\nresults are accompanied by a series of examples illustrating the exact role and\nusefulness of tiered background knowledge.", "published": "2025-03-27 14:14:21", "link": "http://arxiv.org/abs/2503.21526v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Uncertainty-aware Bayesian machine learning modelling of land cover classification", "abstract": "Land cover classification involves the production of land cover maps, which\ndetermine the type of land through remote sensing imagery. Over recent years,\nsuch classification is being performed by machine learning classification\nmodels, which can give highly accurate predictions on land cover per pixel\nusing large quantities of input training data. However, such models do not\ncurrently take account of input measurement uncertainty, which is vital for\ntraceability in metrology. In this work we propose a Bayesian classification\nframework using generative modelling to take account of input measurement\nuncertainty. We take the specific case of Bayesian quadratic discriminant\nanalysis, and apply it to land cover datasets from Copernicus Sentinel-2 in\n2020 and 2021. We benchmark the performance of the model against more popular\nclassification models used in land cover maps such as random forests and neural\nnetworks. We find that such Bayesian models are more trustworthy, in the sense\nthat they are more interpretable, explicitly model the input measurement\nuncertainty, and maintain predictive performance of class probability outputs\nacross datasets of different years and sizes, whilst also being computationally\nefficient.", "published": "2025-03-27 13:59:19", "link": "http://arxiv.org/abs/2503.21510v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "DeepRV: pre-trained spatial priors for accelerated disease mapping", "abstract": "Recently introduced prior-encoding deep generative models (e.g., PriorVAE,\n$\\pi$VAE, and PriorCVAE) have emerged as powerful tools for scalable Bayesian\ninference by emulating complex stochastic processes like Gaussian processes\n(GPs). However, these methods remain largely a proof-of-concept and\ninaccessible to practitioners. We propose DeepRV, a lightweight, decoder-only\napproach that accelerates training, and enhances real-world applicability in\ncomparison to current VAE-based prior encoding approaches. Leveraging\nprobabilistic programming frameworks (e.g., NumPyro) for inference, DeepRV\nachieves significant speedups while also improving the quality of parameter\ninference, closely matching full MCMC sampling. We showcase its effectiveness\nin process emulation and spatial analysis of the UK using simulated data,\ngender-wise cancer mortality rates for individuals under 50, and HIV prevalence\nin Zimbabwe. To bridge the gap between theory and practice, we provide a\nuser-friendly API, enabling scalable and efficient Bayesian inference.", "published": "2025-03-27 13:04:41", "link": "http://arxiv.org/abs/2503.21473v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Nearest Neighbour Equilibrium Clustering", "abstract": "A novel and intuitive nearest neighbours based clustering algorithm is\nintroduced, in which a cluster is defined in terms of an equilibrium condition\nwhich balances its size and cohesiveness. The formulation of the equilibrium\ncondition allows for a quantification of the strength of alignment of each\npoint to a cluster, with these cluster alignment strengths leading naturally to\na model selection criterion which renders the proposed approach fully\nautomatable. The algorithm is simple to implement and computationally\nefficient, and produces clustering solutions of extremely high quality in\ncomparison with relevant benchmarks from the literature. R code to implement\nthe approach is available from https://github.com/DavidHofmeyr/NNEC.", "published": "2025-03-27 12:16:54", "link": "http://arxiv.org/abs/2503.21431v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ProHOC: Probabilistic Hierarchical Out-of-Distribution Classification via Multi-Depth Networks", "abstract": "Out-of-distribution (OOD) detection in deep learning has traditionally been\nframed as a binary task, where samples are either classified as belonging to\nthe known classes or marked as OOD, with little attention given to the semantic\nrelationships between OOD samples and the in-distribution (ID) classes. We\npropose a framework for detecting and classifying OOD samples in a given class\nhierarchy. Specifically, we aim to predict OOD data to their correct internal\nnodes of the class hierarchy, whereas the known ID classes should be predicted\nas their corresponding leaf nodes. Our approach leverages the class hierarchy\nto create a probabilistic model and we implement this model by using networks\ntrained for ID classification at multiple hierarchy depths. We conduct\nexperiments on three datasets with predefined class hierarchies and show the\neffectiveness of our method. Our code is available at\nhttps://github.com/walline/prohoc.", "published": "2025-03-27 11:39:55", "link": "http://arxiv.org/abs/2503.21397v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Scalable Expectation Estimation with Subtractive Mixture Models", "abstract": "Many Monte Carlo (MC) and importance sampling (IS) methods use mixture models\n(MMs) for their simplicity and ability to capture multimodal distributions.\nRecently, subtractive mixture models (SMMs), i.e. MMs with negative\ncoefficients, have shown greater expressiveness and success in generative\nmodeling. However, their negative parameters complicate sampling, requiring\ncostly auto-regressive techniques or accept-reject algorithms that do not scale\nin high dimensions. In this work, we use the difference representation of SMMs\nto construct an unbiased IS estimator ($\\Delta\\text{Ex}$) that removes the need\nto sample from the SMM, enabling high-dimensional expectation estimation with\nSMMs. In our experiments, we show that $\\Delta\\text{Ex}$ can achieve comparable\nestimation quality to auto-regressive sampling while being considerably faster\nin MC estimation. Moreover, we conduct initial experiments with\n$\\Delta\\text{Ex}$ using hand-crafted proposals, gaining first insights into how\nto construct safe proposals for $\\Delta\\text{Ex}$.", "published": "2025-03-27 10:25:03", "link": "http://arxiv.org/abs/2503.21346v1", "categories": ["cs.LG", "stat.CO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Combating the Bullwhip Effect in Rival Online Food Delivery Platforms Using Deep Learning", "abstract": "The wastage of perishable items has led to significant health and economic\ncrises, increasing business uncertainty and fluctuating customer demand. This\nissue is worsened by online food delivery services, where frequent and\nunpredictable orders create inefficiencies in supply chain management,\ncontributing to the bullwhip effect. This effect results in stockouts, excess\ninventory, and inefficiencies. Accurate demand forecasting helps stabilize\ninventory, optimize supplier orders, and reduce waste. This paper presents a\nThird-Party Logistics (3PL) supply chain model involving restaurants, online\nfood apps, and customers, along with a deep learning-based demand forecasting\nmodel using a two-phase Long Short-Term Memory (LSTM) network.\n  Phase one, intra-day forecasting, captures short-term variations, while phase\ntwo, daily forecasting, predicts overall demand. A two-year dataset from\nJanuary 2023 to January 2025 from Swiggy and Zomato is used, employing discrete\nevent simulation and grid search for optimal LSTM hyperparameters. The proposed\nmethod is evaluated using RMSE, MAE, and R-squared score, with R-squared as the\nprimary accuracy measure. Phase one achieves an R-squared score of 0.69 for\nZomato and 0.71 for Swiggy with a training time of 12 minutes, while phase two\nimproves to 0.88 for Zomato and 0.90 for Swiggy with a training time of 8\nminutes.\n  To mitigate demand fluctuations, restaurant inventory is dynamically managed\nusing the newsvendor model, adjusted based on forecasted demand. The proposed\nframework significantly reduces the bullwhip effect, improving forecasting\naccuracy and supply chain efficiency. For phase one, supply chain instability\ndecreases from 2.61 to 0.96, and for phase two, from 2.19 to 0.80. This\ndemonstrates the model's effectiveness in minimizing food waste and maintaining\noptimal restaurant inventory levels.", "published": "2025-03-27 10:22:52", "link": "http://arxiv.org/abs/2503.22753v1", "categories": ["cs.LG", "cs.CY", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Explainable Boosting Machine for Predicting Claim Severity and Frequency in Car Insurance", "abstract": "In a context of constant increase in competition and heightened regulatory\npressure, accuracy, actuarial precision, as well as transparency and\nunderstanding of the tariff, are key issues in non-life insurance.\nTraditionally used generalized linear models (GLM) result in a multiplicative\ntariff that favors interpretability. With the rapid development of machine\nlearning and deep learning techniques, actuaries and the rest of the insurance\nindustry have adopted these techniques widely. However, there is a need to\nassociate them with interpretability techniques. In this paper, our study\nfocuses on introducing an Explainable Boosting Machine (EBM) model that\ncombines intrinsically interpretable characteristics and high prediction\nperformance. This approach is described as a glass-box model and relies on the\nuse of a Generalized Additive Model (GAM) and a cyclic gradient boosting\nalgorithm. It accounts for univariate and pairwise interaction effects between\nfeatures and provides naturally explanations on them. We implement this\napproach on car insurance frequency and severity data and extensively compare\nthe performance of this approach with classical competitors: a GLM, a GAM, a\nCART model and an Extreme Gradient Boosting (XGB) algorithm. Finally, we\nexamine the interpretability of these models to capture the main determinants\nof claim costs.", "published": "2025-03-27 09:59:45", "link": "http://arxiv.org/abs/2503.21321v1", "categories": ["stat.AP", "cs.LG", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Simulation-informed deep learning for enhanced SWOT observations of fine-scale ocean dynamics", "abstract": "Oceanic processes at fine scales are crucial yet difficult to observe\naccurately due to limitations in satellite and in-situ measurements. The\nSurface Water and Ocean Topography (SWOT) mission provides high-resolution Sea\nSurface Height (SSH) data, though noise patterns often obscure fine scale\nstructures. Current methods struggle with noisy data or require extensive\nsupervised training, limiting their effectiveness on real-world observations.\nWe introduce SIMPGEN (Simulation-Informed Metric and Prior for Generative\nEnsemble Networks), an unsupervised adversarial learning framework combining\nreal SWOT observations with simulated reference data. SIMPGEN leverages\nwavelet-informed neural metrics to distinguish noisy from clean fields, guiding\nrealistic SSH reconstructions. Applied to SWOT data, SIMPGEN effectively\nremoves noise, preserving fine-scale features better than existing neural\nmethods. This robust, unsupervised approach not only improves SWOT SSH data\ninterpretation but also demonstrates strong potential for broader oceanographic\napplications, including data assimilation and super-resolution.", "published": "2025-03-27 09:29:33", "link": "http://arxiv.org/abs/2503.21303v1", "categories": ["physics.ao-ph", "cs.LG", "stat.ML"], "primary_category": "physics.ao-ph"}
{"title": "Efficient Learning for Entropy-Regularized Markov Decision Processes via Multilevel Monte Carlo", "abstract": "Designing efficient learning algorithms with complexity guarantees for Markov\ndecision processes (MDPs) with large or continuous state and action spaces\nremains a fundamental challenge. We address this challenge for\nentropy-regularized MDPs with Polish state and action spaces, assuming access\nto a generative model of the environment. We propose a novel family of\nmultilevel Monte Carlo (MLMC) algorithms that integrate fixed-point iteration\nwith MLMC techniques and a generic stochastic approximation of the Bellman\noperator. We quantify the precise impact of the chosen approximate Bellman\noperator on the accuracy of the resulting MLMC estimator. Leveraging this error\nanalysis, we show that using a biased plain MC estimate for the Bellman\noperator results in quasi-polynomial sample complexity, whereas an unbiased\nrandomized multilevel approximation of the Bellman operator achieves polynomial\nsample complexity in expectation. Notably, these complexity bounds are\nindependent of the dimensions or cardinalities of the state and action spaces,\ndistinguishing our approach from existing algorithms whose complexities scale\nwith the sizes of these spaces. We validate these theoretical performance\nguarantees through numerical experiments.", "published": "2025-03-27 07:35:23", "link": "http://arxiv.org/abs/2503.21224v2", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML", "65C05, 90C40 (Primary) 90C39, 60J20, 68Q32 (Secondary)"], "primary_category": "cs.LG"}
{"title": "Unveiling the Power of Uncertainty: A Journey into Bayesian Neural Networks for Stellar dating", "abstract": "Context: Astronomy and astrophysics demand rigorous handling of uncertainties\nto ensure the credibility of outcomes. The growing integration of artificial\nintelligence offers a novel avenue to address this necessity. This convergence\npresents an opportunity to create advanced models capable of quantifying\ndiverse sources of uncertainty and automating complex data relationship\nexploration.\n  What: We introduce a hierarchical Bayesian architecture whose probabilistic\nrelationships are modeled by neural networks, designed to forecast stellar\nattributes such as mass, radius, and age (our main target). This architecture\nhandles both observational uncertainties stemming from measurements and\nepistemic uncertainties inherent in the predictive model itself. As a result,\nour system generates distributions that encapsulate the potential range of\nvalues for our predictions, providing a comprehensive understanding of their\nvariability and robustness.\n  Methods: Our focus is on dating main sequence stars using a technique known\nas Chemical Clocks, which serves as both our primary astronomical challenge and\na model prototype. In this work, we use hierarchical architectures to account\nfor correlations between stellar parameters and optimize information extraction\nfrom our dataset. We also employ Bayesian neural networks for their versatility\nand flexibility in capturing complex data relationships.\n  Results: By integrating our machine learning algorithm into a Bayesian\nframework, we have successfully propagated errors consistently and managed\nuncertainty treatment effectively, resulting in predictions characterized by\nbroader uncertainty margins. This approach facilitates more conservative\nestimates in stellar dating. Our architecture achieves age predictions with a\nmean absolute error of less than 1 Ga for the stars in the test dataset.", "published": "2025-03-27 04:45:48", "link": "http://arxiv.org/abs/2503.21153v1", "categories": ["astro-ph.IM", "astro-ph.GA", "astro-ph.SR", "stat.ML"], "primary_category": "astro-ph.IM"}
{"title": "Squared families: Searching beyond regular probability models", "abstract": "We introduce squared families, which are families of probability densities\nobtained by squaring a linear transformation of a statistic. Squared families\nare singular, however their singularity can easily be handled so that they form\nregular models. After handling the singularity, squared families possess many\nconvenient properties. Their Fisher information is a conformal transformation\nof the Hessian metric induced from a Bregman generator. The Bregman generator\nis the normalising constant, and yields a statistical divergence on the family.\nThe normalising constant admits a helpful parameter-integral factorisation,\nmeaning that only one parameter-independent integral needs to be computed for\nall normalising constants in the family, unlike in exponential families.\nFinally, the squared family kernel is the only integral that needs to be\ncomputed for the Fisher information, statistical divergence and normalising\nconstant. We then describe how squared families are special in the broader\nclass of $g$-families, which are obtained by applying a sufficiently regular\nfunction $g$ to a linear transformation of a statistic. After removing special\nsingularities, positively homogeneous families and exponential families are the\nonly $g$-families for which the Fisher information is a conformal\ntransformation of the Hessian metric, where the generator depends on the\nparameter only through the normalising constant. Even-order monomial families\nalso admit parameter-integral factorisations, unlike exponential families. We\nstudy parameter estimation and density estimation in squared families, in the\nwell-specified and misspecified settings. We use a universal approximation\nproperty to show that squared families can learn sufficiently well-behaved\ntarget densities at a rate of $\\mathcal{O}(N^{-1/2})+C n^{-1/4}$, where $N$ is\nthe number of datapoints, $n$ is the number of parameters, and $C$ is some\nconstant.", "published": "2025-03-27 03:39:35", "link": "http://arxiv.org/abs/2503.21128v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Purifying Approximate Differential Privacy with Randomized Post-processing", "abstract": "We propose a framework to convert $(\\varepsilon, \\delta)$-approximate\nDifferential Privacy (DP) mechanisms into $(\\varepsilon, 0)$-pure DP\nmechanisms, a process we call ``purification''. This algorithmic technique\nleverages randomized post-processing with calibrated noise to eliminate the\n$\\delta$ parameter while preserving utility. By combining the tighter utility\nbounds and computational efficiency of approximate DP mechanisms with the\nstronger guarantees of pure DP, our approach achieves the best of both worlds.\nWe illustrate the applicability of this framework in various settings,\nincluding Differentially Private Empirical Risk Minimization (DP-ERM),\ndata-dependent DP mechanisms such as Propose-Test-Release (PTR), and query\nrelease tasks. To the best of our knowledge, this is the first work to provide\na systematic method for transforming approximate DP into pure DP while\nmaintaining competitive accuracy and computational efficiency.", "published": "2025-03-27 01:10:40", "link": "http://arxiv.org/abs/2503.21071v1", "categories": ["cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Uncertainty propagation in feed-forward neural network models", "abstract": "We develop new uncertainty propagation methods for feed-forward neural\nnetwork architectures with leaky ReLU activation functions subject to random\nperturbations in the input vectors. In particular, we derive analytical\nexpressions for the probability density function (PDF) of the neural network\noutput and its statistical moments as a function of the input uncertainty and\nthe parameters of the network, i.e., weights and biases. A key finding is that\nan appropriate linearization of the leaky ReLU activation function yields\naccurate statistical results even for large perturbations in the input vectors.\nThis can be attributed to the way information propagates through the network.\nWe also propose new analytically tractable Gaussian copula surrogate models to\napproximate the full joint PDF of the neural network output. To validate our\ntheoretical results, we conduct Monte Carlo simulations and a thorough error\nanalysis on a multi-layer neural network representing a nonlinear\nintegro-differential operator between two polynomial function spaces. Our\nfindings demonstrate excellent agreement between the theoretical predictions\nand Monte Carlo simulations.", "published": "2025-03-27 00:16:36", "link": "http://arxiv.org/abs/2503.21059v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Tune It Up: Music Genre Transfer and Prediction", "abstract": "Deep generative models have been used in style transfer tasks for images. In\nthis study, we adapt and improve CycleGAN model to perform music style transfer\non Jazz and Classic genres. By doing so, we aim to easily generate new songs,\ncover music to different music genres and reduce the arrangements needed in\nthose processes. We train and use music genre classifier to assess the\nperformance of the transfer models. To that end, we obtain 87.7% accuracy with\nMulti-layer Perceptron algorithm. To improve our style transfer baseline, we\nadd auxiliary discriminators and triplet loss to our model. According to our\nexperiments, we obtain the best accuracies as 69.4% in Jazz to Classic task and\n39.3% in Classic to Jazz task with our developed genre classifier. We also run\na subjective experiment and results of it show that the overall performance of\nour transfer model is good and it manages to conserve melody of inputs on the\ntransferred outputs. Our code is available at https://github.com/\nfidansamet/tune-it-up", "published": "2025-03-27 21:55:57", "link": "http://arxiv.org/abs/2503.22008v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Expressive Timing in Hindustani Vocal Music", "abstract": "Temporal dynamics are among the cues to expres siveness in music performance\nin different cultures. In the case\n  of Hindustani music, it is well known that expert vocalists\n  often take liberties with the beat, intentionally not aligning their\n  singing precisely with the relatively steady beat provided by\n  the accompanying tabla. This becomes evident when comparing\n  performances of the same composition such as a bandish. We\n  present a methodology for the quantitative study of differences\n  across performed pieces using computational techniques. This is\n  applied to small study of two performances of a popular bandish\n  in raga Yaman, to demonstrate how we can effectively capture the\n  nuances of timing variations that bring out stylistic constraints\n  along with the individual signature of a performer. This work\n  articulates an important step towards the broader goals of music\n  analysis and generative modelling for Indian classical music\n  performance.", "published": "2025-03-27 04:14:44", "link": "http://arxiv.org/abs/2503.21142v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Beyond Subjectivity: Continuous Cybersickness Detection Using EEG-based Multitaper Spectrum Estimation", "abstract": "Virtual reality (VR) presents immersive opportunities across many\napplications, yet the inherent risk of developing cybersickness during\ninteraction can severely reduce enjoyment and platform adoption. Cybersickness\nis marked by symptoms such as dizziness and nausea, which previous work\nprimarily assessed via subjective post-immersion questionnaires and\nmotion-restricted controlled setups. In this paper, we investigate the\n\\emph{dynamic nature} of cybersickness while users experience and freely\ninteract in VR. We propose a novel method to \\emph{continuously} identify and\nquantitatively gauge cybersickness levels from users' \\emph{passively\nmonitored} electroencephalography (EEG) and head motion signals. Our method\nestimates multitaper spectrums from EEG, integrating specialized EEG processing\ntechniques to counter motion artifacts, and, thus, tracks cybersickness levels\nin real-time. Unlike previous approaches, our method requires no user-specific\ncalibration or personalization for detecting cybersickness. Our work addresses\nthe considerable challenge of reproducibility and subjectivity in cybersickness\nresearch.", "published": "2025-03-27 22:31:16", "link": "http://arxiv.org/abs/2503.22024v1", "categories": ["cs.HC", "eess.SP"], "primary_category": "cs.HC"}
{"title": "Beyond the Signal: Medication State Effect on EEG-Based AI models for Parkinson's Disease", "abstract": "Parkinson's disease (PD) poses a growing challenge due to its increasing\nprevalence, complex pathology, and functional ramifications.\nElectroencephalography (EEG), when integrated with artificial intelligence\n(AI), holds promise for monitoring disease progression, identifying\nsub-phenotypes, and personalizing treatment strategies. However, the effect of\nmedication state on AI model learning and generalization remains poorly\nunderstood, potentially limiting EEG-based AI models clinical applicability.\nThis study evaluates how medication state influences the training and\ngeneralization of EEG-based AI models. Paired EEG recordings were utilized from\nindividuals with PD in both ON- and OFF-medication states. AI models were\ntrained on recordings from each state separately and evaluated on independent\ntest sets representing both ON- and OFF-medication conditions. Model\nperformance was assessed using multiple metrics, with accuracy (ACC) as the\nprimary outcome. Statistical significance was assessed via permutation testing\n(p-values<0.05). Our results reveal that models trained on OFF-medication data\nexhibited consistent but suboptimal performance across both medication states\n(ACC_OFF-ON=55.3\\pm8.8 and ACC_OFF-OFF=56.2\\pm8.7). In contrast, models trained\non ON-medication data demonstrated significantly higher performance on\nON-medication recordings (ACC_ON-ON=80.7\\pm7.1) but significantly reduced\ngeneralization to OFF-medication data (ACC_ON-OFF=76.0\\pm7.2). Notably, models\ntrained on ON-medication data consistently outperformed those trained on\nOFF-medication data within their respective states (ACC_ON-ON=80.7\\pm7.1 and\nACC_OFF-OFF=56.2\\pm8.7). Our findings suggest that medication state\nsignificantly influences the patterns learned by AI models. Addressing this\nchallenge is essential to enhance the robustness and clinical utility of AI\nmodels for PD characterization and management.", "published": "2025-03-27 21:24:47", "link": "http://arxiv.org/abs/2503.21992v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Near-Field Beam Training with DFT Codebook based on Beam Pattern Analysis", "abstract": "Extremely large antenna arrays (ELAAs) operating in high-frequency bands have\nspurred the development of near-field communication, driving advancements in\nbeam training and signal processing design. This paper proposed an efficient\nnear-field beam training method using the discrete Fourier transform (DFT)\ncodebook that is conventionally used for far-field users (FUs). We begin by\nanalyzing the received beam pattern and deriving a closed-form expression for\nits width and central beam gain, which are validated through simulations. Using\nthese derivations, we define a modified Rayleigh distance to distinguish\nbetween near-field and far-field users. Building on this, we propose a beam\ntraining method capable of simultaneously estimating user angle and distance\nwith a complexity of O(1). Simulation results confirm the effectiveness of our\nproposed approach, demonstrating its capability for low-complexity near-field\nbeam training while achieving high estimation accuracy.", "published": "2025-03-27 19:59:47", "link": "http://arxiv.org/abs/2503.21954v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enhancing Mobile Crowdsensing Efficiency: A Coverage-aware Resource Allocation Approach", "abstract": "In this study, we investigate the resource management challenges in\nnext-generation mobile crowdsensing networks with the goal of minimizing task\ncompletion latency while ensuring coverage performance, i.e., an essential\nmetric to ensure comprehensive data collection across the monitored area, yet\nit has been commonly overlooked in existing studies. To this end, we formulate\na weighted latency and coverage gap minimization problem via jointly optimizing\nuser selection, subchannel allocation, and sensing task allocation. The\nformulated minimization problem is a non-convex mixed-integer programming\nissue. To facilitate the analysis, we decompose the original optimization\nproblem into two subproblems. One focuses on optimizing sensing task and\nsubband allocation under fixed sensing user selection, which is optimally\nsolved by the Hungarian algorithm via problem reformulation. Building upon\nthese findings, we introduce a time-efficient two-sided swapping method to\nrefine the scheduled user set and enhance system performance. Extensive\nnumerical results demonstrate the effectiveness of our proposed approach\ncompared to various benchmark strategies.", "published": "2025-03-27 19:40:27", "link": "http://arxiv.org/abs/2503.21942v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Leveraging Line-of-Sight Propagation for Near-Field Beamfocusing in Cell-Free Networks", "abstract": "Cell-free (CF) massive multiple-input multiple-output (MIMO) is a promising\napproach for next-generation wireless networks, enabling scalable deployments\nof multiple small access points (APs) to enhance coverage and service for\nmultiple user equipments (UEs). While most existing research focuses on\nlow-frequency bands with Rayleigh fading models, emerging 5G trends are\nshifting toward higher frequencies, where geometric channel models and\nline-of-sight (LoS) propagation become more relevant. In this work, we explore\nhow distributed massive MIMO in the LoS regime can achieve near-field-like\nconditions by forming artificially large arrays through coordinated AP\ndeployments. We investigate centralized and decentralized CF architectures,\nleveraging structured channel estimation (SCE) techniques that exploit the\nline-of-sight properties of geometric channels. Our results demonstrate that\ndense distributed AP deployments significantly improve system performance\nw.r.t. the case of a co-located array, even in highly populated UE scenarios,\nwhile SCE approaches the performance of perfect CSI.", "published": "2025-03-27 15:20:32", "link": "http://arxiv.org/abs/2503.21599v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Real-time Tracking System with partially coupled sources", "abstract": "We consider a pull-based real-time tracking system consisting of multiple\npartially coupled sources and a sink. The sink monitors the sources in\nreal-time and can request one source for an update at each time instant. The\nsources send updates over an unreliable wireless channel. The sources are\npartially coupled, and updates about one source can provide partial knowledge\nabout other sources. We study the problem of minimizing the sum of an average\ndistortion function and a transmission cost. Since the controller is at the\nsink side, the controller (sink) has only partial knowledge about the source\nstates, and thus, we model the problem as a partially observable Markov\ndecision process (POMDP) and then cast it as a belief-MDP problem. Using the\nrelative value iteration algorithm, we solve the problem and propose a control\npolicy. Simulation results show the proposed policy's effectiveness and\nsuperiority compared to a baseline policy.", "published": "2025-03-27 14:39:49", "link": "http://arxiv.org/abs/2503.21552v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Shape Adaptive Reconfigurable Holographic Surfaces", "abstract": "Reconfigurable Intelligent Surfaces (RIS) have emerged as a key solution to\ndynamically adjust wireless propagation by tuning the reflection coefficients\nof large arrays of passive elements. Reconfigurable Holographic Surfaces (RHS)\nbuild on the same foundation as RIS but extend it by employing holographic\nprinciples for finer-grained wave manipulation | that is, applying higher\nspatial control over the reflected signals for more precise beam steering. In\nthis paper, we investigate shape-adaptive RHS deployments in a multi-user\nnetwork. Rather than treating each RHS as a uniform reflecting surface, we\npropose a selective element activation strategy that dynamically adapts the\nspatial arrangement of deployed RHS regions to a subset of predefined shapes.\nIn particular, we formulate a system throughput maximization problem that\noptimizes the shape of the selected RHS elements, active beamforming at the\naccess point (AP), and passive beamforming at the RHS to enhance coverage and\nmitigate signal blockage. The resulting problem is non-convex and becomes even\nmore challenging to solve as the number of RHS and users increases; to tackle\nthis, we introduce an alternating optimization (AO) approach that efficiently\nfinds near-optimal solutions irrespective of the number or spatial\nconfiguration of RHS. Numerical results demonstrate that shape adaptation\nenables more efficient resource distribution, enhancing the effectiveness of\nmulti-RHS deployments as the network scales.", "published": "2025-03-27 14:33:19", "link": "http://arxiv.org/abs/2503.21542v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Polarization-Aware Antenna Selection for Joint Radar and Communication in XL-MIMO Systems", "abstract": "A key challenge in dual-polarized multiplexing for joint radar and\ncommunication (JRC) systems is cross-polarization (cross-pol) leakage caused by\ndepolarization. In conventional MIMO systems, depolarization arises solely from\nthe channel; however, in XL-MIMO systems, non-stationary properties of the\narray cause additional polarization shifts at each antenna element, further\ndegrading JRC performance. This paper introduces a channel model incorporating\npolarization shifts due to the propagation channel and antenna elements in the\nnear-field. We also propose an antenna selection (AS) scheme that dynamically\nchooses antennas based on polarization imbalance and cross-pol leakage,\nenhancing spectral efficiency, symbol error rate, and radar detection\nprobability. Simulations show that the proposed AS significantly outperforms\ntraditional methods, providing scalable benefits for XL-MIMO JRC systems.", "published": "2025-03-27 14:29:05", "link": "http://arxiv.org/abs/2503.21537v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Brain Age Group Classification Based on Resting State Functional Connectivity Metrics", "abstract": "This study investigated age-related changes in functional connectivity using\nresting-state fMRI and explored the efficacy of traditional deep learning for\nclassifying brain developmental stages (BDS). Functional connectivity was\nassessed using Seed-Based Phase Synchronization (SBPS) and Pearson correlation\nacross 160 ROIs. Clustering was performed using t-SNE, and network topology was\nanalyzed through graph-theoretic metrics. Adaptive learning was implemented to\nclassify the age group by extracting bottleneck features through mobileNetV2.\nThese deep features were embedded and classified using Random Forest and PCA.\nResults showed a shift in phase synchronization patterns from sensory-driven\nnetworks in youth to more distributed networks with aging. t-SNE revealed that\nSBPS provided the most distinct clustering of BDS. Global efficiency and\nparticipation coefficient followed an inverted U-shaped trajectory, while\nclustering coefficient and modularity exhibited a U-shaped pattern. MobileNet\noutperformed other models, achieving the highest classification accuracy for\nBDS. Aging was associated with reduced global integration and increased local\nconnectivity, indicating functional network reorganization. While this study\nfocused solely on functional connectivity from resting-state fMRI and a limited\nset of connectivity features, deep learning demonstrated superior\nclassification performance, highlighting its potential for characterizing\nage-related brain changes.", "published": "2025-03-27 12:05:12", "link": "http://arxiv.org/abs/2503.21414v1", "categories": ["q-bio.NC", "eess.SP"], "primary_category": "q-bio.NC"}
{"title": "G{\u00e9}n{\u00e9}ration de Matrices de Corr{\u00e9}lation avec des Structures de Graphe par Optimisation Convexe", "abstract": "This work deals with the generation of theoretical correlation matrices with\nspecific sparsity patterns, associated to graph structures. We present a novel\napproach based on convex optimization, offering greater flexibility compared to\nexisting techniques, notably by controlling the mean of the entry distribution\nin the generated correlation matrices. This allows for the generation of\ncorrelation matrices that better represent realistic data and can be used to\nbenchmark statistical methods for graph inference.", "published": "2025-03-27 09:24:42", "link": "http://arxiv.org/abs/2503.21298v1", "categories": ["eess.SP", "math.OC", "math.ST", "stat.ME", "stat.TH"], "primary_category": "eess.SP"}
{"title": "Low-Cost Phase Precoding for Short-Reach Fiber Links with Direct Detection", "abstract": "Low-cost analog phase precoding is used to compensate chromatic dispersion\n(CD) in fibers with intensity modulation and direct detection (IM/DD). In\ncontrast to conventional precoding with an in-phase and quadrature (IQ)\nMach-Zehnder modulator (MZM), only a single additional phase modulator (PM) is\nrequired at the transmitter. Depending on the CD, the PM generates a periodic\nphase modulation that is modelled by a Fourier series and optimized via a mean\nsquared error (MSE) cost criterion. Numerical results compare achievable\ninformation rates (AIRs) for 4- and 6-PAM. With the additional PM, energy gains\nof up to 3 dB are achieved for moderate fiber lengths.", "published": "2025-03-27 09:01:44", "link": "http://arxiv.org/abs/2503.21282v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "PLAIN: Scalable Estimation Architecture for Integrated Sensing and Communication", "abstract": "Integrated sensing and communication (ISAC) is envisioned be to one of the\nparadigms upon which next-generation mobile networks will be built, extending\nlocalization and tracking capabilities, as well as giving birth to\nenvironment-aware wireless access. A key aspect of sensing integration is\nparameter estimation, which involves extracting information about the\nsurrounding environment, such as the direction, distance, and velocity of\nvarious objects within. This is typically of a high-dimensional nature, which\nleads to significant computational complexity, if performed jointly across\nmultiple sensing dimensions, such as space, frequency, and time. Additionally,\ndue to the incorporation of sensing on top of the data transmission, the time\nwindow available for sensing is likely to be short, resulting in an estimation\nproblem where only a single snapshot is accessible. In this work, we propose\nPLAIN, a tensor-based estimation architecture that flexibly scales with\nmultiple sensing dimensions and can handle high dimensionality, limited\nmeasurement time, and super-resolution requirements. It consists of three\nstages: a compression stage, where the high dimensional input is converted into\nlower dimensionality, without sacrificing resolution; a decoupled estimation\nstage, where the parameters across the different dimensions are estimated in\nparallel with low complexity; an input-based fusion stage, where the decoupled\nparameters are fused together to form a paired multidimensional estimate. We\ninvestigate the performance of the architecture for different configurations\nand compare it against practical sequential and joint estimation baselines, as\nwell as theoretical bounds. Our results show that PLAIN, using tools from\ntensor algebra, subspace-based processing, and compressed sensing, can scale\nflexibly with dimensionality, while operating with low complexity and\nmaintaining super-resolution.", "published": "2025-03-27 08:04:46", "link": "http://arxiv.org/abs/2503.21242v1", "categories": ["eess.SP", "cs.CV"], "primary_category": "eess.SP"}
{"title": "The Optimal Tradeoff Between PAPR and Ambiguity Functions for Generalized OFDM Waveform Set in ISAC Systems", "abstract": "Integrated sensing and communications (ISAC) has been identified as one of\nthe six usage scenarios for IMT-2030. Compared with communication performance,\nsensing performance is much more vulnerable to interference, and the received\nbackscattered sensing signal with target information is usually too weak to be\ndetected. It is interesting to understand the optimal tradeoff between\ninterference rejection and signal strength improvement for the best sensing\nperformance, but unfortunately it still remains unknown. In this paper, the\ntrinity of auto-ambiguity function (AF), cross-AF and peak-to-average-power\nratio (PAPR) is proposed to describe the interference and coverage related\naspects for ISAC systems where multi-carrier waveform is usually assumed. We\nextend the existing orthogonal frequency division multiplexing (OFDM) waveforms\nin 5G to a generalized OFDM waveform set with some new members and a unified\nparametric representation. Then the optimal Pareto tradeoff between PAPR,\nauto-AF and cross-AF (i.e., the union bound) is developed for the generalized\nOFDM waveform set. To achieve the optimal Pareto union bound with reasonable\ncomputational complexity, we further propose a framework to optimize waveform\nparameters and sequences jointly. Finally, some practical design examples are\nprovided and numerical results reveal that significant improvements can be\nachieved compared to the state-of-the-art 5G waveforms and sequences.", "published": "2025-03-27 07:59:04", "link": "http://arxiv.org/abs/2503.21239v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fundamental Limit of Angular Resolution in Partly Calibrated Arrays with Position Errors", "abstract": "We consider high angular resolution detection using distributed mobile\nplatforms implemented with so-called partly calibrated arrays, where position\nerrors between subarrays exist and the counterparts within each subarray are\nideally calibrated. Since position errors between antenna arrays affect the\ncoherent processing of measurements from these arrays, it is commonly believed\nthat its angular resolution is influenced. A key question is whether and how\nmuch the angular resolution of partly calibrated arrays is affected by the\nposition errors, in comparison with ideally calibrated arrays. To address this\nfundamental problem, we theoretically illustrate that partly calibrated arrays\napproximately achieve high angular resolution. Our analysis uses a special\ncharacteristic of Cramer-Rao lower bound (CRB) w.r.t. the source separation:\nWhen the source separation increases, the CRB first declines rapidly, then\nplateaus out, and the turning point is close to the angular resolution limit.\nThis means that the turning point of CRB can be used to indicate angular\nresolution. We then theoretically analyze the declining and plateau phases of\nCRB, and explain that the turning point of CRB in partly calibrated arrays is\nclose to the angular resolution limit of distributed arrays without errors,\ndemonstrating high resolution ability. This work thus provides a theoretical\nguarantee for the high-resolution performance of distributed antenna arrays in\nmobile platforms.", "published": "2025-03-27 03:03:38", "link": "http://arxiv.org/abs/2503.21110v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "In-situ Physical Adjoint Computing in multiple-scattering electromagnetic environments for wave control", "abstract": "Controlling electromagnetic wave propagation in multiple scattering systems\nis a challenging endeavor due to the extraordinary sensitivity generated by\nstrong multi-path contributions at any given location. Overcoming such\ncomplexity has emerged as a central research theme in recent years, motivated\nboth by a wide range of applications -- from wireless communications and\nimaging to optical micromanipulations -- and by the fundamental principles\nunderlying these efforts. Here, we show that an {\\it in-situ} manipulation of\nthe myriad scattering events, achieved through time- and energy-efficient\nadjoint optimization (AO) methodologies, enables {\\it real time} wave-driven\nfunctionalities such as targeted channel emission, coherent perfect absorption,\nand camouflage. Our paradigm shift exploits the highly multi-path nature of\nthese complex environments, where repeated wave-scattering dramatically\namplifies small local AO-informed system variations. Our approach can be\nimmediately applied to in-door wireless technologies and incorporated into\ndiverse wave-based frameworks including imaging, power electronic and optical\nneural networks.", "published": "2025-03-27 03:01:49", "link": "http://arxiv.org/abs/2503.21107v1", "categories": ["eess.SP", "nlin.CD", "physics.optics"], "primary_category": "eess.SP"}
{"title": "Amplitude-Domain Reflection Modulation for Active RIS-Assisted Wireless Communications", "abstract": "In this paper, we propose a novel active reconfigurable intelligent surface\n(RIS)-assisted amplitude-domain reflection modulation (ADRM) transmission\nscheme, termed as ARIS-ADRM. This innovative approach leverages the additional\ndegree of freedom (DoF) provided by the amplitude domain of the active RIS to\nperform index modulation (IM), thereby enhancing spectral efficiency (SE)\nwithout increasing the costs associated with additional radio frequency (RF)\nchains. Specifically, the ARIS-ADRM scheme transmits information bits through\nboth the modulation symbol and the index of active RIS amplitude allocation\npatterns (AAPs). To evaluate the performance of the proposed ARIS-ADRM scheme,\nwe provide an achievable rate analysis and derive a closed-form expression for\nthe upper bound on the average bit error probability (ABEP). Furthermore, we\nformulate an optimization problem to construct the AAP codebook, aiming to\nminimize the ABEP. Simulation results demonstrate that the proposed scheme\nsignificantly improves error performance under the same SE conditions compared\nto its benchmarks. This improvement is due to its ability to flexibly adapt the\ntransmission rate by fully exploiting the amplitude domain DoF provided by the\nactive RIS.", "published": "2025-03-27 02:49:09", "link": "http://arxiv.org/abs/2503.21102v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "5.7 Tb/s Transmission Over a 4.6 km Field-Deployed Free-Space Optical Link in Urban Environment", "abstract": "We transmitted 5.7 Tb/s over a 4.6 km free-space optical link in an urban\nenvironment, spanning the city of Eindhoven, the Netherlands, using a 1.1 THz\nwide wavelength-division multiplexed signal.", "published": "2025-03-27 00:14:04", "link": "http://arxiv.org/abs/2503.21058v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad", "abstract": "Recent math benchmarks for large language models (LLMs) such as MathArena\nindicate that state-of-the-art reasoning models achieve impressive performance\non mathematical competitions like AIME, with the leading model, Gemini-2.5-Pro,\nachieving scores comparable to top human competitors. However, these benchmarks\nevaluate models solely based on final numerical answers, neglecting rigorous\nreasoning and proof generation which are essential for real-world mathematical\ntasks. To address this, we introduce the first comprehensive evaluation of\nfull-solution reasoning for challenging mathematical problems. Using expert\nhuman annotators, we evaluated several state-of-the-art reasoning models on the\nsix problems from the 2025 USAMO within hours of their release. Our results\nreveal that all tested models struggled significantly: only Gemini-2.5-Pro\nachieves a non-trivial score of 25%, while all other models achieve less than\n5%. Through detailed analysis of reasoning traces, we identify the most common\nfailure modes and find several unwanted artifacts arising from the optimization\nstrategies employed during model training. Overall, our results suggest that\ncurrent LLMs are inadequate for rigorous mathematical reasoning tasks,\nhighlighting the need for substantial improvements in reasoning and proof\ngeneration capabilities.", "published": "2025-03-27 19:21:05", "link": "http://arxiv.org/abs/2503.21934v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Outlier dimensions favor frequent tokens in language models", "abstract": "We study last-layer outlier dimensions, i.e. dimensions that display extreme\nactivations for the majority of inputs. We show that outlier dimensions arise\nin many different modern language models, and trace their function back to the\nheuristic of constantly predicting frequent words. We further show how a model\ncan block this heuristic when it is not contextually appropriate, by assigning\na counterbalancing weight mass to the remaining dimensions, and we investigate\nwhich model parameters boost outlier dimensions and when they arise during\ntraining. We conclude that outlier dimensions are a specialized mechanism\ndiscovered by many distinct models to implement a useful token prediction\nheuristic.", "published": "2025-03-27 17:30:50", "link": "http://arxiv.org/abs/2503.21718v3", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
