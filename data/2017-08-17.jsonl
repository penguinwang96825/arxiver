{"title": "Natural Language Processing: State of The Art, Current Trends and\n  Challenges", "abstract": "Natural language processing (NLP) has recently gained much attention for\nrepresenting and analysing human language computationally. It has spread its\napplications in various fields such as machine translation, email spam\ndetection, information extraction, summarization, medical, and question\nanswering etc. The paper distinguishes four phases by discussing different\nlevels of NLP and components of Natural Language Generation (NLG) followed by\npresenting the history and evolution of NLP, state of the art presenting the\nvarious applications of NLP and current trends and challenges.", "published": "2017-08-17 06:42:03", "link": "http://arxiv.org/abs/1708.05148v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Syntactic Iberian Polarity Classification", "abstract": "Lexicon-based methods using syntactic rules for polarity classification rely\non parsers that are dependent on the language and on treebank guidelines. Thus,\nrules are also dependent and require adaptation, especially in multilingual\nscenarios. We tackle this challenge in the context of the Iberian Peninsula,\nreleasing the first symbolic syntax-based Iberian system with rules shared\nacross five official languages: Basque, Catalan, Galician, Portuguese and\nSpanish. The model is made available.", "published": "2017-08-17 13:50:39", "link": "http://arxiv.org/abs/1708.05269v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple Open Stance Classification for Rumour Analysis", "abstract": "Stance classification determines the attitude, or stance, in a (typically\nshort) text. The task has powerful applications, such as the detection of fake\nnews or the automatic extraction of attitudes toward entities or events in the\nmedia. This paper describes a surprisingly simple and efficient classification\napproach to open stance classification in Twitter, for rumour and veracity\nclassification. The approach profits from a novel set of automatically\nidentifiable problem-specific features, which significantly boost classifier\naccuracy and achieve above state-of-the-art results on recent benchmark\ndatasets. This calls into question the value of using complex sophisticated\nmodels for stance classification without first doing informed feature\nextraction.", "published": "2017-08-17 14:06:58", "link": "http://arxiv.org/abs/1708.05286v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Annotated Corpus of Relational Strategies in Customer Service", "abstract": "We create and release the first publicly available commercial customer\nservice corpus with annotated relational segments. Human-computer data from\nthree live customer service Intelligent Virtual Agents (IVAs) in the domains of\ntravel and telecommunications were collected, and reviewers marked all text\nthat was deemed unnecessary to the determination of user intention. After\nmerging the selections of multiple reviewers to create highlighted texts, a\nsecond round of annotation was done to determine the classes of language\npresent in the highlighted sections such as the presence of Greetings,\nBackstory, Justification, Gratitude, Rants, or Emotions. This resulting corpus\nis a valuable resource for improving the quality and relational abilities of\nIVAs. As well as discussing the corpus itself, we compare the usage of such\nlanguage in human-human interactions on TripAdvisor forums. We show that\nremoval of this language from task-based inputs has a positive effect on IVA\nunderstanding by both an increase in confidence and improvement in responses,\ndemonstrating the need for automated methods of its discovery.", "published": "2017-08-17 21:57:47", "link": "http://arxiv.org/abs/1708.05449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large-Scale Domain Adaptation via Teacher-Student Learning", "abstract": "High accuracy speech recognition requires a large amount of transcribed data\nfor supervised training. In the absence of such data, domain adaptation of a\nwell-trained acoustic model can be performed, but even here, high accuracy\nusually requires significant labeled data from the target domain. In this work,\nwe propose an approach to domain adaptation that does not require\ntranscriptions but instead uses a corpus of unlabeled parallel data, consisting\nof pairs of samples from the source domain of the well-trained model and the\ndesired target domain. To perform adaptation, we employ teacher/student (T/S)\nlearning, in which the posterior probabilities generated by the source-domain\nmodel can be used in lieu of labels to train the target-domain model. We\nevaluate the proposed approach in two scenarios, adapting a clean acoustic\nmodel to noisy speech and adapting an adults speech acoustic model to children\nspeech. Significant improvements in accuracy are obtained, with reductions in\nword error rate of up to 44% over the original source model without the need\nfor transcribed data in the target domain. Moreover, we show that increasing\nthe amount of unlabeled data results in additional model robustness, which is\nparticularly beneficial when using simulated training data in the\ntarget-domain.", "published": "2017-08-17 23:37:18", "link": "http://arxiv.org/abs/1708.05466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Copying Mechanism in Image Captioning for Learning Novel\n  Objects", "abstract": "Image captioning often requires a large set of training image-sentence pairs.\nIn practice, however, acquiring sufficient training pairs is always expensive,\nmaking the recent captioning models limited in their ability to describe\nobjects outside of training corpora (i.e., novel objects). In this paper, we\npresent Long Short-Term Memory with Copying Mechanism (LSTM-C) --- a new\narchitecture that incorporates copying into the Convolutional Neural Networks\n(CNN) plus Recurrent Neural Networks (RNN) image captioning framework, for\ndescribing novel objects in captions. Specifically, freely available object\nrecognition datasets are leveraged to develop classifiers for novel objects.\nOur LSTM-C then nicely integrates the standard word-by-word sentence generation\nby a decoder RNN with copying mechanism which may instead select words from\nnovel objects at proper places in the output sentence. Extensive experiments\nare conducted on both MSCOCO image captioning and ImageNet datasets,\ndemonstrating the ability of our proposed LSTM-C architecture to describe novel\nobjects. Furthermore, superior results are reported when compared to\nstate-of-the-art deep models.", "published": "2017-08-17 13:51:39", "link": "http://arxiv.org/abs/1708.05271v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evaluating Visual Conversational Agents via Cooperative Human-AI Games", "abstract": "As AI continues to advance, human-AI teams are inevitable. However, progress\nin AI is routinely measured in isolation, without a human in the loop. It is\ncrucial to benchmark progress in AI, not just in isolation, but also in terms\nof how it translates to helping humans perform certain tasks, i.e., the\nperformance of human-AI teams.\n  In this work, we design a cooperative game - GuessWhich - to measure human-AI\nteam performance in the specific context of the AI being a visual\nconversational agent. GuessWhich involves live interaction between the human\nand the AI. The AI, which we call ALICE, is provided an image which is unseen\nby the human. Following a brief description of the image, the human questions\nALICE about this secret image to identify it from a fixed pool of images.\n  We measure performance of the human-ALICE team by the number of guesses it\ntakes the human to correctly identify the secret image after a fixed number of\ndialog rounds with ALICE. We compare performance of the human-ALICE teams for\ntwo versions of ALICE. Our human studies suggest a counterintuitive trend -\nthat while AI literature shows that one version outperforms the other when\npaired with an AI questioner bot, we find that this improvement in AI-AI\nperformance does not translate to improved human-AI performance. This suggests\na mismatch between benchmarking of AI in isolation and in the context of\nhuman-AI teams.", "published": "2017-08-17 03:27:53", "link": "http://arxiv.org/abs/1708.05122v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.HC"}
{"title": "An Improved Residual LSTM Architecture for Acoustic Modeling", "abstract": "Long Short-Term Memory (LSTM) is the primary recurrent neural networks\narchitecture for acoustic modeling in automatic speech recognition systems.\nResidual learning is an efficient method to help neural networks converge\neasier and faster. In this paper, we propose several types of residual LSTM\nmethods for our acoustic modeling. Our experiments indicate that, compared with\nclassic LSTM, our architecture shows more than 8% relative reduction in Phone\nError Rate (PER) on TIMIT tasks. At the same time, our residual fast LSTM\napproach shows 4% relative reduction in PER on the same task. Besides, we find\nthat all this architecture could have good results on THCHS-30, Librispeech and\nSwitchboard corpora.", "published": "2017-08-17 01:37:21", "link": "http://arxiv.org/abs/1708.05682v1", "categories": ["cs.CL", "cs.AI", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Automatic Organisation and Quality Analysis of User-Generated Content\n  with Audio Fingerprinting", "abstract": "The increase of the quantity of user-generated content experienced in social\nmedia has boosted the importance of analysing and organising the content by its\nquality. Here, we propose a method that uses audio fingerprinting to organise\nand infer the quality of user-generated audio content. The proposed method\ndetects the overlapping segments between different audio clips to organise and\ncluster the data according to events, and to infer the audio quality of the\nsamples. A test setup with concert recordings manually crawled from YouTube is\nused to validate the presented method. The results show that the proposed\nmethod achieves better results than previous methods.", "published": "2017-08-17 14:08:09", "link": "http://arxiv.org/abs/1708.05291v1", "categories": ["eess.AS", "cs.MM"], "primary_category": "eess.AS"}
{"title": "Automatic Organisation, Segmentation, and Filtering of User-Generated\n  Audio Content", "abstract": "Using solely the information retrieved by audio fingerprinting techniques, we\npropose methods to treat a possibly large dataset of user-generated audio\ncontent, that (1) enable the grouping of several audio files that contain a\ncommon audio excerpt (i.e., are relative to the same event), and (2) give\ninformation about how those files are correlated in terms of time and quality\ninside each event. Furthermore, we use supervised learning to detect incorrect\nmatches that may arise from the audio fingerprinting algorithm itself, whilst\nensuring our model learns with previous predictions. All the presented methods\nwere further validated by user-generated recordings of several different\nconcerts manually crawled from YouTube.", "published": "2017-08-17 14:19:17", "link": "http://arxiv.org/abs/1708.05302v1", "categories": ["eess.AS", "cs.IR", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
