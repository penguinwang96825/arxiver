{"title": "Top-down Tree Long Short-Term Memory Networks", "abstract": "Long Short-Term Memory (LSTM) networks, a type of recurrent neural network\nwith a more complex computational unit, have been successfully applied to a\nvariety of sequence modeling tasks. In this paper we develop Tree Long\nShort-Term Memory (TreeLSTM), a neural network model based on LSTM, which is\ndesigned to predict a tree rather than a linear sequence. TreeLSTM defines the\nprobability of a sentence by estimating the generation probability of its\ndependency tree. At each time step, a node is generated based on the\nrepresentation of the generated sub-tree. We further enhance the modeling power\nof TreeLSTM by explicitly representing the correlations between left and right\ndependents. Application of our model to the MSR sentence completion challenge\nachieves results beyond the current state of the art. We also report results on\ndependency parsing reranking achieving competitive performance.", "published": "2015-10-31 02:05:28", "link": "http://arxiv.org/abs/1511.00060v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
