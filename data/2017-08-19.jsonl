{"title": "CLaC @ QATS: Quality Assessment for Text Simplification", "abstract": "This paper describes our approach to the 2016 QATS quality assessment shared\ntask. We trained three independent Random Forest classifiers in order to assess\nthe quality of the simplified texts in terms of grammaticality, meaning\npreservation and simplicity. We used the language model of Google-Ngram as\nfeature to predict the grammaticality. Meaning preservation is predicted using\ntwo complementary approaches based on word embedding and WordNet synonyms. A\nwider range of features including TF-IDF, sentence length and frequency of cue\nphrases are used to evaluate the simplicity aspect. Overall, the accuracy of\nthe system ranges from 33.33% for the overall aspect to 58.73% for\ngrammaticality.", "published": "2017-08-19 03:18:50", "link": "http://arxiv.org/abs/1708.05797v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The CLaC Discourse Parser at CoNLL-2016", "abstract": "This paper describes our submission \"CLaC\" to the CoNLL-2016 shared task on\nshallow discourse parsing. We used two complementary approaches for the task. A\nstandard machine learning approach for the parsing of explicit relations, and a\ndeep learning approach for non-explicit relations. Overall, our parser achieves\nan F1-score of 0.2106 on the identification of discourse relations (0.3110 for\nexplicit relations and 0.1219 for non-explicit relations) on the blind\nCoNLL-2016 test set.", "published": "2017-08-19 03:19:40", "link": "http://arxiv.org/abs/1708.05798v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Contribution of Discourse Structure on Text Complexity Assessment", "abstract": "This paper investigates the influence of discourse features on text\ncomplexity assessment. To do so, we created two data sets based on the Penn\nDiscourse Treebank and the Simple English Wikipedia corpora and compared the\ninfluence of coherence, cohesion, surface, lexical and syntactic features to\nassess text complexity.\n  Results show that with both data sets coherence features are more correlated\nto text complexity than the other types of features. In addition, feature\nselection revealed that with both data sets the top most discriminating feature\nis a coherence feature.", "published": "2017-08-19 03:20:43", "link": "http://arxiv.org/abs/1708.05800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ClaC: Semantic Relatedness of Words and Phrases", "abstract": "The measurement of phrasal semantic relatedness is an important metric for\nmany natural language processing applications. In this paper, we present three\napproaches for measuring phrasal semantics, one based on a semantic network\nmodel, another on a distributional similarity model, and a hybrid between the\ntwo. Our hybrid approach achieved an F-measure of 77.4% on the task of\nevaluating the semantic similarity of words and compositional phrases.", "published": "2017-08-19 03:37:38", "link": "http://arxiv.org/abs/1708.05801v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring the Effect of Discourse Relations on Blog Summarization", "abstract": "The work presented in this paper attempts to evaluate and quantify the use of\ndiscourse relations in the context of blog summarization and compare their use\nto more traditional and factual texts. Specifically, we measured the usefulness\nof 6 discourse relations - namely comparison, contingency, illustration,\nattribution, topic-opinion, and attributive for the task of text summarization\nfrom blogs. We have evaluated the effect of each relation using the TAC 2008\nopinion summarization dataset and compared them with the results with the DUC\n2007 dataset. The results show that in both textual genres, contingency,\ncomparison, and illustration relations provide a significant improvement on\nsummarization content; while attribution, topic-opinion, and attributive\nrelations do not provide a consistent and significant improvement. These\nresults indicate that, at least for summarization, discourse relations are just\nas useful for informal and affective texts as for more traditional news\narticles.", "published": "2017-08-19 04:01:43", "link": "http://arxiv.org/abs/1708.05803v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The CLaC Discourse Parser at CoNLL-2015", "abstract": "This paper describes our submission (kosseim15) to the CoNLL-2015 shared task\non shallow discourse parsing. We used the UIMA framework to develop our parser\nand used ClearTK to add machine learning functionality to the UIMA framework.\nOverall, our parser achieves a result of 17.3 F1 on the identification of\ndiscourse relations on the blind CoNLL-2015 test set, ranking in sixth place.", "published": "2017-08-19 14:43:50", "link": "http://arxiv.org/abs/1708.05857v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Multi-Dialect Segmentation: bi-LSTM-CRF vs. SVM", "abstract": "Arabic word segmentation is essential for a variety of NLP applications such\nas machine translation and information retrieval. Segmentation entails breaking\nwords into their constituent stems, affixes and clitics. In this paper, we\ncompare two approaches for segmenting four major Arabic dialects using only\nseveral thousand training examples for each dialect. The two approaches involve\nposing the problem as a ranking problem, where an SVM ranker picks the best\nsegmentation, and as a sequence labeling problem, where a bi-LSTM RNN coupled\nwith CRF determines where best to segment words. We are able to achieve solid\nsegmentation results for all dialects using rather limited training data. We\nalso show that employing Modern Standard Arabic data for domain adaptation and\nassuming context independence improve overall results.", "published": "2017-08-19 19:52:36", "link": "http://arxiv.org/abs/1708.05891v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A rule based algorithm for detecting negative words in Persian", "abstract": "In this paper, we present a novel method for detecting negative words in\nPersian. We first used an algorithm to an exceptions list which was later\nmodified by hand. We then used the mentioned lists and a Persian polarity\ncorpus in our rule based algorithm to detect negative words.", "published": "2017-08-19 18:18:22", "link": "http://arxiv.org/abs/1708.06708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Drives the International Development Agenda? An NLP Analysis of the\n  United Nations General Debate 1970-2016", "abstract": "There is surprisingly little known about agenda setting for international\ndevelopment in the United Nations (UN) despite it having a significant\ninfluence on the process and outcomes of development efforts. This paper\naddresses this shortcoming using a novel approach that applies natural language\nprocessing techniques to countries' annual statements in the UN General Debate.\nEvery year UN member states deliver statements during the General Debate on\ntheir governments' perspective on major issues in world politics. These\nspeeches provide invaluable information on state preferences on a wide range of\nissues, including international development, but have largely been overlooked\nin the study of global politics. This paper identifies the main international\ndevelopment topics that states raise in these speeches between 1970 and 2016,\nand examine the country-specific drivers of international development rhetoric.", "published": "2017-08-19 16:39:19", "link": "http://arxiv.org/abs/1708.05873v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
