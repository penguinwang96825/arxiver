{"title": "Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral\n  Codes", "abstract": "Automatically analyzing dialogue can help understand and guide behavior in\ndomains such as counseling, where interactions are largely mediated by\nconversation. In this paper, we study modeling behavioral codes used to asses a\npsychotherapy treatment style called Motivational Interviewing (MI), which is\neffective for addressing substance abuse and related problems. Specifically, we\naddress the problem of providing real-time guidance to therapists with a\ndialogue observer that (1) categorizes therapist and client MI behavioral codes\nand, (2) forecasts codes for upcoming utterances to help guide the conversation\nand potentially alert the therapist. For both tasks, we define neural network\nmodels that build upon recent successes in dialogue modeling. Our experiments\ndemonstrate that our models can outperform several baselines for both tasks. We\nalso report the results of a careful analysis that reveals the impact of the\nvarious network design tradeoffs for modeling therapy dialogue.", "published": "2019-06-30 06:03:32", "link": "http://arxiv.org/abs/1907.00326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Language Model Finetuning Techniques for Low-resource\n  Languages", "abstract": "Unlike mainstream languages (such as English and French), low-resource\nlanguages often suffer from a lack of expert-annotated corpora and benchmark\nresources that make it hard to apply state-of-the-art techniques directly. In\nthis paper, we alleviate this scarcity problem for the low-resourced Filipino\nlanguage in two ways. First, we introduce a new benchmark language modeling\ndataset in Filipino which we call WikiText-TL-39. Second, we show that language\nmodel finetuning techniques such as BERT and ULMFiT can be used to consistently\ntrain robust classifiers in low-resource settings, experiencing at most a\n0.0782 increase in validation error when the number of training examples is\ndecreased from 10K to 1K while finetuning using a privately-held sentiment\ndataset.", "published": "2019-06-30 16:32:28", "link": "http://arxiv.org/abs/1907.00409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Supervised Dialogue Learning", "abstract": "The sequential order of utterances is often meaningful in coherent dialogues,\nand the order changes of utterances could lead to low-quality and incoherent\nconversations. We consider the order information as a crucial supervised signal\nfor dialogue learning, which, however, has been neglected by many previous\ndialogue systems. Therefore, in this paper, we introduce a self-supervised\nlearning task, inconsistent order detection, to explicitly capture the flow of\nconversation in dialogues. Given a sampled utterance pair triple, the task is\nto predict whether it is ordered or misordered. Then we propose a\nsampling-based self-supervised network SSN to perform the prediction with\nsampled triple references from previous dialogue history. Furthermore, we\ndesign a joint learning framework where SSN can guide the dialogue systems\ntowards more coherent and relevant dialogue learning through adversarial\ntraining. We demonstrate that the proposed methods can be applied to both\nopen-domain and task-oriented dialogue scenarios, and achieve the new\nstate-of-the-art performance on the OpenSubtitiles and Movie-Ticket Booking\ndatasets.", "published": "2019-06-30 20:17:52", "link": "http://arxiv.org/abs/1907.00448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Reading Comprehension: a Literature Review", "abstract": "Machine reading comprehension aims to teach machines to understand a text\nlike a human and is a new challenging direction in Artificial Intelligence.\nThis article summarizes recent advances in MRC, mainly focusing on two aspects\n(i.e., corpus and techniques). The specific characteristics of various MRC\ncorpus are listed and compared. The main ideas of some typical MRC techniques\nare also described.", "published": "2019-06-30 09:18:31", "link": "http://arxiv.org/abs/1907.01686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mechanisms of Artistic Creativity in Deep Learning Neural Networks", "abstract": "The generative capabilities of deep learning neural networks (DNNs) have been\nattracting increasing attention for both the remarkable artifacts they produce,\nbut also because of the vast conceptual difference between how they are\nprogrammed and what they do. DNNs are 'black boxes' where high-level behavior\nis not explicitly programmed, but emerges from the complex interactions of\nthousands or millions of simple computational elements. Their behavior is often\ndescribed in anthropomorphic terms that can be misleading, seem magical, or\nstoke fears of an imminent singularity in which machines become 'more' than\nhuman. In this paper, we examine 5 distinct behavioral characteristics\nassociated with creativity, and provide an example of a mechanisms from\ngenerative deep learning architectures that give rise to each these\ncharacteristics. All 5 emerge from machinery built for purposes other than the\ncreative characteristics they exhibit, mostly classification. These mechanisms\nof creative generative capabilities thus demonstrate a deep kinship to\ncomputational perceptual processes. By understanding how these different\nbehaviors arise, we hope to on one hand take the magic out of anthropomorphic\ndescriptions, but on the other, to build a deeper appreciation of machinic\nforms of creativity on their own terms that will allow us to nurture their\nfurther development.", "published": "2019-06-30 05:29:38", "link": "http://arxiv.org/abs/1907.00321v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inter and Intra Document Attention for Depression Risk Assessment", "abstract": "We take interest in the early assessment of risk for depression in social\nmedia users. We focus on the eRisk 2018 dataset, which represents users as a\nsequence of their written online contributions. We implement four RNN-based\nsystems to classify the users. We explore several aggregations methods to\ncombine predictions on individual posts. Our best model reads through all\nwritings of a user in parallel but uses an attention mechanism to prioritize\nthe most important ones at each timestep.", "published": "2019-06-30 21:09:48", "link": "http://arxiv.org/abs/1907.00462v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Merge and Label: A novel neural network architecture for nested NER", "abstract": "Named entity recognition (NER) is one of the best studied tasks in natural\nlanguage processing. However, most approaches are not capable of handling\nnested structures which are common in many applications. In this paper we\nintroduce a novel neural network architecture that first merges tokens and/or\nentities into entities forming nested structures, and then labels each of them\nindependently. Unlike previous work, our merge and label approach predicts\nreal-valued instead of discrete segmentation structures, which allow it to\ncombine word and nested entity embeddings while maintaining differentiability.\n%which smoothly groups entities into single vectors across multiple levels. We\nevaluate our approach using the ACE 2005 Corpus, where it achieves\nstate-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT)\nto 82.4, an overall improvement of close to 8 F1 points over previous\napproaches trained on the same data. Additionally we compare it against\nBiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that\nits ability to predict nested structures does not impact performance in simpler\ncases.", "published": "2019-06-30 21:12:14", "link": "http://arxiv.org/abs/1907.00464v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The University of Sydney's Machine Translation System for WMT19", "abstract": "This paper describes the University of Sydney's submission of the WMT 2019\nshared news translation task. We participated in the\nFinnish$\\rightarrow$English direction and got the best BLEU(33.0) score among\nall the participants. Our system is based on the self-attentional Transformer\nnetworks, into which we integrated the most recent effective strategies from\nacademic research (e.g., BPE, back translation, multi-features data selection,\ndata augmentation, greedy model ensemble, reranking, ConMBR system combination,\nand post-processing). Furthermore, we propose a novel augmentation method\n$Cycle Translation$ and a data mixture strategy $Big$/$Small$ parallel\nconstruction to entirely exploit the synthetic corpus. Extensive experiments\nshow that adding the above techniques can make continuous improvements of the\nBLEU scores, and the best result outperforms the baseline (Transformer ensemble\nmodel trained with the original parallel corpus) by approximately 5.3 BLEU\nscore, achieving the state-of-the-art performance.", "published": "2019-06-30 22:55:27", "link": "http://arxiv.org/abs/1907.00494v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Novel Bi-directional Interrelated Model for Joint Intent Detection and\n  Slot Filling", "abstract": "A spoken language understanding (SLU) system includes two main tasks, slot\nfilling (SF) and intent detection (ID). The joint model for the two tasks is\nbecoming a tendency in SLU. But the bi-directional interrelated connections\nbetween the intent and slots are not established in the existing joint models.\nIn this paper, we propose a novel bi-directional interrelated model for joint\nintent detection and slot filling. We introduce an SF-ID network to establish\ndirect connections for the two tasks to help them promote each other mutually.\nBesides, we design an entirely new iteration mechanism inside the SF-ID network\nto enhance the bi-directional interrelated connections. The experimental\nresults show that the relative improvement in the sentence-level semantic frame\naccuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets,\nrespectively, compared to the state-of-the-art model.", "published": "2019-06-30 14:54:01", "link": "http://arxiv.org/abs/1907.00390v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multiplicative Models for Recurrent Language Modeling", "abstract": "Recently, there has been interest in multiplicative recurrent neural networks\nfor language modeling. Indeed, simple Recurrent Neural Networks (RNNs)\nencounter difficulties recovering from past mistakes when generating sequences\ndue to high correlation between hidden states. These challenges can be\nmitigated by integrating second-order terms in the hidden-state update. One\nsuch model, multiplicative Long Short-Term Memory (mLSTM) is particularly\ninteresting in its original formulation because of the sharing of its\nsecond-order term, referred to as the intermediate state. We explore these\narchitectural improvements by introducing new models and testing them on\ncharacter-level language modeling tasks. This allows us to establish the\nrelevance of shared parametrization in recurrent language modeling.", "published": "2019-06-30 20:51:43", "link": "http://arxiv.org/abs/1907.00455v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "BERTphone: Phonetically-Aware Encoder Representations for\n  Utterance-Level Speaker and Language Recognition", "abstract": "We introduce BERTphone, a Transformer encoder trained on large speech corpora\nthat outputs phonetically-aware contextual representation vectors that can be\nused for both speaker and language recognition. This is accomplished by\ntraining on two objectives: the first, inspired by adapting BERT to the\ncontinuous domain, involves masking spans of input frames and reconstructing\nthe whole sequence for acoustic representation learning; the second, inspired\nby the success of bottleneck features from ASR, is a sequence-level CTC loss\napplied to phoneme labels for phonetic representation learning. We pretrain two\nBERTphone models (one on Fisher and one on TED-LIUM) and use them as feature\nextractors into x-vector-style DNNs for both tasks. We attain a\nstate-of-the-art $C_{\\text{avg}}$ of 6.16 on the challenging LRE07 3sec\nclosed-set language recognition task. On Fisher and VoxCeleb speaker\nrecognition tasks, we see an 18% relative reduction in speaker EER when\ntraining on BERTphone vectors instead of MFCCs. In general, BERTphone\noutperforms previous phonetic pretraining approaches on the same data. We\nrelease our code and models at\nhttps://github.com/awslabs/speech-representations.", "published": "2019-06-30 20:54:21", "link": "http://arxiv.org/abs/1907.00457v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Analyzing Utility of Visual Context in Multimodal Speech Recognition\n  Under Noisy Conditions", "abstract": "Multimodal learning allows us to leverage information from multiple sources\n(visual, acoustic and text), similar to our experience of the real world.\nHowever, it is currently unclear to what extent auxiliary modalities improve\nperformance over unimodal models, and under what circumstances the auxiliary\nmodalities are useful. We examine the utility of the auxiliary visual context\nin Multimodal Automatic Speech Recognition in adversarial settings, where we\ndeprive the models from partial audio signal during inference time. Our\nexperiments show that while MMASR models show significant gains over\ntraditional speech-to-text architectures (upto 4.2% WER improvements), they do\nnot incorporate visual information when the audio signal has been corrupted.\nThis shows that current methods of integrating the visual modality do not\nimprove model robustness to noise, and we need better visually grounded\nadaptation techniques.", "published": "2019-06-30 21:49:07", "link": "http://arxiv.org/abs/1907.00477v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Topic Modeling the Reading and Writing Behavior of Information Foragers", "abstract": "The general problem of \"information foraging\" in an environment about which\nagents have incomplete information has been explored in many fields, including\ncognitive psychology, neuroscience, economics, finance, ecology, and computer\nscience. In all of these areas, the searcher aims to enhance future performance\nby surveying enough of existing knowledge to orient themselves in the\ninformation space. Individuals can be viewed as conducting a cognitive search\nin which they must balance exploration of ideas that are novel to them against\nexploitation of knowledge in domains in which they are already expert.\n  In this dissertation, I present several case studies that demonstrate how\nreading and writing behaviors interact to construct personal knowledge bases.\nThese studies use LDA topic modeling to represent the information environment\nof the texts each author read and wrote. Three studies revolve around Charles\nDarwin. Darwin left detailed records of every book he read for 23 years, from\ndisembarking from the H.M.S. Beagle to just after publication of The Origin of\nSpecies. Additionally, he left copies of his drafts before publication. I\ncharacterize his reading behavior, then show how that reading behavior\ninteracted with the drafts and subsequent revisions of The Origin of Species,\nand expand the dataset to include later readings and writings. Then, through a\nstudy of Thomas Jefferson's correspondence, I expand the study to non-book\ndata. Finally, through an examination of neuroscience citation data, I move\nfrom individual behavior to collective behavior in constructing an information\nenvironment. Together, these studies reveal \"the interplay between individual\nand collective phenomena where innovation takes place\" (Tria et al. 2014).", "published": "2019-06-30 22:40:37", "link": "http://arxiv.org/abs/1907.00488v1", "categories": ["cs.CL", "cs.CY", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Multilingual Bottleneck Features for Query by Example Spoken Term\n  Detection", "abstract": "State of the art solutions to query by example spoken term detection\n(QbE-STD) usually rely on bottleneck feature representation of the query and\naudio document to perform dynamic time warping (DTW) based template matching.\nHere, we present a study on QbE-STD performance using several monolingual as\nwell as multilingual bottleneck features extracted from feed forward networks.\nThen, we propose to employ residual networks (ResNet) to estimate the\nbottleneck features and show significant improvements over the corresponding\nfeed forward network based features. The neural networks are trained on\nGlobalPhone corpus and QbE-STD experiments are performed on a very challenging\nQUESST 2014 database.", "published": "2019-06-30 20:14:19", "link": "http://arxiv.org/abs/1907.00443v1", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
