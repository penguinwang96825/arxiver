{"title": "Lite Training Strategies for Portuguese-English and English-Portuguese\n  Translation", "abstract": "Despite the widespread adoption of deep learning for machine translation, it\nis still expensive to develop high-quality translation models. In this work, we\ninvestigate the use of pre-trained models, such as T5 for Portuguese-English\nand English-Portuguese translation tasks using low-cost hardware. We explore\nthe use of Portuguese and English pre-trained language models and propose an\nadaptation of the English tokenizer to represent Portuguese characters, such as\ndiaeresis, acute and grave accents. We compare our models to the Google\nTranslate API and MarianMT on a subset of the ParaCrawl dataset, as well as to\nthe winning submission to the WMT19 Biomedical Translation Shared Task. We also\ndescribe our submission to the WMT20 Biomedical Translation Shared Task. Our\nresults show that our models have a competitive performance to state-of-the-art\nmodels while being trained on modest hardware (a single 8GB gaming GPU for nine\ndays). Our data, models and code are available at\nhttps://github.com/unicamp-dl/Lite-T5-Translation.", "published": "2020-08-20 04:31:03", "link": "http://arxiv.org/abs/2008.08769v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Experimental Study of Deep Neural Network Models for Vietnamese\n  Multiple-Choice Reading Comprehension", "abstract": "Machine reading comprehension (MRC) is a challenging task in natural language\nprocessing that makes computers understanding natural language texts and answer\nquestions based on those texts. There are many techniques for solving this\nproblems, and word representation is a very important technique that impact\nmost to the accuracy of machine reading comprehension problem in the popular\nlanguages like English and Chinese. However, few studies on MRC have been\nconducted in low-resource languages such as Vietnamese. In this paper, we\nconduct several experiments on neural network-based model to understand the\nimpact of word representation to the Vietnamese multiple-choice machine reading\ncomprehension. Our experiments include using the Co-match model on six\ndifferent Vietnamese word embeddings and the BERT model for multiple-choice\nreading comprehension. On the ViMMRC corpus, the accuracy of BERT model is\n61.28% on test set.", "published": "2020-08-20 07:29:14", "link": "http://arxiv.org/abs/2008.08810v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Checkworthiness in Automatic Claim Detection Models: Definitions and\n  Analysis of Datasets", "abstract": "Public, professional and academic interest in automated fact-checking has\ndrastically increased over the past decade, with many aiming to automate one of\nthe first steps in a fact-check procedure: the selection of so-called\ncheckworthy claims. However, there is little agreement on the definition and\ncharacteristics of checkworthiness among fact-checkers, which is consequently\nreflected in the datasets used for training and testing checkworthy claim\ndetection models. After elaborate analysis of checkworthy claim selection\nprocedures in fact-check organisations and analysis of state-of-the-art claim\ndetection datasets, checkworthiness is defined as the concept of having a\nspatiotemporal and context-dependent worth and need to have the correctness of\nthe objectivity it conveys verified. This is irrespective of the claim's\nperceived veracity judgement by an individual based on prior knowledge and\nbeliefs. Concerning the characteristics of current datasets, it is argued that\nthe data is not only highly imbalanced and noisy, but also too limited in scope\nand language. Furthermore, we believe that the subjective concept of\ncheckworthiness might not be a suitable filter for claim detection.", "published": "2020-08-20 09:30:05", "link": "http://arxiv.org/abs/2008.08854v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Decomposable Metric for Explainable Evaluation of Text\n  Generation from AMR", "abstract": "Systems that generate natural language text from abstract meaning\nrepresentations such as AMR are typically evaluated using automatic surface\nmatching metrics that compare the generated texts to reference texts from which\nthe input meaning representations were constructed. We show that besides\nwell-known issues from which such metrics suffer, an additional problem arises\nwhen applying these metrics for AMR-to-text evaluation, since an abstract\nmeaning representation allows for numerous surface realizations. In this work\nwe aim to alleviate these issues by proposing $\\mathcal{M}\\mathcal{F}_\\beta$, a\ndecomposable metric that builds on two pillars. The first is the principle of\nmeaning preservation $\\mathcal{M}$: it measures to what extent a given AMR can\nbe reconstructed from the generated sentence using SOTA AMR parsers and\napplying (fine-grained) AMR evaluation metrics to measure the distance between\nthe original and the reconstructed AMR. The second pillar builds on a principle\nof (grammatical) form $\\mathcal{F}$ that measures the linguistic quality of the\ngenerated text, which we implement using SOTA language models. In two extensive\npilot studies we show that fulfillment of both principles offers benefits for\nAMR-to-text evaluation, including explainability of scores. Since\n$\\mathcal{M}\\mathcal{F}_\\beta$ does not necessarily rely on gold AMRs, it may\nextend to other text generation tasks.", "published": "2020-08-20 11:25:26", "link": "http://arxiv.org/abs/2008.08896v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoKG: Constructing Virtual Knowledge Graphs from Unstructured\n  Documents for Question Answering", "abstract": "Knowledge graphs (KGs) have the advantage of providing fine-grained detail\nfor question-answering systems. Unfortunately, building a reliable KG is\ntime-consuming and expensive as it requires human intervention. To overcome\nthis issue, we propose a novel framework to automatically construct a KG from\nunstructured documents that does not require external alignment. We first\nextract surface-form knowledge tuples from unstructured documents and encode\nthem with contextual information. Entities with similar context semantics are\nthen linked through internal alignment to form a graph structure. This allows\nus to extract the desired information from multiple documents by traversing the\ngenerated KG without a manual process. We examine its performance in retrieval\nbased QA systems by reformulating the WikiMovies and MetaQA datasets into a\ntuple-level retrieval task. The experimental results show that our method\noutperforms traditional retrieval methods by a large margin.", "published": "2020-08-20 14:30:33", "link": "http://arxiv.org/abs/2008.08995v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models as Knowledge Bases: On Entity Representations, Storage\n  Capacity, and Paraphrased Queries", "abstract": "Pretrained language models have been suggested as a possible alternative or\ncomplement to structured knowledge bases. However, this emerging LM-as-KB\nparadigm has so far only been considered in a very limited setting, which only\nallows handling 21k entities whose single-token name is found in common LM\nvocabularies. Furthermore, the main benefit of this paradigm, namely querying\nthe KB using a variety of natural language paraphrases, is underexplored so\nfar. Here, we formulate two basic requirements for treating LMs as KBs: (i) the\nability to store a large number facts involving a large number of entities and\n(ii) the ability to query stored facts. We explore three entity representations\nthat allow LMs to represent millions of entities and present a detailed case\nstudy on paraphrased querying of world knowledge in LMs, thereby providing a\nproof-of-concept that language models can indeed serve as knowledge bases.", "published": "2020-08-20 15:39:36", "link": "http://arxiv.org/abs/2008.09036v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Syntax Trees Help Pre-trained Transformers Extract Information?", "abstract": "Much recent work suggests that incorporating syntax information from\ndependency trees can improve task-specific transformer models. However, the\neffect of incorporating dependency tree information into pre-trained\ntransformer models (e.g., BERT) remains unclear, especially given recent\nstudies highlighting how these models implicitly encode syntax. In this work,\nwe systematically study the utility of incorporating dependency trees into\npre-trained transformers on three representative information extraction tasks:\nsemantic role labeling (SRL), named entity recognition, and relation\nextraction.\n  We propose and investigate two distinct strategies for incorporating\ndependency structure: a late fusion approach, which applies a graph neural\nnetwork on the output of a transformer, and a joint fusion approach, which\ninfuses syntax structure into the transformer attention layers. These\nstrategies are representative of prior work, but we introduce additional model\ndesign elements that are necessary for obtaining improved performance. Our\nempirical analysis demonstrates that these syntax-infused transformers obtain\nstate-of-the-art results on SRL and relation extraction tasks. However, our\nanalysis also reveals a critical shortcoming of these models: we find that\ntheir performance gains are highly contingent on the availability of\nhuman-annotated dependency parses, which raises important questions regarding\nthe viability of syntax-augmented transformers in real-world applications.", "published": "2020-08-20 17:17:38", "link": "http://arxiv.org/abs/2008.09084v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scruples: A Corpus of Community Ethical Judgments on 32,000 Real-Life\n  Anecdotes", "abstract": "As AI systems become an increasing part of people's everyday lives, it\nbecomes ever more important that they understand people's ethical norms.\nMotivated by descriptive ethics, a field of study that focuses on people's\ndescriptive judgments rather than theoretical prescriptions on morality, we\ninvestigate a novel, data-driven approach to machine ethics.\n  We introduce Scruples, the first large-scale dataset with 625,000 ethical\njudgments over 32,000 real-life anecdotes. Each anecdote recounts a complex\nethical situation, often posing moral dilemmas, paired with a distribution of\njudgments contributed by the community members. Our dataset presents a major\nchallenge to state-of-the-art neural language models, leaving significant room\nfor improvement. However, when presented with simplified moral situations, the\nresults are considerably more promising, suggesting that neural models can\neffectively learn simpler ethical building blocks.\n  A key take-away of our empirical analysis is that norms are not always\nclean-cut; many situations are naturally divisive. We present a new method to\nestimate the best possible performance on such tasks with inherently diverse\nlabel distributions, and explore likelihood functions that separate intrinsic\nfrom model uncertainty.", "published": "2020-08-20 17:34:15", "link": "http://arxiv.org/abs/2008.09094v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inducing Language-Agnostic Multilingual Representations", "abstract": "Cross-lingual representations have the potential to make NLP techniques\navailable to the vast majority of languages in the world. However, they\ncurrently require large pretraining corpora or access to typologically similar\nlanguages. In this work, we address these obstacles by removing language\nidentity signals from multilingual embeddings. We examine three approaches for\nthis: (i) re-aligning the vector spaces of target languages (all together) to a\npivot source language; (ii) removing language-specific means and variances,\nwhich yields better discriminativeness of embeddings as a by-product; and (iii)\nincreasing input similarity across languages by removing morphological\ncontractions and sentence reordering. We evaluate on XNLI and reference-free MT\nacross 19 typologically diverse languages. Our findings expose the limitations\nof these approaches -- unlike vector normalization, vector space re-alignment\nand text normalization do not achieve consistent gains across encoders and\nlanguages. Due to the approaches' additive effects, their combination decreases\nthe cross-lingual transfer gap by 8.9 points (m-BERT) and 18.2 points (XLM-R)\non average across all tasks and languages, however. Our code and models are\npublicly available.", "published": "2020-08-20 17:58:56", "link": "http://arxiv.org/abs/2008.09112v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PTT5: Pretraining and validating the T5 model on Brazilian Portuguese\n  data", "abstract": "In natural language processing (NLP), there is a need for more resources in\nPortuguese, since much of the data used in the state-of-the-art research is in\nother languages. In this paper, we pretrain a T5 model on the BrWac corpus, an\nextensive collection of web pages in Portuguese, and evaluate its performance\nagainst other Portuguese pretrained models and multilingual models on three\ndifferent tasks. We show that our Portuguese pretrained models have\nsignificantly better performance over the original T5 models. Moreover, we\ndemonstrate the positive impact of using a Portuguese vocabulary. Our code and\nmodels are available at https://github.com/unicamp-dl/PTT5.", "published": "2020-08-20 18:10:13", "link": "http://arxiv.org/abs/2008.09144v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Have We Reacted To The COVID-19 Pandemic? Analyzing Changing Indian\n  Emotions Through The Lens of Twitter", "abstract": "Since its outbreak, the ongoing COVID-19 pandemic has caused unprecedented\nlosses to human lives and economies around the world. As of 18th July 2020, the\nWorld Health Organization (WHO) has reported more than 13 million confirmed\ncases including close to 600,000 deaths across 216 countries and territories.\nDespite several government measures, India has gradually moved up the ranks to\nbecome the third worst-hit nation by the pandemic after the US and Brazil, thus\ncausing widespread anxiety and fear among her citizens. As majority of the\nworld's population continues to remain confined to their homes, more and more\npeople have started relying on social media platforms such as Twitter for\nexpressing their feelings and attitudes towards various aspects of the\npandemic. With rising concerns of mental well-being, it becomes imperative to\nanalyze the dynamics of public affect in order to anticipate any potential\nthreats and take precautionary measures. Since affective states of human mind\nare more nuanced than meager binary sentiments, here we propose a deep\nlearning-based system to identify people's emotions from their tweets. We\nachieve competitive results on two benchmark datasets for multi-label emotion\nclassification. We then use our system to analyze the evolution of emotional\nresponses among Indians as the pandemic continues to spread its wings. We also\nstudy the development of salient factors contributing towards the changes in\nattitudes over time. Finally, we discuss directions to further improve our work\nand hope that our analysis can aid in better public health monitoring.", "published": "2020-08-20 15:39:05", "link": "http://arxiv.org/abs/2008.09035v1", "categories": ["cs.SI", "cs.CL", "J.4; I.2.0"], "primary_category": "cs.SI"}
{"title": "Discovering Useful Sentence Representations from Large Pretrained\n  Language Models", "abstract": "Despite the extensive success of pretrained language models as encoders for\nbuilding NLP systems, they haven't seen prominence as decoders for sequence\ngeneration tasks. We explore the question of whether these models can be\nadapted to be used as universal decoders. To be considered \"universal,\" a\ndecoder must have an implicit representation for any target sentence $s$, such\nthat it can recover that sentence exactly when conditioned on its\nrepresentation. For large transformer-based language models trained on vast\namounts of English text, we investigate whether such representations can be\neasily discovered using standard optimization methods. We present and compare\nthree representation injection techniques for transformer-based models and\nthree accompanying methods which map sentences to and from this representation\nspace. Experiments show that not only do representations exist for sentences\nfrom a variety of genres. More importantly, without needing complex\noptimization algorithms, our methods recover these sentences almost perfectly\nwithout fine-tuning the underlying language model at all.", "published": "2020-08-20 16:03:51", "link": "http://arxiv.org/abs/2008.09049v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Controlling Dialogue Generation with Semantic Exemplars", "abstract": "Dialogue systems pretrained with large language models generate locally\ncoherent responses, but lack the fine-grained control over responses necessary\nto achieve specific goals. A promising method to control response generation is\nexemplar-based generation, in which models edit exemplar responses that are\nretrieved from training data, or hand-written to strategically address\ndiscourse-level goals, to fit new dialogue contexts. But, current\nexemplar-based approaches often excessively copy words from the exemplar\nresponses, leading to incoherent replies. We present an Exemplar-based Dialogue\nGeneration model, EDGE, that uses the semantic frames present in exemplar\nresponses to guide generation. We show that controlling dialogue generation\nbased on the semantic frames of exemplars, rather than words in the exemplar\nitself, improves the coherence of generated responses, while preserving\nsemantic meaning and conversation goals present in exemplar responses.", "published": "2020-08-20 17:02:37", "link": "http://arxiv.org/abs/2008.09075v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-modal Cooking Workflow Construction for Food Recipes", "abstract": "Understanding food recipe requires anticipating the implicit causal effects\nof cooking actions, such that the recipe can be converted into a graph\ndescribing the temporal workflow of the recipe. This is a non-trivial task that\ninvolves common-sense reasoning. However, existing efforts rely on hand-crafted\nfeatures to extract the workflow graph from recipes due to the lack of\nlarge-scale labeled datasets. Moreover, they fail to utilize the cooking\nimages, which constitute an important part of food recipes. In this paper, we\nbuild MM-ReS, the first large-scale dataset for cooking workflow construction,\nconsisting of 9,850 recipes with human-labeled workflow graphs. Cooking steps\nare multi-modal, featuring both text instructions and cooking images. We then\npropose a neural encoder-decoder model that utilizes both visual and textual\ninformation to construct the cooking workflow, which achieved over 20%\nperformance gain over existing hand-crafted baselines.", "published": "2020-08-20 18:31:25", "link": "http://arxiv.org/abs/2008.09151v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "ImagiFilter: A resource to enable the semi-automatic mining of images at\n  scale", "abstract": "Datasets (semi-)automatically collected from the web can easily scale to\nmillions of entries, but a dataset's usefulness is directly related to how\nclean and high-quality its examples are. In this paper, we describe and\npublicly release an image dataset along with pretrained models designed to\n(semi-)automatically filter out undesirable images from very large image\ncollections, possibly obtained from the web. Our dataset focusses on\nphotographic and/or natural images, a very common use-case in computer vision\nresearch. We provide annotations for coarse prediction, i.e. photographic vs.\nnon-photographic, and smaller fine-grained prediction tasks where we further\nbreak down the non-photographic class into five classes: maps, drawings,\ngraphs, icons, and sketches. Results on held out validation data show that a\nmodel architecture with reduced memory footprint achieves over 96% accuracy on\ncoarse-prediction. Our best model achieves 88% accuracy on the hardest\nfine-grained classification task available. Dataset and pretrained models are\navailable at: https://github.com/houda96/imagi-filter.", "published": "2020-08-20 18:31:52", "link": "http://arxiv.org/abs/2008.09152v1", "categories": ["cs.CV", "cs.CL", "E.0"], "primary_category": "cs.CV"}
{"title": "Assigning function to protein-protein interactions: a weakly supervised\n  BioBERT based approach using PubMed abstracts", "abstract": "Motivation: Protein-protein interactions (PPI) are critical to the function\nof proteins in both normal and diseased cells, and many critical protein\nfunctions are mediated by interactions.Knowledge of the nature of these\ninteractions is important for the construction of networks to analyse\nbiological data. However, only a small percentage of PPIs captured in protein\ninteraction databases have annotations of function available, e.g. only 4% of\nPPI are functionally annotated in the IntAct database. Here, we aim to label\nthe function type of PPIs by extracting relationships described in PubMed\nabstracts.\n  Method: We create a weakly supervised dataset from the IntAct PPI database\ncontaining interacting protein pairs with annotated function and associated\nabstracts from the PubMed database. We apply a state-of-the-art deep learning\ntechnique for biomedical natural language processing tasks, BioBERT, to build a\nmodel - dubbed PPI-BioBERT - for identifying the function of PPIs. In order to\nextract high quality PPI functions at large scale, we use an ensemble of\nPPI-BioBERT models to improve uncertainty estimation and apply an interaction\ntype-specific threshold to counteract the effects of variations in the number\nof training samples per interaction type.\n  Results: We scan 18 million PubMed abstracts to automatically identify 3253\nnew typed PPIs, including phosphorylation and acetylation interactions, with an\noverall precision of 46% (87% for acetylation) based on a human-reviewed\nsample. This work demonstrates that analysis of biomedical abstracts for PPI\nfunction extraction is a feasible approach to substantially increasing the\nnumber of interactions annotated with function captured in online databases.", "published": "2020-08-20 01:42:28", "link": "http://arxiv.org/abs/2008.08727v3", "categories": ["cs.CL", "cs.LG", "q-bio.GN"], "primary_category": "cs.CL"}
{"title": "Speaker-Utterance Dual Attention for Speaker and Utterance Verification", "abstract": "In this paper, we study a novel technique that exploits the interaction\nbetween speaker traits and linguistic content to improve both speaker\nverification and utterance verification performance. We implement an idea of\nspeaker-utterance dual attention (SUDA) in a unified neural network. The dual\nattention refers to an attention mechanism for the two tasks of speaker and\nutterance verification. The proposed SUDA features an attention mask mechanism\nto learn the interaction between the speaker and utterance information streams.\nThis helps to focus only on the required information for respective task by\nmasking the irrelevant counterparts. The studies conducted on RSR2015 corpus\nconfirm that the proposed SUDA outperforms the framework without attention mask\nas well as several competitive systems for both speaker and utterance\nverification.", "published": "2020-08-20 11:37:57", "link": "http://arxiv.org/abs/2008.08901v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Institutional Grammar 2.0 Codebook", "abstract": "The Grammar of Institutions, or Institutional Grammar, is an established\napproach to encode policy information in terms of institutional statements\nbased on a set of pre-defined syntactic components. This codebook provides\ncoding guidelines for a revised version of the Institutional Grammar, the\nInstitutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at\nfacilitating the encoding of policy to meet varying analytical objectives. To\nthis end, it revises the grammar with respect to comprehensiveness,\nflexibility, and specificity by offering multiple levels of expressiveness (IG\nCore, IG Extended, IG Logico). In addition to the encoding of regulative\nstatements, it further introduces the encoding of constitutive institutional\nstatements, as well as statements that exhibit both constitutive and regulative\ncharacteristics. Introducing those aspects, the codebook initially covers\nfundamental concepts of IG 2.0, before providing an overview of pre-coding\nsteps relevant for document preparation. Detailed coding guidelines are\nprovided for both regulative and constitutive statements across all levels of\nexpressiveness, along with the encoding guidelines for statements of mixed form\n-- hybrid and polymorphic institutional statements. The document further\nprovides an overview of taxonomies used in the encoding process and referred to\nthroughout the codebook. The codebook concludes with a summary and discussion\nof relevant considerations to facilitate the coding process. An initial\nReader's Guide helps the reader tailor the content to her interest.\n  Note that this codebook specifically focuses on operational aspects of IG 2.0\nin the context of policy coding. Links to additional resources such as the\nunderlying scientific literature (that offers a comprehensive treatment of the\nunderlying theoretical concepts) are referred to in the DOI and the concluding\nsection of the codebook.", "published": "2020-08-20 12:38:55", "link": "http://arxiv.org/abs/2008.08937v5", "categories": ["cs.MA", "cs.AI", "cs.CL", "stat.ML", "68T30", "I.7.2; I.6.5"], "primary_category": "cs.MA"}
{"title": "VisualSem: A High-quality Knowledge Graph for Vision and Language", "abstract": "An exciting frontier in natural language understanding (NLU) and generation\n(NLG) calls for (vision-and-) language models that can efficiently access\nexternal structured knowledge repositories. However, many existing knowledge\nbases only cover limited domains, or suffer from noisy data, and most of all\nare typically hard to integrate into neural language pipelines. To fill this\ngap, we release VisualSem: a high-quality knowledge graph (KG) which includes\nnodes with multilingual glosses, multiple illustrative images, and visually\nrelevant relations. We also release a neural multi-modal retrieval model that\ncan use images or sentences as inputs and retrieves entities in the KG. This\nmulti-modal retrieval model can be integrated into any (neural network) model\npipeline. We encourage the research community to use VisualSem for data\naugmentation and/or as a source of grounding, among other possible uses.\nVisualSem as well as the multi-modal retrieval models are publicly available\nand can be downloaded in this URL: https://github.com/iacercalixto/visualsem", "published": "2020-08-20 18:20:29", "link": "http://arxiv.org/abs/2008.09150v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "E.0; E.2"], "primary_category": "cs.CL"}
{"title": "Dyadic Speech-based Affect Recognition using DAMI-P2C Parent-child\n  Multimodal Interaction Dataset", "abstract": "Automatic speech-based affect recognition of individuals in dyadic\nconversation is a challenging task, in part because of its heavy reliance on\nmanual pre-processing. Traditional approaches frequently require hand-crafted\nspeech features and segmentation of speaker turns. In this work, we design\nend-to-end deep learning methods to recognize each person's affective\nexpression in an audio stream with two speakers, automatically discovering\nfeatures and time regions relevant to the target speaker's affect. We integrate\na local attention mechanism into the end-to-end architecture and compare the\nperformance of three attention implementations -- one mean pooling and two\nweighted pooling methods. Our results show that the proposed weighted-pooling\nattention solutions are able to learn to focus on the regions containing target\nspeaker's affective information and successfully extract the individual's\nvalence and arousal intensity. Here we introduce and use a \"dyadic affect in\nmultimodal interaction - parent to child\" (DAMI-P2C) dataset collected in a\nstudy of 34 families, where a parent and a child (3-7 years old) engage in\nreading storybooks together. In contrast to existing public datasets for affect\nrecognition, each instance for both speakers in the DAMI-P2C dataset is\nannotated for the perceived affect by three labelers. To encourage more\nresearch on the challenging task of multi-speaker affect sensing, we make the\nannotated DAMI-P2C dataset publicly available, including acoustic features of\nthe dyads' raw audios, affect annotations, and a diverse set of developmental,\nsocial, and demographic profiles of each dyad.", "published": "2020-08-20 20:53:23", "link": "http://arxiv.org/abs/2008.09207v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "I.2.0"], "primary_category": "eess.AS"}
{"title": "Laughter Synthesis: Combining Seq2seq modeling with Transfer Learning", "abstract": "Despite the growing interest for expressive speech synthesis, synthesis of\nnonverbal expressions is an under-explored area. In this paper we propose an\naudio laughter synthesis system based on a sequence-to-sequence TTS synthesis\nsystem. We leverage transfer learning by training a deep learning model to\nlearn to generate both speech and laughs from annotations. We evaluate our\nmodel with a listening test, comparing its performance to an HMM-based laughter\nsynthesis one and assess that it reaches higher perceived naturalness. Our\nsolution is a first step towards a TTS system that would be able to synthesize\nspeech with a control on amusement level with laughter integration.", "published": "2020-08-20 09:37:28", "link": "http://arxiv.org/abs/2008.09483v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Efficient neural speech synthesis for low-resource languages through\n  multilingual modeling", "abstract": "Recent advances in neural TTS have led to models that can produce\nhigh-quality synthetic speech. However, these models typically require large\namounts of training data, which can make it costly to produce a new voice with\nthe desired quality. Although multi-speaker modeling can reduce the data\nrequirements necessary for a new voice, this approach is usually not viable for\nmany low-resource languages for which abundant multi-speaker data is not\navailable. In this paper, we therefore investigated to what extent multilingual\nmulti-speaker modeling can be an alternative to monolingual multi-speaker\nmodeling, and explored how data from foreign languages may best be combined\nwith low-resource language data. We found that multilingual modeling can\nincrease the naturalness of low-resource language speech, showed that\nmultilingual models can produce speech with a naturalness comparable to\nmonolingual multi-speaker models, and saw that the target language naturalness\nwas affected by the strategy used to add foreign language data.", "published": "2020-08-20 14:05:28", "link": "http://arxiv.org/abs/2008.09659v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Generalized Framework for Domain Adaptation of PLDA in Speaker\n  Recognition", "abstract": "This paper proposes a generalized framework for domain adaptation of\nProbabilistic Linear Discriminant Analysis (PLDA) in speaker recognition. It\nnot only includes several existing supervised and unsupervised domain\nadaptation methods but also makes possible more flexible usage of available\ndata in different domains. In particular, we introduce here the two new\ntechniques described below. (1) Correlation-alignment-based interpolation and\n(2) covariance regularization. The proposed correlation-alignment-based\ninterpolation method decreases minCprimary up to 30.5% as compared with that\nfrom an out-of-domain PLDA model before adaptation, and minCprimary is also\n5.5% lower than with a conventional linear interpolation method with optimal\ninterpolation weights. Further, the proposed regularization technique ensures\nrobustness in interpolations w.r.t. varying interpolation weights, which in\npractice is essential.", "published": "2020-08-20 07:38:38", "link": "http://arxiv.org/abs/2008.08815v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Using Multi-Resolution Feature Maps with Convolutional Neural Networks\n  for Anti-Spoofing in ASV", "abstract": "This paper presents a simple but effective method that uses multi-resolution\nfeature maps with convolutional neural networks (CNNs) for anti-spoofing in\nautomatic speaker verification (ASV). The central idea is to alleviate the\nproblem that the feature maps commonly used in anti-spoofing networks are\ninsufficient for building discriminative representations of audio segments, as\nthey are often extracted by a single-length sliding window. Resulting\ntrade-offs between time and frequency resolutions restrict the information in\nsingle spectrograms. The proposed method improves both frequency resolution and\ntime resolution by stacking multiple spectrograms that are extracted using\ndifferent window lengths. These are fed into a convolutional neural network in\nthe form of multiple channels, making it possible to extract more information\nfrom input signals while only marginally increasing computational costs. The\nefficiency of the proposed method has been conformed on the ASVspoof 2019\ndatabase. We show that the use of the proposed multiresolution inputs\nconsistently outperforms that of score fusion across different CNN\narchitectures. Moreover, computational cost remains small.", "published": "2020-08-20 10:00:03", "link": "http://arxiv.org/abs/2008.08865v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "asya: Mindful verbal communication using deep learning", "abstract": "asya is a mobile application that consists of deep learning models which\nanalyze spectra of a human voice and do noise detection, speaker diarization,\ngender detection, tempo estimation, and classification of emotions using only\nvoice. All models are language agnostic and capable of running in real-time.\nOur speaker diarization models have accuracy over 95% on the test data set.\nThese models can be applied for a variety of areas like customer service\nimprovement, sales effective conversations, psychology and couples therapy.", "published": "2020-08-20 13:37:49", "link": "http://arxiv.org/abs/2008.08965v1", "categories": ["eess.AS", "cs.HC", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Blind Mask to Improve Intelligibility of Non-Stationary Noisy Speech", "abstract": "This letter proposes a novel blind acoustic mask (BAM) designed to adaptively\ndetect noise components and preserve target speech segments in time-domain. A\nrobust standard deviation estimator is applied to the non-stationary noisy\nspeech to identify noise masking elements. The main contribution of the\nproposed solution is the use of this noise statistics to derive an adaptive\ninformation to define and select samples with lower noise proportion. Thus,\npreserving speech intelligibility. Additionally, no information of the target\nspeech and noise signals statistics is previously required to this non-ideal\nmask. The BAM and three competitive methods, Ideal Binary Mask (IBM), Target\nBinary Mask (TBM), and Non-stationary Noise Estimation for Speech Enhancement\n(NNESE), are evaluated considering speech signals corrupted by three\nnon-stationary acoustic noises and six values of signal-to-noise ratio (SNR).\nResults demonstrate that the BAM technique achieves intelligibility gains\ncomparable to ideal masks while maintaining good speech quality.", "published": "2020-08-20 19:41:30", "link": "http://arxiv.org/abs/2008.09175v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
