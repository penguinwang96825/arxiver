{"title": "Occurrence Statistics of Entities, Relations and Types on the Web", "abstract": "The problem of collecting reliable estimates of occurrence of entities on the\nopen web forms the premise for this report. The models learned for tagging\nentities cannot be expected to perform well when deployed on the web. This is\nowing to the severe mismatch in the distributions of such entities on the web\nand in the relatively diminutive training data. In this report, we build up the\ncase for maximum mean discrepancy for estimation of occurrence statistics of\nentities on the web, taking a review of named entity disambiguation techniques\nand related concepts along the way.", "published": "2016-05-14 01:13:48", "link": "http://arxiv.org/abs/1605.04359v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rationale-Augmented Convolutional Neural Networks for Text\n  Classification", "abstract": "We present a new Convolutional Neural Network (CNN) model for text\nclassification that jointly exploits labels on documents and their component\nsentences. Specifically, we consider scenarios in which annotators explicitly\nmark sentences (or snippets) that support their overall document\ncategorization, i.e., they provide rationales. Our model exploits such\nsupervision via a hierarchical approach in which each document is represented\nby a linear combination of the vector representations of its component\nsentences. We propose a sentence-level convolutional model that estimates the\nprobability that a given sentence is a rationale, and we then scale the\ncontribution of each sentence to the aggregate document representation in\nproportion to these estimates. Experiments on five classification datasets that\nhave document labels and associated rationales demonstrate that our approach\nconsistently outperforms strong baselines. Moreover, our model naturally\nprovides explanations for its predictions.", "published": "2016-05-14 21:30:57", "link": "http://arxiv.org/abs/1605.04469v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Capturing divergence in dependency trees to improve syntactic projection", "abstract": "Obtaining syntactic parses is a crucial part of many NLP pipelines. However,\nmost of the world's languages do not have large amounts of syntactically\nannotated corpora available for building parsers. Syntactic projection\ntechniques attempt to address this issue by using parallel corpora consisting\nof resource-poor and resource-rich language pairs, taking advantage of a parser\nfor the resource-rich language and word alignment between the languages to\nproject the parses onto the data for the resource-poor language. These\nprojection methods can suffer, however, when the two languages are divergent.\nIn this paper, we investigate the possibility of using small, parallel,\nannotated corpora to automatically detect divergent structural patterns between\ntwo languages. These patterns can then be used to improve structural projection\nalgorithms, allowing for better performing NLP tools for resource-poor\nlanguages, in particular those that may not have large amounts of annotated\ndata necessary for traditional, fully-supervised methods. While this detection\nprocess is not exhaustive, we demonstrate that common patterns of divergence\ncan be identified automatically without prior knowledge of a given language\npair, and the patterns can be used to improve performance of projection\nalgorithms.", "published": "2016-05-14 22:11:07", "link": "http://arxiv.org/abs/1605.04475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large-scale Analysis of Counseling Conversations: An Application of\n  Natural Language Processing to Mental Health", "abstract": "Mental illness is one of the most pressing public health issues of our time.\nWhile counseling and psychotherapy can be effective treatments, our knowledge\nabout how to conduct successful counseling conversations has been limited due\nto lack of large-scale data with labeled outcomes of the conversations. In this\npaper, we present a large-scale, quantitative study on the discourse of\ntext-message-based counseling conversations. We develop a set of novel\ncomputational discourse analysis methods to measure how various linguistic\naspects of conversations are correlated with conversation outcomes. Applying\ntechniques such as sequence-based conversation models, language model\ncomparisons, message clustering, and psycholinguistics-inspired word frequency\nanalyses, we discover actionable conversation strategies that are associated\nwith better conversation outcomes.", "published": "2016-05-14 20:02:05", "link": "http://arxiv.org/abs/1605.04462v3", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
