{"title": "A Framework for Evaluation of Machine Reading Comprehension Gold\n  Standards", "abstract": "Machine Reading Comprehension (MRC) is the task of answering a question over\na paragraph of text. While neural MRC systems gain popularity and achieve\nnoticeable performance, issues are being raised with the methodology used to\nestablish their performance, particularly concerning the data design of gold\nstandards that are used to evaluate them. There is but a limited understanding\nof the challenges present in this data, which makes it hard to draw comparisons\nand formulate reliable hypotheses. As a first step towards alleviating the\nproblem, this paper proposes a unifying framework to systematically investigate\nthe present linguistic features, required reasoning and background knowledge\nand factual correctness on one hand, and the presence of lexical cues as a\nlower bound for the requirement of understanding on the other hand. We propose\na qualitative annotation schema for the first and a set of approximative\nmetrics for the latter. In a first application of the framework, we analyse\nmodern MRC gold standards and present our findings: the absence of features\nthat contribute towards lexical ambiguity, the varying factual correctness of\nthe expected answers and the presence of lexical cues, all of which potentially\nlower the reading comprehension complexity and quality of the evaluation data.", "published": "2020-03-10 11:30:22", "link": "http://arxiv.org/abs/2003.04642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Intent Detection with Dual Sentence Encoders", "abstract": "Building conversational systems in new domains and with added functionality\nrequires resource-efficient models that work under low-data regimes (i.e., in\nfew-shot setups). Motivated by these requirements, we introduce intent\ndetection methods backed by pretrained dual sentence encoders such as USE and\nConveRT. We demonstrate the usefulness and wide applicability of the proposed\nintent detectors, showing that: 1) they outperform intent detectors based on\nfine-tuning the full BERT-Large model or using BERT as a fixed black-box\nencoder on three diverse intent detection data sets; 2) the gains are\nespecially pronounced in few-shot setups (i.e., with only 10 or 30 annotated\nexamples per intent); 3) our intent detectors can be trained in a matter of\nminutes on a single CPU; and 4) they are stable across different hyperparameter\nsettings. In hope of facilitating and democratizing research focused on\nintention detection, we release our code, as well as a new challenging\nsingle-domain intent detection dataset comprising 13,083 annotated examples\nover 77 intents.", "published": "2020-03-10 15:33:54", "link": "http://arxiv.org/abs/2003.04807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-SimLex: A Large-Scale Evaluation of Multilingual and Cross-Lingual\n  Lexical Semantic Similarity", "abstract": "We introduce Multi-SimLex, a large-scale lexical resource and evaluation\nbenchmark covering datasets for 12 typologically diverse languages, including\nmajor languages (e.g., Mandarin Chinese, Spanish, Russian) as well as\nless-resourced ones (e.g., Welsh, Kiswahili). Each language dataset is\nannotated for the lexical relation of semantic similarity and contains 1,888\nsemantically aligned concept pairs, providing a representative coverage of word\nclasses (nouns, verbs, adjectives, adverbs), frequency ranks, similarity\nintervals, lexical fields, and concreteness levels. Additionally, owing to the\nalignment of concepts across languages, we provide a suite of 66 cross-lingual\nsemantic similarity datasets. Due to its extensive size and language coverage,\nMulti-SimLex provides entirely novel opportunities for experimental evaluation\nand analysis. On its monolingual and cross-lingual benchmarks, we evaluate and\nanalyze a wide array of recent state-of-the-art monolingual and cross-lingual\nrepresentation models, including static and contextualized word embeddings\n(such as fastText, M-BERT and XLM), externally informed lexical\nrepresentations, as well as fully unsupervised and (weakly) supervised\ncross-lingual word embeddings. We also present a step-by-step dataset creation\nprotocol for creating consistent, Multi-Simlex-style resources for additional\nlanguages. We make these contributions -- the public release of Multi-SimLex\ndatasets, their creation protocol, strong baseline results, and in-depth\nanalyses which can be be helpful in guiding future developments in multilingual\nlexical semantics and representation learning -- available via a website which\nwill encourage community effort in further expansion of Multi-Simlex to many\nmore languages. Such a large-scale semantic resource could inspire significant\nfurther advances in NLP across languages.", "published": "2020-03-10 17:17:01", "link": "http://arxiv.org/abs/2003.04866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the coexistence of competing languages", "abstract": "We investigate the evolution of competing languages, a subject where much\nprevious literature suggests that the outcome is always the domination of one\nlanguage over all the others. Since coexistence of languages is observed in\nreality, we here revisit the question of language competition, with an emphasis\non uncovering the ways in which coexistence might emerge. We find that this\nemergence is related to symmetry breaking, and explore two particular scenarios\n-- the first relating to an imbalance in the population dynamics of language\nspeakers in a single geographical area, and the second to do with spatial\nheterogeneity, where language preferences are specific to different\ngeographical regions. For each of these, the investigation of paradigmatic\nsituations leads us to a quantitative understanding of the conditions leading\nto language coexistence. We also obtain predictions of the number of surviving\nlanguages as a function of various model parameters.", "published": "2020-03-10 14:06:55", "link": "http://arxiv.org/abs/2003.04748v1", "categories": ["cond-mat.stat-mech", "cs.CL"], "primary_category": "cond-mat.stat-mech"}
{"title": "Video Caption Dataset for Describing Human Actions in Japanese", "abstract": "In recent years, automatic video caption generation has attracted\nconsiderable attention. This paper focuses on the generation of Japanese\ncaptions for describing human actions. While most currently available video\ncaption datasets have been constructed for English, there is no equivalent\nJapanese dataset. To address this, we constructed a large-scale Japanese video\ncaption dataset consisting of 79,822 videos and 399,233 captions. Each caption\nin our dataset describes a video in the form of \"who does what and where.\" To\ndescribe human actions, it is important to identify the details of a person,\nplace, and action. Indeed, when we describe human actions, we usually mention\nthe scene, person, and action. In our experiments, we evaluated two caption\ngeneration methods to obtain benchmark results. Further, we investigated\nwhether those generation methods could specify \"who does what and where.\"", "published": "2020-03-10 17:15:48", "link": "http://arxiv.org/abs/2003.04865v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "TyDi QA: A Benchmark for Information-Seeking Question Answering in\n  Typologically Diverse Languages", "abstract": "Confidently making progress on multilingual modeling requires challenging,\ntrustworthy evaluations. We present TyDi QA---a question answering dataset\ncovering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology---the set of\nlinguistic features each language expresses---such that we expect models\nperforming well on this set to generalize across a large number of the world's\nlanguages. We present a quantitative analysis of the data quality and\nexample-level qualitative linguistic analyses of observed language phenomena\nthat would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by\npeople who want to know the answer, but don't know the answer yet, and the data\nis collected directly in each language without the use of translation.", "published": "2020-03-10 21:11:53", "link": "http://arxiv.org/abs/2003.05002v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hybrid Attention-Based Transformer Block Model for Distant Supervision\n  Relation Extraction", "abstract": "With an exponential explosive growth of various digital text information, it\nis challenging to efficiently obtain specific knowledge from massive\nunstructured text information. As one basic task for natural language\nprocessing (NLP), relation extraction aims to extract the semantic relation\nbetween entity pairs based on the given text. To avoid manual labeling of\ndatasets, distant supervision relation extraction (DSRE) has been widely used,\naiming to utilize knowledge base to automatically annotate datasets.\nUnfortunately, this method heavily suffers from wrong labelling due to the\nunderlying strong assumptions. To address this issue, we propose a new\nframework using hybrid attention-based Transformer block with multi-instance\nlearning to perform the DSRE task. More specifically, the Transformer block is\nfirstly used as the sentence encoder to capture syntactic information of\nsentences, which mainly utilizes multi-head self-attention to extract features\nfrom word level. Then, a more concise sentence-level attention mechanism is\nadopted to constitute the bag representation, aiming to incorporate valid\ninformation of each sentence to effectively represent the bag. Experimental\nresults on the public dataset New York Times (NYT) demonstrate that the\nproposed approach can outperform the state-of-the-art algorithms on the\nevaluation dataset, which verifies the effectiveness of our model for the DSRE\ntask.", "published": "2020-03-10 13:05:52", "link": "http://arxiv.org/abs/2003.11518v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ecological Semantics: Programming Environments for Situated Language\n  Understanding", "abstract": "Large-scale natural language understanding (NLU) systems have made impressive\nprogress: they can be applied flexibly across a variety of tasks, and employ\nminimal structural assumptions. However, extensive empirical research has shown\nthis to be a double-edged sword, coming at the cost of shallow understanding:\ninferior generalization, grounding and explainability. Grounded language\nlearning approaches offer the promise of deeper understanding by situating\nlearning in richer, more structured training environments, but are limited in\nscale to relatively narrow, predefined domains. How might we enjoy the best of\nboth worlds: grounded, general NLU? Following extensive contemporary cognitive\nscience, we propose treating environments as \"first-class citizens\" in semantic\nrepresentations, worthy of research and development in their own right.\nImportantly, models should also be partners in the creation and configuration\nof environments, rather than just actors within them, as in existing\napproaches. To do so, we argue that models must begin to understand and program\nin the language of affordances (which define possible actions in a given\nsituation) both for online, situated discourse comprehension, as well as\nlarge-scale, offline common-sense knowledge mining. To this end we propose an\nenvironment-oriented ecological semantics, outlining theoretical and practical\napproaches towards implementation. We further provide actual demonstrations\nbuilding upon interactive fiction programming languages.", "published": "2020-03-10 08:24:41", "link": "http://arxiv.org/abs/2003.04567v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Learning to Respond with Stickers: A Framework of Unifying\n  Multi-Modality in Multi-Turn Dialog", "abstract": "Stickers with vivid and engaging expressions are becoming increasingly\npopular in online messaging apps, and some works are dedicated to automatically\nselect sticker response by matching text labels of stickers with previous\nutterances. However, due to their large quantities, it is impractical to\nrequire text labels for the all stickers. Hence, in this paper, we propose to\nrecommend an appropriate sticker to user based on multi-turn dialog context\nhistory without any external labels. Two main challenges are confronted in this\ntask. One is to learn semantic meaning of stickers without corresponding text\nlabels. Another challenge is to jointly model the candidate sticker with the\nmulti-turn dialog context. To tackle these challenges, we propose a sticker\nresponse selector (SRS) model. Specifically, SRS first employs a convolutional\nbased sticker image encoder and a self-attention based multi-turn dialog\nencoder to obtain the representation of stickers and utterances. Next, deep\ninteraction network is proposed to conduct deep matching between the sticker\nwith each utterance in the dialog history. SRS then learns the short-term and\nlong-term dependency between all interaction results by a fusion network to\noutput the the final matching score. To evaluate our proposed method, we\ncollect a large-scale real-world dialog dataset with stickers from one of the\nmost popular online chatting platform. Extensive experiments conducted on this\ndataset show that our model achieves the state-of-the-art performance for all\ncommonly-used metrics. Experiments also verify the effectiveness of each\ncomponent of SRS. To facilitate further research in sticker selection field, we\nrelease this dataset of 340K multi-turn dialog and sticker pairs.", "published": "2020-03-10 13:10:26", "link": "http://arxiv.org/abs/2003.04679v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "ReZero is All You Need: Fast Convergence at Large Depth", "abstract": "Deep networks often suffer from vanishing or exploding gradients due to\ninefficient signal propagation, leading to long training times or convergence\ndifficulties. Various architecture designs, sophisticated residual-style\nnetworks, and initialization schemes have been shown to improve deep signal\npropagation. Recently, Pennington et al. used free probability theory to show\nthat dynamical isometry plays an integral role in efficient deep learning. We\nshow that the simplest architecture change of gating each residual connection\nusing a single zero-initialized parameter satisfies initial dynamical isometry\nand outperforms more complex approaches. Although much simpler than its\npredecessors, this gate enables training thousands of fully connected layers\nwith fast convergence and better test performance for ResNets trained on\nCIFAR-10. We apply this technique to language modeling and find that we can\neasily train 120-layer Transformers. When applied to 12 layer Transformers, it\nconverges 56% faster on enwiki8.", "published": "2020-03-10 17:58:01", "link": "http://arxiv.org/abs/2003.04887v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Text classification with word embedding regularization and soft\n  similarity measure", "abstract": "Since the seminal work of Mikolov et al., word embeddings have become the\npreferred word representations for many natural language processing tasks.\nDocument similarity measures extracted from word embeddings, such as the soft\ncosine measure (SCM) and the Word Mover's Distance (WMD), were reported to\nachieve state-of-the-art performance on semantic text similarity and text\nclassification.\n  Despite the strong performance of the WMD on text classification and semantic\ntext similarity, its super-cubic average time complexity is impractical. The\nSCM has quadratic worst-case time complexity, but its performance on text\nclassification has never been compared with the WMD. Recently, two word\nembedding regularization techniques were shown to reduce storage and memory\ncosts, and to improve training speed, document processing speed, and task\nperformance on word analogy, word similarity, and semantic text similarity.\nHowever, the effect of these techniques on text classification has not yet been\nstudied.\n  In our work, we investigate the individual and joint effect of the two word\nembedding regularization techniques on the document processing speed and the\ntask performance of the SCM and the WMD on text classification. For evaluation,\nwe use the $k$NN classifier and six standard datasets: BBCSPORT, TWITTER,\nOHSUMED, REUTERS-21578, AMAZON, and 20NEWS.\n  We show 39% average $k$NN test error reduction with regularized word\nembeddings compared to non-regularized word embeddings. We describe a practical\nprocedure for deriving such regularized embeddings through Cholesky\nfactorization. We also show that the SCM with regularized word embeddings\nsignificantly outperforms the WMD on text classification and is over 10,000\ntimes faster.", "published": "2020-03-10 22:07:34", "link": "http://arxiv.org/abs/2003.05019v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "68P20", "F.2.1; G.1.3; H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Adaptive Name Entity Recognition under Highly Unbalanced Data", "abstract": "For several purposes in Natural Language Processing (NLP), such as\nInformation Extraction, Sentiment Analysis or Chatbot, Named Entity Recognition\n(NER) holds an important role as it helps to determine and categorize entities\nin text into predefined groups such as the names of persons, locations,\nquantities, organizations or percentages, etc. In this report, we present our\nexperiments on a neural architecture composed of a Conditional Random Field\n(CRF) layer stacked on top of a Bi-directional LSTM (BI-LSTM) layer for solving\nNER tasks. Besides, we also employ a fusion input of embedding vectors (Glove,\nBERT), which are pre-trained on the huge corpus to boost the generalization\ncapacity of the model. Unfortunately, due to the heavy unbalanced distribution\ncross-training data, both approaches just attained a bad performance on less\ntraining samples classes. To overcome this challenge, we introduce an add-on\nclassification model to split sentences into two different sets: Weak and\nStrong classes and then designing a couple of Bi-LSTM-CRF models properly to\noptimize performance on each set. We evaluated our models on the test set and\ndiscovered that our method can improve performance for Weak classes\nsignificantly by using a very small data set (approximately 0.45\\%) compared to\nthe rest classes.", "published": "2020-03-10 06:56:52", "link": "http://arxiv.org/abs/2003.10296v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Generating Natural Language Adversarial Examples on a Large Scale with\n  Generative Models", "abstract": "Today text classification models have been widely used. However, these\nclassifiers are found to be easily fooled by adversarial examples. Fortunately,\nstandard attacking methods generate adversarial texts in a pair-wise way, that\nis, an adversarial text can only be created from a real-world text by replacing\na few words. In many applications, these texts are limited in numbers,\ntherefore their corresponding adversarial examples are often not diverse enough\nand sometimes hard to read, thus can be easily detected by humans and cannot\ncreate chaos at a large scale. In this paper, we propose an end to end solution\nto efficiently generate adversarial texts from scratch using generative models,\nwhich are not restricted to perturbing the given texts. We call it unrestricted\nadversarial text generation. Specifically, we train a conditional variational\nautoencoder (VAE) with an additional adversarial loss to guide the generation\nof adversarial examples. Moreover, to improve the validity of adversarial\ntexts, we utilize discrimators and the training framework of generative\nadversarial networks (GANs) to make adversarial texts consistent with real\ndata. Experimental results on sentiment analysis demonstrate the scalability\nand efficiency of our method. It can attack text classification models with a\nhigher success rate than existing methods, and provide acceptable quality for\nhumans in the meantime.", "published": "2020-03-10 03:21:35", "link": "http://arxiv.org/abs/2003.10388v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Benchmarking Study of Embedding-based Entity Alignment for Knowledge\n  Graphs", "abstract": "Entity alignment seeks to find entities in different knowledge graphs (KGs)\nthat refer to the same real-world object. Recent advancement in KG embedding\nimpels the advent of embedding-based entity alignment, which encodes entities\nin a continuous embedding space and measures entity similarities based on the\nlearned embeddings. In this paper, we conduct a comprehensive experimental\nstudy of this emerging field. We survey 23 recent embedding-based entity\nalignment approaches and categorize them based on their techniques and\ncharacteristics. We also propose a new KG sampling algorithm, with which we\ngenerate a set of dedicated benchmark datasets with various heterogeneity and\ndistributions for a realistic evaluation. We develop an open-source library\nincluding 12 representative embedding-based entity alignment approaches, and\nextensively evaluate these approaches, to understand their strengths and\nlimitations. Additionally, for several directions that have not been explored\nin current approaches, we perform exploratory experiments and report our\npreliminary findings for future studies. The benchmark datasets, open-source\nlibrary and experimental results are all accessible online and will be duly\nmaintained.", "published": "2020-03-10 05:32:06", "link": "http://arxiv.org/abs/2003.07743v2", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG", "stat.ML", "I.2.6; H.3.3"], "primary_category": "cs.CL"}
{"title": "Vowels and Prosody Contribution in Neural Network Based Voice Conversion\n  Algorithm with Noisy Training Data", "abstract": "This research presents a neural network based voice conversion (VC) model.\nWhile it is a known fact that voiced sounds and prosody are the most important\ncomponent of the voice conversion framework, what is not known is their\nobjective contributions particularly in a noisy and uncontrolled environment.\nThis model uses a 2-layer feedforward neural network to map the Linear\nprediction analysis coefficients of a source speaker to the acoustic vector\nspace of the target speaker with a view to objectively determine the\ncontributions of the voiced, unvoiced and supra-segmental components of sounds\nto the voice conversion model. Results showed that vowels 'a', 'i', 'o' have\nthe most significant contribution in the conversion success. The voiceless\nsounds were also found to be most affected by the noisy training data. An\naverage noise level of 40 dB above the noise floor were found to degrade the\nvoice conversion success by 55.14 percent relative to the voiced sounds. The\nresult also shows that for cross-gender voice conversion, prosody conversion is\nmore significant in scenarios where a female is the target speaker.", "published": "2020-03-10 11:29:43", "link": "http://arxiv.org/abs/2003.04640v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Quantifying Musical Style: Ranking Symbolic Music based on Similarity to\n  a Style", "abstract": "Modelling human perception of musical similarity is critical for the\nevaluation of generative music systems, musicological research, and many Music\nInformation Retrieval tasks. Although human similarity judgments are the gold\nstandard, computational analysis is often preferable, since results are often\neasier to reproduce, and computational methods are much more scalable.\nMoreover, computation based approaches can be calculated quickly and on demand,\nwhich is a prerequisite for use with an online system. We propose StyleRank, a\nmethod to measure the similarity between a MIDI file and an arbitrary musical\nstyle delineated by a collection of MIDI files. MIDI files are encoded using a\nnovel set of features and an embedding is learned using Random Forests.\nExperimental evidence demonstrates that StyleRank is highly correlated with\nhuman perception of stylistic similarity, and that it is precise enough to rank\ngenerated samples based on their similarity to the style of a corpus. In\naddition, similarity can be measured with respect to a single feature, allowing\nspecific discrepancies between generated samples and a particular musical style\nto be identified.", "published": "2020-03-10 05:20:15", "link": "http://arxiv.org/abs/2003.06226v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
