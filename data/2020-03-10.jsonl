{"title": "Rapid AI Development Cycle for the Coronavirus (COVID-19) Pandemic: Initial Results for Automated Detection & Patient Monitoring using Deep Learning CT Image Analysis", "abstract": "Purpose: Develop AI-based automated CT image analysis tools for detection, quantification, and tracking of Coronavirus; demonstrate they can differentiate coronavirus patients from non-patients. Materials and Methods: Multiple international datasets, including from Chinese disease-infected areas were included. We present a system that utilizes robust 2D and 3D deep learning models, modifying and adapting existing AI models and combining them with clinical understanding. We conducted multiple retrospective experiments to analyze the performance of the system in the detection of suspected COVID-19 thoracic CT features and to evaluate evolution of the disease in each patient over time using a 3D volume review, generating a Corona score. The study includes a testing set of 157 international patients (China and U.S). Results: Classification results for Coronavirus vs Non-coronavirus cases per thoracic CT studies were 0.996 AUC (95%CI: 0.989-1.00) ; on datasets of Chinese control and infected patients. Possible working point: 98.2% sensitivity, 92.2% specificity. For time analysis of Coronavirus patients, the system output enables quantitative measurements for smaller opacities (volume, diameter) and visualization of the larger opacities in a slice-based heat map or a 3D volume display. Our suggested Corona score measures the progression of disease over time. Conclusion: This initial study, which is currently being expanded to a larger population, demonstrated that rapidly developed AI-based image analysis can achieve high accuracy in detection of Coronavirus as well as quantification and tracking of disease burden.", "published": "2020-03-10 23:37:21", "link": "http://arxiv.org/abs/2003.05037v3", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Text classification with word embedding regularization and soft similarity measure", "abstract": "Since the seminal work of Mikolov et al., word embeddings have become the preferred word representations for many natural language processing tasks. Document similarity measures extracted from word embeddings, such as the soft cosine measure (SCM) and the Word Mover's Distance (WMD), were reported to achieve state-of-the-art performance on semantic text similarity and text classification.\n  Despite the strong performance of the WMD on text classification and semantic text similarity, its super-cubic average time complexity is impractical. The SCM has quadratic worst-case time complexity, but its performance on text classification has never been compared with the WMD. Recently, two word embedding regularization techniques were shown to reduce storage and memory costs, and to improve training speed, document processing speed, and task performance on word analogy, word similarity, and semantic text similarity. However, the effect of these techniques on text classification has not yet been studied.\n  In our work, we investigate the individual and joint effect of the two word embedding regularization techniques on the document processing speed and the task performance of the SCM and the WMD on text classification. For evaluation, we use the $k$NN classifier and six standard datasets: BBCSPORT, TWITTER, OHSUMED, REUTERS-21578, AMAZON, and 20NEWS.\n  We show 39% average $k$NN test error reduction with regularized word embeddings compared to non-regularized word embeddings. We describe a practical procedure for deriving such regularized embeddings through Cholesky factorization. We also show that the SCM with regularized word embeddings significantly outperforms the WMD on text classification and is over 10,000 times faster.", "published": "2020-03-10 22:07:34", "link": "http://arxiv.org/abs/2003.05019v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Pricing Interest Rate Derivatives under Volatility Uncertainty", "abstract": "In this paper, we study the pricing of contracts in fixed income markets under volatility uncertainty in the sense of Knightian uncertainty or model uncertainty. The starting point is an arbitrage-free bond market under volatility uncertainty. The uncertainty about the volatility is modeled by a G-Brownian motion, which drives the forward rate dynamics. The absence of arbitrage is ensured by a drift condition. Such a setting leads to a sublinear pricing measure for additional contracts, which yields either a single price or a range of prices. Similar to the forward measure approach, we define the forward sublinear expectation to simplify the pricing of cashflows. Under the forward sublinear expectation, we obtain a robust version of the expectations hypothesis, and we show how to price options on forward prices. In addition, we develop pricing methods for contracts consisting of a stream of cashflows, since the nonlinearity of the pricing measure implies that we cannot price a stream of cashflows by pricing each cashflow separately. With these tools, we derive robust pricing formulas for all major interest rate derivatives. The pricing formulas provide a link to the pricing formulas of traditional models without volatility uncertainty and show that volatility uncertainty naturally leads to unspanned stochastic volatility.", "published": "2020-03-10 09:45:47", "link": "http://arxiv.org/abs/2003.04606v3", "categories": ["q-fin.PR", "q-fin.MF"], "primary_category": "q-fin.PR"}
