{"title": "How big is big enough? Unsupervised word sense disambiguation using a\n  very large corpus", "abstract": "In this paper, the problem of disambiguating a target word for Polish is\napproached by searching for related words with known meaning. These relatives\nare used to build a training corpus from unannotated text. This technique is\nimproved by proposing new rich sources of replacements that substitute the\ntraditional requirement of monosemy with heuristics based on wordnet relations.\nThe na\\\"ive Bayesian classifier has been modified to account for an unknown\ndistribution of senses. A corpus of 600 million web documents (594 billion\ntokens), gathered by the NEKST search engine allows us to assess the\nrelationship between training set size and disambiguation accuracy. The\nclassifier is evaluated using both a wordnet baseline and a corpus with 17,314\nmanually annotated occurrences of 54 ambiguous words.", "published": "2017-10-22 15:12:43", "link": "http://arxiv.org/abs/1710.07960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bringing Semantic Structures to User Intent Detection in Online Medical\n  Queries", "abstract": "The Internet has revolutionized healthcare by offering medical information\nubiquitously to patients via web search. The healthcare status, complex medical\ninformation needs of patients are expressed diversely and implicitly in their\nmedical text queries. Aiming to better capture a focused picture of user's\nmedical-related information search and shed insights on their healthcare\ninformation access strategies, it is challenging yet rewarding to detect\nstructured user intentions from their diversely expressed medical text queries.\nWe introduce a graph-based formulation to explore structured concept\ntransitions for effective user intent detection in medical queries, where each\nnode represents a medical concept mention and each directed edge indicates a\nmedical concept transition. A deep model based on multi-task learning is\nintroduced to extract structured semantic transitions from user queries, where\nthe model extracts word-level medical concept mentions as well as\nsentence-level concept transitions collectively. A customized graph-based\nmutual transfer loss function is designed to impose explicit constraints and\nfurther exploit the contribution of mentioning a medical concept word to the\nimplication of a semantic transition. We observe an 8% relative improvement in\nAUC and 23% relative reduction in coverage error by comparing the proposed\nmodel with the best baseline model for the concept transition inference task on\nreal-world medical text queries.", "published": "2017-10-22 21:03:28", "link": "http://arxiv.org/abs/1710.08015v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Triphone Embedding Improves Phoneme Recognition", "abstract": "In this paper, we present a novel Deep Triphone Embedding (DTE)\nrepresentation derived from Deep Neural Network (DNN) to encapsulate the\ndiscriminative information present in the adjoining speech frames. DTEs are\ngenerated using a four hidden layer DNN with 3000 nodes in each hidden layer at\nthe first-stage. This DNN is trained with the tied-triphone classification\naccuracy as an optimization criterion. Thereafter, we retain the activation\nvectors (3000) of the last hidden layer, for each speech MFCC frame, and\nperform dimension reduction to further obtain a 300 dimensional representation,\nwhich we termed as DTE. DTEs along with MFCC features are fed into a\nsecond-stage four hidden layer DNN, which is subsequently trained for the task\nof tied-triphone classification. Both DNNs are trained using tri-phone labels\ngenerated from a tied-state triphone HMM-GMM system, by performing a\nforced-alignment between the transcriptions and MFCC feature frames. We conduct\nthe experiments on publicly available TED-LIUM speech corpus. The results show\nthat the proposed DTE method provides an improvement of absolute 2.11% in\nphoneme recognition, when compared with a competitive hybrid tied-state\ntriphone HMM-DNN system.", "published": "2017-10-22 01:06:23", "link": "http://arxiv.org/abs/1710.07868v2", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
