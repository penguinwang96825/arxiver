{"title": "Forecasting High Frequency Order Flow Imbalance", "abstract": "Market information events are generated intermittently and disseminated at\nhigh speeds in real-time. Market participants consume this high-frequency data\nto build limit order books, representing the current bids and offers for a\ngiven asset. The arrival processes, or the order flow of bid and offer events,\nare asymmetric and possibly dependent on each other. The quantum and direction\nof this asymmetry are often associated with the direction of the traded price\nmovement. The Order Flow Imbalance (OFI) is an indicator commonly used to\nestimate this asymmetry. This paper uses Hawkes processes to estimate the OFI\nwhile accounting for the lagged dependence in the order flow between bids and\noffers. Secondly, we develop a method to forecast the near-term distribution of\nthe OFI, which can then be used to compare models for forecasting OFI. Thirdly,\nwe propose a method to compare the forecasts of OFI for an arbitrarily large\nnumber of models. We apply the approach developed to tick data from the\nNational Stock Exchange and observe that the Hawkes process modeled with a Sum\nof Exponential's kernel gives the best forecast among all competing models.", "published": "2024-08-07 07:16:06", "link": "http://arxiv.org/abs/2408.03594v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your\n  Language Model Thrives on Quality Data", "abstract": "This paper presents a compute-efficient approach to pre-training a Language\nModel-the \"1.5-Pints\"-in only 9 days, while outperforming state-of-the-art\nmodels as an instruction-following assistant.Based on MT-Bench (a benchmark\nthat emulates human judgments), 1.5-Pints outperforms Apple's OpenELM and\nMicrosoft's Phi.This is achieved by a carefully curated pre-training dataset of\n57 billion tokens, using a mix of automated workflows and manual human review.\nThe selection of the dataset prioritizes content that is considered expository\nand \"textbook-like\" to aid the model in reasoning and logical deduction,\nculminating in its overall ability as a strong and versatile AI model. In terms\nof the model architecture, we employed a modified Mistral tokenizer, alongside\na Llama-2 architecture for wider compatibility. For training, we adopted the\nmethodologies used by StableLM, TinyLlama, and Huggingface Zephyr. 1.5-Pints\ndemonstrates that by focusing on data quality over quantity in LLM training, we\ncan significantly reduce training time and resources required. We believe this\napproach will not only make pre-training more accessible but also reduce our\ncarbon footprint. Our findings and resources from this research are\nopen-sourced, aiming to facilitate further advancements in the field. The\n1.5-Pints model is available in two versions: 2K and 16K context windows.", "published": "2024-08-07 02:14:52", "link": "http://arxiv.org/abs/2408.03506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EgyBERT: A Large Language Model Pretrained on Egyptian Dialect Corpora", "abstract": "This study presents EgyBERT, an Arabic language model pretrained on 10.4 GB\nof Egyptian dialectal texts. We evaluated EgyBERT's performance by comparing it\nwith five other multidialect Arabic language models across 10 evaluation\ndatasets. EgyBERT achieved the highest average F1-score of 84.25% and an\naccuracy of 87.33%, significantly outperforming all other comparative models,\nwith MARBERTv2 as the second best model achieving an F1-score 83.68% and an\naccuracy 87.19%. Additionally, we introduce two novel Egyptian dialectal\ncorpora: the Egyptian Tweets Corpus (ETC), containing over 34.33 million tweets\n(24.89 million sentences) amounting to 2.5 GB of text, and the Egyptian Forums\nCorpus (EFC), comprising over 44.42 million sentences (7.9 GB of text)\ncollected from various Egyptian online forums. Both corpora are used in\npretraining the new model, and they are the largest Egyptian dialectal corpora\nto date reported in the literature. Furthermore, this is the first study to\nevaluate the performance of various language models on Egyptian dialect\ndatasets, revealing significant differences in performance that highlight the\nneed for more dialect-specific models. The results confirm the effectiveness of\nEgyBERT model in processing and analyzing Arabic text expressed in Egyptian\ndialect, surpassing other language models included in the study. EgyBERT model\nis publicly available on \\url{https://huggingface.co/faisalq/EgyBERT}.", "published": "2024-08-07 03:23:55", "link": "http://arxiv.org/abs/2408.03524v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAGED: A Benchmark for Procedural Graphs Extraction from Documents", "abstract": "Automatic extraction of procedural graphs from documents creates a low-cost\nway for users to easily understand a complex procedure by skimming visual\ngraphs. Despite the progress in recent studies, it remains unanswered: whether\nthe existing studies have well solved this task (Q1) and whether the emerging\nlarge language models (LLMs) can bring new opportunities to this task (Q2). To\nthis end, we propose a new benchmark PAGED, equipped with a large high-quality\ndataset and standard evaluations. It investigates five state-of-the-art\nbaselines, revealing that they fail to extract optimal procedural graphs well\nbecause of their heavy reliance on hand-written rules and limited available\ndata. We further involve three advanced LLMs in PAGED and enhance them with a\nnovel self-refine strategy. The results point out the advantages of LLMs in\nidentifying textual elements and their gaps in building logical structures. We\nhope PAGED can serve as a major landmark for automatic procedural graph\nextraction and the investigations in PAGED can offer insights into the research\non logic reasoning among non-sequential elements.", "published": "2024-08-07 08:43:18", "link": "http://arxiv.org/abs/2408.03630v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CARE: A Clue-guided Assistant for CSRs to Read User Manuals", "abstract": "It is time-saving to build a reading assistant for customer service\nrepresentations (CSRs) when reading user manuals, especially information-rich\nones. Current solutions don't fit the online custom service scenarios well due\nto the lack of attention to user questions and possible responses. Hence, we\npropose to develop a time-saving and careful reading assistant for CSRs, named\nCARE. It can help the CSRs quickly find proper responses from the user manuals\nvia explicit clue chains. Specifically, each of the clue chains is formed by\ninferring over the user manuals, starting from the question clue aligned with\nthe user question and ending at a possible response. To overcome the shortage\nof supervised data, we adopt the self-supervised strategy for model learning.\nThe offline experiment shows that CARE is efficient in automatically inferring\naccurate responses from the user manual. The online experiment further\ndemonstrates the superiority of CARE to reduce CSRs' reading burden and keep\nhigh service quality, in particular with >35% decrease in time spent and\nkeeping a >0.75 ICC score.", "published": "2024-08-07 08:44:44", "link": "http://arxiv.org/abs/2408.03633v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NACL: A General and Effective KV Cache Eviction Framework for LLMs at\n  Inference Time", "abstract": "Large Language Models (LLMs) have ignited an innovative surge of AI\napplications, marking a new era of exciting possibilities equipped with\nextended context windows. However, hosting these models is cost-prohibitive\nmainly due to the extensive memory consumption of KV Cache involving\nlong-context modeling. Despite several works proposing to evict unnecessary\ntokens from the KV Cache, most of them rely on the biased local statistics of\naccumulated attention scores and report performance using unconvincing metric\nlike perplexity on inadequate short-text evaluation. In this paper, we propose\nNACL, a general framework for long-context KV cache eviction that achieves more\noptimal and efficient eviction in a single operation during the encoding phase.\nDue to NACL's efficiency, we combine more accurate attention score statistics\nin PROXY TOKENS EVICTION with the diversified random eviction strategy of\nRANDOM EVICTION, aiming to alleviate the issue of attention bias and enhance\nthe robustness in maintaining pivotal tokens for long-context modeling tasks.\nNotably, our method significantly improves the performance on short- and\nlong-text tasks by 80% and 76% respectively, reducing KV Cache by up to 50%\nwith over 95% performance maintenance. The code is available at\nhttps://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL.", "published": "2024-08-07 10:31:07", "link": "http://arxiv.org/abs/2408.03675v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "'Finance Wizard' at the FinLLM Challenge Task: Financial Text\n  Summarization", "abstract": "This paper presents our participation under the team name `Finance Wizard' in\nthe FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. It\ndocuments our pipeline approach of fine-tuning a foundation model into a\ntask-specific model for Financial Text Summarization. It involves (1) adapting\nLlama3 8B, a foundation model, to the Finance domain via continued\npre-training, (2) multi-task instruction-tuning to further equip the model with\nmore finance-related capabilities, (3) finally fine-tuning the model into a\ntask-specific `expert'. Our model, FinLlama3\\_sum, yielded commendable results,\nsecuring the third position in its category with a ROUGE-1 score of 0.521.", "published": "2024-08-07 13:31:44", "link": "http://arxiv.org/abs/2408.03762v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why transformers are obviously good models of language", "abstract": "Nobody knows how language works, but many theories abound. Transformers are a\nclass of neural networks that process language automatically with more success\nthan alternatives, both those based on neural computations and those that rely\non other (e.g. more symbolic) mechanisms. Here, I highlight direct connections\nbetween the transformer architecture and certain theoretical perspectives on\nlanguage. The empirical success of transformers relative to alternative models\nprovides circumstantial evidence that the linguistic approaches that\ntransformers embody should be, at least, evaluated with greater scrutiny by the\nlinguistics community and, at best, considered to be the currently best\navailable theories.", "published": "2024-08-07 15:52:46", "link": "http://arxiv.org/abs/2408.03855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalized Clinical Note Generation from Doctor-Patient Conversations", "abstract": "In this work, we present a novel technique to improve the quality of draft\nclinical notes for physicians. This technique is concentrated on the ability to\nmodel implicit physician conversation styles and note preferences. We also\nintroduce a novel technique for the enrollment of new physicians when a limited\nnumber of clinical notes paired with conversations are available for that\nphysician, without the need to re-train a model to support them. We show that\nour technique outperforms the baseline model by improving the ROUGE-2 score of\nthe History of Present Illness section by 13.8%, the Physical Examination\nsection by 88.6%, and the Assessment & Plan section by 50.8%.", "published": "2024-08-07 16:24:01", "link": "http://arxiv.org/abs/2408.03874v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Words to Worth: Newborn Article Impact Prediction with LLM", "abstract": "As the academic landscape expands, the challenge of efficiently identifying\nimpactful newly published articles grows increasingly vital. This paper\nintroduces a promising approach, leveraging the capabilities of LLMs to predict\nthe future impact of newborn articles solely based on titles and abstracts.\nMoving beyond traditional methods heavily reliant on external information, the\nproposed method employs LLM to discern the shared semantic features of highly\nimpactful papers from a large collection of title-abstract pairs. These\nsemantic features are further utilized to predict the proposed indicator,\nTNCSI_SP, which incorporates favorable normalization properties across value,\nfield, and time. To facilitate parameter-efficient fine-tuning of the LLM, we\nhave also meticulously curated a dataset containing over 12,000 entries, each\nannotated with titles, abstracts, and their corresponding TNCSI_SP values. The\nquantitative results, with an MAE of 0.216 and an NDCG@20 of 0.901, demonstrate\nthat the proposed approach achieves state-of-the-art performance in predicting\nthe impact of newborn articles when compared to several promising methods.\nFinally, we present a real-world application example for predicting the impact\nof newborn journal articles to demonstrate its noteworthy practical value.\nOverall, our findings challenge existing paradigms and propose a shift towards\na more content-focused prediction of academic impact, offering new insights for\narticle impact prediction.", "published": "2024-08-07 17:52:02", "link": "http://arxiv.org/abs/2408.03934v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human Speech Perception in Noise: Can Large Language Models Paraphrase\n  to Improve It?", "abstract": "Large Language Models (LLMs) can generate text by transferring style\nattributes like formality resulting in formal or informal text. However,\ninstructing LLMs to generate text that when spoken, is more intelligible in an\nacoustically difficult environment, is an under-explored topic. We conduct the\nfirst study to evaluate LLMs on a novel task of generating acoustically\nintelligible paraphrases for better human speech perception in noise. Our\nexperiments in English demonstrated that with standard prompting, LLMs struggle\nto control the non-textual attribute, i.e., acoustic intelligibility, while\nefficiently capturing the desired textual attributes like semantic equivalence.\nTo remedy this issue, we propose a simple prompting approach,\nprompt-and-select, which generates paraphrases by decoupling the desired\ntextual and non-textual attributes in the text generation pipeline. Our\napproach resulted in a 40% relative improvement in human speech perception, by\nparaphrasing utterances that are highly distorted in a listening condition with\nbabble noise at a signal-to-noise ratio (SNR) -5 dB. This study reveals the\nlimitation of LLMs in capturing non-textual attributes, and our proposed method\nshowcases the potential of using LLMs for better human speech perception in\nnoise.", "published": "2024-08-07 18:24:23", "link": "http://arxiv.org/abs/2408.04029v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StructuredRAG: JSON Response Formatting with Large Language Models", "abstract": "The ability of Large Language Models (LLMs) to generate structured outputs,\nsuch as JSON, is crucial for their use in Compound AI Systems. However,\nevaluating and improving this capability remains challenging. In this work, we\nintroduce StructuredRAG, a benchmark of six tasks designed to assess LLMs'\nproficiency in following response format instructions. We evaluate two\nstate-of-the-art LLMs, Gemini 1.5 Pro and Llama 3 8B-instruct with 4-bit\nquantization using two distinct prompting strategies. We introduce these\nprompting strategies as f-String and Follow the Format (FF) prompting. Across\n24 experiments, we find an average success rate of 82.55%. We further find a\nhigh variance in performance across tasks, models, and prompting strategies\nwith success rates ranging from 0 to 100%. We find that Llama 3 8B-instruct\noften performs competitively with Gemini 1.5 Pro. We observe that task\ncomplexity significantly influences performance, with tasks involving lists or\ncomposite object outputs proving more challenging. Our findings highlight the\nneed for further research into improving the reliability and consistency of\nstructured output generation in LLMs. We have open-sourced our experimental\ncode and results at github.com/weaviate/structured-rag.", "published": "2024-08-07 19:32:59", "link": "http://arxiv.org/abs/2408.11061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Theorem Provers Help Improve Large Language Model Reasoning", "abstract": "In this paper we demonstrate how logic programming systems and Automated\nfirst-order logic Theorem Provers (ATPs) can improve the accuracy of Large\nLanguage Models (LLMs) for logical reasoning tasks where the baseline\nperformance is given by direct LLM solutions. We first evaluate LLM reasoning\non steamroller problems using the PRONTOQA benchmark. We show how accuracy can\nbe improved with a neuro-symbolic architecture where the LLM acts solely as a\nfront-end for translating a given problem into a formal logic language and an\nautomated reasoning engine is called for solving it. However, this approach\ncritically hinges on the correctness of the LLM translation. To assess this\ntranslation correctness, we secondly define a framework of syntactic and\nsemantic error categories. We implemented the framework and used it to identify\nerrors that LLMs make in the benchmark domain. Based on these findings, we\nthirdly extended our method with capabilities for automatically correcting\nsyntactic and semantic errors. For semantic error correction we integrate\nfirst-order logic ATPs, which is our main and novel contribution. We\ndemonstrate that this approach reduces semantic errors significantly and\nfurther increases the accurracy of LLM logical reasoning.", "published": "2024-08-07 01:03:56", "link": "http://arxiv.org/abs/2408.03492v1", "categories": ["cs.AI", "cs.CL", "F.4.1; I.2.7; I.2.8"], "primary_category": "cs.AI"}
{"title": "MoExtend: Tuning New Experts for Modality and Task Extension", "abstract": "Large language models (LLMs) excel in various tasks but are primarily trained\non text data, limiting their application scope. Expanding LLM capabilities to\ninclude vision-language understanding is vital, yet training them on multimodal\ndata from scratch is challenging and costly. Existing instruction tuning\nmethods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs\nvia fully fine-tuning LLMs to bridge the modality gap. However, full\nfine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous\nknowledge, and high training costs particularly in the era of increasing tasks\nand modalities. To solve this issue, we introduce MoExtend, an effective\nframework designed to streamline the modality adaptation and extension of\nMixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts\ninto pre-trained MoE models, endowing them with novel knowledge without the\nneed to tune pretrained models such as MoE and vision encoders. This approach\nenables rapid adaptation and extension to new modal data or tasks, effectively\naddressing the challenge of accommodating new modalities within LLMs.\nFurthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk\nof catastrophic forgetting. Experimental results demonstrate the efficacy and\nefficiency of MoExtend in enhancing the multimodal capabilities of LLMs,\ncontributing to advancements in multimodal AI research. Code:\nhttps://github.com/zhongshsh/MoExtend.", "published": "2024-08-07 02:28:37", "link": "http://arxiv.org/abs/2408.03511v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "EXAONE 3.0 7.8B Instruction Tuned Language Model", "abstract": "We introduce EXAONE 3.0 instruction-tuned language model, the first open\nmodel in the family of Large Language Models (LLMs) developed by LG AI\nResearch. Among different model sizes, we publicly release the 7.8B\ninstruction-tuned model to promote open research and innovations. Through\nextensive evaluations across a wide range of public and in-house benchmarks,\nEXAONE 3.0 demonstrates highly competitive real-world performance with\ninstruction-following capability against other state-of-the-art open models of\nsimilar size. Our comparative analysis shows that EXAONE 3.0 excels\nparticularly in Korean, while achieving compelling performance across general\ntasks and complex reasoning. With its strong real-world effectiveness and\nbilingual proficiency, we hope that EXAONE keeps contributing to advancements\nin Expert AI. Our EXAONE 3.0 instruction-tuned model is available at\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct", "published": "2024-08-07 04:38:38", "link": "http://arxiv.org/abs/2408.03541v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NatLan: Native Language Prompting Facilitates Knowledge Elicitation\n  Through Language Trigger Provision and Domain Trigger Retention", "abstract": "Multilingual large language models (MLLMs) do not perform as well when\nanswering questions in non-dominant languages as they do in their dominant\nlanguages. Although existing translate-then-answer methods alleviate this\nissue, the mechanisms behind their effectiveness remain unclear. In this study,\nwe analogize the dominant language of MLLMs to the native language of humans\nand use two human cognitive features: the Language Trigger (LT) and the Domain\nTrigger (DT), to interpret the mechanisms behind translate-then-answer methods.\nThis reveals that while sufficient LTs are provided by these methods, there\nremains a deficiency in DT retention. To mitigate this issue, we propose Native\nLanguage Prompting (NatLan), employing a Multi-MLLM collaboration strategy and\nintroducing an additional role-enhanced domain-specific MLLM with stronger\nmultilingual understanding capabilities as the translator. Across five language\nQA benchmarks, NatLan achieves up to a 31.28% improvement in accuracy and,\ncompared to existing state-of-the-art methods, provides comparable or greater\nretention of DTs in up to 87% of cases. Our code is available at\nhttps://github.com/AnonyNLP/NatLan.", "published": "2024-08-07 04:49:38", "link": "http://arxiv.org/abs/2408.03544v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel\n  Chatbot Use Case", "abstract": "This research compares large language model (LLM) fine-tuning methods,\nincluding Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning\n(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally\ncompared LLM evaluation methods including End to End (E2E) benchmark method of\n\"Golden Answers\", traditional natural language processing (NLP) metrics, RAG\nAssessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,\nusing the travel chatbot use case. The travel dataset was sourced from the the\nReddit API by requesting posts from travel-related subreddits to get\ntravel-related conversation prompts and personalized travel experiences, and\naugmented for each fine-tuning method. We used two pretrained LLMs utilized for\nfine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to\nthe two pretrained models. The inferences from these models are extensively\nevaluated against the aforementioned metrics. The best model according to human\nevaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a\nReinforcement Learning from Human Feedback (RLHF) training pipeline, and\nultimately was evaluated as the best model. Our main findings are that: 1)\nquantitative and Ragas metrics do not align with human evaluation, 2) Open AI\nGPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep\nhumans in the loop for evaluation because, 4) traditional NLP metrics\ninsufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms\nQLoRA, but still needs postprocessing, 7) RLHF improves model performance\nsignificantly. Next steps include improving data quality, increasing data\nquantity, exploring RAG methods, and focusing data collection on a specific\ncity, which would improve data quality by narrowing the focus, while creating a\nuseful product.", "published": "2024-08-07 05:52:00", "link": "http://arxiv.org/abs/2408.03562v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unlocking Exocentric Video-Language Data for Egocentric Video\n  Representation Learning", "abstract": "We present EMBED (Egocentric Models Built with Exocentric Data), a method\ndesigned to transform exocentric video-language data for egocentric video\nrepresentation learning. Large-scale exocentric data covers diverse activities\nwith significant potential for egocentric learning, but inherent disparities\nbetween egocentric and exocentric data pose challenges in utilizing one view\nfor the other seamlessly. Egocentric videos predominantly feature close-up\nhand-object interactions, whereas exocentric videos offer a broader perspective\non human activities. Additionally, narratives in egocentric datasets are\ntypically more action-centric and closely linked with the visual content, in\ncontrast to the narrative styles found in exocentric datasets. To address these\nchallenges, we employ a data transformation framework to adapt exocentric data\nfor egocentric training, focusing on identifying specific video clips that\nemphasize hand-object interactions and transforming narration styles to align\nwith egocentric perspectives. By applying both vision and language style\ntransfer, our framework creates a new egocentric dataset derived from\nexocentric video-language data. Through extensive evaluations, we demonstrate\nthe effectiveness of EMBED, achieving state-of-the-art results across various\negocentric downstream tasks, including an absolute improvement of 4.7% on the\nEpic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification\nbenchmarks in zero-shot settings. Furthermore, EMBED enables egocentric\nvideo-language models to perform competitively in exocentric tasks. Finally, we\nshowcase EMBED's application across various exocentric datasets, exhibiting\nstrong generalization capabilities when applied to different exocentric\ndatasets.", "published": "2024-08-07 06:10:45", "link": "http://arxiv.org/abs/2408.03567v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in\n  Long-Horizon Tasks", "abstract": "Building a general-purpose agent is a long-standing vision in the field of\nartificial intelligence. Existing agents have made remarkable progress in many\ndomains, yet they still struggle to complete long-horizon tasks in an open\nworld. We attribute this to the lack of necessary world knowledge and\nmultimodal experience that can guide agents through a variety of long-horizon\ntasks. In this paper, we propose a Hybrid Multimodal Memory module to address\nthe above challenges. It 1) transforms knowledge into Hierarchical Directed\nKnowledge Graph that allows agents to explicitly represent and learn world\nknowledge, and 2) summarises historical information into Abstracted Multimodal\nExperience Pool that provide agents with rich references for in-context\nlearning. On top of the Hybrid Multimodal Memory module, a multimodal agent,\nOptimus-1, is constructed with dedicated Knowledge-guided Planner and\nExperience-Driven Reflector, contributing to a better planning and reflection\nin the face of long-horizon tasks in Minecraft. Extensive experimental results\nshow that Optimus-1 significantly outperforms all existing agents on\nchallenging long-horizon task benchmarks, and exhibits near human-level\nperformance on many tasks. In addition, we introduce various Multimodal Large\nLanguage Models (MLLMs) as the backbone of Optimus-1. Experimental results show\nthat Optimus-1 exhibits strong generalization with the help of the Hybrid\nMultimodal Memory module, outperforming the GPT-4V baseline on many tasks.", "published": "2024-08-07 08:16:32", "link": "http://arxiv.org/abs/2408.03615v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Improving the quality of Persian clinical text with a novel spelling\n  correction system", "abstract": "Background: The accuracy of spelling in Electronic Health Records (EHRs) is a\ncritical factor for efficient clinical care, research, and ensuring patient\nsafety. The Persian language, with its abundant vocabulary and complex\ncharacteristics, poses unique challenges for real-word error correction. This\nresearch aimed to develop an innovative approach for detecting and correcting\nspelling errors in Persian clinical text.\n  Methods: Our strategy employs a state-of-the-art pre-trained model that has\nbeen meticulously fine-tuned specifically for the task of spelling correction\nin the Persian clinical domain. This model is complemented by an innovative\northographic similarity matching algorithm, PERTO, which uses visual similarity\nof characters for ranking correction candidates.\n  Results: The evaluation of our approach demonstrated its robustness and\nprecision in detecting and rectifying word errors in Persian clinical text. In\nterms of non-word error correction, our model achieved an F1-Score of 90.0%\nwhen the PERTO algorithm was employed. For real-word error detection, our model\ndemonstrated its highest performance, achieving an F1-Score of 90.6%.\nFurthermore, the model reached its highest F1-Score of 91.5% for real-word\nerror correction when the PERTO algorithm was employed.\n  Conclusions: Despite certain limitations, our method represents a substantial\nadvancement in the field of spelling error detection and correction for Persian\nclinical text. By effectively addressing the unique challenges posed by the\nPersian language, our approach paves the way for more accurate and efficient\nclinical documentation, contributing to improved patient care and safety.\nFuture research could explore its use in other areas of the Persian medical\ndomain, enhancing its impact and utility.", "published": "2024-08-07 08:31:42", "link": "http://arxiv.org/abs/2408.03622v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Model as a Catalyst: A Paradigm Shift in Base Station\n  Siting Optimization", "abstract": "Traditional base station siting (BSS) methods rely heavily on drive testing\nand user feedback, which are laborious and require extensive expertise in\ncommunication, networking, and optimization. As large language models (LLMs)\nand their associated technologies advance, particularly in the realms of prompt\nengineering and agent engineering, network optimization will witness a\nrevolutionary approach. This approach entails the strategic use of well-crafted\nprompts to infuse human experience and knowledge into these sophisticated LLMs,\nand the deployment of autonomous agents as a communication bridge to seamlessly\nconnect the machine language based LLMs with human users using natural\nlanguage. Furthermore, our proposed framework incorporates retrieval-augmented\ngeneration (RAG) to enhance the system's ability to acquire domain-specific\nknowledge and generate solutions, thereby enabling the customization and\noptimization of the BSS process. This integration represents the future\nparadigm of artificial intelligence (AI) as a service and AI for more ease.\nThis research first develops a novel LLM-empowered BSS optimization framework,\nand heuristically proposes three different potential implementations: the\nstrategies based on Prompt-optimized LLM (PoL), LLM-empowered autonomous BSS\nagent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa).\nThrough evaluation on real-world data, the experiments demonstrate that\nprompt-assisted LLMs and LLM-based agents can generate more efficient and\nreliable network deployments, noticeably enhancing the efficiency of BSS\noptimization and reducing trivial manual participation.", "published": "2024-08-07 08:43:32", "link": "http://arxiv.org/abs/2408.03631v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest\n  Neighbor Search", "abstract": "Named Entity Recognition (NER) is a task in Natural Language Processing (NLP)\nthat aims to identify and classify entities in text into predefined categories.\nHowever, when applied to Arabic data, NER encounters unique challenges stemming\nfrom the language's rich morphological inflections, absence of capitalization\ncues, and spelling variants, where a single word can comprise multiple\nmorphemes. In this paper, we introduce Arabic KNN-NER, our submission to the\nWojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the\nshared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained\nflat-entity recognition for Arabic text, where we identify a single main entity\nand possibly zero or multiple sub-entities for each word. Arabic KNN-NER\naugments the probability distribution of a fine-tuned model with another label\nprobability distribution derived from performing a KNN search over the cached\ntraining data. Our submission achieved 91% on the test set on the WojoodFine\ndataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.", "published": "2024-08-07 09:34:55", "link": "http://arxiv.org/abs/2408.03652v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language\n  Models", "abstract": "WalledEval is a comprehensive AI safety testing toolkit designed to evaluate\nlarge language models (LLMs). It accommodates a diverse range of models,\nincluding both open-weight and API-based ones, and features over 35 safety\nbenchmarks covering areas such as multilingual safety, exaggerated safety, and\nprompt injections. The framework supports both LLM and judge benchmarking and\nincorporates custom mutators to test safety against various text-style\nmutations, such as future tense and paraphrasing. Additionally, WalledEval\nintroduces WalledGuard, a new, small, and performant content moderation tool,\nand two datasets: SGXSTest and HIXSTest, which serve as benchmarks for\nassessing the exaggerated safety of LLMs and judges in cultural contexts. We\nmake WalledEval publicly available at https://github.com/walledai/walledeval.", "published": "2024-08-07 15:22:44", "link": "http://arxiv.org/abs/2408.03837v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hate Speech Detection and Classification in Amharic Text with Deep\n  Learning", "abstract": "Hate speech is a growing problem on social media. It can seriously impact\nsociety, especially in countries like Ethiopia, where it can trigger conflicts\namong diverse ethnic and religious groups. While hate speech detection in\nresource rich languages are progressing, for low resource languages such as\nAmharic are lacking. To address this gap, we develop Amharic hate speech data\nand SBi-LSTM deep learning model that can detect and classify text into four\ncategories of hate speech: racial, religious, gender, and non-hate speech. We\nhave annotated 5k Amharic social media post and comment data into four\ncategories. The data is annotated using a custom annotation tool by a total of\n100 native Amharic speakers. The model achieves a 94.8 F1-score performance.\nFuture improvements will include expanding the dataset and develop state-of-the\nart models.\n  Keywords: Amharic hate speech detection, classification, Amharic dataset,\nDeep Learning, SBi-LSTM", "published": "2024-08-07 15:46:45", "link": "http://arxiv.org/abs/2408.03849v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Biomedical Text Simplification: Promising But\n  Not There Yet", "abstract": "In this system report, we describe the models and methods we used for our\nparticipation in the PLABA2023 task on biomedical abstract simplification, part\nof the TAC 2023 tracks. The system outputs we submitted come from the following\nthree categories: 1) domain fine-tuned T5-like models including Biomedical-T5\nand Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes\n(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we\ncarried out for this task on BioGPT finetuning. In the official automatic\nevaluation using SARI scores, BeeManc ranks 2nd among all teams and our model\nLaySciFive ranks 3rd among all 13 evaluated systems. In the official human\nevaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score\n92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It\nalso produced a high score 91.57 on Fluency in comparison to the highest score\n93.53. In the second round of submissions, our team using ChatGPT-prompting\nranks the 2nd in several categories including simplified term accuracy score\n92.26 and completeness score 96.58, and a very similar score on faithfulness\nscore 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our\ncodes, fine-tuned models, prompts, and data splits from the system development\nstage will be available at https://github.com/ HECTA-UoM/PLABA-MU", "published": "2024-08-07 16:21:41", "link": "http://arxiv.org/abs/2408.03871v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decoding Biases: Automated Methods and LLM Judges for Gender Bias\n  Detection in Language Models", "abstract": "Large Language Models (LLMs) have excelled at language understanding and\ngenerating human-level text. However, even with supervised training and human\nalignment, these LLMs are susceptible to adversarial attacks where malicious\nusers can prompt the model to generate undesirable text. LLMs also inherently\nencode potential biases that can cause various harmful effects during\ninteractions. Bias evaluation metrics lack standards as well as consensus and\nexisting methods often rely on human-generated templates and annotations which\nare expensive and labor intensive. In this work, we train models to\nautomatically create adversarial prompts to elicit biased responses from target\nLLMs. We present LLM- based bias evaluation metrics and also analyze several\nexisting automatic evaluation methods and metrics. We analyze the various\nnuances of model responses, identify the strengths and weaknesses of model\nfamilies, and assess where evaluation methods fall short. We compare these\nmetrics to human evaluation and validate that the LLM-as-a-Judge metric aligns\nwith human judgement on bias in response generation.", "published": "2024-08-07 17:11:34", "link": "http://arxiv.org/abs/2408.03907v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Image-to-LaTeX Converter for Mathematical Formulas and Text", "abstract": "In this project, we train a vision encoder-decoder model to generate LaTeX\ncode from images of mathematical formulas and text. Utilizing a diverse\ncollection of image-to-LaTeX data, we build two models: a base model with a\nSwin Transformer encoder and a GPT-2 decoder, trained on machine-generated\nimages, and a fine-tuned version enhanced with Low-Rank Adaptation (LoRA)\ntrained on handwritten formulas. We then compare the BLEU performance of our\nspecialized model on a handwritten test set with other similar models, such as\nPix2Text, TexTeller, and Sumen. Through this project, we contribute open-source\nmodels for converting images to LaTeX and provide from-scratch code for\nbuilding these models with distributed training and GPU optimizations.", "published": "2024-08-07 18:04:01", "link": "http://arxiv.org/abs/2408.04015v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Improving Large Language Model (LLM) fidelity through context-aware\n  grounding: A systematic approach to reliability and veracity", "abstract": "As Large Language Models (LLMs) become increasingly sophisticated and\nubiquitous in natural language processing (NLP) applications, ensuring their\nrobustness, trustworthiness, and alignment with human values has become a\ncritical challenge. This paper presents a novel framework for contextual\ngrounding in textual models, with a particular emphasis on the Context\nRepresentation stage. Our approach aims to enhance the reliability and ethical\nalignment of these models through a comprehensive, context-aware methodology.\nBy explicitly capturing and representing relevant situational, cultural, and\nethical contexts in a machine-readable format, we lay the foundation for\nanchoring a model's behavior within these contexts. Our approach leverages\ntechniques from knowledge representation and reasoning, such as ontologies,\nsemantic web technologies, and logic-based formalisms. We evaluate our\nframework on real-world textual datasets, demonstrating its effectiveness in\nimproving model performance, fairness, and alignment with human expectations,\nwhile maintaining high accuracy. Furthermore, we discuss the other key\ncomponents of the framework, including context-aware encoding, context-aware\nlearning, interpretability and explainability, and continuous monitoring and\nadaptation. This research contributes to the growing body of work on\nresponsible AI, offering a practical approach to developing more reliable,\ntrustworthy, and ethically-aligned language models. Our findings have\nsignificant implications for the deployment of LLMs in sensitive domains such\nas healthcare, legal systems, and social services, where contextual\nunderstanding is paramount.", "published": "2024-08-07 18:12:02", "link": "http://arxiv.org/abs/2408.04023v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tree Attention: Topology-aware Decoding for Long-Context Attention on\n  GPU clusters", "abstract": "Our formulation reveals that the reduction across the sequence axis can be\nefficiently computed in parallel through a tree reduction. Our algorithm,\ncalled Tree Attention, for parallelizing exact attention computation across\nmultiple GPUs enables cross-device decoding to be performed asymptotically\nfaster (up to 8x faster in our experiments) than state-of-the-art approaches\nsuch as Ring Attention, while also requiring significantly less communication\nvolume and incurring 2x less peak memory. We demonstrate that Tree Attention\nspeeds up decoding up to 4x on Llama 3.1-8B and can be applied to a variety of\nhardware and networking setups such as H100 DGX nodes, AMD MI300x nodes, and\nPCIe connected NVIDIA RTX 4090s. Our code is publicly available here:\nhttps://github.com/Zyphra/tree_attention", "published": "2024-08-07 21:16:55", "link": "http://arxiv.org/abs/2408.04093v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Zero-shot Factual Consistency Evaluation Across Domains", "abstract": "This work addresses the challenge of factual consistency in text generation\nsystems. We unify the tasks of Natural Language Inference, Summarization\nEvaluation, Factuality Verification and Factual Consistency Evaluation to train\nmodels capable of evaluating the factual consistency of source-target pairs\nacross diverse domains. We rigorously evaluate these against eight baselines on\na comprehensive benchmark suite comprising 22 datasets that span various tasks,\ndomains, and document lengths. Results demonstrate that our method achieves\nstate-of-the-art performance on this heterogeneous benchmark while addressing\nefficiency concerns and attaining cross-domain generalization.", "published": "2024-08-07 22:32:19", "link": "http://arxiv.org/abs/2408.04114v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identifying and Mitigating Social Bias Knowledge in Language Models", "abstract": "Generating fair and accurate predictions plays a pivotal role in deploying\nlarge language models (LLMs) in the real world. However, existing debiasing\nmethods inevitably generate unfair or incorrect predictions as they are\ndesigned and evaluated to achieve parity across different social groups but\nleave aside individual commonsense facts, resulting in modified knowledge that\nelicits unreasonable or undesired predictions. In this paper, we first\nestablish a new bias mitigation benchmark, BiaScope, which systematically\nassesses performance by leveraging newly constructed datasets and metrics on\nknowledge retention and generalization. Then, we propose a novel debiasing\napproach, Fairness Stamp (FAST), which enables fine-grained calibration of\nindividual social biases. FAST identifies the decisive layer responsible for\nstoring social biases and then calibrates its outputs by integrating a small\nmodular network, considering both bias mitigation and knowledge-preserving\ndemands. Comprehensive experiments demonstrate that FAST surpasses\nstate-of-the-art baselines with superior debiasing performance while not\ncompromising the overall model capability for knowledge retention and\ndownstream predictions. This highlights the potential of fine-grained debiasing\nstrategies to achieve fairness in LLMs.", "published": "2024-08-07 17:14:58", "link": "http://arxiv.org/abs/2408.11843v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble\n  Exploitation", "abstract": "Multimodal large language models (MLLMs) have extended the success of large\nlanguage models (LLMs) to multiple data types, such as image, text and audio,\nachieving significant performance in various domains, including multimodal\ntranslation, visual question answering and content generation. Nonetheless,\nexisting systems are inefficient to train MLLMs due to substantial GPU bubbles\ncaused by the heterogeneous modality models and complex data dependencies in 3D\nparallelism. This paper proposes Optimus, a distributed MLLM training system\nthat reduces end-to-end MLLM training time. Optimus is based on our principled\nanalysis that scheduling the encoder computation within the LLM bubbles can\nreduce bubbles in MLLM training. To make scheduling encoder computation\npossible for all GPUs, Optimus searches the separate parallel plans for encoder\nand LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM\nbubbles without breaking the original data dependencies in the MLLM model\narchitecture. We further decompose encoder layer computation into a series of\nkernels, and analyze the common bubble pattern of 3D parallelism to carefully\noptimize the sub-millisecond bubble scheduling, minimizing the overall training\ntime. Our experiments in a production cluster show that Optimus accelerates\nMLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs\ncompared to baselines.", "published": "2024-08-07 02:08:29", "link": "http://arxiv.org/abs/2408.03505v1", "categories": ["cs.CL", "cs.AI", "cs.DC"], "primary_category": "cs.CL"}
{"title": "Empirical Analysis of Large Vision-Language Models against Goal\n  Hijacking via Visual Prompt Injection", "abstract": "We explore visual prompt injection (VPI) that maliciously exploits the\nability of large vision-language models (LVLMs) to follow instructions drawn\nonto the input image. We propose a new VPI method, \"goal hijacking via visual\nprompt injection\" (GHVPI), that swaps the execution task of LVLMs from an\noriginal task to an alternative task designated by an attacker. The\nquantitative analysis indicates that GPT-4V is vulnerable to the GHVPI and\ndemonstrates a notable attack success rate of 15.8%, which is an unignorable\nsecurity risk. Our analysis also shows that successful GHVPI requires high\ncharacter recognition capability and instruction-following ability in LVLMs.", "published": "2024-08-07 05:30:10", "link": "http://arxiv.org/abs/2408.03554v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Active Testing of Large Language Model via Multi-Stage Sampling", "abstract": "Performance evaluation plays a crucial role in the development life cycle of\nlarge language models (LLMs). It estimates the model's capability, elucidates\nbehavior characteristics, and facilitates the identification of potential\nissues and limitations, thereby guiding further improvement. Given that LLMs'\ndiverse task-handling abilities stem from large volumes of training data, a\ncomprehensive evaluation also necessitates abundant, well-annotated, and\nrepresentative test data to assess LLM performance across various downstream\ntasks. However, the demand for high-quality test data often entails substantial\ntime, computational resources, and manual efforts, sometimes causing the\nevaluation to be inefficient or impractical. To address these challenges,\nresearchers propose active testing, which estimates the overall performance by\nselecting a subset of test data. Nevertheless, the existing active testing\nmethods tend to be inefficient, even inapplicable, given the unique new\nchallenges of LLMs (e.g., diverse task types, increased model complexity, and\nunavailability of training data). To mitigate such limitations and expedite the\ndevelopment cycle of LLMs, in this work, we introduce AcTracer, an active\ntesting framework tailored for LLMs that strategically selects a small subset\nof test data to achieve a nearly optimal performance estimation for LLMs.\nAcTracer utilizes both internal and external information from LLMs to guide the\ntest sampling process, reducing variance through a multi-stage pool-based\nactive selection. Our experiment results demonstrate that AcTracer achieves\nstate-of-the-art performance compared to existing methods across various tasks,\nwith up to 38.83% improvement over previous SOTA.", "published": "2024-08-07 06:17:48", "link": "http://arxiv.org/abs/2408.03573v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "D.2.5; I.2.7"], "primary_category": "cs.SE"}
{"title": "Teach CLIP to Develop a Number Sense for Ordinal Regression", "abstract": "Ordinal regression is a fundamental problem within the field of computer\nvision, with customised well-trained models on specific tasks. While\npre-trained vision-language models (VLMs) have exhibited impressive performance\non various vision tasks, their potential for ordinal regression has received\nless exploration. In this study, we first investigate CLIP's potential for\nordinal regression, from which we expect the model could generalise to\ndifferent ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP\nfails on this task, since current VLMs have a well-documented limitation of\nencapsulating compositional concepts such as number sense. We propose a simple\nyet effective method called NumCLIP to improve the quantitative understanding\nof VLMs. We disassemble the exact image to number-specific text matching\nproblem into coarse classification and fine prediction stages. We discretize\nand phrase each numerical bin with common language concept to better leverage\nthe available pre-trained alignment in CLIP. To consider the inherent\ncontinuous property of ordinal regression, we propose a novel fine-grained\ncross-modal ranking-based regularisation loss specifically designed to keep\nboth semantic and ordinal alignment in CLIP's feature space. Experimental\nresults on three general ordinal regression tasks demonstrate the effectiveness\nof NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating\nand image aesthetics assessment task, respectively. Code is publicly available\nat https://github.com/xmed-lab/NumCLIP.", "published": "2024-08-07 06:26:04", "link": "http://arxiv.org/abs/2408.03574v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "EnJa: Ensemble Jailbreak on Large Language Models", "abstract": "As Large Language Models (LLMs) are increasingly being deployed in\nsafety-critical applications, their vulnerability to potential jailbreaks --\nmalicious prompts that can disable the safety mechanism of LLMs -- has\nattracted growing research attention. While alignment methods have been\nproposed to protect LLMs from jailbreaks, many have found that aligned LLMs can\nstill be jailbroken by carefully crafted malicious prompts, producing content\nthat violates policy regulations. Existing jailbreak attacks on LLMs can be\ncategorized into prompt-level methods which make up stories/logic to circumvent\nsafety alignment and token-level attack methods which leverage gradient methods\nto find adversarial tokens. In this work, we introduce the concept of Ensemble\nJailbreak and explore methods that can integrate prompt-level and token-level\njailbreak into a more powerful hybrid jailbreak attack. Specifically, we\npropose a novel EnJa attack to hide harmful instructions using prompt-level\njailbreak, boost the attack success rate using a gradient-based attack, and\nconnect the two types of jailbreak attacks via a template-based connector. We\nevaluate the effectiveness of EnJa on several aligned models and show that it\nachieves a state-of-the-art attack success rate with fewer queries and is much\nstronger than any individual jailbreak.", "published": "2024-08-07 07:46:08", "link": "http://arxiv.org/abs/2408.03603v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Is Child-Directed Speech Effective Training Data for Language Models?", "abstract": "While high-performing language models are typically trained on hundreds of\nbillions of words, human children become fluent language users with a much\nsmaller amount of data. What are the features of the data they receive, and how\ndo these features support language modeling objectives? To investigate this\nquestion, we train GPT-2 and RoBERTa models on 29M words of English\nchild-directed speech and a new matched, synthetic dataset (TinyDialogues),\ncomparing to OpenSubtitles, Wikipedia, and a heterogeneous blend of datasets\nfrom the BabyLM challenge. We evaluate the syntactic and semantic knowledge of\nthese models using developmentally-inspired evaluations. Through pretraining\nexperiments, we test whether the global developmental ordering or the local\ndiscourse ordering of children's training data supports high performance\nrelative to other datasets. The local properties of the data affect model\nresults, but surprisingly, global properties do not. Further, child language\ninput is not uniquely valuable for training language models. These findings\nsupport the hypothesis that, rather than proceeding from better data, the\nchild's learning algorithm is substantially more data-efficient than current\nlanguage modeling techniques.", "published": "2024-08-07 08:18:51", "link": "http://arxiv.org/abs/2408.03617v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Logical Fallacy-Informed Framework for Argument Generation", "abstract": "Despite the remarkable performance of Large Language Models (LLMs) in natural\nlanguage processing tasks, they still struggle with generating logically sound\narguments, resulting in potential risks such as spreading misinformation. To\naddress this issue, we introduce FIPO, a fallacy-informed framework that\nleverages preference optimization methods to steer LLMs toward logically sound\narguments. FIPO includes a classification loss, to capture the fine-grained\ninformation on fallacy types. Our results on argumentation datasets show that\nour method reduces the fallacy errors by up to 17.5%. Furthermore, our human\nevaluation results indicate that the quality of the generated arguments by our\nmethod significantly outperforms the fine-tuned baselines, as well as other\npreference optimization methods, such as DPO. These findings highlight the\nimportance of ensuring models are aware of logical fallacies for effective\nargument generation. Our code is available at\ngithub.com/lucamouchel/Logical-Fallacies.", "published": "2024-08-07 08:19:44", "link": "http://arxiv.org/abs/2408.03618v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Local Topology Measures of Contextual Language Model Latent Spaces With\n  Applications to Dialogue Term Extraction", "abstract": "A common approach for sequence tagging tasks based on contextual word\nrepresentations is to train a machine learning classifier directly on these\nembedding vectors. This approach has two shortcomings. First, such methods\nconsider single input sequences in isolation and are unable to put an\nindividual embedding vector in relation to vectors outside the current local\ncontext of use. Second, the high performance of these models relies on\nfine-tuning the embedding model in conjunction with the classifier, which may\nnot always be feasible due to the size or inaccessibility of the underlying\nfeature-generation model. It is thus desirable, given a collection of embedding\nvectors of a corpus, i.e., a datastore, to find features of each vector that\ndescribe its relation to other, similar vectors in the datastore. With this in\nmind, we introduce complexity measures of the local topology of the latent\nspace of a contextual language model with respect to a given datastore. The\neffectiveness of our features is demonstrated through their application to\ndialogue term extraction. Our work continues a line of research that explores\nthe manifold hypothesis for word embeddings, demonstrating that local structure\nin the space carved out by word embeddings can be exploited to infer semantic\nproperties.", "published": "2024-08-07 11:44:32", "link": "http://arxiv.org/abs/2408.03706v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Question Rephrasing for Quantifying Uncertainty in Large Language\n  Models: Applications in Molecular Chemistry Tasks", "abstract": "Uncertainty quantification enables users to assess the reliability of\nresponses generated by large language models (LLMs). We present a novel\nQuestion Rephrasing technique to evaluate the input uncertainty of LLMs, which\nrefers to the uncertainty arising from equivalent variations of the inputs\nprovided to LLMs. This technique is integrated with sampling methods that\nmeasure the output uncertainty of LLMs, thereby offering a more comprehensive\nuncertainty assessment. We validated our approach on property prediction and\nreaction prediction for molecular chemistry tasks.", "published": "2024-08-07 12:38:23", "link": "http://arxiv.org/abs/2408.03732v1", "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Generative Language Models with Retrieval Augmented Generation for\n  Automated Short Answer Scoring", "abstract": "Automated Short Answer Scoring (ASAS) is a critical component in educational\nassessment. While traditional ASAS systems relied on rule-based algorithms or\ncomplex deep learning methods, recent advancements in Generative Language\nModels (GLMs) offer new opportunities for improvement. This study explores the\napplication of GLMs to ASAS, leveraging their off-the-shelf capabilities and\nperformance in various domains. We propose a novel pipeline that combines\nvector databases, transformer-based encoders, and GLMs to enhance short answer\nscoring accuracy. Our approach stores training responses in a vector database,\nretrieves semantically similar responses during inference, and employs a GLM to\nanalyze these responses and determine appropriate scores. We further optimize\nthe system through fine-tuned retrieval processes and prompt engineering.\nEvaluation on the SemEval 2013 dataset demonstrates a significant improvement\non the SCIENTSBANK 3-way and 2-way tasks compared to existing methods,\nhighlighting the potential of GLMs in advancing ASAS technology.", "published": "2024-08-07 14:42:13", "link": "http://arxiv.org/abs/2408.03811v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Leveraging Variation Theory in Counterfactual Data Augmentation for\n  Optimized Active Learning", "abstract": "Active Learning (AL) allows models to learn interactively from user feedback.\nThis paper introduces a counterfactual data augmentation approach to AL,\nparticularly addressing the selection of datapoints for user querying, a\npivotal concern in enhancing data efficiency. Our approach is inspired by\nVariation Theory, a theory of human concept learning that emphasizes the\nessential features of a concept by focusing on what stays the same and what\nchanges. Instead of just querying with existing datapoints, our approach\nsynthesizes artificial datapoints that highlight potential key similarities and\ndifferences among labels using a neuro-symbolic pipeline combining large\nlanguage models (LLMs) and rule-based models. Through an experiment in the\nexample domain of text classification, we show that our approach achieves\nsignificantly higher performance when there are fewer annotated data. As the\nannotated training data gets larger the impact of the generated data starts to\ndiminish showing its capability to address the cold start problem in AL. This\nresearch sheds light on integrating theories of human learning into the\noptimization of AL.", "published": "2024-08-07 14:55:04", "link": "http://arxiv.org/abs/2408.03819v1", "categories": ["cs.LG", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Simplifying Scholarly Abstracts for Accessible Digital Libraries", "abstract": "Standing at the forefront of knowledge dissemination, digital libraries\ncurate vast collections of scientific literature. However, these scholarly\nwritings are often laden with jargon and tailored for domain experts rather\nthan the general public. As librarians, we strive to offer services to a\ndiverse audience, including those with lower reading levels. To extend our\nservices beyond mere access, we propose fine-tuning a language model to rewrite\nscholarly abstracts into more comprehensible versions, thereby making scholarly\nliterature more accessible when requested. We began by introducing a corpus\nspecifically designed for training models to simplify scholarly abstracts. This\ncorpus consists of over three thousand pairs of abstracts and significance\nstatements from diverse disciplines. We then fine-tuned four language models\nusing this corpus. The outputs from the models were subsequently examined both\nquantitatively for accessibility and semantic coherence, and qualitatively for\nlanguage quality, faithfulness, and completeness. Our findings show that the\nresulting models can improve readability by over three grade levels, while\nmaintaining fidelity to the original content. Although commercial\nstate-of-the-art models still hold an edge, our models are much more compact,\ncan be deployed locally in an affordable manner, and alleviate the privacy\nconcerns associated with using commercial models. We envision this work as a\nstep toward more inclusive and accessible libraries, improving our services for\nyoung readers and those without a college degree.", "published": "2024-08-07 16:55:00", "link": "http://arxiv.org/abs/2408.03899v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond", "abstract": "We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)\ndataset comprising the speech counterpart for a portion of the MASSIVE textual\ncorpus. Speech-MASSIVE covers 12 languages from different families and inherits\nfrom MASSIVE the annotations for the intent prediction and slot-filling tasks.\nOur extension is prompted by the scarcity of massively multilingual SLU\ndatasets and the growing need for versatile speech datasets to assess\nfoundation models (LLMs, speech encoders) across languages and tasks. We\nprovide a multimodal, multitask, multilingual dataset and report SLU baselines\nusing both cascaded and end-to-end architectures in various training scenarios\n(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the\nsuitability of Speech-MASSIVE for benchmarking other tasks such as speech\ntranscription, language identification, and speech translation. The dataset,\nmodels, and code are publicly available at:\nhttps://github.com/hlt-mt/Speech-MASSIVE", "published": "2024-08-07 16:55:28", "link": "http://arxiv.org/abs/2408.03900v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CodexGraph: Bridging Large Language Models and Code Repositories via\n  Code Graph Databases", "abstract": "Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval\nand MBPP, but struggle with handling entire code repositories. This challenge\nhas prompted research on enhancing LLM-codebase interaction at a repository\nscale. Current solutions rely on similarity-based retrieval or manual tools and\nAPIs, each with notable drawbacks. Similarity-based retrieval often has low\nrecall in complex tasks, while manual tools and APIs are typically\ntask-specific and require expert knowledge, reducing their generalizability\nacross diverse code tasks and real-world applications. To mitigate these\nlimitations, we introduce CodexGraph, a system that integrates LLM agents with\ngraph database interfaces extracted from code repositories. By leveraging the\nstructural properties of graph databases and the flexibility of the graph query\nlanguage, CodexGraph enables the LLM agent to construct and execute queries,\nallowing for precise, code structure-aware context retrieval and code\nnavigation. We assess CodexGraph using three benchmarks: CrossCodeEval,\nSWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding\napplications. With a unified graph database schema, CodexGraph demonstrates\ncompetitive performance and potential in both academic and real-world\nenvironments, showcasing its versatility and efficacy in software engineering.\nOur application demo:\nhttps://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.", "published": "2024-08-07 17:13:59", "link": "http://arxiv.org/abs/2408.03910v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic\n  Performance for Mercosur Common Nomenclature", "abstract": "Natural language processing (NLP) has seen significant advancements with the\nadvent of large language models (LLMs). However, substantial improvements are\nstill needed for languages other than English, especially for specific domains\nlike the applications of Mercosur Common Nomenclature (NCM), a Brazilian\nHarmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a\nfoundational Portuguese LLM, as an LLM source to implement the NCM application\nprocessing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)\ntechnique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.\nThis approach retains the chain-of-thought (CoT) methodology for prompt\ndevelopment in a more concise and streamlined manner, utilizing brief and\nfocused documents for training. The proposed model demonstrates an efficient\nand cost-effective alternative for fine-tuning smaller LLMs, significantly\noutperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the\nresearch focuses on NCM applications, the methodology can be easily adapted for\nHS applications worldwide.", "published": "2024-08-07 17:54:21", "link": "http://arxiv.org/abs/2408.03936v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet\n  Visualization", "abstract": "Large language models (LLMs) can help writers build story worlds by\ngenerating world elements, such as factions, characters, and locations.\nHowever, making sense of many generated elements can be overwhelming. Moreover,\nif the user wants to precisely control aspects of generated elements that are\ndifficult to specify verbally, prompting alone may be insufficient. We\nintroduce Patchview, a customizable LLM-powered system that visually aids\nworldbuilding by allowing users to interact with story concepts and elements\nthrough the physical metaphor of magnets and dust. Elements in Patchview are\nvisually dragged closer to concepts with high relevance, facilitating\nsensemaking. The user can also steer the generation with verbally elusive\nconcepts by indicating the desired position of the element between concepts.\nWhen the user disagrees with the LLM's visualization and generation, they can\ncorrect those by repositioning the element. These corrections can be used to\nalign the LLM's future behaviors to the user's perception. With a user study,\nwe show that Patchview supports the sensemaking of world elements and steering\nof element generation, facilitating exploration during the worldbuilding\nprocess. Patchview provides insights on how customizable visual representation\ncan help sensemake, steer, and align generative AI model behaviors with the\nuser's intentions.", "published": "2024-08-07 22:27:19", "link": "http://arxiv.org/abs/2408.04112v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Can Rule-Based Insights Enhance LLMs for Radiology Report\n  Classification? Introducing the RadPrompt Methodology", "abstract": "Developing imaging models capable of detecting pathologies from chest X-rays\ncan be cost and time-prohibitive for large datasets as it requires supervision\nto attain state-of-the-art performance. Instead, labels extracted from\nradiology reports may serve as distant supervision since these are routinely\ngenerated as part of clinical practice. Despite their widespread use, current\nrule-based methods for label extraction rely on extensive rule sets that are\nlimited in their robustness to syntactic variability. To alleviate these\nlimitations, we introduce RadPert, a rule-based system that integrates an\nuncertainty-aware information schema with a streamlined set of rules, enhancing\nperformance. Additionally, we have developed RadPrompt, a multi-turn prompting\nstrategy that leverages RadPert to bolster the zero-shot predictive\ncapabilities of large language models, achieving a statistically significant\nimprovement in weighted average F1 score over GPT-4 Turbo. Most notably,\nRadPrompt surpasses both its underlying models, showcasing the synergistic\npotential of LLMs with rule-based models. We have evaluated our methods on two\nEnglish Corpora: the MIMIC-CXR gold-standard test set and a gold-standard\ndataset collected from the Cambridge University Hospitals.", "published": "2024-08-07 23:09:23", "link": "http://arxiv.org/abs/2408.04121v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Incorporating Spatial Awareness in Data-Driven Gesture Generation for\n  Virtual Agents", "abstract": "This paper focuses on enhancing human-agent communication by integrating\nspatial context into virtual agents' non-verbal behaviors, specifically\ngestures. Recent advances in co-speech gesture generation have primarily\nutilized data-driven methods, which create natural motion but limit the scope\nof gestures to those performed in a void. Our work aims to extend these methods\nby enabling generative models to incorporate scene information into\nspeech-driven gesture synthesis. We introduce a novel synthetic gesture dataset\ntailored for this purpose. This development represents a critical step toward\ncreating embodied conversational agents that interact more naturally with their\nenvironment and users.", "published": "2024-08-07 23:23:50", "link": "http://arxiv.org/abs/2408.04127v1", "categories": ["cs.HC", "cs.CL", "cs.GR", "I.3.6; I.2.10"], "primary_category": "cs.HC"}
{"title": "Forecasting Live Chat Intent from Browsing History", "abstract": "Customers reach out to online live chat agents with various intents, such as\nasking about product details or requesting a return. In this paper, we propose\nthe problem of predicting user intent from browsing history and address it\nthrough a two-stage approach. The first stage classifies a user's browsing\nhistory into high-level intent categories. Here, we represent each browsing\nhistory as a text sequence of page attributes and use the ground-truth class\nlabels to fine-tune pretrained Transformers. The second stage provides a large\nlanguage model (LLM) with the browsing history and predicted intent class to\ngenerate fine-grained intents. For automatic evaluation, we use a separate LLM\nto judge the similarity between generated and ground-truth intents, which\nclosely aligns with human judgments. Our two-stage approach yields significant\nperformance gains compared to generating intents without the classification\nstage.", "published": "2024-08-07 01:50:59", "link": "http://arxiv.org/abs/2408.04668v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Prompt and Prejudice", "abstract": "This paper investigates the impact of using first names in Large Language\nModels (LLMs) and Vision Language Models (VLMs), particularly when prompted\nwith ethical decision-making tasks. We propose an approach that appends first\nnames to ethically annotated text scenarios to reveal demographic biases in\nmodel outputs. Our study involves a curated list of more than 300 names\nrepresenting diverse genders and ethnic backgrounds, tested across thousands of\nmoral scenarios. Following the auditing methodologies from social sciences we\npropose a detailed analysis involving popular LLMs/VLMs to contribute to the\nfield of responsible AI by emphasizing the importance of recognizing and\nmitigating biases in these systems. Furthermore, we introduce a novel\nbenchmark, the Pratical Scenarios Benchmark (PSB), designed to assess the\npresence of biases involving gender or demographic prejudices in everyday\ndecision-making scenarios as well as practical scenarios where an LLM might be\nused to make sensible decisions (e.g., granting mortgages or insurances). This\nbenchmark allows for a comprehensive comparison of model behaviors across\ndifferent demographic categories, highlighting the risks and biases that may\narise in practical applications of LLMs and VLMs.", "published": "2024-08-07 14:11:33", "link": "http://arxiv.org/abs/2408.04671v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "AutoFAIR : Automatic Data FAIRification via Machine Reading", "abstract": "The explosive growth of data fuels data-driven research, facilitating\nprogress across diverse domains. The FAIR principles emerge as a guiding\nstandard, aiming to enhance the findability, accessibility, interoperability,\nand reusability of data. However, current efforts primarily focus on manual\ndata FAIRification, which can only handle targeted data and lack efficiency. To\naddress this issue, we propose AutoFAIR, an architecture designed to enhance\ndata FAIRness automately. Firstly, We align each data and metadata operation\nwith specific FAIR indicators to guide machine-executable actions. Then, We\nutilize Web Reader to automatically extract metadata based on language models,\neven in the absence of structured data webpage schemas. Subsequently, FAIR\nAlignment is employed to make metadata comply with FAIR principles by ontology\nguidance and semantic matching. Finally, by applying AutoFAIR to various data,\nespecially in the field of mountain hazards, we observe significant\nimprovements in findability, accessibility, interoperability, and reusability\nof data. The FAIRness scores before and after applying AutoFAIR indicate\nenhanced data value.", "published": "2024-08-07 17:36:58", "link": "http://arxiv.org/abs/2408.04673v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ACL Ready: RAG Based Assistant for the ACL Checklist", "abstract": "The ARR Responsible NLP Research checklist website states that the \"checklist\nis designed to encourage best practices for responsible research, addressing\nissues of research ethics, societal impact and reproducibility.\" Answering the\nquestions is an opportunity for authors to reflect on their work and make sure\nany shared scientific assets follow best practices. Ideally, considering the\nchecklist before submission can favorably impact the writing of a research\npaper. However, the checklist is often filled out at the last moment. In this\nwork, we introduce ACLReady, a retrieval-augmented language model application\nthat can be used to empower authors to reflect on their work and assist authors\nwith the ACL checklist. To test the effectiveness of the system, we conducted a\nqualitative study with 13 users which shows that 92% of users found the\napplication useful and easy to use as well as 77% of the users found that the\napplication provided the information they expected. Our code is publicly\navailable under the CC BY-NC 4.0 license on GitHub.", "published": "2024-08-07 21:07:13", "link": "http://arxiv.org/abs/2408.04675v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MathBridge: A Large Corpus Dataset for Translating Spoken Mathematical\n  Expressions into $LaTeX$ Formulas for Improved Readability", "abstract": "Improving the readability of mathematical expressions in text-based document\nsuch as subtitle of mathematical video, is an significant task. To achieve\nthis, mathematical expressions should be convert to compiled formulas. For\ninstance, the spoken expression ``x equals minus b plus or minus the square\nroot of b squared minus four a c, all over two a'' from automatic speech\nrecognition is more readily comprehensible when displayed as a compiled formula\n$x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$. To convert mathematical spoken\nsentences to compiled formulas, two processes are required: spoken sentences\nare converted into LaTeX formulas, and LaTeX formulas are converted into\ncompiled formulas. The latter can be managed by using LaTeX engines. However,\nthere is no way to do the former effectively. Even if we try to solve this\nusing language models, there is no paired data between spoken sentences and\nLaTeX formulas to train it. In this paper, we introduce MathBridge, the first\nextensive dataset for translating mathematical spoken sentences into LaTeX\nformulas. MathBridge comprises approximately 23 million LaTeX formulas paired\nwith the corresponding mathematical spoken sentences. Through comprehensive\nevaluations, including fine-tuning with proposed data, we discovered that\nMathBridge significantly enhances the capabilities of pretrained language\nmodels for converting to LaTeX formulas from mathematical spoken sentences.\nSpecifically, for the T5-large model, the sacreBLEU score increased from 4.77\nto 46.8, demonstrating substantial enhancement.", "published": "2024-08-07 18:07:15", "link": "http://arxiv.org/abs/2408.07081v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Could ChatGPT get an Engineering Degree? Evaluating Higher Education\n  Vulnerability to AI Assistants", "abstract": "AI assistants are being increasingly used by students enrolled in higher\neducation institutions. While these tools provide opportunities for improved\nteaching and education, they also pose significant challenges for assessment\nand learning outcomes. We conceptualize these challenges through the lens of\nvulnerability, the potential for university assessments and learning outcomes\nto be impacted by student use of generative AI. We investigate the potential\nscale of this vulnerability by measuring the degree to which AI assistants can\ncomplete assessment questions in standard university-level STEM courses.\nSpecifically, we compile a novel dataset of textual assessment questions from\n50 courses at EPFL and evaluate whether two AI assistants, GPT-3.5 and GPT-4\ncan adequately answer these questions. We use eight prompting strategies to\nproduce responses and find that GPT-4 answers an average of 65.8% of questions\ncorrectly, and can even produce the correct answer across at least one\nprompting strategy for 85.1% of questions. When grouping courses in our dataset\nby degree program, these systems already pass non-project assessments of large\nnumbers of core courses in various degree programs, posing risks to higher\neducation accreditation that will be amplified as these models improve. Our\nresults call for revising program-level assessment design in higher education\nin light of advances in generative AI.", "published": "2024-08-07 12:11:49", "link": "http://arxiv.org/abs/2408.11841v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Design and Analysis of Binaural Signal Matching with Arbitrary\n  Microphone Arrays", "abstract": "Binaural reproduction is rapidly becoming a topic of great interest in the\nresearch community, especially with the surge of new and popular devices, such\nas virtual reality headsets, smart glasses, and head-tracked headphones. In\norder to immerse the listener in a virtual or remote environment with such\ndevices, it is essential to generate realistic and accurate binaural signals.\nThis is challenging, especially since the microphone arrays mounted on these\ndevices are typically composed of an arbitrarily-arranged small number of\nmicrophones, which impedes the use of standard audio formats like Ambisonics,\nand provides limited spatial resolution. The binaural signal matching (BSM)\nmethod was developed recently to overcome these challenges. While it produced\nbinaural signals with low error using relatively simple arrays, its performance\ndegraded significantly when head rotation was introduced. This paper aims to\ndevelop the BSM method further and overcome its limitations. For this purpose,\nthe method is first analyzed in detail, and a design framework that guarantees\naccurate binaural reproduction for relatively complex acoustic environments is\npresented. Next, it is shown that the BSM accuracy may significantly degrade at\nhigh frequencies, and thus, a perceptually motivated extension to the method is\nproposed, based on a magnitude least-squares (MagLS) formulation. These\ninsights and developments are then analyzed with the help of an extensive\nsimulation study of a simple six-microphone semi-circular array. It is further\nshown that the BSM-MagLS method can be very useful in compensating for head\nrotations with this array. Finally, a listening experiment is conducted with a\nfour-microphone array on a pair of glasses in a reverberant speech environment\nand including head rotations, where it is shown that BSM-MagLS can indeed\nproduce binaural signals with a high perceived quality.", "published": "2024-08-07 06:34:52", "link": "http://arxiv.org/abs/2408.03581v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Bridging the Gap between Audio and Text using Parallel-attention for\n  User-defined Keyword Spotting", "abstract": "This paper proposes a novel user-defined keyword spotting framework that\naccurately detects audio keywords based on text enrollment. Since audio data\npossesses additional acoustic information compared to text, there are\ndiscrepancies between these two modalities. To address this challenge, we\npresent ParallelKWS, which utilises self- and cross-attention in a parallel\narchitecture to effectively capture information both within and across the two\nmodalities. We further propose a phoneme duration-based alignment loss that\nenforces the sequential correspondence between audio and text features.\nExtensive experimental results demonstrate that our proposed method achieves\nstate-of-the-art performance on several benchmark datasets in both seen and\nunseen domains, without incorporating extra data beyond the dataset used in\nprevious studies.", "published": "2024-08-07 07:13:55", "link": "http://arxiv.org/abs/2408.03593v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Non-Causal to Causal SSL-Supported Transfer Learning: Towards a\n  High-Performance Low-Latency Speech Vocoder", "abstract": "Recently, BigVGAN has emerged as high-performance speech vocoder. Its\nsequence-to-sequence-based synthesis, however, prohibits usage in low-latency\nconversational applications. Our work addresses this shortcoming in three\nsteps. First, we introduce low latency into BigVGAN via implementing causal\nconvolutions, yielding decreased performance. Second, to regain performance, we\npropose a teacher-student transfer learning scheme to distill the high-delay\nnon-causal BigVGAN into our low-latency causal vocoder. Third, taking advantage\nof a self-supervised learning (SSL) model, in our case wav2vec 2.0, we align\nits encoder speech representations extracted from our low-latency causal\nvocoder to the ground truth ones. In speaker-independent settings, both\nproposed training schemes notably elevate the performance of our low-latency\nvocoder, closing up to the original high-delay BigVGAN. At only 21% higher\ncomplexity, our best small causal vocoder achieves 3.96 PESQ and 1.25 MCD,\nexcelling even the original small non-causal BigVGAN (3.64 PESQ) by 0.32 PESQ\nand 0.1 MCD points, respectively.", "published": "2024-08-07 12:49:40", "link": "http://arxiv.org/abs/2408.11842v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Feasibility of iMagLS-BSM -- ILD Informed Binaural Signal Matching with\n  Arbitrary Microphone Arrays", "abstract": "Binaural reproduction for headphone-centric listening has become a focal\npoint in ongoing research, particularly within the realm of advancing\ntechnologies such as augmented and virtual reality (AR and VR). The demand for\nhigh-quality spatial audio in these applications is essential to uphold a\nseamless sense of immersion. However, challenges arise from wearable recording\ndevices equipped with only a limited number of microphones and irregular\nmicrophone placements due to design constraints. These factors contribute to\nlimited reproduction quality compared to reference signals captured by\nhigh-order microphone arrays. This paper introduces a novel optimization loss\ntailored for a beamforming-based, signal-independent binaural reproduction\nscheme. This method, named iMagLS-BSM incorporates an interaural level\ndifference (ILD) error term into the previously proposed binaural signal\nmatching (BSM) magnitude least squares (MagLS) rendering loss for lateral plane\nangles. The method leverages nonlinear programming to minimize the introduced\nloss. Preliminary results show a substantial reduction in ILD error, while\nmaintaining a binaural magnitude error comparable to that achieved with a MagLS\nBSM solution. These findings hold promise for enhancing the overall spatial\nquality of resultant binaural signals.", "published": "2024-08-07 08:04:30", "link": "http://arxiv.org/abs/2408.03611v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "One-Shot Distributed Node-Specific Signal Estimation with\n  Non-Overlapping Latent Subspaces in Acoustic Sensor Networks", "abstract": "A one-shot algorithm called iterationless DANSE (iDANSE) is introduced to\nperform distributed adaptive node-specific signal estimation (DANSE) in a fully\nconnected wireless acoustic sensor network (WASN) deployed in an environment\nwith non-overlapping latent signal subspaces. The iDANSE algorithm matches the\nperformance of a centralized algorithm in a single processing cycle while\ndevices exchange fused versions of their multichannel local microphone signals.\nKey advantages of iDANSE over currently available solutions are its\niterationless nature, which favors deployment in real-time applications, and\nthe fact that devices can exchange fewer fused signals than the number of\nlatent sources in the environment. The proposed method is validated in\nnumerical simulations including a speech enhancement scenario.", "published": "2024-08-07 13:05:59", "link": "http://arxiv.org/abs/2408.03752v2", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Speaker Adaptation for Quantised End-to-End ASR Models", "abstract": "End-to-end models have shown superior performance for automatic speech\nrecognition (ASR). However, such models are often very large in size and thus\nchallenging to deploy on resource-constrained edge devices. While quantisation\ncan reduce model sizes, it can lead to increased word error rates (WERs).\nAlthough improved quantisation methods were proposed to address the issue of\nperformance degradation, the fact that quantised models deployed on edge\ndevices often target only on a small group of users is under-explored. To this\nend, we propose personalisation for quantised models (P4Q), a novel strategy\nthat uses speaker adaptation (SA) to improve quantised end-to-end ASR models by\nfitting them to the characteristics of the target speakers. In this paper, we\nstudy the P4Q strategy based on Whisper and Conformer attention-based\nencoder-decoder (AED) end-to-end ASR models, which leverages a 4-bit block-wise\nNormalFloat4 (NF4) approach for quantisation and the low-rank adaptation (LoRA)\napproach for SA. Experimental results on the LibriSpeech and the TED-LIUM 3\ncorpora show that, with a 7-time reduction in model size and 1% extra\nspeaker-specific parameters, 15.1% and 23.3% relative WER reductions were\nachieved on quantised Whisper and Conformer AED models respectively, comparing\nto the full precision models.", "published": "2024-08-07 15:20:53", "link": "http://arxiv.org/abs/2408.03979v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Facing the Music: Tackling Singing Voice Separation in Cinematic Audio\n  Source Separation", "abstract": "Cinematic audio source separation (CASS), as a standalone problem of\nextracting individual stems from their mixture, is a fairly new subtask of\naudio source separation. A typical setup of CASS is a three-stem problem, with\nthe aim of separating the mixture into the dialogue (DX), music (MX), and\neffects (FX) stems. Given the creative nature of cinematic sound production,\nhowever, several edge cases exist; some sound sources do not fit neatly in any\nof these three stems, necessitating the use of additional auxiliary stems in\nproduction. One very common edge case is the singing voice in film audio, which\nmay belong in either the DX or MX or neither, depending heavily on the\ncinematic context. In this work, we demonstrate a very straightforward\nextension of the dedicated-decoder Bandit and query-based single-decoder\nBanquet models to a four-stem problem, treating non-musical dialogue,\ninstrumental music, singing voice, and effects as separate stems.\nInterestingly, the query-based Banquet model outperformed the dedicated-decoder\nBandit model. We hypothesized that this is due to a better feature alignment at\nthe bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model\nimplementation will be made available at\nhttps://github.com/kwatcharasupat/source-separation-landing.", "published": "2024-08-07 07:04:29", "link": "http://arxiv.org/abs/2408.03588v2", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speech privacy-preserving methods using secret key for convolutional\n  neural network models and their robustness evaluation", "abstract": "In this paper, we propose privacy-preserving methods with a secret key for\nconvolutional neural network (CNN)-based models in speech processing tasks. In\nenvironments where untrusted third parties, like cloud servers, provide\nCNN-based systems, ensuring the privacy of speech queries becomes essential.\nThis paper proposes encryption methods for speech queries using secret keys and\na model structure that allows for encrypted queries to be accepted without\ndecryption. Our approach introduces three types of secret keys: Shuffling,\nFlipping, and random orthogonal matrix (ROM). In experiments, we demonstrate\nthat when the proposed methods are used with the correct key, identification\nperformance did not degrade. Conversely, when an incorrect key is used, the\nperformance significantly decreased. Particularly, with the use of ROM, we show\nthat even with a relatively small key space, high privacy-preserving\nperformance can be maintained many speech processing tasks. Furthermore, we\nalso demonstrate the difficulty of recovering original speech from encrypted\nqueries in various robustness evaluations.", "published": "2024-08-07 16:51:39", "link": "http://arxiv.org/abs/2408.03897v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
