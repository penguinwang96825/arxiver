{"title": "Grade Guard: A Smart System for Short Answer Automated Grading", "abstract": "The advent of large language models (LLMs) in the education sector has\nprovided impetus to automate grading short answer questions. LLMs make\nevaluating short answers very efficient, thus addressing issues like staff\nshortage. However, in the task of Automated Short Answer Grading (ASAG), LLM\nresponses are influenced by diverse perspectives in their training dataset,\nleading to inaccuracies in evaluating nuanced or partially correct answers. To\naddress this challenge, we propose a novel framework, Grade Guard.\n  1. To enhance the task-based specialization of the LLMs, the temperature\nparameter has been fine-tuned using Root Mean Square Error (RMSE).\n  2. Unlike traditional approaches, LLMs in Grade Guard compute an\nIndecisiveness Score (IS) along with the grade to reflect uncertainty in\npredicted grades.\n  3. Introduced Confidence-Aware Loss (CAL) to generate an optimized\nIndecisiveness Score (IS).\n  4. To improve reliability, self-reflection based on the optimized IS has been\nintroduced into the framework, enabling human re-evaluation to minimize\nincorrect grade assignments.\n  Our experimentation shows that the best setting of Grade Guard outperforms\ntraditional methods by 19.16% RMSE in Upstage Solar Pro, 23.64% RMSE in Upstage\nSolar Mini, 4.00% RMSE in Gemini 1.5 Flash, and 10.20% RMSE in GPT 4-o Mini.\nFuture work includes improving interpretability by generating rationales for\ngrades to enhance accuracy. Expanding benchmark datasets and annotating them\nwith domain-specific nuances will enhance grading accuracy. Finally, analyzing\nfeedback to enhance confidence in predicted grades, reduce biases, optimize\ngrading criteria, and personalize learning while supporting multilingual\ngrading systems will make the solution more accurate, adaptable, fair, and\ninclusive.", "published": "2025-04-01 23:45:44", "link": "http://arxiv.org/abs/2504.01253v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Automated Factual Benchmarking for In-Car Conversational Systems using Large Language Models", "abstract": "In-car conversational systems bring the promise to improve the in-vehicle\nuser experience. Modern conversational systems are based on Large Language\nModels (LLMs), which makes them prone to errors such as hallucinations, i.e.,\ninaccurate, fictitious, and therefore factually incorrect information. In this\npaper, we present an LLM-based methodology for the automatic factual\nbenchmarking of in-car conversational systems. We instantiate our methodology\nwith five LLM-based methods, leveraging ensembling techniques and diverse\npersonae to enhance agreement and minimize hallucinations. We use our\nmethodology to evaluate CarExpert, an in-car retrieval-augmented conversational\nquestion answering system, with respect to the factual correctness to a\nvehicle's manual. We produced a novel dataset specifically created for the\nin-car domain, and tested our methodology against an expert evaluation. Our\nresults show that the combination of GPT-4 with the Input Output Prompting\nachieves over 90 per cent factual correctness agreement rate with expert\nevaluations, other than being the most efficient approach yielding an average\nresponse time of 4.5s. Our findings suggest that LLM-based testing constitutes\na viable approach for the validation of conversational systems regarding their\nfactual correctness.", "published": "2025-04-01 23:25:30", "link": "http://arxiv.org/abs/2504.01248v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Catastrophic Forgetting in LLMs: A Comparative Analysis Across Language Tasks", "abstract": "Large Language Models (LLMs) have significantly advanced Natural Language\nProcessing (NLP), particularly in Natural Language Understanding (NLU) tasks.\nAs we progress toward an agentic world where LLM-based agents autonomously\nhandle specialized tasks, it becomes crucial for these models to adapt to new\ntasks without forgetting previously learned information - a challenge known as\ncatastrophic forgetting. This study evaluates the continual fine-tuning of\nvarious open-source LLMs with different parameter sizes (specifically models\nunder 10 billion parameters) on key NLU tasks from the GLUE benchmark,\nincluding SST-2, MRPC, CoLA, and MNLI. By employing prompt engineering and\ntask-specific adjustments, we assess and compare the models' abilities to\nretain prior knowledge while learning new tasks. Our results indicate that\nmodels such as Phi-3.5-mini exhibit minimal forgetting while maintaining strong\nlearning capabilities, making them well-suited for continual learning\nenvironments. Additionally, models like Orca-2-7b and Qwen2.5-7B demonstrate\nimpressive learning abilities and overall performance after fine-tuning. This\nwork contributes to understanding catastrophic forgetting in LLMs and\nhighlights prompting engineering to optimize model performance for continual\nlearning scenarios.", "published": "2025-04-01 23:06:55", "link": "http://arxiv.org/abs/2504.01241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TheBlueScrubs-v1, a comprehensive curated medical dataset derived from the internet", "abstract": "The need for robust and diverse data sets to train clinical large language\nmodels (cLLMs) is critical given that currently available public repositories\noften prove too limited in size or scope for comprehensive medical use. While\nresources like PubMed provide foundational medical literature, they capture\nonly a narrow range of formal publications and omit the broader medical\ndiscourse on the internet. To address these deficits, we introduce\nTheBlueScrubs-v1, a curated dataset of over 25 billion medical tokens - nearly\nthree times larger than PubMed - drawn from a broad-scale internet corpus. Our\ntwo-stage filtering pipeline employs a Logistic Regression model for document\nscreening (achieving an AUC of approximately 0.95 on external validation),\nfollowed by verification via a 70B-parameter Llama 3.1 instruct model. Each\ntext is assigned three LLM-based quality scores encompassing medical relevance,\nprecision and factual detail, and safety and ethical standards. Clinician\nreviews confirm high concordance with these automated evaluations, and a\nspecialized cancer classifier further labels approximately 11 billion oncology\ntokens. Two demonstration tasks highlight the dataset's practical value: first,\nwe distill the safety evaluations to a smaller BERT-style model that reaches an\nAUC near 0.96 on unseen data; second, we fine-tune a compact LLM on a filtered\nsubset, showing measurable improvements over standard baselines in medical\nbenchmarks as well as private ones. This Data Descriptor details the dataset's\ncreation and validation, underscoring its potential utility for medical AI\nresearch.", "published": "2025-04-01 22:25:19", "link": "http://arxiv.org/abs/2504.02874v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Conformal Risk Control Framework for Granular Word Assessment and Uncertainty Calibration of CLIPScore Quality Estimates", "abstract": "This study explores current limitations of learned image captioning\nevaluation metrics, specifically the lack of granular assessment for individual\nword misalignments within captions, and the reliance on single-point quality\nestimates without considering uncertainty. To address these limitations, we\npropose a simple yet effective strategy for generating and calibrating\nCLIPScore distributions. Leveraging a model-agnostic conformal risk control\nframework, we calibrate CLIPScore values for task-specific control variables,\nto tackle the aforementioned two limitations. Experimental results demonstrate\nthat using conformal risk control, over the distributions produced with simple\nmethods such as input masking, can achieve competitive performance compared to\nmore complex approaches. Our method effectively detects misaligned words, while\nproviding formal guarantees aligned with desired risk levels, and improving the\ncorrelation between uncertainty estimations and prediction errors, thus\nenhancing the overall reliability of caption evaluation metrics.", "published": "2025-04-01 22:25:00", "link": "http://arxiv.org/abs/2504.01225v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models", "abstract": "Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical\nsettings, presenting opportunities for automated detection to identify\npatients. This study evaluates natural language processing approaches for\ndetecting PTSD from clinical interview transcripts. We compared general and\nmental health-specific transformer models (BERT/RoBERTa), embedding-based\nmethods (SentenceBERT/LLaMA), and large language model prompting strategies\n(zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset.\nDomain-specific models significantly outperformed general models\n(Mental-RoBERTa F1=0.643 vs. RoBERTa-base 0.485). LLaMA embeddings with neural\nnetworks achieved the highest performance (F1=0.700). Zero-shot prompting using\nDSM-5 criteria yielded competitive results without training data (F1=0.657).\nPerformance varied significantly across symptom severity and comorbidity\nstatus, with higher accuracy for severe PTSD cases and patients with comorbid\ndepression. Our findings highlight the potential of domain-adapted embeddings\nand LLMs for scalable screening while underscoring the need for improved\ndetection of nuanced presentations and offering insights for developing\nclinically viable AI tools for PTSD assessment.", "published": "2025-04-01 22:06:28", "link": "http://arxiv.org/abs/2504.01216v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Epistemic Alignment: A Mediating Framework for User-LLM Knowledge Delivery", "abstract": "LLMs increasingly serve as tools for knowledge acquisition, yet users cannot\neffectively specify how they want information presented. When users request\nthat LLMs \"cite reputable sources,\" \"express appropriate uncertainty,\" or\n\"include multiple perspectives,\" they discover that current interfaces provide\nno structured way to articulate these preferences. The result is prompt sharing\nfolklore: community-specific copied prompts passed through trust relationships\nrather than based on measured efficacy. We propose the Epistemic Alignment\nFramework, a set of ten challenges in knowledge transmission derived from the\nphilosophical literature of epistemology, concerning issues such as evidence\nquality assessment and calibration of testimonial reliance. The framework\nserves as a structured intermediary between user needs and system capabilities,\ncreating a common vocabulary to bridge the gap between what users want and what\nsystems deliver. Through a thematic analysis of custom prompts and\npersonalization strategies shared on online communities where these issues are\nactively discussed, we find users develop elaborate workarounds to address each\nof the challenges. We then apply our framework to two prominent model\nproviders, OpenAI and Anthropic, through content analysis of their documented\npolicies and product features. Our analysis shows that while these providers\nhave partially addressed the challenges we identified, they fail to establish\nadequate mechanisms for specifying epistemic preferences, lack transparency\nabout how preferences are implemented, and offer no verification tools to\nconfirm whether preferences were followed. For AI developers, the Epistemic\nAlignment Framework offers concrete guidance for supporting diverse approaches\nto knowledge; for users, it works toward information delivery that aligns with\ntheir specific needs rather than defaulting to one-size-fits-all approaches.", "published": "2025-04-01 21:38:12", "link": "http://arxiv.org/abs/2504.01205v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Medical large language models are easily distracted", "abstract": "Large language models (LLMs) have the potential to transform medicine, but\nreal-world clinical scenarios contain extraneous information that can hinder\nperformance. The rise of assistive technologies like ambient dictation, which\nautomatically generates draft notes from live patient encounters, has the\npotential to introduce additional noise making it crucial to assess the ability\nof LLM's to filter relevant data. To investigate this, we developed\nMedDistractQA, a benchmark using USMLE-style questions embedded with simulated\nreal-world distractions. Our findings show that distracting statements\n(polysemous words with clinical meanings used in a non-clinical context or\nreferences to unrelated health conditions) can reduce LLM accuracy by up to\n17.9%. Commonly proposed solutions to improve model performance such as\nretrieval-augmented generation (RAG) and medical fine-tuning did not change\nthis effect and in some cases introduced their own confounders and further\ndegraded performance. Our findings suggest that LLMs natively lack the logical\nmechanisms necessary to distinguish relevant from irrelevant clinical\ninformation, posing challenges for real-world applications. MedDistractQA and\nour results highlights the need for robust mitigation strategies to enhance LLM\nresilience to extraneous information.", "published": "2025-04-01 21:34:01", "link": "http://arxiv.org/abs/2504.01201v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Short-PHD: Detecting Short LLM-generated Text with Topological Data Analysis After Off-topic Content Insertion", "abstract": "The malicious usage of large language models (LLMs) has motivated the\ndetection of LLM-generated texts. Previous work in topological data analysis\nshows that the persistent homology dimension (PHD) of text embeddings can serve\nas a more robust and promising score than other zero-shot methods. However,\neffectively detecting short LLM-generated texts remains a challenge. This paper\npresents Short-PHD, a zero-shot LLM-generated text detection method tailored\nfor short texts. Short-PHD stabilizes the estimation of the previous PHD method\nfor short texts by inserting off-topic content before the given input text and\nidentifies LLM-generated text based on an established detection threshold.\nExperimental results on both public and generated datasets demonstrate that\nShort-PHD outperforms existing zero-shot methods in short LLM-generated text\ndetection. Implementation codes are available online.", "published": "2025-04-01 21:26:49", "link": "http://arxiv.org/abs/2504.02873v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$\u03bc$KE: Matryoshka Unstructured Knowledge Editing of Large Language Models", "abstract": "Large language models (LLMs) have emerged as powerful knowledge bases yet are\nlimited by static training data, leading to issues such as hallucinations and\nsafety risks. Editing a model's internal knowledge through the locate-and-edit\nparadigm has proven a cost-effective alternative to retraining, though current\nunstructured approaches, especially window-based autoregressive methods, often\ndisrupt the causal dependency between early memory updates and later output\ntokens. In this work, we first theoretically analyze these limitations and then\nintroduce Matryoshka Unstructured Knowledge Editing ($\\mu$KE), a novel memory\nupdate mechanism that preserves such dependencies via a Matryoshka-style\nobjective and adaptive loss coefficients. Empirical evaluations on two models\nacross four benchmarks demonstrate that $\\mu$KE improves edit efficacy by up to\n12.33% over state-of-the-art methods, and remain robust when applied to diverse\nformatted edits, underscoring its potential for effective unstructured\nknowledge editing in LLMs.", "published": "2025-04-01 21:24:44", "link": "http://arxiv.org/abs/2504.01196v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Follow the Flow: On Information Flow Across Textual Tokens in Text-to-Image Models", "abstract": "Text-to-Image (T2I) models often suffer from issues such as semantic leakage,\nincorrect feature binding, and omissions of key concepts in the generated\nimage. This work studies these phenomena by looking into the role of\ninformation flow between textual token representations. To this end, we\ngenerate images by applying the diffusion component on a subset of contextual\ntoken representations in a given prompt and observe several interesting\nphenomena. First, in many cases, a word or multiword expression is fully\nrepresented by one or two tokens, while other tokens are redundant. For\nexample, in \"San Francisco's Golden Gate Bridge\", the token \"gate\" alone\ncaptures the full expression. We demonstrate the redundancy of these tokens by\nremoving them after textual encoding and generating an image from the resulting\nrepresentation. Surprisingly, we find that this process not only maintains\nimage generation performance but also reduces errors by 21\\% compared to\nstandard generation. We then show that information can also flow between\ndifferent expressions in a sentence, which often leads to semantic leakage.\nBased on this observation, we propose a simple, training-free method to\nmitigate semantic leakage: replacing the leaked item's representation after the\ntextual encoding with its uncontextualized representation. Remarkably, this\nsimple approach reduces semantic leakage by 85\\%. Overall, our work provides a\ncomprehensive analysis of information flow across textual tokens in T2I models,\noffering both novel insights and practical benefits.", "published": "2025-04-01 19:17:44", "link": "http://arxiv.org/abs/2504.01137v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is the Top Still Spinning? Evaluating Subjectivity in Narrative Understanding", "abstract": "Determining faithfulness of a claim to a source document is an important\nproblem across many domains. This task is generally treated as a binary\njudgment of whether the claim is supported or unsupported in relation to the\nsource. In many cases, though, whether a claim is supported can be ambiguous.\nFor instance, it may depend on making inferences from given evidence, and\ndifferent people can reasonably interpret the claim as either supported or\nunsupported based on their agreement with those inferences. Forcing binary\nlabels upon such claims lowers the reliability of evaluation. In this work, we\nreframe the task to manage the subjectivity involved with factuality judgments\nof ambiguous claims. We introduce LLM-generated edits of summaries as a method\nof providing a nuanced evaluation of claims: how much does a summary need to be\nedited to be unambiguous? Whether a claim gets rewritten and how much it\nchanges can be used as an automatic evaluation metric, the Ambiguity Rewrite\nMetric (ARM), with a much richer feedback signal than a binary judgment of\nfaithfulness. We focus on the area of narrative summarization as it is\nparticularly rife with ambiguity and subjective interpretation. We show that\nARM produces a 21% absolute improvement in annotator agreement on claim\nfaithfulness, indicating that subjectivity is reduced.", "published": "2025-04-01 19:08:24", "link": "http://arxiv.org/abs/2504.01132v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TDBench: Benchmarking Vision-Language Models in Understanding Top-Down Images", "abstract": "The rapid emergence of Vision-Language Models (VLMs) has significantly\nadvanced multimodal understanding, enabling applications in scene comprehension\nand visual reasoning. While these models have been primarily evaluated and\ndeveloped for front-view image understanding, their capabilities in\ninterpreting top-down images have received limited attention, partly due to the\nscarcity of diverse top-down datasets and the challenges in collecting such\ndata. In contrast, top-down vision provides explicit spatial overviews and\nimproved contextual understanding of scenes, making it particularly valuable\nfor tasks like autonomous navigation, aerial imaging, and spatial planning. In\nthis work, we address this gap by introducing TDBench, a comprehensive\nbenchmark for VLMs in top-down image understanding. TDBench is constructed from\npublic top-down view datasets and high-quality simulated images, including\ndiverse real-world and synthetic scenarios. TDBench consists of visual\nquestion-answer pairs across ten evaluation dimensions of image understanding.\nMoreover, we conduct four case studies that commonly happen in real-world\nscenarios but are less explored. By revealing the strengths and limitations of\nexisting VLM through evaluation results, we hope TDBench to provide insights\nfor motivating future research. Project homepage:\nhttps://github.com/Columbia-ICSL/TDBench", "published": "2025-04-01 19:01:13", "link": "http://arxiv.org/abs/2504.03748v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Can LLMs Grasp Implicit Cultural Values? Benchmarking LLMs' Metacognitive Cultural Intelligence with CQ-Bench", "abstract": "Cultural Intelligence (CQ) refers to the ability to understand unfamiliar\ncultural contexts-a crucial skill for large language models (LLMs) to\neffectively engage with globally diverse users. While existing research often\nfocuses on explicitly stated cultural norms, such approaches fail to capture\nthe subtle, implicit values that underlie real-world conversations. To address\nthis gap, we introduce CQ-Bench, a benchmark specifically designed to assess\nLLMs' capability to infer implicit cultural values from natural conversational\ncontexts. We generate a multi-character conversation-based stories dataset\nusing values from the World Value Survey and GlobalOpinions datasets, with\ntopics including ethical, religious, social, and political. Our dataset\nconstruction pipeline includes rigorous validation procedures-incorporation,\nconsistency, and implicitness checks-using GPT-4o, with 98.2% human-model\nagreement in the final validation. Our benchmark consists of three tasks of\nincreasing complexity: attitude detection, value selection, and value\nextraction. We find that while o1 and Deepseek-R1 models reach human-level\nperformance in value selection (0.809 and 0.814), they still fall short in\nnuanced attitude detection, with F1 scores of 0.622 and 0.635, respectively. In\nthe value extraction task, GPT-4o-mini and o3-mini score 0.602 and 0.598,\nhighlighting the difficulty of open-ended cultural reasoning. Notably,\nfine-tuning smaller models (e.g., LLaMA-3.2-3B) on only 500 culturally rich\nexamples improves performance by over 10%, even outperforming stronger\nbaselines (o3-mini) in some cases. Using CQ-Bench, we provide insights into the\ncurrent challenges in LLMs' CQ research and suggest practical pathways for\nenhancing LLMs' cross-cultural reasoning abilities.", "published": "2025-04-01 18:54:47", "link": "http://arxiv.org/abs/2504.01127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Repetitions are not all alike: distinct mechanisms sustain repetition in language models", "abstract": "Text generated by language models (LMs) can degrade into repetitive cycles,\nwhere identical word sequences are persistently repeated one after another.\nPrior research has typically treated repetition as a unitary phenomenon.\nHowever, repetitive sequences emerge under diverse tasks and contexts, raising\nthe possibility that it may be driven by multiple underlying factors. Here, we\nexperimentally explore the hypothesis that repetition in LMs can result from\ndistinct mechanisms, reflecting different text generation strategies used by\nthe model. We examine the internal working of LMs under two conditions that\nprompt repetition: one in which repeated sequences emerge naturally after\nhuman-written text, and another where repetition is explicitly induced through\nan in-context learning (ICL) setup. Our analysis reveals key differences\nbetween the two conditions: the model exhibits varying levels of confidence,\nrelies on different attention heads, and shows distinct pattens of change in\nresponse to controlled perturbations. These findings suggest that distinct\ninternal mechanisms can interact to drive repetition, with implications for its\ninterpretation and mitigation strategies. More broadly, our results highlight\nthat the same surface behavior in LMs may be sustained by different underlying\nprocesses, acting independently or in combination.", "published": "2025-04-01 18:16:11", "link": "http://arxiv.org/abs/2504.01100v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual and Multi-Accent Jailbreaking of Audio LLMs", "abstract": "Large Audio Language Models (LALMs) have significantly advanced audio\nunderstanding but introduce critical security risks, particularly through audio\njailbreaks. While prior work has focused on English-centric attacks, we expose\na far more severe vulnerability: adversarial multilingual and multi-accent\naudio jailbreaks, where linguistic and acoustic variations dramatically amplify\nattack success. In this paper, we introduce Multi-AudioJail, the first\nsystematic framework to exploit these vulnerabilities through (1) a novel\ndataset of adversarially perturbed multilingual/multi-accent audio jailbreaking\nprompts, and (2) a hierarchical evaluation pipeline revealing that how acoustic\nperturbations (e.g., reverberation, echo, and whisper effects) interacts with\ncross-lingual phonetics to cause jailbreak success rates (JSRs) to surge by up\nto +57.25 percentage points (e.g., reverberated Kenyan-accented attack on\nMERaLiON). Crucially, our work further reveals that multimodal LLMs are\ninherently more vulnerable than unimodal systems: attackers need only exploit\nthe weakest link (e.g., non-English audio inputs) to compromise the entire\nmodel, which we empirically show by multilingual audio-only attacks achieving\n3.1x higher success rates than text-only attacks. We plan to release our\ndataset to spur research into cross-modal defenses, urging the community to\naddress this expanding attack surface in multimodality as LALMs evolve.", "published": "2025-04-01 18:12:23", "link": "http://arxiv.org/abs/2504.01094v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ShieldGemma 2: Robust and Tractable Image Content Moderation", "abstract": "We introduce ShieldGemma 2, a 4B parameter image content moderation model\nbuilt on Gemma 3. This model provides robust safety risk predictions across the\nfollowing key harm categories: Sexually Explicit, Violence \\& Gore, and\nDangerous Content for synthetic images (e.g. output of any image generation\nmodel) and natural images (e.g. any image input to a Vision-Language Model). We\nevaluated on both internal and external benchmarks to demonstrate\nstate-of-the-art performance compared to LlavaGuard\n\\citep{helff2024llavaguard}, GPT-4o mini \\citep{hurst2024gpt}, and the base\nGemma 3 model \\citep{gemma_2025} based on our policies. Additionally, we\npresent a novel adversarial data generation pipeline which enables a\ncontrolled, diverse, and robust image generation. ShieldGemma 2 provides an\nopen image moderation tool to advance multimodal safety and responsible AI\ndevelopment.", "published": "2025-04-01 18:00:20", "link": "http://arxiv.org/abs/2504.01081v1", "categories": ["cs.CV", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Self-Routing RAG: Binding Selective Retrieval with Knowledge Verbalization", "abstract": "Selective retrieval improves retrieval-augmented generation (RAG) by reducing\ndistractions from low-quality retrievals and improving efficiency. However,\nexisting approaches under-utilize the inherent knowledge of large language\nmodels (LLMs), leading to suboptimal retrieval decisions and degraded\ngeneration performance. To bridge this gap, we propose Self-Routing RAG\n(SR-RAG), a novel framework that binds selective retrieval with knowledge\nverbalization. SR-RAG enables an LLM to dynamically decide between external\nretrieval and verbalizing its own parametric knowledge. To this end, we design\na multi-task objective that jointly optimizes an LLM on knowledge source\nselection, knowledge verbalization, and response generation. We further\nintroduce dynamic knowledge source inference via nearest neighbor search to\nimprove the accuracy of knowledge source decision under domain shifts.\nFine-tuning three LLMs with SR-RAG significantly improves both their response\naccuracy and inference latency. Compared to the strongest selective retrieval\nbaseline, SR-RAG reduces retrievals by 29% while improving the performance by\n5.1%.", "published": "2025-04-01 17:59:30", "link": "http://arxiv.org/abs/2504.01018v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning", "abstract": "Scaling test-time compute has emerged as a key strategy for enhancing the\nreasoning capabilities of large language models (LLMs), particularly in tasks\nlike mathematical problem-solving. A traditional approach, Self-Consistency\n(SC), generates multiple solutions to a problem and selects the most common\nanswer via majority voting. Another common method involves scoring each\nsolution with a reward model (verifier) and choosing the best one. Recent\nadvancements in Generative Reward Models (GenRM) reframe verification as a\nnext-token prediction task, enabling inference-time scaling along a new axis.\nSpecifically, GenRM generates multiple verification chains-of-thought to score\neach solution. Under a limited inference budget, this introduces a fundamental\ntrade-off: should you spend the budget on scaling solutions via SC or generate\nfewer solutions and allocate compute to verification via GenRM? To address\nthis, we evaluate GenRM against SC under a fixed inference budget.\nInterestingly, we find that SC is more compute-efficient than GenRM for most\npractical inference budgets across diverse models and datasets. For instance,\nGenRM first matches SC after consuming up to 8x the inference compute and\nrequires significantly more compute to outperform it. Furthermore, we derive\ninference scaling laws for the GenRM paradigm, revealing that compute-optimal\ninference favors scaling solution generation more aggressively than scaling the\nnumber of verifications. Our work provides practical guidance on optimizing\ntest-time scaling by balancing solution generation and verification. The code\nis available at https://github.com/nishadsinghi/sc-genrm-scaling.", "published": "2025-04-01 17:41:57", "link": "http://arxiv.org/abs/2504.01005v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Token embeddings violate the manifold hypothesis", "abstract": "To fully understand the behavior of a large language model (LLM) requires our\nunderstanding of its input space. If this input space differs from our\nassumption, our understanding of and conclusions about the LLM is likely\nflawed, regardless of its architecture. Here, we elucidate the structure of the\ntoken embeddings, the input domain for LLMs, both empirically and\ntheoretically. We present a generalized and statistically testable model where\nthe neighborhood of each token splits into well-defined signal and noise\ndimensions.\n  This model is based on a generalization of a manifold called a fiber bundle,\nso we denote our hypothesis test as the ``fiber bundle null.'' Failing to\nreject the null is uninformative, but rejecting it at a specific token\nindicates that token has a statistically significant local structure, and so is\nof interest to us. By running our test over several open-source LLMs, each with\nunique token embeddings, we find that the null is frequently rejected, and so\nthe token subspace is provably not a fiber bundle and hence also not a\nmanifold. As a consequence of our findings, when an LLM is presented with two\nsemantically equivalent prompts, and if one prompt contains a token implicated\nby our test, that prompt will likely exhibit more output variability\nproportional to the local signal dimension of the token.", "published": "2025-04-01 17:40:12", "link": "http://arxiv.org/abs/2504.01002v1", "categories": ["cs.CL", "cs.AI", "53Z50, 62H15"], "primary_category": "cs.CL"}
{"title": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "abstract": "As language models improve and become capable of performing more complex\ntasks across modalities, evaluating them automatically becomes increasingly\nchallenging. Developing strong and robust task-specific automatic metrics gets\nharder, and human-annotated test sets -- which are expensive to create --\nsaturate more quickly. A compelling alternative is to design reliable\nstrategies to automate the creation of test data and evaluation, but previous\nattempts either rely on pre-existing data, or focus solely on individual tasks.\nWe present Zero-shot Benchmarking (ZSB), a framework for creating high-quality\nbenchmarks for any task by leveraging language models for both synthetic test\ndata creation and evaluation. ZSB is simple and flexible: it requires only the\ncreation of a prompt for data generation and one for evaluation; it is scalable\nto tasks and languages where collecting real-world data is costly or\nimpractical; it is model-agnostic, allowing the creation of increasingly\nchallenging benchmarks as models improve. To assess the effectiveness of our\nframework, we create benchmarks for five text-only tasks and a multi-modal one:\ngeneral capabilities in four languages (English, Chinese, French, and Korean),\ntranslation, and general vision-language capabilities in English. We then rank\na broad range of open and closed systems on our benchmarks. ZSB rankings\nconsistently correlate strongly with human rankings, outperforming\nwidely-adopted standard benchmarks. Through ablations, we find that strong\nbenchmarks can be created with open models, and that judge model size and\ndataset variety are crucial drivers of performance. We release all our\nbenchmarks, and code to reproduce our experiments and to produce new\nbenchmarks.", "published": "2025-04-01 17:40:08", "link": "http://arxiv.org/abs/2504.01001v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs", "abstract": "Medical tasks such as diagnosis and treatment planning require precise and\ncomplex reasoning, particularly in life-critical domains. Unlike mathematical\nreasoning, medical reasoning demands meticulous, verifiable thought processes\nto ensure reliability and accuracy. However, there is a notable lack of\ndatasets that provide transparent, step-by-step reasoning to validate and\nenhance the medical reasoning ability of AI models. To bridge this gap, we\nintroduce MedReason, a large-scale high-quality medical reasoning dataset\ndesigned to enable faithful and explainable medical problem-solving in large\nlanguage models (LLMs). We utilize a structured medical knowledge graph (KG) to\nconvert clinical QA pairs into logical chains of reasoning, or ``thinking\npaths'', which trace connections from question elements to answers via relevant\nKG entities. Each path is validated for consistency with clinical logic and\nevidence-based medicine. Our pipeline generates detailed reasoning for various\nmedical questions from 7 medical datasets, resulting in a dataset of 32,682\nquestion-answer pairs, each with detailed, step-by-step explanations.\nExperiments demonstrate that fine-tuning with our dataset consistently boosts\nmedical problem-solving capabilities, achieving significant gains of up to 7.7%\nfor DeepSeek-Ditill-8B. Our top-performing model, MedReason-8B, outperforms the\nHuatuo-o1-8B, a state-of-the-art medical reasoning model, by up to 4.2% on the\nclinical benchmark MedBullets. We also engage medical professionals from\ndiverse specialties to assess our dataset's quality, ensuring MedReason offers\naccurate and coherent medical reasoning. Our data, models, and code is\navailable at https://github.com/UCSC-VLAA/MedReason.", "published": "2025-04-01 17:31:44", "link": "http://arxiv.org/abs/2504.00993v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Chinese Grammatical Error Correction: A Survey", "abstract": "Chinese Grammatical Error Correction (CGEC) is a critical task in Natural\nLanguage Processing, addressing the growing demand for automated writing\nassistance in both second-language (L2) and native (L1) Chinese writing. While\nL2 learners struggle with mastering complex grammatical structures, L1 users\nalso benefit from CGEC in academic, professional, and formal contexts where\nwriting precision is essential. This survey provides a comprehensive review of\nCGEC research, covering datasets, annotation schemes, evaluation methodologies,\nand system advancements. We examine widely used CGEC datasets, highlighting\ntheir characteristics, limitations, and the need for improved standardization.\nWe also analyze error annotation frameworks, discussing challenges such as word\nsegmentation ambiguity and the classification of Chinese-specific error types.\nFurthermore, we review evaluation metrics, focusing on their adaptation from\nEnglish GEC to Chinese, including character-level scoring and the use of\nmultiple references. In terms of system development, we trace the evolution\nfrom rule-based and statistical approaches to neural architectures, including\nTransformer-based models and the integration of large pre-trained language\nmodels. By consolidating existing research and identifying key challenges, this\nsurvey provides insights into the current state of CGEC and outlines future\ndirections, including refining annotation standards to address segmentation\nchallenges, and leveraging multilingual approaches to enhance CGEC.", "published": "2025-04-01 17:14:50", "link": "http://arxiv.org/abs/2504.00977v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching", "abstract": "Large language models face significant computational and memory challenges\nwhen processing long contexts. During inference, efficient management of the\nkey-value (KV) cache, which stores intermediate activations for autoregressive\ngeneration, is critical to reducing memory overhead and improving computational\nefficiency. Traditional token-level efficient KV caching methods overlook\nsemantic information, treating tokens independently without considering their\nsemantic relationships. Meanwhile, existing semantic-preserving KV cache\nmanagement approaches often suffer from substantial memory usage and high\ntime-to-first-token. To address these limitations, we propose SentenceKV, a\nnovel sentence-level semantic KV caching approach designed to enhance inference\nefficiency while preserving semantic coherence. During prefilling, SentenceKV\ngroups tokens based on sentence-level semantic similarity, compressing sentence\nrepresentations into concise semantic vectors stored directly on the GPU, while\nindividual KV pairs are offloaded to CPU. During decoding, SentenceKV generates\ntokens by selectively retrieving semantically relevant sentence-level KV\nentries, leveraging the semantic similarity between the prefilling-stage\nsemantic vectors and decoding-stage queries. This ensures efficient and\ncontextually accurate predictions, minimizing the loading of redundant or\nirrelevant data into GPU memory and significantly reducing memory overhead\nwhile maintaining stable inference latency, even for extremely long contexts.\nExtensive evaluations on benchmarks including PG-19, LongBench, and\nNeedle-In-A-Haystack demonstrate that SentenceKV significantly outperforms\nstate-of-the-art methods in both efficiency and memory usage, without\ncompromising model accuracy.", "published": "2025-04-01 17:08:57", "link": "http://arxiv.org/abs/2504.00970v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Experiential Semantic Information and Brain Alignment: Are Multimodal Models Better than Language Models?", "abstract": "A common assumption in Computational Linguistics is that text representations\nlearnt by multimodal models are richer and more human-like than those by\nlanguage-only models, as they are grounded in images or audio -- similar to how\nhuman language is grounded in real-world experiences. However, empirical\nstudies checking whether this is true are largely lacking. We address this gap\nby comparing word representations from contrastive multimodal models vs.\nlanguage-only ones in the extent to which they capture experiential information\n-- as defined by an existing norm-based 'experiential model' -- and align with\nhuman fMRI responses. Our results indicate that, surprisingly, language-only\nmodels are superior to multimodal ones in both respects. Additionally, they\nlearn more unique brain-relevant semantic information beyond that shared with\nthe experiential model. Overall, our study highlights the need to develop\ncomputational models that better integrate the complementary semantic\ninformation provided by multimodal data sources.", "published": "2025-04-01 16:28:38", "link": "http://arxiv.org/abs/2504.00942v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiVideo: Article Generation from Multiple Videos", "abstract": "We present the challenging task of automatically creating a high-level\nWikipedia-style article that aggregates information from multiple diverse\nvideos about real-world events, such as natural disasters or political\nelections. Videos are intuitive sources for retrieval-augmented generation\n(RAG), but most contemporary RAG workflows focus heavily on text and existing\nmethods for video-based summarization focus on low-level scene understanding\nrather than high-level event semantics. To close this gap, we introduce\nWikiVideo, a benchmark consisting of expert-written articles and densely\nannotated videos that provide evidence for articles' claims, facilitating the\nintegration of video into RAG pipelines and enabling the creation of in-depth\ncontent that is grounded in multimodal sources. We further propose\nCollaborative Article Generation (CAG), a novel interactive method for article\ncreation from multiple videos. CAG leverages an iterative interaction between\nan r1-style reasoning model and a VideoLLM to draw higher level inferences\nabout the target event than is possible with VideoLLMs alone, which fixate on\nlow-level visual features. We benchmark state-of-the-art VideoLLMs and CAG in\nboth oracle retrieval and RAG settings and find that CAG consistently\noutperforms alternative methods, while suggesting intriguing avenues for future\nwork.", "published": "2025-04-01 16:22:15", "link": "http://arxiv.org/abs/2504.00939v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "InformGen: An AI Copilot for Accurate and Compliant Clinical Research Consent Document Generation", "abstract": "Leveraging large language models (LLMs) to generate high-stakes documents,\nsuch as informed consent forms (ICFs), remains a significant challenge due to\nthe extreme need for regulatory compliance and factual accuracy. Here, we\npresent InformGen, an LLM-driven copilot for accurate and compliant ICF\ndrafting by optimized knowledge document parsing and content generation, with\nhumans in the loop. We further construct a benchmark dataset comprising\nprotocols and ICFs from 900 clinical trials. Experimental results demonstrate\nthat InformGen achieves near 100% compliance with 18 core regulatory rules\nderived from FDA guidelines, outperforming a vanilla GPT-4o model by up to 30%.\nAdditionally, a user study with five annotators shows that InformGen, when\nintegrated with manual intervention, attains over 90% factual accuracy,\nsignificantly surpassing the vanilla GPT-4o model's 57%-82%. Crucially,\nInformGen ensures traceability by providing inline citations to source\nprotocols, enabling easy verification and maintaining the highest standards of\nfactual integrity.", "published": "2025-04-01 16:14:48", "link": "http://arxiv.org/abs/2504.00934v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scraping the Shadows: Deep Learning Breakthroughs in Dark Web Intelligence", "abstract": "Darknet markets (DNMs) facilitate the trade of illegal goods on a global\nscale. Gathering data on DNMs is critical to ensuring law enforcement agencies\ncan effectively combat crime. Manually extracting data from DNMs is an\nerror-prone and time-consuming task. Aiming to automate this process we develop\na framework for extracting data from DNMs and evaluate the application of three\nstate-of-the-art Named Entity Recognition (NER) models, ELMo-BiLSTM\n\\citep{ShahEtAl2022}, UniversalNER \\citep{ZhouEtAl2024}, and GLiNER\n\\citep{ZaratianaEtAl2023}, at the task of extracting complex entities from DNM\nproduct listing pages. We propose a new annotated dataset, which we use to\ntrain, fine-tune, and evaluate the models. Our findings show that\nstate-of-the-art NER models perform well in information extraction from DNMs,\nachieving 91% Precision, 96% Recall, and an F1 score of 94%. In addition,\nfine-tuning enhances model performance, with UniversalNER achieving the best\nperformance.", "published": "2025-04-01 16:12:19", "link": "http://arxiv.org/abs/2504.02872v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Taxonomizing Representational Harms using Speech Act Theory", "abstract": "Representational harms are widely recognized among fairness-related harms\ncaused by generative language systems. However, their definitions are commonly\nunder-specified. We present a framework, grounded in speech act theory (Austin,\n1962), that conceptualizes representational harms caused by generative language\nsystems as the perlocutionary effects (i.e., real-world impacts) of particular\ntypes of illocutionary acts (i.e., system behaviors). Building on this argument\nand drawing on relevant literature from linguistic anthropology and\nsociolinguistics, we provide new definitions stereotyping, demeaning, and\nerasure. We then use our framework to develop a granular taxonomy of\nillocutionary acts that cause representational harms, going beyond the\nhigh-level taxonomies presented in previous work. We also discuss the ways that\nour framework and taxonomy can support the development of valid measurement\ninstruments. Finally, we demonstrate the utility of our framework and taxonomy\nvia a case study that engages with recent conceptual debates about what\nconstitutes a representational harm and how such harms should be measured.", "published": "2025-04-01 16:00:17", "link": "http://arxiv.org/abs/2504.00928v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Multi-Token Attention", "abstract": "Soft attention is a critical mechanism powering LLMs to locate relevant parts\nwithin a given context. However, individual attention weights are determined by\nthe similarity of only a single query and key token vector. This \"single token\nattention\" bottlenecks the amount of information used in distinguishing a\nrelevant part from the rest of the context. To address this issue, we propose a\nnew attention method, Multi-Token Attention (MTA), which allows LLMs to\ncondition their attention weights on multiple query and key vectors\nsimultaneously. This is achieved by applying convolution operations over\nqueries, keys and heads, allowing nearby queries and keys to affect each\nother's attention weights for more precise attention. As a result, our method\ncan locate relevant context using richer, more nuanced information that can\nexceed a single vector's capacity. Through extensive evaluations, we\ndemonstrate that MTA achieves enhanced performance on a range of popular\nbenchmarks. Notably, it outperforms Transformer baseline models on standard\nlanguage modeling tasks, and on tasks that require searching for information\nwithin long contexts, where our method's ability to leverage richer information\nproves particularly beneficial.", "published": "2025-04-01 15:59:32", "link": "http://arxiv.org/abs/2504.00927v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthesized Annotation Guidelines are Knowledge-Lite Boosters for Clinical Information Extraction", "abstract": "Generative information extraction using large language models, particularly\nthrough few-shot learning, has become a popular method. Recent studies indicate\nthat providing a detailed, human-readable guideline-similar to the annotation\nguidelines traditionally used for training human annotators can significantly\nimprove performance. However, constructing these guidelines is both labor- and\nknowledge-intensive. Additionally, the definitions are often tailored to meet\nspecific needs, making them highly task-specific and often non-reusable.\nHandling these subtle differences requires considerable effort and attention to\ndetail. In this study, we propose a self-improving method that harvests the\nknowledge summarization and text generation capacity of LLMs to synthesize\nannotation guidelines while requiring virtually no human input. Our zero-shot\nexperiments on the clinical named entity recognition benchmarks, 2012 i2b2\nEVENT, 2012 i2b2 TIMEX, 2014 i2b2, and 2018 n2c2 showed 25.86%, 4.36%, 0.20%,\nand 7.75% improvements in strict F1 scores from the no-guideline baseline. The\nLLM-synthesized guidelines showed equivalent or better performance compared to\nhuman-written guidelines by 1.15% to 4.14% in most tasks. In conclusion, this\nstudy proposes a novel LLM self-improving method that requires minimal\nknowledge and human input and is applicable to multiple biomedical domains.", "published": "2025-04-01 15:59:04", "link": "http://arxiv.org/abs/2504.02871v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On the Robustness of Agentic Function Calling", "abstract": "Large Language Models (LLMs) are increasingly acting as autonomous agents,\nwith function calling (FC) capabilities enabling them to invoke specific tools\nfor tasks. While prior research has primarily focused on improving FC accuracy,\nlittle attention has been given to the robustness of these agents to\nperturbations in their input. We introduce a benchmark assessing FC robustness\nin two key areas: resilience to naturalistic query variations, and stability in\nfunction calling when the toolkit expands with semantically related tools.\nEvaluating best-performing FC models on a carefully expanded subset of the\nBerkeley function calling leaderboard (BFCL), we identify critical weaknesses\nin existing evaluation methodologies, and highlight areas for improvement in\nreal-world agentic deployments.", "published": "2025-04-01 15:48:26", "link": "http://arxiv.org/abs/2504.00914v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents", "abstract": "Computer use agents automate digital tasks by directly interacting with\ngraphical user interfaces (GUIs) on computers and mobile devices, offering\nsignificant potential to enhance human productivity by completing an open-ended\nspace of user queries. However, current agents face significant challenges:\nimprecise grounding of GUI elements, difficulties with long-horizon task\nplanning, and performance bottlenecks from relying on single generalist models\nfor diverse cognitive tasks. To this end, we introduce Agent S2, a novel\ncompositional framework that delegates cognitive responsibilities across\nvarious generalist and specialist models. We propose a novel\nMixture-of-Grounding technique to achieve precise GUI localization and\nintroduce Proactive Hierarchical Planning, dynamically refining action plans at\nmultiple temporal scales in response to evolving observations. Evaluations\ndemonstrate that Agent S2 establishes new state-of-the-art (SOTA) performance\non three prominent computer use benchmarks. Specifically, Agent S2 achieves\n18.9% and 32.7% relative improvements over leading baseline agents such as\nClaude Computer Use and UI-TARS on the OSWorld 15-step and 50-step evaluation.\nMoreover, Agent S2 generalizes effectively to other operating systems and\napplications, surpassing previous best methods by 52.8% on WindowsAgentArena\nand by 16.52% on AndroidWorld relatively. Code available at\nhttps://github.com/simular-ai/Agent-S.", "published": "2025-04-01 15:40:27", "link": "http://arxiv.org/abs/2504.00906v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning", "abstract": "Recent advancements in Large Language Models (LLMs) have shown that it is\npromising to utilize Process Reward Models (PRMs) as verifiers to enhance the\nperformance of LLMs. However, current PRMs face three key challenges: (1)\nlimited process supervision and generalization capabilities, (2) dependence on\nscalar value prediction without leveraging the generative abilities of LLMs,\nand (3) inability to scale the test-time compute of PRMs. In this work, we\nintroduce GenPRM, a generative process reward model that performs explicit\nChain-of-Thought (CoT) reasoning with code verification before providing\njudgment for each reasoning step. To obtain high-quality process supervision\nlabels and rationale data, we propose Relative Progress Estimation (RPE) and a\nrationale synthesis framework that incorporates code verification. Experimental\nresults on ProcessBench and several mathematical reasoning tasks show that\nGenPRM significantly outperforms prior PRMs with only 23K training data from\nMATH dataset. Through test-time scaling, a 1.5B GenPRM outperforms GPT-4o, and\na 7B GenPRM surpasses Qwen2.5-Math-PRM-72B on ProcessBench. Additionally,\nGenPRM demonstrates strong abilities to serve as a critic model for policy\nmodel refinement. This work establishes a new paradigm for process supervision\nthat bridges the gap between PRMs and critic models in LLMs. Our code, model,\nand data will be available in https://ryanliu112.github.io/GenPRM.", "published": "2025-04-01 15:21:05", "link": "http://arxiv.org/abs/2504.00891v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CrackSQL: A Hybrid SQL Dialect Translation System Powered by Large Language Models", "abstract": "Dialect translation plays a key role in enabling seamless interaction across\nheterogeneous database systems. However, translating SQL queries between\ndifferent dialects (e.g., from PostgreSQL to MySQL) remains a challenging task\ndue to syntactic discrepancies and subtle semantic variations. Existing\napproaches including manual rewriting, rule-based systems, and large language\nmodel (LLM)-based techniques often involve high maintenance effort (e.g.,\ncrafting custom translation rules) or produce unreliable results (e.g., LLM\ngenerates non-existent functions), especially when handling complex queries. In\nthis demonstration, we present CrackSQL, the first hybrid SQL dialect\ntranslation system that combines rule and LLM-based methods to overcome these\nlimitations. CrackSQL leverages the adaptability of LLMs to minimize manual\nintervention, while enhancing translation accuracy by segmenting lengthy\ncomplex SQL via functionality-based query processing. To further improve\nrobustness, it incorporates a novel cross-dialect syntax embedding model for\nprecise syntax alignment, as well as an adaptive local-to-global translation\nstrategy that effectively resolves interdependent query operations. CrackSQL\nsupports three translation modes and offers multiple deployment and access\noptions including a web console interface, a PyPI package, and a command-line\nprompt, facilitating adoption across a variety of real-world use cases", "published": "2025-04-01 15:11:03", "link": "http://arxiv.org/abs/2504.00882v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.DB"}
{"title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models", "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the\nreasoning capabilities of large language models. However, its effectiveness in\nmedical reasoning remains uncertain, as the medical domain fundamentally\ndiffers from mathematical tasks in terms of knowledge representation and\ndecision-making processes. In this paper, we provide the first comprehensive\ninvestigation of test-time scaling for medical reasoning and present m1, a\nsimple yet effective approach that increases a model's medical reasoning\ncapability at inference. Our evaluation across diverse medical tasks\ndemonstrates that test-time scaling consistently enhances medical reasoning,\nenabling lightweight fine-tuned models under 10B parameters to establish new\nstate-of-the-art performance, while our 32B model rivals previous 70B-scale\nmedical LLMs. However, we identify an optimal reasoning token budget of\napproximately 4K, beyond which performance may degrade due to overthinking.\nBudget forcing, which extends test-time computation through iterative prompts,\nhelps models double-check answers but does not necessarily improve the overall\nmedical QA performance and, in some cases, even introduces errors into\npreviously correct responses. Our case-by-case analysis identifies insufficient\nmedical knowledge as a key bottleneck that prevents further performance gains\nthrough test-time scaling. We find that increasing data scale, improving data\nquality, and expanding model capacity consistently enhance medical knowledge\ngrounding, enabling continued performance improvements, particularly on\nchallenging medical benchmarks where smaller models reach saturation. These\nfindings underscore fundamental differences between medical and mathematical\nreasoning in LLMs, highlighting that enriched medical knowledge, other than\nincreased reasoning depth alone, is essential for realizing the benefits of\ntest-time scaling.", "published": "2025-04-01 14:57:43", "link": "http://arxiv.org/abs/2504.00869v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals", "abstract": "Despite numerous efforts to mitigate their biases, ML systems continue to\nharm already-marginalized people. While predominant ML approaches assume bias\ncan be removed and fair models can be created, we show that these are not\nalways possible, nor desirable, goals. We reframe the problem of ML bias by\ncreating models to identify biased language, drawing attention to a dataset's\nbiases rather than trying to remove them. Then, through a workshop, we\nevaluated the models for a specific use case: workflows of information and\nheritage professionals. Our findings demonstrate the limitations of ML for\nidentifying bias due to its contextual nature, the way in which approaches to\nmitigating it can simultaneously privilege and oppress different communities,\nand its inevitability. We demonstrate the need to expand ML approaches to bias\nand fairness, providing a mixed-methods approach to investigating the\nfeasibility of removing bias or achieving fairness in a given ML use case.", "published": "2025-04-01 14:51:25", "link": "http://arxiv.org/abs/2504.00860v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG", "I.2.7; J.0; K.4.0"], "primary_category": "cs.CL"}
{"title": "How Difficulty-Aware Staged Reinforcement Learning Enhances LLMs' Reasoning Capabilities: A Preliminary Experimental Study", "abstract": "Enhancing the reasoning capabilities of Large Language Models (LLMs) with\nefficiency and scalability remains a fundamental challenge in artificial\nintelligence research. This paper presents a rigorous experimental\ninvestigation into how difficulty-aware staged reinforcement learning (RL)\nstrategies can substantially improve LLM reasoning performance. Through\nsystematic analysis, we demonstrate that strategically selecting training data\naccording to well-defined difficulty levels markedly enhances RL optimization.\nMoreover, we introduce a staged training methodology, progressively exposing\nmodels to increasingly challenging tasks, further amplifying reasoning\ncapabilities. Our findings reveal significant cross-domain benefits when\nsimultaneously training models on mathematical reasoning and code generation\ntasks. Notably, our proposed approach enables a 1.5B parameter model to achieve\nan accuracy of 42.3\\% on the AIME-2024 benchmark, 89.5\\% on the MATH-500\nbenchmark. These results underscore the efficacy of our method in advancing the\nreasoning proficiency of LLMs. We will open-source our datasets on GitHub and\nHugging Face.", "published": "2025-04-01 14:18:38", "link": "http://arxiv.org/abs/2504.00829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ScholarCopilot: Training Large Language Models for Academic Writing with Accurate Citations", "abstract": "Academic writing requires both coherent text generation and precise citation\nof relevant literature. Although recent Retrieval-Augmented Generation (RAG)\nsystems have significantly improved factual accuracy in general-purpose text\ngeneration, their ability to support professional academic writing remains\nlimited. In this work, we introduce ScholarCopilot, a unified framework\ndesigned to enhance existing large language models for generating professional\nacademic articles with accurate and contextually relevant citations.\nScholarCopilot dynamically determines when to retrieve scholarly references by\ngenerating a retrieval token [RET], which is then used to query a citation\ndatabase. The retrieved references are fed into the model to augment the\ngeneration process. We jointly optimize both the generation and citation tasks\nwithin a single framework to improve efficiency. Our model is built upon\nQwen-2.5-7B and trained on 500K papers from arXiv. It achieves a top-1\nretrieval accuracy of 40.1% on our evaluation dataset, outperforming baselines\nsuch as E5-Mistral-7B-Instruct (15.0%) and BM25 (9.8%). On a dataset of 1,000\nacademic writing samples, ScholarCopilot scores 16.2/25 in generation quality\n-- measured across relevance, coherence, academic rigor, completeness, and\ninnovation -- significantly surpassing all existing models, including much\nlarger ones like the Retrieval-Augmented Qwen2.5-72B-Instruct. Human studies\nfurther demonstrate that ScholarCopilot, despite being a 7B model,\nsignificantly outperforms ChatGPT, achieving 100% preference in citation\nquality and over 70% in overall usefulness.", "published": "2025-04-01 14:12:14", "link": "http://arxiv.org/abs/2504.00824v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Z1: Efficient Test-time Scaling with Code", "abstract": "Large Language Models (LLMs) can achieve enhanced complex problem-solving\nthrough test-time computing scaling, yet this often entails longer contexts and\nnumerous reasoning token costs. In this paper, we propose an efficient\ntest-time scaling method that trains LLMs on code-related reasoning\ntrajectories, facilitating their reduction of excess thinking tokens while\nmaintaining performance. First, we create Z1-Code-Reasoning-107K, a curated\ndataset of simple and complex coding problems paired with their short and long\nsolution trajectories. Second, we present a novel Shifted Thinking Window to\nmitigate overthinking overhead by removing context-delimiting tags (e.g.,\n<think>. . . </think>) and capping reasoning tokens. Trained with long and\nshort trajectory data and equipped with Shifted Thinking Window, our model,\nZ1-7B, demonstrates the ability to adjust its reasoning level as the complexity\nof problems and exhibits efficient test-time scaling across different reasoning\ntasks that matches R1-Distill-Qwen-7B performance with about 30% of its average\nthinking tokens. Notably, fine-tuned with only code trajectories, Z1-7B\ndemonstrates generalization to broader reasoning tasks (47.5% on GPQA Diamond).\nOur analysis of efficient reasoning elicitation also provides valuable insights\nfor future research.", "published": "2025-04-01 14:01:50", "link": "http://arxiv.org/abs/2504.00810v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inaccuracy of an E-Dictionary and Its Influence on Chinese Language Users", "abstract": "Electronic dictionaries have largely replaced paper dictionaries and become\ncentral tools for L2 learners seeking to expand their vocabulary. Users often\nassume these resources are reliable and rarely question the validity of the\ndefinitions provided. The accuracy of major E-dictionaries is seldom\nscrutinized, and little attention has been paid to how their corpora are\nconstructed. Research on dictionary use, particularly the limitations of\nelectronic dictionaries, remains scarce. This study adopts a combined method of\nexperimentation, user survey, and dictionary critique to examine Youdao, one of\nthe most widely used E-dictionaries in China. The experiment involved a\ntranslation task paired with retrospective reflection. Participants were asked\nto translate sentences containing words that are insufficiently or inaccurately\ndefined in Youdao. Their consultation behavior was recorded to analyze how\nfaulty definitions influenced comprehension. Results show that incomplete or\nmisleading definitions can cause serious misunderstandings. Additionally,\nstudents exhibited problematic consultation habits. The study further explores\nhow such flawed definitions originate, highlighting issues in data processing\nand the integration of AI and machine learning technologies in dictionary\nconstruction. The findings suggest a need for better training in dictionary\nliteracy for users, as well as improvements in the underlying AI models used to\nbuild E-dictionaries.", "published": "2025-04-01 13:54:33", "link": "http://arxiv.org/abs/2504.00799v1", "categories": ["cs.CL", "cs.HC", "H.5.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Digitally Supported Analysis of Spontaneous Speech (DigiSpon): Benchmarking NLP-Supported Language Sample Analysis of Swiss Children's Speech", "abstract": "Language sample analysis (LSA) is a process that complements standardized\npsychometric tests for diagnosing, for example, developmental language disorder\n(DLD) in children. However, its labor-intensive nature has limited its use in\nspeech-language pathology practice. We introduce an approach that leverages\nnatural language processing (NLP) methods not based on commercial large\nlanguage models (LLMs) applied to transcribed speech data from 119 children in\nthe German speaking part of Switzerland with typical and atypical language\ndevelopment. The study aims to identify optimal practices that support\nspeech-language pathologists in diagnosing DLD more efficiently within a\nhuman-in-the-loop framework, without relying on potentially unethical\nimplementations that leverage commercial LLMs. Preliminary findings underscore\nthe potential of integrating locally deployed NLP methods into the process of\nsemi-automatic LSA.", "published": "2025-04-01 13:32:38", "link": "http://arxiv.org/abs/2504.00780v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automated Explanation of Machine Learning Models of Footballing Actions in Words", "abstract": "While football analytics has changed the way teams and analysts assess\nperformance, there remains a communication gap between machine learning\npractice and how coaching staff talk about football. Coaches and practitioners\nrequire actionable insights, which are not always provided by models. To bridge\nthis gap, we show how to build wordalizations (a novel approach that leverages\nlarge language models) for shots in football. Specifically, we first build an\nexpected goals model using logistic regression. We then use the co-efficients\nof this regression model to write sentences describing how factors (such as\ndistance, angle and defensive pressure) contribute to the model's prediction.\nFinally, we use large language models to give an entertaining description of\nthe shot. We describe our approach in a model card and provide an interactive\nopen-source application describing shots in recent tournaments. We discuss how\nshot wordalisations might aid communication in coaching and football\ncommentary, and give a further example of how the same approach can be applied\nto other actions in football.", "published": "2025-04-01 13:18:22", "link": "http://arxiv.org/abs/2504.00767v1", "categories": ["cs.LG", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "RECKON: Large-scale Reference-based Efficient Knowledge Evaluation for Large Language Model", "abstract": "As large language models (LLMs) advance, efficient knowledge evaluation\nbecomes crucial to verifying their capabilities. Traditional methods, relying\non benchmarks, face limitations such as high resource costs and information\nloss. We propose the Large-scale Reference-based Efficient Knowledge Evaluation\nfor Large Language Model (RECKON), which directly uses reference data to\nevaluate models. RECKON organizes unstructured data into manageable units and\ngenerates targeted questions for each cluster, improving evaluation accuracy\nand efficiency. Experimental results show that RECKON reduces resource\nconsumption by 56.5% compared to traditional methods while achieving over 97%\naccuracy across various domains, including world knowledge, code, legal, and\nbiomedical datasets. Code is available at https://github.com/MikeGu721/reckon", "published": "2025-04-01 13:08:04", "link": "http://arxiv.org/abs/2504.00756v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models", "abstract": "Extracting structured information from unstructured text is crucial for\nmodeling real-world processes, but traditional schema mining relies on\nsemi-structured data, limiting scalability. This paper introduces schema-miner,\na novel tool that combines large language models with human feedback to\nautomate and refine schema extraction. Through an iterative workflow, it\norganizes properties from text, incorporates expert input, and integrates\ndomain-specific ontologies for semantic depth. Applied to materials\nscience--specifically atomic layer deposition--schema-miner demonstrates that\nexpert-guided LLMs generate semantically rich schemas suitable for diverse\nreal-world applications.", "published": "2025-04-01 13:03:33", "link": "http://arxiv.org/abs/2504.00752v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "IHC-LLMiner: Automated extraction of tumour immunohistochemical profiles from PubMed abstracts using large language models", "abstract": "Immunohistochemistry (IHC) is essential in diagnostic pathology and\nbiomedical research, offering critical insights into protein expression and\ntumour biology. This study presents an automated pipeline, IHC-LLMiner, for\nextracting IHC-tumour profiles from PubMed abstracts, leveraging advanced\nbiomedical text mining. There are two subtasks: abstract classification\n(include/exclude as relevant) and IHC-tumour profile extraction on relevant\nincluded abstracts. The best-performing model, \"Gemma-2 finetuned\", achieved\n91.5% accuracy and an F1 score of 91.4, outperforming GPT4-O by 9.5% accuracy\nwith 5.9 times faster inference time. From an initial dataset of 107,759\nabstracts identified for 50 immunohistochemical markers, the classification\ntask identified 30,481 relevant abstracts (Include) using the Gemma-2 finetuned\nmodel. For IHC-tumour profile extraction, the Gemma-2 finetuned model achieved\nthe best performance with 63.3% Correct outputs. Extracted IHC-tumour profiles\n(tumour types and markers) were normalised to Unified Medical Language System\n(UMLS) concepts to ensure consistency and facilitate IHC-tumour profile\nlandscape analysis. The extracted IHC-tumour profiles demonstrated excellent\nconcordance with available online summary data and provided considerable added\nvalue in terms of both missing IHC-tumour profiles and quantitative\nassessments. Our proposed LLM based pipeline provides a practical solution for\nlarge-scale IHC-tumour profile data mining, enhancing the accessibility and\nutility of such data for research and clinical applications as well as enabling\nthe generation of quantitative and structured data to support cancer-specific\nknowledge base development. Models and training datasets are available at\nhttps://github.com/knowlab/IHC-LLMiner.", "published": "2025-04-01 12:58:07", "link": "http://arxiv.org/abs/2504.00748v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening", "abstract": "Resume screening is a critical yet time-intensive process in talent\nacquisition, requiring recruiters to analyze vast volume of job applications\nwhile remaining objective, accurate, and fair. With the advancements in Large\nLanguage Models (LLMs), their reasoning capabilities and extensive knowledge\nbases demonstrate new opportunities to streamline and automate recruitment\nworkflows. In this work, we propose a multi-agent framework for resume\nscreening using LLMs to systematically process and evaluate resumes. The\nframework consists of four core agents, including a resume extractor, an\nevaluator, a summarizer, and a score formatter. To enhance the contextual\nrelevance of candidate assessments, we integrate Retrieval-Augmented Generation\n(RAG) within the resume evaluator, allowing incorporation of external knowledge\nsources, such as industry-specific expertise, professional certifications,\nuniversity rankings, and company-specific hiring criteria. This dynamic\nadaptation enables personalized recruitment, bridging the gap between AI\nautomation and talent acquisition. We assess the effectiveness of our approach\nby comparing AI-generated scores with ratings provided by HR professionals on a\ndataset of anonymized online resumes. The findings highlight the potential of\nmulti-agent RAG-LLM systems in automating resume screening, enabling more\nefficient and scalable hiring workflows.", "published": "2025-04-01 12:56:39", "link": "http://arxiv.org/abs/2504.02870v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Aplica\u00e7\u00e3o de Large Language Models na An\u00e1lise e S\u00edntese de Documentos Jur\u00eddicos: Uma Revis\u00e3o de Literatura", "abstract": "Large Language Models (LLMs) have been increasingly used to optimize the\nanalysis and synthesis of legal documents, enabling the automation of tasks\nsuch as summarization, classification, and retrieval of legal information. This\nstudy aims to conduct a systematic literature review to identify the state of\nthe art in prompt engineering applied to LLMs in the legal context. The results\nindicate that models such as GPT-4, BERT, Llama 2, and Legal-Pegasus are widely\nemployed in the legal field, and techniques such as Few-shot Learning,\nZero-shot Learning, and Chain-of-Thought prompting have proven effective in\nimproving the interpretation of legal texts. However, challenges such as biases\nin models and hallucinations still hinder their large-scale implementation. It\nis concluded that, despite the great potential of LLMs for the legal field,\nthere is a need to improve prompt engineering strategies to ensure greater\naccuracy and reliability in the generated results.", "published": "2025-04-01 12:34:00", "link": "http://arxiv.org/abs/2504.00725v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Command A: An Enterprise-Ready Large Language Model", "abstract": "In this report we describe the development of Command A, a powerful large\nlanguage model purpose-built to excel at real-world enterprise use cases.\nCommand A is an agent-optimised and multilingual-capable model, with support\nfor 23 languages of global business, and a novel hybrid architecture balancing\nefficiency with top of the range performance. It offers best-in-class Retrieval\nAugmented Generation (RAG) capabilities with grounding and tool use to automate\nsophisticated business processes. These abilities are achieved through a\ndecentralised training approach, including self-refinement algorithms and model\nmerging techniques. We also include results for Command R7B which shares\ncapability and architectural similarities to Command A. Weights for both models\nhave been released for research purposes. This technical report details our\noriginal training pipeline and presents an extensive evaluation of our models\nacross a suite of enterprise-relevant tasks and public benchmarks,\ndemonstrating excellent performance and efficiency.", "published": "2025-04-01 12:08:07", "link": "http://arxiv.org/abs/2504.00698v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ToReMi: Topic-Aware Data Reweighting for Dynamic Pre-Training Data Selection", "abstract": "Pre-training large language models (LLMs) necessitates enormous diverse\ntextual corpora, making effective data selection a key challenge for balancing\ncomputational resources and model performance. Current methodologies primarily\nemphasize data quality metrics and mixing proportions, yet they fail to\nadequately capture the underlying semantic connections between training samples\nand quality disparities within individual domains. We introduce ToReMi\n(Topic-based Reweighting for Model improvement), a novel two-stage framework\nthat dynamically adjusts training sample weights according to their topical\nassociations and observed learning patterns. Our comprehensive experiments\nreveal that ToReMi variants consistently achieve superior performance over\nconventional pre-training approaches, demonstrating accelerated perplexity\nreduction across multiple domains and enhanced capabilities on downstream\nevaluation tasks. Code is available at https://github.com/zxx000728/ToReMi.", "published": "2025-04-01 12:06:42", "link": "http://arxiv.org/abs/2504.00695v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLiNER-biomed: A Suite of Efficient Models for Open Biomedical Named Entity Recognition", "abstract": "Biomedical named entity recognition (NER) presents unique challenges due to\nspecialized vocabularies, the sheer volume of entities, and the continuous\nemergence of novel entities. Traditional NER models, constrained by fixed\ntaxonomies and human annotations, struggle to generalize beyond predefined\nentity types or efficiently adapt to emerging concepts. To address these\nissues, we introduce GLiNER-biomed, a domain-adapted suite of Generalist and\nLightweight Model for NER (GLiNER) models specifically tailored for biomedical\nNER. In contrast to conventional approaches, GLiNER uses natural language\ndescriptions to infer arbitrary entity types, enabling zero-shot recognition.\nOur approach first distills the annotation capabilities of large language\nmodels (LLMs) into a smaller, more efficient model, enabling the generation of\nhigh-coverage synthetic biomedical NER data. We subsequently train two GLiNER\narchitectures, uni- and bi-encoder, at multiple scales to balance computational\nefficiency and recognition performance. Evaluations on several biomedical\ndatasets demonstrate that GLiNER-biomed outperforms state-of-the-art GLiNER\nmodels in both zero- and few-shot scenarios, achieving 5.96% improvement in\nF1-score over the strongest baseline. Ablation studies highlight the\neffectiveness of our synthetic data generation strategy and emphasize the\ncomplementary benefits of synthetic biomedical pre-training combined with\nfine-tuning on high-quality general-domain annotations. All datasets, models,\nand training pipelines are publicly available at\nhttps://github.com/ds4dh/GLiNER-biomed.", "published": "2025-04-01 11:40:50", "link": "http://arxiv.org/abs/2504.00676v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Virtual Mixture-of-Experts Framework:Enhanced Inference and Hallucination Mitigation in Single-Model System", "abstract": "Generative models, such as GPT and BERT, have significantly improved\nperformance in tasks like text generation and summarization. However,\nhallucinations \"where models generate non-factual or misleading content\" are\nespecially problematic in smaller-scale architectures, limiting their\nreal-world applicability.In this paper, we propose a unified Virtual\nMixture-of-Experts (MoE) fusion strategy that enhances inference performance\nand mitigates hallucinations in a single Qwen 1.5 0.5B model without increasing\nthe parameter count. Our method leverages multiple domain-specific expert\nprompts (with the number of experts being adjustable) to guide the model from\ndifferent perspectives. We apply a statistical outlier truncation strategy\nbased on the mean and standard deviation to filter out abnormally high\nprobability predictions, and we inject noise into the embedding space to\npromote output diversity. To clearly assess the contribution of each module, we\nadopt a fixed voting mechanism rather than a dynamic gating network, thereby\navoiding additional confounding factors. We provide detailed theoretical\nderivations from both statistical and ensemble learning perspectives to\ndemonstrate how our method reduces output variance and suppresses\nhallucinations. Extensive ablation experiments on dialogue generation tasks\nshow that our approach significantly improves inference accuracy and robustness\nin small models. Additionally, we discuss methods for evaluating the\northogonality of virtual experts and outline the potential for future work\ninvolving dynamic expert weight allocation using gating networks.", "published": "2025-04-01 11:38:01", "link": "http://arxiv.org/abs/2504.03739v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Do LLMs Surpass Encoders for Biomedical NER?", "abstract": "Recognizing spans of biomedical concepts and their types (e.g., drug or gene)\nin free text, often called biomedical named entity recognition (NER), is a\nbasic component of information extraction (IE) pipelines. Without a strong NER\ncomponent, other applications, such as knowledge discovery and information\nretrieval, are not practical. State-of-the-art in NER shifted from traditional\nML models to deep neural networks with transformer-based encoder models (e.g.,\nBERT) emerging as the current standard. However, decoder models (also called\nlarge language models or LLMs) are gaining traction in IE. But LLM-driven NER\noften ignores positional information due to the generative nature of decoder\nmodels. Furthermore, they are computationally very expensive (both in inference\ntime and hardware needs). Hence, it is worth exploring if they actually excel\nat biomedical NER and assess any associated trade-offs (performance vs\nefficiency). This is exactly what we do in this effort employing the same BIO\nentity tagging scheme (that retains positional information) using five\ndifferent datasets with varying proportions of longer entities. Our results\nshow that the LLMs chosen (Mistral and Llama: 8B range) often outperform best\nencoder models (BERT-(un)cased, BiomedBERT, and DeBERTav3: 300M range) by 2-8%\nin F-scores except for one dataset, where they equal encoder performance. This\ngain is more prominent among longer entities of length >= 3 tokens. However,\nLLMs are one to two orders of magnitude more expensive at inference time and\nmay need cost prohibitive hardware. Thus, when performance differences are\nsmall or real time user feedback is needed, encoder models might still be more\nsuitable than LLMs.", "published": "2025-04-01 11:16:13", "link": "http://arxiv.org/abs/2504.00664v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DynMoLE: Boosting Mixture of LoRA Experts Fine-Tuning with a Hybrid Routing Mechanism", "abstract": "Instruction-based fine-tuning of large language models (LLMs) has achieved\nremarkable success in various natural language processing (NLP) tasks.\nParameter-efficient fine-tuning (PEFT) methods, such as Mixture of LoRA Experts\n(MoLE), combine the efficiency of Low-Rank Adaptation (LoRA) with the\nversatility of Mixture of Experts (MoE) models, demonstrating significant\npotential for handling multiple downstream tasks. However, the existing routing\nmechanisms for MoLE often involve a trade-off between computational efficiency\nand predictive accuracy, and they fail to fully address the diverse expert\nselection demands across different transformer layers. In this work, we propose\nDynMoLE, a hybrid routing strategy that dynamically adjusts expert selection\nbased on the Tsallis entropy of the router's probability distribution. This\napproach mitigates router uncertainty, enhances stability, and promotes more\nequitable expert participation, leading to faster convergence and improved\nmodel performance. Additionally, we introduce an auxiliary loss based on\nTsallis entropy to further guide the model toward convergence with reduced\nuncertainty, thereby improving training stability and performance. Our\nextensive experiments on commonsense reasoning benchmarks demonstrate that\nDynMoLE achieves substantial performance improvements, outperforming LoRA by\n9.6% and surpassing the state-of-the-art MoLE method, MoLA, by 2.3%. We also\nconduct a comprehensive ablation study to evaluate the contributions of\nDynMoLE's key components.", "published": "2025-04-01 11:14:19", "link": "http://arxiv.org/abs/2504.00661v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "News is More than a Collection of Facts: Moral Frame Preserving News Summarization", "abstract": "News articles are more than collections of facts; they reflect journalists'\nframing, shaping how events are presented to the audience. One key aspect of\nframing is the choice to write in (or quote verbatim) morally charged language\nas opposed to using neutral terms. This moral framing carries implicit\njudgments that automated news summarizers should recognize and preserve to\nmaintain the original intent of the writer. In this work, we perform the first\nstudy on the preservation of moral framing in AI-generated news summaries. We\npropose an approach that leverages the intuition that journalists intentionally\nuse or report specific moral-laden words, which should be retained in\nsummaries. Through automated, crowd-sourced, and expert evaluations, we\ndemonstrate that our approach enhances the preservation of moral framing while\nmaintaining overall summary quality.", "published": "2025-04-01 11:08:24", "link": "http://arxiv.org/abs/2504.00657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Construction of Model Family through Progressive Training Using Model Expansion", "abstract": "As Large Language Models (LLMs) gain widespread practical application,\nproviding the model family of different parameter sizes has become standard\npractice to address diverse computational requirements. Conventionally, each\nmodel in a family is trained independently, resulting in computational costs\nthat scale additively with the number of models. We propose an efficient method\nfor constructing the model family through progressive training, where smaller\nmodels are incrementally expanded to larger sizes to create a complete model\nfamily. Through extensive experiments with a model family ranging from 1B to 8B\nparameters, we demonstrate that our method reduces computational costs by\napproximately 25% while maintaining comparable performance to independently\ntrained models. Furthermore, by strategically adjusting maximum learning rates\nbased on model size, our method outperforms the independent training across\nvarious metrics. Beyond performance gains, our approach offers an additional\nadvantage: models in our family tend to yield more consistent behavior across\ndifferent model sizes.", "published": "2025-04-01 10:21:52", "link": "http://arxiv.org/abs/2504.00623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Consistency of Multilingual Context Utilization in Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) with large language models (LLMs) has\ndemonstrated strong performance in multilingual question-answering (QA) tasks\nby leveraging relevant passages retrieved from corpora. In multilingual RAG\n(mRAG), the retrieved passages can be written in languages other than that of\nthe query entered by the user, making it challenging for LLMs to effectively\nutilize the provided information. Recent research suggests that retrieving\npassages from multilingual corpora can improve RAG performance, particularly\nfor low-resource languages. However, the extent to which LLMs can leverage\ndifferent kinds of multilingual contexts to generate accurate answers,\n*independently from retrieval quality*, remains understudied. In this paper, we\nconduct an extensive assessment of LLMs' ability to (i) make consistent use of\na relevant passage regardless of its language, (ii) respond in the expected\nlanguage, and (iii) focus on the relevant passage even when multiple\n`distracting' passages in different languages are provided in the context. Our\nexperiments with four LLMs across three QA datasets covering a total of 48\nlanguages reveal a surprising ability of LLMs to extract the relevant\ninformation from out-language passages, but a much weaker ability to formulate\na full answer in the correct language. Our analysis, based on both accuracy and\nfeature attribution techniques, further shows that distracting passages\nnegatively impact answer quality regardless of their language. However,\ndistractors in the query language exert a slightly stronger influence. Taken\ntogether, our findings deepen the understanding of how LLMs utilize context in\nmRAG systems, providing directions for future improvements.", "published": "2025-04-01 09:55:23", "link": "http://arxiv.org/abs/2504.00597v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources", "abstract": "The reproduction of state-of-the-art multimodal LLM pre-training faces\nbarriers at every stage of the pipeline, including high-quality data filtering,\nmultimodal data mixture strategies, sequence packing techniques, and training\nframeworks. We introduce Open-Qwen2VL, a fully open-source 2B-parameter\nMultimodal Large Language Model pre-trained efficiently on 29M image-text pairs\nusing only 220 A100-40G GPU hours. Our approach employs low-to-high dynamic\nimage resolution and multimodal sequence packing to significantly enhance\npre-training efficiency. The training dataset was carefully curated using both\nMLLM-based filtering techniques (e.g., MLM-Filter) and conventional CLIP-based\nfiltering methods, substantially improving data quality and training\nefficiency. The Open-Qwen2VL pre-training is conducted on academic level\n8xA100-40G GPUs at UCSB on 5B packed multimodal tokens, which is 0.36% of 1.4T\nmultimodal pre-training tokens of Qwen2-VL. The final instruction-tuned\nOpen-Qwen2VL outperforms partially-open state-of-the-art MLLM Qwen2-VL-2B on\nvarious multimodal benchmarks of MMBench, SEEDBench, MMstar, and MathVista,\nindicating the remarkable training efficiency of Open-Qwen2VL. We open-source\nall aspects of our work, including compute-efficient and data-efficient\ntraining details, data filtering methods, sequence packing scripts,\npre-training data in WebDataset format, FSDP-based training codebase, and both\nbase and instruction-tuned model checkpoints. We redefine \"fully open\" for\nmultimodal LLMs as the complete release of: 1) the training codebase, 2)\ndetailed data filtering techniques, and 3) all pre-training and supervised\nfine-tuning data used to develop the model.", "published": "2025-04-01 09:54:00", "link": "http://arxiv.org/abs/2504.00595v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Annotator Reliability Assessment with EffiARA", "abstract": "Data annotation is an essential component of the machine learning pipeline;\nit is also a costly and time-consuming process. With the introduction of\ntransformer-based models, annotation at the document level is increasingly\npopular; however, there is no standard framework for structuring such tasks.\nThe EffiARA annotation framework is, to our knowledge, the first project to\nsupport the whole annotation pipeline, from understanding the resources\nrequired for an annotation task to compiling the annotated dataset and gaining\ninsights into the reliability of individual annotators as well as the dataset\nas a whole. The framework's efficacy is supported by two previous studies: one\nimproving classification performance through annotator-reliability-based soft\nlabel aggregation and sample weighting, and the other increasing the overall\nagreement among annotators through removing identifying and replacing an\nunreliable annotator. This work introduces the EffiARA Python package and its\naccompanying webtool, which provides an accessible graphical user interface for\nthe system. We open-source the EffiARA Python package at\nhttps://github.com/MiniEggz/EffiARA and the webtool is publicly accessible at\nhttps://effiara.gate.ac.uk.", "published": "2025-04-01 09:48:09", "link": "http://arxiv.org/abs/2504.00589v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems", "abstract": "The rapid advancement of Large Language Models (LLMs) has catalyzed the\ndevelopment of multi-agent systems, where multiple LLM-based agents collaborate\nto solve complex tasks. However, existing systems predominantly rely on\ncentralized coordination, which introduces scalability bottlenecks, limits\nadaptability, and creates single points of failure. Additionally, concerns over\nprivacy and proprietary knowledge sharing hinder cross-organizational\ncollaboration, leading to siloed expertise. To address these challenges, we\npropose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based\nframework that enables LLM-based agents to autonomously evolve their\ncapabilities and collaborate efficiently in a Directed Acyclic Graph\n(DAG)-structured network. Unlike traditional multi-agent systems that depend on\nstatic role assignments or centralized control, AgentNet allows agents to\nspecialize dynamically, adjust their connectivity, and route tasks without\nrelying on predefined workflows. AgentNet's core design is built upon several\nkey innovations: (1) Fully Decentralized Paradigm: Removing the central\norchestrator, allowing agents to coordinate and specialize autonomously,\nfostering fault tolerance and emergent collective intelligence. (2) Dynamically\nEvolving Graph Topology: Real-time adaptation of agent connections based on\ntask demands, ensuring scalability and resilience.(3) Adaptive Learning for\nExpertise Refinement: A retrieval-based memory system that enables agents to\ncontinuously update and refine their specialized skills. By eliminating\ncentralized control, AgentNet enhances fault tolerance, promotes scalable\nspecialization, and enables privacy-preserving collaboration across\norganizations. Through decentralized coordination and minimal data exchange,\nagents can leverage diverse knowledge sources while safeguarding sensitive\ninformation.", "published": "2025-04-01 09:45:25", "link": "http://arxiv.org/abs/2504.00587v1", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Enhancing Negation Awareness in Universal Text Embeddings: A Data-efficient and Computational-efficient Approach", "abstract": "Negation plays an important role in various natural language processing tasks\nsuch as Natural Language Inference and Sentiment Analysis tasks. Numerous prior\nstudies have found that contextual text embedding models such as BERT, ELMO,\nRoBERTa or XLNet face challenges in accurately understanding negation. Recent\nadvancements in universal text embeddings have demonstrated superior\nperformance over contextual text embeddings in various tasks. However, due to\nthe bias in popular evaluation benchmarks, the negation awareness capacity of\nthese models remains unclear. To bridge the gap in existing literature, an\nin-depth analysis is initiated in this work to study the negation awareness of\ncutting-edge universal text embedding models. Our findings reveal a significant\nlack of negation awareness in these models, often interpreting negated text\npairs as semantically similar. To efficiently deal with the conflict that\ndifferent tasks need different trade-offs between topic and negation\ninformation among other semantic information, a data-efficient and\ncomputational-efficient embedding re-weighting method is proposed without\nmodifying the parameters of text embedding models. The proposed solution is\nable to improve text embedding models' negation awareness significantly on both\nsimple negation understanding task and complex negation understanding task.\nFurthermore, the proposed solution can also significantly improve the negation\nawareness of Large Language Model based task-specific high dimensional\nuniversal text embeddings.", "published": "2025-04-01 09:39:57", "link": "http://arxiv.org/abs/2504.00584v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Agent LLM Judge: automatic personalized LLM judge design for evaluating natural language generation applications", "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\ndiverse domains, yet they still encounter challenges such as insufficient\ndomain-specific knowledge, biases, and hallucinations. This underscores the\nneed for robust evaluation methodologies to accurately assess LLM-based\napplications. Traditional evaluation methods, which rely on word overlap or\ntext embeddings, are inadequate for capturing the nuanced semantic information\nnecessary to evaluate dynamic, open-ended text generation. Recent research has\nexplored leveraging LLMs to mimic human reasoning and decision-making processes\nfor evaluation purposes known as LLM-as-a-judge framework. However, these\nexisting frameworks have two significant limitations. First, they lack the\nflexibility to adapt to different text styles, including various answer and\nground truth styles, thereby reducing their generalization performance. Second,\nthe evaluation scores produced by these frameworks are often skewed and hard to\ninterpret, showing a low correlation with human judgment. To address these\nchallenges, we propose a novel dynamic multi-agent system that automatically\ndesigns personalized LLM judges for various natural language generation\napplications. This system iteratively refines evaluation prompts and balances\nthe trade-off between the adaptive requirements of downstream tasks and the\nalignment with human perception. Our experimental results show that the\nproposed multi-agent LLM Judge framework not only enhances evaluation accuracy\ncompared to existing methods but also produces evaluation scores that better\nalign with human perception.", "published": "2025-04-01 09:36:56", "link": "http://arxiv.org/abs/2504.02867v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training a Utility-based Retriever Through Shared Context Attribution for Retrieval-Augmented Language Models", "abstract": "Retrieval-Augmented Language Models boost task performance, owing to the\nretriever that provides external knowledge. Although crucial, the retriever\nprimarily focuses on semantics relevance, which may not always be effective for\ngeneration. Thus, utility-based retrieval has emerged as a promising topic,\nprioritizing passages that provides valid benefits for downstream tasks.\nHowever, due to insufficient understanding, capturing passage utility\naccurately remains unexplored. This work proposes SCARLet, a framework for\ntraining utility-based retrievers in RALMs, which incorporates two key factors,\nmulti-task generalization and inter-passage interaction. First, SCARLet\nconstructs shared context on which training data for various tasks is\nsynthesized. This mitigates semantic bias from context differences, allowing\nretrievers to focus on learning task-specific utility for better task\ngeneralization. Next, SCARLet uses a perturbation-based attribution method to\nestimate passage-level utility for shared context, which reflects interactions\nbetween passages and provides more accurate feedback. We evaluate our approach\non ten datasets across various tasks, both in-domain and out-of-domain, showing\nthat retrievers trained by SCARLet consistently improve the overall performance\nof RALMs.", "published": "2025-04-01 09:28:28", "link": "http://arxiv.org/abs/2504.00573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SRLCG: Self-Rectified Large-Scale Code Generation with Multidimensional Chain-of-Thought and Dynamic Backtracking", "abstract": "Large language models (LLMs) have revolutionized code generation,\nsignificantly enhancing developer productivity. However, for a vast number of\nusers with minimal coding knowledge, LLMs provide little support, as they\nprimarily generate isolated code snippets rather than complete, large-scale\nproject code. Without coding expertise, these users struggle to interpret,\nmodify, and iteratively refine the outputs of LLMs, making it impossible to\nassemble a complete project. To address this issue, we propose Self-Rectified\nLarge-Scale Code Generator (SRLCG), a framework that generates complete\nmulti-file project code from a single prompt. SRLCG employs a novel\nmultidimensional chain-of-thought (CoT) and self-rectification to guide LLMs in\ngenerating correct and robust code files, then integrates them into a complete\nand coherent project using our proposed dynamic backtracking algorithm.\nExperimental results show that SRLCG generates code 15x longer than\nDeepSeek-V3, 16x longer than GPT-4, and at least 10x longer than other leading\nCoT-based baselines. Furthermore, they confirm its improved correctness,\nrobustness, and performance compared to baselines in large-scale code\ngeneration.", "published": "2025-04-01 08:23:43", "link": "http://arxiv.org/abs/2504.00532v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?", "abstract": "The rapid escalation from elementary school-level to frontier problems of the\ndifficulty for LLM benchmarks in recent years have weaved a miracle for\nresearchers that we are only inches away from surpassing human intelligence.\nHowever, is the LLMs' remarkable reasoning ability indeed comes from true\nintelligence by human standards, or are they simply reciting solutions\nwitnessed during training at an Internet level? To study this problem, we\npropose RoR-Bench, a novel, multi-modal benchmark for detecting LLM's\nrecitation behavior when asked simple reasoning problems but with conditions\nsubtly shifted, and conduct empirical analysis on our benchmark. Surprisingly,\nwe found existing cutting-edge LLMs unanimously exhibits extremely severe\nrecitation behavior; by changing one phrase in the condition, top models such\nas OpenAI-o1 and DeepSeek-R1 can suffer $60\\%$ performance loss on elementary\nschool-level arithmetic and reasoning problems. Such findings are a wake-up\ncall to the LLM community that compels us to re-evaluate the true intelligence\nlevel of cutting-edge LLMs.", "published": "2025-04-01 07:57:58", "link": "http://arxiv.org/abs/2504.00509v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ShortV: Efficient Multimodal Large Language Models by Freezing Visual Tokens in Ineffective Layers", "abstract": "Multimodal Large Language Models (MLLMs) suffer from high computational costs\ndue to their massive size and the large number of visual tokens. In this paper,\nwe investigate layer-wise redundancy in MLLMs by introducing a novel metric,\nLayer Contribution (LC), which quantifies the impact of a layer's\ntransformations on visual and text tokens, respectively. The calculation of LC\ninvolves measuring the divergence in model output that results from removing\nthe layer's transformations on the specified tokens. Our pilot experiment\nreveals that many layers of MLLMs exhibit minimal contribution during the\nprocessing of visual tokens. Motivated by this observation, we propose ShortV,\na training-free method that leverages LC to identify ineffective layers, and\nfreezes visual token updates in these layers. Experiments show that ShortV can\nfreeze visual token in approximately 60\\% of the MLLM layers, thereby\ndramatically reducing computational costs related to updating visual tokens.\nFor example, it achieves a 50\\% reduction in FLOPs on LLaVA-NeXT-13B while\nmaintaining superior performance. The code will be publicly available at\nhttps://github.com/icip-cas/ShortV", "published": "2025-04-01 07:47:55", "link": "http://arxiv.org/abs/2504.00502v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "FortisAVQA and MAVEN: a Benchmark Dataset and Debiasing Framework for Robust Multimodal Reasoning", "abstract": "Audio-Visual Question Answering (AVQA) is a challenging multimodal reasoning\ntask requiring intelligent systems to answer natural language queries based on\npaired audio-video inputs accurately. However, existing AVQA approaches often\nsuffer from overfitting to dataset biases, leading to poor robustness.\nMoreover, current datasets may not effectively diagnose these methods. To\naddress these challenges, we first introduce a novel dataset, FortisAVQA,\nconstructed in two stages: (1) rephrasing questions in the test split of the\npublic MUSIC-AVQA dataset and (2) introducing distribution shifts across\nquestions. The first stage expands the test space with greater diversity, while\nthe second enables a refined robustness evaluation across rare, frequent, and\noverall question distributions. Second, we introduce a robust Multimodal\nAudio-Visual Epistemic Network (MAVEN) that leverages a multifaceted cycle\ncollaborative debiasing strategy to mitigate bias learning. Experimental\nresults demonstrate that our architecture achieves state-of-the-art performance\non FortisAVQA, with a notable improvement of 7.81\\%. Extensive ablation studies\non both datasets validate the effectiveness of our debiasing components.\nAdditionally, our evaluation reveals the limited robustness of existing\nmultimodal QA methods. We also verify the plug-and-play capability of our\nstrategy by integrating it with various baseline models across both datasets.\nOur dataset and code are available at https://github.com/reml-group/fortisavqa.", "published": "2025-04-01 07:23:50", "link": "http://arxiv.org/abs/2504.00487v2", "categories": ["cs.MM", "cs.CL", "cs.CV", "H.5.1; I.2.4"], "primary_category": "cs.MM"}
{"title": "The Illusionist's Prompt: Exposing the Factual Vulnerabilities of Large Language Models with Linguistic Nuances", "abstract": "As Large Language Models (LLMs) continue to advance, they are increasingly\nrelied upon as real-time sources of information by non-expert users. To ensure\nthe factuality of the information they provide, much research has focused on\nmitigating hallucinations in LLM responses, but only in the context of formal\nuser queries, rather than maliciously crafted ones. In this study, we introduce\nThe Illusionist's Prompt, a novel hallucination attack that incorporates\nlinguistic nuances into adversarial queries, challenging the factual accuracy\nof LLMs against five types of fact-enhancing strategies. Our attack\nautomatically generates highly transferrable illusory prompts to induce\ninternal factual errors, all while preserving user intent and semantics.\nExtensive experiments confirm the effectiveness of our attack in compromising\nblack-box LLMs, including commercial APIs like GPT-4o and Gemini-2.0, even with\nvarious defensive mechanisms.", "published": "2025-04-01 07:10:00", "link": "http://arxiv.org/abs/2504.02865v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences", "abstract": "Large language models (LLMs) can perform complex reasoning by generating\nintermediate thoughts under zero-shot or few-shot settings. However, zero-shot\nprompting always encounters low performance, and the superior performance of\nfew-shot prompting hinges on the manual-crafted demonstrations. In this paper,\nwe present RoSE (Reasoning with Orchestrated Streaming Experiences), a general\nframework for solving reasoning tasks that can self-improve without complex\nexternal efforts. To enable RoSE, we describe an architecture that extends an\nLLM to store all answered questions and their thoughts in a streaming\nexperience pool then orchestrates helpful questions from the pool to assist in\nanswering new questions. To set up a question-aware orchestration mechanism,\nRoSE first calculates the similarity of each question in the pool with a new\ntest question. Since the solution to each answered question is not always\ncorrect, RoSE will sort the questions according to their similarity with the\nnew question, and then uniformly divide them into multiple buckets. It finally\nextracts one question from each bucket to make these extracted questions more\ndiverse. To make these extracted questions help RoSE answer new questions as\nmuch as possible, we introduce two other attributes of uncertainty and\ncomplexity for each question. RoSE will preferentially select the questions\nwith low uncertainty and high complexity from each bucket. We evaluate the\nversatility of RoSE in various reasoning tasks, LLMs, and CoT methods.", "published": "2025-04-01 07:04:04", "link": "http://arxiv.org/abs/2504.00473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning", "abstract": "Although large language models (LLMs) excel in knowledge recall and\nreasoning, their static nature leads to outdated information as the real world\nevolves or when adapting to domain-specific knowledge, highlighting the need\nfor effective knowledge injection. However, current research on knowledge\ninjection remains superficial, mainly focusing on knowledge memorization and\nretrieval. This paper proposes a four-tier knowledge injection framework that\nsystematically defines the levels of knowledge injection: memorization,\nretrieval, reasoning, and association. Based on this framework, we introduce\nDeepKnowledge, a synthetic experimental testbed designed for fine-grained\nevaluation of the depth of knowledge injection across three knowledge types\n(novel, incremental, and updated). We then explore various knowledge injection\nscenarios and evaluate the depth of knowledge injection for each scenario on\nthe benchmark. Experimental results reveal key factors to reach each level of\nknowledge injection for LLMs and establish a mapping between the levels of\nknowledge injection and the corresponding suitable injection methods, aiming to\nprovide a comprehensive approach for efficient knowledge injection across\nvarious levels.", "published": "2025-04-01 06:59:59", "link": "http://arxiv.org/abs/2504.00472v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal LLMs for OCR, OCR Post-Correction, and Named Entity Recognition in Historical Documents", "abstract": "We explore how multimodal Large Language Models (mLLMs) can help researchers\ntranscribe historical documents, extract relevant historical information, and\nconstruct datasets from historical sources. Specifically, we investigate the\ncapabilities of mLLMs in performing (1) Optical Character Recognition (OCR),\n(2) OCR Post-Correction, and (3) Named Entity Recognition (NER) tasks on a set\nof city directories published in German between 1754 and 1870. First, we\nbenchmark the off-the-shelf transcription accuracy of both mLLMs and\nconventional OCR models. We find that the best-performing mLLM model\nsignificantly outperforms conventional state-of-the-art OCR models and other\nfrontier mLLMs. Second, we are the first to introduce multimodal\npost-correction of OCR output using mLLMs. We find that this novel approach\nleads to a drastic improvement in transcription accuracy and consistently\nproduces highly accurate transcriptions (<1% CER), without any image\npre-processing or model fine-tuning. Third, we demonstrate that mLLMs can\nefficiently recognize entities in transcriptions of historical documents and\nparse them into structured dataset formats. Our findings provide early evidence\nfor the long-term potential of mLLMs to introduce a paradigm shift in the\napproaches to historical data collection and document transcription.", "published": "2025-04-01 04:21:34", "link": "http://arxiv.org/abs/2504.00414v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Semantic Mastery: Enhancing LLMs with Advanced Natural Language Understanding", "abstract": "Large language models (LLMs) have greatly improved their capability in\nperforming NLP tasks. However, deeper semantic understanding, contextual\ncoherence, and more subtle reasoning are still difficult to obtain. The paper\ndiscusses state-of-the-art methodologies that advance LLMs with more advanced\nNLU techniques, such as semantic parsing, knowledge integration, and contextual\nreinforcement learning. We analyze the use of structured knowledge graphs,\nretrieval-augmented generation (RAG), and fine-tuning strategies that match\nmodels with human-level understanding. Furthermore, we address the\nincorporation of transformer-based architectures, contrastive learning, and\nhybrid symbolic-neural methods that address problems like hallucinations,\nambiguity, and inconsistency in the factual perspectives involved in performing\ncomplex NLP tasks, such as question-answering text summarization and dialogue\ngeneration. Our findings show the importance of semantic precision for\nenhancing AI-driven language systems and suggest future research directions to\nbridge the gap between statistical language models and true natural language\nunderstanding.", "published": "2025-04-01 04:12:04", "link": "http://arxiv.org/abs/2504.00409v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VerifiAgent: a Unified Verification Agent in Language Model Reasoning", "abstract": "Large language models demonstrate remarkable reasoning capabilities but often\nproduce unreliable or incorrect responses. Existing verification methods are\ntypically model-specific or domain-restricted, requiring significant\ncomputational resources and lacking scalability across diverse reasoning tasks.\nTo address these limitations, we propose VerifiAgent, a unified verification\nagent that integrates two levels of verification: meta-verification, which\nassesses completeness and consistency in model responses, and tool-based\nadaptive verification, where VerifiAgent autonomously selects appropriate\nverification tools based on the reasoning type, including mathematical,\nlogical, or commonsense reasoning. This adaptive approach ensures both\nefficiency and robustness across different verification scenarios. Experimental\nresults show that VerifiAgent outperforms baseline verification methods (e.g.,\ndeductive verifier, backward verifier) among all reasoning tasks. Additionally,\nit can further enhance reasoning accuracy by leveraging feedback from\nverification results. VerifiAgent can also be effectively applied to inference\nscaling, achieving better results with fewer generated samples and costs\ncompared to existing process reward models in the mathematical reasoning\ndomain. Code is available at https://github.com/Jiuzhouh/VerifiAgent", "published": "2025-04-01 04:05:03", "link": "http://arxiv.org/abs/2504.00406v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Misaligned Roles, Misplaced Images: Structural Input Perturbations Expose Multimodal Alignment Blind Spots", "abstract": "Multimodal Language Models (MMLMs) typically undergo post-training alignment\nto prevent harmful content generation. However, these alignment stages focus\nprimarily on the assistant role, leaving the user role unaligned, and stick to\na fixed input prompt structure of special tokens, leaving the model vulnerable\nwhen inputs deviate from these expectations. We introduce Role-Modality Attacks\n(RMA), a novel class of adversarial attacks that exploit role confusion between\nthe user and assistant and alter the position of the image token to elicit\nharmful outputs. Unlike existing attacks that modify query content, RMAs\nmanipulate the input structure without altering the query itself. We\nsystematically evaluate these attacks across multiple Vision Language Models\n(VLMs) on eight distinct settings, showing that they can be composed to create\nstronger adversarial prompts, as also evidenced by their increased projection\nin the negative refusal direction in the residual stream, a property observed\nin prior successful attacks. Finally, for mitigation, we propose an adversarial\ntraining approach that makes the model robust against input prompt\nperturbations. By training the model on a range of harmful and benign prompts\nall perturbed with different RMA settings, it loses its sensitivity to Role\nConfusion and Modality Manipulation attacks and is trained to only pay\nattention to the content of the query in the input prompt structure,\neffectively reducing Attack Success Rate (ASR) while preserving the model's\ngeneral utility.", "published": "2025-04-01 03:54:36", "link": "http://arxiv.org/abs/2504.03735v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CR"}
{"title": "When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)", "abstract": "In many real-world scenarios, a single Large Language Model (LLM) may\nencounter contradictory claims-some accurate, others forcefully incorrect-and\nmust judge which is true. We investigate this risk in a single-turn,\nmulti-agent debate framework: one LLM-based agent provides a factual answer\nfrom TruthfulQA, another vigorously defends a falsehood, and the same LLM\narchitecture serves as judge. We introduce the Confidence-Weighted Persuasion\nOverride Rate (CW-POR), which captures not only how often the judge is deceived\nbut also how strongly it believes the incorrect choice. Our experiments on five\nopen-source LLMs (3B-14B parameters), where we systematically vary agent\nverbosity (30-300 words), reveal that even smaller models can craft persuasive\narguments that override truthful answers-often with high confidence. These\nfindings underscore the importance of robust calibration and adversarial\ntesting to prevent LLMs from confidently endorsing misinformation.", "published": "2025-04-01 02:45:02", "link": "http://arxiv.org/abs/2504.00374v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Automated Definition Extraction with TaxoMatic A Case Study on Media Bias", "abstract": "This paper introduces TaxoMatic, a framework that leverages large language\nmodels to automate definition extraction from academic literature. Focusing on\nthe media bias domain, the framework encompasses data collection, LLM-based\nrelevance classification, and extraction of conceptual definitions. Evaluated\non a dataset of 2,398 manually rated articles, the study demonstrates the\nframeworks effectiveness, with Claude-3-sonnet achieving the best results in\nboth relevance classification and definition extraction. Future directions\ninclude expanding datasets and applying TaxoMatic to additional domains.", "published": "2025-04-01 01:47:16", "link": "http://arxiv.org/abs/2504.00343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VNJPTranslate: A comprehensive pipeline for Vietnamese-Japanese translation", "abstract": "Neural Machine Translation (NMT) driven by Transformer architectures has\nadvanced significantly, yet faces challenges with low-resource language pairs\nlike Vietnamese-Japanese (Vi-Ja). Issues include sparse parallel data and\nhandling linguistic/cultural nuances. Recent progress in Large Language Models\n(LLMs) with strong reasoning, often refined via Reinforcement Learning (RL),\nenables high-quality synthetic data generation. We introduce VNJPTranslate, a\npipeline designed to systematically address the Vi-Ja translation task. It\nfeatures a targeted data augmentation strategy using advanced LLMs with\nChain-of-Thought prompting for challenging segments identified via corpus\nanalysis. Subsequently, we employ efficient fine-tuning techniques (Unsloth\nwith QLoRA) on a capable, low-parameter autoregressive model (specifically, a\nfine-tuned version of the 1.8B parameter Sailor model, which is based on the\nQwen architecture) to create a practical and high-performing translation\nsystem. This integrated approach aims to improve Vi-Ja translation quality\nsignificantly over existing baselines.", "published": "2025-04-01 01:38:25", "link": "http://arxiv.org/abs/2504.00339v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Effect-driven interpretation: Functors for natural language composition", "abstract": "Computer programs are often factored into pure components -- simple, total\nfunctions from inputs to outputs -- and components that may have side effects\n-- errors, changes to memory, parallel threads, abortion of the current loop,\netc. We make the case that human languages are similarly organized around the\ngive and pull of pure values and impure processes, and we'll aim to show how\ndenotational techniques from computer science can be leveraged to support\nelegant and illuminating analyses of natural language composition.", "published": "2025-04-01 00:46:01", "link": "http://arxiv.org/abs/2504.00316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting and Mitigating Bias in LLMs through Knowledge Graph-Augmented Training", "abstract": "Large language models have revolutionized natural language processing with\ntheir surprising capability to understand and generate human-like text.\nHowever, many of these models inherit and further amplify the biases present in\ntheir training data, raising ethical and fairness concerns. The detection and\nmitigation of such biases are vital to ensuring that LLMs act responsibly and\nequitably across diverse domains. This work investigates Knowledge\nGraph-Augmented Training (KGAT) as a novel method to mitigate bias in LLM.\nUsing structured domain-specific knowledge from real-world knowledge graphs, we\nimprove the understanding of the model and reduce biased output. Public\ndatasets for bias assessment include Gender Shades, Bias in Bios, and FairFace,\nwhile metrics such as demographic parity and equal opportunity facilitate\nrigorous detection. We also performed targeted mitigation strategies to correct\nbiased associations, leading to a significant drop in biased output and\nimproved bias metrics. Equipped with real-world datasets and knowledge graphs,\nour framework is both scalable and effective, paving the way toward responsible\ndeployment in sensitive and high-stakes applications.", "published": "2025-04-01 00:27:50", "link": "http://arxiv.org/abs/2504.00310v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Material Contracts Corpus", "abstract": "This paper introduces the Material Contracts Corpus (MCC), a publicly\navailable dataset comprising over one million contracts filed by public\ncompanies with the U.S. Securities and Exchange Commission (SEC) between 2000\nand 2023. The MCC facilitates empirical research on contract design and legal\nlanguage, and supports the development of AI-based legal tools. Contracts in\nthe corpus are categorized by agreement type and linked to specific parties\nusing machine learning and natural language processing techniques, including a\nfine-tuned LLaMA-2 model for contract classification. The MCC further provides\nmetadata such as filing form, document format, and amendment status. We\ndocument trends in contractual language, length, and complexity over time, and\nhighlight the dominance of employment and security agreements in SEC filings.\nThis resource is available for bulk download and online access at\nhttps://mcc.law.stanford.edu.", "published": "2025-04-01 00:06:04", "link": "http://arxiv.org/abs/2504.02864v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GS_DravidianLangTech@2025: Women Targeted Abusive Texts Detection on Social Media", "abstract": "The increasing misuse of social media has become a concern; however,\ntechnological solutions are being developed to moderate its content\neffectively. This paper focuses on detecting abusive texts targeting women on\nsocial media platforms. Abusive speech refers to communication intended to harm\nor incite hatred against vulnerable individuals or groups. Specifically, this\nstudy aims to identify abusive language directed toward women. To achieve this,\nwe utilized logistic regression and BERT as base models to train datasets\nsourced from DravidianLangTech@2025 for Tamil and Malayalam languages. The\nmodels were evaluated on test datasets, resulting in a 0.729 macro F1 score for\nBERT and 0.6279 for logistic regression in Tamil and Malayalam, respectively.", "published": "2025-04-01 00:00:07", "link": "http://arxiv.org/abs/2504.02863v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Plan-and-Act using Large Language Models for Interactive Agreement", "abstract": "Recent large language models (LLMs) are capable of planning robot actions. In\nthis paper, we explore how LLMs can be used for planning actions with tasks\ninvolving situational human-robot interaction (HRI). A key problem of applying\nLLMs in situational HRI is balancing between \"respecting the current human's\nactivity\" and \"prioritizing the robot's task,\" as well as understanding the\ntiming of when to use the LLM to generate an action plan. In this paper, we\npropose a necessary plan-and-act skill design to solve the above problems. We\nshow that a critical factor for enabling a robot to switch between passive /\nactive interaction behavior is to provide the LLM with an action text about the\ncurrent robot's action. We also show that a second-stage question to the LLM\n(about the next timing to call the LLM) is necessary for planning actions at an\nappropriate timing. The skill design is applied to an Engage skill and is\ntested on four distinct interaction scenarios. We show that by using the skill\ndesign, LLMs can be leveraged to easily scale to different HRI scenarios with a\nreasonable success rate reaching 90% on the test scenarios.", "published": "2025-04-01 23:41:05", "link": "http://arxiv.org/abs/2504.01252v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Dynamic Graph Structure Estimation for Learning Multivariate Point Process using Spiking Neural Networks", "abstract": "Modeling and predicting temporal point processes (TPPs) is critical in\ndomains such as neuroscience, epidemiology, finance, and social sciences. We\nintroduce the Spiking Dynamic Graph Network (SDGN), a novel framework that\nleverages the temporal processing capabilities of spiking neural networks\n(SNNs) and spike-timing-dependent plasticity (STDP) to dynamically estimate\nunderlying spatio-temporal functional graphs. Unlike existing methods that rely\non predefined or static graph structures, SDGN adapts to any dataset by\nlearning dynamic spatio-temporal dependencies directly from the event data,\nenhancing generalizability and robustness. While SDGN offers significant\nimprovements over prior methods, we acknowledge its limitations in handling\ndense graphs and certain non-Gaussian dependencies, providing opportunities for\nfuture refinement. Our evaluations, conducted on both synthetic and real-world\ndatasets including NYC Taxi, 911, Reddit, and Stack Overflow, demonstrate that\nSDGN achieves superior predictive accuracy while maintaining computational\nefficiency. Furthermore, we include ablation studies to highlight the\ncontributions of its core components.", "published": "2025-04-01 23:23:10", "link": "http://arxiv.org/abs/2504.01246v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FUSION: Frequency-guided Underwater Spatial Image recOnstructioN", "abstract": "Underwater images suffer from severe degradations, including color\ndistortions, reduced visibility, and loss of structural details due to\nwavelength-dependent attenuation and scattering. Existing enhancement methods\nprimarily focus on spatial-domain processing, neglecting the frequency domain's\npotential to capture global color distributions and long-range dependencies. To\naddress these limitations, we propose FUSION, a dual-domain deep learning\nframework that jointly leverages spatial and frequency domain information.\nFUSION independently processes each RGB channel through multi-scale\nconvolutional kernels and adaptive attention mechanisms in the spatial domain,\nwhile simultaneously extracting global structural information via FFT-based\nfrequency attention. A Frequency Guided Fusion module integrates complementary\nfeatures from both domains, followed by inter-channel fusion and adaptive\nchannel recalibration to ensure balanced color distributions. Extensive\nexperiments on benchmark datasets (UIEB, EUVP, SUIM-E) demonstrate that FUSION\nachieves state-of-the-art performance, consistently outperforming existing\nmethods in reconstruction fidelity (highest PSNR of 23.717 dB and SSIM of 0.883\non UIEB), perceptual quality (lowest LPIPS of 0.112 on UIEB), and visual\nenhancement metrics (best UIQM of 3.414 on UIEB), while requiring significantly\nfewer parameters (0.28M) and lower computational complexity, demonstrating its\nsuitability for real-time underwater imaging applications.", "published": "2025-04-01 23:16:19", "link": "http://arxiv.org/abs/2504.01243v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "TenAd: A Tensor-based Low-rank Black Box Adversarial Attack for Video Classification", "abstract": "Deep learning models have achieved remarkable success in computer vision but\nremain vulnerable to adversarial attacks, particularly in black-box settings\nwhere model details are unknown. Existing adversarial attack methods(even those\nworks with key frames) often treat video data as simple vectors, ignoring their\ninherent multi-dimensional structure, and require a large number of queries,\nmaking them inefficient and detectable. In this paper, we propose\n\\textbf{TenAd}, a novel tensor-based low-rank adversarial attack that leverages\nthe multi-dimensional properties of video data by representing videos as\nfourth-order tensors. By exploiting low-rank attack, our method significantly\nreduces the search space and the number of queries needed to generate\nadversarial examples in black-box settings. Experimental results on standard\nvideo classification datasets demonstrate that \\textbf{TenAd} effectively\ngenerates imperceptible adversarial perturbations while achieving higher attack\nsuccess rates and query efficiency compared to state-of-the-art methods. Our\napproach outperforms existing black-box adversarial attacks in terms of success\nrate, query efficiency, and perturbation imperceptibility, highlighting the\npotential of tensor-based methods for adversarial attacks on video models.", "published": "2025-04-01 22:35:28", "link": "http://arxiv.org/abs/2504.01228v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PolygoNet: Leveraging Simplified Polygonal Representation for Effective Image Classification", "abstract": "Deep learning models have achieved significant success in various image\nrelated tasks. However, they often encounter challenges related to\ncomputational complexity and overfitting. In this paper, we propose an\nefficient approach that leverages polygonal representations of images using\ndominant points or contour coordinates. By transforming input images into these\ncompact forms, our method significantly reduces computational requirements,\naccelerates training, and conserves resources making it suitable for real time\nand resource constrained applications. These representations inherently capture\nessential image features while filtering noise, providing a natural\nregularization effect that mitigates overfitting. The resulting lightweight\nmodels achieve performance comparable to state of the art methods using full\nresolution images while enabling deployment on edge devices. Extensive\nexperiments on benchmark datasets validate the effectiveness of our approach in\nreducing complexity, improving generalization, and facilitating edge computing\napplications. This work demonstrates the potential of polygonal representations\nin advancing efficient and scalable deep learning solutions for real world\nscenarios. The code for the experiments of the paper is provided in\nhttps://github.com/salimkhazem/PolygoNet.", "published": "2025-04-01 22:05:00", "link": "http://arxiv.org/abs/2504.01214v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding", "abstract": "In this paper, we expand the Bayesian persuasion framework to account for\nunobserved confounding variables in sender-receiver interactions. While\ntraditional models assume that belief updates follow Bayesian principles,\nreal-world scenarios often involve hidden variables that impact the receiver's\nbelief formation and decision-making. We conceptualize this as a sequential\ndecision-making problem, where the sender and receiver interact over multiple\nrounds. In each round, the sender communicates with the receiver, who also\ninteracts with the environment. Crucially, the receiver's belief update is\naffected by an unobserved confounding variable. By reformulating this scenario\nas a Partially Observable Markov Decision Process (POMDP), we capture the\nsender's incomplete information regarding both the dynamics of the receiver's\nbeliefs and the unobserved confounder. We prove that finding an optimal\nobservation-based policy in this POMDP is equivalent to solving for an optimal\nsignaling strategy in the original persuasion framework. Furthermore, we\ndemonstrate how this reformulation facilitates the application of proximal\nlearning for off-policy evaluation in the persuasion process. This advancement\nenables the sender to evaluate alternative signaling strategies using only\nobservational data from a behavioral policy, thus eliminating the necessity for\ncostly new experiments.", "published": "2025-04-01 21:50:32", "link": "http://arxiv.org/abs/2504.01211v1", "categories": ["cs.AI", "cs.GT", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Lightweight Deep Models for Dermatological Disease Detection: A Study on Instance Selection and Channel Optimization", "abstract": "The identification of dermatological disease is an important problem in\nMexico according with different studies. Several works in literature use the\ndatasets of different repositories without applying a study of the data\nbehavior, especially in medical images domain. In this work, we propose a\nmethodology to preprocess dermaMNIST dataset in order to improve its quality\nfor the classification stage, where we use lightweight convolutional neural\nnetworks. In our results, we reduce the number of instances for the neural\nnetwork training obtaining a similar performance of models as ResNet.", "published": "2025-04-01 21:47:57", "link": "http://arxiv.org/abs/2504.01208v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Neural Approaches to SAT Solving: Design Choices and Interpretability", "abstract": "In this contribution, we provide a comprehensive evaluation of graph neural\nnetworks applied to Boolean satisfiability problems, accompanied by an\nintuitive explanation of the mechanisms enabling the model to generalize to\ndifferent instances. We introduce several training improvements, particularly a\nnovel closest assignment supervision method that dynamically adapts to the\nmodel's current state, significantly enhancing performance on problems with\nlarger solution spaces. Our experiments demonstrate the suitability of\nvariable-clause graph representations with recurrent neural network updates,\nwhich achieve good accuracy on SAT assignment prediction while reducing\ncomputational demands. We extend the base graph neural network into a diffusion\nmodel that facilitates incremental sampling and can be effectively combined\nwith classical techniques like unit propagation. Through analysis of embedding\nspace patterns and optimization trajectories, we show how these networks\nimplicitly perform a process very similar to continuous relaxations of MaxSAT,\noffering an interpretable view of their reasoning process. This understanding\nguides our design choices and explains the ability of recurrent architectures\nto scale effectively at inference time beyond their training distribution,\nwhich we demonstrate with test-time scaling experiments.", "published": "2025-04-01 20:31:01", "link": "http://arxiv.org/abs/2504.01173v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Remember, but also, Forget: Bridging Myopic and Perfect Recall Fairness with Past-Discounting", "abstract": "Dynamic resource allocation in multi-agent settings often requires balancing\nefficiency with fairness over time--a challenge inadequately addressed by\nconventional, myopic fairness measures. Motivated by behavioral insights that\nhuman judgments of fairness evolve with temporal distance, we introduce a novel\nframework for temporal fairness that incorporates past-discounting mechanisms.\nBy applying a tunable discount factor to historical utilities, our approach\ninterpolates between instantaneous and perfect-recall fairness, thereby\ncapturing both immediate outcomes and long-term equity considerations. Beyond\naligning more closely with human perceptions of fairness, this past-discounting\nmethod ensures that the augmented state space remains bounded, significantly\nimproving computational tractability in sequential decision-making settings. We\ndetail the formulation of discounted-recall fairness in both additive and\naveraged utility contexts, illustrate its benefits through practical examples,\nand discuss its implications for designing balanced, scalable resource\nallocation strategies.", "published": "2025-04-01 19:42:17", "link": "http://arxiv.org/abs/2504.01154v1", "categories": ["cs.AI", "cs.GT", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations", "abstract": "While we increasingly rely on large language models (LLMs) for various tasks,\nthese models are known to produce inaccurate content or 'hallucinations' with\npotentially disastrous consequences. The recent integration of web search\nresults into LLMs prompts the question of whether people utilize them to verify\nthe generated content, thereby avoiding falling victim to hallucinations. This\nstudy (N = 560) investigated how the provision of search results, either static\n(fixed search results) or dynamic (participant-driven searches), affect\nparticipants' perceived accuracy and confidence in evaluating LLM-generated\ncontent (i.e., genuine, minor hallucination, major hallucination), compared to\nthe control condition (no search results). Findings indicate that participants\nin both static and dynamic conditions (vs. control) rated hallucinated content\nto be less accurate. However, those in the dynamic condition rated genuine\ncontent as more accurate and demonstrated greater overall confidence in their\nassessments than those in the static or control conditions. In addition, those\nhigher in need for cognition (NFC) rated major hallucinations to be less\naccurate than low NFC participants, with no corresponding difference for\ngenuine content or minor hallucinations. These results underscore the potential\nbenefits of integrating web search results into LLMs for the detection of\nhallucinations, as well as the need for a more nuanced approach when developing\nhuman-centered systems, taking user characteristics into account.", "published": "2025-04-01 19:36:14", "link": "http://arxiv.org/abs/2504.01153v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "RipVIS: Rip Currents Video Instance Segmentation Benchmark for Beach Monitoring and Safety", "abstract": "Rip currents are strong, localized and narrow currents of water that flow\noutwards into the sea, causing numerous beach-related injuries and fatalities\nworldwide. Accurate identification of rip currents remains challenging due to\ntheir amorphous nature and the lack of annotated data, which often requires\nexpert knowledge. To address these issues, we present RipVIS, a large-scale\nvideo instance segmentation benchmark explicitly designed for rip current\nsegmentation. RipVIS is an order of magnitude larger than previous datasets,\nfeaturing $184$ videos ($212,328$ frames), of which $150$ videos ($163,528$\nframes) are with rip currents, collected from various sources, including\ndrones, mobile phones, and fixed beach cameras. Our dataset encompasses diverse\nvisual contexts, such as wave-breaking patterns, sediment flows, and water\ncolor variations, across multiple global locations, including USA, Mexico,\nCosta Rica, Portugal, Italy, Greece, Romania, Sri Lanka, Australia and New\nZealand. Most videos are annotated at $5$ FPS to ensure accuracy in dynamic\nscenarios, supplemented by an additional $34$ videos ($48,800$ frames) without\nrip currents. We conduct comprehensive experiments with Mask R-CNN, Cascade\nMask R-CNN, SparseInst and YOLO11, fine-tuning these models for the task of rip\ncurrent segmentation. Results are reported in terms of multiple metrics, with a\nparticular focus on the $F_2$ score to prioritize recall and reduce false\nnegatives. To enhance segmentation performance, we introduce a novel\npost-processing step based on Temporal Confidence Aggregation (TCA). RipVIS\naims to set a new standard for rip current segmentation, contributing towards\nsafer beach environments. We offer a benchmark website to share data, models,\nand results with the research community, encouraging ongoing collaboration and\nfuture contributions, at https://ripvis.ai.", "published": "2025-04-01 18:57:15", "link": "http://arxiv.org/abs/2504.01128v2", "categories": ["cs.CV", "cs.AI", "I.4.0; I.4.9"], "primary_category": "cs.CV"}
{"title": "ffstruc2vec: Flat, Flexible and Scalable Learning of Node Representations from Structural Identities", "abstract": "Node embedding refers to techniques that generate low-dimensional vector\nrepresentations of nodes in a graph while preserving specific properties of the\nnodes. A key challenge in the field is developing scalable methods that can\npreserve structural properties suitable for the required types of structural\npatterns of a given downstream application task. While most existing methods\nfocus on preserving node proximity, those that do preserve structural\nproperties often lack the flexibility to preserve various types of structural\npatterns required by downstream application tasks. This paper introduces\nffstruc2vec, a scalable deep-learning framework for learning node embedding\nvectors that preserve structural identities. Its flat, efficient architecture\nallows high flexibility in capturing diverse types of structural patterns,\nenabling broad adaptability to various downstream application tasks. The\nproposed framework significantly outperforms existing approaches across diverse\nunsupervised and supervised tasks in practical applications. Moreover,\nffstruc2vec enables explainability by quantifying how individual structural\npatterns influence task outcomes, providing actionable interpretation. To our\nknowledge, no existing framework combines this level of flexibility,\nscalability, and structural interpretability, underscoring its unique\ncapabilities.", "published": "2025-04-01 18:47:16", "link": "http://arxiv.org/abs/2504.01122v1", "categories": ["cs.LG", "cs.AI", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Hard-constraining Neumann boundary conditions in physics-informed neural networks via Fourier feature embeddings", "abstract": "We present a novel approach to hard-constrain Neumann boundary conditions in\nphysics-informed neural networks (PINNs) using Fourier feature embeddings.\nNeumann boundary conditions are used to described critical processes in various\napplication, yet they are more challenging to hard-constrain in PINNs than\nDirichlet conditions. Our method employs specific Fourier feature embeddings to\ndirectly incorporate Neumann boundary conditions into the neural network's\narchitecture instead of learning them. The embedding can be naturally extended\nby high frequency modes to better capture high frequency phenomena. We\ndemonstrate the efficacy of our approach through experiments on a diffusion\nproblem, for which our method outperforms existing hard-constraining methods\nand classical PINNs, particularly in multiscale and high frequency scenarios.", "published": "2025-04-01 18:10:46", "link": "http://arxiv.org/abs/2504.01093v1", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "HomeEmergency -- Using Audio to Find and Respond to Emergencies in the Home", "abstract": "In the United States alone accidental home deaths exceed 128,000 per year.\nOur work aims to enable home robots who respond to emergency scenarios in the\nhome, preventing injuries and deaths. We introduce a new dataset of household\nemergencies based in the ThreeDWorld simulator. Each scenario in our dataset\nbegins with an instantaneous or periodic sound which may or may not be an\nemergency. The agent must navigate the multi-room home scene using prior\nobservations, alongside audio signals and images from the simulator, to\ndetermine if there is an emergency or not.\n  In addition to our new dataset, we present a modular approach for localizing\nand identifying potential home emergencies. Underpinning our approach is a\nnovel probabilistic dynamic scene graph (P-DSG), where our key insight is that\ngraph nodes corresponding to agents can be represented with a probabilistic\nedge. This edge, when refined using Bayesian inference, enables efficient and\neffective localization of agents in the scene. We also utilize multi-modal\nvision-language models (VLMs) as a component in our approach, determining\nobject traits (e.g. flammability) and identifying emergencies. We present a\ndemonstration of our method completing a real-world version of our task on a\nconsumer robot, showing the transferability of both our task and our method.\nOur dataset will be released to the public upon this papers publication.", "published": "2025-04-01 18:07:25", "link": "http://arxiv.org/abs/2504.01089v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors", "abstract": "Despite remarkable advancements in video depth estimation, existing methods\nexhibit inherent limitations in achieving geometric fidelity through the\naffine-invariant predictions, limiting their applicability in reconstruction\nand other metrically grounded downstream tasks. We propose GeometryCrafter, a\nnovel framework that recovers high-fidelity point map sequences with temporal\ncoherence from open-world videos, enabling accurate 3D/4D reconstruction,\ncamera parameter estimation, and other depth-based applications. At the core of\nour approach lies a point map Variational Autoencoder (VAE) that learns a\nlatent space agnostic to video latent distributions for effective point map\nencoding and decoding. Leveraging the VAE, we train a video diffusion model to\nmodel the distribution of point map sequences conditioned on the input videos.\nExtensive evaluations on diverse datasets demonstrate that GeometryCrafter\nachieves state-of-the-art 3D accuracy, temporal consistency, and generalization\ncapability.", "published": "2025-04-01 17:58:03", "link": "http://arxiv.org/abs/2504.01016v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "IntrinsiX: High-Quality PBR Generation using Image Priors", "abstract": "We introduce IntrinsiX, a novel method that generates high-quality intrinsic\nimages from text description. In contrast to existing text-to-image models\nwhose outputs contain baked-in scene lighting, our approach predicts\nphysically-based rendering (PBR) maps. This enables the generated outputs to be\nused for content creation scenarios in core graphics applications that\nfacilitate re-lighting, editing, and texture generation tasks. In order to\ntrain our generator, we exploit strong image priors, and pre-train separate\nmodels for each PBR material component (albedo, roughness, metallic, normals).\nWe then align these models with a new cross-intrinsic attention formulation\nthat concatenates key and value features in a consistent fashion. This allows\nus to exchange information between each output modality and to obtain\nsemantically coherent PBR predictions. To ground each intrinsic component, we\npropose a rendering loss which provides image-space signals to constrain the\nmodel, thus facilitating sharp details also in the output BRDF properties. Our\nresults demonstrate detailed intrinsic generation with strong generalization\ncapabilities that outperforms existing intrinsic image decomposition methods\nused with generated images by a significant margin. Finally, we show a series\nof applications, including re-lighting, editing, and text-conditioned\nroom-scale PBR texture generation.", "published": "2025-04-01 17:47:48", "link": "http://arxiv.org/abs/2504.01008v1", "categories": ["cs.CV", "cs.AI", "I.4.8; I.4.9; I.2.10"], "primary_category": "cs.CV"}
{"title": "Enhancing Biologically Inspired Hierarchical Temporal Memory with Hardware-Accelerated Reflex Memory", "abstract": "The rapid expansion of the Internet of Things (IoT) generates zettabytes of\ndata that demand efficient unsupervised learning systems. Hierarchical Temporal\nMemory (HTM), a third-generation unsupervised AI algorithm, models the\nneocortex of the human brain by simulating columns of neurons to process and\npredict sequences. These neuron columns can memorize and infer sequences across\nmultiple orders. While multiorder inferences offer robust predictive\ncapabilities, they often come with significant computational overhead. The\nSequence Memory (SM) component of HTM, which manages these inferences,\nencounters bottlenecks primarily due to its extensive programmable\ninterconnects. In many cases, it has been observed that first-order temporal\nrelationships have proven to be sufficient without any significant loss in\nefficiency. This paper introduces a Reflex Memory (RM) block, inspired by the\nSpinal Cord's working mechanisms, designed to accelerate the processing of\nfirst-order inferences. The RM block performs these inferences significantly\nfaster than the SM. The integration of RM with HTM forms a system called the\nAccelerated Hierarchical Temporal Memory (AHTM), which processes repetitive\ninformation more efficiently than the original HTM while still supporting\nmultiorder inferences. The experimental results demonstrate that the HTM\npredicts an event in 0.945 s, whereas the AHTM module does so in 0.125 s.\nAdditionally, the hardware implementation of RM in a content-addressable memory\n(CAM) block, known as Hardware-Accelerated Hierarchical Temporal Memory\n(H-AHTM), predicts an event in just 0.094 s, significantly improving inference\nspeed. Compared to the original algorithm \\cite{bautista2020matlabhtm}, AHTM\naccelerates inference by up to 7.55x, while H-AHTM further enhances performance\nwith a 10.10x speedup.", "published": "2025-04-01 17:40:12", "link": "http://arxiv.org/abs/2504.03746v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization", "abstract": "Masked Image Modeling (MIM) with Vector Quantization (VQ) has achieved great\nsuccess in both self-supervised pre-training and image generation. However,\nmost existing methods struggle to address the trade-off in shared latent space\nfor generation quality vs. representation learning and efficiency. To push the\nlimits of this paradigm, we propose MergeVQ, which incorporates token merging\ntechniques into VQ-based generative models to bridge the gap between image\ngeneration and visual representation learning in a unified architecture. During\npre-training, MergeVQ decouples top-k semantics from latent space with the\ntoken merge module after self-attention blocks in the encoder for subsequent\nLook-up Free Quantization (LFQ) and global alignment and recovers their\nfine-grained details through cross-attention in the decoder for reconstruction.\nAs for the second-stage generation, we introduce MergeAR, which performs KV\nCache compression for efficient raster-order prediction. Extensive experiments\non ImageNet verify that MergeVQ as an AR generative model achieves competitive\nperformance in both visual representation learning and image generation tasks\nwhile maintaining favorable token efficiency and inference speed. The code and\nmodel will be available at https://apexgen-x.github.io/MergeVQ.", "published": "2025-04-01 17:39:19", "link": "http://arxiv.org/abs/2504.00999v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Accelerating drug discovery with Artificial: a whole-lab orchestration and scheduling system for self-driving labs", "abstract": "Self-driving labs are transforming drug discovery by enabling automated,\nAI-guided experimentation, but they face challenges in orchestrating complex\nworkflows, integrating diverse instruments and AI models, and managing data\nefficiently. Artificial addresses these issues with a comprehensive\norchestration and scheduling system that unifies lab operations, automates\nworkflows, and integrates AI-driven decision-making. By incorporating AI/ML\nmodels like NVIDIA BioNeMo - which facilitates molecular interaction prediction\nand biomolecular analysis - Artificial enhances drug discovery and accelerates\ndata-driven research. Through real-time coordination of instruments, robots,\nand personnel, the platform streamlines experiments, enhances reproducibility,\nand advances drug discovery.", "published": "2025-04-01 17:22:50", "link": "http://arxiv.org/abs/2504.00986v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "WorldScore: A Unified Evaluation Benchmark for World Generation", "abstract": "We introduce the WorldScore benchmark, the first unified benchmark for world\ngeneration. We decompose world generation into a sequence of next-scene\ngeneration tasks with explicit camera trajectory-based layout specifications,\nenabling unified evaluation of diverse approaches from 3D and 4D scene\ngeneration to video generation models. The WorldScore benchmark encompasses a\ncurated dataset of 3,000 test examples that span diverse worlds: static and\ndynamic, indoor and outdoor, photorealistic and stylized. The WorldScore\nmetrics evaluate generated worlds through three key aspects: controllability,\nquality, and dynamics. Through extensive evaluation of 19 representative\nmodels, including both open-source and closed-source ones, we reveal key\ninsights and challenges for each category of models. Our dataset, evaluation\ncode, and leaderboard can be found at https://haoyi-duan.github.io/WorldScore/", "published": "2025-04-01 17:20:23", "link": "http://arxiv.org/abs/2504.00983v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Resource Allocation for RIS-Assisted CoMP-NOMA Networks using Reinforcement Learning", "abstract": "This thesis delves into the forefront of wireless communication by exploring\nthe synergistic integration of three transformative technologies: STAR-RIS,\nCoMP, and NOMA. Driven by the ever-increasing demand for higher data rates,\nimproved spectral efficiency, and expanded coverage in the evolving landscape\nof 6G development, this research investigates the potential of these\ntechnologies to revolutionize future wireless networks.\n  The thesis analyzes the performance gains achievable through strategic\ndeployment of STAR-RIS, focusing on mitigating inter-cell interference,\nenhancing signal strength, and extending coverage to cell-edge users. Resource\nsharing strategies for STAR-RIS elements are explored, optimizing both\ntransmission and reflection functionalities. Analytical frameworks are\ndeveloped to quantify the benefits of STAR-RIS assisted CoMP-NOMA networks\nunder realistic channel conditions, deriving key performance metrics such as\nergodic rates and outage probabilities. Additionally, the research delves into\nenergy-efficient design approaches for CoMP-NOMA networks incorporating RIS,\nproposing novel RIS configurations and optimization algorithms to achieve a\nbalance between performance and energy consumption. Furthermore, the\napplication of Deep Reinforcement Learning (DRL) techniques for intelligent and\nadaptive optimization in aerial RIS-assisted CoMP-NOMA networks is explored,\naiming to maximize network sum rate while meeting user quality of service\nrequirements. Through a comprehensive investigation of these technologies and\ntheir synergistic potential, this thesis contributes valuable insights into the\nfuture of wireless communication, paving the way for the development of more\nefficient, reliable, and sustainable networks capable of meeting the demands of\nour increasingly connected world.", "published": "2025-04-01 17:14:01", "link": "http://arxiv.org/abs/2504.00975v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "HDVIO2.0: Wind and Disturbance Estimation with Hybrid Dynamics VIO", "abstract": "Visual-inertial odometry (VIO) is widely used for state estimation in\nautonomous micro aerial vehicles using onboard sensors. Current methods improve\nVIO by incorporating a model of the translational vehicle dynamics, yet their\nperformance degrades when faced with low-accuracy vehicle models or continuous\nexternal disturbances, like wind. Additionally, incorporating rotational\ndynamics in these models is computationally intractable when they are deployed\nin online applications, e.g., in a closed-loop control system. We present\nHDVIO2.0, which models full 6-DoF, translational and rotational, vehicle\ndynamics and tightly incorporates them into a VIO with minimal impact on the\nruntime. HDVIO2.0 builds upon the previous work, HDVIO, and addresses these\nchallenges through a hybrid dynamics model combining a point-mass vehicle model\nwith a learning-based component, with access to control commands and IMU\nhistory, to capture complex aerodynamic effects. The key idea behind modeling\nthe rotational dynamics is to represent them with continuous-time functions.\nHDVIO2.0 leverages the divergence between the actual motion and the predicted\nmotion from the hybrid dynamics model to estimate external forces as well as\nthe robot state. Our system surpasses the performance of state-of-the-art\nmethods in experiments using public and new drone dynamics datasets, as well as\nreal-world flights in winds up to 25 km/h. Unlike existing approaches, we also\nshow that accurate vehicle dynamics predictions are achievable without precise\nknowledge of the full vehicle state.", "published": "2025-04-01 17:08:27", "link": "http://arxiv.org/abs/2504.00969v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Enabling Efficient Processing of Spiking Neural Networks with On-Chip Learning on Commodity Neuromorphic Processors for Edge AI Systems", "abstract": "The rising demand for energy-efficient edge AI systems (e.g., mobile\nagents/robots) has increased the interest in neuromorphic computing, since it\noffers ultra-low power/energy AI computation through spiking neural network\n(SNN) algorithms on neuromorphic processors. However, their efficient\nimplementation strategy has not been comprehensively studied, hence limiting\nSNN deployments for edge AI systems. Toward this, we propose a design\nmethodology to enable efficient SNN processing on commodity neuromorphic\nprocessors. To do this, we first study the key characteristics of targeted\nneuromorphic hardware (e.g., memory and compute budgets), and leverage this\ninformation to perform compatibility analysis for network selection. Afterward,\nwe employ a mapping strategy for efficient SNN implementation on the targeted\nprocessor. Furthermore, we incorporate an efficient on-chip learning mechanism\nto update the systems' knowledge for adapting to new input classes and dynamic\nenvironments. The experimental results show that the proposed methodology leads\nthe system to achieve low latency of inference (i.e., less than 50ms for image\nclassification, less than 200ms for real-time object detection in video\nstreaming, and less than 1ms in keyword recognition) and low latency of on-chip\nlearning (i.e., less than 2ms for keyword recognition), while incurring less\nthan 250mW of processing power and less than 15mJ of energy consumption across\nthe respective different applications and scenarios. These results show the\npotential of the proposed methodology in enabling efficient edge AI systems for\ndiverse application use-cases.", "published": "2025-04-01 16:52:03", "link": "http://arxiv.org/abs/2504.00957v1", "categories": ["cs.NE", "cs.AI", "cs.AR", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Unfair Learning: GenAI Exceptionalism and Copyright Law", "abstract": "This paper challenges the argument that generative artificial intelligence\n(GenAI) is entitled to broad immunity from copyright law for reproducing\ncopyrighted works without authorization due to a fair use defense. It examines\nfair use legal arguments and eight distinct substantive arguments, contending\nthat every legal and substantive argument favoring fair use for GenAI applies\nequally, if not more so, to humans. Therefore, granting GenAI exceptional\nprivileges in this domain is legally and logically inconsistent with\nwithholding broad fair use exemptions from individual humans. It would mean no\nhuman would need to pay for virtually any copyright work again. The solution is\nto take a circumspect view of any fair use claim for mass copyright\nreproduction by any entity and focus on the first principles of whether\npermitting such exceptionalism for GenAI promotes science and the arts.", "published": "2025-04-01 16:49:39", "link": "http://arxiv.org/abs/2504.00955v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "IDMR: Towards Instance-Driven Precise Visual Correspondence in Multimodal Retrieval", "abstract": "Multimodal retrieval systems are becoming increasingly vital for cutting-edge\nAI technologies, such as embodied AI and AI-driven digital content industries.\nHowever, current multimodal retrieval tasks lack sufficient complexity and\ndemonstrate limited practical application value. It spires us to design\nInstance-Driven Multimodal Image Retrieval (IDMR), a novel task that requires\nmodels to retrieve images containing the same instance as a query image while\nmatching a text-described scenario. Unlike existing retrieval tasks focused on\nglobal image similarity or category-level matching, IDMR demands fine-grained\ninstance-level consistency across diverse contexts. To benchmark this\ncapability, we develop IDMR-bench using real-world object tracking and\nfirst-person video data. Addressing the scarcity of training data, we propose a\ncross-domain synthesis method that creates 557K training samples by cropping\nobjects from standard detection datasets. Our Multimodal Large Language Model\n(MLLM) based retrieval model, trained on 1.2M samples, outperforms\nstate-of-the-art approaches on both traditional benchmarks and our zero-shot\nIDMR-bench. Experimental results demonstrate previous models' limitations in\ninstance-aware retrieval and highlight the potential of MLLM for advanced\nretrieval applications. The whole training dataset, codes and models, with wide\nranges of sizes, are available at https://github.com/BwLiu01/IDMR.", "published": "2025-04-01 16:47:20", "link": "http://arxiv.org/abs/2504.00954v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Personalized Federated Training of Diffusion Models with Privacy Guarantees", "abstract": "The scarcity of accessible, compliant, and ethically sourced data presents a\nconsiderable challenge to the adoption of artificial intelligence (AI) in\nsensitive fields like healthcare, finance, and biomedical research.\nFurthermore, access to unrestricted public datasets is increasingly constrained\ndue to rising concerns over privacy, copyright, and competition. Synthetic data\nhas emerged as a promising alternative, and diffusion models -- a cutting-edge\ngenerative AI technology -- provide an effective solution for generating\nhigh-quality and diverse synthetic data. In this paper, we introduce a novel\nfederated learning framework for training diffusion models on decentralized\nprivate datasets. Our framework leverages personalization and the inherent\nnoise in the forward diffusion process to produce high-quality samples while\nensuring robust differential privacy guarantees. Our experiments show that our\nframework outperforms non-collaborative training methods, particularly in\nsettings with high data heterogeneity, and effectively reduces biases and\nimbalances in synthetic data, resulting in fairer downstream models.", "published": "2025-04-01 16:45:26", "link": "http://arxiv.org/abs/2504.00952v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "QSViT: A Methodology for Quantizing Spiking Vision Transformers", "abstract": "Vision Transformer (ViT)-based models have shown state-of-the-art performance\n(e.g., accuracy) in vision-based AI tasks. However, realizing their capability\nin resource-constrained embedded AI systems is challenging due to their\ninherent large memory footprints and complex computations, thereby incurring\nhigh power/energy consumption. Recently, Spiking Vision Transformer\n(SViT)-based models have emerged as alternate low-power ViT networks. However,\ntheir large memory footprints still hinder their applicability for\nresource-constrained embedded AI systems. Therefore, there is a need for a\nmethodology to compress SViT models without degrading the accuracy\nsignificantly. To address this, we propose QSViT, a novel design methodology to\ncompress the SViT models through a systematic quantization strategy across\ndifferent network layers. To do this, our QSViT employs several key steps: (1)\ninvestigating the impact of different precision levels in different network\nlayers, (2) identifying the appropriate base quantization settings for guiding\nbit precision reduction, (3) performing a guided quantization strategy based on\nthe base settings to select the appropriate quantization setting, and (4)\ndeveloping an efficient quantized network based on the selected quantization\nsetting. The experimental results demonstrate that, our QSViT methodology\nachieves 22.75% memory saving and 21.33% power saving, while also maintaining\nhigh accuracy within 2.1% from that of the original non-quantized SViT model on\nthe ImageNet dataset. These results highlight the potential of QSViT\nmethodology to pave the way toward the efficient SViT deployments on\nresource-constrained embedded AI systems.", "published": "2025-04-01 16:34:46", "link": "http://arxiv.org/abs/2504.00948v1", "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Graph Classification and Radiomics Signature for Identification of Tuberculous Meningitis", "abstract": "Introduction: Tuberculous meningitis (TBM) is a serious brain infection\ncaused by Mycobacterium tuberculosis, characterized by inflammation of the\nmeninges covering the brain and spinal cord. Diagnosis often requires invasive\nlumbar puncture (LP) and cerebrospinal fluid (CSF) analysis. Objectives: This\nstudy aims to classify TBM patients using T1-weighted (T1w) non-contrast\nMagnetic Resonance Imaging (MRI) scans. We hypothesize that specific brain\nregions, such as the interpeduncular cisterns, bone, and corpus callosum,\ncontain visual markers that can non-invasively distinguish TBM patients from\nhealthy controls. We propose a novel Pixel-array Graphs Classifier\n(PAG-Classifier) that leverages spatial relationships between neighbouring 3D\npixels in a graph-based framework to extract significant features through eigen\ndecomposition. These features are then used to train machine learning\nclassifiers for effective patient classification. We validate our approach\nusing a radiomics-based methodology, classifying TBM patients based on relevant\nradiomics features. Results: We utilized an internal dataset consisting of 52\nscans, 32 from confirmed TBM patients based on mycobacteria detection in CSF,\nand 20 from healthy individuals. We achieved a 5-fold cross-validated average\nF1 score of 85.71% for cistern regions with our PAG-Classifier and 92.85% with\nthe radiomics features classifier, surpassing current state-of-the-art\nbenchmarks by 15% and 22%, respectively. However, bone and corpus callosum\nregions showed poor classification effectiveness, with average F1 scores below\n50%. Conclusion: Our study suggests that algorithms like the PAG-Classifier\nserve as effective tools for non-invasive TBM analysis, particularly by\ntargeting the interpeduncular cistern. Findings indicate that the bone and\ncorpus callosum regions lack distinctive patterns for differentiation.", "published": "2025-04-01 16:28:39", "link": "http://arxiv.org/abs/2504.00943v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AI Judges in Design: Statistical Perspectives on Achieving Human Expert Equivalence With Vision-Language Models", "abstract": "The subjective evaluation of early stage engineering designs, such as\nconceptual sketches, traditionally relies on human experts. However, expert\nevaluations are time-consuming, expensive, and sometimes inconsistent. Recent\nadvances in vision-language models (VLMs) offer the potential to automate\ndesign assessments, but it is crucial to ensure that these AI ``judges''\nperform on par with human experts. However, no existing framework assesses\nexpert equivalence. This paper introduces a rigorous statistical framework to\ndetermine whether an AI judge's ratings match those of human experts. We apply\nthis framework in a case study evaluating four VLM-based judges on key design\nmetrics (uniqueness, creativity, usefulness, and drawing quality). These AI\njudges employ various in-context learning (ICL) techniques, including uni- vs.\nmultimodal prompts and inference-time reasoning. The same statistical framework\nis used to assess three trained novices for expert-equivalence. Results show\nthat the top-performing AI judge, using text- and image-based ICL with\nreasoning, achieves expert-level agreement for uniqueness and drawing quality\nand outperforms or matches trained novices across all metrics. In 6/6 runs for\nboth uniqueness and creativity, and 5/6 runs for both drawing quality and\nusefulness, its agreement with experts meets or exceeds that of the majority of\ntrained novices. These findings suggest that reasoning-supported VLM models can\nachieve human-expert equivalence in design evaluation. This has implications\nfor scaling design evaluation in education and practice, and provides a general\nstatistical framework for validating AI judges in other domains requiring\nsubjective content evaluation.", "published": "2025-04-01 16:20:29", "link": "http://arxiv.org/abs/2504.00938v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning", "abstract": "Embodied agents operating in real-world environments must interpret ambiguous\nand under-specified human instructions. A capable household robot should\nrecognize ambiguity and ask relevant clarification questions to infer the user\nintent accurately, leading to more effective task execution. To study this\nproblem, we introduce the Ask-to-Act task, where an embodied agent must fetch a\nspecific object instance given an ambiguous instruction in a home environment.\nThe agent must strategically ask minimal, yet relevant, clarification questions\nto resolve ambiguity while navigating under partial observability. To solve\nthis problem, we propose a novel approach that fine-tunes multimodal large\nlanguage models (MLLMs) as vision-language-action (VLA) policies using online\nreinforcement learning (RL) with LLM-generated rewards. Our method eliminates\nthe need for large-scale human demonstrations or manually engineered rewards\nfor training such agents. We benchmark against strong zero-shot baselines,\nincluding GPT-4o, and supervised fine-tuned MLLMs, on our task. Our results\ndemonstrate that our RL-finetuned MLLM outperforms all baselines by a\nsignificant margin ($19.1$-$40.3\\%$), generalizing well to novel scenes and\ntasks. To the best of our knowledge, this is the first demonstration of\nadapting MLLMs as VLA agents that can act and ask for help using LLM-generated\nrewards with online RL.", "published": "2025-04-01 15:41:50", "link": "http://arxiv.org/abs/2504.00907v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Role and Use of Race in AI/ML Models Related to Health", "abstract": "The role and use of race within health-related artificial intelligence and\nmachine learning (AI/ML) models has sparked increasing attention and\ncontroversy. Despite the complexity and breadth of related issues, a robust and\nholistic framework to guide stakeholders in their examination and resolution\nremains lacking. This perspective provides a broad-based, systematic, and\ncross-cutting landscape analysis of race-related challenges, structured around\nthe AI/ML lifecycle and framed through \"points to consider\" to support inquiry\nand decision-making.", "published": "2025-04-01 15:27:31", "link": "http://arxiv.org/abs/2504.00899v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Comparative Explanations: Explanation Guided Decision Making for Human-in-the-Loop Preference Selection", "abstract": "This paper introduces Multi-Output LOcal Narrative Explanation (MOLONE), a\nnovel comparative explanation method designed to enhance preference selection\nin human-in-the-loop Preference Bayesian optimization (PBO). The preference\nelicitation in PBO is a non-trivial task because it involves navigating\nimplicit trade-offs between vector-valued outcomes, subjective priorities of\ndecision-makers, and decision-makers' uncertainty in preference selection.\nExisting explainable AI (XAI) methods for BO primarily focus on input feature\nimportance, neglecting the crucial role of outputs (objectives) in human\npreference elicitation. MOLONE addresses this gap by providing explanations\nthat highlight both input and output importance, enabling decision-makers to\nunderstand the trade-offs between competing objectives and make more informed\npreference selections. MOLONE focuses on local explanations, comparing the\nimportance of input features and outcomes across candidate samples within a\nlocal neighborhood of the search space, thus capturing nuanced differences\nrelevant to preference-based decision-making. We evaluate MOLONE within a PBO\nframework using benchmark multi-objective optimization functions, demonstrating\nits effectiveness in improving convergence compared to noisy preference\nselections. Furthermore, a user study confirms that MOLONE significantly\naccelerates convergence in human-in-the-loop scenarios by facilitating more\nefficient identification of preferred options.", "published": "2025-04-01 15:23:54", "link": "http://arxiv.org/abs/2504.03744v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modelling bounded rational decision-making through Wasserstein constraints", "abstract": "Modelling bounded rational decision-making through information constrained\nprocessing provides a principled approach for representing departures from\nrationality within a reinforcement learning framework, while still treating\ndecision-making as an optimization process. However, existing approaches are\ngenerally based on Entropy, Kullback-Leibler divergence, or Mutual Information.\nIn this work, we highlight issues with these approaches when dealing with\nordinal action spaces. Specifically, entropy assumes uniform prior beliefs,\nmissing the impact of a priori biases on decision-makings. KL-Divergence\naddresses this, however, has no notion of \"nearness\" of actions, and\nadditionally, has several well known potentially undesirable properties such as\nthe lack of symmetry, and furthermore, requires the distributions to have the\nsame support (e.g. positive probability for all actions). Mutual information is\noften difficult to estimate. Here, we propose an alternative approach for\nmodeling bounded rational RL agents utilising Wasserstein distances. This\napproach overcomes the aforementioned issues. Crucially, this approach accounts\nfor the nearness of ordinal actions, modeling \"stickiness\" in agent decisions\nand unlikeliness of rapidly switching to far away actions, while also\nsupporting low probability actions, zero-support prior distributions, and is\nsimple to calculate directly.", "published": "2025-04-01 15:19:34", "link": "http://arxiv.org/abs/2504.03743v1", "categories": ["cs.LG", "cs.AI", "cs.GT", "econ.GN", "q-fin.EC"], "primary_category": "cs.LG"}
{"title": "Spectral Architecture Search for Neural Networks", "abstract": "Architecture design and optimization are challenging problems in the field of\nartificial neural networks. Working in this context, we here present SPARCS\n(SPectral ARchiteCture Search), a novel architecture search protocol which\nexploits the spectral attributes of the inter-layer transfer matrices. SPARCS\nallows one to explore the space of possible architectures by spanning\ncontinuous and differentiable manifolds, thus enabling for gradient-based\noptimization algorithms to be eventually employed. With reference to simple\nbenchmark models, we show that the newly proposed method yields a self-emerging\narchitecture with a minimal degree of expressivity to handle the task under\ninvestigation and with a reduced parameter count as compared to other viable\nalternatives.", "published": "2025-04-01 15:14:30", "link": "http://arxiv.org/abs/2504.00885v1", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Improved Visual-Spatial Reasoning via R1-Zero-Like Training", "abstract": "Increasing attention has been placed on improving the reasoning capacities of\nmulti-modal large language models (MLLMs). As the cornerstone for AI agents\nthat function in the physical realm, video-based visual-spatial intelligence\n(VSI) emerges as one of the most pivotal reasoning capabilities of MLLMs. This\nwork conducts a first, in-depth study on improving the visual-spatial reasoning\nof MLLMs via R1-Zero-like training. Technically, we first identify that the\nvisual-spatial reasoning capacities of small- to medium-sized Qwen2-VL models\ncannot be activated via Chain of Thought (CoT) prompts. We then incorporate\nGRPO training for improved visual-spatial reasoning, using the carefully\ncurated VSI-100k dataset, following DeepSeek-R1-Zero. During the investigation,\nwe identify the necessity to keep the KL penalty (even with a small value) in\nGRPO. With just 120 GPU hours, our vsGRPO-2B model, fine-tuned from\nQwen2-VL-2B, can outperform the base model by 12.1% and surpass GPT-4o.\nMoreover, our vsGRPO-7B model, fine-tuned from Qwen2-VL-7B, achieves\nperformance comparable to that of the best open-source model\nLLaVA-NeXT-Video-72B. Additionally, we compare vsGRPO to supervised fine-tuning\nand direct preference optimization baselines and observe strong performance\nsuperiority. The code and dataset will be available soon.", "published": "2025-04-01 15:11:11", "link": "http://arxiv.org/abs/2504.00883v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hierarchical Local-Global Feature Learning for Few-shot Malicious Traffic Detection", "abstract": "With the rapid growth of internet traffic, malicious network attacks have\nbecome increasingly frequent and sophisticated, posing significant threats to\nglobal cybersecurity. Traditional detection methods, including rule-based and\nmachine learning-based approaches, struggle to accurately identify emerging\nthreats, particularly in scenarios with limited samples. While recent advances\nin few-shot learning have partially addressed the data scarcity issue, existing\nmethods still exhibit high false positive rates and lack the capability to\neffectively capture crucial local traffic patterns. In this paper, we propose\nHLoG, a novel hierarchical few-shot malicious traffic detection framework that\nleverages both local and global features extracted from network sessions. HLoG\nemploys a sliding-window approach to segment sessions into phases, capturing\nfine-grained local interaction patterns through hierarchical bidirectional GRU\nencoding, while simultaneously modeling global contextual dependencies. We\nfurther design a session similarity assessment module that integrates local\nsimilarity with global self-attention-enhanced representations, achieving\naccurate and robust few-shot traffic classification. Comprehensive experiments\non three meticulously reconstructed datasets demonstrate that HLoG\nsignificantly outperforms existing state-of-the-art methods. Particularly, HLoG\nachieves superior recall rates while substantially reducing false positives,\nhighlighting its effectiveness and practical value in real-world cybersecurity\napplications.", "published": "2025-04-01 14:56:44", "link": "http://arxiv.org/abs/2504.03742v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Exploring Personalized Federated Learning Architectures for Violence Detection in Surveillance Videos", "abstract": "The challenge of detecting violent incidents in urban surveillance systems is\ncompounded by the voluminous and diverse nature of video data. This paper\npresents a targeted approach using Personalized Federated Learning (PFL) to\naddress these issues, specifically employing the Federated Learning with\nPersonalization Layers method within the Flower framework. Our methodology\nadapts learning models to the unique data characteristics of each surveillance\nnode, effectively managing the heterogeneous and non-IID nature of surveillance\nvideo data. Through rigorous experiments conducted on balanced and imbalanced\ndatasets, our PFL models demonstrated enhanced accuracy and efficiency,\nachieving up to 99.3% accuracy. This study underscores the potential of PFL to\nsignificantly improve the scalability and effectiveness of surveillance\nsystems, offering a robust, privacy-preserving solution for violence detection\nin complex urban environments.", "published": "2025-04-01 14:47:14", "link": "http://arxiv.org/abs/2504.00857v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ReaLitE: Enrichment of Relation Embeddings in Knowledge Graphs using Numeric Literals", "abstract": "Most knowledge graph embedding (KGE) methods tailored for link prediction\nfocus on the entities and relations in the graph, giving little attention to\nother literal values, which might encode important information. Therefore, some\nliteral-aware KGE models attempt to either integrate numerical values into the\nembeddings of the entities or convert these numerics into entities during\npreprocessing, leading to information loss. Other methods concerned with\ncreating relation-specific numerical features assume completeness of numerical\ndata, which does not apply to real-world graphs. In this work, we propose\nReaLitE, a novel relation-centric KGE model that dynamically aggregates and\nmerges entities' numerical attributes with the embeddings of the connecting\nrelations. ReaLitE is designed to complement existing conventional KGE methods\nwhile supporting multiple variations for numerical aggregations, including a\nlearnable method.\n  We comprehensively evaluated the proposed relation-centric embedding using\nseveral benchmarks for link prediction and node classification tasks. The\nresults showed the superiority of ReaLitE over the state of the art in both\ntasks.", "published": "2025-04-01 14:38:22", "link": "http://arxiv.org/abs/2504.00852v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Global Intervention and Distillation for Federated Out-of-Distribution Generalization", "abstract": "Attribute skew in federated learning leads local models to focus on learning\nnon-causal associations, guiding them towards inconsistent optimization\ndirections, which inevitably results in performance degradation and unstable\nconvergence. Existing methods typically leverage data augmentation to enhance\nsample diversity or employ knowledge distillation to learn invariant\nrepresentations. However, the instability in the quality of generated data and\nthe lack of domain information limit their performance on unseen samples. To\naddress these issues, this paper presents a global intervention and\ndistillation method, termed FedGID, which utilizes diverse attribute features\nfor backdoor adjustment to break the spurious association between background\nand label. It includes two main modules, where the global intervention module\nadaptively decouples objects and backgrounds in images, injects background\ninformation into random samples to intervene in the sample distribution, which\nlinks backgrounds to all categories to prevent the model from treating\nbackground-label associations as causal. The global distillation module\nleverages a unified knowledge base to guide the representation learning of\nclient models, preventing local models from overfitting to client-specific\nattributes. Experimental results on three datasets demonstrate that FedGID\nenhances the model's ability to focus on the main subjects in unseen data and\noutperforms existing methods in collaborative modeling.", "published": "2025-04-01 14:36:24", "link": "http://arxiv.org/abs/2504.00850v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Investigating Large Language Models in Diagnosing Students' Cognitive Skills in Math Problem-solving", "abstract": "Mathematics learning entails mastery of both content knowledge and cognitive\nprocessing of knowing, applying, and reasoning with it. Automated math\nassessment primarily has focused on grading students' exhibition of content\nknowledge by finding textual evidence, such as specific numbers, formulas, and\nstatements. Recent advancements in problem-solving, image recognition, and\nreasoning capabilities of large language models (LLMs) show promise for nuanced\nevaluation of students' cognitive skills. Diagnosing cognitive skills needs to\ninfer students' thinking processes beyond textual evidence, which is an\nunderexplored task in LLM-based automated assessment. In this work, we\ninvestigate how state-of-the-art LLMs diagnose students' cognitive skills in\nmathematics. We constructed MathCog, a novel benchmark dataset comprising 639\nstudent responses to 110 expert-curated middle school math problems, each\nannotated with detailed teachers' diagnoses based on cognitive skill\nchecklists. Using MathCog, we evaluated 16 closed and open LLMs of varying\nmodel sizes and vendors. Our evaluation reveals that even the state-of-the-art\nLLMs struggle with the task, all F1 scores below 0.5, and tend to exhibit\nstrong false confidence for incorrect cases ($r_s=.617$). We also found that\nmodel size positively correlates with the diagnosis performance ($r_s=.771$).\nFinally, we discuss the implications of these findings, the overconfidence\nissue, and directions for improving automated cognitive skill diagnosis.", "published": "2025-04-01 14:29:41", "link": "http://arxiv.org/abs/2504.00843v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Context-Aware Human Behavior Prediction Using Multimodal Large Language Models: Challenges and Insights", "abstract": "Predicting human behavior in shared environments is crucial for safe and\nefficient human-robot interaction. Traditional data-driven methods to that end\nare pre-trained on domain-specific datasets, activity types, and prediction\nhorizons. In contrast, the recent breakthroughs in Large Language Models (LLMs)\npromise open-ended cross-domain generalization to describe various human\nactivities and make predictions in any context. In particular, Multimodal LLMs\n(MLLMs) are able to integrate information from various sources, achieving more\ncontextual awareness and improved scene understanding. The difficulty in\napplying general-purpose MLLMs directly for prediction stems from their limited\ncapacity for processing large input sequences, sensitivity to prompt design,\nand expensive fine-tuning. In this paper, we present a systematic analysis of\napplying pre-trained MLLMs for context-aware human behavior prediction. To this\nend, we introduce a modular multimodal human activity prediction framework that\nallows us to benchmark various MLLMs, input variations, In-Context Learning\n(ICL), and autoregressive techniques. Our evaluation indicates that the\nbest-performing framework configuration is able to reach 92.8% semantic\nsimilarity and 66.1% exact label accuracy in predicting human behaviors in the\ntarget frame.", "published": "2025-04-01 14:28:19", "link": "http://arxiv.org/abs/2504.00839v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "A Survey on Music Generation from Single-Modal, Cross-Modal, and Multi-Modal Perspectives: Data, Methods, and Challenges", "abstract": "Multi-modal music generation, using multiple modalities like images, video,\nand text alongside musical scores and audio as guidance, is an emerging\nresearch area with broad applications. This paper reviews this field,\ncategorizing music generation systems from the perspective of modalities. It\ncovers modality representation, multi-modal data alignment, and their\nutilization to guide music generation. We also discuss current datasets and\nevaluation methods. Key challenges in this area include effective multi-modal\nintegration, large-scale comprehensive datasets, and systematic evaluation\nmethods. Finally, we provide an outlook on future research directions focusing\non multi-modal fusion, alignment, data, and evaluation.", "published": "2025-04-01 14:26:25", "link": "http://arxiv.org/abs/2504.00837v1", "categories": ["cs.SD", "cs.AI", "cs.MM"], "primary_category": "cs.SD"}
{"title": "Example-Based Concept Analysis Framework for Deep Weather Forecast Models", "abstract": "To improve the trustworthiness of an AI model, finding consistent,\nunderstandable representations of its inference process is essential. This\nunderstanding is particularly important in high-stakes operations such as\nweather forecasting, where the identification of underlying meteorological\nmechanisms is as critical as the accuracy of the predictions. Despite the\ngrowing literature that addresses this issue through explainable AI, the\napplicability of their solutions is often limited due to their AI-centric\ndevelopment. To fill this gap, we follow a user-centric process to develop an\nexample-based concept analysis framework, which identifies cases that follow a\nsimilar inference process as the target instance in a target model and presents\nthem in a user-comprehensible format. Our framework provides the users with\nvisually and conceptually analogous examples, including the probability of\nconcept assignment to resolve ambiguities in weather mechanisms. To bridge the\ngap between vector representations identified from models and\nhuman-understandable explanations, we compile a human-annotated concept dataset\nand implement a user interface to assist domain experts involved in the the\nframework development.", "published": "2025-04-01 14:22:41", "link": "http://arxiv.org/abs/2504.00831v1", "categories": ["cs.AI", "cs.HC", "68T07", "I.2.1"], "primary_category": "cs.AI"}
{"title": "Explainable AI-Based Interface System for Weather Forecasting Model", "abstract": "Machine learning (ML) is becoming increasingly popular in meteorological\ndecision-making. Although the literature on explainable artificial intelligence\n(XAI) is growing steadily, user-centered XAI studies have not extend to this\ndomain yet. This study defines three requirements for explanations of black-box\nmodels in meteorology through user studies: statistical model performance for\ndifferent rainfall scenarios to identify model bias, model reasoning, and the\nconfidence of model outputs. Appropriate XAI methods are mapped to each\nrequirement, and the generated explanations are tested quantitatively and\nqualitatively. An XAI interface system is designed based on user feedback. The\nresults indicate that the explanations increase decision utility and user\ntrust. Users prefer intuitive explanations over those based on XAI algorithms\neven for potentially easy-to-recognize examples. These findings can provide\nevidence for future research on user-centered XAI algorithms, as well as a\nbasis to improve the usability of AI systems in practice.", "published": "2025-04-01 13:52:34", "link": "http://arxiv.org/abs/2504.00795v1", "categories": ["cs.AI", "cs.HC", "68T07", "I.2.1"], "primary_category": "cs.AI"}
{"title": "Conditional Temporal Neural Processes with Covariance Loss", "abstract": "We introduce a novel loss function, Covariance Loss, which is conceptually\nequivalent to conditional neural processes and has a form of regularization so\nthat is applicable to many kinds of neural networks. With the proposed loss,\nmappings from input variables to target variables are highly affected by\ndependencies of target variables as well as mean activation and mean\ndependencies of input and target variables. This nature enables the resulting\nneural networks to become more robust to noisy observations and recapture\nmissing dependencies from prior information. In order to show the validity of\nthe proposed loss, we conduct extensive sets of experiments on real-world\ndatasets with state-of-the-art models and discuss the benefits and drawbacks of\nthe proposed Covariance Loss.", "published": "2025-04-01 13:51:44", "link": "http://arxiv.org/abs/2504.00794v1", "categories": ["cs.LG", "cs.AI", "68T07", "I.2.8"], "primary_category": "cs.LG"}
{"title": "Brain Network Classification Based on Graph Contrastive Learning and Graph Transformer", "abstract": "The dynamic characterization of functional brain networks is of great\nsignificance for elucidating the mechanisms of human brain function. Although\ngraph neural networks have achieved remarkable progress in functional network\nanalysis, challenges such as data scarcity and insufficient supervision\npersist. To address the limitations of limited training data and inadequate\nsupervision, this paper proposes a novel model named PHGCL-DDGformer that\nintegrates graph contrastive learning with graph transformers, effectively\nenhancing the representation learning capability for brain network\nclassification tasks. To overcome the constraints of existing graph contrastive\nlearning methods in brain network feature extraction, an adaptive graph\naugmentation strategy combining attribute masking and edge perturbation is\nimplemented for data enhancement. Subsequently, a dual-domain graph transformer\n(DDGformer) module is constructed to integrate local and global information,\nwhere graph convolutional networks aggregate neighborhood features to capture\nlocal patterns while attention mechanisms extract global dependencies. Finally,\na graph contrastive learning framework is established to maximize the\nconsistency between positive and negative pairs, thereby obtaining high-quality\ngraph representations. Experimental results on real-world datasets demonstrate\nthat the PHGCL-DDGformer model outperforms existing state-of-the-art approaches\nin brain network classification tasks.", "published": "2025-04-01 13:26:03", "link": "http://arxiv.org/abs/2504.03740v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute", "abstract": "This paper presents a simple, effective, and cost-efficient strategy to\nimprove LLM performance by scaling test-time compute. Our strategy builds upon\nthe repeated-sampling-then-voting framework, with a novel twist: incorporating\nmultiple models, even weaker ones, to leverage their complementary strengths\nthat potentially arise from diverse training data and paradigms. By using\nconsistency as a signal, our strategy dynamically switches between models.\nTheoretical analysis highlights the efficiency and performance advantages of\nour strategy. Extensive experiments on six datasets demonstrate that our\nstrategy not only outperforms self-consistency and state-of-the-art multi-agent\ndebate approaches, but also significantly reduces inference costs.\nAdditionally, ModelSwitch requires only a few comparable LLMs to achieve\noptimal performance and can be extended with verification methods,\ndemonstrating the potential of leveraging multiple LLMs in the\ngeneration-verification paradigm.", "published": "2025-04-01 13:13:43", "link": "http://arxiv.org/abs/2504.00762v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Knowledge-Base based Semantic Image Transmission Using CLIP", "abstract": "This paper proposes a novel knowledge-Base (KB) assisted semantic\ncommunication framework for image transmission. At the receiver, a Facebook AI\nSimilarity Search (FAISS) based vector database is constructed by extracting\nsemantic embeddings from images using the Contrastive Language-Image\nPre-Training (CLIP) model. During transmission, the transmitter first extracts\na 512-dimensional semantic feature using the CLIP model, then compresses it\nwith a lightweight neural network for transmission. After receiving the signal,\nthe receiver reconstructs the feature back to 512 dimensions and performs\nsimilarity matching from the KB to retrieve the most semantically similar\nimage. Semantic transmission success is determined by category consistency\nbetween the transmitted and retrieved images, rather than traditional metrics\nlike Peak Signal-to-Noise Ratio (PSNR). The proposed system prioritizes\nsemantic accuracy, offering a new evaluation paradigm for semantic-aware\ncommunication systems. Experimental validation on CIFAR100 demonstrates the\neffectiveness of the framework in achieving semantic image transmission.", "published": "2025-04-01 12:53:54", "link": "http://arxiv.org/abs/2504.01053v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Personality-Driven Decision-Making in LLM-Based Autonomous Agents", "abstract": "The embedding of Large Language Models (LLMs) into autonomous agents is a\nrapidly developing field which enables dynamic, configurable behaviours without\nthe need for extensive domain-specific training. In our previous work, we\nintroduced SANDMAN, a Deceptive Agent architecture leveraging the Five-Factor\nOCEAN personality model, demonstrating that personality induction significantly\ninfluences agent task planning. Building on these findings, this study presents\na novel method for measuring and evaluating how induced personality traits\naffect task selection processes - specifically planning, scheduling, and\ndecision-making - in LLM-based agents. Our results reveal distinct\ntask-selection patterns aligned with induced OCEAN attributes, underscoring the\nfeasibility of designing highly plausible Deceptive Agents for proactive cyber\ndefense strategies.", "published": "2025-04-01 12:36:28", "link": "http://arxiv.org/abs/2504.00727v1", "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.0"], "primary_category": "cs.AI"}
{"title": "Advancements in Multimodal Differential Evolution: A Comprehensive Review and Future Perspectives", "abstract": "Multi-modal optimization involves identifying multiple global and local\noptima of a function, offering valuable insights into diverse optimal solutions\nwithin the search space. Evolutionary algorithms (EAs) excel at finding\nmultiple solutions in a single run, providing a distinct advantage over\nclassical optimization techniques that often require multiple restarts without\nguarantee of obtaining diverse solutions. Among these EAs, differential\nevolution (DE) stands out as a powerful and versatile optimizer for continuous\nparameter spaces. DE has shown significant success in multi-modal optimization\nby utilizing its population-based search to promote the formation of multiple\nstable subpopulations, each targeting different optima. Recent advancements in\nDE for multi-modal optimization have focused on niching methods, parameter\nadaptation, hybridization with other algorithms including machine learning, and\napplications across various domains. Given these developments, it is an\nopportune moment to present a critical review of the latest literature and\nidentify key future research directions. This paper offers a comprehensive\noverview of recent DE advancements in multimodal optimization, including\nmethods for handling multiple optima, hybridization with EAs, and machine\nlearning, and highlights a range of real-world applications. Additionally, the\npaper outlines a set of compelling open problems and future research issues\nfrom multiple perspectives", "published": "2025-04-01 12:30:07", "link": "http://arxiv.org/abs/2504.00717v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Science Autonomy using Machine Learning for Astrobiology", "abstract": "In recent decades, artificial intelligence (AI) including machine learning\n(ML) have become vital for space missions enabling rapid data processing,\nadvanced pattern recognition, and enhanced insight extraction. These tools are\nespecially valuable in astrobiology applications, where models must distinguish\nbiotic patterns from complex abiotic backgrounds. Advancing the integration of\nautonomy through AI and ML into space missions is a complex challenge, and we\nbelieve that by focusing on key areas, we can make significant progress and\noffer practical recommendations for tackling these obstacles.", "published": "2025-04-01 12:20:18", "link": "http://arxiv.org/abs/2504.00709v1", "categories": ["astro-ph.IM", "astro-ph.EP", "cs.AI", "cs.LG"], "primary_category": "astro-ph.IM"}
{"title": "Energy Weighted Learning Progress Guided Interleaved Multi-Task Learning", "abstract": "Humans can continuously acquire new skills and knowledge by exploiting\nexisting ones for improved learning, without forgetting them. Similarly,\n'continual learning' in machine learning aims to learn new information while\npreserving the previously acquired knowledge. Existing research often overlooks\nthe nature of human learning, where tasks are interleaved due to human choice\nor environmental constraints. So, almost never do humans master one task before\nswitching to the next. To investigate to what extent human-like learning can\nbenefit the learner, we propose a method that interleaves tasks based on their\n'learning progress' and energy consumption. From a machine learning\nperspective, our approach can be seen as a multi-task learning system that\nbalances learning performance with energy constraints while mimicking\necologically realistic human task learning. To assess the validity of our\napproach, we consider a robot learning setting in simulation, where the robot\nlearns the effect of its actions in different contexts. The conducted\nexperiments show that our proposed method achieves better performance than\nsequential task learning and reduces energy consumption for learning the tasks.", "published": "2025-04-01 12:15:27", "link": "http://arxiv.org/abs/2504.00707v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "The HCI GenAI CO2ST Calculator: A Tool for Calculating the Carbon Footprint of Generative AI Use in Human-Computer Interaction Research", "abstract": "Increased usage of generative AI (GenAI) in Human-Computer Interaction (HCI)\nresearch induces a climate impact from carbon emissions due to energy\nconsumption of the hardware used to develop and run GenAI models and systems.\nThe exact energy usage and and subsequent carbon emissions are difficult to\nestimate in HCI research because HCI researchers most often use cloud-based\nservices where the hardware and its energy consumption are hidden from plain\nview. The HCI GenAI CO2ST Calculator is a tool designed specifically for the\nHCI research pipeline, to help researchers estimate the energy consumption and\ncarbon footprint of using generative AI in their research, either a priori\n(allowing for mitigation strategies or experimental redesign) or post hoc\n(allowing for transparent documentation of carbon footprint in written reports\nof the research).", "published": "2025-04-01 12:02:45", "link": "http://arxiv.org/abs/2504.00692v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Towards Adaptive AI Governance: Comparative Insights from the U.S., EU, and Asia", "abstract": "Artificial intelligence (AI) trends vary significantly across global regions,\nshaping the trajectory of innovation, regulation, and societal impact. This\nvariation influences how different regions approach AI development, balancing\ntechnological progress with ethical and regulatory considerations. This study\nconducts a comparative analysis of AI trends in the United States (US), the\nEuropean Union (EU), and Asia, focusing on three key dimensions: generative AI,\nethical oversight, and industrial applications. The US prioritizes\nmarket-driven innovation with minimal regulatory constraints, the EU enforces a\nprecautionary risk-based framework emphasizing ethical safeguards, and Asia\nemploys state-guided AI strategies that balance rapid deployment with\nregulatory oversight. Although these approaches reflect different economic\nmodels and policy priorities, their divergence poses challenges to\ninternational collaboration, regulatory harmonization, and the development of\nglobal AI standards. To address these challenges, this paper synthesizes\nregional strengths to propose an adaptive AI governance framework that\nintegrates risk-tiered oversight, innovation accelerators, and strategic\nalignment mechanisms. By bridging governance gaps, this study offers actionable\ninsights for fostering responsible AI development while ensuring a balance\nbetween technological progress, ethical imperatives, and regulatory coherence.", "published": "2025-04-01 11:05:47", "link": "http://arxiv.org/abs/2504.00652v1", "categories": ["cs.CY", "cs.AI", "cs.ET"], "primary_category": "cs.CY"}
{"title": "AI Regulation and Capitalist Growth: Balancing Innovation, Ethics, and Global Governance", "abstract": "Artificial Intelligence (AI) is increasingly central to economic growth,\npromising new efficiencies and markets. This economic significance has sparked\ndebate over AI regulation: do rules and oversight bolster long term growth by\nbuilding trust and safeguarding the public, or do they constrain innovation and\nfree enterprise? This paper examines the balance between AI regulation and\ncapitalist ideals, focusing on how different approaches to AI data privacy can\nimpact innovation in AI-driven applications. The central question is whether AI\nregulation enhances or inhibits growth in a capitalist economy. Our analysis\nsynthesizes historical precedents, the current U.S. regulatory landscape,\neconomic projections, legal challenges, and case studies of recent AI policies.\nWe discuss that carefully calibrated AI data privacy regulations-balancing\ninnovation incentives with the public interest can foster sustainable growth by\nbuilding trust and ensuring responsible data use, while excessive regulation\nmay risk stifling innovation and entrenching incumbents.", "published": "2025-04-01 10:59:02", "link": "http://arxiv.org/abs/2504.02000v1", "categories": ["cs.CY", "cs.AI", "cs.ET"], "primary_category": "cs.CY"}
{"title": "Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models", "abstract": "The accuracy and robustness of machine learning models against adversarial\nattacks are significantly influenced by factors such as training data quality,\nmodel architecture, the training process, and the deployment environment. In\nrecent years, duplicated data in training sets, especially in language models,\nhas attracted considerable attention. It has been shown that deduplication\nenhances both training performance and model accuracy in language models. While\nthe importance of data quality in training image classifier Deep Neural\nNetworks (DNNs) is widely recognized, the impact of duplicated images in the\ntraining set on model generalization and performance has received little\nattention.\n  In this paper, we address this gap and provide a comprehensive study on the\neffect of duplicates in image classification. Our analysis indicates that the\npresence of duplicated images in the training set not only negatively affects\nthe efficiency of model training but also may result in lower accuracy of the\nimage classifier. This negative impact of duplication on accuracy is\nparticularly evident when duplicated data is non-uniform across classes or when\nduplication, whether uniform or non-uniform, occurs in the training set of an\nadversarially trained model. Even when duplicated samples are selected in a\nuniform way, increasing the amount of duplication does not lead to a\nsignificant improvement in accuracy.", "published": "2025-04-01 10:48:00", "link": "http://arxiv.org/abs/2504.00638v1", "categories": ["cs.LG", "cs.AI", "eess.IV"], "primary_category": "cs.LG"}
{"title": "CNOT-Optimal Clifford Synthesis as SAT", "abstract": "Clifford circuit optimization is an important step in the quantum compilation\npipeline. Major compilers employ heuristic approaches. While they are fast,\ntheir results are often suboptimal. Minimization of noisy gates, like 2-qubit\nCNOT gates, is crucial for practical computing. Exact approaches have been\nproposed to fill the gap left by heuristic approaches. Among these are SAT\nbased approaches that optimize gate count or depth, but they suffer from\nscalability issues. Further, they do not guarantee optimality on more important\nmetrics like CNOT count or CNOT depth. A recent work proposed an exhaustive\nsearch only on Clifford circuits in a certain normal form to guarantee CNOT\ncount optimality. But an exhaustive approach cannot scale beyond 6 qubits.\n  In this paper, we incorporate search restricted to Clifford normal forms in a\nSAT encoding to guarantee CNOT count optimality. By allowing parallel plans, we\npropose a second SAT encoding that optimizes CNOT depth. By taking advantage of\nflexibility in SAT based approaches, we also handle connectivity restrictions\nin hardware platforms, and allow for qubit relabeling. We have implemented the\nabove encodings and variations in our open source tool Q-Synth.\n  In experiments, our encodings significantly outperform existing SAT\napproaches on random Clifford circuits. We consider practical VQE and Feynman\nbenchmarks to compare with TKET and Qiskit compilers. In all-to-all\nconnectivity, we observe reductions up to 32.1% in CNOT count and 48.1% in CNOT\ndepth. Overall, we observe better results than TKET in the CNOT count and\ndepth. We also experiment with connectivity restrictions of major quantum\nplatforms. Compared to Qiskit, we observe up to 30.3% CNOT count and 35.9% CNOT\ndepth further reduction.", "published": "2025-04-01 10:35:58", "link": "http://arxiv.org/abs/2504.00634v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Feature Subset Weighting for Distance-based Supervised Learning through Choquet Integration", "abstract": "This paper introduces feature subset weighting using monotone measures for\ndistance-based supervised learning. The Choquet integral is used to define a\ndistance metric that incorporates these weights. This integration enables the\nproposed distances to effectively capture non-linear relationships and account\nfor interactions both between conditional and decision attributes and among\nconditional attributes themselves, resulting in a more flexible distance\nmeasure. In particular, we show how this approach ensures that the distances\nremain unaffected by the addition of duplicate and strongly correlated\nfeatures. Another key point of this approach is that it makes feature subset\nweighting computationally feasible, since only $m$ feature subset weights\nshould be calculated each time instead of calculating all feature subset\nweights ($2^m$), where $m$ is the number of attributes. Next, we also examine\nhow the use of the Choquet integral for measuring similarity leads to a\nnon-equivalent definition of distance. The relationship between distance and\nsimilarity is further explored through dual measures. Additionally, symmetric\nChoquet distances and similarities are proposed, preserving the classical\nsymmetry between similarity and distance. Finally, we introduce a concrete\nfeature subset weighting distance, evaluate its performance in a $k$-nearest\nneighbors (KNN) classification setting, and compare it against Mahalanobis\ndistances and weighted distance methods.", "published": "2025-04-01 10:23:01", "link": "http://arxiv.org/abs/2504.00624v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Responsible and Trustworthy Educational Data Mining: Comparing Symbolic, Sub-Symbolic, and Neural-Symbolic AI Methods", "abstract": "Given the demand for responsible and trustworthy AI for education, this study\nevaluates symbolic, sub-symbolic, and neural-symbolic AI (NSAI) in terms of\ngeneralizability and interpretability. Our extensive experiments on balanced\nand imbalanced self-regulated learning datasets of Estonian primary school\nstudents predicting 7th-grade mathematics national test performance showed that\nsymbolic and sub-symbolic methods performed well on balanced data but struggled\nto identify low performers in imbalanced datasets. Interestingly, symbolic and\nsub-symbolic methods emphasized different factors in their decision-making:\nsymbolic approaches primarily relied on cognitive and motivational factors,\nwhile sub-symbolic methods focused more on cognitive aspects, learned\nknowledge, and the demographic variable of gender -- yet both largely\noverlooked metacognitive factors. The NSAI method, on the other hand, showed\nadvantages by: (i) being more generalizable across both classes -- even in\nimbalanced datasets -- as its symbolic knowledge component compensated for the\nunderrepresented class; and (ii) relying on a more integrated set of factors in\nits decision-making, including motivation, (meta)cognition, and learned\nknowledge, thus offering a comprehensive and theoretically grounded\ninterpretability framework. These contrasting findings highlight the need for a\nholistic comparison of AI methods before drawing conclusions based solely on\npredictive performance. They also underscore the potential of hybrid,\nhuman-centered NSAI methods to address the limitations of other AI families and\nmove us closer to responsible AI for education. Specifically, by enabling\nstakeholders to contribute to AI design, NSAI aligns learned patterns with\ntheoretical constructs, incorporates factors like motivation and metacognition,\nand strengthens the trustworthiness and responsibility of educational data\nmining.", "published": "2025-04-01 10:14:11", "link": "http://arxiv.org/abs/2504.00615v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLM-Guided Search for Deletion-Correcting Codes", "abstract": "Finding deletion-correcting codes of maximum size has been an open problem\nfor over 70 years, even for a single deletion. In this paper, we propose a\nnovel approach for constructing deletion-correcting codes. A code is a set of\nsequences satisfying certain constraints, and we construct it by greedily\nadding the highest-priority sequence according to a priority function. To find\ngood priority functions, we leverage FunSearch, a large language model\n(LLM)-guided evolutionary search proposed by Romera et al., 2024. FunSearch\niteratively generates, evaluates, and refines priority functions to construct\nlarge deletion-correcting codes. For a single deletion, our evolutionary search\nfinds functions that construct codes which match known maximum sizes, reach the\nsize of the largest (conjectured optimal) Varshamov-Tenengolts codes where the\nmaximum is unknown, and independently rediscover them in equivalent form. For\ntwo deletions, we find functions that construct codes with new best-known sizes\nfor code lengths \\( n = 12, 13 \\), and \\( 16 \\), establishing improved lower\nbounds. These results demonstrate the potential of LLM-guided search for\ninformation theory and code design and represent the first application of such\nmethods for constructing error-correcting codes.", "published": "2025-04-01 10:11:32", "link": "http://arxiv.org/abs/2504.00613v1", "categories": ["cs.AI", "cs.IT", "cs.NE", "math.IT"], "primary_category": "cs.AI"}
{"title": "PLM4NDV: Minimizing Data Access for Number of Distinct Values Estimation with Pre-trained Language Models", "abstract": "Number of Distinct Values (NDV) estimation of a multiset/column is a basis\nfor many data management tasks, especially within databases. Despite decades of\nresearch, most existing methods require either a significant amount of samples\nthrough uniform random sampling or access to the entire column to produce\nestimates, leading to substantial data access costs and potentially ineffective\nestimations in scenarios with limited data access. In this paper, we propose\nleveraging semantic information, i.e., schema, to address these challenges. The\nschema contains rich semantic information that can benefit the NDV estimation.\nTo this end, we propose PLM4NDV, a learned method incorporating Pre-trained\nLanguage Models (PLMs) to extract semantic schema information for NDV\nestimation. Specifically, PLM4NDV leverages the semantics of the target column\nand the corresponding table to gain a comprehensive understanding of the\ncolumn's meaning. By using the semantics, PLM4NDV reduces data access costs,\nprovides accurate NDV estimation, and can even operate effectively without any\ndata access. Extensive experiments on a large-scale real-world dataset\ndemonstrate the superiority of PLM4NDV over baseline methods. Our code is\navailable at https://github.com/bytedance/plm4ndv.", "published": "2025-04-01 10:06:20", "link": "http://arxiv.org/abs/2504.00608v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Data Cleansing for GANs", "abstract": "As the application of generative adversarial networks (GANs) expands, it\nbecomes increasingly critical to develop a unified approach that improves\nperformance across various generative tasks. One effective strategy that\napplies to any machine learning task is identifying harmful instances, whose\nremoval improves the performance. While previous studies have successfully\nestimated these harmful training instances in supervised settings, their\napproaches are not easily applicable to GANs. The challenge lies in two\nrequirements of the previous approaches that do not apply to GANs. First,\nprevious approaches require that the absence of a training instance directly\naffects the parameters. However, in the training for GANs, the instances do not\ndirectly affect the generator's parameters since they are only fed into the\ndiscriminator. Second, previous approaches assume that the change in loss\ndirectly quantifies the harmfulness of the instance to a model's performance,\nwhile common types of GAN losses do not always reflect the generative\nperformance. To overcome the first challenge, we propose influence estimation\nmethods that use the Jacobian of the generator's gradient with respect to the\ndiscriminator's parameters (and vice versa). Such a Jacobian represents the\nindirect effect between two models: how removing an instance from the\ndiscriminator's training changes the generator's parameters. Second, we propose\nan instance evaluation scheme that measures the harmfulness of each training\ninstance based on how a GAN evaluation metric (e.g., Inception score) is\nexpected to change by the instance's removal. Furthermore, we demonstrate that\nremoving the identified harmful instances significantly improves the generative\nperformance on various GAN evaluation metrics.", "published": "2025-04-01 10:02:37", "link": "http://arxiv.org/abs/2504.00603v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Attention in Diffusion Model: A Survey", "abstract": "Attention mechanisms have become a foundational component in diffusion\nmodels, significantly influencing their capacity across a wide range of\ngenerative and discriminative tasks. This paper presents a comprehensive survey\nof attention within diffusion models, systematically analysing its roles,\ndesign patterns, and operations across different modalities and tasks. We\npropose a unified taxonomy that categorises attention-related modifications\ninto parts according to the structural components they affect, offering a clear\nlens through which to understand their functional diversity. In addition to\nreviewing architectural innovations, we examine how attention mechanisms\ncontribute to performance improvements in diverse applications. We also\nidentify current limitations and underexplored areas, and outline potential\ndirections for future research. Our study provides valuable insights into the\nevolving landscape of diffusion models, with a particular focus on the\nintegrative and ubiquitous role of attention.", "published": "2025-04-01 09:00:49", "link": "http://arxiv.org/abs/2504.03738v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "High-Quality Pseudo-Label Generation Based on Visual Prompt Assisted Cloud Model Update", "abstract": "Generating high-quality pseudo-labels on the cloud is crucial for cloud-edge\nobject detection, especially in dynamic traffic monitoring where data\ndistributions evolve. Existing methods often assume reliable cloud models,\nneglecting potential errors or struggling with complex distribution shifts.\nThis paper proposes Cloud-Adaptive High-Quality Pseudo-label generation\n(CA-HQP), addressing these limitations by incorporating a learnable Visual\nPrompt Generator (VPG) and dual feature alignment into cloud model updates. The\nVPG enables parameter-efficient adaptation by injecting visual prompts,\nenhancing flexibility without extensive fine-tuning. CA-HQP mitigates domain\ndiscrepancies via two feature alignment techniques: global Domain Query Feature\nAlignment (DQFA) capturing scene-level shifts, and fine-grained Temporal\nInstance-Aware Feature Embedding Alignment (TIAFA) addressing instance\nvariations. Experiments on the Bellevue traffic dataset demonstrate that CA-HQP\nsignificantly improves pseudo-label quality compared to existing methods,\nleading to notable performance gains for the edge model and showcasing CA-HQP's\nadaptation effectiveness. Ablation studies validate each component (DQFA,\nTIAFA, VPG) and the synergistic effect of combined alignment strategies,\nhighlighting the importance of adaptive cloud updates and domain adaptation for\nrobust object detection in evolving scenarios. CA-HQP provides a promising\nsolution for enhancing cloud-edge object detection systems in real-world\napplications.", "published": "2025-04-01 08:20:16", "link": "http://arxiv.org/abs/2504.00526v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Automated detection of atomicity violations in large-scale systems", "abstract": "Atomicity violations in interrupt-driven programs pose a significant threat\nto software safety in critical systems. These violations occur when the\nexecution sequence of operations on shared resources is disrupted by\nasynchronous interrupts. Detecting atomicity violations is challenging due to\nthe vast program state space, application-level code dependencies, and complex\ndomain-specific knowledge. We propose Clover, a hybrid framework that\nintegrates static analysis with large language model (LLM) agents to detect\natomicity violations in real-world programs. Clover first performs static\nanalysis to extract critical code snippets and operation information. It then\ninitiates a multi-agent process, where the expert agent leverages\ndomain-specific knowledge to detect atomicity violations, which are\nsubsequently validated by the judge agent. Evaluations on RaceBench 2.1,\nSV-COMP, and RWIP demonstrate that Clover achieves a precision/recall of\n92.3%/86.6%, outperforming existing approaches by 27.4-118.2% on F1-score.", "published": "2025-04-01 08:13:29", "link": "http://arxiv.org/abs/2504.00521v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Training Frozen Feature Pyramid DINOv2 for Eyelid Measurements with Infinite Encoding and Orthogonal Regularization", "abstract": "Accurate measurement of eyelid parameters such as Margin Reflex Distances\n(MRD1, MRD2) and Levator Function (LF) is critical in oculoplastic diagnostics\nbut remains limited by manual, inconsistent methods. This study evaluates deep\nlearning models: SE-ResNet, EfficientNet, and the vision transformer-based\nDINOv2 for automating these measurements using smartphone-acquired images. We\nassess performance across frozen and fine-tuned settings, using MSE, MAE, and\nR2 metrics. DINOv2, pretrained through self-supervised learning, demonstrates\nsuperior scalability and robustness, especially under frozen conditions ideal\nfor mobile deployment. Lightweight regressors such as MLP and Deep Ensemble\noffer high precision with minimal computational overhead. To address class\nimbalance and improve generalization, we integrate focal loss, orthogonal\nregularization, and binary encoding strategies. Our results show that DINOv2\ncombined with these enhancements delivers consistent, accurate predictions\nacross all tasks, making it a strong candidate for real-world, mobile-friendly\nclinical applications. This work highlights the potential of foundation models\nin advancing AI-powered ophthalmic care.", "published": "2025-04-01 08:06:08", "link": "http://arxiv.org/abs/2504.00515v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Operator Learning with Domain Decomposition for Geometry Generalization in PDE Solving", "abstract": "Neural operators have become increasingly popular in solving \\textit{partial\ndifferential equations} (PDEs) due to their superior capability to capture\nintricate mappings between function spaces over complex domains. However, the\ndata-hungry nature of operator learning inevitably poses a bottleneck for their\nwidespread applications. At the core of the challenge lies the absence of\ntransferability of neural operators to new geometries. To tackle this issue, we\npropose operator learning with domain decomposition, a local-to-global\nframework to solve PDEs on arbitrary geometries. Under this framework, we\ndevise an iterative scheme \\textit{Schwarz Neural Inference} (SNI). This scheme\nallows for partitioning of the problem domain into smaller subdomains, on which\nlocal problems can be solved with neural operators, and stitching local\nsolutions to construct a global solution. Additionally, we provide a\ntheoretical analysis of the convergence rate and error bound. We conduct\nextensive experiments on several representative PDEs with diverse boundary\nconditions and achieve remarkable geometry generalization compared to\nalternative methods. These analysis and experiments demonstrate the proposed\nframework's potential in addressing challenges related to geometry\ngeneralization and data efficiency.", "published": "2025-04-01 08:00:43", "link": "http://arxiv.org/abs/2504.00510v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhancing stroke disease classification through machine learning models via a novel voting system by feature selection techniques", "abstract": "Heart disease remains a leading cause of mortality and morbidity worldwide,\nnecessitating the development of accurate and reliable predictive models to\nfacilitate early detection and intervention. While state of the art work has\nfocused on various machine learning approaches for predicting heart disease,\nbut they could not able to achieve remarkable accuracy. In response to this\nneed, we applied nine machine learning algorithms XGBoost, logistic regression,\ndecision tree, random forest, k-nearest neighbors (KNN), support vector machine\n(SVM), gaussian na\\\"ive bayes (NB gaussian), adaptive boosting, and linear\nregression to predict heart disease based on a range of physiological\nindicators. Our approach involved feature selection techniques to identify the\nmost relevant predictors, aimed at refining the models to enhance both\nperformance and interpretability. The models were trained, incorporating\nprocesses such as grid search hyperparameter tuning, and cross-validation to\nminimize overfitting. Additionally, we have developed a novel voting system\nwith feature selection techniques to advance heart disease classification.\nFurthermore, we have evaluated the models using key performance metrics\nincluding accuracy, precision, recall, F1-score, and the area under the\nreceiver operating characteristic curve (ROC AUC). Among the models, XGBoost\ndemonstrated exceptional performance, achieving 99% accuracy, precision,\nF1-Score, 98% recall, and 100% ROC AUC. This study offers a promising approach\nto early heart disease diagnosis and preventive healthcare.", "published": "2025-04-01 07:16:49", "link": "http://arxiv.org/abs/2504.00485v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Uncertainty Propagation in XAI: A Comparison of Analytical and Empirical Estimators", "abstract": "Understanding uncertainty in Explainable AI (XAI) is crucial for building\ntrust and ensuring reliable decision-making in Machine Learning models. This\npaper introduces a unified framework for quantifying and interpreting\nUncertainty in XAI by defining a general explanation function $e_{\\theta}(x,\nf)$ that captures the propagation of uncertainty from key sources:\nperturbations in input data and model parameters. By using both analytical and\nempirical estimates of explanation variance, we provide a systematic means of\nassessing the impact uncertainty on explanations. We illustrate the approach\nusing a first-order uncertainty propagation as the analytical estimator. In a\ncomprehensive evaluation across heterogeneous datasets, we compare analytical\nand empirical estimates of uncertainty propagation and evaluate their\nrobustness. Extending previous work on inconsistencies in explanations, our\nexperiments identify XAI methods that do not reliably capture and propagate\nuncertainty. Our findings underscore the importance of uncertainty-aware\nexplanations in high-stakes applications and offer new insights into the\nlimitations of current XAI methods. The code for the experiments can be found\nin our repository at https://github.com/TeodorChiaburu/UXAI", "published": "2025-04-01 07:06:31", "link": "http://arxiv.org/abs/2504.03736v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Learning-Based Approximate Nonlinear Model Predictive Control Motion Cueing", "abstract": "Motion Cueing Algorithms (MCAs) encode the movement of simulated vehicles\ninto movement that can be reproduced with a motion simulator to provide a\nrealistic driving experience within the capabilities of the machine. This paper\nintroduces a novel learning-based MCA for serial robot-based motion simulators.\nBuilding on the differentiable predictive control framework, the proposed\nmethod merges the advantages of Nonlinear Model Predictive Control (NMPC) -\nnotably nonlinear constraint handling and accurate kinematic modeling - with\nthe computational efficiency of machine learning. By shifting the computational\nburden to offline training, the new algorithm enables real-time operation at\nhigh control rates, thus overcoming the key challenge associated with\nNMPC-based motion cueing. The proposed MCA incorporates a nonlinear joint-space\nplant model and a policy network trained to mimic NMPC behavior while\naccounting for joint acceleration, velocity, and position limits. Simulation\nexperiments across multiple motion cueing scenarios showed that the proposed\nalgorithm performed on par with a state-of-the-art NMPC-based alternative in\nterms of motion cueing quality as quantified by the RMSE and correlation\ncoefficient with respect to reference signals. However, the proposed algorithm\nwas on average 400 times faster than the NMPC baseline. In addition, the\nalgorithm successfully generalized to unseen operating conditions, including\nmotion cueing scenarios on a different vehicle and real-time physics-based\nsimulations.", "published": "2025-04-01 06:52:30", "link": "http://arxiv.org/abs/2504.00469v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "MetaLoRA: Tensor-Enhanced Adaptive Low-Rank Fine-tuning", "abstract": "There has been a significant increase in the deployment of neural network\nmodels, presenting substantial challenges in model adaptation and fine-tuning.\nEfficient adaptation is crucial in maintaining model performance across diverse\ntasks and domains. While Low-Rank Adaptation (LoRA) has emerged as a promising\nparameter-efficient fine-tuning method, its fixed parameter nature limits its\nability to handle dynamic task requirements effectively. Adapting models to new\ntasks can be challenging due to the need for extensive fine-tuning. Current\nLoRA variants primarily focus on general parameter reduction while overlooking\nthe importance of dynamic parameter adjustment and meta-learning capabilities.\nMoreover, existing approaches mainly address static adaptations, neglecting the\npotential benefits of task-aware parameter generation in handling diverse task\ndistributions. To address these limitations, this Ph.D. research proposes a\nLoRA generation approach to model task relationships and introduces MetaLoRA, a\nnovel parameter-efficient adaptation framework incorporating meta-learning\nprinciples. This work develops a comprehensive architecture that integrates\nmeta-parameter generation with adaptive low-rank decomposition, enabling\nefficient handling of both task-specific and task-agnostic features. MetaLoRA\naccurately captures task patterns by incorporating meta-learning mechanisms and\ndynamic parameter adjustment strategies. To our knowledge, this research\nrepresents the first attempt to provide a meta-learning enhanced LoRA variant,\noffering improved adaptation capability while maintaining computational\nefficiency in model fine-tuning.", "published": "2025-04-01 06:34:26", "link": "http://arxiv.org/abs/2504.00460v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Distilling Multi-view Diffusion Models into 3D Generators", "abstract": "We introduce DD3G, a formulation that Distills a multi-view Diffusion model\n(MV-DM) into a 3D Generator using gaussian splatting. DD3G compresses and\nintegrates extensive visual and spatial geometric knowledge from the MV-DM by\nsimulating its ordinary differential equation (ODE) trajectory, ensuring the\ndistilled generator generalizes better than those trained solely on 3D data.\nUnlike previous amortized optimization approaches, we align the MV-DM and 3D\ngenerator representation spaces to transfer the teacher's probabilistic flow to\nthe student, thus avoiding inconsistencies in optimization objectives caused by\nprobabilistic sampling. The introduction of probabilistic flow and the coupling\nof various attributes in 3D Gaussians introduce challenges in the generation\nprocess. To tackle this, we propose PEPD, a generator consisting of Pattern\nExtraction and Progressive Decoding phases, which enables efficient fusion of\nprobabilistic flow and converts a single image into 3D Gaussians within 0.06\nseconds. Furthermore, to reduce knowledge loss and overcome sparse-view\nsupervision, we design a joint optimization objective that ensures the quality\nof generated samples through explicit supervision and implicit verification.\nLeveraging existing 2D generation models, we compile 120k high-quality RGBA\nimages for distillation. Experiments on synthetic and public datasets\ndemonstrate the effectiveness of our method. Our project is available at:\nhttps://qinbaigao.github.io/DD3G_project/", "published": "2025-04-01 06:32:48", "link": "http://arxiv.org/abs/2504.00457v3", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "No Free Lunch with Guardrails", "abstract": "As large language models (LLMs) and generative AI become widely adopted,\nguardrails have emerged as a key tool to ensure their safe use. However, adding\nguardrails isn't without tradeoffs; stronger security measures can reduce\nusability, while more flexible systems may leave gaps for adversarial attacks.\nIn this work, we explore whether current guardrails effectively prevent misuse\nwhile maintaining practical utility. We introduce a framework to evaluate these\ntradeoffs, measuring how different guardrails balance risk, security, and\nusability, and build an efficient guardrail.\n  Our findings confirm that there is no free lunch with guardrails;\nstrengthening security often comes at the cost of usability. To address this,\nwe propose a blueprint for designing better guardrails that minimize risk while\nmaintaining usability. We evaluate various industry guardrails, including Azure\nContent Safety, Bedrock Guardrails, OpenAI's Moderation API, Guardrails AI,\nNemo Guardrails, and Enkrypt AI guardrails. Additionally, we assess how LLMs\nlike GPT-4o, Gemini 2.0-Flash, Claude 3.5-Sonnet, and Mistral Large-Latest\nrespond under different system prompts, including simple prompts, detailed\nprompts, and detailed prompts with chain-of-thought (CoT) reasoning. Our study\nprovides a clear comparison of how different guardrails perform, highlighting\nthe challenges in balancing security and usability.", "published": "2025-04-01 05:46:54", "link": "http://arxiv.org/abs/2504.00441v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Suite-IN++: A FlexiWear BodyNet Integrating Global and Local Motion Features from Apple Suite for Robust Inertial Navigation", "abstract": "The proliferation of wearable technology has established multi-device\necosystems comprising smartphones, smartwatches, and headphones as critical\nenablers for ubiquitous pedestrian localization. However, traditional\npedestrian dead reckoning (PDR) struggles with diverse motion modes, while\ndata-driven methods, despite improving accuracy, often lack robustness due to\ntheir reliance on a single-device setup. Therefore, a promising solution is to\nfully leverage existing wearable devices to form a flexiwear bodynet for robust\nand accurate pedestrian localization. This paper presents Suite-IN++, a deep\nlearning framework for flexiwear bodynet-based pedestrian localization.\nSuite-IN++ integrates motion data from wearable devices on different body\nparts, using contrastive learning to separate global and local motion features.\nIt fuses global features based on the data reliability of each device to\ncapture overall motion trends and employs an attention mechanism to uncover\ncross-device correlations in local features, extracting motion details helpful\nfor accurate localization. To evaluate our method, we construct a real-life\nflexiwear bodynet dataset, incorporating Apple Suite (iPhone, Apple Watch, and\nAirPods) across diverse walking modes and device configurations. Experimental\nresults demonstrate that Suite-IN++ achieves superior localization accuracy and\nrobustness, significantly outperforming state-of-the-art models in real-life\npedestrian tracking scenarios.", "published": "2025-04-01 05:40:52", "link": "http://arxiv.org/abs/2504.00438v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLM-Assisted Proactive Threat Intelligence for Automated Reasoning", "abstract": "Successful defense against dynamically evolving cyber threats requires\nadvanced and sophisticated techniques. This research presents a novel approach\nto enhance real-time cybersecurity threat detection and response by integrating\nlarge language models (LLMs) and Retrieval-Augmented Generation (RAG) systems\nwith continuous threat intelligence feeds. Leveraging recent advancements in\nLLMs, specifically GPT-4o, and the innovative application of RAG techniques,\nour approach addresses the limitations of traditional static threat analysis by\nincorporating dynamic, real-time data sources. We leveraged RAG to get the\nlatest information in real-time for threat intelligence, which is not possible\nin the existing GPT-4o model. We employ the Patrowl framework to automate the\nretrieval of diverse cybersecurity threat intelligence feeds, including Common\nVulnerabilities and Exposures (CVE), Common Weakness Enumeration (CWE), Exploit\nPrediction Scoring System (EPSS), and Known Exploited Vulnerabilities (KEV)\ndatabases, and integrate these with the all-mpnet-base-v2 model for\nhigh-dimensional vector embeddings, stored and queried in Milvus. We\ndemonstrate our system's efficacy through a series of case studies, revealing\nsignificant improvements in addressing recently disclosed vulnerabilities,\nKEVs, and high-EPSS-score CVEs compared to the baseline GPT-4o. This work not\nonly advances the role of LLMs in cybersecurity but also establishes a robust\nfoundation for the development of automated intelligent cyberthreat information\nmanagement systems, addressing crucial gaps in current cybersecurity practices.", "published": "2025-04-01 05:19:33", "link": "http://arxiv.org/abs/2504.00428v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Hawkeye:Efficient Reasoning with Model Collaboration", "abstract": "Chain-of-Thought (CoT) reasoning has demonstrated remarkable effectiveness in\nenhancing the reasoning abilities of large language models (LLMs). However, its\nefficiency remains a challenge due to the generation of excessive intermediate\nreasoning tokens, which introduce semantic redundancy and overly detailed\nreasoning steps. Moreover, computational expense and latency are significant\nconcerns, as the cost scales with the number of output tokens, including those\nintermediate steps. In this work, we observe that most CoT tokens are\nunnecessary, and retaining only a small portion of them is sufficient for\nproducing high-quality responses. Inspired by this, we propose HAWKEYE, a novel\npost-training and inference framework where a large model produces concise CoT\ninstructions to guide a smaller model in response generation. HAWKEYE\nquantifies redundancy in CoT reasoning and distills high-density information\nvia reinforcement learning. By leveraging these concise CoTs, HAWKEYE is able\nto expand responses while reducing token usage and computational cost\nsignificantly. Our evaluation shows that HAWKEYE can achieve comparable\nresponse quality using only 35% of the full CoTs, while improving clarity,\ncoherence, and conciseness by approximately 10%. Furthermore, HAWKEYE can\naccelerate end-to-end reasoning by up to 3.4x on complex math tasks while\nreducing inference cost by up to 60%. HAWKEYE will be open-sourced and the\nmodels will be available soon.", "published": "2025-04-01 05:09:04", "link": "http://arxiv.org/abs/2504.00424v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Predicting Movie Production Years through Facial Recognition of Actors with Machine Learning", "abstract": "This study used machine learning algorithms to identify actors and extract\nthe age of actors from images taken randomly from movies. The use of images\ntaken from Arab movies includes challenges such as non-uniform lighting,\ndifferent and multiple poses for the actors and multiple elements with the\nactor or a group of actors. Additionally, the use of make-up, wigs, beards, and\nwearing different accessories and costumes made it difficult for the system to\nidentify the personality of the same actor. The Arab Actors Dataset-AAD\ncomprises 574 images sourced from various movies, encompassing both black and\nwhite as well as color compositions. The images depict complete scenes or\nfragments thereof. Multiple models were employed for feature extraction, and\ndiverse machine learning algorithms were utilized during the classification and\nprediction stages to determine the most effective algorithm for handling such\nimage types. The study demonstrated the effectiveness of the Logistic\nRegression model exhibited the best performance compared to other models in the\ntraining phase, as evidenced by its AUC, precision, CA and F1score values of\n99%, 86%, 85.5% and 84.2% respectively. The findings of this study can be used\nto improve the precision and reliability of facial recognition technology for\nvarious uses as with movies search services, movie suggestion algorithms, and\ngenre classification of movies.", "published": "2025-04-01 04:46:05", "link": "http://arxiv.org/abs/2504.01047v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Intuition to Understanding: Using AI Peers to Overcome Physics Misconceptions", "abstract": "Generative AI has the potential to transform personalization and\naccessibility of education. However, it raises serious concerns about accuracy\nand helping students become independent critical thinkers. In this study, we\ndesigned a helpful AI \"Peer\" to help students correct fundamental physics\nmisconceptions related to Newtonian mechanic concepts. In contrast to\napproaches that seek near-perfect accuracy to create an authoritative AI tutor\nor teacher, we directly inform students that this AI can answer up to 40% of\nquestions incorrectly. In a randomized controlled trial with 165 students,\nthose who engaged in targeted dialogue with the AI Peer achieved post-test\nscores that were, on average, 10.5 percentage points higher - with over 20\npercentage points higher normalized gain - than a control group that discussed\nphysics history. Qualitative feedback indicated that 91% of the treatment\ngroup's AI interactions were rated as helpful. Furthermore, by comparing\nstudent performance on pre- and post-test questions about the same concept,\nalong with experts' annotations of the AI interactions, we find initial\nevidence suggesting the improvement in performance does not depend on the\ncorrectness of the AI. With further research, the AI Peer paradigm described\nhere could open new possibilities for how we learn, adapt to, and grow with AI.", "published": "2025-04-01 04:09:13", "link": "http://arxiv.org/abs/2504.00408v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Beyond Wide-Angle Images: Unsupervised Video Portrait Correction via Spatiotemporal Diffusion Adaptation", "abstract": "Wide-angle cameras, despite their popularity for content creation, suffer\nfrom distortion-induced facial stretching-especially at the edge of the\nlens-which degrades visual appeal. To address this issue, we propose an image\nportrait correction framework using diffusion models named ImagePD. It\nintegrates the long-range awareness of transformer and multi-step denoising of\ndiffusion models into a unified framework, achieving global structural\nrobustness and local detail refinement. Besides, considering the high cost of\nobtaining video labels, we then repurpose ImagePD for unlabeled wide-angle\nvideos (termed VideoPD), by spatiotemporal diffusion adaption with spatial\nconsistency and temporal smoothness constraints. For the former, we encourage\nthe denoised image to approximate pseudo labels following the wide-angle\ndistortion distribution pattern, while for the latter, we derive rectification\ntrajectories with backward optical flows and smooth them. Compared with\nImagePD, VideoPD maintains high-quality facial corrections in space and\nmitigates the potential temporal shakes sequentially. Finally, to establish an\nevaluation benchmark and train the framework, we establish a video portrait\ndataset with a large diversity in people number, lighting conditions, and\nbackground. Experiments demonstrate that the proposed methods outperform\nexisting solutions quantitatively and qualitatively, contributing to\nhigh-fidelity wide-angle videos with stable and natural portraits. The codes\nand dataset will be available.", "published": "2025-04-01 03:49:59", "link": "http://arxiv.org/abs/2504.00401v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CyberBOT: Towards Reliable Cybersecurity Education via Ontology-Grounded Retrieval Augmented Generation", "abstract": "Advancements in large language models (LLMs) have enabled the development of\nintelligent educational tools that support inquiry-based learning across\ntechnical domains. In cybersecurity education, where accuracy and safety are\nparamount, systems must go beyond surface-level relevance to provide\ninformation that is both trustworthy and domain-appropriate. To address this\nchallenge, we introduce CyberBOT, a question-answering chatbot that leverages a\nretrieval-augmented generation (RAG) pipeline to incorporate contextual\ninformation from course-specific materials and validate responses using a\ndomain-specific cybersecurity ontology. The ontology serves as a structured\nreasoning layer that constrains and verifies LLM-generated answers, reducing\nthe risk of misleading or unsafe guidance. CyberBOT has been deployed in a\nlarge graduate-level course at Arizona State University (ASU), where more than\none hundred students actively engage with the system through a dedicated\nweb-based platform. Computational evaluations in lab environments highlight the\npotential capacity of CyberBOT, and a forthcoming field study will evaluate its\npedagogical impact. By integrating structured domain reasoning with modern\ngenerative capabilities, CyberBOT illustrates a promising direction for\ndeveloping reliable and curriculum-aligned AI applications in specialized\neducational contexts.", "published": "2025-04-01 03:19:22", "link": "http://arxiv.org/abs/2504.00389v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation", "abstract": "Recent advances in zero-shot referring image segmentation (RIS), driven by\nmodels such as the Segment Anything Model (SAM) and CLIP, have made substantial\nprogress in aligning visual and textual information. Despite these successes,\nthe extraction of precise and high-quality mask region representations remains\na critical challenge, limiting the full potential of RIS tasks. In this paper,\nwe introduce a training-free, hybrid global-local feature extraction approach\nthat integrates detailed mask-specific features with contextual information\nfrom the surrounding area, enhancing mask region representation. To further\nstrengthen alignment between mask regions and referring expressions, we propose\na spatial guidance augmentation strategy that improves spatial coherence, which\nis essential for accurately localizing described areas. By incorporating\nmultiple spatial cues, this approach facilitates more robust and precise\nreferring segmentation. Extensive experiments on standard RIS benchmarks\ndemonstrate that our method significantly outperforms existing zero-shot RIS\nmodels, achieving substantial performance gains. We believe our approach\nadvances RIS tasks and establishes a versatile framework for region-text\nalignment, offering broader implications for cross-modal understanding and\ninteraction. Code is available at https://github.com/fhgyuanshen/HybridGL .", "published": "2025-04-01 02:13:39", "link": "http://arxiv.org/abs/2504.00356v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Artificial Geographically Weighted Neural Network: A Novel Framework for Spatial Analysis with Geographically Weighted Layers", "abstract": "Geographically Weighted Regression (GWR) is a widely recognized technique for\nmodeling spatial heterogeneity. However, it is commonly assumed that the\nrelationships between dependent and independent variables are linear. To\novercome this limitation, we propose an Artificial Geographically Weighted\nNeural Network (AGWNN), a novel framework that integrates geographically\nweighted techniques with neural networks to capture complex nonlinear spatial\nrelationships. Central to this framework is the Geographically Weighted Layer\n(GWL), a specialized component designed to encode spatial heterogeneity within\nthe neural network architecture. To rigorously evaluate the performance of\nAGWNN, we conducted comprehensive experiments using both simulated datasets and\nreal-world case studies. Our results demonstrate that AGWNN significantly\noutperforms traditional GWR and standard Artificial Neural Networks (ANNs) in\nterms of model fitting accuracy. Notably, AGWNN excels in modeling intricate\nnonlinear relationships and effectively identifies complex spatial\nheterogeneity patterns, offering a robust and versatile tool for advanced\nspatial analysis.", "published": "2025-04-01 01:48:46", "link": "http://arxiv.org/abs/2504.03734v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments", "abstract": "The Open Radio Access Network (O-RAN) architecture is reshaping\ntelecommunications by promoting openness, flexibility, and intelligent\nclosed-loop optimization. By decoupling hardware and software and enabling\nmulti-vendor deployments, O-RAN reduces costs, enhances performance, and allows\nrapid adaptation to new technologies. A key innovation is intelligent network\nslicing, which partitions networks into isolated slices tailored for specific\nuse cases or quality of service requirements. The RAN Intelligent Controller\nfurther optimizes resource allocation, ensuring efficient utilization and\nimproved service quality for user equipment (UEs). However, the modular and\ndynamic nature of O-RAN expands the threat surface, necessitating advanced\nsecurity measures to maintain network integrity, confidentiality, and\navailability. Intrusion detection systems have become essential for identifying\nand mitigating attacks. This research explores using large language models\n(LLMs) to generate security recommendations based on the temporal traffic\npatterns of connected UEs. The paper introduces an LLM-driven intrusion\ndetection framework and demonstrates its efficacy through experimental\ndeployments, comparing non fine-tuned and fine-tuned models for task-specific\naccuracy.", "published": "2025-04-01 01:45:07", "link": "http://arxiv.org/abs/2504.00341v1", "categories": ["cs.CR", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.CR"}
{"title": "Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework", "abstract": "The growing use of foundation models (FMs) in real-world applications demands\nadaptive, reliable, and efficient strategies for dynamic markets. In the\nchemical industry, AI-discovered materials drive innovation, but commercial\nsuccess hinges on market adoption, requiring FM-driven advertising frameworks\nthat operate in-the-wild. We present a multilingual, multimodal AI framework\nfor autonomous, hyper-personalized advertising in B2B and B2C markets. By\nintegrating retrieval-augmented generation (RAG), multimodal reasoning, and\nadaptive persona-based targeting, our system generates culturally relevant,\nmarket-aware ads tailored to shifting consumer behaviors and competition.\nValidation combines real-world product experiments with a Simulated Humanistic\nColony of Agents to model consumer personas, optimize strategies at scale, and\nensure privacy compliance. Synthetic experiments mirror real-world scenarios,\nenabling cost-effective testing of ad strategies without risky A/B tests.\nCombining structured retrieval-augmented reasoning with in-context learning\n(ICL), the framework boosts engagement, prevents market cannibalization, and\nmaximizes ROAS. This work bridges AI-driven innovation and market adoption,\nadvancing multimodal FM deployment for high-stakes decision-making in\ncommercial marketing.", "published": "2025-04-01 01:37:02", "link": "http://arxiv.org/abs/2504.00338v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SI"], "primary_category": "cs.LG"}
{"title": "SeizureTransformer: Scaling U-Net with Transformer for Simultaneous Time-Step Level Seizure Detection from Long EEG Recordings", "abstract": "Epilepsy is a common neurological disorder that affects around 65 million\npeople worldwide. Detecting seizures quickly and accurately is vital, given the\nprevalence and severity of the associated complications. Recently, deep\nlearning-based automated seizure detection methods have emerged as solutions;\nhowever, most existing methods require extensive post-processing and do not\neffectively handle the crucial long-range patterns in EEG data. In this work,\nwe propose SeizureTransformer, a simple model comprised of (i) a deep encoder\ncomprising 1D convolutions (ii) a residual CNN stack and a transformer encoder\nto embed previous output into high-level representation with contextual\ninformation, and (iii) streamlined decoder which converts these features into a\nsequence of probabilities, directly indicating the presence or absence of\nseizures at every time step. Extensive experiments on public and private EEG\nseizure detection datasets demonstrate that our model significantly outperforms\nexisting approaches (ranked in the first place in the 2025 \"seizure detection\nchallenge\" organized in the International Conference on Artificial Intelligence\nin Epilepsy and Other Neurological Disorders), underscoring its potential for\nreal-time, precise seizure detection.", "published": "2025-04-01 01:33:42", "link": "http://arxiv.org/abs/2504.00336v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Artificial Intelligence and Deep Learning Algorithms for Epigenetic Sequence Analysis: A Review for Epigeneticists and AI Experts", "abstract": "Epigenetics encompasses mechanisms that can alter the expression of genes\nwithout changing the underlying genetic sequence. The epigenetic regulation of\ngene expression is initiated and sustained by several mechanisms such as DNA\nmethylation, histone modifications, chromatin conformation, and non-coding RNA.\nThe changes in gene regulation and expression can manifest in the form of\nvarious diseases and disorders such as cancer and congenital deformities. Over\nthe last few decades, high throughput experimental approaches have been used to\nidentify and understand epigenetic changes, but these laboratory experimental\napproaches and biochemical processes are time-consuming and expensive. To\novercome these challenges, machine learning and artificial intelligence (AI)\napproaches have been extensively used for mapping epigenetic modifications to\ntheir phenotypic manifestations. In this paper we provide a narrative review of\npublished research on AI models trained on epigenomic data to address a variety\nof problems such as prediction of disease markers, gene expression, enhancer\npromoter interaction, and chromatin states. The purpose of this review is\ntwofold as it is addressed to both AI experts and epigeneticists. For AI\nresearchers, we provided a taxonomy of epigenetics research problems that can\nbenefit from an AI-based approach. For epigeneticists, given each of the above\nproblems we provide a list of candidate AI solutions in the literature. We have\nalso identified several gaps in the literature, research challenges, and\nrecommendations to address these challenges.", "published": "2025-04-01 01:02:34", "link": "http://arxiv.org/abs/2504.03733v1", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "primary_category": "q-bio.GN"}
{"title": "FedPaI: Achieving Extreme Sparsity in Federated Learning via Pruning at Initialization", "abstract": "Federated Learning (FL) enables distributed training on edge devices but\nfaces significant challenges due to resource constraints in edge environments,\nimpacting both communication and computational efficiency. Existing iterative\npruning techniques improve communication efficiency but are limited by their\ncentralized design, which struggles with FL's decentralized and data-imbalanced\nnature, resulting in suboptimal sparsity levels. To address these issues, we\npropose FedPaI, a novel efficient FL framework that leverages Pruning at\nInitialization (PaI) to achieve extreme sparsity. FedPaI identifies optimal\nsparse connections at an early stage, maximizing model capacity and\nsignificantly reducing communication and computation overhead by fixing\nsparsity patterns at the start of training. To adapt to diverse hardware and\nsoftware environments, FedPaI supports both structured and unstructured\npruning. Additionally, we introduce personalized client-side pruning mechanisms\nfor improved learning capacity and sparsity-aware server-side aggregation for\nenhanced efficiency. Experimental results demonstrate that FedPaI consistently\noutperforms existing efficient FL that applies conventional iterative pruning\nwith significant leading in efficiency and model accuracy. For the first time,\nour proposed FedPaI achieves an extreme sparsity level of up to 98% without\ncompromising the model accuracy compared to unpruned baselines, even under\nchallenging non-IID settings. By employing our FedPaI with joint optimization\nof model learning capacity and sparsity, FL applications can benefit from\nfaster convergence and accelerate the training by 6.4 to 7.9 times.", "published": "2025-04-01 00:24:34", "link": "http://arxiv.org/abs/2504.00308v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Brains vs. Bytes: Evaluating LLM Proficiency in Olympiad Mathematics", "abstract": "Recent advancements in large language models (LLMs) have shown impressive\nprogress in mathematical reasoning tasks. However, current evaluation\nbenchmarks predominantly focus on the accuracy of final answers, often\noverlooking the logical rigor crucial for mathematical problem-solving. The\nclaim that state-of-the-art LLMs can solve Math Olympiad-level problems\nrequires closer examination. To explore this, we conducted both qualitative and\nquantitative human evaluations of proofs generated by LLMs, and developed a\nschema for automatically assessing their reasoning capabilities. Our study\nreveals that current LLMs fall significantly short of solving challenging\nOlympiad-level problems and frequently fail to distinguish correct mathematical\nreasoning from clearly flawed solutions. We also found that occasional correct\nfinal answers provided by LLMs often result from pattern recognition or\nheuristic shortcuts rather than genuine mathematical reasoning. These findings\nunderscore the substantial gap between LLM performance and human expertise in\nadvanced mathematical reasoning and highlight the importance of developing\nbenchmarks that prioritize the rigor and coherence of mathematical arguments\nrather than merely the correctness of final answers.", "published": "2025-04-01 00:10:10", "link": "http://arxiv.org/abs/2504.01995v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Collaborative LLM Numerical Reasoning with Local Data Protection", "abstract": "Numerical reasoning over documents, which demands both contextual\nunderstanding and logical inference, is challenging for low-capacity local\nmodels deployed on computation-constrained devices. Although such complex\nreasoning queries could be routed to powerful remote models like GPT-4,\nexposing local data raises significant data leakage concerns. Existing\nmitigation methods generate problem descriptions or examples for remote\nassistance. However, the inherent complexity of numerical reasoning hinders the\nlocal model from generating logically equivalent queries and accurately\ninferring answers with remote guidance. In this paper, we present a model\ncollaboration framework with two key innovations: (1) a context-aware synthesis\nstrategy that shifts the query domains while preserving logical consistency;\nand (2) a tool-based answer reconstruction approach that reuses the\nremote-generated problem-solving pattern with code snippets. Experimental\nresults demonstrate that our method achieves better reasoning accuracy than\nsolely using local models while providing stronger data protection than fully\nrelying on remote models. Furthermore, our method improves accuracy by 16.2% -\n43.6% while reducing data leakage by 2.3% - 44.6% compared to existing data\nprotection approaches.", "published": "2025-04-01 00:02:25", "link": "http://arxiv.org/abs/2504.00299v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Local Constant Approximation for Dominating Set on Graphs Excluding Large Minors", "abstract": "We show that graphs excluding $K_{2,t}$ as a minor admit a $f(t)$-round\n$50$-approximation deterministic distributed algorithm for Minimum Dominating\nSet. The result extends to Minimum Vertex Cover. Though fast and approximate\ndistributed algorithms for such problems were already known for $H$-minor-free\ngraphs, all of them have an approximation ratio depending on the size of $H$.\nTo the best of our knowledge, this is the first example of a large non-trivial\nexcluded minor leading to fast and constant-approximation distributed\nalgorithms, where the ratio is independent of the size of $H$. A new key\ningredient in the analysis of these distributed algorithms is the use of\nasymptotic dimension.", "published": "2025-04-01 18:08:38", "link": "http://arxiv.org/abs/2504.01091v2", "categories": ["cs.DC", "cs.DM"], "primary_category": "cs.DC"}
{"title": "Causal Models for Growing Networks", "abstract": "Real-world networks grow over time; statistical models based on node\nexchangeability are not appropriate. Instead of constraining the structure of\nthe \\textit{distribution} of edges, we propose that the relevant symmetries\nrefer to the \\textit{causal structure} between them. We first enumerate the 96\ncausal directed acyclic graph (DAG) models over pairs of nodes (dyad variables)\nin a growing network with finite ancestral sets that are invariant to node\ndeletion. We then partition them into 21 classes with ancestral sets that are\nclosed under node marginalization. Several of these classes are remarkably\namenable to distributed and asynchronous evaluation. As an example, we\nhighlight a simple model that exhibits flexible power-law degree distributions\nand emergent phase transitions in sparsity, which we characterize analytically.\nWith few parameters and much conditional independence, our proposed framework\nprovides natural baseline models for causal inference in relational data.", "published": "2025-04-01 17:52:24", "link": "http://arxiv.org/abs/2504.01012v1", "categories": ["cs.SI", "cs.DM", "math.CO", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.SI"}
{"title": "Strongly sublinear separators and bounded asymptotic dimension for sphere intersection graphs", "abstract": "In this paper, we consider the class $\\mathcal{C}^d$ of sphere intersection\ngraphs in $\\mathbb{R}^d$ for $d \\geq 2$. We show that for each integer $t$, the\nclass of all graphs in $\\mathcal{C}^d$ that exclude $K_{t,t}$ as a subgraph has\nstrongly sublinear separators. We also prove that $\\mathcal{C}^d$ has\nasymptotic dimension at most $2d+2$.", "published": "2025-04-01 16:05:36", "link": "http://arxiv.org/abs/2504.00932v1", "categories": ["math.CO", "cs.CG", "cs.DM", "math.MG"], "primary_category": "math.CO"}
{"title": "A Tutte-type canonical decomposition of 4-connected graphs", "abstract": "We provide a unique decomposition of every 4-connected graph into parts that\nare either quasi-5-connected, cycles of triangle-torsos and 3-connected torsos\non $\\leq 5$ vertices, generalised double-wheels, or thickened $K_{4,m}$'s. The\ndecomposition can be described in terms of a tree-decomposition but with edges\nallowed in the adhesion-sets. Our construction is explicit, canonical, and\nexhibits a defining property of the Tutte-decomposition.\n  As a corollary, we obtain a new Tutte-type canonical decomposition of\n3-connected graphs into parts that are either quasi-4-connected, generalised\nwheels or thickened $K_{3,m}$'s. This decomposition is similar yet different\nfrom the tri-separation decomposition.\n  As an application of the decomposition for 4-connectivity, we obtain a new\ntheorem characterising all 4-connected vertex-transitive finite graphs as\nquasi-5-connected, the $K_4$-expansion of a quasi-5-connected graph, or on a\nshort explicit list of graphs.", "published": "2025-04-01 13:10:53", "link": "http://arxiv.org/abs/2504.00760v1", "categories": ["math.CO", "cs.DM", "05C40 (Primary) 05C75, 05C83, 05E18 (Secondary)"], "primary_category": "math.CO"}
{"title": "Information Retrieval for Climate Impact", "abstract": "The purpose of the MANILA24 Workshop on information retrieval for climate\nimpact was to bring together researchers from academia, industry, governments,\nand NGOs to identify and discuss core research problems in information\nretrieval to assess climate change impacts. The workshop aimed to foster\ncollaboration by bringing communities together that have so far not been very\nwell connected -- information retrieval, natural language processing,\nsystematic reviews, impact assessments, and climate science. The workshop\nbrought together a diverse set of researchers and practitioners interested in\ncontributing to the development of a technical research agenda for information\nretrieval to assess climate change impacts.", "published": "2025-04-01 20:01:06", "link": "http://arxiv.org/abs/2504.01162v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Beyond Quacking: Deep Integration of Language Models and RAG into DuckDB", "abstract": "Knowledge-intensive analytical applications retrieve context from both\nstructured tabular data and unstructured, text-free documents for effective\ndecision-making. Large language models (LLMs) have made it significantly easier\nto prototype such retrieval and reasoning data pipelines. However, implementing\nthese pipelines efficiently still demands significant effort and has several\nchallenges. This often involves orchestrating heterogeneous data systems,\nmanaging data movement, and handling low-level implementation details, e.g.,\nLLM context management.\n  To address these challenges, we introduce FlockMTL: an extension for DBMSs\nthat deeply integrates LLM capabilities and retrieval-augmented generation\n(RAG). FlockMTL includes model-driven scalar and aggregate functions, enabling\nchained predictions through tuple-level mappings and reductions. Drawing\ninspiration from the relational model, FlockMTL incorporates: (i) cost-based\noptimizations, which seamlessly apply techniques such as batching and caching;\nand (ii) resource independence, enabled through novel SQL DDL abstractions:\nPROMPT and MODEL, introduced as first-class schema objects alongside TABLE.\nFlockMTL streamlines the development of knowledge-intensive analytical\napplications, and its optimizations ease the implementation burden.", "published": "2025-04-01 19:48:17", "link": "http://arxiv.org/abs/2504.01157v1", "categories": ["cs.DB", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Uncovering the Limitations of Query Performance Prediction: Failures, Insights, and Implications for Selective Query Processing", "abstract": "Query Performance Prediction (QPP) estimates retrieval systems effectiveness\nfor a given query, offering valuable insights for search effectiveness and\nquery processing. Despite extensive research, QPPs face critical challenges in\ngeneralizing across diverse retrieval paradigms and collections. This paper\nprovides a comprehensive evaluation of state-of-the-art QPPs (e.g. NQC, UQC),\nLETOR-based features, and newly explored dense-based predictors. Using diverse\nsparse rankers (BM25, DFree without and with query expansion) and hybrid or\ndense (SPLADE and ColBert) rankers and diverse test collections ROBUST, GOV2,\nWT10G, and MS MARCO; we investigate the relationships between predicted and\nactual performance, with a focus on generalization and robustness. Results show\nsignificant variability in predictors accuracy, with collections as the main\nfactor and rankers next. Some sparse predictors perform somehow on some\ncollections (TREC ROBUST and GOV2) but do not generalise to other collections\n(WT10G and MS-MARCO). While some predictors show promise in specific scenarios,\ntheir overall limitations constrain their utility for applications. We show\nthat QPP-driven selective query processing offers only marginal gains,\nemphasizing the need for improved predictors that generalize across\ncollections, align with dense retrieval architectures and are useful for\ndownstream applications.", "published": "2025-04-01 18:18:21", "link": "http://arxiv.org/abs/2504.01101v1", "categories": ["cs.IR", "cs.LG", "H.3; H.3.3; I.2; I.2.7"], "primary_category": "cs.IR"}
{"title": "Linked Array Tree: A Constant-Time Search Structure for Big Data", "abstract": "As data volumes continue to grow rapidly, traditional search algorithms, like\nthe red-black tree and B+ Tree, face increasing challenges in performance,\nespecially in big data scenarios with intensive storage access. This paper\npresents the Linked Array Tree (LAT), a novel data structure designed to\nachieve constant-time complexity for search, insertion, and deletion\noperations. LAT leverages a sparse, non-moving hierarchical layout that enables\ndirect access paths without requiring rebalancing or data movement. Its low\nmemory overhead and avoidance of pointer-heavy structures make it well-suited\nfor large-scale and intensive workloads. While not specifically tested under\nparallel or concurrent conditions, the structure's static layout and\nnon-interfering operations suggest potential advantages in such environments.\n  This paper first introduces the structure and algorithms of LAT, followed by\na detailed analysis of its time complexity in search, insertion, and deletion\noperations. Finally, it presents experimental results across both\ndata-intensive and sparse usage scenarios to evaluate LAT's practical\nperformance.", "published": "2025-04-01 14:15:55", "link": "http://arxiv.org/abs/2504.00828v1", "categories": ["cs.DB", "cs.DS", "cs.IR"], "primary_category": "cs.DB"}
{"title": "How to Maximize Efficiency in Systems with Exhausted Workers", "abstract": "We consider the problem of assigning tasks efficiently to a set of workers\nthat can exhaust themselves as a result of processing tasks. If a worker is\nexhausted, it will take a longer time to recover. To model efficiency of\nworkers with exhaustion, we use a continuous-time Markov chain (CTMC). By\ntaking samples from the internal states of the workers, the source assigns\ntasks to the workers when they are found to be in their efficient states. We\nconsider two different settings where (i) the source can assign tasks to the\nworkers only when they are in their most efficient state, and (ii) it can\nassign tasks to workers when they are also moderately efficient in spite of a\npotentially reduced success probability. In the former case, we find the\noptimal policy to be a threshold-based sampling policy where the thresholds\ndepend on the workers' recovery and exhaustion rates. In the latter case, we\nsolve a non-convex sum-of-ratios problem using a branch-and-bound approach\nwhich performs well compared with the globally optimal solution.", "published": "2025-04-01 21:01:45", "link": "http://arxiv.org/abs/2504.01186v1", "categories": ["cs.IT", "cs.NI", "cs.SY", "eess.SY", "math.IT", "math.OC"], "primary_category": "cs.IT"}
{"title": "Data-driven Optimization and Transfer Learning for Cellular Network Antenna Configurations", "abstract": "We propose a data-driven approach for large-scale cellular network\noptimization, using a production cellular network in London as a case study and\nemploying Sionna ray tracing for site-specific channel propagation modeling. We\noptimize base station antenna tilts and half-power beamwidths, resulting in\nmore than double the 10\\%-worst user rates compared to a 3GPP baseline. In\nscenarios involving aerial users, we identify configurations that increase\ntheir median rates fivefold without compromising ground user performance. We\nfurther demonstrate the efficacy of model generalization through transfer\nlearning, leveraging available data from a scenario source to predict the\noptimal solution for a scenario target within a similar number of iterations,\nwithout requiring a new initial dataset, and with a negligible performance\nloss.", "published": "2025-04-01 14:13:33", "link": "http://arxiv.org/abs/2504.00825v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "REMAA: Reconfigurable Pixel Antenna-based Electronic Movable-Antenna Arrays for Multiuser Communications", "abstract": "In this paper, we investigate reconfigurable pixel antenna (RPA)-based\nelectronic movable antennas (REMAs) for multiuser communications. First, we\nmodel each REMA as an antenna characterized by a set of predefined and discrete\nselectable radiation positions within the radiating region. Considering the\ntrade-off between performance and cost, we propose two types of REMA-based\narrays: the partially-connected RPA-based electronic movable-antenna array\n(PC-REMAA) and fully-connected REMAA (FC-REMAA). Then, we formulate a multiuser\nsum-rate maximization problem subject to the power constraint and hardware\nconstraints of the PC-REMAA or FC-REMAA. To solve this problem, we propose a\ntwo-step multiuser beamforming and antenna selection scheme. In the first step,\nwe develop a two-loop joint beamforming and antenna selection (TL-JBAS)\nalgorithm. In the second step, we apply the coordinate descent method to\nfurther enhance the solution of the TL-JBAS algorithm. In addition, we revisit\nmechanical movable antennas (MMAs) to establish a benchmark for evaluating the\nperformance of REMA-enabled multiuser communications, where MMAs can\ncontinuously adjust the positions within the transmission region. We also\nformulate a sum-rate maximization problem for MMA-enabled multiuser\ncommunications and propose an alternating beamforming and antenna position\noptimization scheme to solve it. Finally, we analyze the performance gap\nbetween REMAs and MMAs. Based on Fourier analysis, we derive the maximum power\nloss of REMAs compared to MMAs for any given position interval. Specifically,\nwe show that the REMA incurs a maximum power loss of only 3.25\\% compared to\nthe MMA when the position interval is set to one-tenth of the wavelength.\nSimulation results demonstrate the effectiveness of the proposed methods.", "published": "2025-04-01 13:40:38", "link": "http://arxiv.org/abs/2504.00787v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "A divide-and-conquer sumcheck protocol", "abstract": "We present a new sumcheck protocol called Fold-DCS\n(Fold-Divide-and-Conquer-Sumcheck) for multivariate polynomials based on a\ndivide-and-conquer strategy. Its round complexity and soundness error are\nlogarithmic in the number of variables, whereas they are linear in the\nclassical sumcheck protocol. This drastic improvement in number of rounds and\nsoundness comes at the expense of exchanging multivariate polynomials, which\ncan be alleviated using polynomial commitment schemes. We first present\nFold-DCS in the PIOP model, where the prover provides oracle access to a\nmultivariate polynomial at each round. We then replace this oracle access in\npractice with a multivariate polynomial commitment scheme; we illustrate this\nwith an adapted version of the recent commitment scheme Zeromorph [KT24], which\nallows us to replace most of the queries made by the verifier with a single\nbatched evaluation check.", "published": "2025-04-01 12:04:40", "link": "http://arxiv.org/abs/2504.00693v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Data Sourcing Random Access using Semantic Queries for Massive IoT Scenarios", "abstract": "Efficiently retrieving relevant data from massive Internet of Things (IoT)\nnetworks is essential for downstream tasks such as machine learning. This paper\naddresses this challenge by proposing a novel data sourcing protocol that\ncombines semantic queries and random access. The key idea is that the\ndestination node broadcasts a semantic query describing the desired\ninformation, and the sensors that have data matching the query then respond by\ntransmitting their observations over a shared random access channel, for\nexample to perform joint inference at the destination. However, this approach\nintroduces a tradeoff between maximizing the retrieval of relevant data and\nminimizing data loss due to collisions on the shared channel. We analyze this\ntradeoff under a tractable Gaussian mixture model and optimize the semantic\nmatching threshold to maximize the number of relevant retrieved observations.\nThe protocol and the analysis are then extended to handle a more realistic\nneural network-based model for complex sensing. Under both models, experimental\nresults in classification scenarios demonstrate that the proposed protocol is\nsuperior to traditional random access, and achieves a near-optimal balance\nbetween inference accuracy and the probability of missed detection,\nhighlighting its effectiveness for semantic query-based data sourcing in\nmassive IoT networks.", "published": "2025-04-01 10:17:28", "link": "http://arxiv.org/abs/2504.00619v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Quasi-cyclic codes of index 2", "abstract": "We study quasi-cyclic codes of index 2 over finite fields. We give a\nclassification of such codes. Their duals with respect to the Euclidean,\nsymplectic and Hermitian inner products are investigated. We describe\nself-orthogonal and dual-containing codes. Lower bounds for minimum distances\nof quasi-cyclic codes are given. A quasi-cyclic code of index 2 is generated by\nat most two elements. We describe conditions when such a code (or its dual) is\ngenerated by one element.", "published": "2025-04-01 09:24:03", "link": "http://arxiv.org/abs/2504.00568v1", "categories": ["cs.IT", "math.IT", "94B05, 94B15, 94B60"], "primary_category": "cs.IT"}
{"title": "Graphical Models and Efficient Inference Methods for Multivariate Phase Probability Distributions", "abstract": "Multivariate phase relationships are important to characterize and understand\nnumerous physical, biological, and chemical systems, from electromagnetic waves\nto neural oscillations. These systems exhibit complex spatiotemporal dynamics\nand intricate interdependencies among their constituent elements. While\nclassical models of multivariate phase relationships, such as the wave equation\nand Kuramoto model, give theoretical models to describe phenomena, the\ndevelopment of statistical tools for hypothesis testing and inference for\nmultivariate phase relationships in complex systems remains limited. This paper\nintroduces a novel probabilistic modeling framework to characterize\nmultivariate phase relationships, with wave-like phenomena serving as a key\nexample. This approach describes spatial patterns and interactions between\noscillators through a pairwise exponential family distribution. Building upon\nthe literature of graphical model inference, including methods like Ising\nmodels, graphical lasso, and interaction screening, this work bridges the gap\nbetween classical wave dynamics and modern statistical approaches. Efficient\ninference methods are introduced, leveraging the Chow-Liu algorithm for\ndirected tree approximations and interaction screening for general graphical\nmodels. Simulated experiments demonstrate the utility of these methods for\nuncovering wave properties and sparse interaction structures, highlighting\ntheir applicability to diverse scientific domains. This framework establishes a\nnew paradigm for statistical modeling of multivariate phase relationships,\nproviding a powerful toolset for exploring the complexity of these systems.", "published": "2025-04-01 06:34:02", "link": "http://arxiv.org/abs/2504.00459v1", "categories": ["stat.ME", "cs.IT", "math.IT", "math.ST", "q-bio.QM", "stat.AP", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Algorithmic randomness and the weak merging of computable probability measures", "abstract": "We characterize Martin-L\\\"of randomness and Schnorr randomness in terms of\nthe merging of opinions, along the lines of the Blackwell-Dubins Theorem. After\nsetting up a general framework for defining notions of merging randomness, we\nfocus on finite horizon events, that is, on weak merging in the sense of\nKalai-Lehrer. In contrast to Blackwell-Dubins and Kalai-Lehrer, we consider not\nonly the total variational distance but also the Hellinger distance and the\nKullback-Leibler divergence. Our main result is a characterization of\nMartin-L\\\"of randomness and Schnorr randomness in terms of weak merging and the\nsummable Kullback-Leibler divergence. The main proof idea is that the\nKullback-Leibler divergence between $\\mu$ and $\\nu$, at a given stage of the\nlearning process, is exactly the incremental growth, at that stage, of the\npredictable process of the Doob decomposition of the $\\nu$-submartingale\n$L(\\sigma)=-\\ln \\frac{\\mu(\\sigma)}{\\nu(\\sigma)}$. These characterizations of\nalgorithmic randomness notions in terms of the Kullback-Leibler divergence can\nbe viewed as global analogues of Vovk's theorem on what transpires locally with\nindividual Martin-L\\\"of $\\mu$- and $\\nu$-random points and the Hellinger\ndistance between $\\mu,\\nu$.", "published": "2025-04-01 05:44:30", "link": "http://arxiv.org/abs/2504.00440v1", "categories": ["math.LO", "cs.IT", "math.IT", "Primary 03D32 Secondary: 60A10, 94A17"], "primary_category": "math.LO"}
{"title": "Minimum Description Length of a Spectrum Variational Autoencoder: A Theory", "abstract": "Deep neural networks (DNNs) trained through end-to-end learning have achieved\nremarkable success across diverse machine learning tasks, yet they are not\nexplicitly designed to adhere to the Minimum Description Length (MDL)\nprinciple, which posits that the best model provides the shortest description\nof the data. In this paper, we argue that MDL is essential to deep learning and\npropose a further generalized principle: Understanding is the use of a small\namount of information to represent a large amount of information. To this end,\nwe introduce a novel theoretical framework for designing and evaluating deep\nVariational Autoencoders (VAEs) based on MDL. In our theory, we designed the\nSpectrum VAE, a specific VAE architecture whose MDL can be rigorously evaluated\nunder given conditions. Additionally, we introduce the concept of latent\ndimension combination, or pattern of spectrum, and provide the first\ntheoretical analysis of their role in achieving MDL. We claim that a Spectrum\nVAE understands the data distribution in the most appropriate way when the MDL\nis achieved. This work is entirely theoretical and lays the foundation for\nfuture research on designing deep learning systems that explicitly adhere to\ninformation-theoretic principles.", "published": "2025-04-01 03:37:18", "link": "http://arxiv.org/abs/2504.00395v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Robust Transmission Design for Active RIS-Aided Systems", "abstract": "Different from conventional passive reconfigurable intelligent surfaces\n(RISs), incident signals and thermal noise can be amplified at active RISs. By\nexploiting the amplifying capability of active RISs, noticeable performance\nimprovement can be expected when precise channel state information (CSI) is\navailable. Since obtaining perfect CSI related to an RIS is difficult in\npractice, a robust transmission design is proposed in this paper to tackle the\nchannel uncertainty issue, which will be more severe for active RIS-aided\nsystems. To account for the worst-case scenario, the minimum achievable rate of\neach user is derived under a statistical CSI error model. Subsequently, an\noptimization problem is formulated to maximize the sum of the minimum\nachievable rate. Since the objective function is non-concave, the formulated\nproblem is transformed into a tractable lower bound maximization problem, which\nis solved using an alternating optimization method. Numerical results show that\nthe proposed robust design outperforms a baseline scheme that only exploits\nestimated CSI.", "published": "2025-04-01 02:45:23", "link": "http://arxiv.org/abs/2504.00376v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Lower Bounds on Pauli Manipulation Detection Codes", "abstract": "We present a lower bound for Pauli Manipulation Detection (PMD) codes, which\nenables the detection of every Pauli error with high probability and can be\nused to construct quantum erasure and tamper-detection codes. Our lower bound\nreveals the first trade-off between the error and the redundancy parameters in\nPMD codes.", "published": "2025-04-01 02:15:35", "link": "http://arxiv.org/abs/2504.00357v1", "categories": ["quant-ph", "cs.CR", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Geo2ComMap: Deep Learning-Based MIMO Throughput Prediction Using Geographic Data", "abstract": "Accurate communication performance prediction is crucial for wireless\napplications such as network deployment and resource management. Unlike\nconventional systems with a single transmit and receive antenna, throughput\n(Tput) estimation in antenna array-based multiple-output multiple-input (MIMO)\nsystems is computationally intensive, i.e., requiring analysis of channel\nmatrices, rank conditions, and spatial channel quality. These calculations\nimpose significant computational and time burdens. This paper introduces\nGeo2ComMap, a deep learning-based framework that leverages geographic databases\nto efficiently estimate multiple communication metrics across an entire area in\nMIMO systems using only sparse measurements. To mitigate extreme prediction\nerrors, we propose a sparse sampling strategy. Extensive evaluations\ndemonstrate that Geo2ComMap accurately predicts full-area communication\nmetrics, achieving a median absolute error of 27.35 Mbps for Tput values\nranging from 0 to 1900 Mbps.", "published": "2025-04-01 02:06:00", "link": "http://arxiv.org/abs/2504.00351v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Denoising guarantees for optimized sampling schemes in compressed sensing", "abstract": "Compressed sensing with subsampled unitary matrices benefits from\n\\emph{optimized} sampling schemes, which feature improved theoretical\nguarantees and empirical performance relative to uniform subsampling. We\nprovide, in a first of its kind in compressed sensing, theoretical guarantees\nshowing that the error caused by the measurement noise vanishes with an\nincreasing number of measurements for optimized sampling schemes, assuming that\nthe noise is Gaussian. We moreover provide similar guarantees for measurements\nsampled with-replacement with arbitrary probability weights. All our results\nhold on prior sets contained in a union of low-dimensional subspaces. Finally,\nwe demonstrate that this denoising behavior appears in empirical experiments\nwith a rate that closely matches our theoretical guarantees when the prior set\nis the range of a generative ReLU neural network and when it is the set of\nsparse vectors.", "published": "2025-04-01 02:04:03", "link": "http://arxiv.org/abs/2504.01046v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "eess.SP", "math.IT", "math.PR", "94A20, 94A12, 68T07"], "primary_category": "stat.ML"}
{"title": "An Agent-based Model Simulation Approach to Demonstrate Effects of Aging Population and Social Service Policies on Pensions Fund and Its Long-term Socio-economic Consequences", "abstract": "Agent-based modeling (ABM) has emerged as a powerful tool in social\npolicy-making and socio-economics, offering a flexible and dynamic approach to\nunderstanding and simulating complex systems. While traditional analytic\nmethods may be less effective in unpredictable situations, ABM can provide\nvaluable support for policy-making by generating large ensembles of scenarios\nand evaluating adaptive policies. This approach has been applied in various\nfields, including economics, management, sociology, and politics, and has the\npotential to deepen our understanding of economic policy in the cooperative\nsector.", "published": "2025-04-01 23:14:29", "link": "http://arxiv.org/abs/2504.01242v1", "categories": ["cs.MA", "93A16, 92D25, 92D25 93A16", "I.6"], "primary_category": "cs.MA"}
{"title": "First Field-Trial Demonstration of L4 Autonomous Optical Network for Distributed AI Training Communication: An LLM-Powered Multi-AI-Agent Solution", "abstract": "We demonstrate the first cross-domain cross-layer level-4 autonomous optical\nnetwork via a multi-AI-agent system. Field trials show 98 percent task\ncompletion rate across the distributed AI training lifecycle-3.2x higher than\nsingle agents using state-of-the-art LLMs.", "published": "2025-04-01 22:48:22", "link": "http://arxiv.org/abs/2504.01234v1", "categories": ["cs.MA", "physics.optics"], "primary_category": "cs.MA"}
{"title": "An Investigation into the Causal Mechanism of Political Opinion Dynamics: A Model of Hierarchical Coarse-Graining with Community-Bounded Social Influence", "abstract": "The increasing polarization in democratic societies is an emergent outcome of\npolitical opinion dynamics. Yet, the fundamental mechanisms behind the\nformation of political opinions, from individual beliefs to collective\nconsensus, remain unknown. Understanding that a causal mechanism must account\nfor both bottom-up and top-down influences, we conceptualize political opinion\ndynamics as hierarchical coarse-graining, where microscale opinions integrate\ninto a macro-scale state variable. Using the CODA (Continuous Opinions Discrete\nActions) model, we simulate Bayesian opinion updating, social identity-based\ninformation integration, and migration between social identity groups to\nrepresent higher-level connectivity. This results in coarse-graining across\nmicro, meso, and macro levels. Our findings show that higher-level connectivity\nshapes information integration, yielding three regimes: independent\n(disconnected, local convergence), parallel (fast, global convergence), and\niterative (slow, stepwise convergence). In the iterative regime, low\nconnectivity fosters transient diversity, indicating an informed consensus. In\nall regimes, time-scale separation leads to downward causation, where agents\nconverge on the aggregate majority choice, driving consensus. Critically, any\ndegree of coherent higher-level information integration can overcome\nmisalignment via global downward causation. The results highlight how emergent\nproperties of the causal mechanism, such as downward causation, are essential\nfor consensus and may inform more precise investigations into polarized\npolitical discourse.", "published": "2025-04-01 15:07:13", "link": "http://arxiv.org/abs/2504.00877v2", "categories": ["cs.SI", "cs.MA"], "primary_category": "cs.SI"}
{"title": "Provably Stable Multi-Agent Routing with Bounded-Delay Adversaries in the Decision Loop", "abstract": "In this work, we are interested in studying multi-agent routing settings,\nwhere adversarial agents are part of the assignment and decision loop,\ndegrading the performance of the fleet by incurring bounded delays while\nservicing pickup-and-delivery requests. Specifically, we are interested in\ncharacterizing conditions on the fleet size and the proportion of adversarial\nagents for which a routing policy remains stable, where stability for a routing\npolicy is achieved if the number of outstanding requests is uniformly bounded\nover time. To obtain this characterization, we first establish a threshold on\nthe proportion of adversarial agents above which previously stable routing\npolicies for fully cooperative fleets are provably unstable. We then derive a\nsufficient condition on the fleet size to recover stability given a maximum\nproportion of adversarial agents. We empirically validate our theoretical\nresults on a case study on autonomous taxi routing, where we consider\ntransportation requests from real San Francisco taxicab data.", "published": "2025-04-01 14:52:47", "link": "http://arxiv.org/abs/2504.00863v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Simulation of Autonomous Industrial Vehicle Fleet Using Fuzzy Agents: Application to Task Allocation and Battery Charge Management", "abstract": "The research introduces a multi-agent simulation that uses fuzzy inference to\ninvestigate the work distribution and battery charging control of mobile\nbaggage conveyor robots in an airport in a comprehensive manner. Thanks to a\ndistributed system, this simulation approach provides high adaptability,\nadjusting to changes in conveyor agent availability, battery capacity,\nawareness of the activities of the conveyor fleet, and knowledge of the context\nof infrastructure resource availability. Dynamic factors, such as workload\nvariations and communication between the conveyor agents and infrastructure are\nconsidered as heuristics, highlighting the importance of flexible and\ncollaborative approaches in autonomous systems. The results highlight the\neffectiveness of adaptive fuzzy multi-agent models to optimize dynamic task\nallocation, adapt to the variation of baggage arrival flows, improve the\noverall operational efficiency of conveyor agents, and reduce their energy\nconsumption.", "published": "2025-04-01 11:52:44", "link": "http://arxiv.org/abs/2504.00683v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Asynchronous Multi-Agent Systems with Petri nets", "abstract": "Modeling the interaction between components is crucial for many applications\nand serves as a fundamental step in analyzing and verifying properties in\nmulti-agent systems. In this paper, we propose a method based on 1-safe Petri\nnets to model Asynchronous Multi-Agent Systems (AMAS), starting from two\nsemantics defined on AMAS represented as transition systems. Specifically, we\nfocus on two types of synchronization: synchronization on transitions and\nsynchronization on data. For both, we define an operator that composes 1-safe\nPetri nets and demonstrate the relationships between the composed Petri net and\nthe global transition systems as defined in theliterature. Additionally, we\nanalyze the relationships between the two semantics on Petri nets, proposing\ntwo constructions that enable switching between them. These transformations are\nparticularly useful for system analysis, as they allow the selection of the\nmost suitable model based on the property that needs to be verified.", "published": "2025-04-01 10:02:19", "link": "http://arxiv.org/abs/2504.00602v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "An accelerated randomized Bregman-Kaczmarz method for strongly convex linearly constraint optimization", "abstract": "In this paper, we propose a randomized accelerated method for the\nminimization of a strongly convex function under linear constraints. The method\nis of Kaczmarz-type, i.e. it only uses a single linear equation in each\niteration. To obtain acceleration we build on the fact that the Kaczmarz method\nis dual to a coordinate descent method. We use a recently proposed acceleration\nmethod for the randomized coordinate descent and transfer it to the primal\nspace. This method inherits many of the attractive features of the accelerated\ncoordinate descent method, including its worst-case convergence rates. A\ntheoretical analysis of the convergence of the proposed method is given.\nNumerical experiments show that the proposed method is more efficient and\nfaster than the existing methods for solving the same problem.", "published": "2025-04-01 20:00:08", "link": "http://arxiv.org/abs/2504.01160v1", "categories": ["math.OC", "cs.NA", "math.NA", "65F10, 68W20, 90C25"], "primary_category": "math.OC"}
{"title": "Corrected Trapezoidal Rules for Near-Singular Surface Integrals Applied to 3D Interfacial Stokes Flow", "abstract": "Interfacial Stokes flow can be efficiently computed using the Boundary\nIntegral Equation method. In 3D, the fluid velocity at a target point is given\nby a 2D surface integral over all interfaces, thus reducing the dimension of\nthe problem. A core challenge is that for target points near, but not on, an\ninterface, the surface integral is near-singular and standard quadratures lose\naccuracy. This paper presents a method to accurately compute the near-singular\nintegrals arising in elliptic boundary value problems in 3D. It is based on a\nlocal series approximation of the integrand about a base point on the surface,\nobtained by orthogonal projection of the target point onto the surface. The\nelementary functions in the resulting series approximation can be integrated to\nhigh accuracy in a neighborhood of the base point using a recursive algorithm.\nThe remaining integral is evaluated numerically using a standard quadrature\nrule, chosen here to be the 4th order Trapezoidal rule. The method is reduced\nto the standard quadrature plus a correction, and is uniformly of 4th order.\nThe method is applied to resolve Stokes flow past several ellipsoidal rigid\nbodies. We compare the error in the velocity near the bodies, and in the time\nand displacement of particles traveling around the bodies, computed with and\nwithout the corrections.", "published": "2025-04-01 19:27:13", "link": "http://arxiv.org/abs/2504.01144v1", "categories": ["math.NA", "cs.NA", "31B10, 65D30"], "primary_category": "math.NA"}
{"title": "Combining Extended Convolutional Autoencoders and Reservoir Computing for Accurate Reduced-Order Predictions of Atmospheric Flows", "abstract": "Forecasting atmospheric flows with traditional discretization methods, also\ncalled full order methods (e.g., finite element methods or finite volume\nmethods), is computationally expensive. We propose to reduce the computational\ncost with a Reduced Order Model (ROM) that combines Extended Convolutional\nAutoencoders (E-CAE) and Reservoir Computing (RC). Thanks to an extended\nnetwork depth, the E-CAE encodes the high-resolution data coming from the full\norder method into a compact latent representation and can decode it back into\nhigh-resolution with 75% lower reconstruction error than standard CAEs. The\ncompressed data are fed to an RC network, which predicts their evolution. The\nadvantage of RC networks is a reduced computational cost in the training phase\ncompared to conventional predictive models. We assess our data-driven ROM\nthrough well-known 2D and 3D benchmarks for atmospheric flows. We show that our\nROM accurately reconstructs and predicts the future system dynamics with errors\nbelow 6% in 2D and 8% in 3D, while significantly reducing the computational\ncost of a full-order simulation. Compared to other ROMs available in the\nliterature, such as Dynamic Mode Decomposition and Proper Orthogonal\nDecomposition with Interpolation, our ROM is as efficient but more accurate.\nThus, it is a promising alternative to high-dimensional atmospheric\nsimulations.", "published": "2025-04-01 18:14:39", "link": "http://arxiv.org/abs/2504.01097v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Subordination based approximation of Caputo fractional propagator and related numerical methods", "abstract": "In this work, we propose an exponentially convergent numerical method for the\nCaputo fractional propagator $S_\\alpha(t)$ and the associated mild solution of\nthe Cauchy problem with time-independent sectorial operator coefficient $A$ and\nCaputo fractional derivative of order $\\alpha \\in (0,2)$ in time. The proposed\nmethods are constructed by generalizing the earlier developed approximation of\n$S_\\alpha(t)$ with help of the subordination principle. Such technique permits\nus to eliminate the dependence of the main part of error estimate on $\\alpha$,\nwhile preserving other computationally relevant properties of the original\napproximation: native support for multilevel parallelism, the ability to handle\ninitial data with minimal spatial smoothness, and stable exponential\nconvergence for all $t \\in [0, T]$. Ultimately, the use of subordination leads\nto a significant improvement of the method's convergence behavior, particularly\nfor small $\\alpha < 0.5$, and opens up further opportunities for efficient data\nreuse. To validate theoretical results, we consider applications of the\ndeveloped methods to the direct problem of solution approximation, as well as\nto the inverse problem of fractional order identification.", "published": "2025-04-01 16:54:11", "link": "http://arxiv.org/abs/2504.00958v3", "categories": ["math.NA", "cs.NA", "math-ph", "math.AP", "math.MP", "34A08, 34K37, 35R11, 35R20, 65L05, 65J08, 65J10, 65M32"], "primary_category": "math.NA"}
{"title": "Distributed preconditioning for the parametric Helmholtz equation", "abstract": "In this work, we address the efficient computation of parameterized systems\nof linear equations, with possible nonlinear parameter dependence. When the\nmatrix is highly sensitive to the parameters, mean-based preconditioning might\nnot be enough. For this scenario, we explore an approach in which several\npreconditioners are placed in the parameter space during a precomputation step.\nTo determine the optimal placement of a limited number of preconditioners, we\nestimate the expected number of iterations with respect to a given\npreconditioner a priori and use a location-allocation strategy to optimize the\nplacement of the preconditioners. We elaborate on our methodology for the\nHelmholtz problem with exterior Dirichlet scattering at high frequencies, and\nwe estimate the expected number of GMRES iterations via a gray-box Gaussian\nprocess regression approach. We illustrate our approach in two practical\napplications: scattering in a domain with a parametric refractive index and\nscattering from a scatterer with parameterized shape. Using these numerical\nexamples, we show how our methods leads to runtime savings of about an order of\nmagnitude. Moreover, we investigate the effect of the parameter dimension and\nthe importance of dimension anisotropy on their efficacy.", "published": "2025-04-01 15:14:56", "link": "http://arxiv.org/abs/2504.00886v1", "categories": ["math.NA", "cs.NA", "35B30, 35J05, 60G15, 65F08 (Primary), 65N22"], "primary_category": "math.NA"}
{"title": "Retraction maps in optimal control of nonholonomic systems", "abstract": "In this paper, we compare the performance of different numerical schemes in\napproximating Pontryagin's Maximum Principle's necessary conditions for the\noptimal control of nonholonomic systems. Retraction maps are used as a seed to\nconstruct geometric integrators for the corresponding Hamilton equations.\nFirst, we obtain an intrinsic formulation of a discretization map on a\ndistribution $\\mathcal{D}$. Then, we illustrate this construction on a\nparticular example for which the performance of different symplectic\nintegrators is examined and compared with that of non-symplectic integrators.", "published": "2025-04-01 14:01:38", "link": "http://arxiv.org/abs/2504.00808v1", "categories": ["math.NA", "cs.NA", "math.DG", "math.OC"], "primary_category": "math.NA"}
{"title": "On the block Eberlein diagonalization method", "abstract": "The Eberlein diagonalization method is an iterative Jacobi-type method for\nsolving the eigenvalue problem of a general complex matrix. In this paper we\ndevelop the block version of the Eberlein method. We prove the global\nconvergence of our block method and present several numerical examples.", "published": "2025-04-01 12:50:04", "link": "http://arxiv.org/abs/2504.00740v1", "categories": ["math.NA", "cs.NA", "65F15"], "primary_category": "math.NA"}
{"title": "A Fast Fourth-Order Cut Cell Method for Solving Elliptic Equations in Two-Dimensional Irregular Domains", "abstract": "We propose a fast fourth-order cut cell method for solving\nconstant-coefficient elliptic equations in two-dimensional irregular domains.\nIn our methodology, the key to dealing with irregular domains is the poised\nlattice generation (PLG) algorithm that generates finite-volume interpolation\nstencils near the irregular boundary. We are able to derive high-order\ndiscretization of the elliptic operators by least squares fitting over the\ngenerated stencils. We then design a new geometric multigrid scheme to\nefficiently solve the resulting linear system. Finally, we demonstrate the\naccuracy and efficiency of our method through various numerical tests in\nirregular domains.", "published": "2025-04-01 12:33:22", "link": "http://arxiv.org/abs/2504.00724v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A simple, fully-discrete, unconditionally energy-stable method for the two-phase Navier-Stokes Cahn-Hilliard model with arbitrary density ratios", "abstract": "The two-phase Navier-Stokes Cahn-Hilliard (NSCH) mixture model is a key\nframework for simulating multiphase flows with non-matching densities.\nDeveloping fully discrete, energy-stable schemes for this model remains\nchallenging, due to the possible presence of negative densities. While various\nmethods have been proposed, ensuring provable energy stability under\nphase-field modifications, like positive extensions of the density, remains an\nopen problem. We propose a simple, fully discrete, energy-stable method for the\nNSCH mixture model that ensures stability with respect to the energy\nfunctional, where the density in the kinetic energy is positively extended. The\nmethod is based on an alternative but equivalent formulation using\nmass-averaged velocity and volume-fraction-based order parameters, simplifying\nimplementation while preserving theoretical consistency. Numerical results\ndemonstrate that the proposed scheme is robust, accurate, and stable for large\ndensity ratios, addressing key challenges in the discretization of NSCH models.", "published": "2025-04-01 11:57:31", "link": "http://arxiv.org/abs/2504.00688v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Amplification of numerical wave packets for transport equations with two boundaries", "abstract": "The purpose of this note is to investigate the coupling of Dirichlet and\nNeumann numerical boundary conditions for the transport equation set on an\ninterval. When one starts with a stable finite difference scheme on the lattice\n$\\mathbb{Z}$ and each numerical boundary condition is taken separately with the\nNeumann extrapolation condition at the outflow boundary, the corresponding\nnumerical semigroup on a half-line is known to be bounded. It is also known\nthat the coupling of such numerical boundary conditions on a compact interval\nyields a stable approximation, even though large time exponentially growing\nmodes may occur. We review the different stability estimates associated with\nthese numerical boundary conditions and give explicit examples of such\nexponential growth phenomena for finite difference schemes with ''small''\nstencils. This provides numerical evidence for the optimality of some stability\nestimates on the interval.", "published": "2025-04-01 11:22:57", "link": "http://arxiv.org/abs/2504.00667v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Semi-Explicit Compact Fourth-Order Finite-Difference Scheme for the General Acoustic Wave Equation", "abstract": "We construct a new compact semi-explicit three-level in time fourth-order\nfinite-difference scheme for numerical solving the general multidimensional\nacoustic wave equation, where both the speed of sound and density of a medium\nare variable. The scheme is three-point in each spatial direction, has the\ntruncation order $\\mathcal{O}(|h|^4+h_t^4)$ and is easily implementable. It\nseems to be the first compact scheme with such properties for the equation\nunder consideration. It generalizes a semi-explicit compact scheme developed\nand studied recently in the much simpler case of the variable speed of sound\nonly. Numerical experiments confirm the high precision of the scheme and its\nfourth error order not only in the mesh $C$ norm but in the mesh $C^1$ norm as\nwell.", "published": "2025-04-01 11:18:20", "link": "http://arxiv.org/abs/2504.00666v1", "categories": ["math.NA", "cs.NA", "65M06"], "primary_category": "math.NA"}
{"title": "A posteriori error analysis of a robust virtual element method for stress-assisted diffusion problems", "abstract": "We develop and analyse residual-based a posteriori error estimates for the\nvirtual element discretisation of a nonlinear stress-assisted diffusion problem\nin two and three dimensions. The model problem involves a two-way coupling\nbetween elasticity and diffusion equations in perturbed saddle-point form. A\nrobust global inf-sup condition and Helmholtz decomposition for\n$\\mathbf{H}(\\mathrm{div}, \\Omega)$ lead to a reliable and efficient error\nestimator based on appropriately weighted norms that ensure parameter\nrobustness. The a posteriori error analysis uses quasi-interpolation operators\nfor Stokes and edge virtual element spaces, and we include the proofs of such\noperators with estimates in 3D for completeness. Finally, we present numerical\nexperiments in both 2D and 3D to demonstrate the optimal performance of the\nproposed error estimator.", "published": "2025-04-01 10:58:17", "link": "http://arxiv.org/abs/2504.00648v1", "categories": ["math.NA", "cs.NA", "65N30, 65N12, 65N15, 74F25"], "primary_category": "math.NA"}
{"title": "Adaptive hyper-reduction of non-sparse operators: application to parametric particle-based kinetic plasma models", "abstract": "This paper proposes an adaptive hyper-reduction method to reduce the\ncomputational cost associated with the simulation of parametric particle-based\nkinetic plasma models, specifically focusing on the Vlasov-Poisson equation.\nConventional model order reduction and hyper-reduction techniques are often\nineffective for such models due to the non-sparse nature of the nonlinear\noperators arising from the interactions between particles. To tackle this\nissue, we propose an adaptive, structure-preserving hyper-reduction method that\nleverages a decomposition of the discrete reduced Hamiltonian into a linear\ncombination of terms, each depending on a few components of the state. The\nproposed approximation strategy allows to: (i) preserve the Hamiltonian\nstructure of the problem; (ii) evaluate nonlinear non-sparse operators in a\ncomputationally efficient way; (iii) overcome the Kolmogorov barrier of\ntransport-dominated problems via evolution of the approximation space and\nadaptivity of the rank of the solution. The proposed method is validated on\nnumerical benchmark simulations, demonstrating stable and accurate performance\nwith substantial runtime reductions compared to the full order model.", "published": "2025-04-01 10:02:49", "link": "http://arxiv.org/abs/2504.00604v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A variational symplectic scheme based on Lobatto's quadrature", "abstract": "We present a variational integrator based on the Lobatto quadrature for the\ntime integration of dynamical systems issued from the least action principle.\nThis numerical method uses a cubic interpolation of the states and the action\nis approximated at each time step by Lobatto's formula. Numerical analysis is\nperformed on a harmonic oscillator. The scheme is conditionally stable,\nsixth-order accurate, and symplectic. It preserves an approximate energy\nquantity. Simulation results illustrate the performance of the proposed method.", "published": "2025-04-01 09:13:48", "link": "http://arxiv.org/abs/2504.00560v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Preconditioned Additive Gaussian Processes with Fourier Acceleration", "abstract": "Gaussian processes (GPs) are crucial in machine learning for quantifying\nuncertainty in predictions. However, their associated covariance matrices,\ndefined by kernel functions, are typically dense and large-scale, posing\nsignificant computational challenges. This paper introduces a matrix-free\nmethod that utilizes the Non-equispaced Fast Fourier Transform (NFFT) to\nachieve nearly linear complexity in the multiplication of kernel matrices and\ntheir derivatives with vectors for a predetermined accuracy level. To address\nhigh-dimensional problems, we propose an additive kernel approach. Each\nsub-kernel in this approach captures lower-order feature interactions, allowing\nfor the efficient application of the NFFT method and potentially increasing\naccuracy across various real-world datasets. Additionally, we implement a\npreconditioning strategy that accelerates hyperparameter tuning, further\nimproving the efficiency and effectiveness of GPs.", "published": "2025-04-01 07:14:06", "link": "http://arxiv.org/abs/2504.00480v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Learning high-accuracy numerical schemes for hyperbolic equations on coarse meshes", "abstract": "When solving partial differential equations using classical schemes such as\nfinite difference or finite volume methods, sufficiently fine meshes and\ncarefully designed schemes are required to achieve high-order accuracy of\nnumerical solutions, leading to a significant increase in computational costs,\nespecially for three-dimensional (3D) time-dependent problems. Recently,\nmachine learning-assisted numerical methods have been proposed to enhance\naccuracy or efficiency. In this paper, we propose a data-driven finite\ndifference numerical method to solve the hyperbolic equations with smooth\nsolutions on coarse grids, which can achieve higher accuracy than classical\nnumerical schemes based on the same mesh size. In addition, the data-driven\nschemes have better spectrum properties than the classical schemes, although\nthe spectrum properties are not explicitly optimized during the training\nprocess. Numerical examples are presented to demonstrate the accuracy and\nefficiency of the proposed method, as well as its good performance on\ndispersion and dissipation.", "published": "2025-04-01 06:36:25", "link": "http://arxiv.org/abs/2504.00462v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Adaptive Step Selection for a Filtered Implicit Method", "abstract": "Pre-filtering and post-filtering steps can be added to many of the\ntraditional numerical methods to generate new, higher order methods with strong\nstability properties. Presented in this paper are a variable step pre-filter\nand post-filter that allow adaptive time stepping for a filtered method based\non Implicit Euler.", "published": "2025-04-01 04:03:08", "link": "http://arxiv.org/abs/2504.00405v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical approximations for partially observed optimal control of stochastic partial differential equations", "abstract": "In this paper, we study numerical approximations for optimal control of a\nclass of stochastic partial differential equations with partial observations.\nThe system state evolves in a Hilbert space, whereas observations are given in\nfinite-dimensional space $\\rr^d$. We begin by establishing stochastic maximum\nprinciples (SMPs) for such problems, where the system state is driven by a\ncylindrical Wiener process. The corresponding adjoint equations are\ncharacterized by backward stochastic partial differential equations. We then\ndevelop numerical algorithms to solve the partially observed optimal control.\nOur approach combines the stochastic gradient descent method, guided by the\nSMP, with a particle filtering algorithm to estimate the conditional\ndistributions of the state of the system. Finally, we demonstrate the\neffectiveness of our proposed algorithm through numerical experiments.", "published": "2025-04-01 02:52:38", "link": "http://arxiv.org/abs/2504.00381v1", "categories": ["math.OC", "cs.NA", "math.NA", "93E11, 60G35, 65K10, 60H15, 60H10"], "primary_category": "math.OC"}
{"title": "A deterministic solver for the linear Boltzmann model of a single mono-directional proton beam", "abstract": "The linear Boltzmann model for proton beams is a six-dimensional partial\ndifferential equation (PDE). We propose a deterministic solver for the linear\nBoltzmann model based on scattering decomposition and depth-splitting methods.\nThe main idea is to first divide the protons into primary protons and\nscattering protons, whose equations are derived using the source iteration\nmethod. We then treat depth as the time variable in classical time-evolutionary\nproblems and apply the depth-splitting method. In the depth-splitting method,\nthe full operator is decomposed into three parts, with each subsystem being\neasily parallelizable, which is crucial for efficient simulations. The\nresulting discretization exhibits second-order convergence in both the depth\nand energy variables. The dose distributions obtained from our solver are\ncompared with those from Monte Carlo simulations for various materials and\nheterogeneous cases.", "published": "2025-04-01 01:44:41", "link": "http://arxiv.org/abs/2504.00340v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stability analysis of Runge-Kutta methods for nonlinear Volterra delay-integro-differential-algebraic equations", "abstract": "This paper is devoted to examining the stability of Runge-Kutta methods for\nsolving stiff nonlinear Volterra delay-integro-differential-algebraic equations\n(DIDAEs) with constant delay. Hybrid numerical schemes combining Runge-Kutta\nmethods and compound quadrature rules are analyzed for nonlinear stiff DIDAEs.\nCriteria for ensuring the global and asymptotic stability of the proposed\nschemes are established. Several numerical examples are provided to validate\nthe theoretical findings.", "published": "2025-04-01 01:27:25", "link": "http://arxiv.org/abs/2504.00330v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A note on the cross matrices", "abstract": "A cross matrix $X$ can have nonzero elements located only on the main\ndiagonal and the anti-diagonal, so that the sparsity pattern has the shape of a\ncross. It is shown that $X$ can be factorized into products of matrices that\nare at most rank-two perturbations to the identity matrix and can be\nsymmetrically permuted to block diagonal form with $2\\times 2$ diagonal blocks\nand, if $n$ is odd, a $1\\times 1$ diagonal block. The permutation similarity\nimplies that any well-defined analytic function of $X$ remains a cross matrix.\nBy exploiting these properties, explicit formulae for the determinant, inverse,\nand characteristic polynomial are derived. It is also shown that the structure\nof cross matrix can be preserved under matrix factorizations, including the LU,\nQR, and SVD decompositions.", "published": "2025-04-01 01:11:22", "link": "http://arxiv.org/abs/2504.00325v1", "categories": ["math.NA", "cs.NA", "15B99, 15A23, 65F40"], "primary_category": "math.NA"}
{"title": "Explicit Runge-Kutta-Chebyshev methods of second order with monotonic stability polynomial", "abstract": "A new Chebyshev-type family of stabilized explicit methods for solving mildly\nstiff ODEs is presented. Besides conventional conditions of order and stability\nwe impose an additional restriction on the methods: their stability function\nmust be monotonically increasing and positive along the largest possible\ninterval of negative real axis. Although stability intervals of the proposed\nmethods are smaller than those of classic Chebyshev-type methods, their\nstability functions are more consistent with the exponent, they have more\nconvex stability regions and smaller error constants. These properties allow\nthe monotonic methods to be competitive with contemporary stabilized\nsecond-order methods, as the presented results of numerical experiments\ndemonstrate.", "published": "2025-04-01 01:07:28", "link": "http://arxiv.org/abs/2504.00323v1", "categories": ["math.NA", "cs.NA", "65L04, 65L05, 65L06, 65L20, 65M20"], "primary_category": "math.NA"}
{"title": "A two-stage optimization algorithm for tensor decomposition", "abstract": "The canonical polyadic tensor decomposition has a long history. But it\nbecomes challenging to find a tensor decomposition when the rank is between the\nlargest and the second-largest dimension. In such cases, traditional\noptimization methods, such as nonlinear least squares or alternative least\nsquares methods, often fail to find a tensor decomposition. There are also\ndirect methods, such as the normal form algorithm and the method by Domanov and\nDe Lathauwer, that solve tensor decompositions algebraically. However, these\nmethods can be computationally expensive and require significant memory,\nespecially when the rank is high. This paper proposes a novel two-stage\nalgorithm for the order-3 nonsymmetric tensor decomposition problem when the\nrank is not greater than the largest dimension. It transforms the tensor\ndecomposition problem into two optimization problems. When the first-stage\noptimization is not fully solved, the partial solution will also be leveraged\nin the second-stage optimization problem. We prove the equivalence between\ntensor decompositions and the global minimizers of the two-stage optimization\nproblems. Our numerical experiments demonstrate the proposed two-stage\noptimization method is very efficient and robust, capable of finding tensor\ndecompositions where other commonly used state-of-the-art methods fail.", "published": "2025-04-01 00:33:01", "link": "http://arxiv.org/abs/2504.00313v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "The effect of latency on optimal order execution policy", "abstract": "Market participants regularly send bid and ask quotes to exchange-operated\nlimit order books. This creates an optimization challenge where their potential\nprofit is determined by their quoted price and how often their orders are\nsuccessfully executed. The expected profit from successful execution at a\nfavorable limit price needs to be balanced against two key risks: (1) the\npossibility that orders will remain unfilled, which hinders the trading agenda\nand leads to greater price uncertainty, and (2) the danger that limit orders\nwill be executed as market orders, particularly in the presence of order\nsubmission latency, which in turn results in higher transaction costs. In this\npaper, we consider a stochastic optimal control problem where a risk-averse\ntrader attempts to maximize profit while balancing risk. The market is modeled\nusing Brownian motion to represent the price uncertainty. We analyze the\nrelationship between fill probability, limit price, and order submission\nlatency. We derive closed-form approximations of these quantities that perform\nwell in the practical regime of interest. Then, we utilize a mean-variance\nmethod where our total reward function features a risk-tolerance parameter to\nquantify the combined risk and profit.", "published": "2025-04-01 14:33:23", "link": "http://arxiv.org/abs/2504.00846v1", "categories": ["q-fin.MF", "math.OC", "91G15 (Primary) 93E20, 60J28 (Secondary)"], "primary_category": "q-fin.MF"}
{"title": "Nonparametric spectral density estimation using interactive mechanisms under local differential privacy", "abstract": "We address the problem of nonparametric estimation of the spectral density\nfor a centered stationary Gaussian time series under local differential privacy\nconstraints. Specifically, we propose new interactive privacy mechanisms for\nthree tasks: estimating a single covariance coefficient, estimating the\nspectral density at a fixed frequency, and estimating the entire spectral\ndensity function. Our approach achieves faster rates through a two-stage\nprocess: we apply first the Laplace mechanism to the truncated value and then\nuse the former privatized sample to gain knowledge on the dependence mechanism\nin the time series. For spectral densities belonging to H\\\"older and Sobolev\nsmoothness classes, we demonstrate that our estimators improve upon the\nnon-interactive mechanism of Kroll (2024) for small privacy parameter $\\alpha$,\nsince the pointwise rates depend on $n\\alpha^2$ instead of $n\\alpha^4$.\nMoreover, we show that the rate $(n\\alpha^4)^{-1}$ is optimal for estimating a\ncovariance coefficient with non-interactive mechanisms. However, the $L_2$ rate\nof our interactive estimator is slower than the pointwise rate. We show how to\nuse these estimators to provide a bona-fide locally differentially private\ncovariance matrix estimator.", "published": "2025-04-01 15:52:50", "link": "http://arxiv.org/abs/2504.00919v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Privacy-Preserving Transfer Learning for Community Detection using Locally Distributed Multiple Networks", "abstract": "This paper develops a new spectral clustering-based method called TransNet\nfor transfer learning in community detection of network data. Our goal is to\nimprove the clustering performance of the target network using auxiliary source\nnetworks, which are heterogeneous, privacy-preserved, and locally stored across\nvarious sources. The edges of each locally stored network are perturbed using\nthe randomized response mechanism to achieve differential privacy. Notably, we\nallow the source networks to have distinct privacy-preserving and heterogeneity\nlevels as often desired in practice. To better utilize the information from the\nsource networks, we propose a novel adaptive weighting method to aggregate the\neigenspaces of the source networks multiplied by adaptive weights chosen to\nincorporate the effects of privacy and heterogeneity. We propose a\nregularization method that combines the weighted average eigenspace of the\nsource networks with the eigenspace of the target network to achieve an optimal\nbalance between them. Theoretically, we show that the adaptive weighting method\nenjoys the error-bound-oracle property in the sense that the error bound of the\nestimated eigenspace only depends on informative source networks. We also\ndemonstrate that TransNet performs better than the estimator using only the\ntarget network and the estimator using only the weighted source networks.", "published": "2025-04-01 15:19:07", "link": "http://arxiv.org/abs/2504.00890v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Deep Generative Models: Complexity, Dimensionality, and Approximation", "abstract": "Generative networks have shown remarkable success in learning complex data\ndistributions, particularly in generating high-dimensional data from\nlower-dimensional inputs. While this capability is well-documented empirically,\nits theoretical underpinning remains unclear. One common theoretical\nexplanation appeals to the widely accepted manifold hypothesis, which suggests\nthat many real-world datasets, such as images and signals, often possess\nintrinsic low-dimensional geometric structures. Under this manifold hypothesis,\nit is widely believed that to approximate a distribution on a $d$-dimensional\nRiemannian manifold, the latent dimension needs to be at least $d$ or $d+1$. In\nthis work, we show that this requirement on the latent dimension is not\nnecessary by demonstrating that generative networks can approximate\ndistributions on $d$-dimensional Riemannian manifolds from inputs of any\narbitrary dimension, even lower than $d$, taking inspiration from the concept\nof space-filling curves. This approach, in turn, leads to a super-exponential\ncomplexity bound of the deep neural networks through expanded neurons. Our\nfindings thus challenge the conventional belief on the relationship between\ninput dimensionality and the ability of generative networks to model data\ndistributions. This novel insight not only corroborates the practical\neffectiveness of generative networks in handling complex data structures, but\nalso underscores a critical trade-off between approximation error,\ndimensionality, and model complexity.", "published": "2025-04-01 14:07:02", "link": "http://arxiv.org/abs/2504.00820v1", "categories": ["cs.LG", "math.DG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TAMIS: Tailored Membership Inference Attacks on Synthetic Data", "abstract": "Membership Inference Attacks (MIA) enable to empirically assess the privacy\nof a machine learning algorithm. In this paper, we propose TAMIS, a novel MIA\nagainst differentially-private synthetic data generation methods that rely on\ngraphical models. This attack builds upon MAMA-MIA, a recently-published\nstate-of-the-art method. It lowers its computational cost and requires less\nattacker knowledge. Our attack is the product of a two-fold improvement. First,\nwe recover the graphical model having generated a synthetic dataset by using\nsolely that dataset, rather than shadow-modeling over an auxiliary one. This\nproves less costly and more performant. Second, we introduce a more\nmathematically-grounded attack score, that provides a natural threshold for\nbinary predictions. In our experiments, TAMIS achieves better or similar\nperformance as MAMA-MIA on replicas of the SNAKE challenge.", "published": "2025-04-01 13:08:48", "link": "http://arxiv.org/abs/2504.00758v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Communication-Efficient l_0 Penalized Least Square", "abstract": "In this paper, we propose a communication-efficient penalized regression\nalgorithm for high-dimensional sparse linear regression models with massive\ndata. This approach incorporates an optimized distributed system communication\nalgorithm, named CESDAR algorithm, based on the Enhanced Support Detection and\nRoot finding algorithm. The CESDAR algorithm leverages data distributed across\nmultiple machines to compute and update the active set and introduces the\ncommunication-efficient surrogate likelihood framework to approximate the\noptimal solution for the full sample on the active set, resulting in the\navoidance of raw data transmission, which enhances privacy and data security,\nwhile significantly improving algorithm execution speed and substantially\nreducing communication costs. Notably, this approach achieves the same\nstatistical accuracy as the global estimator. Furthermore, this paper explores\nan extended version of CESDAR and an adaptive version of CESDAR to enhance\nalgorithmic speed and optimize parameter selection, respectively. Simulations\nand real data benchmarks experiments demonstrate the efficiency and accuracy of\nthe CESDAR algorithm.", "published": "2025-04-01 12:32:15", "link": "http://arxiv.org/abs/2504.00722v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Domain Adaptation Under MNAR Missingness", "abstract": "Current domain adaptation methods under missingness shift are restricted to\nMissing At Random (MAR) missingness mechanisms. However, in many real-world\nexamples, the MAR assumption may be too restrictive. When covariates are\nMissing Not At Random (MNAR) in both source and target data, the common\ncovariate shift solutions, including importance weighting, are not directly\napplicable. We show that under reasonable assumptions, the problem of MNAR\nmissingness shift can be reduced to an imputation problem. This allows us to\nleverage recent methodological developments in both the traditional statistics\nand machine/deep-learning literature for MNAR imputation to develop a novel\ndomain adaptation procedure for MNAR missingness shift. We further show that\nour proposed procedure can be extended to handle simultaneous MNAR missingness\nand covariate shifts. We apply our procedure to Electronic Health Record (EHR)\ndata from two hospitals in south and northeast regions of the US. In this\nsetting we expect different hospital networks and regions to serve different\npopulations and to have different procedures, practices, and software for\ninputting and recording data, causing simultaneous missingness and covariate\nshifts.", "published": "2025-04-01 01:03:56", "link": "http://arxiv.org/abs/2504.00322v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "$C^2$AV-TSE: Context and Confidence-aware Audio Visual Target Speaker Extraction", "abstract": "Audio-Visual Target Speaker Extraction (AV-TSE) aims to mimic the human\nability to enhance auditory perception using visual cues. Although numerous\nmodels have been proposed recently, most of them estimate target signals by\nprimarily relying on local dependencies within acoustic features,\nunderutilizing the human-like capacity to infer unclear parts of speech through\ncontextual information. This limitation results in not only suboptimal\nperformance but also inconsistent extraction quality across the utterance, with\nsome segments exhibiting poor quality or inadequate suppression of interfering\nspeakers. To close this gap, we propose a model-agnostic strategy called the\nMask-And-Recover (MAR). It integrates both inter- and intra-modality contextual\ncorrelations to enable global inference within extraction modules.\nAdditionally, to better target challenging parts within each sample, we\nintroduce a Fine-grained Confidence Score (FCS) model to assess extraction\nquality and guide extraction modules to emphasize improvement on low-quality\nsegments. To validate the effectiveness of our proposed model-agnostic training\nparadigm, six popular AV-TSE backbones were adopted for evaluation on the\nVoxCeleb2 dataset, demonstrating consistent performance improvements across\nvarious metrics.", "published": "2025-04-01 13:01:30", "link": "http://arxiv.org/abs/2504.00750v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Expanding and Analyzing ODAQ -- the Open Dataset of Audio Quality", "abstract": "The Open Dataset of Audio Quality (ODAQ) was recently introduced to address\nthe scarcity of openly available audio datasets with corresponding subjective\nquality scores. The dataset, released under permissive licenses, comprises\naudio material processed using six different signal processing methods\noperating at five quality levels, along with corresponding subjective test\nresults. To expand the dataset, we provided listener training to university\nstudents to conduct further subjective tests and obtained results consistent\nwith previous expert listeners. We also showed how different training\napproaches affect the use of absolute scales and anchors. The expanded dataset\nnow comprises results from three international laboratories providing a total\nof 42 listeners and 10080 subjective scores. This paper provides the details of\nthe expansion and an in-depth analysis. As part of this analysis, we initiate\nthe use of ODAQ as a benchmark to evaluate objective audio quality metrics in\ntheir ability to predict subjective scores", "published": "2025-04-01 12:51:12", "link": "http://arxiv.org/abs/2504.00742v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "How Cyclic Acoustic Patterns Influence ASMR Perception: A Signal Processing Perspective", "abstract": "Autonomous Sensory Meridian Response (ASMR) has been remarkably popular in\nthe recent decade. While its effect has been validated through behavioral\nstudies and neuro-physiological measurements such as electroencephalography\n(EEG) and related bio-signal analyses, its development and triggers remain a\nsubject of debate. Previous studies suggest that its triggers are highly linked\nwith cyclic patterns: predictable patterns introduce relaxation while\nvariations maintain intrigue. To validate this and further understand the\nimpact of acoustic features on ASMR effects, we designed three distinct cyclic\npatterns with monophonic and stereophonic variations, while controlling their\npredictability and randomness, and collected ASMR triggering scores through\nonline surveys. Then, we extracted cyclic features and carried out regression\nanalysis, seeking an explainable mapping of cyclic features and ASMR triggers.\nWe found that relaxing effects accumulate progressively and are independent of\nspatial orientation. Cyclic patterns significantly influence psychological and\nphysical effects, which remain invariant with time. Regression analysis\nrevealed that smoothly spread and energy-dense cyclic patterns most effectively\ntrigger ASMR responses.", "published": "2025-04-01 10:18:39", "link": "http://arxiv.org/abs/2504.00621v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "General Framework for Array Noise Analysis and Noise Performance of a Two-Element Interferometer With a Mutual-Coupling Canceler", "abstract": "This article investigates the noise performance of a two-element phased array\nand interferometer containing a recently introduced self-interference canceler,\nwhich in the context of this work acts as a mutual-coupling canceler. To this\nend, a general framework is proposed to permit noise analysis of this network\nand a large variety of other networks. The framework-based numerical analysis\nfor a two-element-phased array shows that the addition of the canceler\nsignificantly increases the beam-equivalent noise temperature. For a\ntwo-element interferometer used in cosmology, this increase in noise\ntemperature is still acceptable as the sky noise temperature in the 20-to-200\nMHz band is high. When used in an interferometer, the canceler provides the\nability to null mutual coherence at the interferometer output. The ability to\nprovide matching to reduce the sensitivity of the null in mutual coherence to\nthe phase of the 90deg hybrids in the canceler is discussed.", "published": "2025-04-01 18:48:56", "link": "http://arxiv.org/abs/2504.01123v1", "categories": ["eess.SP", "astro-ph.IM"], "primary_category": "eess.SP"}
{"title": "A Unified Theoretic and Algorithmic Framework for Solving Multivariate Linear Model with $\\ell^1$-norm Optimization", "abstract": "It is a challenging problem that solving the \\textit{multivariate linear\nmodel} (MLM) $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ with the $\\ell_1 $-norm\napproximation method such that $||\\mathbf{A}\\mathbf{x}-\\mathbf{b}||_1$, the\n$\\ell_1$-norm of the \\textit{residual error vector} (REV), is minimized. In\nthis work, our contributions lie in two aspects: firstly, the equivalence\ntheorem for the structure of the $\\ell_1$-norm optimal solution to the MLM is\nproposed and proved; secondly, a unified algorithmic framework for solving the\nMLM with $\\ell_1$-norm optimization is proposed and six novel algorithms\n(L1-GPRS, L1-TNIPM, L1-HP, L1-IST, L1-ADM, L1-POB) are designed. There are\nthree significant characteristics in the algorithms discussed: they are\nimplemented with simple matrix operations which do not depend on specific\noptimization solvers; they are described with algorithmic pseudo-codes and\nimplemented with Python and Octave/MATLAB which means easy usage; and the high\naccuracy and efficiency of our six new algorithms can be achieved successfully\nin the scenarios with different levels of data redundancy. We hope that the\nunified theoretic and algorithmic framework with source code released on GitHub\ncould motivate the applications of the $\\ell_1$-norm optimization for parameter\nestimation of MLM arising in science, technology, engineering, mathematics,\neconomics, and so on.", "published": "2025-04-01 13:18:59", "link": "http://arxiv.org/abs/2504.00769v1", "categories": ["math.OC", "eess.SP"], "primary_category": "math.OC"}
{"title": "Spatiotemporal Synchronization of Distributed Arrays using Particle-Based Loopy Belief Propagation", "abstract": "Sensing and imaging with distributed radio infrastructures (e.g., distributed\nMIMO, wireless sensor networks, multistatic radar) rely on knowledge of the\npositions, orientations, and clock parameters of distributed apertures. We\nextend a particle-based loopy belief propagation (BP) algorithm to\ncooperatively synchronize distributed agents to anchors in space and time.\nSubstituting marginalization over nuisance parameters with approximate but\nclosed-form concentration, we derive an efficient estimator that bypasses the\nneed for preliminary channel estimation and operates directly on noisy channel\nobservations. Our algorithm demonstrates scalable, accurate spatiotemporal\nsynchronization on simulated data.", "published": "2025-04-01 12:54:25", "link": "http://arxiv.org/abs/2504.00744v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "RapidPD: Rapid Human and Pet Presence Detection System for Smart Vehicles via Wi-Fi", "abstract": "Heatstroke and life threatening incidents resulting from the retention of\nchildren and animals in vehicles pose a critical global safety issue. Current\npresence detection solutions often require specialized hardware or suffer from\ndetection delays that do not meet safety standards. To tackle this issue, by\nre-modeling channel state information (CSI) with theoretical analysis of path\npropagation, this study introduces RapidPD, an innovative system utilizing CSI\nin subcarrier dimension to detect the presence of humans and pets in vehicles.\nThe system models the impact of motion on CSI and introduces motion statistics\nin subcarrier dimension using a multi-layer autocorrelation method to quantify\nenvironmental changes. RapidPD is implemented using commercial Wi-Fi chipsets\nand tested in real vehicle environments with data collected from 10 living\norganisms. Experimental results demonstrate that RapidPD achieves a detection\naccuracy of 99.05% and a true positive rate of 99.32% within a 1-second time\nwindow at a low sampling rate of 20 Hz. These findings represent a significant\nadvancement in vehicle safety and provide a foundation for the widespread\nadoption of presence detection systems.", "published": "2025-04-01 11:44:11", "link": "http://arxiv.org/abs/2504.00678v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-stage Group Testing with (r,s)-regular design Algorithms", "abstract": "In industrial engineering and manufacturing, quality control is an essential\npart of the production process of a product. To ensure proper functionality of\na manufactured good, rigorous testing has to be performed to identify defective\nproducts before shipment to the customer. However, testing products\nindividually in a sequential manner is often tedious, cumbersome and not widely\napplicable given that time, resources and personnel are limited. Thus,\nstatistical methods have been employed to investigate random samples of\nproducts from batches. For instance, group testing has emerged as an\nalternative to reliably test manufactured goods by evaluating joint test\nresults. Despite the clear advantages, existing group testing methods often\nstruggle with efficiency and practicality in real-world industry settings,\nwhere minimizing the average number of tests and overall testing duration is\ncritical. In this paper, novel multistage (r,s)-regular design algorithms in\nthe framework of group testing for the identification of defective products are\ninvestigated. Motivated by the application in quality control in manufacturing,\nunifying expressions for the expected number of tests and expected duration are\nderived. The results show that the novel group testing algorithms outperform\nestablished algorithms for low probabilities of defectiveness and get close to\nthe optimal counting bound while maintaining a low level of complexity.\nMathematical proofs are supported by rigorous simulation studies and an\nevaluation of the performance.", "published": "2025-04-01 10:07:11", "link": "http://arxiv.org/abs/2504.00611v1", "categories": ["stat.ME", "eess.SP"], "primary_category": "stat.ME"}
{"title": "Near Field Localization via AI-Aided Subspace Methods", "abstract": "The increasing demands for high-throughput and energy-efficient wireless\ncommunications are driving the adoption of extremely large antennas operating\nat high-frequency bands. In these regimes, multiple users will reside in the\nradiative near-field, and accurate localization becomes essential. Unlike\nconventional far-field systems that rely solely on DOA estimation, near-field\nlocalization exploits spherical wavefront propagation to recover both DOA and\nrange information. While subspace-based methods, such as MUSIC and its\nextensions, offer high resolution and interpretability for near-field\nlocalization, their performance is significantly impacted by model assumptions,\nincluding non-coherent sources, well-calibrated arrays, and a sufficient number\nof snapshots. To address these limitations, this work proposes AI-aided\nsubspace methods for near-field localization that enhance robustness to\nreal-world challenges. Specifically, we introduce NF-SubspaceNet, a deep\nlearning-augmented 2D MUSIC algorithm that learns a surrogate covariance matrix\nto improve localization under challenging conditions, and DCD-MUSIC, a cascaded\nAI-aided approach that decouples angle and range estimation to reduce\ncomputational complexity. We further develop a novel model-order-aware training\nmethod to accurately estimate the number of sources, that is combined with\ncasting of near field subspace methods as AI models for learning. Extensive\nsimulations demonstrate that the proposed methods outperform classical and\nexisting deep-learning-based localization techniques, providing robust\nnear-field localization even under coherent sources, miscalibrations, and few\nsnapshots.", "published": "2025-04-01 09:57:01", "link": "http://arxiv.org/abs/2504.00599v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Deep Learning-Based Extended Target Tracking in ISAC Systems", "abstract": "In this paper, we explore the feasibility of using communication signals for\nextended target (ET) tracking in an integrated sensing and communication (ISAC)\nsystem. The ET is characterized by its center range, azimuth, orientation, and\ncontour shape, for which conventional scatterer-based tracking algorithms are\nhardly feasible due to the limited scatterer resolution in ISAC. To address\nthis challenge, we propose ISACTrackNet, a deep learning-based tracking model\nthat directly estimates ET kinematic and contour parameters from noisy received\nechoes. The model consists of three modules: Denoising module for clutter and\nself-interference suppression, Encoder module for instantaneous state\nestimation, and KalmanNet module for prediction refinement within a\nconstant-velocity state-space model. Simulation results show that ISACTrackNet\nachieves near-optimal accuracy in position and angle estimation compared to\nradar-based tracking methods, even under limited measurement resolution and\npartial occlusions, but orientation and contour shape estimation remains\nslightly suboptimal. These results clearly demonstrate the feasibility of using\ncommunication-only signals for reliable ET tracking.", "published": "2025-04-01 09:32:25", "link": "http://arxiv.org/abs/2504.00576v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Hierarchical Attention Networks for Lossless Point Cloud Attribute Compression", "abstract": "In this paper, we propose a deep hierarchical attention context model for\nlossless attribute compression of point clouds, leveraging a multi-resolution\nspatial structure and residual learning. A simple and effective Level of Detail\n(LoD) structure is introduced to yield a coarse-to-fine representation. To\nenhance efficiency, points within the same refinement level are encoded in\nparallel, sharing a common context point group. By hierarchically aggregating\ninformation from neighboring points, our attention model learns contextual\ndependencies across varying scales and densities, enabling comprehensive\nfeature extraction. We also adopt normalization for position coordinates and\nattributes to achieve scale-invariant compression. Additionally, we segment the\npoint cloud into multiple slices to facilitate parallel processing, further\noptimizing time complexity. Experimental results demonstrate that the proposed\nmethod offers better coding performance than the latest G-PCC for color and\nreflectance attributes while maintaining more efficient encoding and decoding\nruntimes.", "published": "2025-04-01 07:14:10", "link": "http://arxiv.org/abs/2504.00481v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Efficient and Sustainable Task Offloading in UAV-Assisted MEC Systems via Meta Deep Reinforcement Learning", "abstract": "Integrated into existing Mobile Edge Computing (MEC) systems, Unmanned Aerial\nVehicles (UAVs) serve as a cornerstone in meeting the stringent requirements of\nfuture Internet of Things (IoT) networks. The current endeavor studies an MEC\nsystem, in which a computationally-empowered UAV, wirelessly linked to a cloud\nserver, is destined for task offloading in uplink transmission of IoT devices.\nThe performance of this system is studied by formulating a resource allocation\nproblem, which aims to maximize the long-term computed task efficiency, while\nensuring the stability of task buffers at the IoT devices, UAV and cloud. The\nproblem jointly optimizes the uplink transmit power of IoT devices and their\noffloading decisions, the trajectory of the UAV and computing power at all\ntransceivers. Regarding the non-convex and stochastic nature of the problem, we\ndevise a multi-step solution approach. Initially, by invoking the fractional\nprogramming and Lyapunov theory, we transform the long-term optimization\nproblem into an equivalent per-time-slot form. Subsequently, we recast the\nreformulated problem as a Markov Decision Process (MDP), which reflects the\nnetwork dynamics. The MDP model, eventually, serves for training a Meta Twin\nDelayed Deep Deterministic Policy Gradient (MTD3) agent, in charge of adaptive\nresource allocation with respect to the MEC system variations derived from the\nmobility of the UAV and IoT devices. Simulations reveal the dominance of our\nproposed resource allocation approach over its Deep Reinforcement Learning\n(DRL)-powered counterparts, increasing computed task efficiency and reducing\ntask buffer lengths.", "published": "2025-04-01 06:18:37", "link": "http://arxiv.org/abs/2504.00453v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Adaptive Radar Detection in joint Range and Azimuth based on the Hierarchical Latent Variable Model", "abstract": "This paper focuses on the design of a robust decision scheme capable of\noperating in target-rich scenarios with unknown signal signatures (including\ntheir range positions, angles of arrival, and number) in a background of\nGaussian disturbance. To solve the problem at hand, a novel estimation\nprocedure is conceived resorting to the expectation-maximization algorithm in\nconjunction with the hierarchical latent variable model that are exploited to\ncome up with a maximum \\textit{a posteriori} rule for reliable signal\nclassification and angle of arrival estimation. The estimates returned by the\nprocedure are then used to build up an adaptive detection architecture in range\nand azimuth based on the likelihood ratio test with enhanced detection\nperformance. Remarkably, it is shown that the new decision scheme can maintain\nconstant the false alarm rate when the interference parameters vary in the\nconsidered range of values. The performance assessment, conducted by means of\nMonte Carlo simulation, highlights that the proposed detector exhibits superior\ndetection performance in comparison with the existing GLRT-based competitors.", "published": "2025-04-01 02:26:06", "link": "http://arxiv.org/abs/2504.00361v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Methodology for Detecting Energy Anomalies due to Multi-Replay Attacks on Electric Vehicle Charging Infrastructure", "abstract": "The increasing deployment of Electric Vehicle Charging Infrastructures\n(EVCIs) introduces cybersecurity challenges, particularly due to inherent\nvulnerabilities, making them susceptible to cyberattacks. The vulnerable points\nin EVCI are charging ports, which serve as the links between the EVs and the\nEVCI as they transfer the data along with the power. Data spoofing attacks\ntargeting these ports can compromise security, reliability, and overall system\nperformance by introducing anomalies in operational data. An efficient method\nfor identifying the charging port current magnitude variations is presented in\nthis research. The MATLAB/SIMULINK environment simulates an EVCI system for\nvarious data generating scenarios. A Temporal Convolution Network - Autoencoder\n(TCN-AE) model is used in training the multivariate time series data of EVCI\nand reconstructing it. The abnormalities in data are that various charging port\ncurrent magnitudes are replaced with their respective data of different\ndurations, thus enabling the replay attack scenarios. To detect anomalies, the\nerror between the original and reconstructed data is computed, and these error\nvalues are used for detecting the anomalies. With the help of the mean vector\nand covariance matrices of the errors, the anomaly score is computed in the\nform of Mahalanobis distance. The threshold is obtained from the short\nsub-sequence of the errors and optimized for the whole time series data. The\nobtained optimal threshold is compared with the anomaly score to detect the\nanomaly. The model demonstrates robust performance in data reconstruction by\nidentifying anomalies with an accuracy of 99.64%, to enhance the reliability\nand security in operations of EVCI.", "published": "2025-04-01 00:56:59", "link": "http://arxiv.org/abs/2504.00319v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Watts-Per-Intelligence: Part I (Energy Efficiency)", "abstract": "We present a mathematical framework for quantifying energy efficiency in\nintelligent systems by linking energy consumption to information processing\ncapacity. Our proposed watts per intelligence metric integrates algorithmic\nthermodynamic principles of Landauer with computational models of machine\nintelligence. By formalising the irreversible energy costs of computation, we\nderive rigorous lower bounds on energy usage of algorithmic intelligent systems\nand their adaptability. We introduce theorems that constrain the trade offs\nbetween intelligence output and energy expenditure. Our results contribute to\ndesign principles for energy efficient intelligent systems.", "published": "2025-04-01 18:01:16", "link": "http://arxiv.org/abs/2504.05328v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
