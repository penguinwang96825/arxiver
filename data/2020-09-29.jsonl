{"title": "Leader: Prefixing a Length for Faster Word Vector Serialization", "abstract": "Two competing file formats have become the de facto standards for\ndistributing pre-trained word embeddings. Both are named after the most popular\npre-trained embeddings that are distributed in that format. The GloVe format is\nan entirely text based format that suffers from huge file sizes and slow reads,\nand the word2vec format is a smaller binary format that mixes a textual\nrepresentation of words with a binary representation of the vectors themselves.\nBoth formats have problems that we solve with a new format we call the Leader\nformat. We include a word length prefix for faster reads while maintaining the\nsmaller file size a binary format offers. We also created a minimalist library\nto facilitate the reading and writing of various word vector formats, as well\nas tools for converting pre-trained embeddings to our new Leader format.", "published": "2020-09-29 00:25:24", "link": "http://arxiv.org/abs/2009.13699v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Retrieval for Question Answering with Cross-Attention Supervised\n  Data Augmentation", "abstract": "Neural models that independently project questions and answers into a shared\nembedding space allow for efficient continuous space retrieval from large\ncorpora. Independently computing embeddings for questions and answers results\nin late fusion of information related to matching questions to their answers.\nWhile critical for efficient retrieval, late fusion underperforms models that\nmake use of early fusion (e.g., a BERT based classifier with cross-attention\nbetween question-answer pairs). We present a supervised data mining method\nusing an accurate early fusion model to improve the training of an efficient\nlate fusion retrieval model. We first train an accurate classification model\nwith cross-attention between questions and answers. The accurate\ncross-attention model is then used to annotate additional passages in order to\ngenerate weighted training examples for a neural retrieval model. The resulting\nretrieval model with additional data significantly outperforms retrieval models\ndirectly trained with gold annotations on Precision at $N$ (P@N) and Mean\nReciprocal Rank (MRR).", "published": "2020-09-29 07:02:19", "link": "http://arxiv.org/abs/2009.13815v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HINT3: Raising the bar for Intent Detection in the Wild", "abstract": "Intent Detection systems in the real world are exposed to complexities of\nimbalanced datasets containing varying perception of intent, unintended\ncorrelations and domain-specific aberrations. To facilitate benchmarking which\ncan reflect near real-world scenarios, we introduce 3 new datasets created from\nlive chatbots in diverse domains. Unlike most existing datasets that are\ncrowdsourced, our datasets contain real user queries received by the chatbots\nand facilitates penalising unwanted correlations grasped during the training\nprocess. We evaluate 4 NLU platforms and a BERT based classifier and find that\nperformance saturates at inadequate levels on test sets because all systems\nlatch on to unintended patterns in training data.", "published": "2020-09-29 07:44:37", "link": "http://arxiv.org/abs/2009.13833v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020", "abstract": "The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.", "published": "2020-09-29 08:32:32", "link": "http://arxiv.org/abs/2009.13859v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence-to-Sequence Learning for Indonesian Automatic Question\n  Generator", "abstract": "Automatic question generation is defined as the task of automating the\ncreation of question given a various of textual data. Research in automatic\nquestion generator (AQG) has been conducted for more than 10 years, mainly\nfocused on factoid question. In all these studies, the state-of-the-art is\nattained using sequence-to-sequence approach. However, AQG system for\nIndonesian has not ever been researched intensely. In this work we construct an\nIndonesian automatic question generator, adapting the architecture from some\nprevious works. In summary, we used sequence-to-sequence approach using BiGRU,\nBiLSTM, and Transformer with additional linguistic features, copy mechanism,\nand coverage mechanism. Since there is no public large dan popular Indonesian\ndataset for question generation, we translated SQuAD v2.0 factoid question\nanswering dataset, with additional Indonesian TyDiQA dev set for testing. The\nsystem achieved BLEU1, BLEU2, BLEU3, BLEU4, and ROUGE-L score at 38,35, 20,96,\n10,68, 5,78, and 43,4 for SQuAD, and 39.9, 20.78, 10.26, 6.31, 44.13 for\nTyDiQA, respectively. The system performed well when the expected answers are\nnamed entities and are syntactically close with the context explaining them.\nAdditionally, from native Indonesian perspective, the best questions generated\nby our best models on their best cases are acceptable and reasonably useful.", "published": "2020-09-29 09:25:54", "link": "http://arxiv.org/abs/2009.13889v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Utterance-level Dialogue Understanding: An Empirical Study", "abstract": "The recent abundance of conversational data on the Web and elsewhere calls\nfor effective NLP systems for dialog understanding. Complete utterance-level\nunderstanding often requires context understanding, defined by nearby\nutterances. In recent years, a number of approaches have been proposed for\nvarious utterance-level dialogue understanding tasks. Most of these approaches\naccount for the context for effective understanding. In this paper, we explore\nand quantify the role of context for different aspects of a dialogue, namely\nemotion, intent, and dialogue act identification, using state-of-the-art dialog\nunderstanding methods as baselines. Specifically, we employ various\nperturbations to distort the context of a given utterance and study its impact\non the different tasks and baselines. This provides us with insights into the\nfundamental contextual controlling factors of different aspects of a dialogue.\nSuch insights can inspire more effective dialogue understanding models, and\nprovide support for future text generation approaches. The implementation\npertaining to this work is available at\nhttps://github.com/declare-lab/dialogue-understanding.", "published": "2020-09-29 09:50:21", "link": "http://arxiv.org/abs/2009.13902v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning Intraobserver Agreement by Transitivity", "abstract": "Annotation reproducibility and accuracy rely on good consistency within\nannotators. We propose a novel method for measuring within annotator\nconsistency or annotator Intraobserver Agreement (IA). The proposed approach is\nbased on transitivity, a measure that has been thoroughly studied in the\ncontext of rational decision-making. The transitivity measure, in contrast with\nthe commonly used test-retest strategy for annotator IA, is less sensitive to\nthe several types of bias introduced by the test-retest strategy. We present a\nrepresentation theorem to the effect that relative judgement data that meet\ntransitivity can be mapped to a scale (in terms of measurement theory). We also\ndiscuss a further application of transitivity as part of data collection design\nfor addressing the problem of the quadratic complexity of data collection of\nrelative judgements.", "published": "2020-09-29 09:55:04", "link": "http://arxiv.org/abs/2009.13905v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Topic Modeling with Cycle-Consistent Adversarial Training", "abstract": "Advances on deep generative models have attracted significant research\ninterest in neural topic modeling. The recently proposed Adversarial-neural\nTopic Model models topics with an adversarially trained generator network and\nemploys Dirichlet prior to capture the semantic patterns in latent topics. It\nis effective in discovering coherent topics but unable to infer topic\ndistributions for given documents or utilize available document labels. To\novercome such limitations, we propose Topic Modeling with Cycle-consistent\nAdversarial Training (ToMCAT) and its supervised version sToMCAT. ToMCAT\nemploys a generator network to interpret topics and an encoder network to infer\ndocument topics. Adversarial training and cycle-consistent constraints are used\nto encourage the generator and the encoder to produce realistic samples that\ncoordinate with each other. sToMCAT extends ToMCAT by incorporating document\nlabels into the topic modeling process to help discover more coherent topics.\nThe effectiveness of the proposed models is evaluated on\nunsupervised/supervised topic modeling and text classification. The\nexperimental results show that our models can produce both coherent and\ninformative topics, outperforming a number of competitive baselines.", "published": "2020-09-29 12:41:27", "link": "http://arxiv.org/abs/2009.13971v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Topic Modeling by Incorporating Document Relationship Graph", "abstract": "Graph Neural Networks (GNNs) that capture the relationships between graph\nnodes via message passing have been a hot research direction in the natural\nlanguage processing community. In this paper, we propose Graph Topic Model\n(GTM), a GNN based neural topic model that represents a corpus as a document\nrelationship graph. Documents and words in the corpus become nodes in the graph\nand are connected based on document-word co-occurrences. By introducing the\ngraph structure, the relationships between documents are established through\ntheir shared words and thus the topical representation of a document is\nenriched by aggregating information from its neighboring nodes using graph\nconvolution. Extensive experiments on three datasets were conducted and the\nresults demonstrate the effectiveness of the proposed approach.", "published": "2020-09-29 12:45:55", "link": "http://arxiv.org/abs/2009.13972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building Legal Case Retrieval Systems with Lexical Matching and\n  Summarization using A Pre-Trained Phrase Scoring Model", "abstract": "We present our method for tackling the legal case retrieval task of the\nCompetition on Legal Information Extraction/Entailment 2019. Our approach is\nbased on the idea that summarization is important for retrieval. On one hand,\nwe adopt a summarization based model called encoded summarization which encodes\na given document into continuous vector space which embeds the summary\nproperties of the document. We utilize the resource of COLIEE 2018 on which we\ntrain the document representation model. On the other hand, we extract lexical\nfeatures on different parts of a given query and its candidates. We observe\nthat by comparing different parts of the query and its candidates, we can\nachieve better performance. Furthermore, the combination of the lexical\nfeatures with latent features by the summarization-based method achieves even\nbetter performance. We have achieved the state-of-the-art result for the task\non the benchmark of the competition.", "published": "2020-09-29 15:10:59", "link": "http://arxiv.org/abs/2009.14083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Low Compute Language Modeling with In-Domain Embedding\n  Initialisation", "abstract": "Many NLP applications, such as biomedical data and technical support, have\n10-100 million tokens of in-domain data and limited computational resources for\nlearning from it. How should we train a language model in this scenario? Most\nlanguage modeling research considers either a small dataset with a closed\nvocabulary (like the standard 1 million token Penn Treebank), or the whole web\nwith byte-pair encoding. We show that for our target setting in English,\ninitialising and freezing input embeddings using in-domain data can improve\nlanguage model performance by providing a useful representation of rare words,\nand this pattern holds across several different domains. In the process, we\nshow that the standard convention of tying input and output embeddings does not\nimprove perplexity when initializing with embeddings trained on in-domain data.", "published": "2020-09-29 15:48:58", "link": "http://arxiv.org/abs/2009.14109v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Survey on Semantic Parsing from the perspective of Compositionality", "abstract": "Different from previous surveys in semantic parsing (Kamath and Das, 2018)\nand knowledge base question answering(KBQA)(Chakraborty et al., 2019; Zhu et\nal., 2019; Hoffner et al., 2017) we try to takes a different perspective on the\nstudy of semantic parsing. Specifically, we will focus on (a)meaning\ncomposition from syntactical structure(Partee, 1975), and (b) the ability of\nsemantic parsers to handle lexical variation given the context of a knowledge\nbase (KB). In the following section after an introduction of the field of\nsemantic parsing and its uses in KBQA, we will describe meaning representation\nusing grammar formalism CCG (Steedman, 1996). We will discuss semantic\ncomposition using formal languages in Section 2. In section 3 we will consider\nsystems that uses formal languages e.g. $\\lambda$-calculus (Steedman, 1996),\n$\\lambda$-DCS (Liang, 2013). Section 4 and 5 consider semantic parser using\nstructured-language for logical form. Section 6 is on different benchmark\ndatasets ComplexQuestions (Bao et al.,2016) and GraphQuestions (Su et al.,\n2016) that can be used to evaluate semantic parser on their ability to answer\ncomplex questions that are highly compositional in nature.", "published": "2020-09-29 16:03:13", "link": "http://arxiv.org/abs/2009.14116v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parsing with Multilingual BERT, a Small Corpus, and a Small Treebank", "abstract": "Pretrained multilingual contextual representations have shown great success,\nbut due to the limits of their pretraining data, their benefits do not apply\nequally to all language varieties. This presents a challenge for language\nvarieties unfamiliar to these models, whose labeled \\emph{and unlabeled} data\nis too limited to train a monolingual model effectively. We propose the use of\nadditional language-specific pretraining and vocabulary augmentation to adapt\nmultilingual models to low-resource settings. Using dependency parsing of four\ndiverse low-resource language varieties as a case study, we show that these\nmethods significantly improve performance over baselines, especially in the\nlowest-resource cases, and demonstrate the importance of the relationship\nbetween such models' pretraining data and target language varieties.", "published": "2020-09-29 16:12:52", "link": "http://arxiv.org/abs/2009.14124v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Alignment Methods for Multilingual BERT: A Comparative\n  Study", "abstract": "Multilingual BERT (mBERT) has shown reasonable capability for zero-shot\ncross-lingual transfer when fine-tuned on downstream tasks. Since mBERT is not\npre-trained with explicit cross-lingual supervision, transfer performance can\nfurther be improved by aligning mBERT with cross-lingual signal. Prior work\nproposes several approaches to align contextualised embeddings. In this paper\nwe analyse how different forms of cross-lingual supervision and various\nalignment methods influence the transfer capability of mBERT in zero-shot\nsetting. Specifically, we compare parallel corpora vs. dictionary-based\nsupervision and rotational vs. fine-tuning based alignment methods. We evaluate\nthe performance of different alignment methodologies across eight languages on\ntwo tasks: Name Entity Recognition and Semantic Slot Filling. In addition, we\npropose a novel normalisation method which consistently improves the\nperformance of rotation-based alignment including a notable 3% F1 improvement\nfor distant and typologically dissimilar languages. Importantly we identify the\nbiases of the alignment methods to the type of task and proximity to the\ntransfer language. We also find that supervision from parallel corpus is\ngenerally superior to dictionary alignments.", "published": "2020-09-29 20:56:57", "link": "http://arxiv.org/abs/2009.14304v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "INSPIRED: Toward Sociable Recommendation Dialog Systems", "abstract": "In recommendation dialogs, humans commonly disclose their preference and make\nrecommendations in a friendly manner. However, this is a challenge when\ndeveloping a sociable recommendation dialog system, due to the lack of dialog\ndataset annotated with such sociable strategies. Therefore, we present\nINSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation\nwith measures for successful recommendations. To better understand how humans\nmake recommendations in communication, we design an annotation scheme related\nto recommendation strategies based on social science theories and annotate\nthese dialogs. Our analysis shows that sociable recommendation strategies, such\nas sharing personal opinions or communicating with encouragement, more\nfrequently lead to successful recommendations. Based on our dataset, we train\nend-to-end recommendation dialog systems with and without our strategy labels.\nIn both automatic and human evaluation, our model with strategy incorporation\noutperforms the baseline model. This work is a first step for building sociable\nrecommendation dialog systems with a basis of social science theories.", "published": "2020-09-29 21:03:44", "link": "http://arxiv.org/abs/2009.14306v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NatCat: Weakly Supervised Text Classification with Naturally Annotated\n  Resources", "abstract": "We describe NatCat, a large-scale resource for text classification\nconstructed from three data sources: Wikipedia, Stack Exchange, and Reddit.\nNatCat consists of document-category pairs derived from manual curation that\noccurs naturally within online communities. To demonstrate its usefulness, we\nbuild general purpose text classifiers by training on NatCat and evaluate them\non a suite of 11 text classification tasks (CatEval), reporting large\nimprovements compared to prior work. We benchmark different modeling choices\nand resource combinations and show how tasks benefit from particular NatCat\ndata sources.", "published": "2020-09-29 22:49:15", "link": "http://arxiv.org/abs/2009.14335v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaP: A Matrix-based Prediction Approach to Improve Span Extraction in\n  Machine Reading Comprehension", "abstract": "Span extraction is an essential problem in machine reading comprehension.\nMost of the existing algorithms predict the start and end positions of an\nanswer span in the given corresponding context by generating two probability\nvectors. In this paper, we propose a novel approach that extends the\nprobability vector to a probability matrix. Such a matrix can cover more\nstart-end position pairs. Precisely, to each possible start index, the method\nalways generates an end probability vector. Besides, we propose a\nsampling-based training strategy to address the computational cost and memory\nissue in the matrix training phase. We evaluate our method on SQuAD 1.1 and\nthree other question answering benchmarks. Leveraging the most competitive\nmodels BERT and BiDAF as the backbone, our proposed approach can get consistent\nimprovements in all datasets, demonstrating the effectiveness of the proposed\nmethod.", "published": "2020-09-29 23:53:50", "link": "http://arxiv.org/abs/2009.14348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple but Tough-to-Beat Data Augmentation Approach for Natural\n  Language Understanding and Generation", "abstract": "Adversarial training has been shown effective at endowing the learned\nrepresentations with stronger generalization ability. However, it typically\nrequires expensive computation to determine the direction of the injected\nperturbations. In this paper, we introduce a set of simple yet effective data\naugmentation strategies dubbed cutoff, where part of the information within an\ninput sentence is erased to yield its restricted views (during the fine-tuning\nstage). Notably, this process relies merely on stochastic sampling and thus\nadds little computational overhead. A Jensen-Shannon Divergence consistency\nloss is further utilized to incorporate these augmented samples into the\ntraining objective in a principled manner. To verify the effectiveness of the\nproposed strategies, we apply cutoff to both natural language understanding and\ngeneration problems. On the GLUE benchmark, it is demonstrated that cutoff, in\nspite of its simplicity, performs on par or better than several competitive\nadversarial-based approaches. We further extend cutoff to machine translation\nand observe significant gains in BLEU scores (based upon the Transformer Base\nmodel). Moreover, cutoff consistently outperforms adversarial training and\nachieves state-of-the-art results on the IWSLT2014 German-English dataset.", "published": "2020-09-29 07:08:35", "link": "http://arxiv.org/abs/2009.13818v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and\n  Synonym Discovery", "abstract": "Entity set expansion and synonym discovery are two critical NLP tasks.\nPrevious studies accomplish them separately, without exploring their\ninterdependencies. In this work, we hypothesize that these two tasks are\ntightly coupled because two synonymous entities tend to have similar\nlikelihoods of belonging to various semantic classes. This motivates us to\ndesign SynSetExpan, a novel framework that enables two tasks to mutually\nenhance each other. SynSetExpan uses a synonym discovery model to include\npopular entities' infrequent synonyms into the set, which boosts the set\nexpansion recall. Meanwhile, the set expansion model, being able to determine\nwhether an entity belongs to a semantic class, can generate pseudo training\ndata to fine-tune the synonym discovery model towards better accuracy. To\nfacilitate the research on studying the interplays of these two tasks, we\ncreate the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via\ncrowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks\ndemonstrate the effectiveness of SynSetExpan for both entity set expansion and\nsynonym discovery tasks.", "published": "2020-09-29 07:32:17", "link": "http://arxiv.org/abs/2009.13827v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing", "abstract": "We present GraPPa, an effective pre-training approach for table semantic\nparsing that learns a compositional inductive bias in the joint representations\nof textual and tabular data. We construct synthetic question-SQL pairs over\nhigh-quality tables via a synchronous context-free grammar (SCFG) induced from\nexisting text-to-SQL datasets. We pre-train our model on the synthetic data\nusing a novel text-schema linking objective that predicts the syntactic role of\na table field in the SQL for each question-SQL pair. To maintain the model's\nability to represent real-world data, we also include masked language modeling\n(MLM) over several existing table-and-language datasets to regularize the\npre-training process. On four popular fully supervised and weakly supervised\ntable semantic parsing benchmarks, GraPPa significantly outperforms\nRoBERTa-large as the feature representation layers and establishes new\nstate-of-the-art results on all of them.", "published": "2020-09-29 08:17:58", "link": "http://arxiv.org/abs/2009.13845v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced\n  Pre-Trained Language Models", "abstract": "Several recent efforts have been devoted to enhancing pre-trained language\nmodels (PLMs) by utilizing extra heterogeneous knowledge in knowledge graphs\n(KGs) and achieved consistent improvements on various knowledge-driven NLP\ntasks. However, most of these knowledge-enhanced PLMs embed static sub-graphs\nof KGs (\"knowledge context\"), regardless of that the knowledge required by PLMs\nmay change dynamically according to specific text (\"textual context\"). In this\npaper, we propose a novel framework named Coke to dynamically select contextual\nknowledge and embed knowledge context according to textual context for PLMs,\nwhich can avoid the effect of redundant and ambiguous knowledge in KGs that\ncannot match the input text. Our experimental results show that Coke\noutperforms various baselines on typical knowledge-driven NLP tasks, indicating\nthe effectiveness of utilizing dynamic knowledge context for language\nunderstanding. Besides the performance improvements, the dynamically selected\nknowledge in Coke can describe the semantics of text-related knowledge in a\nmore interpretable form than the conventional PLMs. Our source code and\ndatasets will be available to provide more details for Coke.", "published": "2020-09-29 12:29:04", "link": "http://arxiv.org/abs/2009.13964v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contrastive Distillation on Intermediate Representations for Language\n  Model Compression", "abstract": "Existing language model compression methods mostly use a simple L2 loss to\ndistill knowledge in the intermediate representations of a large BERT model to\na smaller one. Although widely used, this objective by design assumes that all\nthe dimensions of hidden representations are independent, failing to capture\nimportant structural knowledge in the intermediate layers of the teacher\nnetwork. To achieve better distillation efficacy, we propose Contrastive\nDistillation on Intermediate Representations (CoDIR), a principled knowledge\ndistillation framework where the student is trained to distill knowledge\nthrough intermediate layers of the teacher via a contrastive objective. By\nlearning to distinguish positive sample from a large set of negative samples,\nCoDIR facilitates the student's exploitation of rich information in teacher's\nhidden layers. CoDIR can be readily applied to compress large-scale language\nmodels in both pre-training and finetuning stages, and achieves superb\nperformance on the GLUE benchmark, outperforming state-of-the-art compression\nmethods.", "published": "2020-09-29 17:31:43", "link": "http://arxiv.org/abs/2009.14167v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Visually-Grounded Planning without Vision: Language Models Infer\n  Detailed Plans from High-level Instructions", "abstract": "The recently proposed ALFRED challenge task aims for a virtual robotic agent\nto complete complex multi-step everyday tasks in a virtual home environment\nfrom high-level natural language directives, such as \"put a hot piece of bread\non a plate\". Currently, the best-performing models are able to complete less\nthan 5% of these tasks successfully. In this work we focus on modeling the\ntranslation problem of converting natural language directives into detailed\nmulti-step sequences of actions that accomplish those goals in the virtual\nenvironment. We empirically demonstrate that it is possible to generate gold\nmulti-step plans from language directives alone without any visual input in 26%\nof unseen cases. When a small amount of visual information is incorporated,\nnamely the starting location in the virtual environment, our best-performing\nGPT-2 model successfully generates gold command sequences in 58% of cases. Our\nresults suggest that contextualized language models may provide strong visual\nsemantic planning modules for grounded virtual agents.", "published": "2020-09-29 18:52:39", "link": "http://arxiv.org/abs/2009.14259v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Clinical Acronym Expansion via Latent Meaning Cells", "abstract": "We introduce Latent Meaning Cells, a deep latent variable model which learns\ncontextualized representations of words by combining local lexical context and\nmetadata. Metadata can refer to granular context, such as section type, or to\nmore global context, such as unique document ids. Reliance on metadata for\ncontextualized representation learning is apropos in the clinical domain where\ntext is semi-structured and expresses high variation in topics. We evaluate the\nLMC model on the task of zero-shot clinical acronym expansion across three\ndatasets. The LMC significantly outperforms a diverse set of baselines at a\nfraction of the pre-training cost and learns clinically coherent\nrepresentations. We demonstrate that not only is metadata itself very helpful\nfor the task, but that the LMC inference algorithm provides an additional large\nbenefit.", "published": "2020-09-29 00:28:30", "link": "http://arxiv.org/abs/2010.02010v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Spatial Attention as an Interface for Image Captioning Models", "abstract": "The internal workings of modern deep learning models stay often unclear to an\nexternal observer, although spatial attention mechanisms are involved. The idea\nof this work is to translate these spatial attentions into natural language to\nprovide a simpler access to the model's function. Thus, I took a neural image\ncaptioning model and measured the reactions to external modification in its\nspatial attention for three different interface methods: a fixation over the\nwhole generation process, a fixation for the first time-steps and an addition\nto the generator's attention. The experimental results for bounding box based\nspatial attention vectors have shown that the captioning model reacts to method\ndependent changes in up to 52.65% and includes in 9.00% of the cases object\ncategories, which were otherwise unmentioned. Afterwards, I established such a\nlink to a hierarchical co-attention network for visual question answering by\nextraction of its word, phrase and question level spatial attentions. Here,\ngenerated captions for the word level included details of the question-answer\npairs in up to 55.20% of the cases. This work indicates that spatial attention\nseen as an external interface for image caption generators is an useful method\nto access visual functions in natural language.", "published": "2020-09-29 16:04:08", "link": "http://arxiv.org/abs/2010.11701v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Adversarial Attacks Against Deep Learning Systems for ICD-9 Code\n  Assignment", "abstract": "Manual annotation of ICD-9 codes is a time consuming and error-prone process.\nDeep learning based systems tackling the problem of automated ICD-9 coding have\nachieved competitive performance. Given the increased proliferation of\nelectronic medical records, such automated systems are expected to eventually\nreplace human coders. In this work, we investigate how a simple typo-based\nadversarial attack strategy can impact the performance of state-of-the-art\nmodels for the task of predicting the top 50 most frequent ICD-9 codes from\ndischarge summaries. Preliminary results indicate that a malicious adversary,\nusing gradient information, can craft specific perturbations, that appear as\nregular human typos, for less than 3% of words in the discharge summary to\nsignificantly affect the performance of the baseline model.", "published": "2020-09-29 01:45:11", "link": "http://arxiv.org/abs/2009.13720v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Double Graph Based Reasoning for Document-level Relation Extraction", "abstract": "Document-level relation extraction aims to extract relations among entities\nwithin a document. Different from sentence-level relation extraction, it\nrequires reasoning over multiple sentences across a document. In this paper, we\npropose Graph Aggregation-and-Inference Network (GAIN) featuring double graphs.\nGAIN first constructs a heterogeneous mention-level graph (hMG) to model\ncomplex interaction among different mentions across the document. It also\nconstructs an entity-level graph (EG), based on which we propose a novel path\nreasoning mechanism to infer relations between entities. Experiments on the\npublic dataset, DocRED, show GAIN achieves a significant performance\nimprovement (2.85 on F1) over the previous state-of-the-art. Our code is\navailable at https://github.com/DreamInvoker/GAIN .", "published": "2020-09-29 03:41:01", "link": "http://arxiv.org/abs/2009.13752v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EEMC: Embedding Enhanced Multi-tag Classification", "abstract": "The recently occurred representation learning make an attractive performance\nin NLP and complex network, it is becoming a fundamental technology in machine\nlearning and data mining. How to use representation learning to improve the\nperformance of classifiers is a very significance research direction. We using\nrepresentation learning technology to map raw data(node of graph) to a\nlow-dimensional feature space. In this space, each raw data obtained a lower\ndimensional vector representation, we do some simple linear operations for\nthose vectors to produce some virtual data, using those vectors and virtual\ndata to training multi-tag classifier. After that we measured the performance\nof classifier by F1 score(Macro% F1 and Micro% F1). Our method make Macro F1\nrise from 28 % - 450% and make average F1 score rise from 12 % - 224%. By\ncontrast, we trained the classifier directly with the lower dimensional vector,\nand measured the performance of classifiers. We validate our algorithm on three\npublic data sets, we found that the virtual data helped the classifier greatly\nimprove the F1 score. Therefore, our algorithm is a effective way to improve\nthe performance of classifier. These result suggest that the virtual data\ngenerated by simple linear operation, in representation space, still retains\nthe information of the raw data. It's also have great significance to the\nlearning of small sample data sets.", "published": "2020-09-29 07:29:34", "link": "http://arxiv.org/abs/2009.13826v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Utility is in the Eye of the User: A Critique of NLP Leaderboards", "abstract": "Benchmarks such as GLUE have helped drive advances in NLP by incentivizing\nthe creation of more accurate models. While this leaderboard paradigm has been\nremarkably successful, a historical focus on performance-based evaluation has\nbeen at the expense of other qualities that the NLP community values in models,\nsuch as compactness, fairness, and energy efficiency. In this opinion paper, we\nstudy the divergence between what is incentivized by leaderboards and what is\nuseful in practice through the lens of microeconomic theory. We frame both the\nleaderboard and NLP practitioners as consumers and the benefit they get from a\nmodel as its utility to them. With this framing, we formalize how leaderboards\n-- in their current form -- can be poor proxies for the NLP community at large.\nFor example, a highly inefficient model would provide less utility to\npractitioners but not to a leaderboard, since it is a cost that only the former\nmust bear. To allow practitioners to better estimate a model's utility to them,\nwe advocate for more transparency on leaderboards, such as the reporting of\nstatistics that are of practical concern (e.g., model size, energy efficiency,\nand inference latency).", "published": "2020-09-29 09:25:31", "link": "http://arxiv.org/abs/2009.13888v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The design and implementation of Language Learning Chatbot with XAI\n  using Ontology and Transfer Learning", "abstract": "In this paper, we proposed a transfer learning-based English language\nlearning chatbot, whose output generated by GPT-2 can be explained by\ncorresponding ontology graph rooted by fine-tuning dataset. We design three\nlevels for systematically English learning, including phonetics level for\nspeech recognition and pronunciation correction, semantic level for specific\ndomain conversation, and the simulation of free-style conversation in English -\nthe highest level of language chatbot communication as free-style conversation\nagent. For academic contribution, we implement the ontology graph to explain\nthe performance of free-style conversation, following the concept of XAI\n(Explainable Artificial Intelligence) to visualize the connections of neural\nnetwork in bionics, and explain the output sentence from language model. From\nimplementation perspective, our Language Learning agent integrated the\nmini-program in WeChat as front-end, and fine-tuned GPT-2 model of transfer\nlearning as back-end to interpret the responses by ontology graph.", "published": "2020-09-29 13:11:40", "link": "http://arxiv.org/abs/2009.13984v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Augmenting Scientific Papers with Just-in-Time, Position-Sensitive\n  Definitions of Terms and Symbols", "abstract": "Despite the central importance of research papers to scientific progress,\nthey can be difficult to read. Comprehension is often stymied when the\ninformation needed to understand a passage resides somewhere else: in another\nsection, or in another paper. In this work, we envision how interfaces can\nbring definitions of technical terms and symbols to readers when and where they\nneed them most. We introduce ScholarPhi, an augmented reading interface with\nfour novel features: (1) tooltips that surface position-sensitive definitions\nfrom elsewhere in a paper, (2) a filter over the paper that \"declutters\" it to\nreveal how the term or symbol is used across the paper, (3) automatic equation\ndiagrams that expose multiple definitions in parallel, and (4) an automatically\ngenerated glossary of important terms and symbols. A usability study showed\nthat the tool helps researchers of all experience levels read papers.\nFurthermore, researchers were eager to have ScholarPhi's definitions available\nto support their everyday reading.", "published": "2020-09-29 18:11:19", "link": "http://arxiv.org/abs/2009.14237v3", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.2"], "primary_category": "cs.HC"}
{"title": "TEST_POSITIVE at W-NUT 2020 Shared Task-3: Joint Event Multi-task\n  Learning for Slot Filling in Noisy Text", "abstract": "The competition of extracting COVID-19 events from Twitter is to develop\nsystems that can automatically extract related events from tweets. The built\nsystem should identify different pre-defined slots for each event, in order to\nanswer important questions (e.g., Who is tested positive? What is the age of\nthe person? Where is he/she?). To tackle these challenges, we propose the Joint\nEvent Multi-task Learning (JOELIN) model. Through a unified global learning\nframework, we make use of all the training data across different events to\nlearn and fine-tune the language model. Moreover, we implement a type-aware\npost-processing procedure using named entity recognition (NER) to further\nfilter the predictions. JOELIN outperforms the BERT baseline by 17.2% in micro\nF1.", "published": "2020-09-29 19:08:45", "link": "http://arxiv.org/abs/2009.14262v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Improving Device Directedness Classification of Utterances with Semantic\n  Lexical Features", "abstract": "User interactions with personal assistants like Alexa, Google Home and Siri\nare typically initiated by a wake term or wakeword. Several personal assistants\nfeature \"follow-up\" modes that allow users to make additional interactions\nwithout the need of a wakeword. For the system to only respond when\nappropriate, and to ignore speech not intended for it, utterances must be\nclassified as device-directed or non-device-directed. State-of-the-art systems\nhave largely used acoustic features for this task, while others have used only\nlexical features or have added LM-based lexical features. We propose a\ndirectedness classifier that combines semantic lexical features with a\nlightweight acoustic feature and show it is effective in classifying\ndirectedness. The mixed-domain lexical and acoustic feature model is able to\nachieve 14% relative reduction of EER over a state-of-the-art acoustic-only\nbaseline model. Finally, we successfully apply transfer learning and\nsemi-supervised learning to the model to improve accuracy even further.", "published": "2020-09-29 20:13:58", "link": "http://arxiv.org/abs/2010.01949v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Gender prediction using limited Twitter Data", "abstract": "Transformer models have shown impressive performance on a variety of NLP\ntasks. Off-the-shelf, pre-trained models can be fine-tuned for specific NLP\nclassification tasks, reducing the need for large amounts of additional\ntraining data. However, little research has addressed how much data is required\nto accurately fine-tune such pre-trained transformer models, and how much data\nis needed for accurate prediction. This paper explores the usability of BERT (a\nTransformer model for word embedding) for gender prediction on social media.\nForensic applications include detecting gender obfuscation, e.g. males posing\nas females in chat rooms. A Dutch BERT model is fine-tuned on different samples\nof a Dutch Twitter dataset labeled for gender, varying in the number of tweets\nused per person. The results show that finetuning BERT contributes to good\ngender classification performance (80% F1) when finetuned on only 200 tweets\nper person. But when using just 20 tweets per person, the performance of our\nclassifier deteriorates non-steeply (to 70% F1). These results show that even\nwith relatively small amounts of data, BERT can be fine-tuned to accurately\nhelp predict the gender of Twitter users, and, consequently, that it is\npossible to determine gender on the basis of just a low volume of tweets. This\nopens up an operational perspective on the swift detection of gender.", "published": "2020-09-29 11:46:07", "link": "http://arxiv.org/abs/2010.02005v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Language Modeling With Implicit Cache Pointers", "abstract": "A cache-inspired approach is proposed for neural language models (LMs) to\nimprove long-range dependency and better predict rare words from long contexts.\nThis approach is a simpler alternative to attention-based pointer mechanism\nthat enables neural LMs to reproduce words from recent history. Without using\nattention and mixture structure, the method only involves appending extra\ntokens that represent words in history to the output layer of a neural LM and\nmodifying training supervisions accordingly. A memory-augmentation unit is\nintroduced to learn words that are particularly likely to repeat. We experiment\nwith both recurrent neural network- and Transformer-based LMs. Perplexity\nevaluation on Penn Treebank and WikiText-2 shows the proposed model outperforms\nboth LSTM and LSTM with attention-based pointer mechanism and is more effective\non rare words. N-best rescoring experiments on Switchboard indicate that it\nbenefits both very rare and frequent words. However, it is challenging for the\nproposed model as well as two other models with attention-based pointer\nmechanism to obtain good overall WER reductions.", "published": "2020-09-29 04:19:55", "link": "http://arxiv.org/abs/2009.13774v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Clova Baseline System for the VoxCeleb Speaker Recognition Challenge\n  2020", "abstract": "This report describes our submission to the VoxCeleb Speaker Recognition\nChallenge (VoxSRC) at Interspeech 2020. We perform a careful analysis of\nspeaker recognition models based on the popular ResNet architecture, and train\na number of variants using a range of loss functions. Our results show\nsignificant improvements over most existing works without the use of model\nensemble or post-processing. We release the training code and pre-trained\nmodels as unofficial baselines for this year's challenge.", "published": "2020-09-29 16:55:25", "link": "http://arxiv.org/abs/2009.14153v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Bespoke Neural Networks for Score-Informed Source Separation", "abstract": "In this paper, we introduce a simple method that can separate arbitrary\nmusical instruments from an audio mixture. Given an unaligned MIDI\ntranscription for a target instrument from an input mixture, we synthesize new\nmixtures from the midi transcription that sound similar to the mixture to be\nseparated. This lets us create a labeled training set to train a network on the\nspecific bespoke task. When this model applied to the original mixture, we\ndemonstrate that this method can: 1) successfully separate out the desired\ninstrument with access to only unaligned MIDI, 2) separate arbitrary\ninstruments, and 3) get results in a fraction of the time of existing methods.\nWe encourage readers to listen to the demos posted here: https://git.io/JUu5q.", "published": "2020-09-29 02:09:23", "link": "http://arxiv.org/abs/2009.13729v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Residual acoustic echo suppression based on efficient multi-task\n  convolutional neural network", "abstract": "Acoustic echo degrades the user experience in voice communication systems\nthus needs to be suppressed completely. We propose a real-time residual\nacoustic echo suppression (RAES) method using an efficient convolutional neural\nnetwork. The double talk detector is used as an auxiliary task to improve the\nperformance of RAES in the context of multi-task learning. The training\ncriterion is based on a novel loss function, which we call as the suppression\nloss, to balance the suppression of residual echo and the distortion of\nnear-end signals. The experimental results show that the proposed method can\nefficiently suppress the residual echo under different circumstances.", "published": "2020-09-29 11:26:25", "link": "http://arxiv.org/abs/2009.13931v2", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Hear Her Fear: Data Sonification for Sensitizing Society on Crime\n  Against Women in India", "abstract": "Data sonification is a means of representing data through sound and has been\nutilized in a variety of applications. Crime against women has been a rising\nconcern in India. We explore the potential of data sonification to provide an\nimmersive engagement with sensitive data on crime against women in Indian\nstates. The data for nine crime categories covering thirty-five Indian states\nover a period of twelve years is acquired from National records. Sonification\ntechniques of parameter mapping and auditory icons are adopted: sound\nparameters such as frequencies, amplitudes and timbres are incorporated to\nrepresent the crime data, and audio sounds of women screams are employed as\nauditory icons to emphasize the traumatic experience. Higher crime rates are\nassigned higher frequencies, harsher scream textures and larger amplitudes. A\nuser-friendly interface is developed with multiple options for sequential and\ncomparative data sonification. Through the interface, a user can evaluate and\ncompare the extent of crime against women in different states, years or crime\ncategories. Sound spatialization is used to immerse the listener in the sound\nand further intensify the sonification experience. To assess and validate\neffectiveness, a user study on twenty participants is conducted with feedback\nobtained through questionnaires. The responses indicate that the participants\ncould comprehend trends in the data easily and found the data sonification\nexperience impactful. Sonification may therefore prove to be a valuable tool\nfor data representation in fields related to social and human studies.", "published": "2020-09-29 17:49:31", "link": "http://arxiv.org/abs/2009.14182v3", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
