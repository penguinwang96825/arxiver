{"title": "DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented\n  Dialogue Representations", "abstract": "Language models pre-trained on general text have achieved impressive results\nin diverse fields. Yet, the distinct linguistic characteristics of\ntask-oriented dialogues (TOD) compared to general text limit the practical\nutility of existing language models. Current task-oriented dialogue\npre-training methods overlook the one-to-many property of conversations, where\nmultiple responses can be appropriate given the same conversation context. In\nthis paper, we propose a novel dialogue pre-training model called DivTOD, which\ncollaborates with LLMs to learn diverse task-oriented dialogue representations.\nDivTOD guides LLMs in transferring diverse knowledge to smaller models while\nremoving domain knowledge that contradicts task-oriented dialogues. Experiments\nshow that our model outperforms strong TOD baselines on various downstream\ndialogue tasks and learns the intrinsic diversity of task-oriented dialogues.", "published": "2024-03-31 04:36:57", "link": "http://arxiv.org/abs/2404.00557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Corpus Metadata to Detect Template-based Translation: An\n  Exploratory Case Study of the Egyptian Arabic Wikipedia Edition", "abstract": "Wikipedia articles (content pages) are commonly used corpora in Natural\nLanguage Processing (NLP) research, especially in low-resource languages other\nthan English. Yet, a few research studies have studied the three Arabic\nWikipedia editions, Arabic Wikipedia (AR), Egyptian Arabic Wikipedia (ARZ), and\nMoroccan Arabic Wikipedia (ARY), and documented issues in the Egyptian Arabic\nWikipedia edition regarding the massive automatic creation of its articles\nusing template-based translation from English to Arabic without human\ninvolvement, overwhelming the Egyptian Arabic Wikipedia with articles that do\nnot only have low-quality content but also with articles that do not represent\nthe Egyptian people, their culture, and their dialect. In this paper, we aim to\nmitigate the problem of template translation that occurred in the Egyptian\nArabic Wikipedia by identifying these template-translated articles and their\ncharacteristics through exploratory analysis and building automatic detection\nsystems. We first explore the content of the three Arabic Wikipedia editions in\nterms of density, quality, and human contributions and utilize the resulting\ninsights to build multivariate machine learning classifiers leveraging\narticles' metadata to detect the template-translated articles automatically. We\nthen publicly deploy and host the best-performing classifier, XGBoost, as an\nonline application called EGYPTIAN WIKIPEDIA SCANNER and release the extracted,\nfiltered, and labeled datasets to the research community to benefit from our\ndatasets and the online, web-based detection system.", "published": "2024-03-31 05:14:38", "link": "http://arxiv.org/abs/2404.00565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ParaICL: Towards Robust Parallel In-Context Learning", "abstract": "Large language models (LLMs) have become the norm in natural language\nprocessing (NLP), excelling in few-shot in-context learning (ICL) with their\nremarkable abilities. Nonetheless, the success of ICL largely hinges on the\nchoice of few-shot demonstration examples, making the selection process\nincreasingly crucial. Existing methods have delved into optimizing the quantity\nand semantic similarity of these examples to improve ICL performances. However,\nour preliminary experiments indicate that the effectiveness of ICL is limited\nby the length of the input context. Moreover, varying combinations of few-shot\ndemonstration examples can significantly boost accuracy across different test\nsamples. To address this, we propose a novel method named parallel in-context\nlearning (ParaICL) that effectively utilizes all demonstration examples without\nexceeding the manageable input context length. ParaICL employs parallel\nbatching to distribute demonstration examples into different batches according\nto the semantic similarities of the questions in the demonstrations to the test\nquestion. It then computes normalized batch semantic scores for each batch. A\nweighted average semantic objective, constrained by adaptive plausibility, is\napplied to select the most appropriate tokens. Through extensive experiments,\nwe validate the effectiveness of ParaICL and conduct ablation studies to\nunderscore its design rationale. We further demonstrate that ParaICL can\nseamlessly integrate with existing methods.", "published": "2024-03-31 05:56:15", "link": "http://arxiv.org/abs/2404.00570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explainable Multi-hop Question Generation: An End-to-End Approach\n  without Intermediate Question Labeling", "abstract": "In response to the increasing use of interactive artificial intelligence, the\ndemand for the capacity to handle complex questions has increased. Multi-hop\nquestion generation aims to generate complex questions that requires multi-step\nreasoning over several documents. Previous studies have predominantly utilized\nend-to-end models, wherein questions are decoded based on the representation of\ncontext documents. However, these approaches lack the ability to explain the\nreasoning process behind the generated multi-hop questions. Additionally, the\nquestion rewriting approach, which incrementally increases the question\ncomplexity, also has limitations due to the requirement of labeling data for\nintermediate-stage questions. In this paper, we introduce an end-to-end\nquestion rewriting model that increases question complexity through sequential\nrewriting. The proposed model has the advantage of training with only the final\nmulti-hop questions, without intermediate questions. Experimental results\ndemonstrate the effectiveness of our model in generating complex questions,\nparticularly 3- and 4-hop questions, which are appropriately paired with input\nanswers. We also prove that our model logically and incrementally increases the\ncomplexity of questions, and the generated multi-hop questions are also\nbeneficial for training question answering models.", "published": "2024-03-31 06:03:54", "link": "http://arxiv.org/abs/2404.00571v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LexAbSumm: Aspect-based Summarization of Legal Decisions", "abstract": "Legal professionals frequently encounter long legal judgments that hold\ncritical insights for their work. While recent advances have led to automated\nsummarization solutions for legal documents, they typically provide generic\nsummaries, which may not meet the diverse information needs of users. To\naddress this gap, we introduce LexAbSumm, a novel dataset designed for\naspect-based summarization of legal case decisions, sourced from the European\nCourt of Human Rights jurisdiction. We evaluate several abstractive\nsummarization models tailored for longer documents on LexAbSumm, revealing a\nchallenge in conditioning these models to produce aspect-specific summaries. We\nrelease LexAbSum to facilitate research in aspect-based summarization for legal\ndomain.", "published": "2024-03-31 08:00:40", "link": "http://arxiv.org/abs/2404.00594v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation", "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities but are prone to\ngenerating inaccurate or hallucinatory responses. This limitation stems from\ntheir reliance on vast pretraining datasets, making them susceptible to errors\nin unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation\n(RAG) addresses this by incorporating external, relevant documents into the\nresponse generation process, thus leveraging non-parametric knowledge alongside\nLLMs' in-context learning abilities. However, existing RAG implementations\nprimarily focus on initial input for context retrieval, overlooking the nuances\nof ambiguous or complex queries that necessitate further clarification or\ndecomposition for accurate responses. To this end, we propose learning to\nRefine Query for Retrieval Augmented Generation (RQ-RAG) in this paper,\nendeavoring to enhance the model by equipping it with capabilities for explicit\nrewriting, decomposition, and disambiguation. Our experimental results indicate\nthat our method, when applied to a 7B Llama2 model, surpasses the previous\nstate-of-the-art (SOTA) by an average of 1.9\\% across three single-hop QA\ndatasets, and also demonstrates enhanced performance in handling complex,\nmulti-hop QA datasets. Our code is available at\nhttps://github.com/chanchimin/RQ-RAG.", "published": "2024-03-31 08:58:54", "link": "http://arxiv.org/abs/2404.00610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reporting Eye-Tracking Data Quality: Towards a New Standard", "abstract": "Eye-tracking datasets are often shared in the format used by their creators\nfor their original analyses, usually resulting in the exclusion of data\nconsidered irrelevant to the primary purpose. In order to increase re-usability\nof existing eye-tracking datasets for more diverse and initially not considered\nuse cases, this work advocates a new approach of sharing eye-tracking data.\nInstead of publishing filtered and pre-processed datasets, the eye-tracking\ndata at all pre-processing stages should be published together with data\nquality reports. In order to transparently report data quality and enable\ncross-dataset comparisons, we develop data quality reporting standards and\nmetrics that can be automatically applied to a dataset, and integrate them into\nthe open-source Python package pymovements\n(https://github.com/aeye-lab/pymovements).", "published": "2024-03-31 09:17:34", "link": "http://arxiv.org/abs/2404.00620v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Against The Achilles' Heel: A Survey on Red Teaming for Generative\n  Models", "abstract": "Generative models are rapidly gaining popularity and being integrated into\neveryday applications, raising concerns over their safe use as various\nvulnerabilities are exposed. In light of this, the field of red teaming is\nundergoing fast-paced growth, highlighting the need for a comprehensive survey\ncovering the entire pipeline and addressing emerging topics. Our extensive\nsurvey, which examines over 120 papers, introduces a taxonomy of fine-grained\nattack strategies grounded in the inherent capabilities of language models.\nAdditionally, we have developed the \"searcher\" framework to unify various\nautomatic red teaming approaches. Moreover, our survey covers novel areas\nincluding multimodal attacks and defenses, risks around LLM-based agents,\noverkill of harmless queries, and the balance between harmlessness and\nhelpfulness.", "published": "2024-03-31 09:50:39", "link": "http://arxiv.org/abs/2404.00629v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoUDA: Coherence Evaluation via Unified Data Augmentation", "abstract": "Coherence evaluation aims to assess the organization and structure of a\ndiscourse, which remains challenging even in the era of large language models.\nDue to the scarcity of annotated data, data augmentation is commonly used for\ntraining coherence evaluation models. However, previous augmentations for this\ntask primarily rely on heuristic rules, lacking designing criteria as guidance.\nIn this paper, we take inspiration from linguistic theory of discourse\nstructure, and propose a data augmentation framework named CoUDA. CoUDA breaks\ndown discourse coherence into global and local aspects, and designs\naugmentation strategies for both aspects, respectively. Especially for local\ncoherence, we propose a novel generative strategy for constructing augmentation\nsamples, which involves post-pretraining a generative model and applying two\ncontrolling mechanisms to control the difficulty of generated samples. During\ninference, CoUDA also jointly evaluates both global and local aspects to\ncomprehensively assess the overall coherence of a discourse. Extensive\nexperiments in coherence evaluation show that, with only 233M parameters, CoUDA\nachieves state-of-the-art performance in both pointwise scoring and pairwise\nranking tasks, even surpassing recent GPT-3.5 and GPT-4 based metrics.", "published": "2024-03-31 13:19:36", "link": "http://arxiv.org/abs/2404.00681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Contamination Detection Methods in Large\n  Language Models", "abstract": "With the rise of Large Language Models (LLMs) in recent years, abundant new\nopportunities are emerging, but also new challenges, among which contamination\nis quickly becoming critical. Business applications and fundraising in\nArtificial Intelligence (AI) have reached a scale at which a few percentage\npoints gained on popular question-answering benchmarks could translate into\ndozens of millions of dollars, placing high pressure on model integrity. At the\nsame time, it is becoming harder and harder to keep track of the data that LLMs\nhave seen; if not impossible with closed-source models like GPT-4 and Claude-3\nnot divulging any information on the training set. As a result, contamination\nbecomes a major issue: LLMs' performance may not be reliable anymore, as the\nhigh performance may be at least partly due to their previous exposure to the\ndata. This limitation jeopardizes real capability improvement in the field of\nNLP, yet, there remains a lack of methods on how to efficiently detect\ncontamination. In this paper, we survey all recent work on contamination\ndetection with LLMs, analyzing their methodologies and use cases to shed light\non the appropriate usage of contamination detection methods. Our work calls the\nNLP research community's attention into systematically taking into account\ncontamination bias in LLM evaluation.", "published": "2024-03-31 14:32:02", "link": "http://arxiv.org/abs/2404.00699v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Controlled Reevaluation of Coreference Resolution Models", "abstract": "All state-of-the-art coreference resolution (CR) models involve finetuning a\npretrained language model. Whether the superior performance of one CR model\nover another is due to the choice of language model or other factors, such as\nthe task-specific architecture, is difficult or impossible to determine due to\nlack of a standardized experimental setup. To resolve this ambiguity, we\nsystematically evaluate five CR models and control for certain design decisions\nincluding the pretrained language model used by each. When controlling for\nlanguage model size, encoder-based CR models outperform more recent\ndecoder-based models in terms of both accuracy and inference speed.\nSurprisingly, among encoder-based CR models, more recent models are not always\nmore accurate, and the oldest CR model that we test generalizes the best to\nout-of-domain textual genres. We conclude that controlling for the choice of\nlanguage model reduces most, but not all, of the increase in F1 score reported\nin the past five years.", "published": "2024-03-31 16:00:41", "link": "http://arxiv.org/abs/2404.00727v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Opera Graeca Adnotata: Building a 34M+ Token Multilayer Corpus for\n  Ancient Greek", "abstract": "In this article, the beta version 0.1.0 of Opera Graeca Adnotata (OGA), the\nlargest open-access multilayer corpus for Ancient Greek (AG) is presented. OGA\nconsists of 1,687 literary works and 34M+ tokens coming from the PerseusDL and\nOpenGreekAndLatin GitHub repositories, which host AG texts ranging from about\n800 BCE to about 250 CE. The texts have been enriched with seven annotation\nlayers: (i) tokenization layer; (ii) sentence segmentation layer; (iii)\nlemmatization layer; (iv) morphological layer; (v) dependency layer; (vi)\ndependency function layer; (vii) Canonical Text Services (CTS) citation layer.\nThe creation of each layer is described by highlighting the main technical and\nannotation-related issues encountered. Tokenization, sentence segmentation, and\nCTS citation are performed by rule-based algorithms, while morphosyntactic\nannotation is the output of the COMBO parser trained on the data of the Ancient\nGreek Dependency Treebank. For the sake of scalability and reusability, the\ncorpus is released in the standoff formats PAULA XML and its offspring LAULA\nXML.", "published": "2024-03-31 16:54:29", "link": "http://arxiv.org/abs/2404.00739v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Robustness to Improved Generalization and Calibration in\n  Pre-trained Language Models", "abstract": "Enhancing generalization and uncertainty quantification in pre-trained\nlanguage models (PLMs) is crucial for their effectiveness and reliability.\nBuilding on machine learning research that established the importance of\nrobustness for improving generalization, we investigate the role of\nrepresentation smoothness, achieved via Jacobian and Hessian regularization, in\nenhancing PLM performance. Although such regularization methods have proven\neffective in computer vision, their application in natural language processing\n(NLP), where PLM inputs are derived from a discrete domain, poses unique\nchallenges. We introduce a novel two-phase regularization approach, JacHess,\nwhich minimizes the norms of the Jacobian and Hessian matrices within PLM\nintermediate representations relative to their inputs. Our evaluation using the\nGLUE benchmark demonstrates that JacHess significantly improves in-domain\ngeneralization and calibration in PLMs, outperforming unregularized fine-tuning\nand other similar regularization methods.", "published": "2024-03-31 18:08:37", "link": "http://arxiv.org/abs/2404.00758v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Social Determinants of Health from Pediatric Patient Notes\n  Using Large Language Models: Novel Corpus and Methods", "abstract": "Social determinants of health (SDoH) play a critical role in shaping health\noutcomes, particularly in pediatric populations where interventions can have\nlong-term implications. SDoH are frequently studied in the Electronic Health\nRecord (EHR), which provides a rich repository for diverse patient data. In\nthis work, we present a novel annotated corpus, the Pediatric Social History\nAnnotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed\nSDoH representations using fine-tuned and in-context learning methods with\nLarge Language Models (LLMs). PedSHAC comprises annotated social history\nsections from 1,260 clinical notes obtained from pediatric patients within the\nUniversity of Washington (UW) hospital system. Employing an event-based\nannotation scheme, PedSHAC captures ten distinct health determinants to\nencompass living and economic stability, prior trauma, education access,\nsubstance use history, and mental health with an overall annotator agreement of\n81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance\nat 78.4 F1 for event arguments. In-context learning approaches with GPT-4\ndemonstrate promise for reliable SDoH extraction with limited annotated\nexamples, with extraction performance at 82.3 F1 for event triggers.", "published": "2024-03-31 23:37:18", "link": "http://arxiv.org/abs/2404.00826v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PID Control-Based Self-Healing to Improve the Robustness of Large\n  Language Models", "abstract": "Despite the effectiveness of deep neural networks in numerous natural\nlanguage processing applications, recent findings have exposed the\nvulnerability of these language models when minor perturbations are introduced.\nWhile appearing semantically indistinguishable to humans, these perturbations\ncan significantly reduce the performance of well-trained language models,\nraising concerns about the reliability of deploying them in safe-critical\nsituations. In this work, we construct a computationally efficient self-healing\nprocess to correct undesired model behavior during online inference when\nperturbations are applied to input data. This is formulated as a trajectory\noptimization problem in which the internal states of the neural network layers\nare automatically corrected using a PID (Proportional-Integral-Derivative)\ncontrol mechanism. The P controller targets immediate state adjustments, while\nthe I and D controllers consider past states and future dynamical trends,\nrespectively. We leverage the geometrical properties of the training data to\ndesign effective linear PID controllers. This approach reduces the\ncomputational cost to that of using just the P controller, instead of the full\nPID control. Further, we introduce an analytical method for approximating the\noptimal control solutions, enhancing the real-time inference capabilities of\nthis controlled system. Moreover, we conduct a theoretical error analysis of\nthe analytic solution in a simplified setting. The proposed PID control-based\nself-healing is a low cost framework that improves the robustness of\npre-trained large language models, whether standard or robustly trained,\nagainst a wide range of perturbations. A detailed implementation can be found\nin:https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models.", "published": "2024-03-31 23:46:51", "link": "http://arxiv.org/abs/2404.00828v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Returning to the Start: Generating Narratives with Related Endpoints", "abstract": "Human writers often bookend their writing with ending sentences that relate\nback to the beginning sentences in order to compose a satisfying narrative that\n\"closes the loop.\" Motivated by this observation, we propose RENarGen, a\ncontrollable story-generation paradigm that generates narratives by ensuring\nthe first and last sentences are related and then infilling the middle\nsentences. Our contributions include an initial exploration of how various\nmethods of bookending from Narratology affect language modeling for stories.\nAutomatic and human evaluations indicate RENarGen produces better stories with\nmore narrative closure than current autoregressive models.", "published": "2024-03-31 23:48:50", "link": "http://arxiv.org/abs/2404.00829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mind Your Neighbours: Leveraging Analogous Instances for Rhetorical Role\n  Labeling for Legal Documents", "abstract": "Rhetorical Role Labeling (RRL) of legal judgments is essential for various\ntasks, such as case summarization, semantic search and argument mining.\nHowever, it presents challenges such as inferring sentence roles from context,\ninterrelated roles, limited annotated data, and label imbalance. This study\nintroduces novel techniques to enhance RRL performance by leveraging knowledge\nfrom semantically similar instances (neighbours). We explore inference-based\nand training-based approaches, achieving remarkable improvements in challenging\nmacro-F1 scores. For inference-based methods, we explore interpolation\ntechniques that bolster label predictions without re-training. While in\ntraining-based methods, we integrate prototypical learning with our novel\ndiscourse-aware contrastive method that work directly on embedding spaces.\nAdditionally, we assess the cross-domain applicability of our methods,\ndemonstrating their effectiveness in transferring knowledge across diverse\nlegal domains.", "published": "2024-03-31 08:10:45", "link": "http://arxiv.org/abs/2404.01344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeBenchGen: Creating Scalable Execution-based Code Generation\n  Benchmarks", "abstract": "To adequately test modern code generation systems, evaluation benchmarks must\nexecute and test the code generated by the system. However, these execution and\ntesting requirements have largely limited benchmarks to settings where code is\neasily executable or has human-written tests. To facilitate evaluation of code\ngeneration systems across diverse scenarios, we present CodeBenchGen, a\nframework to create scalable execution-based benchmarks from naturally\noccurring code sources. Specifically, we leverage a large language model (LLM)\nto sandbox arbitrary pieces of code into evaluation examples, including test\ncases for execution-based evaluation. We illustrate the usefulness of our\nframework by creating a dataset, Exec-CSN, which includes 1,931 examples\ninvolving 293 libraries converted from code in 367 GitHub repositories taken\nfrom the Code- SearchNet dataset. To demonstrate the solvability of examples in\nExec-CSN, we present a human study demonstrating that 81.3% of the examples can\nbe solved by humans and 61% are rated as \"requires effort to solve\". We conduct\ncode generation experiments on open-source and proprietary models and analyze\nthe performance of both humans and models. We provide code and data at:\nhttps://github.com/yiqingxyq/CodeBenchGen.", "published": "2024-03-31 05:20:53", "link": "http://arxiv.org/abs/2404.00566v4", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Harnessing the Power of Large Language Model for Uncertainty Aware Graph\n  Processing", "abstract": "Handling graph data is one of the most difficult tasks. Traditional\ntechniques, such as those based on geometry and matrix factorization, rely on\nassumptions about the data relations that become inadequate when handling large\nand complex graph data. On the other hand, deep learning approaches demonstrate\npromising results in handling large graph data, but they often fall short of\nproviding interpretable explanations. To equip the graph processing with both\nhigh accuracy and explainability, we introduce a novel approach that harnesses\nthe power of a large language model (LLM), enhanced by an uncertainty-aware\nmodule to provide a confidence score on the generated answer. We experiment\nwith our approach on two graph processing tasks: few-shot knowledge graph\ncompletion and graph classification. Our results demonstrate that through\nparameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms\nby a substantial margin across ten diverse benchmark datasets. Moreover, to\naddress the challenge of explainability, we propose an uncertainty estimation\nbased on perturbation, along with a calibration scheme to quantify the\nconfidence scores of the generated answers. Our confidence measure achieves an\nAUC of 0.8 or higher on seven out of the ten datasets in predicting the\ncorrectness of the answer generated by LLM.", "published": "2024-03-31 07:38:39", "link": "http://arxiv.org/abs/2404.00589v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CuSINeS: Curriculum-driven Structure Induced Negative Sampling for\n  Statutory Article Retrieval", "abstract": "In this paper, we introduce CuSINeS, a negative sampling approach to enhance\nthe performance of Statutory Article Retrieval (SAR). CuSINeS offers three key\ncontributions. Firstly, it employs a curriculum-based negative sampling\nstrategy guiding the model to focus on easier negatives initially and\nprogressively tackle more difficult ones. Secondly, it leverages the\nhierarchical and sequential information derived from the structural\norganization of statutes to evaluate the difficulty of samples. Lastly, it\nintroduces a dynamic semantic difficulty assessment using the being-trained\nmodel itself, surpassing conventional static methods like BM25, adapting the\nnegatives to the model's evolving competence. Experimental results on a\nreal-world expert-annotated SAR dataset validate the effectiveness of CuSINeS\nacross four different baselines, demonstrating its versatility.", "published": "2024-03-31 07:49:23", "link": "http://arxiv.org/abs/2404.00590v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Query-driven Relevant Paragraph Extraction from Legal Judgments", "abstract": "Legal professionals often grapple with navigating lengthy legal judgements to\npinpoint information that directly address their queries. This paper focus on\nthis task of extracting relevant paragraphs from legal judgements based on the\nquery. We construct a specialized dataset for this task from the European Court\nof Human Rights (ECtHR) using the case law guides. We assess the performance of\ncurrent retrieval models in a zero-shot way and also establish fine-tuning\nbenchmarks using various models. The results highlight the significant gap\nbetween fine-tuned and zero-shot performance, emphasizing the challenge of\nhandling distribution shift in the legal domain. We notice that the legal\npre-training handles distribution shift on the corpus side but still struggles\non query side distribution shift, with unseen legal queries. We also explore\nvarious Parameter Efficient Fine-Tuning (PEFT) methods to evaluate their\npracticality within the context of information retrieval, shedding light on the\neffectiveness of different PEFT methods across diverse configurations with\npre-training and model architectures influencing the choice of PEFT method.", "published": "2024-03-31 08:03:39", "link": "http://arxiv.org/abs/2404.00595v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ECtHR-PCR: A Dataset for Precedent Understanding and Prior Case\n  Retrieval in the European Court of Human Rights", "abstract": "In common law jurisdictions, legal practitioners rely on precedents to\nconstruct arguments, in line with the doctrine of \\emph{stare decisis}. As the\nnumber of cases grow over the years, prior case retrieval (PCR) has garnered\nsignificant attention. Besides lacking real-world scale, existing PCR datasets\ndo not simulate a realistic setting, because their queries use complete case\ndocuments while only masking references to prior cases. The query is thereby\nexposed to legal reasoning not yet available when constructing an argument for\nan undecided case as well as spurious patterns left behind by citation masks,\npotentially short-circuiting a comprehensive understanding of case facts and\nlegal principles. To address these limitations, we introduce a PCR dataset\nbased on judgements from the European Court of Human Rights (ECtHR), which\nexplicitly separate facts from arguments and exhibit precedential practices,\naiding us to develop this PCR dataset to foster systems' comprehensive\nunderstanding. We benchmark different lexical and dense retrieval approaches\nwith various negative sampling strategies, adapting them to deal with long text\nsequences using hierarchical variants. We found that difficulty-based negative\nsampling strategies were not effective for the PCR task, highlighting the need\nfor investigation into domain-specific difficulty criteria. Furthermore, we\nobserve performance of the dense models degrade with time and calls for further\nresearch into temporal adaptation of retrieval models. Additionally, we assess\nthe influence of different views , Halsbury's and Goodhart's, in practice in\nECtHR jurisdiction using PCR task.", "published": "2024-03-31 08:06:54", "link": "http://arxiv.org/abs/2404.00596v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning to Plan for Language Modeling from Unlabeled Data", "abstract": "By training to predict the next token in an unlabeled corpus, large language\nmodels learn to perform many tasks without any labeled data. However, their\nnext-token-prediction objective arguably limits their performance in scenarios\nthat require planning, such as writing a coherent article. In this paper, we\ntrain a module for planning the future writing process via a self-supervised\nlearning objective. Given the textual context, this planning module learns to\npredict future abstract writing actions, which correspond to centroids in a\nclustered text embedding space. By conditioning on these actions, our model\nextends the successful language model formula to more abstract planning in an\nunsupervised way. Empirically, we demonstrate that our method improves language\nmodeling performance in general, particularly with respect to the text\nstructure. Because our framework uses a planner module that is unsupervised and\nexternal to the language model, new planner modules can be trained at large\nscale and easily be shared with the community.", "published": "2024-03-31 09:04:01", "link": "http://arxiv.org/abs/2404.00614v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmark Transparency: Measuring the Impact of Data on Evaluation", "abstract": "In this paper we present an exploratory research on quantifying the impact\nthat data distribution has on the performance and evaluation of NLP models. We\npropose an automated framework that measures the data point distribution across\n6 different dimensions: ambiguity, difficulty, discriminability, length, noise,\nand perplexity.\n  We use disproportional stratified sampling to measure how much the data\ndistribution affects absolute (Acc/F1) and relative (Rank) model performance.\nWe experiment on 2 different datasets (SQUAD and MNLI) and test a total of 135\ndifferent models (125 on SQUAD and 10 on MNLI). We demonstrate that without\nexplicit control of the data distribution, standard evaluation frameworks are\ninconsistent and unreliable. We find that the impact of the data is\nstatistically significant and is often larger than the impact of changing the\nmetric.\n  In a second set of experiments, we demonstrate that the impact of data on\nevaluation is not just observable, but also predictable. We propose to use\nbenchmark transparency as a method for comparing datasets and quantifying the\nsimilarity between them. We find that the ``dataset similarity vector'' can be\nused to predict how well a model generalizes out of distribution.", "published": "2024-03-31 17:33:43", "link": "http://arxiv.org/abs/2404.00748v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Language Models Recognize Convincing Arguments?", "abstract": "The capabilities of large language models (LLMs) have raised concerns about\ntheir potential to create and propagate convincing narratives. Here, we study\ntheir performance in detecting convincing arguments to gain insights into LLMs'\npersuasive capabilities without directly engaging in experimentation with\nhumans. We extend a dataset by Durmus and Cardie (2018) with debates, votes,\nand user traits and propose tasks measuring LLMs' ability to (1) distinguish\nbetween strong and weak arguments, (2) predict stances based on beliefs and\ndemographic characteristics, and (3) determine the appeal of an argument to an\nindividual based on their traits. We show that LLMs perform on par with humans\nin these tasks and that combining predictions from different LLMs yields\nsignificant performance gains, surpassing human performance. The data and code\nreleased with this paper contribute to the crucial effort of continuously\nevaluating and monitoring LLMs' capabilities and potential impact.\n(https://go.epfl.ch/persuasion-llm)", "published": "2024-03-31 17:38:33", "link": "http://arxiv.org/abs/2404.00750v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "On the True Distribution Approximation of Minimum Bayes-Risk Decoding", "abstract": "Minimum Bayes-risk (MBR) decoding has recently gained renewed attention in\ntext generation. MBR decoding considers texts sampled from a model as\npseudo-references and selects the text with the highest similarity to the\nothers. Therefore, sampling is one of the key elements of MBR decoding, and\nprevious studies reported that the performance varies by sampling methods. From\na theoretical standpoint, this performance variation is likely tied to how\nclosely the samples approximate the true distribution of references. However,\nthis approximation has not been the subject of in-depth study. In this study,\nwe propose using anomaly detection to measure the degree of approximation. We\nfirst closely examine the performance variation and then show that previous\nhypotheses about samples do not correlate well with the variation, but our\nintroduced anomaly scores do. The results are the first to empirically support\nthe link between the performance and the core assumption of MBR decoding.", "published": "2024-03-31 17:47:22", "link": "http://arxiv.org/abs/2404.00752v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rehearsal-Free Modular and Compositional Continual Learning for Language\n  Models", "abstract": "Continual learning aims at incrementally acquiring new knowledge while not\nforgetting existing knowledge. To overcome catastrophic forgetting, methods are\neither rehearsal-based, i.e., store data examples from previous tasks for data\nreplay, or isolate parameters dedicated to each task. However, rehearsal-based\nmethods raise privacy and memory issues, and parameter-isolation continual\nlearning does not consider interaction between tasks, thus hindering knowledge\ntransfer. In this work, we propose MoCL, a rehearsal-free Modular and\nCompositional Continual Learning framework which continually adds new modules\nto language models and composes them with existing modules. Experiments on\nvarious benchmarks show that MoCL outperforms state of the art and effectively\nfacilitates knowledge transfer.", "published": "2024-03-31 20:28:44", "link": "http://arxiv.org/abs/2404.00790v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DiffAgent: Fast and Accurate Text-to-Image API Selection with Large\n  Language Model", "abstract": "Text-to-image (T2I) generative models have attracted significant attention\nand found extensive applications within and beyond academic research. For\nexample, the Civitai community, a platform for T2I innovation, currently hosts\nan impressive array of 74,492 distinct models. However, this diversity presents\na formidable challenge in selecting the most appropriate model and parameters,\na process that typically requires numerous trials. Drawing inspiration from the\ntool usage research of large language models (LLMs), we introduce DiffAgent, an\nLLM agent designed to screen the accurate selection in seconds via API calls.\nDiffAgent leverages a novel two-stage training framework, SFTA, enabling it to\naccurately align T2I API responses with user input in accordance with human\npreferences. To train and evaluate DiffAgent's capabilities, we present\nDABench, a comprehensive dataset encompassing an extensive range of T2I APIs\nfrom the community. Our evaluations reveal that DiffAgent not only excels in\nidentifying the appropriate T2I API but also underscores the effectiveness of\nthe SFTA training framework. Codes are available at\nhttps://github.com/OpenGVLab/DiffAgent.", "published": "2024-03-31 06:28:15", "link": "http://arxiv.org/abs/2404.01342v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs", "abstract": "Businesses and software platforms are increasingly turning to Large Language\nModels (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistance\nwith file access or as reasoning agents for customer service. However, current\nLLM-based customer service models have limited integration with customer\nprofiles and lack the operational capabilities necessary for effective service.\nMoreover, existing API integrations emphasize diversity over the precision and\nerror avoidance essential in real-world customer service scenarios. To address\nthese issues, we propose an LLM agent named CHOPS (CHat with custOmer Profile\nin existing System), designed to: (1) efficiently utilize existing databases or\nsystems for accessing user information or interacting with these systems\nfollowing existing guidelines; (2) provide accurate and reasonable responses or\ncarry out required operations in the system while avoiding harmful operations;\nand (3) leverage a combination of small and large LLMs to achieve satisfying\nperformance at a reasonable inference cost. We introduce a practical dataset,\nthe CPHOS-dataset, which includes a database, guiding files, and QA pairs\ncollected from CPHOS, an online platform that facilitates the organization of\nsimulated Physics Olympiads for high school teachers and students. We have\nconducted extensive experiments to validate the performance of our proposed\nCHOPS architecture using the CPHOS-dataset, with the aim of demonstrating how\nLLMs can enhance or serve as alternatives to human customer service. Code for\nour proposed architecture and dataset can be found at\n{https://github.com/JingzheShi/CHOPS}.", "published": "2024-03-31 07:11:48", "link": "http://arxiv.org/abs/2404.01343v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Bangla Fake News Detection Using Bidirectional Gated Recurrent\n  Units and Deep Learning Techniques", "abstract": "The rise of fake news has made the need for effective detection methods,\nincluding in languages other than English, increasingly important. The study\naims to address the challenges of Bangla which is considered a less important\nlanguage. To this end, a complete dataset containing about 50,000 news items is\nproposed. Several deep learning models have been tested on this dataset,\nincluding the bidirectional gated recurrent unit (GRU), the long short-term\nmemory (LSTM), the 1D convolutional neural network (CNN), and hybrid\narchitectures. For this research, we assessed the efficacy of the model\nutilizing a range of useful measures, including recall, precision, F1 score,\nand accuracy. This was done by employing a big application. We carry out\ncomprehensive trials to show the effectiveness of these models in identifying\nbogus news in Bangla, with the Bidirectional GRU model having a stunning\naccuracy of 99.16%. Our analysis highlights the importance of dataset balance\nand the need for continual improvement efforts to a substantial degree. This\nstudy makes a major contribution to the creation of Bangla fake news detecting\nsystems with limited resources, thereby setting the stage for future\nimprovements in the detection process.", "published": "2024-03-31 09:52:25", "link": "http://arxiv.org/abs/2404.01345v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fairness in Large Language Models: A Taxonomic Survey", "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains. However, despite their promising performance in numerous\nreal-world applications, most of these algorithms lack fairness considerations.\nConsequently, they may lead to discriminatory outcomes against certain\ncommunities, particularly marginalized populations, prompting extensive study\nin fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in\ntraditional machine learning, entails exclusive backgrounds, taxonomies, and\nfulfillment techniques. To this end, this survey presents a comprehensive\noverview of recent advances in the existing literature concerning fair LLMs.\nSpecifically, a brief introduction to LLMs is provided, followed by an analysis\nof factors contributing to bias in LLMs. Additionally, the concept of fairness\nin LLMs is discussed categorically, summarizing metrics for evaluating bias in\nLLMs and existing algorithms for promoting fairness. Furthermore, resources for\nevaluating bias in LLMs, including toolkits and datasets, are summarized.\nFinally, existing research challenges and open questions are discussed.", "published": "2024-03-31 22:22:53", "link": "http://arxiv.org/abs/2404.01349v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revealing Trends in Datasets from the 2022 ACL and EMNLP Conferences", "abstract": "Natural language processing (NLP) has grown significantly since the advent of\nthe Transformer architecture. Transformers have given birth to pre-trained\nlarge language models (PLMs). There has been tremendous improvement in the\nperformance of NLP systems across several tasks. NLP systems are on par or, in\nsome cases, better than humans at accomplishing specific tasks. However, it\nremains the norm that \\emph{better quality datasets at the time of pretraining\nenable PLMs to achieve better performance, regardless of the task.} The need to\nhave quality datasets has prompted NLP researchers to continue creating new\ndatasets to satisfy particular needs. For example, the two top NLP conferences,\nACL and EMNLP, accepted ninety-two papers in 2022, introducing new datasets.\nThis work aims to uncover the trends and insights mined within these datasets.\nMoreover, we provide valuable suggestions to researchers interested in curating\ndatasets in the future.", "published": "2024-03-31 15:13:15", "link": "http://arxiv.org/abs/2404.08666v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MIPS at SemEval-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in\n  Conversations with Multimodal Language Models", "abstract": "This paper presents our winning submission to Subtask 2 of SemEval 2024 Task\n3 on multimodal emotion cause analysis in conversations. We propose a novel\nMultimodal Emotion Recognition and Multimodal Emotion Cause Extraction\n(MER-MCE) framework that integrates text, audio, and visual modalities using\nspecialized emotion encoders. Our approach sets itself apart from\ntop-performing teams by leveraging modality-specific features for enhanced\nemotion understanding and causality inference. Experimental evaluation\ndemonstrates the advantages of our multimodal approach, with our submission\nachieving a competitive weighted F1 score of 0.3435, ranking third with a\nmargin of only 0.0339 behind the 1st team and 0.0025 behind the 2nd team.\nProject: https://github.com/MIPS-COLT/MER-MCE.git", "published": "2024-03-31 01:16:02", "link": "http://arxiv.org/abs/2404.00511v3", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Comparing Bad Apples to Good Oranges: Aligning Large Language Models via\n  Joint Preference Optimization", "abstract": "A common technique for aligning large language models (LLMs) relies on\nacquiring human preferences by comparing multiple generations conditioned on a\nfixed context. This method, however, relies solely on pairwise comparisons,\nwhere the generations are evaluated within an identical context. While\neffective to such conditional preferences often fail to encompass the nuanced\nand multidimensional nature of human preferences. In this work, we revisit the\ntraditional paradigm of preference acquisition and propose a new axis based on\neliciting preferences jointly over the instruction-response pairs. Unlike prior\npreference optimizations, which are designed for conditional ranking protocols\n(e.g., DPO), we propose Joint Preference Optimization (JPO), a new preference\noptimization objective that upweights the joint probability of the chosen\ninstruction-response pair over the rejected instruction-response pair.\nInterestingly, LLMs trained with joint instruction-response preference data\nusing JPO outperform LLM trained with DPO by $5.2\\%$ and $3.3\\%$ win-rate for\nsummarization and open-ended dialogue datasets, respectively. Our findings\nreveal that joint preferences over instruction and response pairs can\nsignificantly enhance the alignment of LLMs by tapping into a broader spectrum\nof human preference elicitation. The data and code is available at\nhttps://github.com/Hritikbansal/dove.", "published": "2024-03-31 02:05:40", "link": "http://arxiv.org/abs/2404.00530v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through\n  Weighted Samplers and Consistency Models", "abstract": "Neural Text-to-Speech (TTS) systems find broad applications in voice\nassistants, e-learning, and audiobook creation. The pursuit of modern models,\nlike Diffusion Models (DMs), holds promise for achieving high-fidelity,\nreal-time speech synthesis. Yet, the efficiency of multi-step sampling in\nDiffusion Models presents challenges. Efforts have been made to integrate GANs\nwith DMs, speeding up inference by approximating denoising distributions, but\nthis introduces issues with model convergence due to adversarial training. To\novercome this, we introduce CM-TTS, a novel architecture grounded in\nconsistency models (CMs). Drawing inspiration from continuous-time diffusion\nmodels, CM-TTS achieves top-quality speech synthesis in fewer steps without\nadversarial training or pre-trained model dependencies. We further design\nweighted samplers to incorporate different sampling positions into model\ntraining with dynamic probabilities, ensuring unbiased learning throughout the\nentire training process. We present a real-time mel-spectrogram generation\nconsistency model, validated through comprehensive evaluations. Experimental\nresults underscore CM-TTS's superiority over existing single-step speech\nsynthesis systems, representing a significant advancement in the field.", "published": "2024-03-31 05:38:08", "link": "http://arxiv.org/abs/2404.00569v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EvoCodeBench: An Evolving Code Generation Benchmark Aligned with\n  Real-World Code Repositories", "abstract": "How to evaluate Large Language Models (LLMs) in code generation is an open\nquestion. Existing benchmarks demonstrate poor alignment with real-world code\nrepositories and are insufficient to evaluate the coding abilities of LLMs.\nThis paper proposes a new benchmark - EvoCodeBench to address the preceding\nproblems, which has three primary advances. (1) EvoCodeBench aligns with\nreal-world repositories in multiple dimensions, e.g., code distributions and\ndependency distributions. (2) EvoCodeBench offers comprehensive annotations\n(e.g., requirements, reference code, and reference dependencies), and robust\nevaluation metrics (e.g., Pass@k and Recall@k). (3) EvoCodeBench is an evolving\nbenchmark to avoid data leakage. We build an automatic pipeline to update\nEvoCodeBench from the latest repositories. We release the first version -\nEvoCodeBench-2403, containing 275 samples from 25 real-world repositories.\nBased on EvoCodeBench, we propose repository-level code generation and evaluate\n10 popular LLMs (e.g., gpt-4, gpt-3.5, DeepSeek Coder, StarCoder 2, CodeLLaMa,\nGemma, and Qwen 1.5). Our experiments reveal the coding abilities of these LLMs\nin real-world repositories. For example, the highest Pass@1 of gpt-4 only is\n20.73% in our experiments. We also analyze failed cases and summarize the\nshortcomings of existing LLMs in EvoCodeBench. We release EvoCodeBench, all\nprompts, and LLMs' completions for further community analysis.", "published": "2024-03-31 08:10:50", "link": "http://arxiv.org/abs/2404.00599v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "AI Act and Large Language Models (LLMs): When critical issues and\n  privacy impact require human and ethical oversight", "abstract": "The imposing evolution of artificial intelligence systems and, specifically,\nof Large Language Models (LLM) makes it necessary to carry out assessments of\ntheir level of risk and the impact they may have in the area of privacy,\npersonal data protection and at an ethical level, especially on the weakest and\nmost vulnerable. This contribution addresses human oversight, ethical\noversight, and privacy impact assessment.", "published": "2024-03-31 08:14:25", "link": "http://arxiv.org/abs/2404.00600v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Extensive Self-Contrast Enables Feedback-Free Language Model Alignment", "abstract": "Reinforcement learning from human feedback (RLHF) has been a central\ntechnique for recent large language model (LLM) alignment. However, its heavy\ndependence on costly human or LLM-as-Judge preference feedback could stymie its\nwider applications. In this work, we introduce Self-Contrast, a feedback-free\nlarge language model alignment method via exploiting extensive self-generated\nnegatives. With only supervised fine-tuning (SFT) targets, Self-Contrast\nleverages the LLM itself to generate massive diverse candidates, and harnesses\na pre-trained embedding model to filter multiple negatives according to text\nsimilarity. Theoretically, we illustrate that in this setting, merely scaling\nnegative responses can still effectively approximate situations with more\nbalanced positive and negative preference annotations. Our experiments with\ndirect preference optimization (DPO) on three datasets show that, Self-Contrast\ncould consistently outperform SFT and standard DPO training by large margins.\nAnd as the number of self-generated negatives increases, the performance of\nSelf-Contrast continues to grow. Code and data are available at\nhttps://github.com/THUDM/Self-Contrast.", "published": "2024-03-31 08:30:15", "link": "http://arxiv.org/abs/2404.00604v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model", "abstract": "The recent advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing, progressively broadening their scope\nto multimodal perception and generation. However, effectively integrating\nlistening capabilities into LLMs poses significant challenges, particularly\nwith respect to generalizing across varied contexts and executing complex\nauditory tasks. In this work, we introduce WavLLM, a robust and adaptive speech\nlarge language model with dual encoders, and a prompt-aware LoRA weight\nadapter, optimized by a two-stage curriculum learning approach. Leveraging dual\nencoders, we decouple different types of speech information, utilizing a\nWhisper encoder to process the semantic content of speech, and a WavLM encoder\nto capture the unique characteristics of the speaker's identity. Within the\ncurriculum learning framework, WavLLM first builds its foundational\ncapabilities by optimizing on mixed elementary single tasks, followed by\nadvanced multi-task training on more complex tasks such as combinations of the\nelementary tasks. To enhance the flexibility and adherence to different tasks\nand instructions, a prompt-aware LoRA weight adapter is introduced in the\nsecond advanced multi-task training stage. We validate the proposed model on\nuniversal speech benchmarks including tasks such as ASR, ST, SV, ER, and also\napply it to specialized datasets like Gaokao English listening comprehension\nset for SQA, and speech Chain-of-Thought (CoT) evaluation set. Experiments\ndemonstrate that the proposed model achieves state-of-the-art performance\nacross a range of speech tasks on the same model size, exhibiting robust\ngeneralization capabilities in executing complex tasks using CoT approach.\nFurthermore, our model successfully completes Gaokao tasks without specialized\ntraining. The codes, models, audio, and Gaokao evaluation set can be accessed\nat \\url{aka.ms/wavllm}.", "published": "2024-03-31 12:01:32", "link": "http://arxiv.org/abs/2404.00656v3", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Observations on Building RAG Systems for Technical Documents", "abstract": "Retrieval augmented generation (RAG) for technical documents creates\nchallenges as embeddings do not often capture domain information. We review\nprior art for important factors affecting RAG and perform experiments to\nhighlight best practices and potential challenges to build RAG systems for\ntechnical documents.", "published": "2024-03-31 12:01:34", "link": "http://arxiv.org/abs/2404.00657v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.LG"}
{"title": "A General and Efficient Training for Transformer via Token Expansion", "abstract": "The remarkable performance of Vision Transformers (ViTs) typically requires\nan extremely large training cost. Existing methods have attempted to accelerate\nthe training of ViTs, yet typically disregard method universality with accuracy\ndropping. Meanwhile, they break the training consistency of the original\ntransformers, including the consistency of hyper-parameters, architecture, and\nstrategy, which prevents them from being widely applied to different\nTransformer networks. In this paper, we propose a novel token growth scheme\nToken Expansion (termed ToE) to achieve consistent training acceleration for\nViTs. We introduce an \"initialization-expansion-merging\" pipeline to maintain\nthe integrity of the intermediate feature distribution of original\ntransformers, preventing the loss of crucial learnable information in the\ntraining process. ToE can not only be seamlessly integrated into the training\nand fine-tuning process of transformers (e.g., DeiT and LV-ViT), but also\neffective for efficient training frameworks (e.g., EfficientTrain), without\ntwisting the original training hyper-parameters, architecture, and introducing\nadditional training strategies. Extensive experiments demonstrate that ToE\nachieves about 1.3x faster for the training of ViTs in a lossless manner, or\neven with performance gains over the full-token training baselines. Code is\navailable at https://github.com/Osilly/TokenExpansion .", "published": "2024-03-31 12:44:24", "link": "http://arxiv.org/abs/2404.00672v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Scaling Properties of Speech Language Models", "abstract": "Speech Language Models (SLMs) aim to learn language from raw audio, without\ntextual resources. Despite significant advances, our current models exhibit\nweak syntax and semantic abilities. However, if the scaling properties of\nneural language models hold for the speech modality, these abilities will\nimprove as the amount of compute used for training increases. In this paper, we\nuse models of this scaling behavior to estimate the scale at which our current\nmethods will yield a SLM with the English proficiency of text-based Large\nLanguage Models (LLMs). We establish a strong correlation between pre-training\nloss and downstream syntactic and semantic performance in SLMs and LLMs, which\nresults in predictable scaling of linguistic performance. We show that the\nlinguistic performance of SLMs scales up to three orders of magnitude more\nslowly than that of text-based LLMs. Additionally, we study the benefits of\nsynthetic data designed to boost semantic understanding and the effects of\ncoarser speech tokenization.", "published": "2024-03-31 13:30:12", "link": "http://arxiv.org/abs/2404.00685v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "eess.AS"}
{"title": "The Larger the Better? Improved LLM Code-Generation via Budget\n  Reallocation", "abstract": "It is a common belief that large language models (LLMs) are better than\nsmaller-sized ones. However, larger models also require significantly more time\nand compute during inference. This begs the question: what happens when both\nmodels operate under the same budget? (e.g., compute, run-time). To address\nthis question, we analyze code generation LLMs of various sizes and make\ncomparisons such as running a 70B model once vs. generating five outputs from a\n13B model. We consider a standard unit-test setup, which can be used to select\nthe correct output from the smaller model. Our findings reveal that the\nrepeated use of smaller models can yield consistent improvements, with gains of\nup to 15% across five tasks. On the other hand, in scenarios where unit-tests\nare unavailable, a ranking-based selection of candidates from the smaller model\nfalls short of the performance of a single output from larger ones. Our results\nhighlight the potential of using smaller models instead of larger ones, and the\nimportance of studying approaches for ranking LLM outputs.", "published": "2024-03-31 15:55:49", "link": "http://arxiv.org/abs/2404.00725v2", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Humane Speech Synthesis through Zero-Shot Emotion and Disfluency\n  Generation", "abstract": "Contemporary conversational systems often present a significant limitation:\ntheir responses lack the emotional depth and disfluent characteristic of human\ninteractions. This absence becomes particularly noticeable when users seek more\npersonalized and empathetic interactions. Consequently, this makes them seem\nmechanical and less relatable to human users. Recognizing this gap, we embarked\non a journey to humanize machine communication, to ensure AI systems not only\ncomprehend but also resonate. To address this shortcoming, we have designed an\ninnovative speech synthesis pipeline. Within this framework, a cutting-edge\nlanguage model introduces both human-like emotion and disfluencies in a\nzero-shot setting. These intricacies are seamlessly integrated into the\ngenerated text by the language model during text generation, allowing the\nsystem to mirror human speech patterns better, promoting more intuitive and\nnatural user interactions. These generated elements are then adeptly\ntransformed into corresponding speech patterns and emotive sounds using a\nrule-based approach during the text-to-speech phase. Based on our experiments,\nour novel system produces synthesized speech that's almost indistinguishable\nfrom genuine human communication, making each interaction feel more personal\nand authentic.", "published": "2024-03-31 00:38:02", "link": "http://arxiv.org/abs/2404.01339v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Heterogeneity over Homogeneity: Investigating Multilingual Speech\n  Pre-Trained Models for Detecting Audio Deepfake", "abstract": "In this work, we investigate multilingual speech Pre-Trained models (PTMs)\nfor Audio deepfake detection (ADD). We hypothesize that multilingual PTMs\ntrained on large-scale diverse multilingual data gain knowledge about diverse\npitches, accents, and tones, during their pre-training phase and making them\nmore robust to variations. As a result, they will be more effective for\ndetecting audio deepfakes. To validate our hypothesis, we extract\nrepresentations from state-of-the-art (SOTA) PTMs including monolingual,\nmultilingual as well as PTMs trained for speaker and emotion recognition, and\nevaluated them on ASVSpoof 2019 (ASV), In-the-Wild (ITW), and DECRO benchmark\ndatabases. We show that representations from multilingual PTMs, with simple\ndownstream networks, attain the best performance for ADD compared to other PTM\nrepresentations, which validates our hypothesis. We also explore the\npossibility of fusion of selected PTM representations for further improvements\nin ADD, and we propose a framework, MiO (Merge into One) for this purpose. With\nMiO, we achieve SOTA performance on ASV and ITW and comparable performance on\nDECRO with current SOTA works.", "published": "2024-03-31 21:48:50", "link": "http://arxiv.org/abs/2404.00809v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Measuring Audio Prompt Adherence with Distribution-based Embedding\n  Distances", "abstract": "An increasing number of generative music models can be conditioned on an\naudio prompt that serves as musical context for which the model is to create an\naccompaniment (often further specified using a text prompt).\n  Evaluation of how well model outputs adhere to the audio prompt is often done\nin a model or problem specific manner, presumably because no generic evaluation\nmethod for audio prompt adherence has emerged.\n  Such a method could be useful both in the development and training of new\nmodels, and to make performance comparable across models.\n  In this paper we investigate whether commonly used distribution-based\ndistances like Fr\\'echet Audio Distance (FAD), can be used to measure audio\nprompt adherence.\n  We propose a simple procedure based on a small number of constituents (an\nembedding model, a projection, an embedding distance, and a data fusion\nmethod), that we systematically assess using a baseline validation.\n  In a follow-up experiment we test the sensitivity of the proposed audio\nadherence measure to pitch and time shift perturbations.\n  The results show that the proposed measure is sensitive to such\nperturbations, even when the reference and candidate distributions are from\ndifferent music collections.\n  Although more experimentation is needed to answer unaddressed questions like\nthe robustness of the measure to acoustic artifacts that do not affect the\naudio prompt adherence, the current results suggest that distribution-based\nembedding distances provide a viable way of measuring audio prompt adherence.\n  An python/pytorch implementation of the proposed measure is publicly\navailable as a github repository.", "published": "2024-03-31 19:12:52", "link": "http://arxiv.org/abs/2404.00775v4", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comparative Analysis of Poetry Reading Audio: Singing, Narrating, or\n  Somewhere In Between?", "abstract": "This paper provides a computational analysis of poetry reading audio signals\nat a large scale to unveil the musicality within professionally-read poems.\nAlthough the acoustic characteristics of other types of spoken language have\nbeen extensively studied, most of the literature is limited to narrative speech\nor singing voice, discussing how different they are from each other. In this\nwork, we develop signal processing methods, which are tailored to capture the\nunique acoustic characteristics of poetry reading based on their silence\npatterns, temporal variations of local pitch, and beat stability. Our\nlarge-scale statistical analyses on three big corpora, each of which consists\nof narration (LibriSpeech), singing voice (Intonation), and poetry reading\n(from The Poetry Foundation), discover that poetry reading does share some\nmusical characteristics with singing voice, although it may also resemble\nnarrative speech.", "published": "2024-03-31 20:28:16", "link": "http://arxiv.org/abs/2404.00789v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Personalized Neural Speech Codec", "abstract": "In this paper, we propose a personalized neural speech codec, envisioning\nthat personalization can reduce the model complexity or improve perceptual\nspeech quality. Despite the common usage of speech codecs where only a single\ntalker is involved on each side of the communication, personalizing a codec for\nthe specific user has rarely been explored in the literature. First, we assume\nspeakers can be grouped into smaller subsets based on their perceptual\nsimilarity. Then, we also postulate that a group-specific codec can focus on\nthe group's speech characteristics to improve its perceptual quality and\ncomputational efficiency. To this end, we first develop a Siamese network that\nlearns the speaker embeddings from the LibriSpeech dataset, which are then\ngrouped into underlying speaker clusters. Finally, we retrain the LPCNet-based\nspeech codec baselines on each of the speaker clusters. Subjective listening\ntests show that the proposed personalization scheme introduces model\ncompression while maintaining speech quality. In other words, with the same\nmodel complexity, personalized codecs produce better speech quality.", "published": "2024-03-31 20:32:40", "link": "http://arxiv.org/abs/2404.00791v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Houston we have a Divergence: A Subgroup Performance Analysis of ASR\n  Models", "abstract": "The Fearless Steps APOLLO Community Resource provides unparalleled\nopportunities to explore the potential of multi-speaker team communications\nfrom NASA Apollo missions. This study focuses on discovering the\ncharacteristics that make Apollo recordings more or less intelligible to\nAutomatic Speech Recognition (ASR) methods. We extract, for each audio\nrecording, interpretable metadata on recordings (signal-to-noise ratio,\nspectral flatness, presence of pauses, sentence duration), transcript (number\nof words spoken, speaking rate), or known a priori (speaker). We identify\nsubgroups of audio recordings based on combinations of these metadata and\ncompute each subgroup's performance (e.g., Word Error Rate) and the difference\nin performance (''divergence'') w.r.t the overall population. We then apply the\nWhisper model in different sizes, trained on English-only or multilingual\ndatasets, in zero-shot or after fine-tuning. We conduct several analyses to (i)\nautomatically identify and describe the most problematic subgroups for a given\nmodel, (ii) examine the impact of fine-tuning w.r.t. zero-shot at the subgroup\nlevel, (iii) understand the effect of model size on subgroup performance, and\n(iv) analyze if multilingual models are more sensitive than monolingual to\nsubgroup performance disparities. The insights enhance our understanding of\nsubgroup-specific performance variations, paving the way for advancements in\noptimizing ASR systems for Earth-to-space communications.", "published": "2024-03-31 10:06:19", "link": "http://arxiv.org/abs/2404.07226v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
