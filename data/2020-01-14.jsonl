{"title": "A BERT based Sentiment Analysis and Key Entity Detection Approach for\n  Online Financial Texts", "abstract": "The emergence and rapid progress of the Internet have brought ever-increasing\nimpact on financial domain. How to rapidly and accurately mine the key\ninformation from the massive negative financial texts has become one of the key\nissues for investors and decision makers. Aiming at the issue, we propose a\nsentiment analysis and key entity detection approach based on BERT, which is\napplied in online financial text mining and public opinion analysis in social\nmedia. By using pre-train model, we first study sentiment analysis, and then we\nconsider key entity detection as a sentence matching or Machine Reading\nComprehension (MRC) task in different granularity. Among them, we mainly focus\non negative sentimental information. We detect the specific entity by using our\napproach, which is different from traditional Named Entity Recognition (NER).\nIn addition, we also use ensemble learning to improve the performance of\nproposed approach. Experimental results show that the performance of our\napproach is generally higher than SVM, LR, NBM, and BERT for two financial\nsentiment analysis and key entity detection datasets.", "published": "2020-01-14 13:50:08", "link": "http://arxiv.org/abs/2001.05326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bi-Decoder Augmented Network for Neural Machine Translation", "abstract": "Neural Machine Translation (NMT) has become a popular technology in recent\nyears, and the encoder-decoder framework is the mainstream among all the\nmethods. It's obvious that the quality of the semantic representations from\nencoding is very crucial and can significantly affect the performance of the\nmodel. However, existing unidirectional source-to-target architectures may\nhardly produce a language-independent representation of the text because they\nrely heavily on the specific relations of the given language pairs. To\nalleviate this problem, in this paper, we propose a novel Bi-Decoder Augmented\nNetwork (BiDAN) for the neural machine translation task. Besides the original\ndecoder which generates the target language sequence, we add an auxiliary\ndecoder to generate back the source language sequence at the training time.\nSince each decoder transforms the representations of the input text into its\ncorresponding language, jointly training with two target ends can make the\nshared encoder has the potential to produce a language-independent semantic\nspace. We conduct extensive experiments on several NMT benchmark datasets and\nthe results demonstrate the effectiveness of our proposed approach.", "published": "2020-01-14 02:05:14", "link": "http://arxiv.org/abs/2001.04586v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Balancing the composition of word embeddings across heterogenous data\n  sets", "abstract": "Word embeddings capture semantic relationships based on contextual\ninformation and are the basis for a wide variety of natural language processing\napplications. Notably these relationships are solely learned from the data and\nsubsequently the data composition impacts the semantic of embeddings which\narguably can lead to biased word vectors. Given qualitatively different data\nsubsets, we aim to align the influence of single subsets on the resulting word\nvectors, while retaining their quality. In this regard we propose a criteria to\nmeasure the shift towards a single data subset and develop approaches to meet\nboth objectives. We find that a weighted average of the two subset embeddings\nbalances the influence of those subsets while word similarity performance\ndecreases. We further propose a promising optimization approach to balance\ninfluences and quality of word embeddings.", "published": "2020-01-14 10:12:50", "link": "http://arxiv.org/abs/2001.04693v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat\n  Groups", "abstract": "To predict the next most likely participant to interact in a multi-party\nconversation is a difficult problem. In a text-based chat group, the only\ninformation available is the sender, the content of the text and the dialogue\nhistory. In this paper we present our study on how these information can be\nused on the prediction task through a corpus and architecture that integrates\nturn-taking classifiers based on Maximum Likelihood Expectation (MLE),\nConvolutional Neural Networks (CNN) and Finite State Automata (FSA). The corpus\nis a synthetic adaptation of the Multi-Domain Wizard-of-Oz dataset (MultiWOZ)\nto a multiple travel service-based bots scenario with dialogue errors and was\ncreated to simulate user's interaction and evaluate the architecture. We\npresent experimental results which show that the CNN approach achieves better\nperformance than the baseline with an accuracy of 92.34%, but the integrated\nsolution with MLE, CNN and FSA achieves performance even better, with 95.65%.", "published": "2020-01-14 22:37:21", "link": "http://arxiv.org/abs/2001.06350v1", "categories": ["cs.CL", "cs.FL"], "primary_category": "cs.CL"}
{"title": "Faster Transformer Decoding: N-gram Masked Self-Attention", "abstract": "Motivated by the fact that most of the information relevant to the prediction\nof target tokens is drawn from the source sentence $S=s_1, \\ldots, s_S$, we\npropose truncating the target-side window used for computing self-attention by\nmaking an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show\nthat the $N$-gram masked self-attention model loses very little in BLEU score\nfor $N$ values in the range $4, \\ldots, 8$, depending on the task.", "published": "2020-01-14 02:14:09", "link": "http://arxiv.org/abs/2001.04589v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improved Robust ASR for Social Robots in Public Spaces", "abstract": "Social robots deployed in public spaces present a challenging task for ASR\nbecause of a variety of factors, including noise SNR of 20 to 5 dB. Existing\nASR models perform well for higher SNRs in this range, but degrade considerably\nwith more noise. This work explores methods for providing improved ASR\nperformance in such conditions. We use the AiShell-1 Chinese speech corpus and\nthe Kaldi ASR toolkit for evaluations. We were able to exceed state-of-the-art\nASR performance with SNR lower than 20 dB, demonstrating the feasibility of\nachieving relatively high performing ASR with open-source toolkits and hundreds\nof hours of training data, which is commonly available.", "published": "2020-01-14 04:21:18", "link": "http://arxiv.org/abs/2001.04619v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning", "abstract": "Word embeddings, i.e., low-dimensional vector representations such as GloVe\nand SGNS, encode word \"meaning\" in the sense that distances between words'\nvectors correspond to their semantic proximity. This enables transfer learning\nof semantics for a variety of natural language processing tasks.\n  Word embeddings are typically trained on large public corpora such as\nWikipedia or Twitter. We demonstrate that an attacker who can modify the corpus\non which the embedding is trained can control the \"meaning\" of new and existing\nwords by changing their locations in the embedding space. We develop an\nexplicit expression over corpus features that serves as a proxy for distance\nbetween words and establish a causative relationship between its values and\nembedding distances. We then show how to use this relationship for two\nadversarial objectives: (1) make a word a top-ranked neighbor of another word,\nand (2) move a word from one semantic cluster to another.\n  An attack on the embedding can affect diverse downstream tasks, demonstrating\nfor the first time the power of data poisoning in transfer learning scenarios.\nWe use this attack to manipulate query expansion in information retrieval\nsystems such as resume search, make certain names more or less visible to named\nentity recognition models, and cause new words to be translated to a particular\ntarget word regardless of the language. Finally, we show how the attacker can\ngenerate linguistically likely corpus modifications, thus fooling defenses that\nattempt to filter implausible sentences from the corpus using a language model.", "published": "2020-01-14 17:48:52", "link": "http://arxiv.org/abs/2001.04935v1", "categories": ["cs.CL", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Modeling Product Search Relevance in e-Commerce", "abstract": "With the rapid growth of e-Commerce, online product search has emerged as a\npopular and effective paradigm for customers to find desired products and\nengage in online shopping. However, there is still a big gap between the\nproducts that customers really desire to purchase and relevance of products\nthat are suggested in response to a query from the customer. In this paper, we\npropose a robust way of predicting relevance scores given a search query and a\nproduct, using techniques involving machine learning, natural language\nprocessing and information retrieval. We compare conventional information\nretrieval models such as BM25 and Indri with deep learning models such as\nword2vec, sentence2vec and paragraph2vec. We share some of our insights and\nfindings from our experiments.", "published": "2020-01-14 21:17:55", "link": "http://arxiv.org/abs/2001.04980v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Robust Speaker Recognition Using Speech Enhancement And Attention Model", "abstract": "In this paper, a novel architecture for speaker recognition is proposed by\ncascading speech enhancement and speaker processing. Its aim is to improve\nspeaker recognition performance when speech signals are corrupted by noise.\nInstead of individually processing speech enhancement and speaker recognition,\nthe two modules are integrated into one framework by a joint optimisation using\ndeep neural networks. Furthermore, to increase robustness against noise, a\nmulti-stage attention mechanism is employed to highlight the speaker related\nfeatures learned from context information in time and frequency domain. To\nevaluate speaker identification and verification performance of the proposed\napproach, we test it on the dataset of VoxCeleb1, one of mostly used benchmark\ndatasets. Moreover, the robustness of our proposed approach is also tested on\nVoxCeleb1 data when being corrupted by three types of interferences, general\nnoise, music, and babble, at different signal-to-noise ratio (SNR) levels. The\nobtained results show that the proposed approach using speech enhancement and\nmulti-stage attention models outperforms two strong baselines not using them in\nmost acoustic conditions in our experiments.", "published": "2020-01-14 20:03:07", "link": "http://arxiv.org/abs/2001.05031v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Auto Completion of User Interface Layout Design Using Transformer-Based\n  Tree Decoders", "abstract": "It has been of increasing interest in the field to develop automatic\nmachineries to facilitate the design process. In this paper, we focus on\nassisting graphical user interface (UI) layout design, a crucial task in app\ndevelopment. Given a partial layout, which a designer has entered, our model\nlearns to complete the layout by predicting the remaining UI elements with a\ncorrect position and dimension as well as the hierarchical structures. Such\nautomation will significantly ease the effort of UI designers and developers.\nWhile we focus on interface layout prediction, our model can be generally\napplicable for other layout prediction problems that involve tree structures\nand 2-dimensional placements. Particularly, we design two versions of\nTransformer-based tree decoders: Pointer and Recursive Transformer, and\nexperiment with these models on a public dataset. We also propose several\nmetrics for measuring the accuracy of tree prediction and ground these metrics\nin the domain of user experience. These contribute a new task and methods to\ndeep learning research.", "published": "2020-01-14 17:24:41", "link": "http://arxiv.org/abs/2001.05308v1", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Supervised Speaker Embedding De-Mixing in Two-Speaker Environment", "abstract": "Separating different speaker properties from a multi-speaker environment is\nchallenging. Instead of separating a two-speaker signal in signal space like\nspeech source separation, a speaker embedding de-mixing approach is proposed.\nThe proposed approach separates different speaker properties from a two-speaker\nsignal in embedding space. The proposed approach contains two steps. In step\none, the clean speaker embeddings are learned and collected by a residual TDNN\nbased network. In step two, the two-speaker signal and the embedding of one of\nthe speakers are both input to a speaker embedding de-mixing network. The\nde-mixing network is trained to generate the embedding of the other speaker by\nreconstruction loss. Speaker identification accuracy and the cosine similarity\nscore between the clean embeddings and the de-mixed embeddings are used to\nevaluate the quality of the obtained embeddings. Experiments are done in two\nkind of data: artificial augmented two-speaker data (TIMIT) and real world\nrecording of two-speaker data (MC-WSJ). Six different speaker embedding\nde-mixing architectures are investigated. Comparing with the performance on the\nclean speaker embeddings, the obtained results show that one of the proposed\narchitectures obtained close performance, reaching 96.9% identification\naccuracy and 0.89 cosine similarity.", "published": "2020-01-14 20:13:43", "link": "http://arxiv.org/abs/2001.06397v2", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Vocabulary-based Method for Quantifying Controversy in Social Media", "abstract": "Identifying controversial topics is not only interesting from a social point\nof view, it also enables the application of methods to avoid the information\nsegregation, creating better discussion contexts and reaching agreements in the\nbest cases. In this paper we develop a systematic method for controversy\ndetection based primarily on the jargon used by the communities in social\nmedia. Our method dispenses with the use of domain-specific knowledge, is\nlanguage-agnostic, efficient and easy to apply. We perform an extensive set of\nexperiments across many languages, regions and contexts, taking controversial\nand non-controversial topics. We find that our vocabulary-based measure\nperforms better than state of the art measures that are based only on the\ncommunity graph structure. Moreover, we shows that it is possible to detect\npolarization through text analysis.", "published": "2020-01-14 17:43:21", "link": "http://arxiv.org/abs/2001.09899v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.IR"}
{"title": "A (Simplified) Supreme Being Necessarily Exists, says the Computer:\n  Computationally Explored Variants of G\u00f6del's Ontological Argument", "abstract": "An approach to universal (meta-)logical reasoning in classical higher-order\nlogic is employed to explore and study simplifications of Kurt G\\\"odel's modal\nontological argument. Some argument premises are modified, others are dropped,\nmodal collapse is avoided and validity is shown already in weak modal logics K\nand T. Key to the gained simplifications of G\\\"odel's original theory is the\nexploitation of a link to the notions of filter and ultrafilter from topology.\nThe paper illustrates how modern knowledge representation and reasoning\ntechnology for quantified non-classical logics can contribute new knowledge to\nother disciplines. The contributed material is also well suited to support\nteaching of non-trivial logic formalisms in classroom.", "published": "2020-01-14 10:26:51", "link": "http://arxiv.org/abs/2001.04701v10", "categories": ["cs.LO", "cs.AI", "cs.CL", "math.GN", "math.LO", "03Axx, 03B15, 03B45, 03B60, 03B80, 68T15, 68T27, 68T30", "F.4.0; F.4.1; I.2.3; I.2.4; J.5; I.1.3"], "primary_category": "cs.LO"}
{"title": "\"Why is 'Chicago' deceptive?\" Towards Building Model-Driven Tutorials\n  for Humans", "abstract": "To support human decision making with machine learning models, we often need\nto elucidate patterns embedded in the models that are unsalient, unknown, or\ncounterintuitive to humans. While existing approaches focus on explaining\nmachine predictions with real-time assistance, we explore model-driven\ntutorials to help humans understand these patterns in a training phase. We\nconsider both tutorials with guidelines from scientific papers, analogous to\ncurrent practices of science communication, and automatically selected examples\nfrom training data with explanations. We use deceptive review detection as a\ntestbed and conduct large-scale, randomized human-subject experiments to\nexamine the effectiveness of such tutorials. We find that tutorials indeed\nimprove human performance, with and without real-time assistance. In\nparticular, although deep learning provides superior predictive performance\nthan simple models, tutorials and explanations from simple models are more\nuseful to humans. Our work suggests future directions for human-centered\ntutorials and explanations towards a synergy between humans and AI.", "published": "2020-01-14 19:00:00", "link": "http://arxiv.org/abs/2001.05871v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.HC"}
{"title": "An Improved Deep Neural Network for Modeling Speaker Characteristics at\n  Different Temporal Scales", "abstract": "This paper presents an improved deep embedding learning method based on\nconvolutional neural network (CNN) for text-independent speaker verification.\nTwo improvements are proposed for x-vector embedding learning: (1) Multi-scale\nconvolution (MSCNN) is adopted in frame-level layers to capture complementary\nspeaker information in different receptive fields. (2) A Baum-Welch statistics\nattention (BWSA) mechanism is applied in pooling-layer, which can integrate\nmore useful long-term speaker characteristics in the temporal pooling layer.\nExperiments are carried out on the NIST SRE16 evaluation set. The results\ndemonstrate the effectiveness of MSCNN and show the proposed BWSA can further\nimprove the performance of the DNN embedding system", "published": "2020-01-14 02:02:47", "link": "http://arxiv.org/abs/2001.04584v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Gaussian speaker embedding learning for text-independent speaker\n  verification", "abstract": "The x-vector maps segments of arbitrary duration to vectors of fixed\ndimension using deep neural network. Combined with the probabilistic linear\ndiscriminant analysis (PLDA) backend, the x-vector/PLDA has become the dominant\nframework in text-independent speaker verification. Nevertheless, how to\nextract the x-vector appropriate for the PLDA backend is a key problem. In this\npaper, we propose a Gaussian noise constrained network (GNCN) to extract\nxvector, which adopts a multi-task learning strategy with the primary task\nclassifying the speakers and the auxiliary task just fitting the Gaussian\nnoises. Experiments are carried out using the SITW database. The results\ndemonstrate the effectiveness of our proposed method", "published": "2020-01-14 02:03:01", "link": "http://arxiv.org/abs/2001.04585v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "HumBug Zooniverse: a crowd-sourced acoustic mosquito dataset", "abstract": "Mosquitoes are the only known vector of malaria, which leads to hundreds of\nthousands of deaths each year. Understanding the number and location of\npotential mosquito vectors is of paramount importance to aid the reduction of\nmalaria transmission cases. In recent years, deep learning has become widely\nused for bioacoustic classification tasks. In order to enable further research\napplications in this field, we release a new dataset of mosquito audio\nrecordings. With over a thousand contributors, we obtained 195,434 labels of\ntwo second duration, of which approximately 10 percent signify mosquito events.\nWe present an example use of the dataset, in which we train a convolutional\nneural network on log-Mel features, showcasing the information content of the\nlabels. We hope this will become a vital resource for those researching all\naspects of malaria, and add to the existing audio datasets for bioacoustic\ndetection and signal processing.", "published": "2020-01-14 12:06:17", "link": "http://arxiv.org/abs/2001.04733v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "DDSP: Differentiable Digital Signal Processing", "abstract": "Most generative models of audio directly generate samples in one of two\ndomains: time or frequency. While sufficient to express any signal, these\nrepresentations are inefficient, as they do not utilize existing knowledge of\nhow sound is generated and perceived. A third approach (vocoders/synthesizers)\nsuccessfully incorporates strong domain knowledge of signal processing and\nperception, but has been less actively researched due to limited expressivity\nand difficulty integrating with modern auto-differentiation-based machine\nlearning methods. In this paper, we introduce the Differentiable Digital Signal\nProcessing (DDSP) library, which enables direct integration of classic signal\nprocessing elements with deep learning methods. Focusing on audio synthesis, we\nachieve high-fidelity generation without the need for large autoregressive\nmodels or adversarial losses, demonstrating that DDSP enables utilizing strong\ninductive biases without losing the expressive power of neural networks.\nFurther, we show that combining interpretable modules permits manipulation of\neach separate model component, with applications such as independent control of\npitch and loudness, realistic extrapolation to pitches not seen during\ntraining, blind dereverberation of room acoustics, transfer of extracted room\nacoustics to new environments, and transformation of timbre between disparate\nsources. In short, DDSP enables an interpretable and modular approach to\ngenerative modeling, without sacrificing the benefits of deep learning. The\nlibrary is publicly available at https://github.com/magenta/ddsp and we welcome\nfurther contributions from the community and domain experts.", "published": "2020-01-14 06:49:37", "link": "http://arxiv.org/abs/2001.04643v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
