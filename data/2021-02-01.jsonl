{"title": "Neural OCR Post-Hoc Correction of Historical Corpora", "abstract": "Optical character recognition (OCR) is crucial for a deeper access to\nhistorical collections. OCR needs to account for orthographic variations,\ntypefaces, or language evolution (i.e., new letters, word spellings), as the\nmain source of character, word, or word segmentation transcription errors. For\ndigital corpora of historical prints, the errors are further exacerbated due to\nlow scan quality and lack of language standardization.\n  For the task of OCR post-hoc correction, we propose a neural approach based\non a combination of recurrent (RNN) and deep convolutional network (ConvNet) to\ncorrect OCR transcription errors. At character level we flexibly capture\nerrors, and decode the corrected output based on a novel attention mechanism.\nAccounting for the input and output similarity, we propose a new loss function\nthat rewards the model's correcting behavior.\n  Evaluation on a historical book corpus in German language shows that our\nmodels are robust in capturing diverse OCR transcription errors and reduce the\nword error rate of 32.3% by more than 89%.", "published": "2021-02-01 01:35:55", "link": "http://arxiv.org/abs/2102.00583v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Harrington Yowlumne Narrative Corpus", "abstract": "Minority languages continue to lack adequate resources for their development,\nespecially in the technological domain. Likewise, the J.P. Harrington Papers\ncollection at the Smithsonian Institution are difficult to access in practical\nterms for community members and researchers due to its handwritten and\ndisorganized format. Our current work seeks to make a portion of this\npublicly-available yet problematic material practically accessible for natural\nlanguage processing use. Here, we present the Harrington Yowlumne Narrative\nCorpus, a corpus of 20 narrative texts that derive from the Tejone\\~no Yowlumne\ncommunity of the Tinliw rancheria in Kern County, California between 1910 and\n1925. We digitally transcribe the texts and, through a Levenshtein\ndistance-based algorithm and manual checking, we provide gold-standard aligned\nnormalized and lemmatized text. We likewise provide POS tags for each\nlemmatized token via a lexicon-based deterministic approach. Altogether, the\ncorpus contains 57,136 transcribed characters aligned with 10,719 gold standard\ntext-normalized words.", "published": "2021-02-01 03:16:24", "link": "http://arxiv.org/abs/2102.00610v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Ranking for Answer Selection", "abstract": "Answer selection is a task to choose the positive answers from a pool of\ncandidate answers for a given question. In this paper, we propose a novel\nstrategy for answer selection, called hierarchical ranking. We introduce three\nlevels of ranking: point-level ranking, pair-level ranking, and list-level\nranking. They formulate their optimization objectives by employing supervisory\ninformation from different perspectives to achieve the same goal of ranking\ncandidate answers. Therefore, the three levels of ranking are related and they\ncan promote each other. We take the well-performed compare-aggregate model as\nthe backbone and explore three schemes to implement the idea of applying the\nhierarchical rankings jointly: the scheme under the Multi-Task Learning (MTL)\nstrategy, the Ranking Integration (RI) scheme, and the Progressive Ranking\nIntegration (PRI) scheme. Experimental results on two public datasets, WikiQA\nand TREC-QA, demonstrate that the proposed hierarchical ranking is effective.\nOur method achieves state-of-the-art (non-BERT) performance on both TREC-QA and\nWikiQA.", "published": "2021-02-01 07:35:52", "link": "http://arxiv.org/abs/2102.00677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metric-Type Identification for Multi-Level Header Numerical Tables in\n  Scientific Papers", "abstract": "Numerical tables are widely used to present experimental results in\nscientific papers. For table understanding, a metric-type is essential to\ndiscriminate numbers in the tables. We introduce a new information extraction\ntask, metric-type identification from multi-level header numerical tables, and\nprovide a dataset extracted from scientific papers consisting of header tables,\ncaptions, and metric-types. We then propose two joint-learning neural\nclassification and generation schemes featuring pointer-generator-based and\nBERT-based models. Our results show that the joint models can handle both\nin-header and out-of-header metric-type identification problems.", "published": "2021-02-01 15:09:36", "link": "http://arxiv.org/abs/2102.00819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gamified Crowdsourcing for Idiom Corpora Construction", "abstract": "Learning idiomatic expressions is seen as one of the most challenging stages\nin second language learning because of their unpredictable meaning. A similar\nsituation holds for their identification within natural language processing\napplications such as machine translation and parsing. The lack of high-quality\nusage samples exacerbates this challenge not only for humans but also for\nartificial intelligence systems. This article introduces a gamified\ncrowdsourcing approach for collecting language learning materials for idiomatic\nexpressions; a messaging bot is designed as an asynchronous multiplayer game\nfor native speakers who compete with each other while providing idiomatic and\nnonidiomatic usage examples and rating other players' entries. As opposed to\nclassical crowdprocessing annotation efforts in the field, for the first time\nin the literature, a crowdcreating & crowdrating approach is implemented and\ntested for idiom corpora construction. The approach is language independent and\nevaluated on two languages in comparison to traditional data preparation\ntechniques in the field. The reaction of the crowd is monitored under different\nmotivational means (namely, gamification affordances and monetary rewards). The\nresults reveal that the proposed approach is powerful in collecting the\ntargeted materials, and although being an explicit crowdsourcing approach, it\nis found entertaining and useful by the crowd. The approach has been shown to\nhave the potential to speed up the construction of idiom corpora for different\nnatural languages to be used as second language learning material, training\ndata for supervised idiom identification systems, or samples for lexicographic\nstudies.", "published": "2021-02-01 14:44:43", "link": "http://arxiv.org/abs/2102.00881v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained\n  Language Models", "abstract": "Recently, it has been found that monolingual English language models can be\nused as knowledge bases. Instead of structural knowledge base queries, masked\nsentences such as \"Paris is the capital of [MASK]\" are used as probes. We\ntranslate the established benchmarks TREx and GoogleRE into 53 languages.\nWorking with mBERT, we investigate three questions. (i) Can mBERT be used as a\nmultilingual knowledge base? Most prior work only considers English. Extending\nresearch to multiple languages is important for diversity and accessibility.\n(ii) Is mBERT's performance as knowledge base language-independent or does it\nvary from language to language? (iii) A multilingual model is trained on more\ntext, e.g., mBERT is trained on 104 Wikipedias. Can mBERT leverage this for\nbetter performance? We find that using mBERT as a knowledge base yields varying\nperformance across languages and pooling predictions across languages improves\nperformance. Conversely, mBERT exhibits a language bias; e.g., when queried in\nItalian, it tends to predict Italy as the country of origin.", "published": "2021-02-01 15:07:06", "link": "http://arxiv.org/abs/2102.00894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counting Protests in News Articles: A Dataset and Semi-Automated Data\n  Collection Pipeline", "abstract": "Between January 2017 and January 2021, thousands of local news sources in the\nUnited States reported on over 42,000 protests about topics such as civil\nrights, immigration, guns, and the environment. Given the vast number of local\njournalists that report on protests daily, extracting these events as\nstructured data to understand temporal and geographic trends can empower civic\ndecision-making. However, the task of extracting events from news articles\npresents well known challenges to the NLP community in the fields of domain\ndetection, slot filling, and coreference resolution.\n  To help improve the resources available for extracting structured data from\nnews stories, our contribution is three-fold. We 1) release a manually labeled\ndataset of news article URLs, dates, locations, crowd size estimates, and 494\ndiscrete descriptive tags corresponding to 42,347 reported protest events in\nthe United States between January 2017 and January 2021; 2) describe the\nsemi-automated data collection pipeline used to discover, sort, and review the\n144,568 English articles that comprise the dataset; and 3) benchmark a\nlong-short term memory (LSTM) low dimensional classifier that demonstrates the\nutility of processing news articles based on syntactic structures, such as\nparagraphs and sentences, to count the number of reported protest events.", "published": "2021-02-01 15:35:21", "link": "http://arxiv.org/abs/2102.00917v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring and Improving Consistency in Pretrained Language Models", "abstract": "Consistency of a model -- that is, the invariance of its behavior under\nmeaning-preserving alternations in its input -- is a highly desirable property\nin natural language processing. In this paper we study the question: Are\nPretrained Language Models (PLMs) consistent with respect to factual knowledge?\nTo this end, we create ParaRel, a high-quality resource of cloze-style query\nEnglish paraphrases. It contains a total of 328 paraphrases for 38 relations.\nUsing ParaRel, we show that the consistency of all PLMs we experiment with is\npoor -- though with high variance between relations. Our analysis of the\nrepresentational spaces of PLMs suggests that they have a poor structure and\nare currently not suitable for representing knowledge robustly. Finally, we\npropose a method for improving model consistency and experimentally demonstrate\nits effectiveness.", "published": "2021-02-01 17:48:42", "link": "http://arxiv.org/abs/2102.01017v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SJ_AJ@DravidianLangTech-EACL2021: Task-Adaptive Pre-Training of\n  Multilingual BERT models for Offensive Language Identification", "abstract": "In this paper we present our submission for the EACL 2021-Shared Task on\nOffensive Language Identification in Dravidian languages. Our final system is\nan ensemble of mBERT and XLM-RoBERTa models which leverage task-adaptive\npre-training of multilingual BERT models with a masked language modeling\nobjective. Our system was ranked 1st for Kannada, 2nd for Malayalam and 3rd for\nTamil.", "published": "2021-02-01 18:41:56", "link": "http://arxiv.org/abs/2102.01051v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Question Answering Modeling Improvements Hold Across Benchmarks?", "abstract": "Do question answering (QA) modeling improvements (e.g., choice of\narchitecture and training procedure) hold consistently across the diverse\nlandscape of QA benchmarks? To study this question, we introduce the notion of\nconcurrence -- two benchmarks have high concurrence on a set of modeling\napproaches if they rank the modeling approaches similarly. We measure the\nconcurrence between 32 QA benchmarks on a set of 20 diverse modeling approaches\nand find that human-constructed benchmarks have high concurrence amongst\nthemselves, even if their passage and question distributions are very\ndifferent. Surprisingly, even downsampled human-constructed benchmarks (i.e.,\ncollecting less data) and programmatically-generated benchmarks (e.g.,\ncloze-formatted examples) have high concurrence with human-constructed\nbenchmarks. These results indicate that, despite years of intense community\nfocus on a small number of benchmarks, the modeling improvements studied hold\nbroadly.", "published": "2021-02-01 18:55:38", "link": "http://arxiv.org/abs/2102.01065v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Spoken Language Modeling from Raw Audio", "abstract": "We introduce Generative Spoken Language Modeling, the task of learning the\nacoustic and linguistic characteristics of a language from raw audio (no text,\nno labels), and a set of metrics to automatically evaluate the learned\nrepresentations at acoustic and linguistic levels for both encoding and\ngeneration. We set up baseline systems consisting of a discrete speech encoder\n(returning pseudo-text units), a generative language model (trained on\npseudo-text), and a speech decoder (generating a waveform from pseudo-text) all\ntrained without supervision and validate the proposed metrics with human\nevaluation. Across 3 speech encoders (CPC, wav2vec 2.0, HuBERT), we find that\nthe number of discrete units (50, 100, or 200) matters in a task-dependent and\nencoder-dependent way, and that some combinations approach text-based systems.", "published": "2021-02-01 21:41:40", "link": "http://arxiv.org/abs/2102.01192v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Teaching Machines to Read and Comprehend with Large-Scale\n  Multi-Subject Question-Answering Data", "abstract": "In spite of much recent research in the area, it is still unclear whether\nsubject-area question-answering data is useful for machine reading\ncomprehension (MRC) tasks. In this paper, we investigate this question. We\ncollect a large-scale multi-subject multiple-choice question-answering dataset,\nExamQA, and use incomplete and noisy snippets returned by a web search engine\nas the relevant context for each question-answering instance to convert it into\na weakly-labeled MRC instance. We then propose a self-teaching paradigm to\nbetter use the generated weakly-labeled MRC instances to improve a target MRC\ntask. Experimental results show that we can obtain +5.1% in accuracy on a\nmultiple-choice MRC dataset, C^3, and +3.8% in exact match on an extractive MRC\ndataset, CMRC 2018 over state-of-the-art MRC baselines, demonstrating the\neffectiveness of our framework and the usefulness of large-scale subject-area\nquestion-answering data for different types of machine reading comprehension\ntasks.", "published": "2021-02-01 23:18:58", "link": "http://arxiv.org/abs/2102.01226v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polyphone Disambiguation in Mandarin Chinese with Semi-Supervised\n  Learning", "abstract": "The majority of Chinese characters are monophonic, while a special group of\ncharacters, called polyphonic characters, have multiple pronunciations. As a\nprerequisite of performing speech-related generative tasks, the correct\npronunciation must be identified among several candidates. This process is\ncalled Polyphone Disambiguation. Although the problem has been well explored\nwith both knowledge-based and learning-based approaches, it remains challenging\ndue to the lack of publicly available labeled datasets and the irregular nature\nof polyphone in Mandarin Chinese. In this paper, we propose a novel\nsemi-supervised learning (SSL) framework for Mandarin Chinese polyphone\ndisambiguation that can potentially leverage unlimited unlabeled text data. We\nexplore the effect of various proxy labeling strategies including\nentropy-thresholding and lexicon-based labeling. Qualitative and quantitative\nexperiments demonstrate that our method achieves state-of-the-art performance.\nIn addition, we publish a novel dataset specifically for the polyphone\ndisambiguation task to promote further research.", "published": "2021-02-01 03:47:59", "link": "http://arxiv.org/abs/2102.00621v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Commonsense Knowledge Mining from Term Definitions", "abstract": "Commonsense knowledge has proven to be beneficial to a variety of application\nareas, including question answering and natural language understanding.\nPrevious work explored collecting commonsense knowledge triples automatically\nfrom text to increase the coverage of current commonsense knowledge graphs. We\ninvestigate a few machine learning approaches to mining commonsense knowledge\ntriples using dictionary term definitions as inputs and provide some initial\nevaluation of the results. We start from extracting candidate triples using\npart-of-speech tag patterns from text, and then compare the performance of\nthree existing models for triple scoring. Our experiments show that term\ndefinitions contain some valid and novel commonsense knowledge triples for some\nsemantic relations, and also indicate some challenges with using existing\ntriple scoring models.", "published": "2021-02-01 05:54:02", "link": "http://arxiv.org/abs/2102.00651v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Many Hands Make Light Work: Using Essay Traits to Automatically Score\n  Essays", "abstract": "Most research in the area of automatic essay grading (AEG) is geared towards\nscoring the essay holistically while there has also been some work done on\nscoring individual essay traits. In this paper, we describe a way to score\nessays holistically using a multi-task learning (MTL) approach, where scoring\nthe essay holistically is the primary task, and scoring the essay traits is the\nauxiliary task. We compare our results with a single-task learning (STL)\napproach, using both LSTMs and BiLSTMs. We also compare our results of the\nauxiliary task with such tasks done in other AEG systems. To find out which\ntraits work best for different types of essays, we conduct ablation tests for\neach of the essay traits. We also report the runtime and number of training\nparameters for each system. We find that MTL-based BiLSTM system gives the best\nresults for scoring the essay holistically, as well as performing well on\nscoring the essay traits.", "published": "2021-02-01 11:31:09", "link": "http://arxiv.org/abs/2102.00781v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phoneme-BERT: Joint Language Modelling of Phoneme Sequence and ASR\n  Transcript", "abstract": "Recent years have witnessed significant improvement in ASR systems to\nrecognize spoken utterances. However, it is still a challenging task for noisy\nand out-of-domain data, where substitution and deletion errors are prevalent in\nthe transcribed text. These errors significantly degrade the performance of\ndownstream tasks. In this work, we propose a BERT-style language model,\nreferred to as PhonemeBERT, that learns a joint language model with phoneme\nsequence and ASR transcript to learn phonetic-aware representations that are\nrobust to ASR errors. We show that PhonemeBERT can be used on downstream tasks\nusing phoneme sequences as additional features, and also in low-resource setup\nwhere we only have ASR-transcripts for the downstream tasks with no phoneme\ninformation available. We evaluate our approach extensively by generating noisy\ndata for three benchmark datasets - Stanford Sentiment Treebank, TREC and ATIS\nfor sentiment, question and intent classification tasks respectively. The\nresults of the proposed approach beats the state-of-the-art baselines\ncomprehensively on each dataset.", "published": "2021-02-01 12:45:15", "link": "http://arxiv.org/abs/2102.00804v2", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Text-to-hashtag Generation using Seq2seq Learning", "abstract": "In this paper, we studied whether models based on BiLSTM and BERT can predict\nhashtags in Brazilian Portuguese for Ecommerce websites. Hashtags have a\nsizable financial impact on Ecommerce. We processed a corpus of Ecommerce\nreviews as inputs, and predicted hashtags as outputs. We evaluated the results\nusing four quantitative metrics: NIST, BLEU, METEOR and a crowdsourced score. A\nword cloud was used as a qualitative metric. While all computer-generated\nmetrics (NIST, BLEU and METEOR) indicated bad results, the crowdsourced results\nproduced amazing scores. We concluded that the texts predicted by the neural\nnetworks are very promising for use as hashtags for products on Ecommerce\nwebsites. The code for this work is available at\nhttps://github.com/augustocamargo/text-to-hashtag.", "published": "2021-02-01 15:28:27", "link": "http://arxiv.org/abs/2102.00904v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting the Prepositional-Phrase Attachment Problem Using Explicit\n  Commonsense Knowledge", "abstract": "We revisit the challenging problem of resolving prepositional-phrase (PP)\nattachment ambiguity. To date, proposed solutions are either rule-based, where\nexplicit grammar rules direct how to resolve ambiguities; or statistical, where\nthe decision is learned from a corpus of labeled examples. We argue that\nexplicit commonsense knowledge bases can provide an essential ingredient for\nmaking good attachment decisions. We implemented a module, named Patch-Comm,\nthat can be used by a variety of conventional parsers, to make attachment\ndecisions. Where the commonsense KB does not provide direct answers, we fall\nback on a more general system that infers \"out-of-knowledge-base\" assertions in\na manner similar to the way some NLP systems handle out-of-vocabulary words.\nOur results suggest that the commonsense knowledge-based approach can provide\nthe best of both worlds, integrating rule-based and statistical techniques. As\nthe field is increasingly coming to recognize the importance of explainability\nin AI, a commonsense approach can enable NLP developers to better understand\nthe behavior of systems, and facilitate natural dialogues with end users.", "published": "2021-02-01 15:48:36", "link": "http://arxiv.org/abs/2102.00924v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"Is depression related to cannabis?\": A knowledge-infused model for\n  Entity and Relation Extraction with Limited Supervision", "abstract": "With strong marketing advocacy of the benefits of cannabis use for improved\nmental health, cannabis legalization is a priority among legislators. However,\npreliminary scientific research does not conclusively associate cannabis with\nimproved mental health. In this study, we explore the relationship between\ndepression and consumption of cannabis in a targeted social media corpus\ninvolving personal use of cannabis with the intent to derive its potential\nmental health benefit. We use tweets that contain an association among three\ncategories annotated by domain experts - Reason, Effect, and Addiction. The\nstate-of-the-art Natural Langauge Processing techniques fall short in\nextracting these relationships between cannabis phrases and the depression\nindicators. We seek to address the limitation by using domain knowledge;\nspecifically, the Drug Abuse Ontology for addiction augmented with Diagnostic\nand Statistical Manual of Mental Disorders lexicons for mental health. Because\nof the lack of annotations due to the limited availability of the domain\nexperts' time, we use supervised contrastive learning in conjunction with GPT-3\ntrained on a vast corpus to achieve improved performance even with limited\nsupervision. Experimental results show that our method can significantly\nextract cannabis-depression relationships better than the state-of-the-art\nrelation extractor. High-quality annotations can be provided using a nearest\nneighbor approach using the learned representations that can be used by the\nscientific community to understand the association between cannabis and\ndepression better.", "published": "2021-02-01 23:02:43", "link": "http://arxiv.org/abs/2102.01222v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inducing Meaningful Units from Character Sequences with Dynamic Capacity\n  Slot Attention", "abstract": "Characters do not convey meaning, but sequences of characters do. We propose\nan unsupervised distributional method to learn the abstract meaningful units in\na sequence of characters. Rather than segmenting the sequence, our Dynamic\nCapacity Slot Attention model discovers continuous representations of the\nobjects in the sequence, extending an architecture for object discovery in\nimages. We train our model on different languages and evaluate the quality of\nthe obtained representations with forward and reverse probing classifiers.\nThese experiments show that our model succeeds in discovering units which are\nsimilar to those proposed previously in form, content and level of abstraction,\nand which show promise for capturing meaningful information at a higher level\nof abstraction.", "published": "2021-02-01 23:11:57", "link": "http://arxiv.org/abs/2102.01223v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GTAE: Graph-Transformer based Auto-Encoders for Linguistic-Constrained\n  Text Style Transfer", "abstract": "Non-parallel text style transfer has attracted increasing research interests\nin recent years. Despite successes in transferring the style based on the\nencoder-decoder framework, current approaches still lack the ability to\npreserve the content and even logic of original sentences, mainly due to the\nlarge unconstrained model space or too simplified assumptions on latent\nembedding space. Since language itself is an intelligent product of humans with\ncertain grammars and has a limited rule-based model space by its nature,\nrelieving this problem requires reconciling the model capacity of deep neural\nnetworks with the intrinsic model constraints from human linguistic rules. To\nthis end, we propose a method called Graph Transformer based Auto Encoder\n(GTAE), which models a sentence as a linguistic graph and performs feature\nextraction and style transfer at the graph level, to maximally retain the\ncontent and the linguistic structure of original sentences. Quantitative\nexperiment results on three non-parallel text style transfer tasks show that\nour model outperforms state-of-the-art methods in content preservation, while\nachieving comparable performance on transfer accuracy and sentence naturalness.", "published": "2021-02-01 11:08:45", "link": "http://arxiv.org/abs/2102.00769v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Scaling Federated Learning for Fine-tuning of Large Language Models", "abstract": "Federated learning (FL) is a promising approach to distributed compute, as\nwell as distributed data, and provides a level of privacy and compliance to\nlegal frameworks. This makes FL attractive for both consumer and healthcare\napplications. While the area is actively being explored, few studies have\nexamined FL in the context of larger language models and there is a lack of\ncomprehensive reviews of robustness across tasks, architectures, numbers of\nclients, and other relevant factors. In this paper, we explore the fine-tuning\nof Transformer-based language models in a federated learning setting. We\nevaluate three popular BERT-variants of different sizes (BERT, ALBERT, and\nDistilBERT) on a number of text classification tasks such as sentiment analysis\nand author identification. We perform an extensive sweep over the number of\nclients, ranging up to 32, to evaluate the impact of distributed compute on\ntask performance in the federated averaging setting. While our findings suggest\nthat the large sizes of the evaluated models are not generally prohibitive to\nfederated training, we found that the different models handle federated\naveraging to a varying degree. Most notably, DistilBERT converges significantly\nslower with larger numbers of clients, and under some circumstances, even\ncollapses to chance level performance. Investigating this issue presents an\ninteresting perspective for future research.", "published": "2021-02-01 14:31:39", "link": "http://arxiv.org/abs/2102.00875v1", "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "End2End Acoustic to Semantic Transduction", "abstract": "In this paper, we propose a novel end-to-end sequence-to-sequence spoken\nlanguage understanding model using an attention mechanism. It reliably selects\ncontextual acoustic features in order to hypothesize semantic contents. An\ninitial architecture capable of extracting all pronounced words and concepts\nfrom acoustic spans is designed and tested. With a shallow fusion language\nmodel, this system reaches a 13.6 concept error rate (CER) and an 18.5 concept\nvalue error rate (CVER) on the French MEDIA corpus, achieving an absolute 2.8\npoints reduction compared to the state-of-the-art. Then, an original model is\nproposed for hypothesizing concepts and their values. This transduction reaches\na 15.4 CER and a 21.6 CVER without any new type of context.", "published": "2021-02-01 17:42:59", "link": "http://arxiv.org/abs/2102.01013v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Universal Neural Vocoding with Parallel WaveNet", "abstract": "We present a universal neural vocoder based on Parallel WaveNet, with an\nadditional conditioning network called Audio Encoder. Our universal vocoder\noffers real-time high-quality speech synthesis on a wide range of use cases. We\ntested it on 43 internal speakers of diverse age and gender, speaking 20\nlanguages in 17 unique styles, of which 7 voices and 5 styles were not exposed\nduring training. We show that the proposed universal vocoder significantly\noutperforms speaker-dependent vocoders overall. We also show that the proposed\nvocoder outperforms several existing neural vocoder architectures in terms of\nnaturalness and universality. These findings are consistent when we further\ntest on more than 300 open-source voices.", "published": "2021-02-01 19:03:27", "link": "http://arxiv.org/abs/2102.01106v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Distantly-Supervised Relation Extraction through BERT-based\n  Label & Instance Embeddings", "abstract": "Distantly-supervised relation extraction (RE) is an effective method to scale\nRE to large corpora but suffers from noisy labels. Existing approaches try to\nalleviate noise through multi-instance learning and by providing additional\ninformation, but manage to recognize mainly the top frequent relations,\nneglecting those in the long-tail. We propose REDSandT (Relation Extraction\nwith Distant Supervision and Transformers), a novel distantly-supervised\ntransformer-based RE method, that manages to capture a wider set of relations\nthrough highly informative instance and label embeddings for RE, by exploiting\nBERT's pre-trained model, and the relationship between labels and entities,\nrespectively. We guide REDSandT to focus solely on relational tokens by\nfine-tuning BERT on a structured input, including the sub-tree connecting an\nentity pair and the entities' types. Using the extracted informative vectors,\nwe shape label embeddings, which we also use as attention mechanism over\ninstances to further reduce noise. Finally, we represent sentences by\nconcatenating relation and instance embeddings. Experiments in the NYT-10\ndataset show that REDSandT captures a broader set of relations with higher\nconfidence, achieving state-of-the-art AUC (0.424).", "published": "2021-02-01 20:50:24", "link": "http://arxiv.org/abs/2102.01156v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Student sentiment Analysis Using Classification With Feature Extraction\n  Techniques", "abstract": "Technical growths have empowered, numerous revolutions in the educational\nsystem by acquainting with technology into the classroom and by elevating the\nlearning experience. Nowadays Web-based learning is getting much popularity.\nThis paper describes the web-based learning and their effectiveness towards\nstudents. One of the prime factors in education or learning system is feedback;\nit is beneficial to learning if it must be used effectively. In this paper, we\nworked on how machine learning techniques like Logistic Regression (LR),\nSupport Vector Machine (SVM), Naive Bayes (NB), Decision Tree (DT) can be\napplied over Web-based learning, emphasis given on sentiment present in the\nfeedback students. We also work on two types of Feature Extraction Technique\n(FETs) namely Count Vector (CVr) or Bag of Words) (BoW) and Term Frequency and\nInverse Document Frequency (TF-IDF) Vector. In the research study, it is our\ngoal for our proposed LR, SVM, NB, and DT models to classify the presence of\nStudent Feedback Dataset (SFB) with improved accuracy with cleaned dataset and\nfeature extraction techniques. The SFB is one of the significant concerns among\nthe student sentimental analysis.", "published": "2021-02-01 18:48:06", "link": "http://arxiv.org/abs/2102.05439v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Civil Rephrases Of Toxic Texts With Self-Supervised Transformers", "abstract": "Platforms that support online commentary, from social networks to news sites,\nare increasingly leveraging machine learning to assist their moderation\nefforts. But this process does not typically provide feedback to the author\nthat would help them contribute according to the community guidelines. This is\nprohibitively time-consuming for human moderators to do, and computational\napproaches are still nascent. This work focuses on models that can help suggest\nrephrasings of toxic comments in a more civil manner. Inspired by recent\nprogress in unpaired sequence-to-sequence tasks, a self-supervised learning\nmodel is introduced, called CAE-T5. CAE-T5 employs a pre-trained text-to-text\ntransformer, which is fine tuned with a denoising and cyclic auto-encoder loss.\nExperimenting with the largest toxicity detection dataset to date (Civil\nComments) our model generates sentences that are more fluent and better at\npreserving the initial content compared to earlier text style transfer systems\nwhich we compare with using several scoring systems and human evaluation.", "published": "2021-02-01 15:27:52", "link": "http://arxiv.org/abs/2102.05456v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Network architectures to classify emotions in Indian Classical\n  Music", "abstract": "Music is often considered as the language of emotions. It has long been known\nto elicit emotions in human being and thus categorizing music based on the type\nof emotions they induce in human being is a very intriguing topic of research.\nWhen the task comes to classify emotions elicited by Indian Classical Music\n(ICM), it becomes much more challenging because of the inherent ambiguity\nassociated with ICM. The fact that a single musical performance can evoke a\nvariety of emotional response in the audience is implicit to the nature of ICM\nrenditions. With the rapid advancements in the field of Deep Learning, this\nMusic Emotion Recognition (MER) task is becoming more and more relevant and\nrobust, hence can be applied to one of the most challenging test case i.e.\nclassifying emotions elicited from ICM. In this paper we present a new dataset\ncalled JUMusEmoDB which presently has 400 audio clips (30 seconds each) where\n200 clips correspond to happy emotions and the remaining 200 clips correspond\nto sad emotion. For supervised classification purposes, we have used 4 existing\ndeep Convolutional Neural Network (CNN) based architectures (resnet18,\nmobilenet v2.0, squeezenet v1.0 and vgg16) on corresponding music spectrograms\nof the 2000 sub-clips (where every clip was segmented into 5 sub-clips of about\n5 seconds each) which contain both time as well as frequency domain\ninformation. The initial results are quite inspiring, and we look forward to\nsetting the baseline values for the dataset using this architecture. This type\nof CNN based classification algorithm using a rich corpus of Indian Classical\nMusic is unique even in the global perspective and can be replicated in other\nmodalities of music also. This dataset is still under development and we plan\nto include more data containing other emotional features as well. We plan to\nmake the dataset publicly available soon.", "published": "2021-02-01 03:41:25", "link": "http://arxiv.org/abs/2102.00616v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On Scaling Contrastive Representations for Low-Resource Speech\n  Recognition", "abstract": "Recent advances in self-supervised learning through contrastive training have\nshown that it is possible to learn a competitive speech recognition system with\nas little as 10 minutes of labeled data. However, these systems are\ncomputationally expensive since they require pre-training followed by\nfine-tuning in a large parameter space. We explore the performance of such\nsystems without fine-tuning by training a state-of-the-art speech recognizer on\nthe fixed representations from the computationally demanding wav2vec 2.0\nframework. We find performance to decrease without fine-tuning and, in the\nextreme low-resource setting, wav2vec 2.0 is inferior to its predecessor. In\naddition, we find that wav2vec 2.0 representations live in a low dimensional\nsubspace and that decorrelating the features of the representations can\nstabilize training of the automatic speech recognizer. Finally, we propose a\nbidirectional extension to the original wav2vec framework that consistently\nimproves performance.", "published": "2021-02-01 13:58:02", "link": "http://arxiv.org/abs/2102.00850v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Music Information Dynamics", "abstract": "Music comprises of a set of complex simultaneous events organized in time. In\nthis paper we introduce a novel framework that we call Deep Musical Information\nDynamics, which combines two parallel streams - a low rate latent\nrepresentation stream that is assumed to capture the dynamics of a thought\nprocess contrasted with a higher rate information dynamics derived from the\nmusical data itself. Motivated by rate-distortion theories of human cognition\nwe propose a framework for exploring possible relations between imaginary\nanticipations existing in the listener's mind and information dynamics of the\nmusical surface itself. This model is demonstrated for the case of symbolic\n(MIDI) data, as accounting for acoustic surface would require many more layers\nto capture instrument properties and performance expressive inflections. The\nmathematical framework is based on variational encoding that first establishes\na high rate representation of the musical observations, which is then reduced\nusing a bit-allocation method into a parallel low rate data stream. The\ncombined loss considered here includes both the information rate in terms of\ntime evolution for each stream, and the fidelity of encoding measured in terms\nof mutual information between the high and low rate representations. In the\nsimulations presented in the paper we are able to juxtapose aspects of\nlatent/imaginary surprisal versus surprisal of the music surface in a manner\nthat is quantifiable and computationally tractable. The set of computational\ntools is discussed in the paper, suggesting that a trade off between\ncompression and prediction are an important factor in the analysis and design\nof time-based music generative models.", "published": "2021-02-01 19:59:59", "link": "http://arxiv.org/abs/2102.01133v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
