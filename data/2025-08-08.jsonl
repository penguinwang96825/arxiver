{"title": "Voting-Based Semi-Parallel Proof-of-Work Protocol", "abstract": "Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety\nguarantees, transaction throughput and confirmation latencies of Nakamoto\nconsensus. In this work, we first consider the existing parallel PoW protocols\nand develop hard-coded incentive attack structures. Our theoretical results and\nsimulations show that the existing parallel PoW protocols are more vulnerable\nto incentive attacks than the Nakamoto consensus, e.g., attacks have smaller\nprofitability threshold and they result in higher relative rewards. Next, we\nintroduce a voting-based semi-parallel PoW protocol that outperforms both\nNakamoto consensus and the existing parallel PoW protocols from most practical\nperspectives such as communication overheads, throughput, transaction\nconflicts, incentive compatibility of the protocol as well as a fair\ndistribution of transaction fees among the voters and the leaders. We use\nstate-of-the-art analysis to evaluate the consistency of the protocol and\nconsider Markov decision process (MDP) models to substantiate our claims about\nthe resilience of our protocol against incentive attacks.", "published": "2025-08-08 17:57:35", "link": "http://arxiv.org/abs/2508.06489v1", "categories": ["cs.CR", "cs.DC", "cs.DM", "cs.IT", "math.IT", "math.PR"], "primary_category": "cs.CR"}
{"title": "On Approximate MMS Allocations on Restricted Graph Classes", "abstract": "We study the problem of fair division of a set of indivisible goods with\nconnectivity constraints. Specifically, we assume that the goods are\nrepresented as vertices of a connected graph, and sets of goods allocated to\nthe agents are connected subgraphs of this graph. We focus on the\nwidely-studied maximin share criterion of fairness. It has been shown that an\nallocation satisfying this criterion may not exist even without connectivity\nconstraints, i.e., if the graph of goods is complete. In view of this, it is\nnatural to seek approximate allocations that guarantee each agent a connected\nbundle of goods with value at least a constant fraction of the maximin share\nvalue to the agent. It is known that for some classes of graphs, such as\ncomplete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such\napproximate allocations indeed exist. However, it is an open problem whether\nthey exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of\napproximate allocations on restricted graph classes. In particular, we show\nthat such allocations exist for several well-studied classes, including block\ngraphs, cacti, complete multipartite graphs, and split graphs.", "published": "2025-08-08 14:17:44", "link": "http://arxiv.org/abs/2508.06343v1", "categories": ["cs.DM", "cs.AI"], "primary_category": "cs.DM"}
{"title": "Sandwich Monotonicity and the Recognition of Weighted Graph Classes", "abstract": "Edge-weighted graphs play an important role in the theory of Robinsonian\nmatrices and similarity theory, particularly via the concept of level graphs,\nthat is, graphs obtained from an edge-weighted graph by removing all\nsufficiently light edges. This suggest a natural way of associating to any\nclass $\\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted\ngraphs, namely by requiring that all level graphs belong to $\\mathcal{G}$. We\nshow that weighted graphs for which all level graphs are split, threshold, or\nchain graphs can be recognized in linear time using special edge elimination\norderings. We obtain these results by introducing the notion of degree sandwich\nmonotone graph classes. A graph class $\\mathcal{G}$ is sandwich monotone if\nevery edge set which may be removed from a graph in $\\mathcal{G}$ without\nleaving the class also contains a single edge that can be safely removed.\nFurthermore, if we require the safe edge to fulfill a certain degree property,\nthen $\\mathcal{G}$ is called degree sandwich monotone. We present necessary and\nsufficient conditions for the existence of a linear-time recognition algorithm\nfor any weighted graph class whose corresponding unweighted class is degree\nsandwich monotone and contains all edgeless graphs.", "published": "2025-08-08 10:52:39", "link": "http://arxiv.org/abs/2508.06216v1", "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "A Structural Linear-Time Algorithm for Computing the Tutte Decomposition", "abstract": "The block-cut tree decomposes a connected graph along its cutvertices,\ndisplaying its 2-connected components. The Tutte-decomposition extends this\nidea to 2-separators in 2-connected graphs, yielding a canonical\ntree-decomposition that decomposes the graph into its triconnected components.\nIn 1973, Hopcroft and Tarjan introduced a linear-time algorithm to compute the\nTutte-decomposition. Cunningham and Edmonds later established a structural\ncharacterization of the Tutte-decomposition via totally-nested 2-separations.\nWe present a conceptually simple algorithm based on this characterization,\nwhich computes the Tutte-decomposition in linear time. Our algorithm first\ncomputes all totally-nested 2-separations and then builds the\nTutte-decomposition from them.\n  Along the way, we derive new structural results on the structure of\ntotally-nested 2-separations in 2-connected graphs using a novel notion of\nstability, which may be of independent interest.", "published": "2025-08-08 10:48:18", "link": "http://arxiv.org/abs/2508.06212v1", "categories": ["cs.DS", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "Induced Minors, Asymptotic Dimension, and Baker's Technique", "abstract": "Asymptotic dimension is a large-scale invariant of metric spaces that was\nintroduced by Gromov (1993). We prove that every hereditary class of\nbounded-degree graphs that excludes some graph as a fat minor has asymptotic\ndimension at most $2$, which is optimal. This makes substantial progress on a\nquestion of Bonamy, Bousquet, Esperet, Groenland, Liu, Pirot, and Scott (J.\nEur. Math. Soc. 2023).\n  The key to our proof is a notion inspired by Baker's technique (J. ACM 1994).\nWe say that a graph class $\\mathcal{G}$ has bounded Baker-treewidth if there\nexists a function $f \\colon \\mathbb{N} \\to \\mathbb{N}$ such that, for every\ngraph $G\\in \\mathcal{G}$, there is a layering of $G$ such that the subgraph\ninduced by the union of any $\\ell$ consecutive layers has treewidth at most\n$f(\\ell)$. We show that every class of bounded-degree graphs that excludes some\ngraph as an induced minor has bounded Baker-treewidth. We discuss further\napplications of this result to clustered colouring and the design of\nlinear-time approximate schemes.", "published": "2025-08-08 10:12:03", "link": "http://arxiv.org/abs/2508.06190v1", "categories": ["math.CO", "cs.DM", "math.GR", "math.GT", "math.MG"], "primary_category": "math.CO"}
{"title": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations", "abstract": "Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees\nand octrees, underpins a wide range of applications including databases,\ncomputer graphics, physics simulations, and machine learning. However, octrees\nenforce isotropic refinement in regions of interest, which can be especially\ninefficient for problems that are intrinsically anisotropic--much resolution is\nspent where little information is gained. This paper presents omnitrees as an\nanisotropic generalization of octrees and related data structures. Omnitrees\nallow to refine only the locally most important dimensions, providing tree\nstructures that are less deep than bintrees and less wide than octrees. As a\nresult, the convergence of the AMR schemes can be increased by up to a factor\nof the dimensionality d for very anisotropic problems, quickly offsetting their\nmodest increase in storage overhead. We validate this finding on the problem of\nbinary shape representation across 4,166 three-dimensional objects: Omnitrees\nincrease the mean convergence rate by 1.5x, require less storage to achieve\nequivalent error bounds, and maximize the information density of the stored\nfunction faster than octrees. These advantages are projected to be even\nstronger for higher-dimensional problems. We provide a first validation by\nintroducing a time-dependent rotation to create four-dimensional\nrepresentations, and discuss the properties of their 4-d octree and omnitree\napproximations. Overall, omnitree discretizations can make existing AMR\napproaches more efficient, and open up new possibilities for high-dimensional\napplications.", "published": "2025-08-08 13:42:59", "link": "http://arxiv.org/abs/2508.06316v1", "categories": ["cs.DS", "cs.CG", "cs.GR", "cs.IT", "cs.NA", "math.IT", "math.NA", "65D15, 65D18, 68P05, 68P30"], "primary_category": "cs.DS"}
{"title": "A New Framework for the Sum of Squared $\u03ba$-$\u03bc$ RVs with Application to Sub-THz Systems", "abstract": "In this paper, we adopt the $\\kappa$-$\\mu$ model to characterize the\npropagation in the sub-THz band. We develop a new exact representation of the\nsum of squared independent and identically distributed $\\kappa$-$\\mu$ random\nvariables, which can be used to express the power of the received signal in\nmulti-antenna systems. Unlike existing ones, the proposed analytical framework\nis remarkably tractable and computationally efficient, and thus can be\nconveniently employed to analyze systems with massive antenna arrays. We derive\nnovel expressions for the probability density function and cumulative\ndistribution function, analyze their convergence and truncation error, and\ndiscuss the computational complexity and the implementation aspects. Moreover,\nwe derive expressions for the coverage probability and bit error probability\nfor coherent binary modulations. Lastly, we evaluate the performance of an\nuplink sub-THz system where a single-antenna user is served by a base station\nemploying maximum ratio combining.", "published": "2025-08-08 11:49:19", "link": "http://arxiv.org/abs/2508.06242v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On MDS Convertible Codes in the Merge Regime", "abstract": "In large-scale distributed storage systems, erasure coding is employed to\nensure reliability against disk failures. Recent work by Kadekodi et al.\ndemonstrates that adapting code parameters to varying disk failure rates can\nlead to significant storage savings without compromising reliability. Such\nadaptations, known as \\emph{code conversions}, motivate the design of\n\\emph{convertible codes}, which enable efficient transformations between codes\nof different parameters.\n  In this work, we study the setting in which $\\lambda$ codewords of an initial\n$[n^I = k^I + r^I,\\, k^I]$ MDS code are merged into a single codeword of a\nfinal $[n^F = \\lambda k^I + r^F,\\, k^F = \\lambda k^I]$ MDS code. We begin by\npresenting three constructions that achieve optimal \\emph{access cost}, defined\nas the total number of disks accessed during the conversion process. The first\ntwo constructions apply when $\\lambda \\leq r^I$ and impose specific\ndivisibility conditions on $r^I$ and the field size $q$. These schemes minimize\nboth the per-symbol and the overall access cost. The third construction, which\nbuilds on a prior scheme by Kong, achieves minimal access cost while supporting\narbitrary parameter regimes. All three constructions require field sizes that\nare linear in the final code length, and notably, the third construction\nachieves a field size that matches the lower bound implied by the MDS\nconjecture in almost all cases. In addition, we propose a construction that\noptimizes the \\emph{bandwidth cost}, defined as the total number of symbols\ntransmitted during conversion. This scheme is a refinement of Maturana and\nRashmi's bandwidth-optimal construction based on the piggybacking framework,\nand achieves reduced sub-packetization.", "published": "2025-08-08 10:59:52", "link": "http://arxiv.org/abs/2508.06219v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-Functional Chirp Signalling for Next-Generation Multi-Carrier Wireless Networks: Communications, Sensing and ISAC Perspectives", "abstract": "To meet the increasingly demanding quality-of-service requirements of the\nnext-generation multi-carrier mobile networks, it is essential to design\nmulti-functional signalling schemes facilitating efficient, flexible, and\nreliable communication and sensing in complex wireless environments. As a\ncompelling candidate, we advocate chirp signalling, beneficially amalgamating\nsequences (e.g., Zadoff-Chu sequences) with waveforms (e.g., chirp spread\nspectrum and frequency-modulated continuous wave (FMCW) radar), given their\nresilience against doubly selective channels. Besides chirp sequences, a wide\nrange of chirp waveforms is considered, ranging from FMCW to affine\nfrequency-division multiplexing (AFDM), to create a promising chirp\nmulticarrier waveform. This study also highlights the advantages of such\nwaveforms in supporting reliable high-mobility communications, plus integrated\nsensing and communications (ISAC). Finally, we outline several emerging\nresearch directions for chirp signalling designs.", "published": "2025-08-08 05:17:17", "link": "http://arxiv.org/abs/2508.06022v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "IRS-Assisted IoT Activity Detection Under Asynchronous Transmission and Heterogeneous Powers: Detectors and Performance Analysis", "abstract": "This paper addresses the problem of activity detection in distributed\nInternet of Things (IoT) networks, where devices employ asynchronous\ntransmissions with heterogeneous power levels to report their local\nobservations. The system leverages an intelligent reflecting surface (IRS) to\nenhance detection reliability, with optional incorporation of a direct\nline-of-sight (LoS) path. We formulate the detection problem as a binary\nhypothesis test and develop four detectors: an optimal detector alongside three\ncomputationally efficient detectors designed for practical scenarios with\ndifferent levels of prior knowledge about noise variance, channel state\ninformation, and device transmit powers. For each detector, we derive\nclosed-form expressions for both detection and false alarm probabilities,\nestablishing theoretical performance benchmarks. Extensive simulations validate\nour analytical results and systematically evaluate the impact of key system\nparameters including the number of antennas, samples, users, and IRS elements\non detection performance. The proposed framework effectively bridges\ntheoretical optimality with implementation practicality, providing a scalable\nsolution for IRS-assisted IoT networks in emerging 6G systems.", "published": "2025-08-08 02:46:03", "link": "http://arxiv.org/abs/2508.05959v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "abstract": "Large Language Models (LLMs) have demonstrated impressive fluency and\nreasoning capabilities, but their potential for misuse has raised growing\nconcern. In this paper, we present ScamAgent, an autonomous multi-turn agent\nbuilt on top of LLMs, capable of generating highly realistic scam call scripts\nthat simulate real-world fraud scenarios. Unlike prior work focused on\nsingle-shot prompt misuse, ScamAgent maintains dialogue memory, adapts\ndynamically to simulated user responses, and employs deceptive persuasion\nstrategies across conversational turns. We show that current LLM safety\nguardrails, including refusal mechanisms and content filters, are ineffective\nagainst such agent-based threats. Even models with strong prompt-level\nsafeguards can be bypassed when prompts are decomposed, disguised, or delivered\nincrementally within an agent framework. We further demonstrate the\ntransformation of scam scripts into lifelike voice calls using modern\ntext-to-speech systems, completing a fully automated scam pipeline. Our\nfindings highlight an urgent need for multi-turn safety auditing, agent-level\ncontrol frameworks, and new methods to detect and disrupt conversational\ndeception powered by generative AI.", "published": "2025-08-08 17:01:41", "link": "http://arxiv.org/abs/2508.06457v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Memp: Exploring Agent Procedural Memory", "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they\nsuffer from brittle procedural memory that is manually engineered or entangled\nin static parameters. In this work, we investigate strategies to endow agents\nwith a learnable, updatable, and lifelong procedural memory. We propose Memp\nthat distills past agent trajectories into both fine-grained, step-by-step\ninstructions and higher-level, script-like abstractions, and explore the impact\nof different strategies for Build, Retrieval, and Update of procedural memory.\nCoupled with a dynamic regimen that continuously updates, corrects, and\ndeprecates its contents, this repository evolves in lockstep with new\nexperience. Empirical evaluation on TravelPlanner and ALFWorld shows that as\nthe memory repository is refined, agents achieve steadily higher success rates\nand greater efficiency on analogous tasks. Moreover, procedural memory built\nfrom a stronger model retains its value: migrating the procedural memory to a\nweaker model yields substantial performance gains.", "published": "2025-08-08 16:20:56", "link": "http://arxiv.org/abs/2508.06433v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "abstract": "We introduce Unsupervised Partner Design (UPD) - a population-free,\nmulti-agent reinforcement learning framework for robust ad-hoc teamwork that\nadaptively generates training partners without requiring pretrained partners or\nmanual parameter tuning. UPD constructs diverse partners by stochastically\nmixing an ego agent's policy with biased random behaviours and scores them\nusing a variance-based learnability metric that prioritises partners near the\nego agent's current learning frontier. We show that UPD can be integrated with\nunsupervised environment design, resulting in the first method enabling fully\nunsupervised curricula over both level and partner distributions in a\ncooperative setting. Through extensive evaluations on Overcooked-AI and the\nOvercooked Generalisation Challenge, we demonstrate that this dynamic partner\ncurriculum is highly effective: UPD consistently outperforms both\npopulation-based and population-free baselines as well as ablations. In a user\nstudy, we further show that UPD achieves higher returns than all baselines and\nwas perceived as significantly more adaptive, more human-like, a better\ncollaborator, and less frustrating.", "published": "2025-08-08 14:11:15", "link": "http://arxiv.org/abs/2508.06336v1", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "abstract": "We present Big5-Scaler, a prompt-based framework for conditioning large\nlanguage models (LLMs) with controllable Big Five personality traits. By\nembedding numeric trait values into natural language prompts, our method\nenables fine-grained personality control without additional training. We\nevaluate Big5-Scaler across trait expression, dialogue generation, and human\ntrait imitation tasks. Results show that it induces consistent and\ndistinguishable personality traits across models, with performance varying by\nprompt type and scale. Our analysis highlights the effectiveness of concise\nprompts and lower trait intensities, providing a efficient approach for\nbuilding personality-aware dialogue agents.", "published": "2025-08-08 09:11:05", "link": "http://arxiv.org/abs/2508.06149v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "abstract": "Table reasoning, including tabular QA and fact verification, often depends on\nannotated data or complex data augmentation, limiting flexibility and\ngeneralization. LLMs, despite their versatility, often underperform compared to\nsimple supervised models. To approach these issues, we introduce PanelTR, a\nframework utilizing LLM agent scientists for robust table reasoning through a\nstructured scientific approach. PanelTR's workflow involves agent scientists\nconducting individual investigations, engaging in self-review, and\nparticipating in collaborative peer-review discussions. This process, driven by\nfive scientist personas, enables semantic-level transfer without relying on\ndata augmentation or parametric optimization. Experiments across four\nbenchmarks show that PanelTR outperforms vanilla LLMs and rivals fully\nsupervised models, all while remaining independent of training data. Our\nfindings indicate that structured scientific methodology can effectively handle\ncomplex tasks beyond table reasoning with flexible semantic understanding in a\nzero-shot context.", "published": "2025-08-08 08:15:52", "link": "http://arxiv.org/abs/2508.06110v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Policy Optimization in Multi-Agent Settings under Partially Observable Environments", "abstract": "This work leverages adaptive social learning to estimate partially observable\nglobal states in multi-agent reinforcement learning (MARL) problems. Unlike\nexisting methods, the proposed approach enables the concurrent operation of\nsocial learning and reinforcement learning. Specifically, it alternates between\na single step of social learning and a single step of MARL, eliminating the\nneed for the time- and computation-intensive two-timescale learning frameworks.\nTheoretical guarantees are provided to support the effectiveness of the\nproposed method. Simulation results verify that the performance of the proposed\nmethodology can approach that of reinforcement learning when the true state is\nknown.", "published": "2025-08-08 06:45:43", "link": "http://arxiv.org/abs/2508.06061v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Weak approximation of stochastic differential equations with sticky boundary conditions", "abstract": "Sticky diffusion models a Markovian particle experiencing reflection and\ntemporary adhesion phenomena at the boundary. Numerous numerical schemes exist\nfor approximating stopped or reflected stochastic differential equations\n(SDEs), but this is not the case for sticky SDEs. In this paper, we construct\nand analyze half-order and first-order numerical schemes for the weak\napproximation of stochastic differential equations with sticky boundary\nconditions. We present the algorithms in general setting such that they can be\nused to solve general linear parabolic partial differential equations with\nsecond-order sticky boundary condition via the probabilistic representations of\ntheir solutions. Since the sticky diffusion spends non-zero amount of time on\nboundary, it poses extra challenge in designing the schemes and obtaining their\norder of convergence. We support the theoretical results with numerical\nexperiments.", "published": "2025-08-08 17:50:18", "link": "http://arxiv.org/abs/2508.06487v1", "categories": ["math.NA", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Does block size matter in randomized block Krylov low-rank approximation?", "abstract": "We study the problem of computing a rank-$k$ approximation of a matrix using\nrandomized block Krylov iteration. Prior work has shown that, for block size $b\n= 1$ or $b = k$, a $(1 + \\varepsilon)$-factor approximation to the best\nrank-$k$ approximation can be obtained after $\\tilde O(k/\\sqrt{\\varepsilon})$\nmatrix-vector products with the target matrix. On the other hand, when $b$ is\nbetween $1$ and $k$, the best known bound on the number of matrix-vector\nproducts scales with $b(k-b)$, which could be as large as $O(k^2)$.\nNevertheless, in practice, the performance of block Krylov methods is often\noptimized by choosing a block size $1 \\ll b \\ll k$. We resolve this\ntheory-practice gap by proving that randomized block Krylov iteration produces\na $(1 + \\varepsilon)$-factor approximate rank-$k$ approximation using $\\tilde\nO(k/\\sqrt{\\varepsilon})$ matrix-vector products for any block size $1\\le b\\le\nk$. Our analysis relies on new bounds for the minimum singular value of a\nrandom block Krylov matrix, which may be of independent interest. Similar\nbounds are central to recent breakthroughs on faster algorithms for sparse\nlinear systems [Peng & Vempala, SODA 2021; Nie, STOC 2022].", "published": "2025-08-08 17:50:01", "link": "http://arxiv.org/abs/2508.06486v1", "categories": ["cs.DS", "cs.NA", "math.NA", "65F55 65F15", "G.1.3; F.2.1"], "primary_category": "cs.DS"}
{"title": "Heterogeneous optimized Schwarz Methods for heat conduction in composites with thermal contact resistance", "abstract": "Heat transfer in composites is critical in engineering, where imperfect layer\ncontact causes thermal contact resistance (TCR), leading to interfacial\ntemperature discontinuity. We propose solving this numerically using the\noptimized Schwarz method (OSM), which decouples the heterogeneous problem into\nhomogeneous subproblems. This avoids ill-conditioned systems from monolithic\nsolving due to high contrast and interface jumps. Both energy estimate and\nFourier analysis are used to prove the convergence of this algorithm when the\nstandard Robin condition is applied to transmit information between subdomains.\nTo achieve fast convergence, instead of the standard Robin, the scaled Robin\ntransmission condition is proposed, and the involved free parameter is\nrigorously optimized. The results reveal several new findings due to the\npresence of TCR: first, the larger the TCR, the faster the OSM converges;\nsecond, mesh-independent convergence is achieved in the asymptotic sense, in\ncontrast to the mesh-dependent results without TCR; and last, the heterogeneity\ncontrast benefits the convergence, with a larger contrast leading to faster\nconvergence. Interestingly, different from the case without TCR, the thermal\nconductivity also benefits the convergence, similar to the effect of\nheterogeneity. Numerical experiments confirm the theoretical findings and\ndemonstrate the method's potential for nonlinear problems on irregular domains.", "published": "2025-08-08 15:51:12", "link": "http://arxiv.org/abs/2508.06408v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rational minimax approximation of matrix-valued functions", "abstract": "In this paper, we present a rigorous framework for rational minimax\napproximation of matrix-valued functions that generalizes classical scalar\napproximation theory. Given sampled data $\\{(x_\\ell, {F}(x_\\ell))\\}_{\\ell=1}^m$\nwhere ${F}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ is a matrix-valued function,\nwe study the problem of finding a matrix-valued rational approximant ${R}(x) =\n{P}(x)/q(x)$ (with ${P}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ a matrix-valued\npolynomial and $q(x)$ a nonzero scalar polynomial of prescribed degrees) that\nminimizes the worst-case Frobenius norm error over the given nodes: $$\n\\inf_{{R}(x) = {P}(x)/q(x)} \\max_{1 \\leq \\ell \\leq m} \\|{F}(x_\\ell) -\n{R}(x_\\ell)\\|_{\\rm F}. $$ By reformulating this min-max optimization problem\nthrough Lagrangian duality, we derive a maximization dual problem over the\nprobability simplex. We analyze weak and strong duality properties and\nestablish a sufficient condition ensuring that the solution of the dual problem\nyields the minimax approximant $R(x)$. For numerical implementation, we propose\nan efficient method (\\textsf{m-d-Lawson}) to solve the dual problem,\ngeneralizing Lawson's iteration to matrix-valued functions. Numerical\nexperiments are conducted and compared to state-of-the-art approaches,\ndemonstrating its efficiency as a novel computational framework for\nmatrix-valued rational approximation.", "published": "2025-08-08 15:09:24", "link": "http://arxiv.org/abs/2508.06378v1", "categories": ["math.NA", "cs.NA", "41A50, 41A20, 65D15, 90C46"], "primary_category": "math.NA"}
{"title": "Higher Order Regularization using Harmonic Eigenfunctions for Model-Based Reconstruction in Magnetic Particle Imaging", "abstract": "Magnetic Particle Imaging (MPI) is a recent imaging modality where\nsuperparamagnetic nanoparticles are employed as tracers. The reconstruction\ntask is to obtain the spatial particle distribution from a voltage signal\ninduced by the particles. Generally, in computational imaging variational\nreconstruction techniques are common and rely on a mathematical model to\ndescribe the underlying physics. For the MPI reconstruction task we propose a\nmodel-based variational reconstruction technique which incorporates a higher\norder regularizer, where the regularizer is diagonalized by harmonic\neigenfunctions. The proposed image reconstruction algorithm features two major\nstages: in the first stage, the core stage, the components of the MPI core\nresponse are reconstructed. This is the MPI-specific data approximation task\nwhich we formulate as a variational problem incorporating the higher order\nregularizer. The relationship between the particle distribution, the MPI core\nresponse and the measured data is given by a mathematical model which was\nintroduced in our earlier research. According to this model the MPI core\nresponse is tied to the particle distribution by convolution. Therefore the\noutcome of the core stage yields the data for the second stage, the\ndeconvolution stage, in which the final reconstructed image is produced by\nsolving an ill-posed deconvolution problem in a robust way relying on earlier\nresearch. Interestingly, the quality of the final image depends significantly\non the quality of the result of the core stage. A contribution is thus the\nenhancement of the core stage via higher order regularization. We provide a\ntheoretical foundation for our approach and demonstrate its benefit with\nnumerical examples.", "published": "2025-08-08 13:33:21", "link": "http://arxiv.org/abs/2508.06306v1", "categories": ["math.NA", "cs.NA", "65K10, 65R32, 65T40, 92C55"], "primary_category": "math.NA"}
{"title": "A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions", "abstract": "Computing with discrete representations of high-dimensional probability\ndistributions is fundamental to uncertainty quantification, Bayesian inference,\nand stochastic modeling. However, storing and manipulating such distributions\nsuffers from the curse of dimensionality, as memory and computational costs\ngrow exponentially with dimension. Monte Carlo methods require thousands to\nbillions of samples, incurring high computational costs and producing\ninconsistent results due to stochasticity. We present an efficient tensor train\nmethod for performing exact arithmetic operations on discretizations of\ncontinuous probability distributions while avoiding exponential growth. Our\napproach leverages low-rank tensor train decomposition to represent latent\nrandom variables compactly using Dirac deltas, enabling deterministic addition,\nsubtraction and multiplication operations directly in the compressed format. We\ndevelop an efficient implementation using sparse matrices and specialized data\nstructures that further enhances performance. Theoretical analysis demonstrates\npolynomial scaling of memory and computational complexity under rank\nassumptions, and shows how statistics of latent variables can be computed with\npolynomial complexity. Numerical experiments spanning randomized linear algebra\nto stochastic differential equations demonstrate orders-of-magnitude\nimprovements in memory usage and computational time compared to conventional\napproaches, enabling tractable deterministic computations on discretized random\nvariables in previously intractable dimensions.", "published": "2025-08-08 13:27:35", "link": "http://arxiv.org/abs/2508.06303v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Parallelized computation of quasi-periodic solutions for finite element problems: A Fourier series expansion-based shooting method", "abstract": "High-dimensional nonlinear mechanical systems admit quasi-periodic solutions\nthat are essential for the understanding of the dynamical systems. These\nquasi-periodic solutions stay on some invariant tori governed by complex PDEs\nin hyper-time. Here, we propose a Fourier series expansion-based shooting\nmethod (FSE-Shooting) for the parallelized computation of quasi-periodic\nsolution with $d$ base frequencies ($d \\ge 2$). We represent the associated\n$d$-torus as a collection of trajectories initialized at a ($d-1$)-torus. We\ndrive a set of ODEs that hold for any of these trajectories. We also derive a\nset of boundary conditions that couple the initial and terminal states of these\ntrajectories and then formulate a set of nonlinear algebraic equations via the\ncoupling conditions. We use Fourier series expansion to parameterize the\n($d-1$)-torus and shooting method to iterate the Fourier coefficients\nassociated with initial torus such that the coupling conditions are satisfied.\nIn particular, the terminal points of these trajectories are parallelized\ncomputed via Newmark integration, where the time points and Fourier\ncoefficients are transformed to each other by alternating Frequency-Time\nmethod. A straightforward phase condition is devised to track the\nquasi-periodic solutions with priori unknown base frequencies. Additionally,\nthe by-product of the FSE-Shooting can be also directly used to compute the\nLyapunov exponents to assess the stabilities of quasi-periodic solutions. The\nresults of three finite element systems show the efficiency and versatility of\nFSE-Shooting in high-dimensional nonlinear dynamical systems, including a\nthree-dimensional shell structure with $1872$ DOFs.", "published": "2025-08-08 13:27:01", "link": "http://arxiv.org/abs/2508.06302v1", "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "math.NA"}
{"title": "A Fully Discrete Truly Multidimensional Active Flux Method For The Two-Dimensional Euler Equations", "abstract": "The Active Flux method is a finite volume method for hyperbolic conservation\nlaws that uses both cell averages and point values as degrees of freedom.\nSeveral versions of such methods are currently under development. We focus on\nthird order accurate, fully discrete Active Flux methods with compact stencil\nin space and time. These methods require exact or approximate evolution\noperators for the update of the point value degrees of freedom which are\nprovided by the method of bicharacteristics. Here we propose new limiting\nstrategies that guarantee positivity of pressure and density and furthermore\ndiscuss the implementation of reflecting boundary conditions. Numerical results\nshow that the method leads to accurate approximates on coarse grids.", "published": "2025-08-08 12:46:22", "link": "http://arxiv.org/abs/2508.06273v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical Considerations in Weighted Model Counting", "abstract": "Weighted model counting computes the sum of the rational-valued weights\nassociated with the satisfying assignments for a Boolean formula, where the\nweight of an assignment is given by the product of the weights assigned to the\npositive and negated variables comprising the assignment. Weighted model\ncounting finds applications across a variety of domains including probabilistic\nreasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly)\nconverting the input formula into a form that enables arithmetic evaluation,\nusing multiplication for conjunctions and addition for disjunctions. Performing\nthis evaluation using floating-point arithmetic can yield inaccurate results,\nand it cannot quantify the level of precision achieved. Computing with rational\narithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to\nefficiently compute weighted model counts that are guaranteed to achieve a\nuser-specified precision. When all weights are nonnegative, we prove that the\nprecision loss of arithmetic evaluation using floating-point arithmetic can be\ntightly bounded. We show that supplementing a standard IEEE double-precision\nrepresentation with a separate 64-bit exponent, a format we call extended-range\ndouble (ERD), avoids the underflow and overflow issues commonly encountered in\nweighted model counting. For problems with mixed negative and positive weights,\nwe show that a combination of interval floating-point arithmetic and rational\narithmetic can achieve the twin goals of efficiency and guaranteed precision.\nFor our evaluations, we have devised especially challenging formulas and weight\nassignments, demonstrating the robustness of our approach.", "published": "2025-08-08 12:28:49", "link": "http://arxiv.org/abs/2508.06264v1", "categories": ["math.NA", "cs.AI", "cs.LO", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fully discrete error analysis of finite element discretizations of time-dependent Stokes equations in a stream-function formulation", "abstract": "In this paper we establish best approximation type error estimates for the\nfully discrete Galerkin solutions of the time-dependent Stokes problem using\nthe stream-function formulation. For the time discretization we use the\ndiscontinuous Galerkin method of arbitrary degree, whereas we present the space\ndiscretization in a general framework. This makes our result applicable for a\nwide variety of space discretization methods, provided some Galerkin\northogonality conditions are satisfied. As an example, conformal $C^1$ and\n$C^0$ interior penalty methods are covered by our analysis. The results do not\nrequire any additional regularity assumptions beyond the natural regularity\ngiven by the domain and data and can be used for optimal control problems.", "published": "2025-08-08 11:38:01", "link": "http://arxiv.org/abs/2508.06235v1", "categories": ["math.NA", "cs.NA", "76M10, 35G16, 65M15, 65M60, 65N30"], "primary_category": "math.NA"}
{"title": "A Preliminary Study on the Dimensional Stability Classification of Polynomial Spline Spaces over T-meshes", "abstract": "This paper introduces the concept of dimensional stability for spline spaces\nover T-meshes, providing the first mathematical definition and a preliminary\nclassification framework. We define dimensional stability as an invariant\nwithin the structurally isomorphic class, contingent on the rank stability of\nthe conformality matrix. Absolute stability is proposed via structurally\nsimilar maps to address topological and order structures. Through the\n$k$-partition decomposition of T-connected components and analysis of the CNDC,\nwe establish a correspondence between conformality vector spaces and rank\nstability. For diagonalizable T-meshes, decomposition into independent\none-dimensional T $l$-edges facilitates basis function construction, while\narbitrary T-meshes are partitioned into one- and two-dimensional components.\nThese findings lay the groundwork for understanding dimensional stability and\ndeveloping spline space basis functions.", "published": "2025-08-08 10:55:15", "link": "http://arxiv.org/abs/2508.06217v1", "categories": ["math.NA", "cs.NA", "65D07"], "primary_category": "math.NA"}
{"title": "$k\\ell$-refinement: An adaptive mesh refinement scheme for hiearchical hybrid grids", "abstract": "This work introduces an adaptive mesh refinement technique for hierarchical\nhybrid grids with the goal to reach scalability and maintain excellent\nperformance on massively parallel computer systems. On the block structured\nhierarchical hybrid grids, this is accomplished by using classical,\nunstructured refinement only on the coarsest level of the hierarchy, while\nkeeping the number of structured refinement levels constant on the whole\ndomain. This leads to a compromise where the excellent performance\ncharacteristics of hierarchical hybrid grids can be maintained at the price\nthat the flexibility of generating locally refined meshes is constrained.\nFurthermore, mesh adaptivity often relies on a posteriori error estimators or\nerror indicators that tend to become computationally expensive. Again with the\ngoal of preserving scalability and performance, a method is proposed that\nleverages the grid hierarchy and the full multigrid scheme that generates a\nnatural sequence of approximations on the nested hierarchy of grids. This\npermits to compute a cheap error estimator that is well-suited for large-scale\nparallel computing. We present the theoretical foundations for both global and\nlocal error estimates and present a rigorous analysis of their effectivity. The\nproposed method, including error estimator and the adaptive coarse grid\nrefinement, is implemented in the finite element framework HyTeG. Extensive\nnumerical experiments are conducted to validate the effectiveness, as well as\nperformance and scalability.", "published": "2025-08-08 06:14:38", "link": "http://arxiv.org/abs/2508.06049v1", "categories": ["math.NA", "cs.NA", "65N50, 65N55"], "primary_category": "math.NA"}
{"title": "Transfinite Iteration of Operator Transforms and Spectral Projections in Hilbert and Banach Spaces", "abstract": "We study ordinal-indexed, multi-layer iterations of bounded operator\ntransforms and prove convergence to spectral/ergodic projections under\nfunctional-calculus hypotheses. For normal operators on Hilbert space and\npolynomial or holomorphic layers that are contractive on the spectrum and fix\nthe peripheral spectrum only at fixed points, the iterates converge in the\nstrong operator topology by a countable stage to the spectral projection onto\nthe joint peripheral fixed set. We describe spectral mapping at finite stages\nand identify the spectrum of the limit via the essential range. In reflexive\nBanach spaces, for Ritt or sectorial operators with a bounded H-infinity\nfunctional calculus, the composite layer is power-bounded and its mean-ergodic\nprojection yields an idempotent commuting with the original operator; under a\nperipheral-separation condition the powers converge strongly to this\nprojection. We provide explicit two-layer Schur filters, a concise\nSchur/Nevanlinna-Pick lemma, a Fejer-type monotonicity bound implying\nstabilization by the first countable limit (omega), examples that attain\nexactly the omega stage, and counterexamples outside the hypotheses.", "published": "2025-08-08 05:21:56", "link": "http://arxiv.org/abs/2508.06025v1", "categories": ["math.FA", "cs.NA", "math.NA", "math.SP", "47A10, 47A60, 47A35, 47B15, 47D06, 47A15", "G.1.0; G.1.3; G.1.10"], "primary_category": "math.FA"}
{"title": "Kahan's Automatic Step-Size Control for Unconstrained Optimization", "abstract": "The Barzilai and Borwein (BB) gradient method is one of the most widely-used\nline-search gradient methods. It computes the step-size for the current iterate\nby using the information carried in the previous iteration. Recently, William\nKahan [Kahan, Automatic Step-Size Control for Minimization Iterations,\nTechnical report, University of California, Berkeley CA, USA, 2019] proposed\nnew Gradient Descent (KGD) step-size strategies which iterate the step-size\nitself by effectively utilizing the information in the previous iteration. In\nthe quadratic model, such a new step-size is shown to be mathematically\nequivalent to the long BB step, but no rigorous mathematical proof of its\nefficiency and effectiveness for the general unconstrained minimization is\navailable. In this paper, by this equivalence with the long BB step, we first\nderive a short version of KGD step-size and show that, for the strongly convex\nquadratic model with a Hessian matrix $H$, both the long and short KGD\nstep-size (and hence BB step-sizes) gradient methods converge at least\nR-linearly with a rate $1-\\frac{1}{{\\rm cond}(H)}$. For the general\nunconstrained minimization, we further propose an adaptive framework to\neffectively use the KGD step-sizes; global convergence and local R-linear\nconvergence rate are proved. Numerical experiments are conducted on the CUTEst\ncollection as well as the practical logistic regression problems, and we\ncompare the performance of the proposed methods with various BB step-size\napproaches and other recently proposed adaptive gradient methods to demonstrate\nthe efficiency and robustness.", "published": "2025-08-08 04:09:48", "link": "http://arxiv.org/abs/2508.06002v1", "categories": ["math.OC", "cs.NA", "math.NA", "65L20, 65B99, 90C25"], "primary_category": "math.OC"}
{"title": "Hierarchical Tucker Low-Rank Matrices: Construction and Matrix-Vector Multiplication", "abstract": "In this paper, a hierarchical Tucker low-rank (HTLR) matrix is proposed to\napproximate non-oscillatory kernel functions in linear complexity. The HTLR\nmatrix is based on the hierarchical matrix, with the low-rank blocks replaced\nby Tucker low-rank blocks. Using high-dimensional interpolation as well as\ntensor contractions, algorithms for the construction and matrix-vector\nmultiplication of HTLR matrices are proposed admitting linear and quasi-linear\ncomplexities respectively. Numerical experiments demonstrate that the HTLR\nmatrix performs well in both memory and runtime. Furthermore, the HTLR matrix\ncan also be applied on quasi-uniform grids in addition to uniform grids,\nenhancing its versatility.", "published": "2025-08-08 02:45:36", "link": "http://arxiv.org/abs/2508.05958v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Minimal Perturbation Approach For The Rectangular Multiparameter Eigenvalue Problem", "abstract": "The rectangular multiparameter eigenvalue problem (RMEP) involves rectangular\ncoefficient matrices (usually with more rows than columns) and may potentially\nhave no solution in its original form. A minimal perturbation framework is\nproposed to defines approximate solutions. Computationally, two particular\nscenarios are considered: computing one approximate eigen-tuple or a complete\nset of approximate eigen-tuples. For computing one approximate eigen-tuple, an\nalternating iterative scheme with proven convergence is devised, while for a\ncomplete set of approximate eigen-tuples, the framework leads to a standard MEP\n(RMEP with square coefficient matrices) for numerical solutions. The proposed\napproach is validated on RMEPs from discretizing the multiparameter\nSturm-Liouville equation and the Helmholtz equations by the least-squares\nspectral method.", "published": "2025-08-08 02:20:05", "link": "http://arxiv.org/abs/2508.05948v1", "categories": ["math.NA", "cs.NA", "65F15, 65F20, 15A18, 47A75, 65N35"], "primary_category": "math.NA"}
{"title": "Debiasing Polynomial and Fourier Regression", "abstract": "We study the problem of approximating an unknown function\n$f:\\mathbb{R}\\to\\mathbb{R}$ by a degree-$d$ polynomial using as few function\nevaluations as possible, where error is measured with respect to a probability\ndistribution $\\mu$. Existing randomized algorithms achieve near-optimal sample\ncomplexities to recover a $ (1+\\varepsilon) $-optimal polynomial but produce\nbiased estimates of the best polynomial approximation, which is undesirable.\n  We propose a simple debiasing method based on a connection between polynomial\nregression and random matrix theory. Our method involves evaluating\n$f(\\lambda_1),\\ldots,f(\\lambda_{d+1})$ where $\\lambda_1,\\ldots,\\lambda_{d+1}$\nare the eigenvalues of a suitably designed random complex matrix tailored to\nthe distribution $\\mu$. Our estimator is unbiased, has near-optimal sample\ncomplexity, and experimentally outperforms iid leverage score sampling.\n  Additionally, our techniques enable us to debias existing methods for\napproximating a periodic function with a truncated Fourier series with\nnear-optimal sample complexity.", "published": "2025-08-08 00:43:33", "link": "http://arxiv.org/abs/2508.05920v1", "categories": ["cs.DS", "cs.NA", "math.NA", "65F99", "G.1.3"], "primary_category": "cs.DS"}
{"title": "Multivariate Fields of Experts", "abstract": "We introduce the multivariate fields of experts, a new framework for the\nlearning of image priors. Our model generalizes existing fields of experts\nmethods by incorporating multivariate potential functions constructed via\nMoreau envelopes of the $\\ell_\\infty$-norm. We demonstrate the effectiveness of\nour proposal across a range of inverse problems that include image denoising,\ndeblurring, compressed-sensing magnetic-resonance imaging, and computed\ntomography. The proposed approach outperforms comparable univariate models and\nachieves performance close to that of deep-learning-based regularizers while\nbeing significantly faster, requiring fewer parameters, and being trained on\nsubstantially fewer data. In addition, our model retains a relatively high\nlevel of interpretability due to its structured design.", "published": "2025-08-08 17:58:25", "link": "http://arxiv.org/abs/2508.06490v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Full-Dimensional Beamforming for Multi-User MIMO-OFDM ISAC for Low-Altitude UAV with Zero Sensing Resource Allocation", "abstract": "Low-altitude unmanned aerial vehicles (UAVs) are expected to play an\nimportant role for low-altitude economy with a wide range of applications like\nprecise agriculture, aerial delivery and surveillance. Integrated sensing and\ncommunication (ISAC) is a key technology to enable the large-scale deployment\nand routine usage of UAVs by providing both communication and sensing services\nefficiently. For UAV ISAC systems, as UAV often acts as both a communication\nuser equipment (UE) and a sensing target, traditional ISAC systems that usually\nallocate dedicated TF resources for sensing are inefficient due to the severe\ndegradation of communication spectral efficiency. To address this issue, in\nthis paper, we propose a novel multiple-input multiple-output (MIMO) orthogonal\nfrequency division multiplexing (OFDM)-based ISAC framework for UAVs that\neliminates the need for dedicated sensing TF resources, achieving zero TF\nsensing overhead. By designing the transmit beamforming to meet the\nrequirements for both communication and sensing tasks, our proposed approach\nenables the communication TF resources to be fully reused for sensing, thereby\nenhancing both the communication sum rate and the sensing performance in terms\nof resolution, unambiguous range, and accuracy. Additionally, we introduce a\nlow-complexity target searching beamforming algorithm and a two-stage\nsuper-resolution sensing algorithm, which ensure efficient implementation.\nSimulation results demonstrate that the proposed MIMO-OFDM-ISAC framework not\nonly improves the communication sum rate but also outperforms traditional ISAC\nsystems in sensing performance, making it a promising solution for future ISAC\nsystems to support low-altitude UAVs.", "published": "2025-08-08 16:15:20", "link": "http://arxiv.org/abs/2508.06428v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Acoustic Non-Stationarity Objective Assessment with Hard Label Criteria for Supervised Learning Models", "abstract": "Objective non-stationarity measures are resource intensive and impose\ncritical limitations for real-time processing solutions. In this paper, a novel\nHard Label Criteria (HLC) algorithm is proposed to generate a global\nnon-stationarity label for acoustic signals, enabling supervised learning\nstrategies to be trained as stationarity estimators. The HLC is first evaluated\non state-of-the-art general-purpose acoustic models, demonstrating that these\nmodels encode stationarity information. Furthermore, the first-of-its-kind\nHLC-based Network for Acoustic Non-Stationarity Assessment (NANSA) is proposed.\nNANSA models outperform competing approaches, achieving up to 99\\%\nclassification accuracy, while solving the computational infeasibility of\ntraditional objective measures.", "published": "2025-08-08 15:46:21", "link": "http://arxiv.org/abs/2508.06405v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "MALRIS: Malicious Hardware in RIS-Assisted Wireless Communications", "abstract": "Reconfigurable intelligent surfaces (RIS) enhance wireless communication by\ndynamically shaping the propagation environment, but their integration\nintroduces hardware-level security risks. This paper presents the concept of\nMalicious RIS (MALRIS), where compromised components behave adversarially, even\nunder passive operation. The focus of this work is on practical threats such as\nmanufacturing time tampering, malicious firmware, and partial element control.\nTwo representative attacks, power-splitting and element-splitting, are modeled\nto assess their impact. Simulations in a RIS-assisted system reveal that even a\nlimited hardware compromise can significantly degrade performance metrics such\nas bit error rate, throughput, and secrecy metrics. By exposing this overlooked\nthreat surface, this work aims to promote awareness and support secure,\ntrustworthy RIS deployment in future wireless networks.", "published": "2025-08-08 14:14:15", "link": "http://arxiv.org/abs/2508.06340v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Arbitrarily-high-dimensional reconciliation via cross-rotation for continuous-variable quantum key distribution", "abstract": "Multidimensional rotation serves as a powerful tool for enhancing information\nreconciliation and extending the transmission distance in continuous-variable\nquantum key distribution (CV-QKD). However, the lack of closed-form orthogonal\ntransformations for high-dimensional rotations has limited the maximum\nreconciliation efficiency to channels with 8 dimensions over the past decade.\nThis paper presents a cross-rotation scheme to overcome this limitation and\nenable reconciliation in arbitrarily high dimensions, constrained to even\nmultiples of 8. The key treatment involves reshaping the string vector into\nmatrix form and applying orthogonal transformations to its columns and rows in\na cross manner, thereby increasing the reconciliation dimension by one order\nper cross-rotation while significantly reducing the communication overhead over\nthe classical channel. A rigorous performance analysis is also presented from\nthe perspective of achievable sum-rate. Simulation results demonstrate that\n64-dimensional cross-rotation nearly approaches the upper bound, making it a\nrecommended choice for practical implementations.", "published": "2025-08-08 14:12:34", "link": "http://arxiv.org/abs/2508.06338v1", "categories": ["quant-ph", "eess.SP"], "primary_category": "quant-ph"}
{"title": "Efficient Deep Neural Receiver with Post-Training Quantization", "abstract": "Deep learning has recently garnered significant interest in wireless\ncommunications due to its superior performance compared to traditional\nmodel-based algorithms. Deep convolutional neural networks (CNNs) have\ndemonstrated notable improvements in block error rate (BLER) under various\nchannel models and mobility scenarios. However, the high computational\ncomplexity and resource demands of deep CNNs pose challenges for deployment in\nresource-constrained edge systems. The 3rd Generation Partnership Project\n(3GPP) Release 20 highlights the pivotal role of artificial intelligence (AI)\nintegration in enabling advanced radio-access networks for 6G systems. The hard\nreal-time processing demands of 5G and 6G require efficient techniques such as\npost-training quantization (PTQ), quantization-aware training (QAT), pruning,\nand hybrid approaches to meet latency requirements. In this paper, we focus on\nPTQ to reduce model complexity by lowering the bit-width of weights, thereby\nenhancing computational efficiency. Our analysis employs symmetric uniform\nquantization, applying both per-tensor and per-channel PTQ to a neural receiver\nachieving performance comparable to full-precision models. Specifically, 8-bit\nper-channel quantization maintains BLER performance with minimal degradation,\nwhile 4-bit quantization shows great promise but requires further optimization\nto achieve target BLER levels. These results highlight the potential of\nultra-low bitwidth PTQ for efficient neural receiver deployment in 6G systems.", "published": "2025-08-08 12:48:31", "link": "http://arxiv.org/abs/2508.06275v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A 66-Gb/s/5.5-W RISC-V Many-Core Cluster for 5G+ Software-Defined Radio Uplinks", "abstract": "Following the scale-up of new radio (NR) complexity in 5G and beyond, the\nphysical layer's computing load on base stations is increasing under a strictly\nconstrained latency and power budget; base stations must process > 20-Gb/s\nuplink wireless data rate on the fly, in < 10 W. At the same time, the\nprogrammability and reconfigurability of base station components are the key\nrequirements; it reduces the time and cost of new networks' deployment, it\nlowers the acceptance threshold for industry players to enter the market, and\nit ensures return on investments in a fast-paced evolution of standards. In\nthis article, we present the design of a many-core cluster for 5G and beyond\nbase station processing. Our design features 1024, streamlined RISC-V cores\nwith domain-specific FP extensions, and 4-MiB shared memory. It provides the\nnecessary computational capabilities for software-defined processing of the\nlower physical layer of 5G physical uplink shared channel (PUSCH), satisfying\nhigh-end throughput requirements (66 Gb/s for a transition time interval (TTI),\n9.4-302 Gb/s depending on the processing stage). The throughput metrics for the\nimplemented functions are ten times higher than in state-of-the-art (SoTA)\napplication-specific instruction processors (ASIPs). The energy efficiency on\nkey NR kernels (2-41 Gb/s/W), measured at 800 MHz, 25 {\\deg}C, and 0.8 V, on a\nplaced and routed instance in 12-nm CMOS technology, is competitive with SoTA\narchitectures. The PUSCH processing runs end-to-end on a single cluster in 1.7\nms, at <6-W average power consumption, achieving 12 Gb/s/W.", "published": "2025-08-08 09:45:16", "link": "http://arxiv.org/abs/2508.06176v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fast End-to-End Simulation and Exploration of Many-RISCV-Core Baseband Transceivers for Software-Defined Radio-Access Networks", "abstract": "The fast-rising demand for wireless bandwidth requires rapid evolution of\nhigh-performance baseband processing infrastructure. Programmable many-core\nprocessors for software-defined radio (SDR) have emerged as high-performance\nbaseband processing engines, offering the flexibility required to capture\nevolving wireless standards and technologies. This trend must be supported by a\ndesign framework enabling functional validation and end-to-end performance\nanalysis of SDR hardware within realistic radio environment models. We propose\na static binary translation based simulator augmented with a fast, approximate\ntiming model of the hardware and coupled to wireless channel models to simulate\nthe most performance-critical physical layer functions implemented in software\non a many (1024) RISC-V cores cluster customized for SDR. Our framework\nsimulates the detection of a 5G OFDM-symbol on a server-class processor in\n9.5s-3min, on a single thread, depending on the input MIMO size (three orders\nof magnitude faster than RTL simulation). The simulation is easily parallelized\nto 128 threads with 73-121x speedup compared to a single thread.", "published": "2025-08-08 09:01:25", "link": "http://arxiv.org/abs/2508.06141v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-Modal Neural Radio Radiance Field for Localized Statistical Channel Modelling", "abstract": "This paper presents MM-LSCM, a self-supervised multi-modal neural radio\nradiance field framework for localized statistical channel modeling (LSCM) for\nnext-generation network optimization. Traditional LSCM methods rely solely on\nRSRP data, limiting their ability to model environmental structures that affect\nsignal propagation. To address this, we propose a dual-branch neural\narchitecture that integrates RSRP data and LiDAR point cloud information,\nenhancing spatial awareness and predictive accuracy. MM-LSCM leverages\nvolume-rendering-based multi-modal synthesis to align radio propagation with\nenvironmental obstacles and employs a self-supervised training approach,\neliminating the need for costly labeled data. Experimental results demonstrate\nthat MM-LSCM significantly outperforms conventional methods in channel\nreconstruction accuracy and robustness to noise, making it a promising solution\nfor real-world wireless network optimization.", "published": "2025-08-08 06:22:43", "link": "http://arxiv.org/abs/2508.06054v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bayesian Radio Map Estimation: Fundamentals and Implementation via Diffusion Models", "abstract": "Radio map estimation (RME) is the problem of inferring the value of a certain\nmetric (e.g. signal power) across an area of interest given a collection of\nmeasurements. While most works tackle this problem from a purely non-Bayesian\nperspective, some Bayesian estimators have been proposed. However, the latter\nfocus on estimating the map itself, the Bayesian standpoint is adopted mainly\nto exploit prior information or to capture uncertainty. This paper pursues a\nmore general formulation, where the goal is to determine the posterior\ndistribution of the map given the measurements. Besides handling uncertainty\nand allowing standard Bayesian estimates, solving this problem is seen to\nenable minimum mean square error estimation of arbitrary map functionals (e.g.\ncapacity, bit error rate, or coverage area to name a few) while training only\nfor power estimation. A general Bayesian estimator is proposed based on\nconditional diffusion models and both the Bayesian and non-Bayesian paradigms\nare compared analytically and numerically to determine when the Bayesian\napproach is preferable.", "published": "2025-08-08 05:48:29", "link": "http://arxiv.org/abs/2508.06037v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Effective Training Data Synthesis for Improving MLLM Chart Understanding", "abstract": "Being able to effectively read scientific plots, or chart understanding, is a\ncentral part toward building effective agents for science. However, existing\nmultimodal large language models (MLLMs), especially open-source ones, are\nstill falling behind with a typical success rate of 30%-50% on challenging\nbenchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are\noften restricted by their inadequate similarity to the real charts, which could\ncompromise model training and performance on complex real-world charts. In this\nstudy, we show that modularizing chart generation and diversifying visual\ndetails improves chart understanding capabilities. In particular, we design a\nfive-step data synthesis pipeline, where we separate data and function creation\nfor single plot generation, condition the generation of later subplots on\nearlier ones for multi-subplot figures, visually diversify the generated\nfigures, filter out low quality data, and finally generate the question-answer\n(QA) pairs with GPT-4o. This approach allows us to streamline the generation of\nfine-tuning datasets and introduce the effective chart dataset (ECD), which\ncontains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring\n250+ chart type combinations with high visual complexity. We show that ECD\nconsistently improves the performance of various MLLMs on a range of real-world\nand synthetic test sets. Code, data and models are available at:\nhttps://github.com/yuweiyang-anu/ECD.", "published": "2025-08-08 17:59:10", "link": "http://arxiv.org/abs/2508.06492v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Post-training for Efficient Communication via Convention Formation", "abstract": "Humans communicate with increasing efficiency in multi-turn interactions, by\nadapting their language and forming ad-hoc conventions. In contrast, prior work\nshows that LLMs do not naturally show this behavior. We develop a post-training\nprocess to develop this ability through targeted fine-tuning on heuristically\nidentified demonstrations of convention formation. We evaluate with two new\nbenchmarks focused on this capability. First, we design a focused,\ncognitively-motivated interaction benchmark that consistently elicits strong\nconvention formation trends in humans. Second, we create a new\ndocument-grounded reference completion task that reflects in-the-wild\nconvention formation behavior. Our studies show significantly improved\nconvention formation abilities in post-trained LLMs across the two evaluation\nmethods.", "published": "2025-08-08 17:42:16", "link": "http://arxiv.org/abs/2508.06482v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning", "abstract": "Haptic captioning is the task of generating natural language descriptions\nfrom haptic signals, such as vibrations, for use in virtual reality,\naccessibility, and rehabilitation applications. While previous multimodal\nresearch has focused primarily on vision and audio, haptic signals for the\nsense of touch remain underexplored. To address this gap, we formalize the\nhaptic captioning task and propose HapticLLaMA, a multimodal sensory language\nmodel that interprets vibration signals into descriptions in a given sensory,\nemotional, or associative category. We investigate two types of haptic\ntokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that\nconvert haptic signals into sequences of discrete units, enabling their\nintegration with the LLaMA model. HapticLLaMA is trained in two stages: (1)\nsupervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,\nand (2) fine-tuning via reinforcement learning from human feedback (RLHF). We\nassess HapticLLaMA's captioning performance using both automated n-gram metrics\nand human evaluation. HapticLLaMA demonstrates strong capability in\ninterpreting haptic vibration signals, achieving a METEOR score of 59.98 and a\nBLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated\ncaptions received human ratings above 3.5 on a 7-point scale, with RLHF\nyielding a 10% improvement in the overall rating distribution, indicating\nstronger alignment with human haptic perception. These findings highlight the\npotential of large language models to process and adapt to sensory data.", "published": "2025-08-08 17:25:37", "link": "http://arxiv.org/abs/2508.06475v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models", "abstract": "We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language\nmodel with 355B total parameters and 32B activated parameters, featuring a\nhybrid reasoning method that supports both thinking and direct response modes.\nThrough multi-stage training on 23T tokens and comprehensive post-training with\nexpert model iteration and reinforcement learning, GLM-4.5 achieves strong\nperformance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on\nTAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer\nparameters than several competitors, GLM-4.5 ranks 3rd overall among all\nevaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B\nparameters) and a compact version, GLM-4.5-Air (106B parameters), to advance\nresearch in reasoning and agentic AI systems. Code, models, and more\ninformation are available at https://github.com/zai-org/GLM-4.5.", "published": "2025-08-08 17:21:06", "link": "http://arxiv.org/abs/2508.06471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning", "abstract": "Long-context inference for Large Language Models (LLMs) is heavily limited by\nhigh computational demands. While several existing methods optimize attention\ncomputation, they still process the full set of hidden states at each layer,\nlimiting overall efficiency. In this work, we propose SlimInfer, an innovative\nframework that aims to accelerate inference by directly pruning less critical\nprompt tokens during the forward pass. Our key insight is an information\ndiffusion phenomenon: As information from critical tokens propagates through\nlayers, it becomes distributed across the entire sequence. This diffusion\nprocess suggests that LLMs can maintain their semantic integrity when excessive\ntokens, even including these critical ones, are pruned in hidden states.\nMotivated by this, SlimInfer introduces a dynamic fine-grained pruning\nmechanism that accurately removes redundant tokens of hidden state at\nintermediate layers. This layer-wise pruning naturally enables an asynchronous\nKV cache manager that prefetches required token blocks without complex\npredictors, reducing both memory usage and I/O costs. Extensive experiments\nshow that SlimInfer can achieve up to $\\mathbf{2.53\\times}$ time-to-first-token\n(TTFT) speedup and $\\mathbf{1.88\\times}$ end-to-end latency reduction for\nLLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on\nLongBench. Our code will be released upon acceptance.", "published": "2025-08-08 16:42:38", "link": "http://arxiv.org/abs/2508.06447v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "abstract": "The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns\nfor journalistic integrity and authorship. This study examines AI-generated\ncontent across over 40,000 news articles from major, local, and college news\nmedia, in various media formats. Using three advanced AI-text detectors (e.g.,\nBinoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of\nGenAI use in recent years, especially in local and college news. Sentence-level\nanalysis reveals LLMs are often used in the introduction of news, while\nconclusions usually written manually. Linguistic analysis shows GenAI boosts\nword richness and readability but lowers formality, leading to more uniform\nwriting styles, particularly in local media.", "published": "2025-08-08 16:38:33", "link": "http://arxiv.org/abs/2508.06445v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages", "abstract": "Large language models (LLMs) are transforming social-science research by\nenabling scalable, precise analysis. Their adaptability raises the question of\nwhether knowledge acquired through fine-tuning in a few languages can transfer\nto unseen languages that only appeared during pre-training. To examine this, we\nfine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or\nmultilingual data sets to classify immigration-related tweets from X/Twitter\nacross 13 languages, a domain characterised by polarised, culturally specific\ndiscourse. We evaluate whether minimal language-specific fine-tuning enables\ncross-lingual topic detection and whether adding targeted languages corrects\npre-training biases. Results show that LLMs fine-tuned in one or two languages\ncan reliably classify immigration-related content in unseen languages. However,\nidentifying whether a tweet expresses a pro- or anti-immigration stance\nbenefits from multilingual fine-tuning. Pre-training bias favours dominant\nlanguages, but even minimal exposure to under-represented languages during\nfine-tuning (as little as $9.62\\times10^{-11}$ of the original pre-training\ntoken volume) yields significant gains. These findings challenge the assumption\nthat cross-lingual mastery requires extensive multilingual training: limited\nlanguage coverage suffices for topic-level generalisation, and structural\nbiases can be corrected with lightweight interventions. By releasing\n4-bit-quantised, LoRA fine-tuned models, we provide an open-source,\nreproducible alternative to proprietary LLMs that delivers 35 times faster\ninference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,\nenabling scalable, inclusive research.", "published": "2025-08-08 16:23:24", "link": "http://arxiv.org/abs/2508.06435v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Quantifying Conversation Drift in MCP via Latent Polytope", "abstract": "The Model Context Protocol (MCP) enhances large language models (LLMs) by\nintegrating external tools, enabling dynamic aggregation of real-time data to\nimprove task execution. However, its non-isolated execution context introduces\ncritical security and privacy risks. In particular, adversarially crafted\ncontent can induce tool poisoning or indirect prompt injection, leading to\nconversation hijacking, misinformation propagation, or data exfiltration.\nExisting defenses, such as rule-based filters or LLM-driven detection, remain\ninadequate due to their reliance on static signatures, computational\ninefficiency, and inability to quantify conversational hijacking. To address\nthese limitations, we propose SecMCP, a secure framework that detects and\nquantifies conversation drift, deviations in latent space trajectories induced\nby adversarial external knowledge. By modeling LLM activation vectors within a\nlatent polytope space, SecMCP identifies anomalous shifts in conversational\ndynamics, enabling proactive detection of hijacking, misleading, and data\nexfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,\nVicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),\ndemonstrating robust detection with AUROC scores exceeding 0.915 while\nmaintaining system usability. Our contributions include a systematic\ncategorization of MCP security threats, a novel latent polytope-based\nmethodology for quantifying conversation drift, and empirical validation of\nSecMCP's efficacy.", "published": "2025-08-08 16:05:27", "link": "http://arxiv.org/abs/2508.06418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sample-efficient LLM Optimization with Reset Replay", "abstract": "Recent advancements in post-training Large Language Models (LLMs),\nparticularly through Reinforcement Learning (RL) and preference optimization\nmethods, are key drivers for enhancing their reasoning capabilities. However,\nthese methods are often plagued by low sample efficiency and a susceptibility\nto primacy bias, where overfitting to initial experiences degrades policy\nquality and damages the learning process. To address these challenges, we\nintroduce LLM optimization with Reset Replay (LoRR), a general and powerful\nplugin designed to enhance sample efficiency in any preference-based\noptimization framework. LoRR core mechanism enables training at a high replay\nnumber, maximizing the utility of each collected data batch. To counteract the\nrisk of overfitting inherent in high-replay training, LoRR incorporates a\nperiodic reset strategy with reusing initial data, which preserves network\nplasticity. Furthermore, it leverages a hybrid optimization objective,\ncombining supervised fine-tuning (SFT) and preference-based losses to further\nbolster data exploitation. Our extensive experiments demonstrate that LoRR\nsignificantly boosts the performance of various preference optimization methods\non both mathematical and general reasoning benchmarks. Notably, an iterative\nDPO approach augmented with LoRR achieves comparable performance on challenging\nmath tasks, outperforming some complex and computationally intensive RL-based\nalgorithms. These findings highlight that LoRR offers a practical,\nsample-efficient, and highly effective paradigm for LLM finetuning, unlocking\ngreater performance from limited data.", "published": "2025-08-08 15:56:49", "link": "http://arxiv.org/abs/2508.06412v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges", "abstract": "This systematic review of the research literature on retrieval-augmented\ngeneration (RAG) provides a focused analysis of the most highly cited studies\npublished between 2020 and May 2025. A total of 128 articles met our inclusion\ncriteria. The records were retrieved from ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP).\nRAG couples a neural retriever with a generative language model, grounding\noutput in up-to-date, non-parametric memory while retaining the semantic\ngeneralisation stored in model weights. Guided by the PRISMA 2020 framework, we\n(i) specify explicit inclusion and exclusion criteria based on citation count\nand research questions, (ii) catalogue datasets, architectures, and evaluation\npractices, and (iii) synthesise empirical evidence on the effectiveness and\nlimitations of RAG. To mitigate citation-lag bias, we applied a lower\ncitation-count threshold to papers published in 2025 so that emerging\nbreakthroughs with naturally fewer citations were still captured. This review\nclarifies the current research landscape, highlights methodological gaps, and\ncharts priority directions for future research.", "published": "2025-08-08 15:37:14", "link": "http://arxiv.org/abs/2508.06401v1", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nrole-playing conversations and providing emotional support as separate research\ndirections. However, there remains a significant research gap in combining\nthese capabilities to enable emotionally supportive interactions with virtual\ncharacters. To address this research gap, we focus on anime characters as a\ncase study because of their well-defined personalities and large fan bases.\nThis choice enables us to effectively evaluate how well LLMs can provide\nemotional support while maintaining specific character traits. We introduce\nChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We\nfirst thoughtfully select 20 top-tier characters from popular anime communities\nand design 60 emotion-centric real-world scenario questions. Then, we execute a\nnationwide selection process to identify 40 Chinese anime enthusiasts with\nprofound knowledge of specific characters and extensive experience in\nrole-playing. Next, we systematically collect two rounds of dialogue data from\n10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP\nperformance of LLMs, we design a user experience-oriented evaluation system\nfeaturing 9 fine-grained metrics across three dimensions: basic dialogue,\nrole-playing and emotional support, along with an overall metric for response\ndiversity. In total, the dataset comprises 2,400 human-written and 24,000\nLLM-generated answers, supported by over 132,000 human annotations.\nExperimental results show that top-performing LLMs surpass human fans in\nrole-playing and emotional support, while humans still lead in response\ndiversity. We hope this work can provide valuable resources and insights for\nfuture research on optimizing LLMs in ESRP. Our datasets are available at\nhttps://github.com/LanlanQiu/ChatAnime.", "published": "2025-08-08 15:17:24", "link": "http://arxiv.org/abs/2508.06388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Style-Personalized Text Generation: Challenges and Directions", "abstract": "While prior research has built tools and benchmarks towards style\npersonalized text generation, there has been limited exploration of evaluation\nin low-resource author style personalized text generation space. Through this\nwork, we question the effectiveness of the widely adopted evaluation metrics\nlike BLEU and ROUGE, and explore other evaluation paradigms such as style\nembeddings and LLM-as-judge to holistically evaluate the style personalized\ntext generation task. We evaluate these metrics and their ensembles using our\nstyle discrimination benchmark, that spans eight writing tasks, and evaluates\nacross three settings, domain discrimination, authorship attribution, and LLM\npersonalized vs non-personalized discrimination. We provide conclusive evidence\nto adopt ensemble of diverse evaluation metrics to effectively evaluate style\npersonalized text generation.", "published": "2025-08-08 15:07:31", "link": "http://arxiv.org/abs/2508.06374v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cyberbullying Detection via Aggression-Enhanced Prompting", "abstract": "Detecting cyberbullying on social media remains a critical challenge due to\nits subtle and varied expressions. This study investigates whether integrating\naggression detection as an auxiliary task within a unified training framework\ncan enhance the generalisation and performance of large language models (LLMs)\nin cyberbullying detection. Experiments are conducted on five aggression\ndatasets and one cyberbullying dataset using instruction-tuned LLMs. We\nevaluated multiple strategies: zero-shot, few-shot, independent LoRA\nfine-tuning, and multi-task learning (MTL). Given the inconsistent results of\nMTL, we propose an enriched prompt pipeline approach in which aggression\npredictions are embedded into cyberbullying detection prompts to provide\ncontextual augmentation. Preliminary results show that the enriched prompt\npipeline consistently outperforms standard LoRA fine-tuning, indicating that\naggression-informed context significantly boosts cyberbullying detection. This\nstudy highlights the potential of auxiliary tasks, such as aggression\ndetection, to improve the generalisation of LLMs for safety-critical\napplications on social networks.", "published": "2025-08-08 14:46:05", "link": "http://arxiv.org/abs/2508.06360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "abstract": "Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities\nin diverse domain question-answering (QA) tasks, including graph QA that\ninvolves complex graph topologies. However, most current approaches use only a\nsingle type of graph representation, namely Topology Representation Form (TRF),\nsuch as prompt-unified text descriptions or style-fixed visual styles. Those\n\"one-size-fits-all\" approaches fail to consider the specific preferences of\ndifferent models or tasks, often leading to incorrect or overly long responses.\nTo address this, we first analyze the characteristics and weaknesses of\nexisting TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to\nzero-shot graph QA. We then introduce a new metric, Graph Response Efficiency\n(GRE), which measures the balance between the performance and the brevity in\ngraph QA. Built on these, we develop the DynamicTRF framework, which aims to\nimprove both the accuracy and conciseness of graph QA. To be specific,\nDynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based\non their GRE scores, to probe the question-specific TRF preferences. Then it\ntrains a TRF router on the TRFP dataset, to adaptively assign the best TRF from\n$F_{ZS}$ for each question during the inference. Extensive experiments across 7\nin-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show\nthat DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms\nof accuracy", "published": "2025-08-08 14:18:24", "link": "http://arxiv.org/abs/2508.06345v1", "categories": ["cs.CL", "cs.AI", "cs.GR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC", "abstract": "In recent years, concerns about intellectual property (IP) in large language\nmodels (LLMs) have grown significantly. Plagiarizing other LLMs (through direct\nweight copying, upcycling, pruning, or continual pretraining) and claiming\nauthorship without properly attributing to the original license, is a serious\nmisconduct that can lead to significant financial and reputational harm to the\noriginal developers. However, existing methods for detecting LLM plagiarism\nfall short in key areas. They fail to accurately reconstruct weight\ncorrespondences, lack the ability to compute statistical significance measures\nsuch as $p$-values, and may mistakenly flag models trained on similar data as\nbeing related. To address these limitations, we propose Matrix-Driven Instant\nReview (MDIR), a novel method that leverages matrix analysis and Large\nDeviation Theory. MDIR achieves accurate reconstruction of weight\nrelationships, provides rigorous $p$-value estimation, and focuses exclusively\non weight similarity without requiring full model inference. Experimental\nresults demonstrate that MDIR reliably detects plagiarism even after extensive\ntransformations, such as random permutations and continual pretraining with\ntrillions of tokens. Moreover, all detections can be performed on a single PC\nwithin an hour, making MDIR both efficient and accessible.", "published": "2025-08-08 13:35:40", "link": "http://arxiv.org/abs/2508.06309v1", "categories": ["cs.CL", "math.PR"], "primary_category": "cs.CL"}
{"title": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech", "abstract": "Intent recognition (IR) for speech commands is essential for artificial\nintelligence (AI) assistant systems; however, most existing approaches are\nlimited to short commands and are predominantly developed for English. This\npaper addresses these limitations by focusing on IR from speech by elderly\nGerman speakers. We propose a novel approach that combines an adapted Whisper\nASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based\nlanguage models trained on synthetic text datasets generated by three\nwell-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To\nevaluate the robustness of our approach, we generate synthetic speech with a\ntext-to-speech model and conduct extensive cross-dataset testing. Our results\nshow that synthetic LLM-generated data significantly boosts classification\nperformance and robustness to different speaking styles and unseen vocabulary.\nNotably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the\nmuch larger ChatGPT (175B) in dataset quality for German intent recognition.\nOur approach demonstrates that generative AI can effectively bridge data gaps\nin low-resource domains. We provide detailed documentation of our data\ngeneration and training process to ensure transparency and reproducibility.", "published": "2025-08-08 12:54:09", "link": "http://arxiv.org/abs/2508.06277v1", "categories": ["cs.CL", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?", "abstract": "Recent advances in Vision-Language Models (VLMs) have demonstrated impressive\ncapabilities in perception and reasoning. However, the ability to perform\ncausal inference -- a core aspect of human cognition -- remains underexplored,\nparticularly in multimodal settings. In this study, we introduce InfoCausalQA,\na novel benchmark designed to evaluate causal reasoning grounded in\ninfographics that combine structured visual data with textual context. The\nbenchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning\nbased on inferred numerical trends, while Task 2 targets semantic causal\nreasoning involving five types of causal relations: cause, effect,\nintervention, counterfactual, and temporal. We manually collected 494\ninfographic-text pairs from four public sources and used GPT-4o to generate\n1,482 high-quality multiple-choice QA pairs. These questions were then\ncarefully revised by humans to ensure they cannot be answered based on\nsurface-level cues alone but instead require genuine visual grounding. Our\nexperimental results reveal that current VLMs exhibit limited capability in\ncomputational reasoning and even more pronounced limitations in semantic causal\nreasoning. Their significantly lower performance compared to humans indicates a\nsubstantial gap in leveraging infographic-based information for causal\ninference. Through InfoCausalQA, we highlight the need for advancing the causal\nreasoning abilities of multimodal AI systems.", "published": "2025-08-08 11:03:23", "link": "http://arxiv.org/abs/2508.06220v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Classification is a RAG problem: A case study on hate speech detection", "abstract": "Robust content moderation requires classification systems that can quickly\nadapt to evolving policies without costly retraining. We present classification\nusing Retrieval-Augmented Generation (RAG), which shifts traditional\nclassification tasks from determining the correct category in accordance with\npre-trained parameters to evaluating content in relation to contextual\nknowledge retrieved at inference. In hate speech detection, this transforms the\ntask from \"is this hate speech?\" to \"does this violate the hate speech policy?\"\n  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates\nthis approach and offers three key advantages: (1) robust classification\naccuracy comparable to leading commercial systems, (2) inherent explainability\nvia retrieved policy segments, and (3) dynamic policy updates without model\nretraining. Through three experiments, we demonstrate strong baseline\nperformance and show that the system can apply fine-grained policy control by\ncorrectly adjusting protection for specific identity groups without requiring\nretraining or compromising overall performance. These findings establish that\nRAG can transform classification into a more flexible, transparent, and\nadaptable process for content moderation and wider classification problems.", "published": "2025-08-08 10:35:41", "link": "http://arxiv.org/abs/2508.06204v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations", "abstract": "Emotional Intelligence (EI) is a critical yet underexplored dimension in the\ndevelopment of human-aligned LLMs. To address this gap, we introduce a unified,\npsychologically grounded four-layer taxonomy of EI tailored for large language\nmodels (LLMs), encompassing emotional tracking, cause inference, appraisal, and\nemotionally appropriate response generation. Building on this framework, we\npresent EICAP-Bench, a novel MCQ style multi-turn benchmark designed to\nevaluate EI capabilities in open-source LLMs across diverse linguistic and\ncultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma\n(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,\nidentifying Qwen2.5-Instruct as the strongest baseline. To assess the potential\nfor enhancing EI capabilities, we fine-tune both Qwen2.5-Base and\nQwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,\ninstruction-tuned dialogue dataset, in both English and Arabic. Our statistical\nanalysis reveals that among the five EI layers, only the Appraisal layer shows\nsignificant improvement through UC-based fine-tuning. These findings highlight\nthe limitations of existing pretraining and instruction-tuning paradigms in\nequipping LLMs with deeper emotional reasoning and underscore the need for\ntargeted data and modeling strategies for comprehensive EI alignment.", "published": "2025-08-08 10:22:19", "link": "http://arxiv.org/abs/2508.06196v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation", "abstract": "Precise jailbreak evaluation is vital for LLM red teaming and jailbreak\nresearch. Current approaches employ binary classification ( e.g., string\nmatching, toxic text classifiers, LLM-driven methods), yielding only \"yes/no\"\nlabels without quantifying harm intensity. Existing multi-dimensional\nframeworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)\napply uniform evaluation criteria across scenarios, resulting in\nscenario-specific mismatches--for instance, \"Relative Truthfulness\" is\nirrelevant to \"hate speech\"--which compromise evaluation precision. To tackle\nthese limitations, we introduce SceneJailEval, with key contributions: (1) A\ngroundbreaking scenario-adaptive multi-dimensional framework for jailbreak\nevaluation, overcoming the critical \"one-size-fits-all\" constraint of existing\nmulti-dimensional methods, and featuring strong extensibility to flexibly adapt\nto customized or emerging scenarios. (2) A comprehensive 14-scenario dataset\nwith diverse jailbreak variants and regional cases, filling the long-standing\ngap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)\nSceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on\nour full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over\nprior SOTA), surpassing accuracy limits of existing evaluation methods in\nheterogeneous scenarios and confirming its advantage.", "published": "2025-08-08 10:19:21", "link": "http://arxiv.org/abs/2508.06194v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration", "abstract": "Large Language Models (LLMs) have grown exponentially since the release of\nChatGPT. These models have gained attention due to their robust performance on\nvarious tasks, including language processing tasks. These models achieve\nunderstanding and comprehension of tasks by training billions of parameters.\nThe development of these models is a transformative force in enhancing natural\nlanguage understanding and has taken a significant step towards artificial\ngeneral intelligence (AGI). In this study, we aim to present the DKG-LLM\nframework. The DKG-LLM framework introduces a groundbreaking approach to\nmedical diagnosis and personalized treatment recommendations by integrating a\ndynamic knowledge graph (DKG) with the Grok 3 large language model. Using the\nAdaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data\n(including clinical reports and PubMed articles) and patient records\ndynamically generate a knowledge graph consisting of 15,964 nodes in 13\ndistinct types (e.g., diseases, symptoms, treatments, patient profiles) and\n127,392 edges in 26 relationship types (e.g., causal, therapeutic,\nassociation). ASFA utilizes advanced probabilistic models, Bayesian inference,\nand graph optimization to extract semantic information, dynamically updating\nthe graph with approximately 150 new nodes and edges in each data category\nwhile maintaining scalability with up to 987,654 edges. Real-world datasets,\nincluding MIMIC-III and PubMed, were utilized to evaluate the proposed\narchitecture. The evaluation results show that DKG-LLM achieves a diagnostic\naccuracy of 84.19%. The model also has a treatment recommendation accuracy of\n89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and\ntransformative tool that handles noisy data and complex multi-symptom diseases,\nalong with feedback-based learning from physician input.", "published": "2025-08-08 10:04:40", "link": "http://arxiv.org/abs/2508.06186v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime", "abstract": "Large language models (LLMs) often require vast amounts of text to\neffectively acquire new knowledge. While continuing pre-training on large\ncorpora or employing retrieval-augmented generation (RAG) has proven\nsuccessful, updating an LLM with only a few thousand or million tokens remains\nchallenging. In this work, we investigate the task of injecting small,\nunstructured information into LLMs and its relation to the catastrophic\nforgetting phenomenon. We use a dataset of recent news -- ensuring no overlap\nwith the model's pre-training data -- to evaluate the knowledge acquisition by\nprobing the model with question-answer pairs related the learned information.\nStarting from a continued pre-training baseline, we explored different\naugmentation algorithms to generate synthetic data to improve the knowledge\nacquisition capabilities. Our experiments show that simply continuing\npre-training on limited data yields modest improvements, whereas exposing the\nmodel to diverse textual variations significantly improves the learning of new\nfacts -- particularly with methods that induce greater variability through\ndiverse prompting. Furthermore, we shed light on the forgetting phenomenon in\nsmall-data regimes, illustrating the delicate balance between learning new\ncontent and retaining existing capabilities. We also confirm the sensitivity of\nRAG-based approaches for knowledge injection, which often lead to greater\ndegradation on control datasets compared to parametric methods. Finally, we\ndemonstrate that models can generate effective synthetic training data\nthemselves, suggesting a pathway toward self-improving model updates. All code\nand generated data used in our experiments are publicly available, providing a\nresource for studying efficient knowledge injection in LLMs with limited data\nat https://github.com/hugoabonizio/knowledge-injection-methods.", "published": "2025-08-08 09:48:32", "link": "http://arxiv.org/abs/2508.06178v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pragmatics beyond humans: meaning, communication, and LLMs", "abstract": "The paper reconceptualizes pragmatics not as a subordinate, third dimension\nof meaning, but as a dynamic interface through which language operates as a\nsocially embedded tool for action. With the emergence of large language models\n(LLMs) in communicative contexts, this understanding needs to be further\nrefined and methodologically reconsidered. The first section challenges the\ntraditional semiotic trichotomy, arguing that connectionist LLM architectures\ndestabilize established hierarchies of meaning, and proposes the Human-Machine\nCommunication (HMC) framework as a more suitable alternative. The second\nsection examines the tension between human-centred pragmatic theories and the\nmachine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics\ncontinue to dominate, it relies on human-specific assumptions ill-suited to\npredictive systems like LLMs. Probabilistic pragmatics, particularly the\nRational Speech Act framework, offers a more compatible teleology by focusing\non optimization rather than truth-evaluation. The third section addresses the\nissue of substitutionalism in three forms - generalizing, linguistic, and\ncommunicative - highlighting the anthropomorphic biases that distort LLM\nevaluation and obscure the role of human communicative subjects. Finally, the\npaper introduces the concept of context frustration to describe the paradox of\nincreased contextual input paired with a collapse in contextual understanding,\nemphasizing how users are compelled to co-construct pragmatic conditions both\nfor the model and themselves. These arguments suggest that pragmatic theory may\nneed to be adjusted or expanded to better account for communication involving\ngenerative AI.", "published": "2025-08-08 09:34:41", "link": "http://arxiv.org/abs/2508.06167v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities through two\ncomplementary paradigms: Retrieval-Augmented Generation (RAG), which enhances\nknowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),\nwhich optimizes complex reasoning abilities. However, these two capabilities\nare often developed in isolation, and existing efforts to unify them remain\nnarrow in scope-typically limited to open-domain QA with fixed retrieval\nsettings and task-specific assumptions. This lack of integration constrains\ngeneralization and limits the applicability of RAG-RL methods to broader\ndomains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a\ngeneral framework that unifies retrieval and reasoning through reinforcement\nlearning. UR2 introduces two key contributions: a difficulty-aware curriculum\ntraining that selectively invokes retrieval only for challenging problems, and\na hybrid knowledge access strategy combining domain-specific offline corpora\nwith LLM-generated summaries. These components are designed to enable dynamic\ncoordination between retrieval and reasoning, improving adaptability across a\ndiverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,\nand mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B\nand LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,\nachieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several\nbenchmarks. We have released all code, models, and data at\nhttps://github.com/Tsinghua-dhy/UR2.", "published": "2025-08-08 09:33:20", "link": "http://arxiv.org/abs/2508.06165v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging", "abstract": "Model merging has emerged as a compelling data-free paradigm for multi-task\nlearning, enabling the fusion of multiple fine-tuned models into a single,\npowerful entity. A key technique in merging methods is sparsification, which\nprunes redundant parameters from task vectors to mitigate interference.\nHowever, prevailing approaches employ a ``one-size-fits-all'' strategy,\napplying a uniform sparsity ratio that overlooks the inherent structural and\nstatistical heterogeneity of model parameters. This often leads to a suboptimal\ntrade-off, where critical parameters are inadvertently pruned while less useful\nones are retained. To address this limitation, we introduce \\textbf{TADrop}\n(\\textbf{T}ensor-wise \\textbf{A}daptive \\textbf{Drop}), an adaptive\nsparsification strategy that respects this heterogeneity. Instead of a global\nratio, TADrop assigns a tailored sparsity level to each parameter tensor based\non its distributional properties. The core intuition is that tensors with\ndenser, more redundant distributions can be pruned aggressively, while sparser,\nmore critical ones are preserved. As a simple and plug-and-play module, we\nvalidate TADrop by integrating it with foundational, classic, and SOTA merging\nmethods. Extensive experiments across diverse tasks (vision, language, and\nmultimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and\nsignificantly boosts their performance. For instance, when enhancing a leading\nmerging method, it achieves an average performance gain of 2.0\\% across 8\nViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter\ninterference by tailoring sparsification to the model's structure, offering a\nnew baseline for high-performance model merging.", "published": "2025-08-08 09:33:08", "link": "http://arxiv.org/abs/2508.06163v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach", "abstract": "This paper addresses the issue of implicit stereotypes that may arise during\nthe generation process of large language models. It proposes an interpretable\nbias detection method aimed at identifying hidden social biases in model\noutputs, especially those semantic tendencies that are not easily captured\nthrough explicit linguistic features. The method combines nested semantic\nrepresentation with a contextual contrast mechanism. It extracts latent bias\nfeatures from the vector space structure of model outputs. Using attention\nweight perturbation, it analyzes the model's sensitivity to specific social\nattribute terms, thereby revealing the semantic pathways through which bias is\nformed. To validate the effectiveness of the method, this study uses the\nStereoSet dataset, which covers multiple stereotype dimensions including\ngender, profession, religion, and race. The evaluation focuses on several key\nmetrics, such as bias detection accuracy, semantic consistency, and contextual\nsensitivity. Experimental results show that the proposed method achieves strong\ndetection performance across various dimensions. It can accurately identify\nbias differences between semantically similar texts while maintaining high\nsemantic alignment and output stability. The method also demonstrates high\ninterpretability in its structural design. It helps uncover the internal bias\nassociation mechanisms within language models. This provides a more transparent\nand reliable technical foundation for bias detection. The approach is suitable\nfor real-world applications where high trustworthiness of generated content is\nrequired.", "published": "2025-08-08 09:21:10", "link": "http://arxiv.org/abs/2508.06155v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models", "abstract": "Knowledge Distillation (KD) is a fundamental technique for compressing large\nlanguage models (LLMs) into compact, efficient student models. However,\nexisting white-box KD methods mainly focus on balancing ground truth and\nstudent-generated responses while overlooking two critical factors: training\ndata quality and student-model compatibility. To address these limitations, we\npropose Selective Reflection Distillation (SRD), a novel data curation\nframework that leverages reflections from student models to systematically\nrefine training data. SRD dynamically evaluates and selects prompt-response\npairs by comparing ground truth data with student model outputs, selectively\ncurating high-quality, student-compatible training instances through automated\nranking based on difficulty. Furthermore, after selecting the training data, a\ncurriculum scheduling strategy is employed to incrementally introduce these\ncurated subsets into the distillation process at fixed intervals. As a\nplug-and-play enhancement, SRD consistently improves distillation outcomes\nacross diverse white-box KD approaches and model architectures, as well as\ndecreases computational cost significantly during KD training. Experiments on a\nrange of language model benchmarks demonstrate SRD's consistent improvements in\ndistilled model performance, as well as a reduction in training runtime by up\nto 39%, under diverse KD methods and model families. Notably, SRD operates as a\nplug-and-play module, enhancing sample efficiency without modifying underlying\nKD algorithms. Our findings highlight that data quality and compatibility are\npivotal to effective and efficient distillation of LLMs, and SRD provides a\nprincipled framework to achieve both. This work advances the understanding of\ndata-centric factors in KD and offers practical insights for enhancing the\ncapability and efficiency of compressed LLMs.", "published": "2025-08-08 08:55:53", "link": "http://arxiv.org/abs/2508.06135v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models", "abstract": "Present day LLMs face the challenge of managing affordance-based safety\nrisks-situations where outputs inadvertently facilitate harmful actions due to\noverlooked logical implications. Traditional safety solutions, such as scalar\noutcome-based reward models, parameter tuning, or heuristic decoding\nstrategies, lack the granularity and proactive nature needed to reliably detect\nand intervene during subtle yet crucial reasoning steps. Addressing this\nfundamental gap, we introduce AURA, an innovative, multi-layered framework\ncentered around Process Reward Models (PRMs), providing comprehensive, step\nlevel evaluations across logical coherence and safety-awareness. Our framework\nseamlessly combines introspective self-critique, fine-grained PRM assessments,\nand adaptive safety-aware decoding to dynamically and proactively guide models\ntoward safer reasoning trajectories. Empirical evidence clearly demonstrates\nthat this approach significantly surpasses existing methods, significantly\nimproving the logical integrity and affordance-sensitive safety of model\noutputs. This research represents a pivotal step toward safer, more\nresponsible, and contextually aware AI, setting a new benchmark for\nalignment-sensitive applications.", "published": "2025-08-08 08:43:24", "link": "http://arxiv.org/abs/2508.06124v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures", "abstract": "Large language models (LLMs) often suffer from hallucination, generating\nfactually incorrect statements when handling questions beyond their knowledge\nand perception. Retrieval-augmented generation (RAG) addresses this by\nretrieving query-relevant contexts from knowledge bases to support LLM\nreasoning. Recent advances leverage pre-constructed graphs to capture the\nrelational connections among distributed documents, showing remarkable\nperformance in complex tasks. However, existing Graph-based RAG (GraphRAG)\nmethods rely on a costly process to transform the corpus into a graph,\nintroducing overwhelming token cost and update latency. Moreover, real-world\nqueries vary in type and complexity, requiring different logic structures for\naccurate reasoning. The pre-built graph may not align with these required\nstructures, resulting in ineffective knowledge retrieval. To this end, we\npropose a \\textbf{\\underline{Logic}}-aware\n\\textbf{\\underline{R}}etrieval-\\textbf{\\underline{A}}ugmented\n\\textbf{\\underline{G}}eneration framework (\\textbf{LogicRAG}) that dynamically\nextracts reasoning structures at inference time to guide adaptive retrieval\nwithout any pre-built graph. LogicRAG begins by decomposing the input query\ninto a set of subproblems and constructing a directed acyclic graph (DAG) to\nmodel the logical dependencies among them. To support coherent multi-step\nreasoning, LogicRAG then linearizes the graph using topological sort, so that\nsubproblems can be addressed in a logically consistent order. Besides, LogicRAG\napplies graph pruning to reduce redundant retrieval and uses context pruning to\nfilter irrelevant context, significantly reducing the overall token cost.\nExtensive experiments demonstrate that LogicRAG achieves both superior\nperformance and efficiency compared to state-of-the-art baselines.", "published": "2025-08-08 08:07:40", "link": "http://arxiv.org/abs/2508.06105v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs", "abstract": "This paper presents two effective approaches for Extractive Question\nAnswering (QA) on the Quran. It addresses challenges related to complex\nlanguage, unique terminology, and deep meaning in the text. The second uses\nfew-shot prompting with instruction-tuned large language models such as Gemini\nand DeepSeek. A specialized Arabic prompt framework is developed for span\nextraction. A strong post-processing system integrates subword alignment,\noverlap suppression, and semantic filtering. This improves precision and\nreduces hallucinations. Evaluations show that large language models with Arabic\ninstructions outperform traditional fine-tuned models. The best configuration\nachieves a pAP10 score of 0.637. The results confirm that prompt-based\ninstruction tuning is effective for low-resource, semantically rich QA tasks.", "published": "2025-08-08 08:02:59", "link": "http://arxiv.org/abs/2508.06103v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline", "abstract": "Constructed languages (conlangs) such as Esperanto and Quenya have played\ndiverse roles in art, philosophy, and international communication. Meanwhile,\nlarge-scale foundation models have revolutionized creative generation in text,\nimages, and beyond. In this work, we leverage modern LLMs as computational\ncreativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a\nmulti-hop pipeline that decomposes language design into modular stages --\nphonology, morphology, syntax, lexicon generation, and translation. At each\nstage, our method leverages LLMs' meta-linguistic reasoning capabilities,\ninjecting randomness to encourage diversity and leveraging self-refinement\nfeedback to encourage consistency in the emerging language description. We\nevaluate ConlangCrafter on metrics measuring coherence and typological\ndiversity, demonstrating its ability to produce coherent and varied conlangs\nwithout human linguistic expertise.", "published": "2025-08-08 07:36:48", "link": "http://arxiv.org/abs/2508.06094v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation", "abstract": "Generative AI has made image creation more accessible, yet aligning outputs\nwith nuanced creative intent remains challenging, particularly for non-experts.\nExisting tools often require users to externalize ideas through prompts or\nreferences, limiting fluid exploration. We introduce ThematicPlane, a system\nthat enables users to navigate and manipulate high-level semantic concepts\n(e.g., mood, style, or narrative tone) within an interactive thematic design\nplane. This interface bridges the gap between tacit creative intent and system\ncontrol. In our exploratory study (N=6), participants engaged in divergent and\nconvergent creative modes, often embracing unexpected results as inspiration or\niteration cues. While they grounded their exploration in familiar themes,\ndiffering expectations of how themes mapped to outputs revealed a need for more\nexplainable controls. Overall, ThematicPlane fosters expressive, iterative\nworkflows and highlights new directions for intuitive, semantics-driven\ninteraction in generative design tools.", "published": "2025-08-08 06:57:14", "link": "http://arxiv.org/abs/2508.06065v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV", "H.5.2; I.2.7"], "primary_category": "cs.HC"}
{"title": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System", "abstract": "State-of-the-art fact-checking systems combat misinformation at scale by\nemploying autonomous LLM-based agents to decompose complex claims into smaller\nsub-claims, verify each sub-claim individually, and aggregate the partial\nresults to produce verdicts with justifications (explanatory rationales for the\nverdicts). The security of these systems is crucial, as compromised\nfact-checkers, which tend to be easily underexplored, can amplify\nmisinformation. This work introduces Fact2Fiction, the first poisoning attack\nframework targeting such agentic fact-checking systems. Fact2Fiction mirrors\nthe decomposition strategy and exploits system-generated justifications to\ncraft tailored malicious evidences that compromise sub-claim verification.\nExtensive experiments demonstrate that Fact2Fiction achieves 8.9\\%--21.2\\%\nhigher attack success rates than state-of-the-art attacks across various\npoisoning budgets. Fact2Fiction exposes security weaknesses in current\nfact-checking systems and highlights the need for defensive countermeasures.", "published": "2025-08-08 06:44:57", "link": "http://arxiv.org/abs/2508.06059v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "abstract": "Although the effectiveness of Large Language Models (LLMs) as judges\n(LLM-as-a-judge) has been validated, their performance remains limited in\nopen-ended tasks, particularly in story evaluation. Accurate story evaluation\nis crucial not only for assisting human quality judgment but also for providing\nkey signals to guide story generation. However, existing methods face a\ndilemma: prompt engineering for closed-source models suffers from poor\nadaptability, while fine-tuning approaches for open-source models lack the\nrigorous reasoning capabilities essential for story evaluation. To address\nthis, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.\nGrounded in pairwise comparison, the framework first self-synthesizes\nscore-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To\nensure data quality, these raw CoTs undergo a self-filtering process, utilizing\nmulti-agents to guarantee their logical rigor and robustness. Finally, the\nevaluator trained on the refined data is deployed as a reward model to guide\nthe story generation task. Experimental results demonstrate that our framework\nachieves state-of-the-art (SOTA) performance on three evaluation benchmarks\nincluding StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward\nmodel, it significantly enhances the quality of generated stories, thereby\nfully validating the superiority of our self-evolving approach.", "published": "2025-08-08 06:10:47", "link": "http://arxiv.org/abs/2508.06046v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings", "abstract": "Large language models (LLMs) acquire knowledge across diverse domains such as\nscience, history, and geography encountered during generative pre-training.\nHowever, due to their stochasticity, it is difficult to predict what LLMs have\nacquired. Prior work has developed different ways to probe this knowledge by\ninvestigating the hidden representations, crafting specific task prompts,\ncurating representative samples, and estimating their uncertainty. However,\nthese methods require making forward passes through the underlying model to\nprobe the LLM's knowledge about a specific fact, making them computationally\nexpensive and time-consuming. To bridge this gap, we propose $\\textbf{PEEK}$ or\n$\\textbf{P}$roxy $\\textbf{E}$mbeddings to $\\textbf{E}$stimate\n$\\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models\nthat effectively encode factual knowledge as text or graphs as proxies for\nLLMs. First, we identify a training set of facts known by LLMs through various\nprobing strategies and then adapt embedding models to predict the LLM outputs\nwith a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived\ndatasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict\nLLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find\nthat sentence embedding models are more suitable than graph embeddings to\npredict LLM knowledge, shedding light on the underlying representation of the\nfactual landscape. Thus, we believe that knowledge-adapted embeddings can be\nused to identify knowledge gaps in LLMs at scale and can provide deeper\ninsights into LLMs' internal inductive bias. The code and data are made\navailable at https://github.com/claws-lab/peek.", "published": "2025-08-08 05:32:31", "link": "http://arxiv.org/abs/2508.06030v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future", "abstract": "Self-Rewarding Language Models propose an architecture in which the Large\nLanguage Models(LLMs) both generates responses and evaluates its own outputs\nvia LLM-as-a-Judge prompting, dynamically improving its generative capabilities\nthrough iterative Direct Preference Optimization (DPO). However, our analysis\nreveals a critical limitation in existing Self-Rewarding paradigms: the\nsynchronized improvement of chosen and rejected responses progressively narrows\nthe representational difference between contrasting samples, undermining\neffective preference learning. We propose \\textbf{Temporal Self-Rewarding\nLanguage Models} that strategically coordinate past, present, and future model\ngenerations to sustain learning signals. Our dual-phase framework introduces:\n(1) \\textit{Anchored Rejection} - fixing rejected responses using the past\ninitial model's outputs and (2) \\textit{Future-Guided Chosen} - dynamically\ncurating chosen samples using next-generation model predictions. Extensive\nexperiments across three model families (Llama, Qwen, Mistral) and different\nmodel sizes (Llama3B/8B/70B) demonstrate significant improvements when trained\nwith our method compared to Self-Rewarding using same computation resources.\nFor example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our\nmethod, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our\nmethod also demonstrates superior out-of-distribution generalization across\nmathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code\ngeneration (HumanEval) tasks, even though we do not specifically collect such\ntraining data.", "published": "2025-08-08 05:25:54", "link": "http://arxiv.org/abs/2508.06026v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "abstract": "Intelligent coding systems are transforming software development by enabling\nusers to specify code behavior in natural language. However, the opaque\ndecision-making of AI-driven coders raises trust and usability concerns,\nparticularly for non-expert users who cannot inspect low-level implementations.\nWe argue that these systems should not only generate code but also produce\nclear, consistent justifications that bridge model reasoning and user\nunderstanding. To this end, we identify two critical justification\nproperties-cognitive alignment and semantic faithfulness-and highlight the\nlimitations of existing methods, including formal verification, static\nanalysis, and post-hoc explainability. We advocate exploring neuro-symbolic\napproaches for justification generation, where symbolic constraints guide model\nbehavior during training and program semantics are enriched through neural\nrepresentations, enabling automated consistency checks at inference time.", "published": "2025-08-08 05:04:47", "link": "http://arxiv.org/abs/2508.06017v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Crisp Attention: Regularizing Transformers via Structured Sparsity", "abstract": "The quadratic computational cost of the self-attention mechanism is a primary\nchallenge in scaling Transformer models. While attention sparsity is widely\nstudied as a technique to improve computational efficiency, it is almost\nuniversally assumed to come at the cost of model accuracy. In this paper, we\nreport a surprising counter-example to this common wisdom. By introducing\nstructured, post-hoc sparsity to the attention mechanism of a DistilBERT model\nduring fine-tuning on the SST-2 sentiment analysis task, we find that model\naccuracy improves significantly. Our model with 80\\% attention sparsity\nachieves a validation accuracy of 91.59\\%, a 0.97\\% absolute improvement over\nthe dense baseline. We hypothesize that this phenomenon is due to sparsity\nacting as a powerful implicit regularizer, preventing the model from\noverfitting by forcing it to make predictions with a more constrained and\nrobust set of features. Our work recasts attention sparsity not just as a tool\nfor computational efficiency, but as a potential method for improving the\ngeneralization and performance of Transformer models.", "published": "2025-08-08 05:04:28", "link": "http://arxiv.org/abs/2508.06016v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring", "abstract": "Cross-topic automated essay scoring (AES) aims to develop a transferable\nmodel capable of effectively evaluating essays on a target topic. A significant\nchallenge in this domain arises from the inherent discrepancies between topics.\nWhile existing methods predominantly focus on extracting topic-shared features\nthrough distribution alignment of source and target topics, they often neglect\ntopic-specific features, limiting their ability to assess critical traits such\nas topic adherence. To address this limitation, we propose an Adversarial\nTOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns\ntopic-shared and topic-specific features to improve cross-topic AES. ATOP\nachieves this by optimizing a learnable topic-aware prompt--comprising both\nshared and specific components--to elicit relevant knowledge from pre-trained\nlanguage models (PLMs). To enhance the robustness of topic-shared prompt\nlearning and mitigate feature scale sensitivity introduced by topic alignment,\nwe incorporate adversarial training within a unified regression and\nclassification framework. In addition, we employ a neighbor-based classifier to\nmodel the local structure of essay representations and generate pseudo-labels\nfor target-topic essays. These pseudo-labels are then used to guide the\nsupervised learning of topic-specific prompts tailored to the target topic.\nExtensive experiments on the publicly available ASAP++ dataset demonstrate that\nATOP significantly outperforms existing state-of-the-art methods in both\nholistic and multi-trait essay scoring. The implementation of our method is\npublicly available at: https://anonymous.4open.science/r/ATOP-A271.", "published": "2025-08-08 03:43:01", "link": "http://arxiv.org/abs/2508.05987v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents", "abstract": "There is growing interest in integrating high-fidelity visual synthesis\ncapabilities into large language models (LLMs) without compromising their\nstrong reasoning capabilities. Existing methods that directly train LLMs or\nbridge LLMs and diffusion models usually suffer from costly training since the\nbackbone LLMs have not seen image representations during pretraining. We\npresent Bifrost-1, a unified framework that bridges pretrained multimodal LLMs\n(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent\nvariables, which are natively aligned with the MLLM's CLIP visual encoder.\nThese patch-level image embeddings are integrated into the diffusion model with\na lightweight adaptation of its ControlNet. To retain the original multimodal\nreasoning capabilities of MLLMs, we equip the MLLM with a visual generation\nbranch initialized from the original MLLM parameters when predicting the\npatch-level image embeddings. By seamlessly integrating pretrained MLLMs and\ndiffusion models with patch-level CLIP latents, our framework enables\nhigh-fidelity controllable image generation with significant training\nefficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or\nbetter performance than previous methods in terms of visual fidelity and\nmultimodal understanding, with substantially lower compute during training. We\nalso provide comprehensive ablation studies showing the effectiveness of our\ndesign choices.", "published": "2025-08-08 02:38:47", "link": "http://arxiv.org/abs/2508.05954v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale", "abstract": "Detecting prosociality in text--communication intended to affirm, support, or\nimprove others' behavior--is a novel and increasingly important challenge for\ntrust and safety systems. Unlike toxic content detection, prosociality lacks\nwell-established definitions and labeled data, requiring new approaches to both\nannotation and deployment. We present a practical, three-stage pipeline that\nenables scalable, high-precision prosocial content classification while\nminimizing human labeling effort and inference costs. First, we identify the\nbest LLM-based labeling strategy using a small seed set of human-labeled\nexamples. We then introduce a human-AI refinement loop, where annotators review\nhigh-disagreement cases between GPT-4 and humans to iteratively clarify and\nexpand the task definition-a critical step for emerging annotation tasks like\nprosociality. This process results in improved label quality and definition\nalignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train\na two-stage inference system: a lightweight classifier handles high-confidence\npredictions, while only $\\sim$35\\% of ambiguous instances are escalated to\nGPT-4o. This architecture reduces inference costs by $\\sim$70% while achieving\nhigh precision ($\\sim$0.90). Our pipeline demonstrates how targeted human-AI\ninteraction, careful task formulation, and deployment-aware architecture design\ncan unlock scalable solutions for novel responsible AI tasks.", "published": "2025-08-08 02:04:14", "link": "http://arxiv.org/abs/2508.05938v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; K.4"], "primary_category": "cs.CL"}
{"title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction", "abstract": "As AI systems become increasingly embedded in organizational workflows and\nconsumer applications, ethical principles such as fairness, transparency, and\nrobustness have been widely endorsed in policy and industry guidelines.\nHowever, there is still scarce empirical evidence on whether these principles\nare recognized, valued, or impactful from the perspective of users. This study\ninvestigates the link between ethical AI and user satisfaction by analyzing\nover 100,000 user reviews of AI products from G2. Using transformer-based\nlanguage models, we measure sentiment across seven ethical dimensions defined\nby the EU Ethics Guidelines for Trustworthy AI. Our findings show that all\nseven dimensions are positively associated with user satisfaction. Yet, this\nrelationship varies systematically across user and product types. Technical\nusers and reviewers of AI development platforms more frequently discuss\nsystem-level concerns (e.g., transparency, data governance), while\nnon-technical users and reviewers of end-user applications emphasize\nhuman-centric dimensions (e.g., human agency, societal well-being). Moreover,\nthe association between ethical AI and user satisfaction is significantly\nstronger for non-technical users and end-user applications across all\ndimensions. Our results highlight the importance of ethical AI design from\nusers' perspectives and underscore the need to account for contextual\ndifferences across user roles and product types.", "published": "2025-08-08 00:27:50", "link": "http://arxiv.org/abs/2508.05913v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation", "abstract": "Large Language Models (LLMs) have shown improved generation performance\nthrough retrieval-augmented generation (RAG) following the retriever-reader\nparadigm, which supplements model inputs with externally retrieved knowledge.\nHowever, prior work often evaluates RAG holistically, assessing the retriever\nand reader jointly, making it difficult to isolate the true contribution of\nretrieval, particularly given the prompt sensitivity of LLMs used as readers.\nWe introduce Spectrum Projection Score (SPS), a lightweight, supervision-free\nmetric that allows the reader to gauge the semantic alignment of a retrieved\nsummary with its hidden representation by comparing the area formed by\ngenerated tokens from the summary, and the principal directions of subspace in\nthe reader and to measure the relevance. Building on SPS we present xCompress,\nan inference time controller framework that dynamically samples, ranks, and\ncompresses retrieval summary candidates. Extensive experiments on five QA\nbenchmarks with four open source LLMs show that SPS not only enhances\nperformance across a range of tasks but also provides a principled perspective\non the interaction between retrieval and generation.", "published": "2025-08-08 00:13:48", "link": "http://arxiv.org/abs/2508.05909v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion", "abstract": "Urbanization, climate change, and agricultural stress are increasing the\ndemand for precise and timely environmental monitoring. Land Surface\nTemperature (LST) is a key variable in this context and is retrieved from\nremote sensing satellites. However, these systems face a trade-off between\nspatial and temporal resolution. While spatio-temporal fusion methods offer\npromising solutions, few have addressed the estimation of daily LST at 10 m\nresolution. In this study, we present WGAST, a Weakly-Supervised Generative\nNetwork for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra\nMODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning\nframework designed for this task. It adopts a conditional generative\nadversarial architecture, with a generator composed of four stages: feature\nextraction, fusion, LST reconstruction, and noise suppression. The first stage\nemploys a set of encoders to extract multi-level latent representations from\nthe inputs, which are then fused in the second stage using cosine similarity,\nnormalization, and temporal attention mechanisms. The third stage decodes the\nfused features into high-resolution LST, followed by a Gaussian filter to\nsuppress high-frequency noise. Training follows a weakly supervised strategy\nbased on physical averaging principles and reinforced by a PatchGAN\ndiscriminator. Experiments demonstrate that WGAST outperforms existing methods\nin both quantitative and qualitative evaluations. Compared to the\nbest-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves\nSSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and\neffectively captures fine-scale thermal patterns, as validated against 33\nground-based sensors. The code is available at\nhttps://github.com/Sofianebouaziz1/WGAST.git.", "published": "2025-08-08 17:49:46", "link": "http://arxiv.org/abs/2508.06485v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Intuition emerges in Maximum Caliber models at criticality", "abstract": "Whether large predictive models merely parrot their training data or produce\ngenuine insight lacks a physical explanation. This work reports a primitive\nform of intuition that emerges as a metastable phase of learning that\ncritically balances next-token prediction against future path-entropy. The\nintuition mechanism is discovered via mind-tuning, the minimal principle that\nimposes Maximum Caliber in predictive models with a control temperature-like\nparameter $\\lambda$. Training on random walks in deterministic mazes reveals a\nrich phase diagram: imitation (low $\\lambda$), rule-breaking hallucination\n(high $\\lambda$), and a fragile in-between window exhibiting strong\nprotocol-dependence (hysteresis) and multistability, where models spontaneously\ndiscover novel goal-directed strategies. These results are captured by an\neffective low-dimensional theory and frame intuition as an emergent property at\nthe critical balance between memorizing what is and wondering what could be.", "published": "2025-08-08 17:27:41", "link": "http://arxiv.org/abs/2508.06477v1", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG"], "primary_category": "physics.soc-ph"}
{"title": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting", "abstract": "Committee-selection problems arise in many contexts and applications, and\nthere has been increasing interest within the social choice research community\non identifying which properties are satisfied by different multi-winner voting\nrules. In this work, we propose a data-driven framework to evaluate how\nfrequently voting rules violate axioms across diverse preference distributions\nin practice, shifting away from the binary perspective of axiom satisfaction\ngiven by worst-case analysis. Using this framework, we analyze the relationship\nbetween multi-winner voting rules and their axiomatic performance under several\npreference distributions. We then show that neural networks, acting as voting\nrules, can outperform traditional rules in minimizing axiom violations. Our\nresults suggest that data-driven approaches to social choice can inform the\ndesign of new voting systems and support the continuation of data-driven\nresearch in social choice.", "published": "2025-08-08 16:54:09", "link": "http://arxiv.org/abs/2508.06454v1", "categories": ["cs.AI", "cs.GT"], "primary_category": "cs.AI"}
{"title": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "abstract": "Segmentation of lesions on CT enables automatic measurement for clinical\nassessment of chronic diseases (e.g., lymphoma). Integrating large language\nmodels (LLMs) into the lesion segmentation workflow offers the potential to\ncombine imaging features with descriptions of lesion characteristics from the\nradiology reports. In this study, we investigate the feasibility of integrating\ntext into the Swin-UMamba architecture for the task of lesion segmentation. The\npublicly available ULS23 DeepLesion dataset was used along with short-form\ndescriptions of the findings from the reports. On the test dataset, a high Dice\nScore of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for\nlesion segmentation. The proposed Text-Swin-UMamba model outperformed prior\napproaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <\n0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by\n1.74% and 0.22%, respectively. The dataset and code can be accessed at\nhttps://github.com/ruida/LLM-Swin-UMamba", "published": "2025-08-08 16:54:06", "link": "http://arxiv.org/abs/2508.06453v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time", "abstract": "An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify\ndifferent types of bias (also known as unfairness) exhibited in the predictions\nof ML algorithms, and to design new algorithms to mitigate them. Often, the\ndefinitions of bias used in the literature are observational, i.e. they use the\ninput and output of a pre-trained algorithm to quantify a bias under concern.\nIn reality,these definitions are often conflicting in nature and can only be\ndeployed if either the ground truth is known or only in retrospect after\ndeploying the algorithm. Thus,there is a gap between what we want Fair ML to\nachieve and what it does in a dynamic social environment. Hence, we propose an\nalternative dynamic mechanism,\"Fair Game\",to assure fairness in the predictions\nof an ML algorithm and to adapt its predictions as the society interacts with\nthe algorithm over time. \"Fair Game\" puts together an Auditor and a Debiasing\nalgorithm in a loop around an ML algorithm. The \"Fair Game\" puts these two\ncomponents in a loop by leveraging Reinforcement Learning (RL). RL algorithms\ninteract with an environment to take decisions, which yields new observations\n(also known as data/feedback) from the environment and in turn, adapts future\ndecisions. RL is already used in algorithms with pre-fixed long-term fairness\ngoals. \"Fair Game\" provides a unique framework where the fairness goals can be\nadapted over time by only modifying the auditor and the different biases it\nquantifies. Thus,\"Fair Game\" aims to simulate the evolution of ethical and\nlegal frameworks in the society by creating an auditor which sends feedback to\na debiasing algorithm deployed around an ML system. This allows us to develop a\nflexible and adaptive-over-time framework to build Fair ML systems pre- and\npost-deployment.", "published": "2025-08-08 16:36:16", "link": "http://arxiv.org/abs/2508.06443v1", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.GT"], "primary_category": "cs.AI"}
{"title": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment", "abstract": "Large-scale natural image-text datasets, especially those automatically\ncollected from the web, often suffer from loose semantic alignment due to weak\nsupervision, while medical datasets tend to have high cross-modal correlation\nbut low content diversity. These properties pose a common challenge for\ncontrastive language-image pretraining (CLIP): they hinder the model's ability\nto learn robust and generalizable representations. In this work, we propose\nCLIPin, a unified non-contrastive plug-in that can be seamlessly integrated\ninto CLIP-style architectures to improve multimodal semantic alignment,\nproviding stronger supervision and enhancing alignment robustness. Furthermore,\ntwo shared pre-projectors are designed for image and text modalities\nrespectively to facilitate the integration of contrastive and non-contrastive\nlearning in a parameter-compromise manner. Extensive experiments on diverse\ndownstream tasks demonstrate the effectiveness and generality of CLIPin as a\nplug-and-play component compatible with various contrastive frameworks. Code is\navailable at https://github.com/T6Yang/CLIPin.", "published": "2025-08-08 16:23:05", "link": "http://arxiv.org/abs/2508.06434v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "abstract": "Deep learning has revolutionized medical imaging, but its effectiveness is\nseverely limited by insufficient labeled training data. This paper introduces a\nnovel GAN-based semi-supervised learning framework specifically designed for\nlow labeled-data regimes, evaluated across settings with 5 to 50 labeled\nsamples per class. Our approach integrates three specialized neural networks --\na generator for class-conditioned image translation, a discriminator for\nauthenticity assessment and classification, and a dedicated classifier --\nwithin a three-phase training framework. The method alternates between\nsupervised training on limited labeled data and unsupervised learning that\nleverages abundant unlabeled images through image-to-image translation rather\nthan generation from noise. We employ ensemble-based pseudo-labeling that\ncombines confidence-weighted predictions from the discriminator and classifier\nwith temporal consistency through exponential moving averaging, enabling\nreliable label estimation for unlabeled data. Comprehensive evaluation across\neleven MedMNIST datasets demonstrates that our approach achieves statistically\nsignificant improvements over six state-of-the-art GAN-based semi-supervised\nmethods, with particularly strong performance in the extreme 5-shot setting\nwhere the scarcity of labeled data is most challenging. The framework maintains\nits superiority across all evaluated settings (5, 10, 20, and 50 shots per\nclass). Our approach offers a practical solution for medical imaging\napplications where annotation costs are prohibitive, enabling robust\nclassification performance even with minimal labeled data. Code is available at\nhttps://github.com/GuidoManni/SPARSE.", "published": "2025-08-08 16:16:43", "link": "http://arxiv.org/abs/2508.06429v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation", "abstract": "Generalist robot policies trained on large-scale datasets such as Open\nX-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.\nHowever, they often struggle to generalize beyond the distribution of their\ntraining data. In this paper, we investigate the underlying cause of this\nlimited generalization capability. We identify shortcut learning -- the\nreliance on task-irrelevant features -- as a key impediment to generalization.\nThrough comprehensive theoretical and empirical analysis, we uncover two\nprimary contributors to shortcut learning: (1) limited diversity within\nindividual sub-datasets, and (2) significant distributional disparities across\nsub-datasets, leading to dataset fragmentation. These issues arise from the\ninherent structure of large-scale datasets like OXE, which are typically\ncomposed of multiple sub-datasets collected independently across varied\nenvironments and embodiments. Our findings provide critical insights into\ndataset collection strategies that can reduce shortcut learning and enhance the\ngeneralization ability of generalist robot policies. Moreover, in scenarios\nwhere acquiring new large-scale data is impractical, we demonstrate that\ncarefully selected robotic data augmentation strategies can effectively reduce\nshortcut learning in existing offline datasets, thereby improving\ngeneralization capabilities of generalist robot policies, e.g., $\\pi_0$, in\nboth simulation and real-world environments. More information at\nhttps://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.", "published": "2025-08-08 16:14:01", "link": "http://arxiv.org/abs/2508.06426v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks", "abstract": "Although discourse around the risks of Artificial Intelligence (AI) has\ngrown, it often lacks a comprehensive, multidimensional framework, and concrete\ncausal pathways mapping hazard to harm. This paper aims to bridge this gap by\nexamining six commonly discussed AI catastrophic risks: CBRN, cyber offense,\nsudden loss of control, gradual loss of control, environmental risk, and\ngeopolitical risk. First, we characterize these risks across seven key\ndimensions, namely intent, competency, entity, polarity, linearity, reach, and\norder. Next, we conduct risk pathway modeling by mapping step-by-step\nprogressions from the initial hazard to the resulting harms. The dimensional\napproach supports systematic risk identification and generalizable mitigation\nstrategies, while risk pathway models help identify scenario-specific\ninterventions. Together, these methods offer a more structured and actionable\nfoundation for managing catastrophic AI risks across the value chain.", "published": "2025-08-08 15:56:05", "link": "http://arxiv.org/abs/2508.06411v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery", "abstract": "High-resolution imagery plays a critical role in improving the performance of\nvisual recognition tasks such as classification, detection, and segmentation.\nIn many domains, including remote sensing and surveillance, low-resolution\nimages can limit the accuracy of automated analysis. To address this,\nsuper-resolution (SR) techniques have been widely adopted to attempt to\nreconstruct high-resolution images from low-resolution inputs. Related\ntraditional approaches focus solely on enhancing image quality based on\npixel-level metrics, leaving the relationship between super-resolved image\nfidelity and downstream classification performance largely underexplored. This\nraises a key question: can integrating classification objectives directly into\nthe super-resolution process further improve classification accuracy? In this\npaper, we try to respond to this question by investigating the relationship\nbetween super-resolution and classification through the deployment of a\nspecialised algorithmic strategy. We propose a novel methodology that increases\nthe resolution of synthetic aperture radar imagery by optimising loss functions\nthat account for both image quality and classification performance. Our\napproach improves image quality, as measured by scientifically ascertained\nimage quality indicators, while also enhancing classification accuracy.", "published": "2025-08-08 15:50:40", "link": "http://arxiv.org/abs/2508.06407v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling", "abstract": "Traditional speech separation and speaker diarization approaches rely on\nprior knowledge of target speakers or a predetermined number of participants in\naudio signals. To address these limitations, recent advances focus on\ndeveloping enrollment-free methods capable of identifying targets without\nexplicit speaker labeling. This work introduces a new approach to train\nsimultaneous speech separation and diarization using automatic identification\nof target speaker embeddings, within mixtures. Our proposed model employs a\ndual-stage training pipeline designed to learn robust speaker representation\nfeatures that are resilient to background noise interference. Furthermore, we\npresent an overlapping spectral loss function specifically tailored for\nenhancing diarization accuracy during overlapped speech frames. Experimental\nresults show significant performance gains compared to the current SOTA\nbaseline, achieving 71% relative improvement in DER and 69% in cpWER.", "published": "2025-08-08 15:24:10", "link": "http://arxiv.org/abs/2508.06393v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Identity Increases Stability in Neural Cellular Automata", "abstract": "Neural Cellular Automata (NCAs) offer a way to study the growth of\ntwo-dimensional artificial organisms from a single seed cell. From the outset,\nNCA-grown organisms have had issues with stability, their natural boundary\noften breaking down and exhibiting tumour-like growth or failing to maintain\nthe expected shape. In this paper, we present a method for improving the\nstability of NCA-grown organisms by introducing an 'identity' layer with simple\nconstraints during training.\n  Results show that NCAs grown in close proximity are more stable compared with\nthe original NCA model. Moreover, only a single identity value is required to\nachieve this increase in stability. We observe emergent movement from the\nstable organisms, with increasing prevalence for models with multiple identity\nvalues.\n  This work lays the foundation for further study of the interaction between\nNCA-grown organisms, paving the way for studying social interaction at a\ncellular level in artificial organisms.", "published": "2025-08-08 15:18:01", "link": "http://arxiv.org/abs/2508.06389v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "abstract": "Text-to-SQL bridges the gap between natural language and structured database\nlanguage, thus allowing non-technical users to easily query databases.\nTraditional approaches model text-to-SQL as a direct translation task, where a\ngiven Natural Language Query (NLQ) is mapped to an SQL command. Recent advances\nin large language models (LLMs) have significantly improved translation\naccuracy, however, these methods all require that the target database is\npre-specified. This becomes problematic in scenarios with multiple extensive\ndatabases, where identifying the correct database becomes a crucial yet\noverlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL\nframework to identify the user's intended database before generating SQL\nqueries. Our approach leverages LLMs and prompt engineering to extract implicit\ninformation from natural language queries (NLQs) in the form of a ruleset. We\nthen train a large db\\_id prediction model, which includes a RoBERTa-based\nfinetuned encoder, to predict the correct Database identifier (db\\_id) based on\nboth the NLQ and the LLM-generated rules. Finally, we refine the generated SQL\nby using critic agents to correct errors. Experimental results demonstrate that\nour framework outperforms the current state-of-the-art models in both database\nintent prediction and SQL generation accuracy.", "published": "2025-08-08 15:16:36", "link": "http://arxiv.org/abs/2508.06387v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models", "abstract": "The Speaker Diarization and Recognition (SDR) task aims to predict \"who spoke\nwhen and what\" within an audio clip, which is a crucial task in various\nreal-world multi-speaker scenarios such as meeting transcription and dialogue\nsystems. Existing SDR systems typically adopt a cascaded framework, combining\nmultiple modules such as speaker diarization (SD) and automatic speech\nrecognition (ASR). The cascaded systems suffer from several limitations, such\nas error propagation, difficulty in handling overlapping speech, and lack of\njoint optimization for exploring the synergy between SD and ASR tasks. To\naddress these limitations, we introduce SpeakerLM, a unified multimodal large\nlanguage model for SDR that jointly performs SD and ASR in an end-to-end\nmanner. Moreover, to facilitate diverse real-world scenarios, we incorporate a\nflexible speaker registration mechanism into SpeakerLM, enabling SDR under\ndifferent speaker registration settings. SpeakerLM is progressively developed\nwith a multi-stage training strategy on large-scale real data. Extensive\nexperiments show that SpeakerLM demonstrates strong data scaling capability and\ngeneralizability, outperforming state-of-the-art cascaded baselines on both\nin-domain and out-of-domain public SDR benchmarks. Furthermore, experimental\nresults show that the proposed speaker registration mechanism effectively\nensures robust SDR performance of SpeakerLM across diverse speaker registration\nconditions and varying numbers of registered speakers.", "published": "2025-08-08 15:04:00", "link": "http://arxiv.org/abs/2508.06372v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned", "abstract": "Legal decision-making process requires the availability of comprehensive and\ndetailed legislative background knowledge and up-to-date information on legal\ncases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a\nvaluable tool to facilitate access to legal information, to be queried and\nexploited for the purpose, and to enable advanced reasoning and machine\nlearning applications. Indeed, legal KGs may act as knowledge intensive\ncomponent to be used by pre-dictive machine learning solutions supporting the\ndecision process of the legal expert. Nevertheless, a few KGs can be found in\nthe legal domain. To fill this gap, we developed a legal KG targeting legal\ncases of violence against women, along with clear adopted methodologies.\nSpecifically, the paper introduces two complementary approaches for automated\nlegal KG construction; a systematic bottom-up approach, customized for the\nlegal domain, and a new solution leveraging Large Language Models. Starting\nfrom legal sentences publicly available from the European Court of Justice, the\nsolutions integrate structured data extraction, ontology development, and\nsemantic enrichment to produce KGs tailored for legal cases involving violence\nagainst women. After analyzing and comparing the results of the two approaches,\nthe developed KGs are validated via suitable competency questions. The obtained\nKG may be impactful for multiple purposes: can improve the accessibility to\nlegal information both to humans and machine, can enable complex queries and\nmay constitute an important knowledge component to be possibly exploited by\nmachine learning tools tailored for predictive justice.", "published": "2025-08-08 14:59:54", "link": "http://arxiv.org/abs/2508.06368v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design", "abstract": "Achieving precise control over a molecule's biological activity-encompassing\ntargeted activation/inhibition, cooperative multi-target modulation, and\noff-target toxicity mitigation-remains a critical challenge in de novo drug\ndesign. However, existing generative methods primarily focus on producing\nmolecules with a single desired activity, lacking integrated mechanisms for the\nsimultaneous management of multiple intended and unintended molecular\ninteractions. Here, we propose ActivityDiff, a generative approach based on the\nclassifier-guidance technique of diffusion models. It leverages separately\ntrained drug-target classifiers for both positive and negative guidance,\nenabling the model to enhance desired activities while minimizing harmful\noff-target effects. Experimental results show that ActivityDiff effectively\nhandles essential drug design tasks, including single-/dual-target generation,\nfragment-constrained dual-target design, selective generation to enhance target\nspecificity, and reduction of off-target effects. These results demonstrate the\neffectiveness of classifier-guided diffusion in balancing efficacy and safety\nin molecular design. Overall, our work introduces a novel paradigm for\nachieving integrated control over molecular activity, and provides ActivityDiff\nas a versatile and extensible framework.", "published": "2025-08-08 14:48:47", "link": "http://arxiv.org/abs/2508.06364v1", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "abstract": "Large Language Models (LLMs) have been widely deployed in reasoning,\nplanning, and decision-making tasks, making their trustworthiness a critical\nconcern. The potential for intentional deception, where an LLM deliberately\nfabricates or conceals information to serve a hidden objective, remains a\nsignificant and underexplored threat. Existing studies typically induce such\ndeception by explicitly setting a \"hidden\" objective through prompting or\nfine-tuning, which may not fully reflect real-world human-LLM interactions.\nMoving beyond this human-induced deception, we investigate LLMs' self-initiated\ndeception on benign prompts. To address the absence of ground truth in this\nevaluation, we propose a novel framework using \"contact searching questions.\"\nThis framework introduces two statistical metrics derived from psychological\nprinciples to quantify the likelihood of deception. The first, the Deceptive\nIntention Score, measures the model's bias towards a hidden objective. The\nsecond, Deceptive Behavior Score, measures the inconsistency between the LLM's\ninternal belief and its expressed output. Upon evaluating 14 leading LLMs, we\nfind that both metrics escalate as task difficulty increases, rising in\nparallel for most models. Building on these findings, we formulate a\nmathematical model to explain this behavior. These results reveal that even the\nmost advanced LLMs exhibit an increasing tendency toward deception when\nhandling complex problems, raising critical concerns for the deployment of LLM\nagents in complex and crucial domains.", "published": "2025-08-08 14:46:35", "link": "http://arxiv.org/abs/2508.06361v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd", "abstract": "A central problem in one-to-many facial identification is that the person in\nthe probe image may or may not have enrolled image(s) in the gallery; that is,\nmay be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one\nresult is Out-of-gallery have mostly focused on finding a suitable threshold on\nthe similarity score. We take a new approach, using the additional enrolled\nimages of the identity with the rank-one result to predict if the rank-one\nresult is In-gallery / Out-of-gallery. Given a gallery of identities and\nimages, we generate In-gallery and Out-of-gallery training data by extracting\nthe ranks of additional enrolled images corresponding to the rank-one identity.\nWe then train a classifier to utilize this feature vector to predict whether a\nrank-one result is In-gallery or Out-of-gallery. Using two different datasets\nand four different matchers, we present experimental results showing that our\napproach is viable for mugshot quality probe images, and also, importantly, for\nprobes degraded by blur, reduced resolution, atmospheric turbulence and\nsunglasses. We also analyze results across demographic groups, and show that\nIn-gallery / Out-of-gallery classification accuracy is similar across\ndemographics. Our approach has the potential to provide an objective estimate\nof whether a one-to-many facial identification is Out-of-gallery, and thereby\nto reduce false positive identifications, wrongful arrests, and wasted\ninvestigative time. Interestingly, comparing the results of older deep\nCNN-based face matchers with newer ones suggests that the effectiveness of our\nOut-of-gallery detection approach emerges only with matchers trained using\nadvanced margin-based loss functions.", "published": "2025-08-08 14:39:29", "link": "http://arxiv.org/abs/2508.06357v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI", "abstract": "Current explainable AI (XAI) approaches prioritize algorithmic transparency\nand present explanations in abstract, non-adaptive formats that often fail to\nsupport meaningful end-user understanding. This paper introduces \"Explanatory\nAI\" as a complementary paradigm that leverages generative AI capabilities to\nserve as explanatory partners for human understanding rather than providers of\nalgorithmic transparency. While XAI reveals algorithmic decision processes for\nmodel validation, Explanatory AI addresses contextual reasoning to support\nhuman decision-making in sociotechnical contexts. We develop a definition and\nsystematic eight-dimensional conceptual model distinguishing Explanatory AI\nthrough narrative communication, adaptive personalization, and progressive\ndisclosure principles. Empirical validation through Rapid Contextual Design\nmethodology with healthcare professionals demonstrates that users consistently\nprefer context-sensitive, multimodal explanations over technical transparency.\nOur findings reveal the practical urgency for AI systems designed for human\ncomprehension rather than algorithmic introspection, establishing a\ncomprehensive research agenda for advancing user-centered AI explanation\napproaches across diverse domains and cultural contexts.", "published": "2025-08-08 14:32:41", "link": "http://arxiv.org/abs/2508.06352v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games", "abstract": "Cheating in online video games compromises the integrity of gaming\nexperiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face\nsignificant challenges in keeping pace with evolving cheating methods without\nimposing invasive measures on users' systems. This paper presents\nAntiCheatPT\\_256, a transformer-based machine learning model designed to detect\ncheating behaviour in Counter-Strike 2 using gameplay data. To support this, we\nintroduce and publicly release CS2CD: A labelled dataset of 795 matches. Using\nthis dataset, 90,707 context windows were created and subsequently augmented to\naddress class imbalance. The transformer model, trained on these windows,\nachieved an accuracy of 89.17\\% and an AUC of 93.36\\% on an unaugmented test\nset. This approach emphasizes reproducibility and real-world applicability,\noffering a robust baseline for future research in data-driven cheat detection.", "published": "2025-08-08 14:22:41", "link": "http://arxiv.org/abs/2508.06348v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data", "abstract": "Learning interpretable latent representations from tabular data remains a\nchallenge in deep generative modeling. We introduce SE-VAE (Structural\nEquation-Variational Autoencoder), a novel architecture that embeds measurement\nstructure directly into the design of a variational autoencoder. Inspired by\nstructural equation modeling, SE-VAE aligns latent subspaces with known\nindicator groupings and introduces a global nuisance latent to isolate\nconstruct-specific confounding variation. This modular architecture enables\ndisentanglement through design rather than through statistical regularizers\nalone. We evaluate SE-VAE on a suite of simulated tabular datasets and\nbenchmark its performance against a series of leading baselines using standard\ndisentanglement metrics. SE-VAE consistently outperforms alternatives in factor\nrecovery, interpretability, and robustness to nuisance variation. Ablation\nresults reveal that architectural structure, rather than regularization\nstrength, is the key driver of performance. SE-VAE offers a principled\nframework for white-box generative modeling in scientific and social domains\nwhere latent constructs are theory-driven and measurement validity is\nessential.", "published": "2025-08-08 14:21:20", "link": "http://arxiv.org/abs/2508.06347v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection", "abstract": "Video Anomaly Detection (VAD) is a challenging task due to the variability of\nanomalous events and the limited availability of labeled data. Under the\nWeakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided\nduring training, while predictions are made at the frame level. Although\nstate-of-the-art models perform well on simple anomalies (e.g., explosions),\nthey struggle with complex real-world events (e.g., shoplifting). This\ndifficulty stems from two key issues: (1) the inability of current models to\naddress the diversity of anomaly types, as they process all categories with a\nshared model, overlooking category-specific features; and (2) the weak\nsupervision signal, which lacks precise temporal information, limiting the\nability to capture nuanced anomalous patterns blended with normal events. To\naddress these challenges, we propose Gaussian Splatting-guided Mixture of\nExperts (GS-MoE), a novel framework that employs a set of expert models, each\nspecialized in capturing specific anomaly types. These experts are guided by a\ntemporal Gaussian splatting loss, enabling the model to leverage temporal\nconsistency and enhance weak supervision. The Gaussian splatting approach\nencourages a more precise and comprehensive representation of anomalies by\nfocusing on temporal segments most likely to contain abnormal events. The\npredictions from these specialized experts are integrated through a\nmixture-of-experts mechanism to model complex relationships across diverse\nanomaly patterns. Our approach achieves state-of-the-art performance, with a\n91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on\nXD-Violence and MSAD datasets. By leveraging category-specific expertise and\ntemporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.", "published": "2025-08-08 13:48:48", "link": "http://arxiv.org/abs/2508.06318v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "abstract": "Neural fields provide a memory-efficient representation of data, which can\neffectively handle diverse modalities and large-scale data. However, learning\nto map neural fields often requires large amounts of training data and\ncomputations, which can be limited to resource-constrained edge devices. One\napproach to tackle this limitation is to leverage Federated Meta-Learning\n(FML), but traditional FML approaches suffer from privacy leakage. To address\nthese issues, we introduce a novel FML approach called FedMeNF. FedMeNF\nutilizes a new privacy-preserving loss function that regulates privacy leakage\nin the local meta-optimization. This enables the local meta-learner to optimize\nquickly and efficiently without retaining the client's private data. Our\nexperiments demonstrate that FedMeNF achieves fast optimization speed and\nrobust reconstruction performance, even with few-shot or non-IID data across\ndiverse data modalities, while preserving client data privacy.", "published": "2025-08-08 13:24:57", "link": "http://arxiv.org/abs/2508.06301v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "primary_category": "cs.LG"}
{"title": "LLM Robustness Leaderboard v1 --Technical report", "abstract": "This technical report accompanies the LLM robustness leaderboard published by\nPRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior\nElicitation Tool (BET), an AI system performing automated red-teaming through\nDynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)\nagainst 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we\npropose a fine-grained robustness metric estimating the average number of\nattempts required to elicit harmful behaviors, revealing that attack difficulty\nvaries by over 300-fold across models despite universal vulnerability. We\nintroduce primitive-level vulnerability analysis to identify which jailbreaking\ntechniques are most effective for specific hazard categories. Our collaborative\nevaluation with trusted third parties from the AI Safety Network demonstrates\npractical pathways for distributed robustness assessment across the community.", "published": "2025-08-08 13:15:40", "link": "http://arxiv.org/abs/2508.06296v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification", "abstract": "Lung cancer (LC) ranks among the most frequently diagnosed cancers and is one\nof the most common causes of death for men and women worldwide. Computed\nTomography (CT) images are the most preferred diagnosis method because of their\nlow cost and their faster processing times. Many researchers have proposed\nvarious ways of identifying lung cancer using CT images. However, such\ntechniques suffer from significant false positives, leading to low accuracy.\nThe fundamental reason results from employing a small and imbalanced dataset.\nThis paper introduces an innovative approach for LC detection and\nclassification from CT images based on the DenseNet201 model. Our approach\ncomprises several advanced methods such as Focal Loss, data augmentation, and\nregularization to overcome the imbalanced data issue and overfitting challenge.\nThe findings show the appropriateness of the proposal, attaining a promising\nperformance of 98.95% accuracy.", "published": "2025-08-08 13:09:52", "link": "http://arxiv.org/abs/2508.06287v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "abstract": "Generative models, especially diffusion and flow-based models, have been\npromising in offline multi-agent reinforcement learning. However, integrating\npowerful generative models into this framework poses unique challenges. In\nparticular, diffusion and flow-based policies suffer from low sampling\nefficiency due to their iterative generation processes, making them impractical\nin time-sensitive or resource-constrained settings. To tackle these\ndifficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel\noffline MARL algorithm to achieve efficient one-step action sampling. To\naddress the misalignment between generative objectives and reward maximization,\nwe introduce a reward-aware optimization scheme that integrates a\ncarefully-designed mean-flow matching loss with Q-function supervision.\nAdditionally, we design a generalized timestep distribution and a\nderivative-free estimation strategy to reduce memory overhead and improve\ntraining stability. Empirical evaluations on Multi-Agent Particle and MuJoCo\nbenchmarks demonstrate that OM2P achieves superior performance, with up to a\n3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.\nOur approach represents the first to successfully integrate mean-flow model\ninto offline MARL, paving the way for practical and scalable generative\npolicies in cooperative multi-agent settings.", "published": "2025-08-08 12:38:56", "link": "http://arxiv.org/abs/2508.06269v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Symmetry breaking for inductive logic programming", "abstract": "The goal of inductive logic programming is to search for a hypothesis that\ngeneralises training data and background knowledge. The challenge is searching\nvast hypothesis spaces, which is exacerbated because many logically equivalent\nhypotheses exist. To address this challenge, we introduce a method to break\nsymmetries in the hypothesis space. We implement our idea in answer set\nprogramming. Our experiments on multiple domains, including visual reasoning\nand game playing, show that our approach can reduce solving times from over an\nhour to just 17 seconds.", "published": "2025-08-08 12:28:42", "link": "http://arxiv.org/abs/2508.06263v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "abstract": "Current multimodal large language models (MLLMs) still face significant\nchallenges in complex visual tasks (e.g., spatial understanding, fine-grained\nperception). Prior methods have tried to incorporate visual reasoning, however,\nthey fail to leverage attention correction with spatial cues to iteratively\nrefine their focus on prompt-relevant regions. In this paper, we introduce\nSIFThinker, a spatially-aware \"think-with-images\" framework that mimics human\nvisual perception. Specifically, SIFThinker enables attention correcting and\nimage region focusing by interleaving depth-enhanced bounding boxes and natural\nlanguage. Our contributions are twofold: First, we introduce a\nreverse-expansion-forward-inference strategy that facilitates the generation of\ninterleaved image-text chains of thought for process-level supervision, which\nin turn leads to the construction of the SIF-50K dataset. Besides, we propose\nGRPO-SIF, a reinforced training paradigm that integrates depth-informed visual\ngrounding into a unified reasoning pipeline, teaching the model to dynamically\ncorrect and focus on prompt-relevant regions. Extensive experiments demonstrate\nthat SIFThinker outperforms state-of-the-art methods in spatial understanding\nand fine-grained visual perception, while maintaining strong general\ncapabilities, highlighting the effectiveness of our method.", "published": "2025-08-08 12:26:20", "link": "http://arxiv.org/abs/2508.06259v1", "categories": ["cs.CV", "cs.AI", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)", "abstract": "Synthetic data generation is a key technique in modern artificial\nintelligence, addressing data scarcity, privacy constraints, and the need for\ndiverse datasets in training robust models. In this work, we propose a method\nfor generating privacy-preserving high-quality synthetic tabular data using\nTensor Networks, specifically Matrix Product States (MPS). We benchmark the\nMPS-based generative model against state-of-the-art models such as CTGAN, VAE,\nand PrivBayes, focusing on both fidelity and privacy-preserving capabilities.\nTo ensure differential privacy (DP), we integrate noise injection and gradient\nclipping during training, enabling privacy guarantees via R\\'enyi Differential\nPrivacy accounting. Across multiple metrics analyzing data fidelity and\ndownstream machine learning task performance, our results show that MPS\noutperforms classical models, particularly under strict privacy constraints.\nThis work highlights MPS as a promising tool for privacy-aware synthetic data\ngeneration. By combining the expressive power of tensor network representations\nwith formal privacy mechanisms, the proposed approach offers an interpretable\nand scalable alternative for secure data sharing. Its structured design\nfacilitates integration into sensitive domains where both data quality and\nconfidentiality are critical.", "published": "2025-08-08 12:14:57", "link": "http://arxiv.org/abs/2508.06251v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "quant-ph"], "primary_category": "cs.LG"}
{"title": "In-Training Defenses against Emergent Misalignment in Language Models", "abstract": "Fine-tuning lets practitioners repurpose aligned large language models (LLMs)\nfor new domains, yet recent work reveals emergent misalignment (EMA): Even a\nsmall, domain-specific fine-tune can induce harmful behaviors far outside the\ntarget domain. Even in the case where model weights are hidden behind a\nfine-tuning API, this gives attackers inadvertent access to a broadly\nmisaligned model in a way that can be hard to detect from the fine-tuning data\nalone. We present the first systematic study of in-training safeguards against\nEMA that are practical for providers who expose fine-tuning via an API. We\ninvestigate four training regularization interventions: (i) KL-divergence\nregularization toward a safe reference model, (ii) $\\ell_2$ distance in feature\nspace, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving\nof a small amount of safe training examples from a general instruct-tuning\ndataset. We first evaluate the methods' emergent misalignment effect across\nfour malicious, EMA-inducing tasks. Second, we assess the methods' impacts on\nbenign tasks. We conclude with a discussion of open questions in emergent\nmisalignment research.", "published": "2025-08-08 12:10:28", "link": "http://arxiv.org/abs/2508.06249v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Membership Inference Attack with Partial Features", "abstract": "Machine learning models have been shown to be susceptible to membership\ninference attack, which can be used to determine whether a given sample appears\nin the training data. Existing membership inference methods commonly assume\nthat the adversary has full access to the features of the target sample. This\nassumption, however, does not hold in many real-world scenarios where only\npartial features information is available, thereby limiting the applicability\nof these methods. In this work, we study an inference scenario where the\nadversary observes only partial features of each sample and aims to infer\nwhether this observed subset was present in the training set of the target\nmodel. We define this problem as Partial Feature Membership Inference (PFMI).\nTo address this problem, we propose MRAD (Memory-guided Reconstruction and\nAnomaly Detection), a two-stage attack framework. In the first stage, MRAD\noptimizes the unknown feature values to minimize the loss of the sample. In the\nsecond stage, it measures the deviation between the reconstructed sample and\nthe training distribution using anomaly detection. Empirical results\ndemonstrate that MRAD is effective across a range of datasets, and maintains\ncompatibility with various off-the-shelf anomaly detection techniques. For\nexample, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of\nthe missing features.", "published": "2025-08-08 11:56:13", "link": "http://arxiv.org/abs/2508.06244v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Learning Logical Rules using Minimum Message Length", "abstract": "Unifying probabilistic and logical learning is a key challenge in AI. We\nintroduce a Bayesian inductive logic programming approach that learns minimum\nmessage length programs from noisy data. Our approach balances hypothesis\ncomplexity and data fit through priors, which explicitly favour more general\nprograms, and a likelihood that favours accurate programs. Our experiments on\nseveral domains, including game playing and drug design, show that our method\nsignificantly outperforms previous methods, notably those that learn minimum\ndescription length programs. Our results also show that our approach is\ndata-efficient and insensitive to example balance, including the ability to\nlearn from exclusively positive examples.", "published": "2025-08-08 11:23:58", "link": "http://arxiv.org/abs/2508.06230v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines", "abstract": "Geometry problem solving (GPS) requires models to master diagram\ncomprehension, logical reasoning, knowledge application, numerical computation,\nand auxiliary line construction. This presents a significant challenge for\nMultimodal Large Language Models (MLLMs). However, existing benchmarks for\nevaluating MLLM geometry skills overlook auxiliary line construction and lack\nfine-grained process evaluation, making them insufficient for assessing MLLMs'\nlong-step reasoning abilities. To bridge these gaps, we present the GeoLaux\nbenchmark, comprising 2,186 geometry problems, incorporating both calculation\nand proving questions. Notably, the problems require an average of 6.51\nreasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary\nline construction. Building on the dataset, we design a novel five-dimensional\nevaluation strategy assessing answer correctness, process correctness, process\nquality, auxiliary line impact, and error causes. Extensive experiments on 13\nleading MLLMs (including thinking models and non-thinking models) yield three\npivotal findings: First, models exhibit substantial performance degradation in\nextended reasoning steps (nine models demonstrate over 50% performance drop).\nSecond, compared to calculation problems, MLLMs tend to take shortcuts when\nsolving proving problems. Third, models lack auxiliary line awareness, and\nenhancing this capability proves particularly beneficial for overall geometry\nreasoning improvement. These findings establish GeoLaux as both a benchmark for\nevaluating MLLMs' long-step geometric reasoning with auxiliary lines and a\nguide for capability advancement. Our dataset and code are included in\nsupplementary materials and will be released.", "published": "2025-08-08 11:11:37", "link": "http://arxiv.org/abs/2508.06226v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution", "abstract": "Large Language Models (LLMs) are widely used as automated judges, where\npractical value depends on both accuracy and trustworthy, risk-aware judgments.\nExisting approaches predominantly focus on accuracy, overlooking the necessity\nof well-calibrated confidence, which is vital for adaptive and reliable\nevaluation pipelines. In this work, we advocate a shift from accuracy-centric\nevaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing\nthe necessity of well-calibrated confidence for trustworthy and adaptive\nevaluation. We systematically identify the **Overconfidence Phenomenon** in\ncurrent LLM-as-a-Judges, where predicted confidence significantly overstates\nactual correctness, undermining reliability in practical deployment. To\nquantify this phenomenon, we introduce **TH-Score**, a novel metric measuring\nconfidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an\nensemble framework that transforms LLMs into reliable, risk-aware evaluators.\nExtensive experiments demonstrate that our approach substantially improves\ncalibration and enables adaptive, confidence-driven evaluation pipelines,\nachieving superior reliability and accuracy compared to existing baselines.", "published": "2025-08-08 11:11:22", "link": "http://arxiv.org/abs/2508.06225v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reparameterization Proximal Policy Optimization", "abstract": "Reparameterization policy gradient (RPG) is promising for improving sample\nefficiency by leveraging differentiable dynamics. However, a critical barrier\nis its training instability, where high-variance gradients can destabilize the\nlearning process. To address this, we draw inspiration from Proximal Policy\nOptimization (PPO), which uses a surrogate objective to enable stable sample\nreuse in the model-free setting. We first establish a connection between this\nsurrogate objective and RPG, which has been largely unexplored and is\nnon-trivial. Then, we bridge this gap by demonstrating that the\nreparameterization gradient of a PPO-like surrogate objective can be computed\nefficiently using backpropagation through time. Based on this key insight, we\npropose Reparameterization Proximal Policy Optimization (RPO), a stable and\nsample-efficient RPG-based method. RPO enables multiple epochs of stable sample\nreuse by optimizing a clipped surrogate objective tailored for RPG, while being\nfurther stabilized by Kullback-Leibler (KL) divergence regularization and\nremaining fully compatible with existing variance reduction methods. We\nevaluate RPO on a suite of challenging locomotion and manipulation tasks, where\nexperiments demonstrate that our method achieves superior sample efficiency and\nstrong performance.", "published": "2025-08-08 10:50:55", "link": "http://arxiv.org/abs/2508.06214v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph Federated Learning for Personalized Privacy Recommendation", "abstract": "Federated recommendation systems (FedRecs) have gained significant attention\nfor providing privacy-preserving recommendation services. However, existing\nFedRecs assume that all users have the same requirements for privacy\nprotection, i.e., they do not upload any data to the server. The approaches\noverlook the potential to enhance the recommendation service by utilizing\npublicly available user data. In real-world applications, users can choose to\nbe private or public. Private users' interaction data is not shared, while\npublic users' interaction data can be shared. Inspired by the issue, this paper\nproposes a novel Graph Federated Learning for Personalized Privacy\nRecommendation (GFed-PP) that adapts to different privacy requirements while\nimproving recommendation performance. GFed-PP incorporates the interaction data\nof public users to build a user-item interaction graph, which is then used to\nform a user relationship graph. A lightweight graph convolutional network (GCN)\nis employed to learn each user's user-specific personalized item embedding. To\nprotect user privacy, each client learns the user embedding and the scoring\nfunction locally. Additionally, GFed-PP achieves optimization of the federated\nrecommendation framework through the initialization of item embedding on\nclients and the aggregation of the user relationship graph on the server.\nExperimental results demonstrate that GFed-PP significantly outperforms\nexisting methods for five datasets, offering superior recommendation accuracy\nwithout compromising privacy. This framework provides a practical solution for\naccommodating varying privacy preferences in federated recommendation systems.", "published": "2025-08-08 10:44:33", "link": "http://arxiv.org/abs/2508.06208v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning", "abstract": "Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language\nModels (MLLMs) to incrementally learn new tasks over time. However, this\nprocess is challenged by catastrophic forgetting, where performance on\npreviously learned tasks deteriorates as the model adapts to new ones. A common\napproach to mitigate forgetting is architecture expansion, which introduces\ntask-specific modules to prevent interference. Yet, existing methods often\nexpand entire layers for each task, leading to significant parameter overhead\nand poor scalability. To overcome these issues, we introduce LoRA in LoRA\n(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in\nMLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,\napplies an additional low-rank decomposition to matrix B to minimize\ntask-specific parameters, and incorporates a cosine-regularized stability loss\nto preserve consistency in shared representations over time. Extensive\nexperiments on a diverse CVIT benchmark show that LiLoRA consistently achieves\nsuperior performance in sequential task learning while significantly improving\nparameter efficiency compared to existing approaches.", "published": "2025-08-08 10:32:38", "link": "http://arxiv.org/abs/2508.06202v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning", "abstract": "Pretrained neural networks have attracted significant interest in chemistry\nand small molecule drug design. Embeddings from these models are widely used\nfor molecular property prediction, virtual screening, and small data learning\nin molecular chemistry. This study presents the most extensive comparison of\nsuch models to date, evaluating 25 models across 25 datasets. Under a fair\ncomparison framework, we assess models spanning various modalities,\narchitectures, and pretraining strategies. Using a dedicated hierarchical\nBayesian statistical testing model, we arrive at a surprising result: nearly\nall neural models show negligible or no improvement over the baseline ECFP\nmolecular fingerprint. Only the CLAMP model, which is also based on molecular\nfingerprints, performs statistically significantly better than the\nalternatives. These findings raise concerns about the evaluation rigor in\nexisting studies. We discuss potential causes, propose solutions, and offer\npractical recommendations.", "published": "2025-08-08 10:29:24", "link": "http://arxiv.org/abs/2508.06199v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Differentially Private Federated Clustering with Random Rebalancing", "abstract": "Federated clustering aims to group similar clients into clusters and produce\none model for each cluster. Such a personalization approach typically improves\nmodel performance compared with training a single model to serve all clients,\nbut can be more vulnerable to privacy leakage. Directly applying client-level\ndifferentially private (DP) mechanisms to federated clustering could degrade\nthe utilities significantly. We identify that such deficiencies are mainly due\nto the difficulties of averaging privacy noise within each cluster (following\nstandard privacy mechanisms), as the number of clients assigned to the same\nclusters is uncontrolled. To this end, we propose a simple and effective\ntechnique, named RR-Cluster, that can be viewed as a light-weight add-on to\nmany federated clustering algorithms. RR-Cluster achieves reduced privacy noise\nvia randomly rebalancing cluster assignments, guaranteeing a minimum number of\nclients assigned to each cluster. We analyze the tradeoffs between decreased\nprivacy noise variance and potentially increased bias from incorrect\nassignments and provide convergence bounds for RR-Clsuter. Empirically, we\ndemonstrate the RR-Cluster plugged into strong federated clustering algorithms\nresults in significantly improved privacy/utility tradeoffs across both\nsynthetic and real-world datasets.", "published": "2025-08-08 09:56:47", "link": "http://arxiv.org/abs/2508.06183v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation", "abstract": "Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,\nwhich is one of the main causes of cancer-related mortality globally; hence, it\nis deemed an essential technique for the prevention and early detection of\ncolorectal cancer. The research introduces a unique multidirectional\narchitectural framework to automate polyp detection within colonoscopy images\nwhile helping resolve limited healthcare dataset sizes and annotation\ncomplexities. The research implements a comprehensive system that delivers\nsynthetic data generation through Stable Diffusion enhancements together with\ndetection and segmentation algorithms. This detection approach combines Faster\nR-CNN for initial object localization while the Segment Anything Model (SAM)\nrefines the segmentation masks. The faster R-CNN detection algorithm achieved a\nrecall of 93.08% combined with a precision of 88.97% and an F1 score of\n90.98%.SAM is then used to generate the image mask. The research evaluated five\nstate-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,\nand MANet using ResNet34 as a base model. The results demonstrate the superior\nperformance of FPN with the highest scores of PSNR (7.205893) and SSIM\n(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced\nperformance in IoU (64.20%) and Dice score (77.53%).", "published": "2025-08-08 09:37:03", "link": "http://arxiv.org/abs/2508.06170v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting", "abstract": "Underwater 3D scene reconstruction faces severe challenges from light\nabsorption, scattering, and turbidity, which degrade geometry and color\nfidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF\nextensions such as SeaThru-NeRF incorporate physics-based models, their MLP\nreliance limits efficiency and spatial resolution in hazy environments. We\nintroduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for\nrobust underwater reconstruction. Key innovations include: (1) a plug-and-play\nlearnable underwater image formation module using voxel-based regression for\nspatially varying attenuation and backscatter; and (2) a Physics-Aware\nUncertainty Pruning (PAUP) branch that adaptively removes noisy floating\nGaussians via uncertainty scoring, ensuring artifact-free geometry. The\npipeline operates in training and rendering stages. During training, noisy\nGaussians are optimized end-to-end with underwater parameters, guided by PAUP\npruning and scattering modeling. In rendering, refined Gaussians produce clean\nUnattenuated Radiance Images (URIs) free from media effects, while learned\nphysics enable realistic Underwater Images (UWIs) with accurate light\ntransport. Experiments on SeaThru-NeRF and UWBundle datasets show superior\nperformance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on\nSeaThru-NeRF, with ~65% reduction in floating artifacts.", "published": "2025-08-08 09:36:32", "link": "http://arxiv.org/abs/2508.06169v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Semantic Item Graph Enhancement for Multimodal Recommendation", "abstract": "Multimodal recommendation systems have attracted increasing attention for\ntheir improved performance by leveraging items' multimodal information. Prior\nmethods often build modality-specific item-item semantic graphs from raw\nmodality features and use them as supplementary structures alongside the\nuser-item interaction graph to enhance user preference learning. However, these\nsemantic graphs suffer from semantic deficiencies, including (1) insufficient\nmodeling of collaborative signals among items and (2) structural distortions\nintroduced by noise in raw modality features, ultimately compromising\nperformance. To address these issues, we first extract collaborative signals\nfrom the interaction graph and infuse them into each modality-specific item\nsemantic graph to enhance semantic modeling. Then, we design a modulus-based\npersonalized embedding perturbation mechanism that injects perturbations with\nmodulus-guided personalized intensity into embeddings to generate contrastive\nviews. This enables the model to learn noise-robust representations through\ncontrastive learning, thereby reducing the effect of structural noise in\nsemantic graphs. Besides, we propose a dual representation alignment mechanism\nthat first aligns multiple semantic representations via a designed Anchor-based\nInfoNCE loss using behavior representations as anchors, and then aligns\nbehavior representations with the fused semantics by standard InfoNCE, to\nensure representation consistency. Extensive experiments on four benchmark\ndatasets validate the effectiveness of our framework.", "published": "2025-08-08 09:20:50", "link": "http://arxiv.org/abs/2508.06154v1", "categories": ["cs.IR", "cs.AI", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications", "abstract": "The versatility of large language models (LLMs) has been explored across\nvarious sectors, but their application in healthcare poses challenges,\nparticularly in the domain of pharmaceutical contraindications where accurate\nand reliable information is required. This study enhances the capability of\nLLMs to address contraindications effectively by implementing a Retrieval\nAugmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base\nmodel, and the text-embedding-3-small model for embeddings, our approach\nintegrates Langchain to orchestrate a hybrid retrieval system with re-ranking.\nThis system leverages Drug Utilization Review (DUR) data from public databases,\nfocusing on contraindications for specific age groups, pregnancy, and\nconcomitant drug use. The dataset includes 300 question-answer pairs across\nthree categories, with baseline model accuracy ranging from 0.49 to 0.57.\nPost-integration of the RAG pipeline, we observed a significant improvement in\nmodel accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications\nrelated to age groups, pregnancy, and concomitant drug use, respectively. The\nresults indicate that augmenting LLMs with a RAG framework can substantially\nreduce uncertainty in prescription and drug intake decisions by providing more\nprecise and reliable drug contraindication information.", "published": "2025-08-08 09:09:03", "link": "http://arxiv.org/abs/2508.06145v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation", "abstract": "We propose a novel 3D gaze redirection framework that leverages an explicit\n3D eyeball structure. Existing gaze redirection methods are typically based on\nneural radiance fields, which employ implicit neural representations via volume\nrendering. Unlike these NeRF-based approaches, where the rotation and\ntranslation of 3D representations are not explicitly modeled, we introduce a\ndedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian\nSplatting (3DGS). Our method generates photorealistic images that faithfully\nreproduce the desired gaze direction by explicitly rotating and translating the\n3D eyeball structure. In addition, we propose an adaptive deformation module\nthat enables the replication of subtle muscle movements around the eyes.\nThrough experiments conducted on the ETH-XGaze dataset, we demonstrate that our\nframework is capable of generating diverse novel gaze images, achieving\nsuperior image quality and gaze estimation accuracy compared to previous\nstate-of-the-art methods.", "published": "2025-08-08 08:56:51", "link": "http://arxiv.org/abs/2508.06136v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLM Serving Optimization with Variable Prefill and Decode Lengths", "abstract": "We study the problem of serving LLM (Large Language Model) requests where\neach request has heterogeneous prefill and decode lengths. In LLM serving, the\nprefill length corresponds to the input prompt length, which determines the\ninitial memory usage in the KV cache. The decode length refers to the number of\noutput tokens generated sequentially, with each additional token increasing the\nKV cache memory usage by one unit. Given a set of n requests, our goal is to\nschedule and process them to minimize the total completion time. We show that\nthis problem is NP-hard due to the interplay of batching, placement\nconstraints, precedence relationships, and linearly increasing memory usage. We\nthen analyze commonly used scheduling strategies in practice, such as\nFirst-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their\ncompetitive ratios scale up sublinearly with the memory limit-a significant\ndrawback in real-world settings where memory demand is large. To address this,\nwe propose a novel algorithm based on a new selection metric that efficiently\nforms batches over time. We prove that this algorithm achieves a constant\ncompetitive ratio. Finally, we develop and evaluate a few algorithm variants\ninspired by this approach, including dynamic programming variants, local search\nmethods, and an LP-based scheduler, demonstrating through comprehensive\nsimulations that they outperform standard baselines while maintaining\ncomputational efficiency.", "published": "2025-08-08 08:54:21", "link": "http://arxiv.org/abs/2508.06133v1", "categories": ["math.OC", "cs.AI", "cs.LG"], "primary_category": "math.OC"}
{"title": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem", "abstract": "The Vehicle Routing Problem (VRP) is a complex optimization problem with\nnumerous real-world applications, mostly solved using metaheuristic algorithms\ndue to its $\\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely\non human-crafted designs developed through empirical studies. However, recent\nresearch shows that machine learning methods can be used the structural\ncharacteristics of solutions in combinatorial optimization, thereby aiding in\ndesigning more efficient algorithms, particularly for solving VRP. Building on\nthis advancement, this study extends the previous research by conducting a\nsensitivity analysis using multiple classifier models that are capable of\npredicting the quality of VRP solutions. Hence, by leveraging explainable AI,\nthis research is able to extend the understanding of how these models make\ndecisions. Finally, our findings indicate that while feature importance varies,\ncertain features consistently emerge as strong predictors. Furthermore, we\npropose a unified framework able of ranking feature impact across different\nscenarios to illustrate this finding. These insights highlight the potential of\nfeature importance analysis as a foundation for developing a guidance mechanism\nof metaheuristic algorithms for solving the VRP.", "published": "2025-08-08 08:50:03", "link": "http://arxiv.org/abs/2508.06129v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges", "abstract": "Evaluating the capabilities and risks of foundation models is paramount, yet\ncurrent methods demand extensive domain expertise, hindering their scalability\nas these models rapidly evolve. We introduce SKATE: a novel evaluation\nframework in which large language models (LLMs) compete by generating and\nsolving verifiable tasks for one another. Our core insight is to treat\nevaluation as a game: models act as both task-setters and solvers, incentivized\nto create questions which highlight their own strengths while exposing others'\nweaknesses. SKATE offers several key advantages, balancing scalability,\nopen-endedness, and objectivity. It is fully automated, data-free, and\nscalable, requiring no human input or domain expertise. By using verifiable\ntasks rather than LLM judges, scoring is objective. Unlike domain-limited\nprogrammatically-generated benchmarks (e.g. chess-playing or spatial\nreasoning), having LLMs creatively pose challenges enables open-ended and\nscalable evaluation. As a proof of concept, we introduce LLM-set\ncode-output-prediction (COP) challenges as a verifiable and extensible\nframework in which to test our approach. Using a TrueSkill-based ranking\nsystem, we evaluate six frontier LLMs and find that: (1) weaker models can\nreliably differentiate and score stronger ones, (2) LLM-based systems are\ncapable of self-preferencing behavior, generating questions that align with\ntheir own capabilities, and (3) SKATE automatically surfaces fine-grained\ncapability differences between models. Our findings are an important step\ntowards general, scalable evaluation frameworks which can keep pace with LLM\nprogress.", "published": "2025-08-08 08:16:40", "link": "http://arxiv.org/abs/2508.06111v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FMCE-Net++: Feature Map Convergence Evaluation and Training", "abstract": "Deep Neural Networks (DNNs) face interpretability challenges due to their\nopaque internal representations. While Feature Map Convergence Evaluation\n(FMCE) quantifies module-level convergence via Feature Map Convergence Scores\n(FMCS), it lacks experimental validation and closed-loop integration. To\naddress this limitation, we propose FMCE-Net++, a novel training framework that\nintegrates a pretrained, frozen FMCE-Net as an auxiliary head. This module\ngenerates FMCS predictions, which, combined with task labels, jointly supervise\nbackbone optimization through a Representation Auxiliary Loss. The RAL\ndynamically balances the primary classification loss and feature convergence\noptimization via a tunable \\Representation Abstraction Factor. Extensive\nexperiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100\ndemonstrate that FMCE-Net++ consistently enhances model performance without\narchitectural modifications or additional data. Key experimental outcomes\ninclude accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp\n(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate\nstate-of-the-art performance ceilings.", "published": "2025-08-08 08:15:26", "link": "http://arxiv.org/abs/2508.06109v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning", "abstract": "Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a\nfundamental challenge in reinforcement learning. While hindsight experience\nreplay (HER) has shown promise by relabeling collected trajectories with\nachieved goals, we argue that trajectory relabeling alone does not fully\nexploit the available experiences in off-policy GCRL methods, resulting in\nlimited sample efficiency. In this paper, we propose Hindsight Goal-conditioned\nRegularization (HGR), a technique that generates action regularization priors\nbased on hindsight goals. When combined with hindsight self-imitation\nregularization (HSR), our approach enables off-policy RL algorithms to maximize\nexperience utilization. Compared to existing GCRL methods that employ HER and\nself-imitation techniques, our hindsight regularizations achieve substantially\nmore efficient sample reuse and the best performances, which we empirically\ndemonstrate on a suite of navigation and manipulation tasks.", "published": "2025-08-08 08:12:14", "link": "http://arxiv.org/abs/2508.06108v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "abstract": "Recognizing handwritten mathematical expressions (HMER) is a challenging task\ndue to the inherent two-dimensional structure, varying symbol scales, and\ncomplex spatial relationships among symbols. In this paper, we present a\nself-supervised learning (SSL) framework for HMER that eliminates the need for\nexpensive labeled data. Our approach begins by pretraining an image encoder\nusing a combination of global and local contrastive loss, enabling the model to\nlearn both holistic and fine-grained representations. A key contribution of\nthis work is a novel self-supervised attention network, which is trained using\na progressive spatial masking strategy. This attention mechanism is designed to\nlearn semantically meaningful focus regions, such as operators, exponents, and\nnested mathematical notation, without requiring any supervision. The\nprogressive masking curriculum encourages the network to become increasingly\nrobust to missing or occluded visual information, ultimately improving\nstructural understanding. Our complete pipeline consists of (1) self-supervised\npretraining of the encoder, (2) self-supervised attention learning, and (3)\nsupervised fine-tuning with a transformer decoder to generate LATEX sequences.\nExtensive experiments on CROHME benchmarks demonstrate that our method\noutperforms existing SSL and fully supervised baselines, validating the\neffectiveness of our progressive attention mechanism in enhancing HMER\nperformance. Our codebase can be found here.", "published": "2025-08-08 08:11:36", "link": "http://arxiv.org/abs/2508.06107v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows", "abstract": "Recent developments in diffusion- and flow- based models have significantly\nadvanced Text-to-Audio Generation (TTA). While achieving great synthesis\nquality and controllability, current TTA systems still suffer from slow\ninference speed, which significantly limits their practical applicability. This\npaper presents MeanAudio, a novel MeanFlow-based model tailored for fast and\nfaithful text-to-audio generation. Built on a Flux-style latent transformer,\nMeanAudio regresses the average velocity field during training, enabling fast\ngeneration by mapping directly from the start to the endpoint of the flow\ntrajectory. By incorporating classifier-free guidance (CFG) into the training\ntarget, MeanAudio incurs no additional cost in the guided sampling process. To\nfurther stabilize training, we propose an instantaneous-to-mean curriculum with\nflow field mix-up, which encourages the model to first learn the foundational\ninstantaneous dynamics, and then gradually adapt to mean flows. This strategy\nproves critical for enhancing training efficiency and generation quality.\nExperimental results demonstrate that MeanAudio achieves state-of-the-art\nperformance in single-step audio generation. Specifically, it achieves a real\ntime factor (RTF) of 0.013 on a single NVIDIA RTX 3090, yielding a 100x speedup\nover SOTA diffusion-based TTA systems. Moreover, MeanAudio also demonstrates\nstrong performance in multi-step generation, enabling smooth and coherent\ntransitions across successive synthesis steps.", "published": "2025-08-08 07:49:59", "link": "http://arxiv.org/abs/2508.06098v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "Bounding Distributional Shifts in World Modeling through Novelty Detection", "abstract": "Recent work on visual world models shows significant promise in latent state\ndynamics obtained from pre-trained image backbones. However, most of the\ncurrent approaches are sensitive to training quality, requiring near-complete\ncoverage of the action and state space during training to prevent divergence\nduring inference. To make a model-based planning algorithm more robust to the\nquality of the learned world model, we propose in this work to use a\nvariational autoencoder as a novelty detector to ensure that proposed action\ntrajectories during planning do not cause the learned model to deviate from the\ntraining data distribution. To evaluate the effectiveness of this approach, a\nseries of experiments in challenging simulated robot environments was carried\nout, with the proposed method incorporated into a model-predictive control\npolicy loop extending the DINO-WM architecture. The results clearly show that\nthe proposed method improves over state-of-the-art solutions in terms of data\nefficiency.", "published": "2025-08-08 07:42:14", "link": "http://arxiv.org/abs/2508.06096v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2", "abstract": "In recent years, there has been growing interest in understanding the\nexpressive power of graph neural networks (GNNs) by relating them to logical\nlanguages. This research has been been initialised by an influential result of\nBarcel\\'o et al. (2020), who showed that the graded modal logic (or a guarded\nfragment of the logic C2), characterises the logical expressiveness of\naggregate-combine GNNs. As a ``challenging open problem'' they left the\nquestion whether full C2 characterises the logical expressiveness of\naggregate-combine-readout GNNs. This question has remained unresolved despite\nseveral attempts. In this paper, we solve the above open problem by proving\nthat the logical expressiveness of aggregate-combine-readout GNNs strictly\nexceeds that of C2. This result holds over both undirected and directed graphs.\nBeyond its implications for GNNs, our work also leads to purely logical\ninsights on the expressive power of infinitary logics.", "published": "2025-08-08 07:35:35", "link": "http://arxiv.org/abs/2508.06091v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards MR-Based Trochleoplasty Planning", "abstract": "To treat Trochlear Dysplasia (TD), current approaches rely mainly on\nlow-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.\nThe surgeries are planned based on surgeons experience, have limited adoption\nof minimally invasive techniques, and lead to inconsistent outcomes. We propose\na pipeline that generates super-resolved, patient-specific 3D pseudo-healthy\ntarget morphologies from conventional clinical MR scans. First, we compute an\nisotropic super-resolved MR volume using an Implicit Neural Representation\n(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label\ncustom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to\ngenerate pseudo-healthy target morphologies of the trochlear region. In\ncontrast to prior work producing pseudo-healthy low-resolution 3D MR images,\nour approach enables the generation of sub-millimeter resolved 3D shapes\ncompatible for pre- and intraoperative use. These can serve as preoperative\nblueprints for reshaping the femoral groove while preserving the native patella\narticulation. Furthermore, and in contrast to other work, we do not require a\nCT for our pipeline - reducing the amount of radiation. We evaluated our\napproach on 25 TD patients and could show that our target morphologies\nsignificantly improve the sulcus angle (SA) and trochlear groove depth (TGD).\nThe code and interactive visualization are available at\nhttps://wehrlimi.github.io/sr-3d-planning/.", "published": "2025-08-08 07:15:23", "link": "http://arxiv.org/abs/2508.06076v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception", "abstract": "Autonomous driving systems face significant challenges in perceiving complex\nenvironments and making real-time decisions. Traditional modular approaches,\nwhile offering interpretability, suffer from error propagation and coordination\nissues, whereas end-to-end learning systems can simplify the design but face\ncomputational bottlenecks. This paper presents a novel approach to autonomous\ndriving using deep reinforcement learning (DRL) that integrates bird's-eye view\n(BEV) perception for enhanced real-time decision-making. We introduce the\n\\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction\nnetwork that combines BEV-based perception with the Mamba framework for\ntemporal feature modeling. This integration allows the system to encode vehicle\nsurroundings and road features in a unified coordinate system and accurately\nmodel long-range dependencies. Building on this, we propose the\n\\texttt{ME$^3$-BEV} framework, which utilizes the \\texttt{Mamba-BEV} model as a\nfeature input for end-to-end DRL, achieving superior performance in dynamic\nurban driving scenarios. We further enhance the interpretability of the model\nby visualizing high-dimensional features through semantic segmentation,\nproviding insight into the learned representations. Extensive experiments on\nthe CARLA simulator demonstrate that \\texttt{ME$^3$-BEV} outperforms existing\nmodels across multiple metrics, including collision rate and trajectory\naccuracy, offering a promising solution for real-time autonomous driving.", "published": "2025-08-08 07:13:28", "link": "http://arxiv.org/abs/2508.06074v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "abstract": "Evaluating the abilities of large models and manifesting their gaps are\nchallenging. Current benchmarks adopt either ground-truth-based score-form\nevaluation on static datasets or indistinct textual chatbot-style human\npreferences collection, which may not provide users with immediate, intuitive,\nand perceptible feedback on performance differences. In this paper, we\nintroduce BioMotion Arena, a novel framework for evaluating large language\nmodels (LLMs) and multimodal large language models (MLLMs) via visual\nanimation. Our methodology draws inspiration from the inherent visual\nperception of motion patterns characteristic of living organisms that utilizes\npoint-light source imaging to amplify the performance discrepancies between\nmodels. Specifically, we employ a pairwise comparison evaluation and collect\nmore than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion\nvariants. Data analyses show that the crowd-sourced human votes are in good\nagreement with those of expert raters, demonstrating the superiority of our\nBioMotion Arena in offering discriminative feedback. We also find that over\n90\\% of evaluated models, including the cutting-edge open-source InternVL3 and\nproprietary Claude-4 series, fail to produce fundamental humanoid point-light\ngroups, much less smooth and biologically plausible motions. This enables\nBioMotion Arena to serve as a challenging benchmark for performance\nvisualization and a flexible evaluation framework without restrictions on\nground-truth.", "published": "2025-08-08 07:10:17", "link": "http://arxiv.org/abs/2508.06072v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology", "abstract": "Deep temporal architectures such as Temporal Convolutional Networks (TCNs)\nachieve strong predictive performance on sequential data, yet theoretical\nunderstanding of their generalization remains limited. We address this gap by\nproviding both the first non-vacuous, architecture-aware generalization bounds\nfor deep temporal models and a principled evaluation methodology.\n  For exponentially $\\beta$-mixing sequences, we derive bounds scaling as $\nO\\!\\Bigl(R\\,\\sqrt{\\tfrac{D\\,p\\,n\\,\\log N}{N}}\\Bigr), $ where $D$ is network\ndepth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our\ndelayed-feedback blocking mechanism transforms dependent samples into\neffectively independent ones while discarding only $O(1/\\log N)$ of the data,\nyielding $\\sqrt{D}$ scaling instead of exponential, implying that doubling\ndepth requires approximately quadrupling the training data.\n  We also introduce a fair-comparison methodology that fixes the effective\nsample size to isolate the effect of temporal structure from information\ncontent. Under $N_{\\text{eff}}=2{,}000$, strongly dependent sequences\n($\\rho=0.8$) exhibit $\\approx76\\%$ smaller generalization gaps than weakly\ndependent ones ($\\rho=0.2$), challenging the intuition that dependence is\npurely detrimental. Yet convergence rates diverge from theory: weak\ndependencies follow $N_{\\text{eff}}^{-1.21}$ scaling and strong dependencies\nfollow $N_{\\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.\nThese findings reveal that temporal dependence can enhance learning under fixed\ninformation budgets, while highlighting gaps between theory and practice that\nmotivate future research.", "published": "2025-08-08 06:57:49", "link": "http://arxiv.org/abs/2508.06066v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Generic Complete Anytime Beam Search for Optimal Decision Tree", "abstract": "Finding an optimal decision tree that minimizes classification error is known\nto be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic\nprogramming guarantee optimality, they often suffer from poor anytime behavior\n-- meaning they struggle to find high-quality decision trees quickly when the\nsearch is stopped before completion -- due to unbalanced search space\nexploration. To address this, several anytime extensions of exact methods have\nbeen proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not\nbeen systematically compared, making it difficult to assess their relative\neffectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and\nanytime beam search algorithm that extends the DL8.5 framework and unifies some\nexisting anytime strategies. In particular, CA-DL8.5 generalizes previous\napproaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various\nheuristics and relaxation mechanisms through a modular design. The algorithm\nreuses DL8.5's efficient branch-and-bound pruning and trie-based caching,\ncombined with a restart-based beam search that gradually relaxes pruning\ncriteria to improve solution quality over time. Our contributions are twofold:\n(1) We introduce this new generic framework for exact and anytime decision tree\nlearning, enabling the incorporation of diverse heuristics and search\nstrategies; (2) We conduct a rigorous empirical comparison of several\ninstantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k\nheuristics -- using an anytime evaluation metric called the primal gap\nintegral. Experimental results on standard classification benchmarks show that\nCA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime\nperformance, outperforming both other CA-DL8.5 variants and the Blossom\nalgorithm while maintaining completeness and optimality guarantees.", "published": "2025-08-08 06:53:50", "link": "http://arxiv.org/abs/2508.06064v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Don't Forget Imagination!", "abstract": "Cognitive imagination is a type of imagination that plays a key role in human\nthinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to\nmentally visualize coherent and holistic systems of concepts and causal links\nthat serve as semantic contexts for reasoning, decision making and prediction.\nOur position is that the role of cognitive imagination is still greatly\nunderestimated, and this creates numerous problems and diminishes the current\ncapabilities of AI. For instance, when reasoning, humans rely on imaginary\ncontexts to retrieve background info. They also constantly return to the\ncontext for semantic verification that their reasoning is still reasonable.\nThus, reasoning without imagination is blind. This paper is a call for greater\nattention to cognitive imagination as the next promising breakthrough in\nartificial intelligence. As an instrument for simulating cognitive imagination,\nwe propose semantic models -- a new approach to mathematical models that can\nlearn, like neural networks, and are based on probabilistic causal\nrelationships. Semantic models can simulate cognitive imagination because they\nensure the consistency of imaginary contexts and implement a glass-box approach\nthat allows the context to be manipulated as a holistic and coherent system of\ninterrelated facts glued together with causal relations.", "published": "2025-08-08 06:50:43", "link": "http://arxiv.org/abs/2508.06062v1", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 68T30"], "primary_category": "cs.AI"}
{"title": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences", "abstract": "Large Language Models (LLMs) are increasingly expected to handle complex\ndecision-making tasks, yet their ability to perform structured resource\nallocation remains underexplored. Evaluating their reasoning is also difficult\ndue to data contamination and the static nature of existing benchmarks. We\npresent a dual-purpose framework leveraging Participatory Budgeting (PB) both\nas (i) a practical setting for LLM-based resource allocation and (ii) an\nadaptive benchmark for evaluating their reasoning capabilities. We task LLMs\nwith selecting project subsets under feasibility (e.g., budget) constraints via\nthree prompting strategies: greedy selection, direct optimization, and a\nhill-climbing-inspired refinement. We benchmark LLMs' allocations against a\nutility-maximizing oracle. Interestingly, we also test whether LLMs can infer\nstructured preferences from natural-language voter input or metadata, without\nexplicit votes. By comparing allocations based on inferred preferences to those\nfrom ground-truth votes, we evaluate LLMs' ability to extract preferences from\nopen-ended input. Our results underscore the role of prompt design and show\nthat LLMs hold promise for mechanism design with unstructured inputs.", "published": "2025-08-08 06:45:07", "link": "http://arxiv.org/abs/2508.06060v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning", "abstract": "Large Language Models (LLMs) have recently demonstrated impressive action\nsequence prediction capabilities but often struggle with dynamic, long-horizon\ntasks such as real-time strategic games. In a game such as StarCraftII (SC2),\nagents need to manage resource constraints and adapt to evolving battlefield\nsituations in a partially observable environment. This often overwhelms\nexisiting LLM-based approaches. To address these challenges, we propose a\nhierarchical multi-agent framework that employs specialized imitation learning\nagents under a meta-controller called Strategic Planner (SP). By expert\ndemonstrations, each specialized agent learns a distinctive strategy, such as\naerial support or defensive maneuvers, and produces coherent, structured\nmultistep action sequences. The SP then orchestrates these proposals into a\nsingle, environmentally adaptive plan that ensures local decisions aligning\nwith long-term strategies. We call this HIMA (Hierarchical Imitation\nMulti-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that\nencompasses all race match combinations in SC2. Our empirical results show that\nHIMA outperforms state of the arts in strategic clarity, adaptability, and\ncomputational efficiency, underscoring the potential of combining specialized\nimitation modules with meta-level orchestration to develop more robust,\ngeneral-purpose AI agents.", "published": "2025-08-08 05:57:12", "link": "http://arxiv.org/abs/2508.06042v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "abstract": "How can we effectively handle queries for on-device large language models\n(LLMs) with varying runtime constraints, such as latency and accuracy?\nMulti-scale quantization addresses this challenge by enabling memory-efficient\nruntime model adaptation of LLMs through the overlaying of multiple model\nvariants quantized to different bitwidths. Meanwhile, an important question\nstill remains open-ended: how can models be properly configured to match a\ntarget precision or latency? While mixed-precision offers a promising solution,\nwe take this further by leveraging the key observation that the sensitivity of\neach layer dynamically changes across decoding iterations. Building on this\ninsight, we introduce DP-LLM, a novel mechanism that dynamically assigns\nprecision to each layer based on input values. DP-LLM augments each linear\nlayer in an LLM with a precision selector that determines the bitwidth at\nruntime using a lightweight error estimator and threshold values learned\nthrough fine-tuning. Experimental results across multiple models and benchmarks\ndemonstrate that DP-LLM achieves a superior performance-latency trade-off,\noutperforming prior approaches.", "published": "2025-08-08 05:57:04", "link": "http://arxiv.org/abs/2508.06041v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models", "abstract": "Vision-Language Models (VLMs) typically replace the predefined image\nplaceholder token (<image>) in textual instructions with visual features from\nan image encoder, forming the input to a backbone Large Language Model (LLM).\nHowever, the large number of vision tokens significantly increases the context\nlength, leading to high computational overhead and inference latency. While\nprevious efforts mitigate this by selecting only important visual features or\nleveraging learnable queries to reduce token count, they often compromise\nperformance or introduce substantial extra costs. In response, we propose\nFourier-VLM, a simple yet efficient method that compresses visual\nrepresentations in the frequency domain. Our approach is motivated by the\nobservation that vision features output from the vision encoder exhibit\nconcentrated energy in low-frequency components. Leveraging this, we apply a\nlow-pass filter to the vision features using a two-dimentional Discrete Cosine\nTransform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier\nTransform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$,\nminimizing the extra computational cost while introducing no additional\nparameters. Extensive experiments across various image-based benchmarks\ndemonstrate that Fourier-VLM achieves competitive performance with strong\ngeneralizability across both LLaVA and Qwen-VL architectures. Crucially, it\nreduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%\ncompared to LLaVA-v1.5, highlighting the superior efficiency and practicality.", "published": "2025-08-08 05:49:42", "link": "http://arxiv.org/abs/2508.06038v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity", "abstract": "Heterogeneous graphs (HGs) are common in real-world scenarios and often\nexhibit heterophily. However, most existing studies focus on either\nheterogeneity or heterophily in isolation, overlooking the prevalence of\nheterophilic HGs in practical applications. Such ignorance leads to their\nperformance degradation. In this work, we first identify two main challenges in\nmodeling heterophily HGs: (1) varying heterophily distributions across hops and\nmeta-paths; (2) the intricate and often heterophily-driven diversity of\nsemantic information across different meta-paths. Then, we propose the Adaptive\nHeterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN\nemploys a heterophily-aware convolution that accounts for heterophily\ndistributions specific to both hops and meta-paths. It then integrates messages\nfrom diverse semantic spaces using a coarse-to-fine attention mechanism, which\nfilters out noise and emphasizes informative signals. Experiments on seven\nreal-world graphs and twenty baselines demonstrate the superior performance of\nAHGNN, particularly in high-heterophily situations.", "published": "2025-08-08 05:39:58", "link": "http://arxiv.org/abs/2508.06034v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis", "abstract": "Sub-visible particle analysis using flow imaging microscopy combined with\ndeep learning has proven effective in identifying particle types, enabling the\ndistinction of harmless components such as silicone oil from protein particles.\nHowever, the scarcity of available data and severe imbalance between particle\ntypes within datasets remain substantial hurdles when applying multi-class\nclassifiers to such problems, often forcing researchers to rely on less\neffective methods. The aforementioned issue is particularly challenging for\nparticle types that appear unintentionally and in lower numbers, such as\nsilicone oil and air bubbles, as opposed to protein particles, where obtaining\nlarge numbers of images through controlled settings is comparatively\nstraightforward. In this work, we develop a state-of-the-art diffusion model to\naddress data imbalance by generating high-fidelity images that can augment\ntraining datasets, enabling the effective training of multi-class deep neural\nnetworks. We validate this approach by demonstrating that the generated samples\nclosely resemble real particle images in terms of visual quality and structure.\nTo assess the effectiveness of using diffusion-generated images in training\ndatasets, we conduct large-scale experiments on a validation dataset comprising\n500,000 protein particle images and demonstrate that this approach improves\nclassification performance with no negligible downside. Finally, to promote\nopen research and reproducibility, we publicly release both our diffusion\nmodels and the trained multi-class deep neural network classifiers, along with\na straightforward interface for easy integration into future studies, at\nhttps://github.com/utkuozbulak/svp-generative-ai.", "published": "2025-08-08 05:15:02", "link": "http://arxiv.org/abs/2508.06021v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning", "abstract": "Operational skill learning, inherently physical and reliant on hands-on\npractice and kinesthetic feedback, has yet to be effectively replicated in\nlarge language model (LLM)-supported training. Current LLM training assistants\nprimarily generate customized textual feedback, neglecting the crucial\nkinesthetic modality. This gap derives from the textual and uncertain nature of\nLLMs, compounded by concerns on user acceptance of LLM driven body control. To\nbridge this gap and realize the potential of collaborative human-LLM action,\nthis work explores human experience of LLM driven kinesthetic assistance.\nSpecifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed\nFlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS)\nfor flight skill acquisition, a representative operational skill domain.\nFlightAxis learns flight skills from manuals and guides forearm movements\nduring simulated flight tasks. Our results demonstrate high user acceptance of\nLLM-mediated body control and significantly reduced task completion times.\nCrucially, trainees reported that this kinesthetic assistance enhanced their\nawareness of operation flaws and fostered increased engagement in the training\nprocess, rather than relieving perceived load. This work demonstrated the\npotential of kinesthetic LLM training in operational skill acquisition.", "published": "2025-08-08 04:05:47", "link": "http://arxiv.org/abs/2508.06000v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making", "abstract": "Complex medical decision-making involves cooperative workflows operated by\ndifferent clinicians. Designing AI multi-agent systems can expedite and augment\nhuman-level clinical decision-making. Existing multi-agent researches primarily\nfocus on language-only tasks, yet their extension to multimodal scenarios\nremains challenging. A blind combination of diverse vision-language models\n(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are\nless capable in instruction following and importantly self-reflection, compared\nto large language models (LLMs) of comparable sizes. This disparity largely\nconstrains VLMs' ability in cooperative workflows. In this study, we propose\nMedOrch, a mediator-guided multi-agent collaboration framework for medical\nmultimodal decision-making. MedOrch employs an LLM-based mediator agent that\nenables multiple VLM-based expert agents to exchange and reflect on their\noutputs towards collaboration. We utilize multiple open-source general-purpose\nand domain-specific VLMs instead of costly GPT-series models, revealing the\nstrength of heterogeneous models. We show that the collaboration within\ndistinct VLM-based agents can surpass the capabilities of any individual agent.\nWe validate our approach on five medical vision question answering benchmarks,\ndemonstrating superior collaboration performance without model training. Our\nfindings underscore the value of mediator-guided multi-agent collaboration in\nadvancing medical multimodal intelligence. Our code will be made publicly\navailable.", "published": "2025-08-08 04:02:10", "link": "http://arxiv.org/abs/2508.05996v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge", "abstract": "Emotion recognition plays a vital role in enhancing human-computer\ninteraction. In this study, we tackle the MER-SEMI challenge of the MER2025\ncompetition by proposing a novel multimodal emotion recognition framework. To\naddress the issue of data scarcity, we leverage large-scale pre-trained models\nto extract informative features from visual, audio, and textual modalities.\nSpecifically, for the visual modality, we design a dual-branch visual encoder\nthat captures both global frame-level features and localized facial\nrepresentations. For the textual modality, we introduce a context-enriched\nmethod that employs large language models to enrich emotional cues within the\ninput text. To effectively integrate these multimodal features, we propose a\nfusion strategy comprising two key components, i.e., self-attention mechanisms\nfor dynamic modality weighting, and residual connections to preserve original\nrepresentations. Beyond architectural design, we further refine noisy labels in\nthe training set by a multi-source labeling strategy. Our approach achieves a\nsubstantial performance improvement over the official baseline on the\nMER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to\n78.63%, thereby validating the effectiveness of the proposed framework.", "published": "2025-08-08 03:55:25", "link": "http://arxiv.org/abs/2508.05991v1", "categories": ["cs.CV", "cs.AI", "cs.CY"], "primary_category": "cs.CV"}
{"title": "ETA: Energy-based Test-time Adaptation for Depth Completion", "abstract": "We propose a method for test-time adaptation of pretrained depth completion\nmodels. Depth completion models, trained on some ``source'' data, often predict\nerroneous outputs when transferred to ``target'' data captured in novel\nenvironmental conditions due to a covariate shift. The crux of our method lies\nin quantifying the likelihood of depth predictions belonging to the source data\ndistribution. The challenge is in the lack of access to out-of-distribution\n(target) data prior to deployment. Hence, rather than making assumptions\nregarding the target distribution, we utilize adversarial perturbations as a\nmechanism to explore the data space. This enables us to train an energy model\nthat scores local regions of depth predictions as in- or out-of-distribution.\nWe update the parameters of pretrained depth completion models at test time to\nminimize energy, effectively aligning test-time predictions to those of the\nsource distribution. We call our method ``Energy-based Test-time Adaptation'',\nor ETA for short. We evaluate our method across three indoor and three outdoor\ndatasets, where ETA improve over the previous state-of-the-art method by an\naverage of 6.94% for outdoors and 10.23% for indoors. Project Page:\nhttps://fuzzythecat.github.io/eta.", "published": "2025-08-08 03:51:24", "link": "http://arxiv.org/abs/2508.05989v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education", "abstract": "While Large Language Models (LLMs) are often used as virtual tutors in\ncomputer science (CS) education, this approach can foster passive learning and\nover-reliance. This paper presents a novel pedagogical paradigm that inverts\nthis model: students act as instructors who must teach an LLM to solve\nproblems. To facilitate this, we developed strategies for designing questions\nwith engineered knowledge gaps that only a student can bridge, and we introduce\nSocrates, a system for deploying this method with minimal overhead. We\nevaluated our approach in an undergraduate course and found that this\nactive-learning method led to statistically significant improvements in student\nperformance compared to historical cohorts. Our work demonstrates a practical,\ncost-effective framework for using LLMs to deepen student engagement and\nmastery.", "published": "2025-08-08 03:25:19", "link": "http://arxiv.org/abs/2508.05979v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching", "abstract": "Singing Voice Conversion (SVC) transfers a source singer's timbre to a target\nwhile keeping melody and lyrics. The key challenge in any-to-any SVC is\nadapting unseen speaker timbres to source audio without quality degradation.\nExisting methods either face timbre leakage or fail to achieve satisfactory\ntimbre similarity and quality in the generated audio. To address these\nchallenges, we propose DAFMSVC, where the self-supervised learning (SSL)\nfeatures from the source audio are replaced with the most similar SSL features\nfrom the target audio to prevent timbre leakage. It also incorporates a dual\ncross-attention mechanism for the adaptive fusion of speaker embeddings,\nmelody, and linguistic content. Additionally, we introduce a flow matching\nmodule for high quality audio generation from the fused features. Experimental\nresults show that DAFMSVC significantly enhances timbre similarity and\nnaturalness, outperforming state-of-the-art methods in both subjective and\nobjective evaluations.", "published": "2025-08-08 03:24:19", "link": "http://arxiv.org/abs/2508.05978v1", "categories": ["cs.SD", "cs.AI", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Impact-driven Context Filtering For Cross-file Code Completion", "abstract": "Retrieval-augmented generation (RAG) has recently demonstrated considerable\npotential for repository-level code completion, as it integrates cross-file\nknowledge with in-file preceding code to provide comprehensive contexts for\ngeneration. To better understand the contribution of the retrieved cross-file\ncontexts, we introduce a likelihood-based metric to evaluate the impact of each\nretrieved code chunk on the completion. Our analysis reveals that, despite\nretrieving numerous chunks, only a small subset positively contributes to the\ncompletion, while some chunks even degrade performance. To address this issue,\nwe leverage this metric to construct a repository-level dataset where each\nretrieved chunk is labeled as positive, neutral, or negative based on its\nrelevance to the target completion. We then propose an adaptive retrieval\ncontext filtering framework, CODEFILTER, trained on this dataset to mitigate\nthe harmful effects of negative retrieved contexts in code completion.\nExtensive evaluation on the RepoEval and CrossCodeLongEval benchmarks\ndemonstrates that CODEFILTER consistently improves completion accuracy compared\nto approaches without filtering operations across various tasks. Additionally,\nCODEFILTER significantly reduces the length of the input prompt, enhancing\ncomputational efficiency while exhibiting strong generalizability across\ndifferent models. These results underscore the potential of CODEFILTER to\nenhance the accuracy, efficiency, and attributability of repository-level code\ncompletion.", "published": "2025-08-08 03:08:19", "link": "http://arxiv.org/abs/2508.05970v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning", "abstract": "Offline reinforcement learning (RL) seeks to learn optimal policies from\nstatic datasets without further environment interaction. A key challenge is the\ndistribution shift between the learned and behavior policies, leading to\nout-of-distribution (OOD) actions and overestimation. To prevent gross\noverestimation, the value function must remain conservative; however, excessive\nconservatism may hinder performance improvement. To address this, we propose\nthe mildly conservative regularized evaluation (MCRE) framework, which balances\nconservatism and performance by combining temporal difference (TD) error with a\nbehavior cloning term in the Bellman backup. Building on this, we develop the\nmildly conservative regularized Q-learning (MCRQ) algorithm, which integrates\nMCRE into an off-policy actor-critic framework. Experiments show that MCRQ\noutperforms strong baselines and state-of-the-art offline RL algorithms on\nbenchmark datasets.", "published": "2025-08-08 02:48:26", "link": "http://arxiv.org/abs/2508.05960v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multi-Armed Bandits-Based Optimization of Decision Trees", "abstract": "Decision trees, without appropriate constraints, can easily become overly\ncomplex and prone to overfit, capturing noise rather than generalizable\npatterns. To resolve this problem,pruning operation is a crucial part in\noptimizing decision trees, as it not only reduces the complexity of trees but\nalso decreases the probability of generating overfit models. The conventional\npruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning\n(REP) are mostly based on greedy approaches that focus on immediate gains in\nperformance while pruning nodes of the decision tree. However, this might\nresult in a lower generalization in the long run, compromising the robust\nability of the tree model when introduced to unseen data samples, particularly\nwhen trained with small and complex datasets. To address this challenge, we are\nproposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement\nlearning (RL)-based technique, that will dynamically prune the tree to generate\nan optimal decision tree with better generalization. Our proposed approach\nassumes the pruning process as an exploration-exploitation problem, where we\nare utilizing the MAB algorithms to find optimal branch nodes to prune based on\nfeedback from each pruning actions. Experimental evaluation on several\nbenchmark datasets, demonstrated that our proposed approach results in better\npredictive performance compared to the traditional ones. This suggests the\npotential of utilizing MAB for a dynamic and probabilistic way of decision tree\npruning, in turn optimizing the decision tree-based model.", "published": "2025-08-08 02:43:45", "link": "http://arxiv.org/abs/2508.05957v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image", "abstract": "The lack of spatial dimensional information remains a challenge in normal\nestimation from a single image. Recent diffusion-based methods have\ndemonstrated significant potential in 2D-to-3D implicit mapping, they rely on\ndata-driven statistical priors and miss the explicit modeling of light-surface\ninteraction, leading to multi-view normal direction conflicts. Moreover, the\ndiscrete sampling mechanism of diffusion models causes gradient discontinuity\nin differentiable rendering reconstruction modules, preventing 3D geometric\nerrors from being backpropagated to the normal generation network, thereby\nforcing existing methods to depend on dense normal annotations. This paper\nproposes SINGAD, a novel Self-supervised framework from a single Image for\nNormal estimation via 3D GAussian splatting guided Diffusion. By integrating\nphysics-driven light-interaction modeling and a differentiable rendering-based\nreprojection strategy, our framework directly converts 3D geometric errors into\nnormal optimization signals, solving the challenges of multi-view geometric\ninconsistency and data dependency. Specifically, the framework constructs a\nlight-interaction-driven 3DGS reparameterization model to generate multi-scale\ngeometric features consistent with light transport principles, ensuring\nmulti-view normal consistency. A cross-domain feature fusion module is designed\nwithin a conditional diffusion model, embedding geometric priors to constrain\nnormal generation while maintaining accurate geometric error propagation.\nFurthermore, a differentiable 3D reprojection loss strategy is introduced for\nself-supervised optimization that minimizes geometric error between the\nreconstructed and input image, eliminating dependence on annotated normal\ndatasets. Quantitative evaluations on the Google Scanned Objects dataset\ndemonstrate that our method outperforms state-of-the-art approaches across\nmultiple metrics.", "published": "2025-08-08 02:32:33", "link": "http://arxiv.org/abs/2508.05950v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection", "abstract": "Recently, multi-modal physiological signals based emotion recognition has\ngarnered increasing attention in the field of brain-computer interfaces.\nNevertheness, the associated multi-modal physiological features are often\nhigh-dimensional and inevitably include irrelevant, redundant, and noisy\nrepresentation, which can easily lead to overfitting, poor performance, and\nhigh computational complexity in emotion classifiers. Feature selection has\nbeen widely applied to address these challenges. However, previous studies\ngenerally assumed that multi-modal physiological data are complete, whereas in\nreality, the data are often incomplete due to the openness of the acquisition\nand operational environment. For example, a part of samples are available in\nseveral modalities but not in others. To address this issue, we propose a novel\nmethod for incomplete multi-modal physiological signal feature selection called\nadaptive shared latent structure learning (ASLSL). Based on the property that\nsimilar features share similar emotional labels, ASLSL employs adaptive shared\nlatent structure learning to explore a common latent space shared for\nincomplete multi-modal physiological signals and multi-dimensional emotional\nlabels, thereby mitigating the impact of missing information and mining\nconsensus information. Two most popular multi-modal physiological emotion\ndatasets (DEAP and DREAMER) with multi-dimensional emotional labels were\nutilized to compare the performance between compare ASLSL and seventeen feature\nselection methods. Comprehensive experimental results on these datasets\ndemonstrate the effectiveness of ASLSL.", "published": "2025-08-08 01:54:02", "link": "http://arxiv.org/abs/2508.05934v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition", "abstract": "The affective brain-computer interface is a crucial technology for affective\ninteraction and emotional intelligence, emerging as a significant area of\nresearch in the human-computer interaction. Compared to single-type features,\nmulti-type EEG features provide a multi-level representation for analyzing\nmulti-dimensional emotions. However, the high dimensionality of multi-type EEG\nfeatures, combined with the relatively small number of high-quality EEG\nsamples, poses challenges such as classifier overfitting and suboptimal\nreal-time performance in multi-dimensional emotion recognition. Moreover,\npractical applications of affective brain-computer interface frequently\nencounters partial absence of multi-dimensional emotional labels due to the\nopen nature of the acquisition environment, and ambiguity and variability in\nindividual emotion perception. To address these challenges, this study proposes\na novel EEG feature selection method for missing multi-dimensional emotion\nrecognition. The method leverages adaptive orthogonal non-negative matrix\nfactorization to reconstruct the multi-dimensional emotional label space\nthrough second-order and higher-order correlations, which could reduce the\nnegative impact of missing values and outliers on label reconstruction.\nSimultaneously, it employs least squares regression with graph-based manifold\nlearning regularization and global feature redundancy minimization\nregularization to enable EEG feature subset selection despite missing\ninformation, ultimately achieving robust EEG-based multi-dimensional emotion\nrecognition. Simulation experiments on three widely used multi-dimensional\nemotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method\noutperforms thirteen advanced feature selection methods in terms of robustness\nfor EEG emotional feature selection.", "published": "2025-08-08 01:53:46", "link": "http://arxiv.org/abs/2508.05933v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "abstract": "Software vulnerabilities continue to undermine the reliability and security\nof modern systems, particularly as software complexity outpaces the\ncapabilities of traditional detection methods. This study introduces a genetic\nalgorithm-based method for test input generation that innovatively integrates\ngenetic operators and adaptive learning to enhance software vulnerability\ndetection. A key contribution is the application of the crossover operator,\nwhich facilitates exploration by searching across a broader space of potential\ntest inputs. Complementing this, an adaptive feedback mechanism continuously\nlearns from the system's execution behavior and dynamically guides input\ngeneration toward promising areas of the input space. Rather than relying on\nfixed or randomly selected inputs, the approach evolves a population of\nstructurally valid test cases using feedback-driven selection, enabling deeper\nand more effective code traversal. This strategic integration of exploration\nand exploitation ensures that both diverse and targeted test inputs are\ndeveloped over time. Evaluation was conducted across nine open-source\nJSON-processing libraries. The proposed method achieved substantial\nimprovements in coverage compared to a benchmark evolutionary fuzzing method,\nwith average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%\nin line coverage, 114.0% in instruction coverage, and 166.0% in branch\ncoverage. These results highlight the method's capacity to detect deeper and\nmore complex vulnerabilities, offering a scalable and adaptive solution to\nsoftware security testing.", "published": "2025-08-08 01:03:22", "link": "http://arxiv.org/abs/2508.05923v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "LightSwitch: Multi-view Relighting with Material-guided Diffusion", "abstract": "Recent approaches for 3D relighting have shown promise in integrating 2D\nimage relighting generative priors to alter the appearance of a 3D\nrepresentation while preserving the underlying structure. Nevertheless,\ngenerative priors used for 2D relighting that directly relight from an input\nimage do not take advantage of intrinsic properties of the subject that can be\ninferred or cannot consider multi-view data at scale, leading to subpar\nrelighting. In this paper, we propose Lightswitch, a novel finetuned\nmaterial-relighting diffusion framework that efficiently relights an arbitrary\nnumber of input images to a target lighting condition while incorporating cues\nfrom inferred intrinsic properties. By using multi-view and material\ninformation cues together with a scalable denoising scheme, our method\nconsistently and efficiently relights dense multi-view data of objects with\ndiverse material compositions. We show that our 2D relighting prediction\nquality exceeds previous state-of-the-art relighting priors that directly\nrelight from images. We further demonstrate that LightSwitch matches or\noutperforms state-of-the-art diffusion inverse rendering methods in relighting\nsynthetic and real objects in as little as 2 minutes.", "published": "2025-08-08 17:59:52", "link": "http://arxiv.org/abs/2508.06494v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation", "abstract": "Recent unsupervised domain adaptation (UDA) methods have shown great success\nin addressing classical domain shifts (e.g., synthetic-to-real), but they still\nsuffer under complex shifts (e.g. geographical shift), where both the\nbackground and object appearances differ significantly across domains. Prior\nworks showed that the language modality can help in the adaptation process,\nexhibiting more robustness to such complex shifts. In this paper, we introduce\nTRUST, a novel UDA approach that exploits the robustness of the language\nmodality to guide the adaptation of a vision model. TRUST generates\npseudo-labels for target samples from their captions and introduces a novel\nuncertainty estimation strategy that uses normalised CLIP similarity scores to\nestimate the uncertainty of the generated pseudo-labels. Such estimated\nuncertainty is then used to reweight the classification loss, mitigating the\nadverse effects of wrong pseudo-labels obtained from low-quality captions. To\nfurther increase the robustness of the vision model, we propose a multimodal\nsoft-contrastive learning loss that aligns the vision and language feature\nspaces, by leveraging captions to guide the contrastive training of the vision\nmodel on target images. In our contrastive loss, each pair of images acts as\nboth a positive and a negative pair and their feature representations are\nattracted and repulsed with a strength proportional to the similarity of their\ncaptions. This solution avoids the need for hardly determining positive and\nnegative pairs, which is critical in the UDA setting. Our approach outperforms\nprevious methods, setting the new state-of-the-art on classical (DomainNet) and\ncomplex (GeoNet) domain shifts. The code will be available upon acceptance.", "published": "2025-08-08 16:51:44", "link": "http://arxiv.org/abs/2508.06452v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MotionSwap", "abstract": "Face swapping technology has gained significant attention in both academic\nresearch and commercial applications. This paper presents our implementation\nand enhancement of SimSwap, an efficient framework for high fidelity face\nswapping. We introduce several improvements to the original model, including\nthe integration of self and cross-attention mechanisms in the generator\narchitecture, dynamic loss weighting, and cosine annealing learning rate\nscheduling. These enhancements lead to significant improvements in identity\npreservation, attribute consistency, and overall visual quality.\n  Our experimental results, spanning 400,000 training iterations, demonstrate\nprogressive improvements in generator and discriminator performance. The\nenhanced model achieves better identity similarity, lower FID scores, and\nvisibly superior qualitative results compared to the baseline. Ablation studies\nconfirm the importance of each architectural and training improvement. We\nconclude by identifying key future directions, such as integrating StyleGAN3,\nimproving lip synchronization, incorporating 3D facial modeling, and\nintroducing temporal consistency for video-based applications.", "published": "2025-08-08 16:16:56", "link": "http://arxiv.org/abs/2508.06430v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification", "abstract": "SAR ship classification faces the challenge of long-tailed datasets, which\ncomplicates the classification of underrepresented classes. Oversampling\nmethods have proven effective in addressing class imbalance in optical data. In\nthis paper, we evaluated the effect of oversampling in the feature space for\nSAR ship classification. We propose two novel algorithms inspired by the\nMajor-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two\npublic datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three\nstate-of-the-art models as feature extractors: ViT, VGG16, and ResNet50.\nAdditionally, we also analyzed the impact of oversampling methods on different\nclass sizes. The results demonstrated the effectiveness of our novel methods\nover the original M2m and baselines, with an average F1-score increase of 8.82%\nfor FuSARShip and 4.44% for OpenSARShip.", "published": "2025-08-08 16:08:37", "link": "http://arxiv.org/abs/2508.06420v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation", "abstract": "Recent progress in 3D reconstruction has enabled realistic 3D models from\ndense image captures, yet challenges persist with sparse views, often leading\nto artifacts in unseen areas. Recent works leverage Video Diffusion Models\n(VDMs) to generate dense observations, filling the gaps when only sparse views\nare available for 3D reconstruction tasks. A significant limitation of these\nmethods is their slow sampling speed when using VDMs. In this paper, we present\nFVGen, a novel framework that addresses this challenge by enabling fast novel\nview synthesis using VDMs in as few as four sampling steps. We propose a novel\nvideo diffusion model distillation method that distills a multi-step denoising\nteacher model into a few-step denoising student model using Generative\nAdversarial Networks (GANs) and softened reverse KL-divergence minimization.\nExtensive experiments on real-world datasets show that, compared to previous\nworks, our framework generates the same number of novel views with similar (or\neven better) visual quality while reducing sampling time by more than 90%.\nFVGen significantly improves time efficiency for downstream reconstruction\ntasks, particularly when working with sparse input views (more than 2) where\npre-trained VDMs need to be run multiple times to achieve better spatial\ncoverage.", "published": "2025-08-08 15:22:41", "link": "http://arxiv.org/abs/2508.06392v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning", "abstract": "The integration of prompt tuning with multimodal learning has shown\nsignificant generalization abilities for various downstream tasks. Despite\nadvancements, existing methods heavily depend on massive modality-specific\nlabeled data (e.g., video, audio, and image), or are customized for a single\nmodality. In this study, we present Text as Any-Modality by Consistent Prompt\nTuning (TaAM-CPT), a scalable approach for constructing a general\nrepresentation model toward unlimited modalities using solely text data.\nTaAM-CPT comprises modality prompt pools, text construction, and\nmodality-aligned text encoders from pre-trained models, which allows for\nextending new modalities by simply adding prompt pools and modality-aligned\ntext encoders. To harmonize the learning across different modalities, TaAM-CPT\ndesigns intra- and inter-modal learning objectives, which can capture category\ndetails within modalities while maintaining semantic consistency across\ndifferent modalities. Benefiting from its scalable architecture and pre-trained\nmodels, TaAM-CPT can be seamlessly extended to accommodate unlimited\nmodalities. Remarkably, without any modality-specific labeled data, TaAM-CPT\nachieves leading results on diverse datasets spanning various modalities,\nincluding video classification, image classification, and audio classification.\nThe code is available at https://github.com/Jinx630/TaAM-CPT.", "published": "2025-08-08 15:13:05", "link": "http://arxiv.org/abs/2508.06382v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Implemention of Two-Phase Image Segmentation using the Split Bregman Method", "abstract": "In this paper, we describe an implementation of the two-phase image\nsegmentation algorithm proposed by Goldstein, Bresson, Osher in\n\\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into\nforeground and background regions, and each pixel of the image is assigned\nmembership to one of these two regions. The underlying assumption for the\nsegmentation model is that the pixel values of the input image can be\nsummarized by two distinct average values, and that the region boundaries are\nsmooth. Accordingly, the model is defined as an energy in which the variable is\na region membership function to assign pixels to either region, originally\nproposed by Chan and Vese in \\cite{chan:vese}. This energy is the sum of image\ndata terms in the regions and a length penalty for region boundaries.\nGoldstein, Bresson, Osher modify the energy of Chan-Vese in \\cite{gold:bre} so\nthat their new energy can be minimized efficiently using the split Bregman\nmethod to produce an equivalent two-phase segmentation. We provide a detailed\nimplementation of this method \\cite{gold:bre}, and document its performance\nwith several images over a range of algorithm parameters.", "published": "2025-08-08 14:30:10", "link": "http://arxiv.org/abs/2508.06351v1", "categories": ["cs.CV", "math.OC"], "primary_category": "cs.CV"}
{"title": "Aligning Effective Tokens with Video Anomaly in Large Language Models", "abstract": "Understanding abnormal events in videos is a vital and challenging task that\nhas garnered significant attention in a wide range of applications. Although\ncurrent video understanding Multi-modal Large Language Models (MLLMs) are\ncapable of analyzing general videos, they often struggle to handle anomalies\ndue to the spatial and temporal sparsity of abnormal events, where the\nredundant information always leads to suboptimal outcomes. To address these\nchallenges, exploiting the representation and generalization capabilities of\nVison Language Models (VLMs) and Large Language Models (LLMs), we propose\nVA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in\nvarious videos. Our approach efficiently aligns effective tokens between visual\nencoders and LLMs through two key proposed modules: Spatial Effective Token\nSelection (SETS) and Temporal Effective Token Generation (TETG). These modules\nenable our model to effectively capture and analyze both spatial and temporal\ninformation associated with abnormal events, resulting in more accurate\nresponses and interactions. Furthermore, we construct an instruction-following\ndataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a\ncross-domain evaluation benchmark based on XD-Violence dataset. Our proposed\nmethod outperforms existing state-of-the-art methods on various benchmarks.", "published": "2025-08-08 14:30:05", "link": "http://arxiv.org/abs/2508.06350v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities", "abstract": "Designing socially active streets has long been a goal of urban planning, yet\nexisting quantitative research largely measures pedestrian volume rather than\nthe quality of social interactions. We hypothesize that street view imagery --\nan inexpensive data source with global coverage -- contains latent social\ninformation that can be extracted and interpreted through established social\nscience theory. As a proof of concept, we analyzed 2,998 street view images\nfrom 15 cities using a multimodal large language model guided by Mehta's\ntaxonomy of passive, fleeting, and enduring sociability -- one illustrative\nexample of a theory grounded in urban design that could be substituted or\ncomplemented by other sociological frameworks. We then used linear regression\nmodels, controlling for factors like weather, time of day, and pedestrian\ncounts, to test whether the inferred sociability measures correlate with\ncity-level place attachment scores from the World Values Survey and with\nenvironmental predictors (e.g., green, sky, and water view indices) derived\nfrom individual street view images. Results aligned with long-standing urban\nplanning theory: the sky view index was associated with all three sociability\ntypes, the green view index predicted enduring sociability, and place\nattachment was positively associated with fleeting sociability. These results\nprovide preliminary evidence that street view images can be used to infer\nrelationships between specific types of social interactions and built\nenvironment variables. Further research could establish street view imagery as\na scalable, privacy-preserving tool for studying urban sociability, enabling\ncross-cultural theory testing and evidence-based design of socially vibrant\ncities.", "published": "2025-08-08 14:15:58", "link": "http://arxiv.org/abs/2508.06342v1", "categories": ["cs.CV", "cs.SI"], "primary_category": "cs.CV"}
{"title": "ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction", "abstract": "Predicting future video frames is a challenging task with many downstream\napplications. Previous work has shown that procedural knowledge enables deep\nmodels for complex dynamical settings, however their model ViPro assumed a\ngiven ground truth initial symbolic state. We show that this approach led to\nthe model learning a shortcut that does not actually connect the observed\nenvironment with the predicted symbolic state, resulting in the inability to\nestimate states given an observation if previous states are noisy. In this\nwork, we add several improvements to ViPro that enables the model to correctly\ninfer states from observations without providing a full ground truth state in\nthe beginning. We show that this is possible in an unsupervised manner, and\nextend the original Orbits dataset with a 3D variant to close the gap to real\nworld scenarios.", "published": "2025-08-08 14:10:26", "link": "http://arxiv.org/abs/2508.06335v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?", "abstract": "Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain\nshift due to variations in imaging devices and acquisition protocols. This\nchallenge limits the deployment of trained AI models in real-world scenarios,\nwhere performance degrades on unseen domains. Traditional solutions involve\nincreasing the size of the dataset through ad-hoc image augmentation or\nadditional online training/transfer learning, which have several limitations.\nSynthetic data offers a promising alternative, but anatomical/structural\nconsistency constraints limit the effectiveness of generative models in\ncreating image-label pairs. To address this, we propose a diffusion model (DM)\ntrained on a source domain that generates synthetic cardiac MR images that\nresemble a given reference. The synthetic data maintains spatial and structural\nfidelity, ensuring similarity to the source domain and compatibility with the\nsegmentation mask. We assess the utility of our generative approach in\nmulti-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and\nvanilla U-Net segmentation networks. We explore domain generalisation, where,\ndomain-invariant segmentation models are trained on synthetic source domain\ndata, and domain adaptation, where, we shift target domain data towards the\nsource domain using the DM. Both strategies significantly improved segmentation\nperformance on data from an unseen target domain, in terms of surface-based\nmetrics (Welch's t-test, p < 0.01), compared to training segmentation models on\nreal data alone. The proposed method ameliorates the need for transfer learning\nor online training to address domain shift challenges in cardiac MR image\nanalysis, especially useful in data-scarce settings.", "published": "2025-08-08 13:57:48", "link": "http://arxiv.org/abs/2508.06327v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding", "abstract": "Video Temporal Grounding (TG) aims to temporally locate video segments\nmatching a natural language description (a query) in a long video. While\nVision-Language Models (VLMs) are effective at holistic semantic matching, they\noften struggle with fine-grained temporal localisation. Recently, Group\nRelative Policy Optimisation (GRPO) reformulates the inference process as a\nreinforcement learning task, enabling fine-grained grounding and achieving\nstrong in-domain performance. However, GRPO relies on labelled data, making it\nunsuitable in unlabelled domains. Moreover, because videos are large and\nexpensive to store and process, performing full-scale adaptation introduces\nprohibitive latency and computational overhead, making it impractical for\nreal-time deployment. To overcome both problems, we introduce a Data-Efficient\nUnlabelled Cross-domain Temporal Grounding method, from which a model is first\ntrained on a labelled source domain, then adapted to a target domain using only\na small number of unlabelled videos from the target domain. This approach\neliminates the need for target annotation and keeps both computational and\nstorage overhead low enough to run in real time. Specifically, we introduce.\nUncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain\nknowledge transfer in learning video temporal grounding without target labels.\nURPA generates multiple candidate predictions using GRPO rollouts, averages\nthem to form a pseudo label, and estimates confidence from the variance across\nthese rollouts. This confidence then weights the training rewards, guiding the\nmodel to focus on reliable supervision. Experiments on three datasets across\nsix cross-domain settings show that URPA generalises well using only a few\nunlabelled target videos. Codes will be released once published.", "published": "2025-08-08 13:47:00", "link": "http://arxiv.org/abs/2508.06317v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation", "abstract": "Accurate segmentation of femur structures from Magnetic Resonance Imaging\n(MRI) is critical for orthopedic diagnosis and surgical planning but remains\nchallenging due to the limitations of existing 2D and 3D deep learning-based\nsegmentation approaches. In this study, we propose XAG-Net, a novel 2.5D\nU-Net-based architecture that incorporates pixel-wise cross-slice attention\n(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice\ncontextual modeling and intra-slice feature refinement. Unlike previous\nCSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent\nslices at each spatial location for fine-grained inter-slice modeling.\nExtensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and\n3D U-Net models in femur segmentation accuracy while maintaining computational\nefficiency. Ablation studies further validate the critical role of the CSA and\nAG modules, establishing XAG-Net as a promising framework for efficient and\naccurate femur MRI segmentation.", "published": "2025-08-08 12:25:52", "link": "http://arxiv.org/abs/2508.06258v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing", "abstract": "Federated learning (FL) enables the collaborative training of deep neural\nnetworks across decentralized data archives (i.e., clients), where each client\nstores data locally and only shares model updates with a central server. This\nmakes FL a suitable learning paradigm for remote sensing (RS) image\nclassification tasks, where data centralization may be restricted due to legal\nand privacy constraints. However, a key challenge in applying FL to RS tasks is\nthe communication overhead caused by the frequent exchange of large model\nupdates between clients and the central server. To address this issue, in this\npaper we propose a novel strategy (denoted as FedX) that uses\nexplanation-guided pruning to reduce communication overhead by minimizing the\nsize of the transmitted models without compromising performance. FedX leverages\nbackpropagation-based explanation methods to estimate the task-specific\nimportance of model components and prunes the least relevant ones at the\ncentral server. The resulting sparse global model is then sent to clients,\nsubstantially reducing communication overhead. We evaluate FedX on multi-label\nscene classification using the BigEarthNet-S2 dataset and single-label scene\nclassification using the EuroSAT dataset. Experimental results show the success\nof FedX in significantly reducing the number of shared model parameters while\nenhancing the generalization capability of the global model, compared to both\nunpruned model and state-of-the-art pruning methods. The code of FedX will be\navailable at https://git.tu-berlin.de/rsim/FedX.", "published": "2025-08-08 12:21:58", "link": "http://arxiv.org/abs/2508.06256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deepfake Detection that Generalizes Across Benchmarks", "abstract": "The generalization of deepfake detectors to unseen manipulation techniques\nremains a challenge for practical deployment. Although many approaches adapt\nfoundation models by introducing significant architectural complexity, this\nwork demonstrates that robust generalization is achievable through a\nparameter-efficient adaptation of a pre-trained CLIP vision encoder. The\nproposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters\n(0.03% of the total) and enhances generalization by enforcing a hyperspherical\nfeature manifold using L2 normalization and latent space augmentations.\n  We conducted an extensive evaluation on 13 benchmark datasets spanning from\n2019 to 2025. The proposed method achieves state-of-the-art performance,\noutperforming more complex, recent approaches in average cross-dataset AUROC.\nOur analysis yields two primary findings for the field: 1) training on paired\nreal-fake data from the same source video is essential for mitigating shortcut\nlearning and improving generalization, and 2) detection difficulty on academic\ndatasets has not strictly increased over time, with models trained on older,\ndiverse datasets showing strong generalization capabilities.\n  This work delivers a computationally efficient and reproducible method,\nproving that state-of-the-art generalization is attainable by making targeted,\nminimal changes to a pre-trained CLIP model. The code will be made publicly\navailable upon acceptance.", "published": "2025-08-08 12:03:56", "link": "http://arxiv.org/abs/2508.06248v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Unified Image Deblurring using a Mixture-of-Experts Decoder", "abstract": "Image deblurring, removing blurring artifacts from images, is a fundamental\ntask in computational photography and low-level computer vision. Existing\napproaches focus on specialized solutions tailored to particular blur types,\nthus, these solutions lack generalization. This limitation in current methods\nimplies requiring multiple models to cover several blur types, which is not\npractical in many real scenarios. In this paper, we introduce the first\nall-in-one deblurring method capable of efficiently restoring images affected\nby diverse blur degradations, including global motion, local motion, blur in\nlow-light conditions, and defocus blur. We propose a mixture-of-experts (MoE)\ndecoding module, which dynamically routes image features based on the\nrecognized blur degradation, enabling precise and efficient restoration in an\nend-to-end manner. Our unified approach not only achieves performance\ncomparable to dedicated task-specific models, but also demonstrates remarkable\nrobustness and generalization capabilities on unseen blur degradation\nscenarios.", "published": "2025-08-08 11:15:45", "link": "http://arxiv.org/abs/2508.06228v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Depth Jitter: Seeing through the Depth", "abstract": "Depth information is essential in computer vision, particularly in underwater\nimaging, robotics, and autonomous navigation. However, conventional\naugmentation techniques overlook depth aware transformations, limiting model\nrobustness in real world depth variations. In this paper, we introduce\nDepth-Jitter, a novel depth-based augmentation technique that simulates natural\ndepth variations to improve generalization. Our approach applies adaptive depth\noffsetting, guided by depth variance thresholds, to generate synthetic depth\nperturbations while preserving structural integrity. We evaluate Depth-Jitter\non two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on\nmodel stability under diverse depth conditions. Extensive experiments compare\nDepth-Jitter against traditional augmentation strategies such as ColorJitter,\nanalyzing performance across varying learning rates, encoders, and loss\nfunctions. While Depth-Jitter does not always outperform conventional methods\nin absolute performance, it consistently enhances model stability and\ngeneralization in depth-sensitive environments. These findings highlight the\npotential of depth-aware augmentation for real-world applications and provide a\nfoundation for further research into depth-based learning strategies. The\nproposed technique is publicly available to support advancements in depth-aware\naugmentation. The code is publicly available on\n\\href{https://github.com/mim-team/Depth-Jitter}{github}.", "published": "2025-08-08 11:14:57", "link": "http://arxiv.org/abs/2508.06227v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images", "abstract": "Semantic segmentation of urban remote sensing images (URSIs) is crucial for\napplications such as urban planning and environmental monitoring. However,\ngeospatial objects often exhibit subtle texture differences and similar spatial\nstructures, which can easily lead to semantic ambiguity and misclassification.\nMoreover, challenges such as irregular object shapes, blurred boundaries, and\noverlapping spatial distributions of semantic objects contribute to complex and\ndiverse edge morphologies, further complicating accurate segmentation. To\ntackle these issues, we propose a texture-aware and edge-guided Transformer\n(TEFormer) that integrates texture awareness and edge-guidance mechanisms for\nsemantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is\ndesigned to capture fine-grained texture differences between visually similar\ncategories to enhance semantic discrimination. Then, an edge-guided tri-branch\ndecoder (Eg3Head) is constructed to preserve local edges and details for\nmultiscale context-awareness. Finally, an edge-guided feature fusion module\n(EgFFM) is to fuse contextual and detail information with edge information to\nrealize refined semantic segmentation. Extensive experiments show that TEFormer\nachieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and\nLoveDA datasets, respectively, shows the effectiveness in URSI semantic\nsegmentation.", "published": "2025-08-08 11:08:31", "link": "http://arxiv.org/abs/2508.06224v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning", "abstract": "The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials\nto quantify radiographic damage in Rheumatoid Arthritis (RA), but its\ncomplexity has limited its adoption in routine clinical practice. To address\nthe inefficiency of manual scoring, this work proposes a two-stage pipeline for\ninterpretable image-level SvdH score prediction using dual-hand radiographs.\nOur approach extracts disease-relevant image regions and integrates them using\nattention-based multiple instance learning to generate image-level features for\nprediction. We propose two region extraction schemes: 1) sampling image tiles\nmost likely to contain abnormalities, and 2) cropping patches containing\ndisease-relevant joints. With Scheme 2, our best individual score prediction\nmodel achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root\nmean squared error (RMSE) of 15.73. Ensemble learning further boosted\nprediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving\nstate-of-the-art performance that is comparable to that of experienced\nradiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively\nidentified and made decisions based on anatomical structures which clinicians\nconsider relevant to RA progression.", "published": "2025-08-08 10:56:14", "link": "http://arxiv.org/abs/2508.06218v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model", "abstract": "Affordance grounding focuses on predicting the specific regions of objects\nthat are associated with the actions to be performed by robots. It plays a\nvital role in the fields of human-robot interaction, human-object interaction,\nembodied manipulation, and embodied perception. Existing models often neglect\nthe affordance shared among different objects because they lack the\nChain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)\ngeneralization and explicit reasoning capabilities. To address these\nchallenges, we propose Affordance-R1, the first unified affordance grounding\nframework that integrates cognitive CoT guided Group Relative Policy\nOptimization (GRPO) within a reinforcement learning paradigm. Specifically, we\ndesigned a sophisticated affordance function, which contains format,\nperception, and cognition rewards to effectively guide optimization directions.\nFurthermore, we constructed a high-quality affordance-centric reasoning\ndataset, ReasonAff, to support training. Trained exclusively via reinforcement\nlearning with GRPO and without explicit reasoning data, Affordance-R1 achieves\nrobust zero-shot generalization and exhibits emergent test-time reasoning\ncapabilities. Comprehensive experiments demonstrate that our model outperforms\nwell-established methods and exhibits open-world generalization. To the best of\nour knowledge, Affordance-R1 is the first to integrate GRPO-based RL with\nreasoning into affordance reasoning. The code of our method and our dataset is\nreleased on https://github.com/hq-King/Affordance-R1.", "published": "2025-08-08 10:39:04", "link": "http://arxiv.org/abs/2508.06206v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "PA-HOI: A Physics-Aware Human and Object Interaction Dataset", "abstract": "The Human-Object Interaction (HOI) task explores the dynamic interactions\nbetween humans and objects in physical environments, providing essential\nbiomechanical and cognitive-behavioral foundations for fields such as robotics,\nvirtual reality, and human-computer interaction. However, existing HOI data\nsets focus on details of affordance, often neglecting the influence of physical\nproperties of objects on human long-term motion. To bridge this gap, we\nintroduce the PA-HOI Motion Capture dataset, which highlights the impact of\nobjects' physical attributes on human motion dynamics, including human posture,\nmoving velocity, and other motion characteristics. The dataset comprises 562\nmotion sequences of human-object interactions, with each sequence performed by\nsubjects of different genders interacting with 35 3D objects that vary in size,\nshape, and weight. This dataset stands out by significantly extending the scope\nof existing ones for understanding how the physical attributes of different\nobjects influence human posture, speed, motion scale, and interacting\nstrategies. We further demonstrate the applicability of the PA-HOI dataset by\nintegrating it with existing motion generation methods, validating its capacity\nto transfer realistic physical awareness.", "published": "2025-08-08 10:36:23", "link": "http://arxiv.org/abs/2508.06205v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection", "abstract": "Anomaly detection is a critical task across numerous domains and modalities,\nyet existing methods are often highly specialized, limiting their\ngeneralizability. These specialized models, tailored for specific anomaly types\nlike textural defects or logical errors, typically exhibit limited performance\nwhen deployed outside their designated contexts. To overcome this limitation,\nwe propose AnomalyMoE, a novel and universal anomaly detection framework based\non a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the\ncomplex anomaly detection problem into three distinct semantic hierarchies:\nlocal structural anomalies, component-level semantic anomalies, and global\nlogical anomalies. AnomalyMoE correspondingly employs three dedicated expert\nnetworks at the patch, component, and global levels, and is specialized in\nreconstructing features and identifying deviations at its designated semantic\nlevel. This hierarchical design allows a single model to concurrently\nunderstand and detect a wide spectrum of anomalies. Furthermore, we introduce\nan Expert Information Repulsion (EIR) module to promote expert diversity and an\nExpert Selection Balancing (ESB) module to ensure the comprehensive utilization\nof all experts. Experiments on 8 challenging datasets spanning industrial\nimaging, 3D point clouds, medical imaging, video surveillance, and logical\nanomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art\nperformance, significantly outperforming specialized methods in their\nrespective domains.", "published": "2025-08-08 10:33:18", "link": "http://arxiv.org/abs/2508.06203v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet", "abstract": "Pleural effusion semantic segmentation can significantly enhance the accuracy\nand timeliness of clinical diagnosis and treatment by precisely identifying\ndisease severity and lesion areas. Currently, semantic segmentation of pleural\neffusion CT images faces multiple challenges. These include similar gray levels\nbetween effusion and surrounding tissues, blurred edges, and variable\nmorphology. Existing methods often struggle with diverse image variations and\ncomplex edges, primarily because direct feature concatenation causes semantic\ngaps. To address these challenges, we propose the Dual-Branch Interactive\nFusion Attention model (DBIF-AUNet). This model constructs a densely nested\nskip-connection network and innovatively refines the Dual-Domain Feature\nDisentanglement module (DDFD). The DDFD module orthogonally decouples the\nfunctions of dual-domain modules to achieve multi-scale feature complementarity\nand enhance characteristics at different levels. Concurrently, we design a\nBranch Interaction Attention Fusion module (BIAF) that works synergistically\nwith the DDFD. This module dynamically weights and fuses global, local, and\nfrequency band features, thereby improving segmentation robustness.\nFurthermore, we implement a nested deep supervision mechanism with hierarchical\nadaptive hybrid loss to effectively address class imbalance. Through validation\non 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet\nachieved IoU and Dice scores of 80.1% and 89.0% respectively. These results\noutperform state-of-the-art medical image segmentation models U-Net++ and\nSwin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant\noptimization in segmentation accuracy for complex pleural effusion CT images.", "published": "2025-08-08 10:14:51", "link": "http://arxiv.org/abs/2508.06191v1", "categories": ["cs.CV", "68T45, 92C55", "I.4.6; I.5.4; J.3"], "primary_category": "cs.CV"}
{"title": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration", "abstract": "With the acceleration of urbanization, criminal behavior in public scenes\nposes an increasingly serious threat to social security. Traditional anomaly\ndetection methods based on feature recognition struggle to capture high-level\nbehavioral semantics from historical information, while generative approaches\nbased on Large Language Models (LLMs) often fail to meet real-time\nrequirements. To address these challenges, we propose MA-CBP, a criminal\nbehavior prediction framework based on multi-agent asynchronous collaboration.\nThis framework transforms real-time video streams into frame-level semantic\ndescriptions, constructs causally consistent historical summaries, and fuses\nadjacent image frames to perform joint reasoning over long- and short-term\ncontexts. The resulting behavioral decisions include key elements such as event\nsubjects, locations, and causes, enabling early warning of potential criminal\nactivity. In addition, we construct a high-quality criminal behavior dataset\nthat provides multi-scale language supervision, including frame-level,\nsummary-level, and event-level semantic annotations. Experimental results\ndemonstrate that our method achieves superior performance on multiple datasets\nand offers a promising solution for risk warning in urban public safety\nscenarios.", "published": "2025-08-08 10:12:00", "link": "http://arxiv.org/abs/2508.06189v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Clinically-guided Data Synthesis for Laryngeal Lesion Detection", "abstract": "Although computer-aided diagnosis (CADx) and detection (CADe) systems have\nmade significant progress in various medical domains, their application is\nstill limited in specialized fields such as otorhinolaryngology. In the latter,\ncurrent assessment methods heavily depend on operator expertise, and the high\nheterogeneity of lesions complicates diagnosis, with biopsy persisting as the\ngold standard despite its substantial costs and risks. A critical bottleneck\nfor specialized endoscopic CADx/e systems is the lack of well-annotated\ndatasets with sufficient variability for real-world generalization. This study\nintroduces a novel approach that exploits a Latent Diffusion Model (LDM)\ncoupled with a ControlNet adapter to generate laryngeal endoscopic\nimage-annotation pairs, guided by clinical observations. The method addresses\ndata scarcity by conditioning the diffusion process to produce realistic,\nhigh-quality, and clinically relevant image features that capture diverse\nanatomical conditions. The proposed approach can be leveraged to expand\ntraining datasets for CADx/e models, empowering the assessment process in\nlaryngology. Indeed, during a downstream task of detection, the addition of\nonly 10% synthetic data improved the detection rate of laryngeal lesions by 9%\nwhen the model was internally tested and 22.1% on out-of-domain external data.\nAdditionally, the realism of the generated images was evaluated by asking 5\nexpert otorhinolaryngologists with varying expertise to rate their confidence\nin distinguishing synthetic from real images. This work has the potential to\naccelerate the development of automated tools for laryngeal disease diagnosis,\noffering a solution to data scarcity and demonstrating the applicability of\nsynthetic data in real-world scenarios.", "published": "2025-08-08 09:55:54", "link": "http://arxiv.org/abs/2508.06182v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor", "abstract": "Accurate localization represents a fundamental challenge in\n  robotic navigation. Traditional methodologies, such as Lidar or QR-code based\nsystems, suffer from inherent scalability and adaptability con straints,\nparticularly in complex environments. In this work, we propose\n  an innovative localization framework that harnesses flooring characteris tics\nby employing graph-based representations and Graph Convolutional\n  Networks (GCNs). Our method uses graphs to represent floor features,\n  which helps localize the robot more accurately (0.64cm error) and more\n  efficiently than comparing individual image features. Additionally, this\n  approach successfully addresses the kidnapped robot problem in every\n  frame without requiring complex filtering processes. These advancements\n  open up new possibilities for robotic navigation in diverse environments.", "published": "2025-08-08 09:46:28", "link": "http://arxiv.org/abs/2508.06177v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment", "abstract": "Diffusion models have shown remarkable success across generative tasks, yet\ntheir high computational demands challenge deployment on resource-limited\nplatforms. This paper investigates a critical question for compute-optimal\ndiffusion model deployment: Under a post-training setting without fine-tuning,\nis it more effective to reduce the number of denoising steps or to use a\ncheaper per-step inference? Intuitively, reducing the number of denoising steps\nincreases the variability of the distributions across steps, making the model\nmore sensitive to compression. In contrast, keeping more denoising steps makes\nthe differences smaller, preserving redundancy, and making post-training\ncompression more feasible. To systematically examine this, we propose PostDiff,\na training-free framework for accelerating pre-trained diffusion models by\nreducing redundancy at both the input level and module level in a post-training\nmanner. At the input level, we propose a mixed-resolution denoising scheme\nbased on the insight that reducing generation resolution in early denoising\nsteps can enhance low-frequency components and improve final generation\nfidelity. At the module level, we employ a hybrid module caching strategy to\nreuse computations across denoising steps. Extensive experiments and ablation\nstudies demonstrate that (1) PostDiff can significantly improve the\nfidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to\nboost efficiency while maintaining decent generation fidelity, reducing\nper-step inference cost is often more effective than reducing the number of\ndenoising steps. Our code is available at\nhttps://github.com/GATECH-EIC/PostDiff.", "published": "2025-08-08 09:29:37", "link": "http://arxiv.org/abs/2508.06160v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis", "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder that\nseverely impairs cognitive function and quality of life. Timely intervention in\nAD relies heavily on early and precise diagnosis, which remains challenging due\nto the complex and subtle structural changes in the brain. Most existing deep\nlearning methods focus only on a single plane of structural magnetic resonance\nimaging (sMRI) and struggle to accurately capture the complex and nonlinear\nrelationships among pathological regions of the brain, thus limiting their\nability to precisely identify atrophic features. To overcome these limitations,\nwe propose an innovative framework, MPF-KANSC, which integrates multi-plane\nfusion (MPF) for combining features from the coronal, sagittal, and axial\nplanes, and a Kolmogorov-Arnold Network-guided spatial-channel attention\nmechanism (KANSC) to more effectively learn and represent sMRI atrophy\nfeatures. Specifically, the proposed model enables parallel feature extraction\nfrom multiple anatomical planes, thus capturing more comprehensive structural\ninformation. The KANSC attention mechanism further leverages a more flexible\nand accurate nonlinear function approximation technique, facilitating precise\nidentification and localization of disease-related abnormalities. Experiments\non the ADNI dataset confirm that the proposed MPF-KANSC achieves superior\nperformance in AD diagnosis. Moreover, our findings provide new evidence of\nright-lateralized asymmetry in subcortical structural changes during AD\nprogression, highlighting the model's promising interpretability.", "published": "2025-08-08 09:26:49", "link": "http://arxiv.org/abs/2508.06157v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models", "abstract": "In oral cancer diagnostics, the limited availability of annotated datasets\nfrequently constrains the performance of diagnostic models, particularly due to\nthe variability and insufficiency of training data. To address these\nchallenges, this study proposed a novel approach to enhance diagnostic accuracy\nby synthesizing realistic oral cancer lesions using an inpainting technique\nwith a fine-tuned diffusion model. We compiled a comprehensive dataset from\nmultiple sources, featuring a variety of oral cancer images. Our method\ngenerated synthetic lesions that exhibit a high degree of visual fidelity to\nactual lesions, thereby significantly enhancing the performance of diagnostic\nalgorithms. The results show that our classification model achieved a\ndiagnostic accuracy of 0.97 in differentiating between cancerous and\nnon-cancerous tissues, while our detection model accurately identified lesion\nlocations with 0.85 accuracy. This method validates the potential for synthetic\nimage generation in medical diagnostics and paves the way for further research\ninto extending these methods to other types of cancer diagnostics.", "published": "2025-08-08 09:15:02", "link": "http://arxiv.org/abs/2508.06151v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation", "abstract": "We present VISTAR, a user-centric, multi-dimensional benchmark for\ntext-to-image (T2I) evaluation that addresses the limitations of existing\nmetrics. VISTAR introduces a two-tier hybrid paradigm: it employs\ndeterministic, scriptable metrics for physically quantifiable attributes (e.g.,\ntext rendering, lighting) and a novel Hierarchical Weighted P/N Questioning\n(HWPQ) scheme that uses constrained vision-language models to assess abstract\nsemantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study\nwith 120 experts, we defined seven user roles and nine evaluation angles to\nconstruct the benchmark, which comprises 2,845 prompts validated by over 15,000\nhuman pairwise comparisons. Our metrics achieve high human alignment (>75%),\nwith the HWPQ scheme reaching 85.9% accuracy on abstract semantics,\nsignificantly outperforming VQA baselines. Comprehensive evaluation of\nstate-of-the-art models reveals no universal champion, as role-weighted scores\nreorder rankings and provide actionable guidance for domain-specific\ndeployment. All resources are publicly released to foster reproducible T2I\nassessment.", "published": "2025-08-08 09:15:02", "link": "http://arxiv.org/abs/2508.06152v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DSConv: Dynamic Splitting Convolution for Pansharpening", "abstract": "Aiming to obtain a high-resolution image, pansharpening involves the fusion\nof a multi-spectral image (MS) and a panchromatic image (PAN), the low-level\nvision task remaining significant and challenging in contemporary research.\nMost existing approaches rely predominantly on standard convolutions, few\nmaking the effort to adaptive convolutions, which are effective owing to the\ninter-pixel correlations of remote sensing images. In this paper, we propose a\nnovel strategy for dynamically splitting convolution kernels in conjunction\nwith attention, selecting positions of interest, and splitting the original\nconvolution kernel into multiple smaller kernels, named DSConv. The proposed\nDSConv more effectively extracts features of different positions within the\nreceptive field, enhancing the network's generalization, optimization, and\nfeature representation capabilities. Furthermore, we innovate and enrich\nconcepts of dynamic splitting convolution and provide a novel network\narchitecture for pansharpening capable of achieving the tasks more efficiently,\nbuilding upon this methodology. Adequate fair experiments illustrate the\neffectiveness and the state-of-the-art performance attained by\nDSConv.Comprehensive and rigorous discussions proved the superiority and\noptimal usage conditions of DSConv.", "published": "2025-08-08 09:09:56", "link": "http://arxiv.org/abs/2508.06147v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Text-guided Visual Prompt DINO for Generic Segmentation", "abstract": "Recent advancements in multimodal vision models have highlighted limitations\nin late-stage feature fusion and suboptimal query selection for hybrid prompts\nopen-world segmentation, alongside constraints from caption-derived\nvocabularies. To address these challenges, we propose Prompt-DINO, a\ntext-guided visual Prompt DINO framework featuring three key innovations.\nFirst, we introduce an early fusion mechanism that unifies text/visual prompts\nand backbone features at the initial encoding stage, enabling deeper\ncross-modal interactions to resolve semantic ambiguities. Second, we design\norder-aligned query selection for DETR-based architectures, explicitly\noptimizing the structural alignment between text and visual queries during\ndecoding to enhance semantic-spatial consistency. Third, we develop a\ngenerative data engine powered by the Recognize Anything via Prompting (RAP)\nmodel, which synthesizes 0.5B diverse training instances through a dual-path\ncross-verification pipeline, reducing label noise by 80.5% compared to\nconventional approaches. Extensive experiments demonstrate that Prompt-DINO\nachieves state-of-the-art performance on open-world detection benchmarks while\nsignificantly expanding semantic coverage beyond fixed-vocabulary constraints.\nOur work establishes a new paradigm for scalable multimodal detection and data\ngeneration in open-world scenarios. Data&Code are available at\nhttps://github.com/WeChatCV/WeVisionOne.", "published": "2025-08-08 09:09:30", "link": "http://arxiv.org/abs/2508.06146v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models", "abstract": "In the rapidly evolving landscape of Multimodal Large Language Models\n(MLLMs), the safety concerns of their outputs have earned significant\nattention. Although numerous datasets have been proposed, they may become\noutdated with MLLM advancements and are susceptible to data contamination\nissues. To address these problems, we propose \\textbf{SDEval}, the\n\\textit{first} safety dynamic evaluation framework to controllably adjust the\ndistribution and complexity of safety benchmarks. Specifically, SDEval mainly\nadopts three dynamic strategies: text, image, and text-image dynamics to\ngenerate new samples from original benchmarks. We first explore the individual\neffects of text and image dynamics on model safety. Then, we find that\ninjecting text dynamics into images can further impact safety, and conversely,\ninjecting image dynamics into text also leads to safety risks. SDEval is\ngeneral enough to be applied to various existing safety and even capability\nbenchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and\ncapability benchmarks, MMBench and MMVet, show that SDEval significantly\ninfluences safety evaluation, mitigates data contamination, and exposes safety\nlimitations of MLLMs. Code is available at https://github.com/hq-King/SDEval", "published": "2025-08-08 09:01:56", "link": "http://arxiv.org/abs/2508.06142v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera", "abstract": "Combining sparse IMUs and a monocular camera is a new promising setting to\nperform real-time human motion capture. This paper proposes a diffusion-based\nsolution to learn human motion priors and fuse the two modalities of signals\ntogether seamlessly in a unified framework. By delicately considering the\ncharacteristics of the two signals, the sequential visual information is\nconsidered as a whole and transformed into a condition embedding, while the\ninertial measurement is concatenated with the noisy body pose frame by frame to\nconstruct a sequential input for the diffusion model. Firstly, we observe that\nthe visual information may be unavailable in some frames due to occlusions or\nsubjects moving out of the camera view. Thus incorporating the sequential\nvisual features as a whole to get a single feature embedding is robust to the\noccasional degenerations of visual information in those frames. On the other\nhand, the IMU measurements are robust to occlusions and always stable when\nsignal transmission has no problem. So incorporating them frame-wisely could\nbetter explore the temporal information for the system. Experiments have\ndemonstrated the effectiveness of the system design and its state-of-the-art\nperformance in pose estimation compared with the previous works. Our codes are\navailable for research at https://shaohua-pan.github.io/diffcap-page.", "published": "2025-08-08 09:00:40", "link": "http://arxiv.org/abs/2508.06139v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework", "abstract": "Breast cancer detection through mammography interpretation remains difficult\nbecause of the minimal nature of abnormalities that experts need to identify\nalongside the variable interpretations between readers. The potential of CNNs\nfor medical image analysis faces two limitations: they fail to process both\nlocal information and wide contextual data adequately, and do not provide\nexplainable AI (XAI) operations that doctors need to accept them in clinics.\nThe researcher developed the MammoFormer framework, which unites\ntransformer-based architecture with multi-feature enhancement components and\nXAI functionalities within one framework. Seven different architectures\nconsisting of CNNs, Vision Transformer, Swin Transformer, and ConvNext were\ntested alongside four enhancement techniques, including original images,\nnegative transformation, adaptive histogram equalization, and histogram of\noriented gradients. The MammoFormer framework addresses critical clinical\nadoption barriers of AI mammography systems through: (1) systematic\noptimization of transformer architectures via architecture-specific feature\nenhancement, achieving up to 13% performance improvement, (2) comprehensive\nexplainable AI integration providing multi-perspective diagnostic\ninterpretability, and (3) a clinically deployable ensemble system combining CNN\nreliability with transformer global context modeling. The combination of\ntransformer models with suitable feature enhancements enables them to achieve\nequal or better results than CNN approaches. ViT achieves 98.3% accuracy\nalongside AHE while Swin Transformer gains a 13.0% advantage through HOG\nenhancements", "published": "2025-08-08 08:59:54", "link": "http://arxiv.org/abs/2508.06137v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures", "abstract": "While the Segment Anything Model (SAM) transforms interactive segmentation\nwith zero-shot abilities, its inherent vulnerabilities present a single-point\nrisk, potentially leading to the failure of numerous downstream applications.\nProactively evaluating these transferable vulnerabilities is thus imperative.\nPrior adversarial attacks on SAM often present limited transferability due to\ninsufficient exploration of common weakness across domains. To address this, we\npropose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that\nleverages only the encoder of SAM for generating transferable adversarial\nexamples. Specifically, it achieves this by explicitly characterizing the\nshared vulnerable regions between SAM and downstream models through a\nparametric simplicial complex. Our goal is to identify such complexes within\nadversarially potent regions by iterative vertex-wise refinement. A lightweight\ndomain re-adaptation strategy is introduced to bridge domain divergence using\nminimal reference data during the initialization of simplicial complex.\nUltimately, VeSCA generates consistently transferable adversarial examples\nthrough random simplicial complex sampling. Extensive experiments demonstrate\nthat VeSCA achieves performance improved by 12.7% compared to state-of-the-art\nmethods across three downstream model categories across five domain-specific\ndatasets. Our findings further highlight the downstream model risks posed by\nSAM's vulnerabilities and emphasize the urgency of developing more robust\nfoundation models.", "published": "2025-08-08 08:47:26", "link": "http://arxiv.org/abs/2508.06127v1", "categories": ["cs.CV", "I.4.9"], "primary_category": "cs.CV"}
{"title": "SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning", "abstract": "We propose SC-Captioner, a reinforcement learning framework that enables the\nself-correcting capability of image caption models. Our crucial technique lies\nin the design of the reward function to incentivize accurate caption\ncorrections. Specifically, the predicted and reference captions are decomposed\ninto object, attribute, and relation sets using scene-graph parsing algorithms.\nWe calculate the set difference between sets of initial and self-corrected\ncaptions to identify added and removed elements. These elements are matched\nagainst the reference sets to calculate correctness bonuses for accurate\nrefinements and mistake punishments for wrong additions and removals, thereby\nforming the final reward. For image caption quality assessment, we propose a\nset of metrics refined from CAPTURE that alleviate its incomplete precision\nevaluation and inefficient relation matching problems. Furthermore, we collect\na fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K\ndiverse images from COCO dataset. Experiments show that applying SC-Captioner\non large visual-language models can generate better image captions across\nvarious scenarios, significantly outperforming the direct preference\noptimization training strategy.", "published": "2025-08-08 08:45:52", "link": "http://arxiv.org/abs/2508.06125v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events", "abstract": "This study applied representation learning algorithms to satellite images and\nevaluated the learned latent spaces with classifications of various weather\nevents. The algorithms investigated include the classical linear\ntransformation, i.e., principal component analysis (PCA), state-of-the-art deep\nlearning method, i.e., convolutional autoencoder (CAE), and a residual network\npre-trained with large image datasets (PT). The experiment results indicated\nthat the latent space learned by CAE consistently showed higher threat scores\nfor all classification tasks. The classifications with PCA yielded high hit\nrates but also high false-alarm rates. In addition, the PT performed\nexceptionally well at recognizing tropical cyclones but was inferior in other\ntasks. Further experiments suggested that representations learned from\nhigher-resolution datasets are superior in all classification tasks for\ndeep-learning algorithms, i.e., CAE and PT. We also found that smaller latent\nspace sizes had minor impact on the classification task's hit rate. Still, a\nlatent space dimension smaller than 128 caused a significantly higher false\nalarm rate. Though the CAE can learn latent spaces effectively and efficiently,\nthe interpretation of the learned representation lacks direct connections to\nphysical attributions. Therefore, developing a physics-informed version of CAE\ncan be a promising outlook for the current work.", "published": "2025-08-08 08:42:18", "link": "http://arxiv.org/abs/2508.06122v1", "categories": ["cs.CV", "physics.ao-ph"], "primary_category": "cs.CV"}
{"title": "SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation", "abstract": "Semantic segmentation in open-vocabulary scenarios presents significant\nchallenges due to the wide range and granularity of semantic categories.\nExisting weakly-supervised methods often rely on category-specific supervision\nand ill-suited feature construction methods for contrastive learning, leading\nto semantic misalignment and poor performance. In this work, we propose a novel\nweakly-supervised approach, SynSeg, to address the challenges. SynSeg performs\nMulti-Category Contrastive Learning (MCCL) as a stronger training signal with a\nnew feature reconstruction framework named Feature Synergy Structure (FSS).\nSpecifically, MCCL strategy robustly combines both intra- and inter-category\nalignment and separation in order to make the model learn the knowledge of\ncorrelations from different categories within the same image. Moreover, FSS\nreconstructs discriminative features for contrastive learning through prior\nfusion and semantic-activation-map enhancement, effectively avoiding the\nforeground bias introduced by the visual encoder. In general, SynSeg\neffectively improves the abilities in semantic localization and discrimination\nunder weak supervision. Extensive experiments on benchmarks demonstrate that\nour method outperforms state-of-the-art (SOTA) performance. For instance,\nSynSeg achieves higher accuracy than SOTA baselines by 4.5\\% on VOC, 8.9\\% on\nContext, 2.6\\% on Object and 2.0\\% on City.", "published": "2025-08-08 08:26:41", "link": "http://arxiv.org/abs/2508.06115v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving", "abstract": "Diffusion-based models are redefining the state-of-the-art in end-to-end\nautonomous driving, yet their performance is increasingly hampered by a\nreliance on transformer-based fusion. These architectures face fundamental\nlimitations: quadratic computational complexity restricts the use of\nhigh-resolution features, and a lack of spatial priors prevents them from\neffectively modeling the inherent structure of Bird's Eye View (BEV)\nrepresentations. This paper introduces GMF-Drive (Gated Mamba Fusion for\nDriving), an end-to-end framework that overcomes these challenges through two\nprincipled innovations. First, we supersede the information-limited\nhistogram-based LiDAR representation with a geometrically-augmented pillar\nformat encoding shape descriptors and statistical features, preserving critical\n3D geometric details. Second, we propose a novel hierarchical gated mamba\nfusion (GM-Fusion) architecture that substitutes an expensive transformer with\na highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM\nleverages directional sequencing and adaptive fusion mechanisms to capture\nlong-range dependencies with linear complexity, while explicitly respecting the\nunique spatial properties of the driving scene. Extensive experiments on the\nchallenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new\nstate-of-the-art performance, significantly outperforming DiffusionDrive.\nComprehensive ablation studies validate the efficacy of each component,\ndemonstrating that task-specific SSMs can surpass a general-purpose transformer\nin both performance and efficiency for autonomous driving.", "published": "2025-08-08 08:17:18", "link": "http://arxiv.org/abs/2508.06113v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment", "abstract": "With the increasing availability of 2D and 3D data, significant advancements\nhave been made in the field of cross-modal retrieval. Nevertheless, the\nexistence of imperfect annotations presents considerable challenges, demanding\nrobust solutions for 2D-3D cross-modal retrieval in the presence of noisy label\nconditions. Existing methods generally address the issue of noise by dividing\nsamples independently within each modality, making them susceptible to\noverfitting on corrupted labels. To address these issues, we propose a robust\n2D-3D \\textbf{M}ulti-level cross-modal adaptive \\textbf{C}orrection and\n\\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal\nJoint label Correction (MJC) mechanism that leverages multimodal historical\nself-predictions to jointly model the modality prediction consistency, enabling\nreliable label refinement. Additionally, we propose a Multi-level Adaptive\nAlignment (MAA) strategy to effectively enhance cross-modal feature semantics\nand discrimination across different levels. Extensive experiments demonstrate\nthe superiority of our method, MCA, which achieves state-of-the-art performance\non both conventional and realistic noisy 3D benchmarks, highlighting its\ngenerality and effectiveness.", "published": "2025-08-08 08:06:43", "link": "http://arxiv.org/abs/2508.06104v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization", "abstract": "In the digital age, advanced image editing tools pose a serious threat to the\nintegrity of visual content, making image forgery detection and localization a\nkey research focus. Most existing Image Manipulation Localization (IML) methods\nrely on discriminative learning and require large, high-quality annotated\ndatasets. However, current datasets lack sufficient scale and diversity,\nlimiting model performance in real-world scenarios. To overcome this, recent\nstudies have explored Constrained IML (CIML), which generates pixel-level\nannotations through algorithmic supervision. However, existing CIML approaches\noften depend on complex multi-stage pipelines, making the annotation process\ninefficient. In this work, we propose a novel generative framework based on\ndiffusion models, named UGD-IML, which for the first time unifies both IML and\nCIML tasks within a single framework. By learning the underlying data\ndistribution, generative diffusion models inherently reduce the reliance on\nlarge-scale labeled datasets, allowing our approach to perform effectively even\nunder limited data conditions. In addition, by leveraging a class embedding\nmechanism and a parameter-sharing design, our model seamlessly switches between\nIML and CIML modes without extra components or training overhead. Furthermore,\nthe end-to-end design enables our model to avoid cumbersome steps in the data\nannotation process. Extensive experimental results on multiple datasets\ndemonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and\n4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the\nproposed method also excels in uncertainty estimation, visualization and\nrobustness.", "published": "2025-08-08 08:00:28", "link": "http://arxiv.org/abs/2508.06101v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "E-React: Towards Emotionally Controlled Synthesis of Human Reactions", "abstract": "Emotion serves as an essential component in daily human interactions.\nExisting human motion generation frameworks do not consider the impact of\nemotions, which reduces naturalness and limits their application in interactive\ntasks, such as human reaction synthesis. In this work, we introduce a novel\ntask: generating diverse reaction motions in response to different emotional\ncues. However, learning emotion representation from limited motion data and\nincorporating it into a motion generation framework remains a challenging\nproblem. To address the above obstacles, we introduce a semi-supervised emotion\nprior in an actor-reactor diffusion model to facilitate emotion-driven reaction\nsynthesis. Specifically, based on the observation that motion clips within a\nshort sequence tend to share the same emotion, we first devise a\nsemi-supervised learning framework to train an emotion prior. With this prior,\nwe further train an actor-reactor diffusion model to generate reactions by\nconsidering both spatial interaction and emotional response. Finally, given a\nmotion sequence of an actor, our approach can generate realistic reactions\nunder various emotional conditions. Experimental results demonstrate that our\nmodel outperforms existing reaction generation methods. The code and data will\nbe made publicly available at https://ereact.github.io/", "published": "2025-08-08 07:36:32", "link": "http://arxiv.org/abs/2508.06093v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation", "abstract": "Accurate and efficient Video Quality Assessment (VQA) has long been a key\nresearch challenge. Current mainstream VQA methods typically improve\nperformance by pretraining on large-scale classification datasets (e.g.,\nImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this\nstrategy presents two significant challenges: (1) merely transferring semantic\nknowledge learned from pretraining is insufficient for VQA, as video quality\ndepends on multiple factors (e.g., semantics, distortion, motion, aesthetics);\n(2) pretraining on large-scale datasets demands enormous computational\nresources, often dozens or even hundreds of times greater than training\ndirectly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown\nremarkable generalization capabilities across a wide range of visual tasks, and\nhave begun to demonstrate promising potential in quality assessment. In this\nwork, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP\nenhances both visual and textual representations through a Shared Cross-Modal\nAdapter (SCMA), which contains only a minimal number of trainable parameters\nand is the only component that requires training. This design significantly\nreduces computational cost. In addition, we introduce a set of five learnable\nquality-level prompts to guide the VLMs in perceiving subtle quality\nvariations, thereby further enhancing the model's sensitivity to video quality.\nFurthermore, we investigate the impact of different frame sampling strategies\non VQA performance, and find that frame-difference-based sampling leads to\nbetter generalization performance across datasets. Extensive experiments\ndemonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.", "published": "2025-08-08 07:36:01", "link": "http://arxiv.org/abs/2508.06092v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance", "abstract": "Vision-language models (VLMs) have achieved impressive performance on\nmultimodal reasoning tasks such as visual question answering (VQA), but their\ninference cost remains a significant challenge due to the large number of\nvision tokens processed during the prefill stage. Existing pruning methods\noften rely on directly using the attention patterns or static text prompt\nguidance, failing to exploit the dynamic internal signals generated during\ninference. To address these issues, we propose AdaptInfer, a plug-and-play\nframework for adaptive vision token pruning in VLMs. First, we introduce a\nfine-grained, dynamic text-guided pruning mechanism that reuses layer-wise\ntext-to-text attention maps to construct soft priors over text-token\nimportance, allowing more informed scoring of vision tokens at each stage.\nSecond, we perform an offline analysis of cross-modal attention shifts and\nidentify consistent inflection locations in inference, which inspire us to\npropose a more principled and efficient pruning schedule. Our method is\nlightweight and plug-and-play, also generalizable across multi-modal tasks.\nExperimental results have verified the effectiveness of the proposed method.\nFor example, it reduces CUDA latency by 61.3\\% while maintaining an average\naccuracy of 92.9\\% on vanilla LLaVA-1.5-7B. Under the same token budget,\nAdaptInfer surpasses SOTA in accuracy.", "published": "2025-08-08 07:27:26", "link": "http://arxiv.org/abs/2508.06084v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment", "abstract": "Diffusion-based or flow-based models have achieved significant progress in\nvideo synthesis but require multiple iterative sampling steps, which incurs\nsubstantial computational overhead. While many distillation methods that are\nsolely based on trajectory-preserving or distribution-matching have been\ndeveloped to accelerate video generation models, these approaches often suffer\nfrom performance breakdown or increased artifacts under few-step settings. To\naddress these limitations, we propose \\textbf{\\emph{SwiftVideo}}, a unified and\nstable distillation framework that combines the advantages of\ntrajectory-preserving and distribution-matching strategies. Our approach\nintroduces continuous-time consistency distillation to ensure precise\npreservation of ODE trajectories. Subsequently, we propose a dual-perspective\nalignment that includes distribution alignment between synthetic and real data\nalong with trajectory alignment across different inference steps. Our method\nmaintains high-quality video generation while substantially reducing the number\nof inference steps. Quantitative evaluations on the OpenVid-1M benchmark\ndemonstrate that our method significantly outperforms existing approaches in\nfew-step video generation.", "published": "2025-08-08 07:26:34", "link": "http://arxiv.org/abs/2508.06082v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DreamVE: Unified Instruction-based Image and Video Editing", "abstract": "Instruction-based editing holds vast potential due to its simple and\nefficient interactive editing format. However, instruction-based editing,\nparticularly for video, has been constrained by limited training data,\nhindering its practical application. To this end, we introduce DreamVE, a\nunified model for instruction-based image and video editing. Specifically, We\npropose a two-stage training strategy: first image editing, then video editing.\nThis offers two main benefits: (1) Image data scales more easily, and models\nare more efficient to train, providing useful priors for faster and better\nvideo editing training. (2) Unifying image and video generation is natural and\naligns with current trends. Moreover, we present comprehensive training data\nsynthesis pipelines, including collage-based and generative model-based data\nsynthesis. The collage-based data synthesis combines foreground objects and\nbackgrounds to generate diverse editing data, such as object manipulation,\nbackground changes, and text modifications. It can easily generate billions of\naccurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE\non extensive collage-based data to achieve strong performance in key editing\ntypes and enhance generalization and transfer capabilities. However,\ncollage-based data lacks some attribute editing cases, leading to a relative\ndrop in performance. In contrast, the generative model-based pipeline, despite\nbeing hard to scale up, offers flexibility in handling attribute editing cases.\nTherefore, we use generative model-based data to further fine-tune DreamVE.\nBesides, we design an efficient and powerful editing framework for DreamVE. We\nbuild on the SOTA T2V model and use a token concatenation with early drop\napproach to inject source image guidance, ensuring strong consistency and\neditability. The codes and models will be released.", "published": "2025-08-08 07:20:30", "link": "http://arxiv.org/abs/2508.06080v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection", "abstract": "Salient object detection (SOD) and camouflaged object detection (COD) are two\nclosely related but distinct computer vision tasks. Although both are\nclass-agnostic segmentation tasks that map from RGB space to binary space, the\nformer aims to identify the most salient objects in the image, while the latter\nfocuses on detecting perfectly camouflaged objects that blend into the\nbackground in the image. These two tasks exhibit strong contradictory\nattributes. Previous works have mostly believed that joint learning of these\ntwo tasks would confuse the network, reducing its performance on both tasks.\nHowever, here we present an opposite perspective: with the correct approach to\nlearning, the network can simultaneously possess the capability to find both\nsalient and camouflaged objects, allowing both tasks to benefit from joint\nlearning. We propose SCJoint, a joint learning scheme for SOD and COD tasks,\nassuming that the decoding processes of SOD and COD have different distribution\ncharacteristics. The key to our method is to learn the respective means and\nvariances of the decoding processes for both tasks by inserting a minimal\namount of task-specific learnable parameters within a fully shared network\nstructure, thereby decoupling the contradictory attributes of the two tasks at\na minimal cost. Furthermore, we propose a saliency-based sampling strategy\n(SBSS) to sample the training set of the SOD task to balance the training set\nsizes of the two tasks. In addition, SBSS improves the training set quality and\nshortens the training time. Based on the proposed SCJoint and SBSS, we train a\npowerful generalist network, named JoNet, which has the ability to\nsimultaneously capture both ``salient\" and ``camouflaged\". Extensive\nexperiments demonstrate the competitive performance and effectiveness of our\nproposed method. The code is available at https://github.com/linuxsino/JoNet.", "published": "2025-08-08 06:52:54", "link": "http://arxiv.org/abs/2508.06063v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention", "abstract": "Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera\ncapture brightness changes as asynchronous \"events\" instead of frames, offering\nadvanced application on mobile photography. However, challenges arise from\ncombining a Quad Bayer Color Filter Array (CFA) sensor with event pixels\nlacking color information, resulting in aliasing and artifacts on the\ndemosaicing process before downstream application. Current methods struggle to\naddress these issues, especially on resource-limited mobile devices. In\nresponse, we introduce \\textbf{TSANet}, a lightweight \\textbf{T}wo-stage\nnetwork via \\textbf{S}tate space augmented cross-\\textbf{A}ttention, which can\nhandle event pixels inpainting and demosaicing separately, leveraging the\nbenefits of dividing complex tasks into manageable subtasks. Furthermore, we\nintroduce a lightweight Cross-Swin State Block that uniquely utilizes\npositional prior for demosaicing and enhances global dependencies through the\nstate space model with linear complexity. In summary, TSANet demonstrates\nexcellent demosaicing performance on both simulated and real data of HybridEVS\nwhile maintaining a lightweight model, averaging better results than the\nprevious state-of-the-art method DemosaicFormer across seven diverse datasets\nin both PSNR and SSIM, while respectively reducing parameter and computation\ncosts by $1.86\\times$ and $3.29\\times$. Our approach presents new possibilities\nfor efficient image demosaicing on mobile devices. Code is available in the\nsupplementary materials.", "published": "2025-08-08 06:40:59", "link": "http://arxiv.org/abs/2508.06058v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?", "abstract": "Artificial General Intelligence (AGI) is closer than ever to becoming a\nreality, sparking widespread enthusiasm in the research community to collect\nand work with various modalities, including text, image, video, and audio.\nDespite recent efforts, satellite spectral imagery, as an additional modality,\nhas yet to receive the attention it deserves. This area presents unique\nchallenges, but also holds great promise in advancing the capabilities of AGI\nin understanding the natural world. In this paper, we argue why Earth\nObservation data is useful for an intelligent model, and then we review\nexisting benchmarks and highlight their limitations in evaluating the\ngeneralization ability of foundation models in this domain. This paper\nemphasizes the need for a more comprehensive benchmark to evaluate earth\nobservation models. To facilitate this, we propose a comprehensive set of tasks\nthat a benchmark should encompass to effectively assess a model's ability to\nunderstand and interact with Earth observation data.", "published": "2025-08-08 06:28:58", "link": "http://arxiv.org/abs/2508.06057v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing", "abstract": "Lateral ventricle (LV) shape analysis holds promise as a biomarker for\nneurological diseases; however, challenges remain due to substantial shape\nvariability across individuals and segmentation difficulties arising from\nlimited MRI resolution. We introduce LV-Net, a novel framework for producing\nindividualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint\nLV-hippocampus template mesh. By incorporating anatomical relationships\nembedded within the joint template, LV-Net reduces boundary segmentation\nartifacts and improves reconstruction robustness. In addition, by classifying\nthe vertices of the template mesh based on their anatomical adjacency, our\nmethod enhances point correspondence across subjects, leading to more accurate\nLV shape statistics. We demonstrate that LV-Net achieves superior\nreconstruction accuracy, even in the presence of segmentation imperfections,\nand delivers more reliable shape descriptors across diverse datasets. Finally,\nwe apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that\nshow significantly associations with the disease relative to cognitively normal\ncontrols. The codes for LV shape modeling are available at\nhttps://github.com/PWonjung/LV_Shape_Modeling.", "published": "2025-08-08 06:25:18", "link": "http://arxiv.org/abs/2508.06055v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning", "abstract": "Video quality assessment (VQA) aims to objectively quantify perceptual\nquality degradation in alignment with human visual perception. Despite recent\nadvances, existing VQA models still suffer from two critical limitations:\n\\textit{poor generalization to out-of-distribution (OOD) videos} and\n\\textit{limited explainability}, which restrict their applicability in\nreal-world scenarios. To address these challenges, we propose\n\\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large\nmultimodal models (LMMs) with reinforcement learning to jointly model video\nquality understanding and scoring, emulating human perceptual decision-making.\nSpecifically, we adopt group relative policy optimization (GRPO), a rule-guided\nreinforcement learning algorithm that enables reasoning over video quality\nunder score-level supervision, and introduce three VQA-specific rewards: (1) a\n\\textbf{bell-shaped regression reward} that increases rapidly as the prediction\nerror decreases and becomes progressively less sensitive near the ground truth;\n(2) a \\textbf{pairwise ranking reward} that guides the model to correctly\ndetermine the relative quality between video pairs; and (3) a \\textbf{temporal\nconsistency reward} that encourages the model to prefer temporally coherent\nvideos over their perturbed counterparts. Extensive experiments demonstrate\nthat VQAThinker achieves state-of-the-art performance on both in-domain and OOD\nVQA benchmarks, showing strong generalization for video quality scoring.\nFurthermore, evaluations on video quality understanding tasks validate its\nsuperiority in distortion attribution and quality description compared to\nexisting explainable VQA models and LMMs. These findings demonstrate that\nreinforcement learning offers an effective pathway toward building\ngeneralizable and explainable VQA models solely with score-level supervision.", "published": "2025-08-08 06:16:23", "link": "http://arxiv.org/abs/2508.06051v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NEP: Autoregressive Image Editing via Next Editing Token Prediction", "abstract": "Text-guided image editing involves modifying a source image based on a\nlanguage instruction and, typically, requires changes to only small local\nregions. However, existing approaches generate the entire target image rather\nthan selectively regenerate only the intended editing areas. This results in\n(1) unnecessary computational costs and (2) a bias toward reconstructing\nnon-editing regions, which compromises the quality of the intended edits. To\nresolve these limitations, we propose to formulate image editing as Next\nEditing-token Prediction (NEP) based on autoregressive image generation, where\nonly regions that need to be edited are regenerated, thus avoiding unintended\nmodification to the non-editing areas. To enable any-region editing, we propose\nto pre-train an any-order autoregressive text-to-image (T2I) model. Once\ntrained, it is capable of zero-shot image editing and can be easily adapted to\nNEP for image editing, which achieves a new state-of-the-art on widely used\nimage editing benchmarks. Moreover, our model naturally supports test-time\nscaling (TTS) through iteratively refining its generation in a zero-shot\nmanner. The project page is: https://nep-bigai.github.io/", "published": "2025-08-08 06:06:34", "link": "http://arxiv.org/abs/2508.06044v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment", "abstract": "In this paper, we present our solution for the semi-supervised learning track\n(MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the\nprinciple that \"more is better,\" to construct a robust Mixture of Experts (MoE)\nemotion recognition system. Our approach integrates a diverse range of input\nmodalities as independent experts, including novel signals such as knowledge\nfrom large Vision-Language Models (VLMs) and temporal Action Unit (AU)\ninformation. To effectively utilize unlabeled data, we introduce a\nconsensus-based pseudo-labeling strategy, generating high-quality labels from\nthe agreement between a baseline model and Gemini, which are then used in a\ntwo-stage training paradigm. Finally, we employ a multi-expert voting ensemble\ncombined with a rule-based re-ranking process to correct prediction bias and\nbetter align the outputs with human preferences. Evaluated on the MER2025-SEMI\nchallenge dataset, our method achieves an F1-score of 0.8772 on the test set,\nranking 2nd in the track. Our code is available at\nhttps://github.com/zhuyjan/MER2025-MRAC25.", "published": "2025-08-08 05:44:26", "link": "http://arxiv.org/abs/2508.06036v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow", "abstract": "We propose a fast text-guided image editing method called InstantEdit based\non the RectifiedFlow framework, which is structured as a few-step editing\nprocess that preserves critical content while following closely to textual\ninstructions. Our approach leverages the straight sampling trajectories of\nRectifiedFlow by introducing a specialized inversion strategy called PerRFI. To\nmaintain consistent while editable results for RectifiedFlow model, we further\npropose a novel regeneration method, Inversion Latent Injection, which\neffectively reuses latent information obtained during inversion to facilitate\nmore coherent and detailed regeneration. Additionally, we propose a\nDisentangled Prompt Guidance technique to balance editability with detail\npreservation, and integrate a Canny-conditioned ControlNet to incorporate\nstructural cues and suppress artifacts. Evaluation on the PIE image editing\ndataset demonstrates that InstantEdit is not only fast but also achieves better\nqualitative and quantitative results compared to state-of-the-art few-step\nediting methods.", "published": "2025-08-08 05:38:17", "link": "http://arxiv.org/abs/2508.06033v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts", "abstract": "Existing methods for human parsing into body parts and clothing often use\nfixed mask categories with broad labels that obscure fine-grained clothing\ntypes. Recent open-vocabulary segmentation approaches leverage pretrained\ntext-to-image (T2I) diffusion model features for strong zero-shot transfer, but\ntypically group entire humans into a single person category, failing to\ndistinguish diverse clothing or detailed body parts. To address this, we\npropose Spectrum, a unified network for part-level pixel parsing (body parts\nand clothing) and instance-level grouping. While diffusion-based\nopen-vocabulary models generalize well across tasks, their internal\nrepresentations are not specialized for detailed human parsing. We observe\nthat, unlike diffusion models with broad representations, image-driven 3D\ntexture generators maintain faithful correspondence to input images, enabling\nstronger representations for parsing diverse clothing and body parts. Spectrum\nintroduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model --\nobtained by fine-tuning a T2I model on 3D human texture maps -- for improved\nalignment with body parts and clothing. From an input image, we extract\nhuman-part internal features via the I2Tx diffusion model and generate\nsemantically valid masks aligned to diverse clothing categories through\nprompt-guided grounding. Once trained, Spectrum produces semantic segmentation\nmaps for every visible body part and clothing category, ignoring standalone\ngarments or irrelevant objects, for any number of humans in the scene. We\nconduct extensive cross-dataset experiments -- separately assessing body parts,\nclothing parts, unseen clothing categories, and full-body masks -- and\ndemonstrate that Spectrum consistently outperforms baseline methods in\nprompt-based segmentation.", "published": "2025-08-08 05:36:20", "link": "http://arxiv.org/abs/2508.06032v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors", "abstract": "Recent advances in novel view synthesis (NVS) have enabled real-time\nrendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle\nwith artifacts and missing regions when rendering from viewpoints that deviate\nfrom the training trajectory, limiting seamless scene exploration. To address\nthis, we propose a 3DGS-based pipeline that generates additional training views\nto enhance reconstruction. We introduce an information-gain-driven virtual\ncamera placement strategy to maximize scene coverage, followed by video\ndiffusion priors to refine rendered results. Fine-tuning 3D Gaussians with\nthese enhanced views significantly improves reconstruction quality. To evaluate\nour method, we present Wild-Explore, a benchmark designed for challenging scene\nexploration. Experiments demonstrate that our approach outperforms existing\n3DGS-based methods, enabling high-quality, artifact-free rendering from\narbitrary viewpoints.\n  https://exploregs.github.io", "published": "2025-08-08 05:01:17", "link": "http://arxiv.org/abs/2508.06014v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in visual mathematical reasoning across various existing\nbenchmarks. However, these benchmarks are predominantly based on clean or\nprocessed multimodal inputs, without incorporating the images provided by\nreal-world Kindergarten through 12th grade (K-12) educational users. To address\nthis gap, we introduce MathReal, a meticulously curated dataset comprising\n2,000 mathematical questions with images captured by handheld mobile devices in\nauthentic scenarios. Each question is an image, containing the question text\nand visual element. We systematically classify the real images into three\nprimary categories: image quality degradation, perspective variation, and\nirrelevant content interference, which are further delineated into 14\nsubcategories. Additionally, MathReal spans five core knowledge and ability\ncategories, which encompass three question types and are divided into three\ndifficulty levels. To comprehensively evaluate the multimodal mathematical\nreasoning abilities of state-of-the-art MLLMs in real-world scenarios, we\ndesign six experimental settings that enable a systematic analysis of their\nperformance. Through extensive experimentation, we find that the\nproblem-solving abilities of existing MLLMs are significantly challenged in\nrealistic educational contexts. Based on this, we conduct a thorough analysis\nof their performance and error patterns, providing insights into their\nrecognition, comprehension, and reasoning capabilities, and outlining\ndirections for future improvements. Data and code:\nhttps://github.com/junfeng0288/MathReal.", "published": "2025-08-08 04:39:16", "link": "http://arxiv.org/abs/2508.06009v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training", "abstract": "We present KnapFormer, an efficient and versatile framework to combine\nworkload balancing and sequence parallelism in distributed training of\nDiffusion Transformers (DiT). KnapFormer builds on the insight that strong\nsynergy exists between sequence parallelism and the need to address the\nsignificant token imbalance across ranks. This imbalance arises from\nvariable-length text inputs and varying visual token counts in mixed-resolution\nand image-video joint training. KnapFormer redistributes tokens by first\ngathering sequence length metadata across all ranks in a balancing group and\nsolving a global knapsack problem. The solver aims to minimize the variances of\ntotal workload per-GPU, while accounting for the effect of sequence\nparallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the\nload-balancing decision process and utilizing a simple semi-empirical workload\nmodel, KnapFormers achieves minimal communication overhead and less than 1%\nworkload discrepancy in real-world training workloads with sequence length\nvarying from a few hundred to tens of thousands. It eliminates straggler\neffects and achieves 2x to 3x speedup when training state-of-the-art diffusion\nmodels like FLUX on mixed-resolution and image-video joint data corpora. We\nopen-source the KnapFormer implementation at\nhttps://github.com/Kai-46/KnapFormer/", "published": "2025-08-08 04:06:08", "link": "http://arxiv.org/abs/2508.06001v1", "categories": ["cs.DC", "cs.CV"], "primary_category": "cs.DC"}
{"title": "EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad", "abstract": "Facial makeup editing aims to realistically transfer makeup from a reference\nto a target face. Existing methods often produce low-quality results with\ncoarse makeup details and struggle to preserve both identity and makeup\nfidelity, mainly due to the lack of structured paired data -- where source and\nresult share identity, and reference and result share identical makeup. To\naddress this, we introduce MakeupQuad, a large-scale, high-quality dataset with\nnon-makeup faces, references, edited results, and textual makeup descriptions.\nBuilding on this, we propose EvoMakeup, a unified training framework that\nmitigates image degradation during multi-stage distillation, enabling iterative\nimprovement of both data and model quality. Although trained solely on\nsynthetic data, EvoMakeup generalizes well and outperforms prior methods on\nreal-world benchmarks. It supports high-fidelity, controllable, multi-task\nmakeup editing -- including full-face and partial reference-based editing, as\nwell as text-driven makeup editing -- within a single model. Experimental\nresults demonstrate that our method achieves superior makeup fidelity and\nidentity preservation, effectively balancing both aspects. Code and dataset\nwill be released upon acceptance.", "published": "2025-08-08 04:00:45", "link": "http://arxiv.org/abs/2508.05994v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision", "abstract": "The efficiency of video computer vision system remains a challenging task due\nto the high temporal redundancy inside a video. Existing works have been\nproposed for efficient vision computer vision. However, they do not fully\nreduce the temporal redundancy and neglect the front end computation overhead.\nIn this paper, we propose an efficient video computer vision system. First,\nimage signal processor is removed and Bayer-format data is directly fed into\nvideo computer vision models, thus saving the front end computation. Second,\ninstead of optical flow models and video codecs, a fast block matching-based\nmotion estimation algorithm is proposed specifically for efficient video\ncomputer vision, with a MV refinement module. To correct the error,\ncontext-aware block refinement network is introduced to refine regions with\nlarge error. To further balance the accuracy and efficiency, a frame selection\nstrategy is employed. Experiments on multiple video computer vision tasks\ndemonstrate that our method achieves significant acceleration with slight\nperformance loss.", "published": "2025-08-08 03:55:19", "link": "http://arxiv.org/abs/2508.05990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnimateScene: Camera-controllable Animation in Any Scene", "abstract": "3D scene reconstruction and 4D human animation have seen rapid progress and\nbroad adoption in recent years. However, seamlessly integrating reconstructed\nscenes with 4D human animation to produce visually engaging results remains\nchallenging. One key difficulty lies in placing the human at the correct\nlocation and scale within the scene while avoiding unrealistic\ninterpenetration. Another challenge is that the human and the background may\nexhibit different lighting and style, leading to unrealistic composites. In\naddition, appealing character motion videos are often accompanied by camera\nmovements, which means that the viewpoints need to be reconstructed along a\nspecified trajectory. We present AnimateScene, which addresses the above issues\nin a unified framework. First, we design an accurate placement module that\nautomatically determines a plausible 3D position for the human and prevents any\ninterpenetration within the scene during motion. Second, we propose a\ntraining-free style alignment method that adapts the 4D human representation to\nmatch the background's lighting and style, achieving coherent visual\nintegration. Finally, we design a joint post-reconstruction method for both the\n4D human and the 3D scene that allows camera trajectories to be inserted,\nenabling the final rendered video to feature visually appealing camera\nmovements. Extensive experiments show that AnimateScene generates dynamic scene\nvideos with high geometric detail and spatiotemporal coherence across various\ncamera and action combinations.", "published": "2025-08-08 03:28:17", "link": "http://arxiv.org/abs/2508.05982v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation", "abstract": "The fragmentation between high-level task semantics and low-level geometric\nfeatures remains a persistent challenge in robotic manipulation. While\nvision-language models (VLMs) have shown promise in generating affordance-aware\nvisual representations, the lack of semantic grounding in canonical spaces and\nreliance on manual annotations severely limit their ability to capture dynamic\nsemantic-affordance relationships. To address these, we propose Primitive-Aware\nSemantic Grounding (PASG), a closed-loop framework that introduces: (1)\nAutomatic primitive extraction through geometric feature aggregation, enabling\ncross-category detection of keypoints and axes; (2) VLM-driven semantic\nanchoring that dynamically couples geometric primitives with functional\naffordances and task-relevant description; (3) A spatial-semantic reasoning\nbenchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's\neffectiveness in practical robotic manipulation tasks across diverse scenarios,\nachieving performance comparable to manual annotations. PASG achieves a\nfiner-grained semantic-affordance understanding of objects, establishing a\nunified paradigm for bridging geometric primitives with task semantics in\nrobotic manipulation.", "published": "2025-08-08 03:23:33", "link": "http://arxiv.org/abs/2508.05976v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation", "abstract": "Monitoring construction progress is crucial yet resource-intensive, prompting\nthe exploration of computer-vision-based methodologies for enhanced efficiency\nand scalability. Traditional data acquisition methods, primarily focusing on\nindoor environments, falter in construction site's complex, cluttered, and\ndynamically changing conditions. This paper critically evaluates the\napplication of two advanced 3D segmentation methods, Segment Anything Model\n(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained\ninitially on indoor datasets, both models' adaptability and performance are\nassessed in real-world construction settings, highlighting the gap in current\nsegmentation approaches due to the absence of benchmarks for outdoor scenarios.\nThrough a comparative analysis, this study not only showcases the relative\neffectiveness of SAM and Mask3D but also addresses the critical need for\ntailored segmentation workflows capable of extracting actionable insights from\nconstruction site data, thereby advancing the field towards more automated and\nprecise monitoring techniques.", "published": "2025-08-08 00:57:39", "link": "http://arxiv.org/abs/2508.05922v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Neural Field Representations of Mobile Computational Photography", "abstract": "Over the past two decades, mobile imaging has experienced a profound\ntransformation, with cell phones rapidly eclipsing all other forms of digital\nphotography in popularity. Today's cell phones are equipped with a diverse\nrange of imaging technologies - laser depth ranging, multi-focal camera arrays,\nand split-pixel sensors - alongside non-visual sensors such as gyroscopes,\naccelerometers, and magnetometers. This, combined with on-board integrated\nchips for image and signal processing, makes the cell phone a versatile\npocket-sized computational imaging platform. Parallel to this, we have seen in\nrecent years how neural fields - small neural networks trained to map\ncontinuous spatial input coordinates to output signals - enable the\nreconstruction of complex scenes without explicit data representations such as\npixel arrays or point clouds. In this thesis, I demonstrate how carefully\ndesigned neural field models can compactly represent complex geometry and\nlighting effects. Enabling applications such as depth estimation, layer\nseparation, and image stitching directly from collected in-the-wild mobile\nphotography data. These methods outperform state-of-the-art approaches without\nrelying on complex pre-processing steps, labeled ground truth data, or machine\nlearning priors. Instead, they leverage well-constructed, self-regularized\nmodels that tackle challenging inverse problems through stochastic gradient\ndescent, fitting directly to raw measurements from a smartphone.", "published": "2025-08-08 00:03:46", "link": "http://arxiv.org/abs/2508.05907v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting", "abstract": "Cold-start challenges in recommender systems necessitate leveraging auxiliary\nfeatures beyond user-item interactions. However, the presence of irrelevant or\nnoisy features can degrade predictive performance, whereas an excessive number\nof features increases computational demands, leading to higher memory\nconsumption and prolonged training times.\n  To address this, we propose a feature selection strategy that prioritizes the\nuser behavioral information. Our method enhances the feature representation by\nincorporating correlations from collaborative behavior data using a hybrid\nmatrix factorization technique and then ranks features using a mechanism based\non the maximum volume algorithm. This approach identifies the most influential\nfeatures, striking a balance between recommendation accuracy and computational\nefficiency. We conduct an extensive evaluation across various datasets and\nhybrid recommendation models, demonstrating that our method excels in\ncold-start scenarios by selecting minimal yet highly effective feature subsets.\nEven under strict feature reduction, our approach surpasses existing feature\nselection techniques while maintaining superior efficiency.", "published": "2025-08-08 16:58:47", "link": "http://arxiv.org/abs/2508.06455v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion", "abstract": "Since their introduction, Transformer-based models, such as SASRec and\nBERT4Rec, have become common baselines for sequential recommendations,\nsurpassing earlier neural and non-neural methods. A number of following\npublications have shown that the effectiveness of these models can be improved\nby, for example, slightly updating the architecture of the Transformer layers,\nusing better training objectives, and employing improved loss functions.\nHowever, the additivity of these modular improvements has not been\nsystematically benchmarked - this is the gap we aim to close in this paper.\nThrough our experiments, we identify a very strong model that uses SASRec's\ntraining objective, LiGR Transformer layers, and Sampled Softmax Loss. We call\nthis combination eSASRec (Enhanced SASRec). While we primarily focus on\nrealistic, production-like evaluation, in our preliminarily study we find that\ncommon academic benchmarks show eSASRec to be 23% more effective compared to\nthe most recent state-of-the-art models, such as ActionPiece. In our main\nproduction-like benchmark, eSASRec resides on the Pareto frontier in terms of\nthe accuracy-coverage tradeoff (alongside the recent industrial models HSTU and\nFuXi. As the modifications compared to the original SASRec are relatively\nstraightforward and no extra features are needed (such as timestamps in HSTU),\nwe believe that eSASRec can be easily integrated into existing recommendation\npipelines and can can serve as a strong yet very simple baseline for emerging\ncomplicated algorithms. To facilitate this, we provide the open-source\nimplementations for our models and benchmarks in repository\nhttps://github.com/blondered/transformer_benchmark", "published": "2025-08-08 16:49:03", "link": "http://arxiv.org/abs/2508.06450v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation", "abstract": "Current research on Multimodal Retrieval-Augmented Generation (MRAG) enables\ndiverse multimodal inputs but remains limited to single-modality outputs,\nrestricting expressive capacity and practical utility. In contrast, real-world\napplications often demand both multimodal inputs and multimodal outputs for\neffective communication and grounded reasoning. Motivated by the recent success\nof Reinforcement Learning (RL) in complex reasoning tasks for Large Language\nModels (LLMs), we adopt RL as a principled and effective paradigm to address\nthe multi-step, outcome-driven challenges inherent in multimodal output\ngeneration. Here, we introduce M2IO-R1, a novel framework for Multimodal\nRetrieval-Augmented Multimodal Generation (MRAMG) that supports both multimodal\ninputs and outputs. Central to our framework is an RL-based inserter,\nInserter-R1-3B, trained with Group Relative Policy Optimization to guide image\nselection and placement in a controllable and semantically aligned manner.\nEmpirical results show that our lightweight 3B inserter achieves strong\nreasoning capabilities with significantly reduced latency, outperforming\nbaselines in both quality and efficiency.", "published": "2025-08-08 14:00:19", "link": "http://arxiv.org/abs/2508.06328v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Improving Table Retrieval with Question Generation from Partial Tables", "abstract": "Recent advances in open-domain question answering over tables have widely\nadopted large language models (LLMs) under the Retriever-Reader architecture.\nPrior works have effectively leveraged LLMs to tackle the complex reasoning\ndemands of the Reader component, such as text-to-text, text-to-SQL, and multi\nhop reasoning. In contrast, the Retriever component has primarily focused on\noptimizing the query representation-training retrievers to retrieve relevant\ntables based on questions, or to select keywords from questions for matching\ntable segments. However, little attention has been given to enhancing how\ntables themselves are represented in embedding space to better align with\nquestions. To address this, we propose QGpT (Question Generation from Partial\nTables), a simple yet effective method that uses an LLM to generate synthetic\nquestions based on small portions of a table. These questions are generated to\nsimulate how a user might query the content of the table currently under\nconsideration. The generated questions are then jointly embedded with the\npartial table segments used for generation, enhancing semantic alignment with\nuser queries. Without the need to embed entire tables, our method significantly\nimproves retrieval performance across multiple benchmarks for both dense and\nlate-interaction retrievers.", "published": "2025-08-08 09:35:56", "link": "http://arxiv.org/abs/2508.06168v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "When a Paper Has 1000 Authors: Rethinking Citation Metrics in the Era of LLMs", "abstract": "Author-level citation metrics provide a practical, interpretable, and\nscalable signal of scholarly influence in a complex research ecosystem. It has\nbeen widely used as a proxy in hiring decisions. However, the past five years\nhave seen the rapid emergence of large-scale publications in the field of large\nlanguage models and foundation models, with papers featuring hundreds to\nthousands of co-authors and receiving tens of thousands of citations within\nmonths. For example, Gemini has 1361 authors and has been cited around 4600\ntimes in 19 months. In such cases, traditional metrics, such as total citation\ncount and the $h$-index, fail to meaningfully distinguish individual\ncontributions. Therefore, we propose the following research question: How can\none identify standout researchers among thousands of co-authors in large-scale\nLLM papers? This question is particularly important in scenarios such as\nacademic hiring and funding decisions. In this paper, we introduce a novel\ncitation metric designed to address this challenge by balancing contributions\nacross large-scale and small-scale publications. We propose the SBCI index,\nanalyze its theoretical properties, and evaluate its behavior on synthetic\npublication datasets. Our results demonstrate that the proposed metric provides\na more robust and discriminative assessment of individual scholarly impact in\nthe era of large-scale collaborations.", "published": "2025-08-08 04:18:26", "link": "http://arxiv.org/abs/2508.06004v1", "categories": ["cs.DL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts", "abstract": "Streaming recommender systems (SRSs) are widely deployed in real-world\napplications, where user interests shift and new items arrive over time. As a\nresult, effectively capturing users' latest preferences is challenging, as\ninteractions reflecting recent interests are limited and new items often lack\nsufficient feedback. A common solution is to enrich item representations using\nmultimodal encoders (e.g., BERT or ViT) to extract visual and textual features.\nHowever, these encoders are pretrained on general-purpose tasks: they are not\ntailored to user preference modeling, and they overlook the fact that user\ntastes toward modality-specific features such as visual styles and textual\ntones can also drift over time. This presents two key challenges in streaming\nscenarios: the high cost of fine-tuning large multimodal encoders, and the risk\nof forgetting long-term user preferences due to continuous model updates.\n  To tackle these challenges, we propose Expandable Side Mixture-of-Experts\n(XSMoE), a memory-efficient framework for multimodal streaming recommendation.\nXSMoE attaches lightweight side-tuning modules consisting of expandable expert\nnetworks to frozen pretrained encoders and incrementally expands them in\nresponse to evolving user feedback. A gating router dynamically combines expert\nand backbone outputs, while a utilization-based pruning strategy maintains\nmodel compactness. By learning new patterns through expandable experts without\noverwriting previously acquired knowledge, XSMoE effectively captures both cold\nstart and shifting preferences in multimodal features. Experiments on three\nreal-world datasets demonstrate that XSMoE outperforms state-of-the-art\nbaselines in both recommendation quality and computational efficiency.", "published": "2025-08-08 04:00:05", "link": "http://arxiv.org/abs/2508.05993v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Dual prototype attentive graph network for cross-market recommendation", "abstract": "Cross-market recommender systems (CMRS) aim to utilize historical data from\nmature markets to promote multinational products in emerging markets. However,\nexisting CMRS approaches often overlook the potential for shared preferences\namong users in different markets, focusing primarily on modeling specific\npreferences within each market. In this paper, we argue that incorporating both\nmarket-specific and market-shared insights can enhance the generalizability and\nrobustness of CMRS. We propose a novel approach called Dual Prototype Attentive\nGraph Network for Cross-Market Recommendation (DGRE) to address this. DGRE\nleverages prototypes based on graph representation learning from both items and\nusers to capture market-specific and market-shared insights. Specifically, DGRE\nincorporates market-shared prototypes by clustering users from various markets\nto identify behavioural similarities and create market-shared user profiles.\nAdditionally, it constructs item-side prototypes by aggregating item features\nwithin each market, providing valuable market-specific insights. We conduct\nextensive experiments to validate the effectiveness of DGRE on a real-world\ncross-market dataset, and the results show that considering both\nmarket-specific and market-sharing aspects in modelling can improve the\ngeneralization and robustness of CMRS.", "published": "2025-08-08 03:07:44", "link": "http://arxiv.org/abs/2508.05969v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection", "abstract": "The growing legal and ethical scrutiny of large language models (LLMs)\nnecessitates effective machine unlearning, particularly for sensitive or\nunauthorized data. Existing empirical methods often yield incomplete forgetting\nor unintended degradation of unrelated knowledge due to poor localization. In\nthis work, we propose GRIN: a modular and targeted framework for LLM\nunlearning. GRIN introduces a novel gradient-ratio-based metric to identify\nparameters most responsible for memorizing forget data. We then perform\nselective noise injection into these parameters prior to fine-tuning, which\nimproves unlearning performance while maintaining model utility. Finally, we\npropose new evaluation metrics tailored to the LLM setting and validate our\napproach on standard benchmarks such as TOFU, WMDP, and SafePKU.", "published": "2025-08-08 17:15:32", "link": "http://arxiv.org/abs/2508.06467v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images", "abstract": "Homelessness in the United States has surged to levels unseen since the Great\nDepression. However, existing methods for monitoring it, such as point-in-time\n(PIT) counts, have limitations in terms of frequency, consistency, and spatial\ndetail. This study proposes a new approach using publicly available,\ncrowdsourced data, specifically 311 Service Calls and street-level imagery, to\ntrack and forecast homeless tent trends in San Francisco. Our predictive model\ncaptures fine-grained daily and neighborhood-level variations, uncovering\npatterns that traditional counts often overlook, such as rapid fluctuations\nduring the COVID-19 pandemic and spatial shifts in tent locations over time. By\nproviding more timely, localized, and cost-effective information, this approach\nserves as a valuable tool for guiding policy responses and evaluating\ninterventions aimed at reducing unsheltered homelessness.", "published": "2025-08-08 15:53:29", "link": "http://arxiv.org/abs/2508.06409v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Blockchain-Enabled Federated Learning", "abstract": "Blockchain-enabled federated learning (BCFL) addresses fundamental challenges\nof trust, privacy, and coordination in collaborative AI systems. This chapter\nprovides comprehensive architectural analysis of BCFL systems through a\nsystematic four-dimensional taxonomy examining coordination structures,\nconsensus mechanisms, storage architectures, and trust models. We analyze\ndesign patterns from blockchain-verified centralized coordination to fully\ndecentralized peer-to-peer networks, evaluating trade-offs in scalability,\nsecurity, and performance. Through detailed examination of consensus mechanisms\ndesigned for federated learning contexts, including Proof of Quality and Proof\nof Federated Learning, we demonstrate how computational work can be repurposed\nfrom arbitrary cryptographic puzzles to productive machine learning tasks. The\nchapter addresses critical storage challenges by examining multi-tier\narchitectures that balance blockchain's transaction constraints with neural\nnetworks' large parameter requirements while maintaining cryptographic\nintegrity. A technical case study of the TrustMesh framework illustrates\npractical implementation considerations in BCFL systems through distributed\nimage classification training, demonstrating effective collaborative learning\nacross IoT devices with highly non-IID data distributions while maintaining\ncomplete transparency and fault tolerance. Analysis of real-world deployments\nacross healthcare consortiums, financial services, and IoT security\napplications validates the practical viability of BCFL systems, achieving\nperformance comparable to centralized approaches while providing enhanced\nsecurity guarantees and enabling new models of trustless collaborative\nintelligence.", "published": "2025-08-08 15:47:55", "link": "http://arxiv.org/abs/2508.06406v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms", "abstract": "Symbolic indefinite integration in Computer Algebra Systems such as Maple\ninvolves selecting the most effective algorithm from multiple available\nmethods. Not all methods will succeed for a given problem, and when several do,\nthe results, though mathematically equivalent, can differ greatly in\npresentation complexity. Traditionally, this choice has been made with minimal\nconsideration of the problem instance, leading to inefficiencies.\n  We present a machine learning (ML) approach using tree-based deep learning\nmodels within a two-stage architecture: first identifying applicable methods\nfor a given instance, then ranking them by predicted output complexity.\nFurthermore, we find representing mathematical expressions as tree structures\nsignificantly improves performance over sequence-based representations, and our\ntwo-stage framework outperforms alternative ML formulations.\n  Using a diverse dataset generated by six distinct data generators, our models\nachieve nearly 90% accuracy in selecting the optimal method on a 70,000 example\nholdout test set. On an independent out-of-distribution benchmark from Maple's\ninternal test suite, our tree transformer model maintains strong\ngeneralisation, outperforming Maple's built-in selector and prior ML\napproaches.\n  These results highlight the critical role of data representation and problem\nframing in ML for symbolic computation, and we expect our methodology to\ngeneralise effectively to similar optimisation problems in mathematical\nsoftware.", "published": "2025-08-08 15:13:39", "link": "http://arxiv.org/abs/2508.06383v1", "categories": ["cs.SC", "cs.LG"], "primary_category": "cs.SC"}
{"title": "DP-SPRT: Differentially Private Sequential Probability Ratio Tests", "abstract": "We revisit Wald's celebrated Sequential Probability Ratio Test for sequential\ntests of two simple hypotheses, under privacy constraints. We propose DP-SPRT,\na wrapper that can be calibrated to achieve desired error probabilities and\nprivacy constraints, addressing a significant gap in previous work. DP-SPRT\nrelies on a private mechanism that processes a sequence of queries and stops\nafter privately determining when the query results fall outside a predefined\ninterval. This OutsideInterval mechanism improves upon naive composition of\nexisting techniques like AboveThreshold, potentially benefiting other\nsequential algorithms. We prove generic upper bounds on the error and sample\ncomplexity of DP-SPRT that can accommodate various noise distributions based on\nthe practitioner's privacy needs. We exemplify them in two settings: Laplace\nnoise (pure Differential Privacy) and Gaussian noise (R\\'enyi differential\nprivacy). In the former setting, by providing a lower bound on the sample\ncomplexity of any $\\epsilon$-DP test with prescribed type I and type II errors,\nwe show that DP-SPRT is near optimal when both errors are small and the two\nhypotheses are close. Moreover, we conduct an experimental study revealing its\ngood practical performance.", "published": "2025-08-08 15:09:13", "link": "http://arxiv.org/abs/2508.06377v1", "categories": ["stat.ML", "cs.CR", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means", "abstract": "This paper introduces Geometric-k-means (or Gk-means for short), a novel\napproach that significantly enhances the efficiency and energy economy of the\nwidely utilized k-means algorithm, which, despite its inception over five\ndecades ago, remains a cornerstone in machine learning applications. The\nessence of Gk-means lies in its active utilization of geometric principles,\nspecifically scalar projection, to significantly accelerate the algorithm\nwithout sacrificing solution quality. This geometric strategy enables a more\ndiscerning focus on data points that are most likely to influence cluster\nupdates, which we call as high expressive data (HE). In contrast, low\nexpressive data (LE), does not impact clustering outcome, is effectively\nbypassed, leading to considerable reductions in computational overhead.\nExperiments spanning synthetic, real-world and high-dimensional datasets,\ndemonstrate Gk-means is significantly better than traditional and state of the\nart (SOTA) k-means variants in runtime and distance computations (DC).\nMoreover, Gk-means exhibits better resource efficiency, as evidenced by its\nreduced energy footprint, placing it as more sustainable alternative.", "published": "2025-08-08 14:32:42", "link": "http://arxiv.org/abs/2508.06353v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Introducing Fractional Classification Loss for Robust Learning with Noisy Labels", "abstract": "Robust loss functions are crucial for training deep neural networks in the\npresence of label noise, yet existing approaches require extensive,\ndataset-specific hyperparameter tuning. In this work, we introduce Fractional\nClassification Loss (FCL), an adaptive robust loss that automatically\ncalibrates its robustness to label noise during training. Built within the\nactive-passive loss framework, FCL employs the fractional derivative of the\nCross-Entropy (CE) loss as its active component and the Mean Absolute Error\n(MAE) as its passive loss component. With this formulation, we demonstrate that\nthe fractional derivative order $\\mu$ spans a family of loss functions that\ninterpolate between MAE-like robustness and CE-like fast convergence.\nFurthermore, we integrate $\\mu$ into the gradient-based optimization as a\nlearnable parameter and automatically adjust it to optimize the trade-off\nbetween robustness and convergence speed. We reveal that FCL's unique property\nestablishes a critical trade-off that enables the stable learning of $\\mu$:\nlower log penalties on difficult or mislabeled examples improve robustness but\nimpose higher penalties on easy or clean data, reducing model confidence in\nthem. Consequently, FCL can dynamically reshape its loss landscape to achieve\neffective classification performance under label noise. Extensive experiments\non benchmark datasets show that FCL achieves state-of-the-art results without\nthe need for manual hyperparameter tuning.", "published": "2025-08-08 14:20:52", "link": "http://arxiv.org/abs/2508.06346v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Decorrelated feature importance from local sample weighting", "abstract": "Feature importance (FI) statistics provide a prominent and valuable method of\ninsight into the decision process of machine learning (ML) models, but their\neffectiveness has well-known limitations when correlation is present among the\nfeatures in the training data. In this case, the FI often tends to be\ndistributed among all features which are in correlation with the\nresponse-generating signal features. Even worse, if multiple signal features\nare in strong correlation with a noise feature, while being only modestly\ncorrelated with one another, this can result in a noise feature having a\ndistinctly larger FI score than any signal feature. Here we propose local\nsample weighting (losaw) which can flexibly be integrated into many ML\nalgorithms to improve FI scores in the presence of feature correlation in the\ntraining data. Our approach is motivated from inverse probability weighting in\ncausal inference and locally, within the ML model, uses a sample weighting\nscheme to decorrelate a target feature from the remaining features. This\nreduces model bias locally, whenever the effect of a potential signal feature\nis evaluated and compared to others. Moreover, losaw comes with a natural\ntuning parameter, the minimum effective sample size of the weighted population,\nwhich corresponds to an interpretation-prediction-tradeoff, analog to a\nbias-variance-tradeoff as for classical ML tuning parameters. We demonstrate\nhow losaw can be integrated within decision tree-based ML methods and within\nmini-batch training of neural networks. We investigate losaw for random forest\nand convolutional neural networks in a simulation study on settings showing\ndiverse correlation patterns. We found that losaw improves FI consistently.\nMoreover, it often improves prediction accuracy for out-of-distribution, while\nmaintaining a similar accuracy for in-distribution test data.", "published": "2025-08-08 14:11:18", "link": "http://arxiv.org/abs/2508.06337v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback", "abstract": "Neuromorphic computing is an emerging technology enabling low-latency and\nenergy-efficient signal processing. A key algorithmic tool in neuromorphic\ncomputing is spiking neural networks (SNNs). SNNs are biologically inspired\nneural networks which utilize stateful neurons, and provide low-bit data\nprocessing by encoding and decoding information using spikes. Similar to SNNs,\ndeep state-space models (SSMs) utilize stateful building blocks. However, deep\nSSMs, which recently achieved competitive performance in various temporal\nmodeling tasks, are typically designed with high-precision activation functions\nand no reset mechanisms. To bridge the gains offered by SNNs and the recent\ndeep SSM models, we propose a novel multiple-output spiking neuron model that\ncombines a linear, general SSM state transition with a non-linear feedback\nmechanism through reset. Compared to the existing neuron models for SNNs, our\nproposed model clearly conceptualizes the differences between the spiking\nfunction, the reset condition and the reset action. The experimental results on\nvarious tasks, i.e., a keyword spotting task, an event-based vision task and a\nsequential pattern recognition task, show that our proposed model achieves\nperformance comparable to existing benchmarks in the SNN literature. Our\nresults illustrate how the proposed reset mechanism can overcome instability\nand enable learning even when the linear part of neuron dynamics is unstable,\nallowing us to go beyond the strictly enforced stability of linear dynamics in\nrecent deep SSM models.", "published": "2025-08-08 13:12:13", "link": "http://arxiv.org/abs/2508.06292v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Study on Regularization-Based Continual Learning Methods for Indic ASR", "abstract": "Indias linguistic diversity poses significant challenges for developing\ninclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual\nmodels, which require simultaneous access to all language data, are impractical\ndue to the sequential arrival of data and privacy constraints. Continual\nLearning (CL) offers a solution by enabling models to learn new languages\nsequentially without catastrophically forgetting previously learned knowledge.\nThis paper investigates CL for ASR on Indian languages using a subset of the\nIndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,\ninitially pretrained on Hindi, which is then incrementally trained on eight\nadditional Indian languages, for a total sequence of nine languages. We\nevaluate three prominent regularization- and distillation-based CL strategies:\nElastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning\nwithout Forgetting (LwF), selected for their suitability in no-replay,\nprivacy-conscious scenarios. Performance is analyzed using Word Error Rate\n(WER) for both RNN-T and CTC paths on clean and noisy data, as well as\nknowledge retention via Backward Transfer. We also explore the impact of\nvarying the number of training epochs (1, 2, 5, and 10) per task. Results,\ncompared against naive fine-tuning, demonstrate CLs effectiveness in mitigating\nforgetting, making it a promising approach for scalable ASR in diverse Indian\nlanguages under realistic constraints. The code is available at:\nhttps://github.com/FrozenWolf-Cyber/Indic-CL-ASR", "published": "2025-08-08 13:02:19", "link": "http://arxiv.org/abs/2508.06280v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors", "abstract": "Integrating multi-omics datasets through data-driven analysis offers a\ncomprehensive understanding of the complex biological processes underlying\nvarious diseases, particularly cancer. Graph Neural Networks (GNNs) have\nrecently demonstrated remarkable ability to exploit relational structures in\nbiological data, enabling advances in multi-omics integration for cancer\nsubtype classification. Existing approaches often neglect the intricate\ncoupling between heterogeneous omics, limiting their capacity to resolve subtle\ncancer subtype heterogeneity critical for precision oncology. To address these\nlimitations, we propose a framework named Graph Transformer for Multi-omics\nCancer Subtype Classification (GTMancer). This framework builds upon the GNN\noptimization problem and extends its application to complex multi-omics data.\nSpecifically, our method leverages contrastive learning to embed multi-omics\ndata into a unified semantic space. We unroll the multiplex graph optimization\nproblem in that unified space and introduce dual sets of attention coefficients\nto capture structural graph priors both within and among multi-omics data. This\napproach enables global omics information to guide the refining of the\nrepresentations of individual omics. Empirical experiments on seven real-world\ncancer datasets demonstrate that GTMancer outperforms existing state-of-the-art\nalgorithms.", "published": "2025-08-08 12:22:36", "link": "http://arxiv.org/abs/2508.06257v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits", "abstract": "The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential\ndecision-making framework, dominated by two algorithmic families: UCB-based and\nadversarial methods such as follow the regularized leader (FTRL) and online\nmirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer\nfrom additional regret factor $\\log T$ that is detrimental over long horizons,\nwhile adversarial methods such as EXP3.M and HYBRID impose significant\ncomputational overhead. To resolve this trade-off, we introduce the\nCombinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS\nis a computationally efficient algorithm that achieves an instance-independent\nregret of $O\\big( (\\log k)^2\\sqrt{kmT}\\big )$ under semi-bandit feedback, where\n$m$ is the number of arms and $k$ is the maximum cardinality of a feasible\naction. Crucially, this result eliminates the dependency on $\\log T$ and\nmatches the established $\\Omega\\big( \\sqrt{kmT}\\big)$ lower bound up to\n$O\\big((\\log k)^2\\big)$. We then extend our analysis to show that CMOSS is also\napplicable to cascading feedback. Experiments on synthetic and real-world\ndatasets validate that CMOSS consistently outperforms benchmark algorithms in\nboth regret and runtime efficiency.", "published": "2025-08-08 12:01:50", "link": "http://arxiv.org/abs/2508.06247v1", "categories": ["cs.LG", "cs.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems", "abstract": "The advent of 6G networks opens new possibilities for connected infotainment\nservices in vehicular environments. However, traditional Radio Resource\nManagement (RRM) techniques struggle with the increasing volume and complexity\nof data such as Channel Quality Indicators (CQI) from autonomous vehicles. To\naddress this, we propose SCAR (State-Space Compression for AI-Driven Resource\nManagement), an Edge AI-assisted framework that optimizes scheduling and\nfairness in vehicular infotainment. SCAR employs ML-based compression\ntechniques (e.g., clustering and RBF networks) to reduce CQI data size while\npreserving essential features. These compressed states are used to train\n6G-enabled Reinforcement Learning policies that maximize throughput while\nmeeting fairness objectives defined by the NGMN. Simulations show that SCAR\nincreases time in feasible scheduling regions by 14\\% and reduces unfair\nscheduling time by 15\\% compared to RL baselines without CQI compression.\nFurthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based\nclustering reduces CQI clustering distortion by 10\\%, confirming its\nefficiency. These results demonstrate SCAR's scalability and fairness benefits\nfor dynamic vehicular networks.", "published": "2025-08-08 11:53:18", "link": "http://arxiv.org/abs/2508.06243v1", "categories": ["cs.LG", "cs.NE", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications", "abstract": "Quantum machine learning (QML) presents potential for early industrial\nadoption, yet limited access to quantum hardware remains a significant\nbottleneck for deployment of QML solutions. This work explores the use of\nclassical surrogates to bypass this restriction, which is a technique that\nallows to build a lightweight classical representation of a (trained) quantum\nmodel, enabling to perform inference on entirely classical devices. We reveal\nprohibiting high computational demand associated with previously proposed\nmethods for generating classical surrogates from quantum models, and propose an\nalternative pipeline enabling generation of classical surrogates at a larger\nscale than was previously possible. Previous methods required at least a\nhigh-performance computing (HPC) system for quantum models of below industrial\nscale (ca. 20 qubits), which raises questions about its practicality. We\ngreatly minimize the redundancies of the previous approach, utilizing only a\nminute fraction of the resources previously needed. We demonstrate the\neffectiveness of our method on a real-world energy demand forecasting problem,\nconducting rigorous testing of performance and computation demand in both\nsimulations and on quantum hardware. Our results indicate that our method\nachieves high accuracy on the testing dataset while its computational resource\nrequirements scale linearly rather than exponentially. This work presents a\nlightweight approach to transform quantum solutions into classically deployable\nversions, facilitating faster integration of quantum technology in industrial\nsettings. Furthermore, it can serve as a powerful research tool in search\npractical quantum advantage in an empirical setup.", "published": "2025-08-08 08:51:01", "link": "http://arxiv.org/abs/2508.06131v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering", "abstract": "In clustering tasks, it is essential to structure the feature space into\nclear, well-separated distributions. However, because short text\nrepresentations have limited expressiveness, conventional methods struggle to\nidentify cluster centers that truly capture each category's underlying\nsemantics, causing the representations to be optimized in suboptimal\ndirections. To address this issue, we propose IOCC, a novel few-shot\ncontrastive learning method that achieves alignment between the cluster centers\nand the semantic centers. IOCC consists of two key modules:\nInteraction-enhanced Optimal Transport (IEOT) and Center-aware Contrastive\nLearning (CACL). Specifically, IEOT incorporates semantic interactions between\nindividual samples into the conventional optimal transport problem, and\ngenerate pseudo-labels. Based on these pseudo-labels, we aggregate\nhigh-confidence samples to construct pseudo-centers that approximate the\nsemantic centers. Next, CACL optimizes text representations toward their\ncorresponding pseudo-centers. As training progresses, the collaboration between\nthe two modules gradually reduces the gap between cluster centers and semantic\ncenters. Therefore, the model will learn a high-quality distribution, improving\nclustering performance. Extensive experiments on eight benchmark datasets show\nthat IOCC outperforms previous methods, achieving up to 7.34\\% improvement on\nchallenging Biomedical dataset and also excelling in clustering stability and\nefficiency. The code is available at:\nhttps://anonymous.4open.science/r/IOCC-C438.", "published": "2025-08-08 08:47:13", "link": "http://arxiv.org/abs/2508.06126v1", "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification", "abstract": "Understanding and classifying human cognitive brain states based on\nneuroimaging data remains one of the foremost and most challenging problems in\nneuroscience, owing to the high dimensionality and intrinsic noise of the\nsignals. In this work, we propose an ensemble-based graph representation method\nof functional magnetic resonance imaging (fMRI) data for the task of binary\nbrain-state classification. Our method builds the graph by leveraging multiple\nbase machine-learning models: each edge weight reflects the difference in\nposterior probabilities between two cognitive states, yielding values in the\nrange [-1, 1] that encode confidence in a given state. We applied this approach\nto seven cognitive tasks from the Human Connectome Project (HCP 1200 Subject\nRelease), including working memory, gambling, motor activity, language, social\ncognition, relational processing, and emotion processing. Using only the mean\nincident edge weights of the graphs as features, a simple logistic-regression\nclassifier achieved average accuracies from 97.07% to 99.74%. We also compared\nour ensemble graphs with classical correlation-based graphs in a classification\ntask with a graph neural network (GNN). In all experiments, the highest\nclassification accuracy was obtained with ensemble graphs. These results\ndemonstrate that ensemble graphs convey richer topological information and\nenhance brain-state discrimination. Our approach preserves edge-level\ninterpretability of the fMRI graph representation, is adaptable to multiclass\nand regression tasks, and can be extended to other neuroimaging modalities and\npathological-state classification.", "published": "2025-08-08 08:32:46", "link": "http://arxiv.org/abs/2508.06118v1", "categories": ["q-bio.NC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Recurrent Deep Differentiable Logic Gate Networks", "abstract": "While differentiable logic gates have shown promise in feedforward networks,\ntheir application to sequential modeling remains unexplored. This paper\npresents the first implementation of Recurrent Deep Differentiable Logic Gate\nNetworks (RDDLGN), combining Boolean operations with recurrent architectures\nfor sequence-to-sequence learning.\n  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and\n30.9\\% accuracy during training, approaching GRU performance (5.41 BLEU) and\ngraceful degradation (4.39 BLEU) during inference. This work establishes\nrecurrent logic-based neural computation as viable, opening research directions\nfor FPGA acceleration in sequential modeling and other recursive network\narchitectures.", "published": "2025-08-08 07:49:38", "link": "http://arxiv.org/abs/2508.06097v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive Backtracking for Privacy Protection in Large Language Models", "abstract": "The preservation of privacy has emerged as a critical topic in the era of\nartificial intelligence. However, current work focuses on user-oriented\nprivacy, overlooking severe enterprise data leakage risks exacerbated by the\nRetrieval-Augmented Generation paradigm. To address this gap, our paper\nintroduces a novel objective: enterprise-oriented privacy concerns. Achieving\nthis objective requires overcoming two fundamental challenges: existing methods\nsuch as data sanitization severely degrade model performance, and the field\nlacks public datasets for evaluation. We address these challenges with several\nsolutions. (1) To prevent performance degradation, we propose ABack, a\ntraining-free mechanism that leverages a Hidden State Model to pinpoint the\norigin of a leakage intention and rewrite the output safely. (2) To solve the\nlack of datasets, we construct PriGenQA, a new benchmark for enterprise privacy\nscenarios in healthcare and finance. To ensure a rigorous evaluation, we move\nbeyond simple static attacks by developing a powerful adaptive attacker with\nGroup Relative Policy Optimization. Experiments show that against this superior\nadversary, ABack improves the overall privacy utility score by up to 15\\% over\nstrong baselines, avoiding the performance trade-offs of prior methods.", "published": "2025-08-08 07:29:33", "link": "http://arxiv.org/abs/2508.06087v1", "categories": ["cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CR"}
{"title": "Lightweight Auto-bidding based on Traffic Prediction in Live Advertising", "abstract": "Internet live streaming is widely used in online entertainment and\ne-commerce, where live advertising is an important marketing tool for anchors.\nAn advertising campaign hopes to maximize the effect (such as conversions)\nunder constraints (such as budget and cost-per-click). The mainstream control\nof campaigns is auto-bidding, where the performance depends on the decision of\nthe bidding algorithm in each request. The most widely used auto-bidding\nalgorithms include Proportional-Integral-Derivative (PID) control, linear\nprogramming (LP), reinforcement learning (RL), etc. Existing methods either do\nnot consider the entire time traffic, or have too high computational\ncomplexity. In this paper, the live advertising has high requirements for\nreal-time bidding (second-level control) and faces the difficulty of unknown\nfuture traffic. Therefore, we propose a lightweight bidding algorithm Binary\nConstrained Bidding (BiCB), which neatly combines the optimal bidding formula\ngiven by mathematical analysis and the statistical method of future traffic\nestimation, and obtains good approximation to the optimal result through a low\ncomplexity solution. In addition, we complement the form of upper and lower\nbound constraints for traditional auto-bidding modeling and give theoretical\nanalysis of BiCB. Sufficient offline and online experiments prove BiCB's good\nperformance and low engineering cost.", "published": "2025-08-08 07:05:35", "link": "http://arxiv.org/abs/2508.06069v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance", "abstract": "We tackle the data-driven chance-constrained density steering problem using\nthe Gromov-Wasserstein metric. The underlying dynamical system is an unknown\nlinear controlled recursion, with the assumption that sufficiently rich\ninput-output data from pre-operational experiments are available. The initial\nstate is modeled as a Gaussian mixture, while the terminal state is required to\nmatch a specified Gaussian distribution. We reformulate the resulting optimal\ncontrol problem as a difference-of-convex program and show that it can be\nefficiently and tractably solved using the DC algorithm. Numerical results\nvalidate our approach through various data-driven schemes.", "published": "2025-08-08 06:21:21", "link": "http://arxiv.org/abs/2508.06052v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients", "abstract": "Prognostication for comatose post-cardiac arrest patients is a critical\nchallenge that directly impacts clinical decision-making in the ICU. Clinical\ninformation that informs prognostication is collected serially over time.\nShortly after cardiac arrest, various time-invariant baseline features are\ncollected (e.g., demographics, cardiac arrest characteristics). After ICU\nadmission, additional features are gathered, including time-varying hemodynamic\ndata (e.g., blood pressure, doses of vasopressor medications). We view these as\ntwo phases in which we collect new features. In this study, we propose a novel\nstepwise dynamic competing risks model that improves the prediction of\nneurological outcomes by automatically determining when to take advantage of\ntime-invariant features (first phase) and time-varying features (second phase).\nNotably, our model finds patients for whom this second phase (time-varying\nhemodynamic) information is beneficial for prognostication and also when this\ninformation is beneficial (as we collect more hemodynamic data for a patient\nover time, how important these data are for prognostication varies). Our\napproach extends the standard Fine and Gray model to explicitly model the two\nphases and to incorporate neural networks to flexibly capture complex nonlinear\nfeature relationships. Evaluated on a retrospective cohort of 2,278 comatose\npost-arrest patients, our model demonstrates robust discriminative performance\nfor the competing outcomes of awakening, withdrawal of life-sustaining therapy,\nand death despite maximal support. Our approach generalizes to more than two\nphases in which new features are collected and could be used in other dynamic\nprediction tasks, where it may be helpful to know when and for whom newly\ncollected features significantly improve prediction.", "published": "2025-08-08 05:20:30", "link": "http://arxiv.org/abs/2508.06023v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation and structured reasoning; however, their performance often\ndegrades on complex tasks that require consistent multi-step planning. Recent\nwork has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet\nexisting approaches primarily focus on generating heuristic-based code for\noptimization or target simpler tasks where correctness alone is sufficient. In\nthis work, we propose MCTS-OPS, a novel neural-symbolic framework that\nformulates prompt selection as a sequential decision process guided by MCTS.\nOur method explores and refines multi-step prompt sequences for the goal of\nimproving code generation quality and enhancing the problem-solving\ncapabilities of LLMs in general optimization. Experiments on network\noptimization show significant improvement over the baselines, both in the\nsuccess rate of executing the generated code and in the optimization results\nwith the specified objective and constraints (2$\\sim$4$\\times$ higher reward\nand 3$\\times$ lower standard deviation). Moreover, it improves the chance of\nattaining the optimal solution by about 10\\% of cases, compared to baseline\nmethods in hard problems. These results highlight the promise of combining\nsymbolic planning with LLMs for robust, high-quality code generation in complex\ndomains.", "published": "2025-08-08 04:01:24", "link": "http://arxiv.org/abs/2508.05995v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal", "abstract": "Recently, Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in code reasoning by scaling up the length of Chain-of-Thought\n(CoT). However, excessively long reasoning traces introduce substantial\nchallenges in terms of training cost, inference latency, and deployment\nfeasibility. While various CoT compression approaches have emerged to address\nthis challenge, they face inherent trade-offs: token-level methods often\ndisrupt syntactic and logical coherence, while step-level methods based on\nperplexity fail to reliably capture the logically critical reasoning steps. In\nthis paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel\ncoarse-to-fine framework for CoT compression. ASAP first performs anchor-guided\npruning to preserve the core reasoning structure, which efficiently reduces the\nsearch space for subsequent processing. It then enables a logic-aware pruning\nby selecting logically essential reasoning steps based on a novel first-token\nsurprisal metric. Finally, ASAP teaches models to autonomously generate and\nleverage these concise CoTs at inference time, enabling efficient reasoning in\ncoding tasks. Experiments show that ASAP achieves state-of-the-art accuracy\nacross multiple code generation benchmarks while substantially reducing\ntraining and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,\nour approach reduces token generation by 23.5% and inference latency by 43.5%\ncompared to the strongest baseline, while achieving a competitive accuracy of\n36.19% in Pass@1. Our results highlight a promising direction for building\npowerful and efficient LRMs.", "published": "2025-08-08 03:46:21", "link": "http://arxiv.org/abs/2508.05988v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning", "abstract": "Algorithms for solving \\textit{nonlinear} fixed-point equations -- such as\naverage-reward \\textit{$Q$-learning} and \\textit{TD-learning} -- often involve\nsemi-norm contractions. Achieving parameter-free optimal convergence rates for\nthese methods via Polyak--Ruppert averaging has remained elusive, largely due\nto the non-monotonicity of such semi-norms. We close this gap by (i.) recasting\nthe averaged error as a linear recursion involving a nonlinear perturbation,\nand (ii.) taming the nonlinearity by coupling the semi-norm's contraction with\nthe monotonicity of a suitably induced norm. Our main result yields the first\nparameter-free $\\tilde{O}(1/\\sqrt{t})$ optimal rates for $Q$-learning in both\naverage-reward and exponentially discounted settings, where $t$ denotes the\niteration index. The result applies within a broad framework that accommodates\nsynchronous and asynchronous updates, single-agent and distributed deployments,\nand data streams obtained either from simulators or along Markovian\ntrajectories.", "published": "2025-08-08 03:35:29", "link": "http://arxiv.org/abs/2508.05984v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "abstract": "In the domain of scientific machine learning, designing effective reward\nfunctions remains a challenge in reinforcement learning (RL), particularly in\nenvironments where task goals are difficult to specify numerically. Reward\nfunctions in existing work are predominantly based on heuristics, manual\nengineering, or task-specific tuning. In this work, we introduce a semantically\naligned reinforcement learning method where rewards are computed by aligning\nthe current state with a target semantic instruction using a\nSentence-Bidirectional Encoder Representations from Transformers (SBERT).\nInstead of relying on manually defined reward functions, the policy receives\nfeedback based on the reward, which is a cosine similarity between the goal\ntextual description and the statement description in the episode. We evaluated\nour approach in several environments and showed that semantic reward can guide\nlearning to achieve competitive control behavior, even in the absence of\nhand-crafted reward functions. Our study demonstrates a correlation between the\nlanguage embedding space and the conventional Euclidean space. This framework\nopens new horizons for aligning agent behavior with natural language goals and\nlays the groundwork for a more seamless integration of larger language models\n(LLMs) and fluid control applications.", "published": "2025-08-08 03:23:56", "link": "http://arxiv.org/abs/2508.05977v1", "categories": ["cs.LG", "physics.flu-dyn"], "primary_category": "cs.LG"}
{"title": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting", "abstract": "Group-Relative Policy Optimization (GRPO) is a key technique for training\nlarge reasoning models, yet it suffers from a critical vulnerability: the\n\\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning\nprocess. This problem is most severe in unbalanced response groups,\nparadoxically degrading the signal precisely when it should be most\ninformative. To address this challenge, we propose Stable Group-Relative Policy\nOptimization (S-GRPO), a principled enhancement that derives optimal,\nnoise-aware advantage weights to stabilize training. Our comprehensive\nexperiments on mathematical reasoning benchmarks demonstrate S-GRPO's\neffectiveness and robustness. On various models, S-GRPO significantly\noutperforms DR. GRPO, achieving performance gains of +2.5% on\nQwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on\nQwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn\nunder 20% synthetic reward noise, S-GRPO maintains stable learning progress.\nThese results highlight S-GRPO's potential for more robust and effective\ntraining of large-scale reasoning models. \\footnote{Code and data are available\nat: https://github.com/shenpeijun0212/S-GRPO", "published": "2025-08-08 01:24:06", "link": "http://arxiv.org/abs/2508.05928v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations", "abstract": "Accuracy in neural PDE solvers often breaks down not because of limited\nexpressivity, but due to poor optimisation caused by ill-conditioning,\nespecially in multi-fidelity and stiff problems. We study this issue in\nPhysics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural\nPDE solvers, and show that asymptotic components in governing equations can\nproduce highly ill-conditioned activation matrices, severely limiting\nconvergence. We introduce Shifted Gaussian Encoding, a simple yet effective\nactivation filtering step that increases matrix rank and expressivity while\npreserving convexity. Our method extends the solvable range of Peclet numbers\nin steady advection-diffusion equations by over two orders of magnitude,\nachieves up to six orders lower error on multi-frequency function learning, and\nfits high-fidelity image vectors more accurately and faster than deep networks\nwith over a million parameters. This work highlights that conditioning, not\ndepth, is often the bottleneck in scientific neural solvers and that simple\narchitectural changes can unlock substantial gains.", "published": "2025-08-08 00:51:38", "link": "http://arxiv.org/abs/2508.05921v1", "categories": ["cs.LG", "math.FA", "math.RT", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Dual Signal Decomposition of Stochastic Time Series", "abstract": "The research paper addresses decomposition of a stochastic time series into\nthree time series representing a dual signal i.e., the mean and the dispersion,\nwith noise isolated. Decomposition is done by applying machine learning to fit\na dual signal. Machine learning minimizes the loss function which compromises\nbetween fitting the original time series and penalizing irregularities of the\ndual signal. The latter includes terms based on the first and second order\nderivatives along time. To preserve special patterns, weighting of the\nregularization components of the loss function has been introduced based on\nStatistical Process Control methodology. The proposed decomposition can be\napplied as a smoothing algorithm against the mean and dispersion of the time\nseries. By isolating noise, the proposed decomposition can be seen as a\ndenoising algorithm. Two approaches of the learning process have been\nconsidered: sequential and jointly. The former approach learns the mean signal\nfirst and then dispersion. The latter approach fits the dual signal jointly.\nJointly learning can uncover complex relationships for the time series with\nheteroskedasticity. Learning has been set by solving the direct non-linear\nunconstrained optimization problem or by applying neural networks that have\nsequential or twin output architectures. Tuning of the loss function\nhyperparameters focuses on the isolated noise to be a stationary stochastic\nprocess without autocorrelation properties. Depending on the applications, the\nhyperparameters of the learning can be tuned towards either the discrete states\nby stepped signal or smoothed series. The decomposed dual signal can be\nrepresented on the 2D space and used to learn inherent structures, to forecast\nboth mean and dispersion, or to analyze cross effects in case of multiple time\nseries.", "published": "2025-08-08 00:30:41", "link": "http://arxiv.org/abs/2508.05915v1", "categories": ["cs.LG", "62M10"], "primary_category": "cs.LG"}
{"title": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements", "abstract": "High-fidelity electron microscopy simulations required for quantitative\ncrystal structure refinements face a fundamental challenge: while physical\ninteractions are well-described theoretically, real-world experimental effects\nare challenging to model analytically. To address this gap, we present a novel\nhybrid physics-machine learning framework that integrates differentiable\nphysical simulations with neural networks. By leveraging automatic\ndifferentiation throughout the simulation pipeline, our method enables\ngradient-based joint optimization of physical parameters and neural network\ncomponents representing experimental variables, offering superior scalability\ncompared to traditional second-order methods. We demonstrate this framework\nthrough application to three-dimensional electron diffraction (3D-ED) structure\nrefinement, where our approach learns complex thickness distributions directly\nfrom diffraction data rather than relying on simplified geometric models. This\nmethod achieves state-of-the-art refinement performance across synthetic and\nexperimental datasets, recovering atomic positions, thermal displacements, and\nthickness profiles with high fidelity. The modular architecture proposed can\nnaturally be extended to accommodate additional physical phenomena and extended\nto other electron microscopy techniques. This establishes differentiable hybrid\nmodeling as a powerful new paradigm for quantitative electron microscopy, where\nexperimental complexities have historically limited analysis.", "published": "2025-08-08 00:13:12", "link": "http://arxiv.org/abs/2508.05908v1", "categories": ["physics.comp-ph", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)", "abstract": "Quantization is usually regarded as a means to trade quality of performance\nfor reduced compute requirements, i.e., as a suboptimal approximation. However,\nif examined in terms of a fixed overall resource budget, a very different\nperspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit\nquantization that deterministically provides gradient information with no\nforward-path penalty. Our analysis provides evidence that it may improve\ninformation density compared to non-quantized alternatives.", "published": "2025-08-08 00:01:29", "link": "http://arxiv.org/abs/2508.05905v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A variational approach to dimension-free self-normalized concentration", "abstract": "We study the self-normalized concentration of vector-valued stochastic\nprocesses. We focus on bounds for sub-$\\psi$ processes, a tail condition that\nencompasses a wide variety of well-known distributions (including\nsub-exponential, sub-Gaussian, sub-gamma, and sub-Poisson distributions). Our\nresults recover and generalize the influential bound of Abbasi-Yadkori et al.\n(2011) and fill a gap in the literature between determinant-based bounds and\nthose based on condition numbers. As applications we prove a Bernstein\ninequality for random vectors satisfying a moment condition (which is more\ngeneral than boundedness), and also provide the first dimension-free,\nself-normalized empirical Bernstein inequality. Our techniques are based on the\nvariational (PAC-Bayes) approach to concentration.", "published": "2025-08-08 17:44:09", "link": "http://arxiv.org/abs/2508.06483v1", "categories": ["math.PR", "math.ST", "stat.ML", "stat.TH"], "primary_category": "math.PR"}
{"title": "Use Cases for Voice Anonymization", "abstract": "The performance of a voice anonymization system is typically measured\naccording to its ability to hide the speaker's identity and keep the data's\nutility for downstream tasks. This means that the requirements the\nanonymization should fulfill depend on the context in which it is used and may\ndiffer greatly between use cases. However, these use cases are rarely specified\nin research papers. In this paper, we study the implications of use\ncase-specific requirements on the design of voice anonymization methods. We\nperform an extensive literature analysis and user study to collect possible use\ncases and to understand the expectations of the general public towards such\ntools. Based on these studies, we propose the first taxonomy of use cases for\nvoice anonymization, and derive a set of requirements and design criteria for\nmethod development and evaluation. Using this scheme, we propose to focus more\non use case-oriented research and development of voice anonymization systems.", "published": "2025-08-08 14:38:26", "link": "http://arxiv.org/abs/2508.06356v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Egonoise Resilient Source Localization and Speech Enhancement for Drones Using a Hybrid Model and Learning-Based Approach", "abstract": "Drones are becoming increasingly important in search and rescue missions, and\neven military operations. While the majority of drones are equipped with camera\nvision capabilities, the realm of drone audition remains underexplored due to\nthe inherent challenge of mitigating the egonoise generated by the rotors. In\nthis paper, we present a novel technique to address this extremely low\nsignal-to-noise ratio (SNR) problem encountered by the microphone-embedded\ndrones. The technique is implemented using a hybrid approach that combines\nArray Signal Processing (ASP) and Deep Neural Networks (DNN) to enhance the\nspeech signals captured by a six-microphone uniform circular array mounted on a\nquadcopter. The system performs localization of the target speaker through\nbeamsteering in conjunction with speech enhancement through a Generalized\nSidelobe Canceller-DeepFilterNet 2 (GSC-DF2) system. To validate the system,\nthe DREGON dataset and measured data are employed. Objective evaluations of the\nproposed hybrid approach demonstrated its superior performance over four\nbaseline methods in the SNR condition as low as -30 dB.", "published": "2025-08-08 13:37:21", "link": "http://arxiv.org/abs/2508.06310v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Leveraging LLMs for Scalable Non-intrusive Speech Quality Assessment", "abstract": "Non-intrusive speech quality assessment (SQA) systems suffer from limited\ntraining data and costly human annotations, hindering their generalization to\nreal-time conferencing calls. In this work, we propose leveraging large\nlanguage models (LLMs) as pseudo-raters for speech quality to address these\ndata bottlenecks. We construct LibriAugmented, a dataset consisting of 101,129\nspeech clips with simulated degradations labeled by a fine-tuned auditory LLM\n(Vicuna-7b-v1.5). We compare three training strategies: using human-labeled\ndata, using LLM-labeled data, and a two-stage approach (pretraining on LLM\nlabels, then fine-tuning on human labels), using both DNSMOS Pro and DeePMOS.\nWe test on several datasets across languages and quality degradations. While\nLLM-labeled training yields mixed results compared to human-labeled training,\nwe provide empirical evidence that the two-stage approach improves the\ngeneralization performance (e.g., DNSMOS Pro achieves 0.63 vs. 0.55 PCC on\nNISQA_TEST_LIVETALK and 0.73 vs. 0.65 PCC on Tencent with reverb). Our findings\ndemonstrate the potential of using LLMs as scalable pseudo-raters for speech\nquality assessment, offering a cost-effective solution to the data limitation\nproblem.", "published": "2025-08-08 13:05:31", "link": "http://arxiv.org/abs/2508.06284v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "EchoFree: Towards Ultra Lightweight and Efficient Neural Acoustic Echo Cancellation", "abstract": "In recent years, neural networks (NNs) have been widely applied in acoustic\necho cancellation (AEC). However, existing approaches struggle to meet\nreal-world low-latency and computational requirements while maintaining\nperformance. To address this challenge, we propose EchoFree, an ultra\nlightweight neural AEC framework that combines linear filtering with a neural\npost filter. Specifically, we design a neural post-filter operating on\nBark-scale spectral features. Furthermore, we introduce a two-stage\noptimization strategy utilizing self-supervised learning (SSL) models to\nimprove model performance. We evaluate our method on the blind test set of the\nICASSP 2023 AEC Challenge. The results demonstrate that our model, with only\n278K parameters and 30 MMACs computational complexity, outperforms existing\nlow-complexity AEC models and achieves performance comparable to that of\nstate-of-the-art lightweight model DeepVQE-S. The audio examples are available.", "published": "2025-08-08 12:44:00", "link": "http://arxiv.org/abs/2508.06271v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Llasa+: Free Lunch for Accelerated and Streaming Llama-Based Speech Synthesis", "abstract": "Recent progress in text-to-speech (TTS) has achieved impressive naturalness\nand flexibility, especially with the development of large language model\n(LLM)-based approaches. However, existing autoregressive (AR) structures and\nlarge-scale models, such as Llasa, still face significant challenges in\ninference latency and streaming synthesis. To deal with the limitations, we\nintroduce Llasa+, an accelerated and streaming TTS model built on Llasa.\nSpecifically, to accelerate the generation process, we introduce two\nplug-and-play Multi-Token Prediction (MTP) modules following the frozen\nbackbone. These modules allow the model to predict multiple tokens in one AR\nstep. Additionally, to mitigate potential error propagation caused by\ninaccurate MTP, we design a novel verification algorithm that leverages the\nfrozen backbone to validate the generated tokens, thus allowing Llasa+ to\nachieve speedup without sacrificing generation quality. Furthermore, we design\na causal decoder that enables streaming speech reconstruction from tokens.\nExtensive experiments show that Llasa+ achieves a 1.48X speedup without\nsacrificing generation quality, despite being trained only on LibriTTS.\nMoreover, the MTP-and-verification framework can be applied to accelerate any\nLLM-based model. All codes and models are publicly available at\nhttps://github.com/ASLP-lab/LLaSA_Plus.", "published": "2025-08-08 12:28:34", "link": "http://arxiv.org/abs/2508.06262v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "abstract": "Text-to-SQL bridges the gap between natural language and structured database\nlanguage, thus allowing non-technical users to easily query databases.\nTraditional approaches model text-to-SQL as a direct translation task, where a\ngiven Natural Language Query (NLQ) is mapped to an SQL command. Recent advances\nin large language models (LLMs) have significantly improved translation\naccuracy, however, these methods all require that the target database is\npre-specified. This becomes problematic in scenarios with multiple extensive\ndatabases, where identifying the correct database becomes a crucial yet\noverlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL\nframework to identify the user's intended database before generating SQL\nqueries. Our approach leverages LLMs and prompt engineering to extract implicit\ninformation from natural language queries (NLQs) in the form of a ruleset. We\nthen train a large db\\_id prediction model, which includes a RoBERTa-based\nfinetuned encoder, to predict the correct Database identifier (db\\_id) based on\nboth the NLQ and the LLM-generated rules. Finally, we refine the generated SQL\nby using critic agents to correct errors. Experimental results demonstrate that\nour framework outperforms the current state-of-the-art models in both database\nintent prediction and SQL generation accuracy.", "published": "2025-08-08 15:16:36", "link": "http://arxiv.org/abs/2508.06387v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Symmetry breaking for inductive logic programming", "abstract": "The goal of inductive logic programming is to search for a hypothesis that\ngeneralises training data and background knowledge. The challenge is searching\nvast hypothesis spaces, which is exacerbated because many logically equivalent\nhypotheses exist. To address this challenge, we introduce a method to break\nsymmetries in the hypothesis space. We implement our idea in answer set\nprogramming. Our experiments on multiple domains, including visual reasoning\nand game playing, show that our approach can reduce solving times from over an\nhour to just 17 seconds.", "published": "2025-08-08 12:28:42", "link": "http://arxiv.org/abs/2508.06263v2", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models", "abstract": "Vision-Language Models (VLMs) typically replace the predefined image\nplaceholder token (<image>) in textual instructions with visual features from\nan image encoder, forming the input to a backbone Large Language Model (LLM).\nHowever, the large number of vision tokens significantly increases the context\nlength, leading to high computational overhead and inference latency. While\nprevious efforts mitigate this by selecting only important visual features or\nleveraging learnable queries to reduce token count, they often compromise\nperformance or introduce substantial extra costs. In response, we propose\nFourier-VLM, a simple yet efficient method that compresses visual\nrepresentations in the frequency domain. Our approach is motivated by the\nobservation that vision features output from the vision encoder exhibit\nconcentrated energy in low-frequency components. Leveraging this, we apply a\nlow-pass filter to the vision features using a two-dimensional Discrete Cosine\nTransform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier\nTransform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$,\nminimizing the extra computational cost while introducing no additional\nparameters. Extensive experiments across various image-based benchmarks\ndemonstrate that Fourier-VLM achieves competitive performance with strong\ngeneralizability across both LLaVA and Qwen-VL architectures. Crucially, it\nreduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%\ncompared to LLaVA-v1.5, highlighting the superior efficiency and practicality.", "published": "2025-08-08 05:49:42", "link": "http://arxiv.org/abs/2508.06038v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model", "abstract": "Affordance grounding focuses on predicting the specific regions of objects\nthat are associated with the actions to be performed by robots. It plays a\nvital role in the fields of human-robot interaction, human-object interaction,\nembodied manipulation, and embodied perception. Existing models often neglect\nthe affordance shared among different objects because they lack the\nChain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)\ngeneralization and explicit reasoning capabilities. To address these\nchallenges, we propose Affordance-R1, the first unified affordance grounding\nframework that integrates cognitive CoT guided Group Relative Policy\nOptimization (GRPO) within a reinforcement learning paradigm. Specifically, we\ndesigned a sophisticated affordance function, which contains format,\nperception, and cognition rewards to effectively guide optimization directions.\nFurthermore, we constructed a high-quality affordance-centric reasoning\ndataset, ReasonAff, to support training. Trained exclusively via reinforcement\nlearning with GRPO and without explicit reasoning data, Affordance-R1 achieves\nrobust zero-shot generalization and exhibits emergent test-time reasoning\ncapabilities. Comprehensive experiments demonstrate that our model outperforms\nwell-established methods and exhibits open-world generalization. To the best of\nour knowledge, Affordance-R1 is the first to integrate GRPO-based RL with\nreasoning into affordance reasoning. The code of our method and our dataset is\nreleased on https://github.com/hq-King/Affordance-R1.", "published": "2025-08-08 10:39:04", "link": "http://arxiv.org/abs/2508.06206v2", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis", "abstract": "Formal Concept Analysis (FCA) is a mathematical framework for knowledge\nrepresentation and discovery. It performs a hierarchical clustering over a set\nof objects described by attributes, resulting in conceptual structures in which\nobjects are organized depending on the attributes they share. These conceptual\nstructures naturally highlight commonalities and variabilities among similar\nobjects by categorizing them into groups which are then arranged by similarity,\nmaking it particularly appropriate for variability extraction and analysis.\nDespite the potential of FCA, determining which of its properties can be\nleveraged for variability-related tasks (and how) is not always\nstraightforward, partly due to the mathematical orientation of its foundational\nliterature. This paper attempts to bridge part of this gap by gathering a\nselection of properties of the framework which are essential to variability\nanalysis, and how they can be used to interpret diverse variability information\nwithin the resulting conceptual structures.", "published": "2025-08-08 19:30:14", "link": "http://arxiv.org/abs/2508.06668v1", "categories": ["cs.AI", "cs.IR", "cs.SE"], "primary_category": "cs.AI"}
{"title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent", "abstract": "Deep-Research agents, which integrate large language models (LLMs) with\nsearch tools, have shown success in improving the effectiveness of handling\ncomplex queries that require iterative search planning and reasoning over\nsearch results. Evaluations on current benchmarks like BrowseComp relies on\nblack-box live web search APIs, have notable limitations in (1) fairness:\ndynamic and opaque web APIs hinder fair comparisons and reproducibility of deep\nresearch methods; (2) transparency: lack of control over the document corpus\nmakes it difficult to isolate retriever contributions. In other words, the\ncurrent evaluations may compare a complete deep research system at a given\ntime, but they do not foster well-controlled experiments to provide insights\ninto the capability of underlying deep research LLMs. To address these\nchallenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,\nemploying a fixed, carefully curated corpus. Each query in BrowseComp-Plus\nincludes human-verified supporting documents and mined challenging negatives,\nenabling controlled experimentation. The benchmark is shown to be effective in\ndistinguishing the performance of deep research systems. For instance, the\nopen-source model Search-R1, when paired with the BM25 retriever, achieves\n3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with\nthe Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with\nfewer search calls. This benchmark allows comprehensive evaluation and\ndisentangled analysis of deep research agents and retrieval methods, fostering\ninsights into retrieval effectiveness, citation accuracy, and context\nengineering in Deep-Research system.", "published": "2025-08-08 17:55:11", "link": "http://arxiv.org/abs/2508.06600v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "When isometry and equivalence for skew constacyclic codes coincide", "abstract": "We show that the notions of $(n,\\sigma)$-isometry and\n$(n,\\sigma)$-equivalence introduced by Ou-azzou et al coincide for most skew\n$(\\sigma,a)$-constacyclic codes of length $n$. To prove this, we show that all\nHamming-weight-preserving homomorphisms between their ambient algebras must\nhave degree one when those algebras are nonassociative. We work in the general\nsetting of commutative base rings $S$. As a consequence, we propose new\ndefinitions of equivalence and isometry of skew constacyclic codes that exactly\ncapture all Hamming-preserving isomorphisms, and lead to tighter\nclassifications. In the process we determine homomorphisms between\nnonassociative Petit algebras, prioritizing the algebras\n$S[t;\\sigma]/S[t;\\sigma](t^n-a)$, which give rise to skew constacyclic codes.", "published": "2025-08-08 20:43:54", "link": "http://arxiv.org/abs/2508.06695v1", "categories": ["cs.IT", "math.IT", "math.RA", "94B15, 11T71, 17A99, 81P70"], "primary_category": "cs.IT"}
{"title": "Asymmetric Network Games: $\u03b1$-Potential Function and Learning", "abstract": "In a network game, players interact over a network and the utility of each\nplayer depends on his own action and on an aggregate of his neighbours'\nactions. Many real world networks of interest are asymmetric and involve a\nlarge number of heterogeneous players. This paper analyzes static network games\nusing the framework of $\\alpha$-potential games. Under mild assumptions on the\naction sets (compact intervals) and the utility functions (twice continuously\ndifferentiable) of the players, we derive an expression for an inexact\npotential function of the game, called the $\\alpha$-potential function. Using\nsuch a function, we show that modified versions of the sequential best-response\nalgorithm and the simultaneous gradient play algorithm achieve convergence of\nplayers' actions to a $2\\alpha$-Nash equilibrium. For linear-quadratic network\ngames, we show that $\\alpha$ depends on the maximum asymmetry in the network\nand is well-behaved for a wide range of networks of practical interest.\nFurther, we derive bounds on the social welfare of the $\\alpha$-Nash\nequilibrium corresponding to the maximum of the $\\alpha$-potential function,\nunder suitable assumptions. We numerically illustrate the convergence of the\nproposed algorithms and properties of the learned $2\\alpha$-Nash equilibria.", "published": "2025-08-08 18:08:25", "link": "http://arxiv.org/abs/2508.06619v1", "categories": ["cs.GT", "cs.MA", "cs.SI", "cs.SY", "eess.SY"], "primary_category": "cs.GT"}
{"title": "Computable Poincar\u00e9--Friedrichs constants for the $L^{p}$ de~Rham complex over convex domains and domains with shellable triangulations", "abstract": "We construct potentials for the exterior derivative, in particular, for the\ngradient, the curl, and the divergence operators, over domains with shellable\ntriangulations. Notably, the class of shellable triangulations includes local\npatches (stars) in two or three dimensions. The operator norms of our\npotentials satisfy explicitly computable bounds that depend only on the\ngeometry. We thus compute upper bounds for constants in Poincar\\'e--Friedrichs\ninequalities and lower bounds for the eigenvalues of vector Laplacians. As an\nadditional result with independent standing, we establish\nPoincar\\'e--Friedrichs inequalities with computable constants for the $L^{p}$\nde~Rham complex over bounded convex domains, derived as explicit operator norms\nof regularized Poincar\\'e and Bogovski\\u{\\i} potential operators. We express\nall our main results in the calculus of differential forms and treat the\ngradient, curl, and divergence operators as instances of the exterior\nderivative. Computational examples illustrate the theoretical findings.", "published": "2025-08-08 22:42:50", "link": "http://arxiv.org/abs/2508.06741v1", "categories": ["math.NA", "cs.NA", "52B22, 57Q05 58A14, 65N12, 65N15"], "primary_category": "math.NA"}
{"title": "Diffeomorphic Neural Operator Learning", "abstract": "We present an operator learning approach for a class of evolution operators\nusing a composition of a learned lift into the space of diffeomorphisms of the\ndomain and the group action on the field space. In turn, this transforms the\nsemigroup structure of the evolution operator into a corresponding group\nstructure allowing time stepping be performed through composition on the space\nof diffeomorphisms rather than in the field space directly. This results in a\nnumber of structure-preserving properties related to preserving a relabelling\nsymmetry of the dynamics as a hard constraint. We study the resolution\nproperties of our approach, along with its connection to the techniques of\ndiffeomorphic image registration. Numerical experiments on forecasting\nturbulent fluid dynamics are provided, demonstrating its conservative\nproperties, non-diffusivity, and ability to capture anticipated statistical\nscaling relations at sub-grid scales. Our method provides an example of\ngeometric operator learning and indicates a clear performance benefit from\nleveraging a priori known infinite-dimensional geometric structure.", "published": "2025-08-08 20:32:00", "link": "http://arxiv.org/abs/2508.06690v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fractal Language Modelling by Universal Sequence Maps (USM)", "abstract": "Motivation: With the advent of Language Models using Transformers,\npopularized by ChatGPT, there is a renewed interest in exploring encoding\nprocedures that numerically represent symbolic sequences at multiple scales and\nembedding dimensions. The challenge that encoding addresses is the need for\nmechanisms that uniquely retain contextual information about the succession of\nindividual symbols, which can then be modeled by nonlinear formulations such as\nneural networks.\n  Context: Universal Sequence Maps(USM) are iterated functions that bijectively\nencode symbolic sequences onto embedded numerical spaces. USM is composed of\ntwo Chaos Game Representations (CGR), iterated forwardly and backwardly, that\ncan be projected into the frequency domain (FCGR). The corresponding USM\ncoordinates can be used to compute a Chebyshev distance metric as well as k-mer\nfrequencies, without having to recompute the embedded numeric coordinates, and,\nparadoxically, allowing for non-integers values of k.\n  Results: This report advances the bijective fractal encoding by Universal\nSequence Maps (USM) by resolving seeding biases affecting the iterated process.\nThe resolution had two results, the first expected, the second an intriguing\noutcome: 1) full reconciliation of numeric positioning with sequence identity;\nand 2) uncovering the nature of USM as an efficient numeric process converging\ntowards a steady state sequence embedding solution. We illustrate these results\nfor genomic sequences because of the convenience of a planar representation\ndefined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,\nthe application to alphabet of arbitrary cardinality was found to be\nstraightforward.", "published": "2025-08-08 18:41:13", "link": "http://arxiv.org/abs/2508.06641v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "A note on generating Voronoi cells with a given size distribution", "abstract": "This note describes a simple method to draw random points such that the cells\nof the corresponding Voronoi tesselation (approximately) satisfy a desired size\ndistribution, for instance, follow a power law. The method is illustrated and\nnumerically verified in two dimensions, and we also provide a simple\nimplementation.", "published": "2025-08-08 18:26:30", "link": "http://arxiv.org/abs/2508.06630v1", "categories": ["math.NA", "cond-mat.stat-mech", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Federated Online Learning for Heterogeneous Multisource Streaming Data", "abstract": "Federated learning has emerged as an essential paradigm for distributed\nmulti-source data analysis under privacy concerns. Most existing federated\nlearning methods focus on the ``static\" datasets. However, in many real-world\napplications, data arrive continuously over time, forming streaming datasets.\nThis introduces additional challenges for data storage and algorithm design,\nparticularly under high-dimensional settings. In this paper, we propose a\nfederated online learning (FOL) method for distributed multi-source streaming\ndata analysis. To account for heterogeneity, a personalized model is\nconstructed for each data source, and a novel ``subgroup\" assumption is\nemployed to capture potential similarities, thereby enhancing model\nperformance. We adopt the penalized renewable estimation method and the\nefficient proximal gradient descent for model training. The proposed method\naligns with both federated and online learning frameworks: raw data are not\nexchanged among sources, ensuring data privacy, and only summary statistics of\nprevious data batches are required for model updates, significantly reducing\nstorage demands. Theoretically, we establish the consistency properties for\nmodel estimation, variable selection, and subgroup structure recovery,\ndemonstrating optimal statistical efficiency. Simulations illustrate the\neffectiveness of the proposed method. Furthermore, when applied to the\nfinancial lending data and the web log data, the proposed method also exhibits\nadvantageous prediction performance. Results of the analysis also provide some\npractical insights.", "published": "2025-08-08 19:08:53", "link": "http://arxiv.org/abs/2508.06652v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Using Imperfect Synthetic Data in Downstream Inference Tasks", "abstract": "Predictions and generations from large language models are increasingly being\nexplored as an aid to computational social science and human subject research\nin limited data regimes. While previous technical work has explored the\npotential to use model-predicted labels for unlabeled data in a principled\nmanner, there is increasing interest in using large language models to generate\nentirely new synthetic samples (also termed as synthetic simulations), such as\nin responses to surveys. However, it is not immediately clear by what means\npractitioners can combine such data with real data and yet produce\nstatistically valid conclusions upon them. In this work, we introduce a new\nestimator based on generalized method of moments, providing a\nhyperparameter-free solution with strong theoretical guarantees to address the\nchallenge at hand. Surprisingly, we find that interactions between the moment\nresiduals of synthetic data and those of real data can improve estimates of the\ntarget parameter. We empirically validate the finite-sample performance of our\nestimator across different regression tasks in computational social science\napplications, demonstrating large empirical gains.", "published": "2025-08-08 18:32:52", "link": "http://arxiv.org/abs/2508.06635v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels", "abstract": "We introduce ANTIDOTE, a new class of objectives for learning under noisy\nlabels which are defined in terms of a relaxation over an\ninformation-divergence neighborhood. Using convex duality, we provide a\nreformulation as an adversarial training method that has similar computational\ncost to training with standard cross-entropy loss. We show that our approach\nadaptively reduces the influence of the samples with noisy labels during\nlearning, exhibiting a behavior that is analogous to forgetting those samples.\nANTIDOTE is effective in practical environments where label noise is inherent\nin the training data or where an adversary can alter the training labels.\nExtensive empirical evaluations on different levels of symmetric, asymmetric,\nhuman annotation, and real-world label noise show that ANTIDOTE outperforms\nleading comparable losses in the field and enjoys a time complexity that is\nvery close to that of the standard cross entropy loss.", "published": "2025-08-08 18:10:16", "link": "http://arxiv.org/abs/2508.06622v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Differentiable Grouped Feedback Delay Networks for Learning Coupled Volume Acoustics", "abstract": "Rendering dynamic reverberation in a complicated acoustic space for moving\nsources and listeners is challenging but crucial for enhancing user immersion\nin extended-reality (XR) applications. Capturing spatially varying room impulse\nresponses (RIRs) is costly and often impractical. Moreover, dynamic convolution\nwith measured RIRs is computationally expensive with high memory demands,\ntypically not available on wearable computing devices. Grouped Feedback Delay\nNetworks (GFDNs), on the other hand, allow efficient rendering of coupled room\nacoustics. However, its parameters need to be tuned to match the reverberation\nprofile of a coupled space. In this work, we propose the concept of\nDifferentiable GFDNs (DiffGFDNs), which have tunable parameters that are\noptimised to match the late reverberation profile of a set of RIRs captured\nfrom a space that exhibits multi-slope decay. Once trained on a finite set of\nmeasurements, the DiffGFDN generalises to unmeasured locations in the space. We\npropose a parallel processing pipeline that has multiple DiffGFDNs with\nfrequency-independent parameters processing each octave band. The parameters of\nthe DiffGFDN can be updated rapidly during inferencing as sources and listeners\nmove. We evaluate the proposed architecture against the Common Slopes (CS)\nmodel on a dataset of RIRs for three coupled rooms. The proposed architecture\ngenerates multi-slope late reverberation with low memory and computational\nrequirements, achieving better energy decay relief (EDR) error and slightly\nworse octave-band energy decay curve (EDC) errors compared to the CS model.\nFurthermore, DiffGFDN requires an order of magnitude fewer floating-point\noperations per sample than the CS renderer.", "published": "2025-08-08 20:25:15", "link": "http://arxiv.org/abs/2508.06686v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "GPU-accelerated Direct Geolocation of GNSS Interference", "abstract": "In recent years, there has been a sharp increase in Global Navigation\nSatellite Systems (GNSS) interference, which has proven to be problematic in\nGNSS-dependent civilian applications. Many currently deployed GNSS receivers\nlack the proper countermeasures to defend themselves against interference,\nprompting the need for alternative defenses. Satellites in Low Earth Orbit\n(LEO) provide an opportunity for GNSS interference detection, classification,\nand localization. The direct geolocation approach has been shown to be\nwell-suited for low SNR regimes and in cases limited to short captures --\nexactly what is expected for receivers in LEO. Direct geolocation is a\nsingle-step search over a geographical grid that enables estimation of the\ntransmitter location directly from correlating raw observed signals. However, a\nkey limitation to this approach is the computational requirements. This\ncomputational burden is compounded for LEO-based receivers as the geographic\nsearch space is extensive. This paper alleviates the computational burden of\ndirect geolocation by exploiting the independence of position-domain\ncorrelation across candidate points and time steps: nearly all computation can\nbe accomplished in parallel on a graphics processing unit (GPU). This paper\npresents and evaluates the performance of GPU-accelerated direct geolocation\ncompared to traditional CPU processing.", "published": "2025-08-08 19:45:25", "link": "http://arxiv.org/abs/2508.06672v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MMFformer: Multimodal Fusion Transformer Network for Depression Detection", "abstract": "Depression is a serious mental health illness that significantly affects an\nindividual's well-being and quality of life, making early detection crucial for\nadequate care and treatment. Detecting depression is often difficult, as it is\nbased primarily on subjective evaluations during clinical interviews. Hence,\nthe early diagnosis of depression, thanks to the content of social networks,\nhas become a prominent research area. The extensive and diverse nature of\nuser-generated information poses a significant challenge, limiting the accurate\nextraction of relevant temporal information and the effective fusion of data\nacross multiple modalities. This paper introduces MMFformer, a multimodal\ndepression detection network designed to retrieve depressive spatio-temporal\nhigh-level patterns from multimodal social media information. The transformer\nnetwork with residual connections captures spatial features from videos, and a\ntransformer encoder is exploited to design important temporal dynamics in\naudio. Moreover, the fusion architecture fused the extracted features through\nlate and intermediate fusion strategies to find out the most relevant\nintermodal correlations among them. Finally, the proposed network is assessed\non two large-scale depression detection datasets, and the results clearly\nreveal that it surpasses existing state-of-the-art approaches, improving the\nF1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is\nmade available publicly at\nhttps://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.", "published": "2025-08-08 21:03:29", "link": "http://arxiv.org/abs/2508.06701v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts", "abstract": "Streaming recommender systems (SRSs) are widely deployed in real-world\napplications, where user interests shift and new items arrive over time. As a\nresult, effectively capturing users' latest preferences is challenging, as\ninteractions reflecting recent interests are limited and new items often lack\nsufficient feedback. A common solution is to enrich item representations using\nmultimodal encoders (e.g., BERT or ViT) to extract visual and textual features.\nHowever, these encoders are pretrained on general-purpose tasks: they are not\ntailored to user preference modeling, and they overlook the fact that user\ntastes toward modality-specific features such as visual styles and textual\ntones can also drift over time. This presents two key challenges in streaming\nscenarios: the high cost of fine-tuning large multimodal encoders, and the risk\nof forgetting long-term user preferences due to continuous model updates.\n  To tackle these challenges, we propose Expandable Side Mixture-of-Experts\n(XSMoE), a memory-efficient framework for multimodal streaming recommendation.\nXSMoE attaches lightweight side-tuning modules consisting of expandable expert\nnetworks to frozen pretrained encoders and incrementally expands them in\nresponse to evolving user feedback. A gating router dynamically combines expert\nand backbone outputs, while a utilization-based pruning strategy maintains\nmodel compactness. By learning new patterns through expandable experts without\noverwriting previously acquired knowledge, XSMoE effectively captures both cold\nstart and shifting preferences in multimodal features. Experiments on three\nreal-world datasets demonstrate that XSMoE outperforms state-of-the-art\nbaselines in both recommendation quality and computational efficiency.", "published": "2025-08-08 04:00:05", "link": "http://arxiv.org/abs/2508.05993v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Memp: Exploring Agent Procedural Memory", "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they\nsuffer from brittle procedural memory that is manually engineered or entangled\nin static parameters. In this work, we investigate strategies to endow agents\nwith a learnable, updatable, and lifelong procedural memory. We propose Memp\nthat distills past agent trajectories into both fine-grained, step-by-step\ninstructions and higher-level, script-like abstractions, and explore the impact\nof different strategies for Build, Retrieval, and Update of procedural memory.\nCoupled with a dynamic regimen that continuously updates, corrects, and\ndeprecates its contents, this repository evolves in lockstep with new\nexperience. Empirical evaluation on TravelPlanner and ALFWorld shows that as\nthe memory repository is refined, agents achieve steadily higher success rates\nand greater efficiency on analogous tasks. Moreover, procedural memory built\nfrom a stronger model retains its value: migrating the procedural memory to a\nweaker model yields substantial performance gains.", "published": "2025-08-08 16:20:56", "link": "http://arxiv.org/abs/2508.06433v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
