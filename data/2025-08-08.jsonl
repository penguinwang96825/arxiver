{"title": "Voting-Based Semi-Parallel Proof-of-Work Protocol", "abstract": "Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety\nguarantees, transaction throughput and confirmation latencies of Nakamoto\nconsensus. In this work, we first consider the existing parallel PoW protocols\nand develop hard-coded incentive attack structures. Our theoretical results and\nsimulations show that the existing parallel PoW protocols are more vulnerable\nto incentive attacks than the Nakamoto consensus, e.g., attacks have smaller\nprofitability threshold and they result in higher relative rewards. Next, we\nintroduce a voting-based semi-parallel PoW protocol that outperforms both\nNakamoto consensus and the existing parallel PoW protocols from most practical\nperspectives such as communication overheads, throughput, transaction\nconflicts, incentive compatibility of the protocol as well as a fair\ndistribution of transaction fees among the voters and the leaders. We use\nstate-of-the-art analysis to evaluate the consistency of the protocol and\nconsider Markov decision process (MDP) models to substantiate our claims about\nthe resilience of our protocol against incentive attacks.", "published": "2025-08-08 17:57:35", "link": "http://arxiv.org/abs/2508.06489v1", "categories": ["cs.CR", "cs.DC", "cs.DM", "cs.IT", "math.IT", "math.PR"], "primary_category": "cs.CR"}
{"title": "On Approximate MMS Allocations on Restricted Graph Classes", "abstract": "We study the problem of fair division of a set of indivisible goods with\nconnectivity constraints. Specifically, we assume that the goods are\nrepresented as vertices of a connected graph, and sets of goods allocated to\nthe agents are connected subgraphs of this graph. We focus on the\nwidely-studied maximin share criterion of fairness. It has been shown that an\nallocation satisfying this criterion may not exist even without connectivity\nconstraints, i.e., if the graph of goods is complete. In view of this, it is\nnatural to seek approximate allocations that guarantee each agent a connected\nbundle of goods with value at least a constant fraction of the maximin share\nvalue to the agent. It is known that for some classes of graphs, such as\ncomplete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such\napproximate allocations indeed exist. However, it is an open problem whether\nthey exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of\napproximate allocations on restricted graph classes. In particular, we show\nthat such allocations exist for several well-studied classes, including block\ngraphs, cacti, complete multipartite graphs, and split graphs.", "published": "2025-08-08 14:17:44", "link": "http://arxiv.org/abs/2508.06343v1", "categories": ["cs.DM", "cs.AI"], "primary_category": "cs.DM"}
{"title": "Sandwich Monotonicity and the Recognition of Weighted Graph Classes", "abstract": "Edge-weighted graphs play an important role in the theory of Robinsonian\nmatrices and similarity theory, particularly via the concept of level graphs,\nthat is, graphs obtained from an edge-weighted graph by removing all\nsufficiently light edges. This suggest a natural way of associating to any\nclass $\\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted\ngraphs, namely by requiring that all level graphs belong to $\\mathcal{G}$. We\nshow that weighted graphs for which all level graphs are split, threshold, or\nchain graphs can be recognized in linear time using special edge elimination\norderings. We obtain these results by introducing the notion of degree sandwich\nmonotone graph classes. A graph class $\\mathcal{G}$ is sandwich monotone if\nevery edge set which may be removed from a graph in $\\mathcal{G}$ without\nleaving the class also contains a single edge that can be safely removed.\nFurthermore, if we require the safe edge to fulfill a certain degree property,\nthen $\\mathcal{G}$ is called degree sandwich monotone. We present necessary and\nsufficient conditions for the existence of a linear-time recognition algorithm\nfor any weighted graph class whose corresponding unweighted class is degree\nsandwich monotone and contains all edgeless graphs.", "published": "2025-08-08 10:52:39", "link": "http://arxiv.org/abs/2508.06216v1", "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "cs.DM"}
{"title": "A Structural Linear-Time Algorithm for Computing the Tutte Decomposition", "abstract": "The block-cut tree decomposes a connected graph along its cutvertices,\ndisplaying its 2-connected components. The Tutte-decomposition extends this\nidea to 2-separators in 2-connected graphs, yielding a canonical\ntree-decomposition that decomposes the graph into its triconnected components.\nIn 1973, Hopcroft and Tarjan introduced a linear-time algorithm to compute the\nTutte-decomposition. Cunningham and Edmonds later established a structural\ncharacterization of the Tutte-decomposition via totally-nested 2-separations.\nWe present a conceptually simple algorithm based on this characterization,\nwhich computes the Tutte-decomposition in linear time. Our algorithm first\ncomputes all totally-nested 2-separations and then builds the\nTutte-decomposition from them.\n  Along the way, we derive new structural results on the structure of\ntotally-nested 2-separations in 2-connected graphs using a novel notion of\nstability, which may be of independent interest.", "published": "2025-08-08 10:48:18", "link": "http://arxiv.org/abs/2508.06212v1", "categories": ["cs.DS", "cs.DM", "math.CO"], "primary_category": "cs.DS"}
{"title": "Induced Minors, Asymptotic Dimension, and Baker's Technique", "abstract": "Asymptotic dimension is a large-scale invariant of metric spaces that was\nintroduced by Gromov (1993). We prove that every hereditary class of\nbounded-degree graphs that excludes some graph as a fat minor has asymptotic\ndimension at most $2$, which is optimal. This makes substantial progress on a\nquestion of Bonamy, Bousquet, Esperet, Groenland, Liu, Pirot, and Scott (J.\nEur. Math. Soc. 2023).\n  The key to our proof is a notion inspired by Baker's technique (J. ACM 1994).\nWe say that a graph class $\\mathcal{G}$ has bounded Baker-treewidth if there\nexists a function $f \\colon \\mathbb{N} \\to \\mathbb{N}$ such that, for every\ngraph $G\\in \\mathcal{G}$, there is a layering of $G$ such that the subgraph\ninduced by the union of any $\\ell$ consecutive layers has treewidth at most\n$f(\\ell)$. We show that every class of bounded-degree graphs that excludes some\ngraph as an induced minor has bounded Baker-treewidth. We discuss further\napplications of this result to clustered colouring and the design of\nlinear-time approximate schemes.", "published": "2025-08-08 10:12:03", "link": "http://arxiv.org/abs/2508.06190v1", "categories": ["math.CO", "cs.DM", "math.GR", "math.GT", "math.MG"], "primary_category": "math.CO"}
{"title": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations", "abstract": "Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees\nand octrees, underpins a wide range of applications including databases,\ncomputer graphics, physics simulations, and machine learning. However, octrees\nenforce isotropic refinement in regions of interest, which can be especially\ninefficient for problems that are intrinsically anisotropic--much resolution is\nspent where little information is gained. This paper presents omnitrees as an\nanisotropic generalization of octrees and related data structures. Omnitrees\nallow to refine only the locally most important dimensions, providing tree\nstructures that are less deep than bintrees and less wide than octrees. As a\nresult, the convergence of the AMR schemes can be increased by up to a factor\nof the dimensionality d for very anisotropic problems, quickly offsetting their\nmodest increase in storage overhead. We validate this finding on the problem of\nbinary shape representation across 4,166 three-dimensional objects: Omnitrees\nincrease the mean convergence rate by 1.5x, require less storage to achieve\nequivalent error bounds, and maximize the information density of the stored\nfunction faster than octrees. These advantages are projected to be even\nstronger for higher-dimensional problems. We provide a first validation by\nintroducing a time-dependent rotation to create four-dimensional\nrepresentations, and discuss the properties of their 4-d octree and omnitree\napproximations. Overall, omnitree discretizations can make existing AMR\napproaches more efficient, and open up new possibilities for high-dimensional\napplications.", "published": "2025-08-08 13:42:59", "link": "http://arxiv.org/abs/2508.06316v1", "categories": ["cs.DS", "cs.CG", "cs.GR", "cs.IT", "cs.NA", "math.IT", "math.NA", "65D15, 65D18, 68P05, 68P30"], "primary_category": "cs.DS"}
{"title": "A New Framework for the Sum of Squared $\u03ba$-$\u03bc$ RVs with Application to Sub-THz Systems", "abstract": "In this paper, we adopt the $\\kappa$-$\\mu$ model to characterize the\npropagation in the sub-THz band. We develop a new exact representation of the\nsum of squared independent and identically distributed $\\kappa$-$\\mu$ random\nvariables, which can be used to express the power of the received signal in\nmulti-antenna systems. Unlike existing ones, the proposed analytical framework\nis remarkably tractable and computationally efficient, and thus can be\nconveniently employed to analyze systems with massive antenna arrays. We derive\nnovel expressions for the probability density function and cumulative\ndistribution function, analyze their convergence and truncation error, and\ndiscuss the computational complexity and the implementation aspects. Moreover,\nwe derive expressions for the coverage probability and bit error probability\nfor coherent binary modulations. Lastly, we evaluate the performance of an\nuplink sub-THz system where a single-antenna user is served by a base station\nemploying maximum ratio combining.", "published": "2025-08-08 11:49:19", "link": "http://arxiv.org/abs/2508.06242v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On MDS Convertible Codes in the Merge Regime", "abstract": "In large-scale distributed storage systems, erasure coding is employed to\nensure reliability against disk failures. Recent work by Kadekodi et al.\ndemonstrates that adapting code parameters to varying disk failure rates can\nlead to significant storage savings without compromising reliability. Such\nadaptations, known as \\emph{code conversions}, motivate the design of\n\\emph{convertible codes}, which enable efficient transformations between codes\nof different parameters.\n  In this work, we study the setting in which $\\lambda$ codewords of an initial\n$[n^I = k^I + r^I,\\, k^I]$ MDS code are merged into a single codeword of a\nfinal $[n^F = \\lambda k^I + r^F,\\, k^F = \\lambda k^I]$ MDS code. We begin by\npresenting three constructions that achieve optimal \\emph{access cost}, defined\nas the total number of disks accessed during the conversion process. The first\ntwo constructions apply when $\\lambda \\leq r^I$ and impose specific\ndivisibility conditions on $r^I$ and the field size $q$. These schemes minimize\nboth the per-symbol and the overall access cost. The third construction, which\nbuilds on a prior scheme by Kong, achieves minimal access cost while supporting\narbitrary parameter regimes. All three constructions require field sizes that\nare linear in the final code length, and notably, the third construction\nachieves a field size that matches the lower bound implied by the MDS\nconjecture in almost all cases. In addition, we propose a construction that\noptimizes the \\emph{bandwidth cost}, defined as the total number of symbols\ntransmitted during conversion. This scheme is a refinement of Maturana and\nRashmi's bandwidth-optimal construction based on the piggybacking framework,\nand achieves reduced sub-packetization.", "published": "2025-08-08 10:59:52", "link": "http://arxiv.org/abs/2508.06219v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Multi-Functional Chirp Signalling for Next-Generation Multi-Carrier Wireless Networks: Communications, Sensing and ISAC Perspectives", "abstract": "To meet the increasingly demanding quality-of-service requirements of the\nnext-generation multi-carrier mobile networks, it is essential to design\nmulti-functional signalling schemes facilitating efficient, flexible, and\nreliable communication and sensing in complex wireless environments. As a\ncompelling candidate, we advocate chirp signalling, beneficially amalgamating\nsequences (e.g., Zadoff-Chu sequences) with waveforms (e.g., chirp spread\nspectrum and frequency-modulated continuous wave (FMCW) radar), given their\nresilience against doubly selective channels. Besides chirp sequences, a wide\nrange of chirp waveforms is considered, ranging from FMCW to affine\nfrequency-division multiplexing (AFDM), to create a promising chirp\nmulticarrier waveform. This study also highlights the advantages of such\nwaveforms in supporting reliable high-mobility communications, plus integrated\nsensing and communications (ISAC). Finally, we outline several emerging\nresearch directions for chirp signalling designs.", "published": "2025-08-08 05:17:17", "link": "http://arxiv.org/abs/2508.06022v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "IRS-Assisted IoT Activity Detection Under Asynchronous Transmission and Heterogeneous Powers: Detectors and Performance Analysis", "abstract": "This paper addresses the problem of activity detection in distributed\nInternet of Things (IoT) networks, where devices employ asynchronous\ntransmissions with heterogeneous power levels to report their local\nobservations. The system leverages an intelligent reflecting surface (IRS) to\nenhance detection reliability, with optional incorporation of a direct\nline-of-sight (LoS) path. We formulate the detection problem as a binary\nhypothesis test and develop four detectors: an optimal detector alongside three\ncomputationally efficient detectors designed for practical scenarios with\ndifferent levels of prior knowledge about noise variance, channel state\ninformation, and device transmit powers. For each detector, we derive\nclosed-form expressions for both detection and false alarm probabilities,\nestablishing theoretical performance benchmarks. Extensive simulations validate\nour analytical results and systematically evaluate the impact of key system\nparameters including the number of antennas, samples, users, and IRS elements\non detection performance. The proposed framework effectively bridges\ntheoretical optimality with implementation practicality, providing a scalable\nsolution for IRS-assisted IoT networks in emerging 6G systems.", "published": "2025-08-08 02:46:03", "link": "http://arxiv.org/abs/2508.05959v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "abstract": "Large Language Models (LLMs) have demonstrated impressive fluency and\nreasoning capabilities, but their potential for misuse has raised growing\nconcern. In this paper, we present ScamAgent, an autonomous multi-turn agent\nbuilt on top of LLMs, capable of generating highly realistic scam call scripts\nthat simulate real-world fraud scenarios. Unlike prior work focused on\nsingle-shot prompt misuse, ScamAgent maintains dialogue memory, adapts\ndynamically to simulated user responses, and employs deceptive persuasion\nstrategies across conversational turns. We show that current LLM safety\nguardrails, including refusal mechanisms and content filters, are ineffective\nagainst such agent-based threats. Even models with strong prompt-level\nsafeguards can be bypassed when prompts are decomposed, disguised, or delivered\nincrementally within an agent framework. We further demonstrate the\ntransformation of scam scripts into lifelike voice calls using modern\ntext-to-speech systems, completing a fully automated scam pipeline. Our\nfindings highlight an urgent need for multi-turn safety auditing, agent-level\ncontrol frameworks, and new methods to detect and disrupt conversational\ndeception powered by generative AI.", "published": "2025-08-08 17:01:41", "link": "http://arxiv.org/abs/2508.06457v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Memp: Exploring Agent Procedural Memory", "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they\nsuffer from brittle procedural memory that is manually engineered or entangled\nin static parameters. In this work, we investigate strategies to endow agents\nwith a learnable, updatable, and lifelong procedural memory. We propose Memp\nthat distills past agent trajectories into both fine-grained, step-by-step\ninstructions and higher-level, script-like abstractions, and explore the impact\nof different strategies for Build, Retrieval, and Update of procedural memory.\nCoupled with a dynamic regimen that continuously updates, corrects, and\ndeprecates its contents, this repository evolves in lockstep with new\nexperience. Empirical evaluation on TravelPlanner and ALFWorld shows that as\nthe memory repository is refined, agents achieve steadily higher success rates\nand greater efficiency on analogous tasks. Moreover, procedural memory built\nfrom a stronger model retains its value: migrating the procedural memory to a\nweaker model yields substantial performance gains.", "published": "2025-08-08 16:20:56", "link": "http://arxiv.org/abs/2508.06433v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "abstract": "We introduce Unsupervised Partner Design (UPD) - a population-free,\nmulti-agent reinforcement learning framework for robust ad-hoc teamwork that\nadaptively generates training partners without requiring pretrained partners or\nmanual parameter tuning. UPD constructs diverse partners by stochastically\nmixing an ego agent's policy with biased random behaviours and scores them\nusing a variance-based learnability metric that prioritises partners near the\nego agent's current learning frontier. We show that UPD can be integrated with\nunsupervised environment design, resulting in the first method enabling fully\nunsupervised curricula over both level and partner distributions in a\ncooperative setting. Through extensive evaluations on Overcooked-AI and the\nOvercooked Generalisation Challenge, we demonstrate that this dynamic partner\ncurriculum is highly effective: UPD consistently outperforms both\npopulation-based and population-free baselines as well as ablations. In a user\nstudy, we further show that UPD achieves higher returns than all baselines and\nwas perceived as significantly more adaptive, more human-like, a better\ncollaborator, and less frustrating.", "published": "2025-08-08 14:11:15", "link": "http://arxiv.org/abs/2508.06336v1", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "abstract": "We present Big5-Scaler, a prompt-based framework for conditioning large\nlanguage models (LLMs) with controllable Big Five personality traits. By\nembedding numeric trait values into natural language prompts, our method\nenables fine-grained personality control without additional training. We\nevaluate Big5-Scaler across trait expression, dialogue generation, and human\ntrait imitation tasks. Results show that it induces consistent and\ndistinguishable personality traits across models, with performance varying by\nprompt type and scale. Our analysis highlights the effectiveness of concise\nprompts and lower trait intensities, providing a efficient approach for\nbuilding personality-aware dialogue agents.", "published": "2025-08-08 09:11:05", "link": "http://arxiv.org/abs/2508.06149v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "abstract": "Table reasoning, including tabular QA and fact verification, often depends on\nannotated data or complex data augmentation, limiting flexibility and\ngeneralization. LLMs, despite their versatility, often underperform compared to\nsimple supervised models. To approach these issues, we introduce PanelTR, a\nframework utilizing LLM agent scientists for robust table reasoning through a\nstructured scientific approach. PanelTR's workflow involves agent scientists\nconducting individual investigations, engaging in self-review, and\nparticipating in collaborative peer-review discussions. This process, driven by\nfive scientist personas, enables semantic-level transfer without relying on\ndata augmentation or parametric optimization. Experiments across four\nbenchmarks show that PanelTR outperforms vanilla LLMs and rivals fully\nsupervised models, all while remaining independent of training data. Our\nfindings indicate that structured scientific methodology can effectively handle\ncomplex tasks beyond table reasoning with flexible semantic understanding in a\nzero-shot context.", "published": "2025-08-08 08:15:52", "link": "http://arxiv.org/abs/2508.06110v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Policy Optimization in Multi-Agent Settings under Partially Observable Environments", "abstract": "This work leverages adaptive social learning to estimate partially observable\nglobal states in multi-agent reinforcement learning (MARL) problems. Unlike\nexisting methods, the proposed approach enables the concurrent operation of\nsocial learning and reinforcement learning. Specifically, it alternates between\na single step of social learning and a single step of MARL, eliminating the\nneed for the time- and computation-intensive two-timescale learning frameworks.\nTheoretical guarantees are provided to support the effectiveness of the\nproposed method. Simulation results verify that the performance of the proposed\nmethodology can approach that of reinforcement learning when the true state is\nknown.", "published": "2025-08-08 06:45:43", "link": "http://arxiv.org/abs/2508.06061v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Weak approximation of stochastic differential equations with sticky boundary conditions", "abstract": "Sticky diffusion models a Markovian particle experiencing reflection and\ntemporary adhesion phenomena at the boundary. Numerous numerical schemes exist\nfor approximating stopped or reflected stochastic differential equations\n(SDEs), but this is not the case for sticky SDEs. In this paper, we construct\nand analyze half-order and first-order numerical schemes for the weak\napproximation of stochastic differential equations with sticky boundary\nconditions. We present the algorithms in general setting such that they can be\nused to solve general linear parabolic partial differential equations with\nsecond-order sticky boundary condition via the probabilistic representations of\ntheir solutions. Since the sticky diffusion spends non-zero amount of time on\nboundary, it poses extra challenge in designing the schemes and obtaining their\norder of convergence. We support the theoretical results with numerical\nexperiments.", "published": "2025-08-08 17:50:18", "link": "http://arxiv.org/abs/2508.06487v1", "categories": ["math.NA", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Does block size matter in randomized block Krylov low-rank approximation?", "abstract": "We study the problem of computing a rank-$k$ approximation of a matrix using\nrandomized block Krylov iteration. Prior work has shown that, for block size $b\n= 1$ or $b = k$, a $(1 + \\varepsilon)$-factor approximation to the best\nrank-$k$ approximation can be obtained after $\\tilde O(k/\\sqrt{\\varepsilon})$\nmatrix-vector products with the target matrix. On the other hand, when $b$ is\nbetween $1$ and $k$, the best known bound on the number of matrix-vector\nproducts scales with $b(k-b)$, which could be as large as $O(k^2)$.\nNevertheless, in practice, the performance of block Krylov methods is often\noptimized by choosing a block size $1 \\ll b \\ll k$. We resolve this\ntheory-practice gap by proving that randomized block Krylov iteration produces\na $(1 + \\varepsilon)$-factor approximate rank-$k$ approximation using $\\tilde\nO(k/\\sqrt{\\varepsilon})$ matrix-vector products for any block size $1\\le b\\le\nk$. Our analysis relies on new bounds for the minimum singular value of a\nrandom block Krylov matrix, which may be of independent interest. Similar\nbounds are central to recent breakthroughs on faster algorithms for sparse\nlinear systems [Peng & Vempala, SODA 2021; Nie, STOC 2022].", "published": "2025-08-08 17:50:01", "link": "http://arxiv.org/abs/2508.06486v1", "categories": ["cs.DS", "cs.NA", "math.NA", "65F55 65F15", "G.1.3; F.2.1"], "primary_category": "cs.DS"}
{"title": "Heterogeneous optimized Schwarz Methods for heat conduction in composites with thermal contact resistance", "abstract": "Heat transfer in composites is critical in engineering, where imperfect layer\ncontact causes thermal contact resistance (TCR), leading to interfacial\ntemperature discontinuity. We propose solving this numerically using the\noptimized Schwarz method (OSM), which decouples the heterogeneous problem into\nhomogeneous subproblems. This avoids ill-conditioned systems from monolithic\nsolving due to high contrast and interface jumps. Both energy estimate and\nFourier analysis are used to prove the convergence of this algorithm when the\nstandard Robin condition is applied to transmit information between subdomains.\nTo achieve fast convergence, instead of the standard Robin, the scaled Robin\ntransmission condition is proposed, and the involved free parameter is\nrigorously optimized. The results reveal several new findings due to the\npresence of TCR: first, the larger the TCR, the faster the OSM converges;\nsecond, mesh-independent convergence is achieved in the asymptotic sense, in\ncontrast to the mesh-dependent results without TCR; and last, the heterogeneity\ncontrast benefits the convergence, with a larger contrast leading to faster\nconvergence. Interestingly, different from the case without TCR, the thermal\nconductivity also benefits the convergence, similar to the effect of\nheterogeneity. Numerical experiments confirm the theoretical findings and\ndemonstrate the method's potential for nonlinear problems on irregular domains.", "published": "2025-08-08 15:51:12", "link": "http://arxiv.org/abs/2508.06408v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rational minimax approximation of matrix-valued functions", "abstract": "In this paper, we present a rigorous framework for rational minimax\napproximation of matrix-valued functions that generalizes classical scalar\napproximation theory. Given sampled data $\\{(x_\\ell, {F}(x_\\ell))\\}_{\\ell=1}^m$\nwhere ${F}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ is a matrix-valued function,\nwe study the problem of finding a matrix-valued rational approximant ${R}(x) =\n{P}(x)/q(x)$ (with ${P}:\\mathbb{C} \\to \\mathbb{C}^{s \\times t}$ a matrix-valued\npolynomial and $q(x)$ a nonzero scalar polynomial of prescribed degrees) that\nminimizes the worst-case Frobenius norm error over the given nodes: $$\n\\inf_{{R}(x) = {P}(x)/q(x)} \\max_{1 \\leq \\ell \\leq m} \\|{F}(x_\\ell) -\n{R}(x_\\ell)\\|_{\\rm F}. $$ By reformulating this min-max optimization problem\nthrough Lagrangian duality, we derive a maximization dual problem over the\nprobability simplex. We analyze weak and strong duality properties and\nestablish a sufficient condition ensuring that the solution of the dual problem\nyields the minimax approximant $R(x)$. For numerical implementation, we propose\nan efficient method (\\textsf{m-d-Lawson}) to solve the dual problem,\ngeneralizing Lawson's iteration to matrix-valued functions. Numerical\nexperiments are conducted and compared to state-of-the-art approaches,\ndemonstrating its efficiency as a novel computational framework for\nmatrix-valued rational approximation.", "published": "2025-08-08 15:09:24", "link": "http://arxiv.org/abs/2508.06378v1", "categories": ["math.NA", "cs.NA", "41A50, 41A20, 65D15, 90C46"], "primary_category": "math.NA"}
{"title": "Higher Order Regularization using Harmonic Eigenfunctions for Model-Based Reconstruction in Magnetic Particle Imaging", "abstract": "Magnetic Particle Imaging (MPI) is a recent imaging modality where\nsuperparamagnetic nanoparticles are employed as tracers. The reconstruction\ntask is to obtain the spatial particle distribution from a voltage signal\ninduced by the particles. Generally, in computational imaging variational\nreconstruction techniques are common and rely on a mathematical model to\ndescribe the underlying physics. For the MPI reconstruction task we propose a\nmodel-based variational reconstruction technique which incorporates a higher\norder regularizer, where the regularizer is diagonalized by harmonic\neigenfunctions. The proposed image reconstruction algorithm features two major\nstages: in the first stage, the core stage, the components of the MPI core\nresponse are reconstructed. This is the MPI-specific data approximation task\nwhich we formulate as a variational problem incorporating the higher order\nregularizer. The relationship between the particle distribution, the MPI core\nresponse and the measured data is given by a mathematical model which was\nintroduced in our earlier research. According to this model the MPI core\nresponse is tied to the particle distribution by convolution. Therefore the\noutcome of the core stage yields the data for the second stage, the\ndeconvolution stage, in which the final reconstructed image is produced by\nsolving an ill-posed deconvolution problem in a robust way relying on earlier\nresearch. Interestingly, the quality of the final image depends significantly\non the quality of the result of the core stage. A contribution is thus the\nenhancement of the core stage via higher order regularization. We provide a\ntheoretical foundation for our approach and demonstrate its benefit with\nnumerical examples.", "published": "2025-08-08 13:33:21", "link": "http://arxiv.org/abs/2508.06306v1", "categories": ["math.NA", "cs.NA", "65K10, 65R32, 65T40, 92C55"], "primary_category": "math.NA"}
{"title": "A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions", "abstract": "Computing with discrete representations of high-dimensional probability\ndistributions is fundamental to uncertainty quantification, Bayesian inference,\nand stochastic modeling. However, storing and manipulating such distributions\nsuffers from the curse of dimensionality, as memory and computational costs\ngrow exponentially with dimension. Monte Carlo methods require thousands to\nbillions of samples, incurring high computational costs and producing\ninconsistent results due to stochasticity. We present an efficient tensor train\nmethod for performing exact arithmetic operations on discretizations of\ncontinuous probability distributions while avoiding exponential growth. Our\napproach leverages low-rank tensor train decomposition to represent latent\nrandom variables compactly using Dirac deltas, enabling deterministic addition,\nsubtraction and multiplication operations directly in the compressed format. We\ndevelop an efficient implementation using sparse matrices and specialized data\nstructures that further enhances performance. Theoretical analysis demonstrates\npolynomial scaling of memory and computational complexity under rank\nassumptions, and shows how statistics of latent variables can be computed with\npolynomial complexity. Numerical experiments spanning randomized linear algebra\nto stochastic differential equations demonstrate orders-of-magnitude\nimprovements in memory usage and computational time compared to conventional\napproaches, enabling tractable deterministic computations on discretized random\nvariables in previously intractable dimensions.", "published": "2025-08-08 13:27:35", "link": "http://arxiv.org/abs/2508.06303v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Parallelized computation of quasi-periodic solutions for finite element problems: A Fourier series expansion-based shooting method", "abstract": "High-dimensional nonlinear mechanical systems admit quasi-periodic solutions\nthat are essential for the understanding of the dynamical systems. These\nquasi-periodic solutions stay on some invariant tori governed by complex PDEs\nin hyper-time. Here, we propose a Fourier series expansion-based shooting\nmethod (FSE-Shooting) for the parallelized computation of quasi-periodic\nsolution with $d$ base frequencies ($d \\ge 2$). We represent the associated\n$d$-torus as a collection of trajectories initialized at a ($d-1$)-torus. We\ndrive a set of ODEs that hold for any of these trajectories. We also derive a\nset of boundary conditions that couple the initial and terminal states of these\ntrajectories and then formulate a set of nonlinear algebraic equations via the\ncoupling conditions. We use Fourier series expansion to parameterize the\n($d-1$)-torus and shooting method to iterate the Fourier coefficients\nassociated with initial torus such that the coupling conditions are satisfied.\nIn particular, the terminal points of these trajectories are parallelized\ncomputed via Newmark integration, where the time points and Fourier\ncoefficients are transformed to each other by alternating Frequency-Time\nmethod. A straightforward phase condition is devised to track the\nquasi-periodic solutions with priori unknown base frequencies. Additionally,\nthe by-product of the FSE-Shooting can be also directly used to compute the\nLyapunov exponents to assess the stabilities of quasi-periodic solutions. The\nresults of three finite element systems show the efficiency and versatility of\nFSE-Shooting in high-dimensional nonlinear dynamical systems, including a\nthree-dimensional shell structure with $1872$ DOFs.", "published": "2025-08-08 13:27:01", "link": "http://arxiv.org/abs/2508.06302v1", "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "math.NA"}
{"title": "A Fully Discrete Truly Multidimensional Active Flux Method For The Two-Dimensional Euler Equations", "abstract": "The Active Flux method is a finite volume method for hyperbolic conservation\nlaws that uses both cell averages and point values as degrees of freedom.\nSeveral versions of such methods are currently under development. We focus on\nthird order accurate, fully discrete Active Flux methods with compact stencil\nin space and time. These methods require exact or approximate evolution\noperators for the update of the point value degrees of freedom which are\nprovided by the method of bicharacteristics. Here we propose new limiting\nstrategies that guarantee positivity of pressure and density and furthermore\ndiscuss the implementation of reflecting boundary conditions. Numerical results\nshow that the method leads to accurate approximates on coarse grids.", "published": "2025-08-08 12:46:22", "link": "http://arxiv.org/abs/2508.06273v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical Considerations in Weighted Model Counting", "abstract": "Weighted model counting computes the sum of the rational-valued weights\nassociated with the satisfying assignments for a Boolean formula, where the\nweight of an assignment is given by the product of the weights assigned to the\npositive and negated variables comprising the assignment. Weighted model\ncounting finds applications across a variety of domains including probabilistic\nreasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly)\nconverting the input formula into a form that enables arithmetic evaluation,\nusing multiplication for conjunctions and addition for disjunctions. Performing\nthis evaluation using floating-point arithmetic can yield inaccurate results,\nand it cannot quantify the level of precision achieved. Computing with rational\narithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to\nefficiently compute weighted model counts that are guaranteed to achieve a\nuser-specified precision. When all weights are nonnegative, we prove that the\nprecision loss of arithmetic evaluation using floating-point arithmetic can be\ntightly bounded. We show that supplementing a standard IEEE double-precision\nrepresentation with a separate 64-bit exponent, a format we call extended-range\ndouble (ERD), avoids the underflow and overflow issues commonly encountered in\nweighted model counting. For problems with mixed negative and positive weights,\nwe show that a combination of interval floating-point arithmetic and rational\narithmetic can achieve the twin goals of efficiency and guaranteed precision.\nFor our evaluations, we have devised especially challenging formulas and weight\nassignments, demonstrating the robustness of our approach.", "published": "2025-08-08 12:28:49", "link": "http://arxiv.org/abs/2508.06264v1", "categories": ["math.NA", "cs.AI", "cs.LO", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fully discrete error analysis of finite element discretizations of time-dependent Stokes equations in a stream-function formulation", "abstract": "In this paper we establish best approximation type error estimates for the\nfully discrete Galerkin solutions of the time-dependent Stokes problem using\nthe stream-function formulation. For the time discretization we use the\ndiscontinuous Galerkin method of arbitrary degree, whereas we present the space\ndiscretization in a general framework. This makes our result applicable for a\nwide variety of space discretization methods, provided some Galerkin\northogonality conditions are satisfied. As an example, conformal $C^1$ and\n$C^0$ interior penalty methods are covered by our analysis. The results do not\nrequire any additional regularity assumptions beyond the natural regularity\ngiven by the domain and data and can be used for optimal control problems.", "published": "2025-08-08 11:38:01", "link": "http://arxiv.org/abs/2508.06235v1", "categories": ["math.NA", "cs.NA", "76M10, 35G16, 65M15, 65M60, 65N30"], "primary_category": "math.NA"}
{"title": "A Preliminary Study on the Dimensional Stability Classification of Polynomial Spline Spaces over T-meshes", "abstract": "This paper introduces the concept of dimensional stability for spline spaces\nover T-meshes, providing the first mathematical definition and a preliminary\nclassification framework. We define dimensional stability as an invariant\nwithin the structurally isomorphic class, contingent on the rank stability of\nthe conformality matrix. Absolute stability is proposed via structurally\nsimilar maps to address topological and order structures. Through the\n$k$-partition decomposition of T-connected components and analysis of the CNDC,\nwe establish a correspondence between conformality vector spaces and rank\nstability. For diagonalizable T-meshes, decomposition into independent\none-dimensional T $l$-edges facilitates basis function construction, while\narbitrary T-meshes are partitioned into one- and two-dimensional components.\nThese findings lay the groundwork for understanding dimensional stability and\ndeveloping spline space basis functions.", "published": "2025-08-08 10:55:15", "link": "http://arxiv.org/abs/2508.06217v1", "categories": ["math.NA", "cs.NA", "65D07"], "primary_category": "math.NA"}
{"title": "$k\\ell$-refinement: An adaptive mesh refinement scheme for hiearchical hybrid grids", "abstract": "This work introduces an adaptive mesh refinement technique for hierarchical\nhybrid grids with the goal to reach scalability and maintain excellent\nperformance on massively parallel computer systems. On the block structured\nhierarchical hybrid grids, this is accomplished by using classical,\nunstructured refinement only on the coarsest level of the hierarchy, while\nkeeping the number of structured refinement levels constant on the whole\ndomain. This leads to a compromise where the excellent performance\ncharacteristics of hierarchical hybrid grids can be maintained at the price\nthat the flexibility of generating locally refined meshes is constrained.\nFurthermore, mesh adaptivity often relies on a posteriori error estimators or\nerror indicators that tend to become computationally expensive. Again with the\ngoal of preserving scalability and performance, a method is proposed that\nleverages the grid hierarchy and the full multigrid scheme that generates a\nnatural sequence of approximations on the nested hierarchy of grids. This\npermits to compute a cheap error estimator that is well-suited for large-scale\nparallel computing. We present the theoretical foundations for both global and\nlocal error estimates and present a rigorous analysis of their effectivity. The\nproposed method, including error estimator and the adaptive coarse grid\nrefinement, is implemented in the finite element framework HyTeG. Extensive\nnumerical experiments are conducted to validate the effectiveness, as well as\nperformance and scalability.", "published": "2025-08-08 06:14:38", "link": "http://arxiv.org/abs/2508.06049v1", "categories": ["math.NA", "cs.NA", "65N50, 65N55"], "primary_category": "math.NA"}
{"title": "Transfinite Iteration of Operator Transforms and Spectral Projections in Hilbert and Banach Spaces", "abstract": "We study ordinal-indexed, multi-layer iterations of bounded operator\ntransforms and prove convergence to spectral/ergodic projections under\nfunctional-calculus hypotheses. For normal operators on Hilbert space and\npolynomial or holomorphic layers that are contractive on the spectrum and fix\nthe peripheral spectrum only at fixed points, the iterates converge in the\nstrong operator topology by a countable stage to the spectral projection onto\nthe joint peripheral fixed set. We describe spectral mapping at finite stages\nand identify the spectrum of the limit via the essential range. In reflexive\nBanach spaces, for Ritt or sectorial operators with a bounded H-infinity\nfunctional calculus, the composite layer is power-bounded and its mean-ergodic\nprojection yields an idempotent commuting with the original operator; under a\nperipheral-separation condition the powers converge strongly to this\nprojection. We provide explicit two-layer Schur filters, a concise\nSchur/Nevanlinna-Pick lemma, a Fejer-type monotonicity bound implying\nstabilization by the first countable limit (omega), examples that attain\nexactly the omega stage, and counterexamples outside the hypotheses.", "published": "2025-08-08 05:21:56", "link": "http://arxiv.org/abs/2508.06025v1", "categories": ["math.FA", "cs.NA", "math.NA", "math.SP", "47A10, 47A60, 47A35, 47B15, 47D06, 47A15", "G.1.0; G.1.3; G.1.10"], "primary_category": "math.FA"}
{"title": "Kahan's Automatic Step-Size Control for Unconstrained Optimization", "abstract": "The Barzilai and Borwein (BB) gradient method is one of the most widely-used\nline-search gradient methods. It computes the step-size for the current iterate\nby using the information carried in the previous iteration. Recently, William\nKahan [Kahan, Automatic Step-Size Control for Minimization Iterations,\nTechnical report, University of California, Berkeley CA, USA, 2019] proposed\nnew Gradient Descent (KGD) step-size strategies which iterate the step-size\nitself by effectively utilizing the information in the previous iteration. In\nthe quadratic model, such a new step-size is shown to be mathematically\nequivalent to the long BB step, but no rigorous mathematical proof of its\nefficiency and effectiveness for the general unconstrained minimization is\navailable. In this paper, by this equivalence with the long BB step, we first\nderive a short version of KGD step-size and show that, for the strongly convex\nquadratic model with a Hessian matrix $H$, both the long and short KGD\nstep-size (and hence BB step-sizes) gradient methods converge at least\nR-linearly with a rate $1-\\frac{1}{{\\rm cond}(H)}$. For the general\nunconstrained minimization, we further propose an adaptive framework to\neffectively use the KGD step-sizes; global convergence and local R-linear\nconvergence rate are proved. Numerical experiments are conducted on the CUTEst\ncollection as well as the practical logistic regression problems, and we\ncompare the performance of the proposed methods with various BB step-size\napproaches and other recently proposed adaptive gradient methods to demonstrate\nthe efficiency and robustness.", "published": "2025-08-08 04:09:48", "link": "http://arxiv.org/abs/2508.06002v1", "categories": ["math.OC", "cs.NA", "math.NA", "65L20, 65B99, 90C25"], "primary_category": "math.OC"}
{"title": "Hierarchical Tucker Low-Rank Matrices: Construction and Matrix-Vector Multiplication", "abstract": "In this paper, a hierarchical Tucker low-rank (HTLR) matrix is proposed to\napproximate non-oscillatory kernel functions in linear complexity. The HTLR\nmatrix is based on the hierarchical matrix, with the low-rank blocks replaced\nby Tucker low-rank blocks. Using high-dimensional interpolation as well as\ntensor contractions, algorithms for the construction and matrix-vector\nmultiplication of HTLR matrices are proposed admitting linear and quasi-linear\ncomplexities respectively. Numerical experiments demonstrate that the HTLR\nmatrix performs well in both memory and runtime. Furthermore, the HTLR matrix\ncan also be applied on quasi-uniform grids in addition to uniform grids,\nenhancing its versatility.", "published": "2025-08-08 02:45:36", "link": "http://arxiv.org/abs/2508.05958v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Minimal Perturbation Approach For The Rectangular Multiparameter Eigenvalue Problem", "abstract": "The rectangular multiparameter eigenvalue problem (RMEP) involves rectangular\ncoefficient matrices (usually with more rows than columns) and may potentially\nhave no solution in its original form. A minimal perturbation framework is\nproposed to defines approximate solutions. Computationally, two particular\nscenarios are considered: computing one approximate eigen-tuple or a complete\nset of approximate eigen-tuples. For computing one approximate eigen-tuple, an\nalternating iterative scheme with proven convergence is devised, while for a\ncomplete set of approximate eigen-tuples, the framework leads to a standard MEP\n(RMEP with square coefficient matrices) for numerical solutions. The proposed\napproach is validated on RMEPs from discretizing the multiparameter\nSturm-Liouville equation and the Helmholtz equations by the least-squares\nspectral method.", "published": "2025-08-08 02:20:05", "link": "http://arxiv.org/abs/2508.05948v1", "categories": ["math.NA", "cs.NA", "65F15, 65F20, 15A18, 47A75, 65N35"], "primary_category": "math.NA"}
{"title": "Debiasing Polynomial and Fourier Regression", "abstract": "We study the problem of approximating an unknown function\n$f:\\mathbb{R}\\to\\mathbb{R}$ by a degree-$d$ polynomial using as few function\nevaluations as possible, where error is measured with respect to a probability\ndistribution $\\mu$. Existing randomized algorithms achieve near-optimal sample\ncomplexities to recover a $ (1+\\varepsilon) $-optimal polynomial but produce\nbiased estimates of the best polynomial approximation, which is undesirable.\n  We propose a simple debiasing method based on a connection between polynomial\nregression and random matrix theory. Our method involves evaluating\n$f(\\lambda_1),\\ldots,f(\\lambda_{d+1})$ where $\\lambda_1,\\ldots,\\lambda_{d+1}$\nare the eigenvalues of a suitably designed random complex matrix tailored to\nthe distribution $\\mu$. Our estimator is unbiased, has near-optimal sample\ncomplexity, and experimentally outperforms iid leverage score sampling.\n  Additionally, our techniques enable us to debias existing methods for\napproximating a periodic function with a truncated Fourier series with\nnear-optimal sample complexity.", "published": "2025-08-08 00:43:33", "link": "http://arxiv.org/abs/2508.05920v1", "categories": ["cs.DS", "cs.NA", "math.NA", "65F99", "G.1.3"], "primary_category": "cs.DS"}
{"title": "Multivariate Fields of Experts", "abstract": "We introduce the multivariate fields of experts, a new framework for the\nlearning of image priors. Our model generalizes existing fields of experts\nmethods by incorporating multivariate potential functions constructed via\nMoreau envelopes of the $\\ell_\\infty$-norm. We demonstrate the effectiveness of\nour proposal across a range of inverse problems that include image denoising,\ndeblurring, compressed-sensing magnetic-resonance imaging, and computed\ntomography. The proposed approach outperforms comparable univariate models and\nachieves performance close to that of deep-learning-based regularizers while\nbeing significantly faster, requiring fewer parameters, and being trained on\nsubstantially fewer data. In addition, our model retains a relatively high\nlevel of interpretability due to its structured design.", "published": "2025-08-08 17:58:25", "link": "http://arxiv.org/abs/2508.06490v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Full-Dimensional Beamforming for Multi-User MIMO-OFDM ISAC for Low-Altitude UAV with Zero Sensing Resource Allocation", "abstract": "Low-altitude unmanned aerial vehicles (UAVs) are expected to play an\nimportant role for low-altitude economy with a wide range of applications like\nprecise agriculture, aerial delivery and surveillance. Integrated sensing and\ncommunication (ISAC) is a key technology to enable the large-scale deployment\nand routine usage of UAVs by providing both communication and sensing services\nefficiently. For UAV ISAC systems, as UAV often acts as both a communication\nuser equipment (UE) and a sensing target, traditional ISAC systems that usually\nallocate dedicated TF resources for sensing are inefficient due to the severe\ndegradation of communication spectral efficiency. To address this issue, in\nthis paper, we propose a novel multiple-input multiple-output (MIMO) orthogonal\nfrequency division multiplexing (OFDM)-based ISAC framework for UAVs that\neliminates the need for dedicated sensing TF resources, achieving zero TF\nsensing overhead. By designing the transmit beamforming to meet the\nrequirements for both communication and sensing tasks, our proposed approach\nenables the communication TF resources to be fully reused for sensing, thereby\nenhancing both the communication sum rate and the sensing performance in terms\nof resolution, unambiguous range, and accuracy. Additionally, we introduce a\nlow-complexity target searching beamforming algorithm and a two-stage\nsuper-resolution sensing algorithm, which ensure efficient implementation.\nSimulation results demonstrate that the proposed MIMO-OFDM-ISAC framework not\nonly improves the communication sum rate but also outperforms traditional ISAC\nsystems in sensing performance, making it a promising solution for future ISAC\nsystems to support low-altitude UAVs.", "published": "2025-08-08 16:15:20", "link": "http://arxiv.org/abs/2508.06428v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Acoustic Non-Stationarity Objective Assessment with Hard Label Criteria for Supervised Learning Models", "abstract": "Objective non-stationarity measures are resource intensive and impose\ncritical limitations for real-time processing solutions. In this paper, a novel\nHard Label Criteria (HLC) algorithm is proposed to generate a global\nnon-stationarity label for acoustic signals, enabling supervised learning\nstrategies to be trained as stationarity estimators. The HLC is first evaluated\non state-of-the-art general-purpose acoustic models, demonstrating that these\nmodels encode stationarity information. Furthermore, the first-of-its-kind\nHLC-based Network for Acoustic Non-Stationarity Assessment (NANSA) is proposed.\nNANSA models outperform competing approaches, achieving up to 99\\%\nclassification accuracy, while solving the computational infeasibility of\ntraditional objective measures.", "published": "2025-08-08 15:46:21", "link": "http://arxiv.org/abs/2508.06405v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "MALRIS: Malicious Hardware in RIS-Assisted Wireless Communications", "abstract": "Reconfigurable intelligent surfaces (RIS) enhance wireless communication by\ndynamically shaping the propagation environment, but their integration\nintroduces hardware-level security risks. This paper presents the concept of\nMalicious RIS (MALRIS), where compromised components behave adversarially, even\nunder passive operation. The focus of this work is on practical threats such as\nmanufacturing time tampering, malicious firmware, and partial element control.\nTwo representative attacks, power-splitting and element-splitting, are modeled\nto assess their impact. Simulations in a RIS-assisted system reveal that even a\nlimited hardware compromise can significantly degrade performance metrics such\nas bit error rate, throughput, and secrecy metrics. By exposing this overlooked\nthreat surface, this work aims to promote awareness and support secure,\ntrustworthy RIS deployment in future wireless networks.", "published": "2025-08-08 14:14:15", "link": "http://arxiv.org/abs/2508.06340v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Arbitrarily-high-dimensional reconciliation via cross-rotation for continuous-variable quantum key distribution", "abstract": "Multidimensional rotation serves as a powerful tool for enhancing information\nreconciliation and extending the transmission distance in continuous-variable\nquantum key distribution (CV-QKD). However, the lack of closed-form orthogonal\ntransformations for high-dimensional rotations has limited the maximum\nreconciliation efficiency to channels with 8 dimensions over the past decade.\nThis paper presents a cross-rotation scheme to overcome this limitation and\nenable reconciliation in arbitrarily high dimensions, constrained to even\nmultiples of 8. The key treatment involves reshaping the string vector into\nmatrix form and applying orthogonal transformations to its columns and rows in\na cross manner, thereby increasing the reconciliation dimension by one order\nper cross-rotation while significantly reducing the communication overhead over\nthe classical channel. A rigorous performance analysis is also presented from\nthe perspective of achievable sum-rate. Simulation results demonstrate that\n64-dimensional cross-rotation nearly approaches the upper bound, making it a\nrecommended choice for practical implementations.", "published": "2025-08-08 14:12:34", "link": "http://arxiv.org/abs/2508.06338v1", "categories": ["quant-ph", "eess.SP"], "primary_category": "quant-ph"}
{"title": "Efficient Deep Neural Receiver with Post-Training Quantization", "abstract": "Deep learning has recently garnered significant interest in wireless\ncommunications due to its superior performance compared to traditional\nmodel-based algorithms. Deep convolutional neural networks (CNNs) have\ndemonstrated notable improvements in block error rate (BLER) under various\nchannel models and mobility scenarios. However, the high computational\ncomplexity and resource demands of deep CNNs pose challenges for deployment in\nresource-constrained edge systems. The 3rd Generation Partnership Project\n(3GPP) Release 20 highlights the pivotal role of artificial intelligence (AI)\nintegration in enabling advanced radio-access networks for 6G systems. The hard\nreal-time processing demands of 5G and 6G require efficient techniques such as\npost-training quantization (PTQ), quantization-aware training (QAT), pruning,\nand hybrid approaches to meet latency requirements. In this paper, we focus on\nPTQ to reduce model complexity by lowering the bit-width of weights, thereby\nenhancing computational efficiency. Our analysis employs symmetric uniform\nquantization, applying both per-tensor and per-channel PTQ to a neural receiver\nachieving performance comparable to full-precision models. Specifically, 8-bit\nper-channel quantization maintains BLER performance with minimal degradation,\nwhile 4-bit quantization shows great promise but requires further optimization\nto achieve target BLER levels. These results highlight the potential of\nultra-low bitwidth PTQ for efficient neural receiver deployment in 6G systems.", "published": "2025-08-08 12:48:31", "link": "http://arxiv.org/abs/2508.06275v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A 66-Gb/s/5.5-W RISC-V Many-Core Cluster for 5G+ Software-Defined Radio Uplinks", "abstract": "Following the scale-up of new radio (NR) complexity in 5G and beyond, the\nphysical layer's computing load on base stations is increasing under a strictly\nconstrained latency and power budget; base stations must process > 20-Gb/s\nuplink wireless data rate on the fly, in < 10 W. At the same time, the\nprogrammability and reconfigurability of base station components are the key\nrequirements; it reduces the time and cost of new networks' deployment, it\nlowers the acceptance threshold for industry players to enter the market, and\nit ensures return on investments in a fast-paced evolution of standards. In\nthis article, we present the design of a many-core cluster for 5G and beyond\nbase station processing. Our design features 1024, streamlined RISC-V cores\nwith domain-specific FP extensions, and 4-MiB shared memory. It provides the\nnecessary computational capabilities for software-defined processing of the\nlower physical layer of 5G physical uplink shared channel (PUSCH), satisfying\nhigh-end throughput requirements (66 Gb/s for a transition time interval (TTI),\n9.4-302 Gb/s depending on the processing stage). The throughput metrics for the\nimplemented functions are ten times higher than in state-of-the-art (SoTA)\napplication-specific instruction processors (ASIPs). The energy efficiency on\nkey NR kernels (2-41 Gb/s/W), measured at 800 MHz, 25 {\\deg}C, and 0.8 V, on a\nplaced and routed instance in 12-nm CMOS technology, is competitive with SoTA\narchitectures. The PUSCH processing runs end-to-end on a single cluster in 1.7\nms, at <6-W average power consumption, achieving 12 Gb/s/W.", "published": "2025-08-08 09:45:16", "link": "http://arxiv.org/abs/2508.06176v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Fast End-to-End Simulation and Exploration of Many-RISCV-Core Baseband Transceivers for Software-Defined Radio-Access Networks", "abstract": "The fast-rising demand for wireless bandwidth requires rapid evolution of\nhigh-performance baseband processing infrastructure. Programmable many-core\nprocessors for software-defined radio (SDR) have emerged as high-performance\nbaseband processing engines, offering the flexibility required to capture\nevolving wireless standards and technologies. This trend must be supported by a\ndesign framework enabling functional validation and end-to-end performance\nanalysis of SDR hardware within realistic radio environment models. We propose\na static binary translation based simulator augmented with a fast, approximate\ntiming model of the hardware and coupled to wireless channel models to simulate\nthe most performance-critical physical layer functions implemented in software\non a many (1024) RISC-V cores cluster customized for SDR. Our framework\nsimulates the detection of a 5G OFDM-symbol on a server-class processor in\n9.5s-3min, on a single thread, depending on the input MIMO size (three orders\nof magnitude faster than RTL simulation). The simulation is easily parallelized\nto 128 threads with 73-121x speedup compared to a single thread.", "published": "2025-08-08 09:01:25", "link": "http://arxiv.org/abs/2508.06141v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multi-Modal Neural Radio Radiance Field for Localized Statistical Channel Modelling", "abstract": "This paper presents MM-LSCM, a self-supervised multi-modal neural radio\nradiance field framework for localized statistical channel modeling (LSCM) for\nnext-generation network optimization. Traditional LSCM methods rely solely on\nRSRP data, limiting their ability to model environmental structures that affect\nsignal propagation. To address this, we propose a dual-branch neural\narchitecture that integrates RSRP data and LiDAR point cloud information,\nenhancing spatial awareness and predictive accuracy. MM-LSCM leverages\nvolume-rendering-based multi-modal synthesis to align radio propagation with\nenvironmental obstacles and employs a self-supervised training approach,\neliminating the need for costly labeled data. Experimental results demonstrate\nthat MM-LSCM significantly outperforms conventional methods in channel\nreconstruction accuracy and robustness to noise, making it a promising solution\nfor real-world wireless network optimization.", "published": "2025-08-08 06:22:43", "link": "http://arxiv.org/abs/2508.06054v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bayesian Radio Map Estimation: Fundamentals and Implementation via Diffusion Models", "abstract": "Radio map estimation (RME) is the problem of inferring the value of a certain\nmetric (e.g. signal power) across an area of interest given a collection of\nmeasurements. While most works tackle this problem from a purely non-Bayesian\nperspective, some Bayesian estimators have been proposed. However, the latter\nfocus on estimating the map itself, the Bayesian standpoint is adopted mainly\nto exploit prior information or to capture uncertainty. This paper pursues a\nmore general formulation, where the goal is to determine the posterior\ndistribution of the map given the measurements. Besides handling uncertainty\nand allowing standard Bayesian estimates, solving this problem is seen to\nenable minimum mean square error estimation of arbitrary map functionals (e.g.\ncapacity, bit error rate, or coverage area to name a few) while training only\nfor power estimation. A general Bayesian estimator is proposed based on\nconditional diffusion models and both the Bayesian and non-Bayesian paradigms\nare compared analytically and numerically to determine when the Bayesian\napproach is preferable.", "published": "2025-08-08 05:48:29", "link": "http://arxiv.org/abs/2508.06037v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
