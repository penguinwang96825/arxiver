{"title": "Learning from Real Users: Rating Dialogue Success with Neural Networks\n  for Reinforcement Learning in Spoken Dialogue Systems", "abstract": "To train a statistical spoken dialogue system (SDS) it is essential that an\naccurate method for measuring task success is available. To date training has\nrelied on presenting a task to either simulated or paid users and inferring the\ndialogue's success by observing whether this presented task was achieved or\nnot. Our aim however is to be able to learn from real users acting under their\nown volition, in which case it is non-trivial to rate the success as any prior\nknowledge of the task is simply unavailable. User feedback may be utilised but\nhas been found to be inconsistent. Hence, here we present two neural network\nmodels that evaluate a sequence of turn-level features to rate the success of a\ndialogue. Importantly these models make no use of any prior knowledge of the\nuser's task. The models are trained on dialogues generated by a simulated user\nand the best model is then used to train a policy on-line which is shown to\nperform at least as well as a baseline system using prior knowledge of the\nuser's task. We note that the models should also be of interest for evaluating\nSDS and for monitoring a dialogue in rule-based SDS.", "published": "2015-08-13 23:44:03", "link": "http://arxiv.org/abs/1508.03386v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Generation of Multimedia Artifacts: An Extractive Summarization-based\n  Approach", "abstract": "We explore methods for content selection and address the issue of coherence\nin the context of the generation of multimedia artifacts. We use audio and\nvideo to present two case studies: generation of film tributes, and\nlecture-driven science talks. For content selection, we use centrality-based\nand diversity-based summarization, along with topic analysis. To establish\ncoherence, we use the emotional content of music, for film tributes, and ensure\ntopic similarity between lectures and documentaries, for science talks.\nComposition techniques for the production of multimedia artifacts are addressed\nas a means of organizing content, in order to improve coherence. We discuss our\nresults considering the above aspects.", "published": "2015-08-13 10:56:42", "link": "http://arxiv.org/abs/1508.03170v1", "categories": ["cs.AI", "cs.CL", "cs.MM", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Talking about the Moving Image: A Declarative Model for Image Schema\n  Based Embodied Perception Grounding and Language Generation", "abstract": "We present a general theory and corresponding declarative model for the\nembodied grounding and natural language based analytical summarisation of\ndynamic visuo-spatial imagery. The declarative model ---ecompassing\nspatio-linguistic abstractions, image schemas, and a spatio-temporal feature\nbased language generator--- is modularly implemented within Constraint Logic\nProgramming (CLP). The implemented model is such that primitives of the theory,\ne.g., pertaining to space and motion, image schemata, are available as\nfirst-class objects with `deep semantics' suited for inference and query. We\ndemonstrate the model with select examples broadly motivated by areas such as\nfilm, design, geography, smart environments where analytical natural language\nbased externalisations of the moving image are central from the viewpoint of\nhuman interaction, evidence-based qualitative analysis, and sensemaking.\n  Keywords: moving image, visual semantics and embodiment, visuo-spatial\ncognition and computation, cognitive vision, computational models of narrative,\ndeclarative spatial reasoning", "published": "2015-08-13 17:34:07", "link": "http://arxiv.org/abs/1508.03276v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
