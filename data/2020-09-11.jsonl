{"title": "UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific\n  Trained BERT", "abstract": "Manipulative and misleading news have become a commodity for some online news\noutlets and these news have gained a significant impact on the global mindset\nof people. Propaganda is a frequently employed manipulation method having as\ngoal to influence readers by spreading ideas meant to distort or manipulate\ntheir opinions. This paper describes our participation in the SemEval-2020,\nTask 11: Detection of Propaganda Techniques in News Articles competition. Our\napproach considers specializing a pre-trained BERT model on propagandistic and\nhyperpartisan news articles, enabling it to create more adequate\nrepresentations for the two subtasks, namely propaganda Span Identification\n(SI) and propaganda Technique Classification (TC). Our proposed system achieved\na F1-score of 46.060% in subtask SI, ranking 5th in the leaderboard from 36\nteams and a micro-averaged F1 score of 54.302% for subtask TC, ranking 19th\nfrom 32 teams.", "published": "2020-09-11 08:44:14", "link": "http://arxiv.org/abs/2009.05289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural\n  Language Understanding", "abstract": "Although Indonesian is known to be the fourth most frequently used language\nover the internet, the research progress on this language in the natural\nlanguage processing (NLP) is slow-moving due to a lack of available resources.\nIn response, we introduce the first-ever vast resource for the training,\nevaluating, and benchmarking on Indonesian natural language understanding\n(IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence\nclassification to pair-sentences sequence labeling with different levels of\ncomplexity. The datasets for the tasks lie in different domains and styles to\nensure task diversity. We also provide a set of Indonesian pre-trained models\n(IndoBERT) trained from a large and clean Indonesian dataset Indo4B collected\nfrom publicly available sources such as social media texts, blogs, news, and\nwebsites. We release baseline models for all twelve tasks, as well as the\nframework for benchmark evaluation, and thus it enables everyone to benchmark\ntheir system performances.", "published": "2020-09-11 12:21:41", "link": "http://arxiv.org/abs/2009.05387v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Relations and Deep Learning", "abstract": "The second edition of \"Semantic Relations Between Nominals\" by Vivi Nastase,\nStan Szpakowicz, Preslav Nakov and Diarmuid \\'O S\\'eaghdha has been published\nin April 2021 by Morgan & Claypool\n(www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?products_id=1627).\nA new Chapter 5 of the book, by Vivi Nastase and Stan Szpakowicz, discusses\nrelation classification/extraction in the deep-learning paradigm which arose\nafter the first edition appeared. This is Chapter 5, made public by the kind\npermission of Morgan & Claypool.", "published": "2020-09-11 13:21:28", "link": "http://arxiv.org/abs/2009.05426v4", "categories": ["cs.CL", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Robust Neural Machine Translation: Modeling Orthographic and\n  Interpunctual Variation", "abstract": "Neural machine translation systems typically are trained on curated corpora\nand break when faced with non-standard orthography or punctuation. Resilience\nto spelling mistakes and typos, however, is crucial as machine translation\nsystems are used to translate texts of informal origins, such as chat\nconversations, social media posts and web pages. We propose a simple generative\nnoise model to generate adversarial examples of ten different types. We use\nthese to augment machine translation systems' training data and show that, when\ntested on noisy data, systems trained using adversarial examples perform almost\nas well as when translating clean data, while baseline systems' performance\ndrops by 2-3 BLEU points. To measure the robustness and noise invariance of\nmachine translation systems' outputs, we use the average translation edit rate\nbetween the translation of the original sentence and its noised variants. Using\nthis measure, we show that systems trained on adversarial examples on average\nyield 50% consistency improvements when compared to baselines trained on clean\ndata.", "published": "2020-09-11 14:12:54", "link": "http://arxiv.org/abs/2009.05460v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Solving Arithmetic Word Problems by Scoring Equations with Recursive\n  Neural Networks", "abstract": "Solving arithmetic word problems is a cornerstone task in assessing language\nunderstanding and reasoning capabilities in NLP systems. Recent works use\nautomatic extraction and ranking of candidate solution equations providing the\nanswer to arithmetic word problems. In this work, we explore novel approaches\nto score such candidate solution equations using tree-structured recursive\nneural network (Tree-RNN) configurations. The advantage of this Tree-RNN\napproach over using more established sequential representations, is that it can\nnaturally capture the structure of the equations. Our proposed method consists\nof transforming the mathematical expression of the equation into an expression\ntree. Further, we encode this tree into a Tree-RNN by using different Tree-LSTM\narchitectures. Experimental results show that our proposed method (i) improves\noverall performance with more than 3% accuracy points compared to previous\nstate-of-the-art, and with over 15% points on a subset of problems that require\nmore complex reasoning, and (ii) outperforms sequential LSTMs by 4% accuracy\npoints on such more complex problems.", "published": "2020-09-11 19:48:42", "link": "http://arxiv.org/abs/2009.05639v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparison of LSTM and BERT for Small Corpus", "abstract": "Recent advancements in the NLP field showed that transfer learning helps with\nachieving state-of-the-art results for new tasks by tuning pre-trained models\ninstead of starting from scratch. Transformers have made a significant\nimprovement in creating new state-of-the-art results for many NLP tasks\nincluding but not limited to text classification, text generation, and sequence\nlabeling. Most of these success stories were based on large datasets. In this\npaper we focus on a real-life scenario that scientists in academia and industry\nface frequently: given a small dataset, can we use a large pre-trained model\nlike BERT and get better results than simple models? To answer this question,\nwe use a small dataset for intent classification collected for building\nchatbots and compare the performance of a simple bidirectional LSTM model with\na pre-trained BERT model. Our experimental results show that bidirectional LSTM\nmodels can achieve significantly higher results than a BERT model for a small\ndataset and these simple models get trained in much less time than tuning the\npre-trained counterparts. We conclude that the performance of a model is\ndependent on the task and the data, and therefore before making a model choice,\nthese factors should be taken into consideration instead of directly choosing\nthe most popular model.", "published": "2020-09-11 14:01:14", "link": "http://arxiv.org/abs/2009.05451v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WOLI at SemEval-2020 Task 12: Arabic Offensive Language Identification\n  on Different Twitter Datasets", "abstract": "Communicating through social platforms has become one of the principal means\nof personal communications and interactions. Unfortunately, healthy\ncommunication is often interfered by offensive language that can have damaging\neffects on the users. A key to fight offensive language on social media is the\nexistence of an automatic offensive language detection system. This paper\npresents the results and the main findings of SemEval-2020, Task 12 OffensEval\nSub-task A Zampieri et al. (2020), on Identifying and categorising Offensive\nLanguage in Social Media. The task was based on the Arabic OffensEval dataset\nMubarak et al. (2020). In this paper, we describe the system submitted by\nWideBot AI Lab for the shared task which ranked 10th out of 52 participants\nwith Macro-F1 86.9% on the golden dataset under CodaLab username\n\"yasserotiefy\". We experimented with various models and the best model is a\nlinear SVM in which we use a combination of both character and word n-grams. We\nalso introduced a neural network approach that enhanced the predictive ability\nof our system that includes CNN, highway network, Bi-LSTM, and attention\nlayers.", "published": "2020-09-11 14:10:03", "link": "http://arxiv.org/abs/2009.05456v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Systematic Generalization on gSCAN with Language Conditioned Embedding", "abstract": "Systematic Generalization refers to a learning algorithm's ability to\nextrapolate learned behavior to unseen situations that are distinct but\nsemantically similar to its training data. As shown in recent work,\nstate-of-the-art deep learning models fail dramatically even on tasks for which\nthey are designed when the test set is systematically different from the\ntraining data. We hypothesize that explicitly modeling the relations between\nobjects in their contexts while learning their representations will help\nachieve systematic generalization. Therefore, we propose a novel method that\nlearns objects' contextualized embeddings with dynamic message passing\nconditioned on the input natural language and end-to-end trainable with other\ndownstream deep learning modules. To our knowledge, this model is the first one\nthat significantly outperforms the provided baseline and reaches\nstate-of-the-art performance on grounded-SCAN (gSCAN), a grounded natural\nlanguage navigation dataset designed to require systematic generalization in\nits test splits.", "published": "2020-09-11 17:35:05", "link": "http://arxiv.org/abs/2009.05552v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards an Atlas of Cultural Commonsense for Machine Reasoning", "abstract": "Existing commonsense reasoning datasets for AI and NLP tasks fail to address\nan important aspect of human life: cultural differences. We introduce an\napproach that extends prior work on crowdsourcing commonsense knowledge by\nincorporating differences in knowledge that are attributable to cultural or\nnational groups. We demonstrate the technique by collecting commonsense\nknowledge that surrounds six fairly universal rituals -- birth, coming-of-age,\nmarriage, funerals, new year, and birthdays -- across two national groups: the\nUnited States and India. Our study expands the different types of relationships\nidentified by existing work in the field of commonsense reasoning for\ncommonplace events, and uses these new types to gather information that\ndistinguish the identity of the groups providing the knowledge. It also moves\nus a step closer towards building a machine that doesn't assume a rigid\nframework of universal (and likely Western-biased) commonsense knowledge, but\nrather has the ability to reason in a contextually and culturally sensitive\nway. Our hope is that cultural knowledge of this sort will lead to more\nhuman-like performance in NLP tasks such as question answering (QA) and text\nunderstanding and generation.", "published": "2020-09-11 21:24:33", "link": "http://arxiv.org/abs/2009.05664v3", "categories": ["cs.AI", "cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.AI"}
{"title": "Coreference Resolution System for Indonesian Text with Mention Pair\n  Method and Singleton Exclusion using Convolutional Neural Network", "abstract": "Neural network has shown promising performance on coreference resolution\nsystems that uses mention pair method. With deep neural network, it can learn\nhidden and deep relations between two mentions. However, there is no work on\ncoreference resolution for Indonesian text that uses this learning technique.\nThe state-of-the-art system for Indonesian text only states the use of lexical\nand syntactic features can improve the existing coreference resolution system.\nIn this paper, we propose a new coreference resolution system for Indonesian\ntext with mention pair method that uses deep neural network to learn the\nrelations of the two mentions. In addition to lexical and syntactic features,\nin order to learn the representation of the mentions words and context, we use\nword embeddings and feed them to Convolutional Neural Network (CNN).\nFurthermore, we do singleton exclusion using singleton classifier component to\nprevent singleton mentions entering any entity clusters at the end. Achieving\n67.37% without singleton exclusion, 63.27% with trained singleton classifier,\nand 75.95% with gold singleton classifier on CoNLL average F1 score, our\nproposed system outperforms the state-of-the-art system.", "published": "2020-09-11 22:21:19", "link": "http://arxiv.org/abs/2009.05675v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian\n  Named Entity Tagger", "abstract": "Researches on Indonesian named entity (NE) tagger have been conducted since\nyears ago. However, most did not use deep learning and instead employed\ntraditional machine learning algorithms such as association rule, support\nvector machine, random forest, na\\\"ive bayes, etc. In those researches, word\nlists as gazetteers or clue words were provided to enhance the accuracy. Here,\nwe attempt to employ deep learning in our Indonesian NE tagger. We use long\nshort-term memory (LSTM) as the topology since it is the state-of-the-art of NE\ntagger. By using LSTM, we do not need a word list in order to enhance the\naccuracy. Basically, there are two main things that we investigate. The first\nis the output layer of the network: Softmax vs conditional random field (CRF).\nThe second is the usage of part of speech (POS) tag embedding input layer.\nUsing 8400 sentences as the training data and 97 sentences as the evaluation\ndata, we find that using POS tag embedding as additional input improves the\nperformance of our Indonesian NE tagger. As for the comparison between Softmax\nand CRF, we find that both architectures have a weakness in classifying an NE\ntag.", "published": "2020-09-11 23:54:31", "link": "http://arxiv.org/abs/2009.05687v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "RECOApy: Data recording, pre-processing and phonetic transcription for\n  end-to-end speech-based applications", "abstract": "Deep learning enables the development of efficient end-to-end speech\nprocessing applications while bypassing the need for expert linguistic and\nsignal processing features. Yet, recent studies show that good quality speech\nresources and phonetic transcription of the training data can enhance the\nresults of these applications. In this paper, the RECOApy tool is introduced.\nRECOApy streamlines the steps of data recording and pre-processing required in\nend-to-end speech-based applications. The tool implements an easy-to-use\ninterface for prompted speech recording, spectrogram and waveform analysis,\nutterance-level normalisation and silence trimming, as well grapheme-to-phoneme\nconversion of the prompts in eight languages: Czech, English, French, German,\nItalian, Polish, Romanian and Spanish.\n  The grapheme-to-phoneme (G2P) converters are deep neural network (DNN) based\narchitectures trained on lexicons extracted from the Wiktionary online\ncollaborative resource. With the different degree of orthographic transparency,\nas well as the varying amount of phonetic entries across the languages, the\nDNN's hyperparameters are optimised with an evolution strategy. The phoneme and\nword error rates of the resulting G2P converters are presented and discussed.\nThe tool, the processed phonetic lexicons and trained G2P models are made\nfreely available.", "published": "2020-09-11 15:26:55", "link": "http://arxiv.org/abs/2009.05493v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Narratives and Needs: Analyzing Experiences of Cyclone Amphan Using\n  Twitter Discourse", "abstract": "People often turn to social media to comment upon and share information about\nmajor global events. Accordingly, social media is receiving increasing\nattention as a rich data source for understanding people's social, political\nand economic experiences of extreme weather events. In this paper, we\ncontribute two novel methodologies that leverage Twitter discourse to\ncharacterize narratives and identify unmet needs in response to Cyclone Amphan,\nwhich affected 18 million people in May 2020.", "published": "2020-09-11 17:49:05", "link": "http://arxiv.org/abs/2009.05560v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "UPB at SemEval-2020 Task 6: Pretrained Language Models for Definition\n  Extraction", "abstract": "This work presents our contribution in the context of the 6th task of\nSemEval-2020: Extracting Definitions from Free Text in Textbooks (DeftEval).\nThis competition consists of three subtasks with different levels of\ngranularity: (1) classification of sentences as definitional or\nnon-definitional,(2) labeling of definitional sentences, and (3) relation\nclassification. We use various pretrained language models (i.e., BERT, XLNet,\nRoBERTa, SciBERT, and ALBERT) to solve each of the three subtasks of the\ncompetition. Specifically, for each language model variant, we experiment by\nboth freezing its weights and fine-tuning them. We also explore a multi-task\narchitecture that was trained to jointly predict the outputs for the second and\nthe third subtasks. Our best performing model evaluated on the DeftEval dataset\nobtains the 32nd place for the first subtask and the 37th place for the second\nsubtask. The code is available for further research at:\nhttps://github.com/avramandrei/DeftEval.", "published": "2020-09-11 18:36:22", "link": "http://arxiv.org/abs/2009.05603v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unit Test Case Generation with Transformers and Focal Context", "abstract": "Automated unit test case generation tools facilitate test-driven development\nand support developers by suggesting tests intended to identify flaws in their\ncode. Existing approaches are usually guided by the test coverage criteria,\ngenerating synthetic test cases that are often difficult for developers to read\nor understand. In this paper we propose AthenaTest, an approach that aims to\ngenerate unit test cases by learning from real-world focal methods and\ndeveloper-written testcases. We formulate unit test case generation as a\nsequence-to-sequence learning task, adopting a two-step training procedure\nconsisting of denoising pretraining on a large unsupervised Java corpus, and\nsupervised finetuning for a downstream translation task of generating unit\ntests. We investigate the impact of natural language and source code\npretraining, as well as the focal context information surrounding the focal\nmethod. Both techniques provide improvements in terms of validation loss, with\npretraining yielding 25% relative improvement and focal context providing\nadditional 11.1% improvement. We also introduce Methods2Test, the largest\npublicly available supervised parallel corpus of unit test case methods and\ncorresponding focal methods in Java, which comprises 780K test cases mined from\n91K open-source repositories from GitHub. We evaluate AthenaTest on five\ndefects4j projects, generating 25K passing test cases covering 43.7% of the\nfocal methods with only 30 attempts. We execute the test cases, collect test\ncoverage information, and compare them with test cases generated by EvoSuite\nand GPT-3, finding that our approach outperforms GPT-3 and has comparable\ncoverage w.r.t. EvoSuite. Finally, we survey professional developers on their\npreference in terms of readability, understandability, and testing\neffectiveness of the generated tests, showing overwhelmingly preference towards\nAthenaTest.", "published": "2020-09-11 18:57:36", "link": "http://arxiv.org/abs/2009.05617v2", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Text-Independent Speaker Verification with Dual Attention Network", "abstract": "This paper presents a novel design of attention model for text-independent\nspeaker verification. The model takes a pair of input utterances and generates\nan utterance-level embedding to represent speaker-specific characteristics in\neach utterance. The input utterances are expected to have highly similar\nembeddings if they are from the same speaker. The proposed attention model\nconsists of a self-attention module and a mutual attention module, which\njointly contributes to the generation of the utterance-level embedding. The\nself-attention weights are computed from the utterance itself while the\nmutual-attention weights are computed with the involvement of the other\nutterance in the input pairs. As a result, each utterance is represented by a\nself-attention weighted embedding and a mutual-attention weighted embedding.\nThe similarity between the embeddings is measured by a cosine distance score\nand a binary classifier output score. The whole model, named Dual Attention\nNetwork, is trained end-to-end on Voxceleb database. The evaluation results on\nVoxceleb 1 test set show that the Dual Attention Network significantly\noutperforms the baseline systems. The best result yields an equal error rate of\n1:6%.", "published": "2020-09-11 15:07:13", "link": "http://arxiv.org/abs/2009.05485v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "On Multitask Loss Function for Audio Event Detection and Localization", "abstract": "Audio event localization and detection (SELD) have been commonly tackled\nusing multitask models. Such a model usually consists of a multi-label event\nclassification branch with sigmoid cross-entropy loss for event activity\ndetection and a regression branch with mean squared error loss for\ndirection-of-arrival estimation. In this work, we propose a multitask\nregression model, in which both (multi-label) event detection and localization\nare formulated as regression problems and use the mean squared error loss\nhomogeneously for model training. We show that the common combination of\nheterogeneous loss functions causes the network to underfit the data whereas\nthe homogeneous mean squared error loss leads to better convergence and\nperformance. Experiments on the development and validation sets of the DCASE\n2020 SELD task demonstrate that the proposed system also outperforms the DCASE\n2020 SELD baseline across all the detection and localization metrics, reducing\nthe overall SELD error (the combined metric) by approximately 10% absolute.", "published": "2020-09-11 16:59:03", "link": "http://arxiv.org/abs/2009.05527v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "SONYC-UST-V2: An Urban Sound Tagging Dataset with Spatiotemporal Context", "abstract": "We present SONYC-UST-V2, a dataset for urban sound tagging with\nspatiotemporal information. This dataset is aimed for the development and\nevaluation of machine listening systems for real-world urban noise monitoring.\nWhile datasets of urban recordings are available, this dataset provides the\nopportunity to investigate how spatiotemporal metadata can aid in the\nprediction of urban sound tags. SONYC-UST-V2 consists of 18510 audio recordings\nfrom the \"Sounds of New York City\" (SONYC) acoustic sensor network, including\nthe timestamp of audio acquisition and location of the sensor. The dataset\ncontains annotations by volunteers from the Zooniverse citizen science\nplatform, as well as a two-stage verification with our team. In this article,\nwe describe our data collection procedure and propose evaluation metrics for\nmultilabel classification of urban sound tags. We report the results of a\nsimple baseline model that exploits spatiotemporal information.", "published": "2020-09-11 01:19:12", "link": "http://arxiv.org/abs/2009.05188v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Generalized Minimal Distortion Principle for Blind Source Separation", "abstract": "We revisit the source image estimation problem from blind source separation\n(BSS). We generalize the traditional minimum distortion principle to maximum\nlikelihood estimation with a model for the residual spectrograms. Because\nresidual spectrograms typically contain other sources, we propose to use a\nmixed-norm model that lets us finely tune sparsity in time and frequency. We\npropose to carry out the minimization of the mixed-norm via\nmajorization-minimization optimization, leading to an iteratively reweighted\nleast-squares algorithm. The algorithm balances well efficiency and ease of\nimplementation. We assess the performance of the proposed method as applied to\ntwo well-known determined BSS and one joint BSS-dereverberation algorithms. We\nfind out that it is possible to tune the parameters to improve separation by up\nto 2 dB, with no increase in distortion, and at little computational cost. The\nmethod thus provides a cheap and easy way to boost the performance of blind\nsource separation.", "published": "2020-09-11 08:43:03", "link": "http://arxiv.org/abs/2009.05288v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
