{"title": "On the importance of normative data in speech-based assessment", "abstract": "Data sets for identifying Alzheimer's disease (AD) are often relatively\nsparse, which limits their ability to train generalizable models. Here, we\naugment such a data set, DementiaBank, with each of two normative data sets,\nthe Wisconsin Longitudinal Study and Talk2Me, each of which employs a\nspeech-based picture-description assessment. Through minority class\noversampling with ADASYN, we outperform state-of-the-art results in binary\nclassification of people with and without AD in DementiaBank. This work\nhighlights the effectiveness of combining sparse and difficult-to-acquire\npatient data with relatively large and easily accessible normative datasets.", "published": "2017-11-30 20:36:50", "link": "http://arxiv.org/abs/1712.00069v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Response Generation with Dynamic Vocabularies", "abstract": "We study response generation for open domain conversation in chatbots.\nExisting methods assume that words in responses are generated from an identical\nvocabulary regardless of their inputs, which not only makes them vulnerable to\ngeneric patterns and irrelevant noise, but also causes a high cost in decoding.\nWe propose a dynamic vocabulary sequence-to-sequence (DVS2S) model which allows\neach input to possess their own vocabulary in decoding. In training, vocabulary\nconstruction and response generation are jointly learned by maximizing a lower\nbound of the true objective with a Monte Carlo sampling method. In inference,\nthe model dynamically allocates a small vocabulary for an input with the word\nprediction model, and conducts decoding only with the small vocabulary. Because\nof the dynamic vocabulary mechanism, DVS2S eludes many generic patterns and\nirrelevant words in generation, and enjoys efficient decoding at the same time.\nExperimental results on both automatic metrics and human annotations show that\nDVS2S can significantly outperform state-of-the-art methods in terms of\nresponse quality, but only requires 60% decoding time compared to the most\nefficient baseline.", "published": "2017-11-30 02:06:47", "link": "http://arxiv.org/abs/1711.11191v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Coherence for Neural Machine Translation with Dynamic and Topic\n  Caches", "abstract": "Sentences in a well-formed text are connected to each other via various links\nto form the cohesive structure of the text. Current neural machine translation\n(NMT) systems translate a text in a conventional sentence-by-sentence fashion,\nignoring such cross-sentence links and dependencies. This may lead to generate\nan incoherent target text for a coherent source text. In order to handle this\nissue, we propose a cache-based approach to modeling coherence for neural\nmachine translation by capturing contextual information either from recently\ntranslated sentences or the entire document. Particularly, we explore two types\nof caches: a dynamic cache, which stores words from the best translation\nhypotheses of preceding sentences, and a topic cache, which maintains a set of\ntarget-side topical words that are semantically related to the document to be\ntranslated. On this basis, we build a new layer to score target words in these\ntwo caches with a cache-based neural model. Here the estimated probabilities\nfrom the cache-based neural model are combined with NMT probabilities into the\nfinal word prediction probabilities via a gating mechanism. Finally, the\nproposed cache-based neural model is trained jointly with NMT system in an\nend-to-end manner. Experiments and analysis presented in this paper demonstrate\nthat the proposed cache-based model achieves substantial improvements over\nseveral state-of-the-art SMT and NMT baselines.", "published": "2017-11-30 04:30:53", "link": "http://arxiv.org/abs/1711.11221v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Domain Adversarial Learning for Slot Filling in Spoken Language\n  Understanding", "abstract": "The goal of this paper is to learn cross-domain representations for slot\nfilling task in spoken language understanding (SLU). Most of the recently\npublished SLU models are domain-specific ones that work on individual task\ndomains. Annotating data for each individual task domain is both financially\ncostly and non-scalable. In this work, we propose an adversarial training\nmethod in learning common features and representations that can be shared\nacross multiple domains. Model that produces such shared representations can be\ncombined with models trained on individual domain SLU data to reduce the amount\nof training samples required for developing a new domain. In our experiments\nusing data sets from multiple domains, we show that adversarial training helps\nin learning better domain-general SLU models, leading to improved slot filling\nF1 scores. We further show that applying adversarial learning on domain-general\nmodel also helps in achieving higher slot filling performance when the model is\njointly optimized with domain-specific models.", "published": "2017-11-30 10:37:56", "link": "http://arxiv.org/abs/1711.11310v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical and Derivational Meaning in Vector-Based Models of\n  Relativisation", "abstract": "Sadrzadeh et al (2013) present a compositional distributional analysis of\nrelative clauses in English in terms of the Frobenius algebraic structure of\nfinite dimensional vector spaces. The analysis relies on distinct type\nassignments and lexical recipes for subject vs object relativisation. The\nsituation for Dutch is different: because of the verb final nature of Dutch,\nrelative clauses are ambiguous between a subject vs object relativisation\nreading. Using an extended version of Lambek calculus, we present a\ncompositional distributional framework that accounts for this derivational\nambiguity, and that allows us to give a single meaning recipe for the relative\npronoun reconciling the Frobenius semantics with the demands of Dutch\nderivational syntax.", "published": "2017-11-30 17:02:52", "link": "http://arxiv.org/abs/1711.11513v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph Centrality Measures for Boosting Popularity-Based Entity Linking", "abstract": "Many Entity Linking systems use collective graph-based methods to\ndisambiguate the entity mentions within a document. Most of them have focused\non graph construction and initial weighting of the candidate entities, less\nattention has been devoted to compare the graph ranking algorithms. In this\nwork, we focus on the graph-based ranking algorithms, therefore we propose to\napply five centrality measures: Degree, HITS, PageRank, Betweenness and\nCloseness. A disambiguation graph of candidate entities is constructed for each\ndocument using the popularity method, then centrality measures are applied to\nchoose the most relevant candidate to boost the results of entity popularity\nmethod. We investigate the effectiveness of each centrality measure on the\nperformance across different domains and datasets. Our experiments show that a\nsimple and fast centrality measure such as Degree centrality can outperform\nother more time-consuming measures.", "published": "2017-11-30 19:39:23", "link": "http://arxiv.org/abs/1712.00044v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Learning to Learn from Weak Supervision by Full Supervision", "abstract": "In this paper, we propose a method for training neural networks when we have\na large set of data with weak labels and a small amount of data with true\nlabels. In our proposed model, we train two neural networks: a target network,\nthe learner and a confidence network, the meta-learner. The target network is\noptimized to perform a given task and is trained using a large set of unlabeled\ndata that are weakly annotated. We propose to control the magnitude of the\ngradient updates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model.", "published": "2017-11-30 13:32:45", "link": "http://arxiv.org/abs/1711.11383v1", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Uncertainty Estimates for Efficient Neural Network-based Dialogue Policy\n  Optimisation", "abstract": "In statistical dialogue management, the dialogue manager learns a policy that\nmaps a belief state to an action for the system to perform. Efficient\nexploration is key to successful policy optimisation. Current deep\nreinforcement learning methods are very promising but rely on epsilon-greedy\nexploration, thus subjecting the user to a random choice of action during\nlearning. Alternative approaches such as Gaussian Process SARSA (GPSARSA)\nestimate uncertainties and are sample efficient, leading to better user\nexperience, but on the expense of a greater computational complexity. This\npaper examines approaches to extract uncertainty estimates from deep Q-networks\n(DQN) in the context of dialogue management. We perform an extensive benchmark\nof deep Bayesian methods to extract uncertainty estimates, namely\nBayes-By-Backprop, dropout, its concrete variation, bootstrapped ensemble and\nalpha-divergences, combining it with DQN algorithm.", "published": "2017-11-30 16:09:02", "link": "http://arxiv.org/abs/1711.11486v1", "categories": ["stat.ML", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "stat.ML"}
{"title": "Calculating Semantic Similarity between Academic Articles using Topic\n  Event and Ontology", "abstract": "Determining semantic similarity between academic documents is crucial to many\ntasks such as plagiarism detection, automatic technical survey and semantic\nsearch. Current studies mostly focus on semantic similarity between concepts,\nsentences and short text fragments. However, document-level semantic matching\nis still based on statistical information in surface level, neglecting article\nstructures and global semantic meanings, which may cause the deviation in\ndocument understanding. In this paper, we focus on the document-level semantic\nsimilarity issue for academic literatures with a novel method. We represent\nacademic articles with topic events that utilize multiple information profiles,\nsuch as research purposes, methodologies and domains to integrally describe the\nresearch work, and calculate the similarity between topic events based on the\ndomain ontology to acquire the semantic similarity between articles.\nExperiments show that our approach achieves significant performance compared to\nstate-of-the-art methods.", "published": "2017-11-30 16:58:46", "link": "http://arxiv.org/abs/1711.11508v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Embodied Question Answering", "abstract": "We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where\nan agent is spawned at a random location in a 3D environment and asked a\nquestion (\"What color is the car?\"). In order to answer, the agent must first\nintelligently navigate to explore the environment, gather information through\nfirst-person (egocentric) vision, and then answer the question (\"orange\").\n  This challenging task requires a range of AI skills -- active perception,\nlanguage understanding, goal-driven navigation, commonsense reasoning, and\ngrounding of language into actions. In this work, we develop the environments,\nend-to-end-trained reinforcement learning agents, and evaluation protocols for\nEmbodiedQA.", "published": "2017-11-30 18:06:47", "link": "http://arxiv.org/abs/1711.11543v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Enabling Embodied Analogies in Intelligent Music Systems", "abstract": "The present methodology is aimed at cross-modal machine learning and uses\nmultidisciplinary tools and methods drawn from a broad range of areas and\ndisciplines, including music, systematic musicology, dance, motion capture,\nhuman-computer interaction, computational linguistics and audio signal\nprocessing. Main tasks include: (1) adapting wisdom-of-the-crowd approaches to\nembodiment in music and dance performance to create a dataset of music and\nmusic lyrics that covers a variety of emotions, (2) applying\naudio/language-informed machine learning techniques to that dataset to identify\nautomatically the emotional content of the music and the lyrics, and (3)\nintegrating motion capture data from a Vicon system and dancers performing on\nthat music.", "published": "2017-11-30 08:27:08", "link": "http://arxiv.org/abs/1712.00334v1", "categories": ["cs.HC", "cs.CL", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.HC"}
{"title": "Raga Identification using Repetitive Note Patterns from prescriptive\n  notations of Carnatic Music", "abstract": "Carnatic music, a form of Indian Art Music, has relied on an oral tradition\nfor transferring knowledge across several generations. Over the last two\nhundred years, the use of prescriptive notations has been adopted for learning,\nsight-playing and sight-singing. Prescriptive notations offer generic\nguidelines for a raga rendition and do not include information about the\nornamentations or the gamakas, which are considered to be critical for\ncharacterizing a raga. In this paper, we show that prescriptive notations\ncontain raga attributes and can reliably identify a raga of Carnatic music from\nits octave-folded prescriptive notations. We restrict the notations to 7 notes\nand suppress the finer note position information. A dictionary based approach\ncaptures the statistics of repetitive note patterns within a raga notation. The\nproposed stochastic models of repetitive note patterns (or SMRNP in short)\nobtained from raga notations of known compositions, outperforms the state of\nthe art melody based raga identification technique on an equivalent melodic\ndata corresponding to the same compositions. This in turn shows that for\nCarnatic music, the note transitions and movements have a greater role in\ndefining the raga structure than the exact note positions.", "published": "2017-11-30 12:49:40", "link": "http://arxiv.org/abs/1711.11357v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A modeling and algorithmic framework for (non)social (co)sparse audio\n  restoration", "abstract": "We propose a unified modeling and algorithmic framework for audio restoration\nproblem. It encompasses analysis sparse priors as well as more classical\nsynthesis sparse priors, and regular sparsity as well as various forms of\nstructured sparsity embodied by shrinkage operators (such as social shrinkage).\nThe versatility of the framework is illustrated on two restoration scenarios:\ndenoising, and declipping. Extensive experimental results on these scenarios\nhighlight both the speedups of 20% or even more offered by the analysis sparse\nprior, and the substantial declipping quality that is achievable with both the\nsocial and the plain flavor. While both flavors overall exhibit similar\nperformance, their detailed comparison displays distinct trends depending\nwhether declipping or denoising is considered.", "published": "2017-11-30 07:38:18", "link": "http://arxiv.org/abs/1711.11259v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Parallel-Data-Free Voice Conversion Using Cycle-Consistent Adversarial\n  Networks", "abstract": "We propose a parallel-data-free voice-conversion (VC) method that can learn a\nmapping from source to target speech without relying on parallel data. The\nproposed method is general purpose, high quality, and parallel-data free and\nworks without any extra data, modules, or alignment procedure. It also avoids\nover-smoothing, which occurs in many conventional statistical model-based VC\nmethods. Our method, called CycleGAN-VC, uses a cycle-consistent adversarial\nnetwork (CycleGAN) with gated convolutional neural networks (CNNs) and an\nidentity-mapping loss. A CycleGAN learns forward and inverse mappings\nsimultaneously using adversarial and cycle-consistency losses. This makes it\npossible to find an optimal pseudo pair from unpaired data. Furthermore, the\nadversarial loss contributes to reducing over-smoothing of the converted\nfeature sequence. We configure a CycleGAN with gated CNNs and train it with an\nidentity-mapping loss. This allows the mapping function to capture sequential\nand hierarchical structures while preserving linguistic information. We\nevaluated our method on a parallel-data-free VC task. An objective evaluation\nshowed that the converted feature sequence was near natural in terms of global\nvariance and modulation spectra. A subjective evaluation showed that the\nquality of the converted speech was comparable to that obtained with a Gaussian\nmixture model-based method under advantageous conditions with parallel and\ntwice the amount of data.", "published": "2017-11-30 09:57:19", "link": "http://arxiv.org/abs/1711.11293v2", "categories": ["stat.ML", "cs.SD", "eess.AS"], "primary_category": "stat.ML"}
{"title": "Deep Neural Networks for Multiple Speaker Detection and Localization", "abstract": "We propose to use neural networks for simultaneous detection and localization\nof multiple sound sources in human-robot interaction. In contrast to\nconventional signal processing techniques, neural network-based sound source\nlocalization methods require fewer strong assumptions about the environment.\nPrevious neural network-based methods have been focusing on localizing a single\nsound source, which do not extend to multiple sources in terms of detection and\nlocalization. In this paper, we thus propose a likelihood-based encoding of the\nnetwork output, which naturally allows the detection of an arbitrary number of\nsources. In addition, we investigate the use of sub-band cross-correlation\ninformation as features for better localization in sound mixtures, as well as\nthree different network architectures based on different motivations.\nExperiments on real data recorded from a robot show that our proposed methods\nsignificantly outperform the popular spatial spectrum-based approaches.", "published": "2017-11-30 18:35:22", "link": "http://arxiv.org/abs/1711.11565v3", "categories": ["cs.SD", "cs.AI", "cs.MM", "cs.RO", "eess.AS"], "primary_category": "cs.SD"}
