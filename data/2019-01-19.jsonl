{"title": "MOROCO: The Moldavian and Romanian Dialectal Corpus", "abstract": "In this work, we introduce the MOldavian and ROmanian Dialectal COrpus\n(MOROCO), which is freely available for download at\nhttps://github.com/butnaruandrei/MOROCO. The corpus contains 33564 samples of\ntext (with over 10 million tokens) collected from the news domain. The samples\nbelong to one of the following six topics: culture, finance, politics, science,\nsports and tech. The data set is divided into 21719 samples for training, 5921\nsamples for validation and another 5924 samples for testing. For each sample,\nwe provide corresponding dialectal and category labels. This allows us to\nperform empirical studies on several classification tasks such as (i) binary\ndiscrimination of Moldavian versus Romanian text samples, (ii) intra-dialect\nmulti-class categorization by topic and (iii) cross-dialect multi-class\ncategorization by topic. We perform experiments using a shallow approach based\non string kernels, as well as a novel deep approach based on character-level\nconvolutional neural networks containing Squeeze-and-Excitation blocks. We also\npresent and analyze the most discriminative features of our best performing\nmodel, before and after named entity removal.", "published": "2019-01-19 15:40:08", "link": "http://arxiv.org/abs/1901.06543v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adaptive Artificial Intelligent Q&A Platform", "abstract": "The paper presents an approach to build a question and answer system that is\ncapable of processing the information in a large dataset and allows the user to\ngain knowledge from this dataset by asking questions in natural language form.\nKey content of this research covers four dimensions which are; Corpus\nPreprocessing, Question Preprocessing, Deep Neural Network for Answer\nExtraction and Answer Generation. The system is capable of understanding the\nquestion, responds to the user's query in natural language form as well. The\ngoal is to make the user feel as if they were interacting with a person than a\nmachine.", "published": "2019-01-19 17:40:08", "link": "http://arxiv.org/abs/1902.02162v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Universal End-to-End Affect Recognition from Multilingual Speech\n  by ConvNets", "abstract": "We propose an end-to-end affect recognition approach using a Convolutional\nNeural Network (CNN) that handles multiple languages, with applications to\nemotion and personality recognition from speech. We lay the foundation of a\nuniversal model that is trained on multiple languages at once. As affect is\nshared across all languages, we are able to leverage shared information between\nlanguages and improve the overall performance for each one. We obtained an\naverage improvement of 12.8% on emotion and 10.1% on personality when compared\nwith the same model trained on each language only. It is end-to-end because we\ndirectly take narrow-band raw waveforms as input. This allows us to accept as\ninput audio recorded from any source and to avoid the overhead and information\nloss of feature extraction. It outperforms a similar CNN using spectrograms as\ninput by 12.8% for emotion and 6.3% for personality, based on F-scores.\nAnalysis of the network parameters and layers activation shows that the network\nlearns and extracts significant features in the first layer, in particular\npitch, energy and contour variations. Subsequent convolutional layers instead\ncapture language-specific representations through the analysis of\nsupra-segmental features. Our model represents an important step for the\ndevelopment of a fully universal affect recognizer, able to recognize\nadditional descriptors, such as stress, and for the future implementation into\naffective interactive systems.", "published": "2019-01-19 09:11:03", "link": "http://arxiv.org/abs/1901.06486v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Evaluating Text-to-Image Matching using Binary Image Selection (BISON)", "abstract": "Providing systems the ability to relate linguistic and visual content is one\nof the hallmarks of computer vision. Tasks such as text-based image retrieval\nand image captioning were designed to test this ability but come with\nevaluation measures that have a high variance or are difficult to interpret. We\nstudy an alternative task for systems that match text and images: given a text\nquery, the system is asked to select the image that best matches the query from\na pair of semantically similar images. The system's accuracy on this Binary\nImage SelectiON (BISON) task is interpretable, eliminates the reliability\nproblems of retrieval evaluations, and focuses on the system's ability to\nunderstand fine-grained visual structure. We gather a BISON dataset that\ncomplements the COCO dataset and use it to evaluate modern text-based image\nretrieval and image captioning systems. Our results provide novel insights into\nthe performance of these systems. The COCO-BISON dataset and corresponding\nevaluation code are publicly available from \\url{http://hexianghu.com/bison/}.", "published": "2019-01-19 22:12:01", "link": "http://arxiv.org/abs/1901.06595v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
