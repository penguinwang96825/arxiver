{"title": "Sentence-level dialects identification in the greater China region", "abstract": "Identifying the different varieties of the same language is more challenging\nthan unrelated languages identification. In this paper, we propose an approach\nto discriminate language varieties or dialects of Mandarin Chinese for the\nMainland China, Hong Kong, Taiwan, Macao, Malaysia and Singapore, a.k.a., the\nGreater China Region (GCR). When applied to the dialects identification of the\nGCR, we find that the commonly used character-level or word-level uni-gram\nfeature is not very efficient since there exist several specific problems such\nas the ambiguity and context-dependent characteristic of words in the dialects\nof the GCR. To overcome these challenges, we use not only the general features\nlike character-level n-gram, but also many new word-level features, including\nPMI-based and word alignment-based features. A series of evaluation results on\nboth the news and open-domain dataset from Wikipedia show the effectiveness of\nthe proposed approach.", "published": "2017-01-08 03:13:37", "link": "http://arxiv.org/abs/1701.01908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-level Representations for Fine-Grained Typing of Knowledge Base\n  Entities", "abstract": "Entities are essential elements of natural language. In this paper, we\npresent methods for learning multi-level representations of entities on three\ncomplementary levels: character (character patterns in entity names extracted,\ne.g., by neural networks), word (embeddings of words in entity names) and\nentity (entity embeddings). We investigate state-of-the-art learning methods on\neach level and find large differences, e.g., for deep learning models,\ntraditional ngram features and the subword model of fasttext (Bojanowski et\nal., 2016) on the character level; for word2vec (Mikolov et al., 2013) on the\nword level; and for the order-aware model wang2vec (Ling et al., 2015a) on the\nentity level. We confirm experimentally that each level of representation\ncontributes complementary information and a joint representation of all three\nlevels improves the existing embedding based baseline for fine-grained entity\ntyping by a large margin. Additionally, we show that adding information from\nentity descriptions further improves multi-level representations of entities.", "published": "2017-01-08 22:20:22", "link": "http://arxiv.org/abs/1701.02025v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
