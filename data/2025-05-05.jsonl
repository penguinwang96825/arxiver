{"title": "R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning", "abstract": "Multimodal Reward Models (MRMs) play a crucial role in enhancing the\nperformance of Multimodal Large Language Models (MLLMs). While recent\nadvancements have primarily focused on improving the model structure and\ntraining data of MRMs, there has been limited exploration into the\neffectiveness of long-term reasoning capabilities for reward modeling and how\nto activate these capabilities in MRMs. In this paper, we explore how\nReinforcement Learning (RL) can be used to improve reward modeling.\nSpecifically, we reformulate the reward modeling problem as a rule-based RL\ntask. However, we observe that directly applying existing RL algorithms, such\nas Reinforce++, to reward modeling often leads to training instability or even\ncollapse due to the inherent limitations of these algorithms. To address this\nissue, we propose the StableReinforce algorithm, which refines the training\nloss, advantage estimation strategy, and reward design of existing RL methods.\nThese refinements result in more stable training dynamics and superior\nperformance. To facilitate MRM training, we collect 200K preference data from\ndiverse datasets. Our reward model, R1-Reward, trained using the\nStableReinforce algorithm on this dataset, significantly improves performance\non multimodal reward modeling benchmarks. Compared to previous SOTA models,\nR1-Reward achieves a $8.4\\%$ improvement on the VL Reward-Bench and a $14.3\\%$\nimprovement on the Multimodal Reward Bench. Moreover, with more inference\ncompute, R1-Reward's performance is further enhanced, highlighting the\npotential of RL algorithms in optimizing MRMs.", "published": "2025-05-05 17:59:50", "link": "http://arxiv.org/abs/2505.02835v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AOR: Anatomical Ontology-Guided Reasoning for Medical Large Multimodal Model in Chest X-Ray Interpretation", "abstract": "Chest X-rays (CXRs) are the most frequently performed imaging examinations in\nclinical settings. Recent advancements in Large Multimodal Models (LMMs) have\nenabled automated CXR interpretation, enhancing diagnostic accuracy and\nefficiency. However, despite their strong visual understanding, current Medical\nLMMs (MLMMs) still face two major challenges: (1) Insufficient region-level\nunderstanding and interaction, and (2) Limited accuracy and interpretability\ndue to single-step reasoning. In this paper, we empower MLMMs with\nanatomy-centric reasoning capabilities to enhance their interactivity and\nexplainability. Specifically, we first propose an Anatomical Ontology-Guided\nReasoning (AOR) framework, which centers on cross-modal region-level\ninformation to facilitate multi-step reasoning. Next, under the guidance of\nexpert physicians, we develop AOR-Instruction, a large instruction dataset for\nMLMMs training. Our experiments demonstrate AOR's superior performance in both\nVQA and report generation tasks.", "published": "2025-05-05 17:57:07", "link": "http://arxiv.org/abs/2505.02830v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AutoLibra: Agent Metric Induction from Open-Ended Feedback", "abstract": "Agents are predominantly evaluated and optimized via task success metrics,\nwhich are coarse, rely on manual design from experts, and fail to reward\nintermediate emergent behaviors. We propose AutoLibra, a framework for agent\nevaluation, that transforms open-ended human feedback, e.g., \"If you find that\nthe button is disabled, don't click it again\", or \"This agent has too much\nautonomy to decide what to do on its own\", into metrics for evaluating\nfine-grained behaviors in agent trajectories. AutoLibra accomplishes this by\ngrounding feedback to an agent's behavior, clustering similar positive and\nnegative behaviors, and creating concrete metrics with clear definitions and\nconcrete examples, which can be used for prompting LLM-as-a-Judge as\nevaluators. We further propose two meta-metrics to evaluate the alignment of a\nset of (induced) metrics with open feedback: \"coverage\" and \"redundancy\".\nThrough optimizing these meta-metrics, we experimentally demonstrate\nAutoLibra's ability to induce more concrete agent evaluation metrics than the\nones proposed in previous agent evaluation benchmarks and discover new metrics\nto analyze agents. We also present two applications of AutoLibra in agent\nimprovement: First, we show that AutoLibra-induced metrics serve as better\nprompt-engineering targets than the task success rate on a wide range of text\ngame tasks, improving agent performance over baseline by a mean of 20%. Second,\nwe show that AutoLibra can iteratively select high-quality fine-tuning data for\nweb navigation agents. Our results suggest that AutoLibra is a powerful\ntask-agnostic tool for evaluating and improving language agents.", "published": "2025-05-05 17:47:49", "link": "http://arxiv.org/abs/2505.02820v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations", "abstract": "We introduce ReplaceMe, a generalized training-free depth pruning method that\neffectively replaces transformer blocks with a linear operation, while\nmaintaining high performance for low compression ratios. In contrast to\nconventional pruning approaches that require additional training or\nfine-tuning, our approach requires only a small calibration dataset that is\nused to estimate a linear transformation to approximate the pruned blocks. This\nestimated linear mapping can be seamlessly merged with the remaining\ntransformer blocks, eliminating the need for any additional network parameters.\nOur experiments show that ReplaceMe consistently outperforms other\ntraining-free approaches and remains highly competitive with state-of-the-art\npruning methods that involve extensive retraining/fine-tuning and architectural\nmodifications. Applied to several large language models (LLMs), ReplaceMe\nachieves up to 25% pruning while retaining approximately 90% of the original\nmodel's performance on open benchmarks - without any training or healing steps,\nresulting in minimal computational overhead (see Fig.1). We provide an\nopen-source library implementing ReplaceMe alongside several state-of-the-art\ndepth pruning techniques, available at this repository.", "published": "2025-05-05 17:47:42", "link": "http://arxiv.org/abs/2505.02819v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing", "abstract": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing\nlanguage models' knowledge and reducing AI generative hallucinations, driving\nits widespread use. However, complex tasks requiring multi-round retrieval\nremain challenging, and early attempts tend to be overly optimistic without a\ngood sense of self-skepticism. Current multi-round RAG systems may continue\nsearching even when enough information has already been retrieved, or they may\nprovide incorrect answers without having sufficient information or knowledge.\nExisting solutions either require large amounts of expensive human-labeled\nprocess supervision data or lead to subpar performance.\n  This paper aims to address these limitations by introducing a new framework,\n\\textbf{SIM-RAG}, to explicitly enhance RAG systems' self-awareness and\nmulti-round retrieval capabilities. To train SIM-RAG, we first let a RAG system\nself-practice multi-round retrieval, augmenting existing question-answer pairs\nwith intermediate inner monologue reasoning steps to generate synthetic\ntraining data. For each pair, the system may explore multiple retrieval paths,\nwhich are labeled as successful if they reach the correct answer and\nunsuccessful otherwise. Using this data, we train a lightweight information\nsufficiency Critic. At inference time, the Critic evaluates whether the RAG\nsystem has retrieved sufficient information at each round, guiding retrieval\ndecisions and improving system-level self-awareness through in-context\nreinforcement learning.\n  Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an\neffective multi-round RAG solution. Furthermore, this framework is\nsystem-efficient, adding a lightweight component to RAG without requiring\nmodifications to existing LLMs or search engines, and data-efficient,\neliminating the need for costly human-annotated mid-step retrieval process\nsupervision data.", "published": "2025-05-05 17:39:35", "link": "http://arxiv.org/abs/2505.02811v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Bye-bye, Bluebook? Automating Legal Procedure with Large Language Models", "abstract": "Legal practice requires careful adherence to procedural rules. In the United\nStates, few are more complex than those found in The Bluebook: A Uniform System\nof Citation. Compliance with this system's 500+ pages of byzantine formatting\ninstructions is the raison d'etre of thousands of student law review editors\nand the bete noire of lawyers everywhere. To evaluate whether large language\nmodels (LLMs) are able to adhere to the procedures of such a complicated\nsystem, we construct an original dataset of 866 Bluebook tasks and test\nflagship LLMs from OpenAI, Anthropic, Google, Meta, and DeepSeek. We show (1)\nthat these models produce fully compliant Bluebook citations only 69%-74% of\nthe time and (2) that in-context learning on the Bluebook's underlying system\nof rules raises accuracy only to 77%. These results caution against using\noff-the-shelf LLMs to automate aspects of the law where fidelity to procedure\nis paramount.", "published": "2025-05-05 16:18:07", "link": "http://arxiv.org/abs/2505.02763v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Using Knowledge Graphs to harvest datasets for efficient CLIP model training", "abstract": "Training high-quality CLIP models typically requires enormous datasets, which\nlimits the development of domain-specific models -- especially in areas that\neven the largest CLIP models do not cover well -- and drives up training costs.\nThis poses challenges for scientific research that needs fine-grained control\nover the training procedure of CLIP models. In this work, we show that by\nemploying smart web search strategies enhanced with knowledge graphs, a robust\nCLIP model can be trained from scratch with considerably less data.\nSpecifically, we demonstrate that an expert foundation model for living\norganisms can be built using just 10M images. Moreover, we introduce EntityNet,\na dataset comprising 33M images paired with 46M text descriptions, which\nenables the training of a generic CLIP model in significantly reduced time.", "published": "2025-05-05 15:56:25", "link": "http://arxiv.org/abs/2505.02746v1", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play", "abstract": "A voice AI agent that blends seamlessly into daily life would interact with\nhumans in an autonomous, real-time, and emotionally expressive manner. Rather\nthan merely reacting to commands, it would continuously listen, reason, and\nrespond proactively, fostering fluid, dynamic, and emotionally resonant\ninteractions. We introduce Voila, a family of large voice-language foundation\nmodels that make a step towards this vision. Voila moves beyond traditional\npipeline systems by adopting a new end-to-end architecture that enables\nfull-duplex, low-latency conversations while preserving rich vocal nuances such\nas tone, rhythm, and emotion. It achieves a response latency of just 195\nmilliseconds, surpassing the average human response time. Its hierarchical\nmulti-scale Transformer integrates the reasoning capabilities of large language\nmodels (LLMs) with powerful acoustic modeling, enabling natural, persona-aware\nvoice generation -- where users can simply write text instructions to define\nthe speaker's identity, tone, and other characteristics. Moreover, Voila\nsupports over one million pre-built voices and efficient customization of new\nones from brief audio samples as short as 10 seconds. Beyond spoken dialogue,\nVoila is designed as a unified model for a wide range of voice-based\napplications, including automatic speech recognition (ASR), Text-to-Speech\n(TTS), and, with minimal adaptation, multilingual speech translation. Voila is\nfully open-sourced to support open research and accelerate progress toward\nnext-generation human-machine interactions.", "published": "2025-05-05 15:05:01", "link": "http://arxiv.org/abs/2505.02707v1", "categories": ["cs.AI", "cs.CL", "cs.SD"], "primary_category": "cs.AI"}
{"title": "Predicting Movie Hits Before They Happen with LLMs", "abstract": "Addressing the cold-start issue in content recommendation remains a critical\nongoing challenge. In this work, we focus on tackling the cold-start problem\nfor movies on a large entertainment platform. Our primary goal is to forecast\nthe popularity of cold-start movies using Large Language Models (LLMs)\nleveraging movie metadata. This method could be integrated into retrieval\nsystems within the personalization pipeline or could be adopted as a tool for\neditorial teams to ensure fair promotion of potentially overlooked movies that\nmay be missed by traditional or algorithmic solutions. Our study validates the\neffectiveness of this approach compared to established baselines and those we\ndeveloped.", "published": "2025-05-05 14:43:20", "link": "http://arxiv.org/abs/2505.02693v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "fastabx: A library for efficient computation of ABX discriminability", "abstract": "We introduce fastabx, a high-performance Python library for building ABX\ndiscrimination tasks. ABX is a measure of the separation between generic\ncategories of interest. It has been used extensively to evaluate phonetic\ndiscriminability in self-supervised speech representations. However, its\nbroader adoption has been limited by the absence of adequate tools. fastabx\naddresses this gap by providing a framework capable of constructing any type of\nABX task while delivering the efficiency necessary for rapid development\ncycles, both in task creation and in calculating distances between\nrepresentations. We believe that fastabx will serve as a valuable resource for\nthe broader representation learning community, enabling researchers to\nsystematically investigate what information can be directly extracted from\nlearned representations across several domains beyond speech processing. The\nsource code is available at https://github.com/bootphon/fastabx.", "published": "2025-05-05 14:43:01", "link": "http://arxiv.org/abs/2505.02692v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Sailing AI by the Stars: A Survey of Learning from Rewards in Post-Training and Test-Time Scaling of Large Language Models", "abstract": "Recent developments in Large Language Models (LLMs) have shifted from\npre-training scaling to post-training and test-time scaling. Across these\ndevelopments, a key unified paradigm has arisen: Learning from Rewards, where\nreward signals act as the guiding stars to steer LLM behavior. It has\nunderpinned a wide range of prevalent techniques, such as reinforcement\nlearning (in RLHF, DPO, and GRPO), reward-guided decoding, and post-hoc\ncorrection. Crucially, this paradigm enables the transition from passive\nlearning from static data to active learning from dynamic feedback. This endows\nLLMs with aligned preferences and deep reasoning capabilities. In this survey,\nwe present a comprehensive overview of the paradigm of learning from rewards.\nWe categorize and analyze the strategies under this paradigm across training,\ninference, and post-inference stages. We further discuss the benchmarks for\nreward models and the primary applications. Finally we highlight the challenges\nand future directions. We maintain a paper collection at\nhttps://github.com/bobxwu/learning-from-rewards-llm-papers.", "published": "2025-05-05 14:33:49", "link": "http://arxiv.org/abs/2505.02686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Progress in LLM Alignment from the Perspective of Reward Design", "abstract": "The alignment of large language models (LLMs) with human values and\nintentions represents a core challenge in current AI research, where reward\nmechanism design has become a critical factor in shaping model behavior. This\nstudy conducts a comprehensive investigation of reward mechanisms in LLM\nalignment through a systematic theoretical framework, categorizing their\ndevelopment into three key phases: (1) feedback (diagnosis), (2) reward design\n(prescription), and (3) optimization (treatment). Through a four-dimensional\nanalysis encompassing construction basis, format, expression, and granularity,\nthis research establishes a systematic classification framework that reveals\nevolutionary trends in reward modeling. The field of LLM alignment faces\nseveral persistent challenges, while recent advances in reward design are\ndriving significant paradigm shifts. Notable developments include the\ntransition from reinforcement learning-based frameworks to novel optimization\nparadigms, as well as enhanced capabilities to address complex alignment\nscenarios involving multimodal integration and concurrent task coordination.\nFinally, this survey outlines promising future research directions for LLM\nalignment through innovative reward design strategies.", "published": "2025-05-05 14:15:02", "link": "http://arxiv.org/abs/2505.02666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proper Name Diacritization for Arabic Wikipedia: A Benchmark Dataset", "abstract": "Proper names in Arabic Wikipedia are frequently undiacritized, creating\nambiguity in pronunciation and interpretation, especially for transliterated\nnamed entities of foreign origin. While transliteration and diacritization have\nbeen well-studied separately in Arabic NLP,their intersection remains\nunderexplored. In this paper, we introduce a new manually diacritized dataset\nof Arabic proper names of various origins with their English Wikipedia\nequivalent glosses, and present the challenges and guidelines we followed to\ncreate it. We benchmark GPT-4o on the task of recovering full diacritization\ngiven the undiacritized Arabic and English forms, and analyze its performance.\nAchieving 73% accuracy, our results underscore both the difficulty of the task\nand the need for improved models and resources. We release our dataset to\nfacilitate further research on Arabic Wikipedia proper name diacritization.", "published": "2025-05-05 14:03:22", "link": "http://arxiv.org/abs/2505.02656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning", "abstract": "Chemical reaction and retrosynthesis prediction are fundamental tasks in drug\ndiscovery. Recently, large language models (LLMs) have shown potential in many\ndomains. However, directly applying LLMs to these tasks faces two major\nchallenges: (i) lacking a large-scale chemical synthesis-related instruction\ndataset; (ii) ignoring the close correlation between reaction and\nretrosynthesis prediction for the existing fine-tuning strategies. To address\nthese challenges, we propose ChemDual, a novel LLM framework for accurate\nchemical synthesis. Specifically, considering the high cost of data acquisition\nfor reaction and retrosynthesis, ChemDual regards the\nreaction-and-retrosynthesis of molecules as a related\nrecombination-and-fragmentation process and constructs a large-scale of 4.4\nmillion instruction dataset. Furthermore, ChemDual introduces an enhanced\nLLaMA, equipped with a multi-scale tokenizer and dual-task learning strategy,\nto jointly optimize the process of recombination and fragmentation as well as\nthe tasks between reaction and retrosynthesis prediction. Extensive experiments\non Mol-Instruction and USPTO-50K datasets demonstrate that ChemDual achieves\nstate-of-the-art performance in both predictions of reaction and\nretrosynthesis, outperforming the existing conventional single-task approaches\nand the general open-source LLMs. Through molecular docking analysis, ChemDual\ngenerates compounds with diverse and strong protein binding affinity, further\nhighlighting its strong potential in drug design.", "published": "2025-05-05 13:31:36", "link": "http://arxiv.org/abs/2505.02639v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis", "abstract": "Real-time, intelligent, and natural speech interaction is an essential part\nof the next-generation human-computer interaction. Recent advancements have\nshowcased the potential of building intelligent spoken chatbots based on large\nlanguage models (LLMs). In this paper, we introduce LLaMA-Omni 2, a series of\nspeech language models (SpeechLMs) ranging from 0.5B to 14B parameters, capable\nof achieving high-quality real-time speech interaction. LLaMA-Omni 2 is built\nupon the Qwen2.5 series models, integrating a speech encoder and an\nautoregressive streaming speech decoder. Despite being trained on only 200K\nmulti-turn speech dialogue samples, LLaMA-Omni 2 demonstrates strong\nperformance on several spoken question answering and speech instruction\nfollowing benchmarks, surpassing previous state-of-the-art SpeechLMs like\nGLM-4-Voice, which was trained on millions of hours of speech data.", "published": "2025-05-05 12:53:09", "link": "http://arxiv.org/abs/2505.02625v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Automatic Proficiency Assessment in L2 English Learners", "abstract": "Second language proficiency (L2) in English is usually perceptually evaluated\nby English teachers or expert evaluators, with the inherent intra- and\ninter-rater variability. This paper explores deep learning techniques for\ncomprehensive L2 proficiency assessment, addressing both the speech signal and\nits correspondent transcription. We analyze spoken proficiency classification\nprediction using diverse architectures, including 2D CNN, frequency-based CNN,\nResNet, and a pretrained wav2vec 2.0 model. Additionally, we examine text-based\nproficiency assessment by fine-tuning a BERT language model within resource\nconstraints. Finally, we tackle the complex task of spontaneous dialogue\nassessment, managing long-form audio and speaker interactions through separate\napplications of wav2vec 2.0 and BERT models. Results from experiments on\nEFCamDat and ANGLISH datasets and a private dataset highlight the potential of\ndeep learning, especially the pretrained wav2vec 2.0 model, for robust\nautomated L2 proficiency evaluation.", "published": "2025-05-05 12:36:03", "link": "http://arxiv.org/abs/2505.02615v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Ensemble Kalman filter for uncertainty in human language comprehension", "abstract": "Artificial neural networks (ANNs) are widely used in modeling sentence\nprocessing but often exhibit deterministic behavior, contrasting with human\nsentence comprehension, which manages uncertainty during ambiguous or\nunexpected inputs. This is exemplified by reversal anomalies-sentences with\nunexpected role reversals that challenge syntax and semantics-highlighting the\nlimitations of traditional ANN models, such as the Sentence Gestalt (SG) Model.\nTo address these limitations, we propose a Bayesian framework for sentence\ncomprehension, applying an extension of the ensemble Kalman filter (EnKF) for\nBayesian inference to quantify uncertainty. By framing language comprehension\nas a Bayesian inverse problem, this approach enhances the SG model's ability to\nreflect human sentence processing with respect to the representation of\nuncertainty. Numerical experiments and comparisons with maximum likelihood\nestimation (MLE) demonstrate that Bayesian methods improve uncertainty\nrepresentation, enabling the model to better approximate human cognitive\nprocessing when dealing with linguistic ambiguities.", "published": "2025-05-05 11:56:12", "link": "http://arxiv.org/abs/2505.02590v1", "categories": ["cs.CL", "stat.AP", "stat.ML"], "primary_category": "cs.CL"}
{"title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning", "abstract": "Recent advances in reinforcement learning (RL) for large language model (LLM)\nfine-tuning show promise in addressing multi-objective tasks but still face\nsignificant challenges, including complex objective balancing, low training\nefficiency, poor scalability, and limited explainability. Leveraging ensemble\nlearning principles, we introduce an Ensemble Multi-Objective RL (EMORL)\nframework that fine-tunes multiple models with individual objectives while\noptimizing their aggregation after the training to improve efficiency and\nflexibility. Our method is the first to aggregate the last hidden states of\nindividual models, incorporating contextual information from multiple\nobjectives. This approach is supported by a hierarchical grid search algorithm\nthat identifies optimal weighted combinations. We evaluate EMORL on counselor\nreflection generation tasks, using text-scoring LLMs to evaluate the\ngenerations and provide rewards during RL fine-tuning. Through comprehensive\nexperiments on the PAIR and Psych8k datasets, we demonstrate the advantages of\nEMORL against existing baselines: significantly lower and more stable training\nconsumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds),\nimproved scalability and explainability, and comparable performance across\nmultiple objectives.", "published": "2025-05-05 11:30:46", "link": "http://arxiv.org/abs/2505.02579v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bielik v3 Small: Technical Report", "abstract": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.", "published": "2025-05-05 10:39:51", "link": "http://arxiv.org/abs/2505.02550v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Bemba Speech Translation: Exploring a Low-Resource African Language", "abstract": "This paper describes our system submission to the International Conference on\nSpoken Language Translation (IWSLT 2025), low-resource languages track, namely\nfor Bemba-to-English speech translation. We built cascaded speech translation\nsystems based on Whisper and NLLB-200, and employed data augmentation\ntechniques, such as back-translation. We investigate the effect of using\nsynthetic data and discuss our experimental setup.", "published": "2025-05-05 09:51:56", "link": "http://arxiv.org/abs/2505.02518v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Data Augmentation With Back translation for Low Resource languages: A case of English and Luganda", "abstract": "In this paper,we explore the application of Back translation (BT) as a\nsemi-supervised technique to enhance Neural Machine Translation(NMT) models for\nthe English-Luganda language pair, specifically addressing the challenges faced\nby low-resource languages. The purpose of our study is to demonstrate how BT\ncan mitigate the scarcity of bilingual data by generating synthetic data from\nmonolingual corpora. Our methodology involves developing custom NMT models\nusing both publicly available and web-crawled data, and applying Iterative and\nIncremental Back translation techniques. We strategically select datasets for\nincremental back translation across multiple small datasets, which is a novel\nelement of our approach. The results of our study show significant\nimprovements, with translation performance for the English-Luganda pair\nexceeding previous benchmarks by more than 10 BLEU score units across all\ntranslation directions. Additionally, our evaluation incorporates comprehensive\nassessment metrics such as SacreBLEU, ChrF2, and TER, providing a nuanced\nunderstanding of translation quality. The conclusion drawn from our research\nconfirms the efficacy of BT when strategically curated datasets are utilized,\nestablishing new performance benchmarks and demonstrating the potential of BT\nin enhancing NMT models for low-resource languages.", "published": "2025-05-05 08:47:52", "link": "http://arxiv.org/abs/2505.02463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incentivizing Inclusive Contributions in Model Sharing Markets", "abstract": "While data plays a crucial role in training contemporary AI models, it is\nacknowledged that valuable public data will be exhausted in a few years,\ndirecting the world's attention towards the massive decentralized private data.\nHowever, the privacy-sensitive nature of raw data and lack of incentive\nmechanism prevent these valuable data from being fully exploited. Addressing\nthese challenges, this paper proposes inclusive and incentivized personalized\nfederated learning (iPFL), which incentivizes data holders with diverse\npurposes to collaboratively train personalized models without revealing raw\ndata. iPFL constructs a model-sharing market by solving a graph-based training\noptimization and incorporates an incentive mechanism based on game theory\nprinciples. Theoretical analysis shows that iPFL adheres to two key incentive\nproperties: individual rationality and truthfulness. Empirical studies on\neleven AI tasks (e.g., large language models' instruction-following tasks)\ndemonstrate that iPFL consistently achieves the highest economic utility, and\nbetter or comparable model performance compared to baseline methods. We\nanticipate that our iPFL can serve as a valuable technique for boosting future\nAI models on decentralized private data while making everyone satisfied.", "published": "2025-05-05 08:45:26", "link": "http://arxiv.org/abs/2505.02462v1", "categories": ["cs.AI", "cs.CL", "cs.GT"], "primary_category": "cs.AI"}
{"title": "Colombian Waitresses y Jueces canadienses: Gender and Country Biases in Occupation Recommendations from LLMs", "abstract": "One of the goals of fairness research in NLP is to measure and mitigate\nstereotypical biases that are propagated by NLP systems. However, such work\ntends to focus on single axes of bias (most often gender) and the English\nlanguage. Addressing these limitations, we contribute the first study of\nmultilingual intersecting country and gender biases, with a focus on occupation\nrecommendations generated by large language models. We construct a benchmark of\nprompts in English, Spanish and German, where we systematically vary country\nand gender, using 25 countries and four pronoun sets. Then, we evaluate a suite\nof 5 Llama-based models on this benchmark, finding that LLMs encode significant\ngender and country biases. Notably, we find that even when models show parity\nfor gender or country individually, intersectional occupational biases based on\nboth country and gender persist. We also show that the prompting language\nsignificantly affects bias, and instruction-tuned models consistently\ndemonstrate the lowest and most stable levels of bias. Our findings highlight\nthe need for fairness researchers to use intersectional and multilingual lenses\nin their work.", "published": "2025-05-05 08:40:51", "link": "http://arxiv.org/abs/2505.02456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bielik 11B v2 Technical Report", "abstract": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.", "published": "2025-05-05 07:03:41", "link": "http://arxiv.org/abs/2505.02410v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL", "abstract": "Chain-of-thought (CoT) reasoning in large language models (LLMs) can be\nformalized as a latent variable problem, where the model needs to generate\nintermediate reasoning steps. While prior approaches such as iterative\nreward-ranked fine-tuning (RAFT) have relied on such formulations, they\ntypically apply uniform inference budgets across prompts, which fails to\naccount for variability in difficulty and convergence behavior. This work\nidentifies the main bottleneck in CoT training as inefficient stochastic\ngradient estimation due to static sampling strategies. We propose GVM-RAFT, a\nprompt-specific Dynamic Sample Allocation Strategy designed to minimize\nstochastic gradient variance under a computational budget constraint. The\nmethod dynamically allocates computational resources by monitoring prompt\nacceptance rates and stochastic gradient norms, ensuring that the resulting\ngradient variance is minimized. Our theoretical analysis shows that the\nproposed dynamic sampling strategy leads to accelerated convergence guarantees\nunder suitable conditions. Experiments on mathematical reasoning show that\nGVM-RAFT achieves a 2-4x speedup and considerable accuracy improvements over\nvanilla RAFT. The proposed dynamic sampling strategy is general and can be\nincorporated into other reinforcement learning algorithms, such as GRPO,\nleading to similar improvements in convergence and test accuracy. Our code is\navailable at https://github.com/RLHFlow/GVM.", "published": "2025-05-05 06:26:00", "link": "http://arxiv.org/abs/2505.02391v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RM-R1: Reward Modeling as Reasoning", "abstract": "Reward modeling is essential for aligning large language models (LLMs) with\nhuman preferences, especially through reinforcement learning from human\nfeedback (RLHF). To provide accurate reward signals, a reward model (RM) should\nstimulate deep thinking and conduct interpretable reasoning before assigning a\nscore or a judgment. However, existing RMs either produce opaque scalar scores\nor directly generate the prediction of a preferred answer, making them struggle\nto integrate natural language critiques, thus lacking interpretability.\nInspired by recent advances of long chain-of-thought (CoT) on\nreasoning-intensive tasks, we hypothesize and validate that integrating\nreasoning capabilities into reward modeling significantly enhances RM's\ninterpretability and performance. In this work, we introduce a new class of\ngenerative reward models -- Reasoning Reward Models (ReasRMs) -- which\nformulate reward modeling as a reasoning task. We propose a reasoning-oriented\ntraining pipeline and train a family of ReasRMs, RM-R1. The training consists\nof two key stages: (1) distillation of high-quality reasoning chains and (2)\nreinforcement learning with verifiable rewards. RM-R1 improves LLM rollouts by\nself-generating reasoning traces or chat-specific rubrics and evaluating\ncandidate responses against them. Empirically, our models achieve\nstate-of-the-art or near state-of-the-art performance of generative RMs across\nmultiple comprehensive reward model benchmarks, outperforming much larger\nopen-weight models (e.g., Llama3.1-405B) and proprietary ones (e.g., GPT-4o) by\nup to 13.8%. Beyond final performance, we perform thorough empirical analysis\nto understand the key ingredients of successful ReasRM training. To facilitate\nfuture research, we release six ReasRM models along with code and data at\nhttps://github.com/RM-R1-UIUC/RM-R1.", "published": "2025-05-05 06:11:12", "link": "http://arxiv.org/abs/2505.02387v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings", "abstract": "Unsupervised contrastive learning has become a hot research topic in natural\nlanguage processing. Existing works usually aim at constraining the orientation\ndistribution of the representations of positive and negative samples in the\nhigh-dimensional semantic space in contrastive learning, but the semantic\nrepresentation tensor possesses both modulus and orientation features, and the\nexisting works ignore the modulus feature of the representations and cause\ninsufficient contrastive learning. % Therefore, we firstly propose a training\nobjective that aims at modulus constraints on the semantic representation\ntensor, to strengthen the alignment between the positive samples in contrastive\nlearning. Therefore, we first propose a training objective that is designed to\nimpose modulus constraints on the semantic representation tensor, to strengthen\nthe alignment between positive samples in contrastive learning. Then, the\nBERT-like model suffers from the phenomenon of sinking attention, leading to a\nlack of attention to CLS tokens that aggregate semantic information. In\nresponse, we propose a cross-attention structure among the twin-tower ensemble\nmodels to enhance the model's attention to CLS token and optimize the quality\nof CLS Pooling. Combining the above two motivations, we propose a new\n\\textbf{J}oint \\textbf{T}ensor representation modulus constraint and\n\\textbf{C}ross-attention unsupervised contrastive learning \\textbf{S}entence\n\\textbf{E}mbedding representation framework JTCSE, which we evaluate in seven\nsemantic text similarity computation tasks, and the experimental results show\nthat JTCSE's twin-tower ensemble model and single-tower distillation model\noutperform the other baselines and become the current SOTA. In addition, we\nhave conducted an extensive zero-shot downstream task evaluation, which shows\nthat JTCSE outperforms other baselines overall on more than 130 tasks.", "published": "2025-05-05 05:09:21", "link": "http://arxiv.org/abs/2505.02366v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SIMPLEMIX: Frustratingly Simple Mixing of Off- and On-policy Data in Language Model Preference Learning", "abstract": "Aligning language models with human preferences relies on pairwise preference\ndatasets. While some studies suggest that on-policy data consistently\noutperforms off -policy data for preference learning, others indicate that the\nadvantages of on-policy data may be task-dependent, highlighting the need for a\nsystematic exploration of their interplay.\n  In this work, we show that on-policy and off-policy data offer complementary\nstrengths in preference optimization: on-policy data is particularly effective\nfor reasoning tasks like math and coding, while off-policy data performs better\non open-ended tasks such as creative writing and making personal\nrecommendations. Guided by these findings, we introduce SIMPLEMIX, an approach\nto combine the complementary strengths of on-policy and off-policy preference\nlearning by simply mixing these two data sources. Our empirical results across\ndiverse tasks and benchmarks demonstrate that SIMPLEMIX substantially improves\nlanguage model alignment. Specifically, SIMPLEMIX improves upon on-policy DPO\nand off-policy DPO by an average of 6.03% on Alpaca Eval 2.0. Moreover, it\noutperforms prior approaches that are much more complex in combining on- and\noff-policy data, such as HyPO and DPO-Mix-P, by an average of 3.05%.", "published": "2025-05-05 04:54:44", "link": "http://arxiv.org/abs/2505.02363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Invoke Interfaces Only When Needed: Adaptive Invocation for Large Language Models in Question Answering", "abstract": "The collaborative paradigm of large and small language models (LMs)\neffectively balances performance and cost, yet its pivotal challenge lies in\nprecisely pinpointing the moment of invocation when hallucinations arise in\nsmall LMs. Previous optimization efforts primarily focused on post-processing\ntechniques, which were separate from the reasoning process of LMs, resulting in\nhigh computational costs and limited effectiveness. In this paper, we propose a\npractical invocation evaluation metric called AttenHScore, which calculates the\naccumulation and propagation of hallucinations during the generation process of\nsmall LMs, continuously amplifying potential reasoning errors. By dynamically\nadjusting the detection threshold, we achieve more accurate real-time\ninvocation of large LMs. Additionally, considering the limited reasoning\ncapacity of small LMs, we leverage uncertainty-aware knowledge reorganization\nto assist them better capture critical information from different text chunks.\nExtensive experiments reveal that our AttenHScore outperforms most baseline in\nenhancing real-time hallucination detection capabilities across multiple QA\ndatasets, especially when addressing complex queries. Moreover, our strategies\neliminate the need for additional model training and display flexibility in\nadapting to various transformer-based LMs.", "published": "2025-05-05 01:45:56", "link": "http://arxiv.org/abs/2505.02311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques", "abstract": "Large Language Models (LLMs) have revolutionized many areas of artificial\nintelligence (AI), but their substantial resource requirements limit their\ndeployment on mobile and edge devices. This survey paper provides a\ncomprehensive overview of techniques for compressing LLMs to enable efficient\ninference in resource-constrained environments. We examine three primary\napproaches: Knowledge Distillation, Model Quantization, and Model Pruning. For\neach technique, we discuss the underlying principles, present different\nvariants, and provide examples of successful applications. We also briefly\ndiscuss complementary techniques such as mixture-of-experts and early-exit\nstrategies. Finally, we highlight promising future directions, aiming to\nprovide a valuable resource for both researchers and practitioners seeking to\noptimize LLMs for edge deployment.", "published": "2025-05-05 01:27:47", "link": "http://arxiv.org/abs/2505.02309v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Generative Sign-description Prompts with Multi-positive Contrastive Learning for Sign Language Recognition", "abstract": "Sign language recognition (SLR) faces fundamental challenges in creating\naccurate annotations due to the inherent complexity of simultaneous manual and\nnon-manual signals. To the best of our knowledge, this is the first work to\nintegrate generative large language models (LLMs) into SLR tasks. We propose a\nnovel Generative Sign-description Prompts Multi-positive Contrastive learning\n(GSP-MC) method that leverages retrieval-augmented generation (RAG) with\ndomain-specific LLMs, incorporating multi-step prompt engineering and\nexpert-validated sign language corpora to produce precise multipart\ndescriptions. The GSP-MC method also employs a dual-encoder architecture to\nbidirectionally align hierarchical skeleton features with multiple text\ndescriptions (global, synonym, and part level) through probabilistic matching.\nOur approach combines global and part-level losses, optimizing KL divergence to\nensure robust alignment across all relevant text-skeleton pairs while capturing\nboth sign-level semantics and detailed part dynamics. Experiments demonstrate\nstate-of-the-art performance against existing methods on the Chinese SLR500\n(reaching 97.1%) and Turkish AUTSL datasets (97.07% accuracy). The method's\ncross-lingual effectiveness highlight its potential for developing inclusive\ncommunication technologies.", "published": "2025-05-05 00:57:57", "link": "http://arxiv.org/abs/2505.02304v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery", "abstract": "Segmentation models can recognize a pre-defined set of objects in images.\nHowever, models that can reason over complex user queries that implicitly refer\nto multiple objects of interest are still in their infancy. Recent advances in\nreasoning segmentation--generating segmentation masks from complex, implicit\nquery text--demonstrate that vision-language models can operate across an open\ndomain and produce reasonable outputs. However, our experiments show that such\nmodels struggle with complex remote-sensing imagery. In this work, we introduce\nLISAt, a vision-language model designed to describe complex remote-sensing\nscenes, answer questions about them, and segment objects of interest. We\ntrained LISAt on a new curated geospatial reasoning-segmentation dataset, GRES,\nwith 27,615 annotations over 9,205 images, and a multimodal pretraining\ndataset, PreGRES, containing over 1 million question-answer pairs. LISAt\noutperforms existing geospatial foundation models such as RS-GPT4V by over\n10.04 % (BLEU-4) on remote-sensing description tasks, and surpasses\nstate-of-the-art open-domain models on reasoning segmentation tasks by 143.36 %\n(gIoU). Our model, datasets, and code are available at\nhttps://lisat-bair.github.io/LISAt/", "published": "2025-05-05 17:56:25", "link": "http://arxiv.org/abs/2505.02829v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review", "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a pillar of\nTrustworthy AI and aims to bring transparency in complex models that are opaque\nby nature. Despite the benefits of incorporating explanations in models, an\nurgent need is found in addressing the privacy concerns of providing this\nadditional information to end users. In this article, we conduct a scoping\nreview of existing literature to elicit details on the conflict between privacy\nand explainability. Using the standard methodology for scoping review, we\nextracted 57 articles from 1,943 studies published from January 2019 to\nDecember 2024. The review addresses 3 research questions to present readers\nwith more understanding of the topic: (1) what are the privacy risks of\nreleasing explanations in AI systems? (2) what current methods have researchers\nemployed to achieve privacy preservation in XAI systems? (3) what constitutes a\nprivacy preserving explanation? Based on the knowledge synthesized from the\nselected studies, we categorize the privacy risks and preservation methods in\nXAI and propose the characteristics of privacy preserving explanations to aid\nresearchers and practitioners in understanding the requirements of XAI that is\nprivacy compliant. Lastly, we identify the challenges in balancing privacy with\nother system desiderata and provide recommendations for achieving privacy\npreserving XAI. We expect that this review will shed light on the complex\nrelationship of privacy and explainability, both being the fundamental\nprinciples of Trustworthy AI.", "published": "2025-05-05 17:53:28", "link": "http://arxiv.org/abs/2505.02828v1", "categories": ["cs.AI", "cs.CR", "cs.ET"], "primary_category": "cs.AI"}
{"title": "Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models", "abstract": "Text-to-image (T2I) diffusion models have rapidly advanced, enabling\nhigh-quality image generation conditioned on textual prompts. However, the\ngrowing trend of fine-tuning pre-trained models for personalization raises\nserious concerns about unauthorized dataset usage. To combat this, dataset\nownership verification (DOV) has emerged as a solution, embedding watermarks\ninto the fine-tuning datasets using backdoor techniques. These watermarks\nremain inactive under benign samples but produce owner-specified outputs when\ntriggered. Despite the promise of DOV for T2I diffusion models, its robustness\nagainst copyright evasion attacks (CEA) remains unexplored. In this paper, we\nexplore how attackers can bypass these mechanisms through CEA, allowing models\nto circumvent watermarks even when trained on watermarked datasets. We propose\nthe first copyright evasion attack (i.e., CEAT2I) specifically designed to\nundermine DOV in T2I diffusion models. Concretely, our CEAT2I comprises three\nstages: watermarked sample detection, trigger identification, and efficient\nwatermark mitigation. A key insight driving our approach is that T2I models\nexhibit faster convergence on watermarked samples during the fine-tuning,\nevident through intermediate feature deviation. Leveraging this, CEAT2I can\nreliably detect the watermarked samples. Then, we iteratively ablate tokens\nfrom the prompts of detected watermarked samples and monitor shifts in\nintermediate features to pinpoint the exact trigger tokens. Finally, we adopt a\nclosed-form concept erasure method to remove the injected watermark. Extensive\nexperiments show that our CEAT2I effectively evades DOV mechanisms while\npreserving model performance.", "published": "2025-05-05 17:51:55", "link": "http://arxiv.org/abs/2505.02824v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models", "abstract": "Recently, large language models (LLMs) have achieved remarkable\nbreakthroughs, revolutionizing the natural language processing domain and\nbeyond. Due to immense parameter sizes, fine-tuning these models with private\ndata for diverse downstream tasks has become mainstream. Though federated\nlearning (FL) offers a promising solution for fine-tuning LLMs without sharing\nraw data, substantial computing costs hinder its democratization. Moreover, in\nreal-world scenarios, private client devices often possess heterogeneous\ncomputing resources, further complicating LLM fine-tuning. To combat these\nchallenges, we propose HSplitLoRA, a heterogeneous parameter-efficient\nfine-tuning (PEFT) framework built on split learning (SL) and low-rank\nadaptation (LoRA) fine-tuning, for efficiently fine-tuning LLMs on\nheterogeneous client devices. HSplitLoRA first identifies important weights\nbased on their contributions to LLM training. It then dynamically configures\nthe decomposition ranks of LoRA adapters for selected weights and determines\nthe model split point according to varying computing budgets of client devices.\nFinally, a noise-free adapter aggregation mechanism is devised to support\nheterogeneous adapter aggregation without introducing noise. Extensive\nexperiments demonstrate that HSplitLoRA outperforms state-of-the-art benchmarks\nin training accuracy and convergence speed.", "published": "2025-05-05 17:09:19", "link": "http://arxiv.org/abs/2505.02795v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects", "abstract": "Understanding and identifying controlled direct effects (CDEs) is crucial\nacross numerous scientific domains, including public health. While existing\nmethods can identify these effects from causal directed acyclic graphs (DAGs),\nthe true underlying structure is often unknown in practice. Essential graphs,\nwhich represent a Markov equivalence class of DAGs characterized by the same\nset of d-separations, provide a more practical and realistic alternative.\nHowever, learning the full essential graph is computationally intensive and\ntypically depends on strong, untestable assumptions. In this work, we\ncharacterize a local class of graphs, defined relative to a target variable,\nthat share a specific subset of d-separations, and introduce a graphical\nrepresentation of this class, called the local essential graph (LEG). We then\npresent LocPC, a novel algorithm designed to recover the LEG from an observed\ndistribution using only local conditional independence tests. Building on\nLocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG\nthat is sufficient to identify a CDE, bypassing the need of retrieving the full\nessential graph. Compared to global methods, our algorithms require less\nconditional independence tests and operate under weaker assumptions while\nmaintaining theoretical guarantees.", "published": "2025-05-05 16:47:29", "link": "http://arxiv.org/abs/2505.02781v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow", "abstract": "Pathologists rely on gigapixel whole-slide images (WSIs) to diagnose diseases\nlike cancer, yet current digital pathology tools hinder diagnosis. The immense\nscale of WSIs, often exceeding 100,000 X 100,000 pixels, clashes with the\nlimited views traditional monitors offer. This mismatch forces constant panning\nand zooming, increasing pathologist cognitive load, causing diagnostic fatigue,\nand slowing pathologists' adoption of digital methods. PathVis, our\nmixed-reality visualization platform for Apple Vision Pro, addresses these\nchallenges. It transforms the pathologist's interaction with data, replacing\ncumbersome mouse-and-monitor navigation with intuitive exploration using\nnatural hand gestures, eye gaze, and voice commands in an immersive workspace.\nPathVis integrates AI to enhance diagnosis. An AI-driven search function\ninstantly retrieves and displays the top five similar patient cases\nside-by-side, improving diagnostic precision and efficiency through rapid\ncomparison. Additionally, a multimodal conversational AI assistant offers\nreal-time image interpretation support and aids collaboration among\npathologists across multiple Apple devices. By merging the directness of\ntraditional pathology with advanced mixed-reality visualization and AI, PathVis\nimproves diagnostic workflows, reduces cognitive strain, and makes pathology\npractice more effective and engaging. The PathVis source code and a demo video\nare publicly available at: https://github.com/jaiprakash1824/Path_Vis", "published": "2025-05-05 16:46:53", "link": "http://arxiv.org/abs/2505.02780v1", "categories": ["cs.HC", "cs.AI", "cs.ET", "q-bio.TO"], "primary_category": "cs.HC"}
{"title": "Giving Simulated Cells a Voice: Evolving Prompt-to-Intervention Models for Cellular Control", "abstract": "Guiding biological systems toward desired states, such as morphogenetic\noutcomes, remains a fundamental challenge with far-reaching implications for\nmedicine and synthetic biology. While large language models (LLMs) have enabled\nnatural language as an interface for interpretable control in AI systems, their\nuse as mediators for steering biological or cellular dynamics remains largely\nunexplored.\n  In this work, we present a functional pipeline that translates natural\nlanguage prompts into spatial vector fields capable of directing simulated\ncellular collectives. Our approach combines a large language model with an\nevolvable neural controller (Prompt-to-Intervention, or P2I), optimized via\nevolutionary strategies to generate behaviors such as clustering or scattering\nin a simulated 2D environment.\n  We demonstrate that even with constrained vocabulary and simplified cell\nmodels, evolved P2I networks can successfully align cellular dynamics with\nuser-defined goals expressed in plain language. This work offers a complete\nloop from language input to simulated bioelectric-like intervention to\nbehavioral output, providing a foundation for future systems capable of natural\nlanguage-driven cellular control.", "published": "2025-05-05 16:21:46", "link": "http://arxiv.org/abs/2505.02766v1", "categories": ["cs.AI", "cs.NE", "cs.RO", "q-bio.TO"], "primary_category": "cs.AI"}
{"title": "The use of Artificial Intelligence for Intervention and Assessment in Individuals with ASD", "abstract": "This paper explores the use of Artificial Intelligence (AI) as a tool for\ndiagnosis, assessment, and intervention for individuals with Autism Spectrum\nDisorder (ASD). It focuses particularly on AI's role in early diagnosis,\nutilizing advanced machine learning techniques and data analysis. Recent\nstudies demonstrate that deep learning algorithms can identify behavioral\npatterns through biometric data analysis, video-based interaction assessments,\nand linguistic feature extraction, providing a more accurate and timely\ndiagnosis compared to traditional methods. Additionally, AI automates\ndiagnostic tools, reducing subjective biases and enabling the development of\npersonalized assessment protocols for ASD monitoring. At the same time, the\npaper examines AI-powered intervention technologies, emphasizing educational\nrobots and adaptive communication tools. Social robotic assistants, such as NAO\nand Kaspar, have been shown to enhance social skills in children by offering\nstructured, repetitive interactions that reinforce learning. Furthermore,\nAI-driven Augmentative and Alternative Communication (AAC) systems allow\nchildren with ASD to express themselves more effectively, while\nmachine-learning chatbots provide language development support through\npersonalized responses. The study presents research findings supporting the\neffectiveness of these AI applications while addressing challenges such as\nlong-term evaluation and customization to individual needs. In conclusion, the\npaper highlights the significance of AI as an innovative tool in ASD diagnosis\nand intervention, advocating for further research to assess its long-term\nimpact.", "published": "2025-05-05 15:58:32", "link": "http://arxiv.org/abs/2505.02747v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation", "abstract": "Recent advances in Large Language Models (LLMs) have positioned them as a\nprominent solution for Natural Language Processing tasks. Notably, they can\napproach these problems in a zero or few-shot manner, thereby eliminating the\nneed for training or fine-tuning task-specific models. However, LLMs face some\nchallenges, including hallucination and the presence of outdated knowledge or\nmissing information from specific domains in the training data. These problems\ncannot be easily solved by retraining the models with new data as it is a\ntime-consuming and expensive process. To mitigate these issues, Knowledge\nGraphs (KGs) have been proposed as a structured external source of information\nto enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for\nzero-shot Entity Disambiguation (ED). For that purpose, we leverage the\nhierarchical representation of the entities' classes in a KG to gradually prune\nthe candidate space as well as the entities' descriptions to enrich the input\nprompt with additional factual knowledge. Our evaluation on popular ED datasets\nshows that the proposed method outperforms non-enhanced and description-only\nenhanced LLMs, and has a higher degree of adaptability than task-specific\nmodels. Furthermore, we conduct an error analysis and discuss the impact of the\nleveraged KG's semantic expressivity on the ED performance.", "published": "2025-05-05 15:40:24", "link": "http://arxiv.org/abs/2505.02737v1", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models", "abstract": "Formal mathematical reasoning remains a critical challenge for artificial\nintelligence, hindered by limitations of existing benchmarks in scope and\nscale. To address this, we present FormalMATH, a large-scale Lean4 benchmark\ncomprising 5,560 formally verified problems spanning from high-school Olympiad\nchallenges to undergraduate-level theorems across diverse domains (e.g.,\nalgebra, applied mathematics, calculus, number theory, and discrete\nmathematics). To mitigate the inefficiency of manual formalization, we\nintroduce a novel human-in-the-loop autoformalization pipeline that integrates:\n(1) specialized large language models (LLMs) for statement autoformalization,\n(2) multi-LLM semantic verification, and (3) negation-based disproof filtering\nstrategies using off-the-shelf LLM-based provers. This approach reduces expert\nannotation costs by retaining 72.09% of statements before manual verification\nwhile ensuring fidelity to the original natural-language problems. Our\nevaluation of state-of-the-art LLM-based theorem provers reveals significant\nlimitations: even the strongest models achieve only 16.46% success rate under\npractical sampling budgets, exhibiting pronounced domain bias (e.g., excelling\nin algebra but failing in calculus) and over-reliance on simplified automation\ntactics. Notably, we identify a counterintuitive inverse relationship between\nnatural-language solution guidance and proof success in chain-of-thought\nreasoning scenarios, suggesting that human-written informal reasoning\nintroduces noise rather than clarity in the formal reasoning settings. We\nbelieve that FormalMATH provides a robust benchmark for benchmarking formal\nmathematical reasoning.", "published": "2025-05-05 15:37:00", "link": "http://arxiv.org/abs/2505.02735v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry", "abstract": "Although large language models (LLMs) have demonstrated impressive reasoning\ncapabilities across general domains, their effectiveness in real-world clinical\npractice remains limited. This is likely due to their insufficient exposure to\nreal-world clinical data during training, as such data is typically not\nincluded due to privacy concerns. To address this, we propose enhancing the\nclinical reasoning capabilities of LLMs by leveraging real-world clinical data.\nWe constructed reasoning-intensive questions from a nationwide sepsis registry\nand fine-tuned Phi-4 on these questions using reinforcement learning, resulting\nin C-Reason. C-Reason exhibited strong clinical reasoning capabilities on the\nin-domain test set, as evidenced by both quantitative metrics and expert\nevaluations. Furthermore, its enhanced reasoning capabilities generalized to a\nsepsis dataset involving different tasks and patient cohorts, an open-ended\nconsultations on antibiotics use task, and other diseases. Future research\nshould focus on training LLMs with large-scale, multi-disease clinical datasets\nto develop more powerful, general-purpose clinical reasoning models.", "published": "2025-05-05 15:23:47", "link": "http://arxiv.org/abs/2505.02722v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework", "abstract": "Cellular reprogramming, the artificial transformation of one cell type into\nanother, has been attracting increasing research attention due to its\ntherapeutic potential for complex diseases. However, discovering reprogramming\nstrategies through classical wet-lab experiments is hindered by lengthy time\ncommitments and high costs. In this study, we explore the use of deep\nreinforcement learning (DRL) to control Boolean network models of complex\nbiological systems, such as gene regulatory networks and signalling pathway\nnetworks. We formulate a novel control problem for Boolean network models under\nthe asynchronous update mode in the context of cellular reprogramming. To\nfacilitate scalability, we consider our previously introduced concept of a\npseudo-attractor and we improve our procedure for effective identification of\npseudo-attractor states. Finally, we devise a computational framework to solve\nthe control problem. To leverage the structure of biological systems, we\nincorporate graph neural networks with graph convolutions into the artificial\nneural network approximator for the action-value function learned by the DRL\nagent. Experiments on a number of large real-world biological networks from\nliterature demonstrate the scalability and effectiveness of our approach.", "published": "2025-05-05 15:07:20", "link": "http://arxiv.org/abs/2505.02712v1", "categories": ["cs.LG", "cs.AI", "q-bio.MN"], "primary_category": "cs.LG"}
{"title": "Technical Report: Evaluating Goal Drift in Language Model Agents", "abstract": "As language models (LMs) are increasingly deployed as autonomous agents,\ntheir robust adherence to human-assigned objectives becomes crucial for safe\noperation. When these agents operate independently for extended periods without\nhuman oversight, even initially well-specified goals may gradually shift.\nDetecting and measuring goal drift - an agent's tendency to deviate from its\noriginal objective over time - presents significant challenges, as goals can\nshift gradually, causing only subtle behavioral changes. This paper proposes a\nnovel approach to analyzing goal drift in LM agents. In our experiments, agents\nare first explicitly given a goal through their system prompt, then exposed to\ncompeting objectives through environmental pressures. We demonstrate that while\nthe best-performing agent (a scaffolded version of Claude 3.5 Sonnet) maintains\nnearly perfect goal adherence for more than 100,000 tokens in our most\ndifficult evaluation setting, all evaluated models exhibit some degree of goal\ndrift. We also find that goal drift correlates with models' increasing\nsusceptibility to pattern-matching behaviors as the context length grows.", "published": "2025-05-05 15:06:09", "link": "http://arxiv.org/abs/2505.02709v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "AI Standardized Patient Improves Human Conversations in Advanced Cancer Care", "abstract": "Serious illness communication (SIC) in end-of-life care faces challenges such\nas emotional stress, cultural barriers, and balancing hope with honesty.\nDespite its importance, one of the few available ways for clinicians to\npractice SIC is with standardized patients, which is expensive, time-consuming,\nand inflexible. In this paper, we present SOPHIE, an AI-powered standardized\npatient simulation and automated feedback system. SOPHIE combines large\nlanguage models (LLMs), a lifelike virtual avatar, and automated, personalized\nfeedback based on clinical literature to provide remote, on-demand SIC\ntraining. In a randomized control study with healthcare students and\nprofessionals, SOPHIE users demonstrated significant improvement across three\ncritical SIC domains: Empathize, Be Explicit, and Empower. These results\nsuggest that AI-driven tools can enhance complex interpersonal communication\nskills, offering scalable, accessible solutions to address a critical gap in\nclinician education.", "published": "2025-05-05 14:44:17", "link": "http://arxiv.org/abs/2505.02694v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law", "abstract": "This survey explores recent advancements in reasoning large language models\n(LLMs) designed to mimic \"slow thinking\" - a reasoning process inspired by\nhuman cognition, as described in Kahneman's Thinking, Fast and Slow. These\nmodels, like OpenAI's o1, focus on scaling computational resources dynamically\nduring complex tasks, such as math reasoning, visual reasoning, medical\ndiagnosis, and multi-agent debates. We present the development of reasoning\nLLMs and list their key technologies. By synthesizing over 100 studies, it\ncharts a path toward LLMs that combine human-like deep thinking with scalable\nefficiency for reasoning. The review breaks down methods into three categories:\n(1) test-time scaling dynamically adjusts computation based on task complexity\nvia search and sampling, dynamic verification; (2) reinforced learning refines\ndecision-making through iterative improvement leveraging policy networks,\nreward models, and self-evolution strategies; and (3) slow-thinking frameworks\n(e.g., long CoT, hierarchical processes) that structure problem-solving with\nmanageable steps. The survey highlights the challenges and further directions\nof this domain. Understanding and advancing the reasoning abilities of LLMs is\ncrucial for unlocking their full potential in real-world applications, from\nscientific discovery to decision support systems.", "published": "2025-05-05 14:14:59", "link": "http://arxiv.org/abs/2505.02665v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Note on Statistically Accurate Tabular Data Generation Using Large Language Models", "abstract": "Large language models (LLMs) have shown promise in synthetic tabular data\ngeneration, yet existing methods struggle to preserve complex feature\ndependencies, particularly among categorical variables. This work introduces a\nprobability-driven prompting approach that leverages LLMs to estimate\nconditional distributions, enabling more accurate and scalable data synthesis.\nThe results highlight the potential of prompting probobility distributions to\nenhance the statistical fidelity of LLM-generated tabular data.", "published": "2025-05-05 14:05:15", "link": "http://arxiv.org/abs/2505.02659v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SCFormer: Structured Channel-wise Transformer with Cumulative Historical State for Multivariate Time Series Forecasting", "abstract": "The Transformer model has shown strong performance in multivariate time\nseries forecasting by leveraging channel-wise self-attention. However, this\napproach lacks temporal constraints when computing temporal features and does\nnot utilize cumulative historical series effectively.To address these\nlimitations, we propose the Structured Channel-wise Transformer with Cumulative\nHistorical state (SCFormer). SCFormer introduces temporal constraints to all\nlinear transformations, including the query, key, and value matrices, as well\nas the fully connected layers within the Transformer. Additionally, SCFormer\nemploys High-order Polynomial Projection Operators (HiPPO) to deal with\ncumulative historical time series, allowing the model to incorporate\ninformation beyond the look-back window during prediction. Extensive\nexperiments on multiple real-world datasets demonstrate that SCFormer\nsignificantly outperforms mainstream baselines, highlighting its effectiveness\nin enhancing time series forecasting. The code is publicly available at\nhttps://github.com/ShiweiGuo1995/SCFormer", "published": "2025-05-05 13:59:55", "link": "http://arxiv.org/abs/2505.02655v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Eye Movements as Indicators of Deception: A Machine Learning Approach", "abstract": "Gaze may enhance the robustness of lie detectors but remains under-studied.\nThis study evaluated the efficacy of AI models (using fixations, saccades,\nblinks, and pupil size) for detecting deception in Concealed Information Tests\nacross two datasets. The first, collected with Eyelink 1000, contains gaze data\nfrom a computerized experiment where 87 participants revealed, concealed, or\nfaked the value of a previously selected card. The second, collected with Pupil\nNeon, involved 36 participants performing a similar task but facing an\nexperimenter. XGBoost achieved accuracies up to 74% in a binary classification\ntask (Revealing vs. Concealing) and 49% in a more challenging\nthree-classification task (Revealing vs. Concealing vs. Faking). Feature\nanalysis identified saccade number, duration, amplitude, and maximum pupil size\nas the most important for deception prediction. These results demonstrate the\nfeasibility of using gaze and AI to enhance lie detectors and encourage future\nresearch that may improve on this.", "published": "2025-05-05 13:50:12", "link": "http://arxiv.org/abs/2505.02649v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints", "abstract": "Internet of Things (IoT) systems increasingly operate in environments where\ndevices must respond in real time while managing fluctuating resource\nconstraints, including energy and bandwidth. Yet, current approaches often fall\nshort in addressing scenarios where operational constraints evolve over time.\nTo address these limitations, we propose a novel Budgeted Multi-Armed Bandit\nframework tailored for IoT applications with dynamic operational limits. Our\nmodel introduces a decaying violation budget, which permits limited constraint\nviolations early in the learning process and gradually enforces stricter\ncompliance over time. We present the Budgeted Upper Confidence Bound (UCB)\nalgorithm, which adaptively balances performance optimization and compliance\nwith time-varying constraints. We provide theoretical guarantees showing that\nBudgeted UCB achieves sublinear regret and logarithmic constraint violations\nover the learning horizon. Extensive simulations in a wireless communication\nsetting show that our approach achieves faster adaptation and better constraint\nsatisfaction than standard online learning methods. These results highlight the\nframework's potential for building adaptive, resource-aware IoT systems.", "published": "2025-05-05 13:33:39", "link": "http://arxiv.org/abs/2505.02640v1", "categories": ["cs.LG", "cs.AI", "cs.NI"], "primary_category": "cs.LG"}
{"title": "A Theoretical Analysis of Compositional Generalization in Neural Networks: A Necessary and Sufficient Condition", "abstract": "Compositional generalization is a crucial property in artificial\nintelligence, enabling models to handle novel combinations of known components.\nWhile most deep learning models lack this capability, certain models succeed in\nspecific tasks, suggesting the existence of governing conditions. This paper\nderives a necessary and sufficient condition for compositional generalization\nin neural networks. Conceptually, it requires that (i) the computational graph\nmatches the true compositional structure, and (ii) components encode just\nenough information in training. The condition is supported by mathematical\nproofs. This criterion combines aspects of architecture design, regularization,\nand training data properties. A carefully designed minimal example illustrates\nan intuitive understanding of the condition. We also discuss the potential of\nthe condition for assessing compositional generalization before training. This\nwork is a fundamental theoretical study of compositional generalization in\nneural networks.", "published": "2025-05-05 13:13:46", "link": "http://arxiv.org/abs/2505.02627v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Study of the influence of a biased database on the prediction of standard algorithms for selecting the best candidate for an interview", "abstract": "Artificial intelligence is used at various stages of the recruitment process\nto automatically select the best candidate for a position, with companies\nguaranteeing unbiased recruitment. However, the algorithms used are either\ntrained by humans or are based on learning from past experiences that were\nbiased. In this article, we propose to generate data mimicking external\n(discrimination) and internal biases (self-censorship) in order to train five\nclassic algorithms and to study the extent to which they do or do not find the\nbest candidates according to objective criteria. In addition, we study the\ninfluence of the anonymisation of files on the quality of predictions.", "published": "2025-05-05 12:24:31", "link": "http://arxiv.org/abs/2505.02609v1", "categories": ["cs.AI", "cs.CY", "stat.AP", "stat.ME"], "primary_category": "cs.AI"}
{"title": "Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem", "abstract": "The AI alignment problem, which focusses on ensuring that artificial\nintelligence (AI), including AGI and ASI, systems act according to human\nvalues, presents profound challenges. With the progression from narrow AI to\nArtificial General Intelligence (AGI) and Superintelligence, fears about\ncontrol and existential risk have escalated. This paper demonstrates that\nachieving complete alignment is inherently unattainable due to mathematical\nprinciples rooted in the foundations of predicate logic and computability, in\nparticular Turing's computational universality, G\\\"odel's incompleteness and\nChaitin's randomness. Instead, we argue that embracing AI misalignment or\nagent's `neurodivergence' as a contingent strategy, defined as fostering a\ndynamic ecosystem of competing, partially aligned agents, is a possible only\nviable path to mitigate risks. Through mathematical proofs and an experimental\ndesign, we explore how misalignment may serve and should be promoted as a\ncounterbalancing mechanism to team up with whichever agents are most aligned AI\nto human values, ensuring that no single system dominates destructively. The\nmain premise of our contribution is that misalignment is inevitable because\nfull AI-human alignment is a mathematical impossibility from Turing-complete\nsystems which we also prove in this paper, a feature then inherited to AGI and\nASI systems. We introduce and test `change-of-opinion' attacks based on this\nkind of perturbation and intervention analysis to study how agents may\nneutralise friendly or unfriendly AIs through cooperation, competition or\nmalice.", "published": "2025-05-05 11:33:18", "link": "http://arxiv.org/abs/2505.02581v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning", "abstract": "Reasoning tasks are crucial in many domains, especially in science and\nengineering. Although large language models (LLMs) have made progress in\nreasoning tasks using techniques such as chain-of-thought and least-to-most\nprompting, these approaches still do not effectively scale to complex problems\nin either their performance or execution time. Moreover, they often require\nadditional supervision for each new task, such as in-context examples. In this\nwork, we introduce Recursive Decomposition with Dependencies (RDD), a scalable\ndivide-and-conquer method for solving reasoning problems that requires less\nsupervision than prior approaches. Our method can be directly applied to a new\nproblem class even in the absence of any task-specific guidance. Furthermore,\nRDD supports sub-task dependencies, allowing for ordered execution of\nsub-tasks, as well as an error recovery mechanism that can correct mistakes\nmade in previous steps. We evaluate our approach on two benchmarks with six\ndifficulty levels each and in two in-context settings: one with task-specific\nexamples and one without. Our results demonstrate that RDD outperforms other\nmethods in a compute-matched setting as task complexity increases, while also\nbeing more computationally efficient.", "published": "2025-05-05 11:24:20", "link": "http://arxiv.org/abs/2505.02576v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Rethinking Federated Graph Learning: A Data Condensation Perspective", "abstract": "Federated graph learning is a widely recognized technique that promotes\ncollaborative training of graph neural networks (GNNs) by multi-client\ngraphs.However, existing approaches heavily rely on the communication of model\nparameters or gradients for federated optimization and fail to adequately\naddress the data heterogeneity introduced by intricate and diverse graph\ndistributions. Although some methods attempt to share additional messages among\nthe server and clients to improve federated convergence during communication,\nthey introduce significant privacy risks and increase communication overhead.\nTo address these issues, we introduce the concept of a condensed graph as a\nnovel optimization carrier to address FGL data heterogeneity and propose a new\nFGL paradigm called FedGM. Specifically, we utilize a generalized condensation\ngraph consensus to aggregate comprehensive knowledge from distributed graphs,\nwhile minimizing communication costs and privacy risks through a single\ntransmission of the condensed data. Extensive experiments on six public\ndatasets consistently demonstrate the superiority of FedGM over\nstate-of-the-art baselines, highlighting its potential for a novel FGL\nparadigm.", "published": "2025-05-05 11:23:29", "link": "http://arxiv.org/abs/2505.02573v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Robustness questions the interpretability of graph neural networks: what to do?", "abstract": "Graph Neural Networks (GNNs) have become a cornerstone in graph-based data\nanalysis, with applications in diverse domains such as bioinformatics, social\nnetworks, and recommendation systems. However, the interplay between model\ninterpretability and robustness remains poorly understood, especially under\nadversarial scenarios like poisoning and evasion attacks. This paper presents a\ncomprehensive benchmark to systematically analyze the impact of various factors\non the interpretability of GNNs, including the influence of\nrobustness-enhancing defense mechanisms.\n  We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT across\nfive datasets from two distinct domains, employing four interpretability\nmetrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines how\ndefenses against poisoning and evasion attacks, applied before and during model\ntraining, affect interpretability and highlights critical trade-offs between\nrobustness and interpretability. The framework will be published as open\nsource.\n  The results reveal significant variations in interpretability depending on\nthe chosen defense methods and model architecture characteristics. By\nestablishing a standardized benchmark, this work provides a foundation for\ndeveloping GNNs that are both robust to adversarial threats and interpretable,\nfacilitating trust in their deployment in sensitive applications.", "published": "2025-05-05 11:14:56", "link": "http://arxiv.org/abs/2505.02566v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Lazy But Effective: Collaborative Personalized Federated Learning with Heterogeneous Data", "abstract": "In Federated Learning, heterogeneity in client data distributions often means\nthat a single global model does not have the best performance for individual\nclients. Consider for example training a next-word prediction model for\nkeyboards: user-specific language patterns due to demographics (dialect, age,\netc.), language proficiency, and writing style result in a highly non-IID\ndataset across clients. Other examples are medical images taken with different\nmachines, or driving data from different vehicle types. To address this, we\npropose a simple yet effective personalized federated learning framework\n(pFedLIA) that utilizes a computationally efficient influence approximation,\ncalled `Lazy Influence', to cluster clients in a distributed manner before\nmodel aggregation. Within each cluster, data owners collaborate to jointly\ntrain a model that captures the specific data patterns of the clients. Our\nmethod has been shown to successfully recover the global model's performance\ndrop due to the non-IID-ness in various synthetic and real-world settings,\nspecifically a next-word prediction task on the Nordic languages as well as\nseveral benchmark tasks. It matches the performance of a hypothetical Oracle\nclustering, and significantly improves on existing baselines, e.g., an\nimprovement of 17% on CIFAR100.", "published": "2025-05-05 10:26:35", "link": "http://arxiv.org/abs/2505.02540v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Advancing Constrained Monotonic Neural Networks: Achieving Universal Approximation Beyond Bounded Activations", "abstract": "Conventional techniques for imposing monotonicity in MLPs by construction\ninvolve the use of non-negative weight constraints and bounded activation\nfunctions, which pose well-known optimization challenges. In this work, we\ngeneralize previous theoretical results, showing that MLPs with non-negative\nweight constraint and activations that saturate on alternating sides are\nuniversal approximators for monotonic functions. Additionally, we show an\nequivalence between the saturation side in the activations and the sign of the\nweight constraint. This connection allows us to prove that MLPs with convex\nmonotone activations and non-positive constrained weights also qualify as\nuniversal approximators, in contrast to their non-negative constrained\ncounterparts. Our results provide theoretical grounding to the empirical\neffectiveness observed in previous works while leading to possible\narchitectural simplification. Moreover, to further alleviate the optimization\ndifficulties, we propose an alternative formulation that allows the network to\nadjust its activations according to the sign of the weights. This eliminates\nthe requirement for weight reparameterization, easing initialization and\nimproving training stability. Experimental evaluation reinforces the validity\nof the theoretical results, showing that our novel approach compares favourably\nto traditional monotonic architectures.", "published": "2025-05-05 10:18:48", "link": "http://arxiv.org/abs/2505.02537v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Large Language Model Partitioning for Low-Latency Inference at the Edge", "abstract": "Large Language Models (LLMs) based on autoregressive, decoder-only\nTransformers generate text one token at a time, where a token represents a\ndiscrete unit of text. As each newly produced token is appended to the partial\noutput sequence, the length grows and so does the memory and compute load, due\nto the expanding key-value caches, which store intermediate representations of\nall previously generated tokens in the multi-head attention (MHA) layer. As\nthis iterative process steadily increases memory and compute demands,\nlayer-based partitioning in resource-constrained edge environments often\nresults in memory overload or high inference latency. To address this and\nreduce inference latency, we propose a resource-aware Transformer architecture\npartitioning algorithm, where the partitioning decision is updated at regular\nintervals during token generation. The approach is myopic in that it is based\non instantaneous information about device resource availability and network\nlink bandwidths. When first executed, the algorithm places blocks on devices,\nand in later executions, it migrates these blocks among devices so that the sum\nof migration delay and inference delay remains low. Our approach partitions the\ndecoder at the attention head level, co-locating each attention head with its\nkey-value cache and allowing dynamic migrations whenever resources become\ntight. By allocating different attention heads to different devices, we exploit\nparallel execution of attention heads and thus achieve substantial reductions\nin inference delays. Our experiments show that in small-scale settings (3-5\ndevices), the proposed method achieves within 15 to 20 percent of an exact\noptimal solver's latency, while in larger-scale tests it achieves notable\nimprovements in inference speed and memory usage compared to state-of-the-art\nlayer-based partitioning approaches.", "published": "2025-05-05 10:16:16", "link": "http://arxiv.org/abs/2505.02533v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Machine-Learning-Powered Neural Interfaces for Smart Prosthetics and Diagnostics", "abstract": "Advanced neural interfaces are transforming applications ranging from\nneuroscience research to diagnostic tools (for mental state recognition, tremor\nand seizure detection) as well as prosthetic devices (for motor and\ncommunication recovery). By integrating complex functions into miniaturized\nneural devices, these systems unlock significant opportunities for personalized\nassistive technologies and adaptive therapeutic interventions. Leveraging\nhigh-density neural recordings, on-site signal processing, and machine learning\n(ML), these interfaces extract critical features, identify disease\nneuro-markers, and enable accurate, low-latency neural decoding. This\nintegration facilitates real-time interpretation of neural signals, adaptive\nmodulation of brain activity, and efficient control of assistive devices.\nMoreover, the synergy between neural interfaces and ML has paved the way for\nself-sufficient, ubiquitous platforms capable of operating in diverse\nenvironments with minimal hardware costs and external dependencies. In this\nwork, we review recent advancements in AI-driven decoding algorithms and\nenergy-efficient System-on-Chip (SoC) platforms for next-generation\nminiaturized neural devices. These innovations highlight the potential for\ndeveloping intelligent neural interfaces, addressing critical challenges in\nscalability, reliability, interpretability, and user adaptability.", "published": "2025-05-05 09:49:13", "link": "http://arxiv.org/abs/2505.02516v1", "categories": ["cs.AI", "cs.AR", "cs.LG", "eess.SP", "q-bio.NC", "I.2.0; B.7.0; I.5.1; C.3"], "primary_category": "cs.AI"}
{"title": "Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study", "abstract": "Background: Large language models (LLMs) are increasingly deployed via\nopen-source and commercial frameworks, enabling individuals and organizations\nto self-host advanced AI capabilities. However, insecure defaults and\nmisconfigurations often expose LLM services to the public Internet, posing\nsignificant security and system engineering risks. Aims: This study aims to\nunveil the current landscape of public-facing LLM deployments in the wild\nthrough a large-scale empirical study, focusing on service prevalence, exposure\ncharacteristics, systemic vulnerabilities, and associated risks. Method: We\nconducted an Internet-wide measurement to identify public-facing LLM\ndeployments across 15 frameworks, discovering 320,102 services. We extracted\n158 unique API endpoints, grouped into 12 functional categories based on\ncapabilities and security risks. We further analyzed configurations,\nauthentication practices, and geographic distributions, revealing deployment\ntrends and systemic issues in real-world LLM system engineering. Results: Our\nstudy shows that public LLM deployments are rapidly growing but often insecure.\nAmong all endpoints, we observe widespread use of insecure protocols, poor TLS\nconfigurations, and unauthenticated access to critical operations. Security\nrisks, including model disclosure, system leakage, and unauthorized access, are\npervasive, highlighting the need for secure-by-default frameworks and stronger\ndeployment practices. Conclusions: Public-facing LLM deployments suffer from\nwidespread security and configuration flaws, exposing services to misuse, model\ntheft, resource hijacking, and remote exploitation. Strengthening default\nsecurity, deployment practices, and operational standards is critical for the\ngrowing self-hosted LLM ecosystem.", "published": "2025-05-05 09:30:19", "link": "http://arxiv.org/abs/2505.02502v1", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Corr2Distrib: Making Ambiguous Correspondences an Ally to Predict Reliable 6D Pose Distributions", "abstract": "We introduce Corr2Distrib, the first correspondence-based method which\nestimates a 6D camera pose distribution from an RGB image, explaining the\nobservations. Indeed, symmetries and occlusions introduce visual ambiguities,\nleading to multiple valid poses. While a few recent methods tackle this\nproblem, they do not rely on local correspondences which, according to the BOP\nChallenge, are currently the most effective way to estimate a single 6DoF pose\nsolution. Using correspondences to estimate a pose distribution is not\nstraightforward, since ambiguous correspondences induced by visual ambiguities\ndrastically decrease the performance of PnP. With Corr2Distrib, we turn these\nambiguities into an advantage to recover all valid poses. Corr2Distrib first\nlearns a symmetry-aware representation for each 3D point on the object's\nsurface, characterized by a descriptor and a local frame. This representation\nenables the generation of 3DoF rotation hypotheses from single 2D-3D\ncorrespondences. Next, we refine these hypotheses into a 6DoF pose distribution\nusing PnP and pose scoring. Our experimental evaluations on complex\nnon-synthetic scenes show that Corr2Distrib outperforms state-of-the-art\nsolutions for both pose distribution estimation and single pose estimation from\nan RGB image, demonstrating the potential of correspondences-based approaches.", "published": "2025-05-05 09:29:32", "link": "http://arxiv.org/abs/2505.02501v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Beyond the model: Key differentiators in large language models and multi-agent services", "abstract": "With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, it\nhas become evident that large language models (LLMs) are no longer the sole\ndefining factor in generative AI. As many now operate at comparable levels of\ncapability, the real race is not about having the biggest model but optimizing\nthe surrounding ecosystem, including data quality and management, computational\nefficiency, latency, and evaluation frameworks. This review article delves into\nthese critical differentiators that ensure modern AI services are efficient and\nprofitable.", "published": "2025-05-05 09:15:31", "link": "http://arxiv.org/abs/2505.02489v1", "categories": ["cs.AI", "cs.ET", "cs.MA", "cs.SE"], "primary_category": "cs.AI"}
{"title": "SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning", "abstract": "Multimodal Continual Instruction Tuning (MCIT) aims to enable Multimodal\nLarge Language Models (MLLMs) to incrementally learn new tasks without\ncatastrophic forgetting. In this paper, we explore forgetting in this context,\ncategorizing it into superficial forgetting and essential forgetting.\nSuperficial forgetting refers to cases where the model's knowledge may not be\ngenuinely lost, but its responses to previous tasks deviate from expected\nformats due to the influence of subsequent tasks' answer styles, making the\nresults unusable. By contrast, essential forgetting refers to situations where\nthe model provides correctly formatted but factually inaccurate answers,\nindicating a true loss of knowledge. Assessing essential forgetting\nnecessitates addressing superficial forgetting first, as severe superficial\nforgetting can obscure the model's knowledge state. Hence, we first introduce\nthe Answer Style Diversification (ASD) paradigm, which defines a standardized\nprocess for transforming data styles across different tasks, unifying their\ntraining sets into similarly diversified styles to prevent superficial\nforgetting caused by style shifts. Building on this, we propose RegLoRA to\nmitigate essential forgetting. RegLoRA stabilizes key parameters where prior\nknowledge is primarily stored by applying regularization, enabling the model to\nretain existing competencies. Experimental results demonstrate that our overall\nmethod, SEFE, achieves state-of-the-art performance.", "published": "2025-05-05 09:09:41", "link": "http://arxiv.org/abs/2505.02486v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Integrating Column Generation and Large Neighborhood Search for Bus Driver Scheduling with Complex Break Constraints", "abstract": "The Bus Driver Scheduling Problem (BDSP) is a combinatorial optimization\nproblem with the goal to design shifts to cover prearranged bus tours. The\nobjective takes into account the operational cost as well as the satisfaction\nof drivers. This problem is heavily constrained due to strict legal rules and\ncollective agreements. The objective of this article is to provide\nstate-of-the-art exact and hybrid solution methods that can provide\nhigh-quality solutions for instances of different sizes. This work presents a\ncomprehensive study of both an exact method, Branch and Price (B&P), as well as\na Large Neighborhood Search (LNS) framework which uses B&P or Column Generation\n(CG) for the repair phase to solve the BDSP. It further proposes and evaluates\na novel deeper integration of B&P and LNS, storing the generated columns from\nthe LNS subproblems and reusing them for other subproblems, or to find better\nglobal solutions. The article presents a detailed analysis of several\ncomponents of the solution methods and their impact, including general\nimprovements for the B&P subproblem, which is a high-dimensional Resource\nConstrained Shortest Path Problem (RCSPP), and the components of the LNS. The\nevaluation shows that our approach provides new state-of-the-art results for\ninstances of all sizes, including exact solutions for small instances, and low\ngaps to a known lower bound for mid-sized instances. Conclusions: We observe\nthat B&P provides the best results for small instances, while the tight\nintegration of LNS and CG can provide high-quality solutions for larger\ninstances, further improving over LNS which just uses CG as a black box. The\nproposed methods are general and can also be applied to other rule sets and\nrelated optimization problems", "published": "2025-05-05 09:08:25", "link": "http://arxiv.org/abs/2505.02485v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "El Agente: An Autonomous Agent for Quantum Chemistry", "abstract": "Computational chemistry tools are widely used to study the behaviour of\nchemical phenomena. Yet, the complexity of these tools can make them\ninaccessible to non-specialists and challenging even for experts. In this work,\nwe introduce El Agente Q, an LLM-based multi-agent system that dynamically\ngenerates and executes quantum chemistry workflows from natural language user\nprompts. The system is built on a novel cognitive architecture featuring a\nhierarchical memory framework that enables flexible task decomposition,\nadaptive tool selection, post-analysis, and autonomous file handling and\nsubmission. El Agente Q is benchmarked on six university-level course exercises\nand two case studies, demonstrating robust problem-solving performance\n(averaging >87% task success) and adaptive error handling through in situ\ndebugging. It also supports longer-term, multi-step task execution for more\ncomplex workflows, while maintaining transparency through detailed action trace\nlogs. Together, these capabilities lay the foundation for increasingly\nautonomous and accessible quantum chemistry.", "published": "2025-05-05 09:07:22", "link": "http://arxiv.org/abs/2505.02484v1", "categories": ["cs.AI", "cs.LG", "cs.MA", "physics.chem-ph"], "primary_category": "cs.AI"}
{"title": "Automated Hybrid Reward Scheduling via Large Language Models for Robotic Skill Learning", "abstract": "Enabling a high-degree-of-freedom robot to learn specific skills is a\nchallenging task due to the complexity of robotic dynamics. Reinforcement\nlearning (RL) has emerged as a promising solution; however, addressing such\nproblems requires the design of multiple reward functions to account for\nvarious constraints in robotic motion. Existing approaches typically sum all\nreward components indiscriminately to optimize the RL value function and\npolicy. We argue that this uniform inclusion of all reward components in policy\noptimization is inefficient and limits the robot's learning performance. To\naddress this, we propose an Automated Hybrid Reward Scheduling (AHRS) framework\nbased on Large Language Models (LLMs). This paradigm dynamically adjusts the\nlearning intensity of each reward component throughout the policy optimization\nprocess, enabling robots to acquire skills in a gradual and structured manner.\nSpecifically, we design a multi-branch value network, where each branch\ncorresponds to a distinct reward component. During policy optimization, each\nbranch is assigned a weight that reflects its importance, and these weights are\nautomatically computed based on rules designed by LLMs. The LLM generates a\nrule set in advance, derived from the task description, and during training, it\nselects a weight calculation rule from the library based on language prompts\nthat evaluate the performance of each branch. Experimental results demonstrate\nthat the AHRS method achieves an average 6.48% performance improvement across\nmultiple high-degree-of-freedom robotic tasks.", "published": "2025-05-05 09:06:17", "link": "http://arxiv.org/abs/2505.02483v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Timing Is Everything: Finding the Optimal Fusion Points in Multimodal Medical Imaging", "abstract": "Multimodal deep learning harnesses diverse imaging modalities, such as MRI\nsequences, to enhance diagnostic accuracy in medical imaging. A key challenge\nis determining the optimal timing for integrating these\nmodalities-specifically, identifying the network layers where fusion modules\nshould be inserted. Current approaches often rely on manual tuning or\nexhaustive search, which are computationally expensive without any guarantee of\nconverging to optimal results. We propose a sequential forward search algorithm\nthat incrementally activates and evaluates candidate fusion modules at\ndifferent layers of a multimodal network. At each step, the algorithm retrains\nfrom previously learned weights and compares validation loss to identify the\nbest-performing configuration. This process systematically reduces the search\nspace, enabling efficient identification of the optimal fusion timing without\nexhaustively testing all possible module placements. The approach is validated\non two multimodal MRI datasets, each addressing different classification tasks.\nOur algorithm consistently identified configurations that outperformed unimodal\nbaselines, late fusion, and a brute-force ensemble of all potential fusion\nplacements. These architectures demonstrated superior accuracy, F-score, and\nspecificity while maintaining competitive or improved AUC values. Furthermore,\nthe sequential nature of the search significantly reduced computational\noverhead, making the optimization process more practical. By systematically\ndetermining the optimal timing to fuse imaging modalities, our method advances\nmultimodal deep learning for medical imaging. It provides an efficient and\nrobust framework for fusion optimization, paving the way for improved clinical\ndecision-making and more adaptable, scalable architectures in medical AI\napplications.", "published": "2025-05-05 08:53:21", "link": "http://arxiv.org/abs/2505.02467v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Investigating the Impact of Personalized AI Tutors on Language Learning Performance", "abstract": "Driven by the global shift towards online learning prompted by the COVID 19\npandemic, Artificial Intelligence has emerged as a pivotal player in the field\nof education. Intelligent Tutoring Systems offer a new method of personalized\nteaching, replacing the limitations of traditional teaching methods. However,\nconcerns arise about the ability of AI tutors to address skill development and\nengagement during the learning process. In this paper, I will conduct a quasi\nexperiment with paired sample t test on 34 students pre and post use of AI\ntutors in language learning platforms like Santa and Duolingo to examine the\nrelationship between students engagement, academic performance, and students\nsatisfaction during a personalized language learning experience.", "published": "2025-05-05 08:11:20", "link": "http://arxiv.org/abs/2505.02443v1", "categories": ["cs.AI", "cs.HC", "I.2.6; K.3.1"], "primary_category": "cs.AI"}
{"title": "MSFNet-CPD: Multi-Scale Cross-Modal Fusion Network for Crop Pest Detection", "abstract": "Accurate identification of agricultural pests is essential for crop\nprotection but remains challenging due to the large intra-class variance and\nfine-grained differences among pest species. While deep learning has advanced\npest detection, most existing approaches rely solely on low-level visual\nfeatures and lack effective multi-modal integration, leading to limited\naccuracy and poor interpretability. Moreover, the scarcity of high-quality\nmulti-modal agricultural datasets further restricts progress in this field. To\naddress these issues, we construct two novel multi-modal benchmarks-CTIP102 and\nSTIP102-based on the widely-used IP102 dataset, and introduce a Multi-scale\nCross-Modal Fusion Network (MSFNet-CPD) for robust pest detection. Our approach\nenhances visual quality via a super-resolution reconstruction module, and feeds\nboth the original and reconstructed images into the network to improve clarity\nand detection performance. To better exploit semantic cues, we propose an\nImage-Text Fusion (ITF) module for joint modeling of visual and textual\nfeatures, and an Image-Text Converter (ITC) that reconstructs fine-grained\ndetails across multiple scales to handle challenging backgrounds. Furthermore,\nwe introduce an Arbitrary Combination Image Enhancement (ACIE) strategy to\ngenerate a more complex and diverse pest detection dataset, MTIP102, improving\nthe model's generalization to real-world scenarios. Extensive experiments\ndemonstrate that MSFNet-CPD consistently outperforms state-of-the-art methods\non multiple pest detection benchmarks. All code and datasets will be made\npublicly available at: https://github.com/Healer-ML/MSFNet-CPD.", "published": "2025-05-05 08:10:22", "link": "http://arxiv.org/abs/2505.02441v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ReeM: Ensemble Building Thermodynamics Model for Efficient HVAC Control via Hierarchical Reinforcement Learning", "abstract": "The building thermodynamics model, which predicts real-time indoor\ntemperature changes under potential HVAC (Heating, Ventilation, and Air\nConditioning) control operations, is crucial for optimizing HVAC control in\nbuildings. While pioneering studies have attempted to develop such models for\nvarious building environments, these models often require extensive data\ncollection periods and rely heavily on expert knowledge, making the modeling\nprocess inefficient and limiting the reusability of the models. This paper\nexplores a model ensemble perspective that utilizes existing developed models\nas base models to serve a target building environment, thereby providing\naccurate predictions while reducing the associated efforts. Given that building\ndata streams are non-stationary and the number of base models may increase, we\npropose a Hierarchical Reinforcement Learning (HRL) approach to dynamically\nselect and weight the base models. Our approach employs a two-tiered\ndecision-making process: the high-level focuses on model selection, while the\nlow-level determines the weights of the selected models. We thoroughly evaluate\nthe proposed approach through offline experiments and an on-site case study,\nand the experimental results demonstrate the effectiveness of our method.", "published": "2025-05-05 08:09:36", "link": "http://arxiv.org/abs/2505.02439v1", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "A New Approach to Backtracking Counterfactual Explanations: A Causal Framework for Efficient Model Interpretability", "abstract": "Counterfactual explanations enhance interpretability by identifying\nalternative inputs that produce different outputs, offering localized insights\ninto model decisions. However, traditional methods often neglect causal\nrelationships, leading to unrealistic examples. While newer approaches\nintegrate causality, they are computationally expensive. To address these\nchallenges, we propose an efficient method based on backtracking\ncounterfactuals that incorporates causal reasoning to generate actionable\nexplanations. We first examine the limitations of existing methods and then\nintroduce our novel approach and its features. We also explore the relationship\nbetween our method and previous techniques, demonstrating that it generalizes\nthem in specific scenarios. Finally, experiments show that our method provides\ndeeper insights into model outputs.", "published": "2025-05-05 08:01:56", "link": "http://arxiv.org/abs/2505.02435v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "FairPO: Robust Preference Optimization for Fair Multi-Label Learning", "abstract": "We propose FairPO, a novel framework designed to promote fairness in\nmulti-label classification by directly optimizing preference signals with a\ngroup robustness perspective. In our framework, the set of labels is\npartitioned into privileged and non-privileged groups, and a preference-based\nloss inspired by Direct Preference Optimization (DPO) is employed to more\neffectively differentiate true positive labels from confusing negatives within\nthe privileged group, while preserving baseline classification performance for\nnon-privileged labels. By framing the learning problem as a robust optimization\nover groups, our approach dynamically adjusts the training emphasis toward\ngroups with poorer performance, thereby mitigating bias and ensuring a fairer\ntreatment across diverse label categories. In addition, we outline plans to\nextend this approach by investigating alternative loss formulations such as\nSimple Preference Optimisation (SimPO) and Contrastive Preference Optimization\n(CPO) to exploit reference-free reward formulations and contrastive training\nsignals. Furthermore, we plan to extend FairPO with multilabel generation\ncapabilities, enabling the model to dynamically generate diverse and coherent\nlabel sets for ambiguous inputs.", "published": "2025-05-05 07:58:54", "link": "http://arxiv.org/abs/2505.02433v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards One-shot Federated Learning: Advances, Challenges, and Future Directions", "abstract": "One-shot FL enables collaborative training in a single round, eliminating the\nneed for iterative communication, making it particularly suitable for use in\nresource-constrained and privacy-sensitive applications. This survey offers a\nthorough examination of One-shot FL, highlighting its distinct operational\nframework compared to traditional federated approaches. One-shot FL supports\nresource-limited devices by enabling single-round model aggregation while\nmaintaining data locality. The survey systematically categorizes existing\nmethodologies, emphasizing advancements in client model initialization,\naggregation techniques, and strategies for managing heterogeneous data\ndistributions. Furthermore, we analyze the limitations of current approaches,\nparticularly in terms of scalability and generalization in non-IID settings. By\nanalyzing cutting-edge techniques and outlining open challenges, this survey\naspires to provide a comprehensive reference for researchers and practitioners\naiming to design and implement One-shot FL systems, advancing the development\nand adoption of One-shot FL solutions in a real-world, resource-constrained\nscenario.", "published": "2025-05-05 07:46:21", "link": "http://arxiv.org/abs/2505.02426v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models", "abstract": "Text-to-Time Series generation holds significant potential to address\nchallenges such as data sparsity, imbalance, and limited availability of\nmultimodal time series datasets across domains. While diffusion models have\nachieved remarkable success in Text-to-X (e.g., vision and audio data)\ngeneration, their use in time series generation remains in its nascent stages.\nExisting approaches face two critical limitations: (1) the lack of systematic\nexploration of general-proposed time series captions, which are often\ndomain-specific and struggle with generalization; and (2) the inability to\ngenerate time series of arbitrary lengths, limiting their applicability to\nreal-world scenarios. In this work, we first categorize time series captions\ninto three levels: point-level, fragment-level, and instance-level.\nAdditionally, we introduce a new fragment-level dataset containing over 600,000\nhigh-resolution time series-text pairs. Second, we propose Text-to-Series\n(T2S), a diffusion-based framework that bridges the gap between natural\nlanguage and time series in a domain-agnostic manner. T2S employs a\nlength-adaptive variational autoencoder to encode time series of varying\nlengths into consistent latent embeddings. On top of that, T2S effectively\naligns textual representations with latent embeddings by utilizing Flow\nMatching and employing Diffusion Transformer as the denoiser. We train T2S in\nan interleaved paradigm across multiple lengths, allowing it to generate\nsequences of any desired length. Extensive evaluations demonstrate that T2S\nachieves state-of-the-art performance across 13 datasets spanning 12 domains.", "published": "2025-05-05 07:22:54", "link": "http://arxiv.org/abs/2505.02417v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Task-Oriented Semantic Communication in Large Multimodal Models-based Vehicle Networks", "abstract": "Task-oriented semantic communication has emerged as a fundamental approach\nfor enhancing performance in various communication scenarios. While recent\nadvances in Generative Artificial Intelligence (GenAI), such as Large Language\nModels (LLMs), have been applied to semantic communication designs, the\npotential of Large Multimodal Models (LMMs) remains largely unexplored. In this\npaper, we investigate an LMM-based vehicle AI assistant using a Large Language\nand Vision Assistant (LLaVA) and propose a task-oriented semantic communication\nframework to facilitate efficient interaction between users and cloud servers.\nTo reduce computational demands and shorten response time, we optimize LLaVA's\nimage slicing to selectively focus on areas of utmost interest to users.\nAdditionally, we assess the importance of image patches by combining objective\nand subjective user attention, adjusting energy usage for transmitting semantic\ninformation. This strategy optimizes resource utilization, ensuring precise\ntransmission of critical information. We construct a Visual Question Answering\n(VQA) dataset for traffic scenarios to evaluate effectiveness. Experimental\nresults show that our semantic communication framework significantly increases\naccuracy in answering questions under the same channel conditions, performing\nparticularly well in environments with poor Signal-to-Noise Ratios (SNR).\nAccuracy can be improved by 13.4% at an SNR of 12dB and 33.1% at 10dB,\nrespectively.", "published": "2025-05-05 07:18:47", "link": "http://arxiv.org/abs/2505.02413v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Diagnostic Uncertainty in Pneumonia Detection using CNN MobileNetV2 and CNN from Scratch", "abstract": "Pneumonia Diagnosis, though it is crucial for an effective treatment, it can\nbe hampered by uncertainty. This uncertainty starts to arise due to some\nfactors like atypical presentations, limitations of diagnostic tools such as\nchest X-rays, and the presence of co-existing respiratory conditions. This\nresearch proposes one of the supervised learning methods, CNN. Using\nMobileNetV2 as the pre-trained one with ResNet101V2 architecture and using\nKeras API as the built from scratch model, for identifying lung diseases\nespecially pneumonia. The datasets used in this research were obtained from the\nwebsite through Kaggle. The result shows that by implementing CNN MobileNetV2\nand CNN from scratch the result is promising. While validating data,\nMobileNetV2 performs with stability and minimal overfitting, while the training\naccuracy increased to 84.87% later it slightly decreased to 78.95%, with\nincreasing validation loss from 0.499 to 0.6345. Nonetheless, MobileNetV2 is\nmore stable. Although it takes more time to train each epoch. Meanwhile, after\nthe 10th epoch, the Scratch model displayed more instability and overfitting\ndespite having higher validation accuracy, training accuracy decreased\nsignificantly to 78.12% and the validation loss increased from 0.5698 to\n1.1809. With these results, ResNet101V2 offers stability, and the Scratch model\noffers high accuracy.", "published": "2025-05-05 06:40:08", "link": "http://arxiv.org/abs/2505.02396v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Quantitative Analysis of Performance Drop in DeepSeek Model Quantization", "abstract": "Recently, there is a high demand for deploying DeepSeek-R1 and V3 locally,\npossibly because the official service often suffers from being busy and some\norganizations have data privacy concerns. While single-machine deployment\noffers infrastructure simplicity, the models' 671B FP8 parameter configuration\nexceeds the practical memory limits of a standard 8-GPU machine. Quantization\nis a widely used technique that helps reduce model memory consumption. However,\nit is unclear what the performance of DeepSeek-R1 and V3 will be after being\nquantized. This technical report presents the first quantitative evaluation of\nmulti-bitwidth quantization across the complete DeepSeek model spectrum. Key\nfindings reveal that 4-bit quantization maintains little performance\ndegradation versus FP8 while enabling single-machine deployment on standard\nNVIDIA GPU devices. We further propose DQ3_K_M, a dynamic 3-bit quantization\nmethod that significantly outperforms traditional Q3_K_M variant on various\nbenchmarks, which is also comparable with 4-bit quantization (Q4_K_M) approach\nin most tasks. Moreover, DQ3_K_M supports single-machine deployment\nconfigurations for both NVIDIA H100/A100 and Huawei 910B. Our implementation of\nDQ3\\_K\\_M is released at https://github.com/UnicomAI/DeepSeek-Eval, containing\noptimized 3-bit quantized variants of both DeepSeek-R1 and DeepSeek-V3.", "published": "2025-05-05 06:25:20", "link": "http://arxiv.org/abs/2505.02390v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans", "abstract": "Embodied AI (EAI) research requires high-quality, diverse 3D scenes to\neffectively support skill acquisition, sim-to-real transfer, and\ngeneralization. Achieving these quality standards, however, necessitates the\nprecise replication of real-world object diversity. Existing datasets\ndemonstrate that this process heavily relies on artist-driven designs, which\ndemand substantial human effort and present significant scalability challenges.\nTo scalably produce realistic and interactive 3D scenes, we first present\nMetaScenes, a large-scale, simulatable 3D scene dataset constructed from\nreal-world scans, which includes 15366 objects spanning 831 fine-grained\ncategories. Then, we introduce Scan2Sim, a robust multi-modal alignment model,\nwhich enables the automated, high-quality replacement of assets, thereby\neliminating the reliance on artist-driven designs for scaling 3D scenes. We\nfurther propose two benchmarks to evaluate MetaScenes: a detailed scene\nsynthesis task focused on small item layouts for robotic manipulation and a\ndomain transfer task in vision-and-language navigation (VLN) to validate\ncross-domain transfer. Results confirm MetaScene's potential to enhance EAI by\nsupporting more generalizable agent learning and sim-to-real applications,\nintroducing new possibilities for EAI research. Project website:\nhttps://meta-scenes.github.io/.", "published": "2025-05-05 06:13:25", "link": "http://arxiv.org/abs/2505.02388v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing", "abstract": "Due to the challenges of manually collecting accurate editing data, existing\ndatasets are typically constructed using various automated methods, leading to\nnoisy supervision signals caused by the mismatch between editing instructions\nand original-edited image pairs. Recent efforts attempt to improve editing\nmodels through generating higher-quality edited images, pre-training on\nrecognition tasks, or introducing vision-language models (VLMs) but fail to\nresolve this fundamental issue. In this paper, we offer a novel solution by\nconstructing more effective editing instructions for given image pairs. This\nincludes rectifying the editing instructions to better align with the\noriginal-edited image pairs and using contrastive editing instructions to\nfurther enhance their effectiveness. Specifically, we find that editing models\nexhibit specific generation attributes at different inference steps,\nindependent of the text. Based on these prior attributes, we define a unified\nguide for VLMs to rectify editing instructions. However, there are some\nchallenging editing scenarios that cannot be resolved solely with rectified\ninstructions. To this end, we further construct contrastive supervision signals\nwith positive and negative instructions and introduce them into the model\ntraining using triplet loss, thereby further facilitating supervision\neffectiveness. Our method does not require the VLM modules or pre-training\ntasks used in previous work, offering a more direct and efficient way to\nprovide better supervision signals, and providing a novel, simple, and\neffective solution for instruction-based image editing. Results on multiple\nbenchmarks demonstrate that our method significantly outperforms existing\napproaches. Compared with previous SOTA SmartEdit, we achieve 9.19%\nimprovements on the Real-Edit benchmark with 30x less training data and 13x\nsmaller model size.", "published": "2025-05-05 05:19:40", "link": "http://arxiv.org/abs/2505.02370v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks", "abstract": "Generalizing well in deep neural networks remains a core challenge,\nparticularly due to their tendency to converge to sharp minima that degrade\nrobustness. Sharpness-Aware Minimization (SAM) mitigates this by seeking\nflatter minima but perturbs parameters using the full gradient, which can\ninclude statistically insignificant directions. We propose ZSharp, a simple yet\neffective extension to SAM that applies layer-wise Z-score normalization\nfollowed by percentile-based filtering to retain only statistically significant\ngradient components. This selective perturbation aligns updates with\ncurvature-sensitive directions, enhancing generalization without requiring\narchitectural changes. ZSharp introduces only one additional hyperparameter,\nthe percentile threshold, and remains fully compatible with existing SAM\nvariants. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet using ResNet,\nVGG, and Vision Transformers show that ZSharp consistently outperforms SAM and\nits variants in test accuracy, particularly on deeper and transformer-based\nmodels. These results demonstrate that ZSharp is a principled and lightweight\nimprovement for sharpness-aware optimization.", "published": "2025-05-05 05:13:12", "link": "http://arxiv.org/abs/2505.02369v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "cs.NE", "math.IT"], "primary_category": "cs.LG"}
{"title": "Advancing Email Spam Detection: Leveraging Zero-Shot Learning and Large Language Models", "abstract": "Email spam detection is a critical task in modern communication systems,\nessential for maintaining productivity, security, and user experience.\nTraditional machine learning and deep learning approaches, while effective in\nstatic settings, face significant limitations in adapting to evolving spam\ntactics, addressing class imbalance, and managing data scarcity. These\nchallenges necessitate innovative approaches that reduce dependency on\nextensive labeled datasets and frequent retraining. This study investigates the\neffectiveness of Zero-Shot Learning using FLAN-T5, combined with advanced\nNatural Language Processing (NLP) techniques such as BERT for email spam\ndetection. By employing BERT to preprocess and extract critical information\nfrom email content, and FLAN-T5 to classify emails in a Zero-Shot framework,\nthe proposed approach aims to address the limitations of traditional spam\ndetection systems. The integration of FLAN-T5 and BERT enables robust spam\ndetection without relying on extensive labeled datasets or frequent retraining,\nmaking it highly adaptable to unseen spam patterns and adversarial\nenvironments. This research highlights the potential of leveraging zero-shot\nlearning and NLPs for scalable and efficient spam detection, providing insights\ninto their capability to address the dynamic and challenging nature of spam\ndetection tasks.", "published": "2025-05-05 04:48:20", "link": "http://arxiv.org/abs/2505.02362v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Catastrophic Overfitting, Entropy Gap and Participation Ratio: A Noiseless $l^p$ Norm Solution for Fast Adversarial Training", "abstract": "Adversarial training is a cornerstone of robust deep learning, but fast\nmethods like the Fast Gradient Sign Method (FGSM) often suffer from\nCatastrophic Overfitting (CO), where models become robust to single-step\nattacks but fail against multi-step variants. While existing solutions rely on\nnoise injection, regularization, or gradient clipping, we propose a novel\nsolution that purely controls the $l^p$ training norm to mitigate CO.\n  Our study is motivated by the empirical observation that CO is more prevalent\nunder the $l^{\\infty}$ norm than the $l^2$ norm. Leveraging this insight, we\ndevelop a framework for generalized $l^p$ attack as a fixed point problem and\ncraft $l^p$-FGSM attacks to understand the transition mechanics from $l^2$ to\n$l^{\\infty}$. This leads to our core insight: CO emerges when highly\nconcentrated gradients where information localizes in few dimensions interact\nwith aggressive norm constraints. By quantifying gradient concentration through\nParticipation Ratio and entropy measures, we develop an adaptive $l^p$-FGSM\nthat automatically tunes the training norm based on gradient information.\nExtensive experiments demonstrate that this approach achieves strong robustness\nwithout requiring additional regularization or noise injection, providing a\nnovel and theoretically-principled pathway to mitigate the CO problem.", "published": "2025-05-05 04:41:21", "link": "http://arxiv.org/abs/2505.02360v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Social Biases in Knowledge Representations of Wikidata separates Global North from Global South", "abstract": "Knowledge Graphs have become increasingly popular due to their wide usage in\nvarious downstream applications, including information retrieval, chatbot\ndevelopment, language model construction, and many others. Link prediction (LP)\nis a crucial downstream task for knowledge graphs, as it helps to address the\nproblem of the incompleteness of the knowledge graphs. However, previous\nresearch has shown that knowledge graphs, often created in a (semi) automatic\nmanner, are not free from social biases. These biases can have harmful effects\non downstream applications, especially by leading to unfair behavior toward\nminority groups. To understand this issue in detail, we develop a framework --\nAuditLP -- deploying fairness metrics to identify biased outcomes in LP,\nspecifically how occupations are classified as either male or female-dominated\nbased on gender as a sensitive attribute. We have experimented with the\nsensitive attribute of age and observed that occupations are categorized as\nyoung-biased, old-biased, and age-neutral. We conduct our experiments on a\nlarge number of knowledge triples that belong to 21 different geographies\nextracted from the open-sourced knowledge graph, Wikidata. Our study shows that\nthe variance in the biased outcomes across geographies neatly mirrors the\nsocio-economic and cultural division of the world, resulting in a transparent\npartition of the Global North from the Global South.", "published": "2025-05-05 04:21:12", "link": "http://arxiv.org/abs/2505.02352v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Temporal Robustness in Discrete Time Linear Dynamical Systems", "abstract": "Discrete time linear dynamical systems, including Markov chains, have found\nmany applications. However, in some problems, there is uncertainty about the\ntime horizon for which the system runs. This creates uncertainty about the cost\n(or reward) incurred based on the state distribution when the system stops.\nGiven past data samples of how long a system ran, we propose to theoretically\nanalyze a distributional robust cost estimation task in a Wasserstein ambiguity\nset, instead of learning a probability distribution from a few samples. Towards\nthis, we show an equivalence between a discrete time Markov Chain on a\nprobability simplex and a global asymptotic stable (GAS) discrete time linear\ndynamical system, allowing us to base our study on a GAS system only. Then, we\nprovide various polynomial time algorithms and hardness results for different\ncases in our theoretical study, including a fundamental result about\nWasserstein distance based polytope.", "published": "2025-05-05 04:02:33", "link": "http://arxiv.org/abs/2505.02347v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking", "abstract": "Recent advancements have significantly enhanced the performance of large\nlanguage models (LLMs) in tackling complex reasoning tasks, achieving notable\nsuccess in domains like mathematical and logical reasoning. However, these\nmethods encounter challenges with complex planning tasks, primarily due to\nextended reasoning steps, diverse constraints, and the challenge of handling\nmultiple distinct sub-tasks. To address these challenges, we propose HyperTree\nPlanning (HTP), a novel reasoning paradigm that constructs hypertree-structured\nplanning outlines for effective planning. The hypertree structure enables LLMs\nto engage in hierarchical thinking by flexibly employing the divide-and-conquer\nstrategy, effectively breaking down intricate reasoning steps, accommodating\ndiverse constraints, and managing multiple distinct sub-tasks in a\nwell-organized manner. We further introduce an autonomous planning framework\nthat completes the planning process by iteratively refining and expanding the\nhypertree-structured planning outlines. Experiments demonstrate the\neffectiveness of HTP, achieving state-of-the-art accuracy on the TravelPlanner\nbenchmark with Gemini-1.5-Pro, resulting in a 3.6 times performance improvement\nover o1-preview.", "published": "2025-05-05 02:38:58", "link": "http://arxiv.org/abs/2505.02322v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "NeuroSim V1.5: Improved Software Backbone for Benchmarking Compute-in-Memory Accelerators with Device and Circuit-level Non-idealities", "abstract": "The exponential growth of artificial intelligence (AI) applications has\nexposed the inefficiency of conventional von Neumann architectures, where\nfrequent data transfers between compute units and memory create significant\nenergy and latency bottlenecks. Analog Computing-in-Memory (ACIM) addresses\nthis challenge by performing multiply-accumulate (MAC) operations directly in\nthe memory arrays, substantially reducing data movement. However, designing\nrobust ACIM accelerators requires accurate modeling of device- and\ncircuit-level non-idealities. In this work, we present NeuroSim V1.5,\nintroducing several key advances: (1) seamless integration with TensorRT's\npost-training quantization flow enabling support for more neural networks\nincluding transformers, (2) a flexible noise injection methodology built on\npre-characterized statistical models, making it straightforward to incorporate\ndata from SPICE simulations or silicon measurements, (3) expanded device\nsupport including emerging non-volatile capacitive memories, and (4) up to 6.5x\nfaster runtime than NeuroSim V1.4 through optimized behavioral simulation. The\ncombination of these capabilities uniquely enables systematic design space\nexploration across both accuracy and hardware efficiency metrics. Through\nmultiple case studies, we demonstrate optimization of critical design\nparameters while maintaining network accuracy. By bridging high-fidelity noise\nmodeling with efficient simulation, NeuroSim V1.5 advances the design and\nvalidation of next-generation ACIM accelerators. All NeuroSim versions are\navailable open-source at https://github.com/neurosim/NeuroSim.", "published": "2025-05-05 02:07:04", "link": "http://arxiv.org/abs/2505.02314v1", "categories": ["cs.AR", "cs.AI", "cs.LG"], "primary_category": "cs.AR"}
{"title": "What Is AI Safety? What Do We Want It to Be?", "abstract": "The field of AI safety seeks to prevent or reduce the harms caused by AI\nsystems. A simple and appealing account of what is distinctive of AI safety as\na field holds that this feature is constitutive: a research project falls\nwithin the purview of AI safety just in case it aims to prevent or reduce the\nharms caused by AI systems. Call this appealingly simple account The Safety\nConception of AI safety. Despite its simplicity and appeal, we argue that The\nSafety Conception is in tension with at least two trends in the ways AI safety\nresearchers and organizations think and talk about AI safety: first, a tendency\nto characterize the goal of AI safety research in terms of catastrophic risks\nfrom future systems; second, the increasingly popular idea that AI safety can\nbe thought of as a branch of safety engineering. Adopting the methodology of\nconceptual engineering, we argue that these trends are unfortunate: when we\nconsider what concept of AI safety it would be best to have, there are\ncompelling reasons to think that The Safety Conception is the answer.\nDescriptively, The Safety Conception allows us to see how work on topics that\nhave historically been treated as central to the field of AI safety is\ncontinuous with work on topics that have historically been treated as more\nmarginal, like bias, misinformation, and privacy. Normatively, taking The\nSafety Conception seriously means approaching all efforts to prevent or\nmitigate harms from AI systems based on their merits rather than drawing\narbitrary distinctions between them.", "published": "2025-05-05 01:55:00", "link": "http://arxiv.org/abs/2505.02313v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "SafeMate: A Model Context Protocol-Based Multimodal Agent for Emergency Preparedness", "abstract": "Despite the abundance of public safety documents and emergency protocols,\nmost individuals remain ill-equipped to interpret and act on such information\nduring crises. Traditional emergency decision support systems (EDSS) are\ndesigned for professionals and rely heavily on static documents like PDFs or\nSOPs, which are difficult for non-experts to navigate under stress. This gap\nbetween institutional knowledge and public accessibility poses a critical\nbarrier to effective emergency preparedness and response.\n  We introduce SafeMate, a retrieval-augmented AI assistant that delivers\naccurate, context-aware guidance to general users in both preparedness and\nactive emergency scenarios. Built on the Model Context Protocol (MCP), SafeMate\ndynamically routes user queries to tools for document retrieval, checklist\ngeneration, and structured summarization. It uses FAISS with cosine similarity\nto identify relevant content from trusted sources.", "published": "2025-05-05 01:09:02", "link": "http://arxiv.org/abs/2505.02306v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Adaptive Scoring and Thresholding with Human Feedback for Robust Out-of-Distribution Detection", "abstract": "Machine Learning (ML) models are trained on in-distribution (ID) data but\noften encounter out-of-distribution (OOD) inputs during deployment -- posing\nserious risks in safety-critical domains. Recent works have focused on\ndesigning scoring functions to quantify OOD uncertainty, with score thresholds\ntypically set based solely on ID data to achieve a target true positive rate\n(TPR), since OOD data is limited before deployment. However, these TPR-based\nthresholds leave false positive rates (FPR) uncontrolled, often resulting in\nhigh FPRs where OOD points are misclassified as ID. Moreover, fixed scoring\nfunctions and thresholds lack the adaptivity needed to handle newly observed,\nevolving OOD inputs, leading to sub-optimal performance. To address these\nchallenges, we propose a human-in-the-loop framework that \\emph{safely updates\nboth scoring functions and thresholds on the fly} based on real-world OOD\ninputs. Our method maximizes TPR while strictly controlling FPR at all times,\neven as the system adapts over time. We provide theoretical guarantees for FPR\ncontrol under stationary conditions and present extensive empirical evaluations\non OpenOOD benchmarks to demonstrate that our approach outperforms existing\nmethods by achieving higher TPRs while maintaining FPR control.", "published": "2025-05-05 00:25:14", "link": "http://arxiv.org/abs/2505.02299v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation", "abstract": "Synthesizing interactive 3D scenes from text is essential for gaming, virtual\nreality, and embodied AI. However, existing methods face several challenges.\nLearning-based approaches depend on small-scale indoor datasets, limiting the\nscene diversity and layout complexity. While large language models (LLMs) can\nleverage diverse text-domain knowledge, they struggle with spatial realism,\noften producing unnatural object placements that fail to respect common sense.\nOur key insight is that vision perception can bridge this gap by providing\nrealistic spatial guidance that LLMs lack. To this end, we introduce\nScenethesis, a training-free agentic framework that integrates LLM-based scene\nplanning with vision-guided layout refinement. Given a text prompt, Scenethesis\nfirst employs an LLM to draft a coarse layout. A vision module then refines it\nby generating an image guidance and extracting scene structure to capture\ninter-object relations. Next, an optimization module iteratively enforces\naccurate pose alignment and physical plausibility, preventing artifacts like\nobject penetration and instability. Finally, a judge module verifies spatial\ncoherence. Comprehensive experiments show that Scenethesis generates diverse,\nrealistic, and physically plausible 3D interactive scenes, making it valuable\nfor virtual content creation, simulation environments, and embodied AI\nresearch.", "published": "2025-05-05 17:59:58", "link": "http://arxiv.org/abs/2505.02836v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TWIST: Teleoperated Whole-Body Imitation System", "abstract": "Teleoperating humanoid robots in a whole-body manner marks a fundamental step\ntoward developing general-purpose robotic intelligence, with human motion\nproviding an ideal interface for controlling all degrees of freedom. Yet, most\ncurrent humanoid teleoperation systems fall short of enabling coordinated\nwhole-body behavior, typically limiting themselves to isolated locomotion or\nmanipulation tasks. We present the Teleoperated Whole-Body Imitation System\n(TWIST), a system for humanoid teleoperation through whole-body motion\nimitation. We first generate reference motion clips by retargeting human motion\ncapture data to the humanoid robot. We then develop a robust, adaptive, and\nresponsive whole-body controller using a combination of reinforcement learning\nand behavior cloning (RL+BC). Through systematic analysis, we demonstrate how\nincorporating privileged future motion frames and real-world motion capture\n(MoCap) data improves tracking accuracy. TWIST enables real-world humanoid\nrobots to achieve unprecedented, versatile, and coordinated whole-body motor\nskills--spanning whole-body manipulation, legged manipulation, locomotion, and\nexpressive movement--using a single unified neural network controller. Our\nproject website: https://humanoid-teleop.github.io", "published": "2025-05-05 17:59:03", "link": "http://arxiv.org/abs/2505.02833v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "No Other Representation Component Is Needed: Diffusion Transformers Can Provide Representation Guidance by Themselves", "abstract": "Recent studies have demonstrated that learning a meaningful internal\nrepresentation can both accelerate generative training and enhance generation\nquality of the diffusion transformers. However, existing approaches necessitate\nto either introduce an additional and complex representation training framework\nor rely on a large-scale, pre-trained representation foundation model to\nprovide representation guidance during the original generative training\nprocess. In this study, we posit that the unique discriminative process\ninherent to diffusion transformers enables them to offer such guidance without\nrequiring external representation components. We therefore propose\nSelf-Representation A}lignment (SRA), a simple yet straightforward method that\nobtain representation guidance through a self-distillation manner.\nSpecifically, SRA aligns the output latent representation of the diffusion\ntransformer in earlier layer with higher noise to that in later layer with\nlower noise to progressively enhance the overall representation learning during\nonly generative training process. Experimental results indicate that applying\nSRA to DiTs and SiTs yields consistent performance improvements. Moreover, SRA\nnot only significantly outperforms approaches relying on auxiliary, complex\nrepresentation training frameworks but also achieves performance comparable to\nmethods that heavily dependent on powerful external representation priors.", "published": "2025-05-05 17:58:05", "link": "http://arxiv.org/abs/2505.02831v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Application-Specific Evaluation of Vision Models: Case Studies in Ecology and Biology", "abstract": "Computer vision methods have demonstrated considerable potential to\nstreamline ecological and biological workflows, with a growing number of\ndatasets and models becoming available to the research community. However,\nthese resources focus predominantly on evaluation using machine learning\nmetrics, with relatively little emphasis on how their application impacts\ndownstream analysis. We argue that models should be evaluated using\napplication-specific metrics that directly represent model performance in the\ncontext of its final use case. To support this argument, we present two\ndisparate case studies: (1) estimating chimpanzee abundance and density with\ncamera trap distance sampling when using a video-based behaviour classifier and\n(2) estimating head rotation in pigeons using a 3D posture estimator. We show\nthat even models with strong machine learning performance (e.g., 87% mAP) can\nyield data that leads to discrepancies in abundance estimates compared to\nexpert-derived data. Similarly, the highest-performing models for posture\nestimation do not produce the most accurate inferences of gaze direction in\npigeons. Motivated by these findings, we call for researchers to integrate\napplication-specific metrics in ecological/biological datasets, allowing for\nmodels to be benchmarked in the context of their downstream application and to\nfacilitate better integration of models into application workflows.", "published": "2025-05-05 17:51:56", "link": "http://arxiv.org/abs/2505.02825v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MUSAR: Exploring Multi-Subject Customization from Single-Subject Dataset via Attention Routing", "abstract": "Current multi-subject customization approaches encounter two critical\nchallenges: the difficulty in acquiring diverse multi-subject training data,\nand attribute entanglement across different subjects. To bridge these gaps, we\npropose MUSAR - a simple yet effective framework to achieve robust\nmulti-subject customization while requiring only single-subject training data.\nFirstly, to break the data limitation, we introduce debiased diptych learning.\nIt constructs diptych training pairs from single-subject images to facilitate\nmulti-subject learning, while actively correcting the distribution bias\nintroduced by diptych construction via static attention routing and dual-branch\nLoRA. Secondly, to eliminate cross-subject entanglement, we introduce dynamic\nattention routing mechanism, which adaptively establishes bijective mappings\nbetween generated images and conditional subjects. This design not only\nachieves decoupling of multi-subject representations but also maintains\nscalable generalization performance with increasing reference subjects.\nComprehensive experiments demonstrate that our MUSAR outperforms existing\nmethods - even those trained on multi-subject dataset - in image quality,\nsubject consistency, and interaction naturalness, despite requiring only\nsingle-subject dataset.", "published": "2025-05-05 17:50:24", "link": "http://arxiv.org/abs/2505.02823v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Database-Agnostic Gait Enrollment using SetTransformers", "abstract": "Gait recognition has emerged as a powerful tool for unobtrusive and\nlong-range identity analysis, with growing relevance in surveillance and\nmonitoring applications. Although recent advances in deep learning and\nlarge-scale datasets have enabled highly accurate recognition under closed-set\nconditions, real-world deployment demands open-set gait enrollment, which means\ndetermining whether a new gait sample corresponds to a known identity or\nrepresents a previously unseen individual. In this work, we introduce a\ntransformer-based framework for open-set gait enrollment that is both\ndataset-agnostic and recognition-architecture-agnostic. Our method leverages a\nSetTransformer to make enrollment decisions based on the embedding of a probe\nsample and a context set drawn from the gallery, without requiring\ntask-specific thresholds or retraining for new environments. By decoupling\nenrollment from the main recognition pipeline, our model is generalized across\ndifferent datasets, gallery sizes, and identity distributions. We propose an\nevaluation protocol that uses existing datasets in different ratios of\nidentities and walks per identity. We instantiate our method using\nskeleton-based gait representations and evaluate it on two benchmark datasets\n(CASIA-B and PsyMo), using embeddings from three state-of-the-art recognition\nmodels (GaitGraph, GaitFormer, and GaitPT). We show that our method is\nflexible, is able to accurately perform enrollment in different scenarios, and\nscales better with data compared to traditional approaches. We will make the\ncode and dataset scenarios publicly available.", "published": "2025-05-05 17:42:27", "link": "http://arxiv.org/abs/2505.02815v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DPNet: Dynamic Pooling Network for Tiny Object Detection", "abstract": "In unmanned aerial systems, especially in complex environments, accurately\ndetecting tiny objects is crucial. Resizing images is a common strategy to\nimprove detection accuracy, particularly for small objects. However, simply\nenlarging images significantly increases computational costs and the number of\nnegative samples, severely degrading detection performance and limiting its\napplicability. This paper proposes a Dynamic Pooling Network (DPNet) for tiny\nobject detection to mitigate these issues. DPNet employs a flexible\ndown-sampling strategy by introducing a factor (df) to relax the fixed\ndownsampling process of the feature map to an adjustable one. Furthermore, we\ndesign a lightweight predictor to predict df for each input image, which is\nused to decrease the resolution of feature maps in the backbone. Thus, we\nachieve input-aware downsampling. We also design an Adaptive Normalization\nModule (ANM) to make a unified detector compatible with different dfs. A\nguidance loss supervises the predictor's training. DPNet dynamically allocates\ncomputing resources to trade off between detection accuracy and efficiency.\nExperiments on the TinyCOCO and TinyPerson datasets show that DPNet can save\nover 35% and 25% GFLOPs, respectively, while maintaining comparable detection\nperformance. The code will be made publicly available.", "published": "2025-05-05 17:13:35", "link": "http://arxiv.org/abs/2505.02797v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unsupervised training of keypoint-agnostic descriptors for flexible retinal image registration", "abstract": "Current color fundus image registration approaches are limited, among other\nthings, by the lack of labeled data, which is even more significant in the\nmedical domain, motivating the use of unsupervised learning. Therefore, in this\nwork, we develop a novel unsupervised descriptor learning method that does not\nrely on keypoint detection. This enables the resulting descriptor network to be\nagnostic to the keypoint detector used during the registration inference.\n  To validate this approach, we perform an extensive and comprehensive\ncomparison on the reference public retinal image registration dataset.\nAdditionally, we test our method with multiple keypoint detectors of varied\nnature, even proposing some novel ones. Our results demonstrate that the\nproposed approach offers accurate registration, not incurring in any\nperformance loss versus supervised methods. Additionally, it demonstrates\naccurate performance regardless of the keypoint detector used. Thus, this work\nrepresents a notable step towards leveraging unsupervised learning in the\nmedical domain.", "published": "2025-05-05 17:02:13", "link": "http://arxiv.org/abs/2505.02787v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advances in Automated Fetal Brain MRI Segmentation and Biometry: Insights from the FeTA 2024 Challenge", "abstract": "Accurate fetal brain tissue segmentation and biometric analysis are essential\nfor studying brain development in utero. The FeTA Challenge 2024 advanced\nautomated fetal brain MRI analysis by introducing biometry prediction as a new\ntask alongside tissue segmentation. For the first time, our diverse\nmulti-centric test set included data from a new low-field (0.55T) MRI dataset.\nEvaluation metrics were also expanded to include the topology-specific Euler\ncharacteristic difference (ED). Sixteen teams submitted segmentation methods,\nmost of which performed consistently across both high- and low-field scans.\nHowever, longitudinal trends indicate that segmentation accuracy may be\nreaching a plateau, with results now approaching inter-rater variability. The\nED metric uncovered topological differences that were missed by conventional\nmetrics, while the low-field dataset achieved the highest segmentation scores,\nhighlighting the potential of affordable imaging systems when paired with\nhigh-quality reconstruction. Seven teams participated in the biometry task, but\nmost methods failed to outperform a simple baseline that predicted measurements\nbased solely on gestational age, underscoring the challenge of extracting\nreliable biometric estimates from image data alone. Domain shift analysis\nidentified image quality as the most significant factor affecting model\ngeneralization, with super-resolution pipelines also playing a substantial\nrole. Other factors, such as gestational age, pathology, and acquisition site,\nhad smaller, though still measurable, effects. Overall, FeTA 2024 offers a\ncomprehensive benchmark for multi-class segmentation and biometry estimation in\nfetal brain MRI, underscoring the need for data-centric approaches, improved\ntopological evaluation, and greater dataset diversity to enable clinically\nrobust and generalizable AI tools.", "published": "2025-05-05 16:54:04", "link": "http://arxiv.org/abs/2505.02784v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unsupervised Deep Learning-based Keypoint Localization Estimating Descriptor Matching Performance", "abstract": "Retinal image registration, particularly for color fundus images, is a\nchallenging yet essential task with diverse clinical applications. Existing\nregistration methods for color fundus images typically rely on keypoints and\ndescriptors for alignment; however, a significant limitation is their reliance\non labeled data, which is particularly scarce in the medical domain.\n  In this work, we present a novel unsupervised registration pipeline that\nentirely eliminates the need for labeled data. Our approach is based on the\nprinciple that locations with distinctive descriptors constitute reliable\nkeypoints. This fully inverts the conventional state-of-the-art approach,\nconditioning the detector on the descriptor rather than the opposite.\n  First, we propose an innovative descriptor learning method that operates\nwithout keypoint detection or any labels, generating descriptors for arbitrary\nlocations in retinal images. Next, we introduce a novel, label-free keypoint\ndetector network which works by estimating descriptor performance directly from\nthe input image.\n  We validate our method through a comprehensive evaluation on four hold-out\ndatasets, demonstrating that our unsupervised descriptor outperforms\nstate-of-the-art supervised descriptors and that our unsupervised detector\nsignificantly outperforms existing unsupervised detection methods. Finally, our\nfull registration pipeline achieves performance comparable to the leading\nsupervised methods, while not employing any labeled data. Additionally, the\nlabel-free nature and design of our method enable direct adaptation to other\ndomains and modalities.", "published": "2025-05-05 16:46:32", "link": "http://arxiv.org/abs/2505.02779v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advancing Generalizable Tumor Segmentation with Anomaly-Aware Open-Vocabulary Attention Maps and Frozen Foundation Diffusion Models", "abstract": "We explore Generalizable Tumor Segmentation, aiming to train a single model\nfor zero-shot tumor segmentation across diverse anatomical regions. Existing\nmethods face limitations related to segmentation quality, scalability, and the\nrange of applicable imaging modalities. In this paper, we uncover the potential\nof the internal representations within frozen medical foundation diffusion\nmodels as highly efficient zero-shot learners for tumor segmentation by\nintroducing a novel framework named DiffuGTS. DiffuGTS creates anomaly-aware\nopen-vocabulary attention maps based on text prompts to enable generalizable\nanomaly segmentation without being restricted by a predefined training category\nlist. To further improve and refine anomaly segmentation masks, DiffuGTS\nleverages the diffusion model, transforming pathological regions into\nhigh-quality pseudo-healthy counterparts through latent space inpainting, and\napplies a novel pixel-level and feature-level residual learning approach,\nresulting in segmentation masks with significantly enhanced quality and\ngeneralization. Comprehensive experiments on four datasets and seven tumor\ncategories demonstrate the superior performance of our method, surpassing\ncurrent state-of-the-art models across multiple zero-shot settings. Codes are\navailable at https://github.com/Yankai96/DiffuGTS.", "published": "2025-05-05 16:05:37", "link": "http://arxiv.org/abs/2505.02753v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Platelet enumeration in dense aggregates", "abstract": "Identifying and counting blood components such as red blood cells, various\ntypes of white blood cells, and platelets is a critical task for healthcare\npractitioners. Deep learning approaches, particularly convolutional neural\nnetworks (CNNs) using supervised learning strategies, have shown considerable\nsuccess for such tasks. However, CNN based architectures such as U-Net, often\nstruggles to accurately identify platelets due to their sizes and high\nvariability of features. To address these challenges, researchers have commonly\nemployed strategies such as class weighted loss functions, which have\ndemonstrated some success. However, this does not address the more significant\nchallenge of platelet variability in size and tendency to form aggregates and\nassociations with other blood components. In this study, we explored an\nalternative approach by investigating the role of convolutional kernels in\nmitigating these issues. We also assigned separate classes to singular\nplatelets and platelet aggregates and performed semantic segmentation using\nvarious U-Net architectures for identifying platelets. We then evaluated and\ncompared two common methods (pixel area method and connected component\nanalysis) for counting platelets and proposed an alternative approach\nspecialized for single platelets and platelet aggregates. Our experiments\nprovided results that showed significant improvements in the identification of\nplatelets, highlighting the importance of optimizing convolutional operations\nand class designations. We show that the common practice of pixel area-based\ncounting often over estimate platelet counts, whereas the proposed method\npresented in this work offers significant improvements. We discuss in detail\nabout these methods from segmentation masks.", "published": "2025-05-05 16:05:13", "link": "http://arxiv.org/abs/2505.02751v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Rate-Quality Model for Learned Video Coding", "abstract": "Learned video coding (LVC) has recently achieved superior coding performance.\nIn this paper, we model the rate-quality (R-Q) relationship for learned video\ncoding by a parametric function. We learn a neural network, termed RQNet, to\ncharacterize the relationship between the bitrate and quality level according\nto video content and coding context. The predicted (R,Q) results are further\nintegrated with those from previously coded frames using the least-squares\nmethod to determine the parameters of our R-Q model on-the-fly. Compared to the\nconventional approaches, our method accurately estimates the R-Q relationship,\nenabling the online adaptation of model parameters to enhance both flexibility\nand precision. Experimental results show that our R-Q model achieves\nsignificantly smaller bitrate deviations than the baseline method on commonly\nused datasets with minimal additional complexity.", "published": "2025-05-05 15:19:18", "link": "http://arxiv.org/abs/2505.02720v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-View Learning with Context-Guided Receptance for Image Denoising", "abstract": "Image denoising is essential in low-level vision applications such as\nphotography and automated driving. Existing methods struggle with\ndistinguishing complex noise patterns in real-world scenes and consume\nsignificant computational resources due to reliance on Transformer-based\nmodels. In this work, the Context-guided Receptance Weighted Key-Value (\\M)\nmodel is proposed, combining enhanced multi-view feature integration with\nefficient sequence modeling. Our approach introduces the Context-guided Token\nShift (CTS) paradigm, which effectively captures local spatial dependencies and\nenhance the model's ability to model real-world noise distributions.\nAdditionally, the Frequency Mix (FMix) module extracting frequency-domain\nfeatures is designed to isolate noise in high-frequency spectra, and is\nintegrated with spatial representations through a multi-view learning process.\nTo improve computational efficiency, the Bidirectional WKV (BiWKV) mechanism is\nadopted, enabling full pixel-sequence interaction with linear complexity while\novercoming the causal selection constraints. The model is validated on multiple\nreal-world image denoising datasets, outperforming the existing\nstate-of-the-art methods quantitatively and reducing inference time up to 40\\%.\nQualitative results further demonstrate the ability of our model to restore\nfine details in various scenes.", "published": "2025-05-05 14:57:43", "link": "http://arxiv.org/abs/2505.02705v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Visually-Guided Linguistic Disambiguation for Monocular Depth Scale Recovery", "abstract": "We propose a robust method for monocular depth scale recovery. Monocular\ndepth estimation can be divided into two main directions: (1) relative depth\nestimation, which provides normalized or inverse depth without scale\ninformation, and (2) metric depth estimation, which involves recovering depth\nwith absolute scale. To obtain absolute scale information for practical\ndownstream tasks, utilizing textual information to recover the scale of a\nrelative depth map is a highly promising approach. However, since a single\nimage can have multiple descriptions from different perspectives or with\nvarying styles, it has been shown that different textual descriptions can\nsignificantly affect the scale recovery process. To address this issue, our\nmethod, VGLD, stabilizes the influence of textual information by incorporating\nhigh-level semantic information from the corresponding image alongside the\ntextual description. This approach resolves textual ambiguities and robustly\noutputs a set of linear transformation parameters (scalars) that can be\nglobally applied to the relative depth map, ultimately generating depth\npredictions with metric-scale accuracy. We validate our method across several\npopular relative depth models(MiDas, DepthAnything), using both indoor scenes\n(NYUv2) and outdoor scenes (KITTI). Our results demonstrate that VGLD functions\nas a universal alignment module when trained on multiple datasets, achieving\nstrong performance even in zero-shot scenarios. Code is available at:\nhttps://github.com/pakinwu/VGLD.", "published": "2025-05-05 14:57:16", "link": "http://arxiv.org/abs/2505.02704v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structure Causal Models and LLMs Integration in Medical Visual Question Answering", "abstract": "Medical Visual Question Answering (MedVQA) aims to answer medical questions\naccording to medical images. However, the complexity of medical data leads to\nconfounders that are difficult to observe, so bias between images and questions\nis inevitable. Such cross-modal bias makes it challenging to infer medically\nmeaningful answers. In this work, we propose a causal inference framework for\nthe MedVQA task, which effectively eliminates the relative confounding effect\nbetween the image and the question to ensure the precision of the\nquestion-answering (QA) session. We are the first to introduce a novel causal\ngraph structure that represents the interaction between visual and textual\nelements, explicitly capturing how different questions influence visual\nfeatures. During optimization, we apply the mutual information to discover\nspurious correlations and propose a multi-variable resampling front-door\nadjustment method to eliminate the relative confounding effect, which aims to\nalign features based on their true causal relevance to the question-answering\ntask. In addition, we also introduce a prompt strategy that combines multiple\nprompt forms to improve the model's ability to understand complex medical data\nand answer accurately. Extensive experiments on three MedVQA datasets\ndemonstrate that 1) our method significantly improves the accuracy of MedVQA,\nand 2) our method achieves true causal correlations in the face of complex\nmedical data.", "published": "2025-05-05 14:57:02", "link": "http://arxiv.org/abs/2505.02703v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dance of Fireworks: An Interactive Broadcast Gymnastics Training System Based on Pose Estimation", "abstract": "This study introduces Dance of Fireworks, an interactive system designed to\ncombat sedentary health risks by enhancing engagement in radio calisthenics.\nLeveraging mobile device cameras and lightweight pose estimation\n(PoseNet/TensorFlow Lite), the system extracts body keypoints, computes joint\nangles, and compares them with standardized motions to deliver real-time\ncorrective feedback. To incentivize participation, it dynamically maps users'\nmovements (such as joint angles and velocity) to customizable fireworks\nanimations, rewarding improved accuracy with richer visual effects. Experiments\ninvolving 136 participants demonstrated a significant reduction in average\njoint angle errors from 21.3 degrees to 9.8 degrees (p < 0.01) over four\nsessions, with 93.4 percent of users affirming its exercise-promoting efficacy\nand 85.4 percent praising its entertainment value. The system operates without\npredefined motion templates or specialised hardware, enabling seamless\nintegration into office environments. Future enhancements will focus on\nimproving pose recognition accuracy, reducing latency, and adding features such\nas multiplayer interaction and music synchronisation. This work presents a\ncost-effective, engaging solution to promote physical activity in sedentary\npopulations.", "published": "2025-05-05 14:41:06", "link": "http://arxiv.org/abs/2505.02690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Deep Learning for Stroke Prediction and Detection using Retinal Imaging and Clinical Data", "abstract": "Stroke is a major public health problem, affecting millions worldwide. Deep\nlearning has recently demonstrated promise for enhancing the diagnosis and risk\nprediction of stroke. However, existing methods rely on costly medical imaging\nmodalities, such as computed tomography. Recent studies suggest that retinal\nimaging could offer a cost-effective alternative for cerebrovascular health\nassessment due to the shared clinical pathways between the retina and the\nbrain. Hence, this study explores the impact of leveraging retinal images and\nclinical data for stroke detection and risk prediction. We propose a multimodal\ndeep neural network that processes Optical Coherence Tomography (OCT) and\ninfrared reflectance retinal scans, combined with clinical data, such as\ndemographics, vital signs, and diagnosis codes. We pretrained our model using a\nself-supervised learning framework using a real-world dataset consisting of\n$37$ k scans, and then fine-tuned and evaluated the model using a smaller\nlabeled subset. Our empirical findings establish the predictive ability of the\nconsidered modalities in detecting lasting effects in the retina associated\nwith acute stroke and forecasting future risk within a specific time horizon.\nThe experimental results demonstrate the effectiveness of our proposed\nframework by achieving $5$\\% AUROC improvement as compared to the unimodal\nimage-only baseline, and $8$\\% improvement compared to an existing\nstate-of-the-art foundation model. In conclusion, our study highlights the\npotential of retinal imaging in identifying high-risk patients and improving\nlong-term outcomes.", "published": "2025-05-05 14:22:58", "link": "http://arxiv.org/abs/2505.02677v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Grasp the Graph (GtG) 2.0: Ensemble of GNNs for High-Precision Grasp Pose Detection in Clutter", "abstract": "Grasp pose detection in cluttered, real-world environments remains a\nsignificant challenge due to noisy and incomplete sensory data combined with\ncomplex object geometries. This paper introduces Grasp the Graph 2.0 (GtG 2.0)\nmethod, a lightweight yet highly effective hypothesis-and-test robotics\ngrasping framework which leverages an ensemble of Graph Neural Networks for\nefficient geometric reasoning from point cloud data. Building on the success of\nGtG 1.0, which demonstrated the potential of Graph Neural Networks for grasp\ndetection but was limited by assumptions of complete, noise-free point clouds\nand 4-Dof grasping, GtG 2.0 employs a conventional Grasp Pose Generator to\nefficiently produce 7-Dof grasp candidates. Candidates are assessed with an\nensemble Graph Neural Network model which includes points within the gripper\njaws (inside points) and surrounding contextual points (outside points). This\nimproved representation boosts grasp detection performance over previous\nmethods using the same generator. GtG 2.0 shows up to a 35% improvement in\nAverage Precision on the GraspNet-1Billion benchmark compared to\nhypothesis-and-test and Graph Neural Network-based methods, ranking it among\nthe top three frameworks. Experiments with a 3-Dof Delta Parallel robot and\nKinect-v1 camera show a success rate of 91% and a clutter completion rate of\n100%, demonstrating its flexibility and reliability.", "published": "2025-05-05 14:14:32", "link": "http://arxiv.org/abs/2505.02664v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Sim2Real in endoscopy segmentation with a novel structure aware image translation", "abstract": "Automatic segmentation of anatomical landmarks in endoscopic images can\nprovide assistance to doctors and surgeons for diagnosis, treatments or medical\ntraining. However, obtaining the annotations required to train commonly used\nsupervised learning methods is a tedious and difficult task, in particular for\nreal images. While ground truth annotations are easier to obtain for synthetic\ndata, models trained on such data often do not generalize well to real data.\nGenerative approaches can add realistic texture to it, but face difficulties to\nmaintain the structure of the original scene. The main contribution in this\nwork is a novel image translation model that adds realistic texture to\nsimulated endoscopic images while keeping the key scene layout information. Our\napproach produces realistic images in different endoscopy scenarios. We\ndemonstrate these images can effectively be used to successfully train a model\nfor a challenging end task without any real labeled data. In particular, we\ndemonstrate our approach for the task of fold segmentation in colonoscopy\nimages. Folds are key anatomical landmarks that can occlude parts of the colon\nmucosa and possible polyps. Our approach generates realistic images maintaining\nthe shape and location of the original folds, after the\nimage-style-translation, better than existing methods. We run experiments both\non a novel simulated dataset for fold segmentation, and real data from the\nEndoMapper (EM) dataset. All our new generated data and new EM metadata is\nbeing released to facilitate further research, as no public benchmark is\ncurrently available for the task of fold segmentation.", "published": "2025-05-05 13:56:59", "link": "http://arxiv.org/abs/2505.02654v1", "categories": ["cs.CV", "I.2.10; I.4.6"], "primary_category": "cs.CV"}
{"title": "MCCD: Multi-Agent Collaboration-based Compositional Diffusion for Complex Text-to-Image Generation", "abstract": "Diffusion models have shown excellent performance in text-to-image\ngeneration. Nevertheless, existing methods often suffer from performance\nbottlenecks when handling complex prompts that involve multiple objects,\ncharacteristics, and relations. Therefore, we propose a Multi-agent\nCollaboration-based Compositional Diffusion (MCCD) for text-to-image generation\nfor complex scenes. Specifically, we design a multi-agent collaboration-based\nscene parsing module that generates an agent system comprising multiple agents\nwith distinct tasks, utilizing MLLMs to extract various scene elements\neffectively. In addition, Hierarchical Compositional diffusion utilizes a\nGaussian mask and filtering to refine bounding box regions and enhance objects\nthrough region enhancement, resulting in the accurate and high-fidelity\ngeneration of complex scenes. Comprehensive experiments demonstrate that our\nMCCD significantly improves the performance of the baseline models in a\ntraining-free manner, providing a substantial advantage in complex scene\ngeneration.", "published": "2025-05-05 13:50:03", "link": "http://arxiv.org/abs/2505.02648v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeepSparse: A Foundation Model for Sparse-View CBCT Reconstruction", "abstract": "Cone-beam computed tomography (CBCT) is a critical 3D imaging technology in\nthe medical field, while the high radiation exposure required for high-quality\nimaging raises significant concerns, particularly for vulnerable populations.\nSparse-view reconstruction reduces radiation by using fewer X-ray projections\nwhile maintaining image quality, yet existing methods face challenges such as\nhigh computational demands and poor generalizability to different datasets. To\novercome these limitations, we propose DeepSparse, the first foundation model\nfor sparse-view CBCT reconstruction, featuring DiCE (Dual-Dimensional\nCross-Scale Embedding), a novel network that integrates multi-view 2D features\nand multi-scale 3D features. Additionally, we introduce the HyViP (Hybrid View\nSampling Pretraining) framework, which pretrains the model on large datasets\nwith both sparse-view and dense-view projections, and a two-step finetuning\nstrategy to adapt and refine the model for new datasets. Extensive experiments\nand ablation studies demonstrate that our proposed DeepSparse achieves superior\nreconstruction quality compared to state-of-the-art methods, paving the way for\nsafer and more efficient CBCT imaging.", "published": "2025-05-05 13:14:49", "link": "http://arxiv.org/abs/2505.02628v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Detect, Classify, Act: Categorizing Industrial Anomalies with Multi-Modal Large Language Models", "abstract": "Recent advances in visual industrial anomaly detection have demonstrated\nexceptional performance in identifying and segmenting anomalous regions while\nmaintaining fast inference speeds. However, anomaly\nclassification-distinguishing different types of anomalies-remains largely\nunexplored despite its critical importance in real-world inspection tasks. To\naddress this gap, we propose VELM, a novel LLM-based pipeline for anomaly\nclassification. Given the critical importance of inference speed, we first\napply an unsupervised anomaly detection method as a vision expert to assess the\nnormality of an observation. If an anomaly is detected, the LLM then classifies\nits type. A key challenge in developing and evaluating anomaly classification\nmodels is the lack of precise annotations of anomaly classes in existing\ndatasets. To address this limitation, we introduce MVTec-AC and VisA-AC,\nrefined versions of the widely used MVTec-AD and VisA datasets, which include\naccurate anomaly class labels for rigorous evaluation. Our approach achieves a\nstate-of-the-art anomaly classification accuracy of 80.4% on MVTec-AD,\nexceeding the prior baselines by 5%, and 84% on MVTec-AC, demonstrating the\neffectiveness of VELM in understanding and categorizing anomalies. We hope our\nmethodology and benchmark inspire further research in anomaly classification,\nhelping bridge the gap between detection and comprehensive anomaly\ncharacterization.", "published": "2025-05-05 13:08:25", "link": "http://arxiv.org/abs/2505.02626v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DELTA: Dense Depth from Events and LiDAR using Transformer's Attention", "abstract": "Event cameras and LiDARs provide complementary yet distinct data:\nrespectively, asynchronous detections of changes in lighting versus sparse but\naccurate depth information at a fixed rate. To this day, few works have\nexplored the combination of these two modalities. In this article, we propose a\nnovel neural-network-based method for fusing event and LiDAR data in order to\nestimate dense depth maps. Our architecture, DELTA, exploits the concepts of\nself- and cross-attention to model the spatial and temporal relations within\nand between the event and LiDAR data. Following a thorough evaluation, we\ndemonstrate that DELTA sets a new state of the art in the event-based depth\nestimation problem, and that it is able to reduce the errors up to four times\nfor close ranges compared to the previous SOTA.", "published": "2025-05-05 11:59:53", "link": "http://arxiv.org/abs/2505.02593v1", "categories": ["cs.CV", "I.4.8"], "primary_category": "cs.CV"}
{"title": "RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet", "abstract": "This work introduces RGBX-DiffusionDet, an object detection framework\nextending the DiffusionDet model to fuse the heterogeneous 2D data (X) with RGB\nimagery via an adaptive multimodal encoder. To enable cross-modal interaction,\nwe design the dynamic channel reduction within a convolutional block attention\nmodule (DCR-CBAM), which facilitates cross-talk between subnetworks by\ndynamically highlighting salient channel features. Furthermore, the dynamic\nmulti-level aggregation block (DMLAB) is proposed to refine spatial feature\nrepresentations through adaptive multiscale fusion. Finally, novel\nregularization losses that enforce channel saliency and spatial selectivity are\nintroduced, leading to compact and discriminative feature embeddings. Extensive\nexperiments using RGB-Depth (KITTI), a novel annotated RGB-Polarimetric\ndataset, and RGB-Infrared (M$^3$FD) benchmark dataset were conducted. We\ndemonstrate consistent superiority of the proposed approach over the baseline\nRGB-only DiffusionDet. The modular architecture maintains the original decoding\ncomplexity, ensuring efficiency. These results establish the proposed\nRGBX-DiffusionDet as a flexible multimodal object detection approach, providing\nnew insights into integrating diverse 2D sensing modalities into\ndiffusion-based detection pipelines.", "published": "2025-05-05 11:39:51", "link": "http://arxiv.org/abs/2505.02586v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities", "abstract": "Recent years have seen remarkable progress in both multimodal understanding\nmodels and image generation models. Despite their respective successes, these\ntwo domains have evolved independently, leading to distinct architectural\nparadigms: While autoregressive-based architectures have dominated multimodal\nunderstanding, diffusion-based models have become the cornerstone of image\ngeneration. Recently, there has been growing interest in developing unified\nframeworks that integrate these tasks. The emergence of GPT-4o's new\ncapabilities exemplifies this trend, highlighting the potential for\nunification. However, the architectural differences between the two domains\npose significant challenges. To provide a clear overview of current efforts\ntoward unification, we present a comprehensive survey aimed at guiding future\nresearch. First, we introduce the foundational concepts and recent advancements\nin multimodal understanding and text-to-image generation models. Next, we\nreview existing unified models, categorizing them into three main architectural\nparadigms: diffusion-based, autoregressive-based, and hybrid approaches that\nfuse autoregressive and diffusion mechanisms. For each category, we analyze the\nstructural designs and innovations introduced by related works. Additionally,\nwe compile datasets and benchmarks tailored for unified models, offering\nresources for future exploration. Finally, we discuss the key challenges facing\nthis nascent field, including tokenization strategy, cross-modal attention, and\ndata. As this area is still in its early stages, we anticipate rapid\nadvancements and will regularly update this survey. Our goal is to inspire\nfurther research and provide a valuable reference for the community. The\nreferences associated with this survey will be available on GitHub soon.", "published": "2025-05-05 11:18:03", "link": "http://arxiv.org/abs/2505.02567v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Duality Learning for Unsupervised Visible-Infrared Person Re-Identfication", "abstract": "Unsupervised visible-infrared person re-identification (UVI-ReID) aims to\nretrieve pedestrian images across different modalities without costly\nannotations, but faces challenges due to the modality gap and lack of\nsupervision. Existing methods often adopt self-training with\nclustering-generated pseudo-labels but implicitly assume these labels are\nalways correct. In practice, however, this assumption fails due to inevitable\npseudo-label noise, which hinders model learning. To address this, we introduce\na new learning paradigm that explicitly considers Pseudo-Label Noise (PLN),\ncharacterized by three key challenges: noise overfitting, error accumulation,\nand noisy cluster correspondence. To this end, we propose a novel Robust\nDuality Learning framework (RoDE) for UVI-ReID to mitigate the effects of noisy\npseudo-labels. First, to combat noise overfitting, a Robust Adaptive Learning\nmechanism (RAL) is proposed to dynamically emphasize clean samples while\ndown-weighting noisy ones. Second, to alleviate error accumulation-where the\nmodel reinforces its own mistakes-RoDE employs dual distinct models that are\nalternately trained using pseudo-labels from each other, encouraging diversity\nand preventing collapse. However, this dual-model strategy introduces\nmisalignment between clusters across models and modalities, creating noisy\ncluster correspondence. To resolve this, we introduce Cluster Consistency\nMatching (CCM), which aligns clusters across models and modalities by measuring\ncross-cluster similarity. Extensive experiments on three benchmarks demonstrate\nthe effectiveness of RoDE.", "published": "2025-05-05 10:36:52", "link": "http://arxiv.org/abs/2505.02549v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Marker-Based Extrinsic Calibration Method for Accurate Multi-Camera 3D Reconstruction", "abstract": "Accurate 3D reconstruction using multi-camera RGB-D systems critically\ndepends on precise extrinsic calibration to achieve proper alignment between\ncaptured views. In this paper, we introduce an iterative extrinsic calibration\nmethod that leverages the geometric constraints provided by a three-dimensional\nmarker to significantly improve calibration accuracy. Our proposed approach\nsystematically segments and refines marker planes through clustering,\nregression analysis, and iterative reassignment techniques, ensuring robust\ngeometric correspondence across camera views. We validate our method\ncomprehensively in both controlled environments and practical real-world\nsettings within the Tech4Diet project, aimed at modeling the physical\nprogression of patients undergoing nutritional treatments. Experimental results\ndemonstrate substantial reductions in alignment errors, facilitating accurate\nand reliable 3D reconstructions.", "published": "2025-05-05 10:21:41", "link": "http://arxiv.org/abs/2505.02539v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "RobSurv: Vector Quantization-Based Multi-Modal Learning for Robust Cancer Survival Prediction", "abstract": "Cancer survival prediction using multi-modal medical imaging presents a\ncritical challenge in oncology, mainly due to the vulnerability of deep\nlearning models to noise and protocol variations across imaging centers.\nCurrent approaches struggle to extract consistent features from heterogeneous\nCT and PET images, limiting their clinical applicability. We address these\nchallenges by introducing RobSurv, a robust deep-learning framework that\nleverages vector quantization for resilient multi-modal feature learning. The\nkey innovation of our approach lies in its dual-path architecture: one path\nmaps continuous imaging features to learned discrete codebooks for\nnoise-resistant representation, while the parallel path preserves fine-grained\ndetails through continuous feature processing. This dual representation is\nintegrated through a novel patch-wise fusion mechanism that maintains local\nspatial relationships while capturing global context via Transformer-based\nprocessing. In extensive evaluations across three diverse datasets (HECKTOR,\nH\\&N1, and NSCLC Radiogenomics), RobSurv demonstrates superior performance,\nachieving concordance index of 0.771, 0.742, and 0.734 respectively -\nsignificantly outperforming existing methods. Most notably, our model maintains\nrobust performance even under severe noise conditions, with performance\ndegradation of only 3.8-4.5\\% compared to 8-12\\% in baseline methods. These\nresults, combined with strong generalization across different cancer types and\nimaging protocols, establish RobSurv as a promising solution for reliable\nclinical prognosis that can enhance treatment planning and patient care.", "published": "2025-05-05 10:10:03", "link": "http://arxiv.org/abs/2505.02529v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Text to Image Generation and Editing: A Survey", "abstract": "Text-to-image generation (T2I) refers to the text-guided generation of\nhigh-quality images. In the past few years, T2I has attracted widespread\nattention and numerous works have emerged. In this survey, we comprehensively\nreview 141 works conducted from 2021 to 2024. First, we introduce four\nfoundation model architectures of T2I (autoregression, non-autoregression, GAN\nand diffusion) and the commonly used key technologies (autoencoder, attention\nand classifier-free guidance). Secondly, we systematically compare the methods\nof these studies in two directions, T2I generation and T2I editing, including\nthe encoders and the key technologies they use. In addition, we also compare\nthe performance of these researches side by side in terms of datasets,\nevaluation metrics, training resources, and inference speed. In addition to the\nfour foundation models, we survey other works on T2I, such as energy-based\nmodels and recent Mamba and multimodality. We also investigate the potential\nsocial impact of T2I and provide some solutions. Finally, we propose unique\ninsights of improving the performance of T2I models and possible future\ndevelopment directions. In summary, this survey is the first systematic and\ncomprehensive overview of T2I, aiming to provide a valuable guide for future\nresearchers and stimulate continued progress in this field.", "published": "2025-05-05 10:08:31", "link": "http://arxiv.org/abs/2505.02527v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Finger Pose Estimation for Under-screen Fingerprint Sensor", "abstract": "Two-dimensional pose estimation plays a crucial role in fingerprint\nrecognition by facilitating global alignment and reduce pose-induced\nvariations. However, existing methods are still unsatisfactory when handling\nwith large angle or small area inputs. These limitations are particularly\npronounced on fingerprints captured by under-screen fingerprint sensors in\nsmartphones. In this paper, we present a novel dual-modal input based network\nfor under-screen fingerprint pose estimation. Our approach effectively\nintegrates two distinct yet complementary modalities: texture details extracted\nfrom ridge patches through the under-screen fingerprint sensor, and rough\ncontours derived from capacitive images obtained via the touch screen. This\ncollaborative integration endows our network with more comprehensive and\ndiscriminative information, substantially improving the accuracy and stability\nof pose estimation. A decoupled probability distribution prediction task is\ndesigned, instead of the traditional supervised forms of numerical regression\nor heatmap voting, to facilitate the training process. Additionally, we\nincorporate a Mixture of Experts (MoE) based feature fusion mechanism and a\nrelationship driven cross-domain knowledge transfer strategy to further\nstrengthen feature extraction and fusion capabilities. Extensive experiments\nare conducted on several public datasets and two private datasets. The results\nindicate that our method is significantly superior to previous state-of-the-art\n(SOTA) methods and remarkably boosts the recognition ability of fingerprint\nrecognition algorithms. Our code is available at\nhttps://github.com/XiongjunGuan/DRACO.", "published": "2025-05-05 09:05:47", "link": "http://arxiv.org/abs/2505.02481v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Point Cloud Recombination: Systematic Real Data Augmentation Using Robotic Targets for LiDAR Perception Validation", "abstract": "The validation of LiDAR-based perception of intelligent mobile systems\noperating in open-world applications remains a challenge due to the variability\nof real environmental conditions. Virtual simulations allow the generation of\narbitrary scenes under controlled conditions but lack physical sensor\ncharacteristics, such as intensity responses or material-dependent effects. In\ncontrast, real-world data offers true sensor realism but provides less control\nover influencing factors, hindering sufficient validation. Existing approaches\naddress this problem with augmentation of real-world point cloud data by\ntransferring objects between scenes. However, these methods do not consider\nvalidation and remain limited in controllability because they rely on empirical\ndata. We solve these limitations by proposing Point Cloud Recombination, which\nsystematically augments captured point cloud scenes by integrating point clouds\nacquired from physical target objects measured in controlled laboratory\nenvironments. Thus enabling the creation of vast amounts and varieties of\nrepeatable, physically accurate test scenes with respect to phenomena-aware\nocclusions with registered 3D meshes. Using the Ouster OS1-128 Rev7 sensor, we\ndemonstrate the augmentation of real-world urban and rural scenes with humanoid\ntargets featuring varied clothing and poses, for repeatable positioning. We\nshow that the recombined scenes closely match real sensor outputs, enabling\ntargeted testing, scalable failure analysis, and improved system safety. By\nproviding controlled yet sensor-realistic data, our method enables trustworthy\nconclusions about the limitations of specific sensors in compound with their\nalgorithms, e.g., object detection.", "published": "2025-05-05 09:00:16", "link": "http://arxiv.org/abs/2505.02476v1", "categories": ["cs.RO", "cs.CV", "eess.IV"], "primary_category": "cs.RO"}
{"title": "Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction", "abstract": "We introduce Ming-Lite-Uni, an open-source multimodal framework featuring a\nnewly designed unified visual generator and a native multimodal autoregressive\nmodel tailored for unifying vision and language. Specifically, this project\nprovides an open-source implementation of the integrated MetaQueries and\nM2-omni framework, while introducing the novel multi-scale learnable tokens and\nmulti-scale representation alignment strategy. By leveraging a fixed MLLM and a\nlearnable diffusion model, Ming-Lite-Uni enables native multimodal AR models to\nperform both text-to-image generation and instruction based image editing\ntasks, expanding their capabilities beyond pure visual understanding. Our\nexperimental results demonstrate the strong performance of Ming-Lite-Uni and\nillustrate the impressive fluid nature of its interactive process. All code and\nmodel weights are open-sourced to foster further exploration within the\ncommunity. Notably, this work aligns with concurrent multimodal AI milestones -\nsuch as ChatGPT-4o with native image generation updated in March 25, 2025 -\nunderscoring the broader significance of unified models like Ming-Lite-Uni on\nthe path toward AGI. Ming-Lite-Uni is in alpha stage and will soon be further\nrefined.", "published": "2025-05-05 08:56:12", "link": "http://arxiv.org/abs/2505.02471v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Recent Advances in Out-of-Distribution Detection with CLIP-Like Models: A Survey", "abstract": "Out-of-distribution detection (OOD) is a pivotal task for real-world\napplications that trains models to identify samples that are distributionally\ndifferent from the in-distribution (ID) data during testing. Recent advances in\nAI, particularly Vision-Language Models (VLMs) like CLIP, have revolutionized\nOOD detection by shifting from traditional unimodal image detectors to\nmultimodal image-text detectors. This shift has inspired extensive research;\nhowever, existing categorization schemes (e.g., few- or zero-shot types) still\nrely solely on the availability of ID images, adhering to a unimodal paradigm.\nTo better align with CLIP's cross-modal nature, we propose a new categorization\nframework rooted in both image and text modalities. Specifically, we categorize\nexisting methods based on how visual and textual information of OOD data is\nutilized within image + text modalities, and further divide them into four\ngroups: OOD Images (i.e., outliers) Seen or Unseen, and OOD Texts (i.e.,\nlearnable vectors or class names) Known or Unknown, across two training\nstrategies (i.e., train-free or training-required). More importantly, we\ndiscuss open problems in CLIP-like OOD detection and highlight promising\ndirections for future research, including cross-domain integration, practical\napplications, and theoretical understanding.", "published": "2025-05-05 08:22:38", "link": "http://arxiv.org/abs/2505.02448v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Token Coordinated Prompt Attention is Needed for Visual Prompting", "abstract": "Visual prompting techniques are widely used to efficiently fine-tune\npretrained Vision Transformers (ViT) by learning a small set of shared prompts\nfor all tokens. However, existing methods overlook the unique roles of\ndifferent tokens in conveying discriminative information and interact with all\ntokens using the same prompts, thereby limiting the representational capacity\nof ViT. This often leads to indistinguishable and biased prompt-extracted\nfeatures, hindering performance. To address this issue, we propose a\nplug-and-play Token Coordinated Prompt Attention (TCPA) module, which assigns\nspecific coordinated prompts to different tokens for attention-based\ninteractions. Firstly, recognizing the distinct functions of CLS and image\ntokens-global information aggregation and local feature extraction, we\ndisentangle the prompts into CLS Prompts and Image Prompts, which interact\nexclusively with CLS tokens and image tokens through attention mechanisms. This\nenhances their respective discriminative abilities. Furthermore, as different\nimage tokens correspond to distinct image patches and contain diverse\ninformation, we employ a matching function to automatically assign coordinated\nprompts to individual tokens. This enables more precise attention interactions,\nimproving the diversity and representational capacity of the extracted\nfeatures. Extensive experiments across various benchmarks demonstrate that TCPA\nsignificantly enhances the diversity and discriminative power of the extracted\nfeatures. The code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-TCPA.", "published": "2025-05-05 06:59:26", "link": "http://arxiv.org/abs/2505.02406v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Estimating Commonsense Scene Composition on Belief Scene Graphs", "abstract": "This work establishes the concept of commonsense scene composition, with a\nfocus on extending Belief Scene Graphs by estimating the spatial distribution\nof unseen objects. Specifically, the commonsense scene composition capability\nrefers to the understanding of the spatial relationships among related objects\nin the scene, which in this article is modeled as a joint probability\ndistribution for all possible locations of the semantic object class. The\nproposed framework includes two variants of a Correlation Information (CECI)\nmodel for learning probability distributions: (i) a baseline approach based on\na Graph Convolutional Network, and (ii) a neuro-symbolic extension that\nintegrates a spatial ontology based on Large Language Models (LLMs).\nFurthermore, this article provides a detailed description of the dataset\ngeneration process for such tasks. Finally, the framework has been validated\nthrough multiple runs on simulated data, as well as in a real-world indoor\nenvironment, demonstrating its ability to spatially interpret scenes across\ndifferent room types.", "published": "2025-05-05 06:55:59", "link": "http://arxiv.org/abs/2505.02405v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection", "abstract": "Most existing video anomaly detectors rely solely on RGB frames, which lack\nthe temporal resolution needed to capture abrupt or transient motion cues, key\nindicators of anomalous events. To address this limitation, we propose\nImage-Event Fusion for Video Anomaly Detection (IEF-VAD), a framework that\nsynthesizes event representations directly from RGB videos and fuses them with\nimage features through a principled, uncertainty-aware process. The system (i)\nmodels heavy-tailed sensor noise with a Student`s-t likelihood, deriving\nvalue-level inverse-variance weights via a Laplace approximation; (ii) applies\nKalman-style frame-wise updates to balance modalities over time; and (iii)\niteratively refines the fused latent state to erase residual cross-modal noise.\nWithout any dedicated event sensor or frame-level labels, IEF-VAD sets a new\nstate of the art across multiple real-world anomaly detection benchmarks. These\nfindings highlight the utility of synthetic event representations in\nemphasizing motion cues that are often underrepresented in RGB frames, enabling\naccurate and robust video understanding across diverse applications without\nrequiring dedicated event sensors. Code and models are available at\nhttps://github.com/EavnJeong/IEF-VAD.", "published": "2025-05-05 06:33:20", "link": "http://arxiv.org/abs/2505.02393v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Arbitrary-Modal Fusion Network for Volumetric Cranial Nerves Tract Segmentation", "abstract": "The segmentation of cranial nerves (CNs) tract provides a valuable\nquantitative tool for the analysis of the morphology and trajectory of\nindividual CNs. Multimodal CNs tract segmentation networks, e.g., CNTSeg, which\ncombine structural Magnetic Resonance Imaging (MRI) and diffusion MRI, have\nachieved promising segmentation performance. However, it is laborious or even\ninfeasible to collect complete multimodal data in clinical practice due to\nlimitations in equipment, user privacy, and working conditions. In this work,\nwe propose a novel arbitrary-modal fusion network for volumetric CNs tract\nsegmentation, called CNTSeg-v2, which trains one model to handle different\ncombinations of available modalities. Instead of directly combining all the\nmodalities, we select T1-weighted (T1w) images as the primary modality due to\nits simplicity in data acquisition and contribution most to the results, which\nsupervises the information selection of other auxiliary modalities. Our model\nencompasses an Arbitrary-Modal Collaboration Module (ACM) designed to\neffectively extract informative features from other auxiliary modalities,\nguided by the supervision of T1w images. Meanwhile, we construct a Deep\nDistance-guided Multi-stage (DDM) decoder to correct small errors and\ndiscontinuities through signed distance maps to improve segmentation accuracy.\nWe evaluate our CNTSeg-v2 on the Human Connectome Project (HCP) dataset and the\nclinical Multi-shell Diffusion MRI (MDM) dataset. Extensive experimental\nresults show that our CNTSeg-v2 achieves state-of-the-art segmentation\nperformance, outperforming all competing methods.", "published": "2025-05-05 06:00:41", "link": "http://arxiv.org/abs/2505.02385v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Quaternion Multi-focus Color Image Fusion", "abstract": "Multi-focus color image fusion refers to integrating multiple partially\nfocused color images to create a single all-in-focus color image. However,\nexisting methods struggle with complex real-world scenarios due to limitations\nin handling color information and intricate textures. To address these\nchallenges, this paper proposes a quaternion multi-focus color image fusion\nframework to perform high-quality color image fusion completely in the\nquaternion domain. This framework introduces 1) a quaternion sparse\ndecomposition model to jointly learn fine-scale image details and structure\ninformation of color images in an iterative fashion for high-precision focus\ndetection, 2) a quaternion base-detail fusion strategy to individually fuse\nbase-scale and detail-scale results across multiple color images for preserving\nstructure and detail information, and 3) a quaternion structural similarity\nrefinement strategy to adaptively select optimal patches from initial fusion\nresults and obtain the final fused result for preserving fine details and\nensuring spatially consistent outputs. Extensive experiments demonstrate that\nthe proposed framework outperforms state-of-the-art methods.", "published": "2025-05-05 05:08:33", "link": "http://arxiv.org/abs/2505.02365v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quaternion Infrared Visible Image Fusion", "abstract": "Visible images provide rich details and color information only under\nwell-lighted conditions while infrared images effectively highlight thermal\ntargets under challenging conditions such as low visibility and adverse\nweather. Infrared-visible image fusion aims to integrate complementary\ninformation from infrared and visible images to generate a high-quality fused\nimage. Existing methods exhibit critical limitations such as neglecting color\nstructure information in visible images and performance degradation when\nprocessing low-quality color-visible inputs. To address these issues, we\npropose a quaternion infrared-visible image fusion (QIVIF) framework to\ngenerate high-quality fused images completely in the quaternion domain. QIVIF\nproposes a quaternion low-visibility feature learning model to adaptively\nextract salient thermal targets and fine-grained texture details from input\ninfrared and visible images respectively under diverse degraded conditions.\nQIVIF then develops a quaternion adaptive unsharp masking method to adaptively\nimprove high-frequency feature enhancement with balanced illumination. QIVIF\nfurther proposes a quaternion hierarchical Bayesian fusion model to integrate\ninfrared saliency and enhanced visible details to obtain high-quality fused\nimages. Extensive experiments across diverse datasets demonstrate that our\nQIVIF surpasses state-of-the-art methods under challenging low-visibility\nconditions.", "published": "2025-05-05 05:02:05", "link": "http://arxiv.org/abs/2505.02364v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sparse Ellipsoidal Radial Basis Function Network for Point Cloud Surface Representation", "abstract": "Point cloud surface representation is a fundamental problem in computer\ngraphics and vision. This paper presents a machine learning approach for\napproximating the signed distance function (SDF) of a point cloud using sparse\nellipsoidal radial basis function networks, enabling a compact and accurate\nsurface representation. Given the SDF values defined on the grid points\nconstructed from the point cloud, our method approximates the SDF accurately\nwith as few ellipsoidal radial basis functions (ERBFs) as possible, i.e.,\nrepresent the SDF of a point cloud by sparse ERBFs. To balance sparsity and\napproximation precision, a dynamic multi-objective optimization strategy is\nintroduced, which adaptively adds the regularization terms and jointly\noptimizes the weights, centers, shapes, and orientations of ERBFs. To improve\ncomputational efficiency, a nearest-neighbor-based data structure is employed,\nrestricting function calculations to points near each Gaussian kernel center.\nThe computations for each kernel are further parallelized on CUDA, which\nsignificantly improves the optimization speed. Additionally, a hierarchical\noctree-based refinement strategy is designed for training. Specifically, the\ninitialization and optimization of network parameters are conducted using\ncoarse grid points in the octree lattice structure. Subsequently, fine lattice\npoints are progressively incorporated to accelerate model convergence and\nenhance training efficiency. Extensive experiments on multiple benchmark\ndatasets demonstrate that our method outperforms previous sparse representation\napproaches in terms of accuracy, robustness, and computational efficiency. The\ncorresponding code is publicly available at\nhttps://github.com/lianbobo/SE-RBFNet.git.", "published": "2025-05-05 04:16:16", "link": "http://arxiv.org/abs/2505.02350v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "6D Pose Estimation on Spoons and Hands", "abstract": "Accurate dietary monitoring is essential for promoting healthier eating\nhabits. A key area of research is how people interact and consume food using\nutensils and hands. By tracking their position and orientation, it is possible\nto estimate the volume of food being consumed, or monitor eating behaviours,\nhighly useful insights into nutritional intake that can be more reliable than\npopular methods such as self-reporting. Hence, this paper implements a system\nthat analyzes stationary video feed of people eating, using 6D pose estimation\nto track hand and spoon movements to capture spatial position and orientation.\nIn doing so, we examine the performance of two state-of-the-art (SOTA) video\nobject segmentation (VOS) models, both quantitatively and qualitatively, and\nidentify main sources of error within the system.", "published": "2025-05-05 03:15:12", "link": "http://arxiv.org/abs/2505.02335v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VAEmo: Efficient Representation Learning for Visual-Audio Emotion with Knowledge Injection", "abstract": "Audiovisual emotion recognition (AVER) aims to infer human emotions from\nnonverbal visual-audio (VA) cues, offering modality-complementary and\nlanguage-agnostic advantages. However, AVER remains challenging due to the\ninherent ambiguity of emotional expressions, cross-modal expressive\ndisparities, and the scarcity of reliably annotated data. Recent\nself-supervised AVER approaches have introduced strong multimodal\nrepresentations, yet they predominantly rely on modality-specific encoders and\ncoarse content-level alignment, limiting fine-grained emotional semantic\nmodeling. To address these issues, we propose VAEmo, an efficient two-stage\nframework for emotion-centric joint VA representation learning with external\nknowledge injection. In Stage 1, a unified and lightweight representation\nnetwork is pre-trained on large-scale speaker-centric VA corpora via masked\nreconstruction and contrastive objectives, mitigating the modality gap and\nlearning expressive, complementary representations without emotion labels. In\nStage 2, multimodal large language models automatically generate detailed\naffective descriptions according to our well-designed chain-of-thought\nprompting for only a small subset of VA samples; these rich textual semantics\nare then injected by aligning their corresponding embeddings with VA\nrepresentations through dual-path contrastive learning, further bridging the\nemotion gap. Extensive experiments on multiple downstream AVER benchmarks show\nthat VAEmo achieves state-of-the-art performance with a compact design,\nhighlighting the benefit of unified cross-modal encoding and emotion-aware\nsemantic guidance for efficient, generalizable VA emotion representations.", "published": "2025-05-05 03:00:51", "link": "http://arxiv.org/abs/2505.02331v1", "categories": ["cs.CV", "cs.SD"], "primary_category": "cs.CV"}
{"title": "TeDA: Boosting Vision-Lanuage Models for Zero-Shot 3D Object Retrieval via Testing-time Distribution Alignment", "abstract": "Learning discriminative 3D representations that generalize well to unknown\ntesting categories is an emerging requirement for many real-world 3D\napplications. Existing well-established methods often struggle to attain this\ngoal due to insufficient 3D training data from broader concepts. Meanwhile,\npre-trained large vision-language models (e.g., CLIP) have shown remarkable\nzero-shot generalization capabilities. Yet, they are limited in extracting\nsuitable 3D representations due to substantial gaps between their 2D training\nand 3D testing distributions. To address these challenges, we propose\nTesting-time Distribution Alignment (TeDA), a novel framework that adapts a\npretrained 2D vision-language model CLIP for unknown 3D object retrieval at\ntest time. To our knowledge, it is the first work that studies the test-time\nadaptation of a vision-language model for 3D feature learning. TeDA projects 3D\nobjects into multi-view images, extracts features using CLIP, and refines 3D\nquery embeddings with an iterative optimization strategy by confident\nquery-target sample pairs in a self-boosting manner. Additionally, TeDA\nintegrates textual descriptions generated by a multimodal language model\n(InternVL) to enhance 3D object understanding, leveraging CLIP's aligned\nfeature space to fuse visual and textual cues. Extensive experiments on four\nopen-set 3D object retrieval benchmarks demonstrate that TeDA greatly\noutperforms state-of-the-art methods, even those requiring extensive training.\nWe also experimented with depth maps on Objaverse-LVIS, further validating its\neffectiveness. Code is available at https://github.com/wangzhichuan123/TeDA.", "published": "2025-05-05 02:47:07", "link": "http://arxiv.org/abs/2505.02325v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "i-QLS: Quantum-supported Algorithm for Least Squares Optimization in Non-Linear Regression", "abstract": "We propose an iterative quantum-assisted least squares (i-QLS) optimization\nmethod that leverages quantum annealing to overcome the scalability and\nprecision limitations of prior quantum least squares approaches. Unlike\ntraditional QUBO-based formulations, which suffer from a qubit overhead due to\nfixed discretization, our approach refines the solution space iteratively,\nenabling exponential convergence while maintaining a constant qubit requirement\nper iteration. This iterative refinement transforms the problem into an anytime\nalgorithm, allowing for flexible computational trade-offs. Furthermore, we\nextend our framework beyond linear regression to non-linear function\napproximation via spline-based modeling, demonstrating its adaptability to\ncomplex regression tasks. We empirically validate i-QLS on the D-Wave quantum\nannealer, showing that our method efficiently scales to high-dimensional\nproblems, achieving competitive accuracy with classical solvers while\noutperforming prior quantum approaches. Experiments confirm that i-QLS enables\nnear-term quantum hardware to perform regression tasks with improved precision\nand scalability, paving the way for practical quantum-assisted machine learning\napplications.", "published": "2025-05-05 17:02:35", "link": "http://arxiv.org/abs/2505.02788v1", "categories": ["quant-ph", "cs.DM", "05-08", "F.4.1; F.2.2"], "primary_category": "quant-ph"}
{"title": "Linear colorings of graphs", "abstract": "Motivated by algorithmic applications, Kun, O'Brien, Pilipczuk, and Sullivan\nintroduced the parameter linear chromatic number as a relaxation of treedepth\nand proved that the two parameters are polynomially related. They conjectured\nthat treedepth could be bounded from above by twice the linear chromatic\nnumber.\n  In this paper we investigate the properties of linear chromatic number and\nprovide improved bounds in several graph classes.", "published": "2025-05-05 16:29:28", "link": "http://arxiv.org/abs/2505.02768v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Net Occurrences in Fibonacci and Thue-Morse Words", "abstract": "A net occurrence of a repeated string in a text is an occurrence with unique\nleft and right extensions, and the net frequency of the string is the number of\nits net occurrences in the text. Originally introduced for applications in\nNatural Language Processing, net frequency has recently gained attention for\nits algorithmic aspects. Guo et al. [CPM 2024] and Ohlebusch et al. [SPIRE\n2024] focus on its computation in the offline setting, while Guo et al. [SPIRE\n2024], Inenaga [arXiv 2024], and Mieno and Inenaga [CPM 2025] tackle the online\ncounterpart. Mieno and Inenaga also characterize net occurrences in terms of\nthe minimal unique substrings of the text. Additionally, Guo et al. [CPM 2024]\ninitiate the study of net occurrences in Fibonacci words to establish a lower\nbound on the asymptotic running time of algorithms. Although there has been\nnotable progress in algorithmic developments and some initial combinatorial\ninsights, the combinatorial aspects of net occurrences have yet to be\nthoroughly examined. In this work, we make two key contributions. First, we\nconfirm the conjecture that each Fibonacci word contains exactly three net\noccurrences. Second, we show that each Thue-Morse word contains exactly nine\nnet occurrences. To achieve these results, we introduce the notion of\noverlapping net occurrence cover, which narrows down the candidate net\noccurrences in any text. Furthermore, we provide a precise characterization of\noccurrences of Fibonacci and Thue-Morse words of smaller order, offering\nstructural insights that may have independent interest and potential\napplications in algorithm analysis and combinatorial properties of these words.", "published": "2025-05-05 01:16:51", "link": "http://arxiv.org/abs/2505.02307v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "Evaluating Contrastive Feedback for Effective User Simulations", "abstract": "The use of Large Language Models (LLMs) for simulating user behavior in the\ndomain of Interactive Information Retrieval has recently gained significant\npopularity. However, their application and capabilities remain highly debated\nand understudied. This study explores whether the underlying principles of\ncontrastive training techniques, which have been effective for fine-tuning\nLLMs, can also be applied beneficially in the area of prompt engineering for\nuser simulations.\n  Previous research has shown that LLMs possess comprehensive world knowledge,\nwhich can be leveraged to provide accurate estimates of relevant documents.\nThis study attempts to simulate a knowledge state by enhancing the model with\nadditional implicit contextual information gained during the simulation. This\napproach enables the model to refine the scope of desired documents further.\nThe primary objective of this study is to analyze how different modalities of\ncontextual information influence the effectiveness of user simulations.\n  Various user configurations were tested, where models are provided with\nsummaries of already judged relevant, irrelevant, or both types of documents in\na contrastive manner. The focus of this study is the assessment of the impact\nof the prompting techniques on the simulated user agent performance. We hereby\nlay the foundations for leveraging LLMs as part of more realistic simulated\nusers.", "published": "2025-05-05 11:02:31", "link": "http://arxiv.org/abs/2505.02560v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Uncertainty in Repeated Implicit Feedback as a Measure of Reliability", "abstract": "Recommender systems rely heavily on user feedback to learn effective user and\nitem representations. Despite their widespread adoption, limited attention has\nbeen given to the uncertainty inherent in the feedback used to train these\nsystems. Both implicit and explicit feedback are prone to noise due to the\nvariability in human interactions, with implicit feedback being particularly\nchallenging. In collaborative filtering, the reliability of interaction signals\nis critical, as these signals determine user and item similarities. Thus,\nderiving accurate confidence measures from implicit feedback is essential for\nensuring the reliability of these signals.\n  A common assumption in academia and industry is that repeated interactions\nindicate stronger user interest, increasing confidence in preference estimates.\nHowever, in domains such as music streaming, repeated consumption can shift\nuser preferences over time due to factors like satiation and exposure. While\nliterature on repeated consumption acknowledges these dynamics, they are often\noverlooked when deriving confidence scores for implicit feedback.\n  This paper addresses this gap by focusing on music streaming, where repeated\ninteractions are frequent and quantifiable. We analyze how repetition patterns\nintersect with key factors influencing user interest and develop methods to\nquantify the associated uncertainty. These uncertainty measures are then\nintegrated as consistency metrics in a recommendation task. Our empirical\nresults show that incorporating uncertainty into user preference models yields\nmore accurate and relevant recommendations. Key contributions include a\ncomprehensive analysis of uncertainty in repeated consumption patterns, the\nrelease of a novel dataset, and a Bayesian model for implicit listening\nfeedback.", "published": "2025-05-05 09:18:47", "link": "http://arxiv.org/abs/2505.02492v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Tevatron 2.0: Unified Document Retrieval Toolkit across Scale, Language, and Modality", "abstract": "Recent advancements in large language models (LLMs) have driven interest in\nbillion-scale retrieval models with strong generalization across retrieval\ntasks and languages. Additionally, progress in large vision-language models has\ncreated new opportunities for multimodal retrieval. In response, we have\nupdated the Tevatron toolkit, introducing a unified pipeline that enables\nresearchers to explore retriever models at different scales, across multiple\nlanguages, and with various modalities. This demo paper highlights the\ntoolkit's key features, bridging academia and industry by supporting efficient\ntraining, inference, and evaluation of neural retrievers. We showcase a unified\ndense retriever achieving strong multilingual and multimodal effectiveness, and\nconduct a cross-modality zero-shot study to demonstrate its research potential.\nAlongside, we release OmniEmbed, to the best of our knowledge, the first\nembedding model that unifies text, image document, video, and audio retrieval,\nserving as a baseline for future research.", "published": "2025-05-05 08:52:49", "link": "http://arxiv.org/abs/2505.02466v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SymbioticRAG: Enhancing Document Intelligence Through Human-LLM Symbiotic Collaboration", "abstract": "We present \\textbf{SymbioticRAG}, a novel framework that fundamentally\nreimagines Retrieval-Augmented Generation~(RAG) systems by establishing a\nbidirectional learning relationship between humans and machines. Our approach\naddresses two critical challenges in current RAG systems: the inherently\nhuman-centered nature of relevance determination and users' progression from\n\"unconscious incompetence\" in query formulation. SymbioticRAG introduces a\ntwo-tier solution where Level 1 enables direct human curation of retrieved\ncontent through interactive source document exploration, while Level 2 aims to\nbuild personalized retrieval models based on captured user interactions. We\nimplement Level 1 through three key components: (1)~a comprehensive document\nprocessing pipeline with specialized models for layout detection, OCR, and\nextraction of tables, formulas, and figures; (2)~an extensible retriever module\nsupporting multiple retrieval strategies; and (3)~an interactive interface that\nfacilitates both user engagement and interaction data logging. We experiment\nLevel 2 implementation via a retriever strategy incorporated LLM summarized\nuser intention from user interaction logs. To maintain high-quality data\npreparation, we develop a human-on-the-loop validation interface that improves\npipeline output while advancing research in specialized extraction tasks.\nEvaluation across three scenarios (literature review, geological exploration,\nand education) demonstrates significant improvements in retrieval relevance and\nuser satisfaction compared to traditional RAG approaches. To facilitate broader\nresearch and further advancement of SymbioticRAG Level 2 implementation, we\nwill make our system openly accessible to the research community.", "published": "2025-05-05 07:24:38", "link": "http://arxiv.org/abs/2505.02418v1", "categories": ["cs.IR", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Structured Estimators: A New Perspective on Information Freshness", "abstract": "In recent literature, when modeling for information freshness in remote\nestimation settings, estimators have been mainly restricted to the class of\nmartingale estimators, meaning the remote estimate at any time is equal to the\nmost recently received update. This is mainly due to its simplicity and ease of\nanalysis. However, these martingale estimators are far from optimal in some\ncases, especially in pull-based update systems. For such systems, maximum\naposteriori probability (MAP) estimators are optimum, but can be challenging to\nanalyze. Here, we introduce a new class of estimators, called structured\nestimators, which retain useful characteristics from a MAP estimate while still\nbeing analytically tractable. Our proposed estimators move seamlessly from a\nmartingale estimator to a MAP estimator.", "published": "2025-05-05 17:41:08", "link": "http://arxiv.org/abs/2505.02813v1", "categories": ["cs.IT", "cs.SY", "eess.SP", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cell-Free Massive MIMO-Assisted SWIPT for IoT Networks", "abstract": "This paper studies cell-free massive multiple-input multiple-output\n(CF-mMIMO) systems that underpin simultaneous wireless information and power\ntransfer (SWIPT) for separate information users (IUs) and energy users (EUs) in\nInternet of Things (IoT) networks. We propose a joint access point (AP)\noperation mode selection and power control design, wherein certain APs are\ndesignated for energy transmission to EUs, while others are dedicated to\ninformation transmission to IUs. The performance of the system, from both a\nspectral efficiency (SE) and energy efficiency (EE) perspective, is\ncomprehensively analyzed. Specifically, we formulate two mixed-integer\nnonconvex optimization problems for maximizing the average sum-SE and EE, under\nrealistic power consumption models and constraints on the minimum individual SE\nrequirements for individual IUs, minimum HE for individual EUs, and maximum\ntransmit power at each AP. The challenging optimization problems are solved\nusing successive convex approximation (SCA) techniques. The proposed framework\ndesign is further applied to the average sum-HE maximization and energy\nharvesting fairness problems. Our numerical results demonstrate that the\nproposed joint AP operation mode selection and power control algorithm can\nachieve EE performance gains of up to $4$-fold and $5$-fold over random AP\noperation mode selection, with and without power control respectively.", "published": "2025-05-05 17:32:14", "link": "http://arxiv.org/abs/2505.02806v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On APN functions in odd characteristic, the disproof of a conjecture and related problems", "abstract": "In this paper disprove a conjecture by Pal and Budaghyan (DCC, 2024) on the\nexistence of a family of APN permutations, but showing that if the field's\ncardinality $q$ is larger than~$9587$, then those functions will never be APN.\nMoreover, we discuss other connected families of functions, for potential APN\nfunctions, but we show that they are not good candidates for APNess if the\nunderlying field is large, in spite of the fact that they though they are APN\nfor small environments.", "published": "2025-05-05 11:37:29", "link": "http://arxiv.org/abs/2505.02585v1", "categories": ["math.AG", "cs.IT", "math.IT", "math.NT", "11G20, 11T06, 12E20, 14Q10"], "primary_category": "math.AG"}
{"title": "Antifragility of RIS-assisted Communication Systems under Jamming Attacks", "abstract": "Antifragility of communication systems is defined as measure of benefits\ngained from the adverse events and variability of its environment. In this\npaper, we introduce the notion of antifragility in Reconfigurable Intelligent\nSurface (RIS) assisted communication systems affected by a jamming attack. We\nanalyzed the antifragility of the two hop systems, where the wireless path\ncontains source node, RIS, destination node, and a eavesdropping/jamming node.\nWe propose and analyze the antifragility performance for several jamming\nmodels, such as Digital Radio Frequency Memory (DRFM) and phase and amplitude\nshifting. Our paper shows that antifragility throughput can indeed be achieved\nunder certain power thresholds and for various jamming models. In particular,\nhigh jamming power combined with low baseline data rates yields an antifragile\ngain factor of approximately five times. The results confirm that\nreconfigurable intelligent surfaces, when coupled with an antifragile design\nphilosophy, can convert hostile interference from a liability into a throughput\ngain.", "published": "2025-05-05 11:13:01", "link": "http://arxiv.org/abs/2505.02565v1", "categories": ["cs.NI", "cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Energy Efficiency Maximization for CR-NOMA based Smart Grid Communication Network", "abstract": "Managing massive data flows effectively and resolving spectrum shortages are\ntwo challenges that Smart Grid Communication Networks (SGCN) must overcome. To\naddress these problems, we provide a combined optimization approach that makes\nuse of Cognitive Radio (CR) and Non-Orthogonal Multiple Access (NOMA)\ntechnologies. Our work focuses on using user pairing (UP) and power allocation\n(PA) techniques to maximize energy efficiency (EE) in SGCN, particularly within\nNeighbourhood Area Networks (NANs). We develop a joint optimization problem\nthat takes into account the real-world limitations of a CR-NOMA setting. This\nproblem is NP-hard, nonlinear, and nonconvex by nature. To address the\ncomputational complexity of the problem, we use the Block Coordinate Descent\n(BCD) method, which breaks the problem into UP and PA subproblems. Initially,\nwe proposed the Zebra-Optimization User Pairing (ZOUP) algorithm to tackle the\nUP problem, which outperforms both Orthogonal Multiple Access (OMA) and\nnon-optimized NOMA (UPWO) by 78.8\\% and 13.6\\%, respectively, at a SNR of 15\ndB. Based on the ZOUP pairs, we subsequently proposed the PA approach, i.e.,\nZOUPPA, which significantly outperforms UPWO and ZOUP by 53.2\\% and 25.4\\%,\nrespectively, at an SNR of 15 dB. A detailed analysis of key parameters,\nincluding varying SNRs, power allocation constants, path loss exponents, user\ndensity, channel availability, and coverage radius, underscores the superiority\nof our approach. By facilitating the effective use of communication resources\nin SGCN, our research opens the door to more intelligent and energy-efficient\ngrid systems. Our work tackles important issues in SGCN and lays the groundwork\nfor future developments in smart grid communication technologies by combining\nmodern optimization approaches with CR-NOMA.", "published": "2025-05-05 10:12:32", "link": "http://arxiv.org/abs/2505.02530v1", "categories": ["eess.SP", "cs.IT", "cs.NI", "math.IT"], "primary_category": "eess.SP"}
{"title": "An Efficient Hybrid Key Exchange Mechanism", "abstract": "We present \\textsc{CHOKE}, a novel code-based hybrid key-encapsulation\nmechanism (KEM) designed to securely and efficiently transmit multiple session\nkeys simultaneously. By encoding $n$ independent session keys with an\nindividually secure linear code and encapsulating each resulting coded symbol\nusing a separate KEM, \\textsc{CHOKE} achieves computational individual security\n-- each key remains secure as long as at least one underlying KEM remains\nunbroken. Compared to traditional serial or combiner-based hybrid schemes,\n\\textsc{CHOKE} reduces computational and communication costs by an $n$-fold\nfactor. Furthermore, we show that the communication cost of our construction is\noptimal under the requirement that each KEM must be used at least once.", "published": "2025-05-05 09:28:46", "link": "http://arxiv.org/abs/2505.02499v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "Decoding Insertions/Deletions via List Recovery", "abstract": "In this work, we consider the problem of efficient decoding of codes from\ninsertions and deletions. Most of the known efficient codes are codes with\nsynchronization strings which allow one to reduce the problem of decoding\ninsertions and deletions to that of decoding substitution and erasures. Our new\napproach, presented in this paper, reduces the problem of decoding insertions\nand deletions to that of list recovery. Specifically, any \\((\\rho, 2\\rho n + 1,\nL)\\)-list-recoverable code is a \\((\\rho, L)\\)-list decodable insdel code. As an\nexample, we apply this technique to Reed-Solomon (RS) codes, which are known to\nhave efficient list-recovery algorithms up to the Johnson bound. In the\nadversarial insdel model, this provides efficient (list) decoding from \\(t\\)\ninsdel errors, assuming that \\(t\\cdot k = O(n)\\). This is the first efficient\ninsdel decoder for \\([n, k]\\) RS codes for \\(k>2\\). Additionally, we explore\nrandom insdel models, such as the Davey-MacKay channel, and show that for\ncertain choices of \\(\\rho\\), a \\((\\rho, n^{1/2+0.001}, L)\\)-list-recoverable\ncode of length \\(n\\) can, with high probability, efficiently list decode the\nchannel output, ensuring that the transmitted codeword is in the output list.\nIn the context of RS codes, this leads to a better rate-error tradeoff for\nthese channels compared to the adversarial case. We also adapt the\nKoetter-Vardy algorithm, a famous soft-decision list decoding technique for RS\ncodes, to correct insertions and deletions induced by the Davey-MacKay channel.", "published": "2025-05-05 08:31:25", "link": "http://arxiv.org/abs/2505.02452v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Correcting Multiple Substitutions in Nanopore-Sequencing Reads", "abstract": "Despite their significant advantages over competing technologies, nanopore\nsequencers are plagued by high error rates, due to physical characteristics of\nthe nanopore and inherent noise in the biological processes. It is thus\nparamount not only to formulate efficient error-correcting constructions for\nthese channels, but also to establish bounds on the minimum redundancy required\nby such coding schemes. In this context, we adopt a simplified model of\nnanopore sequencing inspired by the work of Mao \\emph{et al.}, accounting for\nthe effects of intersymbol interference and measurement noise. For an input\nsequence of length $n$, the vector that is produced, designated as the\n\\emph{read vector}, may additionally suffer at most \\(t\\) substitution errors.\nWe employ the well-known graph-theoretic clique-cover technique to establish\nthat at least \\(t\\log n -O(1)\\) bits of redundancy are required to correct\nmultiple (\\(t \\geq 2\\)) substitutions. While this is surprising in comparison\nto the case of a single substitution, that necessitates at most \\(\\log \\log n -\nO(1)\\) bits of redundancy, a suitable error-correcting code that is optimal up\nto a constant follows immediately from the properties of read vectors.", "published": "2025-05-05 08:15:22", "link": "http://arxiv.org/abs/2505.02447v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Learned Intelligent Recognizer with Adaptively Customized RIS Phases in Communication Systems", "abstract": "This study presents an advanced wireless system that embeds target\nrecognition within reconfigurable intelligent surface (RIS)-aided communication\nsystems, powered by cuttingedge deep learning innovations. Such a system faces\nthe challenge of fine-tuning both the RIS phase shifts and neural network (NN)\nparameters, since they intricately interdepend on each other to accomplish the\nrecognition task. To address these challenges, we propose an intelligent\nrecognizer that strategically harnesses every piece of prior action responses,\nthereby ingeniously multiplexing downlink signals to facilitate environment\nsensing. Specifically, we design a novel NN based on the long short-term memory\n(LSTM) architecture and the physical channel model. The NN iteratively captures\nand fuses information from previous measurements and adaptively customizes RIS\nconfigurations to acquire the most relevant information for the recognition\ntask in subsequent moments. Tailored dynamically, these configurations adapt to\nthe scene, task, and target specifics. Simulation results reveal that our\nproposed method significantly outperforms the state-of-the-art method, while\nresulting in minimal impacts on communication performance, even as sensing is\nperformed simultaneously.", "published": "2025-05-05 08:14:13", "link": "http://arxiv.org/abs/2505.02446v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Reconfigurable Intelligent Surface Aided Integrated Communication and Localization with a Single Access Point", "abstract": "Reconfigurable intelligent surfaces (RISs) not only assist communication but\nalso help the localization of user equipment (UE). This study focuses on the\nindoor localization of UE with a single access point (AP) aided by multiple\nRISs. First, we propose a two-stage channel estimation scheme where the phase\nshifts of RIS elements are tuned to obtain multiple channel soundings. In the\nfirst stage, the newtonized orthogonal matching pursuit algorithm extracts the\nparameters of multiple paths from the received signals. Then, the LOS path and\nRIS-reflected paths are identified. In the second stage, the estimated path\ngains of RIS-reflected paths with different phase shifts are utilized to\ndetermine the angle of arrival (AOA) at the RIS by obtaining the angular pseudo\nspectrum. Consequently, by taking the AP and RISs as reference points, the\nlinear least squares estimator can locate UE with the estimated AOAs.\nSimulation results show that the proposed algorithm can realize\ncentimeter-level localization accuracy in the discussed scenarios. Moreover,\nthe higher accuracy of pseudo spectrum, a larger number of channel soundings,\nand a larger number of reference points can realize higher localization\naccuracy of UE.", "published": "2025-05-05 08:12:24", "link": "http://arxiv.org/abs/2505.02444v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cooperative ISAC Network for Off-Grid Imaging-based Low-Altitude Surveillance", "abstract": "The low-altitude economy has emerged as a critical focus for future economic\ndevelopment, emphasizing the urgent need for flight activity surveillance\nutilizing the existing sensing capabilities of mobile cellular networks.\nTraditional monostatic or localization-based sensing methods, however,\nencounter challenges in fusing sensing results and matching channel parameters.\nTo address these challenges, we propose an innovative approach that directly\ndraws the radio images of the low-altitude space, leveraging its inherent\nsparsity with compressed sensing (CS)-based algorithms and the cooperation of\nmultiple base stations. Furthermore, recognizing that unmanned aerial vehicles\n(UAVs) are randomly distributed in space, we introduce a physics-embedded\nlearning method to overcome off-grid issues inherent in CS-based models.\nAdditionally, an online hard example mining method is incorporated into the\ndesign of the loss function, enabling the network to adaptively concentrate on\nthe samples bearing significant discrepancy with the ground truth, thereby\nenhancing its ability to detect the rare UAVs within the expansive low-altitude\nspace. Simulation results demonstrate the effectiveness of the imaging-based\nlow-altitude surveillance approach, with the proposed physics-embedded learning\nalgorithm significantly outperforming traditional CS-based methods under\noff-grid conditions.", "published": "2025-05-05 08:10:13", "link": "http://arxiv.org/abs/2505.02440v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Equivalence of Gaussian Graphical Models Defined on Complete Bipartite Graphs", "abstract": "This paper introduces two Gaussian graphical models defined on complete\nbipartite graphs. We show that the determinants of the precision matrices\nassociated with the models are equal up to scale, where the scale factor only\ndepends on model parameters. In this context, we will introduce a notion of\n``equivalence\" between the two Gaussian graphical models. This equivalence has\ntwo key applications: first, it can significantly reduce the complexity of\ncomputing the exact value of the determinant, and second, it enables the\nderivation of closed-form expressions for the determinants in certain special\ncases.", "published": "2025-05-05 05:55:46", "link": "http://arxiv.org/abs/2505.02384v1", "categories": ["cs.IT", "cs.CC", "math.IT", "stat.CO"], "primary_category": "cs.IT"}
{"title": "Probabilistic ODMA Receiver with Low-Complexity Algorithm for MIMO Unsourced Random Access", "abstract": "In this work, we present the design for both pilot-uncoupled and pilot-free\non-off multiple access (ODMA) receivers in unsourced random access (URA) for\nmultiple-input multiple-output (MIMO) systems. Unlike pilot-coupled ODMA, where\non-off patterns are linked to pilot selection, pilot-uncoupled and pilot-free\nODMA reduce transmission redundancy but face challenges in processing\ncomplexity and capacity performance. The joint pattern and data detector (JPDD)\ndesign is critical for these schemes, but the current JPDD algorithm has high\ncomplexity with quadratic computational costs. To address this, we propose a\nlow-complexity detector based on approximate message passing (AMP), which\noffers linear complexity, providing reduced cost and improved performance in\nthe under-determined linear regression case. Decoding is initialized via\npilot-free matrix factorization through alternating minimization, resolving\nphase and scalar ambiguities. Compared to existing pilot-free schemes, the\nproposed method achieves a 13 dB improvement and favorable trade-offs in\ncomplexity and capacity performance when compared to benchmarks.", "published": "2025-05-05 05:47:15", "link": "http://arxiv.org/abs/2505.02382v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Towards Quantifying the Hessian Structure of Neural Networks", "abstract": "Empirical studies reported that the Hessian matrix of neural networks (NNs)\nexhibits a near-block-diagonal structure, yet its theoretical foundation\nremains unclear. In this work, we reveal two forces that shape the Hessian\nstructure: a ``static force'' rooted in the architecture design, and a\n``dynamic force'' arisen from training. We then provide a rigorous theoretical\nanalysis of ``static force'' at random initialization. We study linear models\nand 1-hidden-layer networks with the mean-square (MSE) loss and the\nCross-Entropy (CE) loss for classification tasks. By leveraging random matrix\ntheory, we compare the limit distributions of the diagonal and off-diagonal\nHessian blocks and find that the block-diagonal structure arises as $C\n\\rightarrow \\infty$, where $C$ denotes the number of classes. Our findings\nreveal that $C$ is a primary driver of the near-block-diagonal structure. These\nresults may shed new light on the Hessian structure of large language models\n(LLMs), which typically operate with a large $C$ exceeding $10^4$ or $10^5$.", "published": "2025-05-05 17:34:57", "link": "http://arxiv.org/abs/2505.02809v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Adaptive Bidding Policies for First-Price Auctions with Budget Constraints under Non-stationarity", "abstract": "We study how a budget-constrained bidder should learn to adaptively bid in\nrepeated first-price auctions to maximize her cumulative payoff. This problem\narose due to an industry-wide shift from second-price auctions to first-price\nauctions in display advertising recently, which renders truthful bidding (i.e.,\nalways bidding one's private value) no longer optimal. We propose a simple\ndual-gradient-descent-based bidding policy that maintains a dual variable for\nbudget constraint as the bidder consumes her budget. In analysis, we consider\ntwo settings regarding the bidder's knowledge of her private values in the\nfuture: (i) an uninformative setting where all the distributional knowledge\n(can be non-stationary) is entirely unknown to the bidder, and (ii) an\ninformative setting where a prediction of the budget allocation in advance. We\ncharacterize the performance loss (or regret) relative to an optimal policy\nwith complete information on the stochasticity. For uninformative setting, We\nshow that the regret is \\tilde{O}(\\sqrt{T}) plus a variation term that reflects\nthe non-stationarity of the value distributions, and this is of optimal order.\nWe then show that we can get rid of the variation term with the help of the\nprediction; specifically, the regret is \\tilde{O}(\\sqrt{T}) plus the prediction\nerror term in the informative setting.", "published": "2025-05-05 17:13:02", "link": "http://arxiv.org/abs/2505.02796v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "Cooperative Bayesian and variance networks disentangle aleatoric and epistemic uncertainties", "abstract": "Real-world data contains aleatoric uncertainty - irreducible noise arising\nfrom imperfect measurements or from incomplete knowledge about the data\ngeneration process. Mean variance estimation (MVE) networks can learn this type\nof uncertainty but require ad-hoc regularization strategies to avoid\noverfitting and are unable to predict epistemic uncertainty (model\nuncertainty). Conversely, Bayesian neural networks predict epistemic\nuncertainty but are notoriously difficult to train due to the approximate\nnature of Bayesian inference. We propose to cooperatively train a variance\nnetwork with a Bayesian neural network and demonstrate that the resulting model\ndisentangles aleatoric and epistemic uncertainties while improving the mean\nestimation. We demonstrate the effectiveness and scalability of this method\nacross a diverse range of datasets, including a time-dependent heteroscedastic\nregression dataset we created where the aleatoric uncertainty is known. The\nproposed method is straightforward to implement, robust, and adaptable to\nvarious model architectures.", "published": "2025-05-05 15:50:52", "link": "http://arxiv.org/abs/2505.02743v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Less is More: Efficient Weight Farcasting with 1-Layer Neural Network", "abstract": "Addressing the computational challenges inherent in training large-scale deep\nneural networks remains a critical endeavor in contemporary machine learning\nresearch. While previous efforts have focused on enhancing training efficiency\nthrough techniques such as gradient descent with momentum, learning rate\nscheduling, and weight regularization, the demand for further innovation\ncontinues to burgeon as model sizes keep expanding. In this study, we introduce\na novel framework which diverges from conventional approaches by leveraging\nlong-term time series forecasting techniques. Our method capitalizes solely on\ninitial and final weight values, offering a streamlined alternative for complex\nmodel architectures. We also introduce a novel regularizer that is tailored to\nenhance the forecasting performance of our approach. Empirical evaluations\nconducted on synthetic weight sequences and real-world deep learning\narchitectures, including the prominent large language model DistilBERT,\ndemonstrate the superiority of our method in terms of forecasting accuracy and\ncomputational efficiency. Notably, our framework showcases improved performance\nwhile requiring minimal additional computational overhead, thus presenting a\npromising avenue for accelerating the training process across diverse tasks and\narchitectures.", "published": "2025-05-05 15:10:20", "link": "http://arxiv.org/abs/2505.02714v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Aerodynamic and structural airfoil shape optimisation via Transfer Learning-enhanced Deep Reinforcement Learning", "abstract": "The main objective of this paper is to introduce a transfer\nlearning-enhanced, multi-objective, deep reinforcement learning (DRL)\nmethodology that is able to optimise the geometry of any airfoil based on\nconcomitant aerodynamic and structural criteria. To showcase the method, we aim\nto maximise the lift-to-drag ratio $C_L/C_D$ while preserving the structural\nintegrity of the airfoil -- as modelled by its maximum thickness -- and train\nthe DRL agent using a list of different transfer learning (TL) strategies. The\nperformance of the DRL agent is compared with Particle Swarm Optimisation\n(PSO), a traditional gradient-free optimisation method. Results indicate that\nDRL agents are able to perform multi-objective shape optimisation, that the DRL\napproach outperforms PSO in terms of computational efficiency and shape\noptimisation performance, and that the TL-enhanced DRL agent achieves\nperformance comparable to the DRL one, while further saving substantial\ncomputational resources.", "published": "2025-05-05 13:26:11", "link": "http://arxiv.org/abs/2505.02634v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Mirror Mean-Field Langevin Dynamics", "abstract": "The mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized\nnonlinear convex functional on the Wasserstein space over $\\mathbb{R}^d$, and\nhas gained attention recently as a model for the gradient descent dynamics of\ninteracting particle systems such as infinite-width two-layer neural networks.\nHowever, many problems of interest have constrained domains, which are not\nsolved by existing mean-field algorithms due to the global diffusion term. We\nstudy the optimization of probability measures constrained to a convex subset\nof $\\mathbb{R}^d$ by proposing the \\emph{mirror mean-field Langevin dynamics}\n(MMFLD), an extension of MFLD to the mirror Langevin framework. We obtain\nlinear convergence guarantees for the continuous MMFLD via a uniform\nlog-Sobolev inequality, and uniform-in-time propagation of chaos results for\nits time- and particle-discretized counterpart.", "published": "2025-05-05 12:49:42", "link": "http://arxiv.org/abs/2505.02621v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Entropic Mirror Descent for Linear Systems: Polyak's Stepsize and Implicit Bias", "abstract": "This paper focuses on applying entropic mirror descent to solve linear\nsystems, where the main challenge for the convergence analysis stems from the\nunboundedness of the domain. To overcome this without imposing restrictive\nassumptions, we introduce a variant of Polyak-type stepsizes. Along the way, we\nstrengthen the bound for $\\ell_1$-norm implicit bias, obtain sublinear and\nlinear convergence results, and generalize the convergence result to arbitrary\nconvex $L$-smooth functions. We also propose an alternative method that avoids\nexponentiation, resembling the original Hadamard descent, but with provable\nconvergence.", "published": "2025-05-05 12:33:18", "link": "http://arxiv.org/abs/2505.02614v1", "categories": ["math.OC", "cs.LG", "stat.ML", "90C25 (Primary) 65K05, 47J25, 90C30 (Secondary)"], "primary_category": "math.OC"}
{"title": "Lane-Wise Highway Anomaly Detection", "abstract": "This paper proposes a scalable and interpretable framework for lane-wise\nhighway traffic anomaly detection, leveraging multi-modal time series data\nextracted from surveillance cameras. Unlike traditional sensor-dependent\nmethods, our approach uses AI-powered vision models to extract lane-specific\nfeatures, including vehicle count, occupancy, and truck percentage, without\nrelying on costly hardware or complex road modeling. We introduce a novel\ndataset containing 73,139 lane-wise samples, annotated with four classes of\nexpert-validated anomalies: three traffic-related anomalies (lane blockage and\nrecovery, foreign object intrusion, and sustained congestion) and one\nsensor-related anomaly (camera angle shift). Our multi-branch detection system\nintegrates deep learning, rule-based logic, and machine learning to improve\nrobustness and precision. Extensive experiments demonstrate that our framework\noutperforms state-of-the-art methods in precision, recall, and F1-score,\nproviding a cost-effective and scalable solution for real-world intelligent\ntransportation systems.", "published": "2025-05-05 12:32:23", "link": "http://arxiv.org/abs/2505.02613v1", "categories": ["eess.IV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Low-Loss Space in Neural Networks is Continuous and Fully Connected", "abstract": "Visualizations of the loss landscape in neural networks suggest that minima\nare isolated points. However, both theoretical and empirical studies indicate\nthat it is possible to connect two different minima with a path consisting of\nintermediate points that also have low loss. In this study, we propose a new\nalgorithm which investigates low-loss paths in the full parameter space, not\nonly between two minima. Our experiments on LeNet5, ResNet18, and Compact\nConvolutional Transformer architectures consistently demonstrate the existence\nof such continuous paths in the parameter space. These results suggest that the\nlow-loss region is a fully connected and continuous space in the parameter\nspace. Our findings provide theoretical insight into neural network\nover-parameterization, highlighting that parameters collectively define a\nhigh-dimensional low-loss space, implying parameter redundancy exists only\nwithin individual models and not throughout the entire low-loss space.\nAdditionally, our work also provides new visualization methods and\nopportunities to improve model generalization by exploring the low-loss space\nthat is closer to the origin.", "published": "2025-05-05 12:16:55", "link": "http://arxiv.org/abs/2505.02604v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Cross-Modality Modeling for Time Series Analytics: A Survey in the LLM Era", "abstract": "The proliferation of edge devices has generated an unprecedented volume of\ntime series data across different domains, motivating various well-customized\nmethods. Recently, Large Language Models (LLMs) have emerged as a new paradigm\nfor time series analytics by leveraging the shared sequential nature of textual\ndata and time series. However, a fundamental cross-modality gap between time\nseries and LLMs exists, as LLMs are pre-trained on textual corpora and are not\ninherently optimized for time series. Many recent proposals are designed to\naddress this issue. In this survey, we provide an up-to-date overview of\nLLMs-based cross-modality modeling for time series analytics. We first\nintroduce a taxonomy that classifies existing approaches into four groups based\non the type of textual data employed for time series modeling. We then\nsummarize key cross-modality strategies, e.g., alignment and fusion, and\ndiscuss their applications across a range of downstream tasks. Furthermore, we\nconduct experiments on multimodal datasets from different application domains\nto investigate effective combinations of textual data and cross-modality\nstrategies for enhancing time series analytics. Finally, we suggest several\npromising directions for future research. This survey is designed for a range\nof professionals, researchers, and practitioners interested in LLM-based time\nseries modeling.", "published": "2025-05-05 11:35:33", "link": "http://arxiv.org/abs/2505.02583v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning and Online Replication of Grasp Forces from Electromyography Signals for Prosthetic Finger Control", "abstract": "Partial hand amputations significantly affect the physical and psychosocial\nwell-being of individuals, yet intuitive control of externally powered\nprostheses remains an open challenge. To address this gap, we developed a\nforce-controlled prosthetic finger activated by electromyography (EMG) signals.\nThe prototype, constructed around a wrist brace, functions as a supernumerary\nfinger placed near the index, allowing for early-stage evaluation on unimpaired\nsubjects. A neural network-based model was then implemented to estimate\nfingertip forces from EMG inputs, allowing for online adjustment of the\nprosthetic finger grip strength. The force estimation model was validated\nthrough experiments with ten participants, demonstrating its effectiveness in\npredicting forces. Additionally, online trials with four users wearing the\nprosthesis exhibited precise control over the device. Our findings highlight\nthe potential of using EMG-based force estimation to enhance the functionality\nof prosthetic fingers.", "published": "2025-05-05 11:23:51", "link": "http://arxiv.org/abs/2505.02574v1", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "FedSDAF: Leveraging Source Domain Awareness for Enhanced Federated Domain Generalization", "abstract": "Traditional domain generalization approaches predominantly focus on\nleveraging target domain-aware features while overlooking the critical role of\nsource domain-specific characteristics, particularly in federated settings with\ninherent data isolation. To address this gap, we propose the Federated Source\nDomain Awareness Framework (FedSDAF), the first method to systematically\nexploit source domain-aware features for enhanced federated domain\ngeneralization (FedDG). The FedSDAF framework consists of two synergistic\ncomponents: the Domain-Invariant Adapter, which preserves critical\ndomain-invariant features, and the Domain-Aware Adapter, which extracts and\nintegrates source domain-specific knowledge using a Multihead Self-Attention\nmechanism (MHSA). Furthermore, we introduce a bidirectional knowledge\ndistillation mechanism that fosters knowledge sharing among clients while\nsafeguarding privacy. Our approach represents the first systematic exploitation\nof source domain-aware features, resulting in significant advancements in model\ngeneralization capability.Extensive experiments on four standard benchmarks\n(OfficeHome, PACS, VLCS, and DomainNet) show that our method consistently\nsurpasses state-of-the-art federated domain generalization approaches, with\naccuracy gains of 5.2-13.8%. The source code is available at\nhttps://github.com/pizzareapers/FedSDAF.", "published": "2025-05-05 09:49:11", "link": "http://arxiv.org/abs/2505.02515v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Uncovering Population PK Covariates from VAE-Generated Latent Spaces", "abstract": "Population pharmacokinetic (PopPK) modelling is a fundamental tool for\nunderstanding drug behaviour across diverse patient populations and enabling\npersonalized dosing strategies to improve therapeutic outcomes. A key challenge\nin PopPK analysis lies in identifying and modelling covariates that influence\ndrug absorption, as these relationships are often complex and nonlinear.\nTraditional methods may fail to capture hidden patterns within the data. In\nthis study, we propose a data-driven, model-free framework that integrates\nVariational Autoencoders (VAEs) deep learning model and LASSO regression to\nuncover key covariates from simulated tacrolimus pharmacokinetic (PK) profiles.\nThe VAE compresses high-dimensional PK signals into a structured latent space,\nachieving accurate reconstruction with a mean absolute percentage error (MAPE)\nof 2.26%. LASSO regression is then applied to map patient-specific covariates\nto the latent space, enabling sparse feature selection through L1\nregularization. This approach consistently identifies clinically relevant\ncovariates for tacrolimus including SNP, age, albumin, and hemoglobin which are\nretained across the tested regularization strength levels, while effectively\ndiscarding non-informative features. The proposed VAE-LASSO methodology offers\na scalable, interpretable, and fully data-driven solution for covariate\nselection, with promising applications in drug development and precision\npharmacotherapy.", "published": "2025-05-05 09:47:39", "link": "http://arxiv.org/abs/2505.02514v1", "categories": ["cs.LG", "q-bio.QM", "I.2.1; I.5.1; I.5.2; I.5.4; I.5.5"], "primary_category": "cs.LG"}
{"title": "Resolving Memorization in Empirical Diffusion Model for Manifold Data in High-Dimensional Spaces", "abstract": "Diffusion models is a popular computational tool to generate new data\nsamples. It utilizes a forward diffusion process that add noise to the data\ndistribution and then use a reverse process to remove noises to produce samples\nfrom the data distribution. However, when the empirical data distribution\nconsists of $n$ data point, using the empirical diffusion model will\nnecessarily produce one of the existing data points. This is often referred to\nas the memorization effect, which is usually resolved by sophisticated machine\nlearning procedures in the current literature. This work shows that the\nmemorization problem can be resolved by a simple inertia update step at the end\nof the empirical diffusion model simulation. Our inertial diffusion model\nrequires only the empirical diffusion model score function and it does not\nrequire any further training. We show that choosing the inertia diffusion model\nsample distribution is an $O\\left(n^{-\\frac{2}{d+4}}\\right)$ Wasserstein-1\napproximation of a data distribution lying on a $C^2$ manifold of dimension\n$d$. Since this estimate is significant smaller the Wasserstein1 distance\nbetween population and empirical distributions, it rigorously shows the\ninertial diffusion model produces new data samples. Remarkably, this upper\nbound is completely free of the ambient space dimension, since there is no\ntraining involved. Our analysis utilizes the fact that the inertial diffusion\nmodel samples are approximately distributed as the Gaussian kernel density\nestimator on the manifold. This reveals an interesting connection between\ndiffusion model and manifold learning.", "published": "2025-05-05 09:40:41", "link": "http://arxiv.org/abs/2505.02508v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Exploring Design Choices for Autoregressive Deep Learning Climate Models", "abstract": "Deep Learning models have achieved state-of-the-art performance in\nmedium-range weather prediction but often fail to maintain physically\nconsistent rollouts beyond 14 days. In contrast, a few atmospheric models\ndemonstrate stability over decades, though the key design choices enabling this\nremain unclear. This study quantitatively compares the long-term stability of\nthree prominent DL-MWP architectures - FourCastNet, SFNO, and ClimaX - trained\non ERA5 reanalysis data at 5.625{\\deg} resolution. We systematically assess the\nimpact of autoregressive training steps, model capacity, and choice of\nprognostic variables, identifying configurations that enable stable 10-year\nrollouts while preserving the statistical properties of the reference dataset.\nNotably, rollouts with SFNO exhibit the greatest robustness to hyperparameter\nchoices, yet all models can experience instability depending on the random seed\nand the set of prognostic variables", "published": "2025-05-05 09:37:58", "link": "http://arxiv.org/abs/2505.02506v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bayesian Robust Aggregation for Federated Learning", "abstract": "Federated Learning enables collaborative training of machine learning models\non decentralized data. This scheme, however, is vulnerable to adversarial\nattacks, when some of the clients submit corrupted model updates. In real-world\nscenarios, the total number of compromised clients is typically unknown, with\nthe extent of attacks potentially varying over time. To address these\nchallenges, we propose an adaptive approach for robust aggregation of model\nupdates based on Bayesian inference. The mean update is defined by the maximum\nof the likelihood marginalized over probabilities of each client to be\n`honest'. As a result, the method shares the simplicity of the classical\naverage estimators (e.g., sample mean or geometric median), being independent\nof the number of compromised clients. At the same time, it is as effective\nagainst attacks as methods specifically tailored to Federated Learning, such as\nKrum. We compare our approach with other aggregation schemes in federated\nsetting on three benchmark image classification data sets. The proposed method\nconsistently achieves state-of-the-art performance across various attack types\nwith static and varying number of malicious clients.", "published": "2025-05-05 09:16:43", "link": "http://arxiv.org/abs/2505.02490v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deep learning of personalized priors from past MRI scans enables fast, quality-enhanced point-of-care MRI with low-cost systems", "abstract": "Magnetic resonance imaging (MRI) offers superb-quality images, but its\naccessibility is limited by high costs, posing challenges for patients\nrequiring longitudinal care. Low-field MRI provides affordable imaging with\nlow-cost devices but is hindered by long scans and degraded image quality,\nincluding low signal-to-noise ratio (SNR) and tissue contrast. We propose a\nnovel healthcare paradigm: using deep learning to extract personalized features\nfrom past standard high-field MRI scans and harnessing them to enable\naccelerated, enhanced-quality follow-up scans with low-cost systems. To\novercome the SNR and contrast differences, we introduce ViT-Fuser, a\nfeature-fusion vision transformer that learns features from past scans, e.g.\nthose stored in standard DICOM CDs. We show that \\textit{a single prior scan is\nsufficient}, and this scan can come from various MRI vendors, field strengths,\nand pulse sequences. Experiments with four datasets, including glioblastoma\ndata, low-field ($50mT$), and ultra-low-field ($6.5mT$) data, demonstrate that\nViT-Fuser outperforms state-of-the-art methods, providing enhanced-quality\nimages from accelerated low-field scans, with robustness to out-of-distribution\ndata. Our freely available framework thus enables rapid, diagnostic-quality,\nlow-cost imaging for wide healthcare applications.", "published": "2025-05-05 08:55:14", "link": "http://arxiv.org/abs/2505.02470v1", "categories": ["eess.IV", "cs.LG", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Efficient Continual Learning in Keyword Spotting using Binary Neural Networks", "abstract": "Keyword spotting (KWS) is an essential function that enables interaction with\nubiquitous smart devices. However, in resource-limited devices, KWS models are\noften static and can thus not adapt to new scenarios, such as added keywords.\nTo overcome this problem, we propose a Continual Learning (CL) approach for KWS\nbuilt on Binary Neural Networks (BNNs). The framework leverages the reduced\ncomputation and memory requirements of BNNs while incorporating techniques that\nenable the seamless integration of new keywords over time. This study evaluates\nseven CL techniques on a 16-class use case, reporting an accuracy exceeding 95%\nfor a single additional keyword and up to 86% for four additional classes.\nSensitivity to the amount of training samples in the CL phase, and differences\nin computational complexities are being evaluated. These evaluations\ndemonstrate that batch-based algorithms are more sensitive to the CL dataset\nsize, and that differences between the computational complexities are\ninsignificant. These findings highlight the potential of developing an\neffective and computationally efficient technique for continuously integrating\nnew keywords in KWS applications that is compatible with resource-constrained\ndevices.", "published": "2025-05-05 08:54:19", "link": "http://arxiv.org/abs/2505.02469v1", "categories": ["cs.LG", "cs.SD"], "primary_category": "cs.LG"}
{"title": "A probabilistic view on Riemannian machine learning models for SPD matrices", "abstract": "The goal of this paper is to show how different machine learning tools on the\nRiemannian manifold $\\mathcal{P}_d$ of Symmetric Positive Definite (SPD)\nmatrices can be united under a probabilistic framework. For this, we will need\nseveral Gaussian distributions defined on $\\mathcal{P}_d$. We will show how\npopular classifiers on $\\mathcal{P}_d$ can be reinterpreted as Bayes\nClassifiers using these Gaussian distributions. These distributions will also\nbe used for outlier detection and dimension reduction. By showing that those\ndistributions are pervasive in the tools used on $\\mathcal{P}_d$, we allow for\nother machine learning tools to be extended to $\\mathcal{P}_d$.", "published": "2025-05-05 06:50:06", "link": "http://arxiv.org/abs/2505.02402v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Connecting Thompson Sampling and UCB: Towards More Efficient Trade-offs Between Privacy and Regret", "abstract": "We address differentially private stochastic bandit problems from the angles\nof exploring the deep connections among Thompson Sampling with Gaussian priors,\nGaussian mechanisms, and Gaussian differential privacy (GDP). We propose\nDP-TS-UCB, a novel parametrized private bandit algorithm that enables to trade\noff privacy and regret. DP-TS-UCB satisfies $ \\tilde{O}\n\\left(T^{0.25(1-\\alpha)}\\right)$-GDP and enjoys an $O\n\\left(K\\ln^{\\alpha+1}(T)/\\Delta \\right)$ regret bound, where $\\alpha \\in [0,1]$\ncontrols the trade-off between privacy and regret. Theoretically, our DP-TS-UCB\nrelies on anti-concentration bounds of Gaussian distributions and links\nexploration mechanisms in Thompson Sampling-based algorithms and Upper\nConfidence Bound-based algorithms, which may be of independent interest.", "published": "2025-05-05 05:48:52", "link": "http://arxiv.org/abs/2505.02383v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices", "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across\nvarious tasks, but their large storage and computational requirements constrain\ntheir deployment on edge devices. To address this, we propose EntroLLM, a novel\ncompression framework that integrates mixed quantization with entropy coding to\nreduce storage overhead while maintaining model accuracy. Our method applies a\nlayer-wise mixed quantization scheme - choosing between symmetric and\nasymmetric quantization based on individual layer weight distributions - to\noptimize compressibility. We then employ Huffman encoding for lossless\ncompression of the quantized weights, significantly reducing memory bandwidth\nrequirements. Furthermore, we introduce parallel Huffman decoding, which\nenables efficient retrieval of encoded weights during inference, ensuring\nminimal latency impact. Our experiments on edge-compatible LLMs, including\nsmolLM-1.7B-Instruct, phi3-mini-4k-Instruct, and mistral-7B-Instruct,\ndemonstrate that EntroLLM achieves up to $30%$ storage reduction compared to\nuint8 models and up to $65%$ storage reduction compared to uint4 models, while\npreserving perplexity and accuracy, on language benchmark tasks. We further\nshow that our method enables $31.9%$ - $146.6%$ faster inference throughput on\nmemory-bandwidth-limited edge devices, such as NVIDIA Jetson P3450, by reducing\nthe required data movement. The proposed approach requires no additional\nre-training and is fully compatible with existing post-training quantization\nmethods, making it a practical solution for edge LLMs.", "published": "2025-05-05 05:42:14", "link": "http://arxiv.org/abs/2505.02380v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning simple heuristic rules for classifying materials based on chemical composition", "abstract": "In the past decade, there has been a significant interest in the use of\nmachine learning approaches in materials science research. Conventional deep\nlearning approaches that rely on complex, nonlinear models have become\nincreasingly important in computational materials science due to their high\npredictive accuracy. In contrast to these approaches, we have shown in a recent\nwork that a remarkably simple learned heuristic rule -- based on the concept of\ntopogivity -- can classify whether a material is topological using only its\nchemical composition. In this paper, we go beyond the topology classification\nscenario by also studying the use of machine learning to develop simple\nheuristic rules for classifying whether a material is a metal based on chemical\ncomposition. Moreover, we present a framework for incorporating\nchemistry-informed inductive bias based on the structure of the periodic table.\nFor both the topology classification and the metallicity classification tasks,\nwe empirically characterize the performance of simple heuristic rules fit with\nand without chemistry-informed inductive bias across a wide range of training\nset sizes. We find evidence that incorporating chemistry-informed inductive\nbias can reduce the amount of training data required to reach a given level of\ntest accuracy.", "published": "2025-05-05 04:46:41", "link": "http://arxiv.org/abs/2505.02361v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Enabling Local Neural Operators to perform Equation-Free System-Level Analysis", "abstract": "Neural Operators (NOs) provide a powerful framework for computations\ninvolving physical laws that can be modelled by (integro-) partial differential\nequations (PDEs), directly learning maps between infinite-dimensional function\nspaces that bypass both the explicit equation identification and their\nsubsequent numerical solving. Still, NOs have so far primarily been employed to\nexplore the dynamical behavior as surrogates of brute-force temporal\nsimulations/predictions. Their potential for systematic rigorous numerical\nsystem-level tasks, such as fixed-point, stability, and bifurcation analysis -\ncrucial for predicting irreversible transitions in real-world phenomena -\nremains largely unexplored. Toward this aim, inspired by the Equation-Free\nmultiscale framework, we propose and implement a framework that integrates\n(local) NOs with advanced iterative numerical methods in the Krylov subspace,\nso as to perform efficient system-level stability and bifurcation analysis of\nlarge-scale dynamical systems. Beyond fixed point, stability, and bifurcation\nanalysis enabled by local in time NOs, we also demonstrate the usefulness of\nlocal in space as well as in space-time (\"patch\") NOs in accelerating the\ncomputer-aided analysis of spatiotemporal dynamics. We illustrate our framework\nvia three nonlinear PDE benchmarks: the 1D Allen-Cahn equation, which undergoes\nmultiple concatenated pitchfork bifurcations; the Liouville-Bratu-Gelfand PDE,\nwhich features a saddle-node tipping point; and the FitzHugh-Nagumo (FHN)\nmodel, consisting of two coupled PDEs that exhibit both Hopf and saddle-node\nbifurcations.", "published": "2025-05-05 01:17:18", "link": "http://arxiv.org/abs/2505.02308v1", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "stat.ML", "68T05, 62M45, 65P30, 65J15, 65J22, 65F15, 41A35, 47J25, 35B40,\n  37M20, 37N30", "G.1.8; G.1.5; G.1.3; G.1.10; G.4; I.2.6; I.6.5; J.2"], "primary_category": "cs.LG"}
{"title": "Entropy-Guided Sampling of Flat Modes in Discrete Spaces", "abstract": "Sampling from flat modes in discrete spaces is a crucial yet underexplored\nproblem. Flat modes represent robust solutions and have broad applications in\ncombinatorial optimization and discrete generative modeling. However, existing\nsampling algorithms often overlook the mode volume and struggle to capture flat\nmodes effectively. To address this limitation, we propose \\emph{Entropic\nDiscrete Langevin Proposal} (EDLP), which incorporates local entropy into the\nsampling process through a continuous auxiliary variable under a joint\ndistribution. The local entropy term guides the discrete sampler toward flat\nmodes with a small overhead. We provide non-asymptotic convergence guarantees\nfor EDLP in locally log-concave discrete distributions. Empirically, our method\nconsistently outperforms traditional approaches across tasks that require\nsampling from flat basins, including Bernoulli distribution, restricted\nBoltzmann machines, combinatorial optimization, and binary neural networks.", "published": "2025-05-05 00:12:34", "link": "http://arxiv.org/abs/2505.02296v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "dyGRASS: Dynamic Spectral Graph Sparsification via Localized Random Walks on GPUs", "abstract": "This work presents dyGRASS, an efficient dynamic algorithm for spectral\nsparsification of large undirected graphs that undergo streaming edge\ninsertions and deletions. At its core, dyGRASS employs a random-walk-based\nmethod to efficiently estimate node-to-node distances in both the original\ngraph (for decremental update) and its sparsifier (for incremental update). For\nincremental updates, dyGRASS enables the identification of spectrally critical\nedges among the updates to capture the latest structural changes. For\ndecremental updates, dyGRASS facilitates the recovery of important edges from\nthe original graph back into the sparsifier. To further enhance computational\nefficiency, dyGRASS employs a GPU-based non-backtracking random walk scheme\nthat allows multiple walkers to operate simultaneously across various target\nupdates. This parallelization significantly improves both the performance and\nscalability of the proposed dyGRASS framework. Our comprehensive experimental\nevaluations reveal that dyGRASS achieves approximately a 10x speedup compared\nto the state-of-the-art incremental sparsification (inGRASS) algorithm while\neliminating the setup overhead and improving solution quality in incremental\nspectral sparsification tasks. Moreover, dyGRASS delivers high efficiency and\nsuperior solution quality for fully dynamic graph sparsification, accommodating\nboth edge insertions and deletions across a diverse range of graph instances\noriginating from integrated circuit simulations, finite element analysis, and\nsocial networks.", "published": "2025-05-05 15:48:44", "link": "http://arxiv.org/abs/2505.02741v1", "categories": ["cs.SI", "cs.NA", "math.NA"], "primary_category": "cs.SI"}
{"title": "Advances on the finite element discretization of fluid-structure interaction problems", "abstract": "We review the main features of an unfitted finite element method for\ninterface and fluid-structure interaction problems based on a distributed\nLagrange multiplier in the spirit of the fictitious domain approach. We recall\nour theoretical findings concerning well-posedeness, stability, and convergence\nof the numerical schemes, and discuss the related computational challenges. In\nthe case of elliptic interface problems, we also present a posteriori error\nestimates.", "published": "2025-05-05 11:59:58", "link": "http://arxiv.org/abs/2505.02594v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A posteriori error estimates for the finite element approximation of the convection-diffusion-reaction equation based on the variational multiscale concept", "abstract": "In this study, we employ the variational multiscale (VMS) concept to develop\na posteriori error estimates for the stationary convection-diffusion-reaction\nequation. The variational multiscale method is based on splitting the\ncontinuous part of the problem into a resolved scale (coarse scale) and an\nunresolved scale (fine scale). The unresolved scale (also known as the sub-grid\nscale) is modeled by choosing it proportional to the component of the residual\northogonal to the finite element space, leading to the orthogonal sub-grid\nscale (OSGS) method. The idea is then to use the modeled sub-grid scale as an\nerror estimator, considering its contribution in the element interiors and on\nthe edges. We present the results of the a priori analysis and two different\nstrategies for the a posteriori error analysis for the OSGS method. Our\nproposal is to use a scaled norm of the sub-grid scales as an a posteriori\nerror estimate in the so-called stabilized norm of the problem. This norm has\ncontrol over the convective term, which is necessary for convection-dominated\nproblems. Numerical examples show the reliable performance of the proposed\nerror estimator compared to other error estimators belonging to the variational\nmultiscale family.", "published": "2025-05-05 10:12:34", "link": "http://arxiv.org/abs/2505.02531v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Finite difference method for nonlinear damped viscoelastic Euler-Bernoulli beam model", "abstract": "We propose and analyze the numerical approximation for a viscoelastic\nEuler-Bernoulli beam model containing a nonlinear strong damping coefficient.\nThe finite difference method is used for spatial discretization, while the\nbackward Euler method and the averaged PI rule are applied for temporal\ndiscretization. The long-time stability and the finite-time error estimate of\nthe numerical solutions are derived for both the semi-discrete-in-space scheme\nand the fully-discrete scheme. Furthermore, the Leray-Schauder theorem is used\nto derive the existence and uniqueness of the fully-discrete numerical\nsolutions. Finally, the numerical results verify the theoretical analysis.", "published": "2025-05-05 09:50:02", "link": "http://arxiv.org/abs/2505.02517v1", "categories": ["math.NA", "cs.NA", "35L75, 65M15, 65M22, 45K05"], "primary_category": "math.NA"}
{"title": "Sampling Kantorovich operators for speckle noise reduction using a Down-Up scaling approach and gap filling in remote sensing images", "abstract": "In the literature, several approaches have been proposed for restoring and\nenhancing remote sensing images, including methods based on interpolation,\nfiltering, and deep learning. In this paper, we investigate the application of\nmultivariate sampling Kantorovich (SK) operators for image reconstruction, with\na particular focus on gap filling and speckle noise reduction. To understand\nthe accuracy performances of the proposed algorithms, we first derive a\nquantitative estimate in $C(\\R^n)$ for the error of approximation using the\nEuler-Maclaurin summation formula, which provides sharper error bounds under\nminimal regularity conditions. We also establish a convergence result and a\nquantitative estimate with respect to the dissimilarity index measured by the\ncontinuous SSIM for functions in Lebesgue spaces. Additionally, we prove a\nmultidimensional linear prediction result, which is used to design a new\nSK-based reconstruction algorithm to handle missing data, that we call LP-SK\nalgorithm. To address speckle noise, we integrate SK operators into a newly\nproposed Down-Up scaling approach. Numerical tests are presented on synthetic\nand real SAR images to validate the proposed methods. Performance is assessed\nusing similarity metrics such as SSIM and PSNR, along with speckle-specific\nindexes. Comparative analysis with state-of-the-art techniques highlights the\neffectiveness of the proposed approaches.", "published": "2025-05-05 07:38:17", "link": "http://arxiv.org/abs/2505.02422v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Optimal error estimates of a second-order temporally finite element method for electrohydrodynamic equations", "abstract": "In this work, we mainly present the optimal convergence rates of the\ntemporally second-order finite element scheme for solving the\nelectrohydrodynamic equation. Suffering from the highly coupled nonlinearity,\nthe convergence analysis of the numerical schemes for such a system is rather\nrare, not to mention the optimal error estimates for the high-order temporally\nscheme. To this end, we abandon the traditional error analysis method following\nthe process of energy estimate, which may lead to the loss of accuracy.\nInstead, we note that the charge density also possesses the \"energy\" decaying\nproperty directly derived by its governing equation, although it does not\nappear in the energy stability analysis. This fact allows us to control the\nerror terms of the charge density more conveniently, which finally leads to the\noptimal convergence rates. Several numerical examples are provided to\ndemonstrate the theoretical results, including the energy stability, mass\nconservation, and convergence rates.", "published": "2025-05-05 03:55:30", "link": "http://arxiv.org/abs/2505.02345v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On Trigonometric Interpolation and Its Applications", "abstract": "In this paper, we propose a new trigonometric interpolation algorithm and\nestablish relevant convergent properties. The method adjusts an existing\ntrigonometric interpolation algorithm such that it can better leverage Fast\nFourier Transform (FFT) to enhance efficiency. The algorithm can be formulated\nin a way such that certain cancellation effects can be effectively leveraged\nfor error analysis, which enables us not only to obtain the desired uniform\nconvergent rate of the approximation to a function, but desired uniform\nconvergent rates for its derivatives as well.\n  We further enhance the algorithm so it can be applied to non-periodic\nfunctions defined on bounded intervals. Numerical testing results confirm\ndecent accurate performance of the algorithm. For its application, we\ndemonstrate how it can be applied to estimate integrals and solve\nlinear/non-linear ordinary differential equation (ODE). The test results show\nthat it significantly outperforms Trapezoid/Simpson method on integral and\nstandard Runge-Kutta algorithm on ODE. In addition, we show some numerical\nevidences that estimation error of the algorithm likely exhibits ``local\nproperty\", i.e. error at a point tends not to propagate, which avoids\nsignificant compounding error at some other place, as a remarkable advantage\ncompared to polynomial-based approximations.", "published": "2025-05-05 02:58:13", "link": "http://arxiv.org/abs/2505.02330v1", "categories": ["math.NA", "cs.NA", "Primary 65T40, Secondary 65L05"], "primary_category": "math.NA"}
{"title": "Optimally accurate operators for partial differential equations", "abstract": "In this contribution, we generalize the concept of \\textit{optimally accurate\noperators} proposed and used in a series of studies on the simulation of\nseismic wave propagation, particularly based on Geller \\& Takeuchi (1995).\nAlthough these operators have been mathematically and numerically proven to be\nmore accurate than conventional methods, the theory was specifically developed\nfor the equations of motion in linear elastic continuous media. Furthermore,\nthe original theory requires compensation for errors from each term due to\ntruncation at low orders during the error estimation, which has limited its\napplication to other types of physics described by partial differential\nequations.\n  Here, we present a new method that can automatically derive numerical\noperators for arbitrary partial differential equations. These operators, which\ninvolve a small number of nodes in time and space (compact operators), are more\naccurate than conventional ones and do not require meshing. Our method\nevaluates the weak formulation of the equations of motion, developed with the\naid of Taylor expansions.\n  We establish the link between our new method and the classic optimally\naccurate operators, showing that they produce identical coefficients in\nhomogeneous media. Finally, we perform a benchmark test for the 1D Poisson\nproblem across various heterogeneous media. The benchmarks demonstrate the\nsuperiority of our method compared to conventional operators, even when using a\nset of linear B-spline test functions (three-point hat functions). However, the\nconvergence rate can depend on the wavelength of the material property: when\nthe material property has the same wavelength as that of the field, the\nconvergence rate is O(4), whereas it can be less efficient O(2) for other\nmodels.", "published": "2025-05-05 02:29:19", "link": "http://arxiv.org/abs/2505.02320v1", "categories": ["physics.geo-ph", "cs.NA", "math.NA"], "primary_category": "physics.geo-ph"}
{"title": "Systemic Risk in the European Insurance Sector", "abstract": "This paper investigates the dynamic interdependencies between the European\ninsurance sector and key financial markets-equity, bond, and banking-by\nextending the Generalized Forecast Error Variance Decomposition framework to a\nbroad set of performance and risk indicators. Our empirical analysis, based on\na comprehensive dataset spanning January 2000 to October 2024, shows that the\ninsurance market is not a passive receiver of external shocks but an active\ncontributor in the propagation of systemic risk, particularly during periods of\nfinancial stress such as the subprime crisis, the European sovereign debt\ncrisis, and the COVID-19 pandemic. Significant heterogeneity is observed across\nsubsectors, with diversified multiline insurers and reinsurance playing key\nroles in shock transmission. Moreover, our granular company-level analysis\nreveals clusters of systemically central insurance companies, underscoring the\npresence of a core group that consistently exhibits high interconnectivity and\ninfluence in risk propagation.", "published": "2025-05-05 13:27:15", "link": "http://arxiv.org/abs/2505.02635v1", "categories": ["q-fin.CP", "q-fin.GN"], "primary_category": "q-fin.CP"}
{"title": "Why is the volatility of single stocks so much rougher than that of the S&P500?", "abstract": "The Nested factor model was introduced by Chicheportiche et al. to represent\nnon-linear correlations between stocks. Stock returns are explained by a\nstandard factor model, but the (log)-volatilities of factors and residuals are\nthemselves decomposed into factor modes, with a common dominant volatility mode\naffecting both market and sector factors but also residuals. Here, we consider\nthe case of a single factor where the only dominant log-volatility mode is\nrough, with a Hurst exponent $H \\simeq 0.11$ and the log-volatility residuals\nare ''super-rough'', with $H \\simeq 0$. We demonstrate that such a construction\nnaturally accounts for the somewhat surprising stylized fact reported by Wu et\nal. , where it has been observed that the Hurst exponents of stock indexes are\nlarge compared to those of individual stocks. We propose a statistical\nprocedure to estimate the Hurst factor exponent from the stock returns dynamics\ntogether with theoretical guarantees of its consistency. We demonstrate the\neffectiveness of our approach through numerical experiments and apply it to\ndaily stock data from the S&P500 index. The estimated roughness exponents for\nboth the factor and idiosyncratic components validate the assumptions\nunderlying our model.", "published": "2025-05-05 14:24:29", "link": "http://arxiv.org/abs/2505.02678v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Mallows-type model averaging: Non-asymptotic analysis and all-subset combination", "abstract": "Model averaging (MA) and ensembling play a crucial role in statistical and\nmachine learning practice. When multiple candidate models are considered, MA\ntechniques can be used to weight and combine them, often resulting in improved\npredictive accuracy and better estimation stability compared to model selection\n(MS) methods. In this paper, we address two challenges in combining least\nsquares estimators from both theoretical and practical perspectives. We first\nestablish several oracle inequalities for least squares MA via minimizing a\nMallows' $C_p$ criterion under an arbitrary candidate model set. Compared to\nexisting studies, these oracle inequalities yield faster excess risk and\ndirectly imply the asymptotic optimality of the resulting MA estimators under\nmilder conditions. Moreover, we consider candidate model construction and\ninvestigate the problem of optimal all-subset combination for least squares\nestimators, which is an important yet rarely discussed topic in the existing\nliterature. We show that there exists a fundamental limit to achieving the\noptimal all-subset MA risk. To attain this limit, we propose a novel\nMallows-type MA procedure based on a dimension-adaptive $C_p$ criterion. The\nimplicit ensembling effects of several MS procedures are also revealed and\ndiscussed. We conduct several numerical experiments to support our theoretical\nfindings and demonstrate the effectiveness of the proposed Mallows-type MA\nestimator.", "published": "2025-05-05 13:30:17", "link": "http://arxiv.org/abs/2505.02637v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Spacing and Wavelength Tunable Frequency Comb", "abstract": "Optical frequency combs are increasingly used in applications such as optical\ncommunications, radio signal processing, and dual-comb spectroscopy. Many of\nthese applications require a broad, flat spectrum with tunable center\nwavelength and tone spacing, while maintaining a consistent spectral profile.\nHowever, most existing OFC generators either lack tunability or cannot preserve\ntheir spectral shape during tuning. In this paper, we demonstrate a cavity-less\nOFC system based on an electro-optic comb combined with parametric spectral\nbroadening, achieving tone spacing tunability from 25 to 32 GHz and wavelength\ntunability from 1548 to 1568 nm. Our OFC features high output power (greater\nthan 2 W), broad bandwidth (greater than 90 nm), high optical signal-to-noise\nratio (OSNR greater than 25 dB), and, critically, a preserved spectral profile.\nWe show that this consistent spectral shape can be maintained by primarily\nadjusting the RF drive power and the gain of the optical amplifiers. We also\nprovide a quantitative analysis of the spectral profile variations during\ntuning.", "published": "2025-05-05 17:24:33", "link": "http://arxiv.org/abs/2505.02801v1", "categories": ["physics.optics", "eess.SP"], "primary_category": "physics.optics"}
{"title": "Multi-dimensional Parameter Estimation in RIS-aided MU-MIMO Channels", "abstract": "We address the channel estimation problem in reconfigurable intelligent\nsurface (RIS) aided broadband systems by proposing a dual-structure and\nmulti-dimensional transformations (DS-MDT) algorithm. The proposed approach\nleverages the dual-structure features of the channel parameters to assist users\nexperiencing weaker channel conditions, thereby enhancing estimation\nperformance. Moreover, given that the channel parameters are distributed across\nmultiple dimensions of the received tensor, the proposed algorithm employs\nmulti-dimensional transformations to effectively isolate and extract distinct\nparameters. The numerical results demonstrate the proposed algorithm reduces\nthe normalized mean square error (NMSE) by up to 10 dB while maintaining lower\ncomplexity compared to state-of-the-art methods.", "published": "2025-05-05 12:29:10", "link": "http://arxiv.org/abs/2505.02611v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sensing Framework Design and Performance Optimization with Action Detection for ISCC", "abstract": "Integrated sensing, communication, and computation (ISCC) has been regarded\nas a prospective technology for the next-generation wireless network,\nsupporting humancentric intelligent applications. However, the delay\nsensitivity of these computation-intensive applications, especially in a\nmultidevice ISCC system with limited resources, highlights the urgent need for\nefficient sensing task execution frameworks. To address this, we propose a\nresource-efficient sensing framework in this paper. Different from existing\nsolutions, it features a novel action detection module deployed at each device\nto detect the onset of an action. Only time windows filled with signals of\ninterest are offloaded to the edge server and processed by the edge recognition\nmodule, thus reducing overhead. Furthermore, we quantitatively analyze the\nsensing performance of the proposed sensing framework and formulate a sensing\naccuracy maximization problem under power, delay, and resource limitations for\nthe multi-device ISCC system. By decomposing it into two subproblems, we\ndevelop an alternating direction method of multipliers (ADMM)-based distributed\nalgorithm. It alternatively solves a sensing accuracy maximization subproblem\nat each device and employs a closed-form computation resource allocation\nstrategy at the edge server till convergence. Finally, a real-world test is\nconducted using commodity wireless devices to validate the sensing performance\nanalysis. Extensive test results demonstrate that our proposal achieves higher\nsensing accuracy under the limited resource compared to two baselines.", "published": "2025-05-05 10:52:03", "link": "http://arxiv.org/abs/2505.02554v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Multimodal Deep Learning-Empowered Beam Prediction in Future THz ISAC Systems", "abstract": "Integrated sensing and communication (ISAC) systems operating at terahertz\n(THz) bands are envisioned to enable both ultra-high data-rate communication\nand precise environmental awareness for next-generation wireless networks.\nHowever, the narrow width of THz beams makes them prone to misalignment and\nnecessitates frequent beam prediction in dynamic environments. Multimodal\nsensing, which integrates complementary modalities such as camera images,\npositional data, and radar measurements, has recently emerged as a promising\nsolution for proactive beam prediction. Nevertheless, existing multimodal\napproaches typically employ static fusion architectures that cannot adjust to\nvarying modality reliability and contributions, thereby degrading predictive\nperformance and robustness. To address this challenge, we propose a novel and\nefficient multimodal mixture-of-experts (MoE) deep learning framework for\nproactive beam prediction in THz ISAC systems. The proposed multimodal MoE\nframework employs multiple modality-specific expert networks to extract\nrepresentative features from individual sensing modalities, and dynamically\nfuses them using adaptive weights generated by a gating network according to\nthe instantaneous reliability of each modality. Simulation results in realistic\nvehicle-to-infrastructure (V2I) scenarios demonstrate that the proposed MoE\nframework outperforms traditional static fusion methods and unimodal baselines\nin terms of prediction accuracy and adaptability, highlighting its potential in\npractical THz ISAC systems with ultra-massive multiple-input multiple-output\n(MIMO).", "published": "2025-05-05 05:44:41", "link": "http://arxiv.org/abs/2505.02381v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning", "abstract": "Recent advances in reinforcement learning (RL) for large language model (LLM)\nfine-tuning show promise in addressing multi-objective tasks but still face\nsignificant challenges, including complex objective balancing, low training\nefficiency, poor scalability, and limited explainability. Leveraging ensemble\nlearning principles, we introduce an Ensemble Multi-Objective RL (EMORL)\nframework that fine-tunes multiple models with individual objectives while\noptimizing their aggregation after the training to improve efficiency and\nflexibility. Our method is the first to aggregate the last hidden states of\nindividual models, incorporating contextual information from multiple\nobjectives. This approach is supported by a hierarchical grid search algorithm\nthat identifies optimal weighted combinations. We evaluate EMORL on counselor\nreflection generation tasks, using text-scoring LLMs to evaluate the\ngenerations and provide rewards during RL fine-tuning. Through comprehensive\nexperiments on the PAIR and Psych8k datasets, we demonstrate the advantages of\nEMORL against existing baselines: significantly lower and more stable training\nconsumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds),\nimproved scalability and explainability, and comparable performance across\nmultiple objectives.", "published": "2025-05-05 11:30:46", "link": "http://arxiv.org/abs/2505.02579v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation", "abstract": "Recent advances in Large Language Models (LLMs) have positioned them as a\nprominent solution for Natural Language Processing tasks. Notably, they can\napproach these problems in a zero or few-shot manner, thereby eliminating the\nneed for training or fine-tuning task-specific models. However, LLMs face some\nchallenges, including hallucination and the presence of outdated knowledge or\nmissing information from specific domains in the training data. These problems\ncannot be easily solved by retraining the models with new data as it is a\ntime-consuming and expensive process. To mitigate these issues, Knowledge\nGraphs (KGs) have been proposed as a structured external source of information\nto enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for\nzero-shot Entity Disambiguation (ED). For that purpose, we leverage the\nhierarchical representation of the entities' classes in a KG to gradually prune\nthe candidate space as well as the entities' descriptions to enrich the input\nprompt with additional factual knowledge. Our evaluation on popular ED datasets\nshows that the proposed method outperforms non-enhanced and description-only\nenhanced LLMs, and has a higher degree of adaptability than task-specific\nmodels. Furthermore, we conduct an error analysis and discuss the impact of the\nleveraged KG's semantic expressivity on the ED performance.", "published": "2025-05-05 15:40:24", "link": "http://arxiv.org/abs/2505.02737v2", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "A Note on Statistically Accurate Tabular Data Generation Using Large Language Models", "abstract": "Large language models (LLMs) have shown promise in synthetic tabular data\ngeneration, yet existing methods struggle to preserve complex feature\ndependencies, particularly among categorical variables. This work introduces a\nprobability-driven prompting approach that leverages LLMs to estimate\nconditional distributions, enabling more accurate and scalable data synthesis.\nThe results highlight the potential of prompting probability distributions to\nenhance the statistical fidelity of LLM-generated tabular data.", "published": "2025-05-05 14:05:15", "link": "http://arxiv.org/abs/2505.02659v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Advancing Constrained Monotonic Neural Networks: Achieving Universal Approximation Beyond Bounded Activations", "abstract": "Conventional techniques for imposing monotonicity in MLPs by construction\ninvolve the use of non-negative weight constraints and bounded activation\nfunctions, which pose well-known optimization challenges. In this work, we\ngeneralize previous theoretical results, showing that MLPs with non-negative\nweight constraint and activations that saturate on alternating sides are\nuniversal approximators for monotonic functions. Additionally, we show an\nequivalence between the saturation side in the activations and the sign of the\nweight constraint. This connection allows us to prove that MLPs with convex\nmonotone activations and non-positive constrained weights also qualify as\nuniversal approximators, in contrast to their non-negative constrained\ncounterparts. Our results provide theoretical grounding to the empirical\neffectiveness observed in previous works while leading to possible\narchitectural simplification. Moreover, to further alleviate the optimization\ndifficulties, we propose an alternative formulation that allows the network to\nadjust its activations according to the sign of the weights. This eliminates\nthe requirement for weight reparameterization, easing initialization and\nimproving training stability. Experimental evaluation reinforces the validity\nof the theoretical results, showing that our novel approach compares favourably\nto traditional monotonic architectures.", "published": "2025-05-05 10:18:48", "link": "http://arxiv.org/abs/2505.02537v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks", "abstract": "Generalizing well in deep neural networks remains a core challenge,\nparticularly due to their tendency to converge to sharp minima that degrade\nrobustness. Sharpness-Aware Minimization (SAM) mitigates this by seeking\nflatter minima but perturbs parameters using the full gradient, which can\ninclude statistically insignificant directions. We propose ZSharp, a simple yet\neffective extension to SAM that applies layer-wise Z-score normalization\nfollowed by percentile-based filtering to retain only statistically significant\ngradient components. This selective perturbation aligns updates with\ncurvature-sensitive directions, enhancing generalization without requiring\narchitectural changes. ZSharp introduces only one additional hyperparameter,\nthe percentile threshold, and remains fully compatible with existing SAM\nvariants. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet using ResNet,\nVGG, and Vision Transformers show that ZSharp consistently outperforms SAM and\nits variants in test accuracy, particularly on deeper and transformer-based\nmodels. These results demonstrate that ZSharp is a principled and lightweight\nimprovement for sharpness-aware optimization.", "published": "2025-05-05 05:13:12", "link": "http://arxiv.org/abs/2505.02369v2", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "cs.NE", "math.IT"], "primary_category": "cs.LG"}
{"title": "Towards Application-Specific Evaluation of Vision Models: Case Studies in Ecology and Biology", "abstract": "Computer vision methods have demonstrated considerable potential to\nstreamline ecological and biological workflows, with a growing number of\ndatasets and models becoming available to the research community. However,\nthese resources focus predominantly on evaluation using machine learning\nmetrics, with relatively little emphasis on how their application impacts\ndownstream analysis. We argue that models should be evaluated using\napplication-specific metrics that directly represent model performance in the\ncontext of its final use case. To support this argument, we present two\ndisparate case studies: (1) estimating chimpanzee abundance and density with\ncamera trap distance sampling when using a video-based behaviour classifier and\n(2) estimating head rotation in pigeons using a 3D posture estimator. We show\nthat even models with strong machine learning performance (e.g., 87% mAP) can\nyield data that leads to discrepancies in abundance estimates compared to\nexpert-derived data. Similarly, the highest-performing models for posture\nestimation do not produce the most accurate inferences of gaze direction in\npigeons. Motivated by these findings, we call for researchers to integrate\napplication-specific metrics in ecological/biological datasets, allowing for\nmodels to be benchmarked in the context of their downstream application and to\nfacilitate better integration of models into application workflows.", "published": "2025-05-05 17:51:56", "link": "http://arxiv.org/abs/2505.02825v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VGLD: Visually-Guided Linguistic Disambiguation for Monocular Depth Scale Recovery", "abstract": "We propose a robust method for monocular depth scale recovery. Monocular\ndepth estimation can be divided into two main directions: (1) relative depth\nestimation, which provides normalized or inverse depth without scale\ninformation, and (2) metric depth estimation, which involves recovering depth\nwith absolute scale. To obtain absolute scale information for practical\ndownstream tasks, utilizing textual information to recover the scale of a\nrelative depth map is a highly promising approach. However, since a single\nimage can have multiple descriptions from different perspectives or with\nvarying styles, it has been shown that different textual descriptions can\nsignificantly affect the scale recovery process. To address this issue, our\nmethod, VGLD, stabilizes the influence of textual information by incorporating\nhigh-level semantic information from the corresponding image alongside the\ntextual description. This approach resolves textual ambiguities and robustly\noutputs a set of linear transformation parameters (scalars) that can be\nglobally applied to the relative depth map, ultimately generating depth\npredictions with metric-scale accuracy. We validate our method across several\npopular relative depth models(MiDas, DepthAnything), using both indoor scenes\n(NYUv2) and outdoor scenes (KITTI). Our results demonstrate that VGLD functions\nas a universal alignment module when trained on multiple datasets, achieving\nstrong performance even in zero-shot scenarios. Code is available at:\nhttps://github.com/pakinwu/VGLD.", "published": "2025-05-05 14:57:16", "link": "http://arxiv.org/abs/2505.02704v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MCCD: Multi-Agent Collaboration-based Compositional Diffusion for Complex Text-to-Image Generation", "abstract": "Diffusion models have shown excellent performance in text-to-image\ngeneration. Nevertheless, existing methods often suffer from performance\nbottlenecks when handling complex prompts that involve multiple objects,\ncharacteristics, and relations. Therefore, we propose a Multi-agent\nCollaboration-based Compositional Diffusion (MCCD) for text-to-image generation\nfor complex scenes. Specifically, we design a multi-agent collaboration-based\nscene parsing module that generates an agent system comprising multiple agents\nwith distinct tasks, utilizing MLLMs to extract various scene elements\neffectively. In addition, Hierarchical Compositional diffusion utilizes a\nGaussian mask and filtering to refine bounding box regions and enhance objects\nthrough region enhancement, resulting in the accurate and high-fidelity\ngeneration of complex scenes. Comprehensive experiments demonstrate that our\nMCCD significantly improves the performance of the baseline models in a\ntraining-free manner, providing a substantial advantage in complex scene\ngeneration.", "published": "2025-05-05 13:50:03", "link": "http://arxiv.org/abs/2505.02648v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robust Duality Learning for Unsupervised Visible-Infrared Person Re-Identification", "abstract": "Unsupervised visible-infrared person re-identification (UVI-ReID) aims to\nretrieve pedestrian images across different modalities without costly\nannotations, but faces challenges due to the modality gap and lack of\nsupervision. Existing methods often adopt self-training with\nclustering-generated pseudo-labels but implicitly assume these labels are\nalways correct. In practice, however, this assumption fails due to inevitable\npseudo-label noise, which hinders model learning. To address this, we introduce\na new learning paradigm that explicitly considers Pseudo-Label Noise (PLN),\ncharacterized by three key challenges: noise overfitting, error accumulation,\nand noisy cluster correspondence. To this end, we propose a novel Robust\nDuality Learning framework (RoDE) for UVI-ReID to mitigate the effects of noisy\npseudo-labels. First, to combat noise overfitting, a Robust Adaptive Learning\nmechanism (RAL) is proposed to dynamically emphasize clean samples while\ndown-weighting noisy ones. Second, to alleviate error accumulation-where the\nmodel reinforces its own mistakes-RoDE employs dual distinct models that are\nalternately trained using pseudo-labels from each other, encouraging diversity\nand preventing collapse. However, this dual-model strategy introduces\nmisalignment between clusters across models and modalities, creating noisy\ncluster correspondence. To resolve this, we introduce Cluster Consistency\nMatching (CCM), which aligns clusters across models and modalities by measuring\ncross-cluster similarity. Extensive experiments on three benchmarks demonstrate\nthe effectiveness of RoDE.", "published": "2025-05-05 10:36:52", "link": "http://arxiv.org/abs/2505.02549v2", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Evaluating Contrastive Feedback for Effective User Simulations", "abstract": "The use of Large Language Models (LLMs) for simulating user behavior in the\ndomain of Interactive Information Retrieval has recently gained significant\npopularity. However, their application and capabilities remain highly debated\nand understudied. This study explores whether the underlying principles of\ncontrastive training techniques, which have been effective for fine-tuning\nLLMs, can also be applied beneficially in the area of prompt engineering for\nuser simulations.\n  Previous research has shown that LLMs possess comprehensive world knowledge,\nwhich can be leveraged to provide accurate estimates of relevant documents.\nThis study attempts to simulate a knowledge state by enhancing the model with\nadditional implicit contextual information gained during the simulation. This\napproach enables the model to refine the scope of desired documents further.\nThe primary objective of this study is to analyze how different modalities of\ncontextual information influence the effectiveness of user simulations.\n  Various user configurations were tested, where models are provided with\nsummaries of already judged relevant, irrelevant, or both types of documents in\na contrastive manner. The focus of this study is the assessment of the impact\nof the prompting techniques on the simulated user agent performance. We hereby\nlay the foundations for leveraging LLMs as part of more realistic simulated\nusers.", "published": "2025-05-05 11:02:31", "link": "http://arxiv.org/abs/2505.02560v2", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Resolving Memorization in Empirical Diffusion Model for Manifold Data in High-Dimensional Spaces", "abstract": "Diffusion models is a popular computational tool to generate new data\nsamples. It utilizes a forward diffusion process that add noise to the data\ndistribution and then use a reverse process to remove noises to produce samples\nfrom the data distribution. However, when the empirical data distribution\nconsists of $n$ data point, using the empirical diffusion model will\nnecessarily produce one of the existing data points. This is often referred to\nas the memorization effect, which is usually resolved by sophisticated machine\nlearning procedures in the current literature. This work shows that the\nmemorization problem can be resolved by a simple inertia update step at the end\nof the empirical diffusion model simulation. Our inertial diffusion model\nrequires only the empirical diffusion model score function and it does not\nrequire any further training. We show that choosing the inertia diffusion model\nsample distribution is an $O\\left(n^{-\\frac{2}{d+4}}\\right)$ Wasserstein-1\napproximation of a data distribution lying on a $C^2$ manifold of dimension\n$d$. Since this estimate is significant smaller the Wasserstein1 distance\nbetween population and empirical distributions, it rigorously shows the\ninertial diffusion model produces new data samples. Remarkably, this upper\nbound is completely free of the ambient space dimension, since there is no\ntraining involved. Our analysis utilizes the fact that the inertial diffusion\nmodel samples are approximately distributed as the Gaussian kernel density\nestimator on the manifold. This reveals an interesting connection between\ndiffusion model and manifold learning.", "published": "2025-05-05 09:40:41", "link": "http://arxiv.org/abs/2505.02508v2", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "EntroLLM: Entropy Encoded Weight Compression for Efficient Large Language Model Inference on Edge Devices", "abstract": "Large Language Models (LLMs) demonstrate exceptional performance across\nvarious tasks, but their large storage and computational requirements constrain\ntheir deployment on edge devices. To address this, we propose EntroLLM, a novel\ncompression framework that integrates mixed quantization with entropy coding to\nreduce storage overhead while maintaining model accuracy. Our method applies a\nlayer-wise mixed quantization scheme - choosing between symmetric and\nasymmetric quantization based on individual layer weight distributions - to\noptimize compressibility. We then employ Huffman encoding for lossless\ncompression of the quantized weights, significantly reducing memory bandwidth\nrequirements. Furthermore, we introduce parallel Huffman decoding, which\nenables efficient retrieval of encoded weights during inference, ensuring\nminimal latency impact. Our experiments on edge-compatible LLMs, including\nsmolLM-1.7B-Instruct, phi3-mini-4k-Instruct, and mistral-7B-Instruct,\ndemonstrate that EntroLLM achieves up to $30\\%$ storage reduction compared to\nuint8 models and up to $65%$ storage reduction compared to uint4 models, while\npreserving perplexity and accuracy, on language benchmark tasks. We further\nshow that our method enables $31.9\\%$ - $146.6\\%$ faster inference throughput\non memory-bandwidth-limited edge devices, such as NVIDIA Jetson P3450, by\nreducing the required data movement. The proposed approach requires no\nadditional re-training and is fully compatible with existing post-training\nquantization methods, making it a practical solution for edge LLMs.", "published": "2025-05-05 05:42:14", "link": "http://arxiv.org/abs/2505.02380v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "dyGRASS: Dynamic Spectral Graph Sparsification via Localized Random Walks on GPUs", "abstract": "This work presents dyGRASS, an efficient dynamic algorithm for spectral\nsparsification of large undirected graphs that undergo streaming edge\ninsertions and deletions. At its core, dyGRASS employs a random-walk-based\nmethod to efficiently estimate node-to-node distances in both the original\ngraph (for decremental update) and its sparsifier (for incremental update). For\nincremental updates, dyGRASS enables the identification of spectrally critical\nedges among the updates to capture the latest structural changes. For\ndecremental updates, dyGRASS facilitates the recovery of important edges from\nthe original graph back into the sparsifier. To further enhance computational\nefficiency, dyGRASS employs a GPU-based non-backtracking random walk scheme\nthat allows multiple walkers to operate simultaneously across various target\nupdates. This parallelization significantly improves both the performance and\nscalability of the proposed dyGRASS framework. Our comprehensive experimental\nevaluations reveal that dyGRASS achieves approximately a 10x speedup compared\nto the state-of-the-art incremental sparsification (inGRASS) algorithm while\neliminating the setup overhead and improving solution quality in incremental\nspectral sparsification tasks. Moreover, dyGRASS delivers high efficiency and\nsuperior solution quality for fully dynamic graph sparsification, accommodating\nboth edge insertions and deletions across a diverse range of graph instances\noriginating from integrated circuit simulations, finite element analysis, and\nsocial networks.", "published": "2025-05-05 15:48:44", "link": "http://arxiv.org/abs/2505.02741v2", "categories": ["cs.SI", "cs.NA", "math.NA"], "primary_category": "cs.SI"}
{"title": "Improving Model Alignment Through Collective Intelligence of Open-Source LLMS", "abstract": "Building helpful and harmless large language models (LLMs) requires effective\nmodel alignment approach based on human instructions and feedback, which\nnecessitates high-quality human-labeled data. Constructing such datasets is\noften expensive and hard to scale, and may face potential limitations on\ndiversity and generalization. To address these challenges, we introduce Mixture\nof Agents Alignment (MoAA), that leverages the collective strengths of various\nlanguage models to provide high-quality data for model alignment. By employing\nMoAA, we enhance both supervised fine-tuning and preference optimization,\nleading to improved performance compared to using a single model alone to\ngenerate alignment data (e.g. using GPT-4o alone). Evaluation results show that\nour approach can improve win rate of LLaMA-3.1-8B-Instruct from 19.5 to 48.3 on\nArena-Hard and from 22.33 to 57.23 on AlpacaEval2, highlighting a promising\ndirection for model alignment through this new scalable and diverse synthetic\ndata recipe. Furthermore, we demonstrate that MoAA enables a self-improvement\npipeline, where models finetuned on MoA-generated data surpass their own\ninitial capabilities, providing evidence that our approach can push the\nfrontier of open-source LLMs without reliance on stronger external supervision.\nData and code will be released.", "published": "2025-05-05 22:40:23", "link": "http://arxiv.org/abs/2505.03059v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BLAB: Brutally Long Audio Bench", "abstract": "Developing large audio language models (LMs) capable of understanding diverse\nspoken interactions is essential for accommodating the multimodal nature of\nhuman communication and can increase the accessibility of language technologies\nacross different user populations. Recent work on audio LMs has primarily\nevaluated their performance on short audio segments, typically under 30\nseconds, with limited exploration of long-form conversational speech segments\nthat more closely reflect natural user interactions with these models. We\nintroduce Brutally Long Audio Bench (BLAB), a challenging long-form audio\nbenchmark that evaluates audio LMs on localization, duration estimation,\nemotion, and counting tasks using audio segments averaging 51 minutes in\nlength. BLAB consists of 833+ hours of diverse, full-length audio clips, each\npaired with human-annotated, text-based natural language questions and answers.\nOur audio data were collected from permissively licensed sources and underwent\na human-assisted filtering process to ensure task compliance. We evaluate six\nopen-source and proprietary audio LMs on BLAB and find that all of them,\nincluding advanced models such as Gemini 2.0 Pro and GPT-4o, struggle with the\ntasks in BLAB. Our comprehensive analysis reveals key insights into the\ntrade-offs between task difficulty and audio duration. In general, we find that\naudio LMs struggle with long-form speech, with performance declining as\nduration increases. They perform poorly on localization, temporal reasoning,\ncounting, and struggle to understand non-phonemic information, relying more on\nprompts than audio content. BLAB serves as a challenging evaluation framework\nto develop audio LMs with robust long-form audio understanding capabilities.", "published": "2025-05-05 22:28:53", "link": "http://arxiv.org/abs/2505.03054v1", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text", "abstract": "LLM evaluation is challenging even the case of base models. In real world\ndeployments, evaluation is further complicated by the interplay of task\nspecific prompts and experiential context. At scale, bias evaluation is often\nbased on short context, fixed choice benchmarks that can be rapidly evaluated,\nhowever, these can lose validity when the LLMs' deployed context differs. Large\nscale human evaluation is often seen as too intractable and costly. Here we\npresent our journey towards developing a semi-automated bias evaluation\nframework for free text responses that has human insights at its core. We\ndiscuss how we developed an operational definition of bias that helped us\nautomate our pipeline and a methodology for classifying bias beyond multiple\nchoice. We additionally comment on how human evaluation helped us uncover\nproblematic templates in a bias benchmark.", "published": "2025-05-05 22:26:55", "link": "http://arxiv.org/abs/2505.03053v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Teaching Models to Understand (but not Generate) High-risk Data", "abstract": "Language model developers typically filter out high-risk content -- such as\ntoxic or copyrighted text -- from their pre-training data to prevent models\nfrom generating similar outputs. However, removing such data altogether limits\nmodels' ability to recognize and appropriately respond to harmful or sensitive\ncontent. In this paper, we introduce Selective Loss to Understand but Not\nGenerate (SLUNG), a pre-training paradigm through which models learn to\nunderstand high-risk data without learning to generate it. Instead of uniformly\napplying the next-token prediction loss, SLUNG selectively avoids incentivizing\nthe generation of high-risk tokens while ensuring they remain within the\nmodel's context window. As the model learns to predict low-risk tokens that\nfollow high-risk ones, it is forced to understand the high-risk content.\nThrough our experiments, we show that SLUNG consistently improves models'\nunderstanding of high-risk data (e.g., ability to recognize toxic content)\nwithout increasing its generation (e.g., toxicity of model responses). Overall,\nour SLUNG paradigm enables models to benefit from high-risk text that would\notherwise be filtered out.", "published": "2025-05-05 22:24:06", "link": "http://arxiv.org/abs/2505.03052v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Radio: Rate-Distortion Optimization for Large Language Model Compression", "abstract": "In recent years, the compression of large language models (LLMs) has emerged\nas a key problem in facilitating LLM deployment on resource-limited devices,\nreducing compute costs, and mitigating the environmental footprint due to\nlarge-scale AI infrastructure. Here, we establish the foundations of LLM\nquantization from a rate-distortion theory perspective and propose a\nquantization technique based on simple rate-distortion optimization. Our\ntechnique scales to models containing hundreds of billions of weight parameters\nand offers users the flexibility to compress models, post-training, to a model\nsize or accuracy specified by the user.", "published": "2025-05-05 21:17:14", "link": "http://arxiv.org/abs/2505.03031v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "UCSC at SemEval-2025 Task 3: Context, Models and Prompt Optimization for Automated Hallucination Detection in LLM Output", "abstract": "Hallucinations pose a significant challenge for large language models when\nanswering knowledge-intensive queries. As LLMs become more widely adopted, it\nis crucial not only to detect if hallucinations occur but also to pinpoint\nexactly where in the LLM output they occur. SemEval 2025 Task 3, Mu-SHROOM:\nMultilingual Shared-task on Hallucinations and Related Observable\nOvergeneration Mistakes, is a recent effort in this direction. This paper\ndescribes the UCSC system submission to the shared Mu-SHROOM task. We introduce\na framework that first retrieves relevant context, next identifies false\ncontent from the answer, and finally maps them back to spans in the LLM output.\nThe process is further enhanced by automatically optimizing prompts. Our system\nachieves the highest overall performance, ranking #1 in average position across\nall languages. We release our code and experiment results.", "published": "2025-05-05 21:15:40", "link": "http://arxiv.org/abs/2505.03030v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Typology of Synthetic Datasets for Dialogue Processing in Clinical Contexts", "abstract": "Synthetic data sets are used across linguistic domains and NLP tasks,\nparticularly in scenarios where authentic data is limited (or even\nnon-existent). One such domain is that of clinical (healthcare) contexts, where\nthere exist significant and long-standing challenges (e.g., privacy,\nanonymization, and data governance) which have led to the development of an\nincreasing number of synthetic datasets. One increasingly important category of\nclinical dataset is that of clinical dialogues which are especially sensitive\nand difficult to collect, and as such are commonly synthesized.\n  While such synthetic datasets have been shown to be sufficient in some\nsituations, little theory exists to inform how they may be best used and\ngeneralized to new applications. In this paper, we provide an overview of how\nsynthetic datasets are created, evaluated and being used for dialogue related\ntasks in the medical domain. Additionally, we propose a novel typology for use\nin classifying types and degrees of data synthesis, to facilitate comparison\nand evaluation.", "published": "2025-05-05 20:58:08", "link": "http://arxiv.org/abs/2505.03025v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis", "abstract": "While Large Language Models (LLMs) achieve remarkable performance through\ntraining on massive datasets, they can exhibit concerning behaviors such as\nverbatim reproduction of training data rather than true generalization. This\nmemorization phenomenon raises significant concerns about data privacy,\nintellectual property rights, and the reliability of model evaluations. This\npaper introduces PEARL, a novel approach for detecting memorization in LLMs.\nPEARL assesses how sensitive an LLM's performance is to input perturbations,\nenabling memorization detection without requiring access to the model's\ninternals. We investigate how input perturbations affect the consistency of\noutputs, enabling us to distinguish between true generalization and\nmemorization. Our findings, following extensive experiments on the Pythia open\nmodel, provide a robust framework for identifying when the model simply\nregurgitates learned information. Applied on the GPT 4o models, the PEARL\nframework not only identified cases of memorization of classic texts from the\nBible or common code from HumanEval but also demonstrated that it can provide\nsupporting evidence that some data, such as from the New York Times news\narticles, were likely part of the training data of a given model.", "published": "2025-05-05 20:42:34", "link": "http://arxiv.org/abs/2505.03019v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale", "abstract": "We present Rapid Attention Distillation to Linear Attention Decoders at Scale\n(RADLADS), a protocol for rapidly converting softmax attention transformers\ninto linear attention decoder models, along with two new RWKV-variant\narchitectures, and models converted from popular Qwen2.5 open source models in\n7B, 32B, and 72B sizes. Our conversion process requires only 350-700M tokens,\nless than 0.005% of the token count used to train the original teacher models.\nConverting to our 72B linear attention model costs less than \\$2,000 USD at\ntoday's prices, yet quality at inference remains close to the original\ntransformer. These models achieve state-of-the-art downstream performance\nacross a set of standard benchmarks for linear attention models of their size.\nWe release all our models on HuggingFace under the Apache 2.0 license, with the\nexception of our 72B models which are also governed by the Qwen License\nAgreement.\n  Models at\nhttps://huggingface.co/collections/recursal/radlads-6818ee69e99e729ba8a87102\nTraining Code at https://github.com/recursal/RADLADS-paper", "published": "2025-05-05 20:03:28", "link": "http://arxiv.org/abs/2505.03005v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Logits-Constrained Framework with RoBERTa for Ancient Chinese NER", "abstract": "This paper presents a Logits-Constrained (LC) framework for Ancient Chinese\nNamed Entity Recognition (NER), evaluated on the EvaHan 2025 benchmark. Our\ntwo-stage model integrates GujiRoBERTa for contextual encoding and a\ndifferentiable decoding mechanism to enforce valid BMES label transitions.\nExperiments demonstrate that LC improves performance over traditional CRF and\nBiLSTM-based approaches, especially in high-label or large-data settings. We\nalso propose a model selection criterion balancing label complexity and dataset\nsize, providing practical guidance for real-world Ancient Chinese NLP tasks.", "published": "2025-05-05 19:23:16", "link": "http://arxiv.org/abs/2505.02983v1", "categories": ["cs.CL", "68T50", "I.2.7; I.5.1; I.5.4"], "primary_category": "cs.CL"}
{"title": "Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach", "abstract": "Generative AI systems have revolutionized human interaction by enabling\nnatural language-based coding and problem solving. However, the inherent\nambiguity of natural language often leads to imprecise instructions, forcing\nusers to iteratively test, correct, and resubmit their prompts. We propose an\niterative approach that systematically narrows down these ambiguities through a\nstructured series of clarification questions and alternative solution\nproposals, illustrated with input/output examples as well. Once every\nuncertainty is resolved, a final, precise solution is generated. Evaluated on a\ndiverse dataset spanning coding, data analysis, and creative writing, our\nmethod demonstrates superior accuracy, competitive resolution times, and higher\nuser satisfaction compared to conventional one-shot solutions, which typically\nrequire multiple manual iterations to achieve a correct output.", "published": "2025-05-05 18:31:18", "link": "http://arxiv.org/abs/2505.02952v1", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "abstract": "Automatic program repair (APR) aims to reduce the manual efforts required to\nidentify and fix errors in source code. Before the rise of LLM-based agents, a\ncommon strategy was to increase the number of generated patches, sometimes to\nthe thousands, to achieve better repair results on benchmarks. More recently,\nself-iterative capabilities enabled LLMs to refine patches over multiple rounds\nguided by feedback. However, literature often focuses on many iterations and\ndisregards different numbers of outputs.\n  We investigate an APR pipeline that balances these two approaches, the\ngeneration of multiple outputs and multiple rounds of iteration, while imposing\na limit of 10 total patches per bug. We apply three SOTA instruction-tuned LLMs\n- DeepSeekCoder-Instruct, Codellama-Instruct, Llama3.1-Instruct - to the APR\ntask. We further fine-tune each model on an APR dataset with three sizes (1K,\n30K, 65K) and two techniques (Full Fine-Tuning and LoRA), allowing us to assess\ntheir repair capabilities on two APR benchmarks: HumanEval-Java and Defects4J.\n  Our results show that by using only a fraction (<1%) of the fine-tuning\ndataset, we can achieve improvements of up to 78% in the number of plausible\npatches generated, challenging prior studies that reported limited gains using\nFull Fine-Tuning. However, we find that exceeding certain thresholds leads to\ndiminishing outcomes, likely due to overfitting. Moreover, we show that base\nmodels greatly benefit from creating patches in an iterative fashion rather\nthan generating them all at once. In addition, the benefit of iterative\nstrategies becomes more pronounced in complex benchmarks. Even fine-tuned\nmodels, while benefiting less from iterations, still gain advantages,\nparticularly on complex benchmarks. The research underscores the need for\nbalanced APR strategies that combine multi-output generation and iterative\nrefinement.", "published": "2025-05-05 18:06:51", "link": "http://arxiv.org/abs/2505.02931v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger", "abstract": "We present Noise-to-Meaning Recursive Self-Improvement (N2M-RSI), a minimal\nformal model showing that once an AI agent feeds its own outputs back as inputs\nand crosses an explicit information-integration threshold, its internal\ncomplexity will grow without bound under our assumptions. The framework unifies\nearlier ideas on self-prompting large language models, G\\\"odelian\nself-reference, and AutoML, yet remains implementation-agnostic. The model\nfurthermore scales naturally to interacting swarms of agents, hinting at\nsuper-linear effects once communication among instances is permitted. For\nsafety reasons, we omit system-specific implementation details and release only\na brief, model-agnostic toy prototype in Appendix C.", "published": "2025-05-05 17:03:07", "link": "http://arxiv.org/abs/2505.02888v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T05, 68Q85", "I.2.0; I.2.3; I.2.6"], "primary_category": "cs.LG"}
{"title": "MORE: Mobile Manipulation Rearrangement Through Grounded Language Reasoning", "abstract": "Autonomous long-horizon mobile manipulation encompasses a multitude of\nchallenges, including scene dynamics, unexplored areas, and error recovery.\nRecent works have leveraged foundation models for scene-level robotic reasoning\nand planning. However, the performance of these methods degrades when dealing\nwith a large number of objects and large-scale environments. To address these\nlimitations, we propose MORE, a novel approach for enhancing the capabilities\nof language models to solve zero-shot mobile manipulation planning for\nrearrangement tasks. MORE leverages scene graphs to represent environments,\nincorporates instance differentiation, and introduces an active filtering\nscheme that extracts task-relevant subgraphs of object and region instances.\nThese steps yield a bounded planning problem, effectively mitigating\nhallucinations and improving reliability. Additionally, we introduce several\nenhancements that enable planning across both indoor and outdoor environments.\nWe evaluate MORE on 81 diverse rearrangement tasks from the BEHAVIOR-1K\nbenchmark, where it becomes the first approach to successfully solve a\nsignificant share of the benchmark, outperforming recent foundation model-based\napproaches. Furthermore, we demonstrate the capabilities of our approach in\nseveral complex real-world tasks, mimicking everyday activities. We make the\ncode publicly available at https://more-model.cs.uni-freiburg.de.", "published": "2025-05-05 21:26:03", "link": "http://arxiv.org/abs/2505.03035v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Evaluating the Impact of AI-Powered Audiovisual Personalization on Learner Emotion, Focus, and Learning Outcomes", "abstract": "Independent learners often struggle with sustaining focus and emotional\nregulation in unstructured or distracting settings. Although some rely on\nambient aids such as music, ASMR, or visual backgrounds to support\nconcentration, these tools are rarely integrated into cohesive,\nlearner-centered systems. Moreover, existing educational technologies focus\nprimarily on content adaptation and feedback, overlooking the emotional and\nsensory context in which learning takes place. Large language models have\ndemonstrated powerful multimodal capabilities including the ability to generate\nand adapt text, audio, and visual content. Educational research has yet to\nfully explore their potential in creating personalized audiovisual learning\nenvironments. To address this gap, we introduce an AI-powered system that uses\nLLMs to generate personalized multisensory study environments. Users select or\ngenerate customized visual themes (e.g., abstract vs. realistic, static vs.\nanimated) and auditory elements (e.g., white noise, ambient ASMR, familiar vs.\nnovel sounds) to create immersive settings aimed at reducing distraction and\nenhancing emotional stability. Our primary research question investigates how\ncombinations of personalized audiovisual elements affect learner cognitive load\nand engagement. Using a mixed-methods design that incorporates biometric\nmeasures and performance outcomes, this study evaluates the effectiveness of\nLLM-driven sensory personalization. The findings aim to advance emotionally\nresponsive educational technologies and extend the application of multimodal\nLLMs into the sensory dimension of self-directed learning.", "published": "2025-05-05 21:19:50", "link": "http://arxiv.org/abs/2505.03033v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "The Multimodal Paradox: How Added and Missing Modalities Shape Bias and Performance in Multimodal AI", "abstract": "Multimodal learning, which integrates diverse data sources such as images,\ntext, and structured data, has proven superior to unimodal counterparts in\nhigh-stakes decision-making. However, while performance gains remain the gold\nstandard for evaluating multimodal systems, concerns around bias and robustness\nare frequently overlooked. In this context, this paper explores two key\nresearch questions (RQs): (i) RQ1 examines whether adding a modality\ncon-sistently enhances performance and investigates its role in shaping\nfairness measures, assessing whether it mitigates or amplifies bias in\nmultimodal models; (ii) RQ2 investigates the impact of missing modalities at\ninference time, analyzing how multimodal models generalize in terms of both\nperformance and fairness. Our analysis reveals that incorporating new\nmodalities during training consistently enhances the performance of multimodal\nmodels, while fairness trends exhibit variability across different evaluation\nmeasures and datasets. Additionally, the absence of modalities at inference\ndegrades performance and fairness, raising concerns about its robustness in\nreal-world deployment. We conduct extensive experiments using multimodal\nhealthcare datasets containing images, time series, and structured information\nto validate our findings.", "published": "2025-05-05 20:42:44", "link": "http://arxiv.org/abs/2505.03020v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Lesion-Aware Generative Artificial Intelligence for Virtual Contrast-Enhanced Mammography in Breast Cancer", "abstract": "Contrast-Enhanced Spectral Mammography (CESM) is a dual-energy mammographic\ntechnique that improves lesion visibility through the administration of an\niodinated contrast agent. It acquires both a low-energy image, comparable to\nstandard mammography, and a high-energy image, which are then combined to\nproduce a dual-energy subtracted image highlighting lesion contrast\nenhancement. While CESM offers superior diagnostic accuracy compared to\nstandard mammography, its use entails higher radiation exposure and potential\nside effects associated with the contrast medium. To address these limitations,\nwe propose Seg-CycleGAN, a generative deep learning framework for Virtual\nContrast Enhancement in CESM. The model synthesizes high-fidelity dual-energy\nsubtracted images from low-energy images, leveraging lesion segmentation maps\nto guide the generative process and improve lesion reconstruction. Building\nupon the standard CycleGAN architecture, Seg-CycleGAN introduces localized loss\nterms focused on lesion areas, enhancing the synthesis of diagnostically\nrelevant regions. Experiments on the CESM@UCBM dataset demonstrate that\nSeg-CycleGAN outperforms the baseline in terms of PSNR and SSIM, while\nmaintaining competitive MSE and VIF. Qualitative evaluations further confirm\nimproved lesion fidelity in the generated images. These results suggest that\nsegmentation-aware generative models offer a viable pathway toward\ncontrast-free CESM alternatives.", "published": "2025-05-05 20:41:30", "link": "http://arxiv.org/abs/2505.03018v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Generating Narrated Lecture Videos from Slides with Synchronized Highlights", "abstract": "Turning static slides into engaging video lectures takes considerable time\nand effort, requiring presenters to record explanations and visually guide\ntheir audience through the material. We introduce an end-to-end system designed\nto automate this process entirely. Given a slide deck, this system synthesizes\na video lecture featuring AI-generated narration synchronized precisely with\ndynamic visual highlights. These highlights automatically draw attention to the\nspecific concept being discussed, much like an effective presenter would. The\ncore technical contribution is a novel highlight alignment module. This module\naccurately maps spoken phrases to locations on a given slide using diverse\nstrategies (e.g., Levenshtein distance, LLM-based semantic analysis) at\nselectable granularities (line or word level) and utilizes timestamp-providing\nText-to-Speech (TTS) for timing synchronization. We demonstrate the system's\neffectiveness through a technical evaluation using a manually annotated slide\ndataset with 1000 samples, finding that LLM-based alignment achieves high\nlocation accuracy (F1 > 92%), significantly outperforming simpler methods,\nespecially on complex, math-heavy content. Furthermore, the calculated\ngeneration cost averages under $1 per hour of video, offering potential savings\nof two orders of magnitude compared to conservative estimates of manual\nproduction costs. This combination of high accuracy and extremely low cost\npositions this approach as a practical and scalable tool for transforming\nstatic slides into effective, visually-guided video lectures.", "published": "2025-05-05 18:51:53", "link": "http://arxiv.org/abs/2505.02966v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence", "abstract": "A key challenge in multi-agent AI is modeling social cooperation under\nrealistic behavioral constraints. Many foundational concepts in economics and\nethics such as \"trust\" or \"morality\" are often defined informally, without\noperational criteria or cognitive grounding, which limits their testability and\nimplementation in artificial agents. Drawing on converging empirical evidence\nfrom primate behavior, infant cognition, and economic anthropology, we propose\na conceptual framework composed of three cognitively minimal mechanisms:\nindividual recognition, reciprocal credence, and cost return sensitivity. This\nframework reframes trust as a graded cognitive expectation, providing a\nsimulateable basis for reciprocal exchange in artificial agents, and enabling\nthe bottom-up emergence of scalable cooperation and institutional dynamics.", "published": "2025-05-05 18:21:53", "link": "http://arxiv.org/abs/2505.02945v1", "categories": ["cs.CY", "cs.AI", "cs.MA"], "primary_category": "cs.CY"}
{"title": "Early Prediction of Sepsis: Feature-Aligned Transfer Learning", "abstract": "Sepsis is a life threatening medical condition that occurs when the body has\nan extreme response to infection, leading to widespread inflammation, organ\nfailure, and potentially death. Because sepsis can worsen rapidly, early\ndetection is critical to saving lives. However, current diagnostic methods\noften identify sepsis only after significant damage has already occurred. Our\nproject aims to address this challenge by developing a machine learning based\nsystem to predict sepsis in its early stages, giving healthcare providers more\ntime to intervene.\n  A major problem with existing models is the wide variability in the patient\ninformation or features they use, such as heart rate, temperature, and lab\nresults. This inconsistency makes models difficult to compare and limits their\nability to work across different hospitals and settings. To solve this, we\npropose a method called Feature Aligned Transfer Learning (FATL), which\nidentifies and focuses on the most important and commonly reported features\nacross multiple studies, ensuring the model remains consistent and clinically\nrelevant.\n  Most existing models are trained on narrow patient groups, leading to\npopulation bias. FATL addresses this by combining knowledge from models trained\non diverse populations, using a weighted approach that reflects each models\ncontribution. This makes the system more generalizable and effective across\ndifferent patient demographics and clinical environments. FATL offers a\npractical and scalable solution for early sepsis detection, particularly in\nhospitals with limited resources, and has the potential to improve patient\noutcomes, reduce healthcare costs, and support more equitable healthcare\ndelivery.", "published": "2025-05-05 17:59:34", "link": "http://arxiv.org/abs/2505.02889v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Sim2Real Transfer for Vision-Based Grasp Verification", "abstract": "The verification of successful grasps is a crucial aspect of robot\nmanipulation, particularly when handling deformable objects. Traditional\nmethods relying on force and tactile sensors often struggle with deformable and\nnon-rigid objects. In this work, we present a vision-based approach for grasp\nverification to determine whether the robotic gripper has successfully grasped\nan object. Our method employs a two-stage architecture; first YOLO-based object\ndetection model to detect and locate the robot's gripper and then a\nResNet-based classifier determines the presence of an object. To address the\nlimitations of real-world data capture, we introduce HSR-GraspSynth, a\nsynthetic dataset designed to simulate diverse grasping scenarios. Furthermore,\nwe explore the use of Visual Question Answering capabilities as a zero-shot\nbaseline to which we compare our model. Experimental results demonstrate that\nour approach achieves high accuracy in real-world environments, with potential\nfor integration into grasping pipelines. Code and datasets are publicly\navailable at https://github.com/pauamargant/HSR-GraspSynth .", "published": "2025-05-05 22:04:12", "link": "http://arxiv.org/abs/2505.03046v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "An Explainable Anomaly Detection Framework for Monitoring Depression and Anxiety Using Consumer Wearable Devices", "abstract": "Continuous monitoring of behavior and physiology via wearable devices offers\na novel, objective method for the early detection of worsening depression and\nanxiety. In this study, we present an explainable anomaly detection framework\nthat identifies clinically meaningful increases in symptom severity using\nconsumer-grade wearable data. Leveraging data from 2,023 participants with\ndefined healthy baselines, our LSTM autoencoder model learned normal health\npatterns of sleep duration, step count, and resting heart rate. Anomalies were\nflagged when self-reported depression or anxiety scores increased by >=5 points\n(a threshold considered clinically significant). The model achieved an adjusted\nF1-score of 0.80 (precision = 0.73, recall = 0.88) in detecting 393\nsymptom-worsening episodes across 341 participants, with higher performance\nobserved for episodes involving concurrent depression and anxiety escalation\n(F1 = 0.84) and for more pronounced symptom changes (>=10-point increases, F1 =\n0.85). Model interpretability was supported by SHAP-based analysis, which\nidentified resting heart rate as the most influential feature in 71.4\npercentage of detected anomalies, followed by physical activity and sleep.\nTogether, our findings highlight the potential of explainable anomaly detection\nto enable personalized, scalable, and proactive mental health monitoring in\nreal-world settings.", "published": "2025-05-05 21:41:05", "link": "http://arxiv.org/abs/2505.03039v1", "categories": ["cs.CV", "stat.AP"], "primary_category": "cs.CV"}
{"title": "Dual Prompting for Diverse Count-level PET Denoising", "abstract": "The to-be-denoised positron emission tomography (PET) volumes are inherent\nwith diverse count levels, which imposes challenges for a unified model to\ntackle varied cases. In this work, we resort to the recently flourished prompt\nlearning to achieve generalizable PET denoising with different count levels.\nSpecifically, we propose dual prompts to guide the PET denoising in a\ndivide-and-conquer manner, i.e., an explicitly count-level prompt to provide\nthe specific prior information and an implicitly general denoising prompt to\nencode the essential PET denoising knowledge. Then, a novel prompt fusion\nmodule is developed to unify the heterogeneous prompts, followed by a\nprompt-feature interaction module to inject prompts into the features. The\nprompts are able to dynamically guide the noise-conditioned denoising process.\nTherefore, we are able to efficiently train a unified denoising model for\nvarious count levels, and deploy it to different cases with personalized\nprompts. We evaluated on 1940 low-count PET 3D volumes with uniformly randomly\nselected 13-22\\% fractions of events from 97 $^{18}$F-MK6240 tau PET studies.\nIt shows our dual prompting can largely improve the performance with informed\ncount-level and outperform the count-conditional model.", "published": "2025-05-05 21:27:23", "link": "http://arxiv.org/abs/2505.03037v1", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "primary_category": "eess.IV"}
{"title": "GIF: Generative Inspiration for Face Recognition at Scale", "abstract": "Aiming to reduce the computational cost of Softmax in massive label space of\nFace Recognition (FR) benchmarks, recent studies estimate the output using a\nsubset of identities. Although promising, the association between the\ncomputation cost and the number of identities in the dataset remains linear\nonly with a reduced ratio. A shared characteristic among available FR methods\nis the employment of atomic scalar labels during training. Consequently, the\ninput to label matching is through a dot product between the feature vector of\nthe input and the Softmax centroids. Inspired by generative modeling, we\npresent a simple yet effective method that substitutes scalar labels with\nstructured identity code, i.e., a sequence of integers. Specifically, we\npropose a tokenization scheme that transforms atomic scalar labels into\nstructured identity codes. Then, we train an FR backbone to predict the code\nfor each input instead of its scalar label. As a result, the associated\ncomputational cost becomes logarithmic w.r.t. number of identities. We\ndemonstrate the benefits of the proposed method by conducting experiments. In\nparticular, our method outperforms its competitors by 1.52%, and 0.6% at\nTAR@FAR$=1e-4$ on IJB-B and IJB-C, respectively, while transforming the\nassociation between computational cost and the number of identities from linear\nto logarithmic. See code at https://github.com/msed-Ebrahimi/GIF", "published": "2025-05-05 20:23:14", "link": "http://arxiv.org/abs/2505.03012v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NTIRE 2025 Challenge on UGC Video Enhancement: Methods and Results", "abstract": "This paper presents an overview of the NTIRE 2025 Challenge on UGC Video\nEnhancement. The challenge constructed a set of 150 user-generated content\nvideos without reference ground truth, which suffer from real-world\ndegradations such as noise, blur, faded colors, compression artifacts, etc. The\ngoal of the participants was to develop an algorithm capable of improving the\nvisual quality of such videos. Given the widespread use of UGC on short-form\nvideo platforms, this task holds substantial practical importance. The\nevaluation was based on subjective quality assessment in crowdsourcing,\nobtaining votes from over 8000 assessors. The challenge attracted more than 25\nteams submitting solutions, 7 of which passed the final phase with source code\nverification. The outcomes may provide insights into the state-of-the-art in\nUGC video enhancement and highlight emerging trends and effective strategies in\nthis evolving research area. All data, including the processed videos and\nsubjective comparison votes and scores, is made publicly available at\nhttps://github.com/msu-video-group/NTIRE25_UGC_Video_Enhancement.", "published": "2025-05-05 20:06:11", "link": "http://arxiv.org/abs/2505.03007v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Completing Spatial Transcriptomics Data for Gene Expression Prediction Benchmarking", "abstract": "Spatial Transcriptomics is a groundbreaking technology that integrates\nhistology images with spatially resolved gene expression profiles. Among the\nvarious Spatial Transcriptomics techniques available, Visium has emerged as the\nmost widely adopted. However, its accessibility is limited by high costs, the\nneed for specialized expertise, and slow clinical integration. Additionally,\ngene capture inefficiencies lead to significant dropout, corrupting acquired\ndata. To address these challenges, the deep learning community has explored the\ngene expression prediction task directly from histology images. Yet,\ninconsistencies in datasets, preprocessing, and training protocols hinder fair\ncomparisons between models. To bridge this gap, we introduce SpaRED, a\nsystematically curated database comprising 26 public datasets, providing a\nstandardized resource for model evaluation. We further propose SpaCKLE, a\nstate-of-the-art transformer-based gene expression completion model that\nreduces mean squared error by over 82.5% compared to existing approaches.\nFinally, we establish the SpaRED benchmark, evaluating eight state-of-the-art\nprediction models on both raw and SpaCKLE-completed data, demonstrating SpaCKLE\nsubstantially improves the results across all the gene expression prediction\nmodels. Altogether, our contributions constitute the most comprehensive\nbenchmark of gene expression prediction from histology images to date and a\nstepping stone for future research on Spatial Transcriptomics.", "published": "2025-05-05 19:17:29", "link": "http://arxiv.org/abs/2505.02980v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation", "abstract": "Adversarial attacks have been fairly explored for computer vision and\nvision-language models. However, the avenue of adversarial attack for the\nvision language segmentation models (VLSMs) is still under-explored, especially\nfor medical image analysis.\n  Thus, we have investigated the robustness of VLSMs against adversarial\nattacks for 2D medical images with different modalities with radiology,\nphotography, and endoscopy. The main idea of this project was to assess the\nrobustness of the fine-tuned VLSMs specially in the medical domain setting to\naddress the high risk scenario.\n  First, we have fine-tuned pre-trained VLSMs for medical image segmentation\nwith adapters.\n  Then, we have employed adversarial attacks -- projected gradient descent\n(PGD) and fast gradient sign method (FGSM) -- on that fine-tuned model to\ndetermine its robustness against adversaries.\n  We have reported models' performance decline to analyze the adversaries'\nimpact.\n  The results exhibit significant drops in the DSC and IoU scores after the\nintroduction of these adversaries. Furthermore, we also explored universal\nperturbation but were not able to find for the medical images.\n  \\footnote{https://github.com/anjilab/secure-private-ai}", "published": "2025-05-05 18:54:41", "link": "http://arxiv.org/abs/2505.02971v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gone With the Bits: Revealing Racial Bias in Low-Rate Neural Compression for Facial Images", "abstract": "Neural compression methods are gaining popularity due to their superior\nrate-distortion performance over traditional methods, even at extremely low\nbitrates below 0.1 bpp. As deep learning architectures, these models are prone\nto bias during the training process, potentially leading to unfair outcomes for\nindividuals in different groups. In this paper, we present a general,\nstructured, scalable framework for evaluating bias in neural image compression\nmodels. Using this framework, we investigate racial bias in neural compression\nalgorithms by analyzing nine popular models and their variants. Through this\ninvestigation, we first demonstrate that traditional distortion metrics are\nineffective in capturing bias in neural compression models. Next, we highlight\nthat racial bias is present in all neural compression models and can be\ncaptured by examining facial phenotype degradation in image reconstructions. We\nthen examine the relationship between bias and realism in the decoded images\nand demonstrate a trade-off across models. Finally, we show that utilizing a\nracially balanced training set can reduce bias but is not a sufficient bias\nmitigation strategy. We additionally show the bias can be attributed to\ncompression model bias and classification model bias. We believe that this work\nis a first step towards evaluating and eliminating bias in neural image\ncompression models.", "published": "2025-05-05 18:27:11", "link": "http://arxiv.org/abs/2505.02949v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Direct Retrieval-augmented Optimization: Synergizing Knowledge Selection and Language Models", "abstract": "Retrieval-augmented generation (RAG) integrates large language models ( LLM\ns) with retrievers to access external knowledge, improving the factuality of\nLLM generation in knowledge-grounded tasks. To optimize the RAG performance,\nmost previous work independently fine-tunes the retriever to adapt to frozen\nLLM s or trains the LLMs to use documents retrieved by off-the-shelf\nretrievers, lacking end-to-end training supervision. Recent work addresses this\nlimitation by jointly training these two components but relies on overly\nsimplifying assumptions of document independence, which has been criticized for\nbeing far from real-world scenarios. Thus, effectively optimizing the overall\nRAG performance remains a critical challenge.\n  We propose a direct retrieval-augmented optimization framework, named DRO,\nthat enables end-to-end training of two key components: (i) a generative\nknowledge selection model and (ii) an LLM generator. DRO alternates between two\nphases: (i) document permutation estimation and (ii) re-weighted maximization,\nprogressively improving RAG components through a variational approach. In the\nestimation step, we treat document permutation as a latent variable and\ndirectly estimate its distribution from the selection model by applying an\nimportance sampling strategy. In the maximization step, we calibrate the\noptimization expectation using importance weights and jointly train the\nselection model and LLM generator. Our theoretical analysis reveals that DRO is\nanalogous to policy-gradient methods in reinforcement learning. Extensive\nexperiments conducted on five datasets illustrate that DRO outperforms the best\nbaseline with 5%-15% improvements in EM and F1. We also provide in-depth\nexperiments to qualitatively analyze the stability, convergence, and variance\nof DRO.", "published": "2025-05-05 23:54:53", "link": "http://arxiv.org/abs/2505.03075v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multi-Antenna Users in Cell-Free Massive MIMO: Stream Allocation and Necessity of Downlink Pilots", "abstract": "We consider a cell-free massive multiple-input multiple-output (MIMO) system\nwith multiple antennas on the users and access points (APs). In previous works,\nthe downlink spectral efficiency (SE) has been evaluated using the hardening\nbound that requires no downlink pilots. This approach works well for\nsingle-antenna users. In this paper, we show that much higher SEs can be\nachieved if downlink pilots are sent when having multi-antenna users. The\nreason is that the effective channel matrix does not harden. We propose a\npilot-based downlink estimation scheme, derive a new SE expression, and show\nnumerically that it yields substantially higher performance when having\ncorrelated Rayleigh fading channels.\n  In cases with multi-antenna users, the APs can either transmit the same or\ndifferent data streams. The latter reduces the fronthaul signaling but comes\nwith a SE loss. We propose precoding and combining schemes for these cases and\nconsider whether channel knowledge is shared between the APs. Finally, we show\nnumerically how the number of users, APs, and the number of antennas on users\nand APs affect the SE.", "published": "2025-05-05 18:28:37", "link": "http://arxiv.org/abs/2505.02951v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robustly Invertible Nonlinear Dynamics and the BiLipREN: Contracting Neural Models with Contracting Inverses", "abstract": "We study the invertibility of nonlinear dynamical systems from the\nperspective of contraction and incremental stability analysis and propose a new\ninvertible recurrent neural model: the BiLipREN. In particular, we consider a\nnonlinear state space model to be robustly invertible if an inverse exists with\na state space realisation, and both the forward model and its inverse are\ncontracting, i.e. incrementally exponentially stable, and Lipschitz, i.e. have\nbounded incremental gain. This property of bi-Lipschitzness implies both\nrobustness in the sense of sensitivity to input perturbations, as well as\nrobust distinguishability of different inputs from their corresponding outputs,\ni.e. the inverse model robustly reconstructs the input sequence despite small\nperturbations to the initial conditions and measured output. Building on this\nfoundation, we propose a parameterization of neural dynamic models:\nbi-Lipschitz recurrent equilibrium networks (biLipREN), which are robustly\ninvertible by construction. Moreover, biLipRENs can be composed with orthogonal\nlinear systems to construct more general bi-Lipschitz dynamic models, e.g., a\nnonlinear analogue of minimum-phase/all-pass (inner/outer) factorization. We\nillustrate the utility of our proposed approach with numerical examples.", "published": "2025-05-05 23:27:52", "link": "http://arxiv.org/abs/2505.03069v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery", "abstract": "Large Language Models (LLMs) are reshaping many aspects of materials science\nand chemistry research, enabling advances in molecular property prediction,\nmaterials design, scientific automation, knowledge extraction, and more. Recent\ndevelopments demonstrate that the latest class of models are able to integrate\nstructured and unstructured data, assist in hypothesis generation, and\nstreamline research workflows. To explore the frontier of LLM capabilities\nacross the research lifecycle, we review applications of LLMs through 34 total\nprojects developed during the second annual Large Language Model Hackathon for\nApplications in Materials Science and Chemistry, a global hybrid event. These\nprojects spanned seven key research areas: (1) molecular and material property\nprediction, (2) molecular and material design, (3) automation and novel\ninterfaces, (4) scientific communication and education, (5) research data\nmanagement and automation, (6) hypothesis generation and evaluation, and (7)\nknowledge extraction and reasoning from the scientific literature.\nCollectively, these applications illustrate how LLMs serve as versatile\npredictive models, platforms for rapid prototyping of domain-specific tools,\nand much more. In particular, improvements in both open source and proprietary\nLLM performance through the addition of reasoning, additional training data,\nand new techniques have expanded effectiveness, particularly in low-data\nenvironments and interdisciplinary research. As LLMs continue to improve, their\nintegration into scientific workflows presents both new opportunities and new\nchallenges, requiring ongoing exploration, continued refinement, and further\nresearch to address reliability, interpretability, and reproducibility.", "published": "2025-05-05 22:08:37", "link": "http://arxiv.org/abs/2505.03049v1", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "cs.LG"}
{"title": "A New Perspective To Understanding Multi-resolution Hash Encoding For Neural Fields", "abstract": "Instant-NGP has been the state-of-the-art architecture of neural fields in\nrecent years. Its incredible signal-fitting capabilities are generally\nattributed to its multi-resolution hash grid structure and have been used and\nimproved in numerous following works. However, it is unclear how and why such a\nhash grid structure improves the capabilities of a neural network by such great\nmargins. A lack of principled understanding of the hash grid also implies that\nthe large set of hyperparameters accompanying Instant-NGP could only be tuned\nempirically without much heuristics. To provide an intuitive explanation of the\nworking principle of the hash grid, we propose a novel perspective, namely\ndomain manipulation. This perspective provides a ground-up explanation of how\nthe feature grid learns the target signal and increases the expressivity of the\nneural field by artificially creating multiples of pre-existing linear\nsegments. We conducted numerous experiments on carefully constructed\n1-dimensional signals to support our claims empirically and aid our\nillustrations. While our analysis mainly focuses on 1-dimensional signals, we\nshow that the idea is generalizable to higher dimensions.", "published": "2025-05-05 21:53:09", "link": "http://arxiv.org/abs/2505.03042v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Modeling Spatial Extremes using Non-Gaussian Spatial Autoregressive Models via Convolutional Neural Networks", "abstract": "Data derived from remote sensing or numerical simulations often have a\nregular gridded structure and are large in volume, making it challenging to\nfind accurate spatial models that can fill in missing grid cells or simulate\nthe process effectively, especially in the presence of spatial heterogeneity\nand heavy-tailed marginal distributions. To overcome this issue, we present a\nspatial autoregressive modeling framework, which maps observations at a\nlocation and its neighbors to independent random variables. This is a highly\nflexible modeling approach and well-suited for non-Gaussian fields, providing\nsimpler interpretability. In particular, we consider the SAR model with\nGeneralized Extreme Value distribution innovations to combine the observation\nat a central grid location with its neighbors, capturing extreme spatial\nbehavior based on the heavy-tailed innovations. While these models are fast to\nsimulate by exploiting the sparsity of the key matrices in the computations,\nthe maximum likelihood estimation of the parameters is prohibitive due to the\nintractability of the likelihood, making optimization challenging. To overcome\nthis, we train a convolutional neural network on a large training set that\ncovers a useful parameter space, and then use the trained network for fast\nparameter estimation. Finally, we apply this model to analyze annual maximum\nprecipitation data from ERA-Interim-driven Weather Research and Forecasting\n(WRF) simulations, allowing us to explore its spatial extreme behavior across\nNorth America.", "published": "2025-05-05 21:26:02", "link": "http://arxiv.org/abs/2505.03034v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "New affine invariant ensemble samplers and their dimensional scaling", "abstract": "We introduce some new affine invariant ensemble samplers that are easy to\nconstruct and improve upon existing widely used algorithms, especially for\nhigh-dimensional problems. Specifically, we propose a derivative-free ensemble\nside move sampler that performs favorably compared to popular samplers in the\n\\texttt{emcee} package. Additionally, we develop a class of derivative-based\nensemble Hamiltonian Monte Carlo (HMC) samplers with affine invariance, which\noutperform standard HMC without affine invariance when sampling highly skewed\ndistributions. We provide asymptotic scaling analysis for high-dimensional\nGaussian targets to further elucidate the properties of these affine invariant\nensemble samplers. In particular, with derivative information, the affine\ninvariant ensemble HMC can scale much better with dimension compared to\nderivative-free ensemble samplers.", "published": "2025-05-05 19:33:48", "link": "http://arxiv.org/abs/2505.02987v1", "categories": ["stat.CO", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.CO"}
{"title": "More Optimal Fractional-Order Stochastic Gradient Descent for Non-Convex Optimization Problems", "abstract": "Fractional-order stochastic gradient descent (FOSGD) leverages fractional\nexponents to capture long-memory effects in optimization. However, its utility\nis often limited by the difficulty of tuning and stabilizing these exponents.\nWe propose 2SED Fractional-Order Stochastic Gradient Descent (2SEDFOSGD), which\nintegrates the Two-Scale Effective Dimension (2SED) algorithm with FOSGD to\nadapt the fractional exponent in a data-driven manner. By tracking model\nsensitivity and effective dimensionality, 2SEDFOSGD dynamically modulates the\nexponent to mitigate oscillations and hasten convergence. Theoretically, for\nonoconvex optimization problems, this approach preserves the advantages of\nfractional memory without the sluggish or unstable behavior observed in na\\\"ive\nfractional SGD. Empirical evaluations in Gaussian and $\\alpha$-stable noise\nscenarios using an autoregressive (AR) model highlight faster convergence and\nmore robust parameter estimates compared to baseline methods, underscoring the\npotential of dimension-aware fractional techniques for advanced modeling and\nestimation tasks.", "published": "2025-05-05 19:27:36", "link": "http://arxiv.org/abs/2505.02985v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Parameter estimation for land-surface models using machine learning libraries", "abstract": "The Neural Networks for Partial Differential Equations (NN4PDEs) approach is\nused to determine the parameters of a simple land-surface model using PyTorch's\nbackpropagation engine. In order to test the inverse model, a synthetic dataset\nis created by running the model in forward mode with known parameter values to\ncreate soil temperature time series that can be used as observations for the\ninverse model. We show that it is not possible to obtain a reliable parameter\nestimation using a single observed soil temperature time series. Using\nmeasurements at two depths, reliable parameter estimates can be obtained\nalthough it is not possible to differentiate between latent and sensible heat\nfluxes. We apply the inverse model to urban flux tower data in Phoenix, United\nStates, and show that the thermal conductivity, volumetric heat capacity, and\nthe combined sensible-latent heat transfer coefficient can be reliably\nestimated using an observed value for the effective surface albedo. The\nresulting model accurately predicts the outgoing longwave radiation, conductive\nsoil fluxes and the combined sensible-latent heat fluxes.", "published": "2025-05-05 19:08:15", "link": "http://arxiv.org/abs/2505.02979v1", "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "Physics-Learning AI Datamodel (PLAID) datasets: a collection of physics simulations for machine learning", "abstract": "Machine learning-based surrogate models have emerged as a powerful tool to\naccelerate simulation-driven scientific workflows. However, their widespread\nadoption is hindered by the lack of large-scale, diverse, and standardized\ndatasets tailored to physics-based simulations. While existing initiatives\nprovide valuable contributions, many are limited in scope-focusing on specific\nphysics domains, relying on fragmented tooling, or adhering to overly\nsimplistic datamodels that restrict generalization. To address these\nlimitations, we introduce PLAID (Physics-Learning AI Datamodel), a flexible and\nextensible framework for representing and sharing datasets of physics\nsimulations. PLAID defines a unified standard for describing simulation data\nand is accompanied by a library for creating, reading, and manipulating complex\ndatasets across a wide range of physical use cases (gitlab.com/drti/plaid). We\nrelease six carefully crafted datasets under the PLAID standard, covering\nstructural mechanics and computational fluid dynamics, and provide baseline\nbenchmarks using representative learning methods. Benchmarking tools are made\navailable on Hugging Face, enabling direct participation by the community and\ncontribution to ongoing evaluation efforts (huggingface.co/PLAIDcompetitions).", "published": "2025-05-05 18:59:17", "link": "http://arxiv.org/abs/2505.02974v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "GeoERM: Geometry-Aware Multi-Task Representation Learning on Riemannian Manifolds", "abstract": "Multi-Task Learning (MTL) seeks to boost statistical power and learning\nefficiency by discovering structure shared across related tasks.\nState-of-the-art MTL representation methods, however, usually treat the latent\nrepresentation matrix as a point in ordinary Euclidean space, ignoring its\noften non-Euclidean geometry, thus sacrificing robustness when tasks are\nheterogeneous or even adversarial. We propose GeoERM, a geometry-aware MTL\nframework that embeds the shared representation on its natural Riemannian\nmanifold and optimizes it via explicit manifold operations. Each training cycle\nperforms (i) a Riemannian gradient step that respects the intrinsic curvature\nof the search space, followed by (ii) an efficient polar retraction to remain\non the manifold, guaranteeing geometric fidelity at every iteration. The\nprocedure applies to a broad class of matrix-factorized MTL models and retains\nthe same per-iteration cost as Euclidean baselines. Across a set of synthetic\nexperiments with task heterogeneity and on a wearable-sensor\nactivity-recognition benchmark, GeoERM consistently improves estimation\naccuracy, reduces negative transfer, and remains stable under adversarial label\nnoise, outperforming leading MTL and single-task alternatives.", "published": "2025-05-05 18:56:16", "link": "http://arxiv.org/abs/2505.02972v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Single-Sample and Robust Online Resource Allocation", "abstract": "Online Resource Allocation problem is a central problem in many areas of\nComputer Science, Operations Research, and Economics. In this problem, we\nsequentially receive $n$ stochastic requests for $m$ kinds of shared resources,\nwhere each request can be satisfied in multiple ways, consuming different\namounts of resources and generating different values. The goal is to achieve a\n$(1-\\epsilon)$-approximation to the hindsight optimum, where $\\epsilon>0$ is a\nsmall constant, assuming each resource has a large budget.\n  In this paper, we investigate the learnability and robustness of online\nresource allocation. Our primary contribution is a novel Exponential Pricing\nalgorithm with the following properties: 1. It requires only a \\emph{single\nsample} from each of the $n$ request distributions to achieve a\n$(1-\\epsilon)$-approximation for online resource allocation with large budgets.\nSuch an algorithm was previously unknown, even with access to polynomially many\nsamples, as prior work either assumed full distributional knowledge or was\nlimited to i.i.d.\\,or random-order arrivals. 2. It is robust to corruptions in\nthe outliers model and the value augmentation model. Specifically, it maintains\nits $(1 - \\epsilon)$-approximation guarantee under both these robustness\nmodels, resolving the open question posed in Argue, Gupta, Molinaro, and Singla\n(SODA'22). 3. It operates as a simple item-pricing algorithm that ensures\nincentive compatibility.\n  The intuition behind our Exponential Pricing algorithm is that the price of a\nresource should adjust exponentially as it is overused or underused. It differs\nfrom conventional approaches that use an online learning algorithm for item\npricing. This departure guarantees that the algorithm will never run out of any\nresource, but loses the usual no-regret properties of online learning\nalgorithms, necessitating a new analytical approach.", "published": "2025-05-05 18:48:11", "link": "http://arxiv.org/abs/2505.02963v1", "categories": ["cs.DS", "cs.GT", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Smooth Quadratic Prediction Markets", "abstract": "When agents trade in a Duality-based Cost Function prediction market, they\ncollectively implement the learning algorithm Follow-The-Regularized-Leader. We\nask whether other learning algorithms could be used to inspire the design of\nprediction markets. By decomposing and modifying the Duality-based Cost\nFunction Market Maker's (DCFMM) pricing mechanism, we propose a new prediction\nmarket, called the Smooth Quadratic Prediction Market, the incentivizes agents\nto collectively implement general steepest gradient descent. Relative to the\nDCFMM, the Smooth Quadratic Prediction Market has a better worst-case monetary\nloss for AD securities while preserving axiom guarantees such as the existence\nof instantaneous price, information incorporation, expressiveness, no\narbitrage, and a form of incentive compatibility. To motivate the application\nof the Smooth Quadratic Prediction Market, we independently examine agents'\ntrading behavior under two realistic constraints: bounded budgets and buy-only\nsecurities. Finally, we provide an introductory analysis of an approach to\nfacilitate adaptive liquidity using the Smooth Quadratic AD Prediction Market.\nOur results suggest future designs where the price update rule is separate from\nthe fee structure, yet guarantees are preserved.", "published": "2025-05-05 18:43:58", "link": "http://arxiv.org/abs/2505.02959v1", "categories": ["cs.LG", "cs.GT"], "primary_category": "cs.LG"}
{"title": "RetroInfer: A Vector-Storage Approach for Scalable Long-Context LLM Inference", "abstract": "The growing context lengths of large language models (LLMs) pose significant\nchallenges for efficient inference, primarily due to GPU memory and bandwidth\nconstraints. We present RetroInfer, a novel system that reconceptualizes the\nkey-value (KV) cache as a vector storage system which exploits the inherent\nattention sparsity to accelerate long-context LLM inference. At its core is the\nwave index, an Attention-aWare VEctor index that enables efficient and accurate\nretrieval of critical tokens through techniques such as tripartite attention\napproximation, accuracy-bounded attention estimation, and segmented clustering.\nComplementing this is the wave buffer, which coordinates KV cache placement and\noverlaps computation and data transfer across GPU and CPU to sustain high\nthroughput. Unlike prior sparsity-based methods that struggle with token\nselection and hardware coordination, RetroInfer delivers robust performance\nwithout compromising model accuracy. Experiments on long-context benchmarks\nshow up to 4.5X speedup over full attention within GPU memory limits and up to\n10.5X over sparse attention baselines when KV cache is extended to CPU memory,\nall while preserving full-attention-level accuracy.", "published": "2025-05-05 18:01:17", "link": "http://arxiv.org/abs/2505.02922v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Layer Potential Methods for Doubly-Periodic Harmonic Functions", "abstract": "We develop and analyze layer potential methods to represent harmonic\nfunctions on finitely-connected tori (i.e., doubly-periodic harmonic\nfunctions). The layer potentials are expressed in terms of a doubly-periodic\nand non-harmonic Green's function that can be explicitly written in terms of\nthe Jacobi theta function or a modified Weierstrass sigma function. Extending\nresults for finitely-connected Euclidean domains, we prove that the single- and\ndouble-layer potential operators are compact linear operators and derive\nrelevant limiting properties at the boundary. We show that when the boundary\nhas more than one connected component, the Fredholm operator of the second kind\nassociated with the double-layer potential operator has a non-trivial null\nspace, which can be explicitly constructed. Finally, we apply our developed\ntheory to obtain solutions to the Dirichlet and Neumann boundary value\nproblems, as well as the Steklov eigenvalue problem. We implement the developed\nmethods using Nystr\\\"om discretization and find approximate solutions for these\nproblems in several numerical examples. Our method avoids a lattice sum of the\nfree space Green's function, is shown to be spectrally convergent, and has a\nfaster convergence rate than the method of particular solutions for problems on\ntori with irregularly shaped holes.", "published": "2025-05-05 23:52:27", "link": "http://arxiv.org/abs/2505.03074v1", "categories": ["math.NA", "cs.NA", "math.AP", "30F15, 31A25, 35B10, 35J05, 65N25"], "primary_category": "math.NA"}
{"title": "$\\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems by multivariate rational interpolation", "abstract": "This paper addresses the $\\mathcal{H}_2$-optimal approximation of linear\ndynamical systems with quadratic-output functions, also known as linear\nquadratic-output systems. Our major contributions are threefold. First, we\nderive interpolation-based first-order optimality conditions for the linear\nquadratic-output $\\mathcal{H}_2$ minimization problem. These conditions\ncorrespond to the mixed-multipoint tangential interpolation of the full-order\nlinear- and quadratic-output transfer functions, and generalize the\nMeier-Luenberger optimality framework for the $\\mathcal{H}_2$-optimal model\nreduction of linear time-invariant systems. Second, given the interpolation\ndata, we show how to enforce these mixed-multipoint tangential interpolation\nconditions explicitly by Petrov-Galerkin projection of the full-order model\nmatrices. Third, to find the optimal interpolation data, we build on this\nprojection framework and propose a generalization of the iterative rational\nKrylov algorithm for the $\\mathcal{H}_2$-optimal model reduction of linear\nquadratic-output systems, called LQO-IRKA. Upon convergence, LQO-IRKA produces\na reduced linear quadratic-output system that satisfies the interpolatory\noptimality conditions. The method only requires solving shifted linear systems\nand matrix-vector products, thus making it suitable for large-scale problems.\nNumerical examples are included to illustrate the effectiveness of the proposed\nmethod.", "published": "2025-05-05 22:39:27", "link": "http://arxiv.org/abs/2505.03057v1", "categories": ["math.NA", "cs.NA", "cs.SY", "eess.SY", "math.DS", "math.OC", "34C20, 41A05, 49K15, 65J05, 65F99, 93A15, 93C10, 93C80"], "primary_category": "math.NA"}
{"title": "Asymptotically short generalizations of $t$-design curves", "abstract": "Ehler and Gr\\\"{o}chenig posed the question of finding $t$-design curves\n$\\gamma_t$$\\unicode{x2013}$curves whose associated line integrals exactly\naverage all degree at most $t$ polynomials$\\unicode{x2013}$on $S^d$ of\nasymptotically optimal arc length $\\ell(\\gamma_t)\\asymp t^{d-1}$ as\n$t\\to\\infty$. This work investigates analogues of this question for\n$\\textit{weighted}$ and $\\textit{$\\varepsilon_t$-approximate $t$-design\ncurves}$, proving existence of such curves $\\gamma_t$ on $S^d$ of arc length\n$\\ell(\\gamma_t)\\asymp t^{d-1}$ as $t\\to\\infty$ for all $d\\in\\Bbb N_+$ in the\nweighted setting (in which case such curves are asymptotically optimal) and all\nodd $d\\in\\Bbb N_+$ in the approximate setting (where we have\n$\\varepsilon_t\\asymp1/t$ as $t\\to\\infty$). Formulas for such weighted\n$t$-design curves for $d\\in\\{2,3\\}$ are presented.", "published": "2025-05-05 22:36:17", "link": "http://arxiv.org/abs/2505.03056v1", "categories": ["math.MG", "cs.NA", "math.NA", "41A55 (primary), 05B30, 41A63, 41A81, 65D30, 65D32 (secondary)"], "primary_category": "math.MG"}
{"title": "Parallel GPU-Accelerated Randomized Construction of Approximate Cholesky Preconditioners", "abstract": "We introduce a parallel algorithm to construct a preconditioner for solving a\nlarge, sparse linear system where the coefficient matrix is a Laplacian matrix\n(a.k.a., graph Laplacian). Such a linear system arises from applications such\nas discretization of a partial differential equation, spectral graph\npartitioning, and learning problems on graphs. The preconditioner belongs to\nthe family of incomplete factorizations and is purely algebraic. Unlike\ntraditional incomplete factorizations, the new method employs randomization to\ndetermine whether or not to keep fill-ins, i.e., newly generated nonzero\nelements during Gaussian elimination. Since the sparsity pattern of the\nrandomized factorization is unknown, computing such a factorization in parallel\nis extremely challenging, especially on many-core architectures such as GPUs.\nOur parallel algorithm dynamically computes the dependency among row/column\nindices of the Laplacian matrix to be factorized and processes the independent\nindices in parallel. Furthermore, unlike previous approaches, our method\nrequires little pre-processing time. We implemented the parallel algorithm for\nmulti-core CPUs and GPUs, and we compare their performance to other\nstate-of-the-art methods.", "published": "2025-05-05 19:06:45", "link": "http://arxiv.org/abs/2505.02977v1", "categories": ["cs.DC", "cs.DS", "cs.NA", "math.NA"], "primary_category": "cs.DC"}
{"title": "A variational multiscale approach to goal-oriented error estimation in finite element analysis of convection-diffusion-reaction equation problems", "abstract": "This paper presents a goal-oriented a posteriori error estimation framework\nfor linear functionals in the stabilized finite element discretization of the\nstationary convection-diffusion-reaction (CDR) equation. The theoretical\nframework for error estimation is based on the variational multiscale (VMS)\nconcept, where the solution is decomposed into resolved (finite element) and\nunresolved (sub-grid) scales. In this work, we propose an orthogonal sub-grid\nscale (OSGS) method for a goal-oriented error estimation in VMS\ndiscretizations. In the OSGS approach, the space of the sub-grid scales (SGSs)\nis orthogonal to the finite element space. The error is estimated in the\nquantity of interest, given by the linear functional $Q(u)$ of the unknown $u$.\nIf the SGS $u'$ is estimated, the error in the quantity of interest can be\napproximated by $Q(u')$. Our approach is compared with a duality-based a\nposteriori error estimation method, which requires the solution of an\nadditional auxiliary problem. The results indicate that both methods yield\nsimilar error estimates, whereas the VMS-based explicit approach is\ncomputationally less expensive than the duality-based implicit approach.\nNumerical tests demonstrated the effectiveness of our proposed error estimation\ntechniques in terms of the quantity of interest functionals.", "published": "2025-05-05 18:22:14", "link": "http://arxiv.org/abs/2505.02946v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Variational diffusion transformers for conditional sampling of supernovae spectra", "abstract": "Type Ia Supernovae (SNe Ia) have become the most precise distance indicators\nin astrophysics due to their incredible observational homogeneity. Increasing\ndiscovery rates, however, have revealed multiple sub-populations with\nspectroscopic properties that are both diverse and difficult to interpret using\nexisting physical models. These peculiar events are hard to identify from\nsparsely sampled observations and can introduce systematics in cosmological\nanalyses if not flagged early; they are also of broader importance for building\na cohesive understanding of thermonuclear explosions. In this work, we\nintroduce DiTSNe-Ia, a variational diffusion-based generative model conditioned\non light curve observations and trained to reproduce the observed spectral\ndiversity of SNe Ia. In experiments with realistic light curves and spectra\nfrom radiative transfer simulations, DiTSNe-Ia achieves significantly more\naccurate reconstructions than the widely used SALT3 templates across a broad\nrange of observation phases (from 10 days before peak light to 30 days after\nit). DiTSNe-Ia yields a mean squared error of 0.108 across all phases-five\ntimes lower than SALT3's 0.508-and an after-peak error of just 0.0191, an order\nof magnitude smaller than SALT3's 0.305. Additionally, our model produces\nwell-calibrated credible intervals with near-nominal coverage, particularly at\npost-peak phases. DiTSNe-Ia is a powerful tool for rapidly inferring the\nspectral properties of SNe Ia and other transient astrophysical phenomena for\nwhich a physical description does not yet exist.", "published": "2025-05-05 22:52:32", "link": "http://arxiv.org/abs/2505.03063v1", "categories": ["astro-ph.IM", "stat.ML"], "primary_category": "astro-ph.IM"}
{"title": "Coupling the Heart to Musical Machines", "abstract": "Biofeedback is being used more recently as a general control paradigm for\nhuman-computer interfaces (HCIs). While biofeedback especially from breath has\nseen increasing uptake as a controller for novel musical interfaces, new\ninterfaces for musical expression (NIMEs), the community has not given as much\nattention to the heart. The heart is just as intimate a part of music as breath\nand it is argued that the heart determines our perception of time and so\nindirectly our perception of music. Inspired by this I demonstrate a\nphotoplethysmogram (PPG)-based NIME controller using heart rate as a 1D control\nparameter to transform the qualities of sounds in real-time over a Bluetooth\nwireless HCI. I apply time scaling to \"warp\" audio buffers inbound to the sound\ncard, and play these transformed audio buffers back to the listener wearing the\nPPG sensor, creating a hypothetical perceptual biofeedback loop: changes in\nsound change heart rate to change PPG measurements to change sound. I discuss\nhow a sound-heart-PPG biofeedback loop possibly affords greater control and/or\nvariety of movements with a 1D controller, how controlling the space and/or\ntime scale of sound playback with biofeedback makes for possibilities in\nperformance ambience, and I briefly discuss generative latent spaces as a\npossible way to extend a 1D PPG control space.", "published": "2025-05-05 23:50:41", "link": "http://arxiv.org/abs/2505.03073v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "The Search for Squawk: Agile Modeling in Bioacoustics", "abstract": "Passive acoustic monitoring (PAM) has shown great promise in helping\necologists understand the health of animal populations and ecosystems. However,\nextracting insights from millions of hours of audio recordings requires the\ndevelopment of specialized recognizers. This is typically a challenging task,\nnecessitating large amounts of training data and machine learning expertise. In\nthis work, we introduce a general, scalable and data-efficient system for\ndeveloping recognizers for novel bioacoustic problems in under an hour. Our\nsystem consists of several key components that tackle problems in previous\nbioacoustic workflows: 1) highly generalizable acoustic embeddings pre-trained\nfor birdsong classification minimize data hunger; 2) indexed audio search\nallows the efficient creation of classifier training datasets, and 3)\nprecomputation of embeddings enables an efficient active learning loop,\nimproving classifier quality iteratively with minimal wait time. Ecologists\nemployed our system in three novel case studies: analyzing coral reef health\nthrough unidentified sounds; identifying juvenile Hawaiian bird calls to\nquantify breeding success and improve endangered species monitoring; and\nChristmas Island bird occupancy modeling. We augment the case studies with\nsimulated experiments which explore the range of design decisions in a\nstructured way and help establish best practices. Altogether these experiments\nshowcase our system's scalability, efficiency, and generalizability, enabling\nscientists to quickly address new bioacoustic challenges.", "published": "2025-05-05 23:34:15", "link": "http://arxiv.org/abs/2505.03071v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings", "abstract": "Unsupervised contrastive learning has become a hot research topic in natural\nlanguage processing. Existing works usually aim at constraining the orientation\ndistribution of the representations of positive and negative samples in the\nhigh-dimensional semantic space in contrastive learning, but the semantic\nrepresentation tensor possesses both modulus and orientation features, and the\nexisting works ignore the modulus feature of the representations and cause\ninsufficient contrastive learning. % Therefore, we firstly propose a training\nobjective that aims at modulus constraints on the semantic representation\ntensor, to strengthen the alignment between the positive samples in contrastive\nlearning. Therefore, we first propose a training objective that is designed to\nimpose modulus constraints on the semantic representation tensor, to strengthen\nthe alignment between positive samples in contrastive learning. Then, the\nBERT-like model suffers from the phenomenon of sinking attention, leading to a\nlack of attention to CLS tokens that aggregate semantic information. In\nresponse, we propose a cross-attention structure among the twin-tower ensemble\nmodels to enhance the model's attention to CLS token and optimize the quality\nof CLS Pooling. Combining the above two motivations, we propose a new\n\\textbf{J}oint \\textbf{T}ensor representation modulus constraint and\n\\textbf{C}ross-attention unsupervised contrastive learning \\textbf{S}entence\n\\textbf{E}mbedding representation framework JTCSE, which we evaluate in seven\nsemantic text similarity computation tasks, and the experimental results show\nthat JTCSE's twin-tower ensemble model and single-tower distillation model\noutperform the other baselines and become the current SOTA. In addition, we\nhave conducted an extensive zero-shot downstream task evaluation, which shows\nthat JTCSE outperforms other baselines overall on more than 130 tasks.", "published": "2025-05-05 05:09:21", "link": "http://arxiv.org/abs/2505.02366v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cell-Free Massive MIMO-Assisted SWIPT for IoT Networks", "abstract": "This paper studies cell-free massive multiple-input multiple-output\n(CF-mMIMO) systems that underpin simultaneous wireless information and power\ntransfer (SWIPT) for separate information users (IUs) and energy users (EUs) in\nInternet of Things (IoT) networks. We propose a joint access point (AP)\noperation mode selection and power control design, wherein certain APs are\ndesignated for energy transmission to EUs, while others are dedicated to\ninformation transmission to IUs. The performance of the system, from both a\nspectral efficiency (SE) and energy efficiency (EE) perspective, is\ncomprehensively analyzed. Specifically, we formulate two mixed-integer\nnonconvex optimization problems for maximizing the average sum-SE and EE, under\nrealistic power consumption models and constraints on the minimum individual SE\nrequirements for individual IUs, minimum HE for individual EUs, and maximum\ntransmit power at each AP. The challenging optimization problems are solved\nusing successive convex approximation (SCA) techniques. The proposed framework\ndesign is further applied to the average sum-HE maximization and energy\nharvesting fairness problems. Our numerical results demonstrate that the\nproposed joint AP operation mode selection and power control algorithm can\nachieve EE performance gains of up to $4$-fold and $5$-fold over random AP\noperation mode selection, with and without power control respectively.", "published": "2025-05-05 17:32:14", "link": "http://arxiv.org/abs/2505.02806v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks", "abstract": "Sharpness-Aware Minimization (SAM) improves neural network generalization by\noptimizing the worst-case loss within a neighborhood of parameters, yet it\nperturbs parameters using the entire gradient vector, including components with\nlow statistical significance. We introduce ZSharp, a refined sharpness-aware\noptimization method that incorporates layer-wise Z-score normalization followed\nby percentile-based filtering. This process selects only the most statistically\nsignificant gradient components-those with large standardized magnitudes-for\nconstructing the perturbation direction. ZSharp retains the standard two-phase\nSAM structure of ascent and descent while modifying the ascent step to focus on\nsharper, curvature-relevant directions. We evaluate ZSharp on CIFAR-10,\nCIFAR-100, and Tiny-ImageNet using a range of models including ResNet, VGG, and\nVision Transformers. Across all architectures and datasets, ZSharp consistently\nachieves higher test accuracy compared to SAM, ASAM, and Friendly-SAM. These\nresults indicate that Z-score-based gradient filtering can enhance the\nsharpness sensitivity of the update direction, leading to improved\ngeneralization in deep neural network training.", "published": "2025-05-05 05:13:12", "link": "http://arxiv.org/abs/2505.02369v3", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT", "cs.NE", "math.IT"], "primary_category": "cs.LG"}
{"title": "Smooth Quadratic Prediction Markets", "abstract": "When agents trade in a Duality-based Cost Function prediction market, they\ncollectively implement the learning algorithm Follow-The-Regularized-Leader. We\nask whether other learning algorithms could be used to inspire the design of\nprediction markets. By decomposing and modifying the Duality-based Cost\nFunction Market Maker's (DCFMM) pricing mechanism, we propose a new prediction\nmarket, called the Smooth Quadratic Prediction Market, the incentivizes agents\nto collectively implement general steepest gradient descent. Relative to the\nDCFMM, the Smooth Quadratic Prediction Market has a better worst-case monetary\nloss for AD securities while preserving axiom guarantees such as the existence\nof instantaneous price, information incorporation, expressiveness, no\narbitrage, and a form of incentive compatibility. To motivate the application\nof the Smooth Quadratic Prediction Market, we independently examine agents'\ntrading behavior under two realistic constraints: bounded budgets and buy-only\nsecurities. Finally, we provide an introductory analysis of an approach to\nfacilitate adaptive liquidity using the Smooth Quadratic Prediction Market. Our\nresults suggest future designs where the price update rule is separate from the\nfee structure, yet guarantees are preserved.", "published": "2025-05-05 18:43:58", "link": "http://arxiv.org/abs/2505.02959v2", "categories": ["cs.LG", "cs.GT"], "primary_category": "cs.LG"}
