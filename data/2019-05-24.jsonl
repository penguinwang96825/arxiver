{"title": "An Analysis of Source-Side Grammatical Errors in NMT", "abstract": "The quality of Neural Machine Translation (NMT) has been shown to\nsignificantly degrade when confronted with source-side noise. We present the\nfirst large-scale study of state-of-the-art English-to-German NMT on real\ngrammatical noise, by evaluating on several Grammar Correction corpora. We\npresent methods for evaluating NMT robustness without true references, and we\nuse them for extensive analysis of the effects that different grammatical\nerrors have on the NMT output. We also introduce a technique for visualizing\nthe divergence distribution caused by a source-side error, which allows for\nadditional insights.", "published": "2019-05-24 04:16:46", "link": "http://arxiv.org/abs/1905.10024v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Outline Generation: Understanding the Inherent Content Structure of\n  Documents", "abstract": "In this paper, we introduce and tackle the Outline Generation (OG) task,\nwhich aims to unveil the inherent content structure of a multi-paragraph\ndocument by identifying its potential sections and generating the corresponding\nsection headings. Without loss of generality, the OG task can be viewed as a\nnovel structured summarization task. To generate a sound outline, an ideal OG\nmodel should be able to capture three levels of coherence, namely the coherence\nbetween context paragraphs, that between a section and its heading, and that\nbetween context headings. The first one is the foundation for section\nidentification, while the latter two are critical for consistent heading\ngeneration. In this work, we formulate the OG task as a hierarchical structured\nprediction problem, i.e., to first predict a sequence of section boundaries and\nthen a sequence of section headings accordingly. We propose a novel\nhierarchical structured neural generation model, named HiStGen, for the task.\nOur model attempts to capture the three-level coherence via the following ways.\nFirst, we introduce a Markov paragraph dependency mechanism between context\nparagraphs for section identification. Second, we employ a section-aware\nattention mechanism to ensure the semantic coherence between a section and its\nheading. Finally, we leverage a Markov heading dependency mechanism and a\nreview mechanism between context headings to improve the consistency and\neliminate duplication between section headings. Besides, we build a novel\nWIKIOG dataset, a public collection which consists of over 1.75 million\ndocument-outline pairs for research on the OG task. Experimental results on our\nbenchmark dataset demonstrate that our model can significantly outperform\nseveral state-of-the-art sequential generation models for the OG task.", "published": "2019-05-24 05:29:33", "link": "http://arxiv.org/abs/1905.10039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions", "abstract": "In this paper we study yes/no questions that are naturally occurring ---\nmeaning that they are generated in unprompted and unconstrained settings. We\nbuild a reading comprehension dataset, BoolQ, of such questions, and show that\nthey are unexpectedly challenging. They often query for complex, non-factoid\ninformation, and require difficult entailment-like inference to solve. We also\nexplore the effectiveness of a range of transfer learning baselines. We find\nthat transferring from entailment data is more effective than transferring from\nparaphrase or extractive QA data, and that it, surprisingly, continues to be\nvery beneficial even when starting from massive pre-trained language models\nsuch as BERT. Our best method trains BERT on MultiNLI and then re-trains it on\nour train set. It achieves 80.4% accuracy compared to 90% accuracy of human\nannotators (and 62% majority-baseline), leaving a significant gap for future\nwork.", "published": "2019-05-24 05:48:49", "link": "http://arxiv.org/abs/1905.10044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dual Reinforcement Learning Framework for Unsupervised Text Style\n  Transfer", "abstract": "Unsupervised text style transfer aims to transfer the underlying style of\ntext but keep its main content unchanged without parallel data. Most existing\nmethods typically follow two steps: first separating the content from the\noriginal style, and then fusing the content with the desired style. However,\nthe separation in the first step is challenging because the content and style\ninteract in subtle ways in natural language. Therefore, in this paper, we\npropose a dual reinforcement learning framework to directly transfer the style\nof the text via a one-step mapping model, without any separation of content and\nstyle. Specifically, we consider the learning of the source-to-target and\ntarget-to-source mappings as a dual task, and two rewards are designed based on\nsuch a dual structure to reflect the style accuracy and content preservation,\nrespectively. In this way, the two one-step mapping models can be trained via\nreinforcement learning, without any use of parallel data. Automatic evaluations\nshow that our model outperforms the state-of-the-art systems by a large margin,\nespecially with more than 8 BLEU points improvement averaged on two benchmark\ndatasets. Human evaluations also validate the effectiveness of our model in\nterms of style accuracy, content preservation and fluency. Our code and data,\nincluding outputs of all baselines and our model are available at\nhttps://github.com/luofuli/DualLanST.", "published": "2019-05-24 07:02:05", "link": "http://arxiv.org/abs/1905.10060v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Context and External Knowledge for Pronoun Coreference\n  Resolution", "abstract": "Linking pronominal expressions to the correct references requires, in many\ncases, better analysis of the contextual information and external knowledge. In\nthis paper, we propose a two-layer model for pronoun coreference resolution\nthat leverages both context and external knowledge, where a knowledge attention\nmechanism is designed to ensure the model leveraging the appropriate source of\nexternal knowledge based on different context. Experimental results demonstrate\nthe validity and effectiveness of our model, where it outperforms\nstate-of-the-art models by a large margin.", "published": "2019-05-24 13:52:14", "link": "http://arxiv.org/abs/1905.10238v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Out-of-Domain Utterance Handling With Counterfeit Data\n  Augmentation", "abstract": "Neural dialog models often lack robustness to anomalous user input and\nproduce inappropriate responses which leads to frustrating user experience.\nAlthough there are a set of prior approaches to out-of-domain (OOD) utterance\ndetection, they share a few restrictions: they rely on OOD data or multiple\nsub-domains, and their OOD detection is context-independent which leads to\nsuboptimal performance in a dialog. The goal of this paper is to propose a\nnovel OOD detection method that does not require OOD data by utilizing\ncounterfeit OOD turns in the context of a dialog. For the sake of fostering\nfurther research, we also release new dialog datasets which are 3 publicly\navailable dialog corpora augmented with OOD turns in a controllable way. Our\nmethod outperforms state-of-the-art dialog models equipped with a conventional\nOOD detection mechanism by a large margin in the presence of OOD utterances.", "published": "2019-05-24 14:18:18", "link": "http://arxiv.org/abs/1905.10247v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "What Syntactic Structures block Dependencies in RNN Language Models?", "abstract": "Recurrent Neural Networks (RNNs) trained on a language modeling task have\nbeen shown to acquire a number of non-local grammatical dependencies with some\nsuccess. Here, we provide new evidence that RNN language models are sensitive\nto hierarchical syntactic structure by investigating the filler--gap dependency\nand constraints on it, known as syntactic islands. Previous work is\ninconclusive about whether RNNs learn to attenuate their expectations for gaps\nin island constructions in particular or in any sufficiently complex syntactic\nenvironment. This paper gives new evidence for the former by providing control\nstudies that have been lacking so far. We demonstrate that two state-of-the-art\nRNN models are are able to maintain the filler--gap dependency through\nunbounded sentential embeddings and are also sensitive to the hierarchical\nrelationship between the filler and the gap. Next, we demonstrate that the\nmodels are able to maintain possessive pronoun gender expectations through\nisland constructions---this control case rules out the possibility that island\nconstructions block all information flow in these networks. We also evaluate\nthree untested islands constraints: coordination islands, left branch islands,\nand sentential subject islands. Models are able to learn left branch islands\nand learn coordination islands gradiently, but fail to learn sentential subject\nislands. Through these controls and new tests, we provide evidence that model\nbehavior is due to finer-grained expectations than gross syntactic complexity,\nbut also that the models are conspicuously un-humanlike in some of their\nperformance characteristics.", "published": "2019-05-24 20:06:04", "link": "http://arxiv.org/abs/1905.10431v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Call for Prudent Choice of Subword Merge Operations in Neural Machine\n  Translation", "abstract": "Most neural machine translation systems are built upon subword units\nextracted by methods such as Byte-Pair Encoding (BPE) or wordpiece. However,\nthe choice of number of merge operations is generally made by following\nexisting recipes. In this paper, we conduct a systematic exploration on\ndifferent numbers of BPE merge operations to understand how it interacts with\nthe model architecture, the strategy to build vocabularies and the language\npair. Our exploration could provide guidance for selecting proper BPE\nconfigurations in the future. Most prominently: we show that for LSTM-based\narchitectures, it is necessary to experiment with a wide range of different BPE\noperations as there is no typical optimal BPE configuration, whereas for\nTransformer architectures, smaller BPE size tends to be a typically optimal\nchoice. We urge the community to make prudent choices with subword merge\noperations, as our experiments indicate that a sub-optimal BPE configuration\nalone could easily reduce the system performance by 3-4 BLEU points.", "published": "2019-05-24 21:32:28", "link": "http://arxiv.org/abs/1905.10453v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Debiasing Word Embeddings Improves Multimodal Machine Translation", "abstract": "In recent years, pretrained word embeddings have proved useful for multimodal\nneural machine translation (NMT) models to address the shortage of available\ndatasets. However, the integration of pretrained word embeddings has not yet\nbeen explored extensively. Further, pretrained word embeddings in high\ndimensional spaces have been reported to suffer from the hubness problem.\nAlthough some debiasing techniques have been proposed to address this problem\nfor other natural language processing tasks, they have seldom been studied for\nmultimodal NMT models. In this study, we examine various kinds of word\nembeddings and introduce two debiasing techniques for three multimodal NMT\nmodels and two language pairs -- English-German translation and English-French\ntranslation. With our optimal settings, the overall performance of multimodal\nmodels was improved by up to +1.93 BLEU and +2.02 METEOR for English-German\ntranslation and +1.73 BLEU and +0.95 METEOR for English-French translation.", "published": "2019-05-24 22:11:57", "link": "http://arxiv.org/abs/1905.10464v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Designing a Symbolic Intermediate Representation for Neural Surface\n  Realization", "abstract": "Generated output from neural NLG systems often contain errors such as\nhallucination, repetition or contradiction. This work focuses on designing a\nsymbolic intermediate representation to be used in multi-stage neural\ngeneration with the intention of reducing the frequency of failed outputs. We\nshow that surface realization from this intermediate representation is of high\nquality and when the full system is applied to the E2E dataset it outperforms\nthe winner of the E2E challenge. Furthermore, by breaking out the surface\nrealization step from typically end-to-end neural systems, we also provide a\nframework for non-neural content selection and planning systems to potentially\ntake advantage of semi-supervised pretraining of neural surface realization\nmodels.", "published": "2019-05-24 23:57:11", "link": "http://arxiv.org/abs/1905.10486v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Critical Reasoning for Robust Visual Question Answering", "abstract": "Visual Question Answering (VQA) deep-learning systems tend to capture\nsuperficial statistical correlations in the training data because of strong\nlanguage priors and fail to generalize to test data with a significantly\ndifferent question-answer (QA) distribution. To address this issue, we\nintroduce a self-critical training objective that ensures that visual\nexplanations of correct answers match the most influential image regions more\nthan other competitive answer candidates. The influential regions are either\ndetermined from human visual/textual explanations or automatically from just\nsignificant words in the question and answer. We evaluate our approach on the\nVQA generalization task using the VQA-CP dataset, achieving a new\nstate-of-the-art i.e., 49.5% using textual explanations and 48.5% using\nautomatically annotated regions.", "published": "2019-05-24 01:52:31", "link": "http://arxiv.org/abs/1905.09998v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Personalizing Dialogue Agents via Meta-Learning", "abstract": "Existing personalized dialogue models use human designed persona descriptions\nto improve dialogue consistency. Collecting such descriptions from existing\ndialogues is expensive and requires hand-crafted feature designs. In this\npaper, we propose to extend Model-Agnostic Meta-Learning (MAML)(Finn et al.,\n2017) to personalized dialogue learning without using any persona descriptions.\nOur model learns to quickly adapt to new personas by leveraging only a few\ndialogue samples collected from the same user, which is fundamentally different\nfrom conditioning the response on the persona descriptions. Empirical results\non Persona-chat dataset (Zhang et al., 2018) indicate that our solution\noutperforms non-meta-learning baselines using automatic evaluation metrics, and\nin terms of human-evaluated fluency and consistency.", "published": "2019-05-24 05:01:14", "link": "http://arxiv.org/abs/1905.10033v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "mu-Forcing: Training Variational Recurrent Autoencoders for Text\n  Generation", "abstract": "It has been previously observed that training Variational Recurrent\nAutoencoders (VRAE) for text generation suffers from serious uninformative\nlatent variables problem. The model would collapse into a plain language model\nthat totally ignore the latent variables and can only generate repeating and\ndull samples. In this paper, we explore the reason behind this issue and\npropose an effective regularizer based approach to address it. The proposed\nmethod directly injects extra constraints on the posteriors of latent variables\ninto the learning process of VRAE, which can flexibly and stably control the\ntrade-off between the KL term and the reconstruction term, making the model\nlearn dense and meaningful latent representations. The experimental results\nshow that the proposed method outperforms several strong baselines and can make\nthe model learn interpretable latent variables and generate diverse meaningful\nsentences. Furthermore, the proposed method can perform well without using\nother strategies, such as KL annealing.", "published": "2019-05-24 07:32:37", "link": "http://arxiv.org/abs/1905.10072v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Controlling Risk of Web Question Answering", "abstract": "Web question answering (QA) has become an indispensable component in modern\nsearch systems, which can significantly improve users' search experience by\nproviding a direct answer to users' information need. This could be achieved by\napplying machine reading comprehension (MRC) models over the retrieved passages\nto extract answers with respect to the search query. With the development of\ndeep learning techniques, state-of-the-art MRC performances have been achieved\nby recent deep methods. However, existing studies on MRC seldom address the\npredictive uncertainty issue, i.e., how likely the prediction of an MRC model\nis wrong, leading to uncontrollable risks in real-world Web QA applications. In\nthis work, we first conduct an in-depth investigation over the risk of Web QA.\nWe then introduce a novel risk control framework, which consists of a qualify\nmodel for uncertainty estimation using the probe idea, and a decision model for\nselectively output. For evaluation, we introduce risk-related metrics, rather\nthan the traditional EM and F1 in MRC, for the evaluation of risk-aware Web QA.\nThe empirical results over both the real-world Web QA dataset and the academic\nMRC benchmark collection demonstrate the effectiveness of our approach.", "published": "2019-05-24 07:55:42", "link": "http://arxiv.org/abs/1905.10077v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "MatchZoo: A Learning, Practicing, and Developing System for Neural Text\n  Matching", "abstract": "Text matching is the core problem in many natural language processing (NLP)\ntasks, such as information retrieval, question answering, and conversation.\nRecently, deep leaning technology has been widely adopted for text matching,\nmaking neural text matching a new and active research domain. With a large\nnumber of neural matching models emerging rapidly, it becomes more and more\ndifficult for researchers, especially those newcomers, to learn and understand\nthese new models. Moreover, it is usually difficult to try these models due to\nthe tedious data pre-processing, complicated parameter configuration, and\nmassive optimization tricks, not to mention the unavailability of public codes\nsometimes. Finally, for researchers who want to develop new models, it is also\nnot an easy task to implement a neural text matching model from scratch, and to\ncompare with a bunch of existing models. In this paper, therefore, we present a\nnovel system, namely MatchZoo, to facilitate the learning, practicing and\ndesigning of neural text matching models. The system consists of a powerful\nmatching library and a user-friendly and interactive studio, which can help\nresearchers: 1) to learn state-of-the-art neural text matching models\nsystematically, 2) to train, test and apply these models with simple\nconfigurable steps; and 3) to develop their own models with rich APIs and\nassistance.", "published": "2019-05-24 15:34:54", "link": "http://arxiv.org/abs/1905.10289v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Human vs. Muppet: A Conservative Estimate of Human Performance on the\n  GLUE Benchmark", "abstract": "The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding\ntasks which has seen dramatic progress in the past year, with average\nperformance moving from 70.0 at launch to 83.9, state of the art at the time of\nwriting (May 24, 2019). Here, we measure human performance on the benchmark, in\norder to learn whether significant headroom remains for further progress. We\nprovide a conservative estimate of human performance on the benchmark through\ncrowdsourcing: Our annotators are non-experts who must learn each task from a\nbrief set of instructions and 20 examples. In spite of limited training, these\nannotators robustly outperform the state of the art on six of the nine GLUE\ntasks and achieve an average score of 87.1. Given the fast pace of progress\nhowever, the headroom we observe is quite limited. To reproduce the data-poor\nsetting that our annotators must learn in, we also train the BERT model (Devlin\net al., 2019) in limited-data regimes, and conclude that low-resource sentence\nclassification remains a challenge for modern neural network approaches to text\nunderstanding.", "published": "2019-05-24 19:55:34", "link": "http://arxiv.org/abs/1905.10425v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using Deep Networks and Transfer Learning to Address Disinformation", "abstract": "We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.", "published": "2019-05-24 19:10:18", "link": "http://arxiv.org/abs/1905.10412v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Differentiable Representations For Multihop Inference Rules", "abstract": "We present efficient differentiable implementations of second-order multi-hop\nreasoning using a large symbolic knowledge base (KB). We introduce a new\noperation which can be used to compositionally construct second-order multi-hop\ntemplates in a neural model, and evaluate a number of alternative\nimplementations, with different time and memory trade offs. These techniques\nscale to KBs with millions of entities and tens of millions of triples, and\nlead to simple models with competitive performance on several learning tasks\nrequiring multi-hop reasoning.", "published": "2019-05-24 19:20:03", "link": "http://arxiv.org/abs/1905.10417v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "HUMBO: Bridging Response Generation and Facial Expression Synthesis", "abstract": "Spoken dialogue systems that assist users to solve complex tasks such as\nmovie ticket booking have become an emerging research topic in artificial\nintelligence and natural language processing areas. With a well-designed\ndialogue system as an intelligent personal assistant, people can accomplish\ncertain tasks more easily via natural language interactions. Today there are\nseveral virtual intelligent assistants in the market; however, most systems\nonly focus on textual or vocal interaction. In this paper, we present HUMBO, a\nsystem aiming at generating dialogue responses and simultaneously synthesize\ncorresponding visual expressions on faces for better multimodal interaction.\nHUMBO can (1) let users determine the appearances of virtual assistants by a\nsingle image, and (2) generate coherent emotional utterances and facial\nexpressions on the user-provided image. This is not only a brand new research\ndirection but more importantly, an ultimate step toward more human-like virtual\nassistants.", "published": "2019-05-24 10:22:16", "link": "http://arxiv.org/abs/1905.11240v3", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Ex-Twit: Explainable Twitter Mining on Health Data", "abstract": "Since most machine learning models provide no explanations for the\npredictions, their predictions are obscure for the human. The ability to\nexplain a model's prediction has become a necessity in many applications\nincluding Twitter mining. In this work, we propose a method called Explainable\nTwitter Mining (Ex-Twit) combining Topic Modeling and Local Interpretable\nModel-agnostic Explanation (LIME) to predict the topic and explain the model\npredictions. We demonstrate the effectiveness of Ex-Twit on Twitter\nhealth-related data.", "published": "2019-05-24 15:26:18", "link": "http://arxiv.org/abs/1906.02132v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Specialized Decision Surface and Disentangled Feature for\n  Weakly-Supervised Polyphonic Sound Event Detection", "abstract": "In this paper, a special decision surface for the weakly-supervised sound\nevent detection (SED) and a disentangled feature (DF) for the multi-label\nproblem in polyphonic SED are proposed. We approach SED as a multiple instance\nlearning (MIL) problem and utilize a neural network framework with a pooling\nmodule to solve it. General MIL approaches include two kinds: the\ninstance-level approaches and embedding-level approaches. We present a method\nof generating instance-level probabilities for the embedding level approaches\nwhich tend to perform better than the instance-level approaches in terms of\nbag-level classification but can not provide instance-level probabilities in\ncurrent approaches. Moreover, we further propose a specialized decision surface\n(SDS) for the embedding-level attention pooling. We analyze and explained why\nan embedding-level attention module with SDS is better than other typical\npooling modules from the perspective of the high-level feature space. As for\nthe problem of the unbalanced dataset and the co-occurrence of multiple\ncategories in the polyphonic event detection task, we propose a DF to reduce\ninterference among categories, which optimizes the high-level feature space by\ndisentangling it based on class-wise identifiable information and obtaining\nmultiple different subspaces. Experiments on the dataset of DCASE 2018 Task 4\nshow that the proposed SDS and DF significantly improve the detection\nperformance of the embedding-level MIL approach with an attention pooling\nmodule and outperform the first place system in the challenge by 6.6 percentage\npoints.", "published": "2019-05-24 08:46:56", "link": "http://arxiv.org/abs/1905.10091v6", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fast computation of loudness using a deep neural network", "abstract": "The present paper introduces a deep neural network (DNN) for predicting the\ninstantaneous loudness of a sound from its time waveform. The DNN was trained\nusing the output of a more complex model, called the Cambridge loudness model.\nWhile a modern PC can perform a few hundred loudness computations per second\nusing the Cambridge loudness model, it can perform more than 100,000 per second\nusing the DNN, allowing real-time calculation of loudness. The root-mean-square\ndeviation between the predictions of instantaneous loudness level using the two\nmodels was less than 0.5 phon for unseen types of sound. We think that the\ngeneral approach of simulating a complex perceptual model by a much faster DNN\ncan be applied to other perceptual models to make them run in real time.", "published": "2019-05-24 18:28:39", "link": "http://arxiv.org/abs/1905.10399v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Self-supervised audio representation learning for mobile devices", "abstract": "We explore self-supervised models that can be potentially deployed on mobile\ndevices to learn general purpose audio representations. Specifically, we\npropose methods that exploit the temporal context in the spectrogram domain.\nOne method estimates the temporal gap between two short audio segments\nextracted at random from the same audio clip. The other methods are inspired by\nWord2Vec, a popular technique used to learn word embeddings, and aim at\nreconstructing a temporal spectrogram slice from past and future slices or,\nalternatively, at reconstructing the context of surrounding slices from the\ncurrent slice. We focus our evaluation on small encoder architectures, which\ncan be potentially run on mobile devices during both inference (re-using a\ncommon learned representation across multiple downstream tasks) and training\n(capturing the true data distribution without compromising users' privacy when\ncombined with federated learning). We evaluate the quality of the embeddings\nproduced by the self-supervised learning models, and show that they can be\nre-used for a variety of downstream tasks, and for some tasks even approach the\nperformance of fully supervised models of similar size.", "published": "2019-05-24 13:57:40", "link": "http://arxiv.org/abs/1905.11796v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
