{"title": "TFW, DamnGina, Juvie, and Hotsie-Totsie: On the Linguistic and Social\n  Aspects of Internet Slang", "abstract": "Slang is ubiquitous on the Internet. The emergence of new social contexts\nlike micro-blogs, question-answering forums, and social networks has enabled\nslang and non-standard expressions to abound on the web. Despite this, slang\nhas been traditionally viewed as a form of non-standard language -- a form of\nlanguage that is not the focus of linguistic analysis and has largely been\nneglected. In this work, we use UrbanDictionary to conduct the first\nlarge-scale linguistic analysis of slang and its social aspects on the Internet\nto yield insights into this variety of language that is increasingly used all\nover the world online.\n  We begin by computationally analyzing the phonological, morphological and\nsyntactic properties of slang. We then study linguistic patterns in four\nspecific categories of slang namely alphabetisms, blends, clippings, and\nreduplicatives. Our analysis reveals that slang demonstrates extra-grammatical\nrules of phonological and morphological formation that markedly distinguish it\nfrom the standard form shedding insight into its generative patterns. Next, we\nanalyze the social aspects of slang by studying subject restriction and\nstereotyping in slang usage. Analyzing tens of thousands of such slang words\nreveals that the majority of slang on the Internet belongs to two major\ncategories: sex and drugs. We also noted that not only is slang usage not\nimmune to prevalent social biases and prejudices but also reflects such biases\nand stereotypes more intensely than the standard variety.", "published": "2017-12-22 03:21:05", "link": "http://arxiv.org/abs/1712.08291v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Source-side Prediction for Neural Headline Generation", "abstract": "The encoder-decoder model is widely used in natural language generation\ntasks. However, the model sometimes suffers from repeated redundant generation,\nmisses important phrases, and includes irrelevant entities. Toward solving\nthese problems we propose a novel source-side token prediction module. Our\nmethod jointly estimates the probability distributions over source and target\nvocabularies to capture a correspondence between source and target tokens. The\nexperiments show that the proposed model outperforms the current\nstate-of-the-art method in the headline generation task. Additionally, we show\nthat our method has an ability to learn a reasonable token-wise correspondence\nwithout knowing any true alignments.", "published": "2017-12-22 04:36:07", "link": "http://arxiv.org/abs/1712.08302v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Novel Ranking-Based Lexical Similarity Measure for Word Embedding", "abstract": "Distributional semantics models derive word space from linguistic items in\ncontext. Meaning is obtained by defining a distance measure between vectors\ncorresponding to lexical entities. Such vectors present several problems. In\nthis paper we provide a guideline for post process improvements to the baseline\nvectors. We focus on refining the similarity aspect, address imperfections of\nthe model by applying the hubness reduction method, implementing relational\nknowledge into the model, and providing a new ranking similarity definition\nthat give maximum weight to the top 1 component value. This feature ranking is\nsimilar to the one used in information retrieval. All these enrichments\noutperform current literature results for joint ESL and TOEF sets comparison.\nSince single word embedding is a basic element of any semantic task one can\nexpect a significant improvement of results for these tasks. Moreover, our\nimproved method of text processing can be translated to continuous distributed\nrepresentation of biological sequences for deep proteomics and genomics.", "published": "2017-12-22 13:40:41", "link": "http://arxiv.org/abs/1712.08439v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disentangled Representations for Manipulation of Sentiment in Text", "abstract": "The ability to change arbitrary aspects of a text while leaving the core\nmessage intact could have a strong impact in fields like marketing and politics\nby enabling e.g. automatic optimization of message impact and personalized\nlanguage adapted to the receiver's profile. In this paper we take a first step\ntowards such a system by presenting an algorithm that can manipulate the\nsentiment of a text while preserving its semantics using disentangled\nrepresentations. Validation is performed by examining trajectories in embedding\nspace and analyzing transformed sentences for semantic preservation while\nexpression of desired sentiment shift.", "published": "2017-12-22 11:18:35", "link": "http://arxiv.org/abs/1712.10066v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracking the Diffusion of Named Entities", "abstract": "Existing studies of how information diffuses across social networks have thus\nfar concentrated on analysing and recovering the spread of deterministic\ninnovations such as URLs, hashtags, and group membership. However investigating\nhow mentions of real-world entities appear and spread has yet to be explored,\nlargely due to the computationally intractable nature of performing large-scale\nentity extraction. In this paper we present, to the best of our knowledge, one\nof the first pieces of work to closely examine the diffusion of named entities\non social media, using Reddit as our case study platform. We first investigate\nhow named entities can be accurately recognised and extracted from discussion\nposts. We then use these extracted entities to study the patterns of entity\ncascades and how the probability of a user adopting an entity (i.e. mentioning\nit) is associated with exposures to the entity. We put these pieces together by\npresenting a parallelised diffusion model that can forecast the probability of\nentity adoption, finding that the influence of adoption between users can be\ncharacterised by their prior interactions -- as opposed to whether the users\npropagated entity-adoptions beforehand. Our findings have important\nimplications for researchers studying influence and language, and for community\nanalysts who wish to understand entity-level influence dynamics.", "published": "2017-12-22 09:01:00", "link": "http://arxiv.org/abs/1712.08349v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Find the Conversation Killers: a Predictive Study of Thread-ending Posts", "abstract": "How to improve the quality of conversations in online communities has\nattracted considerable attention recently. Having engaged, urbane, and reactive\nonline conversations has a critical effect on the social life of Internet\nusers. In this study, we are particularly interested in identifying a post in a\nmulti-party conversation that is unlikely to be further replied to, which\ntherefore kills that thread of the conversation. For this purpose, we propose a\ndeep learning model called the ConverNet. ConverNet is attractive due to its\ncapability of modeling the internal structure of a long conversation and its\nappropriate encoding of the contextual information of the conversation, through\neffective integration of attention mechanisms. Empirical experiments on\nreal-world datasets demonstrate the effectiveness of the proposal model. For\nthe widely concerned topic, our analysis also offers implications for improving\nthe quality and user experience of online conversations.", "published": "2017-12-22 19:58:01", "link": "http://arxiv.org/abs/1712.08636v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Letter-Based Speech Recognition with Gated ConvNets", "abstract": "In the recent literature, \"end-to-end\" speech systems often refer to\nletter-based acoustic models trained in a sequence-to-sequence manner, either\nvia a recurrent model or via a structured output learning approach (such as\nCTC). In contrast to traditional phone (or senone)-based approaches, these\n\"end-to-end'' approaches alleviate the need of word pronunciation modeling, and\ndo not require a \"forced alignment\" step at training time. Phone-based\napproaches remain however state of the art on classical benchmarks. In this\npaper, we propose a letter-based speech recognition system, leveraging a\nConvNet acoustic model. Key ingredients of the ConvNet are Gated Linear Units\nand high dropout. The ConvNet is trained to map audio sequences to their\ncorresponding letter transcriptions, either via a classical CTC approach, or\nvia a recent variant called ASG. Coupled with a simple decoder at inference\ntime, our system matches the best existing letter-based systems on WSJ (in word\nerror rate), and shows near state of the art performance on LibriSpeech.", "published": "2017-12-22 17:42:15", "link": "http://arxiv.org/abs/1712.09444v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emo, Love, and God: Making Sense of Urban Dictionary, a Crowd-Sourced\n  Online Dictionary", "abstract": "The Internet facilitates large-scale collaborative projects and the emergence\nof Web 2.0 platforms, where producers and consumers of content unify, has\ndrastically changed the information market. On the one hand, the promise of the\n\"wisdom of the crowd\" has inspired successful projects such as Wikipedia, which\nhas become the primary source of crowd-based information in many languages. On\nthe other hand, the decentralized and often un-monitored environment of such\nprojects may make them susceptible to low quality content. In this work, we\nfocus on Urban Dictionary, a crowd-sourced online dictionary. We combine\ncomputational methods with qualitative annotation and shed light on the overall\nfeatures of Urban Dictionary in terms of growth, coverage and types of content.\nWe measure a high presence of opinion-focused entries, as opposed to the\nmeaning-focused entries that we expect from traditional dictionaries.\nFurthermore, Urban Dictionary covers many informal, unfamiliar words as well as\nproper nouns. Urban Dictionary also contains offensive content, but highly\noffensive content tends to receive lower scores through the dictionary's voting\nsystem. The low threshold to include new material in Urban Dictionary enables\nquick recording of new words and new meanings, but the resulting heterogeneous\ncontent can pose challenges in using Urban Dictionary as a source to study\nlanguage innovation.", "published": "2017-12-22 20:27:11", "link": "http://arxiv.org/abs/1712.08647v2", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Music of Brain and Music on Brain: A Novel EEG Sonification approach", "abstract": "Can we hear the sound of our brain? Is there any technique which can enable\nus to hear the neuro-electrical impulses originating from the different lobes\nof brain? The answer to all these questions is YES. In this paper we present a\nnovel method with which we can sonify the Electroencephalogram (EEG) data\nrecorded in rest state as well as under the influence of a simplest acoustical\nstimuli - a tanpura drone. The tanpura drone has a very simple yet very complex\nacoustic features, which is generally used for creation of an ambiance during a\nmusical performance. Hence, for this pilot project we chose to study the\ncorrelation between a simple acoustic stimuli (tanpura drone) and sonified EEG\ndata. Till date, there have been no study which deals with the direct\ncorrelation between a bio-signal and its acoustic counterpart and how that\ncorrelation varies under the influence of different types of stimuli. This is\nthe first of its kind study which bridges this gap and looks for a direct\ncorrelation between music signal and EEG data using a robust mathematical\nmicroscope called Multifractal Detrended Cross Correlation Analysis (MFDXA).\nFor this, we took EEG data of 10 participants in 2 min 'rest state' (i.e. with\nwhite noise) and in 2 min 'tanpura drone' (musical stimulus) listening\ncondition. Next, the EEG signals from different electrodes were sonified and\nMFDXA technique was used to assess the degree of correlation (or the cross\ncorrelation coefficient) between tanpura signal and EEG signals. The variation\nof {\\gamma}x for different lobes during the course of the experiment also\nprovides major interesting new information. Only music stimuli has the ability\nto engage several areas of the brain significantly unlike other stimuli (which\nengages specific domains only).", "published": "2017-12-22 08:30:47", "link": "http://arxiv.org/abs/1712.08336v1", "categories": ["q-bio.NC", "cs.SD", "eess.AS", "physics.data-an"], "primary_category": "q-bio.NC"}
{"title": "On Using Backpropagation for Speech Texture Generation and Voice\n  Conversion", "abstract": "Inspired by recent work on neural network image generation which rely on\nbackpropagation towards the network inputs, we present a proof-of-concept\nsystem for speech texture synthesis and voice conversion based on two\nmechanisms: approximate inversion of the representation learned by a speech\nrecognition neural network, and on matching statistics of neuron activations\nbetween different source and target utterances. Similar to image texture\nsynthesis and neural style transfer, the system works by optimizing a cost\nfunction with respect to the input waveform samples. To this end we use a\ndifferentiable mel-filterbank feature extraction pipeline and train a\nconvolutional CTC speech recognition network. Our system is able to extract\nspeaker characteristics from very limited amounts of target speaker data, as\nlittle as a few seconds, and can be used to generate realistic speech babble or\nreconstruct an utterance in a different voice.", "published": "2017-12-22 09:19:23", "link": "http://arxiv.org/abs/1712.08363v2", "categories": ["cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Music Genre Classification with Paralleling Recurrent Convolutional\n  Neural Network", "abstract": "Deep learning has been demonstrated its effectiveness and efficiency in music\ngenre classification. However, the existing achievements still have several\nshortcomings which impair the performance of this classification task. In this\npaper, we propose a hybrid architecture which consists of the paralleling CNN\nand Bi-RNN blocks. They focus on spatial features and temporal frame orders\nextraction respectively. Then the two outputs are fused into one powerful\nrepresentation of musical signals and fed into softmax function for\nclassification. The paralleling network guarantees the extracting features\nrobust enough to represent music. Moreover, the experiments prove our proposed\narchitecture improve the music genre classification performance and the\nadditional Bi-RNN block is a supplement for CNNs.", "published": "2017-12-22 09:49:26", "link": "http://arxiv.org/abs/1712.08370v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
