{"title": "SemVLP: Vision-Language Pre-training by Aligning Semantics at Multiple\n  Levels", "abstract": "Vision-language pre-training (VLP) on large-scale image-text pairs has\nrecently witnessed rapid progress for learning cross-modal representations.\nExisting pre-training methods either directly concatenate image representation\nand text representation at a feature level as input to a single-stream\nTransformer, or use a two-stream cross-modal Transformer to align the\nimage-text representation at a high-level semantic space. In real-world\nimage-text data, we observe that it is easy for some of the image-text pairs to\nalign simple semantics on both modalities, while others may be related after\nhigher-level abstraction. Therefore, in this paper, we propose a new\npre-training method SemVLP, which jointly aligns both the low-level and\nhigh-level semantics between image and text representations. The model is\npre-trained iteratively with two prevalent fashions: single-stream pre-training\nto align at a fine-grained feature level and two-stream pre-training to align\nhigh-level semantics, by employing a shared Transformer network with a\npluggable cross-modal attention module. An extensive set of experiments have\nbeen conducted on four well-established vision-language understanding tasks to\ndemonstrate the effectiveness of the proposed SemVLP in aligning cross-modal\nrepresentations towards different semantic granularities.", "published": "2021-03-14 02:39:14", "link": "http://arxiv.org/abs/2103.07829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A `Sourceful' Twist: Emoji Prediction Based on Sentiment, Hashtags and\n  Application Source", "abstract": "We widely use emojis in social networking to heighten, mitigate or negate the\nsentiment of the text. Emoji suggestions already exist in many cross-platform\napplications but an emoji is predicted solely based a few prominent words\ninstead of understanding the subject and substance of the text. Through this\npaper, we showcase the importance of using Twitter features to help the model\nunderstand the sentiment involved and hence to predict the most suitable emoji\nfor the text. Hashtags and Application Sources like Android, etc. are two\nfeatures which we found to be important yet underused in emoji prediction and\nTwitter sentiment analysis on the whole. To approach this shortcoming and to\nfurther understand emoji behavioral patterns, we propose a more balanced\ndataset by crawling additional Twitter data, including timestamp, hashtags, and\napplication source acting as additional attributes to the tweet. Our data\nanalysis and neural network model performance evaluations depict that using\nhashtags and application sources as features allows to encode different\ninformation and is effective in emoji prediction.", "published": "2021-03-14 03:05:04", "link": "http://arxiv.org/abs/2103.07833v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning a Word-Level Language Model with Sentence-Level Noise\n  Contrastive Estimation for Contextual Sentence Probability Estimation", "abstract": "Inferring the probability distribution of sentences or word sequences is a\nkey process in natural language processing. While word-level language models\n(LMs) have been widely adopted for computing the joint probabilities of word\nsequences, they have difficulty in capturing a context long enough for sentence\nprobability estimation (SPE). To overcome this, recent studies introduced\ntraining methods using sentence-level noise-contrastive estimation (NCE) with\nrecurrent neural networks (RNNs). In this work, we attempt to extend it for\ncontextual SPE, which aims to estimate a conditional sentence probability given\na previous text. The proposed NCE samples negative sentences independently of a\nprevious text so that the trained model gives higher probabilities to the\nsentences that are more consistent with \\textcolor{blue}{the} context. We apply\nour method to a simple word-level RNN LM to focus on the effect of the\nsentence-level NCE training rather than on the network architecture. The\nquality of estimation was evaluated against multiple-choice cloze-style\nquestions including both human and automatically generated questions. The\nexperimental results show that the proposed method improved the SPE quality for\nthe word-level RNN LM.", "published": "2021-03-14 09:17:37", "link": "http://arxiv.org/abs/2103.07875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Systematic Review of Reproducibility Research in Natural Language\n  Processing", "abstract": "Against the background of what has been termed a reproducibility crisis in\nscience, the NLP field is becoming increasingly interested in, and\nconscientious about, the reproducibility of its results. The past few years\nhave seen an impressive range of new initiatives, events and active research in\nthe area. However, the field is far from reaching a consensus about how\nreproducibility should be defined, measured and addressed, with diversity of\nviews currently increasing rather than converging. With this focused\ncontribution, we aim to provide a wide-angle, and as near as possible complete,\nsnapshot of current work on reproducibility in NLP, delineating differences and\nsimilarities, and providing pointers to common denominators.", "published": "2021-03-14 13:53:05", "link": "http://arxiv.org/abs/2103.07929v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crowdsourced Phrase-Based Tokenization for Low-Resourced Neural Machine\n  Translation: The Case of Fon Language", "abstract": "Building effective neural machine translation (NMT) models for very\nlow-resourced and morphologically rich African indigenous languages is an open\nchallenge. Besides the issue of finding available resources for them, a lot of\nwork is put into preprocessing and tokenization. Recent studies have shown that\nstandard tokenization methods do not always adequately deal with the\ngrammatical, diacritical, and tonal properties of some African languages. That,\ncoupled with the extremely low availability of training samples, hinders the\nproduction of reliable NMT models. In this paper, using Fon language as a case\nstudy, we revisit standard tokenization methods and introduce\nWord-Expressions-Based (WEB) tokenization, a human-involved super-words\ntokenization strategy to create a better representative vocabulary for\ntraining. Furthermore, we compare our tokenization strategy to others on the\nFon-French and French-Fon translation tasks.", "published": "2021-03-14 22:12:14", "link": "http://arxiv.org/abs/2103.08052v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeepStyle: User Style Embedding for Authorship Attribution of Short\n  Texts", "abstract": "Authorship attribution (AA), which is the task of finding the owner of a\ngiven text, is an important and widely studied research topic with many\napplications. Recent works have shown that deep learning methods could achieve\nsignificant accuracy improvement for the AA task. Nevertheless, most of these\nproposed methods represent user posts using a single type of feature (e.g.,\nword bi-grams) and adopt a text classification approach to address the task.\nFurthermore, these methods offer very limited explainability of the AA results.\nIn this paper, we address these limitations by proposing DeepStyle, a novel\nembedding-based framework that learns the representations of users' salient\nwriting styles. We conduct extensive experiments on two real-world datasets\nfrom Twitter and Weibo. Our experiment results show that DeepStyle outperforms\nthe state-of-the-art baselines on the AA task.", "published": "2021-03-14 15:56:37", "link": "http://arxiv.org/abs/2103.11798v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "DeepHate: Hate Speech Detection via Multi-Faceted Text Representations", "abstract": "Online hate speech is an important issue that breaks the cohesiveness of\nonline social communities and even raises public safety concerns in our\nsocieties. Motivated by this rising issue, researchers have developed many\ntraditional machine learning and deep learning methods to detect hate speech in\nonline social platforms automatically. However, most of these methods have only\nconsidered single type textual feature, e.g., term frequency, or using word\nembeddings. Such approaches neglect the other rich textual information that\ncould be utilized to improve hate speech detection. In this paper, we propose\nDeepHate, a novel deep learning model that combines multi-faceted text\nrepresentations such as word embeddings, sentiments, and topical information,\nto detect hate speech in online social platforms. We conduct extensive\nexperiments and evaluate DeepHate on three large publicly available real-world\ndatasets. Our experiment results show that DeepHate outperforms the\nstate-of-the-art baselines on the hate speech detection task. We also perform\ncase studies to provide insights into the salient features that best aid in\ndetecting hate speech in online social platforms.", "published": "2021-03-14 16:11:30", "link": "http://arxiv.org/abs/2103.11799v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "AngryBERT: Joint Learning Target and Emotion for Hate Speech Detection", "abstract": "Automated hate speech detection in social media is a challenging task that\nhas recently gained significant traction in the data mining and Natural\nLanguage Processing community. However, most of the existing methods adopt a\nsupervised approach that depended heavily on the annotated hate speech\ndatasets, which are imbalanced and often lack training samples for hateful\ncontent. This paper addresses the research gaps by proposing a novel multitask\nlearning-based model, AngryBERT, which jointly learns hate speech detection\nwith sentiment classification and target identification as secondary relevant\ntasks. We conduct extensive experiments to augment three commonly-used hate\nspeech detection datasets. Our experiment results show that AngryBERT\noutperforms state-of-the-art single-task-learning and multitask learning\nbaselines. We conduct ablation studies and case studies to empirically examine\nthe strengths and characteristics of our AngryBERT model and show that the\nsecondary tasks are able to improve hate speech detection.", "published": "2021-03-14 16:17:26", "link": "http://arxiv.org/abs/2103.11800v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Improving Code Summarization with Block-wise Abstract Syntax Tree\n  Splitting", "abstract": "Automatic code summarization frees software developers from the heavy burden\nof manual commenting and benefits software development and maintenance.\nAbstract Syntax Tree (AST), which depicts the source code's syntactic\nstructure, has been incorporated to guide the generation of code summaries.\nHowever, existing AST based methods suffer from the difficulty of training and\ngenerate inadequate code summaries. In this paper, we present the Block-wise\nAbstract Syntax Tree Splitting method (BASTS for short), which fully utilizes\nthe rich tree-form syntax structure in ASTs, for improving code summarization.\nBASTS splits the code of a method based on the blocks in the dominator tree of\nthe Control Flow Graph, and generates a split AST for each code split. Each\nsplit AST is then modeled by a Tree-LSTM using a pre-training strategy to\ncapture local non-linear syntax encoding. The learned syntax encoding is\ncombined with code encoding, and fed into Transformer to generate high-quality\ncode summaries. Comprehensive experiments on benchmarks have demonstrated that\nBASTS significantly outperforms state-of-the-art approaches in terms of various\nevaluation metrics. To facilitate reproducibility, our implementation is\navailable at https://github.com/XMUDM/BASTS.", "published": "2021-03-14 05:04:06", "link": "http://arxiv.org/abs/2103.07845v2", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Claim Verification using a Multi-GAN based Model", "abstract": "This article describes research on claim verification carried out using a\nmultiple GAN-based model. The proposed model consists of three pairs of\ngenerators and discriminators. The generator and discriminator pairs are\nresponsible for generating synthetic data for supported and refuted claims and\nclaim labels. A theoretical discussion about the proposed model is provided to\nvalidate the equilibrium state of the model. The proposed model is applied to\nthe FEVER dataset, and a pre-trained language model is used for the input text\ndata. The synthetically generated data helps to gain information which helps\nthe model to perform better than state of the art models and other standard\nclassifiers.", "published": "2021-03-14 19:15:53", "link": "http://arxiv.org/abs/2103.08001v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50"], "primary_category": "cs.LG"}
{"title": "Blind Estimation of Room Acoustic Parameters and Speech Transmission\n  Index using MTF-based CNNs", "abstract": "This paper proposes a blind estimation method based on the modulation\ntransfer function and Schroeder model for estimating reverberation time in\nseven-octave bands. Therefore, the speech transmission index and five\nroom-acoustic parameters can be estimated.", "published": "2021-03-14 12:11:11", "link": "http://arxiv.org/abs/2103.07904v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
