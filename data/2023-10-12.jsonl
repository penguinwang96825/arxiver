{"title": "Clustering of Spell Variations for Proper Nouns Transliterated from the\n  other languages", "abstract": "One of the prominent problems with processing and operating on text data is\nthe non uniformity of it. Due to the change in the dialects and languages, the\ncaliber of translation is low. This creates a unique problem while using NLP in\ntext data; which is the spell variation arising from the inconsistent\ntranslations and transliterations. This problem can also be further aggravated\nby the human error arising from the various ways to write a Proper Noun from an\nIndian language into its English equivalent. Translating proper nouns\noriginating from Indian languages can be complicated as some proper nouns are\nalso used as common nouns which might be taken literally. Applications of NLP\nthat require addresses, names and other proper nouns face this problem\nfrequently. We propose a method to cluster these spell variations for proper\nnouns using ML techniques and mathematical similarity equations. We aimed to\nuse Affinity Propagation to determine relative similarity between the tokens.\nThe results are augmented by filtering the token-variation pair by a similarity\nthreshold. We were able to reduce the spell variations by a considerable\namount. This application can significantly reduce the amount of human\nannotation efforts needed for data cleansing and formatting.", "published": "2023-10-12 00:57:32", "link": "http://arxiv.org/abs/2310.07962v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Harnessing Large Language Models' Empathetic Response Generation\n  Capabilities for Online Mental Health Counselling Support", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious information-seeking and reasoning tasks. These computational systems\ndrive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also\ncarry substantial promise in meeting the growing demands of mental health care,\nalbeit relatively unexplored. As such, this study sought to examine LLMs'\ncapability to generate empathetic responses in conversations that emulate those\nin a mental health counselling setting. We selected five LLMs: version 3.5 and\nversion 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways\nLanguage Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple\ninstructional prompt, these models responded to utterances derived from the\nEmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we\ncompared their responses to those from traditional response generation dialogue\nsystems, which were fine-tuned on the ED dataset, along with human-generated\nresponses. Notably, we discovered that responses from the LLMs were remarkably\nmore empathetic in most scenarios. We position our findings in light of\ncatapulting advancements in creating empathetic conversational systems.", "published": "2023-10-12 03:33:06", "link": "http://arxiv.org/abs/2310.08017v1", "categories": ["cs.CL", "I.2"], "primary_category": "cs.CL"}
{"title": "Training Generative Question-Answering on Synthetic Data Obtained from\n  an Instruct-tuned Model", "abstract": "This paper presents a simple and cost-effective method for synthesizing data\nto train question-answering systems. For training, fine-tuning GPT models is a\ncommon practice in resource-rich languages like English, however, it becomes\nchallenging for non-English languages due to the scarcity of sufficient\nquestion-answer (QA) pairs. Existing approaches use question and answer\ngenerators trained on human-authored QA pairs, which involves substantial human\nexpenses. In contrast, we use an instruct-tuned model to generate QA pairs in a\nzero-shot or few-shot manner. We conduct experiments to compare various\nstrategies for obtaining QA pairs from the instruct-tuned model. The results\ndemonstrate that a model trained on our proposed synthetic data achieves\ncomparable performance to a model trained on manually curated datasets, without\nincurring human costs.", "published": "2023-10-12 06:46:07", "link": "http://arxiv.org/abs/2310.08072v2", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using\n  Natural Language Processing", "abstract": "Climate change's impact on human health poses unprecedented and diverse\nchallenges. Unless proactive measures based on solid evidence are implemented,\nthese threats will likely escalate and continue to endanger human well-being.\nThe escalating advancements in information and communication technologies have\nfacilitated the widespread availability and utilization of social media\nplatforms. Individuals utilize platforms such as Twitter and Facebook to\nexpress their opinions, thoughts, and critiques on diverse subjects,\nencompassing the pressing issue of climate change. The proliferation of climate\nchange-related content on social media necessitates comprehensive analysis to\nglean meaningful insights. This paper employs natural language processing (NLP)\ntechniques to analyze climate change discourse and quantify the sentiment of\nclimate change-related tweets. We use ClimateBERT, a pretrained model\nfine-tuned specifically for the climate change domain. The objective is to\ndiscern the sentiment individuals express and uncover patterns in public\nopinion concerning climate change. Analyzing tweet sentiments allows a deeper\ncomprehension of public perceptions, concerns, and emotions about this critical\nglobal challenge. The findings from this experiment unearth valuable insights\ninto public sentiment and the entities associated with climate change\ndiscourse. Policymakers, researchers, and organizations can leverage such\nanalyses to understand public perceptions, identify influential actors, and\ndevise informed strategies to address climate change challenges.", "published": "2023-10-12 07:48:50", "link": "http://arxiv.org/abs/2310.08099v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QASiNa: Religious Domain Question Answering using Sirah Nabawiyah", "abstract": "Nowadays, Question Answering (QA) tasks receive significant research focus,\nparticularly with the development of Large Language Model (LLM) such as Chat\nGPT [1]. LLM can be applied to various domains, but it contradicts the\nprinciples of information transmission when applied to the Islamic domain. In\nIslam we strictly regulates the sources of information and who can give\ninterpretations or tafseer for that sources [2]. The approach used by LLM to\ngenerate answers based on its own interpretation is similar to the concept of\ntafseer, LLM is neither an Islamic expert nor a human which is not permitted in\nIslam. Indonesia is the country with the largest Islamic believer population in\nthe world [3]. With the high influence of LLM, we need to make evaluation of\nLLM in religious domain. Currently, there is only few religious QA dataset\navailable and none of them using Sirah Nabawiyah especially in Indonesian\nLanguage. In this paper, we propose the Question Answering Sirah Nabawiyah\n(QASiNa) dataset, a novel dataset compiled from Sirah Nabawiyah literatures in\nIndonesian language. We demonstrate our dataset by using mBERT [4], XLM-R [5],\nand IndoBERT [6] which fine-tuned with Indonesian translation of SQuAD v2.0\n[7]. XLM-R model returned the best performance on QASiNa with EM of 61.20,\nF1-Score of 75.94, and Substring Match of 70.00. We compare XLM-R performance\nwith Chat GPT-3.5 and GPT-4 [1]. Both Chat GPT version returned lower EM and\nF1-Score with higher Substring Match, the gap of EM and Substring Match get\nwider in GPT-4. The experiment indicate that Chat GPT tends to give excessive\ninterpretations as evidenced by its higher Substring Match scores compared to\nEM and F1-Score, even after providing instruction and context. This concludes\nChat GPT is unsuitable for question answering task in religious domain\nespecially for Islamic religion.", "published": "2023-10-12 07:52:19", "link": "http://arxiv.org/abs/2310.08102v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who Wrote it and Why? Prompting Large-Language Models for Authorship\n  Verification", "abstract": "Authorship verification (AV) is a fundamental task in natural language\nprocessing (NLP) and computational linguistics, with applications in forensic\nanalysis, plagiarism detection, and identification of deceptive content.\nExisting AV techniques, including traditional stylometric and deep learning\napproaches, face limitations in terms of data requirements and lack of\nexplainability. To address these limitations, this paper proposes PromptAV, a\nnovel technique that leverages Large-Language Models (LLMs) for AV by providing\nstep-by-step stylometric explanation prompts. PromptAV outperforms\nstate-of-the-art baselines, operates effectively with limited training data,\nand enhances interpretability through intuitive explanations, showcasing its\npotential as an effective and interpretable solution for the AV task.", "published": "2023-10-12 08:24:15", "link": "http://arxiv.org/abs/2310.08123v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-grained Conversational Decoding via Isotropic and Proximal Search", "abstract": "General-purpose text decoding approaches are usually adopted for dialogue\nresponse generation. Although the quality of the generated responses can be\nimproved with dialogue-specific encoding methods, conversational decoding\nmethods are still under-explored. Inspired by \\citet{wu2023learning} that a\ngood dialogue feature space should follow the rules of locality and isotropy,\nwe present a fine-grained conversational decoding method, termed\n\\textit{isotropic and proximal search (IPS)}. Our method is designed to\ngenerate the semantic-concentrated response, while still maintaining\ninformativeness and discrimination against the context. Experiments show that\nour approach outperforms existing decoding strategies in the dialogue field\nacross both automatic and human evaluation metrics. More in-depth analyses\nfurther confirm the effectiveness of our approach.", "published": "2023-10-12 08:38:12", "link": "http://arxiv.org/abs/2310.08130v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context Compression for Auto-regressive Transformers with Sentinel\n  Tokens", "abstract": "The quadratic complexity of the attention module makes it gradually become\nthe bulk of compute in Transformer-based LLMs during generation. Moreover, the\nexcessive key-value cache that arises when dealing with long inputs also brings\nsevere issues on memory footprint and inference latency. In this work, we\npropose a plug-and-play approach that is able to incrementally compress the\nintermediate activation of a specified span of tokens into compact ones,\nthereby reducing both memory and computational cost when processing subsequent\ncontext. Experiments on both in-domain language modeling and zero-shot\nopen-ended document generation demonstrate the advantage of our approach over\nsparse attention baselines in terms of fluency, n-gram matching, and semantic\nsimilarity. At last, we comprehensively profile the benefit of context\ncompression on improving the system throughout. Code is available at\nhttps://github.com/DRSY/KV_Compression.", "published": "2023-10-12 09:18:19", "link": "http://arxiv.org/abs/2310.08152v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ziya-Visual: Bilingual Large Vision-Language Model via Multi-Task\n  Instruction Tuning", "abstract": "Recent advancements enlarge the capabilities of large language models (LLMs)\nin zero-shot image-to-text generation and understanding by integrating\nmulti-modal inputs. However, such success is typically limited to English\nscenarios due to the lack of large-scale and high-quality non-English\nmulti-modal resources, making it extremely difficult to establish competitive\ncounterparts in other languages. In this paper, we introduce the Ziya-Visual\nseries, a set of bilingual large-scale vision-language models (LVLMs) designed\nto incorporate visual semantics into LLM for multi-modal dialogue. Composed of\nZiya-Visual-Base and Ziya-Visual-Chat, our models adopt the Querying\nTransformer from BLIP-2, further exploring the assistance of optimization\nschemes such as instruction tuning, multi-stage training and low-rank\nadaptation module for visual-language alignment. In addition, we stimulate the\nunderstanding ability of GPT-4 in multi-modal scenarios, translating our\ngathered English image-text datasets into Chinese and generating\ninstruction-response through the in-context learning method. The experiment\nresults demonstrate that compared to the existing LVLMs, Ziya-Visual achieves\ncompetitive performance across a wide range of English-only tasks including\nzero-shot image-text retrieval, image captioning, and visual question\nanswering. The evaluation leaderboard accessed by GPT-4 also indicates that our\nmodels possess satisfactory image-text understanding and generation\ncapabilities in Chinese multi-modal scenario dialogues. Code, demo and models\nare available at\n~\\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.", "published": "2023-10-12 09:39:17", "link": "http://arxiv.org/abs/2310.08166v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multiclass Classification of Policy Documents with Large Language Models", "abstract": "Classifying policy documents into policy issue topics has been a long-time\neffort in political science and communication disciplines. Efforts to automate\ntext classification processes for social science research purposes have so far\nachieved remarkable results, but there is still a large room for progress. In\nthis work, we test the prediction performance of an alternative strategy, which\nrequires human involvement much less than full manual coding. We use the GPT\n3.5 and GPT 4 models of the OpenAI, which are pre-trained instruction-tuned\nLarge Language Models (LLM), to classify congressional bills and congressional\nhearings into Comparative Agendas Project's 21 major policy issue topics. We\npropose three use-case scenarios and estimate overall accuracies ranging from\n%58-83 depending on scenario and GPT model employed. The three scenarios aims\nat minimal, moderate, and major human interference, respectively. Overall, our\nresults point towards the insufficiency of complete reliance on GPT with\nminimal human intervention, an increasing accuracy along with the human effort\nexerted, and a surprisingly high accuracy achieved in the most humanly\ndemanding use-case. However, the superior use-case achieved the %83 accuracy on\nthe %65 of the data in which the two models agreed, suggesting that a similar\napproach to ours can be relatively easily implemented and allow for mostly\nautomated coding of a majority of a given dataset. This could free up resources\nallowing manual human coding of the remaining %35 of the data to achieve an\noverall higher level of accuracy while reducing costs significantly.", "published": "2023-10-12 09:41:22", "link": "http://arxiv.org/abs/2310.08167v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for\n  Sentence Simplification", "abstract": "Automatic evaluation for sentence simplification remains a challenging\nproblem. Most popular evaluation metrics require multiple high-quality\nreferences -- something not readily available for simplification -- which makes\nit difficult to test performance on unseen domains. Furthermore, most existing\nmetrics conflate simplicity with correlated attributes such as fluency or\nmeaning preservation. We propose a new learned evaluation metric (SLE) which\nfocuses on simplicity, outperforming almost all existing metrics in terms of\ncorrelation with human judgements.", "published": "2023-10-12 09:49:10", "link": "http://arxiv.org/abs/2310.08170v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Cognitive Knowledge Structure of Large Language Models: An\n  Educational Diagnostic Assessment Approach", "abstract": "Large Language Models (LLMs) have not only exhibited exceptional performance\nacross various tasks, but also demonstrated sparks of intelligence. Recent\nstudies have focused on assessing their capabilities on human exams and\nrevealed their impressive competence in different domains. However, cognitive\nresearch on the overall knowledge structure of LLMs is still lacking. In this\npaper, based on educational diagnostic assessment method, we conduct an\nevaluation using MoocRadar, a meticulously annotated human test dataset based\non Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain\ninsights of their cognitive capabilities. This research emphasizes the\nsignificance of investigating LLMs' knowledge and understanding the disparate\ncognitive patterns of LLMs. By shedding light on models' knowledge, researchers\ncan advance development and utilization of LLMs in a more informed and\neffective manner.", "published": "2023-10-12 09:55:45", "link": "http://arxiv.org/abs/2310.08172v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Visual Question Generation in Bengali", "abstract": "The task of Visual Question Generation (VQG) is to generate human-like\nquestions relevant to the given image. As VQG is an emerging research field,\nexisting works tend to focus only on resource-rich language such as English due\nto the availability of datasets. In this paper, we propose the first Bengali\nVisual Question Generation task and develop a novel transformer-based\nencoder-decoder architecture that generates questions in Bengali when given an\nimage. We propose multiple variants of models - (i) image-only: baseline model\nof generating questions from images without additional information, (ii)\nimage-category and image-answer-category: guided VQG where we condition the\nmodel to generate questions based on the answer and the category of expected\nquestion. These models are trained and evaluated on the translated VQAv2.0\ndataset. Our quantitative and qualitative results establish the first state of\nthe art models for VQG task in Bengali and demonstrate that our models are\ncapable of generating grammatically correct and relevant questions. Our\nquantitative results show that our image-cat model achieves a BLUE-1 score of\n33.12 and BLEU-3 score of 7.56 which is the highest of the other two variants.\nWe also perform a human evaluation to assess the quality of the generation\ntasks. Human evaluation suggests that image-cat model is capable of generating\ngoal-driven and attribute-specific questions and also stays relevant to the\ncorresponding image.", "published": "2023-10-12 10:26:26", "link": "http://arxiv.org/abs/2310.08187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models are Universal Embedders", "abstract": "In the large language model (LLM) revolution, embedding is a key component of\nvarious systems. For example, it is used to retrieve knowledge or memories for\nLLMs, to build content moderation filters, etc. As such cases span from English\nto other natural or programming languages, from retrieval to classification and\nbeyond, it is desirable to build a unified embedding model rather than\ndedicated ones for each scenario. In this work, we make an initial step towards\nthis goal, demonstrating that multiple languages (both natural and programming)\npre-trained transformer decoders can embed universally when finetuned on\nlimited English data. We provide a comprehensive practice with thorough\nevaluations. On English MTEB, our models achieve competitive performance on\ndifferent embedding tasks by minimal training data. On other benchmarks, such\nas multilingual classification and code search, our models (without any\nsupervision) perform comparably to, or even surpass heavily supervised\nbaselines and/or APIs. These results provide evidence of a promising path\ntowards building powerful unified embedders that can be applied across tasks\nand languages.", "published": "2023-10-12 11:25:46", "link": "http://arxiv.org/abs/2310.08232v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who Said That? Benchmarking Social Media AI Detection", "abstract": "AI-generated text has proliferated across various online platforms, offering\nboth transformative prospects and posing significant risks related to\nmisinformation and manipulation. Addressing these challenges, this paper\nintroduces SAID (Social media AI Detection), a novel benchmark developed to\nassess AI-text detection models' capabilities in real social media platforms.\nIt incorporates real AI-generate text from popular social media platforms like\nZhihu and Quora. Unlike existing benchmarks, SAID deals with content that\nreflects the sophisticated strategies employed by real AI users on the Internet\nwhich may evade detection or gain visibility, providing a more realistic and\nchallenging evaluation landscape. A notable finding of our study, based on the\nZhihu dataset, reveals that annotators can distinguish between AI-generated and\nhuman-generated texts with an average accuracy rate of 96.5%. This finding\nnecessitates a re-evaluation of human capability in recognizing AI-generated\ntext in today's widely AI-influenced environment. Furthermore, we present a new\nuser-oriented AI-text detection challenge focusing on the practicality and\neffectiveness of identifying AI-generated text based on user information and\nmultiple responses. The experimental results demonstrate that conducting\ndetection tasks on actual social media platforms proves to be more challenging\ncompared to traditional simulated AI-text detection, resulting in a decreased\naccuracy. On the other hand, user-oriented AI-generated text detection\nsignificantly improve the accuracy of detection.", "published": "2023-10-12 11:35:24", "link": "http://arxiv.org/abs/2310.08240v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Odia Braille Literacy: The Influence of Speed on Error\n  Reduction and Enhanced Comprehension", "abstract": "This study aims to conduct an extensive detailed analysis of the Odia Braille\nreading comprehension among students with visual disability. Specifically, the\nstudy explores their reading speed and hand or finger movements. The study also\naims to investigate any comprehension difficulties and reading errors they may\nencounter. Six students from the 9th and 10th grades, aged between 14 and 16,\nparticipated in the study. We observed participants hand movements to\nunderstand how reading errors were connected to hand movement and identify the\nstudents reading difficulties. We also evaluated the participants Odia Braille\nreading skills, including their reading speed (in words per minute), errors,\nand comprehension. The average speed of Odia Braille reader is 17.64wpm.\nAccording to the study, there was a noticeable correlation between reading\nspeed and reading errors. As reading speed decreased, the number of reading\nerrors tended to increase. Moreover, the study established a link between\nreduced Braille reading errors and improved reading comprehension. In contrast,\nthe study found that better comprehension was associated with increased reading\nspeed. The researchers concluded with some interesting findings about preferred\nBraille reading patterns. These findings have important theoretical,\ndevelopmental, and methodological implications for instruction.", "published": "2023-10-12 12:36:46", "link": "http://arxiv.org/abs/2310.08280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MProto: Multi-Prototype Network with Denoised Optimal Transport for\n  Distantly Supervised Named Entity Recognition", "abstract": "Distantly supervised named entity recognition (DS-NER) aims to locate entity\nmentions and classify their types with only knowledge bases or gazetteers and\nunlabeled corpus. However, distant annotations are noisy and degrade the\nperformance of NER models. In this paper, we propose a noise-robust prototype\nnetwork named MProto for the DS-NER task. Different from previous\nprototype-based NER methods, MProto represents each entity type with multiple\nprototypes to characterize the intra-class variance among entity\nrepresentations. To optimize the classifier, each token should be assigned an\nappropriate ground-truth prototype and we consider such token-prototype\nassignment as an optimal transport (OT) problem. Furthermore, to mitigate the\nnoise from incomplete labeling, we propose a novel denoised optimal transport\n(DOT) algorithm. Specifically, we utilize the assignment result between Other\nclass tokens and all prototypes to distinguish unlabeled entity tokens from\ntrue negatives. Experiments on several DS-NER benchmarks demonstrate that our\nMProto achieves state-of-the-art performance. The source code is now available\non Github.", "published": "2023-10-12 13:02:34", "link": "http://arxiv.org/abs/2310.08298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Demonstration Examples are Equally Beneficial: Reweighting\n  Demonstration Examples for In-Context Learning", "abstract": "Large Language Models (LLMs) have recently gained the In-Context Learning\n(ICL) ability with the models scaling up, allowing them to quickly adapt to\ndownstream tasks with only a few demonstration examples prepended in the input\nsequence. Nonetheless, the current practice of ICL treats all demonstration\nexamples equally, which still warrants improvement, as the quality of examples\nis usually uneven. In this paper, we investigate how to determine approximately\noptimal weights for demonstration examples and how to apply them during ICL. To\nassess the quality of weights in the absence of additional validation data, we\ndesign a masked self-prediction (MSP) score that exhibits a strong correlation\nwith the final ICL performance. To expedite the weight-searching process, we\ndiscretize the continuous weight space and adopt beam search. With\napproximately optimal weights obtained, we further propose two strategies to\napply them to demonstrations at different model positions. Experimental results\non 8 text classification tasks show that our approach outperforms conventional\nICL by a large margin. Our code are publicly available at\nhttps:github.com/Zhe-Young/WICL.", "published": "2023-10-12 13:15:11", "link": "http://arxiv.org/abs/2310.08309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Large Language Models to Knowledge Graphs for Biomarker Discovery\n  in Cancer", "abstract": "Domain experts often rely on most recent knowledge for apprehending and\ndisseminating specific biological processes that help them design strategies\nfor developing prevention and therapeutic decision-making in various disease\nscenarios. A challenging scenarios for artificial intelligence (AI) is using\nbiomedical data (e.g., texts, imaging, omics, and clinical) to provide\ndiagnosis and treatment recommendations for cancerous conditions.~Data and\nknowledge about biomedical entities like cancer, drugs, genes, proteins, and\ntheir mechanism is spread across structured (knowledge bases (KBs)) and\nunstructured (e.g., scientific articles) sources. A large-scale knowledge graph\n(KG) can be constructed by integrating and extracting facts about semantically\ninterrelated entities and relations. Such a KG not only allows exploration and\nquestion answering (QA) but also enables domain experts to deduce new\nknowledge. However, exploring and querying large-scale KGs is tedious for\nnon-domain users due to their lack of understanding of the data assets and\nsemantic technologies. In this paper, we develop a domain KG to leverage\ncancer-specific biomarker discovery and interactive QA. For this, we\nconstructed a domain ontology called OncoNet Ontology (ONO), which enables\nsemantic reasoning for validating gene-disease (different types of cancer)\nrelations. The KG is further enriched by harmonizing the ONO, metadata,\ncontrolled vocabularies, and biomedical concepts from scientific articles by\nemploying BioBERT- and SciBERT-based information extractors. Further, since the\nbiomedical domain is evolving, where new findings often replace old ones,\nwithout having access to up-to-date scientific findings, there is a high chance\nan AI system exhibits concept drift while providing diagnosis and treatment.\nTherefore, we fine-tune the KG using large language models (LLMs) based on more\nrecent articles and KBs.", "published": "2023-10-12 14:36:13", "link": "http://arxiv.org/abs/2310.08365v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems\n  via Knowledge Enhancement and Alignment", "abstract": "Pretrained language models (PLMs) based knowledge-grounded dialogue systems\nare prone to generate responses that are factually inconsistent with the\nprovided knowledge source. In such inconsistent responses, the dialogue models\nfail to accurately express the external knowledge they rely upon. Inspired by\nprevious work which identified that feed-forward networks (FFNs) within\nTransformers are responsible for factual knowledge expressions, we investigate\ntwo methods to efficiently improve the factual expression capability {of FFNs}\nby knowledge enhancement and alignment respectively. We first propose\n\\textsc{K-Dial}, which {explicitly} introduces {extended FFNs in Transformers\nto enhance factual knowledge expressions} given the specific patterns of\nknowledge-grounded dialogue inputs. Additionally, we apply the reinforcement\nlearning for factual consistency (RLFC) method to implicitly adjust FFNs'\nexpressions in responses by aligning with gold knowledge for the factual\nconsistency preference. To comprehensively assess the factual consistency and\ndialogue quality of responses, we employ extensive automatic measures and human\nevaluations including sophisticated fine-grained NLI-based metrics.\nExperimental results on WoW and CMU\\_DoG datasets demonstrate that our methods\nefficiently enhance the ability of the FFN module to convey factual knowledge,\nvalidating the efficacy of improving factual consistency for knowledge-grounded\ndialogue systems.", "published": "2023-10-12 14:44:05", "link": "http://arxiv.org/abs/2310.08372v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GraphextQA: A Benchmark for Evaluating Graph-Enhanced Large Language\n  Models", "abstract": "While multi-modal models have successfully integrated information from image,\nvideo, and audio modalities, integrating graph modality into large language\nmodels (LLMs) remains unexplored. This discrepancy largely stems from the\ninherent divergence between structured graph data and unstructured text data.\nIncorporating graph knowledge provides a reliable source of information,\nenabling potential solutions to address issues in text generation, e.g.,\nhallucination, and lack of domain knowledge. To evaluate the integration of\ngraph knowledge into language models, a dedicated dataset is needed. However,\nthere is currently no benchmark dataset specifically designed for multimodal\ngraph-language models. To address this gap, we propose GraphextQA, a question\nanswering dataset with paired subgraphs, retrieved from Wikidata, to facilitate\nthe evaluation and future development of graph-language models. Additionally,\nwe introduce a baseline model called CrossGNN, which conditions answer\ngeneration on the paired graphs by cross-attending question-aware graph\nfeatures at decoding. The proposed dataset is designed to evaluate\ngraph-language models' ability to understand graphs and make use of it for\nanswer generation. We perform experiments with language-only models and the\nproposed graph-language model to validate the usefulness of the paired graphs\nand to demonstrate the difficulty of the task.", "published": "2023-10-12 16:46:58", "link": "http://arxiv.org/abs/2310.08487v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Uncertainty-based Retrieval Framework for Ancient Chinese CWS and\n  POS", "abstract": "Automatic analysis for modern Chinese has greatly improved the accuracy of\ntext mining in related fields, but the study of ancient Chinese is still\nrelatively rare. Ancient text division and lexical annotation are important\nparts of classical literature comprehension, and previous studies have tried to\nconstruct auxiliary dictionary and other fused knowledge to improve the\nperformance. In this paper, we propose a framework for ancient Chinese Word\nSegmentation and Part-of-Speech Tagging that makes a twofold effort: on the one\nhand, we try to capture the wordhood semantics; on the other hand, we\nre-predict the uncertain samples of baseline model by introducing external\nknowledge. The performance of our architecture outperforms pre-trained BERT\nwith CRF and existing tools such as Jiayan.", "published": "2023-10-12 16:55:44", "link": "http://arxiv.org/abs/2310.08496v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-augmented Preference Learning from Natural Language", "abstract": "Finding preferences expressed in natural language is an important but\nchallenging task. State-of-the-art(SotA) methods leverage transformer-based\nmodels such as BERT, RoBERTa, etc. and graph neural architectures such as graph\nattention networks. Since Large Language Models (LLMs) are equipped to deal\nwith larger context lengths and have much larger model sizes than the\ntransformer-based model, we investigate their ability to classify comparative\ntext directly. This work aims to serve as a first step towards using LLMs for\nthe CPC task. We design and conduct a set of experiments that format the\nclassification task into an input prompt for the LLM and a methodology to get a\nfixed-format response that can be automatically evaluated. Comparing\nperformances with existing methods, we see that pre-trained LLMs are able to\noutperform the previous SotA models with no fine-tuning involved. Our results\nshow that the LLMs can consistently outperform the SotA when the target text is\nlarge -- i.e. composed of multiple sentences --, and are still comparable to\nthe SotA performance in shorter text. We also find that few-shot learning\nyields better performance than zero-shot learning.", "published": "2023-10-12 17:17:27", "link": "http://arxiv.org/abs/2310.08523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Approach Towards Autoformalization", "abstract": "Verifying mathematical proofs is difficult, but can be automated with the\nassistance of a computer. Autoformalization is the task of automatically\ntranslating natural language mathematics into a formal language that can be\nverified by a program. This is a challenging task, and especially for\nhigher-level mathematics found in research papers. Research paper mathematics\nrequires large amounts of background and context. In this paper, we propose an\navenue towards tackling autoformalization for research-level mathematics, by\nbreaking the task into easier and more approachable subtasks: unlinked\nformalization (formalization with unlinked definitions and theorems), entity\nlinking (linking to the proper theorems and definitions), and finally adjusting\ntypes so it passes the type checker. In addition, we present arXiv2Formal, a\nbenchmark dataset for unlinked formalization consisting of 50 theorems\nformalized for the Lean theorem prover sampled from papers on arXiv.org. We\nwelcome any contributions from the community to future versions of this\ndataset.", "published": "2023-10-12 00:50:24", "link": "http://arxiv.org/abs/2310.07957v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Large Language Models for Multi-Modal Out-of-Distribution\n  Detection", "abstract": "Out-of-distribution (OOD) detection is essential for reliable and trustworthy\nmachine learning. Recent multi-modal OOD detection leverages textual\ninformation from in-distribution (ID) class names for visual OOD detection, yet\nit currently neglects the rich contextual information of ID classes. Large\nlanguage models (LLMs) encode a wealth of world knowledge and can be prompted\nto generate descriptive features for each class. Indiscriminately using such\nknowledge causes catastrophic damage to OOD detection due to LLMs'\nhallucinations, as is observed by our analysis. In this paper, we propose to\napply world knowledge to enhance OOD detection performance through selective\ngeneration from LLMs. Specifically, we introduce a consistency-based\nuncertainty calibration method to estimate the confidence score of each\ngeneration. We further extract visual objects from each image to fully\ncapitalize on the aforementioned world knowledge. Extensive experiments\ndemonstrate that our method consistently outperforms the state-of-the-art.", "published": "2023-10-12 04:14:28", "link": "http://arxiv.org/abs/2310.08027v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "To token or not to token: A Comparative Study of Text Representations\n  for Cross-Lingual Transfer", "abstract": "Choosing an appropriate tokenization scheme is often a bottleneck in\nlow-resource cross-lingual transfer. To understand the downstream implications\nof text representation choices, we perform a comparative analysis on language\nmodels having diverse text representation modalities including 2\nsegmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model\n(\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we\npropose a scoring Language Quotient (LQ) metric capable of providing a weighted\nrepresentation of both zero-shot and few-shot evaluation combined. Utilizing\nthis metric, we perform experiments comprising 19 source languages and 133\ntarget languages on three tasks (POS tagging, Dependency parsing, and NER). Our\nanalysis reveals that image-based models excel in cross-lingual transfer when\nlanguages are closely related and share visually similar scripts. However, for\ntasks biased toward word meaning (POS, NER), segmentation-based models prove to\nbe superior. Furthermore, in dependency parsing tasks where word relationships\nplay a crucial role, models with their character-level focus, outperform\nothers. Finally, we propose a recommendation scheme based on our findings to\nguide model selection according to task and language requirements.", "published": "2023-10-12 06:59:10", "link": "http://arxiv.org/abs/2310.08078v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Low-Resource Clickbait Spoiling for Indonesian via Question Answering", "abstract": "Clickbait spoiling aims to generate a short text to satisfy the curiosity\ninduced by a clickbait post. As it is a newly introduced task, the dataset is\nonly available in English so far. Our contributions include the construction of\nmanually labeled clickbait spoiling corpus in Indonesian and an evaluation on\nusing cross-lingual zero-shot question answering-based models to tackle\nclikcbait spoiling for low-resource language like Indonesian. We utilize\nselection of multilingual language models. The experimental results suggest\nthat XLM-RoBERTa (large) model outperforms other models for phrase and passage\nspoilers, meanwhile, mDeBERTa (base) model outperforms other models for\nmultipart spoilers.", "published": "2023-10-12 07:17:17", "link": "http://arxiv.org/abs/2310.08085v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Promptor: A Conversational and Autonomous Prompt Generation Agent for\n  Intelligent Text Entry Techniques", "abstract": "Text entry is an essential task in our day-to-day digital interactions.\nNumerous intelligent features have been developed to streamline this process,\nmaking text entry more effective, efficient, and fluid. These improvements\ninclude sentence prediction and user personalization. However, as deep\nlearning-based language models become the norm for these advanced features, the\nnecessity for data collection and model fine-tuning increases. These challenges\ncan be mitigated by harnessing the in-context learning capability of large\nlanguage models such as GPT-3.5. This unique feature allows the language model\nto acquire new skills through prompts, eliminating the need for data collection\nand fine-tuning. Consequently, large language models can learn various text\nprediction techniques. We initially showed that, for a sentence prediction\ntask, merely prompting GPT-3.5 surpassed a GPT-2 backed system and is\ncomparable with a fine-tuned GPT-3.5 model, with the latter two methods\nrequiring costly data collection, fine-tuning and post-processing. However, the\ntask of prompting large language models to specialize in specific text\nprediction tasks can be challenging, particularly for designers without\nexpertise in prompt engineering. To address this, we introduce Promptor, a\nconversational prompt generation agent designed to engage proactively with\ndesigners. Promptor can automatically generate complex prompts tailored to meet\nspecific needs, thus offering a solution to this challenge. We conducted a user\nstudy involving 24 participants creating prompts for three intelligent text\nentry tasks, half of the participants used Promptor while the other half\ndesigned prompts themselves. The results show that Promptor-designed prompts\nresult in a 35% increase in similarity and 22% in coherence over those by\ndesigners.", "published": "2023-10-12 07:51:43", "link": "http://arxiv.org/abs/2310.08101v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form\n  Narrative Text Generation", "abstract": "Plan-and-Write is a common hierarchical approach in long-form narrative text\ngeneration, which first creates a plan to guide the narrative writing.\nFollowing this approach, several studies rely on simply prompting large\nlanguage models for planning, which often yields suboptimal results. In this\npaper, we propose a new framework called Evaluation-guided Iterative Plan\nExtraction for long-form narrative text generation (EIPE-text), which extracts\nplans from the corpus of narratives and utilizes the extracted plans to\nconstruct a better planner. EIPE-text has three stages: plan extraction,\nlearning, and inference. In the plan extraction stage, it iteratively extracts\nand improves plans from the narrative corpus and constructs a plan corpus. We\npropose a question answer (QA) based evaluation mechanism to automatically\nevaluate the plans and generate detailed plan refinement instructions to guide\nthe iterative improvement. In the learning stage, we build a better planner by\nfine-tuning with the plan corpus or in-context learning with examples in the\nplan corpus. Finally, we leverage a hierarchical approach to generate long-form\nnarratives. We evaluate the effectiveness of EIPE-text in the domains of novels\nand storytelling. Both GPT-4-based evaluations and human evaluations\ndemonstrate that our method can generate more coherent and relevant long-form\nnarratives. Our code will be released in the future.", "published": "2023-10-12 10:21:37", "link": "http://arxiv.org/abs/2310.08185v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Text-based Knowledge Graph Completion with Zero-Shot Large\n  Language Models: A Focus on Semantic Enhancement", "abstract": "The design and development of text-based knowledge graph completion (KGC)\nmethods leveraging textual entity descriptions are at the forefront of\nresearch. These methods involve advanced optimization techniques such as soft\nprompts and contrastive learning to enhance KGC models. The effectiveness of\ntext-based methods largely hinges on the quality and richness of the training\ndata. Large language models (LLMs) can utilize straightforward prompts to alter\ntext data, thereby enabling data augmentation for KGC. Nevertheless, LLMs\ntypically demand substantial computational resources. To address these issues,\nwe introduce a framework termed constrained prompts for KGC (CP-KGC). This\nCP-KGC framework designs prompts that adapt to different datasets to enhance\nsemantic richness. Additionally, CP-KGC employs a context constraint strategy\nto effectively identify polysemous entities within KGC datasets. Through\nextensive experimentation, we have verified the effectiveness of this\nframework. Even after quantization, the LLM (Qwen-7B-Chat-int4) still enhances\nthe performance of text-based KGC methods \\footnote{Code and datasets are\navailable at\n\\href{https://github.com/sjlmg/CP-KGC}{https://github.com/sjlmg/CP-KGC}}. This\nstudy extends the performance limits of existing models and promotes further\nintegration of KGC with LLMs.", "published": "2023-10-12 12:31:23", "link": "http://arxiv.org/abs/2310.08279v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Expanding the Vocabulary of BERT for Knowledge Base Construction", "abstract": "Knowledge base construction entails acquiring structured information to\ncreate a knowledge base of factual and relational data, facilitating question\nanswering, information retrieval, and semantic understanding. The challenge\ncalled \"Knowledge Base Construction from Pretrained Language Models\" at\nInternational Semantic Web Conference 2023 defines tasks focused on\nconstructing knowledge base using language model. Our focus was on Track 1 of\nthe challenge, where the parameters are constrained to a maximum of 1 billion,\nand the inclusion of entity descriptions within the prompt is prohibited.\n  Although the masked language model offers sufficient flexibility to extend\nits vocabulary, it is not inherently designed for multi-token prediction. To\naddress this, we present Vocabulary Expandable BERT for knowledge base\nconstruction, which expand the language model's vocabulary while preserving\nsemantic embeddings for newly added words. We adopt task-specific\nre-pre-training on masked language model to further enhance the language model.\n  Through experimentation, the results show the effectiveness of our\napproaches. Our framework achieves F1 score of 0.323 on the hidden test set and\n0.362 on the validation set, both data set is provided by the challenge.\nNotably, our framework adopts a lightweight language model (BERT-base, 0.13\nbillion parameters) and surpasses the model using prompts directly on large\nlanguage model (Chatgpt-3, 175 billion parameters). Besides, Token-Recode\nachieves comparable performances as Re-pretrain. This research advances\nlanguage understanding models by enabling the direct embedding of multi-token\nentities, signifying a substantial step forward in link prediction task in\nknowledge graph and metadata completion in data management.", "published": "2023-10-12 12:52:46", "link": "http://arxiv.org/abs/2310.08291v1", "categories": ["cs.CL", "cs.AI", "68T20"], "primary_category": "cs.CL"}
{"title": "Reconstructing Materials Tetrahedron: Challenges in Materials\n  Information Extraction", "abstract": "The discovery of new materials has a documented history of propelling human\nprogress for centuries and more. The behaviour of a material is a function of\nits composition, structure, and properties, which further depend on its\nprocessing and testing conditions. Recent developments in deep learning and\nnatural language processing have enabled information extraction at scale from\npublished literature such as peer-reviewed publications, books, and patents.\nHowever, this information is spread in multiple formats, such as tables, text,\nand images, and with little or no uniformity in reporting style giving rise to\nseveral machine learning challenges. Here, we discuss, quantify, and document\nthese challenges in automated information extraction (IE) from materials\nscience literature towards the creation of a large materials science knowledge\nbase. Specifically, we focus on IE from text and tables and outline several\nchallenges with examples. We hope the present work inspires researchers to\naddress the challenges in a coherent fashion, providing a fillip to IE towards\ndeveloping a materials knowledge base.", "published": "2023-10-12 14:57:24", "link": "http://arxiv.org/abs/2310.08383v3", "categories": ["cs.CL", "cond-mat.mtrl-sci"], "primary_category": "cs.CL"}
{"title": "Prompting Large Language Models with Chain-of-Thought for Few-Shot\n  Knowledge Base Question Generation", "abstract": "The task of Question Generation over Knowledge Bases (KBQG) aims to convert a\nlogical form into a natural language question. For the sake of expensive cost\nof large-scale question annotation, the methods of KBQG under low-resource\nscenarios urgently need to be developed. However, current methods heavily rely\non annotated data for fine-tuning, which is not well-suited for few-shot\nquestion generation. The emergence of Large Language Models (LLMs) has shown\ntheir impressive generalization ability in few-shot tasks. Inspired by\nChain-of-Thought (CoT) prompting, which is an in-context learning strategy for\nreasoning, we formulate KBQG task as a reasoning problem, where the generation\nof a complete question is splitted into a series of sub-question generation.\nOur proposed prompting method KQG-CoT first retrieves supportive logical forms\nfrom the unlabeled data pool taking account of the characteristics of the\nlogical form. Then, we write a prompt to explicit the reasoning chain of\ngenerating complicated questions based on the selected demonstrations. To\nfurther ensure prompt quality, we extend KQG-CoT into KQG-CoT+ via sorting the\nlogical forms by their complexity. We conduct extensive experiments over three\npublic KBQG datasets. The results demonstrate that our prompting method\nconsistently outperforms other prompting baselines on the evaluated datasets.\nRemarkably, our KQG-CoT+ method could surpass existing few-shot SoTA results of\nthe PathQuestions dataset by 18.25, 10.72, and 10.18 absolute points on BLEU-4,\nMETEOR, and ROUGE-L, respectively.", "published": "2023-10-12 15:08:14", "link": "http://arxiv.org/abs/2310.08395v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative\n  Writing", "abstract": "We evaluate a range of recent LLMs on English creative writing, a challenging\nand complex task that requires imagination, coherence, and style. We use a\ndifficult, open-ended scenario chosen to avoid training data reuse: an epic\nnarration of a single combat between Ignatius J. Reilly, the protagonist of the\nPulitzer Prize-winning novel A Confederacy of Dunces (1980), and a pterodactyl,\na prehistoric flying reptile. We ask several LLMs and humans to write such a\nstory and conduct a human evalution involving various criteria such as fluency,\ncoherence, originality, humor, and style. Our results show that some\nstate-of-the-art commercial LLMs match or slightly outperform our writers in\nmost dimensions; whereas open-source LLMs lag behind. Humans retain an edge in\ncreativity, while humor shows a binary divide between LLMs that can handle it\ncomparably to humans and those that fail at it. We discuss the implications and\nlimitations of our study and suggest directions for future research.", "published": "2023-10-12 15:56:24", "link": "http://arxiv.org/abs/2310.08433v1", "categories": ["cs.CL", "cs.CY", "68T50, 00A64", "I.2.7; J.5"], "primary_category": "cs.CL"}
{"title": "Understanding the Humans Behind Online Misinformation: An Observational\n  Study Through the Lens of the COVID-19 Pandemic", "abstract": "The proliferation of online misinformation has emerged as one of the biggest\nthreats to society. Considerable efforts have focused on building\nmisinformation detection models, still the perils of misinformation remain\nabound. Mitigating online misinformation and its ramifications requires a\nholistic approach that encompasses not only an understanding of its intricate\nlandscape in relation to the complex issue and topic-rich information ecosystem\nonline, but also the psychological drivers of individuals behind it. Adopting a\ntime series analytic technique and robust causal inference-based design, we\nconduct a large-scale observational study analyzing over 32 million COVID-19\ntweets and 16 million historical timeline tweets. We focus on understanding the\nbehavior and psychology of users disseminating misinformation during COVID-19\nand its relationship with the historical inclinations towards sharing\nmisinformation on Non-COVID domains before the pandemic. Our analysis\nunderscores the intricacies inherent to cross-domain misinformation, and\nhighlights that users' historical inclination toward sharing misinformation is\npositively associated with their present behavior pertaining to misinformation\nsharing on emergent topics and beyond. This work may serve as a valuable\nfoundation for designing user-centric inoculation strategies and\necologically-grounded agile interventions for effectively tackling online\nmisinformation.", "published": "2023-10-12 16:42:53", "link": "http://arxiv.org/abs/2310.08483v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language\n  Models", "abstract": "Recently, using a powerful proprietary Large Language Model (LLM) (e.g.,\nGPT-4) as an evaluator for long-form responses has become the de facto\nstandard. However, for practitioners with large-scale evaluation tasks and\ncustom criteria in consideration (e.g., child-readability), using proprietary\nLLMs as an evaluator is unreliable due to the closed-source nature,\nuncontrolled versioning, and prohibitive costs. In this work, we propose\nPrometheus, a fully open-source LLM that is on par with GPT-4's evaluation\ncapabilities when the appropriate reference materials (reference answer, score\nrubric) are accompanied. We first construct the Feedback Collection, a new\ndataset that consists of 1K fine-grained score rubrics, 20K instructions, and\n100K responses and language feedback generated by GPT-4. Using the Feedback\nCollection, we train Prometheus, a 13B evaluator LLM that can assess any given\nlong-form text based on customized score rubric provided by the user.\nExperimental results show that Prometheus scores a Pearson correlation of 0.897\nwith human evaluators when evaluating with 45 customized score rubrics, which\nis on par with GPT-4 (0.882), and greatly outperforms ChatGPT (0.392).\nFurthermore, measuring correlation with GPT-4 with 1222 customized score\nrubrics across four benchmarks (MT Bench, Vicuna Bench, Feedback Bench, Flask\nEval) shows similar trends, bolstering Prometheus's capability as an evaluator\nLLM. Lastly, Prometheus achieves the highest accuracy on two human preference\nbenchmarks (HHH Alignment & MT Bench Human Judgment) compared to open-sourced\nreward models explicitly trained on human preference datasets, highlighting its\npotential as an universal reward model. We open-source our code, dataset, and\nmodel at https://kaistai.github.io/prometheus/.", "published": "2023-10-12 16:50:08", "link": "http://arxiv.org/abs/2310.08491v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Formally Specifying the High-Level Behavior of LLM-Based Agents", "abstract": "Autonomous, goal-driven agents powered by LLMs have recently emerged as\npromising tools for solving challenging problems without the need for\ntask-specific finetuned models that can be expensive to procure. Currently, the\ndesign and implementation of such agents is ad hoc, as the wide variety of\ntasks that LLM-based agents may be applied to naturally means there can be no\none-size-fits-all approach to agent design. In this work we aim to alleviate\nthe difficulty of designing and implementing new agents by proposing a\nminimalistic generation framework that simplifies the process of building\nagents. The framework we introduce allows the user to define desired agent\nbehaviors in a high-level, declarative specification that is then used to\nconstruct a decoding monitor which guarantees the LLM will produce an output\nexhibiting the desired behavior. Our declarative approach, in which the\nbehavior is described without concern for how it should be implemented or\nenforced, enables rapid design, implementation, and experimentation with\ndifferent LLM-based agents. We demonstrate how the proposed framework can be\nused to implement recent LLM-based agents (e.g., ReACT), and show how the\nflexibility of our approach can be leveraged to define a new agent with more\ncomplex behavior, the Plan-Act-Summarize-Solve (PASS) agent. Lastly, we\ndemonstrate that our method outperforms other agents on multiple popular\nreasoning-centric question-answering benchmarks.", "published": "2023-10-12 17:24:15", "link": "http://arxiv.org/abs/2310.08535v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of\n  Language Models with Hypothesis Refinement", "abstract": "The ability to derive underlying principles from a handful of observations\nand then generalize to novel situations -- known as inductive reasoning -- is\ncentral to human intelligence. Prior work suggests that language models (LMs)\noften fall short on inductive reasoning, despite achieving impressive success\non research benchmarks. In this work, we conduct a systematic study of the\ninductive reasoning capabilities of LMs through iterative hypothesis\nrefinement, a technique that more closely mirrors the human inductive process\nthan standard input-output prompting. Iterative hypothesis refinement employs a\nthree-step process: proposing, selecting, and refining hypotheses in the form\nof textual rules. By examining the intermediate rules, we observe that LMs are\nphenomenal hypothesis proposers (i.e., generating candidate rules), and when\ncoupled with a (task-specific) symbolic interpreter that is able to\nsystematically filter the proposed set of rules, this hybrid approach achieves\nstrong results across inductive reasoning benchmarks that require inducing\ncausal relations, language-like instructions, and symbolic concepts. However,\nthey also behave as puzzling inductive reasoners, showing notable performance\ngaps between rule induction (i.e., identifying plausible rules) and rule\napplication (i.e., applying proposed rules to instances), suggesting that LMs\nare proposing hypotheses without being able to actually apply the rules.\nThrough empirical and human analyses, we further reveal several discrepancies\nbetween the inductive reasoning processes of LMs and humans, shedding light on\nboth the potentials and limitations of using LMs in inductive reasoning tasks.", "published": "2023-10-12 17:51:10", "link": "http://arxiv.org/abs/2310.08559v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Circuit Component Reuse Across Tasks in Transformer Language Models", "abstract": "Recent work in mechanistic interpretability has shown that behaviors in\nlanguage models can be successfully reverse-engineered through circuit\nanalysis. A common criticism, however, is that each circuit is task-specific,\nand thus such analysis cannot contribute to understanding the models at a\nhigher level. In this work, we present evidence that insights (both low-level\nfindings about specific heads and higher-level findings about general\nalgorithms) can indeed generalize across tasks. Specifically, we study the\ncircuit discovered in Wang et al. (2022) for the Indirect Object Identification\n(IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that\nit is mostly reused to solve a seemingly different task: Colored Objects\n(Ippolito & Callison-Burch, 2023). We provide evidence that the process\nunderlying both tasks is functionally very similar, and contains about a 78%\noverlap in in-circuit attention heads. We further present a proof-of-concept\nintervention experiment, in which we adjust four attention heads in middle\nlayers in order to 'repair' the Colored Objects circuit and make it behave like\nthe IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the\nColored Objects task and explain most sources of error. The intervention\naffects downstream attention heads in specific ways predicted by their\ninteractions in the IOI circuit, indicating that this subcircuit behavior is\ninvariant to the different task inputs. Overall, our results provide evidence\nthat it may yet be possible to explain large language models' behavior in terms\nof a relatively small number of interpretable task-general algorithmic building\nblocks and computational components.", "published": "2023-10-12 22:12:28", "link": "http://arxiv.org/abs/2310.08744v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Calibrating Likelihoods towards Consistency in Summarization Models", "abstract": "Despite the recent advances in abstractive text summarization, current\nsummarization models still suffer from generating factually inconsistent\nsummaries, reducing their utility for real-world application. We argue that the\nmain reason for such behavior is that the summarization models trained with\nmaximum likelihood objective assign high probability to plausible sequences\ngiven the context, but they often do not accurately rank sequences by their\nconsistency. In this work, we solve this problem by calibrating the likelihood\nof model generated sequences to better align with a consistency metric measured\nby natural language inference (NLI) models. The human evaluation study and\nautomatic metrics show that the calibrated models generate more consistent and\nhigher-quality summaries. We also show that the models trained using our method\nreturn probabilities that are better aligned with the NLI scores, which\nsignificantly increase reliability of summarization models.", "published": "2023-10-12 23:17:56", "link": "http://arxiv.org/abs/2310.08764v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Think, Act, and Ask: Open-World Interactive Personalized Robot\n  Navigation", "abstract": "Zero-Shot Object Navigation (ZSON) enables agents to navigate towards\nopen-vocabulary objects in unknown environments. The existing works of ZSON\nmainly focus on following individual instructions to find generic object\nclasses, neglecting the utilization of natural language interaction and the\ncomplexities of identifying user-specific objects. To address these\nlimitations, we introduce Zero-shot Interactive Personalized Object Navigation\n(ZIPON), where robots need to navigate to personalized goal objects while\nengaging in conversations with users. To solve ZIPON, we propose a new\nframework termed Open-woRld Interactive persOnalized Navigation (ORION), which\nuses Large Language Models (LLMs) to make sequential decisions to manipulate\ndifferent modules for perception, navigation and communication. Experimental\nresults show that the performance of interactive agents that can leverage user\nfeedback exhibits significant improvement. However, obtaining a good balance\nbetween task completion and the efficiency of navigation and interaction\nremains challenging for all methods. We further provide more findings on the\nimpact of diverse user feedback forms on the agents' performance. Code is\navailable at https://github.com/sled-group/navchat.", "published": "2023-10-12 01:17:56", "link": "http://arxiv.org/abs/2310.07968v4", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large\n  Language Models", "abstract": "Large Language Models (LLMs) excel in NLP, but their demands hinder their\nwidespread deployment. While Quantization-Aware Training (QAT) offers a\nsolution, its extensive training costs make Post-Training Quantization (PTQ) a\nmore practical approach for LLMs. In existing studies, activation outliers in\nparticular channels are identified as the bottleneck to PTQ accuracy. They\npropose to transform the magnitudes from activations to weights, which however\noffers limited alleviation or suffers from unstable gradients, resulting in a\nsevere performance drop at low-bitwidth. In this paper, we propose QLLM, an\naccurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM\nintroduces an adaptive channel reassembly technique that reallocates the\nmagnitude of outliers to other channels, thereby mitigating their impact on the\nquantization range. This is achieved by channel disassembly and channel\nassembly, which first breaks down the outlier channels into several\nsub-channels to ensure a more balanced distribution of activation magnitudes.\nThen similar channels are merged to maintain the original channel number for\nefficiency. Additionally, an adaptive strategy is designed to autonomously\ndetermine the optimal number of sub-channels for channel disassembly. To\nfurther compensate for the performance loss caused by quantization, we propose\nan efficient tuning method that only learns a small number of low-rank weights\nwhile freezing the pre-trained quantized model. After training, these low-rank\nparameters can be fused into the frozen weights without affecting inference.\nExtensive experiments on LLaMA-1 and LLaMA-2 show that QLLM can obtain accurate\nquantized models efficiently. For example, QLLM quantizes the 4-bit LLaMA-2-70B\nwithin 10 hours on a single A100-80G GPU, outperforming the previous\nstate-of-the-art method by 7.89% on the average accuracy across five zero-shot\ntasks.", "published": "2023-10-12 05:25:49", "link": "http://arxiv.org/abs/2310.08041v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Negative Pairs in Code Search", "abstract": "Recently, contrastive learning has become a key component in fine-tuning code\nsearch models for software development efficiency and effectiveness. It pulls\ntogether positive code snippets while pushing negative samples away given\nsearch queries. Among contrastive learning, InfoNCE is the most widely used\nloss function due to its better performance. However, the following problems in\nnegative samples of InfoNCE may deteriorate its representation learning: 1) The\nexistence of false negative samples in large code corpora due to duplications.\n2). The failure to explicitly differentiate between the potential relevance of\nnegative samples. As an example, a bubble sorting algorithm example is less\n``negative'' than a file saving function for the quick sorting algorithm query.\nIn this paper, we tackle the above problems by proposing a simple yet effective\nSoft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss\nfunction, we apply three methods to estimate the weights of negative pairs and\nshow that the vanilla InfoNCE loss is a special case of Soft-InfoNCE.\nTheoretically, we analyze the effects of Soft-InfoNCE on controlling the\ndistribution of learnt code representations and on deducing a more precise\nmutual information estimation. We furthermore discuss the superiority of\nproposed loss functions with other design alternatives. Extensive experiments\ndemonstrate the effectiveness of Soft-InfoNCE and weights estimation methods\nunder state-of-the-art code search models on a large-scale public dataset\nconsisting of six programming languages. Source code is available at\n\\url{https://github.com/Alex-HaochenLi/Soft-InfoNCE}.", "published": "2023-10-12 06:32:42", "link": "http://arxiv.org/abs/2310.08069v1", "categories": ["cs.SE", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Voice Conversion for Stuttered Speech, Instruments, Unseen Languages and\n  Textually Described Voices", "abstract": "Voice conversion aims to convert source speech into a target voice using\nrecordings of the target speaker as a reference. Newer models are producing\nincreasingly realistic output. But what happens when models are fed with\nnon-standard data, such as speech from a user with a speech impairment? We\ninvestigate how a recent voice conversion model performs on non-standard\ndownstream voice conversion tasks. We use a simple but robust approach called\nk-nearest neighbors voice conversion (kNN-VC). We look at four non-standard\napplications: stuttered voice conversion, cross-lingual voice conversion,\nmusical instrument conversion, and text-to-voice conversion. The latter\ninvolves converting to a target voice specified through a text description,\ne.g. \"a young man with a high-pitched voice\". Compared to an established\nbaseline, we find that kNN-VC retains high performance in stuttered and\ncross-lingual voice conversion. Results are more mixed for the musical\ninstrument and text-to-voice conversion tasks. E.g., kNN-VC works well on some\ninstruments like drums but not on others. Nevertheless, this shows that voice\nconversion models - and kNN-VC in particular - are increasingly applicable in a\nrange of non-standard downstream tasks. But there are still limitations when\nsamples are very far from the training distribution. Code, samples, trained\nmodels: https://rf5.github.io/sacair2023-knnvc-demo/.", "published": "2023-10-12 08:00:25", "link": "http://arxiv.org/abs/2310.08104v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "On the Relevance of Phoneme Duration Variability of Synthesized Training\n  Data for Automatic Speech Recognition", "abstract": "Synthetic data generated by text-to-speech (TTS) systems can be used to\nimprove automatic speech recognition (ASR) systems in low-resource or domain\nmismatch tasks. It has been shown that TTS-generated outputs still do not have\nthe same qualities as real data. In this work we focus on the temporal\nstructure of synthetic data and its relation to ASR training. By using a novel\noracle setup we show how much the degradation of synthetic data quality is\ninfluenced by duration modeling in non-autoregressive (NAR) TTS. To get\nreference phoneme durations we use two common alignment methods, a hidden\nMarkov Gaussian-mixture model (HMM-GMM) aligner and a neural connectionist\ntemporal classification (CTC) aligner. Using a simple algorithm based on random\nwalks we shift phoneme duration distributions of the TTS system closer to real\ndurations, resulting in an improvement of an ASR system using synthetic data in\na semi-supervised setting.", "published": "2023-10-12 08:45:21", "link": "http://arxiv.org/abs/2310.08132v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SimCKP: Simple Contrastive Learning of Keyphrase Representations", "abstract": "Keyphrase generation (KG) aims to generate a set of summarizing words or\nphrases given a source document, while keyphrase extraction (KE) aims to\nidentify them from the text. Because the search space is much smaller in KE, it\nis often combined with KG to predict keyphrases that may or may not exist in\nthe corresponding document. However, current unified approaches adopt sequence\nlabeling and maximization-based generation that primarily operate at a token\nlevel, falling short in observing and scoring keyphrases as a whole. In this\nwork, we propose SimCKP, a simple contrastive learning framework that consists\nof two stages: 1) An extractor-generator that extracts keyphrases by learning\ncontext-aware phrase-level representations in a contrastive manner while also\ngenerating keyphrases that do not appear in the document; 2) A reranker that\nadapts scores for each generated phrase by likewise aligning their\nrepresentations with the corresponding document. Experimental results on\nmultiple benchmark datasets demonstrate the effectiveness of our proposed\napproach, which outperforms the state-of-the-art models by a significant\nmargin.", "published": "2023-10-12 11:11:54", "link": "http://arxiv.org/abs/2310.08221v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast Word Error Rate Estimation Using Self-Supervised Representations\n  for Speech and Text", "abstract": "Word error rate (WER) estimation aims to evaluate the quality of an automatic\nspeech recognition (ASR) system's output without requiring ground-truth labels.\nThis task has gained increasing attention as advanced ASR systems are trained\non large amounts of data. In this context, the computational efficiency of a\nWER estimator becomes essential in practice. However, previous works have not\nprioritised this aspect. In this paper, a Fast estimator for WER (Fe-WER) is\nintroduced, utilizing average pooling over self-supervised learning\nrepresentations for speech and text. Our results demonstrate that Fe-WER\noutperformed a baseline relatively by 14.10% in root mean square error and\n1.22% in Pearson correlation coefficient on Ted-Lium3. Moreover, a comparative\nanalysis of the distributions of target WER and WER estimates was conducted,\nincluding an examination of the average values per speaker. Lastly, the\ninference speed was approximately 3.4 times faster in the real-time factor.", "published": "2023-10-12 11:17:40", "link": "http://arxiv.org/abs/2310.08225v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models", "abstract": "Large language models (LLMs) often make factually incorrect responses despite\ntheir success in various applications. In this paper, we hypothesize that\nrelying heavily on simple co-occurrence statistics of the pre-training corpora\nis one of the main factors that cause factual errors. Our results reveal that\nLLMs are vulnerable to the co-occurrence bias, defined as preferring frequently\nco-occurred words over the correct answer. Consequently, LLMs struggle to\nrecall facts whose subject and object rarely co-occur in the pre-training\ndataset although they are seen during finetuning. We show that co-occurrence\nbias remains despite scaling up model sizes or finetuning. Therefore, we\nsuggest finetuning on a debiased dataset to mitigate the bias by filtering out\nbiased samples whose subject-object co-occurrence count is high. Although\ndebiased finetuning allows LLMs to memorize rare facts in the training set, it\nis not effective in recalling rare facts unseen during finetuning. Further\nresearch in mitigation will help build reliable language models by preventing\npotential errors. The code is available at\n\\url{https://github.com/CheongWoong/impact_of_cooccurrence}.", "published": "2023-10-12 12:01:32", "link": "http://arxiv.org/abs/2310.08256v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Defending Our Privacy With Backdoors", "abstract": "The proliferation of large AI models trained on uncurated, often sensitive\nweb-scraped data has raised significant privacy concerns. One of the concerns\nis that adversaries can extract information about the training data using\nprivacy attacks. Unfortunately, the task of removing specific information from\nthe models without sacrificing performance is not straightforward and has\nproven to be challenging. We propose a rather easy yet effective defense based\non backdoor attacks to remove private information, such as names and faces of\nindividuals, from vision-language models by fine-tuning them for only a few\nminutes instead of re-training them from scratch. Specifically, by\nstrategically inserting backdoors into text encoders, we align the embeddings\nof sensitive phrases with those of neutral terms-\"a person\" instead of the\nperson's actual name. For image encoders, we map individuals' embeddings to be\nremoved from the model to a universal, anonymous embedding. The results of our\nextensive experimental evaluation demonstrate the effectiveness of our\nbackdoor-based defense on CLIP by assessing its performance using a specialized\nprivacy attack for zero-shot classifiers. Our approach provides a new\n\"dual-use\" perspective on backdoor attacks and presents a promising avenue to\nenhance the privacy of individuals within models trained on uncurated\nweb-scraped data.", "published": "2023-10-12 13:33:04", "link": "http://arxiv.org/abs/2310.08320v4", "categories": ["cs.LG", "cs.CL", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MCU: An Evaluation Framework for Open-Ended Game Agents", "abstract": "Developing AI agents capable of interacting with open-world environments to\nsolve diverse tasks is a compelling challenge. However, evaluating such\nopen-ended agents remains difficult, with current benchmarks facing scalability\nlimitations. To address this, we introduce Minecraft Universe (MCU), a\ncomprehensive evaluation framework set within the open-world video game\nMinecraft. MCU incorporates three key components: (1) an expanding collection\nof 3,452 composable atomic tasks that encompasses 11 major categories and 41\nsubcategories of challenges; (2) a task composition mechanism capable of\ngenerating infinite diverse tasks with varying difficulty; and (3) a general\nevaluation framework that achieves 91.5% alignment with human ratings for\nopen-ended task assessment. Empirical results reveal that even state-of-the-art\nfoundation agents struggle with the increasing diversity and complexity of\ntasks. These findings highlight the necessity of MCU as a robust benchmark to\ndrive progress in AI agent development within open-ended environments.", "published": "2023-10-12 14:38:25", "link": "http://arxiv.org/abs/2310.08367v3", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Towards Better Evaluation of Instruction-Following: A Case-Study in\n  Summarization", "abstract": "Despite recent advances, evaluating how well large language models (LLMs)\nfollow user instructions remains an open problem. While evaluation methods of\nlanguage models have seen a rise in prompt-based approaches, limited work on\nthe correctness of these methods has been conducted. In this work, we perform a\nmeta-evaluation of a variety of metrics to quantify how accurately they measure\nthe instruction-following abilities of LLMs. Our investigation is performed on\ngrounded query-based summarization by collecting a new short-form, real-world\ndataset riSum, containing 300 document-instruction pairs with 3 answers each.\nAll 900 answers are rated by 3 human annotators. Using riSum, we analyze the\nagreement between evaluation methods and human judgment. Finally, we propose\nnew LLM-based reference-free evaluation methods that improve upon established\nbaselines and perform on par with costly reference-based metrics that require\nhigh-quality summaries.", "published": "2023-10-12 15:07:11", "link": "http://arxiv.org/abs/2310.08394v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DistillSpec: Improving Speculative Decoding via Knowledge Distillation", "abstract": "Speculative decoding (SD) accelerates large language model inference by\nemploying a faster draft model for generating multiple tokens, which are then\nverified in parallel by the larger target model, resulting in the text\ngenerated according to the target model distribution. However, identifying a\ncompact draft model that is well-aligned with the target model is challenging.\nTo tackle this issue, we propose DistillSpec that uses knowledge distillation\nto better align the draft model with the target model, before applying SD.\nDistillSpec makes two key design choices, which we demonstrate via systematic\nstudy to be crucial to improving the draft and target alignment: utilizing\non-policy data generation from the draft model, and tailoring the divergence\nfunction to the task and decoding strategy. Notably, DistillSpec yields\nimpressive 10 - 45% speedups over standard SD on a range of standard\nbenchmarks, using both greedy and non-greedy sampling. Furthermore, we combine\nDistillSpec with lossy SD to achieve fine-grained control over the latency vs.\ntask performance trade-off. Finally, in practical scenarios with models of\nvarying sizes, first using distillation to boost the performance of the target\nmodel and then applying DistillSpec to train a well-aligned draft model can\nreduce decoding latency by 6-10x with minimal performance drop, compared to\nstandard decoding without distillation.", "published": "2023-10-12 16:21:04", "link": "http://arxiv.org/abs/2310.08461v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HoneyBee: Progressive Instruction Finetuning of Large Language Models\n  for Materials Science", "abstract": "We propose an instruction-based process for trustworthy data curation in\nmaterials science (MatSci-Instruct), which we then apply to finetune a\nLLaMa-based language model targeted for materials science (HoneyBee).\nMatSci-Instruct helps alleviate the scarcity of relevant, high-quality\nmaterials science textual data available in the open literature, and HoneyBee\nis the first billion-parameter language model specialized to materials science.\nIn MatSci-Instruct we improve the trustworthiness of generated data by\nprompting multiple commercially available large language models for generation\nwith an Instructor module (e.g. Chat-GPT) and verification from an independent\nVerifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset of\nmultiple tasks and measure the quality of our dataset along multiple\ndimensions, including accuracy against known facts, relevance to materials\nscience, as well as completeness and reasonableness of the data. Moreover, we\niteratively generate more targeted instructions and instruction-data in a\nfinetuning-evaluation-feedback loop leading to progressively better performance\nfor our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmark\nshows HoneyBee's outperformance of existing language models on materials\nscience tasks and iterative improvement in successive stages of\ninstruction-data refinement. We study the quality of HoneyBee's language\nmodeling through automatic evaluation and analyze case studies to further\nunderstand the model's capabilities and limitations. Our code and relevant\ndatasets are publicly available at\n\\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee}.", "published": "2023-10-12 17:06:19", "link": "http://arxiv.org/abs/2310.08511v1", "categories": ["cs.CL", "cond-mat.mtrl-sci", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do pretrained Transformers Learn In-Context by Gradient Descent?", "abstract": "The emergence of In-Context Learning (ICL) in LLMs remains a remarkable\nphenomenon that is partially understood. To explain ICL, recent studies have\ncreated theoretical connections to Gradient Descent (GD). We ask, do such\nconnections hold up in actual pre-trained language models? We highlight the\nlimiting assumptions in prior works that make their setup considerably\ndifferent from the practical setup in which language models are trained. For\nexample, their experimental verification uses \\emph{ICL objective} (training\nmodels explicitly for ICL), which differs from the emergent ICL in the wild.\nFurthermore, the theoretical hand-constructed weights used in these studies\nhave properties that don't match those of real LLMs. We also look for evidence\nin real models. We observe that ICL and GD have different sensitivity to the\norder in which they observe demonstrations. Finally, we probe and compare the\nICL vs. GD hypothesis in a natural setting. We conduct comprehensive empirical\nanalyses on language models pre-trained on natural data (LLaMa-7B). Our\ncomparisons of three performance metrics highlight the inconsistent behavior of\nICL and GD as a function of various factors such as datasets, models, and the\nnumber of demonstrations. We observe that ICL and GD modify the output\ndistribution of language models differently. These results indicate that\n\\emph{the equivalence between ICL and GD remains an open hypothesis} and calls\nfor further studies.", "published": "2023-10-12 17:32:09", "link": "http://arxiv.org/abs/2310.08540v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Visual Data-Type Understanding does not emerge from Scaling\n  Vision-Language Models", "abstract": "Recent advances in the development of vision-language models (VLMs) are\nyielding remarkable success in recognizing visual semantic content, including\nimpressive instances of compositional image understanding. Here, we introduce\nthe novel task of Visual Data-Type Identification, a basic perceptual skill\nwith implications for data curation (e.g., noisy data-removal from large\ndatasets, domain-specific retrieval) and autonomous vision (e.g.,\ndistinguishing changing weather conditions from camera lens staining). We\ndevelop two datasets consisting of animal images altered across a diverse set\nof 27 visual data-types, spanning four broad categories. An extensive zero-shot\nevaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced\nperformance landscape. While VLMs are reasonably good at identifying certain\nstylistic \\textit{data-types}, such as cartoons and sketches, they struggle\nwith simpler data-types arising from basic manipulations like image rotations\nor additive noise. Our findings reveal that (i) model scaling alone yields\nmarginal gains for contrastively-trained models like CLIP, and (ii) there is a\npronounced drop in performance for the largest auto-regressively trained VLMs\nlike OpenFlamingo. This finding points to a blind spot in current frontier\nVLMs: they excel in recognizing semantic content but fail to acquire an\nunderstanding of visual data-types through scaling. By analyzing the\npre-training distributions of these models and incorporating data-type\ninformation into the captions during fine-tuning, we achieve a significant\nenhancement in performance. By exploring this previously uncharted task, we aim\nto set the stage for further advancing VLMs to equip them with visual data-type\nunderstanding. Code and datasets are released at\nhttps://github.com/bethgelab/DataTypeIdentification.", "published": "2023-10-12 17:59:30", "link": "http://arxiv.org/abs/2310.08577v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Tree-Planner: Efficient Close-loop Task Planning with Large Language\n  Models", "abstract": "This paper studies close-loop task planning, which refers to the process of\ngenerating a sequence of skills (a plan) to accomplish a specific goal while\nadapting the plan based on real-time observations. Recently, prompting Large\nLanguage Models (LLMs) to generate actions iteratively has become a prevalent\nparadigm due to its superior performance and user-friendliness. However, this\nparadigm is plagued by two inefficiencies: high token consumption and redundant\nerror correction, both of which hinder its scalability for large-scale testing\nand applications. To address these issues, we propose Tree-Planner, which\nreframes task planning with LLMs into three distinct phases: plan sampling,\naction tree construction, and grounded deciding. Tree-Planner starts by using\nan LLM to sample a set of potential plans before execution, followed by the\naggregation of them to form an action tree. Finally, the LLM performs a\ntop-down decision-making process on the tree, taking into account real-time\nenvironmental information. Experiments show that Tree-Planner achieves\nstate-of-the-art performance while maintaining high efficiency. By decomposing\nLLM queries into a single plan-sampling call and multiple grounded-deciding\ncalls, a considerable part of the prompt are less likely to be repeatedly\nconsumed. As a result, token consumption is reduced by 92.2% compared to the\npreviously best-performing model. Additionally, by enabling backtracking on the\naction tree as needed, the correction process becomes more flexible, leading to\na 40.5% decrease in error corrections.", "published": "2023-10-12 17:59:50", "link": "http://arxiv.org/abs/2310.08582v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
{"title": "LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models", "abstract": "Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves generalization in\ndownstream tasks. We evaluate our method on natural language understanding,\nquestion answering, summarization, and natural language generation tasks.\nExperiments show that our method is highly effective and outperforms existing\nquantization methods, especially in the challenging 2-bit and 2/4-bit mixed\nprecision regimes. The code is available on https://github.com/yxli2123/LoftQ.", "published": "2023-10-12 18:34:08", "link": "http://arxiv.org/abs/2310.08659v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4\n  on mock CFA Exams", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance on a\nwide range of Natural Language Processing (NLP) tasks, often matching or even\nbeating state-of-the-art task-specific models. This study aims at assessing the\nfinancial reasoning capabilities of LLMs. We leverage mock exam questions of\nthe Chartered Financial Analyst (CFA) Program to conduct a comprehensive\nevaluation of ChatGPT and GPT-4 in financial analysis, considering Zero-Shot\n(ZS), Chain-of-Thought (CoT), and Few-Shot (FS) scenarios. We present an\nin-depth analysis of the models' performance and limitations, and estimate\nwhether they would have a chance at passing the CFA exams. Finally, we outline\ninsights into potential strategies and improvements to enhance the\napplicability of LLMs in finance. In this perspective, we hope this work paves\nthe way for future studies to continue enhancing LLMs for financial reasoning\nthrough rigorous evaluation.", "published": "2023-10-12 19:28:57", "link": "http://arxiv.org/abs/2310.08678v1", "categories": ["cs.CL", "cs.AI", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "Toward Joint Language Modeling for Speech Units and Text", "abstract": "Speech and text are two major forms of human language. The research community\nhas been focusing on mapping speech to text or vice versa for many years.\nHowever, in the field of language modeling, very little effort has been made to\nmodel them jointly. In light of this, we explore joint language modeling for\nspeech units and text. Specifically, we compare different speech tokenizers to\ntransform continuous speech signals into discrete units and use different\nmethods to construct mixed speech-text data. We introduce automatic metrics to\nevaluate how well the joint LM mixes speech and text. We also fine-tune the LM\non downstream spoken language understanding (SLU) tasks with different\nmodalities (speech or text) and test its performance to assess the model's\nlearning of shared representations. Our results show that by mixing speech\nunits and text with our proposed mixing techniques, the joint LM improves over\na speech-only baseline on SLU tasks and shows zero-shot cross-modal\ntransferability.", "published": "2023-10-12 20:53:39", "link": "http://arxiv.org/abs/2310.08715v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Zero-Shot Language Agent for Computer Control with Structured\n  Reflection", "abstract": "Large language models (LLMs) have shown increasing capacity at planning and\nexecuting a high-level goal in a live computer environment (e.g. MiniWoB++). To\nperform a task, recent works often require a model to learn from trace examples\nof the task via either supervised learning or few/many-shot prompting. Without\nthese trace examples, it remains a challenge how an agent can autonomously\nlearn and improve its control on a computer, which limits the ability of an\nagent to perform a new task. We approach this problem with a zero-shot agent\nthat requires no given expert traces. Our agent plans for executable actions on\na partially observed environment, and iteratively progresses a task by\nidentifying and learning from its mistakes via self-reflection and structured\nthought management. On the easy tasks of MiniWoB++, we show that our zero-shot\nagent often outperforms recent SoTAs, with more efficient reasoning. For tasks\nwith more complexity, our reflective agent performs on par with prior best\nmodels, even though previous works had the advantages of accessing expert\ntraces or additional screen information.", "published": "2023-10-12 21:53:37", "link": "http://arxiv.org/abs/2310.08740v3", "categories": ["cs.CL", "cs.SY", "eess.SY"], "primary_category": "cs.CL"}
{"title": "CompA: Addressing the Gap in Compositional Reasoning in Audio-Language\n  Models", "abstract": "A fundamental characteristic of audio is its compositional nature.\nAudio-language models (ALMs) trained using a contrastive approach (e.g., CLAP)\nthat learns a shared representation between audio and language modalities have\nimproved performance in many downstream applications, including zero-shot audio\nclassification, audio retrieval, etc. However, the ability of these models to\neffectively perform compositional reasoning remains largely unexplored and\nnecessitates additional research. In this paper, we propose CompA, a collection\nof two expert-annotated benchmarks with a majority of real-world audio samples,\nto evaluate compositional reasoning in ALMs. Our proposed CompA-order evaluates\nhow well an ALM understands the order or occurrence of acoustic events in\naudio, and CompA-attribute evaluates attribute-binding of acoustic events. An\ninstance from either benchmark consists of two audio-caption pairs, where both\naudios have the same acoustic events but with different compositions. An ALM is\nevaluated on how well it matches the right audio to the right caption. Using\nthis benchmark, we first show that current ALMs perform only marginally better\nthan random chance, thereby struggling with compositional reasoning. Next, we\npropose CompA-CLAP, where we fine-tune CLAP using a novel learning method to\nimprove its compositional reasoning abilities. To train CompA-CLAP, we first\npropose improvements to contrastive training with composition-aware hard\nnegatives, allowing for more focused training. Next, we propose a novel modular\ncontrastive loss that helps the model learn fine-grained compositional\nunderstanding and overcomes the acute scarcity of openly available\ncompositional audios. CompA-CLAP significantly improves over all our baseline\nmodels on the CompA benchmark, indicating its superior compositional reasoning\ncapabilities.", "published": "2023-10-12 22:43:38", "link": "http://arxiv.org/abs/2310.08753v4", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Large language models can replicate cross-cultural differences in\n  personality", "abstract": "We use a large-scale experiment (N=8000) to determine whether GPT-4 can\nreplicate cross-cultural differences in the Big Five, measured using the\nTen-Item Personality Inventory. We used the US and South Korea as the cultural\npair, given that prior research suggests substantial personality differences\nbetween people from these two countries. We manipulated the target of the\nsimulation (US vs. Korean), the language of the inventory (English vs. Korean),\nand the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4\nreplicated the cross-cultural differences for each factor. However, mean\nratings had an upward bias and exhibited lower variation than in the human\nsamples, as well as lower structural validity. We provide preliminary evidence\nthat LLMs can aid cross-cultural researchers and practitioners.", "published": "2023-10-12 11:17:23", "link": "http://arxiv.org/abs/2310.10679v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; K.4.2; J.4"], "primary_category": "cs.CL"}
{"title": "Can We Edit Multimodal Large Language Models?", "abstract": "In this paper, we focus on editing Multimodal Large Language Models (MLLMs).\nCompared to editing single-modal LLMs, multimodal model editing is more\nchallenging, which demands a higher level of scrutiny and careful consideration\nin the editing process. To facilitate research in this area, we construct a new\nbenchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite\nof innovative metrics for evaluation. We conduct comprehensive experiments\ninvolving various model editing baselines and analyze the impact of editing\ndifferent components for multimodal LLMs. Empirically, we notice that previous\nbaselines can implement editing multimodal LLMs to some extent, but the effect\nis still barely satisfactory, indicating the potential difficulty of this task.\nWe hope that our work can provide the NLP community with insights. Code and\ndataset are available in https://github.com/zjunlp/EasyEdit.", "published": "2023-10-12 16:32:44", "link": "http://arxiv.org/abs/2310.08475v5", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Transformers as Decision Makers: Provable In-Context Reinforcement\n  Learning via Supervised Pretraining", "abstract": "Large transformer models pretrained on offline reinforcement learning\ndatasets have demonstrated remarkable in-context reinforcement learning (ICRL)\ncapabilities, where they can make good decisions when prompted with interaction\ntrajectories from unseen environments. However, when and how transformers can\nbe trained to perform ICRL have not been theoretically well-understood. In\nparticular, it is unclear which reinforcement-learning algorithms transformers\ncan perform in context, and how distribution mismatch in offline training data\naffects the learned algorithms. This paper provides a theoretical framework\nthat analyzes supervised pretraining for ICRL. This includes two recently\nproposed training methods -- algorithm distillation and decision-pretrained\ntransformers. First, assuming model realizability, we prove the\nsupervised-pretrained transformer will imitate the conditional expectation of\nthe expert algorithm given the observed trajectory. The generalization error\nwill scale with model capacity and a distribution divergence factor between the\nexpert and offline algorithms. Second, we show transformers with ReLU attention\ncan efficiently approximate near-optimal online reinforcement learning\nalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, and\nUCB-VI for tabular Markov decision processes. This provides the first\nquantitative analysis of the ICRL capabilities of transformers pretrained from\noffline trajectories.", "published": "2023-10-12 17:55:02", "link": "http://arxiv.org/abs/2310.08566v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "A Single Speech Enhancement Model Unifying Dereverberation, Denoising,\n  Speaker Counting, Separation, and Extraction", "abstract": "We propose a multi-task universal speech enhancement (MUSE) model that can\nperform five speech enhancement (SE) tasks: dereverberation, denoising, speech\nseparation (SS), target speaker extraction (TSE), and speaker counting. This is\nachieved by integrating two modules into an SE model: 1) an internal separation\nmodule that does both speaker counting and separation; and 2) a TSE module that\nextracts the target speech from the internal separation outputs using target\nspeaker cues. The model is trained to perform TSE if the target speaker cue is\ngiven and SS otherwise. By training the model to remove noise and\nreverberation, we allow the model to tackle the five tasks mentioned above with\na single model, which has not been accomplished yet. Evaluation results\ndemonstrate that the proposed MUSE model can successfully handle multiple tasks\nwith a single model.", "published": "2023-10-12 12:28:51", "link": "http://arxiv.org/abs/2310.08277v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Crowdsourced and Automatic Speech Prominence Estimation", "abstract": "The prominence of a spoken word is the degree to which an average native\nlistener perceives the word as salient or emphasized relative to its context.\nSpeech prominence estimation is the process of assigning a numeric value to the\nprominence of each word in an utterance. These prominence labels are useful for\nlinguistic analysis, as well as training automated systems to perform\nemphasis-controlled text-to-speech or emotion recognition. Manually annotating\nprominence is time-consuming and expensive, which motivates the development of\nautomated methods for speech prominence estimation. However, developing such an\nautomated system using machine-learning methods requires human-annotated\ntraining data. Using our system for acquiring such human annotations, we\ncollect and open-source crowdsourced annotations of a portion of the LibriTTS\ndataset. We use these annotations as ground truth to train a neural speech\nprominence estimator that generalizes to unseen speakers, datasets, and\nspeaking styles. We investigate design decisions for neural prominence\nestimation as well as how neural prominence estimation improves as a function\nof two key factors of annotation cost: dataset size and the number of\nannotations per utterance.", "published": "2023-10-12 16:23:28", "link": "http://arxiv.org/abs/2310.08464v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "End-to-end Online Speaker Diarization with Target Speaker Tracking", "abstract": "This paper proposes an online target speaker voice activity detection system\nfor speaker diarization tasks, which does not require a priori knowledge from\nthe clustering-based diarization system to obtain the target speaker\nembeddings. By adapting the conventional target speaker voice activity\ndetection for real-time operation, this framework can identify speaker\nactivities using self-generated embeddings, resulting in consistent performance\nwithout permutation inconsistencies in the inference phase. During the\ninference process, we employ a front-end model to extract the frame-level\nspeaker embeddings for each coming block of a signal. Next, we predict the\ndetection state of each speaker based on these frame-level speaker embeddings\nand the previously estimated target speaker embedding. Then, the target speaker\nembeddings are updated by aggregating these frame-level speaker embeddings\naccording to the predictions in the current block. Our model predicts the\nresults for each block and updates the target speakers' embeddings until\nreaching the end of the signal. Experimental results show that the proposed\nmethod outperforms the offline clustering-based diarization system on the\nDIHARD III and AliMeeting datasets. The proposed method is further extended to\nmulti-channel data, which achieves similar performance with the\nstate-of-the-art offline diarization systems.", "published": "2023-10-12 20:02:07", "link": "http://arxiv.org/abs/2310.08696v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multimodal Variational Auto-encoder based Audio-Visual Segmentation", "abstract": "We propose an Explicit Conditional Multimodal Variational Auto-Encoder\n(ECMVAE) for audio-visual segmentation (AVS), aiming to segment sound sources\nin the video sequence. Existing AVS methods focus on implicit feature fusion\nstrategies, where models are trained to fit the discrete samples in the\ndataset. With a limited and less diverse dataset, the resulting performance is\nusually unsatisfactory. In contrast, we address this problem from an effective\nrepresentation learning perspective, aiming to model the contribution of each\nmodality explicitly. Specifically, we find that audio contains critical\ncategory information of the sound producers, and visual data provides candidate\nsound producer(s). Their shared information corresponds to the target sound\nproducer(s) shown in the visual data. In this case, cross-modal shared\nrepresentation learning is especially important for AVS. To achieve this, our\nECMVAE factorizes the representations of each modality with a modality-shared\nrepresentation and a modality-specific representation. An orthogonality\nconstraint is applied between the shared and specific representations to\nmaintain the exclusive attribute of the factorized latent code. Further, a\nmutual information maximization regularizer is introduced to achieve extensive\nexploration of each modality. Quantitative and qualitative evaluations on the\nAVSBench demonstrate the effectiveness of our approach, leading to a new\nstate-of-the-art for AVS, with a 3.84 mIOU performance leap on the challenging\nMS3 subset for multiple sound source segmentation.", "published": "2023-10-12 13:09:40", "link": "http://arxiv.org/abs/2310.08303v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A cry for help: Early detection of brain injury in newborns", "abstract": "Since the 1960s, neonatal clinicians have known that newborns suffering from\ncertain neurological conditions exhibit altered crying patterns such as the\nhigh-pitched cry in birth asphyxia. Despite an annual burden of over 1.5\nmillion infant deaths and disabilities, early detection of neonatal brain\ninjuries due to asphyxia remains a challenge, particularly in developing\ncountries where the majority of births are not attended by a trained physician.\nHere we report on the first inter-continental clinical study to demonstrate\nthat neonatal brain injury can be reliably determined from recorded infant\ncries using an AI algorithm we call Roseline. Previous and recent work has been\nlimited by the lack of a large, high-quality clinical database of cry\nrecordings, constraining the application of state-of-the-art machine learning.\nWe develop a new training methodology for audio-based pathology detection\nmodels and evaluate this system on a large database of newborn cry sounds\nacquired from geographically diverse settings -- 5 hospitals across 3\ncontinents. Our system extracts interpretable acoustic biomarkers that support\nclinical decisions and is able to accurately detect neurological injury from\nnewborns' cries with an AUC of 92.5% (88.7% sensitivity at 80% specificity).\nCry-based neurological monitoring opens the door for low-cost, easy-to-use,\nnon-invasive and contact-free screening of at-risk babies, especially when\nintegrated into simple devices like smartphones or neonatal ICU monitors. This\nwould provide a reliable tool where there are no alternatives, but also curtail\nthe need to regularly exert newborns to physically-exhausting or\nradiation-exposing assessments such as brain CT scans. This work sets the stage\nfor embracing the infant cry as a vital sign and indicates the potential of\nAI-driven sound monitoring for the future of affordable healthcare.", "published": "2023-10-12 13:56:42", "link": "http://arxiv.org/abs/2310.08338v3", "categories": ["eess.AS", "cs.SD", "q-bio.NC"], "primary_category": "eess.AS"}
{"title": "Impact of time and note duration tokenizations on deep learning symbolic\n  music modeling", "abstract": "Symbolic music is widely used in various deep learning tasks, including\ngeneration, transcription, synthesis, and Music Information Retrieval (MIR). It\nis mostly employed with discrete models like Transformers, which require music\nto be tokenized, i.e., formatted into sequences of distinct elements called\ntokens. Tokenization can be performed in different ways. As Transformer can\nstruggle at reasoning, but capture more easily explicit information, it is\nimportant to study how the way the information is represented for such model\nimpact their performances. In this work, we analyze the common tokenization\nmethods and experiment with time and note duration representations. We compare\nthe performances of these two impactful criteria on several tasks, including\ncomposer and emotion classification, music generation, and sequence\nrepresentation learning. We demonstrate that explicit information leads to\nbetter results depending on the task.", "published": "2023-10-12 16:56:37", "link": "http://arxiv.org/abs/2310.08497v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
