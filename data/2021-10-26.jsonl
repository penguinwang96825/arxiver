{"title": "Task-Specific Dependency-based Word Embedding Methods", "abstract": "Two task-specific dependency-based word embedding methods are proposed for\ntext classification in this work. In contrast with universal word embedding\nmethods that work for generic tasks, we design task-specific word embedding\nmethods to offer better performance in a specific task. Our methods follow the\nPPMI matrix factorization framework and derive word contexts from the\ndependency parse tree. The first one, called the dependency-based word\nembedding (DWE), chooses keywords and neighbor words of a target word in the\ndependency parse tree as contexts to build the word-context matrix. The second\nmethod, named class-enhanced dependency-based word embedding (CEDWE), learns\nfrom word-context as well as word-class co-occurrence statistics. DWE and CEDWE\nare evaluated on popular text classification datasets to demonstrate their\neffectiveness. It is shown by experimental results they outperform several\nstate-of-the-art word embedding methods.", "published": "2021-10-26 03:09:41", "link": "http://arxiv.org/abs/2110.13376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain", "abstract": "During the fine-tuning phase of transfer learning, the pretrained vocabulary\nremains unchanged, while model parameters are updated. The vocabulary generated\nbased on the pretrained data is suboptimal for downstream data when domain\ndiscrepancy exists. We propose to consider the vocabulary as an optimizable\nparameter, allowing us to update the vocabulary by expanding it with\ndomain-specific vocabulary based on a tokenization statistic. Furthermore, we\npreserve the embeddings of the added words from overfitting to downstream data\nby utilizing knowledge learned from a pretrained language model with a\nregularization term. Our method achieved consistent performance improvements on\ndiverse domains (i.e., biomedical, computer science, news, and reviews).", "published": "2021-10-26 06:26:01", "link": "http://arxiv.org/abs/2110.13434v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decomposing Complex Questions Makes Multi-Hop QA Easier and More\n  Interpretable", "abstract": "Multi-hop QA requires the machine to answer complex questions through finding\nmultiple clues and reasoning, and provide explanatory evidence to demonstrate\nthe machine reasoning process. We propose Relation Extractor-Reader and\nComparator (RERC), a three-stage framework based on complex question\ndecomposition, which is the first work that the RERC model has been proposed\nand applied in solving the multi-hop QA challenges. The Relation Extractor\ndecomposes the complex question, and then the Reader answers the sub-questions\nin turn, and finally the Comparator performs numerical comparison and\nsummarizes all to get the final answer, where the entire process itself\nconstitutes a complete reasoning evidence path. In the 2WikiMultiHopQA dataset,\nour RERC model has achieved the most advanced performance, with a winning joint\nF1 score of 53.58 on the leaderboard. All indicators of our RERC are close to\nhuman performance, with only 1.95 behind the human level in F1 score of support\nfact. At the same time, the evidence path provided by our RERC framework has\nexcellent readability and faithfulness.", "published": "2021-10-26 08:10:35", "link": "http://arxiv.org/abs/2110.13472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simultaneous Neural Machine Translation with Constituent Label\n  Prediction", "abstract": "Simultaneous translation is a task in which translation begins before the\nspeaker has finished speaking, so it is important to decide when to start the\ntranslation process. However, deciding whether to read more input words or\nstart to translate is difficult for language pairs with different word orders\nsuch as English and Japanese. Motivated by the concept of pre-reordering, we\npropose a couple of simple decision rules using the label of the next\nconstituent predicted by incremental constituent label prediction. In\nexperiments on English-to-Japanese simultaneous translation, the proposed\nmethod outperformed baselines in the quality-latency trade-off.", "published": "2021-10-26 08:23:20", "link": "http://arxiv.org/abs/2110.13480v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Sufficiency of Arguments through Conclusion Generation", "abstract": "The premises of an argument give evidence or other reasons to support a\nconclusion. However, the amount of support required depends on the generality\nof a conclusion, the nature of the individual premises, and similar. An\nargument whose premises make its conclusion rationally worthy to be drawn is\ncalled sufficient in argument quality research. Previous work tackled\nsufficiency assessment as a standard text classification problem, not modeling\nthe inherent relation of premises and conclusion. In this paper, we hypothesize\nthat the conclusion of a sufficient argument can be generated from its\npremises. To study this hypothesis, we explore the potential of assessing\nsufficiency based on the output of large-scale pre-trained language models. Our\nbest model variant achieves an F1-score of .885, outperforming the previous\nstate-of-the-art and being on par with human experts. While manual evaluation\nreveals the quality of the generated conclusions, their impact remains low\nultimately.", "published": "2021-10-26 08:47:53", "link": "http://arxiv.org/abs/2110.13495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Part & Whole Extraction: Towards A Deep Understanding of Quantitative\n  Facts for Percentages in Text", "abstract": "We study the problem of quantitative facts extraction for text with\npercentages. For example, given the sentence \"30 percent of Americans like\nwatching football, while 20% prefer to watch NBA.\", our goal is to obtain a\ndeep understanding of the percentage numbers (\"30 percent\" and \"20%\") by\nextracting their quantitative facts: part (\"like watching football\" and \"prefer\nto watch NBA\") and whole (\"Americans). These quantitative facts can empower new\napplications like automated infographic generation. We formulate part and whole\nextraction as a sequence tagging problem. Due to the large gap between\npart/whole and its corresponding percentage, we introduce skip mechanism in\nsequence modeling, and achieved improved performance on both our task and the\nCoNLL-2003 named entity recognition task. Experimental results demonstrate that\nlearning to skip in sequence tagging is promising.", "published": "2021-10-26 09:00:44", "link": "http://arxiv.org/abs/2110.13505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Rule Induction", "abstract": "Rules have a number of desirable properties. It is easy to understand, infer\nnew knowledge, and communicate with other inference systems. One weakness of\nthe previous rule induction systems is that they only find rules within a\nknowledge base (KB) and therefore cannot generalize to more open and complex\nreal-world rules. Recently, the language model (LM)-based rule generation are\nproposed to enhance the expressive power of the rules. In this paper, we\nrevisit the differences between KB-based rule induction and LM-based rule\ngeneration. We argue that, while KB-based methods inducted rules by discovering\ndata commonalities, the current LM-based methods are \"learning rules from\nrules\". This limits these methods to only produce \"canned\" rules whose patterns\nare constrained by the annotated rules, while discarding the rich expressive\npower of LMs for free text.\n  Therefore, in this paper, we propose the open rule induction problem, which\naims to induce open rules utilizing the knowledge in LMs. Besides, we propose\nthe Orion (\\underline{o}pen \\underline{r}ule \\underline{i}nducti\\underline{on})\nsystem to automatically mine open rules from LMs without supervision of\nannotated rules. We conducted extensive experiments to verify the quality and\nquantity of the inducted open rules. Surprisingly, when applying the open rules\nin downstream tasks (i.e. relation extraction), these automatically inducted\nrules even outperformed the manually annotated rules.", "published": "2021-10-26 11:20:24", "link": "http://arxiv.org/abs/2110.13577v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "s2s-ft: Fine-Tuning Pretrained Transformer Encoders for\n  Sequence-to-Sequence Learning", "abstract": "Pretrained bidirectional Transformers, such as BERT, have achieved\nsignificant improvements in a wide variety of language understanding tasks,\nwhile it is not straightforward to directly apply them for natural language\ngeneration. In this paper, we present a sequence-to-sequence fine-tuning\ntoolkit s2s-ft, which adopts pretrained Transformers for conditional generation\ntasks. Inspired by UniLM, we implement three sequence-to-sequence fine-tuning\nalgorithms, namely, causal fine-tuning, masked fine-tuning, and pseudo-masked\nfine-tuning. By leveraging the existing pretrained bidirectional Transformers,\nexperimental results show that s2s-ft achieves strong performance on several\nbenchmarks of abstractive summarization, and question generation. Moreover, we\ndemonstrate that the package s2s-ft supports both monolingual and multilingual\nNLG tasks. The s2s-ft toolkit is available at\nhttps://github.com/microsoft/unilm/tree/master/s2s-ft.", "published": "2021-10-26 12:45:34", "link": "http://arxiv.org/abs/2110.13640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotating Implicit Reasoning in Arguments with Causal Links", "abstract": "Most of the existing work that focus on the identification of implicit\nknowledge in arguments generally represent implicit knowledge in the form of\ncommonsense or factual knowledge. However, such knowledge is not sufficient to\nunderstand the implicit reasoning link between individual argumentative\ncomponents (i.e., claim and premise). In this work, we focus on identifying the\nimplicit knowledge in the form of argumentation knowledge which can help in\nunderstanding the reasoning link in arguments. Being inspired by the Argument\nfrom Consequences scheme, we propose a semi-structured template to represent\nsuch argumentation knowledge that explicates the implicit reasoning in\narguments via causality. We create a novel two-phase annotation process with\nsimplified guidelines and show how to collect and filter high-quality implicit\nreasonings via crowdsourcing. We find substantial inter-annotator agreement for\nquality evaluation between experts, but find evidence that casts a few\nquestions on the feasibility of collecting high-quality semi-structured\nimplicit reasoning through our crowdsourcing process. We release our\nmaterials(i.e., crowdsourcing guidelines and collected implicit reasonings) to\nfacilitate further research towards the structured representation of\nargumentation knowledge.", "published": "2021-10-26 13:28:53", "link": "http://arxiv.org/abs/2110.13692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Attacks and Defenses for Social Network Text Processing\n  Applications: Techniques, Challenges and Future Research Directions", "abstract": "The growing use of social media has led to the development of several Machine\nLearning (ML) and Natural Language Processing(NLP) tools to process the\nunprecedented amount of social media content to make actionable decisions.\nHowever, these MLand NLP algorithms have been widely shown to be vulnerable to\nadversarial attacks. These vulnerabilities allow adversaries to launch a\ndiversified set of adversarial attacks on these algorithms in different\napplications of social media text processing. In this paper, we provide a\ncomprehensive review of the main approaches for adversarial attacks and\ndefenses in the context of social media applications with a particular focus on\nkey challenges and future research directions. In detail, we cover literature\non six key applications, namely (i) rumors detection, (ii) satires detection,\n(iii) clickbait & spams identification, (iv) hate speech detection,\n(v)misinformation detection, and (vi) sentiment analysis. We then highlight the\nconcurrent and anticipated future research questions and provide\nrecommendations and directions for future work.", "published": "2021-10-26 19:33:40", "link": "http://arxiv.org/abs/2110.13980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unified Instance and Knowledge Alignment Pretraining for Aspect-based\n  Sentiment Analysis", "abstract": "Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment\npolarity towards an aspect. Because of the expensive and limited labelled data,\nthe pretraining strategy has become the de-facto standard for ABSA. However,\nthere always exists severe domain shift between the pretraining and downstream\nABSA datasets, hindering the effective knowledge transfer when directly\nfinetuning and making the downstream task performs sub-optimal. To mitigate\nsuch domain shift, we introduce a unified alignment pretraining framework into\nthe vanilla pretrain-finetune pipeline with both instance- and knowledge-level\nalignments. Specifically, we first devise a novel coarse-to-fine retrieval\nsampling approach to select target domain-related instances from the\nlarge-scale pretraining dataset, thus aligning the instances between\npretraining and target domains (First Stage). Then, we introduce a knowledge\nguidance-based strategy to further bridge the domain gap at the knowledge\nlevel. In practice, we formulate the model pretrained on the sampled instances\ninto a knowledge guidance model and a learner model, respectively. On the\ntarget dataset, we design an on-the-fly teacher-student joint fine-tuning\napproach to progressively transfer the knowledge from the knowledge guidance\nmodel to the learner model (Second Stage). Thereby, the learner model can\nmaintain more domain-invariant knowledge when learning new knowledge from the\ntarget dataset. In the Third Stage, the learner model is finetuned to better\nadapt its learned knowledge to the target dataset. Extensive experiments and\nanalyses on several ABSA benchmarks demonstrate the effectiveness and\nuniversality of our proposed pretraining framework. Our source code and models\nare publicly available at https://github.com/WHU-ZQH/UIKA.", "published": "2021-10-26 04:03:45", "link": "http://arxiv.org/abs/2110.13398v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Character-based Language Models Improve Downstream Task Performance\n  in Low-Resource and Noisy Language Scenarios?", "abstract": "Recent impressive improvements in NLP, largely based on the success of\ncontextual neural language models, have been mostly demonstrated on at most a\ncouple dozen high-resource languages. Building language models and, more\ngenerally, NLP systems for non-standardized and low-resource languages remains\na challenging task. In this work, we focus on North-African colloquial\ndialectal Arabic written using an extension of the Latin script, called\nNArabizi, found mostly on social media and messaging communication. In this\nlow-resource scenario with data displaying a high level of variability, we\ncompare the downstream performance of a character-based language model on\npart-of-speech tagging and dependency parsing to that of monolingual and\nmultilingual models. We show that a character-based model trained on only 99k\nsentences of NArabizi and fined-tuned on a small treebank of this language\nleads to performance close to those obtained with the same architecture\npre-trained on large multilingual and monolingual models. Confirming these\nresults a on much larger data set of noisy French user-generated content, we\nargue that such character-based language models can be an asset for NLP in\nlow-resource and high language variability set-tings.", "published": "2021-10-26 14:59:16", "link": "http://arxiv.org/abs/2110.13658v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Explicit-Joint and Supervised-Contrastive Learning Framework for\n  Few-Shot Intent Classification and Slot Filling", "abstract": "Intent classification (IC) and slot filling (SF) are critical building blocks\nin task-oriented dialogue systems. These two tasks are closely-related and can\nflourish each other. Since only a few utterances can be utilized for\nidentifying fast-emerging new intents and slots, data scarcity issue often\noccurs when implementing IC and SF. However, few IC/SF models perform well when\nthe number of training samples per class is quite small. In this paper, we\npropose a novel explicit-joint and supervised-contrastive learning framework\nfor few-shot intent classification and slot filling. Its highlights are as\nfollows. (i) The model extracts intent and slot representations via\nbidirectional interactions, and extends prototypical network to achieve\nexplicit-joint learning, which guarantees that IC and SF tasks can mutually\nreinforce each other. (ii) The model integrates with supervised contrastive\nlearning, which ensures that samples from same class are pulled together and\nsamples from different classes are pushed apart. In addition, the model follows\na not common but practical way to construct the episode, which gets rid of the\ntraditional setting with fixed way and shot, and allows for unbalanced\ndatasets. Extensive experiments on three public datasets show that our model\ncan achieve promising performance.", "published": "2021-10-26 13:28:28", "link": "http://arxiv.org/abs/2110.13691v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hierarchical Transformers Are More Efficient Language Models", "abstract": "Transformer models yield impressive results on many NLP and sequence modeling\ntasks. Remarkably, Transformers can handle long sequences which allows them to\nproduce long coherent outputs: full paragraphs produced by GPT-3 or\nwell-structured images produced by DALL-E. These large language models are\nimpressive but also very inefficient and costly, which limits their\napplications and accessibility. We postulate that having an explicit\nhierarchical architecture is the key to Transformers that efficiently handle\nlong sequences. To verify this claim, we first study different ways to\ndownsample and upsample activations in Transformers so as to make them\nhierarchical. We use the best performing upsampling and downsampling layers to\ncreate Hourglass - a hierarchical Transformer language model. Hourglass\nimproves upon the Transformer baseline given the same amount of computation and\ncan yield the same results as Transformers more efficiently. In particular,\nHourglass sets new state-of-the-art for Transformer models on the ImageNet32\ngeneration task and improves language modeling efficiency on the widely studied\nenwik8 benchmark.", "published": "2021-10-26 14:00:49", "link": "http://arxiv.org/abs/2110.13711v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs", "abstract": "Query embedding (QE) -- which aims to embed entities and first-order logical\n(FOL) queries in low-dimensional spaces -- has shown great power in multi-hop\nreasoning over knowledge graphs. Recently, embedding entities and queries with\ngeometric shapes becomes a promising direction, as geometric shapes can\nnaturally represent answer sets of queries and logical relationships among\nthem. However, existing geometry-based models have difficulty in modeling\nqueries with negation, which significantly limits their applicability. To\naddress this challenge, we propose a novel query embedding model, namely Cone\nEmbeddings (ConE), which is the first geometry-based QE model that can handle\nall the FOL operations, including conjunction, disjunction, and negation.\nSpecifically, ConE represents entities and queries as Cartesian products of\ntwo-dimensional cones, where the intersection and union of cones naturally\nmodel the conjunction and disjunction operations. By further noticing that the\nclosure of complement of cones remains cones, we design geometric complement\noperators in the embedding space for the negation operations. Experiments\ndemonstrate that ConE significantly outperforms existing state-of-the-art\nmethods on benchmark datasets.", "published": "2021-10-26 14:04:02", "link": "http://arxiv.org/abs/2110.13715v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "CLAUSEREC: A Clause Recommendation Framework for AI-aided Contract\n  Authoring", "abstract": "Contracts are a common type of legal document that frequent in several\nday-to-day business workflows. However, there has been very limited NLP\nresearch in processing such documents, and even lesser in generating them.\nThese contracts are made up of clauses, and the unique nature of these clauses\ncalls for specific methods to understand and generate such documents. In this\npaper, we introduce the task of clause recommendation, asa first step to aid\nand accelerate the author-ing of contract documents. We propose a two-staged\npipeline to first predict if a specific clause type is relevant to be added in\na contract, and then recommend the top clauses for the given type based on the\ncontract context. We pretrain BERT on an existing library of clauses with two\nadditional tasks and use it for our prediction and recommendation. We\nexperiment with classification methods and similarity-based heuristics for\nclause relevance prediction, and generation-based methods for clause\nrecommendation, and evaluate the results from various methods on several clause\ntypes. We provide analyses on the results, and further outline the advantages\nand limitations of the various methods for this line of research.", "published": "2021-10-26 09:20:16", "link": "http://arxiv.org/abs/2110.15794v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Probabilistic Entity Representation Model for Reasoning over Knowledge\n  Graphs", "abstract": "Logical reasoning over Knowledge Graphs (KGs) is a fundamental technique that\ncan provide efficient querying mechanism over large and incomplete databases.\nCurrent approaches employ spatial geometries such as boxes to learn query\nrepresentations that encompass the answer entities and model the logical\noperations of projection and intersection. However, their geometry is\nrestrictive and leads to non-smooth strict boundaries, which further results in\nambiguous answer entities. Furthermore, previous works propose transformation\ntricks to handle unions which results in non-closure and, thus, cannot be\nchained in a stream. In this paper, we propose a Probabilistic Entity\nRepresentation Model (PERM) to encode entities as a Multivariate Gaussian\ndensity with mean and covariance parameters to capture its semantic position\nand smooth decision boundary, respectively. Additionally, we also define the\nclosed logical operations of projection, intersection, and union that can be\naggregated using an end-to-end objective function. On the logical query\nreasoning problem, we demonstrate that the proposed PERM significantly\noutperforms the state-of-the-art methods on various public benchmark KG\ndatasets on standard evaluation metrics. We also evaluate PERM's competence on\na COVID-19 drug-repurposing case study and show that our proposed work is able\nto recommend drugs with substantially better F1 than current methods. Finally,\nwe demonstrate the working of our PERM's query answering process through a\nlow-dimensional visualization of the Gaussian representations.", "published": "2021-10-26 09:26:10", "link": "http://arxiv.org/abs/2110.13522v2", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "BioIE: Biomedical Information Extraction with Multi-head Attention\n  Enhanced Graph Convolutional Network", "abstract": "Constructing large-scaled medical knowledge graphs can significantly boost\nhealthcare applications for medical surveillance, bring much attention from\nrecent research. An essential step in constructing large-scale MKG is\nextracting information from medical reports. Recently, information extraction\ntechniques have been proposed and show promising performance in biomedical\ninformation extraction. However, these methods only consider limited types of\nentity and relation due to the noisy biomedical text data with complex entity\ncorrelations. Thus, they fail to provide enough information for constructing\nMKGs and restrict the downstream applications. To address this issue, we\npropose Biomedical Information Extraction, a hybrid neural network to extract\nrelations from biomedical text and unstructured medical reports. Our model\nutilizes a multi-head attention enhanced graph convolutional network to capture\nthe complex relations and context information while resisting the noise from\nthe data. We evaluate our model on two major biomedical relationship extraction\ntasks, chemical-disease relation and chemical-protein interaction, and a\ncross-hospital pan-cancer pathology report corpus. The results show that our\nmethod achieves superior performance than baselines. Furthermore, we evaluate\nthe applicability of our method under a transfer learning setting and show that\nBioIE achieves promising performance in processing medical text from different\nformats and writing styles.", "published": "2021-10-26 13:19:28", "link": "http://arxiv.org/abs/2110.13683v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Assessing Evaluation Metrics for Speech-to-Speech Translation", "abstract": "Speech-to-speech translation combines machine translation with speech\nsynthesis, introducing evaluation challenges not present in either task alone.\nHow to automatically evaluate speech-to-speech translation is an open question\nwhich has not previously been explored. Translating to speech rather than to\ntext is often motivated by unwritten languages or languages without\nstandardized orthographies. However, we show that the previously used automatic\nmetric for this task is best equipped for standardized high-resource languages\nonly. In this work, we first evaluate current metrics for speech-to-speech\ntranslation, and second assess how translation to dialectal variants rather\nthan to standardized languages impacts various evaluation methods.", "published": "2021-10-26 17:35:20", "link": "http://arxiv.org/abs/2110.13877v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Understanding Interlocking Dynamics of Cooperative Rationalization", "abstract": "Selective rationalization explains the prediction of complex neural networks\nby finding a small subset of the input that is sufficient to predict the neural\nmodel output. The selection mechanism is commonly integrated into the model\nitself by specifying a two-component cascaded system consisting of a rationale\ngenerator, which makes a binary selection of the input features (which is the\nrationale), and a predictor, which predicts the output based only on the\nselected features. The components are trained jointly to optimize prediction\nperformance. In this paper, we reveal a major problem with such cooperative\nrationalization paradigm -- model interlocking. Interlocking arises when the\npredictor overfits to the features selected by the generator thus reinforcing\nthe generator's selection even if the selected rationales are sub-optimal. The\nfundamental cause of the interlocking problem is that the rationalization\nobjective to be minimized is concave with respect to the generator's selection\npolicy. We propose a new rationalization framework, called A2R, which\nintroduces a third component into the architecture, a predictor driven by soft\nattention as opposed to selection. The generator now realizes both soft and\nhard attention over the features and these are fed into the two different\npredictors. While the generator still seeks to support the original predictor\nperformance, it also minimizes a gap between the two predictors. As we will\nshow theoretically, since the attention-based predictor exhibits a better\nconvexity property, A2R can overcome the concavity barrier. Our experiments on\ntwo synthetic benchmarks and two real datasets demonstrate that A2R can\nsignificantly alleviate the interlock problem and find explanations that better\nalign with human judgments. We release our code at\nhttps://github.com/Gorov/Understanding_Interlocking.", "published": "2021-10-26 17:39:18", "link": "http://arxiv.org/abs/2110.13880v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech\n  Processing", "abstract": "Self-supervised learning (SSL) achieves great success in speech recognition,\nwhile limited exploration has been attempted for other speech processing tasks.\nAs speech signal contains multi-faceted information including speaker identity,\nparalinguistics, spoken content, etc., learning universal representations for\nall speech tasks is challenging. To tackle the problem, we propose a new\npre-trained model, WavLM, to solve full-stack downstream speech tasks. WavLM\njointly learns masked speech prediction and denoising in pre-training. By this\nmeans, WavLM does not only keep the speech content modeling capability by the\nmasked speech prediction, but also improves the potential to non-ASR tasks by\nthe speech denoising. In addition, WavLM employs gated relative position bias\nfor the Transformer structure to better capture the sequence ordering of input\nspeech. We also scale up the training dataset from 60k hours to 94k hours.\nWavLM Large achieves state-of-the-art performance on the SUPERB benchmark, and\nbrings significant improvements for various speech processing tasks on their\nrepresentative benchmarks. The code and pre-trained models are available at\nhttps://aka.ms/wavlm.", "published": "2021-10-26 17:55:19", "link": "http://arxiv.org/abs/2110.13900v5", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Diachronic Text Mining Investigation of Therapeutic Candidates for\n  COVID-19", "abstract": "Diachronic text mining has frequently been applied to long-term linguistic\nsurveys of word meaning and usage shifts over time. In this paper we apply\nshort-term diachronic text mining to a rapidly growing corpus of scientific\npublications on COVID-19 captured in the CORD-19 dataset in order to identify\nco-occurrences and analyze the behavior of potential candidate treatments. We\nused a data set associated with a COVID-19 drug re-purposing study from Oak\nRidge National Laboratory. This study identified existing candidate coronavirus\ntreatments, including drugs and approved compounds, which had been analyzed and\nranked according to their potential for blocking the ability of the SARS-COV-2\nvirus to invade human cells. We investigated the occurrence of these candidates\nin temporal instances of the CORD-19 corpus. We found that at least 25% of the\nidentified terms occurred in temporal instances of the corpus to the extent\nthat their frequency and contextual dynamics could be evaluated. We identified\nthree classes of behaviors: those where frequency and contextual shifts were\nsmall and positively correlated; those where there was no correlation between\nfrequency and contextual changes; and those where there was a negative\ncorrelation between frequency and contextual shift. We speculate that the\nlatter two patterns are indicative that a target candidate therapeutics is\nundergoing active evaluation. The patterns we detected demonstrate the\npotential benefits of using diachronic text mining techniques with a large\ndynamic text corpus to track drug-repurposing activities across international\nclinical and laboratory settings.", "published": "2021-10-26 19:20:26", "link": "http://arxiv.org/abs/2110.13971v1", "categories": ["cs.CL", "cs.IR", "q-bio.OT"], "primary_category": "cs.CL"}
{"title": "DASentimental: Detecting depression, anxiety and stress in texts via\n  emotional recall, cognitive networks and machine learning", "abstract": "Most current affect scales and sentiment analysis on written text focus on\nquantifying valence (sentiment) -- the most primary dimension of emotion.\nHowever, emotions are broader and more complex than valence. Distinguishing\nnegative emotions of similar valence could be important in contexts such as\nmental health. This project proposes a semi-supervised machine learning model\n(DASentimental) to extract depression, anxiety and stress from written text.\nFirst, we trained the model to spot how sequences of recalled emotion words by\n$N=200$ individuals correlated with their responses to the Depression Anxiety\nStress Scale (DASS-21). Within the framework of cognitive network science, we\nmodel every list of recalled emotions as a walk over a networked mental\nrepresentation of semantic memory, with emotions connected according to free\nassociations in people's memory. Among several tested machine learning\napproaches, we find that a multilayer perceptron neural network trained on word\nsequences and semantic network distances can achieve state-of-art,\ncross-validated predictions for depression ($R = 0.7$), anxiety ($R = 0.44$)\nand stress ($R = 0.52$). Though limited by sample size, this first-of-its-kind\napproach enables quantitative explorations of key semantic dimensions behind\nDAS levels. We find that semantic distances between recalled emotions and the\ndyad \"sad-happy\" are crucial features for estimating depression levels but are\nless important for anxiety and stress. We also find that semantic distance of\nrecalls from \"fear\" can boost the prediction of anxiety but it becomes\nredundant when the \"sad-happy\" dyad is considered. Adopting DASentimental as a\nsemi-supervised learning tool to estimate DAS in text, we apply it to a dataset\nof 142 suicide notes. We conclude by discussing key directions for future\nresearch enabled by artificial intelligence detecting stress, anxiety and\ndepression.", "published": "2021-10-26 13:58:46", "link": "http://arxiv.org/abs/2110.13710v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CY"}
{"title": "Towards Audio Domain Adaptation for Acoustic Scene Classification using\n  Disentanglement Learning", "abstract": "The deployment of machine listening algorithms in real-life applications is\noften impeded by a domain shift caused for instance by different microphone\ncharacteristics. In this paper, we propose a novel domain adaptation strategy\nbased on disentanglement learning. The goal is to disentangle task-specific and\ndomain-specific characteristics in the analyzed audio recordings. In\nparticular, we combine two strategies: First, we apply different binary masks\nto internal embedding representations and, second, we suggest a novel\ncombination of categorical cross-entropy and variance-based losses. Our results\nconfirm the disentanglement of both tasks on an embedding level but show only\nminor improvement in the acoustic scene classification performance, when\ntraining data from both domains can be used. As a second finding, we can\nconfirm the effectiveness of a state-of-the-art unsupervised domain adaptation\nstrategy, which performs across-domain adaptation on a feature-level instead.", "published": "2021-10-26 11:39:42", "link": "http://arxiv.org/abs/2110.13586v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AQP: An Open Modular Python Platform for Objective Speech and Audio\n  Quality Metrics", "abstract": "Audio quality assessment has been widely researched in the signal processing\narea. Full-reference objective metrics (e.g., POLQA, ViSQOL) have been\ndeveloped to estimate the audio quality relying only on human rating\nexperiments. To evaluate the audio quality of novel audio processing\ntechniques, researchers constantly need to compare objective quality metrics.\nTesting different implementations of the same metric and evaluating new\ndatasets are fundamental and ongoing iterative activities. In this paper, we\npresent AQP - an open-source, node-based, light-weight Python pipeline for\naudio quality assessment. AQP allows researchers to test and compare objective\nquality metrics helping to improve robustness, reproducibility and development\nspeed. We introduce the platform, explain the motivations, and illustrate with\nexamples how, using AQP, objective quality metrics can be (i) compared and\nbenchmarked; (ii) prototyped and adapted in a modular fashion; (iii) visualised\nand checked for errors. The code has been shared on GitHub to encourage\nadoption and contributions from the community.", "published": "2021-10-26 11:43:02", "link": "http://arxiv.org/abs/2110.13589v2", "categories": ["cs.SD", "eess.AS", "H.5.5; D.2.11; D.2.13"], "primary_category": "cs.SD"}
{"title": "CS-Rep: Making Speaker Verification Networks Embracing\n  Re-parameterization", "abstract": "Automatic speaker verification (ASV) systems, which determine whether two\nspeeches are from the same speaker, mainly focus on verification accuracy while\nignoring inference speed. However, in real applications, both inference speed\nand verification accuracy are essential. This study proposes cross-sequential\nre-parameterization (CS-Rep), a novel topology re-parameterization strategy for\nmulti-type networks, to increase the inference speed and verification accuracy\nof models. CS-Rep solves the problem that existing re-parameterization methods\nare unsuitable for typical ASV backbones. When a model applies CS-Rep, the\ntraining-period network utilizes a multi-branch topology to capture speaker\ninformation, whereas the inference-period model converts to a time-delay neural\nnetwork (TDNN)-like plain backbone with stacked TDNN layers to achieve the fast\ninference speed. Based on CS-Rep, an improved TDNN with friendly test and\ndeployment called Rep-TDNN is proposed. Compared with the state-of-the-art\nmodel ECAPA-TDNN, which is highly recognized in the industry, Rep-TDNN\nincreases the actual inference speed by about 50% and reduces the EER by 10%.\nThe code will be released.", "published": "2021-10-26 08:00:03", "link": "http://arxiv.org/abs/2110.13465v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers\n  and Self-supervised Pretraining", "abstract": "We introduce a block-online variant of the temporal feature-wise linear\nmodulation (TFiLM) model to achieve bandwidth extension. The proposed\narchitecture simplifies the UNet backbone of the TFiLM to reduce inference time\nand employs an efficient transformer at the bottleneck to alleviate performance\ndegradation. We also utilize self-supervised pretraining and data augmentation\nto enhance the quality of bandwidth extended signals and reduce the sensitivity\nwith respect to downsampling methods. Experiment results on the VCTK dataset\nshow that the proposed method outperforms several recent baselines in both\nintrusive and non-intrusive metrics. Pretraining and filter augmentation also\nhelp stabilize and enhance the overall performance.", "published": "2021-10-26 08:43:46", "link": "http://arxiv.org/abs/2110.13492v5", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
