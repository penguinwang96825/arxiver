{"title": "RSL19BD at DBDC4: Ensemble of Decision Tree-based and LSTM-based Models", "abstract": "RSL19BD (Waseda University Sakai Laboratory) participated in the Fourth\nDialogue Breakdown Detection Challenge (DBDC4) and submitted five runs to both\nEnglish and Japanese subtasks. In these runs, we utilise the Decision\nTree-based model and the Long Short-Term Memory-based (LSTM-based) model\nfollowing the approaches of RSL17BD and KTH in the Third Dialogue Breakdown\nDetection Challenge (DBDC3) respectively. The Decision Tree-based model follows\nthe approach of RSL17BD but utilises RandomForestRegressor instead of\nExtraTreesRegressor. In addition, instead of predicting the mean and the\nvariance of the probability distribution of the three breakdown labels, it\npredicts the probability of each label directly. The LSTM-based model follows\nthe approach of KTH with some changes in the architecture and utilises\nConvolutional Neural Network (CNN) to perform text feature extraction. In\naddition, instead of targeting the single breakdown label and minimising the\ncategorical cross entropy loss, it targets the probability distribution of the\nthree breakdown labels and minimises the mean squared error. Run 1 utilises a\nDecision Tree-based model; Run 2 utilises an LSTM-based model; Run 3 performs\nan ensemble of 5 LSTM-based models; Run 4 performs an ensemble of Run 1 and Run\n2; Run 5 performs an ensemble of Run 1 and Run 3. Run 5 statistically\nsignificantly outperformed all other runs in terms of MSE (NB, PB, B) for the\nEnglish data and all other runs except Run 4 in terms of MSE (NB, PB, B) for\nthe Japanese data (alpha level = 0.05).", "published": "2019-05-06 02:39:31", "link": "http://arxiv.org/abs/1905.01799v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Large Parallel Corpus of Full-Text Scientific Articles", "abstract": "The Scielo database is an important source of scientific information in Latin\nAmerica, containing articles from several research domains. A striking\ncharacteristic of Scielo is that many of its full-text contents are presented\nin more than one language, thus being a potential source of parallel corpora.\nIn this article, we present the development of a parallel corpus from Scielo in\nthree languages: English, Portuguese, and Spanish. Sentences were automatically\naligned using the Hunalign algorithm for all language pairs, and for a subset\nof trilingual articles also. We demonstrate the capabilities of our corpus by\ntraining a Statistical Machine Translation system (Moses) for each language\npair, which outperformed related works on scientific articles. Sentence\nalignment was also manually evaluated, presenting an average of 98.8% correctly\naligned sentences across all languages. Our parallel corpus is freely available\nin the TMX format, with complementary information regarding article metadata.", "published": "2019-05-06 07:33:00", "link": "http://arxiv.org/abs/1905.01852v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UFRGS Participation on the WMT Biomedical Translation Shared Task", "abstract": "This paper describes the machine translation systems developed by the\nUniversidade Federal do Rio Grande do Sul (UFRGS) team for the biomedical\ntranslation shared task. Our systems are based on statistical machine\ntranslation and neural machine translation, using the Moses and OpenNMT\ntoolkits, respectively. We participated in four translation directions for the\nEnglish/Spanish and English/Portuguese language pairs. To create our training\ndata, we concatenated several parallel corpora, both from in-domain and\nout-of-domain sources, as well as terminological resources from UMLS. Our\nsystems achieved the best BLEU scores according to the official shared task\nevaluation.", "published": "2019-05-06 07:36:59", "link": "http://arxiv.org/abs/1905.01855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distributional Semantics and Linguistic Theory", "abstract": "Distributional semantics provides multi-dimensional, graded, empirically\ninduced word representations that successfully capture many aspects of meaning\nin natural languages, as shown in a large body of work in computational\nlinguistics; yet, its impact in theoretical linguistics has so far been\nlimited. This review provides a critical discussion of the literature on\ndistributional semantics, with an emphasis on methods and results that are of\nrelevance for theoretical linguistics, in three areas: semantic change,\npolysemy and composition, and the grammar-semantics interface (specifically,\nthe interface of semantics with syntax and with derivational morphology). The\nreview aims at fostering greater cross-fertilization of theoretical and\ncomputational approaches to language, as a means to advance our collective\nknowledge of how it works.", "published": "2019-05-06 09:32:28", "link": "http://arxiv.org/abs/1905.01896v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "English-Bhojpuri SMT System: Insights from the Karaka Model", "abstract": "This thesis has been divided into six chapters namely: Introduction, Karaka\nModel and it impacts on Dependency Parsing, LT Resources for Bhojpuri,\nEnglish-Bhojpuri SMT System: Experiment, Evaluation of EB-SMT System, and\nConclusion. Chapter one introduces this PhD research by detailing the\nmotivation of the study, the methodology used for the study and the literature\nreview of the existing MT related work in Indian Languages. Chapter two talks\nof the theoretical background of Karaka and Karaka model. Along with this, it\ntalks about previous related work. It also discusses the impacts of the Karaka\nmodel in NLP and dependency parsing. It compares Karaka dependency and\nUniversal Dependency. It also presents a brief idea of the implementation of\nthese models in the SMT system for English-Bhojpuri language pair.", "published": "2019-05-06 19:04:57", "link": "http://arxiv.org/abs/1905.02239v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comprehensible Context-driven Text Game Playing", "abstract": "In order to train a computer agent to play a text-based computer game, we\nmust represent each hidden state of the game. A Long Short-Term Memory (LSTM)\nmodel running over observed texts is a common choice for state construction.\nHowever, a normal Deep Q-learning Network (DQN) for such an agent requires\nmillions of steps of training or more to converge. As such, an LSTM-based DQN\ncan take tens of days to finish the training process. Though we can use a\nConvolutional Neural Network (CNN) as a text-encoder to construct states much\nfaster than the LSTM, doing so without an understanding of the syntactic\ncontext of the words being analyzed can slow convergence. In this paper, we use\na fast CNN to encode position- and syntax-oriented structures extracted from\nobserved texts as states. We additionally augment the reward signal in a\nuniversal and practical manner. Together, we show that our improvements can not\nonly speed up the process by one order of magnitude but also learn a superior\nagent.", "published": "2019-05-06 21:14:41", "link": "http://arxiv.org/abs/1905.02265v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anonymized BERT: An Augmentation Approach to the Gendered Pronoun\n  Resolution Challenge", "abstract": "We present our 7th place solution to the Gendered Pronoun Resolution\nchallenge, which uses BERT without fine-tuning and a novel augmentation\nstrategy designed for contextual embedding token-level tasks. Our method\nanonymizes the referent by replacing candidate names with a set of common\nplaceholder names. Besides the usual benefits of effectively increasing\ntraining data size, this approach diversifies idiosyncratic information\nembedded in names. Using same set of common first names can also help the model\nrecognize names better, shorten token length, and remove gender and regional\nbiases associated with names. The system scored 0.1947 log loss in stage 2,\nwhere the augmentation contributed to an improvements of 0.04. Post-competition\nanalysis shows that, when using different embedding layers, the system scores\n0.1799 which would be third place.", "published": "2019-05-06 01:16:33", "link": "http://arxiv.org/abs/1905.01780v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Caveats in Generating Medical Imaging Labels from Radiology Reports", "abstract": "Acquiring high-quality annotations in medical imaging is usually a costly\nprocess. Automatic label extraction with natural language processing (NLP) has\nemerged as a promising workaround to bypass the need of expert annotation.\nDespite the convenience, the limitation of such an approximation has not been\ncarefully examined and is not well understood. With a challenging set of 1,000\nchest X-ray studies and their corresponding radiology reports, we show that\nthere exists a surprisingly large discrepancy between what radiologists\nvisually perceive and what they clinically report. Furthermore, with inherently\nflawed report as ground truth, the state-of-the-art medical NLP fails to\nproduce high-fidelity labels.", "published": "2019-05-06 22:38:18", "link": "http://arxiv.org/abs/1905.02283v1", "categories": ["cs.CL", "cs.CV", "eess.IV"], "primary_category": "cs.CL"}
{"title": "Topology of Networks in Generalized Musical Spaces", "abstract": "The abstraction of musical structures (notes, melodies, chords, harmonic or\nrhythmic progressions, etc.) as mathematical objects in a geometrical space is\none of the great accomplishments of contemporary music theory. Building on this\nfoundation, I generalize the concept of musical spaces as networks and derive\nfunctional principles of compositional design by the direct analysis of the\nnetwork topology. This approach provides a novel framework for the analysis and\nquantification of similarity of musical objects and structures, and suggests a\nway to relate such measures to the human perception of different musical\nentities. Finally, the analysis of a single work or a corpus of compositions as\ncomplex networks provides alternative ways of interpreting the compositional\nprocess of a composer by quantifying emergent behaviors with well-established\nstatistical mechanics techniques. Interpreting the latter as probabilistic\nrandomness in the network, I develop novel compositional design frameworks that\nare central to my own artistic research.", "published": "2019-05-06 06:59:24", "link": "http://arxiv.org/abs/1905.01842v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Investigating kernel shapes and skip connections for deep learning-based\n  harmonic-percussive separation", "abstract": "In this paper we propose an efficient deep learning encoder-decoder network\nfor performing Harmonic-Percussive Source Separation (HPSS). It is shown that\nwe are able to greatly reduce the number of model trainable parameters by using\na dense arrangement of skip connections between the model layers. We also\nexplore the utilisation of different kernel sizes for the 2D filters of the\nconvolutional layers with the objective of allowing the network to learn the\ndifferent time-frequency patterns associated with percussive and harmonic\nsources more efficiently. The training and evaluation of the separation has\nbeen done using the training and test sets of the MUSDB18 dataset. Results show\nthat the proposed deep network achieves automatic learning of high-level\nfeatures and maintains HPSS performance at a state-of-the-art level while\nreducing the number of parameters and training time.", "published": "2019-05-06 09:47:44", "link": "http://arxiv.org/abs/1905.01899v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning with Learned Loss Function: Speech Enhancement with Quality-Net\n  to Improve Perceptual Evaluation of Speech Quality", "abstract": "Utilizing a human-perception-related objective function to train a speech\nenhancement model has become a popular topic recently. The main reason is that\nthe conventional mean squared error (MSE) loss cannot represent auditory\nperception well. One of the typical hu-man-perception-related metrics, which is\nthe perceptual evaluation of speech quality (PESQ), has been proven to provide\na high correlation to the quality scores rated by humans. Owing to its complex\nand non-differentiable properties, however, the PESQ function may not be used\nto optimize speech enhancement models directly. In this study, we propose\noptimizing the enhancement model with an approximated PESQ function, which is\ndifferentiable and learned from the training data. The experimental results\nshow that the learned surrogate function can guide the enhancement model to\nfurther boost the PESQ score (in-crease of 0.18 points compared to the results\ntrained with MSE loss) and maintain the speech intelligibility.", "published": "2019-05-06 09:46:37", "link": "http://arxiv.org/abs/1905.01898v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Zero-Shot Audio Classification Based on Class Label Embeddings", "abstract": "This paper proposes a zero-shot learning approach for audio classification\nbased on the textual information about class labels without any audio samples\nfrom target classes. We propose an audio classification system built on the\nbilinear model, which takes audio feature embeddings and semantic class label\nembeddings as input, and measures the compatibility between an audio feature\nembedding and a class label embedding. We use VGGish to extract audio feature\nembeddings from audio recordings. We treat textual labels as semantic side\ninformation of audio classes, and use Word2Vec to generate class label\nembeddings. Results on the ESC-50 dataset show that the proposed system can\nperform zero-shot audio classification with small training dataset. It can\nachieve accuracy (26 % on average) better than random guess (10 %) on each\naudio category. Particularly, it reaches up to 39.7 % for the category of\nnatural audio classes.", "published": "2019-05-06 11:08:08", "link": "http://arxiv.org/abs/1905.01926v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
