{"title": "Deep Feelings: A Massive Cross-Lingual Study on the Relation between\n  Emotions and Virality", "abstract": "This article provides a comprehensive investigation on the relations between\nvirality of news articles and the emotions they are found to evoke. Virality,\nin our view, is a phenomenon with many facets, i.e. under this generic term\nseveral different effects of persuasive communication are comprised. By\nexploiting a high-coverage and bilingual corpus of documents containing metrics\nof their spread on social networks as well as a massive affective annotation\nprovided by readers, we present a thorough analysis of the interplay between\nevoked emotions and viral facets. We highlight and discuss our findings in\nlight of a cross-lingual approach: while we discover differences in evoked\nemotions and corresponding viral effects, we provide preliminary evidence of a\ngeneralized explanatory model rooted in the deep structure of emotions: the\nValence-Arousal-Dominance (VAD) circumplex. We find that viral facets appear to\nbe consistently affected by particular VAD configurations, and these\nconfigurations indicate a clear connection with distinct phenomena underlying\npersuasive communication.", "published": "2015-03-16 16:43:58", "link": "http://arxiv.org/abs/1503.04723v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "Long Short-Term Memory Over Tree Structures", "abstract": "The chain-structured long short-term memory (LSTM) has showed to be effective\nin a wide range of problems such as speech recognition and machine translation.\nIn this paper, we propose to extend it to tree structures, in which a memory\ncell can reflect the history memories of multiple child cells or multiple\ndescendant cells in a recursive process. We call the model S-LSTM, which\nprovides a principled way of considering long-distance interaction over\nhierarchies, e.g., language or image parse structures. We leverage the models\nfor semantic composition to understand the meaning of text, a fundamental\nproblem in natural language understanding, and show that it outperforms a\nstate-of-the-art recursive model by replacing its composition layers with the\nS-LSTM memory blocks. We also show that utilizing the given structures is\nhelpful in achieving a performance better than that without considering the\nstructures.", "published": "2015-03-16 23:59:02", "link": "http://arxiv.org/abs/1503.04881v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
