{"title": "Recurrent Neural Network-Based Sentence Encoder with Gated Attention for\n  Natural Language Inference", "abstract": "The RepEval 2017 Shared Task aims to evaluate natural language understanding\nmodels for sentence representation, in which a sentence is represented as a\nfixed-length vector with neural networks and the quality of the representation\nis tested with a natural language inference task. This paper describes our\nsystem (alpha) that is ranked among the top in the Shared Task, on both the\nin-domain test set (obtaining a 74.9% accuracy) and on the cross-domain test\nset (also attaining a 74.9% accuracy), demonstrating that the model generalizes\nwell to the cross-domain data. Our model is equipped with intra-sentence\ngated-attention composition which helps achieve a better performance. In\naddition to submitting our model to the Shared Task, we have also tested it on\nthe Stanford Natural Language Inference (SNLI) dataset. We obtain an accuracy\nof 85.5%, which is the best reported result on SNLI when cross-sentence\nattention is not allowed, the same condition enforced in RepEval 2017.", "published": "2017-08-04 01:55:18", "link": "http://arxiv.org/abs/1708.01353v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Massively Multilingual Neural Grapheme-to-Phoneme Conversion", "abstract": "Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and\nautomatic speech recognition systems. Most g2p systems are monolingual: they\nrequire language-specific data or handcrafting of rules. Such systems are\ndifficult to extend to low resource languages, for which data and handcrafted\nrules are not available. As an alternative, we present a neural\nsequence-to-sequence approach to g2p which is trained on\nspelling--pronunciation pairs in hundreds of languages. The system shares a\nsingle encoder and decoder across all languages, allowing it to utilize the\nintrinsic similarities between different writing systems. We show an 11%\nimprovement in phoneme error rate over an approach based on adapting\nhigh-resource monolingual g2p models to low-resource languages. Our model is\nalso much more compact relative to previous approaches.", "published": "2017-08-04 11:57:02", "link": "http://arxiv.org/abs/1708.01464v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting the Law Area and Decisions of French Supreme Court Cases", "abstract": "In this paper, we investigate the application of text classification methods\nto predict the law area and the decision of cases judged by the French Supreme\nCourt. We also investigate the influence of the time period in which a ruling\nwas made over the textual form of the case description and the extent to which\nit is necessary to mask the judge's motivation for a ruling to emulate a\nreal-world test scenario. We report results of 96% f1 score in predicting a\ncase ruling, 90% f1 score in predicting the law area of a case, and 75.9% f1\nscore in estimating the time span when a ruling has been issued using a linear\nSupport Vector Machine (SVM) classifier trained on lexical features.", "published": "2017-08-04 23:10:31", "link": "http://arxiv.org/abs/1708.01681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MemexQA: Visual Memex Question Answering", "abstract": "This paper proposes a new task, MemexQA: given a collection of photos or\nvideos from a user, the goal is to automatically answer questions that help\nusers recover their memory about events captured in the collection. Towards\nsolving the task, we 1) present the MemexQA dataset, a large, realistic\nmultimodal dataset consisting of real personal photos and crowd-sourced\nquestions/answers, 2) propose MemexNet, a unified, end-to-end trainable network\narchitecture for image, text and video question answering. Experimental results\non the MemexQA dataset demonstrate that MemexNet outperforms strong baselines\nand yields the state-of-the-art on this novel and challenging task. The\npromising results on TextQA and VideoQA suggest MemexNet's efficacy and\nscalability across various QA tasks.", "published": "2017-08-04 00:17:48", "link": "http://arxiv.org/abs/1708.01336v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Hashtag Healthcare: From Tweets to Mental Health Journals Using Deep\n  Transfer Learning", "abstract": "As the popularity of social media platforms continues to rise, an\never-increasing amount of human communication and self- expression takes place\nonline. Most recent research has focused on mining social media for public user\nopinion about external entities such as product reviews or sentiment towards\npolitical news. However, less attention has been paid to analyzing users'\ninternalized thoughts and emotions from a mental health perspective. In this\npaper, we quantify the semantic difference between public Tweets and private\nmental health journals used in online cognitive behavioral therapy. We will use\ndeep transfer learning techniques for analyzing the semantic gap between the\ntwo domains. We show that for the task of emotional valence prediction, social\nmedia can be successfully harnessed to create more accurate, robust, and\npersonalized mental health models. Our results suggest that the semantic gap\nbetween public and private self-expression is small, and that utilizing the\nabundance of available social media is one way to overcome the small sample\nsizes of mental health data, which are commonly limited by availability and\nprivacy concerns.", "published": "2017-08-04 03:47:35", "link": "http://arxiv.org/abs/1708.01372v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "The Argument Reasoning Comprehension Task: Identification and\n  Reconstruction of Implicit Warrants", "abstract": "Reasoning is a crucial part of natural language argumentation. To comprehend\nan argument, one must analyze its warrant, which explains why its claim follows\nfrom its premises. As arguments are highly contextualized, warrants are usually\npresupposed and left implicit. Thus, the comprehension does not only require\nlanguage understanding and logic skills, but also depends on common sense. In\nthis paper we develop a methodology for reconstructing warrants systematically.\nWe operationalize it in a scalable crowdsourcing process, resulting in a freely\nlicensed dataset with warrants for 2k authentic arguments from news comments.\nOn this basis, we present a new challenging task, the argument reasoning\ncomprehension task. Given an argument with a claim and a premise, the goal is\nto choose the correct implicit warrant from two options. Both warrants are\nplausible and lexically close, but lead to contradicting claims. A solution to\nthis task will define a substantial step towards automatic warrant\nreconstruction. However, experiments with several neural attention and language\nmodels reveal that current approaches do not suffice.", "published": "2017-08-04 08:46:03", "link": "http://arxiv.org/abs/1708.01425v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Speaker-Independent Lipreading with Domain-Adversarial\n  Training", "abstract": "We present a Lipreading system, i.e. a speech recognition system using only\nvisual features, which uses domain-adversarial training for speaker\nindependence. Domain-adversarial training is integrated into the optimization\nof a lipreader based on a stack of feedforward and LSTM (Long Short-Term\nMemory) recurrent neural networks, yielding an end-to-end trainable system\nwhich only requires a very small number of frames of untranscribed target data\nto substantially improve the recognition accuracy on the target speaker. On\npairs of different source and target speakers, we achieve a relative accuracy\nimprovement of around 40% with only 15 to 20 seconds of untranscribed target\nspeech data. On multi-speaker training setups, the accuracy improvements are\nsmaller but still substantial.", "published": "2017-08-04 15:57:38", "link": "http://arxiv.org/abs/1708.01565v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Measure for Dialog Complexity and its Application in Streamlining\n  Service Operations", "abstract": "Dialog is a natural modality for interaction between customers and businesses\nin the service industry. As customers call up the service provider, their\ninteractions may be routine or extraordinary. We believe that these\ninteractions, when seen as dialogs, can be analyzed to obtain a better\nunderstanding of customer needs and how to efficiently address them. We\nintroduce the idea of a dialog complexity measure to characterize multi-party\ninteractions, propose a general data-driven method to calculate it, use it to\ndiscover insights in public and enterprise dialog datasets, and demonstrate its\nbeneficial usage in facilitating better handling of customer requests and\nevaluating service agents.", "published": "2017-08-04 03:44:35", "link": "http://arxiv.org/abs/1708.04134v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Language Design as Information Renormalization", "abstract": "Here we consider some well-known facts in syntax from a physics perspective,\nallowing us to establish equivalences between both fields with many\nconsequences. Mainly, we observe that the operation MERGE, put forward by N.\nChomsky in 1995, can be interpreted as a physical information coarse-graining.\nThus, MERGE in linguistics entails information renormalization in physics,\naccording to different time scales. We make this point mathematically formal in\nterms of language models. In this setting, MERGE amounts to a probability\ntensor implementing a coarse-graining, akin to a probabilistic context-free\ngrammar. The probability vectors of meaningful sentences are given by\nstochastic tensor networks (TN) built from diagonal tensors and which are\nmostly loop-free, such as Tree Tensor Networks and Matrix Product States, thus\nbeing computationally very efficient to manipulate. We show that this implies\nthe polynomially-decaying (long-range) correlations experimentally observed in\nlanguage, and also provides arguments in favour of certain types of neural\nnetworks for language processing. Moreover, we show how to obtain such language\nmodels from quantum states that can be efficiently prepared on a quantum\ncomputer, and use this to find bounds on the perplexity of the probability\ndistribution of words in a sentence. Implications of our results are discussed\nacross several ambits.", "published": "2017-08-04 14:35:38", "link": "http://arxiv.org/abs/1708.01525v5", "categories": ["cs.CL", "cond-mat.str-el", "physics.hist-ph", "quant-ph"], "primary_category": "cs.CL"}
{"title": "A network approach to topic models", "abstract": "One of the main computational and scientific challenges in the modern age is\nto extract useful information from unstructured texts. Topic models are one\npopular machine-learning approach which infers the latent topical structure of\na collection of documents. Despite their success --- in particular of its most\nwidely used variant called Latent Dirichlet Allocation (LDA) --- and numerous\napplications in sociology, history, and linguistics, topic models are known to\nsuffer from severe conceptual and practical problems, e.g. a lack of\njustification for the Bayesian priors, discrepancies with statistical\nproperties of real texts, and the inability to properly choose the number of\ntopics. Here we obtain a fresh view on the problem of identifying topical\nstructures by relating it to the problem of finding communities in complex\nnetworks. This is achieved by representing text corpora as bipartite networks\nof documents and words. By adapting existing community-detection methods --\nusing a stochastic block model (SBM) with non-parametric priors -- we obtain a\nmore versatile and principled framework for topic modeling (e.g., it\nautomatically detects the number of topics and hierarchically clusters both the\nwords and documents). The analysis of artificial and real corpora demonstrates\nthat our SBM approach leads to better topic models than LDA in terms of\nstatistical model selection. More importantly, our work shows how to formally\nrelate methods from community detection and topic modeling, opening the\npossibility of cross-fertilization between these two fields.", "published": "2017-08-04 22:35:50", "link": "http://arxiv.org/abs/1708.01677v2", "categories": ["stat.ML", "cs.CL", "physics.data-an", "physics.soc-ph"], "primary_category": "stat.ML"}
