{"title": "Can recursive neural tensor networks learn logical reasoning?", "abstract": "Recursive neural network models and their accompanying vector representations\nfor words have seen success in an array of increasingly semantically\nsophisticated tasks, but almost nothing is known about their ability to\naccurately capture the aspects of linguistic meaning that are necessary for\ninterpretation or reasoning. To evaluate this, I train a recursive model on a\nnew corpus of constructed examples of logical reasoning in short sentences,\nlike the inference of \"some animal walks\" from \"some dog walks\" or \"some cat\nwalks,\" given that dogs and cats are animals. This model learns representations\nthat generalize well to new types of reasoning pattern in all but a few cases,\na result which is promising for the ability of learned representation models to\ncapture logical reasoning.", "published": "2013-12-21 02:29:42", "link": "http://arxiv.org/abs/1312.6192v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
