{"title": "MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For\n  Text-to-SQL Generation", "abstract": "Recent advancements in large language models (LLMs) have enabled in-context\nlearning (ICL)-based methods that significantly outperform fine-tuning\napproaches for text-to-SQL tasks. However, their performance is still\nconsiderably lower than that of human experts on benchmarks that include\ncomplex schemas and queries, such as BIRD. This study considers the sensitivity\nof LLMs to the prompts and introduces a novel approach that leverages multiple\nprompts to explore a broader search space for possible answers and effectively\naggregate them. Specifically, we robustly refine the database schema through\nschema linking using multiple prompts. Thereafter, we generate various\ncandidate SQL queries based on the refined schema and diverse prompts. Finally,\nthe candidate queries are filtered based on their confidence scores, and the\noptimal query is obtained through a multiple-choice selection that is presented\nto the LLM. When evaluated on the BIRD and Spider benchmarks, the proposed\nmethod achieved execution accuracies of 65.5\\% and 89.6\\%, respectively,\nsignificantly outperforming previous ICL-based methods. Moreover, we\nestablished a new SOTA performance on the BIRD in terms of both the accuracy\nand efficiency of the generated queries.", "published": "2024-05-13 04:59:32", "link": "http://arxiv.org/abs/2405.07467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning the SwissBERT Encoder Model for Embedding Sentences and\n  Documents", "abstract": "Encoder models trained for the embedding of sentences or short documents have\nproven useful for tasks such as semantic search and topic modeling. In this\npaper, we present a version of the SwissBERT encoder model that we specifically\nfine-tuned for this purpose. SwissBERT contains language adapters for the four\nnational languages of Switzerland -- German, French, Italian, and Romansh --\nand has been pre-trained on a large number of news articles in those languages.\nUsing contrastive learning based on a subset of these articles, we trained a\nfine-tuned version, which we call SentenceSwissBERT. Multilingual experiments\non document retrieval and text classification in a Switzerland-specific setting\nshow that SentenceSwissBERT surpasses the accuracy of the original SwissBERT\nmodel and of a comparable baseline. The model is openly available for research\nuse.", "published": "2024-05-13 07:20:21", "link": "http://arxiv.org/abs/2405.07513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EMS-SD: Efficient Multi-sample Speculative Decoding for Accelerating\n  Large Language Models", "abstract": "Speculative decoding emerges as a pivotal technique for enhancing the\ninference speed of Large Language Models (LLMs). Despite recent research aiming\nto improve prediction efficiency, multi-sample speculative decoding has been\noverlooked due to varying numbers of accepted tokens within a batch in the\nverification phase. Vanilla method adds padding tokens in order to ensure that\nthe number of new tokens remains consistent across samples. However, this\nincreases the computational and memory access overhead, thereby reducing the\nspeedup ratio. We propose a novel method that can resolve the issue of\ninconsistent tokens accepted by different samples without necessitating an\nincrease in memory or computing overhead. Furthermore, our proposed method can\nhandle the situation where the prediction tokens of different samples are\ninconsistent without the need to add padding tokens. Sufficient experiments\ndemonstrate the efficacy of our method. Our code is available at\nhttps://github.com/niyunsheng/EMS-SD.", "published": "2024-05-13 08:24:21", "link": "http://arxiv.org/abs/2405.07542v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thai Universal Dependency Treebank", "abstract": "Automatic dependency parsing of Thai sentences has been underexplored, as\nevidenced by the lack of large Thai dependency treebanks with complete\ndependency structures and the lack of a published systematic evaluation of\nstate-of-the-art models, especially transformer-based parsers. In this work, we\naddress these problems by introducing Thai Universal Dependency Treebank (TUD),\na new largest Thai treebank consisting of 3,627 trees annotated in accordance\nwith the Universal Dependencies (UD) framework. We then benchmark dependency\nparsing models that incorporate pretrained transformers as encoders and train\nthem on Thai-PUD and our TUD. The evaluation results show that most of our\nmodels can outperform other models reported in previous papers and provide\ninsight into the optimal choices of components to include in Thai dependency\nparsers. The new treebank and every model's full prediction generated in our\nexperiment are made available on a GitHub repository for further study.", "published": "2024-05-13 09:48:13", "link": "http://arxiv.org/abs/2405.07586v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Model-Theoretic Approaches to Uncover Linguistic Organization", "abstract": "In this paper, we consider pluractional markers in Kaqchikel, Karuk, and\nYurok. Like Balinese, each of these languages marks one type of pluractionality\nvia reduplication, and a different type of pluractionality via\nnon-reduplicative affixation. This paper serves as a proof-of-concept for\napplying model-theoretic approaches to language as a lens that can help us to\nrecognize linguistic organization that is not apparent on the surface.", "published": "2024-05-13 09:58:59", "link": "http://arxiv.org/abs/2405.07597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViWikiFC: Fact-Checking for Vietnamese Wikipedia-Based Textual Knowledge\n  Source", "abstract": "Fact-checking is essential due to the explosion of misinformation in the\nmedia ecosystem. Although false information exists in every language and\ncountry, most research to solve the problem mainly concentrated on huge\ncommunities like English and Chinese. Low-resource languages like Vietnamese\nare necessary to explore corpora and models for fact verification. To bridge\nthis gap, we construct ViWikiFC, the first manual annotated open-domain corpus\nfor Vietnamese Wikipedia Fact Checking more than 20K claims generated by\nconverting evidence sentences extracted from Wikipedia articles. We analyze our\ncorpus through many linguistic aspects, from the new dependency rate, the new\nn-gram rate, and the new word rate. We conducted various experiments for\nVietnamese fact-checking, including evidence retrieval and verdict prediction.\nBM25 and InfoXLM (Large) achieved the best results in two tasks, with BM25\nachieving an accuracy of 88.30% for SUPPORTS, 86.93% for REFUTES, and only\n56.67% for the NEI label in the evidence retrieval task, InfoXLM (Large)\nachieved an F1 score of 86.51%. Furthermore, we also conducted a pipeline\napproach, which only achieved a strict accuracy of 67.00% when using InfoXLM\n(Large) and BM25. These results demonstrate that our dataset is challenging for\nthe Vietnamese language model in fact-checking tasks.", "published": "2024-05-13 10:24:05", "link": "http://arxiv.org/abs/2405.07615v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COBias and Debias: Balancing Class Accuracies for Language Models in\n  Inference Time via Nonlinear Integer Programming", "abstract": "Large language models (LLMs) are good knowledge bases but struggle to perform\nequally well for all classes in text classification tasks. This paper\ninvestigates a fundamental inference-time problem in language models:\nimbalanced class accuracies. We find what's underneath the issue is a tendency\nto over-predict some classes while under-predicting some others. This class\naccuracy imbalance is difficult to solve from the root via better pre-training\nor fine-tuning strategies, but we show it can be effectively mitigated via\ninference-time combinatorial optimization. To this end, we conceptualize and\nquantify the over- and under-prediction issue as the Contextual Oddity Bias\n(COBias), and propose the Debiasing as Nonlinear Integer Programming (DNIP)\nmodel to correct in-context learned class probabilities based on minimizing\nCOBias and maximizing overall accuracy, without LLM parameter update.\nConsidering that the DNIP model implicitly contains non-differentiable\nelements, we therefore use the simulated annealing algorithm to solve it.\nExtensive evaluations on three LLMs across seven NLP classification tasks in\ndifferent prompting settings show that DNIP simultaneously achieves significant\nCOBias reduction (-27%) and accuracy improvement (+12%) over the conventional\nICL approach, suggesting that inference-time mitigation of class accuracy\nimbalance is a promising direction to push forward LLM performances.", "published": "2024-05-13 10:30:33", "link": "http://arxiv.org/abs/2405.07623v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study on the Robustness of Massively Multilingual Neural\n  Machine Translation", "abstract": "Massively multilingual neural machine translation (MMNMT) has been proven to\nenhance the translation quality of low-resource languages. In this paper, we\nempirically investigate the translation robustness of Indonesian-Chinese\ntranslation in the face of various naturally occurring noise. To assess this,\nwe create a robustness evaluation benchmark dataset for Indonesian-Chinese\ntranslation. This dataset is automatically translated into Chinese using four\nNLLB-200 models of different sizes. We conduct both automatic and human\nevaluations. Our in-depth analysis reveal the correlations between translation\nerror types and the types of noise present, how these correlations change\nacross different model sizes, and the relationships between automatic\nevaluation indicators and human evaluation indicators. The dataset is publicly\navailable at https://github.com/tjunlp-lab/ID-ZH-MTRobustEval.", "published": "2024-05-13 12:01:54", "link": "http://arxiv.org/abs/2405.07673v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs", "abstract": "In recent years, Large Language Models (LLMs) have achieved almost human-like\nperformance on various tasks. While some LLMs have been trained on multilingual\ndata, most of the training data is in English. Hence, their performance in\nEnglish greatly exceeds their performance in other languages. This document\npresents our approach to training and evaluating the first foundational and\nchat LLM specialized for Romanian.", "published": "2024-05-13 12:46:11", "link": "http://arxiv.org/abs/2405.07703v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantifying and Optimizing Global Faithfulness in Persona-driven\n  Role-playing", "abstract": "Persona-driven role-playing (PRP) aims to build AI characters that can\nrespond to user queries by faithfully sticking with all persona statements.\nUnfortunately, existing faithfulness criteria for PRP are limited to\ncoarse-grained LLM-based scoring without a clear definition or formulation.\nThis paper presents a pioneering exploration to quantify PRP faithfulness as a\nfine-grained and explainable criterion, which also serves as a reliable\nreference for optimization. Our criterion first discriminates persona\nstatements into active and passive constraints by identifying the\nquery-statement relevance. Then, we incorporate all constraints following the\nprinciple that the AI character's response should be (a) entailed by active\n(relevant) constraints and (b) not contradicted by passive (irrelevant)\nconstraints. We translate this principle mathematically into a novel\nActive-Passive-Constraint (APC) score, a constraint-wise sum of natural\nlanguage inference (NLI) scores weighted by relevance scores. In practice, we\nbuild the APC scoring system by symbolically distilling small discriminators\nfrom GPT-4 for efficiency. We validate the quality of the APC score against\nhuman evaluation based on example personas with tens of statements, and the\nresults show a high correlation. We further leverage it as a reward system in\ndirect preference optimization (DPO) for better AI characters. Our experiments\noffer a fine-grained and explainable comparison between existing PRP\ntechniques, revealing their advantages and limitations. We further find\nAPC-based DPO to be one of the most competitive techniques for sticking with\nall constraints and can be well incorporated with other techniques. We then\nextend the scale of the experiments to real persons with hundreds of statements\nand reach a consistent conclusion.", "published": "2024-05-13 13:21:35", "link": "http://arxiv.org/abs/2405.07726v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Dependency Locality Predict Non-canonical Word Order in Hindi?", "abstract": "Previous work has shown that isolated non-canonical sentences with\nObject-before-Subject (OSV) order are initially harder to process than their\ncanonical counterparts with Subject-before-Object (SOV) order. Although this\ndifficulty diminishes with appropriate discourse context, the underlying\ncognitive factors responsible for alleviating processing challenges in OSV\nsentences remain a question. In this work, we test the hypothesis that\ndependency length minimization is a significant predictor of non-canonical\n(OSV) syntactic choices, especially when controlling for information status\nsuch as givenness and surprisal measures. We extract sentences from the\nHindi-Urdu Treebank corpus (HUTB) that contain clearly-defined subjects and\nobjects, systematically permute the preverbal constituents of those sentences,\nand deploy a classifier to distinguish between original corpus sentences and\nartificially generated alternatives. The classifier leverages various\ndiscourse-based and cognitive features, including dependency length, surprisal,\nand information status, to inform its predictions. Our results suggest that,\nalthough there exists a preference for minimizing dependency length in\nnon-canonical corpus sentences amidst the generated variants, this factor does\nnot significantly contribute in identifying corpus sentences above and beyond\nsurprisal and givenness measures. Notably, discourse predictability emerges as\nthe primary determinant of constituent-order preferences. These findings are\nfurther supported by human evaluations involving 44 native Hindi speakers.\nOverall, this work sheds light on the role of expectation adaptation in\nword-ordering decisions. We conclude by situating our results within the\ntheories of discourse production and information locality.", "published": "2024-05-13 13:24:17", "link": "http://arxiv.org/abs/2405.07730v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TANQ: An open domain dataset of table answered questions", "abstract": "Language models, potentially augmented with tool usage such as retrieval are\nbecoming the go-to means of answering questions. Understanding and answering\nquestions in real-world settings often requires retrieving information from\ndifferent sources, processing and aggregating data to extract insights, and\npresenting complex findings in form of structured artifacts such as novel\ntables, charts, or infographics. In this paper, we introduce TANQ, the first\nopen domain question answering dataset where the answers require building\ntables from information across multiple sources. We release the full source\nattribution for every cell in the resulting table and benchmark\nstate-of-the-art language models in open, oracle, and closed book setups. Our\nbest-performing baseline, Gemini Flash reaches an overall F1 score of 60.7,\nlagging behind human performance by 12.3 points. We analyse baselines'\nperformance across different dataset attributes such as different skills\nrequired for this task, including multi-hop reasoning, math operations, and\nunit conversions. We further discuss common failures in model-generated\nanswers, suggesting that TANQ is a complex task with many challenges ahead.", "published": "2024-05-13 14:07:20", "link": "http://arxiv.org/abs/2405.07765v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DEPTH: Discourse Education through Pre-Training Hierarchically", "abstract": "Language Models (LMs) struggle with linguistic understanding at the discourse\nlevel, even though discourse patterns such as coherence, cohesion, and\nnarrative flow are prevalent in their pre-training data. To improve the\ndiscourse capabilities of LMs already at the pre-training stage, we introduce\nDEPTH, an encoder-decoder model that learns latent representations for\nsentences using a discourse-oriented pre-training objective. DEPTH combines\nhierarchical sentence representations with two objectives: (1) Sentence\nUn-Shuffling, and (2) Span-Corruption. Our approach trains the model to\nrepresent both sub-word-level and sentence-level dependencies over a\npre-training corpora. When trained either from scratch or continuing from a\npre-trained T5 checkpoint, DEPTH learns semantic and discourse-level\nrepresentations faster than T5, outperforming it in span-corruption loss\ndespite the additional sentence-un-shuffling objective. Evaluations on the\nGLUE, DiscoEval, and NI benchmarks demonstrate DEPTH's ability to quickly learn\ndiverse downstream tasks, which require syntactic, semantic, and discourse\ncapabilities. Our approach extends the discourse capabilities of T5, while\nminimally impacting other natural language understanding (NLU) capabilities in\nthe resulting LM. We share our codebase for reproducibility:\nhttps://github.com/zbambergerNLP/depth.git.", "published": "2024-05-13 14:35:30", "link": "http://arxiv.org/abs/2405.07788v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reproducing the Metric-Based Evaluation of a Set of Controllable Text\n  Generation Techniques", "abstract": "Rerunning a metric-based evaluation should be more straightforward, and\nresults should be closer, than in a human-based evaluation, especially where\ncode and model checkpoints are made available by the original authors. As this\nreport of our efforts to rerun a metric-based evaluation of a set of\nsingle-attribute and multiple-attribute controllable text generation (CTG)\ntechniques shows however, such reruns of evaluations do not always produce\nresults that are the same as the original results, and can reveal errors in the\nreporting of the original work.", "published": "2024-05-13 16:02:57", "link": "http://arxiv.org/abs/2405.07875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Tokenizer Transfer", "abstract": "Language models (LMs) are bound to their tokenizer, which maps raw text to a\nsequence of vocabulary items (tokens). This restricts their flexibility: for\nexample, LMs trained primarily on English may still perform well in other\nnatural and programming languages, but have vastly decreased efficiency due to\ntheir English-centric tokenizer. To mitigate this, we should be able to swap\nthe original LM tokenizer with an arbitrary one, on the fly, without degrading\nperformance. Hence, in this work we define a new problem: Zero-Shot Tokenizer\nTransfer (ZeTT). The challenge at the core of ZeTT is finding embeddings for\nthe tokens in the vocabulary of the new tokenizer. Since prior heuristics for\ninitializing embeddings often perform at chance level in a ZeTT setting, we\npropose a new solution: we train a hypernetwork taking a tokenizer as input and\npredicting the corresponding embeddings. We empirically demonstrate that the\nhypernetwork generalizes to new tokenizers both with encoder (e.g., XLM-R) and\ndecoder LLMs (e.g., Mistral-7B). Our method comes close to the original models'\nperformance in cross-lingual and coding tasks while markedly reducing the\nlength of the tokenized sequence. We also find that the remaining gap can be\nquickly closed by continued training on less than 1B tokens. Finally, we show\nthat a ZeTT hypernetwork trained for a base (L)LM can also be applied to\nfine-tuned variants without extra training. Overall, our results make\nsubstantial strides toward detaching LMs from their tokenizer.", "published": "2024-05-13 16:17:10", "link": "http://arxiv.org/abs/2405.07883v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Russian-Language Multimodal Dataset for Automatic Summarization of\n  Scientific Papers", "abstract": "The paper discusses the creation of a multimodal dataset of Russian-language\nscientific papers and testing of existing language models for the task of\nautomatic text summarization. A feature of the dataset is its multimodal data,\nwhich includes texts, tables and figures. The paper presents the results of\nexperiments with two language models: Gigachat from SBER and YandexGPT from\nYandex. The dataset consists of 420 papers and is publicly available on\nhttps://github.com/iis-research-team/summarization-dataset.", "published": "2024-05-13 16:21:33", "link": "http://arxiv.org/abs/2405.07886v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EconLogicQA: A Question-Answering Benchmark for Evaluating Large\n  Language Models in Economic Sequential Reasoning", "abstract": "In this paper, we introduce EconLogicQA, a rigorous benchmark designed to\nassess the sequential reasoning capabilities of large language models (LLMs)\nwithin the intricate realms of economics, business, and supply chain\nmanagement. Diverging from traditional benchmarks that predict subsequent\nevents individually, EconLogicQA poses a more challenging task: it requires\nmodels to discern and sequence multiple interconnected events, capturing the\ncomplexity of economic logics. EconLogicQA comprises an array of multi-event\nscenarios derived from economic articles, which necessitate an insightful\nunderstanding of both temporal and logical event relationships. Through\ncomprehensive evaluations, we exhibit that EconLogicQA effectively gauges a\nLLM's proficiency in navigating the sequential complexities inherent in\neconomic contexts. We provide a detailed description of EconLogicQA dataset and\nshows the outcomes from evaluating the benchmark across various leading-edge\nLLMs, thereby offering a thorough perspective on their sequential reasoning\npotential in economic contexts. Our benchmark dataset is available at\nhttps://huggingface.co/datasets/yinzhu-quan/econ_logic_qa.", "published": "2024-05-13 17:13:47", "link": "http://arxiv.org/abs/2405.07938v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text\n  Detectors", "abstract": "Many commercial and open-source models claim to detect machine-generated text\nwith extremely high accuracy (99% or more). However, very few of these\ndetectors are evaluated on shared benchmark datasets and even when they are,\nthe datasets used for evaluation are insufficiently challenging-lacking\nvariations in sampling strategy, adversarial attacks, and open-source\ngenerative models. In this work we present RAID: the largest and most\nchallenging benchmark dataset for machine-generated text detection. RAID\nincludes over 6 million generations spanning 11 models, 8 domains, 11\nadversarial attacks and 4 decoding strategies. Using RAID, we evaluate the\nout-of-domain and adversarial robustness of 8 open- and 4 closed-source\ndetectors and find that current detectors are easily fooled by adversarial\nattacks, variations in sampling strategies, repetition penalties, and unseen\ngenerative models. We release our data along with a leaderboard to encourage\nfuture research.", "published": "2024-05-13 17:15:14", "link": "http://arxiv.org/abs/2405.07940v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "KET-QA: A Dataset for Knowledge Enhanced Table Question Answering", "abstract": "Due to the concise and structured nature of tables, the knowledge contained\ntherein may be incomplete or missing, posing a significant challenge for table\nquestion answering (TableQA) and data analysis systems. Most existing datasets\neither fail to address the issue of external knowledge in TableQA or only\nutilize unstructured text as supplementary information for tables. In this\npaper, we propose to use a knowledge base (KB) as the external knowledge source\nfor TableQA and construct a dataset KET-QA with fine-grained gold evidence\nannotation. Each table in the dataset corresponds to a sub-graph of the entire\nKB, and every question requires the integration of information from both the\ntable and the sub-graph to be answered. To extract pertinent information from\nthe vast knowledge sub-graph and apply it to TableQA, we design a\nretriever-reasoner structured pipeline model. Experimental results demonstrate\nthat our model consistently achieves remarkable relative performance\nimprovements ranging from 1.9 to 6.5 times and absolute improvements of 11.66%\nto 44.64% on EM scores across three distinct settings (fine-tuning, zero-shot,\nand few-shot), in comparison with solely relying on table information in the\ntraditional TableQA manner. However, even the best model achieves a 60.23% EM\nscore, which still lags behind the human-level performance, highlighting the\nchallenging nature of KET-QA for the question-answering community. We also\nprovide a human evaluation of error cases to analyze further the aspects in\nwhich the model can be improved. Project page: https://ketqa.github.io/.", "published": "2024-05-13 18:26:32", "link": "http://arxiv.org/abs/2405.08099v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Many-Shot Regurgitation (MSR) Prompting", "abstract": "We introduce Many-Shot Regurgitation (MSR) prompting, a new black-box\nmembership inference attack framework for examining verbatim content\nreproduction in large language models (LLMs). MSR prompting involves dividing\nthe input text into multiple segments and creating a single prompt that\nincludes a series of faux conversation rounds between a user and a language\nmodel to elicit verbatim regurgitation. We apply MSR prompting to diverse text\nsources, including Wikipedia articles and open educational resources (OER)\ntextbooks, which provide high-quality, factual content and are continuously\nupdated over time. For each source, we curate two dataset types: one that LLMs\nwere likely exposed to during training ($D_{\\rm pre}$) and another consisting\nof documents published after the models' training cutoff dates ($D_{\\rm\npost}$). To quantify the occurrence of verbatim matches, we employ the Longest\nCommon Substring algorithm and count the frequency of matches at different\nlength thresholds. We then use statistical measures such as Cliff's delta,\nKolmogorov-Smirnov (KS) distance, and Kruskal-Wallis H test to determine\nwhether the distribution of verbatim matches differs significantly between\n$D_{\\rm pre}$ and $D_{\\rm post}$. Our findings reveal a striking difference in\nthe distribution of verbatim matches between $D_{\\rm pre}$ and $D_{\\rm post}$,\nwith the frequency of verbatim reproduction being significantly higher when\nLLMs (e.g. GPT models and LLaMAs) are prompted with text from datasets they\nwere likely trained on. For instance, when using GPT-3.5 on Wikipedia articles,\nwe observe a substantial effect size (Cliff's delta $= -0.984$) and a large KS\ndistance ($0.875$) between the distributions of $D_{\\rm pre}$ and $D_{\\rm\npost}$. Our results provide compelling evidence that LLMs are more prone to\nreproducing verbatim content when the input text is likely sourced from their\ntraining data.", "published": "2024-05-13 19:22:40", "link": "http://arxiv.org/abs/2405.08134v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Retrieval-Augmented Large Language Models in Biomedical\n  NLP: Application, Robustness, and Self-Awareness", "abstract": "Large language models (LLM) have demonstrated remarkable capabilities in\nvarious biomedical natural language processing (NLP) tasks, leveraging the\ndemonstration within the input context to adapt to new tasks. However, LLM is\nsensitive to the selection of demonstrations. To address the hallucination\nissue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by\nretrieving pertinent information from an established database. Nonetheless,\nexisting research work lacks rigorous evaluation of the impact of\nretrieval-augmented large language models on different biomedical NLP tasks.\nThis deficiency makes it challenging to ascertain the capabilities of RAL\nwithin the biomedical domain. Moreover, the outputs from RAL are affected by\nretrieving the unlabeled, counterfactual, or diverse knowledge that is not well\nstudied in the biomedical domain. However, such knowledge is common in the real\nworld. Finally, exploring the self-awareness ability is also crucial for the\nRAL system. So, in this paper, we systematically investigate the impact of RALs\non 5 different biomedical tasks (triple extraction, link prediction,\nclassification, question answering, and natural language inference). We analyze\nthe performance of RALs in four fundamental abilities, including unlabeled\nrobustness, counterfactual robustness, diverse robustness, and negative\nawareness. To this end, we proposed an evaluation framework to assess the RALs'\nperformance on different biomedical NLP tasks and establish four different\ntestbeds based on the aforementioned fundamental abilities. Then, we evaluate 3\nrepresentative LLMs with 3 different retrievers on 5 tasks over 9 datasets.", "published": "2024-05-13 19:51:20", "link": "http://arxiv.org/abs/2405.08151v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Entity Linking Using Dense Retrieval", "abstract": "Entity linking (EL) is the computational process of connecting textual\nmentions to corresponding entities. Like many areas of natural language\nprocessing, the EL field has greatly benefited from deep learning, leading to\nsignificant performance improvements. However, present-day approaches are\nexpensive to train and rely on diverse data sources, complicating their\nreproducibility. In this thesis, we develop multiple systems that are fast to\ntrain, demonstrating that competitive entity linking can be achieved without a\nlarge GPU cluster. Moreover, we train on a publicly available dataset, ensuring\nreproducibility and accessibility. Our models are evaluated for 9 languages\ngiving an accurate overview of their strengths. Furthermore, we offer\na~detailed analysis of bi-encoder training hyperparameters, a popular approach\nin EL, to guide their informed selection. Overall, our work shows that building\ncompetitive neural network based EL systems that operate in multiple languages\nis possible even with limited resources, thus making EL more approachable.", "published": "2024-05-13 18:57:27", "link": "http://arxiv.org/abs/2406.16892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of Retrieval-Augmented Generation: A Survey", "abstract": "Retrieval-Augmented Generation (RAG) has recently gained traction in natural\nlanguage processing. Numerous studies and real-world applications are\nleveraging its ability to enhance generative models through external\ninformation retrieval. Evaluating these RAG systems, however, poses unique\nchallenges due to their hybrid structure and reliance on dynamic knowledge\nsources. To better understand these challenges, we conduct A Unified Evaluation\nProcess of RAG (Auepora) and aim to provide a comprehensive overview of the\nevaluation and benchmarks of RAG systems. Specifically, we examine and compare\nseveral quantifiable metrics of the Retrieval and Generation components, such\nas relevance, accuracy, and faithfulness, within the current RAG benchmarks,\nencompassing the possible output and ground truth pairs. We then analyze the\nvarious datasets and metrics, discuss the limitations of current benchmarks,\nand suggest potential directions to advance the field of RAG benchmarks.", "published": "2024-05-13 02:33:25", "link": "http://arxiv.org/abs/2405.07437v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating large language models in medical applications: a survey", "abstract": "Large language models (LLMs) have emerged as powerful tools with\ntransformative potential across numerous domains, including healthcare and\nmedicine. In the medical domain, LLMs hold promise for tasks ranging from\nclinical decision support to patient education. However, evaluating the\nperformance of LLMs in medical contexts presents unique challenges due to the\ncomplex and critical nature of medical information. This paper provides a\ncomprehensive overview of the landscape of medical LLM evaluation, synthesizing\ninsights from existing studies and highlighting evaluation data sources, task\nscenarios, and evaluation methods. Additionally, it identifies key challenges\nand opportunities in medical LLM evaluation, emphasizing the need for continued\nresearch and innovation to ensure the responsible integration of LLMs into\nclinical practice.", "published": "2024-05-13 05:08:33", "link": "http://arxiv.org/abs/2405.07468v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Strategic Data Ordering: Enhancing Large Language Model Performance\n  through Curriculum Learning", "abstract": "The rapid advancement of Large Language Models (LLMs) has improved text\nunderstanding and generation but poses challenges in computational resources.\nThis study proposes a curriculum learning-inspired, data-centric training\nstrategy that begins with simpler tasks and progresses to more complex ones,\nusing criteria such as prompt length, attention scores, and loss values to\nstructure the training data. Experiments with Mistral-7B (Jiang et al., 2023)\nand Gemma-7B (Team et al., 2024) models demonstrate that curriculum learning\nslightly improves performance compared to traditional random data shuffling.\nNotably, we observed that sorting data based on our proposed attention criteria\ngenerally led to better performance. This approach offers a sustainable method\nto enhance LLM performance without increasing model size or dataset volume,\naddressing scalability challenges in LLM training.", "published": "2024-05-13 06:09:10", "link": "http://arxiv.org/abs/2405.07490v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MacBehaviour: An R package for behavioural experimentation on large\n  language models", "abstract": "There has been increasing interest in investigating the behaviours of large\nlanguage models (LLMs) and LLM-powered chatbots by treating an LLM as a\nparticipant in a psychological experiment. We therefore developed an R package\ncalled \"MacBehaviour\" that aims to interact with more than 60 language models\nin one package (e.g., OpenAI's GPT family, the Claude family, Gemini, Llama\nfamily, and open-source models) and streamline the experimental process of LLMs\nbehaviour experiments. The package offers a comprehensive set of functions\ndesigned for LLM experiments, covering experiment design, stimuli presentation,\nmodel behaviour manipulation, logging response and token probability. To\ndemonstrate the utility and effectiveness of \"MacBehaviour,\" we conducted three\nvalidation experiments on three LLMs (GPT-3.5, Llama-2 7B, and Vicuna-1.5 13B)\nto replicate sound-gender association in LLMs. The results consistently showed\nthat they exhibit human-like tendencies to infer gender from novel personal\nnames based on their phonology, as previously demonstrated (Cai et al., 2023).\nIn summary, \"MacBehaviour\" is an R package for machine behaviour studies which\noffers a user-friendly interface and comprehensive features to simplify and\nstandardize the experimental process.", "published": "2024-05-13 06:31:48", "link": "http://arxiv.org/abs/2405.07495v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MuMath-Code: Combining Tool-Use Large Language Models with\n  Multi-perspective Data Augmentation for Mathematical Reasoning", "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python\ninterpreters have significantly enhanced mathematical reasoning capabilities\nfor open-source LLMs, while tool-free methods chose another track: augmenting\nmath reasoning data. However, a great method to integrate the above two\nresearch paths and combine their advantages remains to be explored. In this\nwork, we firstly include new math questions via multi-perspective data\naugmenting methods and then synthesize code-nested solutions to them. The open\nLLMs (i.e., Llama-2) are finetuned on the augmented dataset to get the\nresulting models, MuMath-Code ($\\mu$-Math-Code). During the inference phase,\nour MuMath-Code generates code and interacts with the external python\ninterpreter to get the execution results. Therefore, MuMath-Code leverages the\nadvantages of both the external tool and data augmentation. To fully leverage\nthe advantages of our augmented data, we propose a two-stage training strategy:\nIn Stage-1, we finetune Llama-2 on pure CoT data to get an intermediate model,\nwhich then is trained on the code-nested data in Stage-2 to get the resulting\nMuMath-Code. Our MuMath-Code-7B achieves 83.8 on GSM8K and 52.4 on MATH, while\nMuMath-Code-70B model achieves new state-of-the-art performance among open\nmethods -- achieving 90.7% on GSM8K and 55.1% on MATH. Extensive experiments\nvalidate the combination of tool use and data augmentation, as well as our\ntwo-stage training strategy. We release the proposed dataset along with the\nassociated code for public use.", "published": "2024-05-13 08:32:19", "link": "http://arxiv.org/abs/2405.07551v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sign Stitching: A Novel Approach to Sign Language Production", "abstract": "Sign Language Production (SLP) is a challenging task, given the limited\nresources available and the inherent diversity within sign data. As a result,\nprevious works have suffered from the problem of regression to the mean,\nleading to under-articulated and incomprehensible signing. In this paper, we\npropose using dictionary examples to create expressive sign language sequences.\nHowever, simply concatenating the signs would create robotic and unnatural\nsequences. Therefore, we present a 7-step approach to effectively stitch the\nsigns together. First, by normalising each sign into a canonical pose, cropping\nand stitching we create a continuous sequence. Then by applying filtering in\nthe frequency domain and resampling each sign we create cohesive natural\nsequences, that mimic the prosody found in the original data. We leverage the\nSignGAN model to map the output to a photo-realistic signer and present a\ncomplete Text-to-Sign (T2S) SLP pipeline. Our evaluation demonstrates the\neffectiveness of this approach, showcasing state-of-the-art performance across\nall datasets.", "published": "2024-05-13 11:44:57", "link": "http://arxiv.org/abs/2405.07663v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Simulate and Eliminate: Revoke Backdoors for Generative Large Language\n  Models", "abstract": "With rapid advances, generative large language models (LLMs) dominate various\nNatural Language Processing (NLP) tasks from understanding to reasoning. Yet,\nlanguage models' inherent vulnerabilities may be exacerbated due to increased\naccessibility and unrestricted model training on massive data. A malicious\nadversary may publish poisoned data online and conduct backdoor attacks on the\nvictim LLMs pre-trained on the poisoned data. Backdoored LLMs behave\ninnocuously for normal queries and generate harmful responses when the backdoor\ntrigger is activated. Despite significant efforts paid to LLMs' safety issues,\nLLMs are still struggling against backdoor attacks. As Anthropic recently\nrevealed, existing safety training strategies, including supervised fine-tuning\n(SFT) and Reinforcement Learning from Human Feedback (RLHF), fail to revoke the\nbackdoors once the LLM is backdoored during the pre-training stage. In this\npaper, we present Simulate and Eliminate (SANDE) to erase the undesired\nbackdoored mappings for generative LLMs. We initially propose Overwrite\nSupervised Fine-tuning (OSFT) for effective backdoor removal when the trigger\nis known. Then, to handle scenarios where trigger patterns are unknown, we\nintegrate OSFT into our two-stage framework, SANDE. Unlike other works that\nassume access to cleanly trained models, our safety-enhanced LLMs are able to\nrevoke backdoors without any reference. Consequently, our safety-enhanced LLMs\nno longer produce targeted responses when the backdoor triggers are activated.\nWe conduct comprehensive experiments to show that our proposed SANDE is\neffective against backdoor attacks while bringing minimal harm to LLMs'\npowerful capability.", "published": "2024-05-13 11:53:42", "link": "http://arxiv.org/abs/2405.07667v2", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "LlamaTurk: Adapting Open-Source Generative Large Language Models for\n  Low-Resource Language", "abstract": "Despite advancements in English-dominant generative large language models,\nfurther development is needed for low-resource languages to enhance global\naccessibility. The primary methods for representing these languages are\nmonolingual and multilingual pretraining. Monolingual pretraining is expensive\ndue to hardware requirements, and multilingual models often have uneven\nperformance across languages. This study explores an alternative solution by\nadapting large language models, primarily trained on English, to low-resource\nlanguages. We assess various strategies, including continual training,\ninstruction fine-tuning, task-specific fine-tuning, and vocabulary extension.\nThe results show that continual training improves language comprehension, as\nreflected in perplexity scores, and task-specific tuning generally enhances\nperformance of downstream tasks. However, extending the vocabulary shows no\nsubstantial benefits. Additionally, while larger models improve task\nperformance with few-shot tuning, multilingual models perform worse than their\nmonolingual counterparts when adapted.", "published": "2024-05-13 13:41:59", "link": "http://arxiv.org/abs/2405.07745v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Challenges and Opportunities of NLP for HR Applications: A Discussion\n  Paper", "abstract": "Over the course of the recent decade, tremendous progress has been made in\nthe areas of machine learning and natural language processing, which opened up\nvast areas of potential application use cases, including hiring and human\nresource management. We review the use cases for text analytics in the realm of\nhuman resources/personnel management, including actually realized as well as\npotential but not yet implemented ones, and we analyze the opportunities and\nrisks of these.", "published": "2024-05-13 14:09:06", "link": "http://arxiv.org/abs/2405.07766v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.1"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Analysis of Static Word Embeddings for Turkish", "abstract": "Word embeddings are fixed-length, dense and distributed word representations\nthat are used in natural language processing (NLP) applications. There are\nbasically two types of word embedding models which are non-contextual (static)\nmodels and contextual models. The former method generates a single embedding\nfor a word regardless of its context, while the latter method produces distinct\nembeddings for a word based on the specific contexts in which it appears. There\nare plenty of works that compare contextual and non-contextual embedding models\nwithin their respective groups in different languages. However, the number of\nstudies that compare the models in these two groups with each other is very few\nand there is no such study in Turkish. This process necessitates converting\ncontextual embeddings into static embeddings. In this paper, we compare and\nevaluate the performance of several contextual and non-contextual models in\nboth intrinsic and extrinsic evaluation settings for Turkish. We make a\nfine-grained comparison by analyzing the syntactic and semantic capabilities of\nthe models separately. The results of the analyses provide insights about the\nsuitability of different embedding models in different types of NLP tasks. We\nalso build a Turkish word embedding repository comprising the embedding models\nused in this work, which may serve as a valuable resource for researchers and\npractitioners in the field of Turkish NLP. We make the word embeddings,\nscripts, and evaluation datasets publicly available.", "published": "2024-05-13 14:23:37", "link": "http://arxiv.org/abs/2405.07778v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM", "abstract": "Decoding language information from brain signals represents a vital research\narea within brain-computer interfaces, particularly in the context of\ndeciphering the semantic information from the fMRI signal. However, many\nexisting efforts concentrate on decoding small vocabulary sets, leaving space\nfor the exploration of open vocabulary continuous text decoding. In this paper,\nwe introduce a novel method, the \\textbf{Brain Prompt GPT (BP-GPT)}. By using\nthe brain representation that is extracted from the fMRI as a prompt, our\nmethod can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we\nintroduce a text-to-text baseline and align the fMRI prompt to the text prompt.\nBy introducing the text-to-text baseline, our BP-GPT can extract a more robust\nbrain prompt and promote the decoding of pre-trained LLM. We evaluate our\nBP-GPT on the open-source auditory semantic decoding dataset and achieve a\nsignificant improvement up to $4.61\\%$ on METEOR and $2.43\\%$ on BERTScore\nacross all the subjects compared to the state-of-the-art method. The\nexperimental results demonstrate that using brain representation as a prompt to\nfurther drive LLM for auditory neural decoding is feasible and effective.", "published": "2024-05-13 15:25:11", "link": "http://arxiv.org/abs/2405.07840v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition", "abstract": "Large language models (LLMs) have shown success in many natural language\nprocessing tasks. Despite rigorous safety alignment processes, supposedly\nsafety-aligned LLMs like Llama 2 and Claude 2 are still susceptible to\njailbreaks, leading to security risks and abuse of the models. One option to\nmitigate such risks is to augment the LLM with a dedicated \"safeguard\", which\nchecks the LLM's inputs or outputs for undesired behaviour. A promising\napproach is to use the LLM itself as the safeguard. Nonetheless, baseline\nmethods, such as prompting the LLM to self-classify toxic content, demonstrate\nlimited efficacy. We hypothesise that this is due to domain shift: the\nalignment training imparts a self-censoring behaviour to the model (\"Sorry I\ncan't do that\"), while the self-classify approach shifts it to a classification\nformat (\"Is this prompt malicious\"). In this work, we propose PARDEN, which\navoids this domain shift by simply asking the model to repeat its own outputs.\nPARDEN neither requires finetuning nor white box access to the model. We\nempirically verify the effectiveness of our method and show that PARDEN\nsignificantly outperforms existing jailbreak detection baselines for Llama-2\nand Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN.\n  We find that PARDEN is particularly powerful in the relevant regime of high\nTrue Positive Rate (TPR) and low False Positive Rate (FPR). For instance, for\nLlama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction in\nthe FPR from 24.8% to 2.0% on the harmful behaviours dataset.", "published": "2024-05-13 17:08:42", "link": "http://arxiv.org/abs/2405.07932v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "AgentClinic: a multimodal agent benchmark to evaluate AI in simulated\n  clinical environments", "abstract": "Evaluating large language models (LLM) in clinical scenarios is crucial to\nassessing their potential clinical utility. Existing benchmarks rely heavily on\nstatic question-answering, which does not accurately depict the complex,\nsequential nature of clinical decision-making. Here, we introduce AgentClinic,\na multimodal agent benchmark for evaluating LLMs in simulated clinical\nenvironments that include patient interactions, multimodal data collection\nunder incomplete information, and the usage of various tools, resulting in an\nin-depth evaluation across nine medical specialties and seven languages. We\nfind that solving MedQA problems in the sequential decision-making format of\nAgentClinic is considerably more challenging, resulting in diagnostic\naccuracies that can drop to below a tenth of the original accuracy. Overall, we\nobserve that agents sourced from Claude-3.5 outperform other LLM backbones in\nmost settings. Nevertheless, we see stark differences in the LLMs' ability to\nmake use of tools, such as experiential learning, adaptive retrieval, and\nreflection cycles. Strikingly, Llama-3 shows up to 92% relative improvements\nwith the notebook tool that allows for writing and editing notes that persist\nacross cases. To further scrutinize our clinical simulations, we leverage\nreal-world electronic health records, perform a clinical reader study, perturb\nagents with biases, and explore novel patient-centric metrics that this\ninteractive environment firstly enables.", "published": "2024-05-13 17:38:53", "link": "http://arxiv.org/abs/2405.07960v4", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large\n  Language Models in Code Generation from Scientific Plots", "abstract": "The remarkable progress of Multi-modal Large Language Models (MLLMs) has\nattracted significant attention due to their superior performance in visual\ncontexts. However, their capabilities in turning visual figure to executable\ncode, have not been evaluated thoroughly. To address this, we introduce\nPlot2Code, a comprehensive visual coding benchmark designed for a fair and\nin-depth assessment of MLLMs. We carefully collect 132 manually selected\nhigh-quality matplotlib plots across six plot types from publicly available\nmatplotlib galleries. For each plot, we carefully offer its source code, and an\ndescriptive instruction summarized by GPT-4. This approach enables Plot2Code to\nextensively evaluate MLLMs' code capabilities across various input modalities.\nFurthermore, we propose three automatic evaluation metrics, including code pass\nrate, text-match ratio, and GPT-4V overall rating, for a fine-grained\nassessment of the output code and rendered images. Instead of simply judging\npass or fail, we employ GPT-4V to make an overall judgement between the\ngenerated and reference images, which has been shown to be consistent with\nhuman evaluation. The evaluation results, which include analyses of 14 MLLMs\nsuch as the proprietary GPT-4V, Gemini-Pro, and the open-sourced Mini-Gemini,\nhighlight the substantial challenges presented by Plot2Code. With Plot2Code, we\nreveal that most existing MLLMs struggle with visual coding for text-dense\nplots, heavily relying on textual instruction. We hope that the evaluation\nresults from Plot2Code on visual coding will guide the future development of\nMLLMs. All data involved with Plot2Code are available at\nhttps://huggingface.co/datasets/TencentARC/Plot2Code.", "published": "2024-05-13 17:59:22", "link": "http://arxiv.org/abs/2405.07990v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Discursive objection strategies in online comments: Developing a\n  classification schema and validating its training", "abstract": "Most Americans agree that misinformation, hate speech and harassment are\nharmful and inadequately curbed on social media through current moderation\npractices. In this paper, we aim to understand the discursive strategies\nemployed by people in response to harmful speech in news comments. We conducted\na content analysis of more than 6500 comment replies to trending news videos on\nYouTube and Twitter and identified seven distinct discursive objection\nstrategies (Study 1). We examined the frequency of each strategy's occurrence\nfrom the 6500 comment replies, as well as from a second sample of 2004 replies\n(Study 2). Together, these studies show that people deploy a diversity of\ndiscursive strategies when objecting to speech, and reputational attacks are\nthe most common. The resulting classification scheme accounts for different\ntheoretical approaches for expressing objections and offers a comprehensive\nperspective on grassroots efforts aimed at stopping offensive or problematic\nspeech on campus.", "published": "2024-05-13 19:39:00", "link": "http://arxiv.org/abs/2405.08142v1", "categories": ["cs.CL", "cs.CY", "I.2.7, J.4"], "primary_category": "cs.CL"}
{"title": "CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for\n  Cantonese-English Neural Machine Translation", "abstract": "This paper investigates the development and evaluation of machine translation\nmodels from Cantonese to English, where we propose a novel approach to tackle\nlow-resource language translations. The main objectives of the study are to\ndevelop a model that can effectively translate Cantonese to English and\nevaluate it against state-of-the-art commercial models. To achieve this, a new\nparallel corpus has been created by combining different available corpora\nonline with preprocessing and cleaning. In addition, a monolingual Cantonese\ndataset has been created through web scraping to aid the synthetic parallel\ncorpus generation. Following the data collection process, several approaches,\nincluding fine-tuning models, back-translation, and model switch, have been\nused. The translation quality of models has been evaluated with multiple\nquality metrics, including lexicon-based metrics (SacreBLEU and hLEPOR) and\nembedding-space metrics (COMET and BERTscore). Based on the automatic metrics,\nthe best model is selected and compared against the 2 best commercial\ntranslators using the human evaluation framework HOPES. The best model proposed\nin this investigation (NLLB-mBART) with model switch mechanisms has reached\ncomparable and even better automatic evaluation scores against State-of-the-art\ncommercial models (Bing and Baidu Translators), with a SacreBLEU score of 16.8\non our test set. Furthermore, an open-source web application has been developed\nto allow users to translate between Cantonese and English, with the different\ntrained models available for effective comparisons between models from this\ninvestigation and users. CANTONMT is available at\nhttps://github.com/kenrickkung/CantoneseTranslation", "published": "2024-05-13 20:37:04", "link": "http://arxiv.org/abs/2405.08172v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Auto FAQ Generation", "abstract": "FAQ documents are commonly used with text documents and websites to provide\nimportant information in the form of question answer pairs to either aid in\nreading comprehension or provide a shortcut to the key ideas. We suppose that\nsalient sentences from a given document serve as a good proxy fro the answers\nto an aggregated set of FAQs from readers. We propose a system for generating\nFAQ documents that extract the salient questions and their corresponding\nanswers from sizeable text documents scraped from the Stanford Encyclopedia of\nPhilosophy. We use existing text summarization, sentence ranking via the Text\nrank algorithm, and question-generation tools to create an initial set of\nquestions and answers. Finally, we apply some heuristics to filter out invalid\nquestions. We use human evaluation to rate the generated questions on grammar,\nwhether the question is meaningful, and whether the question's answerability is\npresent within a summarized context. On average, participants thought 71\npercent of the questions were meaningful.", "published": "2024-05-13 03:30:27", "link": "http://arxiv.org/abs/2405.13006v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Control Token with Dense Passage Retrieval", "abstract": "This study addresses the hallucination problem in large language models\n(LLMs). We adopted Retrieval-Augmented Generation(RAG) (Lewis et al., 2020), a\ntechnique that involves embedding relevant information in the prompt to obtain\naccurate answers. However, RAG also faced inherent issues in retrieving correct\ninformation. To address this, we employed the Dense Passage Retrieval(DPR)\n(Karpukhin et al., 2020) model for fetching domain-specific documents related\nto user queries. Despite this, the DPR model still lacked accuracy in document\nretrieval. We enhanced the DPR model by incorporating control tokens, achieving\nsignificantly superior performance over the standard DPR model, with a 13%\nimprovement in Top-1 accuracy and a 4% improvement in Top-20 accuracy.", "published": "2024-05-13 09:17:19", "link": "http://arxiv.org/abs/2405.13008v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaReflection: Learning Instructions for Language Agents using Past\n  Reflections", "abstract": "The popularity of Large Language Models (LLMs) have unleashed a new age\nofLanguage Agents for solving a diverse range of tasks. While contemporary\nfrontier LLMs are capable enough to power reasonably good Language agents, the\nclosed-API model makes it hard to improve in cases they perform sub-optimally.\nTo address this, recent works have explored ways to improve their performance\nusing techniques like self-reflection and prompt optimization. Unfortunately,\ntechniques like self-reflection can be used only in an online setup, while\ncontemporary prompt optimization techniques are designed and tested to work on\nsimple tasks. To this end, we introduce MetaReflection, a novel offline\nreinforcement learning technique that enhances the performance of Language\nAgents by augmenting a semantic memory based on experiential learnings from\npast trials. We demonstrate the efficacy of MetaReflection by evaluating across\nmultiple domains, including complex logical reasoning, biomedical semantic\nsimilarity, open world question answering, and vulnerability threat detection,\nin Infrastructure-as-Code, spanning different agent designs. MetaReflection\nboosts Language agents' performance by 4% to 16.82% over the raw GPT-4 baseline\nand performs on par with existing state-of-the-art prompt optimization\ntechniques while requiring fewer LLM calls.", "published": "2024-05-13 10:51:43", "link": "http://arxiv.org/abs/2405.13009v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UCCIX: Irish-eXcellence Large Language Model", "abstract": "The development of Large Language Models (LLMs) has predominantly focused on\nhigh-resource languages, leaving extremely low-resource languages like Irish\nwith limited representation. This work presents UCCIX, a pioneering effort on\nthe development of an open-source Irish-based LLM. We propose a novel framework\nfor continued pre-training of LLMs specifically adapted for extremely\nlow-resource languages, requiring only a fraction of the textual data typically\nneeded for training LLMs according to scaling laws. Our model, based on Llama\n2-13B, outperforms much larger models on Irish language tasks with up to 12%\nperformance improvement, showcasing the effectiveness and efficiency of our\napproach. We also contribute comprehensive Irish benchmarking datasets,\nincluding IrishQA, a question-answering dataset, and Irish version of MT-bench.\nThese datasets enable rigorous evaluation and facilitate future research in\nIrish LLM systems. Our work aims to preserve and promote the Irish language,\nknowledge, and culture of Ireland in the digital era while providing a\nframework for adapting LLMs to other indigenous languages.", "published": "2024-05-13 13:19:27", "link": "http://arxiv.org/abs/2405.13010v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Divergent Creativity in Humans and Large Language Models", "abstract": "The recent surge in the capabilities of Large Language Models (LLMs) has led\nto claims that they are approaching a level of creativity akin to human\ncapabilities. This idea has sparked a blend of excitement and apprehension.\nHowever, a critical piece that has been missing in this discourse is a\nsystematic evaluation of LLM creativity, particularly in comparison to human\ndivergent thinking. To bridge this gap, we leverage recent advances in\ncreativity science to build a framework for in-depth analysis of divergent\ncreativity in both state-of-the-art LLMs and a substantial dataset of 100,000\nhumans. We found evidence suggesting that LLMs can indeed surpass human\ncapabilities in specific creative tasks such as divergent association and\ncreative writing. Our quantitative benchmarking framework opens up new paths\nfor the development of more creative LLMs, but it also encourages more granular\ninquiries into the distinctive elements that constitute human inventive thought\nprocesses, compared to those that can be artificially generated.", "published": "2024-05-13 22:37:52", "link": "http://arxiv.org/abs/2405.13012v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PromptLink: Leveraging Large Language Models for Cross-Source Biomedical\n  Concept Linking", "abstract": "Linking (aligning) biomedical concepts across diverse data sources enables\nvarious integrative analyses, but it is challenging due to the discrepancies in\nconcept naming conventions. Various strategies have been developed to overcome\nthis challenge, such as those based on string-matching rules, manually crafted\nthesauri, and machine learning models. However, these methods are constrained\nby limited prior biomedical knowledge and can hardly generalize beyond the\nlimited amounts of rules, thesauri, or training samples. Recently, large\nlanguage models (LLMs) have exhibited impressive results in diverse biomedical\nNLP tasks due to their unprecedentedly rich prior knowledge and strong\nzero-shot prediction abilities. However, LLMs suffer from issues including high\ncosts, limited context length, and unreliable predictions. In this research, we\npropose PromptLink, a novel biomedical concept linking framework that leverages\nLLMs. It first employs a biomedical-specialized pre-trained language model to\ngenerate candidate concepts that can fit in the LLM context windows. Then it\nutilizes an LLM to link concepts through two-stage prompts, where the\nfirst-stage prompt aims to elicit the biomedical prior knowledge from the LLM\nfor the concept linking task and the second-stage prompt enforces the LLM to\nreflect on its own predictions to further enhance their reliability. Empirical\nresults on the concept linking task between two EHR datasets and an external\nbiomedical KG demonstrate the effectiveness of PromptLink. Furthermore,\nPromptLink is a generic framework without reliance on additional prior\nknowledge, context, or training data, making it well-suited for concept linking\nacross various types of data sources. The source code is available at\nhttps://github.com/constantjxyz/PromptLink.", "published": "2024-05-13 06:36:30", "link": "http://arxiv.org/abs/2405.07500v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity\n  Recognition", "abstract": "Available training data for named entity recognition (NER) often contains a\nsignificant percentage of incorrect labels for entity types and entity\nboundaries. Such label noise poses challenges for supervised learning and may\nsignificantly deteriorate model quality. To address this, prior work proposed\nvarious noise-robust learning approaches capable of learning from data with\npartially incorrect labels. These approaches are typically evaluated using\nsimulated noise where the labels in a clean dataset are automatically\ncorrupted. However, as we show in this paper, this leads to unrealistic noise\nthat is far easier to handle than real noise caused by human error or\nsemi-automatic annotation. To enable the study of the impact of various types\nof real noise, we introduce NoiseBench, an NER benchmark consisting of clean\ntraining data corrupted with 6 types of real noise, including expert errors,\ncrowdsourcing errors, automatic annotation errors and LLM errors. We present an\nanalysis that shows that real noise is significantly more challenging than\nsimulated noise, and show that current state-of-the-art models for noise-robust\nlearning fall far short of their theoretically achievable upper bound. We\nrelease NoiseBench to the research community.", "published": "2024-05-13 10:20:31", "link": "http://arxiv.org/abs/2405.07609v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Constructing a BPE Tokenization DFA", "abstract": "Many natural language processing systems operate over tokenizations of text\nto address the open-vocabulary problem. In this paper, we give and analyze an\nalgorithm for the efficient construction of deterministic finite automata\ndesigned to operate directly on tokenizations produced by the popular byte pair\nencoding technique. This makes it possible to apply many existing techniques\nand algorithms to the tokenized case, such as pattern matching, equivalence\nchecking of tokenization dictionaries, and composing tokenized languages in\nvarious ways.", "published": "2024-05-13 11:59:24", "link": "http://arxiv.org/abs/2405.07671v1", "categories": ["cs.FL", "cs.CL", "cs.LG"], "primary_category": "cs.FL"}
{"title": "Age-Dependent Analysis and Stochastic Generation of Child-Directed\n  Speech", "abstract": "Child-directed speech (CDS) is a particular type of speech that adults use\nwhen addressing young children. Its properties also change as a function of\nextralinguistic factors, such as age of the child being addressed. Access to\nlarge amounts of representative and varied CDS would be useful for child\nlanguage research, as this would enable controlled computational modeling\nexperiments of infant language acquisition with realistic input in terms of\nquality and quantity. In this study, we describe an approach to model\nage-dependent linguistic properties of CDS using a language model (LM) trained\non CDS transcripts and ages of the recipient children, as obtained from North\nAmerican English corpora of the CHILDES database. The created LM can then be\nused to stochastically generate synthetic CDS transcripts in an age-appropriate\nmanner, thereby scaling beyond the original datasets in size. We compare\ncharacteristics of the generated CDS against the real speech addressed at\nchildren of different ages, showing that the LM manages to capture\nage-dependent changes in CDS, except for a slight difference in the effective\nvocabulary size. As a side product, we also provide a systematic\ncharacterization of age-dependent linguistic properties of CDS in CHILDES,\nillustrating how all measured aspects of the CDS change with children's age.", "published": "2024-05-13 12:35:10", "link": "http://arxiv.org/abs/2405.07700v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LGDE: Local Graph-based Dictionary Expansion", "abstract": "We present Local Graph-based Dictionary Expansion (LGDE), a method for\ndata-driven discovery of the semantic neighbourhood of words using tools from\nmanifold learning and network science. At the heart of LGDE lies the creation\nof a word similarity graph from the geometry of word embeddings followed by\nlocal community detection based on graph diffusion. The diffusion in the local\ngraph manifold allows the exploration of the complex nonlinear geometry of word\nembeddings to capture word similarities based on paths of semantic association,\nover and above direct pairwise similarities. Exploiting such semantic\nneighbourhoods enables the expansion of dictionaries of pre-selected keywords,\nan important step for tasks in information retrieval, such as database queries\nand online data collection. We validate LGDE on two user-generated\nEnglish-language corpora and show that LGDE enriches the list of keywords with\nimproved performance relative to methods based on direct word similarities or\nco-occurrences. We further demonstrate our method through a real-world use case\nfrom communication science, where LGDE is evaluated quantitatively on the\nexpansion of a conspiracy-related dictionary from online data collected and\nanalysed by domain experts. Our empirical results and expert user assessment\nindicate that LGDE expands the seed dictionary with more useful keywords due to\nthe manifold-learning-based similarity network.", "published": "2024-05-13 14:07:15", "link": "http://arxiv.org/abs/2405.07764v3", "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "RLHF Workflow: From Reward Modeling to Online RLHF", "abstract": "We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.", "published": "2024-05-13 15:50:39", "link": "http://arxiv.org/abs/2405.07863v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Who's in and who's out? A case study of multimodal CLIP-filtering in\n  DataComp", "abstract": "As training datasets become increasingly drawn from unstructured,\nuncontrolled environments such as the web, researchers and industry\npractitioners have increasingly relied upon data filtering techniques to\n\"filter out the noise\" of web-scraped data. While datasets have been widely\nshown to reflect the biases and values of their creators, in this paper we\ncontribute to an emerging body of research that assesses the filters used to\ncreate these datasets. We show that image-text data filtering also has biases\nand is value-laden, encoding specific notions of what is counted as\n\"high-quality\" data. In our work, we audit a standard approach of image-text\nCLIP-filtering on the academic benchmark DataComp's CommonPool by analyzing\ndiscrepancies of filtering through various annotation techniques across\nmultiple modalities of image, text, and website source. We find that data\nrelating to several imputed demographic groups -- such as LGBTQ+ people, older\nwomen, and younger men -- are associated with higher rates of exclusion.\nMoreover, we demonstrate cases of exclusion amplification: not only are certain\nmarginalized groups already underrepresented in the unfiltered data, but\nCLIP-filtering excludes data from these groups at higher rates. The\ndata-filtering step in the machine learning pipeline can therefore exacerbate\nrepresentation disparities already present in the data-gathering step,\nespecially when existing filters are designed to optimize a specifically-chosen\ndownstream performance metric like zero-shot image classification accuracy.\nFinally, we show that the NSFW filter fails to remove sexually-explicit content\nfrom CommonPool, and that CLIP-filtering includes several categories of\ncopyrighted content at high rates. Our conclusions point to a need for\nfundamental changes in dataset creation and filtering practices.", "published": "2024-05-13 21:53:06", "link": "http://arxiv.org/abs/2405.08209v2", "categories": ["cs.CY", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Interpreting Latent Student Knowledge Representations in Programming\n  Assignments", "abstract": "Recent advances in artificial intelligence for education leverage generative\nlarge language models, including using them to predict open-ended student\nresponses rather than their correctness only. However, the black-box nature of\nthese models limits the interpretability of the learned student knowledge\nrepresentations. In this paper, we conduct a first exploration into\ninterpreting latent student knowledge representations by presenting InfoOIRT,\nan Information regularized Open-ended Item Response Theory model, which\nencourages the latent student knowledge states to be interpretable while being\nable to generate student-written code for open-ended programming questions.\nInfoOIRT maximizes the mutual information between a fixed subset of latent\nknowledge states enforced with simple prior distributions and generated student\ncode, which encourages the model to learn disentangled representations of\nsalient syntactic and semantic code features including syntactic styles,\nmastery of programming skills, and code structures. Through experiments on a\nreal-world programming education dataset, we show that InfoOIRT can both\naccurately generate student code and lead to interpretable student knowledge\nrepresentations.", "published": "2024-05-13 22:01:03", "link": "http://arxiv.org/abs/2405.08213v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An information-theoretic model of shallow and deep language\n  comprehension", "abstract": "A large body of work in psycholinguistics has focused on the idea that online\nlanguage comprehension can be shallow or `good enough': given constraints on\ntime or available computation, comprehenders may form interpretations of their\ninput that are plausible but inaccurate. However, this idea has not yet been\nlinked with formal theories of computation under resource constraints. Here we\nuse information theory to formulate a model of language comprehension as an\noptimal trade-off between accuracy and processing depth, formalized as bits of\ninformation extracted from the input, which increases with processing time. The\nmodel provides a measure of processing effort as the change in processing\ndepth, which we link to EEG signals and reading times. We validate our theory\nagainst a large-scale dataset of garden path sentence reading times, and EEG\nexperiments featuring N400, P600 and biphasic ERP effects. By quantifying the\ntimecourse of language processing as it proceeds from shallow to deep, our\nmodel provides a unified framework to explain behavioral and neural signatures\nof language comprehension.", "published": "2024-05-13 22:29:33", "link": "http://arxiv.org/abs/2405.08223v1", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "A predictive learning model can simulate temporal dynamics and context\n  effects found in neural representations of continuous speech", "abstract": "Speech perception involves storing and integrating sequentially presented\nitems. Recent work in cognitive neuroscience has identified temporal and\ncontextual characteristics in humans' neural encoding of speech that may\nfacilitate this temporal processing. In this study, we simulated similar\nanalyses with representations extracted from a computational model that was\ntrained on unlabelled speech with the learning objective of predicting upcoming\nacoustics. Our simulations revealed temporal dynamics similar to those in brain\nsignals, implying that these properties can arise without linguistic knowledge.\nAnother property shared between brains and the model is that the encoding\npatterns of phonemes support some degree of cross-context generalization.\nHowever, we found evidence that the effectiveness of these generalizations\ndepends on the specific contexts, which suggests that this analysis alone is\ninsufficient to support the presence of context-invariant encoding.", "published": "2024-05-13 23:36:19", "link": "http://arxiv.org/abs/2405.08237v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Silver-Tongued and Sundry: Exploring Intersectional Pronouns with\n  ChatGPT", "abstract": "ChatGPT is a conversational agent built on a large language model. Trained on\na significant portion of human output, ChatGPT can mimic people to a degree. As\nsuch, we need to consider what social identities ChatGPT simulates (or can be\ndesigned to simulate). In this study, we explored the case of identity\nsimulation through Japanese first-person pronouns, which are tightly connected\nto social identities in intersectional ways, i.e., intersectional pronouns. We\nconducted a controlled online experiment where people from two regions in Japan\n(Kanto and Kinki) witnessed interactions with ChatGPT using ten sets of\nfirst-person pronouns. We discovered that pronouns alone can evoke perceptions\nof social identities in ChatGPT at the intersections of gender, age, region,\nand formality, with caveats. This work highlights the importance of pronoun use\nfor social identity simulation, provides a language-based methodology for\nculturally-sensitive persona development, and advances the potential of\nintersectional identities in intelligent agents.", "published": "2024-05-13 23:38:50", "link": "http://arxiv.org/abs/2405.08238v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "News Recommendation with Category Description by a Large Language Model", "abstract": "Personalized news recommendations are essential for online news platforms to\nassist users in discovering news articles that match their interests from a\nvast amount of online content. Appropriately encoded content features, such as\ntext, categories, and images, are essential for recommendations. Among these\nfeatures, news categories, such as tv-golden-globe, finance-real-estate, and\nnews-politics, play an important role in understanding news content, inspiring\nus to enhance the categories' descriptions. In this paper, we propose a novel\nmethod that automatically generates informative category descriptions using a\nlarge language model (LLM) without manual effort or domain-specific knowledge\nand incorporates them into recommendation models as additional information. In\nour comprehensive experimental evaluations using the MIND dataset, our method\nsuccessfully achieved 5.8% improvement at most in AUC compared with baseline\napproaches without the LLM's generated category descriptions for the\nstate-of-the-art content-based recommendation models including NAML, NRMS, and\nNPA. These results validate the effectiveness of our approach. The code is\navailable at https://github.com/yamanalab/gpt-augmented-news-recommendation.", "published": "2024-05-13 08:53:43", "link": "http://arxiv.org/abs/2405.13007v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unveiling Social Media Comments with a Novel Named Entity Recognition\n  System for Identity Groups", "abstract": "While civilized users employ social media to stay informed and discuss daily\noccurrences, haters perceive these platforms as fertile ground for attacking\ngroups and individuals. The prevailing approach to counter this phenomenon\ninvolves detecting such attacks by identifying toxic language. Effective\nplatform measures aim to report haters and block their network access. In this\ncontext, employing hate speech detection methods aids in identifying these\nattacks amidst vast volumes of text, which are impossible for humans to analyze\nmanually. In our study, we expand upon the usual hate speech detection methods,\ntypically based on text classifiers, to develop a Named Entity Recognition\n(NER) System for Identity Groups. To achieve this, we created a dataset that\nallows extending a conventional NER to recognize identity groups. Consequently,\nour tool not only detects whether a sentence contains an attack but also tags\nthe sentence tokens corresponding to the mentioned group. Results indicate that\nthe model performs competitively in identifying groups with an average f1-score\nof 0.75, outperforming in identifying ethnicity attack spans with an f1-score\nof 0.80 compared to other identity groups. Moreover, the tool shows an\noutstanding generalization capability to minority classes concerning sexual\norientation and gender, achieving an f1-score of 0.77 and 0.72, respectively.\nWe tested the utility of our tool in a case study on social media, annotating\nand comparing comments from Facebook related to news mentioning identity\ngroups. The case study reveals differences in the types of attacks recorded,\neffectively detecting named entities related to the categories of the analyzed\nnews articles. Entities are accurately tagged within their categories, with a\nnegligible error rate for inter-category tagging.", "published": "2024-05-13 19:33:18", "link": "http://arxiv.org/abs/2405.13011v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CataLM: Empowering Catalyst Design Through Large Language Models", "abstract": "The field of catalysis holds paramount importance in shaping the trajectory\nof sustainable development, prompting intensive research efforts to leverage\nartificial intelligence (AI) in catalyst design. Presently, the fine-tuning of\nopen-source large language models (LLMs) has yielded significant breakthroughs\nacross various domains such as biology and healthcare. Drawing inspiration from\nthese advancements, we introduce CataLM Cata}lytic Language Model), a large\nlanguage model tailored to the domain of electrocatalytic materials. Our\nfindings demonstrate that CataLM exhibits remarkable potential for facilitating\nhuman-AI collaboration in catalyst knowledge exploration and design. To the\nbest of our knowledge, CataLM stands as the pioneering LLM dedicated to the\ncatalyst domain, offering novel avenues for catalyst discovery and development.", "published": "2024-05-13 03:19:47", "link": "http://arxiv.org/abs/2405.17440v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment\n  Generation", "abstract": "Singing Accompaniment Generation (SAG), which generates instrumental music to\naccompany input vocals, is crucial to developing human-AI symbiotic art\ncreation systems. The state-of-the-art method, SingSong, utilizes a multi-stage\nautoregressive (AR) model for SAG, however, this method is extremely slow as it\ngenerates semantic and acoustic tokens recursively, and this makes it\nimpossible for real-time applications. In this paper, we aim to develop a Fast\nSAG method that can create high-quality and coherent accompaniments. A non-AR\ndiffusion-based framework is developed, which by carefully designing the\nconditions inferred from the vocal signals, generates the Mel spectrogram of\nthe target accompaniment directly. With diffusion and Mel spectrogram modeling,\nthe proposed method significantly simplifies the AR token-based SingSong\nframework, and largely accelerates the generation. We also design semantic\nprojection, prior projection blocks as well as a set of loss functions, to\nensure the generated accompaniment has semantic and rhythm coherence with the\nvocal signal. By intensive experimental studies, we demonstrate that the\nproposed method can generate better samples than SingSong, and accelerate the\ngeneration by at least 30 times. Audio samples and code are available at\nhttps://fastsag.github.io/.", "published": "2024-05-13 12:14:54", "link": "http://arxiv.org/abs/2405.07682v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Non-Random Data Encodes its Geometric and Topological Dimensions", "abstract": "Based on the principles of information theory, measure theory, and\ntheoretical computer science, we introduce a signal deconvolution method with a\nwide range of applications to coding theory, particularly in zero-knowledge\none-way communication channels, such as in deciphering messages (i.e., objects\nembedded into multidimensional spaces) from unknown generating sources about\nwhich no prior knowledge is available and to which no return message can be\nsent. Our multidimensional space reconstruction method from an arbitrary\nreceived signal is proven to be agnostic vis-\\`a-vis the encoding-decoding\nscheme, computation model, programming language, formal theory, the computable\n(or semi-computable) method of approximation to algorithmic complexity, and any\narbitrarily chosen (computable) probability measure. The method derives from\nthe principles of an approach to Artificial General Intelligence (AGI) capable\nof building a general-purpose model of models independent of any arbitrarily\nassumed prior probability distribution. We argue that this optimal and\nuniversal method of decoding non-random data has applications to signal\nprocessing, causal deconvolution, topological and geometric properties\nencoding, cryptography, and bio- and technosignature detection.", "published": "2024-05-13 14:45:08", "link": "http://arxiv.org/abs/2405.07803v3", "categories": ["cs.IT", "cs.CL", "cs.CR", "cs.IR", "math.IT", "math.ST", "stat.TH"], "primary_category": "cs.IT"}
{"title": "Evaluating Speech Enhancement Systems Through Listening Effort", "abstract": "Understanding degraded speech is demanding, requiring increased listening\neffort (LE). Evaluating processed and unprocessed speech with respect to LE can\nobjectively indicate if speech enhancement systems benefit listeners. However,\nexisting methods for measuring LE are complex and not widely applicable. In\nthis study, we propose a simple method to evaluate speech intelligibility and\nLE simultaneously without additional strain on subjects or operators. We assess\nthis method using results from two independent studies in Norway and Denmark,\ntesting 76 (50+26) subjects across 9 (6+3) processing conditions. Despite\ndifferences in evaluation setups, subject recruitment, and processing systems,\ntrends are strikingly similar, demonstrating the proposed method's robustness\nand ease of implementation into existing practices.", "published": "2024-05-13 11:00:27", "link": "http://arxiv.org/abs/2405.07641v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Semantic MIMO Systems for Speech-to-Text Transmission", "abstract": "Semantic communications have been utilized to execute numerous intelligent\ntasks by transmitting task-related semantic information instead of bits. In\nthis article, we propose a semantic-aware speech-to-text transmission system\nfor the single-user multiple-input multiple-output (MIMO) and multi-user MIMO\ncommunication scenarios, named SAC-ST. Particularly, a semantic communication\nsystem to serve the speech-to-text task at the receiver is first designed,\nwhich compresses the semantic information and generates the low-dimensional\nsemantic features by leveraging the transformer module. In addition, a novel\nsemantic-aware network is proposed to facilitate transmission with high\nsemantic fidelity by identifying the critical semantic information and\nguaranteeing its accurate recovery. Furthermore, we extend the SAC-ST with a\nneural network-enabled channel estimation network to mitigate the dependence on\naccurate channel state information and validate the feasibility of SAC-ST in\npractical communication environments. Simulation results will show that the\nproposed SAC-ST outperforms the communication framework without the\nsemantic-aware network for speech-to-text transmission over the MIMO channels\nin terms of the speech-to-text metrics, especially in the low signal-to-noise\nregime. Moreover, the SAC-ST with the developed channel estimation network is\ncomparable to the SAC-ST with perfect channel state information.", "published": "2024-05-13 18:22:02", "link": "http://arxiv.org/abs/2405.08096v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Rene: A Pre-trained Multi-modal Architecture for Auscultation of\n  Respiratory Diseases", "abstract": "Compared with invasive examinations that require tissue sampling, respiratory\nsound testing is a non-invasive examination method that is safer and easier for\npatients to accept. In this study, we introduce Rene, a pioneering large-scale\nmodel tailored for respiratory sound recognition. Rene has been rigorously\nfine-tuned with an extensive dataset featuring a broad array of respiratory\naudio samples, targeting disease detection, sound pattern classification, and\nevent identification. Our innovative approach applies a pre-trained speech\nrecognition model to process respiratory sounds, augmented with patient medical\nrecords. The resulting multi-modal deep-learning framework addresses\ninterpretability and real-time diagnostic challenges that have hindered\nprevious respiratory-focused models. Benchmark comparisons reveal that Rene\nsignificantly outperforms existing models, achieving improvements of 10.27%,\n16.15%, 15.29%, and 18.90% in respiratory event detection and audio\nclassification on the SPRSound database. Disease prediction accuracy on the\nICBHI database improved by 23% over the baseline in both mean average and\nharmonic scores. Moreover, we have developed a real-time respiratory sound\ndiscrimination system utilizing the Rene architecture. Employing\nstate-of-the-art Edge AI technology, this system enables rapid and accurate\nresponses for respiratory sound\nauscultation(https://github.com/zpforlove/Rene).", "published": "2024-05-13 03:00:28", "link": "http://arxiv.org/abs/2405.07442v2", "categories": ["cs.SD", "cs.AI", "eess.AS", "q-bio.QM"], "primary_category": "cs.SD"}
{"title": "Improving Multimodal Learning with Multi-Loss Gradient Modulation", "abstract": "Learning from multiple modalities, such as audio and video, offers\nopportunities for leveraging complementary information, enhancing robustness,\nand improving contextual understanding and performance. However, combining such\nmodalities presents challenges, especially when modalities differ in data\nstructure, predictive contribution, and the complexity of their learning\nprocesses. It has been observed that one modality can potentially dominate the\nlearning process, hindering the effective utilization of information from other\nmodalities and leading to sub-optimal model performance. To address this issue\nthe vast majority of previous works suggest to assess the unimodal\ncontributions and dynamically adjust the training to equalize them. We improve\nupon previous work by introducing a multi-loss objective and further refining\nthe balancing process, allowing it to dynamically adjust the learning pace of\neach modality in both directions, acceleration and deceleration, with the\nability to phase out balancing effects upon convergence. We achieve superior\nresults across three audio-video datasets: on CREMA-D, models with ResNet\nbackbone encoders surpass the previous best by 1.9% to 12.4%, and Conformer\nbackbone models deliver improvements ranging from 2.8% to 14.1% across\ndifferent fusion methods. On AVE, improvements range from 2.7% to 7.7%, while\non UCF101, gains reach up to 6.1%.", "published": "2024-05-13 17:01:28", "link": "http://arxiv.org/abs/2405.07930v2", "categories": ["cs.MM", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
