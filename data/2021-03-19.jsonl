{"title": "Extractive Summarization of Call Transcripts", "abstract": "Text summarization is the process of extracting the most important\ninformation from the text and presenting it concisely in fewer sentences. Call\ntranscript is a text that involves textual description of a phone conversation\nbetween a customer (caller) and agent(s) (customer representatives). This paper\npresents an indigenously developed method that combines topic modeling and\nsentence selection with punctuation restoration in condensing ill-punctuated or\nun-punctuated call transcripts to produce summaries that are more readable.\nExtensive testing, evaluation and comparisons have demonstrated the efficacy of\nthis summarizer for call transcript summarization.", "published": "2021-03-19 02:40:59", "link": "http://arxiv.org/abs/2103.10599v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MuRIL: Multilingual Representations for Indian Languages", "abstract": "India is a multilingual society with 1369 rationalized languages and dialects\nbeing spoken across the country (INDIA, 2011). Of these, the 22 scheduled\nlanguages have a staggering total of 1.17 billion speakers and 121 languages\nhave more than 10,000 speakers (INDIA, 2011). India also has the second largest\n(and an ever growing) digital footprint (Statista, 2020). Despite this, today's\nstate-of-the-art multilingual systems perform suboptimally on Indian (IN)\nlanguages. This can be explained by the fact that multilingual language models\n(LMs) are often trained on 100+ languages together, leading to a small\nrepresentation of IN languages in their vocabulary and training data.\nMultilingual LMs are substantially less effective in resource-lean scenarios\n(Wu and Dredze, 2020; Lauscher et al., 2020), as limited data doesn't help\ncapture the various nuances of a language. One also commonly observes IN\nlanguage text transliterated to Latin or code-mixed with English, especially in\ninformal settings (for example, on social media platforms) (Rijhwani et al.,\n2017). This phenomenon is not adequately handled by current state-of-the-art\nmultilingual LMs. To address the aforementioned gaps, we propose MuRIL, a\nmultilingual LM specifically built for IN languages. MuRIL is trained on\nsignificantly large amounts of IN text corpora only. We explicitly augment\nmonolingual text corpora with both translated and transliterated document\npairs, that serve as supervised cross-lingual signals in training. MuRIL\nsignificantly outperforms multilingual BERT (mBERT) on all tasks in the\nchallenging cross-lingual XTREME benchmark (Hu et al., 2020). We also present\nresults on transliterated (native to Latin script) test sets of the chosen\ndatasets and demonstrate the efficacy of MuRIL in handling transliterated data.", "published": "2021-03-19 11:06:37", "link": "http://arxiv.org/abs/2103.10730v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Congolese Swahili Machine Translation for Humanitarian Response", "abstract": "In this paper we describe our efforts to make a bidirectional Congolese\nSwahili (SWC) to French (FRA) neural machine translation system with the\nmotivation of improving humanitarian translation workflows. For training, we\ncreated a 25,302-sentence general domain parallel corpus and combined it with\npublicly available data. Experimenting with low-resource methodologies like\ncross-dialect transfer and semi-supervised learning, we recorded improvements\nof up to 2.4 and 3.5 BLEU points in the SWC-FRA and FRA-SWC directions,\nrespectively. We performed human evaluations to assess the usability of our\nmodels in a COVID-domain chatbot that operates in the Democratic Republic of\nCongo (DRC). Direct assessment in the SWC-FRA direction demonstrated an average\nquality ranking of 6.3 out of 10 with 75% of the target strings conveying the\nmain message of the source text. For the FRA-SWC direction, our preliminary\ntests on post-editing assessment showed its potential usefulness for\nmachine-assisted translation. We make our models, datasets containing up to 1\nmillion sentences, our development pipeline, and a translator web-app available\nfor public use.", "published": "2021-03-19 11:15:48", "link": "http://arxiv.org/abs/2103.10734v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conceptual similarity and communicative need shape colexification: an\n  experimental study", "abstract": "Colexification refers to the phenomenon of multiple meanings sharing one word\nin a language. Cross-linguistic lexification patterns have been shown to be\nlargely predictable, as similar concepts are often colexified. We test a recent\nclaim that, beyond this general tendency, communicative needs play an important\nrole in shaping colexification patterns. We approach this question by means of\na series of human experiments, using an artificial language communication game\nparadigm. Our results across four experiments match the previous\ncross-linguistic findings: all other things being equal, speakers do prefer to\ncolexify similar concepts. However, we also find evidence supporting the\ncommunicative need hypothesis: when faced with a frequent need to distinguish\nsimilar pairs of meanings, speakers adjust their colexification preferences to\nmaintain communicative efficiency, and avoid colexifying those similar meanings\nwhich need to be distinguished in communication. This research provides further\nevidence to support the argument that languages are shaped by the needs and\npreferences of their speakers.", "published": "2021-03-19 21:18:16", "link": "http://arxiv.org/abs/2103.11024v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cost-effective Deployment of BERT Models in Serverless Environment", "abstract": "In this study we demonstrate the viability of deploying BERT-style models to\nserverless environments in a production setting. Since the freely available\npre-trained models are too large to be deployed in this way, we utilize\nknowledge distillation and fine-tune the models on proprietary datasets for two\nreal-world tasks: sentiment analysis and semantic textual similarity. As a\nresult, we obtain models that are tuned for a specific domain and deployable in\nserverless environments. The subsequent performance analysis shows that this\nsolution results in latency levels acceptable for production use and that it is\nalso a cost-effective approach for small-to-medium size deployments of BERT\nmodels, all without any infrastructure overhead.", "published": "2021-03-19 07:45:17", "link": "http://arxiv.org/abs/2103.10673v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Masked Conditional Random Fields for Sequence Labeling", "abstract": "Conditional Random Field (CRF) based neural models are among the most\nperformant methods for solving sequence labeling problems. Despite its great\nsuccess, CRF has the shortcoming of occasionally generating illegal sequences\nof tags, e.g. sequences containing an \"I-\" tag immediately after an \"O\" tag,\nwhich is forbidden by the underlying BIO tagging scheme. In this work, we\npropose Masked Conditional Random Field (MCRF), an easy to implement variant of\nCRF that impose restrictions on candidate paths during both training and\ndecoding phases. We show that the proposed method thoroughly resolves this\nissue and brings consistent improvement over existing CRF-based models with\nnear zero additional cost.", "published": "2021-03-19 08:23:24", "link": "http://arxiv.org/abs/2103.10682v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Acoustic word embeddings for zero-resource languages using\n  self-supervised contrastive learning and multilingual adaptation", "abstract": "Acoustic word embeddings (AWEs) are fixed-dimensional representations of\nvariable-length speech segments. For zero-resource languages where labelled\ndata is not available, one AWE approach is to use unsupervised\nautoencoder-based recurrent models. Another recent approach is to use\nmultilingual transfer: a supervised AWE model is trained on several\nwell-resourced languages and then applied to an unseen zero-resource language.\nWe consider how a recent contrastive learning loss can be used in both the\npurely unsupervised and multilingual transfer settings. Firstly, we show that\nterms from an unsupervised term discovery system can be used for contrastive\nself-supervision, resulting in improvements over previous unsupervised\nmonolingual AWE models. Secondly, we consider how multilingual AWE models can\nbe adapted to a specific zero-resource language using discovered terms. We find\nthat self-supervised contrastive adaptation outperforms adapted multilingual\ncorrespondence autoencoder and Siamese AWE models, giving the best overall\nresults in a word discrimination task on six zero-resource languages.", "published": "2021-03-19 11:08:35", "link": "http://arxiv.org/abs/2103.10731v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Play the Shannon Game With Language Models: A Human-Free Approach to\n  Summary Evaluation", "abstract": "The goal of a summary is to concisely state the most important information in\na document. With this principle in mind, we introduce new reference-free\nsummary evaluation metrics that use a pretrained language model to estimate the\ninformation content shared between a document and its summary. These metrics\nare a modern take on the Shannon Game, a method for summary quality scoring\nproposed decades ago, where we replace human annotators with language models.\nWe also view these metrics as an extension of BLANC, a recently proposed\napproach to summary quality measurement based on the performance of a language\nmodel with and without the help of a summary. Using transformer based language\nmodels, we empirically verify that our metrics achieve state-of-the-art\ncorrelation with human judgement of the summary quality dimensions of both\ncoherence and relevance, as well as competitive correlation with human\njudgement of consistency and fluency.", "published": "2021-03-19 17:27:58", "link": "http://arxiv.org/abs/2103.10918v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "API2Com: On the Improvement of Automatically Generated Code Comments\n  Using API Documentations", "abstract": "Code comments can help in program comprehension and are considered as\nimportant artifacts to help developers in software maintenance. However, the\ncomments are mostly missing or are outdated, specially in complex software\nprojects. As a result, several automatic comment generation models are\ndeveloped as a solution. The recent models explore the integration of external\nknowledge resources such as Unified Modeling Language class diagrams to improve\nthe generated comments. In this paper, we propose API2Com, a model that\nleverages the Application Programming Interface Documentations (API Docs) as a\nknowledge resource for comment generation. The API Docs include the description\nof the methods in more details and therefore, can provide better context in the\ngenerated comments. The API Docs are used along with the code snippets and\nAbstract Syntax Trees in our model. We apply the model on a large Java dataset\nof over 130,000 methods and evaluate it using both Transformer and RNN-base\narchitectures. Interestingly, when API Docs are used, the performance increase\nis negligible. We therefore run different experiments to reason about the\nresults. For methods that only contain one API, adding API Docs improves the\nresults by 4% BLEU score on average (BLEU score is an automatic evaluation\nmetric used in machine translation). However, as the number of APIs that are\nused in a method increases, the performance of the model in generating comments\ndecreases due to long documentations used in the input. Our results confirm\nthat the API Docs can be useful in generating better comments, but, new\ntechniques are required to identify the most informative ones in a method\nrather than using all documentations simultaneously.", "published": "2021-03-19 07:29:40", "link": "http://arxiv.org/abs/2103.10668v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Controllable Generation from Pre-trained Language Models via Inverse\n  Prompting", "abstract": "Large-scale pre-trained language models have demonstrated strong capabilities\nof generating realistic text. However, it remains challenging to control the\ngeneration results. Previous approaches such as prompting are far from\nsufficient, which limits the usage of language models. To tackle this\nchallenge, we propose an innovative method, inverse prompting, to better\ncontrol text generation. The core idea of inverse prompting is to use generated\ntext to inversely predict the prompt during beam search, which enhances the\nrelevance between the prompt and the generated text and provides better\ncontrollability. Empirically, we pre-train a large-scale Chinese language model\nto perform a systematic study using human evaluation on the tasks of\nopen-domain poem generation and open-domain long-form question answering. Our\nresults show that our proposed method substantially outperforms the baselines\nand that our generation quality is close to human performance on some of the\ntasks.\n  Narrators can try our poem generation demo at\nhttps://pretrain.aminer.cn/apps/poetry.html, while our QA demo can be found at\nhttps://pretrain.aminer.cn/app/qa. For researchers, the code is provided in\nhttps://github.com/THUDM/InversePrompting.", "published": "2021-03-19 08:36:52", "link": "http://arxiv.org/abs/2103.10685v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Attention-based model for predicting question relatedness on Stack\n  Overflow", "abstract": "Stack Overflow is one of the most popular Programming Community-based\nQuestion Answering (PCQA) websites that has attracted more and more users in\nrecent years. When users raise or inquire questions in Stack Overflow,\nproviding related questions can help them solve problems. Although there are\nmany approaches based on deep learning that can automatically predict the\nrelatedness between questions, those approaches are limited since interaction\ninformation between two questions may be lost. In this paper, we adopt the deep\nlearning technique, propose an Attention-based Sentence pair Interaction Model\n(ASIM) to predict the relatedness between questions on Stack Overflow\nautomatically. We adopt the attention mechanism to capture the semantic\ninteraction information between the questions. Besides, we have pre-trained and\nreleased word embeddings specific to the software engineering domain for this\ntask, which may also help other related tasks. The experiment results\ndemonstrate that ASIM has made significant improvement over the baseline\napproaches in Precision, Recall, and Micro-F1 evaluation metrics, achieving\nstate-of-the-art performance in this task. Our model also performs well in the\nduplicate question detection task of AskUbuntu, which is a similar but\ndifferent task, proving its generalization and robustness.", "published": "2021-03-19 12:18:03", "link": "http://arxiv.org/abs/2103.10763v6", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Let Your Heart Speak in its Mother Tongue: Multilingual Captioning of\n  Cardiac Signals", "abstract": "Cardiac signals, such as the electrocardiogram, convey a significant amount\nof information about the health status of a patient which is typically\nsummarized by a clinician in the form of a clinical report, a cumbersome\nprocess that is prone to errors. To streamline this routine process, we propose\na deep neural network capable of captioning cardiac signals; it receives a\ncardiac signal as input and generates a clinical report as output. We extend\nthis further to generate multilingual reports. To that end, we create and make\npublicly available a multilingual clinical report dataset. In the absence of\nsufficient labelled data, deep neural networks can benefit from a warm-start,\nor pre-training, procedure in which parameters are first learned in an\narbitrary task. We propose such a task in the form of discriminative\nmultilingual pre-training where tokens from clinical reports are randomly\nreplaced with those from other languages and the network is tasked with\npredicting the language of all tokens. We show that our method performs on par\nwith state-of-the-art pre-training methods such as MLM, ELECTRA, and MARGE,\nwhile simultaneously generating diverse and plausible clinical reports. We also\ndemonstrate that multilingual models can outperform their monolingual\ncounterparts, informally terming this beneficial phenomenon as the blessing of\nmultilinguality.", "published": "2021-03-19 20:30:13", "link": "http://arxiv.org/abs/2103.11011v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TextEssence: A Tool for Interactive Analysis of Semantic Shifts Between\n  Corpora", "abstract": "Embeddings of words and concepts capture syntactic and semantic regularities\nof language; however, they have seen limited use as tools to study\ncharacteristics of different corpora and how they relate to one another. We\nintroduce TextEssence, an interactive system designed to enable comparative\nanalysis of corpora using embeddings. TextEssence includes visual,\nneighbor-based, and similarity-based modes of embedding analysis in a\nlightweight, web-based interface. We further propose a new measure of embedding\nconfidence based on nearest neighborhood overlap, to assist in identifying\nhigh-quality embeddings for corpus analysis. A case study on COVID-19\nscientific literature illustrates the utility of the system. TextEssence is\navailable from https://github.com/drgriffis/text-essence.", "published": "2021-03-19 21:26:28", "link": "http://arxiv.org/abs/2103.11029v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "SoK: A Modularized Approach to Study the Security of Automatic Speech\n  Recognition Systems", "abstract": "With the wide use of Automatic Speech Recognition (ASR) in applications such\nas human machine interaction, simultaneous interpretation, audio transcription,\netc., its security protection becomes increasingly important. Although recent\nstudies have brought to light the weaknesses of popular ASR systems that enable\nout-of-band signal attack, adversarial attack, etc., and further proposed\nvarious remedies (signal smoothing, adversarial training, etc.), a systematic\nunderstanding of ASR security (both attacks and defenses) is still missing,\nespecially on how realistic such threats are and how general existing\nprotection could be. In this paper, we present our systematization of knowledge\nfor ASR security and provide a comprehensive taxonomy for existing work based\non a modularized workflow. More importantly, we align the research in this\ndomain with that on security in Image Recognition System (IRS), which has been\nextensively studied, using the domain knowledge in the latter to help\nunderstand where we stand in the former. Generally, both IRS and ASR are\nperceptual systems. Their similarities allow us to systematically study\nexisting literature in ASR security based on the spectrum of attacks and\ndefense solutions proposed for IRS, and pinpoint the directions of more\nadvanced attacks and the directions potentially leading to more effective\nprotection in ASR. In contrast, their differences, especially the complexity of\nASR compared with IRS, help us learn unique challenges and opportunities in ASR\nsecurity. Particularly, our experimental study shows that transfer learning\nacross ASR models is feasible, even in the absence of knowledge about models\n(even their types) and training data.", "published": "2021-03-19 06:24:04", "link": "http://arxiv.org/abs/2103.10651v2", "categories": ["cs.CR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "USTC-NELSLIP System Description for DIHARD-III Challenge", "abstract": "This system description describes our submission system to the Third DIHARD\nSpeech Diarization Challenge. Besides the traditional clustering based system,\nthe innovation of our system lies in the combination of various front-end\ntechniques to solve the diarization problem, including speech separation and\ntarget-speaker based voice activity detection (TS-VAD), combined with iterative\ndata purification. We also adopted audio domain classification to design\ndomain-dependent processing. Finally, we performed post processing to do system\nfusion and selection. Our best system achieved DERs of 11.30% in track 1 and\n16.78% in track 2 on evaluation set, respectively.", "published": "2021-03-19 07:00:51", "link": "http://arxiv.org/abs/2103.10661v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
