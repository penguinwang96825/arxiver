{"title": "FinBERT-MRC: financial named entity recognition using BERT under the\n  machine reading comprehension paradigm", "abstract": "Financial named entity recognition (FinNER) from literature is a challenging\ntask in the field of financial text information extraction, which aims to\nextract a large amount of financial knowledge from unstructured texts. It is\nwidely accepted to use sequence tagging frameworks to implement FinNER tasks.\nHowever, such sequence tagging models cannot fully take advantage of the\nsemantic information in the texts. Instead, we formulate the FinNER task as a\nmachine reading comprehension (MRC) problem and propose a new model termed\nFinBERT-MRC. This formulation introduces significant prior information by\nutilizing well-designed queries, and extracts start index and end index of\ntarget entities without decoding modules such as conditional random fields\n(CRF). We conduct experiments on a publicly available Chinese financial dataset\nChFinAnn and a real-word bussiness dataset AdminPunish. FinBERT-MRC model\nachieves average F1 scores of 92.78% and 96.80% on the two datasets,\nrespectively, with average F1 gains +3.94% and +0.89% over some sequence\ntagging models including BiLSTM-CRF, BERT-Tagger, and BERT-CRF. The source code\nis available at https://github.com/zyz0000/FinBERT-MRC.", "published": "2022-05-31 00:44:57", "link": "http://arxiv.org/abs/2205.15485v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Event-Level Sentiment Analysis with Structured Arguments", "abstract": "Previous studies about event-level sentiment analysis (SA) usually model the\nevent as a topic, a category or target terms, while the structured arguments\n(e.g., subject, object, time and location) that have potential effects on the\nsentiment are not well studied. In this paper, we redefine the task as\nstructured event-level SA and propose an End-to-End Event-level Sentiment\nAnalysis ($\\textit{E}^{3}\\textit{SA}$) approach to solve this issue.\nSpecifically, we explicitly extract and model the event structure information\nfor enhancing event-level SA. Extensive experiments demonstrate the great\nadvantages of our proposed approach over the state-of-the-art methods. Noting\nthe lack of the dataset, we also release a large-scale real-world dataset with\nevent arguments and sentiment labelling for promoting more\nresearches\\footnote{The dataset is available at\nhttps://github.com/zhangqi-here/E3SA}.", "published": "2022-05-31 02:44:24", "link": "http://arxiv.org/abs/2205.15511v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured\n  Sentiment Analysis", "abstract": "Structured sentiment analysis, which aims to extract the complex semantic\nstructures such as holders, expressions, targets, and polarities, has obtained\nwidespread attention from both industry and academia. Unfortunately, the\nexisting structured sentiment analysis datasets refer to a few languages and\nare relatively small, limiting neural network models' performance. In this\npaper, we focus on the cross-lingual structured sentiment analysis task, which\naims to transfer the knowledge from the source language to the target one.\nNotably, we propose a Knowledge-Enhanced Adversarial Model (\\texttt{KEAM}) with\nboth implicit distributed and explicit structural knowledge to enhance the\ncross-lingual transfer. First, we design an adversarial embedding adapter for\nlearning an informative and robust representation by capturing implicit\nsemantic information from diverse multi-lingual embeddings adaptively. Then, we\npropose a syntax GCN encoder to transfer the explicit semantic information\n(e.g., universal dependency tree) among multiple languages. We conduct\nexperiments on five datasets and compare \\texttt{KEAM} with both the supervised\nand unsupervised methods. The extensive experimental results show that our\n\\texttt{KEAM} model outperforms all the unsupervised baselines in various\nmetrics.", "published": "2022-05-31 03:07:51", "link": "http://arxiv.org/abs/2205.15514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-level Supervised Contrastive Learning Framework for Low-Resource\n  Natural Language Inference", "abstract": "Natural Language Inference (NLI) is a growingly essential task in natural\nlanguage understanding, which requires inferring the relationship between the\nsentence pairs (premise and hypothesis). Recently, low-resource natural\nlanguage inference has gained increasing attention, due to significant savings\nin manual annotation costs and a better fit with real-world scenarios. Existing\nworks fail to characterize discriminative representations between different\nclasses with limited training data, which may cause faults in label prediction.\nHere we propose a multi-level supervised contrastive learning framework named\nMultiSCL for low-resource natural language inference. MultiSCL leverages a\nsentence-level and pair-level contrastive learning objective to discriminate\nbetween different classes of sentence pairs by bringing those in one class\ntogether and pushing away those in different classes. MultiSCL adopts a data\naugmentation module that generates different views for input samples to better\nlearn the latent representation. The pair-level representation is obtained from\na cross attention module. We conduct extensive experiments on two public NLI\ndatasets in low-resource settings, and the accuracy of MultiSCL exceeds other\nmodels by 3.1% on average. Moreover, our method outperforms the previous\nstate-of-the-art method on cross-domain tasks of text classification.", "published": "2022-05-31 05:54:18", "link": "http://arxiv.org/abs/2205.15550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "hmBERT: Historical Multilingual Language Models for Named Entity\n  Recognition", "abstract": "Compared to standard Named Entity Recognition (NER), identifying persons,\nlocations, and organizations in historical texts constitutes a big challenge.\nTo obtain machine-readable corpora, the historical text is usually scanned and\nOptical Character Recognition (OCR) needs to be performed. As a result, the\nhistorical corpora contain errors. Also, entities like location or organization\ncan change over time, which poses another challenge. Overall, historical texts\ncome with several peculiarities that differ greatly from modern texts and large\nlabeled corpora for training a neural tagger are hardly available for this\ndomain. In this work, we tackle NER for historical German, English, French,\nSwedish, and Finnish by training large historical language models. We\ncircumvent the need for large amounts of labeled data by using unlabeled data\nfor pretraining a language model. We propose hmBERT, a historical multilingual\nBERT-based language model, and release the model in several versions of\ndifferent sizes. Furthermore, we evaluate the capability of hmBERT by solving\ndownstream NER as part of this year's HIPE-2022 shared task and provide\ndetailed analysis and insights. For the Multilingual Classical Commentary\ncoarse-grained NER challenge, our tagger HISTeria outperforms the other teams'\nmodels for two out of three languages.", "published": "2022-05-31 07:30:33", "link": "http://arxiv.org/abs/2205.15575v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Preparing an Endangered Language for the Digital Age: The Case of\n  Judeo-Spanish", "abstract": "We develop machine translation and speech synthesis systems to complement the\nefforts of revitalizing Judeo-Spanish, the exiled language of Sephardic Jews,\nwhich survived for centuries, but now faces the threat of extinction in the\ndigital age. Building on resources created by the Sephardic community of Turkey\nand elsewhere, we create corpora and tools that would help preserve this\nlanguage for future generations. For machine translation, we first develop a\nSpanish to Judeo-Spanish rule-based machine translation system, in order to\ngenerate large volumes of synthetic parallel data in the relevant language\npairs: Turkish, English and Spanish. Then, we train baseline neural machine\ntranslation engines using this synthetic data and authentic parallel data\ncreated from translations by the Sephardic community. For text-to-speech\nsynthesis, we present a 3.5 hour single speaker speech corpus for building a\nneural speech synthesis engine. Resources, model weights and online inference\nengines are shared publicly.", "published": "2022-05-31 08:26:33", "link": "http://arxiv.org/abs/2205.15599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "APPReddit: a Corpus of Reddit Posts Annotated for Appraisal", "abstract": "Despite the large number of computational resources for emotion recognition,\nthere is a lack of data sets relying on appraisal models. According to\nAppraisal theories, emotions are the outcome of a multi-dimensional evaluation\nof events. In this paper, we present APPReddit, the first corpus of\nnon-experimental data annotated according to this theory. After describing its\ndevelopment, we compare our resource with enISEAR, a corpus of events created\nin an experimental setting and annotated for appraisal. Results show that the\ntwo corpora can be mapped notwithstanding different typologies of data and\nannotations schemes. A SVM model trained on APPReddit predicts four appraisal\ndimensions without significant loss. Merging both corpora in a single training\nset increases the prediction of 3 out of 4 dimensions. Such findings pave the\nway to a better performing classification model for appraisal prediction.", "published": "2022-05-31 09:11:57", "link": "http://arxiv.org/abs/2205.15627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NEWTS: A Corpus for News Topic-Focused Summarization", "abstract": "Text summarization models are approaching human levels of fidelity. Existing\nbenchmarking corpora provide concordant pairs of full and abridged versions of\nWeb, news or, professional content. To date, all summarization datasets operate\nunder a one-size-fits-all paradigm that may not reflect the full range of\norganic summarization needs. Several recently proposed models (e.g., plug and\nplay language models) have the capacity to condition the generated summaries on\na desired range of themes. These capacities remain largely unused and\nunevaluated as there is no dedicated dataset that would support the task of\ntopic-focused summarization.\n  This paper introduces the first topical summarization corpus NEWTS, based on\nthe well-known CNN/Dailymail dataset, and annotated via online crowd-sourcing.\nEach source article is paired with two reference summaries, each focusing on a\ndifferent theme of the source document. We evaluate a representative range of\nexisting techniques and analyze the effectiveness of different prompting\nmethods.", "published": "2022-05-31 10:01:38", "link": "http://arxiv.org/abs/2205.15661v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Forget Cheap Training Signals Before Building Unsupervised\n  Bilingual Word Embeddings", "abstract": "Bilingual Word Embeddings (BWEs) are one of the cornerstones of cross-lingual\ntransfer of NLP models. They can be built using only monolingual corpora\nwithout supervision leading to numerous works focusing on unsupervised BWEs.\nHowever, most of the current approaches to build unsupervised BWEs do not\ncompare their results with methods based on easy-to-access cross-lingual\nsignals. In this paper, we argue that such signals should always be considered\nwhen developing unsupervised BWE methods. The two approaches we find most\neffective are: 1) using identical words as seed lexicons (which unsupervised\napproaches incorrectly assume are not available for orthographically distinct\nlanguage pairs) and 2) combining such lexicons with pairs extracted by matching\nromanized versions of words with an edit distance threshold. We experiment on\nthirteen non-Latin languages (and English) and show that such cheap signals\nwork well and that they outperform using more complex unsupervised methods on\ndistant language pairs such as Chinese, Japanese, Kannada, Tamil, and Thai. In\naddition, they are even competitive with the use of high-quality lexicons in\nsupervised approaches. Our results show that these training signals should not\nbe neglected when building BWEs, even for distant languages.", "published": "2022-05-31 12:00:55", "link": "http://arxiv.org/abs/2205.15713v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EMS: Efficient and Effective Massively Multilingual Sentence Embedding\n  Learning", "abstract": "Massively multilingual sentence representation models, e.g., LASER,\nSBERT-distill, and LaBSE, help significantly improve cross-lingual downstream\ntasks. However, the use of a large amount of data or inefficient model\narchitectures results in heavy computation to train a new model according to\nour preferred languages and domains. To resolve this issue, we introduce\nefficient and effective massively multilingual sentence embedding (EMS), using\ncross-lingual token-level reconstruction (XTR) and sentence-level contrastive\nlearning as training objectives. Compared with related studies, the proposed\nmodel can be efficiently trained using significantly fewer parallel sentences\nand GPU computation resources. Empirical results showed that the proposed model\nsignificantly yields better or comparable results with regard to cross-lingual\nsentence retrieval, zero-shot cross-lingual genre classification, and sentiment\nclassification. Ablative analyses demonstrated the efficiency and effectiveness\nof each component of the proposed model. We release the codes for model\ntraining and the EMS pre-trained sentence embedding model, which supports 62\nlanguages ( https://github.com/Mao-KU/EMS ).", "published": "2022-05-31 12:29:25", "link": "http://arxiv.org/abs/2205.15744v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LEXpander: applying colexification networks to automated lexicon\n  expansion", "abstract": "Recent approaches to text analysis from social media and other corpora rely\non word lists to detect topics, measure meaning, or to select relevant\ndocuments. These lists are often generated by applying computational lexicon\nexpansion methods to small, manually-curated sets of root words. Despite the\nwide use of this approach, we still lack an exhaustive comparative analysis of\nthe performance of lexicon expansion methods and how they can be improved with\nadditional linguistic data. In this work, we present LEXpander, a method for\nlexicon expansion that leverages novel data on colexification, i.e. semantic\nnetworks connecting words based on shared concepts and translations to other\nlanguages. We evaluate LEXpander in a benchmark including widely used methods\nfor lexicon expansion based on various word embedding models and synonym\nnetworks. We find that LEXpander outperforms existing approaches in terms of\nboth precision and the trade-off between precision and recall of generated word\nlists in a variety of tests. Our benchmark includes several linguistic\ncategories and sentiment variables in English and German. We also show that the\nexpanded word lists constitute a high-performing text analysis method in\napplication cases to various corpora. This way, LEXpander poses a systematic\nautomated solution to expand short lists of words into exhaustive and accurate\nword lists that can closely approximate word lists generated by experts in\npsychology and linguistics.", "published": "2022-05-31 14:55:29", "link": "http://arxiv.org/abs/2205.15850v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local\n  Languages", "abstract": "Natural language processing (NLP) has a significant impact on society via\ntechnologies such as machine translation and search engines. Despite its\nsuccess, NLP technology is only widely available for high-resource languages\nsuch as English and Chinese, while it remains inaccessible to many languages\ndue to the unavailability of data resources and benchmarks. In this work, we\nfocus on developing resources for languages in Indonesia. Despite being the\nsecond most linguistically diverse country, most languages in Indonesia are\ncategorized as endangered and some are even extinct. We develop the first-ever\nparallel resource for 10 low-resource languages in Indonesia. Our resource\nincludes datasets, a multi-task benchmark, and lexicons, as well as a parallel\nIndonesian-English dataset. We provide extensive analyses and describe the\nchallenges when creating such resources. We hope that our work can spark NLP\nresearch on Indonesian and other underrepresented languages.", "published": "2022-05-31 17:03:50", "link": "http://arxiv.org/abs/2205.15960v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Usefulness of Embeddings, Clusters and Strings for Text Generator\n  Evaluation", "abstract": "A good automatic evaluation metric for language generation ideally correlates\nhighly with human judgements of text quality. Yet, there is a dearth of such\nmetrics, which inhibits the rapid and efficient progress of language\ngenerators. One exception is the recently proposed Mauve. In theory, Mauve\nmeasures an information-theoretic divergence between two probability\ndistributions over strings: one representing the language generator under\nevaluation; the other representing the true natural language distribution.\nMauve's authors argue that its success comes from the qualitative properties of\ntheir proposed divergence. Yet in practice, as this divergence is uncomputable,\nMauve approximates it by measuring the divergence between multinomial\ndistributions over clusters instead, where cluster assignments are attained by\ngrouping strings based on a pre-trained language model's embeddings. As we\nshow, however, this is not a tight approximation -- in either theory or\npractice. This begs the question: why does Mauve work so well? In this work, we\nshow that Mauve was right for the wrong reasons, and that its newly proposed\ndivergence is not necessary for its high performance. In fact, classical\ndivergences paired with its proposed cluster-based approximation may actually\nserve as better evaluation metrics. We finish the paper with a probing\nanalysis; this analysis leads us to conclude that -- by encoding syntactic- and\ncoherence-level features of text, while ignoring surface-level features -- such\ncluster-based substitutes to string distributions may simply be better for\nevaluating state-of-the-art language generators.", "published": "2022-05-31 17:58:49", "link": "http://arxiv.org/abs/2205.16001v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Unified Framework for Emotion Identification and Generation in\n  Dialogues", "abstract": "Social chatbots have gained immense popularity, and their appeal lies not\njust in their capacity to respond to the diverse requests from users, but also\nin the ability to develop an emotional connection with users. To further\ndevelop and promote social chatbots, we need to concentrate on increasing user\ninteraction and take into account both the intellectual and emotional quotient\nin the conversational agents. In this paper, we propose a multi-task framework\nthat jointly identifies the emotion of a given dialogue and generates response\nin accordance to the identified emotion. We employ a BERT based network for\ncreating an empathetic system and use a mixed objective function that trains\nthe end-to-end network with both the classification and generation loss.\nExperimental results show that our proposed framework outperforms current\nstate-of-the-art models", "published": "2022-05-31 02:58:49", "link": "http://arxiv.org/abs/2205.15513v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Refining Low-Resource Unsupervised Translation by Language\n  Disentanglement of Multilingual Model", "abstract": "Numerous recent work on unsupervised machine translation (UMT) implies that\ncompetent unsupervised translations of low-resource and unrelated languages,\nsuch as Nepali or Sinhala, are only possible if the model is trained in a\nmassive multilingual environment, where these low-resource languages are mixed\nwith high-resource counterparts. Nonetheless, while the high-resource languages\ngreatly help kick-start the target low-resource translation tasks, the language\ndiscrepancy between them may hinder their further improvement. In this work, we\npropose a simple refinement procedure to separate languages from a pre-trained\nmultilingual UMT model for it to focus on only the target low-resource task.\nOur method achieves the state of the art in the fully unsupervised translation\ntasks of English to Nepali, Sinhala, Gujarati, Latvian, Estonian and Kazakh,\nwith BLEU score gains of 3.5, 3.5, 3.3, 4.1, 4.2, and 3.3, respectively. Our\ncodebase is available at\nhttps://github.com/nxphi47/refine_unsup_multilingual_mt", "published": "2022-05-31 05:14:50", "link": "http://arxiv.org/abs/2205.15544v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Why are NLP Models Fumbling at Elementary Math? A Survey of Deep\n  Learning based Word Problem Solvers", "abstract": "From the latter half of the last decade, there has been a growing interest in\ndeveloping algorithms for automatically solving mathematical word problems\n(MWP). It is a challenging and unique task that demands blending surface level\ntext pattern recognition with mathematical reasoning. In spite of extensive\nresearch, we are still miles away from building robust representations of\nelementary math word problems and effective solutions for the general task. In\nthis paper, we critically examine the various models that have been developed\nfor solving word problems, their pros and cons and the challenges ahead. In the\nlast two years, a lot of deep learning models have recorded competing results\non benchmark datasets, making a critical and conceptual analysis of literature\nhighly useful at this juncture. We take a step back and analyse why, in spite\nof this abundance in scholarly interest, the predominantly used experiment and\ndataset designs continue to be a stumbling block. From the vantage point of\nhaving analyzed the literature closely, we also endeavour to provide a road-map\nfor future math word problem research.", "published": "2022-05-31 10:51:25", "link": "http://arxiv.org/abs/2205.15683v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual Transformers for Product Matching -- Experiments and a New\n  Benchmark in Polish", "abstract": "Product matching corresponds to the task of matching identical products\nacross different data sources. It typically employs available product features\nwhich, apart from being multimodal, i.e., comprised of various data types,\nmight be non-homogeneous and incomplete. The paper shows that pre-trained,\nmultilingual Transformer models, after fine-tuning, are suitable for solving\nthe product matching problem using textual features both in English and Polish\nlanguages. We tested multilingual mBERT and XLM-RoBERTa models in English on\nWeb Data Commons - training dataset and gold standard for large-scale product\nmatching. The obtained results show that these models perform similarly to the\nlatest solutions tested on this set, and in some cases, the results were even\nbetter.\n  Additionally, we prepared a new dataset entirely in Polish and based on\noffers in selected categories obtained from several online stores for the\nresearch purpose. It is the first open dataset for product matching tasks in\nPolish, which allows comparing the effectiveness of the pre-trained models.\nThus, we also showed the baseline results obtained by the fine-tuned mBERT and\nXLM-RoBERTa models on the Polish datasets.", "published": "2022-05-31 12:00:05", "link": "http://arxiv.org/abs/2205.15712v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Uzbek Sentiment Analysis based on local Restaurant Reviews", "abstract": "Extracting useful information for sentiment analysis and classification\nproblems from a big amount of user-generated feedback, such as restaurant\nreviews, is a crucial task of natural language processing, which is not only\nfor customer satisfaction where it can give personalized services, but can also\ninfluence the further development of a company. In this paper, we present a\nwork done on collecting restaurant reviews data as a sentiment analysis dataset\nfor the Uzbek language, a member of the Turkic family which is heavily affected\nby the low-resource constraint, and provide some further analysis of the novel\ndataset by evaluation using different techniques, from logistic regression\nbased models, to support vector machines, and even deep learning models, such\nas recurrent neural networks, as well as convolutional neural networks. The\npaper includes detailed information on how the data was collected, how it was\npre-processed for better quality optimization, as well as experimental setups\nfor the evaluation process. The overall evaluation results indicate that by\nperforming pre-processing steps, such as stemming for agglutinative languages,\nthe system yields better results, eventually achieving 91% accuracy result in\nthe best performing model", "published": "2022-05-31 16:21:00", "link": "http://arxiv.org/abs/2205.15930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Retriever and Go Beyond: A Thesis Proposal", "abstract": "Information Retriever (IR) aims to find the relevant documents (e.g.\nsnippets, passages, and articles) to a given query at large scale. IR plays an\nimportant role in many tasks such as open domain question answering and\ndialogue systems, where external knowledge is needed. In the past, searching\nalgorithms based on term matching have been widely used. Recently, neural-based\nalgorithms (termed as neural retrievers) have gained more attention which can\nmitigate the limitations of traditional methods. Regardless of the success\nachieved by neural retrievers, they still face many challenges, e.g. suffering\nfrom a small amount of training data and failing to answer simple\nentity-centric questions. Furthermore, most of the existing neural retrievers\nare developed for pure-text query. This prevents them from handling\nmulti-modality queries (i.e. the query is composed of textual description and\nimages). This proposal has two goals. First, we introduce methods to address\nthe abovementioned issues of neural retrievers from three angles, new model\narchitectures, IR-oriented pretraining tasks, and generating large scale\ntraining data. Second, we identify the future research direction and propose\npotential corresponding solution.", "published": "2022-05-31 17:59:30", "link": "http://arxiv.org/abs/2205.16005v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming\n  Language Models", "abstract": "Pre-trained programming language (PL) models (such as CodeT5, CodeBERT,\nGraphCodeBERT, etc.,) have the potential to automate software engineering tasks\ninvolving code understanding and code generation. However, these models operate\nin the natural channel of code, i.e., they are primarily concerned with the\nhuman understanding of the code. They are not robust to changes in the input\nand thus, are potentially susceptible to adversarial attacks in the natural\nchannel. We propose, CodeAttack, a simple yet effective black-box attack model\nthat uses code structure to generate effective, efficient, and imperceptible\nadversarial code samples and demonstrates the vulnerabilities of the\nstate-of-the-art PL models to code-specific adversarial attacks. We evaluate\nthe transferability of CodeAttack on several code-code (translation and repair)\nand code-NL (summarization) tasks across different programming languages.\nCodeAttack outperforms state-of-the-art adversarial NLP attack models to\nachieve the best overall drop in performance while being more efficient,\nimperceptible, consistent, and fluent. The code can be found at\nhttps://github.com/reddy-lab-code-research/CodeAttack.", "published": "2022-05-31 18:40:01", "link": "http://arxiv.org/abs/2206.00052v3", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "A Mixture-of-Expert Approach to RL-based Dialogue Management", "abstract": "Despite recent advancements in language models (LMs), their application to\ndialogue management (DM) problems and ability to carry on rich conversations\nremain a challenge. We use reinforcement learning (RL) to develop a dialogue\nagent that avoids being short-sighted (outputting generic utterances) and\nmaximizes overall user satisfaction. Most existing RL approaches to DM train\nthe agent at the word-level, and thus, have to deal with a combinatorially\ncomplex action space even for a medium-size vocabulary. As a result, they\nstruggle to produce a successful and engaging dialogue even if they are\nwarm-started with a pre-trained LM. To address this issue, we develop a\nRL-based DM using a novel mixture of expert language model (MoE-LM) that\nconsists of (i) a LM capable of learning diverse semantics for conversation\nhistories, (ii) a number of {\\em specialized} LMs (or experts) capable of\ngenerating utterances corresponding to a particular attribute or personality,\nand (iii) a RL-based DM that performs dialogue planning with the utterances\ngenerated by the experts. Our MoE approach provides greater flexibility to\ngenerate sensible utterances with different intents and allows RL to focus on\nconversational-level DM. We compare it with SOTA baselines on open-domain\ndialogues and demonstrate its effectiveness both in terms of the diversity and\nsensibility of the generated utterances and the overall DM performance.", "published": "2022-05-31 19:00:41", "link": "http://arxiv.org/abs/2206.00059v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VALHALLA: Visual Hallucination for Machine Translation", "abstract": "Designing better machine translation systems by considering auxiliary inputs\nsuch as images has attracted much attention in recent years. While existing\nmethods show promising performance over the conventional text-only translation\nsystems, they typically require paired text and image as input during\ninference, which limits their applicability to real-world scenarios. In this\npaper, we introduce a visual hallucination framework, called VALHALLA, which\nrequires only source sentences at inference time and instead uses hallucinated\nvisual representations for multimodal machine translation. In particular, given\na source sentence an autoregressive hallucination transformer is used to\npredict a discrete visual representation from the input text, and the combined\ntext and hallucinated representations are utilized to obtain the target\ntranslation. We train the hallucination transformer jointly with the\ntranslation transformer using standard backpropagation with cross-entropy\nlosses while being guided by an additional loss that encourages consistency\nbetween predictions using either ground-truth or hallucinated visual\nrepresentations. Extensive experiments on three standard translation datasets\nwith a diverse set of language pairs demonstrate the effectiveness of our\napproach over both text-only baselines and state-of-the-art methods. Project\npage: http://www.svcl.ucsd.edu/projects/valhalla.", "published": "2022-05-31 20:25:15", "link": "http://arxiv.org/abs/2206.00100v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Leveraging Pre-Trained Language Models to Streamline Natural Language\n  Interaction for Self-Tracking", "abstract": "Current natural language interaction for self-tracking tools largely depends\non bespoke implementation optimized for a specific tracking theme and data\nformat, which is neither generalizable nor scalable to a tremendous design\nspace of self-tracking. However, training machine learning models in the\ncontext of self-tracking is challenging due to the wide variety of tracking\ntopics and data formats. In this paper, we propose a novel NLP task for\nself-tracking that extracts close- and open-ended information from a\nretrospective activity log described as a plain text, and a domain-agnostic,\nGPT-3-based NLU framework that performs this task. The framework augments the\nprompt using synthetic samples to transform the task into 10-shot learning, to\naddress a cold-start problem in bootstrapping a new tracking topic. Our\npreliminary evaluation suggests that our approach significantly outperforms the\nbaseline QA models. Going further, we discuss future application domains toward\nwhich the NLP and HCI researchers can collaborate.", "published": "2022-05-31 01:58:04", "link": "http://arxiv.org/abs/2205.15503v3", "categories": ["cs.CL", "cs.AI", "cs.HC", "I.2.7; H.5.1"], "primary_category": "cs.CL"}
{"title": "ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts", "abstract": "Vision-Language Navigation (VLN) is a challenging task that requires an\nembodied agent to perform action-level modality alignment, i.e., make\ninstruction-asked actions sequentially in complex visual environments. Most\nexisting VLN agents learn the instruction-path data directly and cannot\nsufficiently explore action-level alignment knowledge inside the multi-modal\ninputs. In this paper, we propose modAlity-aligneD Action PrompTs (ADAPT),\nwhich provides the VLN agent with action prompts to enable the explicit\nlearning of action-level modality alignment to pursue successful navigation.\nSpecifically, an action prompt is defined as a modality-aligned pair of an\nimage sub-prompt and a text sub-prompt, where the former is a single-view\nobservation and the latter is a phrase like ''walk past the chair''. When\nstarting navigation, the instruction-related action prompt set is retrieved\nfrom a pre-built action prompt base and passed through a prompt encoder to\nobtain the prompt feature. Then the prompt feature is concatenated with the\noriginal instruction feature and fed to a multi-layer transformer for action\nprediction. To collect high-quality action prompts into the prompt base, we use\nthe Contrastive Language-Image Pretraining (CLIP) model which has powerful\ncross-modality alignment ability. A modality alignment loss and a sequential\nconsistency loss are further introduced to enhance the alignment of the action\nprompt and enforce the agent to focus on the related prompt sequentially.\nExperimental results on both R2R and RxR show the superiority of ADAPT over\nstate-of-the-art methods.", "published": "2022-05-31 02:41:31", "link": "http://arxiv.org/abs/2205.15509v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GateNLP-UShef at SemEval-2022 Task 8: Entity-Enriched Siamese\n  Transformer for Multilingual News Article Similarity", "abstract": "This paper describes the second-placed system on the leaderboard of\nSemEval-2022 Task 8: Multilingual News Article Similarity. We propose an\nentity-enriched Siamese Transformer which computes news article similarity\nbased on different sub-dimensions, such as the shared narrative, entities,\nlocation and time of the event discussed in the news article. Our system\nexploits a Siamese network architecture using a Transformer encoder to learn\ndocument-level representations for the purpose of capturing the narrative\ntogether with the auxiliary entity-based features extracted from the news\narticles. The intuition behind using all these features together is to capture\nthe similarity between news articles at different granularity levels and to\nassess the extent to which different news outlets write about \"the same\nevents\". Our experimental results and detailed ablation study demonstrate the\neffectiveness and the validity of our proposed method.", "published": "2022-05-31 14:11:45", "link": "http://arxiv.org/abs/2205.15812v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Do self-supervised speech models develop human-like perception biases?", "abstract": "Self-supervised models for speech processing form representational spaces\nwithout using any external labels. Increasingly, they appear to be a feasible\nway of at least partially eliminating costly manual annotations, a problem of\nparticular concern for low-resource languages. But what kind of\nrepresentational spaces do these models construct? Human perception specializes\nto the sounds of listeners' native languages. Does the same thing happen in\nself-supervised models? We examine the representational spaces of three kinds\nof state-of-the-art self-supervised models: wav2vec 2.0, HuBERT and contrastive\npredictive coding (CPC), and compare them with the perceptual spaces of\nFrench-speaking and English-speaking human listeners, both globally and taking\naccount of the behavioural differences between the two language groups. We show\nthat the CPC model shows a small native language effect, but that wav2vec 2.0\nand HuBERT seem to develop a universal speech perception space which is not\nlanguage specific. A comparison against the predictions of supervised phone\nrecognisers suggests that all three self-supervised models capture relatively\nfine-grained perceptual phenomena, while supervised models are better at\ncapturing coarser, phone-level, effects of listeners' native language, on\nperception.", "published": "2022-05-31 14:21:40", "link": "http://arxiv.org/abs/2205.15819v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Predicting non-native speech perception using the Perceptual\n  Assimilation Model and state-of-the-art acoustic models", "abstract": "Our native language influences the way we perceive speech sounds, affecting\nour ability to discriminate non-native sounds. We compare two ideas about the\ninfluence of the native language on speech perception: the Perceptual\nAssimilation Model, which appeals to a mental classification of sounds into\nnative phoneme categories, versus the idea that rich, fine-grained phonetic\nrepresentations tuned to the statistics of the native language, are sufficient.\nWe operationalize this idea using representations from two state-of-the-art\nspeech models, a Dirichlet process Gaussian mixture model and the more recent\nwav2vec 2.0 model. We present a new, open dataset of French- and\nEnglish-speaking participants' speech perception behaviour for 61 vowel sounds\nfrom six languages. We show that phoneme assimilation is a better predictor\nthan fine-grained phonetic modelling, both for the discrimination behaviour as\na whole, and for predicting differences in discriminability associated with\ndifferences in native language background. We also show that wav2vec 2.0, while\nnot good at capturing the effects of native language on speech perception, is\ncomplementary to information about native phoneme assimilation, and provides a\ngood model of low-level phonetic representations, supporting the idea that both\ncategorical and fine-grained perception are used during speech perception.", "published": "2022-05-31 14:25:59", "link": "http://arxiv.org/abs/2205.15823v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of\n  Movie Dialogues", "abstract": "Movies reflect society and also hold power to transform opinions. Social\nbiases and stereotypes present in movies can cause extensive damage due to\ntheir reach. These biases are not always found to be the need of storyline but\ncan creep in as the author's bias. Movie production houses would prefer to\nascertain that the bias present in a script is the story's demand. Today, when\ndeep learning models can give human-level accuracy in multiple tasks, having an\nAI solution to identify the biases present in the script at the writing stage\ncan help them avoid the inconvenience of stalled release, lawsuits, etc. Since\nAI solutions are data intensive and there exists no domain specific data to\naddress the problem of biases in scripts, we introduce a new dataset of movie\nscripts that are annotated for identity bias. The dataset contains dialogue\nturns annotated for (i) bias labels for seven categories, viz., gender,\nrace/ethnicity, religion, age, occupation, LGBTQ, and other, which contains\nbiases like body shaming, personality bias, etc. (ii) labels for sensitivity,\nstereotype, sentiment, emotion, emotion intensity, (iii) all labels annotated\nwith context awareness, (iv) target groups and reason for bias labels and (v)\nexpert-driven group-validation process for high quality annotations. We also\nreport various baseline performances for bias identification and category\ndetection on our dataset.", "published": "2022-05-31 16:49:51", "link": "http://arxiv.org/abs/2205.15951v2", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph - Deep Learning: A Case Study in Question Answering in\n  Aviation Safety Domain", "abstract": "In the commercial aviation domain, there are a large number of documents,\nlike, accident reports (NTSB, ASRS) and regulatory directives (ADs). There is a\nneed for a system to access these diverse repositories efficiently in order to\nservice needs in the aviation industry, like maintenance, compliance, and\nsafety. In this paper, we propose a Knowledge Graph (KG) guided Deep Learning\n(DL) based Question Answering (QA) system for aviation safety. We construct a\nKnowledge Graph from Aircraft Accident reports and contribute this resource to\nthe community of researchers. The efficacy of this resource is tested and\nproved by the aforesaid QA system. Natural Language Queries constructed from\nthe documents mentioned above are converted into SPARQL (the interface language\nof the RDF graph database) queries and answered. On the DL side, we have two\ndifferent QA models: (i) BERT QA which is a pipeline of Passage Retrieval\n(Sentence-BERT based) and Question Answering (BERT based), and (ii) the\nrecently released GPT-3. We evaluate our system on a set of queries created\nfrom the accident reports. Our combined QA system achieves 9.3% increase in\naccuracy over GPT-3 and 40.3% increase over BERT QA. Thus, we infer that KG-DL\nperforms better than either singly.", "published": "2022-05-31 16:49:55", "link": "http://arxiv.org/abs/2205.15952v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IGLU Gridworld: Simple and Fast Environment for Embodied Dialog Agents", "abstract": "We present the IGLU Gridworld: a reinforcement learning environment for\nbuilding and evaluating language conditioned embodied agents in a scalable way.\nThe environment features visual agent embodiment, interactive learning through\ncollaboration, language conditioned RL, and combinatorically hard task (3d\nblocks building) space.", "published": "2022-05-31 23:08:22", "link": "http://arxiv.org/abs/2206.00142v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Prompt Injection: Parameterization of Fixed Inputs", "abstract": "Recent works have shown that attaching prompts to the input is effective at\nconditioning Language Models (LM) to perform specific tasks. However, prompts\nare always included in the input text during inference, thus incurring\nsubstantial computational and memory overhead. Also, there is currently no\nstraightforward method of utilizing prompts that are longer than the maximum\ninput length of the LMs without incurring additional costs during inference. We\npropose Prompt Injection (PI), a novel formulation of injecting the prompt into\nthe parameters of an LM to be an efficient alternative to attaching fixed\nprompts to the input. We show that in scenarios with long fixed prompts, PI can\nbe up to 280 times more efficient in terms of total FLOPs than previous\napproaches. We further explore methodologies for PI and show promising results\nin persona-dependent conversation, semantic parsing, and zero-shot learning\nwith task instructions. Through these explorations, we show that PI can be a\npromising direction for conditioning language models, especially in scenarios\nwith long and fixed prompts.", "published": "2022-05-31 08:43:07", "link": "http://arxiv.org/abs/2206.11349v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Contribution of Lyrics and Acoustics to Collaborative Understanding\n  of Mood", "abstract": "In this work, we study the association between song lyrics and mood through a\ndata-driven analysis. Our data set consists of nearly one million songs, with\nsong-mood associations derived from user playlists on the Spotify streaming\nplatform. We take advantage of state-of-the-art natural language processing\nmodels based on transformers to learn the association between the lyrics and\nmoods. We find that a pretrained transformer-based language model in a\nzero-shot setting -- i.e., out of the box with no further training on our data\n-- is powerful for capturing song-mood associations. Moreover, we illustrate\nthat training on song-mood associations results in a highly accurate model that\npredicts these associations for unseen songs. Furthermore, by comparing the\nprediction of a model using lyrics with one using acoustic features, we observe\nthat the relative importance of lyrics for mood prediction in comparison with\nacoustics depends on the specific mood. Finally, we verify if the models are\ncapturing the same information about lyrics and acoustics as humans through an\nannotation task where we obtain human judgments of mood-song relevance based on\nlyrics and acoustics.", "published": "2022-05-31 19:58:41", "link": "http://arxiv.org/abs/2207.05680v1", "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "An Informational Space Based Semantic Analysis for Scientific Texts", "abstract": "One major problem in Natural Language Processing is the automatic analysis\nand representation of human language. Human language is ambiguous and deeper\nunderstanding of semantics and creating human-to-machine interaction have\nrequired an effort in creating the schemes for act of communication and\nbuilding common-sense knowledge bases for the 'meaning' in texts. This paper\nintroduces computational methods for semantic analysis and the quantifying the\nmeaning of short scientific texts. Computational methods extracting semantic\nfeature are used to analyse the relations between texts of messages and\n'representations of situations' for a newly created large collection of\nscientific texts, Leicester Scientific Corpus. The representation of\nscientific-specific meaning is standardised by replacing the situation\nrepresentations, rather than psychological properties, with the vectors of some\nattributes: a list of scientific subject categories that the text belongs to.\nFirst, this paper introduces 'Meaning Space' in which the informational\nrepresentation of the meaning is extracted from the occurrence of the word in\ntexts across the scientific categories, i.e., the meaning of a word is\nrepresented by a vector of Relative Information Gain about the subject\ncategories. Then, the meaning space is statistically analysed for Leicester\nScientific Dictionary-Core and we investigate 'Principal Components of the\nMeaning' to describe the adequate dimensions of the meaning. The research in\nthis paper conducts the base for the geometric representation of the meaning of\ntexts.", "published": "2022-05-31 11:19:32", "link": "http://arxiv.org/abs/2205.15696v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Conversational Speech Separation: an Evaluation Study for Streaming\n  Applications", "abstract": "Continuous speech separation (CSS) is a recently proposed framework which\naims at separating each speaker from an input mixture signal in a streaming\nfashion. Hereafter we perform an evaluation study on practical design\nconsiderations for a CSS system, addressing important aspects which have been\nneglected in recent works. In particular, we focus on the trade-off between\nseparation performance, computational requirements and output latency showing\nhow an offline separation algorithm can be used to perform CSS with a desired\nlatency. We carry out an extensive analysis on the choice of CSS processing\nwindow size and hop size on sparsely overlapped data. We find out that the best\ntrade-off between computational burden and performance is obtained for a window\nof 5 s.", "published": "2022-05-31 11:35:22", "link": "http://arxiv.org/abs/2205.15700v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
