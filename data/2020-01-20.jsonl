{"title": "Text-based inference of moral sentiment change", "abstract": "We present a text-based framework for investigating moral sentiment change of\nthe public via longitudinal corpora. Our framework is based on the premise that\nlanguage use can inform people's moral perception toward right or wrong, and we\nbuild our methodology by exploring moral biases learned from diachronic word\nembeddings. We demonstrate how a parameter-free model supports inference of\nhistorical shifts in moral sentiment toward concepts such as slavery and\ndemocracy over centuries at three incremental levels: moral relevance, moral\npolarity, and fine-grained moral dimensions. We apply this methodology to\nvisualizing moral time courses of individual concepts and analyzing the\nrelations between psycholinguistic variables and rates of moral sentiment\nchange at scale. Our work offers opportunities for applying natural language\nprocessing toward characterizing moral sentiment change in society.", "published": "2020-01-20 18:52:45", "link": "http://arxiv.org/abs/2001.07209v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-level Head-wise Match and Aggregation in Transformer for Textual\n  Sequence Matching", "abstract": "Transformer has been successfully applied to many natural language processing\ntasks. However, for textual sequence matching, simple matching between the\nrepresentation of a pair of sequences might bring in unnecessary noise. In this\npaper, we propose a new approach to sequence pair matching with Transformer, by\nlearning head-wise matching representations on multiple levels. Experiments\nshow that our proposed approach can achieve new state-of-the-art performance on\nmultiple tasks that rely only on pre-computed sequence-vector-representation,\nsuch as SNLI, MNLI-match, MNLI-mismatch, QQP, and SQuAD-binary.", "published": "2020-01-20 20:02:02", "link": "http://arxiv.org/abs/2001.07234v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nested-Wasserstein Self-Imitation Learning for Sequence Generation", "abstract": "Reinforcement learning (RL) has been widely studied for improving\nsequence-generation models. However, the conventional rewards used for RL\ntraining typically cannot capture sufficient semantic information and therefore\nrender model bias. Further, the sparse and delayed rewards make RL exploration\ninefficient. To alleviate these issues, we propose the concept of\nnested-Wasserstein distance for distributional semantic matching. To further\nexploit it, a novel nested-Wasserstein self-imitation learning framework is\ndeveloped, encouraging the model to exploit historical high-rewarded sequences\nfor enhanced exploration and better semantic matching. Our solution can be\nunderstood as approximately executing proximal policy optimization with\nWasserstein trust-regions. Experiments on a variety of unconditional and\nconditional sequence-generation tasks demonstrate the proposed approach\nconsistently leads to improved performance.", "published": "2020-01-20 02:19:13", "link": "http://arxiv.org/abs/2001.06944v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Audio Summarization with Audio Features and Probability Distribution\n  Divergence", "abstract": "The automatic summarization of multimedia sources is an important task that\nfacilitates the understanding of an individual by condensing the source while\nmaintaining relevant information. In this paper we focus on audio summarization\nbased on audio features and the probability of distribution divergence. Our\nmethod, based on an extractive summarization approach, aims to select the most\nrelevant segments until a time threshold is reached. It takes into account the\nsegment's length, position and informativeness value. Informativeness of each\nsegment is obtained by mapping a set of audio features issued from its\nMel-frequency Cepstral Coefficients and their corresponding Jensen-Shannon\ndivergence score. Results over a multi-evaluator scheme shows that our approach\nprovides understandable and informative summaries.", "published": "2020-01-20 13:10:01", "link": "http://arxiv.org/abs/2001.07098v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Single headed attention based sequence-to-sequence model for\n  state-of-the-art results on Switchboard", "abstract": "It is generally believed that direct sequence-to-sequence (seq2seq) speech\nrecognition models are competitive with hybrid models only when a large amount\nof data, at least a thousand hours, is available for training. In this paper,\nwe show that state-of-the-art recognition performance can be achieved on the\nSwitchboard-300 database using a single headed attention, LSTM based model.\nUsing a cross-utterance language model, our single-pass speaker independent\nsystem reaches 6.4% and 12.5% word error rate (WER) on the Switchboard and\nCallHome subsets of Hub5'00, without a pronunciation lexicon. While careful\nregularization and data augmentation are crucial in achieving this level of\nperformance, experiments on Switchboard-2000 show that nothing is more useful\nthan more data. Overall, the combination of various regularizations and a\nsimple but fairly large model results in a new state of the art, 4.7% and 7.8%\nWER on the Switchboard and CallHome sets, using SWB-2000 without any external\ndata resources.", "published": "2020-01-20 22:03:42", "link": "http://arxiv.org/abs/2001.07263v3", "categories": ["eess.AS", "cs.CL", "68T10", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Unsupervised Sentiment Analysis for Code-mixed Data", "abstract": "Code-mixing is the practice of alternating between two or more languages.\nMostly observed in multilingual societies, its occurrence is increasing and\ntherefore its importance. A major part of sentiment analysis research has been\nmonolingual, and most of them perform poorly on code-mixed text. In this work,\nwe introduce methods that use different kinds of multilingual and cross-lingual\nembeddings to efficiently transfer knowledge from monolingual text to\ncode-mixed text for sentiment analysis of code-mixed text. Our methods can\nhandle code-mixed text through a zero-shot learning. Our methods beat\nstate-of-the-art on English-Spanish code-mixed sentiment analysis by absolute\n3\\% F1-score. We are able to achieve 0.58 F1-score (without parallel corpus)\nand 0.62 F1-score (with parallel corpus) on the same benchmark in a zero-shot\nway as compared to 0.68 F1-score in supervised settings. Our code is publicly\navailable.", "published": "2020-01-20 06:12:12", "link": "http://arxiv.org/abs/2001.11384v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analysis of the quotation corpus of the Russian Wiktionary", "abstract": "The quantitative evaluation of quotations in the Russian Wiktionary was\nperformed using the developed Wiktionary parser. It was found that the number\nof quotations in the dictionary is growing fast (51.5 thousands in 2011, 62\nthousands in 2012). These quotations were extracted and saved in the relational\ndatabase of a machine-readable dictionary. For this database, tables related to\nthe quotations were designed. A histogram of distribution of quotations of\nliterary works written in different years was built. It was made an attempt to\nexplain the characteristics of the histogram by associating it with the years\nof the most popular and cited (in the Russian Wiktionary) writers of the\nnineteenth century. It was found that more than one-third of all the quotations\n(the example sentences) contained in the Russian Wiktionary are taken by the\neditors of a Wiktionary entry from the Russian National Corpus.", "published": "2020-01-20 12:30:17", "link": "http://arxiv.org/abs/2002.00734v1", "categories": ["cs.CL", "cs.IR", "68T50", "H.3.3"], "primary_category": "cs.CL"}
{"title": "SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions", "abstract": "Existing VQA datasets contain questions with varying levels of complexity.\nWhile the majority of questions in these datasets require perception for\nrecognizing existence, properties, and spatial relationships of entities, a\nsignificant portion of questions pose challenges that correspond to reasoning\ntasks - tasks that can only be answered through a synthesis of perception and\nknowledge about the world, logic and / or reasoning. Analyzing performance\nacross this distinction allows us to notice when existing VQA models have\nconsistency issues; they answer the reasoning questions correctly but fail on\nassociated low-level perception questions. For example, in Figure 1, models\nanswer the complex reasoning question \"Is the banana ripe enough to eat?\"\ncorrectly, but fail on the associated perception question \"Are the bananas\nmostly green or yellow?\" indicating that the model likely answered the\nreasoning question correctly but for the wrong reason. We quantify the extent\nto which this phenomenon occurs by creating a new Reasoning split of the VQA\ndataset and collecting VQA-introspect, a new dataset1 which consists of 238K\nnew perception questions which serve as sub questions corresponding to the set\nof perceptual tasks needed to effectively answer the complex reasoning\nquestions in the Reasoning split. Our evaluation shows that state-of-the-art\nVQA models have comparable performance in answering perception and reasoning\nquestions, but suffer from consistency problems. To address this shortcoming,\nwe propose an approach called Sub-Question Importance-aware Network Tuning\n(SQuINT), which encourages the model to attend to the same parts of the image\nwhen answering the reasoning question and the perception sub question. We show\nthat SQuINT improves model consistency by ~5%, also marginally improving\nperformance on the Reasoning questions in VQA, while also displaying better\nattention maps.", "published": "2020-01-20 01:02:36", "link": "http://arxiv.org/abs/2001.06927v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Early Forecasting of Text Classification Accuracy and F-Measure with\n  Active Learning", "abstract": "When creating text classification systems, one of the major bottlenecks is\nthe annotation of training data. Active learning has been proposed to address\nthis bottleneck using stopping methods to minimize the cost of data annotation.\nAn important capability for improving the utility of stopping methods is to\neffectively forecast the performance of the text classification models.\nForecasting can be done through the use of logarithmic models regressed on some\nportion of the data as learning is progressing. A critical unexplored question\nis what portion of the data is needed for accurate forecasting. There is a\ntension, where it is desirable to use less data so that the forecast can be\nmade earlier, which is more useful, versus it being desirable to use more data,\nso that the forecast can be more accurate. We find that when using active\nlearning it is even more important to generate forecasts earlier so as to make\nthem more useful and not waste annotation effort. We investigate the difference\nin forecasting difficulty when using accuracy and F-measure as the text\nclassification system performance metrics and we find that F-measure is more\ndifficult to forecast. We conduct experiments on seven text classification\ndatasets in different semantic domains with different characteristics and with\nthree different base machine learning algorithms. We find that forecasting is\neasiest for decision tree learning, moderate for Support Vector Machines, and\nmost difficult for neural networks.", "published": "2020-01-20 06:27:33", "link": "http://arxiv.org/abs/2001.10337v2", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML", "H.3.3; I.2.6; I.2.7; I.5.4"], "primary_category": "cs.IR"}
{"title": "Recommending Themes for Ad Creative Design via Visual-Linguistic\n  Representations", "abstract": "There is a perennial need in the online advertising industry to refresh ad\ncreatives, i.e., images and text used for enticing online users towards a\nbrand. Such refreshes are required to reduce the likelihood of ad fatigue among\nonline users, and to incorporate insights from other successful campaigns in\nrelated product categories. Given a brand, to come up with themes for a new ad\nis a painstaking and time consuming process for creative strategists.\nStrategists typically draw inspiration from the images and text used for past\nad campaigns, as well as world knowledge on the brands. To automatically infer\nad themes via such multimodal sources of information in past ad campaigns, we\npropose a theme (keyphrase) recommender system for ad creative strategists. The\ntheme recommender is based on aggregating results from a visual question\nanswering (VQA) task, which ingests the following: (i) ad images, (ii) text\nassociated with the ads as well as Wikipedia pages on the brands in the ads,\nand (iii) questions around the ad. We leverage transformer based cross-modality\nencoders to train visual-linguistic representations for our VQA task. We study\ntwo formulations for the VQA task along the lines of classification and\nranking; via experiments on a public dataset, we show that cross-modal\nrepresentations lead to significantly better classification accuracy and\nranking precision-recall metrics. Cross-modal representations show better\nperformance compared to separate image and text representations. In addition,\nthe use of multimodal information shows a significant lift over using only\ntextual or visual information.", "published": "2020-01-20 18:04:10", "link": "http://arxiv.org/abs/2001.07194v2", "categories": ["cs.CL", "cs.CV", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Interpretable Filter Learning Using Soft Self-attention For Raw Waveform\n  Speech Recognition", "abstract": "Speech recognition from raw waveform involves learning the spectral\ndecomposition of the signal in the first layer of the neural acoustic model\nusing a convolution layer. In this work, we propose a raw waveform\nconvolutional filter learning approach using soft self-attention. The acoustic\nfilter bank in the proposed model is implemented using a parametric\ncosine-modulated Gaussian filter bank whose parameters are learned. A\nnetwork-in-network architecture provides self-attention to generate attention\nweights over the sub-band filters. The attention weighted log filter bank\nenergies are fed to the acoustic model for the task of speech recognition.\nExperiments are conducted on Aurora-4 (additive noise with channel artifact),\nand CHiME-3 (additive noise with reverberation) databases. In these\nexperiments, the attention based filter learning approach provides considerable\nimprovements in ASR performance over the baseline mel filter-bank features and\nother robust front-ends (average relative improvement of 7% in word error rate\nover baseline features on Aurora-4 dataset, and 5% on CHiME-3 database). Using\nthe self-attention weights, we also present an analysis on the interpretability\nof the filters for the ASR task.", "published": "2020-01-20 11:39:44", "link": "http://arxiv.org/abs/2001.07067v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "JVS-MuSiC: Japanese multispeaker singing-voice corpus", "abstract": "Thanks to developments in machine learning techniques, it has become possible\nto synthesize high-quality singing voices of a single singer. An open\nmultispeaker singing-voice corpus would further accelerate the research in\nsinging-voice synthesis. However, conventional singing-voice corpora only\nconsist of the singing voices of a single singer. We designed a Japanese\nmultispeaker singing-voice corpus called \"JVS-MuSiC\" with the aim to analyze\nand synthesize a variety of voices. The corpus consists of 100 singers'\nrecordings of the same song, Katatsumuri, which is a Japanese children's song.\nIt also includes another song that is different for each singer. In this paper,\nwe describe the design of the corpus and experimental analyses using JVS-MuSiC.\nWe investigated the relationship between 1) the similarity of singing voices\nand perceptual oneness of unison singing voices and between 2) the similarity\nof singing voices and that of speech. The results suggest that 1) there is a\npositive and moderate correlation between singing-voice similarity and the\noneness of unison and that 2) the correlation between singing-voice similarity\nand speech similarity is weak. This corpus is freely available online.", "published": "2020-01-20 10:20:56", "link": "http://arxiv.org/abs/2001.07044v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pairwise Discriminative Neural PLDA for Speaker Verification", "abstract": "The state-of-art approach to speaker verification involves the extraction of\ndiscriminative embeddings like x-vectors followed by a generative model\nback-end using a probabilistic linear discriminant analysis (PLDA). In this\npaper, we propose a Pairwise neural discriminative model for the task of\nspeaker verification which operates on a pair of speaker embeddings such as\nx-vectors/i-vectors and outputs a score that can be considered as a scaled\nlog-likelihood ratio. We construct a differentiable cost function which\napproximates speaker verification loss, namely the minimum detection cost. The\npre-processing steps of linear discriminant analysis (LDA), unit length\nnormalization and within class covariance normalization are all modeled as\nlayers of a neural model and the speaker verification cost functions can be\nback-propagated through these layers during training. We also explore\nregularization techniques to prevent overfitting, which is a major concern in\nusing discriminative back-end models for verification tasks. The experiments\nare performed on the NIST SRE 2018 development and evaluation datasets. We\nobserve average relative improvements of 8% in CMN2 condition and 30% in VAST\ncondition over the PLDA baseline system.", "published": "2020-01-20 09:52:52", "link": "http://arxiv.org/abs/2001.07034v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
