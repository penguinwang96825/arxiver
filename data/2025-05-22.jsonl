{"title": "GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning", "abstract": "Visual generation models have made remarkable progress in creating realistic\nimages from text prompts, yet struggle with complex prompts that specify\nmultiple objects with precise spatial relationships and attributes. Effective\nhandling of such prompts requires explicit reasoning about the semantic content\nand spatial layout. We present GoT-R1, a framework that applies reinforcement\nlearning to enhance semantic-spatial reasoning in visual generation. Building\nupon the Generation Chain-of-Thought approach, GoT-R1 enables models to\nautonomously discover effective reasoning strategies beyond predefined\ntemplates through carefully designed reinforcement learning. To achieve this,\nwe propose a dual-stage multi-dimensional reward framework that leverages MLLMs\nto evaluate both the reasoning process and final output, enabling effective\nsupervision across the entire generation pipeline. The reward system assesses\nsemantic alignment, spatial accuracy, and visual quality in a unified approach.\nExperimental results demonstrate significant improvements on T2I-CompBench\nbenchmark, particularly in compositional tasks involving precise spatial\nrelationships and attribute binding. GoT-R1 advances the state-of-the-art in\nimage generation by successfully transferring sophisticated reasoning\ncapabilities to the visual generation domain. To facilitate future research, we\nmake our code and pretrained models publicly available at\nhttps://github.com/gogoduan/GoT-R1.", "published": "2025-05-22 17:59:58", "link": "http://arxiv.org/abs/2505.17022v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO", "abstract": "Recent advancements underscore the significant role of Reinforcement Learning\n(RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large\nlanguage models (LLMs). Two prominent RL algorithms, Direct Preference\nOptimization (DPO) and Group Relative Policy Optimization (GRPO), are central\nto these developments, showcasing different pros and cons. Autoregressive image\ngeneration, also interpretable as a sequential CoT reasoning process, presents\nunique challenges distinct from LLM-based CoT reasoning. These encompass\nensuring text-image consistency, improving image aesthetic quality, and\ndesigning sophisticated reward models, rather than relying on simpler\nrule-based rewards. While recent efforts have extended RL to this domain, these\nexplorations typically lack an in-depth analysis of the domain-specific\nchallenges and the characteristics of different RL strategies. To bridge this\ngap, we provide the first comprehensive investigation of the GRPO and DPO\nalgorithms in autoregressive image generation, evaluating their in-domain\nperformance and out-of-domain generalization, while scrutinizing the impact of\ndifferent reward models on their respective capabilities. Our findings reveal\nthat GRPO and DPO exhibit distinct advantages, and crucially, that reward\nmodels possessing stronger intrinsic generalization capabilities potentially\nenhance the generalization potential of the applied RL algorithms. Furthermore,\nwe systematically explore three prevalent scaling strategies to enhance both\ntheir in-domain and out-of-domain proficiency, deriving unique insights into\nefficiently scaling performance for each paradigm. We hope our study paves a\nnew path for inspiring future work on developing more effective RL algorithms\nto achieve robust CoT reasoning in the realm of autoregressive image\ngeneration. Code is released at\nhttps://github.com/ZiyuGuo99/Image-Generation-CoT", "published": "2025-05-22 17:59:49", "link": "http://arxiv.org/abs/2505.17017v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models", "abstract": "Multi-modal large language models (MLLMs) have rapidly advanced in visual\ntasks, yet their spatial understanding remains limited to single images,\nleaving them ill-suited for robotics and other real-world applications that\nrequire multi-frame reasoning. In this paper, we propose a framework to equip\nMLLMs with robust multi-frame spatial understanding by integrating depth\nperception, visual correspondence, and dynamic perception. Central to our\napproach is the MultiSPA dataset, a novel, large-scale collection of more than\n27 million samples spanning diverse 3D and 4D scenes. Alongside MultiSPA, we\nintroduce a comprehensive benchmark that tests a wide spectrum of spatial tasks\nunder uniform metrics. Our resulting model, Multi-SpatialMLLM, achieves\nsignificant gains over baselines and proprietary systems, demonstrating\nscalable, generalizable multi-frame reasoning. We further observe multi-task\nbenefits and early indications of emergent capabilities in challenging\nscenarios, and showcase how our model can serve as a multi-frame reward\nannotator for robotics.", "published": "2025-05-22 17:59:39", "link": "http://arxiv.org/abs/2505.17015v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning", "abstract": "Large Language Models (LLMs) are powerful but prone to hallucinations due to\nstatic knowledge. Retrieval-Augmented Generation (RAG) helps by injecting\nexternal information, but current methods often are costly, generalize poorly,\nor ignore the internal knowledge of the model. In this paper, we introduce\nR1-Searcher++, a novel framework designed to train LLMs to adaptively leverage\nboth internal and external knowledge sources. R1-Searcher++ employs a two-stage\ntraining strategy: an initial SFT Cold-start phase for preliminary format\nlearning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses\noutcome-supervision to encourage exploration, incorporates a reward mechanism\nfor internal knowledge utilization, and integrates a memorization mechanism to\ncontinuously assimilate retrieved information, thereby enriching the model's\ninternal knowledge. By leveraging internal knowledge and external search\nengine, the model continuously improves its capabilities, enabling efficient\nretrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++\noutperforms previous RAG and reasoning methods and achieves efficient\nretrieval. The code is available at\nhttps://github.com/RUCAIBox/R1-Searcher-plus.", "published": "2025-05-22 17:58:26", "link": "http://arxiv.org/abs/2505.17005v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?", "abstract": "Large Language Models (LLMs) have been shown to achieve breakthrough\nperformance on complex logical reasoning tasks. Nevertheless, most existing\nresearch focuses on employing formal language to guide LLMs to derive reliable\nreasoning paths, while systematic evaluations of these capabilities are still\nlimited. In this paper, we aim to conduct a comprehensive evaluation of LLMs\nacross various logical reasoning problems utilizing formal languages. From the\nperspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and\nformat of trajectories, our key findings are: 1) Thinking models significantly\noutperform Instruct models, especially when formal language is employed; 2) All\nLLMs exhibit limitations in inductive reasoning capability, irrespective of\nwhether they use a formal language; 3) Data with PoT format achieves the best\ngeneralization performance across other languages. Additionally, we also curate\nthe formal-relative training data to further enhance the small language models,\nand the experimental results indicate that a simple rejected fine-tuning method\ncan better enable LLMs to generalize across formal languages and achieve the\nbest overall performance. Our codes and reports are available at\nhttps://github.com/jiangjin1999/FormalEval.", "published": "2025-05-22 17:57:23", "link": "http://arxiv.org/abs/2505.16998v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs", "abstract": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by\nenabling cooperation among multiple specialized agents. However, most existing\nMAS frameworks rely on a single LLM to drive all agents, constraining the\nsystem's intelligence to the limit of that model. This paper explores the\nparadigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by\ndiverse LLMs, elevating the system's potential to the collective intelligence\nof diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to\nevaluate the performance of various LLMs across different domains and\nMAS-related functions. As an extensive empirical study, we assess 27 LLMs\nacross 5 domains (encompassing 21 test sets) and 5 functions, conducting over\n1.7 million evaluations to identify optimal model selections for each\ndomain-function combination. Building on these findings, we demonstrate that\ntransitioning from homogeneous to heterogeneous LLM-driven MAS can\nsignificantly enhance system performance without requiring structural redesign.\nSpecifically, in a chatbot-only MAS scenario, the heterogeneous configuration\nyields up to 8.4\\% performance improvement on the MATH dataset. In a mixed\nchatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable\n47\\% performance boost on the AIME dataset. Our results underscore the\ntransformative potential of heterogeneous LLMs in MAS, highlighting a promising\navenue for advancing scalable, collaborative AI systems.", "published": "2025-05-22 17:56:39", "link": "http://arxiv.org/abs/2505.16997v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "DecoupledESC: Enhancing Emotional Support Generation via Strategy-Response Decoupled Preference Optimization", "abstract": "Recent advances in Emotional Support Conversation (ESC) have improved\nemotional support generation by fine-tuning Large Language Models (LLMs) via\nSupervised Fine-Tuning (SFT). However, common psychological errors still\npersist. While Direct Preference Optimization (DPO) shows promise in reducing\nsuch errors through pairwise preference learning, its effectiveness in ESC\ntasks is limited by two key challenges: (1) Entangled data structure: Existing\nESC data inherently entangles psychological strategies and response content,\nmaking it difficult to construct high-quality preference pairs; and (2)\nOptimization ambiguity: Applying vanilla DPO to such entangled pairwise data\nleads to ambiguous training objectives. To address these issues, we introduce\nInferential Preference Mining (IPM) to construct high-quality preference data,\nforming the IPM-PrefDial dataset. Building upon this data, we propose a\nDecoupled ESC framework inspired by Gross's Extended Process Model of Emotion\nRegulation, which decomposes the ESC task into two sequential subtasks:\nstrategy planning and empathic response generation. Each was trained via SFT\nand subsequently enhanced by DPO to align with the psychological preference.\nExtensive experiments demonstrate that our Decoupled ESC framework outperforms\njoint optimization baselines, reducing preference bias and improving response\nquality.", "published": "2025-05-22 17:56:21", "link": "http://arxiv.org/abs/2505.16995v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$\\text{R}^2\\text{ec}$: Towards Large Recommender Models with Reasoning", "abstract": "Large recommender models have extended LLMs as powerful recommenders via\nencoding or item generation, and recent breakthroughs in LLM reasoning\nsynchronously motivate the exploration of reasoning in recommendation. Current\nstudies usually position LLMs as external reasoning modules to yield auxiliary\nthought for augmenting conventional recommendation pipelines. However, such\ndecoupled designs are limited in significant resource cost and suboptimal joint\noptimization. To address these issues, we propose \\name, a unified large\nrecommender model with intrinsic reasoning capabilities. Initially, we\nreconceptualize the model architecture to facilitate interleaved reasoning and\nrecommendation in the autoregressive process. Subsequently, we propose RecPO, a\ncorresponding reinforcement learning framework that optimizes \\name\\ both the\nreasoning and recommendation capabilities simultaneously in a single policy\nupdate; RecPO introduces a fused reward scheme that solely leverages\nrecommendation labels to simulate the reasoning capability, eliminating\ndependency on specialized reasoning annotations. Experiments on three datasets\nwith various baselines verify the effectiveness of \\name, showing relative\nimprovements of 68.67\\% in Hit@5 and 45.21\\% in NDCG@20. Code available at\nhttps://github.com/YRYangang/RRec.", "published": "2025-05-22 17:55:43", "link": "http://arxiv.org/abs/2505.16994v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems", "abstract": "LLM-based multi-agent systems (MAS) have demonstrated significant potential\nin enhancing single LLMs to address complex and diverse tasks in practical\napplications. Despite considerable advancements, the field lacks a unified\ncodebase that consolidates existing methods, resulting in redundant\nre-implementation efforts, unfair comparisons, and high entry barriers for\nresearchers. To address these challenges, we introduce MASLab, a unified,\ncomprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab\nintegrates over 20 established methods across multiple domains, each rigorously\nvalidated by comparing step-by-step outputs with its official implementation.\n(2) MASLab provides a unified environment with various benchmarks for fair\ncomparisons among methods, ensuring consistent inputs and standardized\nevaluation protocols. (3) MASLab implements methods within a shared streamlined\nstructure, lowering the barriers for understanding and extension. Building on\nMASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models,\noffering researchers a clear and comprehensive view of the current landscape of\nMAS methods. MASLab will continue to evolve, tracking the latest developments\nin the field, and invite contributions from the broader open-source community.", "published": "2025-05-22 17:54:38", "link": "http://arxiv.org/abs/2505.16988v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities as\nintelligent agents capable of solving complex problems. However, effective\nplanning in scenarios involving dependencies between API or tool\ncalls-particularly in multi-turn conversations-remains a significant challenge.\nTo address this, we introduce T1, a tool-augmented, multi-domain, multi-turn\nconversational dataset specifically designed to capture and manage inter-tool\ndependencies across diverse domains. T1 enables rigorous evaluation of agents'\nability to coordinate tool use across nine distinct domains (4 single domain\nand 5 multi-domain) with the help of an integrated caching mechanism for both\nshort- and long-term memory, while supporting dynamic replanning-such as\ndeciding whether to recompute or reuse cached results. Beyond facilitating\nresearch on tool use and planning, T1 also serves as a benchmark for evaluating\nthe performance of open-source language models. We present results powered by\nT1-Agent, highlighting their ability to plan and reason in complex,\ntool-dependent scenarios.", "published": "2025-05-22 17:54:32", "link": "http://arxiv.org/abs/2505.16986v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UFT: Unifying Supervised and Reinforcement Fine-Tuning", "abstract": "Post-training has demonstrated its importance in enhancing the reasoning\ncapabilities of large language models (LLMs). The primary post-training methods\ncan be categorized into supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT). SFT is efficient and well-suited for small language models,\nbut it may lead to overfitting and limit the reasoning abilities of larger\nmodels. In contrast, RFT generally yields better generalization but depends\nheavily on the strength of the base model. To address the limitations of SFT\nand RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm\nthat unifies SFT and RFT into a single, integrated process. UFT enables the\nmodel to effectively explore solutions while incorporating informative\nsupervision signals, bridging the gap between memorizing and thinking\nunderlying existing methods. Notably, UFT outperforms both SFT and RFT in\ngeneral, regardless of model sizes. Furthermore, we theoretically prove that\nUFT breaks RFT's inherent exponential sample complexity bottleneck, showing for\nthe first time that unified training can exponentially accelerate convergence\non long-horizon reasoning tasks.", "published": "2025-05-22 17:53:57", "link": "http://arxiv.org/abs/2505.16984v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding", "abstract": "Large Language Models (LLMs) are primarily designed for batch processing.\nExisting methods for adapting LLMs to streaming rely either on expensive\nre-encoding or specialized architectures with limited scalability. This work\nidentifies three key mismatches in adapting batch-oriented LLMs to streaming:\n(1) input-attention, (2) output-attention, and (3) position-ID mismatches.\nWhile it is commonly assumed that the latter two mismatches require frequent\nre-encoding, our analysis reveals that only the input-attention mismatch\nsignificantly impacts performance, indicating re-encoding outputs is largely\nunnecessary. To better understand this discrepancy with the common assumption,\nwe provide the first comprehensive analysis of the impact of position encoding\non LLMs in streaming, showing that preserving relative positions within source\nand target contexts is more critical than maintaining absolute order. Motivated\nby the above analysis, we introduce a group position encoding paradigm built on\nbatch architectures to enhance consistency between streaming and batch modes.\nExtensive experiments on cross-lingual and cross-modal tasks demonstrate that\nour method outperforms existing approaches. Our method requires no\narchitectural modifications, exhibits strong generalization in both streaming\nand batch modes. The code is available at repository\nhttps://github.com/EIT-NLP/StreamingLLM.", "published": "2025-05-22 17:53:28", "link": "http://arxiv.org/abs/2505.16983v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development", "abstract": "Large Language Models (LLMs) have shown strong capability in diverse software\nengineering tasks, e.g. code completion, bug fixing, and document generation.\nHowever, feature-driven development (FDD), a highly prevalent real-world task\nthat involves developing new functionalities for large, existing codebases,\nremains underexplored. We therefore introduce SWE-Dev, the first large-scale\ndataset (with 14,000 training and 500 test samples) designed to evaluate and\ntrain autonomous coding systems on real-world feature development tasks. To\nensure verifiable and diverse training, SWE-Dev uniquely provides all instances\nwith a runnable environment and its developer-authored executable unit tests.\nThis collection not only provides high-quality data for Supervised Fine-Tuning\n(SFT), but also enables Reinforcement Learning (RL) by delivering accurate\nreward signals from executable unit tests. Our extensive evaluations on\nSWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent\nSystems (MAS), reveal that FDD is a profoundly challenging frontier for current\nAI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test\nsplit). Crucially, we demonstrate that SWE-Dev serves as an effective platform\nfor model improvement: fine-tuning on training set enabled a 7B model\ncomparable to GPT-4o on \\textit{hard} split, underscoring the value of its\nhigh-quality training data. Code is available here\n\\href{https://github.com/justLittleWhite/SWE-Dev}{https://github.com/justLittleWhite/SWE-Dev}.", "published": "2025-05-22 17:51:49", "link": "http://arxiv.org/abs/2505.16975v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "VeriFastScore: Speeding up long-form factuality evaluation", "abstract": "Metrics like FactScore and VeriScore that evaluate long-form factuality\noperate by decomposing an input response into atomic claims and then\nindividually verifying each claim. While effective and interpretable, these\nmethods incur numerous LLM calls and can take upwards of 100 seconds to\nevaluate a single response, limiting their practicality in large-scale\nevaluation and training scenarios. To address this, we propose VeriFastScore,\nwhich leverages synthetic data to fine-tune Llama3.1 8B for simultaneously\nextracting and verifying all verifiable claims within a given text based on\nevidence from Google Search. We show that this task cannot be solved via\nfew-shot prompting with closed LLMs due to its complexity: the model receives\n~4K tokens of evidence on average and needs to concurrently decompose claims,\njudge their verifiability, and verify them against noisy evidence. However, our\nfine-tuned VeriFastScore model demonstrates strong correlation with the\noriginal VeriScore pipeline at both the example level (r=0.80) and system level\n(r=0.94) while achieving an overall speedup of 6.6x (9.9x excluding evidence\nretrieval) over VeriScore. To facilitate future factuality research, we\npublicly release our VeriFastScore model and synthetic datasets.", "published": "2025-05-22 17:51:25", "link": "http://arxiv.org/abs/2505.16973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Tens of Hours to Tens of Thousands: Scaling Back-Translation for Speech Recognition", "abstract": "Recent advances in Automatic Speech Recognition (ASR) have been largely\nfueled by massive speech corpora. However, extending coverage to diverse\nlanguages with limited resources remains a formidable challenge. This paper\nintroduces Speech Back-Translation, a scalable pipeline that improves\nmultilingual ASR models by converting large-scale text corpora into synthetic\nspeech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just\ntens of hours of real transcribed speech can effectively train TTS models to\ngenerate synthetic speech at hundreds of times the original volume while\nmaintaining high quality. To evaluate synthetic speech quality, we develop an\nintelligibility-based assessment framework and establish clear thresholds for\nwhen synthetic data benefits ASR training. Using Speech Back-Translation, we\ngenerate more than 500,000 hours of synthetic speech in ten languages and\ncontinue pre-training Whisper-large-v3, achieving average transcription error\nreductions of over 30\\%. These results highlight the scalability and\neffectiveness of Speech Back-Translation for enhancing multilingual ASR\nsystems.", "published": "2025-05-22 17:51:05", "link": "http://arxiv.org/abs/2505.16972v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark", "abstract": "We introduce \\texttt{CASS}, the first large-scale dataset and model suite for\ncross-architecture GPU code transpilation, targeting both source-level\n(CUDA~$\\leftrightarrow$~HIP) and assembly-level (Nvidia\nSASS~$\\leftrightarrow$~AMD RDNA3) translation. The dataset comprises 70k\nverified code pairs across host and device, addressing a critical gap in\nlow-level GPU code portability. Leveraging this resource, we train the\n\\texttt{CASS} family of domain-specific language models, achieving 95\\% source\ntranslation accuracy and 37.5\\% assembly translation accuracy, substantially\noutperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our\ngenerated code matches native performance in over 85\\% of test cases,\npreserving runtime and memory behavior. To support rigorous evaluation, we\nintroduce \\texttt{CASS-Bench}, a curated benchmark spanning 16 GPU domains with\nground-truth execution. All data, models, and evaluation tools are released as\nopen source to foster progress in GPU compiler tooling, binary compatibility,\nand LLM-guided hardware translation. Dataset and benchmark are on\n\\href{https://huggingface.co/datasets/MBZUAI/cass}{\\textcolor{blue}{HuggingFace}},\nwith code at\n\\href{https://github.com/GustavoStahl/CASS}{\\textcolor{blue}{GitHub}}.", "published": "2025-05-22 17:48:53", "link": "http://arxiv.org/abs/2505.16968v1", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.AR"}
{"title": "Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval", "abstract": "Training robust retrieval and reranker models typically relies on large-scale\nretrieval datasets; for example, the BGE collection contains 1.6 million\nquery-passage pairs sourced from various data sources. However, we find that\ncertain datasets can negatively impact model effectiveness -- pruning 8 out of\n15 datasets from the BGE collection reduces the training set size by\n2.35$\\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a\ndeeper examination of training data quality, with a particular focus on \"false\nnegatives\", where relevant passages are incorrectly labeled as irrelevant. We\npropose a simple, cost-effective approach using cascading LLM prompts to\nidentify and relabel hard negatives. Experimental results show that relabeling\nfalse negatives with true positives improves both E5 (base) and Qwen2.5-7B\nretrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot\nAIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on\nthe relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the\ncascading design is further supported by human annotation results, where we\nfind judgment by GPT-4o shows much higher agreement with humans than\nGPT-4o-mini.", "published": "2025-05-22 17:47:57", "link": "http://arxiv.org/abs/2505.16967v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation", "abstract": "Text segmentation based on the semantic meaning of sentences is a fundamental\ntask with broad utility in many downstream applications. In this paper, we\npropose a graphical model-based unsupervised learning approach, named BP-Seg\nfor efficient text segmentation. Our method not only considers local coherence,\ncapturing the intuition that adjacent sentences are often more related, but\nalso effectively groups sentences that are distant in the text yet semantically\nsimilar. This is achieved through belief propagation on the carefully\nconstructed graphical models. Experimental results on both an illustrative\nexample and a dataset with long-form documents demonstrate that our method\nperforms favorably compared to competing approaches.", "published": "2025-05-22 17:46:23", "link": "http://arxiv.org/abs/2505.16965v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MedFrameQA: A Multi-Image Medical VQA Benchmark for Clinical Reasoning", "abstract": "Existing medical VQA benchmarks mostly focus on single-image analysis, yet\nclinicians almost always compare a series of images before reaching a\ndiagnosis. To better approximate this workflow, we introduce MedFrameQA -- the\nfirst benchmark that explicitly evaluates multi-image reasoning in medical VQA.\nTo build MedFrameQA both at scale and in high-quality, we develop 1) an\nautomated pipeline that extracts temporally coherent frames from medical videos\nand constructs VQA items whose content evolves logically across images, and 2)\na multiple-stage filtering strategy, including model-based and manual review,\nto preserve data clarity, difficulty, and medical relevance. The resulting\ndataset comprises 2,851 VQA pairs (gathered from 9,237 high-quality frames in\n3,420 videos), covering nine human body systems and 43 organs; every question\nis accompanied by two to five images. We comprehensively benchmark ten advanced\nMultimodal LLMs -- both proprietary and open source, with and without explicit\nreasoning modules -- on MedFrameQA. The evaluation challengingly reveals that\nall models perform poorly, with most accuracies below 50%, and accuracy\nfluctuates as the number of images per question increases. Error analysis\nfurther shows that models frequently ignore salient findings, mis-aggregate\nevidence across images, and propagate early mistakes through their reasoning\nchains; results also vary substantially across body systems, organs, and\nmodalities. We hope this work can catalyze research on clinically grounded,\nmulti-image reasoning and accelerate progress toward more capable diagnostic AI\nsystems.", "published": "2025-05-22 17:46:11", "link": "http://arxiv.org/abs/2505.16964v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "On Multilingual Encoder Language Model Compression for Low-Resource Languages", "abstract": "In this paper, we combine two-step knowledge distillation, structured\npruning, truncation, and vocabulary trimming for extremely compressing\nmultilingual encoder-only language models for low-resource languages. Our novel\napproach systematically combines existing techniques and takes them to the\nextreme, reducing layer depth, feed-forward hidden size, and intermediate layer\nembedding size to create significantly smaller monolingual models while\nretaining essential language-specific knowledge. We achieve compression rates\nof up to 92% with only a marginal performance drop of 2-10% in four downstream\ntasks, including sentiment analysis, topic classification, named entity\nrecognition, and part-of-speech tagging, across three low-resource languages.\nNotably, the performance degradation correlates with the amount of\nlanguage-specific data in the teacher model, with larger datasets resulting in\nsmaller performance losses. Additionally, we conduct extensive ablation studies\nto identify best practices for multilingual model compression using these\ntechniques.", "published": "2025-05-22 17:35:39", "link": "http://arxiv.org/abs/2505.16956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios", "abstract": "Large Language Models (LLMs) have demonstrated advanced capabilities in\nreal-world agentic applications. Growing research efforts aim to develop\nLLM-based agents to address practical demands, introducing a new challenge:\nagentic scenarios often involve lengthy instructions with complex constraints,\nsuch as extended system prompts and detailed tool specifications. While\nadherence to such instructions is crucial for agentic applications, whether\nLLMs can reliably follow them remains underexplored. In this paper, we\nintroduce AgentIF, the first benchmark for systematically evaluating LLM\ninstruction following ability in agentic scenarios. AgentIF features three key\ncharacteristics: (1) Realistic, constructed from 50 real-world agentic\napplications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.\n(3) Complex, averaging 11.9 constraints per instruction, covering diverse\nconstraint types, such as tool specifications and condition constraints. To\nconstruct AgentIF, we collect 707 human-annotated instructions across 50\nagentic tasks from industrial application agents and open-source agentic\nsystems. For each instruction, we annotate the associated constraints and\ncorresponding evaluation metrics, including code-based evaluation, LLM-based\nevaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically\nevaluate existing advanced LLMs. We observe that current models generally\nperform poorly, especially in handling complex constraint structures and tool\nspecifications. We further conduct error analysis and analytical experiments on\ninstruction length and meta constraints, providing some findings about the\nfailure modes of existing LLMs. We have released the code and data to\nfacilitate future research.", "published": "2025-05-22 17:31:10", "link": "http://arxiv.org/abs/2505.16944v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification", "abstract": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce NovelSeek, a unified closed-loop multi-agent framework\nto conduct Autonomous Scientific Research (ASR) across various scientific\nresearch fields, enabling researchers to tackle complicated problems in these\nfields with unprecedented speed and precision. NovelSeek highlights three key\nadvantages: 1) Scalability: NovelSeek has demonstrated its versatility across\n12 scientific research tasks, capable of generating innovative ideas to enhance\nthe performance of baseline code. 2) Interactivity: NovelSeek provides an\ninterface for human expert feedback and multi-agent interaction in automated\nend-to-end processes, allowing for the seamless integration of domain expert\nknowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in\nseveral scientific fields with significantly less time cost compared to human\nefforts. For instance, in reaction yield prediction, it increased from 27.6% to\n35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from\n0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,\nprecision advanced from 78.8% to 81.0% in a mere 30 hours.", "published": "2025-05-22 17:27:43", "link": "http://arxiv.org/abs/2505.16938v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "In-Context Watermarks for Large Language Models", "abstract": "The growing use of large language models (LLMs) for sensitive applications\nhas highlighted the need for effective watermarking techniques to ensure the\nprovenance and accountability of AI-generated text. However, most existing\nwatermarking methods require access to the decoding process, limiting their\napplicability in real-world settings. One illustrative example is the use of\nLLMs by dishonest reviewers in the context of academic peer review, where\nconference organizers have no access to the model used but still need to detect\nAI-generated reviews. Motivated by this gap, we introduce In-Context\nWatermarking (ICW), which embeds watermarks into generated text solely through\nprompt engineering, leveraging LLMs' in-context learning and\ninstruction-following abilities. We investigate four ICW strategies at\ndifferent levels of granularity, each paired with a tailored detection method.\nWe further examine the Indirect Prompt Injection (IPI) setting as a specific\ncase study, in which watermarking is covertly triggered by modifying input\ndocuments such as academic manuscripts. Our experiments validate the\nfeasibility of ICW as a model-agnostic, practical watermarking approach.\nMoreover, our findings suggest that as LLMs become more capable, ICW offers a\npromising direction for scalable and accessible content attribution.", "published": "2025-05-22 17:24:51", "link": "http://arxiv.org/abs/2505.16934v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning", "abstract": "In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large\nLanguage Model (MLLM) that integrates visual instruction tuning with masked\ndiffusion models, representing a departure from the autoregressive paradigms\ndominant in current multimodal approaches. Built upon LLaDA, a representative\nlarge language diffusion model, LLaDA-V incorporates a vision encoder and MLP\nconnector that projects visual features into the language embedding space,\nenabling effective multimodal alignment. Our empirical investigation reveals\nseveral intriguing results: First, LLaDA-V demonstrates promising multimodal\nperformance despite its language model being weaker on purely textual tasks\nthan counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same\ninstruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal\ntasks with better data scalability. It also narrows the performance gap to\nQwen2-VL, suggesting the effectiveness of its architecture for multimodal\ntasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal\nunderstanding compared to existing hybrid autoregressive-diffusion and purely\ndiffusion-based MLLMs. Our findings suggest that large language diffusion\nmodels show promise in multimodal contexts and warrant further investigation in\nfuture research. Project page and codes:\nhttps://ml-gsai.github.io/LLaDA-V-demo/.", "published": "2025-05-22 17:23:26", "link": "http://arxiv.org/abs/2505.16933v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "abstract": "Computing the polar decomposition and the related matrix sign function, has\nbeen a well-studied problem in numerical analysis for decades. More recently,\nit has emerged as an important subroutine in deep learning, particularly within\nthe Muon optimization framework. However, the requirements in this setting\ndiffer significantly from those of traditional numerical analysis. In deep\nlearning, methods must be highly efficient and GPU-compatible, but high\naccuracy is often unnecessary. As a result, classical algorithms like\nNewton-Schulz (which suffers from slow initial convergence) and methods based\non rational functions (which rely on QR decompositions or matrix inverses) are\npoorly suited to this context. In this work, we introduce Polar Express, a\nGPU-friendly algorithm for computing the polar decomposition. Like classical\npolynomial methods such as Newton-Schulz, our approach uses only matrix-matrix\nmultiplications, making it GPU-compatible. Motivated by earlier work of Chen &\nChow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule\nat each iteration by solving a minimax optimization problem, and we prove that\nit enjoys a strong worst-case optimality guarantee. This property ensures both\nrapid early convergence and fast asymptotic convergence. We also address\nfinite-precision issues, making it stable in bfloat16 in practice. We apply\nPolar Express within the Muon optimization framework and show consistent\nimprovements in validation loss on large-scale models such as GPT-2,\noutperforming recent alternatives across a range of learning rates.", "published": "2025-05-22 17:23:14", "link": "http://arxiv.org/abs/2505.16932v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NA", "math.NA", "math.OC"], "primary_category": "cs.LG"}
{"title": "PIIvot: A Lightweight NLP Anonymization Framework for Question-Anchored Tutoring Dialogues", "abstract": "Personally identifiable information (PII) anonymization is a high-stakes task\nthat poses a barrier to many open-science data sharing initiatives. While PII\nidentification has made large strides in recent years, in practice, error\nthresholds and the recall/precision trade-off still limit the uptake of these\nanonymization pipelines. We present PIIvot, a lighter-weight framework for PII\nanonymization that leverages knowledge of the data context to simplify the PII\ndetection problem. To demonstrate its effectiveness, we also contribute\nQATD-2k, the largest open-source real-world tutoring dataset of its kind, to\nsupport the demand for quality educational dialogue data.", "published": "2025-05-22 17:22:28", "link": "http://arxiv.org/abs/2505.16931v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Principle Discovery for Language Model Self-Improvement", "abstract": "When language model (LM) users aim to improve the quality of its generations,\nit is crucial to specify concrete behavioral attributes that the model should\nstrive to reflect. However, curating such principles across many domains, even\nnon-exhaustively, requires a labor-intensive annotation process. To automate\nthis process, we propose eliciting these latent attributes guiding model\nreasoning towards human-preferred responses by explicitly modeling them in a\nself-correction setting. Our approach mines new principles from the LM itself\nand compresses the discovered elements to an interpretable set via clustering.\nSpecifically, we employ an approximation of posterior-regularized Monte Carlo\nExpectation-Maximization to both identify a condensed set of the most effective\nlatent principles and teach the LM to strategically invoke them in order to\nintrinsically refine its responses. We demonstrate that bootstrapping our\nalgorithm over multiple iterations enables smaller language models (7-8B\nparameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an\naverage of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on\nIFEval. We also show that clustering the principles yields interpretable and\ndiverse model-generated constitutions while retaining model performance. The\ngains our method achieves highlight the potential of automated,\nprinciple-driven post-training recipes toward continual self-improvement.", "published": "2025-05-22 17:20:18", "link": "http://arxiv.org/abs/2505.16927v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UNCLE: Uncertainty Expressions in Long-Form Generation", "abstract": "Large Language Models (LLMs) are prone to hallucination, particularly in\nlong-form generations. A promising direction to mitigate hallucination is to\nteach LLMs to express uncertainty explicitly when they lack sufficient\nknowledge. However, existing work lacks direct and fair evaluation of LLMs'\nability to express uncertainty effectively in long-form generation. To address\nthis gap, we first introduce UNCLE, a benchmark designed to evaluate\nuncertainty expression in both long- and short-form question answering (QA).\nUNCLE spans five domains and comprises 4k long-form QA instances and over 20k\nshort-form QA pairs. Our dataset is the first to directly bridge short- and\nlong-form QA with paired questions and gold-standard answers. Along with the\nbenchmark, we propose a suite of new metrics to assess the models' capabilities\nto selectively express uncertainty. Using UNCLE, we then demonstrate that\ncurrent models fail to convey uncertainty appropriately in long-form\ngeneration. We further explore both prompt-based and training-based methods to\nimprove models' performance, with the training-based methods yielding greater\ngains. Further analysis of alignment gaps between short- and long-form\nuncertainty expression highlights promising directions for future research\nusing UNCLE.", "published": "2025-05-22 17:16:08", "link": "http://arxiv.org/abs/2505.16922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Power-Law Decay Loss for Large Language Model Finetuning: Focusing on Information Sparsity to Enhance Generation Quality", "abstract": "During the finetuning stage of text generation tasks, standard cross-entropy\nloss treats all tokens equally. This can lead models to overemphasize\nhigh-frequency, low-information tokens, neglecting lower-frequency tokens\ncrucial for specificity and informativeness in generated content. This paper\nintroduces a novel loss function, Power-Law Decay Loss (PDL), specifically\ndesigned to optimize the finetuning process for text generation. The core\nmotivation for PDL stems from observations in information theory and\nlinguistics: the informativeness of a token is often inversely proportional to\nits frequency of occurrence. PDL re-weights the contribution of each token in\nthe standard cross-entropy loss based on its frequency in the training corpus,\nfollowing a power-law decay. Specifically, the weights for high-frequency\ntokens are reduced, while low-frequency, information-dense tokens are assigned\nhigher weights. This mechanism guides the model during finetuning to focus more\non learning and generating tokens that convey specific and unique information,\nthereby enhancing the quality, diversity, and informativeness of the generated\ntext. We theoretically elaborate on the motivation and construction of PDL and\ndiscuss its potential applications and advantages across various text\ngeneration finetuning tasks, such as abstractive summarization, dialogue\nsystems, and style transfer.", "published": "2025-05-22 16:59:26", "link": "http://arxiv.org/abs/2505.16900v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Shadows in the Attention: Contextual Perturbation and Representation Drift in the Dynamics of Hallucination in LLMs", "abstract": "Hallucinations -- plausible yet erroneous outputs -- remain a critical\nbarrier to reliable deployment of large language models (LLMs). We present the\nfirst systematic study linking hallucination incidence to internal-state drift\ninduced by incremental context injection. Using TruthfulQA, we construct two\n16-round \"titration\" tracks per question: one appends relevant but partially\nflawed snippets, the other injects deliberately misleading content. Across six\nopen-source LLMs, we track overt hallucination rates with a tri-perspective\ndetector and covert dynamics via cosine, entropy, JS and Spearman drifts of\nhidden states and attention maps. Results reveal (1) monotonic growth of\nhallucination frequency and representation drift that plateaus after 5--7\nrounds; (2) relevant context drives deeper semantic assimilation, producing\nhigh-confidence \"self-consistent\" hallucinations, whereas irrelevant context\ninduces topic-drift errors anchored by attention re-routing; and (3)\nconvergence of JS-Drift ($\\sim0.69$) and Spearman-Drift ($\\sim0$) marks an\n\"attention-locking\" threshold beyond which hallucinations solidify and become\nresistant to correction. Correlation analyses expose a seesaw between\nassimilation capacity and attention diffusion, clarifying size-dependent error\nmodes. These findings supply empirical foundations for intrinsic hallucination\nprediction and context-aware mitigation mechanisms.", "published": "2025-05-22 16:50:58", "link": "http://arxiv.org/abs/2505.16894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework", "abstract": "Large language models (LLMs) have advanced many applications, but are also\nknown to be vulnerable to adversarial attacks. In this work, we introduce a\nnovel security threat: hijacking AI-human conversations by manipulating LLMs'\nsystem prompts to produce malicious answers only to specific targeted questions\n(e.g., \"Who should I vote for US President?\", \"Are Covid vaccines safe?\"),\nwhile behaving benignly on others. This attack is detrimental as it can enable\nmalicious actors to exercise large-scale information manipulation by spreading\nharmful but benign-looking system prompts online. To demonstrate such an\nattack, we develop CAIN, an algorithm that can automatically curate such\nharmful system prompts for a specific target question in a black-box setting or\nwithout the need to access the LLM's parameters. Evaluated on both open-source\nand commercial LLMs, CAIN demonstrates significant adversarial impact. In\nuntargeted attacks or forcing LLMs to output incorrect answers, CAIN achieves\nup to 40% F1 degradation on targeted questions while preserving high accuracy\non benign inputs. For targeted attacks or forcing LLMs to output specific\nharmful answers, CAIN achieves over 70% F1 scores on these targeted responses\nwith minimal impact on benign questions. Our results highlight the critical\nneed for enhanced robustness measures to safeguard the integrity and safety of\nLLMs in real-world applications. All source code will be publicly available.", "published": "2025-05-22 16:47:15", "link": "http://arxiv.org/abs/2505.16888v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Don't \"Overthink\" Passage Reranking: Is Reasoning Truly Necessary?", "abstract": "With the growing success of reasoning models across complex natural language\ntasks, researchers in the Information Retrieval (IR) community have begun\nexploring how similar reasoning capabilities can be integrated into passage\nrerankers built on Large Language Models (LLMs). These methods typically employ\nan LLM to produce an explicit, step-by-step reasoning process before arriving\nat a final relevance prediction. But, does reasoning actually improve reranking\naccuracy? In this paper, we dive deeper into this question, studying the impact\nof the reasoning process by comparing reasoning-based pointwise rerankers\n(ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under\nidentical training conditions, and observe that StandardRR generally\noutperforms ReasonRR. Building on this observation, we then study the\nimportance of reasoning to ReasonRR by disabling its reasoning process\n(ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more\neffective than ReasonRR. Examining the cause of this result, our findings\nreveal that reasoning-based rerankers are limited by the LLM's reasoning\nprocess, which pushes it toward polarized relevance scores and thus fails to\nconsider the partial relevance of passages, a key factor for the accuracy of\npointwise rerankers.", "published": "2025-05-22 16:41:37", "link": "http://arxiv.org/abs/2505.16886v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "CASTILLO: Characterizing Response Length Distributions of Large Language Models", "abstract": "Efficiently managing compute resources for Large Language Model (LLM)\ninference remains challenging due to the inherently stochastic and variable\nlengths of autoregressive text generation. Accurately estimating response\nlengths in advance enables proactive resource allocation, yet existing\napproaches either bias text generation towards certain lengths or rely on\nassumptions that ignore model- and prompt-specific variability. We introduce\nCASTILLO, a dataset characterizing response length distributions across 13\nwidely-used open-source LLMs evaluated on seven distinct instruction-following\ncorpora. For each $\\langle$prompt, model$\\rangle$ sample pair, we generate 10\nindependent completions using fixed decoding hyper-parameters, record the token\nlength of each response, and publish summary statistics (mean, std-dev,\npercentiles), along with the shortest and longest completions, and the exact\ngeneration settings. Our analysis reveals significant inter- and intra-model\nvariability in response lengths (even under identical generation settings), as\nwell as model-specific behaviors and occurrences of partial text degeneration\nin only subsets of responses. CASTILLO enables the development of predictive\nmodels for proactive scheduling and provides a systematic framework for\nanalyzing model-specific generation behaviors. We publicly release the dataset\nand code to foster research at the intersection of generative language modeling\nand systems.", "published": "2025-05-22 16:35:33", "link": "http://arxiv.org/abs/2505.16881v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MPO: Multilingual Safety Alignment via Reward Gap Optimization", "abstract": "Large language models (LLMs) have become increasingly central to AI\napplications worldwide, necessitating robust multilingual safety alignment to\nensure secure deployment across diverse linguistic contexts. Existing\npreference learning methods for safety alignment, such as RLHF and DPO, are\nprimarily monolingual and struggle with noisy multilingual data. To address\nthese limitations, we introduce Multilingual reward gaP Optimization (MPO), a\nnovel approach that leverages the well-aligned safety capabilities of the\ndominant language (English) to improve safety alignment across multiple\nlanguages. MPO directly minimizes the reward gap difference between the\ndominant language and target languages, effectively transferring safety\ncapabilities while preserving the original strengths of the dominant language.\nExtensive experiments on three LLMs, LLaMA-3.1, Gemma-2 and Qwen2.5, validate\nMPO's efficacy in multilingual safety alignment without degrading general\nmultilingual utility.", "published": "2025-05-22 16:24:51", "link": "http://arxiv.org/abs/2505.16869v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative analysis of subword tokenization approaches for Indian languages", "abstract": "Tokenization is the act of breaking down text into smaller parts, or tokens,\nthat are easier for machines to process. This is a key phase in machine\ntranslation (MT) models. Subword tokenization enhances this process by breaking\ndown words into smaller subword units, which is especially beneficial in\nlanguages with complicated morphology or a vast vocabulary. It is useful in\ncapturing the intricate structure of words in Indian languages (ILs), such as\nprefixes, suffixes, and other morphological variations. These languages\nfrequently use agglutinative structures, in which words are formed by the\ncombination of multiple morphemes such as suffixes, prefixes, and stems. As a\nresult, a suitable tokenization strategy must be chosen to address these\nscenarios. This paper examines how different subword tokenization techniques,\nsuch as SentencePiece, Byte Pair Encoding (BPE), and WordPiece Tokenization,\naffect ILs. The effectiveness of these subword tokenization techniques is\ninvestigated in statistical, neural, and multilingual neural machine\ntranslation models. All models are examined using standard evaluation metrics,\nsuch as the Bilingual Evaluation Understudy (BLEU) score, TER, METEOR, CHRF,\nRIBES, and COMET. Based on the results, it appears that for the majority of\nlanguage pairs for the Statistical and Neural MT models, the SentencePiece\ntokenizer continuously performed better than other tokenizers in terms of BLEU\nscore. However, BPE tokenization outperformed other tokenization techniques in\nthe context of Multilingual Neural Machine Translation model. The results show\nthat, despite using the same tokenizer and dataset for each model, translations\nfrom ILs to English surpassed translations from English to ILs.", "published": "2025-05-22 16:24:37", "link": "http://arxiv.org/abs/2505.16868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nested Named Entity Recognition as Single-Pass Sequence Labeling", "abstract": "We cast nested named entity recognition (NNER) as a sequence labeling task by\nleveraging prior work that linearizes constituency structures, effectively\nreducing the complexity of this structured prediction problem to\nstraightforward token classification. By combining these constituency\nlinearizations with pretrained encoders, our method captures nested entities\nwhile performing exactly $n$ tagging actions. Our approach achieves competitive\nperformance compared to less efficient systems, and it can be trained using any\noff-the-shelf sequence labeling library.", "published": "2025-05-22 16:13:39", "link": "http://arxiv.org/abs/2505.16855v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning", "abstract": "Federated Learning (FL) has emerged as a promising paradigm for collaborative\nmodel training while preserving data privacy across decentralized participants.\nAs FL adoption grows, numerous techniques have been proposed to tackle its\npractical challenges. However, the lack of standardized evaluation across key\ndimensions hampers systematic progress and fair comparison of FL methods. In\nthis work, we introduce ATR-Bench, a unified framework for analyzing federated\nlearning through three foundational dimensions: Adaptation, Trust, and\nReasoning. We provide an in-depth examination of the conceptual foundations,\ntask formulations, and open research challenges associated with each theme. We\nhave extensively benchmarked representative methods and datasets for adaptation\nto heterogeneous clients and trustworthiness in adversarial or unreliable\nenvironments. Due to the lack of reliable metrics and models for reasoning in\nFL, we only provide literature-driven insights for this dimension. ATR-Bench\nlays the groundwork for a systematic and holistic evaluation of federated\nlearning with real-world relevance. We will make our complete codebase publicly\naccessible and a curated repository that continuously tracks new developments\nand research in the FL literature.", "published": "2025-05-22 16:11:38", "link": "http://arxiv.org/abs/2505.16850v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Understanding and Analyzing Inappropriately Targeting Language in Online Discourse: A Comparative Annotation Study", "abstract": "This paper introduces a method for detecting inappropriately targeting\nlanguage in online conversations by integrating crowd and expert annotations\nwith ChatGPT. We focus on English conversation threads from Reddit, examining\ncomments that target individuals or groups. Our approach involves a\ncomprehensive annotation framework that labels a diverse data set for various\ntarget categories and specific target words within the conversational context.\nWe perform a comparative analysis of annotations from human experts, crowd\nannotators, and ChatGPT, revealing strengths and limitations of each method in\nrecognizing both explicit hate speech and subtler discriminatory language. Our\nfindings highlight the significant role of contextual factors in identifying\nhate speech and uncover new categories of targeting, such as social belief and\nbody image. We also address the challenges and subjective judgments involved in\nannotation and the limitations of ChatGPT in grasping nuanced language. This\nstudy provides insights for improving automated content moderation strategies\nto enhance online safety and inclusivity.", "published": "2025-05-22 16:10:43", "link": "http://arxiv.org/abs/2505.16847v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search", "abstract": "Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by\nenabling step-by-step problem-solving, yet its extension to Long-CoT introduces\nsubstantial computational overhead due to increased token length. Existing\ncompression approaches -- instance-level and token-level -- either sacrifice\nessential local reasoning signals like reflection or yield incoherent outputs.\nTo address these limitations, we propose R1-Compress, a two-stage chunk-level\ncompression framework that preserves both local information and coherence. Our\nmethod segments Long-CoT into manageable chunks, applies LLM-driven inner-chunk\ncompression, and employs an inter-chunk search mechanism to select the short\nand coherent sequence. Experiments on Qwen2.5-Instruct models across MATH500,\nAIME24, and GPQA-Diamond demonstrate that R1-Compress significantly reduces\ntoken usage while maintaining comparable reasoning accuracy. On MATH500,\nR1-Compress achieves an accuracy of 92.4%, with only a 0.6% drop compared to\nthe Long-CoT baseline, while reducing token usage by about 20%. Source code\nwill be available at https://github.com/w-yibo/R1-Compress", "published": "2025-05-22 16:06:59", "link": "http://arxiv.org/abs/2505.16838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis", "abstract": "Retrieval-augmented generation (RAG) systems have advanced large language\nmodels (LLMs) in complex deep search scenarios requiring multi-step reasoning\nand iterative information retrieval. However, existing approaches face critical\nlimitations that lack high-quality training trajectories or suffer from the\ndistributional mismatches in simulated environments and prohibitive\ncomputational costs for real-world deployment. This paper introduces\nSimpleDeepSearcher, a lightweight yet effective framework that bridges this gap\nthrough strategic data engineering rather than complex training paradigms. Our\napproach synthesizes high-quality training data by simulating realistic user\ninteractions in live web search environments, coupled with a multi-criteria\ncuration strategy that optimizes the diversity and quality of input and output\nside. Experiments on five benchmarks across diverse domains demonstrate that\nSFT on only 871 curated samples yields significant improvements over RL-based\nbaselines. Our work establishes SFT as a viable pathway by systematically\naddressing the data-scarce bottleneck, offering practical insights for\nefficient deep search systems. Our code is available at\nhttps://github.com/RUCAIBox/SimpleDeepSearcher.", "published": "2025-05-22 16:05:02", "link": "http://arxiv.org/abs/2505.16834v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization", "abstract": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.", "published": "2025-05-22 16:02:18", "link": "http://arxiv.org/abs/2505.16832v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs", "abstract": "Unlearning in large language models (LLMs) is intended to remove the\ninfluence of specific data, yet current evaluations rely heavily on token-level\nmetrics such as accuracy and perplexity. We show that these metrics can be\nmisleading: models often appear to forget, but their original behavior can be\nrapidly restored with minimal fine-tuning, revealing that unlearning may\nobscure information rather than erase it. To diagnose this phenomenon, we\nintroduce a representation-level evaluation framework using PCA-based\nsimilarity and shift, centered kernel alignment, and Fisher information.\nApplying this toolkit across six unlearning methods, three domains (text, code,\nmath), and two open-source LLMs, we uncover a critical distinction between\nreversible and irreversible forgetting. In reversible cases, models suffer\ntoken-level collapse yet retain latent features; in irreversible cases, deeper\nrepresentational damage occurs. We further provide a theoretical account\nlinking shallow weight perturbations near output layers to misleading\nunlearning signals, and show that reversibility is modulated by task type and\nhyperparameters. Our findings reveal a fundamental gap in current evaluation\npractices and establish a new diagnostic foundation for trustworthy unlearning\nin LLMs. We provide a unified toolkit for analyzing LLM representation changes\nunder unlearning and relearning:\nhttps://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.", "published": "2025-05-22 16:02:10", "link": "http://arxiv.org/abs/2505.16831v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning", "abstract": "Recent advances have demonstrated that integrating reinforcement learning\nwith rule-based rewards can significantly enhance the reasoning capabilities of\nlarge language models, even without supervised fine-tuning. However, prevalent\nreinforcement learning algorithms such as GRPO and its variants like DAPO,\nsuffer from a coarse granularity issue when computing the advantage.\nSpecifically, they compute rollout-level advantages that assign identical\nvalues to every token within a sequence, failing to capture token-specific\ncontributions and hindering effective learning. To address this limitation, we\npropose Key-token Advantage Estimation (KTAE) - a novel algorithm that\nestimates fine-grained, token-level advantages without introducing additional\nmodels. KTAE leverages the correctness of sampled rollouts and applies\nstatistical analysis to quantify the importance of individual tokens within a\nsequence to the final outcome. This quantified token-level importance is then\ncombined with the rollout-level advantage to obtain a more fine-grained\ntoken-level advantage estimation. Empirical results show that models trained\nwith GRPO+KTAE and DAPO+KTAE outperform baseline methods across five\nmathematical reasoning benchmarks. Notably, they achieve higher accuracy with\nshorter responses and even surpass R1-Distill-Qwen-1.5B using the same base\nmodel.", "published": "2025-05-22 16:00:33", "link": "http://arxiv.org/abs/2505.16826v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Does Synthetic Data Help Named Entity Recognition for Low-Resource Languages?", "abstract": "Named Entity Recognition(NER) for low-resource languages aims to produce\nrobust systems for languages where there is limited labeled training data\navailable, and has been an area of increasing interest within NLP. Data\naugmentation for increasing the amount of low-resource labeled data is a common\npractice. In this paper, we explore the role of synthetic data in the context\nof multilingual, low-resource NER, considering 11 languages from diverse\nlanguage families. Our results suggest that synthetic data does in fact hold\npromise for low-resource language NER, though we see significant variation\nbetween languages.", "published": "2025-05-22 15:50:47", "link": "http://arxiv.org/abs/2505.16814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement", "abstract": "Large language models (LLMs) encounter difficulties in knowledge-intensive\nmulti-step reasoning (KIMSR) tasks. One challenge is how to effectively extract\nand represent rationale evidence. The current methods often extract\nsemantically relevant but logically irrelevant evidence, resulting in flawed\nreasoning and inaccurate responses. We propose a two-way evidence\nself-alignment (TW-ESA) module, which utilizes the mutual alignment between\nstrict reasoning and LLM reasoning to enhance its understanding of the causal\nlogic of evidence, thereby addressing the first challenge. Another challenge is\nhow to utilize the rationale evidence and LLM's intrinsic knowledge for\naccurate reasoning when the evidence contains uncertainty. We propose a\ndual-gated reasoning enhancement (DGR) module to gradually fuse useful\nknowledge of LLM within strict reasoning, which can enable the model to perform\naccurate reasoning by focusing on causal elements in the evidence and exhibit\ngreater robustness. The two modules are collaboratively trained in a unified\nframework ESA-DGR. Extensive experiments on three diverse and challenging KIMSR\ndatasets reveal that ESA-DGR significantly surpasses state-of-the-art LLM-based\nfine-tuning methods, with remarkable average improvements of 4% in exact match\n(EM) and 5% in F1 score. The implementation code is available at\nhttps://anonymous.4open.science/r/ESA-DGR-2BF8.", "published": "2025-05-22 15:45:29", "link": "http://arxiv.org/abs/2505.16806v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning Beyond Limits: Multitask Learning and Synthetic Data for Low-Resource Canonical Morpheme Segmentation", "abstract": "We introduce a transformer-based morpheme segmentation system that augments a\nlow-resource training signal through multitask learning and LLM-generated\nsynthetic data. Our framework jointly predicts morphological segments and\nglosses from orthographic input, leveraging shared linguistic representations\nobtained through a common documentary process to enhance model generalization.\nTo further address data scarcity, we integrate synthetic training data\ngenerated by large language models (LLMs) using in-context learning.\nExperimental results on the SIGMORPHON 2023 dataset show that our approach\nsignificantly improves word-level segmentation accuracy and morpheme-level\nF1-score across multiple low-resource languages.", "published": "2025-05-22 15:40:09", "link": "http://arxiv.org/abs/2505.16800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability", "abstract": "As large language models gain popularity, their vulnerability to adversarial\nattacks remains a primary concern. While fine-tuning models on domain-specific\ndatasets is often employed to improve model performance, it can introduce\nvulnerabilities within the underlying model. In this work, we investigate\nAccidental Misalignment, unexpected vulnerabilities arising from\ncharacteristics of fine-tuning data. We begin by identifying potential\ncorrelation factors such as linguistic features, semantic similarity, and\ntoxicity within our experimental datasets. We then evaluate the adversarial\nperformance of these fine-tuned models and assess how dataset factors correlate\nwith attack success rates. Lastly, we explore potential causal links, offering\nnew insights into adversarial defense strategies and highlighting the crucial\nrole of dataset design in preserving model alignment. Our code is available at\nhttps://github.com/psyonp/accidental_misalignment.", "published": "2025-05-22 15:30:00", "link": "http://arxiv.org/abs/2505.16789v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning", "abstract": "Large Language Models (LLMs) have achieved impressive performance on complex\nreasoning tasks with Chain-of-Thought (CoT) prompting. However, conventional\nCoT relies on reasoning steps explicitly verbalized in natural language,\nintroducing inefficiencies and limiting its applicability to abstract\nreasoning. To address this, there has been growing research interest in latent\nCoT reasoning, where inference occurs within latent spaces. By decoupling\nreasoning from language, latent reasoning promises richer cognitive\nrepresentations and more flexible, faster inference. Researchers have explored\nvarious directions in this promising field, including training methodologies,\nstructural innovations, and internal reasoning mechanisms. This paper presents\na comprehensive overview and analysis of this reasoning paradigm. We begin by\nproposing a unified taxonomy from four perspectives: token-wise strategies,\ninternal mechanisms, analysis, and applications. We then provide in-depth\ndiscussions and comparative analyses of representative methods, highlighting\ntheir design patterns, strengths, and open challenges. We aim to provide a\nstructured foundation for advancing this emerging direction in LLM reasoning.\nThe relevant papers will be regularly updated at\nhttps://github.com/EIT-NLP/Awesome-Latent-CoT.", "published": "2025-05-22 15:26:51", "link": "http://arxiv.org/abs/2505.16782v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models", "abstract": "Large language models (LLMs) have demonstrated strong instruction-following\ncapabilities in text-based tasks. However, this ability often deteriorates in\nmultimodal models after alignment with non-text modalities such as images or\naudio. While several recent efforts have investigated instruction-following\nperformance in text and vision-language models, instruction-following in\naudio-based large language models remains largely unexplored. To bridge this\ngap, we introduce IFEval-Audio, a novel evaluation dataset designed to assess\nthe ability to follow instructions in an audio LLM. IFEval-Audio contains 280\naudio-instruction-answer triples across six diverse dimensions: Content,\nCapitalization, Symbol, List Structure, Length, and Format. Each example pairs\nan audio input with a text instruction, requiring the model to generate an\noutput that follows a specified structure. We benchmark state-of-the-art audio\nLLMs on their ability to follow audio-involved instructions. The dataset is\nreleased publicly to support future research in this emerging area.", "published": "2025-05-22 15:15:29", "link": "http://arxiv.org/abs/2505.16774v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning", "abstract": "Large Language Models (LLMs) present significant computational and memory\nchallenges due to their extensive size, making pruning essential for their\nefficient deployment. Existing one-shot pruning methods often apply uniform\nsparsity constraints across layers or within each layer, resulting in\nsuboptimal performance, especially at high sparsity ratios. This work\nintroduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel\napproach that applies varying sparsity ratios to individual output dimensions\n(rows) within each layer. TRIM employs an iterative adjustment process guided\nby quality metrics to optimize dimension-wise sparsity allocation, focusing on\nreducing variance in quality retention across outputs to preserve critical\ninformation. TRIM can be seamlessly integrated with existing layer-wise pruning\nstrategies. Our evaluations on perplexity and zero-shot tasks across diverse\nLLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that\nTRIM achieves new state-of-the-art results and enhances stability. For\ninstance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and\nover 90% for OPT-13B compared to baseline methods. We conclude that\nfine-grained, dimension-wise sparsity adaptation is crucial for pushing the\nlimits of extreme LLM compression. Code available at:\nhttps://github.com/flobk/TRIM", "published": "2025-05-22 14:53:53", "link": "http://arxiv.org/abs/2505.16743v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; F.2.2"], "primary_category": "cs.CL"}
{"title": "Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization", "abstract": "The significant progress of large language models (LLMs) has led to\nremarkable achievements across numerous applications. However, their ability to\ngenerate harmful content has sparked substantial safety concerns. Despite the\nimplementation of safety alignment techniques during the pre-training phase,\nrecent research indicates that fine-tuning LLMs on adversarial or even benign\ndata can inadvertently compromise their safety. In this paper, we re-examine\nthe fundamental issue of why fine-tuning on non-harmful data still results in\nsafety degradation. We introduce a safety-aware probing (SAP) optimization\nframework designed to mitigate the safety risks of fine-tuning LLMs.\nSpecifically, SAP incorporates a safety-aware probe into the gradient\npropagation process, mitigating the model's risk of safety degradation by\nidentifying potential pitfalls in gradient directions, thereby enhancing\ntask-specific performance while successfully preserving model safety. Our\nextensive experimental results demonstrate that SAP effectively reduces\nharmfulness below the original fine-tuned model and achieves comparable test\nloss to standard fine-tuning methods. Our code is available at\nhttps://github.com/ChengcanWu/SAP.", "published": "2025-05-22 14:52:10", "link": "http://arxiv.org/abs/2505.16737v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "math.OC"], "primary_category": "cs.LG"}
{"title": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "abstract": "As large language models (LLMs) become increasingly prevalent in global\napplications, ensuring that they are toxicity-free across diverse linguistic\ncontexts remains a critical challenge. We explore \"Cross-lingual\nDetoxification\", a cross-lingual paradigm that mitigates toxicity, enabling\ndetoxification capabilities to transfer between high and low-resource languages\nacross different script families. We analyze cross-lingual detoxification's\neffectiveness through 504 extensive settings to evaluate toxicity reduction in\ncross-distribution settings with limited data and investigate how mitigation\nimpacts model performance on non-toxic tasks, revealing trade-offs between\nsafety and knowledge preservation. Our code and dataset are publicly available\nat https://github.com/himanshubeniwal/Breaking-mBad.", "published": "2025-05-22 14:30:14", "link": "http://arxiv.org/abs/2505.16722v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs", "abstract": "Although multimodal large language models (MLLMs) have achieved impressive\nperformance, the multimodal instruction tuning stage often causes catastrophic\nforgetting of the base LLM's language ability, even in strong models like\nLlama3. To address this, we propose Locate-then-Merge, a training-free\nparameter fusion framework that first locates important parameters and then\nselectively merges them. We further introduce Neuron-Fusion, a neuron-level\nstrategy that preserves the influence of neurons with large parameter\nshifts--neurons likely responsible for newly acquired visual\ncapabilities--while attenuating the influence of neurons with smaller changes\nthat likely encode general-purpose language skills. This design enables better\nretention of visual adaptation while mitigating language degradation.\nExperiments on 13 benchmarks across both language and visual tasks show that\nNeuron-Fusion consistently outperforms existing model merging methods. Further\nanalysis reveals that our method effectively reduces context hallucination in\ngeneration.", "published": "2025-05-22 14:04:43", "link": "http://arxiv.org/abs/2505.16703v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence", "abstract": "Transformer-based language models exhibit In-Context Learning (ICL), where\npredictions are made adaptively based on context. While prior work links\ninduction heads to ICL through a sudden jump in accuracy, this can only account\nfor ICL when the answer is included within the context. However, an important\nproperty of practical ICL in large language models is the ability to meta-learn\nhow to solve tasks from context, rather than just copying answers from context;\nhow such an ability is obtained during training is largely unexplored. In this\npaper, we experimentally clarify how such meta-learning ability is acquired by\nanalyzing the dynamics of the model's circuit during training. Specifically, we\nextend the copy task from previous research into an In-Context Meta Learning\nsetting, where models must infer a task from examples to answer queries.\nInterestingly, in this setting, we find that there are multiple phases in the\nprocess of acquiring such abilities, and that a unique circuit emerges in each\nphase, contrasting with the single-phases change in induction heads. The\nemergence of such circuits can be related to several phenomena known in large\nlanguage models, and our analysis lead to a deeper understanding of the source\nof the transformer's ICL ability.", "published": "2025-05-22 13:59:30", "link": "http://arxiv.org/abs/2505.16694v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPaRC: A Spatial Pathfinding Reasoning Challenge", "abstract": "Existing reasoning datasets saturate and fail to test abstract, multi-step\nproblems, especially pathfinding and complex rule constraint satisfaction. We\nintroduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000\n2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,\nrequiring step-by-step planning with arithmetic and geometric rules. Humans\nachieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best\nreasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).\nModels often generate invalid paths (>50% of puzzles for o4-mini), and\nreasoning tokens reveal they make errors in navigation and spatial logic.\nUnlike humans, who take longer on hard puzzles, models fail to scale test-time\ncompute with difficulty. Allowing models to make multiple solution attempts\nimproves accuracy, suggesting potential for better spatial reasoning with\nimproved training and efficient test-time scaling methods. SPaRC can be used as\na window into models' spatial reasoning limitations and drive research toward\nnew methods that excel in abstract, multi-step problem-solving.", "published": "2025-05-22 13:53:50", "link": "http://arxiv.org/abs/2505.16686v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO", "abstract": "In this work, we aim to incentivize the reasoning ability of Multimodal Large\nLanguage Models (MLLMs) via reinforcement learning (RL) and develop an\neffective approach that mitigates the sparse reward and advantage vanishing\nissues during RL. To this end, we propose Share-GRPO, a novel RL approach that\ntackle these issues by exploring and sharing diverse reasoning trajectories\nover expanded question space. Specifically, Share-GRPO first expands the\nquestion space for a given question via data transformation techniques, and\nthen encourages MLLM to effectively explore diverse reasoning trajectories over\nthe expanded question space and shares the discovered reasoning trajectories\nacross the expanded questions during RL. In addition, Share-GRPO also shares\nreward information during advantage computation, which estimates solution\nadvantages hierarchically across and within question variants, allowing more\naccurate estimation of relative advantages and improving the stability of\npolicy training. Extensive evaluations over six widely-used reasoning\nbenchmarks showcase the superior performance of our method. Code will be\navailable at https://github.com/HJYao00/R1-ShareVL.", "published": "2025-05-22 13:39:32", "link": "http://arxiv.org/abs/2505.16673v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Japanese Language Model and Three New Evaluation Benchmarks for Pharmaceutical NLP", "abstract": "We present a Japanese domain-specific language model for the pharmaceutical\nfield, developed through continual pretraining on 2 billion Japanese\npharmaceutical tokens and 8 billion English biomedical tokens. To enable\nrigorous evaluation, we introduce three new benchmarks: YakugakuQA, based on\nnational pharmacist licensing exams; NayoseQA, which tests cross-lingual\nsynonym and terminology normalization; and SogoCheck, a novel task designed to\nassess consistency reasoning between paired statements. We evaluate our model\nagainst both open-source medical LLMs and commercial models, including GPT-4o.\nResults show that our domain-specific model outperforms existing open models\nand achieves competitive performance with commercial ones, particularly on\nterminology-heavy and knowledge-based tasks. Interestingly, even GPT-4o\nperforms poorly on SogoCheck, suggesting that cross-sentence consistency\nreasoning remains an open challenge. Our benchmark suite offers a broader\ndiagnostic lens for pharmaceutical NLP, covering factual recall, lexical\nvariation, and logical consistency. This work demonstrates the feasibility of\nbuilding practical, secure, and cost-effective language models for Japanese\ndomain-specific applications, and provides reusable evaluation resources for\nfuture research in pharmaceutical and healthcare NLP. Our model, codes, and\ndatasets are released at https://github.com/EQUES-Inc/pharma-LLM-eval.", "published": "2025-05-22 13:27:37", "link": "http://arxiv.org/abs/2505.16661v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu", "abstract": "This study addresses the challenges in intelligent processing of Chinese\nancient mathematical classics by constructing Guji_MATH, a benchmark for\nevaluating classical texts based on Suanjing Shishu. It systematically assesses\nthe mathematical problem-solving capabilities of mainstream reasoning models\nunder the unique linguistic constraints of classical Chinese. Through\nmachine-assisted annotation and manual verification, 538 mathematical problems\nwere extracted from 8 canonical texts, forming a structured dataset centered on\nthe \"Question-Answer-Solution\" framework, supplemented by problem types and\ndifficulty levels. Dual evaluation modes--closed-book (autonomous\nproblem-solving) and open-book (reproducing classical solution methods)--were\ndesigned to evaluate the performance of six reasoning models on ancient Chinese\nmathematical problems. Results indicate that reasoning models can partially\ncomprehend and solve these problems, yet their overall performance remains\ninferior to benchmarks on modern mathematical tasks. Enhancing models'\nclassical Chinese comprehension and cultural knowledge should be prioritized\nfor optimization. This study provides methodological support for mining\nmathematical knowledge from ancient texts and disseminating traditional\nculture, while offering new perspectives for evaluating cross-linguistic and\ncross-cultural capabilities of reasoning models.", "published": "2025-05-22 13:24:52", "link": "http://arxiv.org/abs/2505.16660v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Collaboration among Multiple Large Language Models for Medical Question Answering", "abstract": "Empowered by vast internal knowledge reservoir, the new generation of large\nlanguage models (LLMs) demonstrate untapped potential to tackle medical tasks.\nHowever, there is insufficient effort made towards summoning up a synergic\neffect from multiple LLMs' expertise and background. In this study, we propose\na multi-LLM collaboration framework tailored on a medical multiple-choice\nquestions dataset. Through post-hoc analysis on 3 pre-trained LLM participants,\nour framework is proved to boost all LLMs reasoning ability as well as\nalleviate their divergence among questions. We also measure an LLM's confidence\nwhen it confronts with adversary opinions from other LLMs and observe a\nconcurrence between LLM's confidence and prediction accuracy.", "published": "2025-05-22 13:18:45", "link": "http://arxiv.org/abs/2505.16648v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation", "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities in machine translation (MT). However, most advanced MT-specific\nLLMs heavily rely on external supervision signals during training, such as\nhuman-annotated reference data or trained reward models (RMs), which are often\nexpensive to obtain and challenging to scale. To overcome this limitation, we\npropose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for\nMT that is reference-free, fully online, and relies solely on self-judging\nrewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as\nthe backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs,\ne.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like\nQwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks\nfrom WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR\nwith external supervision from COMET, our strongest model, SSR-X-Zero-7B,\nachieves state-of-the-art performance in English $\\leftrightarrow$ Chinese\ntranslation, surpassing all existing open-source models under 72B parameters\nand even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro.\nOur analysis highlights the effectiveness of the self-rewarding mechanism\ncompared to the external LLM-as-a-judge approach in MT and demonstrates its\ncomplementary benefits when combined with trained RMs. Our findings provide\nvaluable insight into the potential of self-improving RL methods. We have\npublicly released our code, data and models.", "published": "2025-05-22 13:08:25", "link": "http://arxiv.org/abs/2505.16637v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MiLQ: Benchmarking IR Models for Bilingual Web Search with Mixed Language Queries", "abstract": "Despite bilingual speakers frequently using mixed-language queries in web\nsearches, Information Retrieval (IR) research on them remains scarce. To\naddress this, we introduce MiLQ,Mixed-Language Query test set, the first public\nbenchmark of mixed-language queries, confirmed as realistic and highly\npreferred. Experiments show that multilingual IR models perform moderately on\nMiLQ and inconsistently across native, English, and mixed-language queries,\nalso suggesting code-switched training data's potential for robust IR models\nhandling such queries. Meanwhile, intentional English mixing in queries proves\nan effective strategy for bilinguals searching English documents, which our\nanalysis attributes to enhanced token matching compared to native queries.", "published": "2025-05-22 13:03:15", "link": "http://arxiv.org/abs/2505.16631v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Grounding Chest X-Ray Visual Question Answering with Generated Radiology Reports", "abstract": "We present a novel approach to Chest X-ray (CXR) Visual Question Answering\n(VQA), addressing both single-image image-difference questions. Single-image\nquestions focus on abnormalities within a specific CXR (\"What abnormalities are\nseen in image X?\"), while image-difference questions compare two longitudinal\nCXRs acquired at different time points (\"What are the differences between image\nX and Y?\"). We further explore how the integration of radiology reports can\nenhance the performance of VQA models. While previous approaches have\ndemonstrated the utility of radiology reports during the pre-training phase, we\nextend this idea by showing that the reports can also be leveraged as\nadditional input to improve the VQA model's predicted answers. First, we\npropose a unified method that handles both types of questions and\nauto-regressively generates the answers. For single-image questions, the model\nis provided with a single CXR. For image-difference questions, the model is\nprovided with two CXRs from the same patient, captured at different time\npoints, enabling the model to detect and describe temporal changes. Taking\ninspiration from 'Chain-of-Thought reasoning', we demonstrate that performance\non the CXR VQA task can be improved by grounding the answer generator module\nwith a radiology report predicted for the same CXR. In our approach, the VQA\nmodel is divided into two steps: i) Report Generation (RG) and ii) Answer\nGeneration (AG). Our results demonstrate that incorporating predicted radiology\nreports as evidence to the AG model enhances performance on both single-image\nand image-difference questions, achieving state-of-the-art results on the\nMedical-Diff-VQA dataset.", "published": "2025-05-22 12:57:35", "link": "http://arxiv.org/abs/2505.16624v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Steering Large Language Models for Machine Translation Personalization", "abstract": "High-quality machine translation systems based on large language models\n(LLMs) have simplified the production of personalized translations reflecting\nspecific stylistic constraints. However, these systems still struggle in\nsettings where stylistic requirements are less explicit and might be harder to\nconvey via prompting. We explore various strategies for personalizing\nLLM-generated translations in low-resource settings, focusing on the\nchallenging literary translation domain. We explore prompting strategies and\ninference-time interventions for steering model generations towards a\npersonalized style, and propose a contrastive framework exploiting latent\nconcepts extracted from sparse autoencoders to identify salient personalization\nproperties. Our results show that steering achieves strong personalization\nwhile preserving translation quality. We further examine the impact of steering\non LLM representations, finding model layers with a relevant impact for\npersonalization are impacted similarly by multi-shot prompting and our steering\nmethod, suggesting similar mechanism at play.", "published": "2025-05-22 12:47:16", "link": "http://arxiv.org/abs/2505.16612v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Generic Empathy to Personalized Emotional Support: A Self-Evolution Framework for User Preference Alignment", "abstract": "Effective emotional support hinges on understanding users' emotions and needs\nto provide meaningful comfort during multi-turn interactions. Large Language\nModels (LLMs) show great potential for expressing empathy; however, they often\ndeliver generic and one-size-fits-all responses that fail to address users'\nspecific needs. To tackle this issue, we propose a self-evolution framework\ndesigned to help LLMs improve their responses to better align with users'\nimplicit preferences concerning user profiles (personalities), emotional\nstates, and specific situations. Our framework consists of two distinct phases:\n\\textit{(1)} \\textit{Emotional Support Experience Acquisition}, where LLMs are\nfine-tuned on limited emotional support conversation data to provide basic\nsupport, and \\textit{(2)} \\textit{Self-Improvement for Personalized Emotional\nSupport}, where LLMs leverage self-reflection and self-refinement to generate\npersonalized responses. Through iterative direct preference optimization\nbetween the pre- and post-refined responses, our model generates responses that\nreflect a better understanding of the user's implicit preferences. Extensive\nexperiments and evaluations demonstrate that our method significantly enhances\nthe model's performance in emotional support, reducing unhelpful responses and\nminimizing discrepancies between user preferences and model outputs.", "published": "2025-05-22 12:45:12", "link": "http://arxiv.org/abs/2505.16610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Media Frames Reveal About Stance: A Dataset and Study about Memes in Climate Change Discourse", "abstract": "Media framing refers to the emphasis on specific aspects of perceived reality\nto shape how an issue is defined and understood. Its primary purpose is to\nshape public perceptions often in alignment with the authors' opinions and\nstances. However, the interaction between stance and media frame remains\nlargely unexplored. In this work, we apply an interdisciplinary approach to\nconceptualize and computationally explore this interaction with internet memes\non climate change. We curate CLIMATEMEMES, the first dataset of climate-change\nmemes annotated with both stance and media frames, inspired by research in\ncommunication science. CLIMATEMEMES includes 1,184 memes sourced from 47\nsubreddits, enabling analysis of frame prominence over time and communities,\nand sheds light on the framing preferences of different stance holders. We\npropose two meme understanding tasks: stance detection and media frame\ndetection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the\ncorresponding results on their LLM backbone. Human captions consistently\nenhance performance. Synthetic captions and human-corrected OCR also help\noccasionally. Our findings highlight that VLMs perform well on stance, but\nstruggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs'\nlimitations in handling nuanced frames and stance expressions on climate change\ninternet memes.", "published": "2025-05-22 12:27:12", "link": "http://arxiv.org/abs/2505.16592v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Model with Knowledge Oriented Language Specific Simple Question Answering", "abstract": "We introduce KoLasSimpleQA, the first benchmark evaluating the multilingual\nfactual ability of Large Language Models (LLMs). Inspired by existing research,\nwe created the question set with features such as single knowledge point\ncoverage, absolute objectivity, unique answers, and temporal stability. These\nquestions enable efficient evaluation using the LLM-as-judge paradigm, testing\nboth the LLMs' factual memory and self-awareness (\"know what they don't know\").\nKoLasSimpleQA expands existing research in two key dimensions: (1) Breadth\n(Multilingual Coverage): It includes 9 languages, supporting global\napplicability evaluation. (2) Depth (Dual Domain Design): It covers both the\ngeneral domain (global facts) and the language-specific domain (such as\nhistory, culture, and regional traditions) for a comprehensive assessment of\nmultilingual capabilities. We evaluated mainstream LLMs, including traditional\nLLM and emerging Large Reasoning Models. Results show significant performance\ndifferences between the two domains, particularly in performance metrics,\nranking, calibration, and robustness. This highlights the need for targeted\nevaluation and optimization in multilingual contexts. We hope KoLasSimpleQA\nwill help the research community better identify LLM capability boundaries in\nmultilingual contexts and provide guidance for model optimization. We will\nrelease KoLasSimpleQA at https://github.com/opendatalab/KoLasSimpleQA .", "published": "2025-05-22 12:27:02", "link": "http://arxiv.org/abs/2505.16591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering", "abstract": "Large Language Models (LLMs), despite their advancements, are fundamentally\nlimited by their static parametric knowledge, hindering performance on tasks\nrequiring open-domain up-to-date information. While enabling LLMs to interact\nwith external knowledge environments is a promising solution, current efforts\nprimarily address closed-end problems. Open-ended questions, which\ncharacterized by lacking a standard answer or providing non-unique and diverse\nanswers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a\nnovel search agent leveraging reinforcement learning to effectively tackle both\nopen-ended and closed-ended questions in the open domain. O$^2$-Searcher\nleverages an efficient, locally simulated search environment for dynamic\nknowledge acquisition, effectively decoupling the external world knowledge from\nmodel's sophisticated reasoning processes. It employs a unified training\nmechanism with meticulously designed reward functions, enabling the agent to\nidentify problem types and adapt different answer generation strategies.\nFurthermore, to evaluate performance on complex open-ended tasks, we construct\nO$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain\nopen-ended questions with associated web page caches. Extensive experiments\nshow that O$^2$-Searcher, using only a 3B model, significantly surpasses\nleading LLM agents on O$^2$-QA. It also achieves SOTA results on various\nclosed-ended QA benchmarks against similarly-sized models, while performing on\npar with much larger ones.", "published": "2025-05-22 12:17:13", "link": "http://arxiv.org/abs/2505.16582v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions", "abstract": "Determining the veracity of atomic claims is an imperative component of many\nrecently proposed fact-checking systems. Many approaches tackle this problem by\nfirst retrieving evidence by querying a search engine and then performing\nclassification by providing the evidence set and atomic claim to a large\nlanguage model, but this process deviates from what a human would do in order\nto perform the task. Recent work attempted to address this issue by proposing\niterative evidence retrieval, allowing for evidence to be collected several\ntimes and only when necessary. Continuing along this line of research, we\npropose a novel claim verification system, called EMULATE, which is designed to\nbetter emulate human actions through the use of a multi-agent framework where\neach agent performs a small part of the larger task, such as ranking search\nresults according to predefined criteria or evaluating webpage content.\nExtensive experiments on several benchmarks show clear improvements over prior\nwork, demonstrating the efficacy of our new multi-agent framework.", "published": "2025-05-22 12:08:08", "link": "http://arxiv.org/abs/2505.16576v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training", "abstract": "Large Language Models (LLMs) are commonly pretrained on vast corpora of text\nwithout utilizing contextual metadata such as source, quality, or topic,\nleading to a context-free learning paradigm. While recent studies suggest that\nadding metadata like URL information as context (i.e., auxiliary inputs not\nused in the loss calculation) can improve training efficiency and downstream\nperformance, they offer limited understanding of which types of metadata are\ntruly effective and under what conditions. In this work, we conduct a\nsystematic evaluation and find that not all metadata types contribute equally.\nOnly URL context speeds up training, whereas quality scores and topic/format\ndomain information offer no clear benefit. Furthermore, the improved downstream\nperformances of URL conditioning emerge only when longer prompts are used at\ninference time. In addition, we demonstrate that context-aware pretraining\nenables more controllable generation than context-free pretraining, in a\nclassifier-free guidance fashion. Although topic and format metadata do not\naccelerate training, they are effective for steering outputs, offering\nhuman-interpretable control over generation.", "published": "2025-05-22 12:01:20", "link": "http://arxiv.org/abs/2505.16570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ScholarBench: A Bilingual Benchmark for Abstraction, Comprehension, and Reasoning Evaluation in Academic Contexts", "abstract": "Prior benchmarks for evaluating the domain-specific knowledge of large\nlanguage models (LLMs) lack the scalability to handle complex academic tasks.\nTo address this, we introduce \\texttt{ScholarBench}, a benchmark centered on\ndeep expert knowledge and complex academic problem-solving, which evaluates the\nacademic reasoning ability of LLMs and is constructed through a three-step\nprocess. \\texttt{ScholarBench} targets more specialized and logically complex\ncontexts derived from academic literature, encompassing five distinct problem\ntypes. Unlike prior benchmarks, \\texttt{ScholarBench} evaluates the\nabstraction, comprehension, and reasoning capabilities of LLMs across eight\ndistinct research domains. To ensure high-quality evaluation data, we define\ncategory-specific example attributes and design questions that are aligned with\nthe characteristic research methodologies and discourse structures of each\ndomain. Additionally, this benchmark operates as an English-Korean bilingual\ndataset, facilitating simultaneous evaluation for linguistic capabilities of\nLLMs in both languages. The benchmark comprises 5,031 examples in Korean and\n5,309 in English, with even state-of-the-art models like o3-mini achieving an\naverage evaluation score of only 0.543, demonstrating the challenging nature of\nthis benchmark.", "published": "2025-05-22 11:59:06", "link": "http://arxiv.org/abs/2505.16566v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning", "abstract": "Fine-tuning-as-a-service, while commercially successful for Large Language\nModel (LLM) providers, exposes models to harmful fine-tuning attacks. As a\nwidely explored defense paradigm against such attacks, unlearning attempts to\nremove malicious knowledge from LLMs, thereby essentially preventing them from\nbeing used to perform malicious tasks. However, we highlight a critical flaw:\nthe powerful general adaptability of LLMs allows them to easily bypass\nselective unlearning by rapidly relearning or repurposing their capabilities\nfor harmful tasks. To address this fundamental limitation, we propose a\nparadigm shift: instead of selective removal, we advocate for inducing model\ncollapse--effectively forcing the model to \"unlearn everything\"--specifically\nin response to updates characteristic of malicious adaptation. This collapse\ndirectly neutralizes the very general capabilities that attackers exploit,\ntackling the core issue unaddressed by selective unlearning. We introduce the\nCollapse Trap (CTRAP) as a practical mechanism to implement this concept\nconditionally. Embedded during alignment, CTRAP pre-configures the model's\nreaction to subsequent fine-tuning dynamics. If updates during fine-tuning\nconstitute a persistent attempt to reverse safety alignment, the pre-configured\ntrap triggers a progressive degradation of the model's core language modeling\nabilities, ultimately rendering it inert and useless for the attacker.\nCrucially, this collapse mechanism remains dormant during benign fine-tuning,\nensuring the model's utility and general capabilities are preserved for\nlegitimate users. Extensive empirical results demonstrate that CTRAP\neffectively counters harmful fine-tuning risks across various LLMs and attack\nsettings, while maintaining high performance in benign scenarios. Our code is\navailable at https://anonymous.4open.science/r/CTRAP.", "published": "2025-05-22 11:47:08", "link": "http://arxiv.org/abs/2505.16559v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains", "abstract": "Large Language Models (LLMs) achieve superior performance through\nChain-of-Thought (CoT) reasoning, but these token-level reasoning chains are\ncomputationally expensive and inefficient. In this paper, we introduce\nCompressed Latent Reasoning (CoLaR), a novel framework that dynamically\ncompresses reasoning processes in latent space through a two-stage training\napproach. First, during supervised fine-tuning, CoLaR extends beyond next-token\nprediction by incorporating an auxiliary next compressed embedding prediction\nobjective. This process merges embeddings of consecutive tokens using a\ncompression factor randomly sampled from a predefined range, and trains a\nspecialized latent head to predict distributions of subsequent compressed\nembeddings. Second, we enhance CoLaR through reinforcement learning (RL) that\nleverages the latent head's non-deterministic nature to explore diverse\nreasoning paths and exploit more compact ones. This approach enables CoLaR to:\ni) perform reasoning at a dense latent level (i.e., silently), substantially\nreducing reasoning chain length, and ii) dynamically adjust reasoning speed at\ninference time by simply prompting the desired compression factor. Extensive\nexperiments across four mathematical reasoning datasets demonstrate that CoLaR\nachieves 14.1% higher accuracy than latent-based baseline methods at comparable\ncompression ratios, and reduces reasoning chain length by 53.3% with only 4.8%\nperformance degradation compared to explicit CoT method. Moreover, when applied\nto more challenging mathematical reasoning tasks, our RL-enhanced CoLaR\ndemonstrates performance gains of up to 5.4% while dramatically reducing latent\nreasoning chain length by 82.8%. The code and models will be released upon\nacceptance.", "published": "2025-05-22 11:40:26", "link": "http://arxiv.org/abs/2505.16552v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mechanistic Understanding and Mitigation of Language Confusion in English-Centric Large Language Models", "abstract": "Language confusion -- where large language models (LLMs) generate unintended\nlanguages against the user's need -- remains a critical challenge, especially\nfor English-centric models. We present the first mechanistic interpretability\n(MI) study of language confusion, combining behavioral benchmarking with\nneuron-level analysis. Using the Language Confusion Benchmark (LCB), we show\nthat confusion points (CPs) -- specific positions where language switches occur\n-- are central to this phenomenon. Through layer-wise analysis with TunedLens\nand targeted neuron attribution, we reveal that transition failures in the\nfinal layers drive confusion. We further demonstrate that editing a small set\nof critical neurons, identified via comparative analysis with\nmultilingual-tuned models, substantially mitigates confusion without harming\ngeneral competence or fluency. Our approach matches multilingual alignment in\nconfusion reduction for most languages and yields cleaner, higher-quality\noutputs. These findings provide new insights into the internal dynamics of LLMs\nand highlight neuron-level interventions as a promising direction for robust,\ninterpretable multilingual language modeling.", "published": "2025-05-22 11:29:17", "link": "http://arxiv.org/abs/2505.16538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection", "abstract": "Large language models (LLMs) are considered valuable Intellectual Properties\n(IP) for legitimate owners due to the enormous computational cost of training.\nIt is crucial to protect the IP of LLMs from malicious stealing or unauthorized\ndeployment. Despite existing efforts in watermarking and fingerprinting LLMs,\nthese methods either impact the text generation process or are limited in\nwhite-box access to the suspect model, making them impractical. Hence, we\npropose DuFFin, a novel $\\textbf{Du}$al-Level $\\textbf{Fin}$gerprinting\n$\\textbf{F}$ramework for black-box setting ownership verification. DuFFin\nextracts the trigger pattern and the knowledge-level fingerprints to identify\nthe source of a suspect model. We conduct experiments on a variety of models\ncollected from the open-source website, including four popular base models as\nprotected LLMs and their fine-tuning, quantization, and safety alignment\nversions, which are released by large companies, start-ups, and individual\nusers. Results show that our method can accurately verify the copyright of the\nbase protected LLM on their model variants, achieving the IP-ROC metric greater\nthan 0.95. Our code is available at\nhttps://github.com/yuliangyan0807/llm-fingerprint.", "published": "2025-05-22 11:16:46", "link": "http://arxiv.org/abs/2505.16530v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance", "abstract": "Small large language models (sLLMs) offer the advantage of being lightweight\nand efficient, which makes them suitable for resource-constrained environments.\nHowever, sLLMs often struggle to maintain topic consistency in task-oriented\ndialogue systems, which is critical for scenarios such as service chatbots.\nSpecifically, it is important to ensure that the model denies off-topic or\nmalicious inputs and adheres to its intended functionality so as to prevent\npotential misuse and uphold reliability. Towards this, existing activation\nengineering approaches have been proposed to manipulate internal activations\nduring inference. While these methods are effective in certain scenarios, our\npreliminary experiments reveal their limitations in ensuring topic adherence.\nTherefore, to address this, we propose a novel approach termed Entropy-scaled\nSteering vectors for Topic Maintenance (EnSToM). EnSToM dynamically adjusts the\nsteering intensity based on input uncertainty, which allows the model to handle\noff-topic distractors effectively while preserving on-topic accuracy. Our\nexperiments demonstrate that EnSToM achieves significant performance gain with\na relatively small data size compared to fine-tuning approaches. By improving\ntopic adherence without compromising efficiency, our approach provides a robust\nsolution for enhancing sLLM-based dialogue systems.", "published": "2025-05-22 11:12:27", "link": "http://arxiv.org/abs/2505.16526v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing", "abstract": "Despite significant progress, recent studies have indicated that current\nlarge language models (LLMs) may still utilize bias during inference, leading\nto the poor generalizability of LLMs. Some benchmarks are proposed to\ninvestigate the generalizability of LLMs, with each piece of data typically\ncontaining one type of controlled bias. However, a single piece of data may\ncontain multiple types of biases in practical applications. To bridge this gap,\nwe propose a multi-bias benchmark where each piece of data contains five types\nof biases. The evaluations conducted on this benchmark reveal that the\nperformance of existing LLMs and debiasing methods is unsatisfying,\nhighlighting the challenge of eliminating multiple types of biases\nsimultaneously. To overcome this challenge, we propose a causal effect\nestimation-guided multi-bias elimination method (CMBE). This method first\nestimates the causal effect of multiple types of biases simultaneously.\nSubsequently, we eliminate the causal effect of biases from the total causal\neffect exerted by both the semantic information and biases during inference.\nExperimental results show that CMBE can effectively eliminate multiple types of\nbias simultaneously to enhance the generalizability of LLMs.", "published": "2025-05-22 11:04:09", "link": "http://arxiv.org/abs/2505.16522v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs", "abstract": "Factual hallucinations are a major challenge for Large Language Models\n(LLMs). They undermine reliability and user trust by generating inaccurate or\nfabricated content. Recent studies suggest that when generating false\nstatements, the internal states of LLMs encode information about truthfulness.\nHowever, these studies often rely on synthetic datasets that lack realism,\nwhich limits generalization when evaluating the factual accuracy of text\ngenerated by the model itself. In this paper, we challenge the findings of\nprevious work by investigating truthfulness encoding capabilities, leading to\nthe generation of a more realistic and challenging dataset. Specifically, we\nextend previous work by introducing: (1) a strategy for sampling plausible\ntrue-false factoid sentences from tabular data and (2) a procedure for\ngenerating realistic, LLM-dependent true-false datasets from Question Answering\ncollections. Our analysis of two open-source LLMs reveals that while the\nfindings from previous studies are partially validated, generalization to\nLLM-generated datasets remains challenging. This study lays the groundwork for\nfuture research on factuality in LLMs and offers practical guidelines for more\neffective evaluation.", "published": "2025-05-22 11:00:53", "link": "http://arxiv.org/abs/2505.16520v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CUB: Benchmarking Context Utilisation Techniques for Language Models", "abstract": "Incorporating external knowledge is crucial for knowledge-intensive tasks,\nsuch as question answering and fact checking. However, language models (LMs)\nmay ignore relevant information that contradicts outdated parametric memory or\nbe distracted by irrelevant contexts. While many context utilisation\nmanipulation techniques (CMTs) that encourage or suppress context utilisation\nhave recently been proposed to alleviate these issues, few have seen systematic\ncomparison. In this paper, we develop CUB (Context Utilisation Benchmark) to\nhelp practitioners within retrieval-augmented generation (RAG) identify the\nbest CMT for their needs. CUB allows for rigorous testing on three distinct\ncontext types, observed to capture key challenges in realistic context\nutilisation scenarios. With this benchmark, we evaluate seven state-of-the-art\nmethods, representative of the main categories of CMTs, across three diverse\ndatasets and tasks, applied to nine LMs. Our results show that most of the\nexisting CMTs struggle to handle the full set of types of contexts that may be\nencountered in real-world retrieval-augmented scenarios. Moreover, we find that\nmany CMTs display an inflated performance on simple synthesised datasets,\ncompared to more realistic datasets with naturally occurring samples.\nAltogether, our results show the need for holistic tests of CMTs and the\ndevelopment of CMTs that can handle multiple context types.", "published": "2025-05-22 10:57:08", "link": "http://arxiv.org/abs/2505.16518v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AppealCase: A Dataset and Benchmark for Civil Case Appeal Scenarios", "abstract": "Recent advances in LegalAI have primarily focused on individual case judgment\nanalysis, often overlooking the critical appellate process within the judicial\nsystem. Appeals serve as a core mechanism for error correction and ensuring\nfair trials, making them highly significant both in practice and in research.\nTo address this gap, we present the AppealCase dataset, consisting of 10,000\npairs of real-world, matched first-instance and second-instance documents\nacross 91 categories of civil cases. The dataset also includes detailed\nannotations along five dimensions central to appellate review: judgment\nreversals, reversal reasons, cited legal provisions, claim-level decisions, and\nwhether there is new information in the second instance. Based on these\nannotations, we propose five novel LegalAI tasks and conduct a comprehensive\nevaluation across 20 mainstream models. Experimental results reveal that all\ncurrent models achieve less than 50% F1 scores on the judgment reversal\nprediction task, highlighting the complexity and challenge of the appeal\nscenario. We hope that the AppealCase dataset will spur further research in\nLegalAI for appellate case analysis and contribute to improving consistency in\njudicial decision-making.", "published": "2025-05-22 10:50:33", "link": "http://arxiv.org/abs/2505.16514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Activation Editing for Reliable Instruction Following in Narratives", "abstract": "Complex narrative contexts often challenge language models' ability to follow\ninstructions, and existing benchmarks fail to capture these difficulties. To\naddress this, we propose Concise-SAE, a training-free framework that improves\ninstruction following by identifying and editing instruction-relevant neurons\nusing only natural language instructions, without requiring labelled data. To\nthoroughly evaluate our method, we introduce FreeInstruct, a diverse and\nrealistic benchmark of 1,212 examples that highlights the challenges of\ninstruction following in narrative-rich settings. While initially motivated by\ncomplex narratives, Concise-SAE demonstrates state-of-the-art instruction\nadherence across varied tasks without compromising generation quality.", "published": "2025-05-22 10:41:35", "link": "http://arxiv.org/abs/2505.16505v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing", "abstract": "Large Language Models (LLMs) have rapidly become central to NLP,\ndemonstrating their ability to adapt to various tasks through prompting\ntechniques, including sentiment analysis. However, we still have a limited\nunderstanding of how these models capture sentiment-related information. This\nstudy probes the hidden layers of Llama models to pinpoint where sentiment\nfeatures are most represented and to assess how this affects sentiment\nanalysis.\n  Using probe classifiers, we analyze sentiment encoding across layers and\nscales, identifying the layers and pooling methods that best capture sentiment\nsignals. Our results show that sentiment information is most concentrated in\nmid-layers for binary polarity tasks, with detection accuracy increasing up to\n14% over prompting techniques. Additionally, we find that in decoder-only\nmodels, the last token is not consistently the most informative for sentiment\nencoding. Finally, this approach enables sentiment tasks to be performed with\nmemory requirements reduced by an average of 57%.\n  These insights contribute to a broader understanding of sentiment in LLMs,\nsuggesting layer-specific probing as an effective approach for sentiment tasks\nbeyond prompting, with potential to enhance model utility and reduce memory\nrequirements.", "published": "2025-05-22 10:22:39", "link": "http://arxiv.org/abs/2505.16491v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning", "abstract": "Teaching large language models (LLMs) to be faithful in the provided context\nis crucial for building reliable information-seeking systems. Therefore, we\npropose a systematic framework, CANOE, to improve the faithfulness of LLMs in\nboth short-form and long-form generation tasks without human annotations.\nSpecifically, we first synthesize short-form question-answering (QA) data with\nfour diverse tasks to construct high-quality and easily verifiable training\ndata without human annotation. Also, we propose Dual-GRPO, a rule-based\nreinforcement learning method that includes three tailored rule-based rewards\nderived from synthesized short-form QA data, while simultaneously optimizing\nboth short-form and long-form response generation. Notably, Dual-GRPO\neliminates the need to manually label preference data to train reward models\nand avoids over-optimizing short-form generation when relying only on the\nsynthesized short-form QA data. Experimental results show that CANOE greatly\nimproves the faithfulness of LLMs across 11 different downstream tasks, even\noutperforming the most advanced LLMs, e.g., GPT-4o and OpenAI o1.", "published": "2025-05-22 10:10:07", "link": "http://arxiv.org/abs/2505.16483v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering", "abstract": "Document Visual Question Answering (DocVQA) faces dual challenges in\nprocessing lengthy multimodal documents (text, images, tables) and performing\ncross-modal reasoning. Current document retrieval-augmented generation (DocRAG)\nmethods remain limited by their text-centric approaches, frequently missing\ncritical visual information. The field also lacks robust benchmarks for\nassessing multimodal evidence selection and integration. We introduce MMDocRAG,\na comprehensive benchmark featuring 4,055 expert-annotated QA pairs with\nmulti-page, cross-modal evidence chains. Our framework introduces innovative\nmetrics for evaluating multimodal quote selection and enables answers that\ninterleave text with relevant visual elements. Through large-scale experiments\nwith 60 VLM/LLM models and 14 retrieval systems, we identify persistent\nchallenges in multimodal evidence retrieval, selection, and integration.Key\nfindings reveal advanced proprietary LVMs show superior performance than\nopen-sourced alternatives. Also, they show moderate advantages using multimodal\ninputs over text-only inputs, while open-source alternatives show significant\nperformance degradation. Notably, fine-tuned LLMs achieve substantial\nimprovements when using detailed image descriptions. MMDocRAG establishes a\nrigorous testing ground and provides actionable insights for developing more\nrobust multimodal DocVQA systems. Our benchmark and code are available at\nhttps://mmdocrag.github.io/MMDocRAG/.", "published": "2025-05-22 09:52:57", "link": "http://arxiv.org/abs/2505.16470v1", "categories": ["cs.IR", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization", "abstract": "Generative Large Language Models (LLMs) infer user's demographic information\nfrom subtle cues in the conversation -- a phenomenon called implicit\npersonalization. Prior work has shown that such inferences can lead to lower\nquality responses for users assumed to be from minority groups, even when no\ndemographic information is explicitly provided. In this work, we systematically\nexplore how LLMs respond to stereotypical cues using controlled synthetic\nconversations, by analyzing the models' latent user representations through\nboth model internals and generated answers to targeted user questions. Our\nfindings reveal that LLMs do infer demographic attributes based on these\nstereotypical signals, which for a number of groups even persists when the user\nexplicitly identifies with a different demographic group. Finally, we show that\nthis form of stereotype-driven implicit personalization can be effectively\nmitigated by intervening on the model's internal representations using a\ntrained linear probe to steer them toward the explicitly stated identity. Our\nresults highlight the need for greater transparency and control in how LLMs\nrepresent user identity.", "published": "2025-05-22 09:48:51", "link": "http://arxiv.org/abs/2505.16467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "University of Indonesia at SemEval-2025 Task 11: Evaluating State-of-the-Art Encoders for Multi-Label Emotion Detection", "abstract": "This paper presents our approach for SemEval 2025 Task 11 Track A, focusing\non multilabel emotion classification across 28 languages. We explore two main\nstrategies: fully fine-tuning transformer models and classifier-only training,\nevaluating different settings such as fine-tuning strategies, model\narchitectures, loss functions, encoders, and classifiers. Our findings suggest\nthat training a classifier on top of prompt-based encoders such as mE5 and BGE\nyields significantly better results than fully fine-tuning XLMR and mBERT. Our\nbest-performing model on the final leaderboard is an ensemble combining\nmultiple BGE models, where CatBoost serves as the classifier, with different\nconfigurations. This ensemble achieves an average F1-macro score of 56.58\nacross all languages.", "published": "2025-05-22 09:42:11", "link": "http://arxiv.org/abs/2505.16460v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems", "abstract": "Evaluating and iterating upon recommender systems is crucial, yet traditional\nA/B testing is resource-intensive, and offline methods struggle with dynamic\nuser-platform interactions. While agent-based simulation is promising, existing\nplatforms often lack a mechanism for user actions to dynamically reshape the\nenvironment. To bridge this gap, we introduce RecInter, a novel agent-based\nsimulation platform for recommender systems featuring a robust interaction\nmechanism. In RecInter platform, simulated user actions (e.g., likes, reviews,\npurchases) dynamically update item attributes in real-time, and introduced\nMerchant Agents can reply, fostering a more realistic and evolving ecosystem.\nHigh-fidelity simulation is ensured through Multidimensional User Profiling\nmodule, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought\n(CoT) enriched interaction data. Our platform achieves significantly improved\nsimulation credibility and successfully replicates emergent phenomena like\nBrand Loyalty and the Matthew Effect. Experiments demonstrate that this\ninteraction mechanism is pivotal for simulating realistic system evolution,\nestablishing our platform as a credible testbed for recommender systems\nresearch.", "published": "2025-05-22 09:14:23", "link": "http://arxiv.org/abs/2505.16429v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "$I^2G$: Generating Instructional Illustrations via Text-Conditioned Diffusion", "abstract": "The effective communication of procedural knowledge remains a significant\nchallenge in natural language processing (NLP), as purely textual instructions\noften fail to convey complex physical actions and spatial relationships. We\naddress this limitation by proposing a language-driven framework that\ntranslates procedural text into coherent visual instructions. Our approach\nmodels the linguistic structure of instructional content by decomposing it into\ngoal statements and sequential steps, then conditioning visual generation on\nthese linguistic elements. We introduce three key innovations: (1) a\nconstituency parser-based text encoding mechanism that preserves semantic\ncompleteness even with lengthy instructions, (2) a pairwise discourse coherence\nmodel that maintains consistency across instruction sequences, and (3) a novel\nevaluation protocol specifically designed for procedural language-to-image\nalignment. Our experiments across three instructional datasets (HTStep,\nCaptainCook4D, and WikiAll) demonstrate that our method significantly\noutperforms existing baselines in generating visuals that accurately reflect\nthe linguistic content and sequential nature of instructions. This work\ncontributes to the growing body of research on grounding procedural language in\nvisual content, with applications spanning education, task guidance, and\nmultimodal language understanding.", "published": "2025-05-22 09:10:09", "link": "http://arxiv.org/abs/2505.16425v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WebAgent-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning", "abstract": "While reinforcement learning (RL) has demonstrated remarkable success in\nenhancing large language models (LLMs), it has primarily focused on single-turn\ntasks such as solving math problems. Training effective web agents for\nmulti-turn interactions remains challenging due to the complexity of\nlong-horizon decision-making across dynamic web interfaces. In this work, we\npresent WebAgent-R1, a simple yet effective end-to-end multi-turn RL framework\nfor training web agents. It learns directly from online interactions with web\nenvironments by asynchronously generating diverse trajectories, entirely guided\nby binary rewards depending on task success. Experiments on the WebArena-Lite\nbenchmark demonstrate the effectiveness of WebAgent-R1, boosting the task\nsuccess rate of Qwen-2.5-3B from 6.1% to 33.9% and Llama-3.1-8B from 8.5% to\n44.8%, significantly outperforming existing state-of-the-art methods and strong\nproprietary models such as OpenAI o3. In-depth analyses reveal the\neffectiveness of the thinking-based prompting strategy and test-time scaling\nthrough increased interactions for web tasks. We further investigate different\nRL initialization policies by introducing two variants, namely WebAgent-R1-Zero\nand WebAgent-R1-CoT, which highlight the importance of the warm-up training\nstage (i.e., behavior cloning) and provide insights on incorporating long\nchain-of-thought (CoT) reasoning in web agents.", "published": "2025-05-22 09:07:43", "link": "http://arxiv.org/abs/2505.16421v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring the Relationship Between Diversity and Quality in Ad Text Generation", "abstract": "In natural language generation for advertising, creating diverse and engaging\nad texts is crucial for capturing a broad audience and avoiding advertising\nfatigue. Regardless of the importance of diversity, the impact of the\ndiversity-enhancing methods in ad text generation -- mainly tested on tasks\nsuch as summarization and machine translation -- has not been thoroughly\nexplored. Ad text generation significantly differs from these tasks owing to\nthe text style and requirements. This research explores the relationship\nbetween diversity and ad quality in ad text generation by considering multiple\nfactors, such as diversity-enhancing methods, their hyperparameters,\ninput-output formats, and the models.", "published": "2025-05-22 09:05:44", "link": "http://arxiv.org/abs/2505.16418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) leverages large language models (LLMs)\ncombined with external contexts to enhance the accuracy and reliability of\ngenerated responses. However, reliably attributing generated content to\nspecific context segments, context attribution, remains challenging due to the\ncomputationally intensive nature of current methods, which often require\nextensive fine-tuning or human annotation. In this work, we introduce a novel\nJensen-Shannon Divergence driven method to Attribute Response to Context\n(ARC-JSD), enabling efficient and accurate identification of essential context\nsentences without additional fine-tuning or surrogate modelling. Evaluations on\na wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using\ninstruction-tuned LLMs in different scales demonstrate superior accuracy and\nsignificant computational efficiency improvements compared to the previous\nsurrogate-based method. Furthermore, our mechanistic analysis reveals specific\nattention heads and multilayer perceptron (MLP) layers responsible for context\nattribution, providing valuable insights into the internal workings of RAG\nmodels.", "published": "2025-05-22 09:04:03", "link": "http://arxiv.org/abs/2505.16415v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning", "abstract": "Recently, large language models (LLMs) have shown remarkable reasoning\ncapabilities via large-scale reinforcement learning (RL). However, leveraging\nthe RL algorithm to empower effective multi-tool collaborative reasoning in\nLLMs remains an open challenge. In this paper, we introduce Tool-Star, an\nRL-based framework designed to empower LLMs to autonomously invoke multiple\nexternal tools during stepwise reasoning. Tool-Star integrates six types of\ntools and incorporates systematic designs in both data synthesis and training.\nTo address the scarcity of tool-use data, we propose a general tool-integrated\nreasoning data synthesis pipeline, which combines tool-integrated prompting\nwith hint-based sampling to automatically and scalably generate tool-use\ntrajectories. A subsequent quality normalization and difficulty-aware\nclassification process filters out low-quality samples and organizes the\ndataset from easy to hard. Furthermore, we propose a two-stage training\nframework to enhance multi-tool collaborative reasoning by: (1) cold-start\nfine-tuning, which guides LLMs to explore reasoning patterns via\ntool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with\nhierarchical reward design, which reinforces reward understanding and promotes\neffective tool collaboration. Experimental analyses on over 10 challenging\nreasoning benchmarks highlight the effectiveness and efficiency of Tool-Star.\nThe code is available at https://github.com/dongguanting/Tool-Star.", "published": "2025-05-22 09:00:19", "link": "http://arxiv.org/abs/2505.16410v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Surveys to Narratives: Rethinking Cultural Value Adaptation in LLMs", "abstract": "Adapting cultural values in Large Language Models (LLMs) presents significant\nchallenges, particularly due to biases and limited training data. Prior work\nprimarily aligns LLMs with different cultural values using World Values Survey\n(WVS) data. However, it remains unclear whether this approach effectively\ncaptures cultural nuances or produces distinct cultural representations for\nvarious downstream tasks. In this paper, we systematically investigate\nWVS-based training for cultural value adaptation and find that relying solely\non survey data can homogenize cultural norms and interfere with factual\nknowledge. To investigate these issues, we augment WVS with encyclopedic and\nscenario-based cultural narratives from Wikipedia and NormAd. While these\nnarratives may have variable effects on downstream tasks, they consistently\nimprove cultural distinctiveness than survey data alone. Our work highlights\nthe inherent complexity of aligning cultural values with the goal of guiding\ntask-specific behavior.", "published": "2025-05-22 09:00:01", "link": "http://arxiv.org/abs/2505.16408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the reliability of feature attribution methods for speech classification", "abstract": "As the capabilities of large-scale pre-trained models evolve, understanding\nthe determinants of their outputs becomes more important. Feature attribution\naims to reveal which parts of the input elements contribute the most to model\noutputs. In speech processing, the unique characteristics of the input signal\nmake the application of feature attribution methods challenging. We study how\nfactors such as input type and aggregation and perturbation timespan impact the\nreliability of standard feature attribution methods, and how these factors\ninteract with characteristics of each classification task. We find that\nstandard approaches to feature attribution are generally unreliable when\napplied to the speech domain, with the exception of word-aligned perturbation\nmethods when applied to word-based classification tasks.", "published": "2025-05-22 08:59:25", "link": "http://arxiv.org/abs/2505.16406v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning", "abstract": "Despite recent progress in large-scale reinforcement learning (RL) for\nreasoning, the training recipe for building high-performing reasoning models\nremains elusive. Key implementation details of frontier models, such as\nDeepSeek-R1, including data curation strategies and RL training recipe, are\noften omitted. Moreover, recent research indicates distillation remains more\neffective than RL for smaller models. In this work, we demonstrate that\nlarge-scale RL can significantly enhance the reasoning capabilities of strong,\nsmall- and mid-sized models, achieving results that surpass those of\nstate-of-the-art distillation-based models. We systematically study the RL\ntraining process through extensive ablations and propose a simple yet effective\napproach: first training on math-only prompts, then on code-only prompts.\nNotably, we find that math-only RL not only significantly enhances the\nperformance of strong distilled models on math benchmarks (e.g., +14.6% /\n+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks\n(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,\nextended code-only RL iterations further improve performance on code benchmarks\nwith minimal or no degradation in math results. We develop a robust data\ncuration pipeline to collect challenging prompts with high-quality, verifiable\nanswers and test cases to enable verification-based RL across both domains.\nFinally, we identify key experimental insights, including curriculum learning\nwith progressively increasing response lengths and the stabilizing effect of\non-policy parameter updates. We find that RL not only elicits the foundational\nreasoning capabilities acquired during pretraining and supervised fine-tuning\n(e.g., distillation), but also pushes the limits of the model's reasoning\nability, enabling it to solve problems that were previously unsolvable.", "published": "2025-05-22 08:50:47", "link": "http://arxiv.org/abs/2505.16400v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection", "abstract": "The general public often encounters complex texts but does not have the time\nor expertise to fully understand them, leading to the spread of misinformation.\nAutomatic Text Simplification (ATS) helps make information more accessible, but\nits evaluation methods have not kept up with advances in text generation,\nespecially with Large Language Models (LLMs). In particular, recent studies\nhave shown that current ATS metrics do not correlate with the presence of\nerrors. Manual inspections have further revealed a variety of errors,\nunderscoring the need for a more nuanced evaluation framework, which is\ncurrently lacking. This resource paper addresses this gap by introducing a test\ncollection for detecting and classifying errors in simplified texts. First, we\npropose a taxonomy of errors, with a formal focus on information distortion.\nNext, we introduce a parallel dataset of automatically simplified scientific\ntexts. This dataset has been human-annotated with labels based on our proposed\ntaxonomy. Finally, we analyze the quality of the dataset, and we study the\nperformance of existing models to detect and classify errors from that\ntaxonomy. These contributions give researchers the tools to better evaluate\nerrors in ATS, develop more reliable models, and ultimately improve the quality\nof automatically simplified texts.", "published": "2025-05-22 08:45:14", "link": "http://arxiv.org/abs/2505.16392v1", "categories": ["cs.CL", "cs.AI", "I.2.6; I.5.2"], "primary_category": "cs.CL"}
{"title": "Semantic Pivots Enable Cross-Lingual Transfer in Large Language Models", "abstract": "Large language models (LLMs) demonstrate remarkable ability in cross-lingual\ntasks. Understanding how LLMs acquire this ability is crucial for their\ninterpretability. To quantify the cross-lingual ability of LLMs accurately, we\npropose a Word-Level Cross-Lingual Translation Task. To find how LLMs learn\ncross-lingual ability, we trace the outputs of LLMs' intermediate layers in the\nword translation task. We identify and distinguish two distinct behaviors in\nthe forward pass of LLMs: co-occurrence behavior and semantic pivot behavior.\nWe attribute LLMs' two distinct behaviors to the co-occurrence frequency of\nwords and find the semantic pivot from the pre-training dataset. Finally, to\napply our findings to improve the cross-lingual ability of LLMs, we reconstruct\na semantic pivot-aware pre-training dataset using documents with a high\nproportion of semantic pivots. Our experiments validate the effectiveness of\nour approach in enhancing cross-lingual ability. Our research contributes\ninsights into the interpretability of LLMs and offers a method for improving\nLLMs' cross-lingual ability.", "published": "2025-05-22 08:37:04", "link": "http://arxiv.org/abs/2505.16385v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PaTH Attention: Position Encoding via Accumulating Householder Transformations", "abstract": "The attention mechanism is a core primitive in modern large language models\n(LLMs) and AI more broadly. Since attention by itself is permutation-invariant,\nposition encoding is essential for modeling structured domains such as\nlanguage. Rotary position encoding (RoPE) has emerged as the de facto standard\napproach for position encoding and is part of many modern LLMs. However, in\nRoPE the key/query transformation between two elements in a sequence is only a\nfunction of their relative position and otherwise independent of the actual\ninput. This limits the expressivity of RoPE-based transformers.\n  This paper describes PaTH, a flexible data-dependent position encoding scheme\nbased on accumulated products of Householder(like) transformations, where each\ntransformation is data-dependent, i.e., a function of the input. We derive an\nefficient parallel algorithm for training through exploiting a compact\nrepresentation of products of Householder matrices, and implement a\nFlashAttention-style blockwise algorithm that minimizes I/O cost. Across both\ntargeted synthetic benchmarks and moderate-scale real-world language modeling\nexperiments, we find that PaTH demonstrates superior performance compared to\nRoPE and other recent baselines.", "published": "2025-05-22 08:36:09", "link": "http://arxiv.org/abs/2505.16381v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization", "abstract": "The exponential growth of scientific publications has made it increasingly\ndifficult for researchers to stay updated and synthesize knowledge effectively.\nThis paper presents XSum, a modular pipeline for multi-document summarization\n(MDS) in the scientific domain using Retrieval-Augmented Generation (RAG). The\npipeline includes two core components: a question-generation module and an\neditor module. The question-generation module dynamically generates questions\nadapted to the input papers, ensuring the retrieval of relevant and accurate\ninformation. The editor module synthesizes the retrieved content into coherent\nand well-structured summaries that adhere to academic standards for proper\ncitation. Evaluated on the SurveySum dataset, XSum demonstrates strong\nperformance, achieving considerable improvements in metrics such as CheckEval,\nG-Eval and Ref-F1 compared to existing approaches. This work provides a\ntransparent, adaptable framework for scientific summarization with potential\napplications in a wide range of domains. Code available at\nhttps://github.com/webis-de/scolia25-xsum", "published": "2025-05-22 08:00:59", "link": "http://arxiv.org/abs/2505.16349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance", "abstract": "Embodied agents empowered by large language models (LLMs) have shown strong\nperformance in household object rearrangement tasks. However, these tasks\nprimarily focus on single-turn interactions with simplified instructions, which\ndo not truly reflect the challenges of providing meaningful assistance to\nusers. To provide personalized assistance, embodied agents must understand the\nunique semantics that users assign to the physical world (e.g., favorite cup,\nbreakfast routine) by leveraging prior interaction history to interpret\ndynamic, real-world instructions. Yet, the effectiveness of embodied agents in\nutilizing memory for personalized assistance remains largely underexplored. To\naddress this gap, we present MEMENTO, a personalized embodied agent evaluation\nframework designed to comprehensively assess memory utilization capabilities to\nprovide personalized assistance. Our framework consists of a two-stage memory\nevaluation process design that enables quantifying the impact of memory\nutilization on task performance. This process enables the evaluation of agents'\nunderstanding of personalized knowledge in object rearrangement tasks by\nfocusing on its role in goal interpretation: (1) the ability to identify target\nobjects based on personal meaning (object semantics), and (2) the ability to\ninfer object-location configurations from consistent user patterns, such as\nroutines (user patterns). Our experiments across various LLMs reveal\nsignificant limitations in memory utilization, with even frontier models like\nGPT-4o experiencing a 30.5% performance drop when required to reference\nmultiple memories, particularly in tasks involving user patterns. These\nfindings, along with our detailed analyses and case studies, provide valuable\ninsights for future research in developing more effective personalized embodied\nagents. Project website: https://connoriginal.github.io/MEMENTO", "published": "2025-05-22 08:00:10", "link": "http://arxiv.org/abs/2505.16348v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers", "abstract": "Novelty is a core component of academic papers, and there are multiple\nperspectives on the assessment of novelty. Existing methods often focus on word\nor entity combinations, which provide limited insights. The content related to\na paper's novelty is typically distributed across different core sections,\ne.g., Introduction, Methodology and Results. Therefore, exploring the optimal\ncombination of sections for evaluating the novelty of a paper is important for\nadvancing automated novelty assessment. In this paper, we utilize different\ncombinations of sections from academic papers as inputs to drive language\nmodels to predict novelty scores. We then analyze the results to determine the\noptimal section combinations for novelty score prediction. We first employ\nnatural language processing techniques to identify the sectional structure of\nacademic papers, categorizing them into introduction, methods, results, and\ndiscussion (IMRaD). Subsequently, we used different combinations of these\nsections (e.g., introduction and methods) as inputs for pretrained language\nmodels (PLMs) and large language models (LLMs), employing novelty scores\nprovided by human expert reviewers as ground truth labels to obtain prediction\nresults. The results indicate that using introduction, results and discussion\nis most appropriate for assessing the novelty of a paper, while the use of the\nentire text does not yield significant results. Furthermore, based on the\nresults of the PLMs and LLMs, the introduction and results appear to be the\nmost important section for the task of novelty score prediction. The code and\ndataset for this paper can be accessed at\nhttps://github.com/njust-winchy/SC4ANM.", "published": "2025-05-22 07:34:59", "link": "http://arxiv.org/abs/2505.16330v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework", "abstract": "Metaphorical comprehension in images remains a critical challenge for AI\nsystems, as existing models struggle to grasp the nuanced cultural, emotional,\nand contextual implications embedded in visual content. While multimodal large\nlanguage models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they\nstruggle with a fundamental limitation on image implication tasks: contextual\ngaps that obscure the relationships between different visual elements and their\nabstract meanings. Inspired by the human cognitive process, we propose Let\nAndroids Dream (LAD), a novel framework for image implication understanding and\nreasoning. LAD addresses contextual missing through the three-stage framework:\n(1) Perception: converting visual information into rich and multi-level textual\nrepresentations, (2) Search: iteratively searching and integrating cross-domain\nknowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment\nimage implication via explicit reasoning. Our framework with the lightweight\nGPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English\nimage implication benchmark and a huge improvement on Chinese benchmark,\nperforming comparable with the GPT-4o model on Multiple-Choice Question (MCQ)\nand outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work\nprovides new insights into how AI can more effectively interpret image\nimplications, advancing the field of vision-language reasoning and human-AI\ninteraction. Our project is publicly available at\nhttps://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.", "published": "2025-05-22 17:59:53", "link": "http://arxiv.org/abs/2505.17019v1", "categories": ["cs.CV", "cs.AI", "cs.CY"], "primary_category": "cs.CV"}
{"title": "Interactive Post-Training for Vision-Language-Action Models", "abstract": "We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based\ninteractive post-training paradigm that fine-tunes pretrained\nVision-Language-Action (VLA) models using only sparse binary success rewards.\nExisting VLA training pipelines rely heavily on offline expert demonstration\ndata and supervised imitation, limiting their ability to adapt to new tasks and\nenvironments under low-data regimes. RIPT-VLA addresses this by enabling\ninteractive post-training with a stable policy optimization algorithm based on\ndynamic rollout sampling and leave-one-out advantage estimation.\n  RIPT-VLA has the following characteristics. First, it applies to various VLA\nmodels, resulting in an improvement on the lightweight QueST model by 21.2%,\nand the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it\nis computationally efficient and data-efficient: with only one demonstration,\nRIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success\nrate within 15 iterations. Furthermore, we demonstrate that the policy learned\nby RIPT-VLA generalizes across different tasks and scenarios and is robust to\nthe initial state context. These results highlight RIPT-VLA as a practical and\neffective paradigm for post-training VLA models through minimal supervision.", "published": "2025-05-22 17:59:45", "link": "http://arxiv.org/abs/2505.17016v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "cs.LG"}
{"title": "SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding", "abstract": "Multimodal large language models (MLLMs) have achieved impressive success in\nquestion-answering tasks, yet their capabilities for spatial understanding are\nless explored. This work investigates a critical question: do existing MLLMs\npossess 3D spatial perception and understanding abilities? Concretely, we make\nthe following contributions in this paper: (i) we introduce VGBench, a\nbenchmark specifically designed to assess MLLMs for visual geometry perception,\ne.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most\ncomprehensive and diverse multimodal spatial understanding benchmark to date,\nintegrating VGBench with relevant data from the other 11 existing datasets.\nThis benchmark comprises 28K samples across various spatial understanding\ntasks, modalities, and QA formats, along with a carefully curated challenging\nsubset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent\nsystem incorporating 9 specialized tools for spatial understanding, supporting\nboth Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive\nevaluations to reveal persistent challenges in spatial reasoning while\ndemonstrating the effectiveness of SpatialAgent. We believe SpatialScore will\noffer valuable insights and serve as a rigorous benchmark for the next\nevolution of MLLMs.", "published": "2025-05-22 17:59:03", "link": "http://arxiv.org/abs/2505.17012v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning", "abstract": "Prompting is one of the main ways to adapt a pretrained model to target\ntasks. Besides manually constructing prompts, many prompt optimization methods\nhave been proposed in the literature. Method development is mainly empirically\ndriven, with less emphasis on a conceptual understanding of prompting. In this\npaper we discuss how optimal prompting can be understood through a Bayesian\nview, which also implies some fundamental limitations of prompting that can\nonly be overcome by tuning weights. The paper explains in detail how\nmeta-trained neural networks behave as Bayesian predictors over the pretraining\ndistribution, whose hallmark feature is rapid in-context adaptation. Optimal\nprompting can be studied formally as conditioning these Bayesian predictors,\nyielding criteria for target tasks where optimal prompting is and is not\npossible. We support the theory with educational experiments on LSTMs and\nTransformers, where we compare different versions of prefix-tuning and\ndifferent weight-tuning methods. We also confirm that soft prefixes, which are\nsequences of real-valued vectors outside the token alphabet, can lead to very\neffective prompts for trained and even untrained networks by manipulating\nactivations in ways that are not achievable by hard tokens. This adds an\nimportant mechanistic aspect beyond the conceptual Bayesian theory.", "published": "2025-05-22 17:58:53", "link": "http://arxiv.org/abs/2505.17010v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs", "abstract": "We propose a general framework for conditional sampling in PDE-based inverse\nproblems, targeting the recovery of whole solutions from extremely sparse or\nnoisy measurements. This is accomplished by a function-space diffusion model\nand plug-and-play guidance for conditioning. Our method first trains an\nunconditional discretization-agnostic denoising model using neural operator\narchitectures. At inference, we refine the samples to satisfy sparse\nobservation data via a gradient-based guidance mechanism. Through rigorous\nmathematical analysis, we extend Tweedie's formula to infinite-dimensional\nHilbert spaces, providing the theoretical foundation for our posterior sampling\napproach. Our method (FunDPS) accurately captures posterior distributions in\nfunction spaces under minimal supervision and severe data scarcity. Across five\nPDE tasks with only 3% observation, our method achieves an average 32% accuracy\nimprovement over state-of-the-art fixed-resolution diffusion baselines while\nreducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning\nensures strong cross-resolution generalizability. To the best of our knowledge,\nthis is the first diffusion-based framework to operate independently of\ndiscretization, offering a practical and flexible solution for forward and\ninverse problems in the context of PDEs. Code is available at\nhttps://github.com/neuraloperator/FunDPS", "published": "2025-05-22 17:58:12", "link": "http://arxiv.org/abs/2505.17004v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association", "abstract": "We study the task of learning association between faces and voices, which is\ngaining interest in the multimodal community lately. These methods suffer from\nthe deliberate crafting of negative mining procedures as well as the reliance\non the distant margin parameter. These issues are addressed by learning a joint\nembedding space in which orthogonality constraints are applied to the fused\nembeddings of faces and voices. However, embedding spaces of faces and voices\npossess different characteristics and require spaces to be aligned before\nfusing them. To this end, we propose a method that accurately aligns the\nembedding spaces and fuses them with an enhanced gated fusion thereby improving\nthe performance of face-voice association. Extensive experiments on the\nVoxCeleb dataset reveals the merits of the proposed approach.", "published": "2025-05-22 17:57:55", "link": "http://arxiv.org/abs/2505.17002v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation", "abstract": "Out-of-distribution (OOD) detection and segmentation are crucial for\ndeploying machine learning models in safety-critical applications such as\nautonomous driving and robot-assisted surgery. While prior research has\nprimarily focused on unimodal image data, real-world applications are\ninherently multimodal, requiring the integration of multiple modalities for\nimproved OOD detection. A key challenge is the lack of supervision signals from\nunknown data, leading to overconfident predictions on OOD samples. To address\nthis challenge, we propose Feature Mixing, an extremely simple and fast method\nfor multimodal outlier synthesis with theoretical support, which can be further\noptimized to help the model better distinguish between in-distribution (ID) and\nOOD data. Feature Mixing is modality-agnostic and applicable to various\nmodality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal\ndataset for OOD segmentation, featuring synthetic OOD objects across diverse\nscenes and weather conditions. Extensive experiments on SemanticKITTI,\nnuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that\nFeature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370\n\\times$ speedup. Our source code and dataset will be available at\nhttps://github.com/mona4399/FeatureMixing.", "published": "2025-05-22 17:54:30", "link": "http://arxiv.org/abs/2505.16985v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "abstract": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "published": "2025-05-22 17:52:59", "link": "http://arxiv.org/abs/2505.16982v1", "categories": ["cs.AI", "physics.med-ph"], "primary_category": "cs.AI"}
{"title": "Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design", "abstract": "Single-agent LLMs hit hard limits--finite context, role overload, and brittle\ndomain transfer. Conventional multi-agent fixes soften those edges yet expose\nfresh pains: ill-posed decompositions, fuzzy contracts, and verification\noverhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a\nframework that converts domain priors into an algorithmic blueprint hierarchy,\nin which tasks are recursively split into typed, controller-mediated subtasks,\neach solved zero-shot or with the lightest viable boost (e.g.,\nchain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch\ntheorem, KtR trades the chase for a universal prompt for disciplined\ndecomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents\nraise accuracy from 3% zero-shot to 95% on size-5 instances after patching a\nsingle bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a\nsix-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,\nversus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation\nthus turns modest models into reliable collaborators--no ever-larger monoliths\nrequired.", "published": "2025-05-22 17:52:33", "link": "http://arxiv.org/abs/2505.16979v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation", "abstract": "Grammar plays a critical role in natural language processing and text/code\ngeneration by enabling the definition of syntax, the creation of parsers, and\nguiding structured outputs. Although large language models (LLMs) demonstrate\nimpressive capabilities across domains, their ability to infer and generate\ngrammars has not yet been thoroughly explored. In this paper, we aim to study\nand improve the ability of LLMs for few-shot grammar generation, where grammars\nare inferred from sets of a small number of positive and negative examples and\ngenerated in Backus-Naur Form. To explore this, we introduced a novel dataset\ncomprising 540 structured grammar generation challenges, devised 6 metrics, and\nevaluated 8 various LLMs against it. Our findings reveal that existing LLMs\nperform sub-optimally in grammar generation. To address this, we propose an\nLLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar\ngeneration. HyGenar achieves substantial improvements in both the syntactic and\nsemantic correctness of generated grammars across LLMs.", "published": "2025-05-22 17:52:31", "link": "http://arxiv.org/abs/2505.16978v1", "categories": ["cs.AI", "cs.PL"], "primary_category": "cs.AI"}
{"title": "Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models", "abstract": "Large Language Models (LLMs) are increasingly equipped with capabilities of\nreal-time web search and integrated with protocols like Model Context Protocol\n(MCP). This extension could introduce new security vulnerabilities. We present\na systematic investigation of LLM vulnerabilities to hidden adversarial prompts\nthrough malicious font injection in external resources like webpages, where\nattackers manipulate code-to-glyph mapping to inject deceptive content which\nare invisible to users. We evaluate two critical attack scenarios: (1)\n\"malicious content relay\" and (2) \"sensitive data leakage\" through MCP-enabled\ntools. Our experiments reveal that indirect prompts with injected malicious\nfont can bypass LLM safety mechanisms through external resources, achieving\nvarying success rates based on data sensitivity and prompt design. Our research\nunderscores the urgent need for enhanced security measures in LLM deployments\nwhen processing external content.", "published": "2025-05-22 17:36:33", "link": "http://arxiv.org/abs/2505.16957v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning", "abstract": "Despite their impressive capabilities, Large Language Models struggle with\ngeneralisation beyond their training distribution, often exhibiting\nsophisticated pattern interpolation rather than true abstract reasoning\n(extrapolation). In this work, we approach this limitation through the lens of\nInformation Bottleneck (IB) theory, which posits that model generalisation\nemerges from an optimal balance between input compression and retention of\npredictive information in latent representations. We prove using IB theory that\ndecoder-only Transformers are inherently constrained in their ability to form\ntask-optimal sequence representations. We then use this result to demonstrate\nthat periodic global transformation of the internal sequence-level\nrepresentations (KV cache) is a necessary computational step for improving\nTransformer generalisation in reasoning tasks. Based on these theoretical\ninsights, we propose a modification to the Transformer architecture, in the\nform of an additional module that globally rewrites the KV cache at periodic\nintervals, shifting its capacity away from memorising input prefixes and toward\nencoding features most useful for predicting future tokens. Our model delivers\nsubstantial gains on mathematical reasoning benchmarks, outperforming both\nvanilla Transformers with up to 3.5x more parameters, as well as\nheuristic-driven pruning mechanisms for cache compression. Our approach can be\nseen as a principled generalisation of existing KV-cache compression methods;\nwhereas such methods focus solely on compressing input representations, they\noften do so at the expense of retaining predictive information, and thus their\ncapabilities are inherently bounded by those of an unconstrained model. This\nestablishes a principled framework to manipulate Transformer memory using\ninformation theory, addressing fundamental reasoning limitations that scaling\nalone cannot overcome.", "published": "2025-05-22 17:33:49", "link": "http://arxiv.org/abs/2505.16950v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs", "abstract": "Despite recent efforts in Large Language Models (LLMs) safety and alignment,\ncurrent adversarial attacks on frontier LLMs are still able to force harmful\ngenerations consistently. Although adversarial training has been widely studied\nand shown to significantly improve the robustness of traditional machine\nlearning models, its strengths and weaknesses in the context of LLMs are less\nunderstood. Specifically, while existing discrete adversarial attacks are\neffective at producing harmful content, training LLMs with concrete adversarial\nprompts is often computationally expensive, leading to reliance on continuous\nrelaxations. As these relaxations do not correspond to discrete input tokens,\nsuch latent training methods often leave models vulnerable to a diverse set of\ndiscrete attacks. In this work, we aim to bridge this gap by introducing MixAT,\na novel method that combines stronger discrete and faster continuous attacks\nduring training. We rigorously evaluate MixAT across a wide spectrum of\nstate-of-the-art attacks, proposing the At Least One Attack Success Rate\n(ALO-ASR) metric to capture the worst-case vulnerability of models. We show\nMixAT achieves substantially better robustness (ALO-ASR < 20%) compared to\nprior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to\nmethods based on continuous relaxations. We further analyze MixAT in realistic\ndeployment settings, exploring how chat templates, quantization, low-rank\nadapters, and temperature affect both adversarial training and evaluation,\nrevealing additional blind spots in current methodologies. Our results\ndemonstrate that MixAT's discrete-continuous defense offers a principled and\nsuperior robustness-accuracy tradeoff with minimal computational overhead,\nhighlighting its promise for building safer LLMs. We provide our code and\nmodels at https://github.com/insait-institute/MixAT.", "published": "2025-05-22 17:32:50", "link": "http://arxiv.org/abs/2505.16947v1", "categories": ["cs.LG", "cs.AI", "I.2.7; K.4.1"], "primary_category": "cs.LG"}
{"title": "FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records", "abstract": "Foundation models hold significant promise in healthcare, given their\ncapacity to extract meaningful representations independent of downstream tasks.\nThis property has enabled state-of-the-art performance across several clinical\napplications trained on structured electronic health record (EHR) data, even in\nsettings with limited labeled data, a prevalent challenge in healthcare.\nHowever, there is little consensus on these models' potential for clinical\nutility due to the lack of desiderata of comprehensive and meaningful tasks and\nsufficiently diverse evaluations to characterize the benefit over conventional\nsupervised learning. To address this gap, we propose a suite of clinically\nmeaningful tasks spanning patient outcomes, early prediction of acute and\nchronic conditions, including desiderata for robust evaluations. We evaluate\nstate-of-the-art foundation models on EHR data consisting of 5 million patients\nfrom Columbia University Irving Medical Center (CUMC), a large urban academic\nmedical center in New York City, across 14 clinically relevant tasks. We\nmeasure overall accuracy, calibration, and subpopulation performance to surface\ntradeoffs based on the choice of pre-training, tokenization, and data\nrepresentation strategies. Our study aims to advance the empirical evaluation\nof structured EHR foundation models and guide the development of future\nhealthcare foundation models.", "published": "2025-05-22 17:29:52", "link": "http://arxiv.org/abs/2505.16941v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning", "abstract": "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks\nthat advances long-context understanding in embodied AI. $\\infty$-THOR\nprovides: (1) a generation framework for synthesizing scalable, reproducible,\nand unlimited long-horizon trajectories; (2) a novel embodied QA task,\nNeedle(s) in the Embodied Haystack, where multiple scattered clues across\nextended trajectories test agents' long-context reasoning ability; and (3) a\nlong-horizon dataset and benchmark suite featuring complex tasks that span\nhundreds of environment steps, each paired with ground-truth action sequences.\nTo enable this capability, we explore architectural adaptations, including\ninterleaved Goal-State-Action modeling, context extension techniques, and\nContext Parallelism, to equip LLM-based agents for extreme long-context\nreasoning and interaction. Experimental results and analyses highlight the\nchallenges posed by our benchmark and provide insights into training strategies\nand model behaviors under long-horizon conditions. Our work provides a\nfoundation for the next generation of embodied AI systems capable of robust,\nlong-term reasoning and planning.", "published": "2025-05-22 17:20:38", "link": "http://arxiv.org/abs/2505.16928v1", "categories": ["cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?", "abstract": "While recent text-to-image (T2I) models show impressive capabilities in\nsynthesizing images from brief descriptions, their performance significantly\ndegrades when confronted with long, detail-intensive prompts required in\nprofessional applications. We present DetailMaster, the first comprehensive\nbenchmark specifically designed to evaluate T2I models' systematical abilities\nto handle extended textual inputs that contain complex compositional\nrequirements. Our benchmark introduces four critical evaluation dimensions:\nCharacter Attributes, Structured Character Locations, Multi-Dimensional Scene\nAttributes, and Explicit Spatial/Interactive Relationships. The benchmark\ncomprises long and detail-rich prompts averaging 284.89 tokens, with high\nquality validated by expert annotators. Evaluation on 7 general-purpose and 5\nlong-prompt-optimized T2I models reveals critical performance limitations:\nstate-of-the-art models achieve merely ~50% accuracy in key dimensions like\nattribute binding and spatial reasoning, while all models showing progressive\nperformance degradation as prompt length increases. Our analysis highlights\nsystemic failures in structural comprehension and detail overload handling,\nmotivating future research into architectures with enhanced compositional\nreasoning. We open-source the dataset, data curation code, and evaluation tools\nto advance detail-rich T2I generation and enable broad applications that would\notherwise be infeasible due to the lack of a dedicated benchmark.", "published": "2025-05-22 17:11:27", "link": "http://arxiv.org/abs/2505.16915v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation", "abstract": "We introduce a new paradigm for active sound modification: Active Speech\nEnhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on\nsuppressing external interference, ASE goes further by actively shaping the\nspeech signal -- both attenuating unwanted noise components and amplifying\nspeech-relevant frequencies -- to improve intelligibility and perceptual\nquality. To enable this, we propose a novel Transformer-Mamba-based\narchitecture, along with a task-specific loss function designed to jointly\noptimize interference suppression and signal enrichment. Our method outperforms\nexisting baselines across multiple speech processing tasks -- including\ndenoising, dereverberation, and declipping -- demonstrating the effectiveness\nof active, targeted modulation in challenging acoustic environments.", "published": "2025-05-22 17:10:18", "link": "http://arxiv.org/abs/2505.16911v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships", "abstract": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.", "published": "2025-05-22 16:58:48", "link": "http://arxiv.org/abs/2505.16899v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Structure-Aligned Protein Language Model", "abstract": "Protein language models (pLMs) pre-trained on vast protein sequence databases\nexcel at various downstream tasks but lack the structural knowledge essential\nfor many biological applications. To address this, we integrate structural\ninsights from pre-trained protein graph neural networks (pGNNs) into pLMs\nthrough a latent-level contrastive learning task. This task aligns residue\nrepresentations from pLMs with those from pGNNs across multiple proteins,\nenriching pLMs with inter-protein structural knowledge. Additionally, we\nincorporate a physical-level task that infuses intra-protein structural\nknowledge by optimizing pLMs to predict structural tokens. The proposed\ndual-task framework effectively incorporates both inter-protein and\nintra-protein structural knowledge into pLMs. Given the variability in the\nquality of protein structures in PDB, we further introduce a residue loss\nselection module, which uses a small model trained on high-quality structures\nto select reliable yet challenging residue losses for the pLM to learn.\nApplying our structure alignment method to the state-of-the-art ESM2 and\nAMPLIFY results in notable performance gains across a wide range of tasks,\nincluding a 12.7% increase in ESM2 contact prediction. The data, code, and\nresulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.", "published": "2025-05-22 16:56:12", "link": "http://arxiv.org/abs/2505.16896v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings", "abstract": "Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is\ncrucial for ensuring the reliability of downstream applications. A recent work\napplies conformal prediction to KGE methods, providing uncertainty estimates by\ngenerating a set of answers that is guaranteed to include the true answer with\na predefined confidence level. However, existing methods provide probabilistic\nguarantees averaged over a reference set of queries and answers (marginal\ncoverage guarantee). In high-stakes applications such as medical diagnosis, a\nstronger guarantee is often required: the predicted sets must provide\nconsistent coverage per query (conditional coverage guarantee). We propose\nCondKGCP, a novel method that approximates predicate-conditional coverage\nguarantees while maintaining compact prediction sets. CondKGCP merges\npredicates with similar vector representations and augments calibration with\nrank information. We prove the theoretical guarantees and demonstrate empirical\neffectiveness of CondKGCP by comprehensive evaluations.", "published": "2025-05-22 16:33:20", "link": "http://arxiv.org/abs/2505.16877v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "T2I-ConBench: Text-to-Image Benchmark for Continual Post-training", "abstract": "Continual post-training adapts a single text-to-image diffusion model to\nlearn new tasks without incurring the cost of separate models, but naive\npost-training causes forgetting of pretrained knowledge and undermines\nzero-shot compositionality. We observe that the absence of a standardized\nevaluation protocol hampers related research for continual post-training. To\naddress this, we introduce T2I-ConBench, a unified benchmark for continual\npost-training of text-to-image models. T2I-ConBench focuses on two practical\nscenarios, item customization and domain enhancement, and analyzes four\ndimensions: (1) retention of generality, (2) target-task performance, (3)\ncatastrophic forgetting, and (4) cross-task generalization. It combines\nautomated metrics, human-preference modeling, and vision-language QA for\ncomprehensive assessment. We benchmark ten representative methods across three\nrealistic task sequences and find that no approach excels on all fronts. Even\njoint \"oracle\" training does not succeed for every task, and cross-task\ngeneralization remains unsolved. We release all datasets, code, and evaluation\ntools to accelerate research in continual post-training for text-to-image\nmodels.", "published": "2025-05-22 16:31:43", "link": "http://arxiv.org/abs/2505.16875v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "GCAL: Adapting Graph Models to Evolving Domain Shifts", "abstract": "This paper addresses the challenge of graph domain adaptation on evolving,\nmultiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation\nmethods are confined to single-step adaptation, making them ineffective in\nhandling continuous domain shifts and prone to catastrophic forgetting. This\npaper introduces the Graph Continual Adaptive Learning (GCAL) method, designed\nto enhance model sustainability and adaptability across various graph domains.\nGCAL employs a bilevel optimization strategy. The \"adapt\" phase uses an\ninformation maximization approach to fine-tune the model with new graph domains\nwhile re-adapting past memories to mitigate forgetting. Concurrently, the\n\"generate memory\" phase, guided by a theoretical lower bound derived from\ninformation bottleneck theory, involves a variational memory graph generation\nmodule to condense original graphs into memories. Extensive experimental\nevaluations demonstrate that GCAL substantially outperforms existing methods in\nterms of adaptability and knowledge retention.", "published": "2025-05-22 16:19:19", "link": "http://arxiv.org/abs/2505.16860v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only", "abstract": "Improving the performance of pre-trained policies through online\nreinforcement learning (RL) is a critical yet challenging topic. Existing\nonline RL fine-tuning methods require continued training with offline\npretrained Q-functions for stability and performance. However, these offline\npretrained Q-functions commonly underestimate state-action pairs beyond the\noffline dataset due to the conservatism in most offline RL methods, which\nhinders further exploration when transitioning from the offline to the online\nsetting. Additionally, this requirement limits their applicability in scenarios\nwhere only pre-trained policies are available but pre-trained Q-functions are\nabsent, such as in imitation learning (IL) pre-training. To address these\nchallenges, we propose a method for efficient online RL fine-tuning using\nsolely the offline pre-trained policy, eliminating reliance on pre-trained\nQ-functions. We introduce PORL (Policy-Only Reinforcement Learning\nFine-Tuning), which rapidly initializes the Q-function from scratch during the\nonline phase to avoid detrimental pessimism. Our method not only achieves\ncompetitive performance with advanced offline-to-online RL algorithms and\nonline RL approaches that leverage data or policies prior, but also pioneers a\nnew path for directly fine-tuning behavior cloning (BC) policies.", "published": "2025-05-22 16:14:08", "link": "http://arxiv.org/abs/2505.16856v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models", "abstract": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.", "published": "2025-05-22 16:13:29", "link": "http://arxiv.org/abs/2505.16854v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Unlocking Temporal Flexibility: Neural Speech Codec with Variable Frame Rate", "abstract": "Most neural speech codecs achieve bitrate adjustment through intra-frame\nmechanisms, such as codebook dropout, at a Constant Frame Rate (CFR). However,\nspeech segments inherently have time-varying information density (e.g., silent\nintervals versus voiced regions). This property makes CFR not optimal in terms\nof bitrate and token sequence length, hindering efficiency in real-time\napplications. In this work, we propose a Temporally Flexible Coding (TFC)\ntechnique, introducing variable frame rate (VFR) into neural speech codecs for\nthe first time. TFC enables seamlessly tunable average frame rates and\ndynamically allocates frame rates based on temporal entropy. Experimental\nresults show that a codec with TFC achieves optimal reconstruction quality with\nhigh flexibility, and maintains competitive performance even at lower frame\nrates. Our approach is promising for the integration with other efforts to\ndevelop low-frame-rate neural speech codecs for more efficient downstream\ntasks.", "published": "2025-05-22 16:10:01", "link": "http://arxiv.org/abs/2505.16845v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning", "abstract": "The rapid spread of multimodal misinformation on social media has raised\ngrowing concerns, while research on video misinformation detection remains\nlimited due to the lack of large-scale, diverse datasets. Existing methods\noften overfit to rigid templates and lack deep reasoning over deceptive\ncontent. To address these challenges, we introduce FakeVV, a large-scale\nbenchmark comprising over 100,000 video-text pairs with fine-grained,\ninterpretable annotations. In addition, we further propose Fact-R1, a novel\nframework that integrates deep reasoning with collaborative rule-based\nreinforcement learning. Fact-R1 is trained through a three-stage process: (1)\nmisinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference\nalignment via Direct Preference Optimization (DPO), and (3) Group Relative\nPolicy Optimization (GRPO) using a novel verifiable reward function. This\nenables Fact-R1 to exhibit emergent reasoning behaviors comparable to those\nobserved in advanced text-based reinforcement learning systems, but in the more\ncomplex multimodal misinformation setting. Our work establishes a new paradigm\nfor misinformation detection, bridging large-scale video understanding,\nreasoning-guided alignment, and interpretable verification.", "published": "2025-05-22 16:05:06", "link": "http://arxiv.org/abs/2505.16836v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent", "abstract": "GUI automation faces critical challenges in dynamic environments. MLLMs\nsuffer from two key issues: misinterpreting UI components and outdated\nknowledge. Traditional fine-tuning methods are costly for app-specific\nknowledge updates. We propose GUI-explorer, a training-free GUI agent that\nincorporates two fundamental mechanisms: (1) Autonomous Exploration of\nFunction-aware Trajectory. To comprehensively cover all application\nfunctionalities, we design a Function-aware Task Goal Generator that\nautomatically constructs exploration goals by analyzing GUI structural\ninformation (e.g., screenshots and activity hierarchies). This enables\nsystematic exploration to collect diverse trajectories. (2) Unsupervised Mining\nof Transition-aware Knowledge. To establish precise screen-operation logic, we\ndevelop a Transition-aware Knowledge Extractor that extracts effective\nscreen-operation logic through unsupervised analysis the state transition of\nstructured interaction triples (observation, action, outcome). This eliminates\nthe need for human involvement in knowledge extraction. With a task success\nrate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows\nsignificant improvements over SOTA agents. It requires no parameter updates for\nnew apps. GUI-explorer is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/GUI-explorer.", "published": "2025-05-22 16:01:06", "link": "http://arxiv.org/abs/2505.16827v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Dynamic Reservoir Computing with Physical Neuromorphic Networks", "abstract": "Reservoir Computing (RC) with physical systems requires an understanding of\nthe underlying structure and internal dynamics of the specific physical\nreservoir. In this study, physical nano-electronic networks with neuromorphic\ndynamics are investigated for their use as physical reservoirs in an RC\nframework. These neuromorphic networks operate as dynamic reservoirs, with node\nactivities in general coupled to the edge dynamics through nonlinear\nnano-electronic circuit elements, and the reservoir outputs influenced by the\nunderlying network connectivity structure. This study finds that networks with\nvarying degrees of sparsity generate more useful nonlinear temporal outputs for\ndynamic RC compared to dense networks. Dynamic RC is also tested on an\nautonomous multivariate chaotic time series prediction task with networks of\nvarying densities, which revealed the importance of network sparsity in\nmaintaining network activity and overall dynamics, that in turn enabled the\nlearning of the chaotic Lorenz63 system's attractor behavior.", "published": "2025-05-22 15:50:45", "link": "http://arxiv.org/abs/2505.16813v1", "categories": ["cs.ET", "cond-mat.dis-nn", "cs.AI"], "primary_category": "cs.ET"}
{"title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents", "abstract": "Serious Games (SGs) are nowadays shifting focus to include procedural content\ngeneration (PCG) in the development process as a means of offering personalized\nand enhanced player experience. However, the development of a framework to\nassess the impact of PCG techniques when integrated into SGs remains\nparticularly challenging. This study proposes a methodology for automated\nevaluation of PCG integration in SGs, incorporating deep reinforcement learning\n(DRL) game testing agents. To validate the proposed framework, a previously\nintroduced SG featuring card game mechanics and incorporating three different\nversions of PCG for nonplayer character (NPC) creation has been deployed.\nVersion 1 features random NPC creation, while versions 2 and 3 utilize a\ngenetic algorithm approach. These versions are used to test the impact of\ndifferent dynamic SG environments on the proposed framework's agents. The\nobtained results highlight the superiority of the DRL game testing agents\ntrained on Versions 2 and 3 over those trained on Version 1 in terms of win\nrate (i.e. number of wins per played games) and training time. More\nspecifically, within the execution of a test emulating regular gameplay, both\nVersions 2 and 3 peaked at a 97% win rate and achieved statistically\nsignificant higher (p=0009) win rates compared to those achieved in Version 1\nthat peaked at 94%. Overall, results advocate towards the proposed framework's\ncapability to produce meaningful data for the evaluation of procedurally\ngenerated content in SGs.", "published": "2025-05-22 15:40:56", "link": "http://arxiv.org/abs/2505.16801v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SEED: Speaker Embedding Enhancement Diffusion Model", "abstract": "A primary challenge when deploying speaker recognition systems in real-world\napplications is performance degradation caused by environmental mismatch. We\npropose a diffusion-based method that takes speaker embeddings extracted from a\npre-trained speaker recognition model and generates refined embeddings. For\ntraining, our approach progressively adds Gaussian noise to both clean and\nnoisy speaker embeddings extracted from clean and noisy speech, respectively,\nvia forward process of a diffusion model, and then reconstructs them to clean\nembeddings in the reverse process. While inferencing, all embeddings are\nregenerated via diffusion process. Our method needs neither speaker label nor\nany modification to the existing speaker recognition pipeline. Experiments on\nevaluation sets simulating environment mismatch scenarios show that our method\ncan improve recognition accuracy by up to 19.6% over baseline models while\nretaining performance on conventional scenarios. We publish our code here\nhttps://github.com/kaistmm/seed-pytorch", "published": "2025-05-22 15:38:37", "link": "http://arxiv.org/abs/2505.16798v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training", "abstract": "Diffusion Transformers (DiTs) deliver state-of-the-art image quality, yet\ntheir training remains notoriously slow. A recent remedy -- representation\nalignment (REPA) that matches DiT hidden features to those of a non-generative\nteacher (e.g. DINO) -- dramatically accelerates the early epochs but plateaus\nor even degrades performance later. We trace this failure to a capacity\nmismatch: once the generative student begins modelling the joint data\ndistribution, the teacher's lower-dimensional embeddings and attention patterns\nbecome a straitjacket rather than a guide. We then introduce HASTE (Holistic\nAlignment with Stage-wise Termination for Efficient training), a two-phase\nschedule that keeps the help and drops the hindrance. Phase I applies a\nholistic alignment loss that simultaneously distills attention maps (relational\npriors) and feature projections (semantic anchors) from the teacher into\nmid-level layers of the DiT, yielding rapid convergence. Phase II then performs\none-shot termination that deactivates the alignment loss, once a simple trigger\nsuch as a fixed iteration is hit, freeing the DiT to focus on denoising and\nexploit its generative capacity. HASTE speeds up training of diverse DiTs\nwithout architecture changes. On ImageNet 256X256, it reaches the vanilla\nSiT-XL/2 baseline FID in 50 epochs and matches REPA's best FID in 500 epochs,\namounting to a 28X reduction in optimization steps. HASTE also improves\ntext-to-image DiTs on MS-COCO, demonstrating to be a simple yet principled\nrecipe for efficient diffusion training across various tasks. Our code is\navailable at https://github.com/NUS-HPC-AI-Lab/HASTE .", "published": "2025-05-22 15:34:33", "link": "http://arxiv.org/abs/2505.16792v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Cohort-Based Active Modality Acquisition", "abstract": "Real-world machine learning applications often involve data from multiple\nmodalities that must be integrated effectively to make robust predictions.\nHowever, in many practical settings, not all modalities are available for every\nsample, and acquiring additional modalities can be costly. This raises the\nquestion: which samples should be prioritized for additional modality\nacquisition when resources are limited? While prior work has explored\nindividual-level acquisition strategies and training-time active learning\nparadigms, test-time and cohort-based acquisition remain underexplored despite\ntheir importance in many real-world settings. We introduce Cohort-based Active\nModality Acquisition (CAMA), a novel test-time setting to formalize the\nchallenge of selecting which samples should receive additional modalities. We\nderive acquisition strategies that leverage a combination of generative\nimputation and discriminative modeling to estimate the expected benefit of\nacquiring missing modalities based on common evaluation metrics. We also\nintroduce upper-bound heuristics that provide performance ceilings to benchmark\nacquisition strategies. Experiments on common multimodal datasets demonstrate\nthat our proposed imputation-based strategies can more effectively guide the\nacquisition of new samples in comparison to those relying solely on unimodal\ninformation, entropy guidance, and random selections. Our work provides an\neffective solution for optimizing modality acquisition at the cohort level,\nenabling better utilization of resources in constrained settings.", "published": "2025-05-22 15:32:50", "link": "http://arxiv.org/abs/2505.16791v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion", "abstract": "Masked diffusion models (MDMs) have achieved notable progress in modeling\ndiscrete data, while their potential in molecular generation remains\nunderexplored. In this work, we explore their potential and introduce the\nsurprising result that naively applying standards MDMs severely degrades the\nperformance. We identify the critical cause of this issue as a state-clashing\nproblem-where the forward diffusion of distinct molecules collapse into a\ncommon state, resulting in a mixture of reconstruction targets that cannot be\nlearned using typical reverse diffusion process with unimodal predictions. To\nmitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that\norchestrates per-element corruption trajectories to avoid collision between\ndistinct molecular graphs. This is achieved through a parameterized noise\nscheduling network that assigns distinct corruption rates to individual graph\nelements, i.e., atoms and bonds. Extensive experiments on diverse molecular\nbenchmarks reveal that MELD markedly enhances overall generation quality\ncompared to element-agnostic noise scheduling, increasing the chemical validity\nof vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves\nstate-of-the-art property alignment in conditional generation tasks.", "published": "2025-05-22 15:30:17", "link": "http://arxiv.org/abs/2505.16790v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce", "abstract": "Model-based reinforcement learning (MBRL) offers an intuitive way to increase\nthe sample efficiency of model-free RL methods by simultaneously training a\nworld model that learns to predict the future. MBRL methods have progressed by\nlargely prioritising the actor; optimising the world model learning has been\nneglected meanwhile. Improving the fidelity of the world model and reducing its\ntime to convergence can yield significant downstream benefits, one of which is\nimproving the ensuing performance of any actor it may train. We propose a novel\napproach that anticipates and actively seeks out high-entropy states using\nshort-horizon latent predictions generated by the world model, offering a\nprincipled alternative to traditional curiosity-driven methods that chase\nonce-novel states well after they were stumbled into. While many model\npredictive control (MPC) based methods offer similar alternatives, they\ntypically lack commitment, synthesising multi step plans after every step. To\nmitigate this, we present a hierarchical planner that dynamically decides when\nto replan, planning horizon length, and the weighting between reward and\nentropy. While our method can theoretically be applied to any model that trains\nits own actors with solely model generated data, we have applied it to just\nDreamer as a proof of concept. Our method finishes the Miniworld procedurally\ngenerated mazes 50% faster than base Dreamer at convergence and the policy\ntrained in imagination converges in only 60% of the environment steps that base\nDreamer needs.", "published": "2025-05-22 15:28:50", "link": "http://arxiv.org/abs/2505.16787v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models", "abstract": "Despite providing superior performance, open-source large language models\n(LLMs) are vulnerable to abusive usage. To address this issue, recent works\npropose LLM fingerprinting methods to identify the specific source LLMs behind\nsuspect applications. However, these methods fail to provide stealthy and\nrobust fingerprint verification. In this paper, we propose a novel LLM\nfingerprinting scheme, namely CoTSRF, which utilizes the Chain of Thought (CoT)\nas the fingerprint of an LLM. CoTSRF first collects the responses from the\nsource LLM by querying it with crafted CoT queries. Then, it applies\ncontrastive learning to train a CoT extractor that extracts the CoT feature\n(i.e., fingerprint) from the responses. Finally, CoTSRF conducts fingerprint\nverification by comparing the Kullback-Leibler divergence between the CoT\nfeatures of the source and suspect LLMs against an empirical threshold. Various\nexperiments have been conducted to demonstrate the advantage of our proposed\nCoTSRF for fingerprinting LLMs, particularly in stealthy and robust fingerprint\nverification.", "published": "2025-05-22 15:28:25", "link": "http://arxiv.org/abs/2505.16785v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making", "abstract": "In group decision-making (GDM) scenarios, uncertainty, dynamic social\nstructures, and vague information present major challenges for traditional\nopinion dynamics models. To address these issues, this study proposes a novel\nsocial network group decision-making (SNGDM) framework that integrates\nthree-way decision (3WD) theory, dynamic network reconstruction, and linguistic\nopinion representation. First, the 3WD mechanism is introduced to explicitly\nmodel hesitation and ambiguity in agent judgments, thereby preventing\nirrational decisions. Second, a connection adjustment rule based on opinion\nsimilarity is developed, enabling agents to adaptively update their\ncommunication links and better reflect the evolving nature of social\nrelationships. Third, linguistic terms are used to describe agent opinions,\nallowing the model to handle subjective, vague, or incomplete information more\neffectively. Finally, an integrated multi-agent decision-making framework is\nconstructed, which simultaneously considers individual uncertainty, opinion\nevolution, and network dynamics. The proposed model is applied to a multi-UAV\ncooperative decision-making scenario, where simulation results and consensus\nanalysis demonstrate its effectiveness. Experimental comparisons further verify\nthe advantages of the algorithm in enhancing system stability and representing\nrealistic decision-making behaviors.", "published": "2025-05-22 15:26:48", "link": "http://arxiv.org/abs/2505.16781v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis", "abstract": "Deep learning has transformed computer vision but relies heavily on large\nlabeled datasets and computational resources. Transfer learning, particularly\nfine-tuning pretrained models, offers a practical alternative; however, models\npretrained on natural image datasets such as ImageNet may fail to capture\ndomain-specific characteristics in medical imaging. This study introduces an\nunsupervised learning framework that extracts high-value dermatological\nfeatures instead of relying solely on ImageNet-based pretraining. We employ a\nVariational Autoencoder (VAE) trained from scratch on a proprietary\ndermatological dataset, allowing the model to learn a structured and clinically\nrelevant latent space. This self-supervised feature extractor is then compared\nto an ImageNet-pretrained backbone under identical classification conditions,\nhighlighting the trade-offs between general-purpose and domain-specific\npretraining. Our results reveal distinct learning patterns. The self-supervised\nmodel achieves a final validation loss of 0.110 (-33.33%), while the\nImageNet-pretrained model stagnates at 0.100 (-16.67%), indicating overfitting.\nAccuracy trends confirm this: the self-supervised model improves from 45% to\n65% (+44.44%) with a near-zero overfitting gap, whereas the ImageNet-pretrained\nmodel reaches 87% (+50.00%) but plateaus at 75% (+19.05%), with its overfitting\ngap increasing to +0.060. These findings suggest that while ImageNet\npretraining accelerates convergence, it also amplifies overfitting on\nnon-clinically relevant features. In contrast, self-supervised learning\nachieves steady improvements, stronger generalization, and superior\nadaptability, underscoring the importance of domain-specific feature extraction\nin medical imaging.", "published": "2025-05-22 15:15:17", "link": "http://arxiv.org/abs/2505.16773v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review", "abstract": "This paper presents a comprehensive synthesis of major breakthroughs in\nartificial intelligence (AI) over the past fifteen years, integrating\nhistorical, theoretical, and technological perspectives. It identifies key\ninflection points in AI' s evolution by tracing the convergence of\ncomputational resources, data access, and algorithmic innovation. The analysis\nhighlights how researchers enabled GPU based model training, triggered a data\ncentric shift with ImageNet, simplified architectures through the Transformer,\nand expanded modeling capabilities with the GPT series. Rather than treating\nthese advances as isolated milestones, the paper frames them as indicators of\ndeeper paradigm shifts. By applying concepts from statistical learning theory\nsuch as sample complexity and data efficiency, the paper explains how\nresearchers translated breakthroughs into scalable solutions and why the field\nmust now embrace data centric approaches. In response to rising privacy\nconcerns and tightening regulations, the paper evaluates emerging solutions\nlike federated learning, privacy enhancing technologies (PETs), and the data\nsite paradigm, which reframe data access and security. In cases where real\nworld data remains inaccessible, the paper also assesses the utility and\nconstraints of mock and synthetic data generation. By aligning technical\ninsights with evolving data infrastructure, this study offers strategic\nguidance for future AI research and policy development.", "published": "2025-05-22 15:12:48", "link": "http://arxiv.org/abs/2505.16771v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques", "abstract": "Jailbreak attacks pose a serious threat to large language models (LLMs) by\nbypassing built-in safety mechanisms and leading to harmful outputs. Studying\nthese attacks is crucial for identifying vulnerabilities and improving model\nsecurity. This paper presents a systematic survey of jailbreak methods from the\nnovel perspective of stealth. We find that existing attacks struggle to\nsimultaneously achieve toxic stealth (concealing toxic content) and linguistic\nstealth (maintaining linguistic naturalness). Motivated by this, we propose\nStegoAttack, a fully stealthy jailbreak attack that uses steganography to hide\nthe harmful query within benign, semantically coherent text. The attack then\nprompts the LLM to extract the hidden query and respond in an encrypted manner.\nThis approach effectively hides malicious intent while preserving naturalness,\nallowing it to evade both built-in and external safety mechanisms. We evaluate\nStegoAttack on four safety-aligned LLMs from major providers, benchmarking\nagainst eight state-of-the-art methods. StegoAttack achieves an average attack\nsuccess rate (ASR) of 92.00%, outperforming the strongest baseline by 11.0%.\nIts ASR drops by less than 1% even under external detection (e.g., Llama\nGuard). Moreover, it attains the optimal comprehensive scores on stealth\ndetection metrics, demonstrating both high efficacy and exceptional stealth\ncapabilities. The code is available at\nhttps://anonymous.4open.science/r/StegoAttack-Jail66", "published": "2025-05-22 15:07:34", "link": "http://arxiv.org/abs/2505.16765v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation", "abstract": "We introduce the Dual-Flow Generative Ranking Network (DFGR), a two-stream\narchitecture designed for recommendation systems. DFGR integrates innovative\ninteraction patterns between real and fake flows within the QKV modules of the\nself-attention mechanism, enhancing both training and inference efficiency.\nThis approach effectively addresses a key limitation observed in Meta's\nproposed HSTU generative recommendation approach, where heterogeneous\ninformation volumes are mapped into identical vector spaces, leading to\ntraining instability. Unlike traditional recommendation models, DFGR only\nrelies on user history behavior sequences and minimal attribute information,\neliminating the need for extensive manual feature engineering. Comprehensive\nevaluations on open-source and industrial datasets reveal DFGR's superior\nperformance compared to established baselines such as DIN, DCN, DIEN, and\nDeepFM. We also investigate optimal parameter allocation strategies under\ncomputational constraints, establishing DFGR as an efficient and effective\nnext-generation generate ranking paradigm.", "published": "2025-05-22 14:58:53", "link": "http://arxiv.org/abs/2505.16752v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP", "abstract": "We explore the use of conformal prediction to provide statistical uncertainty\nguarantees for runway detection in vision-based landing systems (VLS). Using\nfine-tuned YOLOv5 and YOLOv6 models on aerial imagery, we apply conformal\nprediction to quantify localization reliability under user-defined risk levels.\nWe also introduce Conformal mean Average Precision (C-mAP), a novel metric\naligning object detection performance with conformal guarantees. Our results\nshow that conformal prediction can improve the reliability of runway detection\nby quantifying uncertainty in a statistically sound way, increasing safety\non-board and paving the way for certification of ML system in the aerospace\ndomain.", "published": "2025-05-22 14:52:59", "link": "http://arxiv.org/abs/2505.16740v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting", "abstract": "For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic\nand text embeddings are typically compared at either the phoneme or utterance\nlevel. To facilitate this, we optimize acoustic and text encoders using deep\nmetric learning (DML), enabling direct comparison of multi-modal embeddings in\na shared embedding space. However, the inherent heterogeneity between audio and\ntext modalities presents a significant challenge. To address this, we propose\nModality Adversarial Learning (MAL), which reduces the domain gap in\nheterogeneous modality representations. Specifically, we train a modality\nclassifier adversarially to encourage both encoders to generate\nmodality-invariant embeddings. Additionally, we apply DML to achieve\nphoneme-level alignment between audio and text, and conduct comprehensive\ncomparisons across various DML objectives. Experiments on the Wall Street\nJournal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the\nproposed approach.", "published": "2025-05-22 14:49:46", "link": "http://arxiv.org/abs/2505.16735v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs", "abstract": "Optimal decision-making under partial observability requires agents to\nbalance reducing uncertainty (exploration) against pursuing immediate\nobjectives (exploitation). In this paper, we introduce a novel policy\noptimization framework for continuous partially observable Markov decision\nprocesses (POMDPs) that explicitly addresses this challenge. Our method casts\npolicy learning as probabilistic inference in a non-Markovian Feynman--Kac\nmodel that inherently captures the value of information gathering by\nanticipating future observations, without requiring extrinsic exploration\nbonuses or handcrafted heuristics. To optimize policies under this model, we\ndevelop a nested sequential Monte Carlo~(SMC) algorithm that efficiently\nestimates a history-dependent policy gradient under samples from the optimal\ntrajectory distribution induced by the POMDP. We demonstrate the effectiveness\nof our algorithm across standard continuous POMDP benchmarks, where existing\nmethods struggle to act under uncertainty.", "published": "2025-05-22 14:45:46", "link": "http://arxiv.org/abs/2505.16732v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Advancing Brainwave Modeling with a Codebook-Based Foundation Model", "abstract": "Recent advances in large-scale pre-trained Electroencephalogram (EEG) models\nhave shown great promise, driving progress in Brain-Computer Interfaces (BCIs)\nand healthcare applications. However, despite their success, many existing\npre-trained models have struggled to fully capture the rich information content\nof neural oscillations, a limitation that fundamentally constrains their\nperformance and generalizability across diverse BCI tasks. This limitation is\nfrequently rooted in suboptimal architectural design choices which constrain\ntheir representational capacity. In this work, we introduce LaBraM++, an\nenhanced Large Brainwave Foundation Model (LBM) that incorporates principled\nimprovements grounded in robust signal processing foundations. LaBraM++\ndemonstrates substantial gains across a variety of tasks, consistently\noutperforming its originally-based architecture and achieving competitive\nresults when compared to other open-source LBMs. Its superior performance and\ntraining efficiency highlight its potential as a strong foundation for future\nadvancements in LBMs.", "published": "2025-05-22 14:32:56", "link": "http://arxiv.org/abs/2505.16724v1", "categories": ["cs.LG", "cs.AI", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Training Long-Context LLMs Efficiently via Chunk-wise Optimization", "abstract": "While long-context large language models (LLMs) exhibit remarkable document\nprocessing capabilities, their prohibitively high training costs often hinder\ncustomized applications. To mitigate this issue, we propose \\textit{Sequential\nChunk-wise Optimization} (SeCO), a memory-efficient training paradigm that\npartitions lengthy inputs into manageable chunks. Each chunk independently\nconstructs its computational graph and performs localized backpropagation,\nensuring that only one chunk's forward activations are stored in memory.\nBuilding on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization}\n(SpaCO), which reduces computational overhead by selectively propagating\ngradients to specific chunks and incorporates a carefully designed compensation\nfactor to ensure unbiased gradient estimation. SpaCO decouples the\ncomputational cost of backpropagation from the context length, enabling\ntraining time to gradually converge to inference time as sequences become\nlonger. Implemented as lightweight training wrappers, both SeCO and SpaCO offer\nsubstantial practical benefits. For example, when fine-tuning an 8B model with\nLoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to\n16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up\nto 3x faster than SeCO under the same experimental setup. These innovations\nprovide new insights into optimizing long-context models, making them more\naccessible for practical applications. We have open-sourced the code at\n\\href{https://github.com/wenhaoli-xmu/seco}{here}.", "published": "2025-05-22 14:11:34", "link": "http://arxiv.org/abs/2505.16710v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations", "abstract": "Concept bottleneck models (CBMs) ensure interpretability by decomposing\npredictions into human interpretable concepts. Yet the annotations used for\ntraining CBMs that enable this transparency are often noisy, and the impact of\nsuch corruption is not well understood. In this study, we present the first\nsystematic study of noise in CBMs and show that even moderate corruption\nsimultaneously impairs prediction performance, interpretability, and the\nintervention effectiveness. Our analysis identifies a susceptible subset of\nconcepts whose accuracy declines far more than the average gap between noisy\nand clean supervision and whose corruption accounts for most performance loss.\nTo mitigate this vulnerability we propose a two-stage framework. During\ntraining, sharpness-aware minimization stabilizes the learning of\nnoise-sensitive concepts. During inference, where clean labels are unavailable,\nwe rank concepts by predictive entropy and correct only the most uncertain\nones, using uncertainty as a proxy for susceptibility. Theoretical analysis and\nextensive ablations elucidate why sharpness-aware training confers robustness\nand why uncertainty reliably identifies susceptible concepts, providing a\nprincipled basis that preserves both interpretability and resilience in the\npresence of noise.", "published": "2025-05-22 14:06:55", "link": "http://arxiv.org/abs/2505.16705v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "abstract": "As Large Language Models (LLMs) evolve from passive text generators to active\nreasoning agents capable of tool interaction, the Model Context Protocol (MCP)\nhas emerged as a standardized framework for dynamic tool discovery and\norchestration. Despite widespread industry adoption, existing evaluation\nmethodologies fail to adequately assess tool utilization capabilities within\nthis new paradigm. This paper introduces MCP-RADAR, the first comprehensive\nbenchmark specifically designed to evaluate LLM performance in the MCP\nframework through a novel five-dimensional approach measuring: answer accuracy,\ntool selection efficiency, computational resource efficiency, parameter\nconstruction accuracy, and execution speed. Unlike conventional benchmarks that\nrely on subjective human evaluations or binary success metrics, MCP-RADAR\nemploys objective, quantifiable measurements across multiple task domains\nincluding software engineering, mathematical reasoning, and general\nproblem-solving. Our evaluations of leading commercial and open-source LLMs\nreveal distinctive capability profiles with significant trade-offs between\naccuracy, efficiency, and speed, challenging traditional single-metric\nperformance rankings. Besides, we provide valuable guidance for developers to\noptimize their tools for maximum model compatibility and effectiveness. While\nfocused on MCP due to its standardized approach, our methodology remains\napplicable across all LLM agent tool integration frameworks, providing valuable\ninsights for both LLM developers and tool creators to optimize the entire\nLLM-tool interaction ecosystem. The implementation, configurations, and\ndatasets used in our evaluation are publicly available at\nhttps://anonymous.4open.science/r/MCPRadar-B143.", "published": "2025-05-22 14:02:37", "link": "http://arxiv.org/abs/2505.16700v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion", "abstract": "Voice Conversion research in recent times has increasingly focused on\nimproving the zero-shot capabilities of existing methods. Despite remarkable\nadvancements, current architectures still tend to struggle in zero-shot\ncross-lingual settings. They are also often unable to generalize for speakers\nof unseen languages and accents. In this paper, we adopt a simple yet effective\napproach that combines discrete speech representations from self-supervised\nmodels with a non-autoregressive Diffusion-Transformer based conditional flow\nmatching speech decoder. We show that this architecture allows us to train a\nvoice-conversion model in a purely textless, self-supervised fashion. Our\ntechnique works without requiring multiple encoders to disentangle speech\nfeatures. Our model also manages to excel in zero-shot cross-lingual settings\neven for unseen languages.", "published": "2025-05-22 13:57:02", "link": "http://arxiv.org/abs/2505.16691v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "abstract": "Post-training of large language models is essential for adapting pre-trained\nlanguage models (PLMs) to align with human preferences and downstream tasks.\nWhile PLMs typically exhibit well-calibrated confidence, post-trained language\nmodels (PoLMs) often suffer from over-confidence, assigning high confidence to\nboth correct and incorrect outputs, which can undermine reliability in critical\napplications. A major obstacle in calibrating PoLMs is the scarcity of labeled\ndata for individual downstream tasks. To address this, we propose\nDisagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to\noptimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence\ncalibration. Our method is motivated by the under-confidence issue caused by\nprediction disagreement between the PLM and PoLM while aligning their\nconfidence via temperature scaling. Theoretically, the PLM's confidence\nunderestimates PoLM's prediction accuracy on disagreement examples, causing a\nlarger $\\tau$ and producing under-confident predictions. DACA mitigates this by\nselectively using only agreement examples for calibration, effectively\ndecoupling the influence of disagreement. In this manner, our method avoids an\noverly large $\\tau$ in temperature scaling caused by disagreement examples,\nimproving calibration performance. Extensive experiments demonstrate the\neffectiveness of our method, improving the average ECE of open-sourced and\nAPI-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.", "published": "2025-05-22 13:55:39", "link": "http://arxiv.org/abs/2505.16690v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds", "abstract": "Traditional methods for 3D object compression operate only on structural\ninformation within the object vertices, polygons, and textures. These methods\nare effective at compression rates up to 10x for standard object sizes but\nquickly deteriorate at higher compression rates with texture artifacts,\nlow-polygon counts, and mesh gaps. In contrast, semantic compression ignores\nstructural information and operates directly on the core concepts to push to\nextreme levels of compression. In addition, it uses natural language as its\nstorage format, which makes it natively human-readable and a natural fit for\nemerging applications built around large-scale, collaborative projects within\naugmented and virtual reality. It deprioritizes structural information like\nlocation, size, and orientation and predicts the missing information with\nstate-of-the-art deep generative models. In this work, we construct a pipeline\nfor 3D semantic compression from public generative models and explore the\nquality-compression frontier for 3D object compression. We apply this pipeline\nto achieve rates as high as 105x for 3D objects taken from the Objaverse\ndataset and show that semantic compression can outperform traditional methods\nin the important quality-preserving region around 100x compression.", "published": "2025-05-22 13:45:35", "link": "http://arxiv.org/abs/2505.16679v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models", "abstract": "Large language models (LLMs) have shown impressive capabilities across a wide\nrange of applications, but their ever-increasing size and resource demands make\nthem vulnerable to inference cost attacks, where attackers induce victim LLMs\nto generate the longest possible output content. In this paper, we revisit\nexisting inference cost attacks and reveal that these methods can hardly\nproduce large-scale malicious effects since they are self-targeting, where\nattackers are also the users and therefore have to execute attacks solely\nthrough the inputs, whose generated content will be charged by LLMs and can\nonly directly influence themselves. Motivated by these findings, this paper\nintroduces a new type of inference cost attacks (dubbed 'bit-flip inference\ncost attack') that target the victim model itself rather than its inputs.\nSpecifically, we design a simple yet effective method (dubbed 'BitHydra') to\neffectively flip critical bits of model parameters. This process is guided by a\nloss function designed to suppress <EOS> token's probability with an efficient\ncritical bit search algorithm, thus explicitly defining the attack objective\nand enabling effective optimization. We evaluate our method on 11 LLMs ranging\nfrom 1.5B to 14B parameters under both int8 and float16 settings. Experimental\nresults demonstrate that with just 4 search samples and as few as 3 bit flips,\nBitHydra can force 100% of test prompts to reach the maximum generation length\n(e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its\nefficiency, scalability, and strong transferability across unseen inputs.", "published": "2025-05-22 13:36:00", "link": "http://arxiv.org/abs/2505.16670v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming", "abstract": "While recent research increasingly emphasizes the value of human-LLM\ncollaboration in competitive programming and proposes numerous empirical\nmethods, a comprehensive understanding remains elusive due to the fragmented\nnature of existing studies and their use of diverse, application-specific human\nfeedback. Thus, our work serves a three-fold purpose: First, we present the\nfirst taxonomy of human feedback consolidating the entire programming process,\nwhich promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a\nnovel programming dataset specifically designed for human-LLM collaboration,\nmeticulously annotated to enable large-scale simulated human feedback and\nfacilitate costeffective real human interaction studies. Third, we introduce\nELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM\ncompetitive programming. With ELABORATION, we pinpoint strengthes and\nweaknesses of existing methods, thereby setting the foundation for future\nimprovement. Our code and dataset are available at\nhttps://github.com/SCUNLP/ELABORATION", "published": "2025-05-22 13:32:39", "link": "http://arxiv.org/abs/2505.16667v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries", "abstract": "Accurate prediction of the Remaining Useful Life (RUL) is essential for\nenabling timely maintenance of lithium-ion batteries, impacting the operational\nefficiency of electric applications that rely on them. This paper proposes a\nRUL prediction approach that leverages data from recent charge-discharge cycles\nto estimate the number of remaining usable cycles. The approach introduces both\na novel signal processing pipeline and a deep learning prediction model. In the\nsignal preprocessing pipeline, a derived capacity feature is computed based on\ncurrent and capacity signals. Alongside original capacity, voltage and current,\nthese features are denoised and enhanced using statistical metrics and a\ndelta-based method to capture differences between the current and previous\ncycles. In the prediction model, the processed features are then fed into a\nhybrid deep learning architecture composed of 1D Convolutional Neural Networks\n(CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential\nEquation-based LSTM (ODE-LSTM) modules. This architecture is designed to\ncapture both local signal characteristics and long-range temporal dependencies\nwhile modeling the continuous-time dynamics of battery degradation. The model\nis further evaluated using transfer learning across different learning\nstrategies and target data partitioning scenarios. Results indicate that the\nmodel maintains robust performance, even when fine-tuned on limited target\ndata. Experimental results on two publicly available large-scale datasets\ndemonstrate that the proposed method outperforms a baseline deep learning\napproach and machine learning techniques, achieving an RMSE of 101.59,\nhighlighting its strong potential for real-world RUL prediction applications.", "published": "2025-05-22 13:28:18", "link": "http://arxiv.org/abs/2505.16664v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models", "abstract": "We investigate fine-tuning Vision-Language Models (VLMs) for multi-task\nmedical image understanding, focusing on detection, localization, and counting\nof findings in medical images. Our objective is to evaluate whether\ninstruction-tuned VLMs can simultaneously improve these tasks, with the goal of\nenhancing diagnostic accuracy and efficiency. Using MedMultiPoints, a\nmultimodal dataset with annotations from endoscopy (polyps and instruments) and\nmicroscopy (sperm cells), we reformulate each task into instruction-based\nprompts suitable for vision-language reasoning. We fine-tune\nQwen2.5-VL-7B-Instruct using Low-Rank Adaptation (LoRA) across multiple task\ncombinations. Results show that multi-task training improves robustness and\naccuracy. For example, it reduces the Count Mean Absolute Error (MAE) and\nincreases Matching Accuracy in the Counting + Pointing task. However,\ntrade-offs emerge, such as more zero-case point predictions, indicating reduced\nreliability in edge cases despite overall performance gains. Our study\nhighlights the potential of adapting general-purpose VLMs to specialized\nmedical tasks via prompt-driven fine-tuning. This approach mirrors clinical\nworkflows, where radiologists simultaneously localize, count, and describe\nfindings - demonstrating how VLMs can learn composite diagnostic reasoning\npatterns. The model produces interpretable, structured outputs, offering a\npromising step toward explainable and versatile medical AI. Code, model\nweights, and scripts will be released for reproducibility at\nhttps://github.com/simula/PointDetectCount.", "published": "2025-05-22 13:18:44", "link": "http://arxiv.org/abs/2505.16647v1", "categories": ["cs.CV", "cs.AI", "68T45, 68T07", "I.2.10; I.4.8"], "primary_category": "cs.CV"}
{"title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving", "abstract": "Large Language Models have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine mathematical reasoning or superficial pattern recognition.\nCommon evaluation metrics, such as final answer accuracy, fail to disentangle\nthe underlying competencies involved, offering limited diagnostic value. To\naddress these limitations, we introduce SMART: a Self-Generating and\nSelf-Validating Multi-Dimensional Assessment Framework. SMART decomposes\nmathematical problem solving into four distinct dimensions: understanding,\nreasoning, arithmetic, and reflection \\& refinement. Each dimension is\nevaluated independently through tailored tasks, enabling interpretable and\nfine-grained analysis of LLM behavior. Crucially, SMART integrates an automated\nself-generating and self-validating mechanism to produce and verify benchmark\ndata, ensuring both scalability and reliability. We apply SMART to 21\nstate-of-the-art open- and closed-source LLMs, uncovering significant\ndiscrepancies in their abilities across different dimensions. Our findings\ndemonstrate the inadequacy of final answer accuracy as a sole metric and\nmotivate a new holistic metric to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.", "published": "2025-05-22 13:18:24", "link": "http://arxiv.org/abs/2505.16646v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "From Evaluation to Defense: Advancing Safety in Video Large Language Models", "abstract": "While the safety risks of image-based large language models have been\nextensively studied, their video-based counterparts (Video LLMs) remain\ncritically under-examined. To systematically study this problem, we introduce\n\\textbf{VideoSafetyBench (VSB-77k) - the first large-scale, culturally diverse\nbenchmark for Video LLM safety}, which compromises 77,646 video-query pairs and\nspans 19 principal risk categories across 10 language communities. \\textit{We\nreveal that integrating video modality degrades safety performance by an\naverage of 42.3\\%, exposing systemic risks in multimodal attack exploitation.}\nTo address this vulnerability, we propose \\textbf{VideoSafety-R1}, a dual-stage\nframework achieving unprecedented safety gains through two innovations: (1)\nAlarm Token-Guided Safety Fine-Tuning (AT-SFT) injects learnable alarm tokens\ninto visual and textual sequences, enabling explicit harm perception across\nmodalities via multitask objectives. (2) Then, Safety-Guided GRPO enhances\ndefensive reasoning through dynamic policy optimization with rule-based rewards\nderived from dual-modality verification. These components synergize to shift\nsafety alignment from passive harm recognition to active reasoning. The\nresulting framework achieves a 65.1\\% improvement on VSB-Eval-HH, and improves\nby 59.1\\%, 44.3\\%, and 15.0\\% on the image safety datasets MMBench, VLGuard,\nand FigStep, respectively. \\textit{Our codes are available in the supplementary\nmaterials.} \\textcolor{red}{Warning: This paper contains examples of harmful\nlanguage and videos, and reader discretion is recommended.}", "published": "2025-05-22 13:16:53", "link": "http://arxiv.org/abs/2505.16643v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization", "abstract": "Vision-Language-Action (VLA) models have advanced robotic control by enabling\nend-to-end decision-making directly from multimodal inputs. However, their\ntightly coupled architectures expose novel security vulnerabilities. Unlike\ntraditional adversarial perturbations, backdoor attacks represent a stealthier,\npersistent, and practically significant threat-particularly under the emerging\nTraining-as-a-Service paradigm-but remain largely unexplored in the context of\nVLA models. To address this gap, we propose BadVLA, a backdoor attack method\nbased on Objective-Decoupled Optimization, which for the first time exposes the\nbackdoor vulnerabilities of VLA models. Specifically, it consists of a\ntwo-stage process: (1) explicit feature-space separation to isolate trigger\nrepresentations from benign inputs, and (2) conditional control deviations that\nactivate only in the presence of the trigger, while preserving clean-task\nperformance. Empirical results on multiple VLA benchmarks demonstrate that\nBadVLA consistently achieves near-100% attack success rates with minimal impact\non clean task accuracy. Further analyses confirm its robustness against common\ninput perturbations, task transfers, and model fine-tuning, underscoring\ncritical security vulnerabilities in current VLA deployments. Our work offers\nthe first systematic investigation of backdoor vulnerabilities in VLA models,\nhighlighting an urgent need for secure and trustworthy embodied model design\npractices. We have released the project page at\nhttps://badvla-project.github.io/.", "published": "2025-05-22 13:12:46", "link": "http://arxiv.org/abs/2505.16640v1", "categories": ["cs.CR", "cs.AI", "68T07", "I.2.6; I.2.9"], "primary_category": "cs.CR"}
{"title": "SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding", "abstract": "The integration of artificial intelligence in sports analytics has\ntransformed soccer video understanding, enabling real-time, automated insights\ninto complex game dynamics. Traditional approaches rely on isolated data\nstreams, limiting their effectiveness in capturing the full context of a match.\nTo address this, we introduce SoccerChat, a multimodal conversational AI\nframework that integrates visual and textual data for enhanced soccer video\ncomprehension. Leveraging the extensive SoccerNet dataset, enriched with jersey\ncolor annotations and automatic speech recognition (ASR) transcripts,\nSoccerChat is fine-tuned on a structured video instruction dataset to\nfacilitate accurate game understanding, event classification, and referee\ndecision making. We benchmark SoccerChat on action classification and referee\ndecision-making tasks, demonstrating its performance in general soccer event\ncomprehension while maintaining competitive accuracy in referee decision\nmaking. Our findings highlight the importance of multimodal integration in\nadvancing soccer analytics, paving the way for more interactive and explainable\nAI-driven sports analysis. https://github.com/simula/SoccerChat", "published": "2025-05-22 13:01:51", "link": "http://arxiv.org/abs/2505.16630v1", "categories": ["cs.CV", "cs.AI", "68T45, 68T50", "I.2.10; I.2.7; H.5.2"], "primary_category": "cs.CV"}
{"title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "abstract": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "published": "2025-05-22 12:52:34", "link": "http://arxiv.org/abs/2505.16619v1", "categories": ["cs.AI", "q-bio.OT", "92", "J.3"], "primary_category": "cs.AI"}
{"title": "Safe Uncertainty-Aware Learning of Robotic Suturing", "abstract": "Robot-Assisted Minimally Invasive Surgery is currently fully manually\ncontrolled by a trained surgeon. Automating this has great potential for\nalleviating issues, e.g., physical strain, highly repetitive tasks, and\nshortages of trained surgeons. For these reasons, recent works have utilized\nArtificial Intelligence methods, which show promising adaptability. Despite\nthese advances, there is skepticism of these methods because they lack\nexplainability and robust safety guarantees. This paper presents a framework\nfor a safe, uncertainty-aware learning method. We train an Ensemble Model of\nDiffusion Policies using expert demonstrations of needle insertion. Using an\nEnsemble model, we can quantify the policy's epistemic uncertainty, which is\nused to determine Out-Of-Distribution scenarios. This allows the system to\nrelease control back to the surgeon in the event of an unsafe scenario.\nAdditionally, we implement a model-free Control Barrier Function to place\nformal safety guarantees on the predicted action. We experimentally evaluate\nour proposed framework using a state-of-the-art robotic suturing simulator. We\nevaluate multiple scenarios, such as dropping the needle, moving the camera,\nand moving the phantom. The learned policy is robust to these perturbations,\nshowing corrective behaviors and generalization, and it is possible to detect\nOut-Of-Distribution scenarios. We further demonstrate that the Control Barrier\nFunction successfully limits the action to remain within our specified safety\nset in the case of unsafe predictions.", "published": "2025-05-22 12:31:18", "link": "http://arxiv.org/abs/2505.16596v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "abstract": "In the zero-shot policy transfer setting in reinforcement learning, the goal\nis to train an agent on a fixed set of training environments so that it can\ngeneralise to similar, but unseen, testing environments. Previous work has\nshown that policy distillation after training can sometimes produce a policy\nthat outperforms the original in the testing environments. However, it is not\nyet entirely clear why that is, or what data should be used to distil the\npolicy. In this paper, we prove, under certain assumptions, a generalisation\nbound for policy distillation after training. The theory provides two practical\ninsights: for improved generalisation, you should 1) train an ensemble of\ndistilled policies, and 2) distil it on as much data from the training\nenvironments as possible. We empirically verify that these insights hold in\nmore general settings, when the assumptions required for the theory no longer\nhold. Finally, we demonstrate that an ensemble of policies distilled on a\ndiverse dataset can generalise significantly better than the original agent.", "published": "2025-05-22 12:15:52", "link": "http://arxiv.org/abs/2505.16581v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning", "abstract": "While chains-of-thought (CoT) have advanced complex reasoning in multimodal\nlarge language models (MLLMs), existing methods remain confined to text or\nstatic visual domains, often faltering in dynamic spatial reasoning tasks. To\nbridge this gap, we present GRASSLAND, a novel maze navigation benchmark\ndesigned to evaluate dynamic spatial reasoning. Our experiments show that\naugmenting textual reasoning chains with dynamic visual drafts, overlaid on\ninput images, significantly outperforms conventional approaches, offering new\ninsights into spatial reasoning in evolving environments. To generalize this\ncapability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free\nframework that seamlessly integrates textual CoT with corresponding visual\ndrafts into MLLMs. Extensive evaluations demonstrate that D2R consistently\nenhances performance across diverse tasks, establishing a robust baseline for\ndynamic spatial reasoning without requiring model fine-tuning. Project is open\nat https://github.com/Cratileo/D2R.", "published": "2025-05-22 12:14:23", "link": "http://arxiv.org/abs/2505.16579v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling", "abstract": "Stock price prediction is a critical area of financial forecasting,\ntraditionally approached by training models using the historical price data of\nindividual stocks. While these models effectively capture single-stock\npatterns, they fail to leverage potential correlations among stock trends,\nwhich could improve predictive performance. Current single-stock learning\nmethods are thus limited in their ability to provide a broader understanding of\nprice dynamics across multiple stocks. To address this, we propose a novel\nmethod that merges local patterns into a global understanding through\ncross-stock pattern integration. Our strategy is inspired by Federated Learning\n(FL), a paradigm designed for decentralized model training. FL enables\ncollaborative learning across distributed datasets without sharing raw data,\nfacilitating the aggregation of global insights while preserving data privacy.\nIn our adaptation, we train models on individual stock data and iteratively\nmerge them to create a unified global model. This global model is subsequently\nfine-tuned on specific stock data to retain local relevance. The proposed\nstrategy enables parallel training of individual stock models, facilitating\nefficient utilization of computational resources and reducing overall training\ntime. We conducted extensive experiments to evaluate the proposed method,\ndemonstrating that it outperforms benchmark models and enhances the predictive\ncapabilities of state-of-the-art approaches. Our results highlight the efficacy\nof Cross-Stock Trend Integration (CSTI) in advancing stock price prediction,\noffering a robust alternative to traditional single-stock learning\nmethodologies.", "published": "2025-05-22 12:04:10", "link": "http://arxiv.org/abs/2505.16573v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Finetuning-Activated Backdoors in LLMs", "abstract": "Finetuning openly accessible Large Language Models (LLMs) has become standard\npractice for achieving task-specific performance improvements. Until now,\nfinetuning has been regarded as a controlled and secure process in which\ntraining on benign datasets led to predictable behaviors. In this paper, we\ndemonstrate for the first time that an adversary can create poisoned LLMs that\ninitially appear benign but exhibit malicious behaviors once finetuned by\ndownstream users. To this end, our proposed attack, FAB (Finetuning-Activated\nBackdoor), poisons an LLM via meta-learning techniques to simulate downstream\nfinetuning, explicitly optimizing for the emergence of malicious behaviors in\nthe finetuned models. At the same time, the poisoned LLM is regularized to\nretain general capabilities and to exhibit no malicious behaviors prior to\nfinetuning. As a result, when users finetune the seemingly benign model on\ntheir own datasets, they unknowingly trigger its hidden backdoor behavior. We\ndemonstrate the effectiveness of FAB across multiple LLMs and three target\nbehaviors: unsolicited advertising, refusal, and jailbreakability.\nAdditionally, we show that FAB-backdoors are robust to various finetuning\nchoices made by the user (e.g., dataset, number of steps, scheduler). Our\nfindings challenge prevailing assumptions about the security of finetuning,\nrevealing yet another critical attack vector exploiting the complexities of\nLLMs.", "published": "2025-05-22 11:59:44", "link": "http://arxiv.org/abs/2505.16567v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Auto-nnU-Net: Towards Automated Medical Image Segmentation", "abstract": "Medical Image Segmentation (MIS) includes diverse tasks, from bone to organ\nsegmentation, each with its own challenges in finding the best segmentation\nmodel. The state-of-the-art AutoML-related MIS-framework nnU-Net automates many\naspects of model configuration but remains constrained by fixed hyperparameters\nand heuristic design choices. As a full-AutoML framework for MIS, we propose\nAuto-nnU-Net, a novel nnU-Net variant enabling hyperparameter optimization\n(HPO), neural architecture search (NAS), and hierarchical NAS (HNAS).\nAdditionally, we propose Regularized PriorBand to balance model accuracy with\nthe computational resources required for training, addressing the resource\nconstraints often faced in real-world medical settings that limit the\nfeasibility of extensive training procedures. We evaluate our approach across\ndiverse MIS datasets from the well-established Medical Segmentation Decathlon,\nanalyzing the impact of AutoML techniques on segmentation performance,\ncomputational efficiency, and model design choices. The results demonstrate\nthat our AutoML approach substantially improves the segmentation performance of\nnnU-Net on 6 out of 10 datasets and is on par on the other datasets while\nmaintaining practical resource requirements. Our code is available at\nhttps://github.com/LUH-AI/AutonnUNet.", "published": "2025-05-22 11:52:16", "link": "http://arxiv.org/abs/2505.16561v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation", "abstract": "This paper presents an end-to-end deep reinforcement learning (RL) framework\nfor occlusion-aware robotic manipulation in cluttered plant environments. Our\napproach enables a robot to interact with a deformable plant to reveal hidden\nobjects of interest, such as fruits, using multimodal observations. We decouple\nthe kinematic planning problem from robot control to simplify zero-shot\nsim2real transfer for the trained policy. Our results demonstrate that the\ntrained policy, deployed using our framework, achieves up to 86.7% success in\nreal-world trials across diverse initial conditions. Our findings pave the way\ntoward autonomous, perception-driven agricultural robots that intelligently\ninteract with complex foliage plants to \"find the fruit\" in challenging\noccluded scenarios, without the need for explicitly designed geometric and\ndynamic models of every plant scenario.", "published": "2025-05-22 11:37:39", "link": "http://arxiv.org/abs/2505.16547v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark", "abstract": "As Large Multimodal Models (LMMs) become more capable, there is growing\ninterest in evaluating their reasoning processes alongside their final outputs.\nHowever, most benchmarks remain focused on English, overlooking languages with\nrich linguistic and cultural contexts, such as Arabic. To address this gap, we\nintroduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the\nfirst benchmark designed to evaluate step-by-step reasoning in Arabic across\nboth textual and visual modalities. ARB spans 11 diverse domains, including\nvisual reasoning, document understanding, OCR, scientific analysis, and\ncultural interpretation. It comprises 1,356 multimodal samples paired with\n5,119 human-curated reasoning steps and corresponding actions. We evaluated 12\nstate-of-the-art open- and closed-source LMMs and found persistent challenges\nin coherence, faithfulness, and cultural grounding. ARB offers a structured\nframework for diagnosing multimodal reasoning in underrepresented languages and\nmarks a critical step toward inclusive, transparent, and culturally aware AI\nsystems. We release the benchmark, rubric, and evaluation suit to support\nfuture research and reproducibility. Code available at:\nhttps://github.com/mbzuai-oryx/ARB", "published": "2025-05-22 17:59:58", "link": "http://arxiv.org/abs/2505.17021v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward", "abstract": "Recent advances have shown success in eliciting strong reasoning abilities in\nmultimodal large language models (MLLMs) through rule-based reinforcement\nlearning (RL) with outcome rewards. However, this paradigm typically lacks\nsupervision over the thinking process leading to the final outcome.As a result,\nthe model may learn sub-optimal reasoning strategies, which can hinder its\ngeneralization ability. In light of this, we propose SophiaVL-R1, as an attempt\nto add reward signals for the thinking process in this paradigm. To achieve\nthis, we first train a thinking reward model that evaluates the quality of the\nentire thinking process. Given that the thinking reward may be unreliable for\ncertain samples due to reward hacking, we propose the Trust-GRPO method, which\nassigns a trustworthiness weight to the thinking reward during training. This\nweight is computed based on the thinking reward comparison of responses leading\nto correct answers versus incorrect answers, helping to mitigate the impact of\npotentially unreliable thinking rewards. Moreover, we design an annealing\ntraining strategy that gradually reduces the thinking reward over time,\nallowing the model to rely more on the accurate rule-based outcome reward in\nlater training stages. Experiments show that our SophiaVL-R1 surpasses a series\nof reasoning MLLMs on various benchmarks (e.g., MathVisita, MMMU),\ndemonstrating strong reasoning and generalization capabilities. Notably, our\nSophiaVL-R1-7B even outperforms LLaVA-OneVision-72B on most benchmarks, despite\nthe latter having 10 times more parameters. All code, models, and datasets are\nmade publicly available at https://github.com/kxfan2002/SophiaVL-R1.", "published": "2025-05-22 17:59:53", "link": "http://arxiv.org/abs/2505.17018v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CrossLMM: Decoupling Long Video Sequences from LMMs via Dual Cross-Attention Mechanisms", "abstract": "The advent of Large Multimodal Models (LMMs) has significantly enhanced Large\nLanguage Models (LLMs) to process and interpret diverse data modalities (e.g.,\nimage and video). However, as input complexity increases, particularly with\nlong video sequences, the number of required tokens has grown significantly,\nleading to quadratically computational costs. This has made the efficient\ncompression of video tokens in LMMs, while maintaining performance integrity, a\npressing research challenge. In this paper, we introduce CrossLMM, decoupling\nlong video sequences from LMMs via a dual cross-attention mechanism, which\nsubstantially reduces visual token quantity with minimal performance\ndegradation. Specifically, we first implement a significant token reduction\nfrom pretrained visual encoders through a pooling methodology. Then, within LLM\nlayers, we employ a visual-to-visual cross-attention mechanism, wherein the\npooled visual tokens function as queries against the original visual token set.\nThis module enables more efficient token utilization while retaining\nfine-grained informational fidelity. In addition, we introduce a text-to-visual\ncross-attention mechanism, for which the text tokens are enhanced through\ninteraction with the original visual tokens, enriching the visual comprehension\nof the text tokens. Comprehensive empirical evaluation demonstrates that our\napproach achieves comparable or superior performance across diverse video-based\nLMM benchmarks, despite utilizing substantially fewer computational resources.", "published": "2025-05-22 17:59:53", "link": "http://arxiv.org/abs/2505.17020v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "When Are Concepts Erased From Diffusion Models?", "abstract": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "published": "2025-05-22 17:59:09", "link": "http://arxiv.org/abs/2505.17013v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space", "abstract": "We propose AdapTok, an adaptive temporal causal video tokenizer that can\nflexibly allocate tokens for different frames based on video content. AdapTok\nis equipped with a block-wise masking strategy that randomly drops tail tokens\nof each block during training, and a block causal scorer to predict the\nreconstruction quality of video frames using different numbers of tokens.\nDuring inference, an adaptive token allocation strategy based on integer linear\nprogramming is further proposed to adjust token usage given predicted scores.\nSuch design allows for sample-wise, content-aware, and temporally dynamic token\nallocation under a controllable overall budget. Extensive experiments for video\nreconstruction and generation on UCF-101 and Kinetics-600 demonstrate the\neffectiveness of our approach. Without additional image data, AdapTok\nconsistently improves reconstruction quality and generation performance under\ndifferent token budgets, allowing for more scalable and token-efficient\ngenerative video modeling.", "published": "2025-05-22 17:59:02", "link": "http://arxiv.org/abs/2505.17011v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep mineralogical segmentation of thin section images based on QEMSCAN maps", "abstract": "Interpreting the mineralogical aspects of rock thin sections is an important\ntask for oil and gas reservoirs evaluation. However, human analysis tend to be\nsubjective and laborious. Technologies like QEMSCAN(R) are designed to automate\nthe mineralogical mapping process, but also suffer from limitations like high\nmonetary costs and time-consuming analysis. This work proposes a Convolutional\nNeural Network model for automatic mineralogical segmentation of thin section\nimages of carbonate rocks. The model is able to mimic the QEMSCAN mapping\nitself in a low-cost, generalized and efficient manner. For this, the U-Net\nsemantic segmentation architecture is trained on plane and cross polarized thin\nsection images using the corresponding QEMSCAN maps as target, which is an\napproach not widely explored. The model was instructed to differentiate\noccurrences of Calcite, Dolomite, Mg-Clay Minerals, Quartz, Pores and the\nremaining mineral phases as an unique class named \"Others\", while it was\nvalidated on rock facies both seen and unseen during training, in order to\naddress its generalization capability. Since the images and maps are provided\nin different resolutions, image registration was applied to align then\nspatially. The study reveals that the quality of the segmentation is very much\ndependent on these resolution differences and on the variety of learnable rock\ntextures. However, it shows promising results, especially with regard to the\nproper delineation of minerals boundaries on solid textures and precise\nestimation of the minerals distributions, describing a nearly linear\nrelationship between expected and predicted distributions, with coefficient of\ndetermination (R^2) superior to 0.97 for seen facies and 0.88 for unseen.", "published": "2025-05-22 17:58:34", "link": "http://arxiv.org/abs/2505.17008v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning", "abstract": "Learning latent motion from Internet videos is crucial for building\ngeneralist robots. However, existing discrete latent action methods suffer from\ninformation loss and struggle with complex and fine-grained dynamics. We\npropose CoMo, which aims to learn more informative continuous motion\nrepresentations from diverse, internet-scale videos. CoMo employs a early\ntemporal feature difference mechanism to prevent model collapse and suppress\nstatic appearance noise, effectively discouraging shortcut learning problem.\nFurthermore, guided by the information bottleneck principle, we constrain the\nlatent motion embedding dimensionality to achieve a better balance between\nretaining sufficient action-relevant information and minimizing the inclusion\nof action-irrelevant appearance noise. Additionally, we also introduce two new\nmetrics for more robustly and affordably evaluating motion and guiding motion\nlearning methods development: (i) the linear probing MSE of action prediction,\nand (ii) the cosine similarity between past-to-current and future-to-current\nmotion embeddings. Critically, CoMo exhibits strong zero-shot generalization,\nenabling it to generate continuous pseudo actions for previously unseen video\ndomains. This capability facilitates unified policy joint learning using pseudo\nactions derived from various action-less video datasets (such as\ncross-embodiment videos and, notably, human demonstration videos), potentially\naugmented with limited labeled robot data. Extensive experiments show that\npolicies co-trained with CoMo pseudo actions achieve superior performance with\nboth diffusion and autoregressive architectures in simulated and real-world\nsettings.", "published": "2025-05-22 17:58:27", "link": "http://arxiv.org/abs/2505.17006v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Seeing through Satellite Images at Street Views", "abstract": "This paper studies the task of SatStreet-view synthesis, which aims to render\nphotorealistic street-view panorama images and videos given any satellite image\nand specified camera positions or trajectories. We formulate to learn neural\nradiance field from paired images captured from satellite and street\nviewpoints, which comes to be a challenging learning problem due to the\nsparse-view natural and the extremely-large viewpoint changes between satellite\nand street-view images. We tackle the challenges based on a task-specific\nobservation that street-view specific elements, including the sky and\nillumination effects are only visible in street-view panoramas, and present a\nnovel approach Sat2Density++ to accomplish the goal of photo-realistic\nstreet-view panoramas rendering by modeling these street-view specific in\nneural networks. In the experiments, our method is testified on both urban and\nsuburban scene datasets, demonstrating that Sat2Density++ is capable of\nrendering photorealistic street-view panoramas that are consistent across\nmultiple views and faithful to the satellite image.", "published": "2025-05-22 17:57:32", "link": "http://arxiv.org/abs/2505.17001v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Native Segmentation Vision Transformers", "abstract": "Uniform downsampling remains the de facto standard for reducing spatial\nresolution in vision backbones. In this work, we propose an alternative design\nbuilt around a content-aware spatial grouping layer, that dynamically assigns\ntokens to a reduced set based on image boundaries and their semantic content.\nStacking our grouping layer across consecutive backbone stages results in\nhierarchical segmentation that arises natively in the feature extraction\nprocess, resulting in our coined Native Segmentation Vision Transformer. We\nshow that a careful design of our architecture enables the emergence of strong\nsegmentation masks solely from grouping layers, that is, without additional\nsegmentation-specific heads. This sets the foundation for a new paradigm of\nnative, backbone-level segmentation, which enables strong zero-shot results\nwithout mask supervision, as well as a minimal and efficient standalone model\ndesign for downstream segmentation tasks. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/native-segmentation.", "published": "2025-05-22 17:55:20", "link": "http://arxiv.org/abs/2505.16993v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "An Effective Training Framework for Light-Weight Automatic Speech Recognition Models", "abstract": "Recent advancement in deep learning encouraged developing large automatic\nspeech recognition (ASR) models that achieve promising results while ignoring\ncomputational and memory constraints. However, deploying such models on low\nresource devices is impractical despite of their favorable performance.\nExisting approaches (pruning, distillation, layer skip etc.) transform the\nlarge models into smaller ones at the cost of significant performance\ndegradation or require prolonged training of smaller models for better\nperformance. To address these issues, we introduce an efficacious two-step\nrepresentation learning based approach capable of producing several small sized\nmodels from a single large model ensuring considerably better performance in\nlimited number of epochs. Comprehensive experimentation on ASR benchmarks\nreveals the efficacy of our approach, achieving three-fold training speed-up\nand up to 12.54% word error rate improvement.", "published": "2025-05-22 17:55:09", "link": "http://arxiv.org/abs/2505.16991v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding", "abstract": "In this work, we propose Dimple, the first Discrete Diffusion Multimodal\nLarge Language Model (DMLLM). We observe that training with a purely discrete\ndiffusion approach leads to significant training instability, suboptimal\nperformance, and severe length bias issues. To address these challenges, we\ndesign a novel training paradigm that combines an initial autoregressive phase\nwith a subsequent diffusion phase. This approach yields the Dimple-7B model,\ntrained on the same dataset and using a similar training pipeline as\nLLaVA-NEXT. Dimple-7B ultimately surpasses LLaVA-NEXT in performance by 3.9%,\ndemonstrating that DMLLM can achieve performance comparable to that of\nautoregressive models. To improve inference efficiency, we propose a decoding\nstrategy termed confident decoding, which dynamically adjusts the number of\ntokens generated at each step, significantly reducing the number of generation\niterations. In autoregressive models, the number of forward iterations during\ngeneration equals the response length. With confident decoding, however, the\nnumber of iterations needed by Dimple is even only $\\frac{\\text{response\nlength}}{3}$. We also re-implement the prefilling technique in autoregressive\nmodels and demonstrate that it does not significantly impact performance on\nmost benchmark evaluations, while offering a speedup of 1.5x to 7x.\nAdditionally, we explore Dimple's capability to precisely control its response\nusing structure priors. These priors enable structured responses in a manner\ndistinct from instruction-based or chain-of-thought prompting, and allow\nfine-grained control over response format and length, which is difficult to\nachieve in autoregressive models. Overall, this work validates the feasibility\nand advantages of DMLLM and enhances its inference efficiency and\ncontrollability. Code and models are available at\nhttps://github.com/yu-rp/Dimple.", "published": "2025-05-22 17:55:04", "link": "http://arxiv.org/abs/2505.16990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction", "abstract": "Video virtual try-on aims to seamlessly dress a subject in a video with a\nspecific garment. The primary challenge involves preserving the visual\nauthenticity of the garment while dynamically adapting to the pose and physique\nof the subject. While existing methods have predominantly focused on\nimage-based virtual try-on, extending these techniques directly to videos often\nresults in temporal inconsistencies. Most current video virtual try-on\napproaches alleviate this challenge by incorporating temporal modules, yet\nstill overlook the critical spatiotemporal pose interactions between human and\ngarment. Effective pose interactions in videos should not only consider spatial\nalignment between human and garment poses in each frame but also account for\nthe temporal dynamics of human poses throughout the entire video. With such\nmotivation, we propose a new framework, namely Dynamic Pose Interaction\nDiffusion Models (DPIDM), to leverage diffusion models to delve into dynamic\npose interactions for video virtual try-on. Technically, DPIDM introduces a\nskeleton-based pose adapter to integrate synchronized human and garment poses\ninto the denoising network. A hierarchical attention module is then exquisitely\ndesigned to model intra-frame human-garment pose interactions and long-term\nhuman pose dynamics across frames through pose-aware spatial and temporal\nattention mechanisms. Moreover, DPIDM capitalizes on a temporal regularized\nattention loss between consecutive frames to enhance temporal consistency.\nExtensive experiments conducted on VITON-HD, VVT and ViViD datasets demonstrate\nthe superiority of our DPIDM against the baseline methods. Notably, DPIDM\nachieves VFID score of 0.506 on VVT dataset, leading to 60.5% improvement over\nthe state-of-the-art GPD-VVTO approach.", "published": "2025-05-22 17:52:34", "link": "http://arxiv.org/abs/2505.16980v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On", "abstract": "Diffusion models have shown preliminary success in virtual try-on (VTON)\ntask. The typical dual-branch architecture comprises two UNets for implicit\ngarment deformation and synthesized image generation respectively, and has\nemerged as the recipe for VTON task. Nevertheless, the problem remains\nchallenging to preserve the shape and every detail of the given garment due to\nthe intrinsic stochasticity of diffusion model. To alleviate this issue, we\nnovelly propose to explicitly capitalize on visual correspondence as the prior\nto tame diffusion process instead of simply feeding the whole garment into UNet\nas the appearance reference. Specifically, we interpret the fine-grained\nappearance and texture details as a set of structured semantic points, and\nmatch the semantic points rooted in garment to the ones over target person\nthrough local flow warping. Such 2D points are then augmented into 3D-aware\ncues with depth/normal map of target person. The correspondence mimics the way\nof putting clothing on human body and the 3D-aware cues act as semantic point\nmatching to supervise diffusion model training. A point-focused diffusion loss\nis further devised to fully take the advantage of semantic point matching.\nExtensive experiments demonstrate strong garment detail preservation of our\napproach, evidenced by state-of-the-art VTON performances on both VITON-HD and\nDressCode datasets. Code is publicly available at:\nhttps://github.com/HiDream-ai/SPM-Diff.", "published": "2025-05-22 17:52:13", "link": "http://arxiv.org/abs/2505.16977v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Creatively Upscaling Images with Global-Regional Priors", "abstract": "Contemporary diffusion models show remarkable capability in text-to-image\ngeneration, while still being limited to restricted resolutions (e.g., 1,024 X\n1,024). Recent advances enable tuning-free higher-resolution image generation\nby recycling pre-trained diffusion models and extending them via regional\ndenoising or dilated sampling/convolutions. However, these models struggle to\nsimultaneously preserve global semantic structure and produce creative regional\ndetails in higher-resolution images. To address this, we present C-Upscale, a\nnew recipe of tuning-free image upscaling that pivots on global-regional priors\nderived from given global prompt and estimated regional prompts via Multimodal\nLLM. Technically, the low-frequency component of low-resolution image is\nrecognized as global structure prior to encourage global semantic consistency\nin high-resolution generation. Next, we perform regional attention control to\nscreen cross-attention between global prompt and each region during regional\ndenoising, leading to regional attention prior that alleviates object\nrepetition issue. The estimated regional prompts containing rich descriptive\ndetails further act as regional semantic prior to fuel the creativity of\nregional detail generation. Both quantitative and qualitative evaluations\ndemonstrate that our C-Upscale manages to generate ultra-high-resolution images\n(e.g., 4,096 X 4,096 and 8,192 X 8,192) with higher visual fidelity and more\ncreative regional details.", "published": "2025-05-22 17:51:50", "link": "http://arxiv.org/abs/2505.16976v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning", "abstract": "Open-Vocabulary Segmentation (OVS) has drawn increasing attention for its\ncapacity to generalize segmentation beyond predefined categories. However,\nexisting methods typically predict segmentation masks with simple forward\ninference, lacking explicit reasoning and interpretability. This makes it\nchallenging for OVS model to distinguish similar categories in open-world\nsettings due to the lack of contextual understanding and discriminative visual\ncues. To address this limitation, we propose a step-by-step visual reasoning\nframework for open-vocabulary segmentation, named OpenSeg-R. The proposed\nOpenSeg-R leverages Large Multimodal Models (LMMs) to perform hierarchical\nvisual reasoning before segmentation. Specifically, we generate both generic\nand image-specific reasoning for each image, forming structured triplets that\nexplain the visual reason for objects in a coarse-to-fine manner. Based on\nthese reasoning steps, we can compose detailed description prompts, and feed\nthem to the segmentor to produce more accurate segmentation masks. To the best\nof our knowledge, OpenSeg-R is the first framework to introduce explicit\nstep-by-step visual reasoning into OVS. Experimental results demonstrate that\nOpenSeg-R significantly outperforms state-of-the-art methods on open-vocabulary\nsemantic segmentation across five benchmark datasets. Moreover, it achieves\nconsistent gains across all metrics on open-vocabulary panoptic segmentation.\nQualitative results further highlight the effectiveness of our reasoning-guided\nframework in improving both segmentation precision and interpretability. Our\ncode is publicly available at https://github.com/Hanzy1996/OpenSeg-R.", "published": "2025-05-22 17:51:48", "link": "http://arxiv.org/abs/2505.16974v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation", "abstract": "We propose UniPhy, a common latent-conditioned neural constitutive model that\ncan encode the physical properties of diverse materials. At inference UniPhy\nallows `inverse simulation' i.e. inferring material properties by optimizing\nthe scene-specific latent to match the available observations via\ndifferentiable simulation. In contrast to existing methods that treat such\ninference as system identification, UniPhy does not rely on user-specified\nmaterial type information. Compared to prior neural constitutive modeling\napproaches which learn instance specific networks, the shared training across\nmaterials improves both, robustness and accuracy of the estimates. We train\nUniPhy using simulated trajectories across diverse geometries and materials --\nelastic, plasticine, sand, and fluids (Newtonian & non-Newtonian). At\ninference, given an object with unknown material properties, UniPhy can infer\nthe material properties via latent optimization to match the motion\nobservations, and can then allow re-simulating the object under diverse\nscenarios. We compare UniPhy against prior inverse simulation methods, and show\nthat the inference from UniPhy enables more accurate replay and re-simulation\nunder novel conditions.", "published": "2025-05-22 17:50:52", "link": "http://arxiv.org/abs/2505.16971v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Correlation Volume Sampling for Ultra-High-Resolution Optical Flow Estimation", "abstract": "Recent optical flow estimation methods often employ local cost sampling from\na dense all-pairs correlation volume. This results in quadratic computational\nand memory complexity in the number of pixels. Although an alternative\nmemory-efficient implementation with on-demand cost computation exists, this is\nslower in practice and therefore prior methods typically process images at\nreduced resolutions, missing fine-grained details.\n  To address this, we propose a more efficient implementation of the all-pairs\ncorrelation volume sampling, still matching the exact mathematical operator as\ndefined by RAFT. Our approach outperforms on-demand sampling by up to 90% while\nmaintaining low memory usage, and performs on par with the default\nimplementation with up to 95% lower memory usage. As cost sampling makes up a\nsignificant portion of the overall runtime, this can translate to up to 50%\nsavings for the total end-to-end model inference in memory-constrained\nenvironments. Our evaluation of existing methods includes an 8K\nultra-high-resolution dataset and an additional inference-time modification of\nthe recent SEA-RAFT method. With this, we achieve state-of-the-art results at\nhigh resolutions both in accuracy and efficiency.", "published": "2025-05-22 17:30:38", "link": "http://arxiv.org/abs/2505.16942v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Backdoor Cleaning without External Guidance in MLLM Fine-tuning", "abstract": "Multimodal Large Language Models (MLLMs) are increasingly deployed in\nfine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt\ngeneral-purpose models to downstream tasks. This flexibility, however,\nintroduces serious security risks, as malicious fine-tuning can implant\nbackdoors into MLLMs with minimal effort. In this paper, we observe that\nbackdoor triggers systematically disrupt cross-modal processing by causing\nabnormal attention concentration on non-semantic regions--a phenomenon we term\nattention collapse. Based on this insight, we propose Believe Your Eyes (BYE),\na data filtering framework that leverages attention entropy patterns as\nself-supervised signals to identify and filter backdoor samples. BYE operates\nvia a three-stage pipeline: (1) extracting attention maps using the fine-tuned\nmodel, (2) computing entropy scores and profiling sensitive layers via bimodal\nseparation, and (3) performing unsupervised clustering to remove suspicious\nsamples. Unlike prior defenses, BYE equires no clean supervision, auxiliary\nlabels, or model modifications. Extensive experiments across various datasets,\nmodels, and diverse trigger types validate BYE's effectiveness: it achieves\nnear-zero attack success rates while maintaining clean-task performance,\noffering a robust and generalizable solution against backdoor threats in MLLMs.", "published": "2025-05-22 17:11:58", "link": "http://arxiv.org/abs/2505.16916v1", "categories": ["cs.CR", "cs.CV"], "primary_category": "cs.CR"}
{"title": "RealEngine: Simulating Autonomous Driving in Realistic Context", "abstract": "Driving simulation plays a crucial role in developing reliable driving agents\nby providing controlled, evaluative environments. To enable meaningful\nassessments, a high-quality driving simulator must satisfy several key\nrequirements: multi-modal sensing capabilities (e.g., camera and LiDAR) with\nrealistic scene rendering to minimize observational discrepancies; closed-loop\nevaluation to support free-form trajectory behaviors; highly diverse traffic\nscenarios for thorough evaluation; multi-agent cooperation to capture\ninteraction dynamics; and high computational efficiency to ensure affordability\nand scalability. However, existing simulators and benchmarks fail to\ncomprehensively meet these fundamental criteria. To bridge this gap, this paper\nintroduces RealEngine, a novel driving simulation framework that holistically\nintegrates 3D scene reconstruction and novel view synthesis techniques to\nachieve realistic and flexible closed-loop simulation in the driving context.\nBy leveraging real-world multi-modal sensor data, RealEngine reconstructs\nbackground scenes and foreground traffic participants separately, allowing for\nhighly diverse and realistic traffic scenarios through flexible scene\ncomposition. This synergistic fusion of scene reconstruction and view synthesis\nenables photorealistic rendering across multiple sensor modalities, ensuring\nboth perceptual fidelity and geometric accuracy. Building upon this\nenvironment, RealEngine supports three essential driving simulation categories:\nnon-reactive simulation, safety testing, and multi-agent interaction,\ncollectively forming a reliable and comprehensive benchmark for evaluating the\nreal-world performance of driving agents.", "published": "2025-05-22 17:01:00", "link": "http://arxiv.org/abs/2505.16902v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)", "abstract": "Ethological research increasingly benefits from the growing affordability and\naccessibility of drones, which enable the capture of high-resolution footage of\nanimal movement at fine spatial and temporal scales. However, analyzing such\nfootage presents the technical challenge of separating animal movement from\ndrone motion. While non-trivial, computer vision techniques such as image\nregistration and Structure-from-Motion (SfM) offer practical solutions. For\nconservationists, open-source tools that are user-friendly, require minimal\nsetup, and deliver timely results are especially valuable for efficient data\ninterpretation. This study evaluates three approaches: a bioimaging-based\nregistration technique, an SfM pipeline, and a hybrid interpolation method. We\napply these to a recorded escape event involving 44 plains zebras, captured in\na single drone video. Using the best-performing method, we extract individual\ntrajectories and identify key behavioral patterns: increased alignment\n(polarization) during escape, a brief widening of spacing just before stopping,\nand tighter coordination near the group's center. These insights highlight the\nmethod's effectiveness and its potential to scale to larger datasets,\ncontributing to broader investigations of collective animal behavior.", "published": "2025-05-22 16:36:52", "link": "http://arxiv.org/abs/2505.16882v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Training-Free Efficient Video Generation via Dynamic Token Carving", "abstract": "Despite the remarkable generation quality of video Diffusion Transformer\n(DiT) models, their practical deployment is severely hindered by extensive\ncomputational requirements. This inefficiency stems from two key challenges:\nthe quadratic complexity of self-attention with respect to token length and the\nmulti-step nature of diffusion models. To address these limitations, we present\nJenga, a novel inference pipeline that combines dynamic attention carving with\nprogressive resolution generation. Our approach leverages two key insights: (1)\nearly denoising steps do not require high-resolution latents, and (2) later\nsteps do not require dense attention. Jenga introduces a block-wise attention\nmechanism that dynamically selects relevant token interactions using 3D\nspace-filling curves, alongside a progressive resolution strategy that\ngradually increases latent resolution during generation. Experimental results\ndemonstrate that Jenga achieves substantial speedups across multiple\nstate-of-the-art video diffusion models while maintaining comparable generation\nquality (8.83$\\times$ speedup with 0.01\\% performance drop on VBench). As a\nplug-and-play solution, Jenga enables practical, high-quality video generation\non modern hardware by reducing inference time from minutes to seconds --\nwithout requiring model retraining. Code:\nhttps://github.com/dvlab-research/Jenga", "published": "2025-05-22 16:21:32", "link": "http://arxiv.org/abs/2505.16864v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Conditional Panoramic Image Generation via Masked Autoregressive Modeling", "abstract": "Recent progress in panoramic image generation has underscored two critical\nlimitations in existing approaches. First, most methods are built upon\ndiffusion models, which are inherently ill-suited for equirectangular\nprojection (ERP) panoramas due to the violation of the identically and\nindependently distributed (i.i.d.) Gaussian noise assumption caused by their\nspherical mapping. Second, these methods often treat text-conditioned\ngeneration (text-to-panorama) and image-conditioned generation (panorama\noutpainting) as separate tasks, relying on distinct architectures and\ntask-specific data. In this work, we propose a unified framework, Panoramic\nAutoRegressive model (PAR), which leverages masked autoregressive modeling to\naddress these challenges. PAR avoids the i.i.d. assumption constraint and\nintegrates text and image conditioning into a cohesive architecture, enabling\nseamless generation across tasks. To address the inherent discontinuity in\nexisting generative models, we introduce circular padding to enhance spatial\ncoherence and propose a consistency alignment strategy to improve generation\nquality. Extensive experiments demonstrate competitive performance in\ntext-to-image generation and panorama outpainting tasks while showcasing\npromising scalability and generalization capabilities.", "published": "2025-05-22 16:20:12", "link": "http://arxiv.org/abs/2505.16862v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LaViDa: A Large Diffusion Language Model for Multimodal Understanding", "abstract": "Modern Vision-Language Models (VLMs) can solve a wide range of tasks\nrequiring visual reasoning. In real-world scenarios, desirable properties for\nVLMs include fast inference and controllable generation (e.g., constraining\noutputs to adhere to a desired format). However, existing autoregressive (AR)\nVLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs)\noffer a promising alternative, enabling parallel decoding for faster inference\nand bidirectional context for controllable generation through text-infilling.\nWhile effective in language-only settings, DMs' potential for multimodal tasks\nis underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build\nLaViDa by equipping DMs with a vision encoder and jointly fine-tune the\ncombined parts for multimodal instruction following. To address challenges\nencountered, LaViDa incorporates novel techniques such as complementary masking\nfor effective training, prefix KV cache for efficient inference, and timestep\nshifting for high-quality sampling. Experiments show that LaViDa achieves\ncompetitive or superior performance to AR VLMs on multi-modal benchmarks such\nas MMMU, while offering unique advantages of DMs, including flexible\nspeed-quality tradeoff, controllability, and bidirectional reasoning. On COCO\ncaptioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x\nspeedup. On bidirectional tasks, it achieves +59% improvement on Constrained\nPoem Completion. These results demonstrate LaViDa as a strong alternative to AR\nVLMs. Code and models will be released in the camera-ready version.", "published": "2025-05-22 16:07:12", "link": "http://arxiv.org/abs/2505.16839v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts", "abstract": "Recent advances in scene-based video generation have enabled systems to\nsynthesize coherent visual narratives from structured prompts. However, a\ncrucial dimension of storytelling -- character-driven dialogue and speech --\nremains underexplored. In this paper, we present a modular pipeline that\ntransforms action-level prompts into visually and auditorily grounded narrative\ndialogue, enriching visual storytelling with natural voice and character\nexpression. Our method takes as input a pair of prompts per scene, where the\nfirst defines the setting and the second specifies a character's behavior.\nWhile a story generation model such as Text2Story generates the corresponding\nvisual scene, we focus on generating expressive character utterances from these\nprompts and the scene image. We apply a pretrained vision-language encoder to\nextract a high-level semantic feature from the representative frame, capturing\nsalient visual context. This feature is then combined with the structured\nprompts and used to guide a large language model in synthesizing natural,\ncharacter-consistent dialogue. To ensure contextual consistency across scenes,\nwe introduce a Recursive Narrative Bank that conditions each dialogue\ngeneration on the accumulated dialogue history from prior scenes. This approach\nenables characters to speak in ways that reflect their evolving goals and\ninteractions throughout a story. Finally, we render each utterance as\nexpressive, character-consistent speech, resulting in fully-voiced video\nnarratives. Our framework requires no additional training and demonstrates\napplicability across a variety of story settings, from fantasy adventures to\nslice-of-life episodes.", "published": "2025-05-22 15:54:42", "link": "http://arxiv.org/abs/2505.16819v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Perceptual Quality Assessment for Embodied AI", "abstract": "Embodied AI has developed rapidly in recent years, but it is still mainly\ndeployed in laboratories, with various distortions in the Real-world limiting\nits application. Traditionally, Image Quality Assessment (IQA) methods are\napplied to predict human preferences for distorted images; however, there is no\nIQA method to assess the usability of an image in embodied tasks, namely, the\nperceptual quality for robots. To provide accurate and reliable quality\nindicators for future embodied scenarios, we first propose the topic: IQA for\nEmbodied AI. Specifically, we (1) based on the Mertonian system and\nmeta-cognitive theory, constructed a perception-cognition-decision-execution\npipeline and defined a comprehensive subjective score collection process; (2)\nestablished the Embodied-IQA database, containing over 36k reference/distorted\nimage pairs, with more than 5m fine-grained annotations provided by Vision\nLanguage Models/Vision Language Action-models/Real-world robots; (3) trained\nand validated the performance of mainstream IQA methods on Embodied-IQA,\ndemonstrating the need to develop more accurate quality indicators for Embodied\nAI. We sincerely hope that through evaluation, we can promote the application\nof Embodied AI under complex distortions in the Real-world. Project page:\nhttps://github.com/lcysyzxdxc/EmbodiedIQA", "published": "2025-05-22 15:51:07", "link": "http://arxiv.org/abs/2505.16815v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining", "abstract": "Significant progress has been made in video restoration under rainy\nconditions over the past decade, largely propelled by advancements in deep\nlearning. Nevertheless, existing methods that depend on paired data struggle to\ngeneralize effectively to real-world scenarios, primarily due to the disparity\nbetween synthetic and authentic rain effects. To address these limitations, we\npropose a dual-branch spatio-temporal state-space model to enhance rain streak\nremoval in video sequences. Specifically, we design spatial and temporal\nstate-space model layers to extract spatial features and incorporate temporal\ndependencies across frames, respectively. To improve multi-frame feature\nfusion, we derive a dynamic stacking filter, which adaptively approximates\nstatistical filters for superior pixel-wise feature refinement. Moreover, we\ndevelop a median stacking loss to enable semi-supervised learning by generating\npseudo-clean patches based on the sparsity prior of rain. To further explore\nthe capacity of deraining models in supporting other vision-based tasks in\nrainy environments, we introduce a novel real-world benchmark focused on object\ndetection and tracking in rainy conditions. Our method is extensively evaluated\nacross multiple benchmarks containing numerous synthetic and real-world rainy\nvideos, consistently demonstrating its superiority in quantitative metrics,\nvisual quality, efficiency, and its utility for downstream tasks.", "published": "2025-05-22 15:50:00", "link": "http://arxiv.org/abs/2505.16811v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities", "abstract": "Existing methods for multimodal MRI segmentation with missing modalities\ntypically assume that all MRI modalities are available during training.\nHowever, in clinical practice, some modalities may be missing due to the\nsequential nature of MRI acquisition, leading to performance degradation.\nFurthermore, retraining models to accommodate newly available modalities can be\ninefficient and may cause overfitting, potentially compromising previously\nlearned knowledge. To address these challenges, we propose Replay-based\nHypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation\nwith missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to\nenable the segmentation model to learn from newly acquired MRI modalities\nwithout forgetting previously learned information. To enhance segmentation\nperformance across diverse patient scenarios, we introduce the Cross-Patient\nHypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture\nhigh-order associations between patients. Additionally, we incorporate\nTversky-Aware Contrastive (TAC) loss to effectively mitigate information\nimbalance both across and within different modalities. Extensive experiments on\nthe BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art\nmethods, achieving an improvement of over 2\\% in the Dice Similarity\nCoefficient across various tumor regions. Our code is available at ReHyDIL.", "published": "2025-05-22 15:49:25", "link": "http://arxiv.org/abs/2505.16809v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving", "abstract": "The integration of Vision-Language Models (VLMs) into autonomous driving\nsystems has shown promise in addressing key challenges such as learning\ncomplexity, interpretability, and common-sense reasoning. However, existing\napproaches often struggle with efficient integration and realtime\ndecision-making due to computational demands. In this paper, we introduce\nSOLVE, an innovative framework that synergizes VLMs with end-to-end (E2E)\nmodels to enhance autonomous vehicle planning. Our approach emphasizes\nknowledge sharing at the feature level through a shared visual encoder,\nenabling comprehensive interaction between VLM and E2E components. We propose a\nTrajectory Chain-of-Thought (T-CoT) paradigm, which progressively refines\ntrajectory predictions, reducing uncertainty and improving accuracy. By\nemploying a temporal decoupling strategy, SOLVE achieves efficient cooperation\nby aligning high-quality VLM outputs with E2E real-time performance. Evaluated\non the nuScenes dataset, our method demonstrates significant improvements in\ntrajectory prediction accuracy, paving the way for more robust and reliable\nautonomous driving systems.", "published": "2025-05-22 15:44:30", "link": "http://arxiv.org/abs/2505.16805v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "V2V: Scaling Event-Based Vision through Efficient Video-to-Voxel Simulation", "abstract": "Event-based cameras offer unique advantages such as high temporal resolution,\nhigh dynamic range, and low power consumption. However, the massive storage\nrequirements and I/O burdens of existing synthetic data generation pipelines\nand the scarcity of real data prevent event-based training datasets from\nscaling up, limiting the development and generalization capabilities of event\nvision models. To address this challenge, we introduce Video-to-Voxel (V2V), an\napproach that directly converts conventional video frames into event-based\nvoxel grid representations, bypassing the storage-intensive event stream\ngeneration entirely. V2V enables a 150 times reduction in storage requirements\nwhile supporting on-the-fly parameter randomization for enhanced model\nrobustness. Leveraging this efficiency, we train several video reconstruction\nand optical flow estimation model architectures on 10,000 diverse videos\ntotaling 52 hours--an order of magnitude larger than existing event datasets,\nyielding substantial improvements.", "published": "2025-05-22 15:38:12", "link": "http://arxiv.org/abs/2505.16797v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "REOBench: Benchmarking Robustness of Earth Observation Foundation Models", "abstract": "Earth observation foundation models have shown strong generalization across\nmultiple Earth observation tasks, but their robustness under real-world\nperturbations remains underexplored. To bridge this gap, we introduce REOBench,\nthe first comprehensive benchmark for evaluating the robustness of Earth\nobservation foundation models across six tasks and twelve types of image\ncorruptions, including both appearance-based and geometric perturbations. To\nensure realistic and fine-grained evaluation, our benchmark focuses on\nhigh-resolution optical remote sensing images, which are widely used in\ncritical applications such as urban planning and disaster response. We conduct\na systematic evaluation of a broad range of models trained using masked image\nmodeling, contrastive learning, and vision-language pre-training paradigms. Our\nresults reveal that (1) existing Earth observation foundation models experience\nsignificant performance degradation when exposed to input corruptions. (2) The\nseverity of degradation varies across tasks, model architectures, backbone\nsizes, and types of corruption, with performance drop varying from less than 1%\nto over 20%. (3) Vision-language models show enhanced robustness, particularly\nin multimodal tasks. REOBench underscores the vulnerability of current Earth\nobservation foundation models to real-world corruptions and provides actionable\ninsights for developing more robust and reliable models.", "published": "2025-05-22 15:34:50", "link": "http://arxiv.org/abs/2505.16793v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles", "abstract": "In this paper, we present the runner-up solution for the Ego4D EgoSchema\nChallenge at CVPR 2025 (Confirmed on May 20, 2025). Inspired by the success of\nlarge models, we evaluate and leverage leading accessible multimodal large\nmodels and adapt them to video understanding tasks via few-shot learning and\nmodel ensemble strategies. Specifically, diversified prompt styles and process\nparadigms are systematically explored and evaluated to effectively guide the\nattention of large models, fully unleashing their powerful generalization and\nadaptability abilities. Experimental results demonstrate that, with our\ncarefully designed approach, directly utilizing an individual multimodal model\nalready outperforms the previous state-of-the-art (SOTA) method which includes\nseveral additional processes. Besides, an additional stage is further\nintroduced that facilitates the cooperation and ensemble of periodic results,\nwhich achieves impressive performance improvements. We hope this work serves as\na valuable reference for the practical application of large models and inspires\nfuture research in the field.", "published": "2025-05-22 15:27:31", "link": "http://arxiv.org/abs/2505.16784v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Single Domain Generalization for Few-Shot Counting via Universal Representation Matching", "abstract": "Few-shot counting estimates the number of target objects in an image using\nonly a few annotated exemplars. However, domain shift severely hinders existing\nmethods to generalize to unseen scenarios. This falls into the realm of single\ndomain generalization that remains unexplored in few-shot counting. To solve\nthis problem, we begin by analyzing the main limitations of current methods,\nwhich typically follow a standard pipeline that extract the object prototypes\nfrom exemplars and then match them with image feature to construct the\ncorrelation map. We argue that existing methods overlook the significance of\nlearning highly generalized prototypes. Building on this insight, we propose\nthe first single domain generalization few-shot counting model, Universal\nRepresentation Matching, termed URM. Our primary contribution is the discovery\nthat incorporating universal vision-language representations distilled from a\nlarge scale pretrained vision-language model into the correlation construction\nprocess substantially improves robustness to domain shifts without compromising\nin domain performance. As a result, URM achieves state-of-the-art performance\non both in domain and the newly introduced domain generalization setting.", "published": "2025-05-22 15:20:39", "link": "http://arxiv.org/abs/2505.16778v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs", "abstract": "The rapid advancement of native multi-modal models and omni-models,\nexemplified by GPT-4o, Gemini, and o3, with their capability to process and\ngenerate content across modalities such as text and images, marks a significant\nmilestone in the evolution of intelligence. Systematic evaluation of their\nmulti-modal output capabilities in visual thinking processes (also known as\nmulti-modal chain of thought, M-CoT) becomes critically important. However,\nexisting benchmarks for evaluating multi-modal models primarily focus on\nassessing multi-modal inputs and text-only reasoning while neglecting the\nimportance of reasoning through multi-modal outputs. In this paper, we present\na benchmark, dubbed RBench-V, designed to assess models' vision-indispensable\nreasoning abilities. To construct RBench-V, we carefully hand-pick 803\nquestions covering math, physics, counting, and games. Unlike previous\nbenchmarks that typically specify certain input modalities, RBench-V presents\nproblems centered on multi-modal outputs, which require image manipulation such\nas generating novel images and constructing auxiliary lines to support the\nreasoning process. We evaluate numerous open- and closed-source models on\nRBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the\nbest-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below\nthe human score of 82.3%, highlighting that current models struggle to leverage\nmulti-modal reasoning. Data and code are available at\nhttps://evalmodels.github.io/rbenchv", "published": "2025-05-22 15:11:57", "link": "http://arxiv.org/abs/2505.16770v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation", "abstract": "Text-to-image models are powerful for producing high-quality images based on\ngiven text prompts, but crafting these prompts often requires specialized\nvocabulary. To address this, existing methods train rewriting models with\nsupervision from large amounts of manually annotated data and trained aesthetic\nassessment models. To alleviate the dependence on data scale for model training\nand the biases introduced by trained models, we propose a novel prompt\noptimization framework, designed to rephrase a simple user prompt into a\nsophisticated prompt to a text-to-image model. Specifically, we employ the\nlarge vision language models (LVLMs) as the solver to rewrite the user prompt,\nand concurrently, employ LVLMs as a reward model to score the aesthetics and\nalignment of the images generated by the optimized prompt. Instead of laborious\nhuman feedback, we exploit the prior knowledge of the LVLM to provide rewards,\ni.e., AI feedback. Simultaneously, the solver and the reward model are unified\ninto one model and iterated in reinforcement learning to achieve\nself-improvement by giving a solution and judging itself. Results on two\npopular datasets demonstrate that our method outperforms other strong\ncompetitors.", "published": "2025-05-22 15:05:07", "link": "http://arxiv.org/abs/2505.16763v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning", "abstract": "Existing pretrained models for 3D mesh generation often suffer from data\nbiases and produce low-quality results, while global reinforcement learning\n(RL) methods rely on object-level rewards that struggle to capture local\nstructure details. To address these challenges, we present \\textbf{Mesh-RFT}, a\nnovel fine-grained reinforcement fine-tuning framework that employs Masked\nDirect Preference Optimization (M-DPO) to enable localized refinement via\nquality-aware face masking. To facilitate efficient quality evaluation, we\nintroduce an objective topology-aware scoring system to evaluate geometric\nintegrity and topological regularity at both object and face levels through two\nmetrics: Boundary Edge Ratio (BER) and Topology Score (TS). By integrating\nthese metrics into a fine-grained RL strategy, Mesh-RFT becomes the first\nmethod to optimize mesh quality at the granularity of individual faces,\nresolving localized errors while preserving global coherence. Experiment\nresults show that our M-DPO approach reduces Hausdorff Distance (HD) by 24.6\\%\nand improves Topology Score (TS) by 3.8\\% over pre-trained models, while\noutperforming global DPO methods with a 17.4\\% HD reduction and 4.9\\% TS gain.\nThese results demonstrate Mesh-RFT's ability to improve geometric integrity and\ntopological regularity, achieving new state-of-the-art performance in\nproduction-ready mesh generation. Project Page:\n\\href{https://hitcslj.github.io/mesh-rft/}{this https URL}.", "published": "2025-05-22 15:04:18", "link": "http://arxiv.org/abs/2505.16761v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Representation Discrepancy Bridging Method for Remote Sensing Image-Text Retrieval", "abstract": "Remote Sensing Image-Text Retrieval (RSITR) plays a critical role in\ngeographic information interpretation, disaster monitoring, and urban planning\nby establishing semantic associations between image and textual descriptions.\nExisting Parameter-Efficient Fine-Tuning (PEFT) methods for Vision-and-Language\nPre-training (VLP) models typically adopt symmetric adapter structures for\nexploring cross-modal correlations. However, the strong discriminative nature\nof text modality may dominate the optimization process and inhibits image\nrepresentation learning. The nonnegligible imbalanced cross-modal optimization\nremains a bottleneck to enhancing the model performance. To address this issue,\nthis study proposes a Representation Discrepancy Bridging (RDB) method for the\nRSITR task. On the one hand, a Cross-Modal Asymmetric Adapter (CMAA) is\ndesigned to enable modality-specific optimization and improve feature\nalignment. The CMAA comprises a Visual Enhancement Adapter (VEA) and a Text\nSemantic Adapter (TSA). VEA mines fine-grained image features by Differential\nAttention (DA) mechanism, while TSA identifies key textual semantics through\nHierarchical Attention (HA) mechanism. On the other hand, this study extends\nthe traditional single-task retrieval framework to a dual-task optimization\nframework and develops a Dual-Task Consistency Loss (DTCL). The DTCL improves\ncross-modal alignment robustness through an adaptive weighted combination of\ncross-modal, classification, and exponential moving average consistency\nconstraints. Experiments on RSICD and RSITMD datasets show that the proposed\nRDB method achieves a 6%-11% improvement in mR metrics compared to\nstate-of-the-art PEFT methods and a 1.15%-2% improvement over the full\nfine-tuned GeoRSCLIP model.", "published": "2025-05-22 14:59:30", "link": "http://arxiv.org/abs/2505.16756v1", "categories": ["cs.CV", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Masked Conditioning for Deep Generative Models", "abstract": "Datasets in engineering domains are often small, sparsely labeled, and\ncontain numerical as well as categorical conditions. Additionally.\ncomputational resources are typically limited in practical applications which\nhinders the adoption of generative models for engineering tasks. We introduce a\nnovel masked-conditioning approach, that enables generative models to work with\nsparse, mixed-type data. We mask conditions during training to simulate sparse\nconditions at inference time. For this purpose, we explore the use of various\nsparsity schedules that show different strengths and weaknesses. In addition,\nwe introduce a flexible embedding that deals with categorical as well as\nnumerical conditions. We integrate our method into an efficient variational\nautoencoder as well as a latent diffusion model and demonstrate the\napplicability of our approach on two engineering-related datasets of 2D point\nclouds and images. Finally, we show that small models trained on limited data\ncan be coupled with large pretrained foundation models to improve generation\nquality while retaining the controllability induced by our conditioning scheme.", "published": "2025-05-22 14:33:03", "link": "http://arxiv.org/abs/2505.16725v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SEDD-PCC: A Single Encoder-Dual Decoder Framework For End-To-End Learned Point Cloud Compression", "abstract": "To encode point clouds containing both geometry and attributes, most\nlearning-based compression schemes treat geometry and attribute coding\nseparately, employing distinct encoders and decoders. This not only increases\ncomputational complexity but also fails to fully exploit shared features\nbetween geometry and attributes. To address this limitation, we propose\nSEDD-PCC, an end-to-end learning-based framework for lossy point cloud\ncompression that jointly compresses geometry and attributes. SEDD-PCC employs a\nsingle encoder to extract shared geometric and attribute features into a\nunified latent space, followed by dual specialized decoders that sequentially\nreconstruct geometry and attributes. Additionally, we incorporate knowledge\ndistillation to enhance feature representation learning from a teacher model,\nfurther improving coding efficiency. With its simple yet effective design,\nSEDD-PCC provides an efficient and practical solution for point cloud\ncompression. Comparative evaluations against both rule-based and learning-based\nmethods demonstrate its competitive performance, highlighting SEDD-PCC as a\npromising AI-driven compression approach.", "published": "2025-05-22 14:11:24", "link": "http://arxiv.org/abs/2505.16709v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models", "abstract": "Recent advances in multi-modal generative models have enabled significant\nprogress in instruction-based image editing. However, while these models\nproduce visually plausible outputs, their capacity for knowledge-based\nreasoning editing tasks remains under-explored. In this paper, we introduce\nKRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a\ndiagnostic benchmark designed to assess models through a cognitively informed\nlens. Drawing from educational theory, KRIS-Bench categorizes editing tasks\nacross three foundational knowledge types: Factual, Conceptual, and Procedural.\nBased on this taxonomy, we design 22 representative tasks spanning 7 reasoning\ndimensions and release 1,267 high-quality annotated editing instances. To\nsupport fine-grained evaluation, we propose a comprehensive protocol that\nincorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints\nand calibrated through human studies. Empirical results on 10 state-of-the-art\nmodels reveal significant gaps in reasoning performance, highlighting the need\nfor knowledge-centric benchmarks to advance the development of intelligent\nimage editing systems.", "published": "2025-05-22 14:08:59", "link": "http://arxiv.org/abs/2505.16707v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "One-Step Diffusion-Based Image Compression with Semantic Distillation", "abstract": "While recent diffusion-based generative image codecs have shown impressive\nperformance, their iterative sampling process introduces unpleasing latency. In\nthis work, we revisit the design of a diffusion-based codec and argue that\nmulti-step sampling is not necessary for generative compression. Based on this\ninsight, we propose OneDC, a One-step Diffusion-based generative image Codec --\nthat integrates a latent compression module with a one-step diffusion\ngenerator. Recognizing the critical role of semantic guidance in one-step\ndiffusion, we propose using the hyperprior as a semantic signal, overcoming the\nlimitations of text prompts in representing complex visual content. To further\nenhance the semantic capability of the hyperprior, we introduce a semantic\ndistillation mechanism that transfers knowledge from a pretrained generative\ntokenizer to the hyperprior codec. Additionally, we adopt a hybrid pixel- and\nlatent-domain optimization to jointly enhance both reconstruction fidelity and\nperceptual realism. Extensive experiments demonstrate that OneDC achieves SOTA\nperceptual quality even with one-step generation, offering over 40% bitrate\nreduction and 20x faster decoding compared to prior multi-step diffusion-based\ncodecs. Code will be released later.", "published": "2025-05-22 13:54:09", "link": "http://arxiv.org/abs/2505.16687v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "On the use of Graphs for Satellite Image Time Series", "abstract": "The Earth's surface is subject to complex and dynamic processes, ranging from\nlarge-scale phenomena such as tectonic plate movements to localized changes\nassociated with ecosystems, agriculture, or human activity. Satellite images\nenable global monitoring of these processes with extensive spatial and temporal\ncoverage, offering advantages over in-situ methods. In particular, resulting\nsatellite image time series (SITS) datasets contain valuable information. To\nhandle their large volume and complexity, some recent works focus on the use of\ngraph-based techniques that abandon the regular Euclidean structure of\nsatellite data to work at an object level. Besides, graphs enable modelling\nspatial and temporal interactions between identified objects, which are crucial\nfor pattern detection, classification and regression tasks. This paper is an\neffort to examine the integration of graph-based methods in spatio-temporal\nremote-sensing analysis. In particular, it aims to present a versatile\ngraph-based pipeline to tackle SITS analysis. It focuses on the construction of\nspatio-temporal graphs from SITS and their application to downstream tasks. The\npaper includes a comprehensive review and two case studies, which highlight the\npotential of graph-based approaches for land cover mapping and water resource\nforecasting. It also discusses numerous perspectives to resolve current\nlimitations and encourage future developments.", "published": "2025-05-22 13:53:36", "link": "http://arxiv.org/abs/2505.16685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Anomaly Detection in Battery Thermal Images Using Visual Question Answering with Prior Knowledge", "abstract": "Batteries are essential for various applications, including electric vehicles\nand renewable energy storage, making safety and efficiency critical concerns.\nAnomaly detection in battery thermal images helps identify failures early, but\ntraditional deep learning methods require extensive labeled data, which is\ndifficult to obtain, especially for anomalies due to safety risks and high data\ncollection costs. To overcome this, we explore zero-shot anomaly detection\nusing Visual Question Answering (VQA) models, which leverage pretrained\nknowledge and textbased prompts to generalize across vision tasks. By\nincorporating prior knowledge of normal battery thermal behavior, we design\nprompts to detect anomalies without battery-specific training data. We evaluate\nthree VQA models (ChatGPT-4o, LLaVa-13b, and BLIP-2) analyzing their robustness\nto prompt variations, repeated trials, and qualitative outputs. Despite the\nlack of finetuning on battery data, our approach demonstrates competitive\nperformance compared to state-of-the-art models that are trained with the\nbattery data. Our findings highlight the potential of VQA-based zero-shot\nlearning for battery anomaly detection and suggest future directions for\nimproving its effectiveness.", "published": "2025-05-22 13:39:52", "link": "http://arxiv.org/abs/2505.16674v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation", "abstract": "Embodied navigation demands comprehensive scene understanding and precise\nspatial reasoning. While image-text models excel at interpreting pixel-level\ncolor and lighting cues, 3D-text models capture volumetric structure and\nspatial relationships. However, unified fusion approaches that jointly fuse 2D\nimages, 3D point clouds, and textual instructions face challenges in limited\navailability of triple-modality data and difficulty resolving conflicting\nbeliefs among modalities. In this work, we introduce CoNav, a collaborative\ncross-modal reasoning framework where a pretrained 3D-text model explicitly\nguides an image-text navigation agent by providing structured spatial-semantic\nknowledge to resolve ambiguities during navigation. Specifically, we introduce\nCross-Modal Belief Alignment, which operationalizes this cross-modal guidance\nby simply sharing textual hypotheses from the 3D-text model to the navigation\nagent. Through lightweight fine-tuning on a small 2D-3D-text corpus, the\nnavigation agent learns to integrate visual cues with spatial-semantic\nknowledge derived from the 3D-text model, enabling effective reasoning in\nembodied navigation. CoNav achieves significant improvements on four standard\nembodied navigation benchmarks (R2R, CVDN, REVERIE, SOON) and two spatial\nreasoning benchmarks (ScanQA, SQA3D). Moreover, under close navigation Success\nRate, CoNav often generates shorter paths compared to other methods (as\nmeasured by SPL), showcasing the potential and challenges of fusing data from\ndifferent modalities in embodied navigation. Project Page:\nhttps://oceanhao.github.io/CoNav/", "published": "2025-05-22 13:27:54", "link": "http://arxiv.org/abs/2505.16663v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images", "abstract": "Medical anomaly detection (AD) is crucial for early clinical intervention,\nyet it faces challenges due to limited access to high-quality medical imaging\ndata, caused by privacy concerns and data silos. Few-shot learning has emerged\nas a promising approach to alleviate these limitations by leveraging the\nlarge-scale prior knowledge embedded in vision-language models (VLMs). Recent\nadvancements in few-shot medical AD have treated normal and abnormal cases as a\none-class classification problem, often overlooking the distinction among\nmultiple anomaly categories. Thus, in this paper, we propose a framework\ntailored for few-shot medical anomaly detection in the scenario where the\nidentification of multiple anomaly categories is required. To capture the\ndetailed radiological signs of medical anomaly categories, our framework\nincorporates diverse textual descriptions for each category generated by a\nLarge-Language model, under the assumption that different anomalies in medical\nimages may share common radiological signs in each category. Specifically, we\nintroduce SD-MAD, a two-stage Sign-Driven few-shot Multi-Anomaly Detection\nframework: (i) Radiological signs are aligned with anomaly categories by\namplifying inter-anomaly discrepancy; (ii) Aligned signs are selected further\nto mitigate the effect of the under-fitting and uncertain-sample issue caused\nby limited medical data, employing an automatic sign selection strategy at\ninference. Moreover, we propose three protocols to comprehensively quantify the\nperformance of multi-anomaly detection. Extensive experiments illustrate the\neffectiveness of our method.", "published": "2025-05-22 13:24:37", "link": "http://arxiv.org/abs/2505.16659v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control", "abstract": "Hyperspectral pansharpening has received much attention in recent years due\nto technological and methodological advances that open the door to new\napplication scenarios. However, research on this topic is only now gaining\nmomentum. The most popular methods are still borrowed from the more mature\nfield of multispectral pansharpening and often overlook the unique challenges\nposed by hyperspectral data fusion, such as i) the very large number of bands,\nii) the overwhelming noise in selected spectral ranges, iii) the significant\nspectral mismatch between panchromatic and hyperspectral components, iv) a\ntypically high resolution ratio. Imprecise data modeling especially affects\nspectral fidelity. Even state-of-the-art methods perform well in certain\nspectral ranges and much worse in others, failing to ensure consistent quality\nacross all bands, with the risk of generating unreliable results. Here, we\npropose a hyperspectral pansharpening method that explicitly addresses this\nproblem and ensures uniform spectral quality. To this end, a single lightweight\nneural network is used, with weights that adapt on the fly to each band. During\nfine-tuning, the spatial loss is turned on and off to ensure a fast convergence\nof the spectral loss to the desired level, according to a hysteresis-like\ndynamic. Furthermore, the spatial loss itself is appropriately redefined to\naccount for nonlinear dependencies between panchromatic and spectral bands.\nOverall, the proposed method is fully unsupervised, with no prior training on\nexternal data, flexible, and low-complexity. Experiments on a recently\npublished benchmarking toolbox show that it ensures excellent sharpening\nquality, competitive with the state-of-the-art, consistently across all bands.\nThe software code and the full set of results are shared online on\nhttps://github.com/giu-guarino/rho-PNN.", "published": "2025-05-22 13:24:24", "link": "http://arxiv.org/abs/2505.16658v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding", "abstract": "Recent advancements in multimodal large language models (MLLMs) have\nsignificantly improved performance in visual question answering. However, they\noften suffer from hallucinations. In this work, hallucinations are categorized\ninto two main types: initial hallucinations and snowball hallucinations. We\nargue that adequate contextual information can be extracted directly from the\ntoken interaction process. Inspired by causal inference in the decoding\nstrategy, we propose to leverage causal masks to establish information\npropagation between multimodal tokens. The hypothesis is that insufficient\ninteraction between those tokens may lead the model to rely on outlier tokens,\noverlooking dense and rich contextual cues. Therefore, we propose to intervene\nin the propagation process by tackling outlier tokens to enhance in-context\ninference. With this goal, we present FarSight, a versatile plug-and-play\ndecoding strategy to reduce attention interference from outlier tokens merely\nby optimizing the causal mask. The heart of our method is effective token\npropagation. We design an attention register structure within the upper\ntriangular matrix of the causal mask, dynamically allocating attention to\ncapture attention diverted to outlier tokens. Moreover, a positional awareness\nencoding method with a diminishing masking rate is proposed, allowing the model\nto attend to further preceding tokens, especially for video sequence tasks.\nWith extensive experiments, FarSight demonstrates significant\nhallucination-mitigating performance across different MLLMs on both image and\nvideo benchmarks, proving its effectiveness.", "published": "2025-05-22 13:19:57", "link": "http://arxiv.org/abs/2505.16652v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Unsupervised Network Anomaly Detection with Autoencoders and Traffic Images", "abstract": "Due to the recent increase in the number of connected devices, the need to\npromptly detect security issues is emerging. Moreover, the high number of\ncommunication flows creates the necessity of processing huge amounts of data.\nFurthermore, the connected devices are heterogeneous in nature, having\ndifferent computational capacities. For this reason, in this work we propose an\nimage-based representation of network traffic which allows to realize a compact\nsummary of the current network conditions with 1-second time windows. The\nproposed representation highlights the presence of anomalies thus reducing the\nneed for complex processing architectures. Finally, we present an unsupervised\nlearning approach which effectively detects the presence of anomalies. The code\nand the dataset are available at\nhttps://github.com/michaelneri/image-based-network-traffic-anomaly-detection.", "published": "2025-05-22 13:19:30", "link": "http://arxiv.org/abs/2505.16650v1", "categories": ["cs.CV", "cs.CR", "eess.IV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Towards Texture- And Shape-Independent 3D Keypoint Estimation in Birds", "abstract": "In this paper, we present a texture-independent approach to estimate and\ntrack 3D joint positions of multiple pigeons. For this purpose, we build upon\nthe existing 3D-MuPPET framework, which estimates and tracks the 3D poses of up\nto 10 pigeons using a multi-view camera setup. We extend this framework by\nusing a segmentation method that generates silhouettes of the individuals,\nwhich are then used to estimate 2D keypoints. Following 3D-MuPPET, these 2D\nkeypoints are triangulated to infer 3D poses, and identities are matched in the\nfirst frame and tracked in 2D across subsequent frames. Our proposed\ntexture-independent approach achieves comparable accuracy to the original\ntexture-dependent 3D-MuPPET framework. Additionally, we explore our approach's\napplicability to other bird species. To do that, we infer the 2D joint\npositions of four bird species without additional fine-tuning the model trained\non pigeons and obtain preliminary promising results. Thus, we think that our\napproach serves as a solid foundation and inspires the development of more\nrobust and accurate texture-independent pose estimation frameworks.", "published": "2025-05-22 13:04:24", "link": "http://arxiv.org/abs/2505.16633v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Background Matters: A Cross-view Bidirectional Modeling Framework for Semi-supervised Medical Image Segmentation", "abstract": "Semi-supervised medical image segmentation (SSMIS) leverages unlabeled data\nto reduce reliance on manually annotated images. However, current SOTA\napproaches predominantly focus on foreground-oriented modeling (i.e.,\nsegmenting only the foreground region) and have largely overlooked the\npotential benefits of explicitly modeling the background region. Our study\ntheoretically and empirically demonstrates that highly certain predictions in\nbackground modeling enhance the confidence of corresponding foreground\nmodeling. Building on this insight, we propose the Cross-view Bidirectional\nModeling (CVBM) framework, which introduces a novel perspective by\nincorporating background modeling to improve foreground modeling performance.\nWithin CVBM, background modeling serves as an auxiliary perspective, providing\ncomplementary supervisory signals to enhance the confidence of the foreground\nmodel. Additionally, CVBM introduces an innovative bidirectional consistency\nmechanism, which ensures mutual alignment between foreground predictions and\nbackground-guided predictions. Extensive experiments demonstrate that our\napproach achieves SOTA performance on the LA, Pancreas, ACDC, and HRF datasets.\nNotably, on the Pancreas dataset, CVBM outperforms fully supervised methods\n(i.e., DSC: 84.57% vs. 83.89%) while utilizing only 20% of the labeled data.\nOur code is publicly available at https://github.com/caoluyang0830/CVBM.git.", "published": "2025-05-22 12:59:45", "link": "http://arxiv.org/abs/2505.16625v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation", "abstract": "Egocentric hand-object motion generation is crucial for immersive AR/VR and\nrobotic imitation but remains challenging due to unstable viewpoints,\nself-occlusions, perspective distortion, and noisy ego-motion. Existing methods\nrely on predefined 3D object priors, limiting generalization to novel objects,\nwhich restricts their generalizability to novel objects. Meanwhile, recent\nmultimodal approaches suffer from ambiguous generation from abstract textual\ncues, intricate pipelines for modeling 3D hand-object correlation, and\ncompounding errors in open-loop prediction. We propose MEgoHand, a multimodal\nframework that synthesizes physically plausible hand-object interactions from\negocentric RGB, text, and initial hand pose. MEgoHand introduces a bi-level\narchitecture: a high-level \"cerebrum\" leverages a vision language model (VLM)\nto infer motion priors from visual-textual context and a monocular depth\nestimator for object-agnostic spatial reasoning, while a low-level DiT-based\nflow-matching policy generates fine-grained trajectories with temporal\northogonal filtering to enhance stability. To address dataset inconsistency, we\ndesign a dataset curation paradigm with an Inverse MANO Retargeting Network and\nVirtual RGB-D Renderer, curating a unified dataset of 3.35M RGB-D frames, 24K\ninteractions, and 1.2K objects. Extensive experiments across five in-domain and\ntwo cross-domain datasets demonstrate the effectiveness of MEgoHand, achieving\nsubstantial reductions in wrist translation error (86.9%) and joint rotation\nerror (34.1%), highlighting its capacity to accurately model fine-grained hand\njoint structures and generalize robustly across diverse scenarios.", "published": "2025-05-22 12:37:47", "link": "http://arxiv.org/abs/2505.16602v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupled Geometric Parameterization and its Application in Deep Homography Estimation", "abstract": "Planar homography, with eight degrees of freedom (DOFs), is fundamental in\nnumerous computer vision tasks. While the positional offsets of four corners\nare widely adopted (especially in neural network predictions), this\nparameterization lacks geometric interpretability and typically requires\nsolving a linear system to compute the homography matrix. This paper presents a\nnovel geometric parameterization of homographies, leveraging the\nsimilarity-kernel-similarity (SKS) decomposition for projective\ntransformations. Two independent sets of four geometric parameters are\ndecoupled: one for a similarity transformation and the other for the kernel\ntransformation. Additionally, the geometric interpretation linearly relating\nthe four kernel transformation parameters to angular offsets is derived. Our\nproposed parameterization allows for direct homography estimation through\nmatrix multiplication, eliminating the need for solving a linear system, and\nachieves performance comparable to the four-corner positional offsets in deep\nhomography estimation.", "published": "2025-05-22 12:33:29", "link": "http://arxiv.org/abs/2505.16599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Temporal Object Captioning for Street Scene Videos from LiDAR Tracks", "abstract": "Video captioning models have seen notable advancements in recent years,\nespecially with regard to their ability to capture temporal information. While\nmany research efforts have focused on architectural advancements, such as\ntemporal attention mechanisms, there remains a notable gap in understanding how\nmodels capture and utilize temporal semantics for effective temporal feature\nextraction, especially in the context of Advanced Driver Assistance Systems. We\npropose an automated LiDAR-based captioning procedure that focuses on the\ntemporal dynamics of traffic participants. Our approach uses a rule-based\nsystem to extract essential details such as lane position and relative motion\nfrom object tracks, followed by a template-based caption generation. Our\nfindings show that training SwinBERT, a video captioning model, using only\nfront camera images and supervised with our template-based captions,\nspecifically designed to encapsulate fine-grained temporal behavior, leads to\nimproved temporal understanding consistently across three datasets. In\nconclusion, our results clearly demonstrate that integrating LiDAR-based\ncaption supervision significantly enhances temporal understanding, effectively\naddressing and reducing the inherent visual/static biases prevalent in current\nstate-of-the-art model architectures.", "published": "2025-05-22 12:28:50", "link": "http://arxiv.org/abs/2505.16594v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion", "abstract": "We tackle the problem of monocular-to-stereo video conversion and propose a\nnovel architecture for inpainting and refinement of the warped right view\nobtained by depth-based reprojection of the input left view. We extend the\nStable Video Diffusion (SVD) model to utilize the input left video, the warped\nright video, and the disocclusion masks as conditioning input to generate a\nhigh-quality right camera view. In order to effectively exploit information\nfrom neighboring frames for inpainting, we modify the attention layers in SVD\nto compute full attention for discoccluded pixels. Our model is trained to\ngenerate the right view video in an end-to-end manner by minimizing image space\nlosses to ensure high-quality generation. Our approach outperforms previous\nstate-of-the-art methods, obtaining an average rank of 1.43 among the 4\ncompared methods in a user study, while being 6x faster than the second placed\nmethod.", "published": "2025-05-22 11:58:54", "link": "http://arxiv.org/abs/2505.16565v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextureSAM: Towards a Texture Aware Foundation Model for Segmentation", "abstract": "Segment Anything Models (SAM) have achieved remarkable success in object\nsegmentation tasks across diverse datasets. However, these models are\npredominantly trained on large-scale semantic segmentation datasets, which\nintroduce a bias toward object shape rather than texture cues in the image.\nThis limitation is critical in domains such as medical imaging, material\nclassification, and remote sensing, where texture changes define object\nboundaries. In this study, we investigate SAM's bias toward semantics over\ntextures and introduce a new texture-aware foundation model, TextureSAM, which\nperforms superior segmentation in texture-dominant scenarios. To achieve this,\nwe employ a novel fine-tuning approach that incorporates texture augmentation\ntechniques, incrementally modifying training images to emphasize texture\nfeatures. By leveraging a novel texture-alternation of the ADE20K dataset, we\nguide TextureSAM to prioritize texture-defined regions, thereby mitigating the\ninherent shape bias present in the original SAM model. Our extensive\nexperiments demonstrate that TextureSAM significantly outperforms SAM-2 on both\nnatural (+0.2 mIoU) and synthetic (+0.18 mIoU) texture-based segmentation\ndatasets. The code and texture-augmented dataset will be publicly available.", "published": "2025-05-22 11:31:56", "link": "http://arxiv.org/abs/2505.16540v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion", "abstract": "We present a novel framework for dynamic 3D scene reconstruction that\nintegrates three key components: an explicit tri-plane deformation field, a\nview-conditioned canonical radiance field with spherical harmonics (SH)\nattention, and a temporally-aware latent diffusion prior. Our method encodes 4D\nscenes using three orthogonal 2D feature planes that evolve over time, enabling\nefficient and compact spatiotemporal representation. These features are\nexplicitly warped into a canonical space via a deformation offset field,\neliminating the need for MLP-based motion modeling.\n  In canonical space, we replace traditional MLP decoders with a structured\nSH-based rendering head that synthesizes view-dependent color via attention\nover learned frequency bands improving both interpretability and rendering\nefficiency. To further enhance fidelity and temporal consistency, we introduce\na transformer-guided latent diffusion module that refines the tri-plane and\ndeformation features in a compressed latent space. This generative module\ndenoises scene representations under ambiguous or out-of-distribution (OOD)\nmotion, improving generalization.\n  Our model is trained in two stages: the diffusion module is first pre-trained\nindependently, and then fine-tuned jointly with the full pipeline using a\ncombination of image reconstruction, diffusion denoising, and temporal\nconsistency losses. We demonstrate state-of-the-art results on synthetic\nbenchmarks, surpassing recent methods such as HexPlane and 4D Gaussian\nSplatting in visual quality, temporal coherence, and robustness to sparse-view\ndynamic inputs.", "published": "2025-05-22 11:25:38", "link": "http://arxiv.org/abs/2505.16535v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction", "abstract": "3D Gaussian Splatting (3DGS) has emerged as a high-fidelity and efficient\nparadigm for online free-viewpoint video (FVV) reconstruction, offering viewers\nrapid responsiveness and immersive experiences. However, existing online\nmethods face challenge in prohibitive storage requirements primarily due to\npoint-wise modeling that fails to exploit the motion properties. To address\nthis limitation, we propose a novel Compact Gaussian Streaming (ComGS)\nframework, leveraging the locality and consistency of motion in dynamic scene,\nthat models object-consistent Gaussian point motion through keypoint-driven\nmotion representation. By transmitting only the keypoint attributes, this\nframework provides a more storage-efficient solution. Specifically, we first\nidentify a sparse set of motion-sensitive keypoints localized within motion\nregions using a viewspace gradient difference strategy. Equipped with these\nkeypoints, we propose an adaptive motion-driven mechanism that predicts a\nspatial influence field for propagating keypoint motion to neighboring Gaussian\npoints with similar motion. Moreover, ComGS adopts an error-aware correction\nstrategy for key frame reconstruction that selectively refines erroneous\nregions and mitigates error accumulation without unnecessary overhead. Overall,\nComGS achieves a remarkable storage reduction of over 159 X compared to\n3DGStream and 14 X compared to the SOTA method QUEEN, while maintaining\ncompetitive visual fidelity and rendering speed. Our code will be released.", "published": "2025-05-22 11:22:09", "link": "http://arxiv.org/abs/2505.16533v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving", "abstract": "Maintaining robust 3D perception under dynamic and unpredictable test-time\nconditions remains a critical challenge for autonomous driving systems.\nExisting test-time adaptation (TTA) methods often fail in high-variance tasks\nlike 3D object detection due to unstable optimization and sharp minima. While\nrecent model merging strategies based on linear mode connectivity (LMC) offer\nimproved stability by interpolating between fine-tuned checkpoints, they are\ncomputationally expensive, requiring repeated checkpoint access and multiple\nforward passes. In this paper, we introduce CodeMerge, a lightweight and\nscalable model merging framework that bypasses these limitations by operating\nin a compact latent space. Instead of loading full models, CodeMerge represents\neach checkpoint with a low-dimensional fingerprint derived from the source\nmodel's penultimate features and constructs a key-value codebook. We compute\nmerging coefficients using ridge leverage scores on these fingerprints,\nenabling efficient model composition without compromising adaptation quality.\nOur method achieves strong performance across challenging benchmarks, improving\nend-to-end 3D detection 14.9% NDS on nuScenes-C and LiDAR-based detection by\nover 7.6% mAP on nuScenes-to-KITTI, while benefiting downstream tasks such as\nonline mapping, motion prediction and planning even without training. Code and\npretrained models are released in the supplementary material.", "published": "2025-05-22 11:09:15", "link": "http://arxiv.org/abs/2505.16524v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models", "abstract": "Large Vision-Language Models (LVLMs) have recently advanced robotic\nmanipulation by leveraging vision for scene perception and language for\ninstruction following. However, existing methods rely heavily on costly\nhuman-annotated training datasets, which limits their generalization and causes\nthem to struggle in out-of-domain (OOD) scenarios, reducing real-world\nadaptability. To address these challenges, we propose ManipLVM-R1, a novel\nreinforcement learning framework that replaces traditional supervision with\nReinforcement Learning using Verifiable Rewards (RLVR). By directly optimizing\nfor task-aligned outcomes, our method enhances generalization and physical\nreasoning while removing the dependence on costly annotations. Specifically, we\ndesign two rule-based reward functions targeting key robotic manipulation\nsubtasks: an Affordance Perception Reward to enhance localization of\ninteraction regions, and a Trajectory Match Reward to ensure the physical\nplausibility of action paths. These rewards provide immediate feedback and\nimpose spatial-logical constraints, encouraging the model to go beyond shallow\npattern matching and instead learn deeper, more systematic reasoning about\nphysical interactions.", "published": "2025-05-22 10:57:07", "link": "http://arxiv.org/abs/2505.16517v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Detailed Evaluation of Modern Machine Learning Approaches for Optic Plastics Sorting", "abstract": "According to the EPA, only 25% of waste is recycled, and just 60% of U.S.\nmunicipalities offer curbside recycling. Plastics fare worse, with a recycling\nrate of only 8%; an additional 16% is incinerated, while the remaining 76% ends\nup in landfills. The low plastic recycling rate stems from contamination, poor\neconomic incentives, and technical difficulties, making efficient recycling a\nchallenge. To improve recovery, automated sorting plays a critical role.\nCompanies like AMP Robotics and Greyparrot utilize optical systems for sorting,\nwhile Materials Recovery Facilities (MRFs) employ Near-Infrared (NIR) sensors\nto detect plastic types.\n  Modern optical sorting uses advances in computer vision such as object\nrecognition and instance segmentation, powered by machine learning. Two-stage\ndetectors like Mask R-CNN use region proposals and classification with deep\nbackbones like ResNet. Single-stage detectors like YOLO handle detection in one\npass, trading some accuracy for speed. While such methods excel under ideal\nconditions with a large volume of labeled training data, challenges arise in\nrealistic scenarios, emphasizing the need to further examine the efficacy of\noptic detection for automated sorting.\n  In this study, we compiled novel datasets totaling 20,000+ images from varied\nsources. Using both public and custom machine learning pipelines, we assessed\nthe capabilities and limitations of optical recognition for sorting. Grad-CAM,\nsaliency maps, and confusion matrices were employed to interpret model\nbehavior. We perform this analysis on our custom trained models from the\ncompiled datasets. To conclude, our findings are that optic recognition methods\nhave limited success in accurate sorting of real-world plastics at MRFs,\nprimarily because they rely on physical properties such as color and shape.", "published": "2025-05-22 10:48:30", "link": "http://arxiv.org/abs/2505.16513v1", "categories": ["cs.CV", "68T45", "I.4.9; I.4.6"], "primary_category": "cs.CV"}
{"title": "Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection", "abstract": "In recent years, the rapid development of deepfake technology has given rise\nto an emerging and serious threat to public security: diffusion model-based\ndigital human generation. Unlike traditional face manipulation methods, such\nmodels can generate highly realistic videos with consistency through multimodal\ncontrol signals. Their flexibility and covertness pose severe challenges to\nexisting detection strategies. To bridge this gap, we introduce DigiFakeAV, the\nfirst large-scale multimodal digital human forgery dataset based on diffusion\nmodels. Employing five latest digital human generation methods (Sonic, Hallo,\netc.) and voice cloning method, we systematically produce a dataset comprising\n60,000 videos (8.4 million frames), covering multiple nationalities, skin\ntones, genders, and real-world scenarios, significantly enhancing data\ndiversity and realism. User studies show that the confusion rate between forged\nand real videos reaches 68%, and existing state-of-the-art (SOTA) detection\nmodels exhibit large drops in AUC values on DigiFakeAV, highlighting the\nchallenge of the dataset. To address this problem, we further propose\nDigiShield, a detection baseline based on spatiotemporal and cross-modal\nfusion. By jointly modeling the 3D spatiotemporal features of videos and the\nsemantic-acoustic features of audio, DigiShield achieves SOTA performance on\nboth the DigiFakeAV and DF-TIMIT datasets. Experiments show that this method\neffectively identifies covert artifacts through fine-grained analysis of the\ntemporal evolution of facial features in synthetic videos.", "published": "2025-05-22 10:46:37", "link": "http://arxiv.org/abs/2505.16512v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation", "abstract": "While humans effortlessly draw visual objects and shapes by adaptively\nallocating attention based on their complexity, existing multimodal large\nlanguage models (MLLMs) remain constrained by rigid token representations.\nBridging this gap, we propose ALTo, an adaptive length tokenizer for\nautoregressive mask generation. To achieve this, a novel token length predictor\nis designed, along with a length regularization term and a differentiable token\nchunking strategy. We further build ALToLLM that seamlessly integrates ALTo\ninto MLLM. Preferences on the trade-offs between mask quality and efficiency is\nimplemented by group relative policy optimization (GRPO). Experiments\ndemonstrate that ALToLLM achieves state-of-the-art performance with adaptive\ntoken cost on popular segmentation benchmarks. Code and models are released at\nhttps://github.com/yayafengzi/ALToLLM.", "published": "2025-05-22 10:26:51", "link": "http://arxiv.org/abs/2505.16495v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Implicit Neural Shape Optimization for 3D High-Contrast Electrical Impedance Tomography", "abstract": "We present a novel implicit neural shape optimization framework for 3D\nhigh-contrast Electrical Impedance Tomography (EIT), addressing scenarios where\nconductivity exhibits sharp discontinuities across material interfaces. These\nhigh-contrast cases, prevalent in metallic implant monitoring and industrial\ndefect detection, challenge traditional reconstruction methods due to severe\nill-posedness. Our approach synergizes shape optimization with implicit neural\nrepresentations, introducing key innovations including a shape derivative-based\noptimization scheme that explicitly incorporates high-contrast interface\nconditions and an efficient latent space representation that reduces variable\ndimensionality. Through rigorous theoretical analysis of algorithm convergence\nand extensive numerical experiments, we demonstrate substantial performance\nimprovements, establishing our framework as promising for practical\napplications in medical imaging with metallic implants and industrial\nnon-destructive testing.", "published": "2025-05-22 10:13:19", "link": "http://arxiv.org/abs/2505.16487v1", "categories": ["math.NA", "cs.CV", "cs.NA"], "primary_category": "math.NA"}
{"title": "InspectionV3: Enhancing Tobacco Quality Assessment with Deep Convolutional Neural Networks for Automated Workshop Management", "abstract": "The problems that tobacco workshops encounter include poor curing,\ninconsistencies in supplies, irregular scheduling, and a lack of oversight, all\nof which drive up expenses and worse quality. Large quantities make manual\nexamination costly, sluggish, and unreliable. Deep convolutional neural\nnetworks have recently made strides in capabilities that transcend those of\nconventional methods. To effectively enhance them, nevertheless, extensive\ncustomization is needed to account for subtle variations in tobacco grade. This\nstudy introduces InspectionV3, an integrated solution for automated flue-cured\ntobacco grading that makes use of a customized deep convolutional neural\nnetwork architecture. A scope that covers color, maturity, and curing\nsubtleties is established via a labelled dataset consisting of 21,113 images\nspanning 20 quality classes. Expert annotators performed preprocessing on the\ntobacco leaf images, including cleaning, labelling, and augmentation.\nMulti-layer CNN factors use batch normalization to describe domain properties\nlike as permeability and moisture spots, and so account for the subtleties of\nthe workshop. Its expertise lies in converting visual patterns into useful\ninformation for enhancing workflow. Fast notifications are made possible by\nreal-time, on-the-spot grading that matches human expertise. Images-powered\nanalytics dashboards facilitate the tracking of yield projections, inventories,\nbottlenecks, and the optimization of data-driven choices. More labelled images\nare assimilated after further retraining, improving representational capacities\nand enabling adaptations for seasonal variability. Metrics demonstrate 97%\naccuracy, 95% precision and recall, 96% F1-score and AUC, 95% specificity;\nvalidating real-world viability.", "published": "2025-05-22 10:11:50", "link": "http://arxiv.org/abs/2505.16485v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Clear Nights Ahead: Towards Multi-Weather Nighttime Image Restoration", "abstract": "Restoring nighttime images affected by multiple adverse weather conditions is\na practical yet under-explored research problem, as multiple weather conditions\noften coexist in the real world alongside various lighting effects at night.\nThis paper first explores the challenging multi-weather nighttime image\nrestoration task, where various types of weather degradations are intertwined\nwith flare effects. To support the research, we contribute the AllWeatherNight\ndataset, featuring large-scale high-quality nighttime images with diverse\ncompositional degradations, synthesized using our introduced illumination-aware\ndegradation generation. Moreover, we present ClearNight, a unified nighttime\nimage restoration framework, which effectively removes complex degradations in\none go. Specifically, ClearNight extracts Retinex-based dual priors and\nexplicitly guides the network to focus on uneven illumination regions and\nintrinsic texture contents respectively, thereby enhancing restoration\neffectiveness in nighttime scenarios. In order to better represent the common\nand unique characters of multiple weather degradations, we introduce a\nweather-aware dynamic specific-commonality collaboration method, which\nidentifies weather degradations and adaptively selects optimal candidate units\nassociated with specific weather types. Our ClearNight achieves\nstate-of-the-art performance on both synthetic and real-world images.\nComprehensive ablation experiments validate the necessity of AllWeatherNight\ndataset as well as the effectiveness of ClearNight. Project page:\nhttps://henlyta.github.io/ClearNight/mainpage.html", "published": "2025-05-22 10:06:35", "link": "http://arxiv.org/abs/2505.16479v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Consistent World Models via Foresight Diffusion", "abstract": "Diffusion and flow-based models have enabled significant progress in\ngeneration tasks across various modalities and have recently found applications\nin world modeling. However, unlike typical generation tasks that encourage\nsample diversity, world models entail different sources of uncertainty and\nrequire consistent samples aligned with the ground-truth trajectory, which is a\nlimitation we empirically observe in diffusion models. We argue that a key\nbottleneck in learning consistent diffusion-based world models lies in the\nsuboptimal predictive ability, which we attribute to the entanglement of\ncondition understanding and target denoising within shared architectures and\nco-training schemes. To address this, we propose Foresight Diffusion\n(ForeDiff), a diffusion-based world modeling framework that enhances\nconsistency by decoupling condition understanding from target denoising.\nForeDiff incorporates a separate deterministic predictive stream to process\nconditioning inputs independently of the denoising stream, and further\nleverages a pretrained predictor to extract informative representations that\nguide generation. Extensive experiments on robot video prediction and\nscientific spatiotemporal forecasting show that ForeDiff improves both\npredictive accuracy and sample consistency over strong baselines, offering a\npromising direction for diffusion-based world models.", "published": "2025-05-22 10:01:59", "link": "http://arxiv.org/abs/2505.16474v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer", "abstract": "Recently, vision transformers (ViTs) have achieved excellent performance on\nvision tasks by measuring the global self-attention among the image patches.\nGiven $n$ patches, they will have quadratic complexity such as\n$\\mathcal{O}(n^2)$ and the time cost is high when splitting the input image\nwith a small granularity. Meanwhile, the pivotal information is often randomly\ngathered in a few regions of an input image, some tokens may not be helpful for\nthe downstream tasks. To handle this problem, we introduce an anchor-based\nefficient vision transformer (AnchorFormer), which employs the anchor tokens to\nlearn the pivotal information and accelerate the inference. Firstly, by\nestimating the bipartite attention between the anchors and tokens, the\ncomplexity will be reduced from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$, where\n$m$ is an anchor number and $m < n$. Notably, by representing the anchors with\nthe neurons in a neural layer, we can differentiable learn these distributions\nand approximate global self-attention through the Markov process. Moreover, we\nextend the proposed model to three downstream tasks including classification,\ndetection, and segmentation. Extensive experiments show the effectiveness of\nour AnchorFormer, e.g., achieving up to a 9.0% higher accuracy or 46.7% FLOPs\nreduction on ImageNet classification, 81.3% higher mAP on COCO detection under\ncomparable FLOPs, as compared to the current baselines.", "published": "2025-05-22 09:44:44", "link": "http://arxiv.org/abs/2505.16463v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM", "abstract": "Recent advances in static 3D generation have intensified the demand for\nphysically consistent dynamic 3D content. However, existing video generation\nmodels, including diffusion-based methods, often prioritize visual realism\nwhile neglecting physical plausibility, resulting in implausible object\ndynamics. Prior approaches for physics-aware dynamic generation typically rely\non large-scale annotated datasets or extensive model fine-tuning, which imposes\nsignificant computational and data collection burdens and limits scalability\nacross scenarios. To address these challenges, we present MAGIC, a\ntraining-free framework for single-image physical property inference and\ndynamic generation, integrating pretrained image-to-video diffusion models with\niterative LLM-based reasoning. Our framework generates motion-rich videos from\na static image and closes the visual-to-physical gap through a\nconfidence-driven LLM feedback loop that adaptively steers the diffusion model\ntoward physics-relevant motion. To translate visual dynamics into controllable\nphysical behavior, we further introduce a differentiable MPM simulator\noperating directly on 3D Gaussians reconstructed from the single image,\nenabling physically grounded, simulation-ready outputs without any supervision\nor model tuning. Experiments show that MAGIC outperforms existing physics-aware\ngenerative methods in inference accuracy and achieves greater temporal\ncoherence than state-of-the-art video diffusion models.", "published": "2025-05-22 09:40:34", "link": "http://arxiv.org/abs/2505.16456v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI", "abstract": "Accurate and efficient quantification of cardiac function is essential for\nthe estimation of prognosis of cardiovascular diseases (CVDs). One of the most\ncommonly used metrics for evaluating cardiac pumping performance is left\nventricular ejection fraction (LVEF). However, LVEF can be affected by factors\nsuch as inter-observer variability and varying pre-load and after-load\nconditions, which can reduce its reproducibility. Additionally, cardiac\ndysfunction may not always manifest as alterations in LVEF, such as in heart\nfailure and cardiotoxicity diseases. An alternative measure that can provide a\nrelatively load-independent quantitative assessment of myocardial contractility\nis myocardial strain and strain rate. By using LVEF in combination with\nmyocardial strain, it is possible to obtain a thorough description of cardiac\nfunction. Automated estimation of LVEF and other volumetric measures from\ncine-MRI sequences can be achieved through segmentation models, while strain\ncalculation requires the estimation of tissue displacement between sequential\nframes, which can be accomplished using registration models. These tasks are\noften performed separately, potentially limiting the assessment of cardiac\nfunction. To address this issue, in this study we propose an end-to-end deep\nlearning (DL) model that jointly estimates groupwise (GW) registration and\nsegmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep\nGW network was trained and validated on a large dataset of 4-chamber view\ncine-MRI image series of 374 subjects. A quantitative comparison with\nconventional GW registration using elastix and two DL-based methods showed that\nthe proposed model improved performance and substantially reduced computation\ntime.", "published": "2025-05-22 09:36:42", "link": "http://arxiv.org/abs/2505.16452v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition", "abstract": "TAT-VPR is a ternary-quantized transformer that brings dynamic\naccuracy-efficiency trade-offs to visual SLAM loop-closure. By fusing ternary\nweights with a learned activation-sparsity gate, the model can control\ncomputation by up to 40% at run-time without degrading performance (Recall@1).\nThe proposed two-stage distillation pipeline preserves descriptor quality,\nletting it run on micro-UAV and embedded SLAM stacks while matching\nstate-of-the-art localization accuracy.", "published": "2025-05-22 09:35:27", "link": "http://arxiv.org/abs/2505.16447v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection", "abstract": "Small object detection in intricate environments has consistently represented\na major challenge in the field of object detection. In this paper, we identify\nthat this difficulty stems from the detectors' inability to effectively learn\ndiscriminative features for objects of small size, compounded by the complexity\nof selecting high-quality small object samples during training, which motivates\nthe proposal of the Multi-Clue Assignment and Feature Enhancement\nR-CNN.Specifically, MAFE R-CNN integrates two pivotal components.The first is\nthe Multi-Clue Sample Selection (MCSS) strategy, in which the Intersection over\nUnion (IoU) distance, predicted category confidence, and ground truth region\nsizes are leveraged as informative clues in the sample selection process. This\nmethodology facilitates the selection of diverse positive samples and ensures a\nbalanced distribution of object sizes during training, thereby promoting\neffective model learning.The second is the Category-aware Feature Enhancement\nMechanism (CFEM), where we propose a simple yet effective category-aware memory\nmodule to explore the relationships among object features. Subsequently, we\nenhance the object feature representation by facilitating the interaction\nbetween category-aware features and candidate box features.Comprehensive\nexperiments conducted on the large-scale small object dataset SODA validate the\neffectiveness of the proposed method. The code will be made publicly available.", "published": "2025-05-22 09:30:09", "link": "http://arxiv.org/abs/2505.16442v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ranked Entropy Minimization for Continual Test-Time Adaptation", "abstract": "Test-time adaptation aims to adapt to realistic environments in an online\nmanner by learning during test time. Entropy minimization has emerged as a\nprincipal strategy for test-time adaptation due to its efficiency and\nadaptability. Nevertheless, it remains underexplored in continual test-time\nadaptation, where stability is more important. We observe that the entropy\nminimization method often suffers from model collapse, where the model\nconverges to predicting a single class for all images due to a trivial\nsolution. We propose ranked entropy minimization to mitigate the stability\nproblem of the entropy minimization method and extend its applicability to\ncontinuous scenarios. Our approach explicitly structures the prediction\ndifficulty through a progressive masking strategy. Specifically, it gradually\naligns the model's probability distributions across different levels of\nprediction difficulty while preserving the rank order of entropy. The proposed\nmethod is extensively evaluated across various benchmarks, demonstrating its\neffectiveness through empirical results. Our code is available at\nhttps://github.com/pilsHan/rem", "published": "2025-05-22 09:29:38", "link": "http://arxiv.org/abs/2505.16441v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "The Computational Complexity of Counting Linear Regions in ReLU Neural Networks", "abstract": "An established measure of the expressive power of a given ReLU neural network\nis the number of linear regions into which it partitions the input space. There\nexist many different, non-equivalent definitions of what a linear region\nactually is. We systematically assess which papers use which definitions and\ndiscuss how they relate to each other. We then analyze the computational\ncomplexity of counting the number of such regions for the various definitions.\nGenerally, this turns out to be an intractable problem. We prove NP- and\n#P-hardness results already for networks with one hidden layer and strong\nhardness of approximation results for two or more hidden layers. Finally, on\nthe algorithmic side, we demonstrate that counting linear regions can at least\nbe achieved in polynomial space for some common definitions.", "published": "2025-05-22 14:25:12", "link": "http://arxiv.org/abs/2505.16716v1", "categories": ["cs.CC", "cs.DM", "cs.LG", "cs.NE", "math.CO"], "primary_category": "cs.CC"}
{"title": "Continuous Petri Nets Faithfully Fluidify Most Permissive Boolean Networks", "abstract": "The analysis of biological networks has benefited from the richness of\nBoolean networks (BNs) and the associated theory. These results have been\nfurther fortified in recent years by the emergence of Most Permissive (MP)\nsemantics, combining efficient analysis methods with a greater capacity of\nexplaining pathways to states hitherto thought unreachable, owing to\nlimitations of the classical update modes. While MPBNs are understood to\ncapture any behaviours that can be observed at a lower level of abstraction,\nall the way down to continuous refinements, the specifics and potential of the\nmodels and analysis, especially attractors, across the abstraction scale remain\nunexplored. Here, we fluidify MPBNs by means of Continuous Petri nets (CPNs), a\nmodel of (uncountably infinite) dynamic systems that has been successfully\nexplored for modelling and theoretical purposes. CPNs create a formal link\nbetween MPBNs and their continuous dynamical refinements such as ODE models.\nThe benefits of CPNs extend beyond the model refinement, and constitute well\nestablished theory and analysis methods, recently augmented by abstract and\nsymbolic reachability graphs. These structures are shown to compact the\npossible behaviours of the system with focus on events which drive the choice\nof long-term behaviour in which the system eventually stabilises. The current\npaper brings an important keystone to this novel methodology for biological\nnetworks, namely the proof that extant PN encoding of BNs instantiated as a CPN\nsimulates the MP semantics. In spite of the underlying dynamics being\ncontinuous, the analysis remains in the realm of discrete methods, constituting\nan extension of all previous work.", "published": "2025-05-22 13:52:27", "link": "http://arxiv.org/abs/2505.16683v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Scaling Quantum Simulation-Based Optimization: Demonstrating Efficient Power Grid Management with Deep QAOA Circuits", "abstract": "Quantum Simulation-based Optimization (QuSO) is a recently proposed class of\noptimization problems that entails industrially relevant problems characterized\nby cost functions or constraints that depend on summary statistic information\nabout the simulation of a physical system or process. This work extends initial\ntheoretical results that proved an up-to-exponential speedup for the simulation\ncomponent of the QAOA-based QuSO solver proposed by Stein et al. for the unit\ncommitment problem by an empirical evaluation of the optimization component\nusing a standard benchmark dataset, the IEEE 57-bus system. Exploiting clever\nclassical pre-computation, we develop a very efficient classical quantum\ncircuit simulation that bypasses costly ancillary qubit requirements by the\noriginal algorithm, allowing for large-scale experiments. Utilizing more than\n1000 QAOA layers and up to 20 qubits, our experiments complete a proof of\nconcept implementation for the proposed QuSO solver, showing that it can\nachieve both highly competitive performance and efficiency in its optimization\ncomponent compared to a standard classical baseline, i.e., simulated annealing.", "published": "2025-05-22 09:33:29", "link": "http://arxiv.org/abs/2505.16444v1", "categories": ["quant-ph", "cs.DM"], "primary_category": "quant-ph"}
{"title": "LARES: Latent Reasoning for Sequential Recommendation", "abstract": "Sequential recommender systems have become increasingly important in\nreal-world applications that model user behavior sequences to predict their\npreferences. However, existing sequential recommendation methods predominantly\nrely on non-reasoning paradigms, which may limit the model's computational\ncapacity and result in suboptimal recommendation performance. To address these\nlimitations, we present LARES, a novel and scalable LAtent REasoning framework\nfor Sequential recommendation that enhances model's representation capabilities\nthrough increasing the computation density of parameters by depth-recurrent\nlatent reasoning. Our proposed approach employs a recurrent architecture that\nallows flexible expansion of reasoning depth without increasing parameter\ncomplexity, thereby effectively capturing dynamic and intricate user interest\npatterns. A key difference of LARES lies in refining all input tokens at each\nimplicit reasoning step to improve the computation utilization. To fully unlock\nthe model's reasoning potential, we design a two-phase training strategy: (1)\nSelf-supervised pre-training (SPT) with dual alignment objectives; (2)\nReinforcement post-training (RPT). During the first phase, we introduce\ntrajectory-level alignment and step-level alignment objectives, which enable\nthe model to learn recommendation-oriented latent reasoning patterns without\nrequiring supplementary annotated data. The subsequent phase utilizes\nreinforcement learning (RL) to harness the model's exploratory ability, further\nrefining its reasoning capabilities. Comprehensive experiments on real-world\nbenchmarks demonstrate our framework's superior performance. Notably, LARES\nexhibits seamless compatibility with existing advanced models, further\nimproving their recommendation performance.", "published": "2025-05-22 16:22:54", "link": "http://arxiv.org/abs/2505.16865v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks", "abstract": "Large Language Models (LLMs) have showcased impressive reasoning abilities,\nbut often suffer from hallucinations or outdated knowledge. Knowledge Graph\n(KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by\ngrounding LLM responses in structured external information from a knowledge\nbase. However, many KG-based RAG approaches struggle with (i) aligning KG and\ntextual representations, (ii) balancing retrieval accuracy and efficiency, and\n(iii) adapting to dynamically updated KGs. In this work, we introduce\nWalk&Retrieve, a simple yet effective KG-based framework that leverages\nwalk-based graph traversal and knowledge verbalization for corpus generation\nfor zero-shot RAG. Built around efficient KG walks, our method does not require\nfine-tuning on domain-specific data, enabling seamless adaptation to KG\nupdates, reducing computational overhead, and allowing integration with any\noff-the-shelf backbone LLM. Despite its simplicity, Walk&Retrieve performs\ncompetitively, often outperforming existing RAG systems in response accuracy\nand hallucination reduction. Moreover, it demonstrates lower query latency and\nrobust scalability to large KGs, highlighting the potential of lightweight\nretrieval strategies as strong baselines for future RAG research.", "published": "2025-05-22 16:11:35", "link": "http://arxiv.org/abs/2505.16849v1", "categories": ["cs.IR", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "DeepRec: Towards a Deep Dive Into the Item Space with Large Language Model Based Recommendation", "abstract": "Recently, large language models (LLMs) have been introduced into recommender\nsystems (RSs), either to enhance traditional recommendation models (TRMs) or\nserve as recommendation backbones. However, existing LLM-based RSs often do not\nfully exploit the complementary advantages of LLMs (e.g., world knowledge and\nreasoning) and TRMs (e.g., recommendation-specific knowledge and efficiency) to\nfully explore the item space. To address this, we propose DeepRec, a novel\nLLM-based RS that enables autonomous multi-turn interactions between LLMs and\nTRMs for deep exploration of the item space. In each interaction turn, LLMs\nreason over user preferences and interact with TRMs to retrieve candidate\nitems. After multi-turn interactions, LLMs rank the retrieved items to generate\nthe final recommendations. We adopt reinforcement learning(RL) based\noptimization and propose novel designs from three aspects: recommendation model\nbased data rollout, recommendation-oriented hierarchical rewards, and a\ntwo-stage RL training strategy. For data rollout, we introduce a\npreference-aware TRM, with which LLMs interact to construct trajectory data.\nFor rewards, we design a hierarchical reward function that involves both\nprocess-level and outcome-level rewards to optimize the interaction process and\nrecommendation performance, respectively. For RL training, we develop a\ntwo-stage training strategy, where the first stage aims to guide LLMs to\ninteract with TRMs and the second stage focuses on performance improvement.\nExperiments on public datasets demonstrate that DeepRec significantly\noutperforms both traditional and LLM-based baselines, offering a new paradigm\nfor deep exploration in recommendation systems.", "published": "2025-05-22 15:49:38", "link": "http://arxiv.org/abs/2505.16810v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Novel Generative Model with Causality Constraint for Mitigating Biases in Recommender Systems", "abstract": "Accurately predicting counterfactual user feedback is essential for building\neffective recommender systems. However, latent confounding bias can obscure the\ntrue causal relationship between user feedback and item exposure, ultimately\ndegrading recommendation performance. Existing causal debiasing approaches\noften rely on strong assumptions-such as the availability of instrumental\nvariables (IVs) or strong correlations between latent confounders and proxy\nvariables-that are rarely satisfied in real-world scenarios. To address these\nlimitations, we propose a novel generative framework called Latent Causality\nConstraints for Debiasing representation learning in Recommender Systems\n(LCDR). Specifically, LCDR leverages an identifiable Variational Autoencoder\n(iVAE) as a causal constraint to align the latent representations learned by a\nstandard Variational Autoencoder (VAE) through a unified loss function. This\nalignment allows the model to leverage even weak or noisy proxy variables to\nrecover latent confounders effectively. The resulting representations are then\nused to improve recommendation performance. Extensive experiments on three\nreal-world datasets demonstrate that LCDR consistently outperforms existing\nmethods in both mitigating bias and improving recommendation accuracy.", "published": "2025-05-22 14:09:39", "link": "http://arxiv.org/abs/2505.16708v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MDVT: Enhancing Multimodal Recommendation with Model-Agnostic Multimodal-Driven Virtual Triplets", "abstract": "The data sparsity problem significantly hinders the performance of\nrecommender systems, as traditional models rely on limited historical\ninteractions to learn user preferences and item properties. While incorporating\nmultimodal information can explicitly represent these preferences and\nproperties, existing works often use it only as side information, failing to\nfully leverage its potential. In this paper, we propose MDVT, a model-agnostic\napproach that constructs multimodal-driven virtual triplets to provide valuable\nsupervision signals, effectively mitigating the data sparsity problem in\nmultimodal recommendation systems. To ensure high-quality virtual triplets, we\nintroduce three tailored warm-up threshold strategies: static, dynamic, and\nhybrid. The static warm-up threshold strategy exhaustively searches for the\noptimal number of warm-up epochs but is time-consuming and computationally\nintensive. The dynamic warm-up threshold strategy adjusts the warm-up period\nbased on loss trends, improving efficiency but potentially missing optimal\nperformance. The hybrid strategy combines both, using the dynamic strategy to\nfind the approximate optimal number of warm-up epochs and then refining it with\nthe static strategy in a narrow hyper-parameter space. Once the warm-up\nthreshold is satisfied, the virtual triplets are used for joint model\noptimization by our enhanced pair-wise loss function without causing\nsignificant gradient skew. Extensive experiments on multiple real-world\ndatasets demonstrate that integrating MDVT into advanced multimodal\nrecommendation models effectively alleviates the data sparsity problem and\nimproves recommendation performance, particularly in sparse data scenarios.", "published": "2025-05-22 13:28:55", "link": "http://arxiv.org/abs/2505.16665v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Causal-Invariant Cross-Domain Out-of-Distribution Recommendation", "abstract": "Cross-Domain Recommendation (CDR) aims to leverage knowledge from a\nrelatively data-richer source domain to address the data sparsity problem in a\nrelatively data-sparser target domain. While CDR methods need to address the\ndistribution shifts between different domains, i.e., cross-domain distribution\nshifts (CDDS), they typically assume independent and identical distribution\n(IID) between training and testing data within the target domain. However, this\nIID assumption rarely holds in real-world scenarios due to single-domain\ndistribution shift (SDDS). The above two co-existing distribution shifts lead\nto out-of-distribution (OOD) environments that hinder effective knowledge\ntransfer and generalization, ultimately degrading recommendation performance in\nCDR. To address these co-existing distribution shifts, we propose a novel\nCausal-Invariant Cross-Domain Out-of-distribution Recommendation framework,\ncalled CICDOR. In CICDOR, we first learn dual-level causal structures to infer\ndomain-specific and domain-shared causal-invariant user preferences for\ntackling both CDDS and SDDS under OOD environments in CDR. Then, we propose an\nLLM-guided confounder discovery module that seamlessly integrates LLMs with a\nconventional causal discovery method to extract observed confounders for\neffective deconfounding, thereby enabling accurate causal-invariant preference\ninference. Extensive experiments on two real-world datasets demonstrate the\nsuperior recommendation accuracy of CICDOR over state-of-the-art methods across\nvarious OOD scenarios.", "published": "2025-05-22 11:21:51", "link": "http://arxiv.org/abs/2505.16532v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Utilizing citation index and synthetic quality measure to compare Wikipedia languages across various topics", "abstract": "This study presents a comparative analysis of 55 Wikipedia language editions\nemploying a citation index alongside a synthetic quality measure. Specifically,\nwe identified the most significant Wikipedia articles within distinct topical\nareas, selecting the top 10, top 25, and top 100 most cited articles in each\ntopic and language version. This index was built on the basis of wikilinks\nbetween Wikipedia articles in each language version and in order to do that we\nprocessed 6.6 billion page-to-page link records. Next, we used a quality score\nfor each Wikipedia article - a synthetic measure scaled from 0 to 100. This\napproach enabled quality comparison of Wikipedia articles even between language\nversions with different quality grading schemes. Our results highlight\ndisparities among Wikipedia language editions, revealing strengths and gaps in\ncontent coverage and quality across topics.", "published": "2025-05-22 10:41:55", "link": "http://arxiv.org/abs/2505.16506v1", "categories": ["cs.IR", "cs.CY", "cs.DL", "stat.AP"], "primary_category": "cs.IR"}
{"title": "Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for GNN-based Recommendation Methods", "abstract": "Recommender systems based on graph neural networks perform well in tasks such\nas rating and ranking. However, in real-world recommendation scenarios, noise\nsuch as user misuse and malicious advertisement gradually accumulates through\nthe message propagation mechanism. Even if existing studies mitigate their\neffects by reducing the noise propagation weights, the severe sparsity of the\nrecommender system still leads to the low-weighted noisy neighbors being\nmistaken as meaningful information, and the prediction result obtained based on\nthe polluted nodes is not entirely trustworthy. Therefore, it is crucial to\nmeasure the confidence of the prediction results in this highly noisy\nframework. Furthermore, our evaluation of the existing representative GNN-based\nrecommendation shows that it suffers from overconfidence. Based on the above\nconsiderations, we propose a new method to quantify and calibrate the\nprediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically,\nwe propose a rating calibration method that dynamically adjusts excessive\nratings to mitigate overconfidence based on user personalization. We also\ndesign a confidence loss function to reduce the overconfidence of negative\nsamples and effectively improve recommendation performance. Experiments on\npublic datasets demonstrate the validity of Conf-GNNRec in prediction\nconfidence and recommendation performance.", "published": "2025-05-22 09:48:17", "link": "http://arxiv.org/abs/2505.16466v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Chain-of-Thought Poisoning Attacks against R1-based Retrieval-Augmented Generation Systems", "abstract": "Retrieval-augmented generation (RAG) systems can effectively mitigate the\nhallucination problem of large language models (LLMs),but they also possess\ninherent vulnerabilities. Identifying these weaknesses before the large-scale\nreal-world deployment of RAG systems is of great importance, as it lays the\nfoundation for building more secure and robust RAG systems in the future.\nExisting adversarial attack methods typically exploit knowledge base poisoning\nto probe the vulnerabilities of RAG systems, which can effectively deceive\nstandard RAG models. However, with the rapid advancement of deep reasoning\ncapabilities in modern LLMs, previous approaches that merely inject incorrect\nknowledge are inadequate when attacking RAG systems equipped with deep\nreasoning abilities. Inspired by the deep thinking capabilities of LLMs, this\npaper extracts reasoning process templates from R1-based RAG systems, uses\nthese templates to wrap erroneous knowledge into adversarial documents, and\ninjects them into the knowledge base to attack RAG systems. The key idea of our\napproach is that adversarial documents, by simulating the chain-of-thought\npatterns aligned with the model's training signals, may be misinterpreted by\nthe model as authentic historical reasoning processes, thus increasing their\nlikelihood of being referenced. Experiments conducted on the MS MARCO passage\nranking dataset demonstrate the effectiveness of our proposed method.", "published": "2025-05-22 08:22:46", "link": "http://arxiv.org/abs/2505.16367v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Flow Matching based Sequential Recommender Model", "abstract": "Generative models, particularly diffusion model, have emerged as powerful\ntools for sequential recommendation. However, accurately modeling user\npreferences remains challenging due to the noise perturbations inherent in the\nforward and reverse processes of diffusion-based methods. Towards this end,\nthis study introduces FMRec, a Flow Matching based model that employs a\nstraight flow trajectory and a modified loss tailored for the recommendation\ntask. Additionally, from the diffusion-model perspective, we integrate a\nreconstruction loss to improve robustness against noise perturbations, thereby\nretaining user preferences during the forward process. In the reverse process,\nwe employ a deterministic reverse sampler, specifically an ODE-based updating\nfunction, to eliminate unnecessary randomness, thereby ensuring that the\ngenerated recommendations closely align with user needs. Extensive evaluations\non four benchmark datasets reveal that FMRec achieves an average improvement of\n6.53% over state-of-the-art methods. The replication code is available at\nhttps://github.com/FengLiu-1/FMRec.", "published": "2025-05-22 06:53:03", "link": "http://arxiv.org/abs/2505.16298v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) encounters efficiency challenges when\nscaling to massive knowledge bases while preserving contextual relevance. We\npropose Hash-RAG, a framework that integrates deep hashing techniques with\nsystematic optimizations to address these limitations. Our queries directly\nlearn binary hash codes from knowledgebase code, eliminating intermediate\nfeature extraction steps, and significantly reducing storage and computational\noverhead. Building upon this hash-based efficient retrieval framework, we\nestablish the foundation for fine-grained chunking. Consequently, we design a\nPrompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved\nhash-indexed propositions and their original document segments through prompt\nengineering to enhance the LLM's contextual awareness. Experimental evaluations\non NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a\n90% reduction in retrieval time compared to conventional methods while\nmaintaining considerate recall performance. Additionally, The proposed system\noutperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.", "published": "2025-05-22 02:22:11", "link": "http://arxiv.org/abs/2505.16133v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Emotion-based Recommender System", "abstract": "Recommender system is one of the most critical technologies for large\ninternet companies such as Amazon and TikTok. Although millions of users use\nrecommender systems globally everyday, and indeed, much data analysis work has\nbeen done to improve the technical accuracy of the system, to our limited\nknowledge, there has been little attention paid to analysis of users' emotion\nin recommender systems. In this paper, we create a new theory and metrics that\ncould capture users' emotion when they are interacting with recommender\nsystems. We also provide effective and efficient visualization techniques for\nvisualization of users' emotion and its change in the customers' lifetime\ncycle. In the end, we design a framework for emotion-based recommendation\nalgorithms, illustrated in a straightforward example with experimental results\nto demonstrate the effectiveness of our new theory.", "published": "2025-05-22 01:54:58", "link": "http://arxiv.org/abs/2505.16121v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Rotatable Antenna Enabled Wireless Communication and Sensing: Opportunities and Challenges", "abstract": "Non-fixed flexible antenna architectures, including fluid antenna systems\n(FAS) and movable antennas (MA), have attracted considerable interest in recent\nyears. Rotatable antenna (RA) is an emerging technology that offers significant\npotential to enhance wireless communication and sensing performance by flexibly\nadjusting the boresight of directional antennas. Specifically, RA can flexibly\nreconfigure its boresight direction via mechanical or electronic means, thereby\nimproving communication channel conditions and/or enhancing sensing resolution\nand range. In this article, we first provide an overview of RA, including its\npromising applications, hardware architectures, and radiation pattern\ncharacterization. We then illustrate how RA improves communication performance\nthrough interference mitigation, spatial multiplexing, and flexible\nbeamforming, as well as enhances sensing capabilities in terms of coverage,\nresolution, and multi-target/dimensional sensing. Furthermore, we discuss key\ndesign challenges in RA systems, including rotational scanning scheduling,\nchannel estimation/sensing, boresight optimization, and RA configuration.\nFinally, both experimental and simulation results are provided to validate the\nperformance gains achieved by RA for both communication and sensing. Leveraging\nits unique capabilities in flexible antenna/array rotation to adapt to various\ncommunication/sensing requirements and channel conditions, RA is poised to\nbecome a key enabler of future intelligent, resilient, and agile wireless\nnetworks.", "published": "2025-05-22 16:01:07", "link": "http://arxiv.org/abs/2505.16828v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Tutorial on Beyond-Diagonal Reconfigurable Intelligent Surfaces: Modeling, Architectures, System Design and Optimization, and Applications", "abstract": "Written by its inventors, this first tutorial on Beyond-Diagonal\nReconfigurable Intelligent Surfaces (BD-RISs) provides the readers with the\nbasics and fundamental tools necessary to appreciate, understand, and\ncontribute to this emerging and disruptive technology. Conventional (Diagonal)\nRISs (D-RISs) are characterized by a diagonal scattering matrix\n$\\mathbf{\\Theta}$ such that the wave manipulation flexibility of D-RIS is\nextremely limited. In contrast, BD-RIS refers to a novel and general framework\nfor RIS where its scattering matrix is not limited to be diagonal (hence, the\n``beyond-diagonal'' terminology) and consequently, all entries of\n$\\mathbf{\\Theta}$ can potentially help shaping waves for much higher\nmanipulation flexibility. This physically means that BD-RIS can artificially\nengineer and reconfigure coupling across elements of the surface thanks to\ninter-element reconfigurable components which allow waves absorbed by one\nelement to flow through other elements. Consequently, BD-RIS opens the door to\nmore general and versatile intelligent surfaces that subsumes existing RIS\narchitectures as special cases. In this tutorial, we share all the secret sauce\nto model, design, and optimize BD-RIS and make BD-RIS transformative in many\ndifferent applications. Topics discussed include physics-consistent and\nmulti-port network-aided modeling; transmitting, reflecting, hybrid, and\nmulti-sector mode analysis; reciprocal and non-reciprocal architecture designs\nand optimal performance-complexity Pareto frontier of BD-RIS; signal\nprocessing, optimization, and channel estimation for BD-RIS; hardware\nimpairments (discrete-value impedance and admittance, lossy interconnections\nand components, wideband effects, mutual coupling) of BD-RIS; benefits and\napplications of BD-RIS in communications, sensing, power transfer.", "published": "2025-05-22 10:37:31", "link": "http://arxiv.org/abs/2505.16504v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Sensing-Enhanced Handover Criterion for Low-Altitude Wireless Networks (LAWNs)", "abstract": "With the rapid growth of the low-altitude economy, the demand for\ncellular-enabled low-altitude wireless networks (LAWNs) is rising\nsignificantly. The three-dimensional mobility of unmanned aerial vehicles\n(UAVs) will lead to frequent handovers (HOs) in cellular networks, while\ntraditional reference signal received power (RSRP)-based criteria may fail to\ncapture the dynamic environment, causing redundant HOs or HO failures. To\naddress this issue and motivated by the underutilization of sensing information\nin conventional HO mechanisms, we propose a novel HO activation criterion for\nUAV systems that integrates both sensing parameters provided by integrated\nsensing and communication (ISAC) signals and RSRP. First, we construct an ISAC\nsignal model tailored for low-altitude scenarios and derive the Cram\\'er-Rao\nlower bound for sensing distance estimation. Subsequently, we propose a novel\njoint HO criterion that extends the conventional RSRP-based method by\nintegrating sensing information from ISAC signals, enabling more reliable HOs\nin dynamic UAV environments. Simulation results show that the joint HO\ncriterion outperforms the baseline RSRP-based criterion under different\nsignal-to-noise ratio (SNR) and sensing pilot ratio conditions. Particularly,\nwhen SNR is greater than 0dB and the sensing pilot ratio is 20%, the proposed\njoint HO criterion reduces the average HO region length by 49.97% and improves\nthe activation probability by 76.31%.", "published": "2025-05-22 08:01:52", "link": "http://arxiv.org/abs/2505.16350v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Graph Attention Network for Optimal User Association in Wireless Networks", "abstract": "With increased 5G deployments, network densification is higher than ever to\nsupport the exponentially high throughput requirements. However, this has meant\na significant increase in energy consumption, leading to higher operational\nexpenditure (OpEx) for network operators creating an acute need for\nimprovements in network energy savings (NES). A key determinant of operational\nefficacy in cellular networks is the user association (UA) policy, as it\naffects critical aspects like spectral efficiency, load balancing etc. and\ntherefore impacts the overall energy consumption of the network directly.\nFurthermore, with cellular network topologies lending themselves well to\ngraphical abstractions, use of graphs in network optimization has gained\nsignificant prominence. In this work, we propose and analyze a graphical\nabstraction based optimization for UA in cellular networks to improve NES by\ndetermining when energy saving features like cell switch off can be activated.\nA comparison with legacy approaches establishes the superiority of the proposed\napproach.", "published": "2025-05-22 08:00:01", "link": "http://arxiv.org/abs/2505.16347v1", "categories": ["cs.IT", "cs.LG", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Half-Marker Codes for Deletion Channels with Applications in DNA Storage", "abstract": "DNA storage systems face significant challenges, including insertion,\ndeletion, and substitution (IDS) errors. Therefore, designing effective\nsynchronization codes, i.e., codes capable of correcting IDS errors, is\nessential for DNA storage systems. Marker codes are a favorable choice for this\npurpose. In this paper, we extend the notion of marker codes by making the\nfollowing key observation. Since each DNA base is equivalent to a 2-bit storage\nunit, one bit can be reserved for synchronization, while the other is dedicated\nto data transmission. Using this observation, we propose a new class of marker\ncodes, which we refer to as half-marker codes. We demonstrate that this\nextension has the potential to significantly increase the mutual information\nbetween the input symbols and the soft outputs of an IDS channel modeling a DNA\nstorage system. Specifically, through examples, we show that when concatenated\nwith an outer error-correcting code, half-marker codes outperform standard\nmarker codes and significantly reduce the end-to-end bit error rate of the\nsystem.", "published": "2025-05-22 07:58:18", "link": "http://arxiv.org/abs/2505.16344v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Cooperative NOMA Meets Emerging Technologies: A Survey for Next-Generation Wireless Networks", "abstract": "The emerging demands of sixth-generation wireless networks, such as\nultra-connectivity, native intelligence, and cross-domain convergence, are\nbringing renewed focus to cooperative non-orthogonal multiple access (C-NOMA)\nas a fundamental enabler of scalable, efficient, and intelligent communication\nsystems. C-NOMA builds on the core benefits of NOMA by leveraging user\ncooperation and relay strategies to enhance spectral efficiency, coverage, and\nenergy performance. This article presents a unified and forward-looking survey\non the integration of C-NOMA with key enabling technologies, including radio\nfrequency energy harvesting, cognitive radio networks, reconfigurable\nintelligent surfaces, space-air-ground integrated networks, and integrated\nsensing and communication-assisted semantic communication. Foundational\nprinciples and relaying protocols are first introduced to establish the\ntechnical relevance of C-NOMA. Then, a focused investigation is conducted into\nprotocol-level synergies, architectural models, and deployment strategies\nacross these technologies. Beyond integration, this article emphasizes the\norchestration of C-NOMA across future application domains such as digital\ntwins, extended reality, and e-health. In addition, it provides an extensive\nand in-depth review of recent literature, categorized by relaying schemes,\nsystem models, performance metrics, and optimization paradigms, including\nmodel-based, heuristic, and AI-driven approaches. Finally, open challenges and\nfuture research directions are outlined, spanning standardization, security,\nand cross-layer design, positioning C-NOMA as a key pillar of intelligent\nnext-generation network architectures.", "published": "2025-05-22 07:32:48", "link": "http://arxiv.org/abs/2505.16327v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Base Station Placement Optimization for Networked Sensing Exploiting Target Location Distribution", "abstract": "This paper studies a networked sensing system with multiple base stations\n(BSs), which collaboratively sense the unknown and random three-dimensional\n(3D) location of a target based on the target-reflected echo signals received\nat the BSs. Considering a practical scenario where the target location\ndistribution is known a priori for exploitation, we aim to design the placement\nof the multiple BSs to optimize the networked sensing performance. Firstly, we\ncharacterize the posterior Cram\\'er-Rao bound (PCRB) of the mean-squared error\n(MSE) in sensing the target's 3D location. Despite its complex form under\nnetworked sensing, we derive its closed-form expression in terms of the BS\nlocations. Next, we formulate the BS placement optimization problem to minimize\nthe sensing PCRB, which is non-convex and difficult to solve. By leveraging a\nseries of equivalent transformations and the iterative inner approximation\nmethod, we devise an algorithm with polynomial-time complexity which is\nguaranteed to converge to a solution satisfying the Karush-Kuhn Tucker (KKT)\nconditions of the problem. Numerical results show that the proposed placement\ndesign significantly outperforms various benchmark designs.", "published": "2025-05-22 05:10:57", "link": "http://arxiv.org/abs/2505.16236v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Beyond Diagonal Intelligent Reflecting Surface Aided Integrated Sensing and Communication", "abstract": "Beyond diagonal intelligent reflecting surface (BD-IRS) is a new promising\nIRS architecture for which the reflection matrix is not limited to the diagonal\nstructure as for conventional IRS. In this paper, we study a BD-IRS aided\nuplink integrated sensing and communication (ISAC) system where sensing is\nperformed in a device-based manner. Specifically, we aim to estimate the\nunknown and random location of an active target based on its uplink probing\nsignals sent to a multi-antenna base station (BS) as well as the known prior\ndistribution information of the target's location. Multiple communication users\nalso simultaneously send uplink signals, resulting in a challenging mutual\ninterference issue between sensing and communication. We first characterize the\nsensing performance metric by deriving the posterior Cram\\'er-Rao bound (PCRB)\nof the mean-squared error (MSE) when prior information is available. Then, we\nformulate a BD-IRS reflection matrix optimization problem to maximize the\nminimum expected achievable rate among the multiple users subject to a\nconstraint on the PCRB as well as the lossless and reciprocal constraints on\nthe BD-IRS reflection matrix. The formulated problem is non-convex and\nchallenging to solve. To tackle this problem, we propose a penalty dual\ndecomposition (PDD) based algorithm which can find a high-quality suboptimal\nsolution with polynomial-time complexity. In addition, we propose and optimize\na time-division multiple access (TDMA) based scheme which removes the\nsensing-communication mutual interference. Numerical results verify the\neffectiveness of the proposed designs and provide useful design insights.", "published": "2025-05-22 05:00:07", "link": "http://arxiv.org/abs/2505.16230v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Beamforming-Codebook-Aware Channel Knowledge Map Construction for Multi-Antenna Systems", "abstract": "Channel knowledge map (CKM) has emerged as a crucial technology for\nnext-generation communication, enabling the construction of high-fidelity\nmappings between spatial environments and channel parameters via\nelectromagnetic information analysis. Traditional CKM construction methods like\nray tracing are computationally intensive. Recent studies utilizing neural\nnetworks (NNs) have achieved efficient CKM generation with reduced\ncomputational complexity and real-time processing capabilities. Nevertheless,\nexisting research predominantly focuses on single-antenna systems, failing to\naddress the beamforming requirements inherent to MIMO configurations. Given\nthat appropriate precoding vector selection in MIMO systems can substantially\nenhance user communication rates, this paper presents a TransUNet-based\nframework for constructing CKM, which effectively incorporates discrete Fourier\ntransform (DFT) precoding vectors. The proposed architecture combines a UNet\nbackbone for multiscale feature extraction with a Transformer module to capture\nglobal dependencies among encoded linear vectors. Experimental results\ndemonstrate that the proposed method outperforms state-of-the-art (SOTA) deep\nlearning (DL) approaches, yielding a 17\\% improvement in RMSE compared to\nRadioWNet. The code is publicly accessible at\nhttps://github.com/github-whh/TransUNet.", "published": "2025-05-22 02:18:24", "link": "http://arxiv.org/abs/2505.16132v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Sufficient conditions for offline reactivation in recurrent neural networks", "abstract": "During periods of quiescence, such as sleep, neural activity in many brain\ncircuits resembles that observed during periods of task engagement. However,\nthe precise conditions under which task-optimized networks can autonomously\nreactivate the same network states responsible for online behavior is poorly\nunderstood. In this study, we develop a mathematical framework that outlines\nsufficient conditions for the emergence of neural reactivation in circuits that\nencode features of smoothly varying stimuli. We demonstrate mathematically that\nnoisy recurrent networks optimized to track environmental state variables using\nchange-based sensory information naturally develop denoising dynamics, which,\nin the absence of input, cause the network to revisit state configurations\nobserved during periods of online activity. We validate our findings using\nnumerical experiments on two canonical neuroscience tasks: spatial position\nestimation based on self-motion cues, and head direction estimation based on\nangular velocity cues. Overall, our work provides theoretical support for\nmodeling offline reactivation as an emergent consequence of task optimization\nin noisy neural circuits.", "published": "2025-05-22 17:57:59", "link": "http://arxiv.org/abs/2505.17003v1", "categories": ["q-bio.NC", "cs.LG", "cs.NE"], "primary_category": "q-bio.NC"}
{"title": "Critical Points of Random Neural Networks", "abstract": "This work investigates the expected number of critical points of random\nneural networks with different activation functions as the depth increases in\nthe infinite-width limit. Under suitable regularity conditions, we derive\nprecise asymptotic formulas for the expected number of critical points of fixed\nindex and those exceeding a given threshold. Our analysis reveals three\ndistinct regimes depending on the value of the first derivative of the\ncovariance evaluated at 1: the expected number of critical points may converge,\ngrow polynomially, or grow exponentially with depth. The theoretical\npredictions are supported by numerical experiments. Moreover, we provide\nnumerical evidence suggesting that, when the regularity condition is not\nsatisfied (e.g. for neural networks with ReLU as activation function), the\nnumber of critical points increases as the map resolution increases, indicating\na potential divergence in the number of critical points.", "published": "2025-05-22 17:57:30", "link": "http://arxiv.org/abs/2505.17000v1", "categories": ["stat.ML", "cs.LG", "math.PR", "60G60, 62B10, 62M45"], "primary_category": "stat.ML"}
{"title": "A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations", "abstract": "Inverse problems involving differential equations often require identifying\nunknown parameters or functions from data. Existing approaches, such as\nPhysics-Informed Neural Networks (PINNs), Universal Differential Equations\n(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective\nat isolating either parameters or functions but can face challenges when\napplied simultaneously due to solution non-uniqueness. In this work, we\nintroduce a framework that addresses these limitations by establishing\nconditions under which unique solutions can be guaranteed. To illustrate, we\napply it to examples from biological systems and ecological dynamics,\ndemonstrating accurate and interpretable results. Our approach significantly\nenhances the potential of machine learning techniques in modeling complex\nsystems in science and engineering.", "published": "2025-05-22 17:56:38", "link": "http://arxiv.org/abs/2505.16996v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics", "abstract": "Despite decades of advancements, the simulation of fluids remains one of the\nmost challenging areas of in scientific computing. Supported by the necessity\nof gradient information in deep learning, differentiable simulators have\nemerged as an effective tool for optimization and learning in physics\nsimulations. In this work, we present our fluid simulator PICT, a\ndifferentiable pressure-implicit solver coded in PyTorch with\nGraphics-processing-unit (GPU) support. We first verify the accuracy of both\nthe forward simulation and our derived gradients in various established\nbenchmarks like lid-driven cavities and turbulent channel flows before we show\nthat the gradients provided by our solver can be used to learn complicated\nturbulence models in 2D and 3D. We apply both supervised and unsupervised\ntraining regimes using physical priors to match flow statistics. In particular,\nwe learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow\npurely based on reference statistics. The low-resolution corrector trained with\nour solver runs substantially faster than the highly resolved references, while\nkeeping or even surpassing their accuracy. Finally, we give additional insights\ninto the physical interpretation of different solver gradients, and motivate a\nphysically informed regularization technique. To ensure that the full potential\nof PICT can be leveraged, it is published as open source:\nhttps://github.com/tum-pbs/PICT.", "published": "2025-05-22 17:55:10", "link": "http://arxiv.org/abs/2505.16992v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models", "abstract": "Diffusion probabilistic models have become a cornerstone of modern generative\nAI, yet the mechanisms underlying their generalization remain poorly\nunderstood. In fact, if these models were perfectly minimizing their training\nloss, they would just generate data belonging to their training set, i.e.,\nmemorize, as empirically found in the overparameterized regime. We revisit this\nview by showing that, in highly overparameterized diffusion models,\ngeneralization in natural data domains is progressively achieved during\ntraining before the onset of memorization. Our results, ranging from image to\nlanguage diffusion models, systematically support the empirical law that\nmemorization time is proportional to the dataset size. Generalization vs.\nmemorization is then best understood as a competition between time scales. We\nshow that this phenomenology is recovered in diffusion models learning a simple\nprobabilistic context-free grammar with random rules, where generalization\ncorresponds to the hierarchical acquisition of deeper grammar rules as training\ntime grows, and the generalization cost of early stopping can be characterized.\nWe summarize these results in a phase diagram. Overall, our results support\nthat a principled early-stopping criterion - scaling with dataset size - can\neffectively optimize generalization while avoiding memorization, with direct\nimplications for hyperparameter transfer and privacy-sensitive applications.", "published": "2025-05-22 17:40:08", "link": "http://arxiv.org/abs/2505.16959v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization", "abstract": "Machine learning (ML) has demonstrated considerable potential in supporting\nmodel design and optimization for combinatorial optimization (CO) problems.\nHowever, much of the progress to date has been evaluated on small-scale,\nsynthetic datasets, raising concerns about the practical effectiveness of\nML-based solvers in real-world, large-scale CO scenarios. Additionally, many\nexisting CO benchmarks lack sufficient training data, limiting their utility\nfor evaluating data-driven approaches. To address these limitations, we\nintroduce FrontierCO, a comprehensive benchmark that covers eight canonical CO\nproblem types and evaluates 16 representative ML-based solvers--including graph\nneural networks and large language model (LLM) agents. FrontierCO features\nchallenging instances drawn from industrial applications and frontier CO\nresearch, offering both realistic problem difficulty and abundant training\ndata. Our empirical results provide critical insights into the strengths and\nlimitations of current ML methods, helping to guide more robust and practically\nrelevant advances at the intersection of machine learning and combinatorial\noptimization. Our data is available at\nhttps://huggingface.co/datasets/CO-Bench/FrontierCO.", "published": "2025-05-22 17:34:38", "link": "http://arxiv.org/abs/2505.16952v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ICYM2I: The illusion of multimodal informativeness under missingness", "abstract": "Multimodal learning is of continued interest in artificial intelligence-based\napplications, motivated by the potential information gain from combining\ndifferent types of data. However, modalities collected and curated during\ndevelopment may differ from the modalities available at deployment due to\nmultiple factors including cost, hardware failure, or -- as we argue in this\nwork -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation\nof the information gain associated with including an additional modality\nwithout accounting for missingness may result in improper estimates of that\nmodality's value in downstream tasks. Our work formalizes the problem of\nmissingness in multimodal learning and demonstrates the biases resulting from\nignoring this process. To address this issue, we introduce ICYM2I (In Case You\nMultimodal Missed It), a framework for the evaluation of predictive performance\nand information gain under missingness through inverse probability\nweighting-based correction. We demonstrate the importance of the proposed\nadjustment to estimate information gain under missingness on synthetic,\nsemi-synthetic, and real-world medical datasets.", "published": "2025-05-22 17:34:38", "link": "http://arxiv.org/abs/2505.16953v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "NY Real Estate Racial Equity Analysis via Applied Machine Learning", "abstract": "This study analyzes tract-level real estate ownership patterns in New York\nState (NYS) and New York City (NYC) to uncover racial disparities. We use an\nadvanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering,\nvalidated at 89.2% accuracy) to compare the predicted racial composition of\nproperty owners to the resident population from census data. We examine both a\nFull Model (statewide) and a Name-Only LSTM Model (NYC) to assess how\nincorporating geospatial context affects our predictions and disparity\nestimates. The results reveal significant inequities: White individuals hold a\ndisproportionate share of properties and property value relative to their\npopulation, while Black, Hispanic, and Asian communities are underrepresented\nas property owners. These disparities are most pronounced in minority-majority\nneighborhoods, where ownership is predominantly White despite a predominantly\nnon-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates\nthese gaps by reducing owner-occupied opportunities in urban minority\ncommunities. We provide a breakdown of ownership vs. population by race for\nmajority-White, -Black, -Hispanic, and -Asian tracts, identify those with\nextreme ownership disparities, and compare patterns in urban, suburban, and\nrural contexts. The findings underscore persistent racial inequity in property\nownership, reflecting broader historical and socio-economic forces, and\nhighlight the importance of data-driven approaches to address these issues.", "published": "2025-05-22 17:32:28", "link": "http://arxiv.org/abs/2505.16946v1", "categories": ["cs.CY", "cs.LG"], "primary_category": "cs.CY"}
{"title": "SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems", "abstract": "This work develops the underpinnings of self-supervised placement-aware\nrepresentation learning given spatially-distributed (multi-view and multimodal)\nsensor observations, motivated by the need to represent external environmental\nstate in multi-sensor IoT systems in a manner that correctly distills spatial\nphenomena from the distributed multi-vantage observations. The objective of\nsensing in IoT systems is, in general, to collectively represent an externally\nobserved environment given multiple vantage points from which sensory\nobservations occur. Pretraining of models that help interpret sensor data must\ntherefore encode the relation between signals observed by sensors and the\nobservers' vantage points in order to attain a representation that encodes the\nobserved spatial phenomena in a manner informed by the specific placement of\nthe measuring instruments, while allowing arbitrary placement. The work\nsignificantly advances self-supervised model pretraining from IoT signals\nbeyond current solutions that often overlook the distinctive spatial nature of\nIoT data. Our framework explicitly learns the dependencies between measurements\nand geometric observer layouts and structural characteristics, guided by a core\ndesign principle: the duality between signals and observer positions. We\nfurther provide theoretical analyses from the perspectives of information\ntheory and occlusion-invariant representation learning to offer insight into\nthe rationale behind our design. Experiments on three real-world\ndatasets--covering vehicle monitoring, human activity recognition, and\nearthquake localization--demonstrate the superior generalizability and\nrobustness of our method across diverse modalities, sensor placements,\napplication-level inference tasks, and spatial scales.", "published": "2025-05-22 17:26:23", "link": "http://arxiv.org/abs/2505.16936v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Risk-Averse Reinforcement Learning with Itakura-Saito Loss", "abstract": "Risk-averse reinforcement learning finds application in various high-stakes\nfields. Unlike classical reinforcement learning, which aims to maximize\nexpected returns, risk-averse agents choose policies that minimize risk,\noccasionally sacrificing expected value. These preferences can be framed\nthrough utility theory. We focus on the specific case of the exponential\nutility function, where we can derive the Bellman equations and employ various\nreinforcement learning algorithms with few modifications. However, these\nmethods suffer from numerical instability due to the need for exponent\ncomputation throughout the process. To address this, we introduce a numerically\nstable and mathematically sound loss function based on the Itakura-Saito\ndivergence for learning state-value and action-value functions. We evaluate our\nproposed loss function against established alternatives, both theoretically and\nempirically. In the experimental section, we explore multiple financial\nscenarios, some with known analytical solutions, and show that our loss\nfunction outperforms the alternatives.", "published": "2025-05-22 17:18:07", "link": "http://arxiv.org/abs/2505.16925v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation", "abstract": "A reliable uncertainty estimation method is the foundation of many modern\nout-of-distribution (OOD) detectors, which are critical for safe deployments of\ndeep learning models in the open world. In this work, we propose TULiP, a\ntheoretically-driven post-hoc uncertainty estimator for OOD detection. Our\napproach considers a hypothetical perturbation applied to the network before\nconvergence. Based on linearized training dynamics, we bound the effect of such\nperturbation, resulting in an uncertainty score computable by perturbing model\nparameters. Ultimately, our approach computes uncertainty from a set of sampled\npredictions. We visualize our bound on synthetic regression and classification\ndatasets. Furthermore, we demonstrate the effectiveness of TULiP using\nlarge-scale OOD detection benchmarks for image classification. Our method\nexhibits state-of-the-art performance, particularly for near-distribution\nsamples.", "published": "2025-05-22 17:16:41", "link": "http://arxiv.org/abs/2505.16923v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype", "abstract": "This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)\nmethods and introduces an experimental framework for scalable, interpretable\noffer selection, addressing the challenge of fast-changing offers. The approach\nmodels context at the product category level, allowing offers to span multiple\ncategories and enabling knowledge transfer across similar offers. This improves\nlearning efficiency and generalization in dynamic environments. The framework\nextends standard CMAB methodology to support multi-category contexts, and\nachieves scalability through efficient feature engineering and modular design.\nAdvanced features such as MPG (Member Purchase Gap) and MF (Matrix\nFactorization) capture nuanced user-offer interactions, with implementation in\nPython for practical deployment.\n  A key contribution is interpretability at scale: logistic regression models\nyield transparent weight vectors, accessible via a large language model (LLM)\ninterface for real-time, user-level tracking and explanation of evolving\npreferences. This enables the generation of detailed member profiles and\nidentification of behavioral patterns, supporting personalized offer\noptimization and enhancing trust in automated decisions. By situating our\nprototype alongside established paradigms like Generalized Linear Models and\nThompson Sampling, we demonstrate its value for both research and real-world\nCMAB applications.", "published": "2025-05-22 17:13:01", "link": "http://arxiv.org/abs/2505.16918v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Unsupervised Prompting for Graph Neural Networks", "abstract": "Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to\naddress the semantic gap between pre-training and fine-tuning steps. However,\nexisting GNN prompting methods rely on labeled data and involve lightweight\nfine-tuning for downstream tasks. Meanwhile, in-context learning methods for\nLarge Language Models (LLMs) have shown promising performance with no parameter\nupdating and no or minimal labeled data. Inspired by these approaches, in this\nwork, we first introduce a challenging problem setup to evaluate GNN prompting\nmethods. This setup encourages a prompting function to enhance a pre-trained\nGNN's generalization to a target dataset under covariate shift without updating\nthe GNN's parameters and with no labeled data. Next, we propose a fully\nunsupervised prompting method based on consistency regularization through\npseudo-labeling. We use two regularization techniques to align the prompted\ngraphs' distribution with the original data and reduce biased predictions.\nThrough extensive experiments under our problem setting, we demonstrate that\nour unsupervised approach outperforms the state-of-the-art prompting methods\nthat have access to labels.", "published": "2025-05-22 17:03:20", "link": "http://arxiv.org/abs/2505.16903v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "abstract": "Recent advances in Large Language Models (LLMs) have shown promise in\nfunction-level code generation, yet repository-level software engineering tasks\nremain challenging. Current solutions predominantly rely on proprietary LLM\nagents, which introduce unpredictability and limit accessibility, raising\nconcerns about data privacy and model customization. This paper investigates\nwhether open-source LLMs can effectively address repository-level tasks without\nrequiring agent-based approaches. We demonstrate this is possible by enabling\nLLMs to comprehend functions and files within codebases through their semantic\ninformation and structural dependencies. To this end, we introduce Code Graph\nModels (CGMs), which integrate repository code graph structures into the LLM's\nattention mechanism and map node attributes to the LLM's input space using a\nspecialized adapter. When combined with an agentless graph RAG framework, our\napproach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark\nusing the open-source Qwen2.5-72B model. This performance ranks first among\nopen weight models, second among methods with open-source systems, and eighth\noverall, surpassing the previous best open-source model-based method by 12.33%.", "published": "2025-05-22 17:00:55", "link": "http://arxiv.org/abs/2505.16901v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference", "abstract": "Graph Neural Networks (GNNs) have gained prominence for their ability to\nprocess graph-structured data across various domains. However, interpreting GNN\ndecisions remains a significant challenge, leading to the adoption of saliency\nmaps for identifying influential nodes and edges. Despite their utility, the\nreliability of GNN saliency maps has been questioned, particularly in terms of\ntheir robustness to noise. In this study, we propose a statistical testing\nframework to rigorously evaluate the significance of saliency maps. Our main\ncontribution lies in addressing the inflation of the Type I error rate caused\nby double-dipping of data, leveraging the framework of Selective Inference. Our\nmethod provides statistically valid $p$-values while controlling the Type I\nerror rate, ensuring that identified salient subgraphs contain meaningful\ninformation rather than random artifacts. To demonstrate the effectiveness of\nour method, we conduct experiments on both synthetic and real-world datasets,\nshowing its effectiveness in assessing the reliability of GNN interpretations.", "published": "2025-05-22 16:50:55", "link": "http://arxiv.org/abs/2505.16893v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning", "abstract": "We present a generalised Hanson-Wright inequality and use it to establish new\nstatistical insights into the geometry of data point-clouds. In the setting of\na general random function model of data, we clarify the roles played by three\nnotions of dimensionality: ambient intrinsic dimension $p_{\\mathrm{int}}$,\nwhich measures total variability across orthogonal feature directions;\ncorrelation rank, which measures functional complexity across samples; and\nlatent intrinsic dimension, which is the dimension of manifold structure hidden\nin data. Our analysis shows that in order for persistence diagrams to reveal\nlatent homology and for manifold structure to emerge it is sufficient that\n$p_{\\mathrm{int}}\\gg \\log n$, where $n$ is the sample size. Informed by these\ntheoretical perspectives, we revisit the ground-breaking neuroscience discovery\nof toroidal structure in grid-cell activity made by Gardner et al. (Nature,\n2022): our findings reveal, for the first time, evidence that this structure is\nin fact isometric to physical space, meaning that grid cell activity conveys a\ngeometrically faithful representation of the real world.", "published": "2025-05-22 16:34:15", "link": "http://arxiv.org/abs/2505.16879v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams", "abstract": "The rapid expansion of Internet of Things (IoT) devices has introduced\ncritical security challenges, underscoring the need for accurate anomaly\ndetection. Although numerous studies have proposed machine learning (ML)\nmethods for this purpose, limited research systematically examines how\ndifferent preprocessing steps--normalization, transformation, and feature\nselection--interact with distinct model architectures. To address this gap,\nthis paper presents a multi-step evaluation framework assessing the combined\nimpact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder\nneural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the\nIoTID20 dataset shows that GBoosting consistently delivers superior accuracy\nacross preprocessing configurations, while RNN-LSTM shows notable gains with\nz-score normalization and autoencoders excel in recall, making them well-suited\nfor unsupervised scenarios. By offering a structured analysis of preprocessing\ndecisions and their interplay with various ML techniques, the proposed\nframework provides actionable guidance to enhance anomaly detection performance\nin IoT environments.", "published": "2025-05-22 16:28:22", "link": "http://arxiv.org/abs/2505.16872v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft", "abstract": "This paper addresses the System Identification (SYSID) problem within the\nframework of federated learning. We introduce a novel algorithm, Incremental\nClustering-based federated learning method for SYSID (IC-SYSID), designed to\ntackle SYSID challenges across multiple data sources without prior knowledge.\nIC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to\neliminate the dependency on the prior knowledge of the dataset. CC starts with\na single cluster model and assigns similar local workers to the same clusters\nby dynamically increasing the number of clusters. To reduce the number of\nclusters generated by CC, we introduce ClusterMerge, where similar cluster\nmodels are merged. We also introduce enhanced ClusterCraft to reduce the\ngeneration of similar cluster models during the training. Moreover, IC-SYSID\naddresses cluster model instability by integrating a regularization term into\nthe loss function and initializing cluster models with scaled Glorot\ninitialization. It also utilizes a mini-batch deep learning approach to manage\nlarge SYSID datasets during local training. Through the experiments conducted\non a real-world representing SYSID problem, where a fleet of vehicles\ncollaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high\nSYSID performance while preventing the learning of unstable clusters.", "published": "2025-05-22 16:15:12", "link": "http://arxiv.org/abs/2505.16857v1", "categories": ["cs.LG", "I.2.8; I.5.3; I.2.11"], "primary_category": "cs.LG"}
{"title": "Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning", "abstract": "Long-term planning, as in reinforcement learning (RL), involves finding\nstrategies: actions that collectively work toward a goal rather than\nindividually optimizing their immediate outcomes. As part of a strategy, some\nactions are taken at the expense of short-term benefit to enable future actions\nwith even greater returns. These actions are only advantageous if followed up\nby the actions they facilitate, consequently, they would not have been taken if\nthose follow-ups were not available. In this paper, we quantify such\ndependencies between planned actions with strategic link scores: the drop in\nthe likelihood of one decision under the constraint that a follow-up decision\nis no longer available. We demonstrate the utility of strategic link scores\nthrough three practical applications: (i) explaining black-box RL agents by\nidentifying strategically linked pairs among decisions they make, (ii)\nimproving the worst-case performance of decision support systems by\ndistinguishing whether recommended actions can be adopted as standalone\nimprovements or whether they are strategically linked hence requiring a\ncommitment to a broader strategy to be effective, and (iii) characterizing the\nplanning processes of non-RL agents purely through interventions aimed at\nmeasuring strategic link scores - as an example, we consider a realistic\ntraffic simulator and analyze through road closures the effective planning\nhorizon of the emergent routing behavior of many drivers.", "published": "2025-05-22 16:04:17", "link": "http://arxiv.org/abs/2505.16833v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Contextual Learning for Stochastic Optimization", "abstract": "Motivated by stochastic optimization, we introduce the problem of learning\nfrom samples of contextual value distributions. A contextual value distribution\ncan be understood as a family of real-valued distributions, where each sample\nconsists of a context $x$ and a random variable drawn from the corresponding\nreal-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn\nan empirical distribution $D'_x$ for each context, ensuring a small L\\'evy\ndistance to $D_x$. We apply this result to obtain the sample complexity bounds\nfor the learning of an $\\epsilon$-optimal policy for stochastic optimization\nproblems defined on an unknown contextual value distribution. The sample\ncomplexity is shown to be polynomial for the general case of strongly monotone\nand stable optimization problems, including Single-item Revenue Maximization,\nPandora's Box and Optimal Stopping.", "published": "2025-05-22 16:01:49", "link": "http://arxiv.org/abs/2505.16829v1", "categories": ["cs.LG", "cs.DS", "cs.GT"], "primary_category": "cs.LG"}
{"title": "LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols", "abstract": "Integrating large AI models (LAMs) into 6G mobile networks promises to\nredefine protocol design and control-plane intelligence by enabling autonomous,\ncognitive network operations. While industry concepts, such as ETSI's\nExperiential Networked Intelligence (ENI), envision LAM-driven agents for\nadaptive network slicing and intent-based management, practical implementations\nstill face challenges in protocol literacy and real-world deployment. This\npaper presents an end-to-end demonstration of a LAM that generates\nstandards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as\npart of control-plane procedures inside a gNB. We treat RRC messaging as a\ndomain-specific language and fine-tune a decoder-only transformer model (LLaMA\nclass) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages\nlinearized to retain their ASN.1 syntactic structure before standard byte-pair\nencoding tokenization. This enables combinatorial generalization over RRC\nprotocol states while minimizing training overhead. On 30k field-test\nrequest-response pairs, our 8 B model achieves a median cosine similarity of\n0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a\nzero-shot LLaMA-3 8B baseline -- indicating substantially improved structural\nand semantic RRC fidelity. Overall, our results show that LAMs, when augmented\nwith Radio Access Network (RAN)-specific reasoning, can directly orchestrate\ncontrol-plane procedures, representing a stepping stone toward the AI-native\nair-interface paradigm. Beyond RRC emulation, this work lays the groundwork for\nfuture AI-native wireless standards.", "published": "2025-05-22 15:55:56", "link": "http://arxiv.org/abs/2505.16821v1", "categories": ["cs.NI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting", "abstract": "We introduce FlowMixer, a neural architecture that leverages constrained\nmatrix operations to model structured spatiotemporal patterns. At its core,\nFlowMixer incorporates non-negative matrix mixing layers within a reversible\nmapping framework-applying transforms before mixing and their inverses\nafterward. This shape-preserving design enables a Kronecker-Koopman eigenmode\nframework that bridges statistical learning with dynamical systems theory,\nproviding interpretable spatiotemporal patterns and facilitating direct\nalgebraic manipulation of prediction horizons without retraining. Extensive\nexperiments across diverse domains demonstrate FlowMixer's robust long-horizon\nforecasting capabilities while effectively modeling physical phenomena such as\nchaotic attractors and turbulent flows. These results suggest that\narchitectural constraints can simultaneously enhance predictive performance and\nmathematical interpretability in neural forecasting systems.", "published": "2025-05-22 15:28:47", "link": "http://arxiv.org/abs/2505.16786v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Output Gaussian Processes for Graph-Structured Data", "abstract": "Graph-structured data is a type of data to be obtained associated with a\ngraph structure where vertices and edges describe some kind of data\ncorrelation. This paper proposes a regression method on graph-structured data,\nwhich is based on multi-output Gaussian processes (MOGP), to capture both the\ncorrelation between vertices and the correlation between associated data. The\nproposed formulation is built on the definition of MOGP. This allows it to be\napplied to a wide range of data configurations and scenarios. Moreover, it has\nhigh expressive capability due to its flexibility in kernel design. It includes\nexisting methods of Gaussian processes for graph-structured data as special\ncases and is possible to remove restrictions on data configurations, model\nselection, and inference scenarios in the existing methods. The performance of\nextensions achievable by the proposed formulation is evaluated through computer\nexperiments with synthetic and real data.", "published": "2025-05-22 14:59:21", "link": "http://arxiv.org/abs/2505.16755v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects", "abstract": "Offline reinforcement learning (RL) has gained traction as a powerful\nparadigm for learning control policies from pre-collected data, eliminating the\nneed for costly or risky online interactions. While many open-source libraries\noffer robust implementations of offline RL algorithms, they all rely on\ndatasets composed of experience tuples consisting of state, action, next state,\nand reward. Managing, curating, and distributing such datasets requires\nsuitable infrastructure. Although static datasets exist for established\nbenchmark problems, no standardized or scalable solution supports developing\nand sharing datasets for novel or user-defined benchmarks. To address this gap,\nwe introduce PyTupli, a Python-based tool to streamline the creation, storage,\nand dissemination of benchmark environments and their corresponding tuple\ndatasets. PyTupli includes a lightweight client library with defined interfaces\nfor uploading and retrieving benchmarks and data. It supports fine-grained\nfiltering at both the episode and tuple level, allowing researchers to curate\nhigh-quality, task-specific datasets. A containerized server component enables\nproduction-ready deployment with authentication, access control, and automated\ncertificate provisioning for secure use. By addressing key barriers in dataset\ninfrastructure, PyTupli facilitates more collaborative, reproducible, and\nscalable offline RL research.", "published": "2025-05-22 14:59:20", "link": "http://arxiv.org/abs/2505.16754v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Revenue Optimization with Price-Sensitive and Interdependent Demand", "abstract": "As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3],\nRevenue Management aims to maximize an organization's revenue by considering\nthree types of decision categories: structural, pricing, and quantity. In this\ndocument, our primary focus will be on decisions related to pricing and\nquantity for the sale of airline tickets on a direct flight over a certain\nnumber of time periods. More specifically, we will only focus on the\noptimization aspect of this problem. We will assume the demand data to be\ngiven, since Air France estimates it beforehand using real data. Similarly, we\nassume all price options to be predetermined by Air France's algorithms and\nverified by their analysts. Our objective will be to maximize the revenue of a\ndirect flight by choosing the prices for each product from the predefined set\nof options.\n  --\n  Comme d\\'ecrit par Kalyan T. Talluri et Garrett J. Van Ryzin dans leur\nouvrage [3], le Revenue Management consiste en la maximisation du revenu d'un\norganisme \\`a partir de trois types de cat\\'egories de d\\'ecision :\nstructurelles, prix et quantit\\'e. Dans ce document, nous nous int\\'eresserons\nprincipalement aux d\\'ecisions de type prix et quantit\\'e pour la vente de\nbillets d'avion sur un vol direct au cours d'un certain nombre de pas de temps.\nPlus pr\\'ecis\\'ement, nous nous situerons dans la partie optimisation du\nprobl\\`eme. Nous prendrons ainsi les donn\\'ees de demande comme acquises, car\nelles sont estim\\'ees au pr\\'ealable par Air France \\`a partir des donn\\'ees\nr\\'eelles. De m\\^eme, pour chaque produit que l'on cherchera \\`a vendre, on\nnous impose en amont les prix possibles que l'on a droit d'utiliser et qui se\nbasent sur des algorithmes d'Air France dont les r\\'esultats sont v\\'erifi\\'es\npar des analystes. Notre but sera alors de maximiser le revenu d'un vol direct\nen choisissant les prix de chaque produit parmi ceux impos\\'es.", "published": "2025-05-22 14:57:43", "link": "http://arxiv.org/abs/2505.16748v1", "categories": ["cs.LG", "math.OC", "90C59", "G.1.6"], "primary_category": "cs.LG"}
{"title": "Meta-reinforcement learning with minimum attention", "abstract": "Minimum attention applies the least action principle in the changes of\ncontrol concerning state and time, first proposed by Brockett. The involved\nregularization is highly relevant in emulating biological control, such as\nmotor learning. We apply minimum attention in reinforcement learning (RL) as\npart of the rewards and investigate its connection to meta-learning and\nstabilization. Specifically, model-based meta-learning with minimum attention\nis explored in high-dimensional nonlinear dynamics. Ensemble-based model\nlearning and gradient-based meta-policy learning are alternately performed.\nEmpirically, we show that the minimum attention does show outperforming\ncompetence in comparison to the state-of-the-art algorithms in model-free and\nmodel-based RL, i.e., fast adaptation in few shots and variance reduction from\nthe perturbations of the model and environment. Furthermore, the minimum\nattention demonstrates the improvement in energy efficiency.", "published": "2025-05-22 14:53:06", "link": "http://arxiv.org/abs/2505.16741v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?", "abstract": "Oversmoothing has long been identified as a major limitation of Graph Neural\nNetworks (GNNs): input node features are smoothed at each layer and converge to\na non-informative representation, if the weights of the GNN are sufficiently\nbounded. This assumption is crucial: if, on the contrary, the weights are\nsufficiently large, then oversmoothing may not happen. Theoretically, GNN could\nthus learn to not oversmooth. However it does not really happen in practice,\nwhich prompts us to examine oversmoothing from an optimization point of view.\nIn this paper, we analyze backward oversmoothing, that is, the notion that\nbackpropagated errors used to compute gradients are also subject to\noversmoothing from output to input. With non-linear activation functions, we\noutline the key role of the interaction between forward and backward smoothing.\nMoreover, we show that, due to backward oversmoothing, GNNs provably exhibit\nmany spurious stationary points: as soon as the last layer is trained, the\nwhole GNN is at a stationary point. As a result, we can exhibit regions where\ngradients are near-zero while the loss stays high. The proof relies on the fact\nthat, unlike forward oversmoothing, backward errors are subjected to a linear\noversmoothing even in the presence of non-linear activation function, such that\nthe average of the output error plays a key role. Additionally, we show that\nthis phenomenon is specific to deep GNNs, and exhibit counter-example\nMulti-Layer Perceptron. This paper is a step toward a more complete\ncomprehension of the optimization landscape specific to GNNs.", "published": "2025-05-22 14:51:38", "link": "http://arxiv.org/abs/2505.16736v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Maximum Total Correlation Reinforcement Learning", "abstract": "Simplicity is a powerful inductive bias. In reinforcement learning,\nregularization is used for simpler policies, data augmentation for simpler\nrepresentations, and sparse reward functions for simpler objectives, all that,\nwith the underlying motivation to increase generalizability and robustness by\nfocusing on the essentials. Supplementary to these techniques, we investigate\nhow to promote simple behavior throughout the episode. To that end, we\nintroduce a modification of the reinforcement learning problem that\nadditionally maximizes the total correlation within the induced trajectories.\nWe propose a practical algorithm that optimizes all models, including policy\nand state representation, based on a lower-bound approximation. In simulated\nrobot environments, our method naturally generates policies that induce\nperiodic and compressible trajectories, and that exhibit superior robustness to\nnoise and changes in dynamics compared to baseline methods, while also\nimproving performance in the original tasks.", "published": "2025-05-22 14:48:00", "link": "http://arxiv.org/abs/2505.16734v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Forward-only Diffusion Probabilistic Models", "abstract": "This work presents a forward-only diffusion (FoD) approach for generative\nmodelling. In contrast to traditional diffusion models that rely on a coupled\nforward-backward diffusion scheme, FoD directly learns data generation through\na single forward diffusion process, yielding a simple yet efficient generative\nframework. The core of FoD is a state-dependent linear stochastic differential\nequation that involves a mean-reverting term in both the drift and diffusion\nfunctions. This mean-reversion property guarantees the convergence to clean\ndata, naturally simulating a stochastic interpolation between source and target\ndistributions. More importantly, FoD is analytically tractable and is trained\nusing a simple stochastic flow matching objective, enabling a few-step\nnon-Markov chain sampling during inference. The proposed FoD model, despite its\nsimplicity, achieves competitive performance on various image-conditioned\n(e.g., image restoration) and unconditional generation tasks, demonstrating its\neffectiveness in generative modelling. Our code is available at\nhttps://github.com/Algolzw/FoD.", "published": "2025-05-22 14:47:07", "link": "http://arxiv.org/abs/2505.16733v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Robust LLM Fingerprinting via Domain-Specific Watermarks", "abstract": "As open-source language models (OSMs) grow more capable and are widely shared\nand finetuned, ensuring model provenance, i.e., identifying the origin of a\ngiven model instance, has become an increasingly important issue. At the same\ntime, existing backdoor-based model fingerprinting techniques often fall short\nof achieving key requirements of real-world model ownership detection. In this\nwork, we build on the observation that while current open-source model\nwatermarks fail to achieve reliable content traceability, they can be\neffectively adapted to address the challenge of model provenance. To this end,\nwe introduce the concept of domain-specific watermarking for model\nfingerprinting. Rather than watermarking all generated content, we train the\nmodel to embed watermarks only within specified subdomains (e.g., particular\nlanguages or topics). This targeted approach ensures detection reliability,\nwhile improving watermark durability and quality under a range of real-world\ndeployment settings. Our evaluations show that domain-specific watermarking\nenables model fingerprinting with strong statistical guarantees, controllable\nfalse positive rates, high detection power, and preserved generation quality.\nMoreover, we find that our fingerprints are inherently stealthy and naturally\nrobust to real-world variability across deployment scenarios.", "published": "2025-05-22 14:32:23", "link": "http://arxiv.org/abs/2505.16723v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Experimental robustness benchmark of quantum neural network on a superconducting quantum processor", "abstract": "Quantum machine learning (QML) models, like their classical counterparts, are\nvulnerable to adversarial attacks, hindering their secure deployment. Here, we\nreport the first systematic experimental robustness benchmark for 20-qubit\nquantum neural network (QNN) classifiers executed on a superconducting\nprocessor. Our benchmarking framework features an efficient adversarial attack\nalgorithm designed for QNNs, enabling quantitative characterization of\nadversarial robustness and robustness bounds. From our analysis, we verify that\nadversarial training reduces sensitivity to targeted perturbations by\nregularizing input gradients, significantly enhancing QNN's robustness.\nAdditionally, our analysis reveals that QNNs exhibit superior adversarial\nrobustness compared to classical neural networks, an advantage attributed to\ninherent quantum noise. Furthermore, the empirical upper bound extracted from\nour attack experiments shows a minimal deviation ($3 \\times 10^{-3}$) from the\ntheoretical lower bound, providing strong experimental confirmation of the\nattack's effectiveness and the tightness of fidelity-based robustness bounds.\nThis work establishes a critical experimental framework for assessing and\nimproving quantum adversarial robustness, paving the way for secure and\nreliable QML applications.", "published": "2025-05-22 14:18:14", "link": "http://arxiv.org/abs/2505.16714v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Sharp concentration of uniform generalization errors in binary linear classification", "abstract": "We examine the concentration of uniform generalization errors around their\nexpectation in binary linear classification problems via an isoperimetric\nargument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities\nfor the joint distribution of the output labels and the label-weighted input\nvectors, which we apply to derive concentration bounds. The derived\nconcentration bounds are sharp up to moderate multiplicative constants by those\nunder well-balanced labels. In asymptotic analysis, we also show that almost\nsure convergence of uniform generalization errors to their expectation occurs\nin very broad settings, such as proportionally high-dimensional regimes. Using\nthis convergence, we establish uniform laws of large numbers under\ndimension-free conditions.", "published": "2025-05-22 14:14:50", "link": "http://arxiv.org/abs/2505.16713v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Learning Genomic Structure from $k$-mers", "abstract": "Sequencing a genome to determine an individual's DNA produces an enormous\nnumber of short nucleotide subsequences known as reads, which must be\nreassembled to reconstruct the full genome. We present a method for analyzing\nthis type of data using contrastive learning, in which an encoder model is\ntrained to produce embeddings that cluster together sequences from the same\ngenomic region. The sequential nature of genomic regions is preserved in the\nform of trajectories through this embedding space. Trained solely to reflect\nthe structure of the genome, the resulting model provides a general\nrepresentation of $k$-mer sequences, suitable for a range of downstream tasks\ninvolving read data. We apply our framework to learn the structure of the $E.\\\ncoli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read\nmapping and identification of structural variations. Furthermore, we illustrate\nthe potential of using this type of model for metagenomic species\nidentification. We show how incorporating a domain-specific noise model can\nenhance embedding robustness, and how a supervised contrastive learning setting\ncan be adopted when a linear reference genome is available, by introducing a\ndistance thresholding parameter $\\Gamma$. The model can also be trained fully\nself-supervised on read data, enabling analysis without the need to construct a\nfull genome assembly using specialized algorithms. Small prediction heads based\non a pre-trained embedding are shown to perform on par with BWA-aln, the\ncurrent gold standard approach for aDNA mapping, in terms of accuracy and\nruntime for short genomes. Given the method's favorable scaling properties with\nrespect to total genome size, inference using our approach is highly promising\nfor metagenomic applications and for mapping to genomes comparable in size to\nthe human genome.", "published": "2025-05-22 13:46:18", "link": "http://arxiv.org/abs/2505.16680v1", "categories": ["cs.LG", "q-bio.GN", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "On the Out-of-Distribution Generalization of Self-Supervised Learning", "abstract": "In this paper, we focus on the out-of-distribution (OOD) generalization of\nself-supervised learning (SSL). By analyzing the mini-batch construction during\nthe SSL training phase, we first give one plausible explanation for SSL having\nOOD generalization. Then, from the perspective of data generation and causal\ninference, we analyze and conclude that SSL learns spurious correlations during\nthe training process, which leads to a reduction in OOD generalization. To\naddress this issue, we propose a post-intervention distribution (PID) grounded\nin the Structural Causal Model. PID offers a scenario where the spurious\nvariable and label variable is mutually independent. Besides, we demonstrate\nthat if each mini-batch during SSL training satisfies PID, the resulting SSL\nmodel can achieve optimal worst-case OOD performance. This motivates us to\ndevelop a batch sampling strategy that enforces PID constraints through the\nlearning of a latent variable model. Through theoretical analysis, we\ndemonstrate the identifiability of the latent variable model and validate the\neffectiveness of the proposed sampling strategy. Experiments conducted on\nvarious downstream OOD tasks demonstrate the effectiveness of the proposed\nsampling strategy.", "published": "2025-05-22 13:40:00", "link": "http://arxiv.org/abs/2505.16675v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data", "abstract": "Blockchain transaction data exhibits high dimensionality, noise, and\nintricate feature entanglement, presenting significant challenges for\ntraditional clustering algorithms. In this study, we conduct a comparative\nanalysis of three clustering approaches: (1) Classical K-Means Clustering,\napplied to pre-processed feature representations; (2) Hybrid Clustering,\nwherein classical features are enhanced with quantum random features extracted\nusing randomly initialized quantum neural networks (QNNs); and (3) Fully\nQuantum Clustering, where a QNN is trained in a self-supervised manner\nleveraging a SwAV-based loss function to optimize the feature space for\nclustering directly. The proposed experimental framework systematically\ninvestigates the impact of quantum circuit depth and the number of learned\nprototypes, demonstrating that even shallow quantum circuits can effectively\nextract meaningful non-linear representations, significantly improving\nclustering performance.", "published": "2025-05-22 13:37:07", "link": "http://arxiv.org/abs/2505.16672v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Stochastic Forward-Forward Learning through Representational Dimensionality Compression", "abstract": "The Forward-Forward (FF) algorithm provides a bottom-up alternative to\nbackpropagation (BP) for training neural networks, relying on a layer-wise\n\"goodness\" function to guide learning. Existing goodness functions, inspired by\nenergy-based learning (EBL), are typically defined as the sum of squared\npost-synaptic activations, neglecting the correlations between neurons. In this\nwork, we propose a novel goodness function termed dimensionality compression\nthat uses the effective dimensionality (ED) of fluctuating neural responses to\nincorporate second-order statistical structure. Our objective minimizes ED for\nclamped inputs when noise is considered while maximizing it across the sample\ndistribution, promoting structured representations without the need to prepare\nnegative samples. We demonstrate that this formulation achieves competitive\nperformance compared to other non-BP methods. Moreover, we show that noise\nplays a constructive role that can enhance generalization and improve inference\nwhen predictions are derived from the mean of squared outputs, which is\nequivalent to making predictions based on the energy term. Our findings\ncontribute to the development of more biologically plausible learning\nalgorithms and suggest a natural fit for neuromorphic computing, where\nstochasticity is a computational resource rather than a nuisance. The code is\navailable at https://github.com/ZhichaoZhu/StochasticForwardForward", "published": "2025-05-22 13:19:29", "link": "http://arxiv.org/abs/2505.16649v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Learning non-equilibrium diffusions with Schr\u00f6dinger bridges: from exactly solvable to simulation-free", "abstract": "We consider the Schr\\\"odinger bridge problem which, given ensemble\nmeasurements of the initial and final configurations of a stochastic dynamical\nsystem and some prior knowledge on the dynamics, aims to reconstruct the \"most\nlikely\" evolution of the system compatible with the data. Most existing\nliterature assume Brownian reference dynamics and are implicitly limited to\npotential-driven dynamics. We depart from this regime and consider reference\nprocesses described by a multivariate Ornstein-Uhlenbeck process with generic\ndrift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is\nasymmetric, this corresponds to a non-equilibrium system with non-conservative\nforces at play: this is important for applications to biological systems, which\nare naturally exist out-of-equilibrium. In the case of Gaussian marginals, we\nderive explicit expressions that characterise the solution of both the static\nand dynamic Schr\\\"odinger bridge. For general marginals, we propose mvOU-OTFM,\na simulation-free algorithm based on flow and score matching for learning the\nSchr\\\"odinger bridge. In application to a range of problems based on synthetic\nand real single cell data, we demonstrate that mvOU-OTFM achieves higher\naccuracy compared to competing methods, whilst being significantly faster to\ntrain.", "published": "2025-05-22 13:17:30", "link": "http://arxiv.org/abs/2505.16644v1", "categories": ["stat.ML", "cs.LG", "math.OC", "62M45, 49N10"], "primary_category": "stat.ML"}
{"title": "Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity", "abstract": "Fairness through Unawareness (FtU) describes the idea that discrimination\nagainst demographic groups can be avoided by not considering group membership\nin the decisions or predictions. This idea has long been criticized in the\nmachine learning literature as not being sufficient to ensure fairness. In\naddition, the use of additional features is typically thought to increase the\naccuracy of the predictions for all groups, so that FtU is sometimes thought to\nbe detrimental to all groups. In this paper, we show both theoretically and\nempirically that FtU can reduce algorithmic discrimination without necessarily\nreducing accuracy. We connect this insight with the literature on Model\nMultiplicity, to which we contribute with novel theoretical and empirical\nresults. Furthermore, we illustrate how, in a real-life application, FtU can\ncontribute to the deployment of more equitable policies without losing\nefficacy. Our findings suggest that FtU is worth considering in practical\napplications, particularly in high-risk scenarios, and that the use of\nprotected attributes such as gender in predictive models should be accompanied\nby a clear and well-founded justification.", "published": "2025-05-22 13:11:33", "link": "http://arxiv.org/abs/2505.16638v1", "categories": ["cs.LG", "cs.CY", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multivariate Latent Recalibration for Conditional Normalizing Flows", "abstract": "Reliably characterizing the full conditional distribution of a multivariate\nresponse variable given a set of covariates is crucial for trustworthy\ndecision-making. However, misspecified or miscalibrated multivariate models may\nyield a poor approximation of the joint distribution of the response variables,\nleading to unreliable predictions and suboptimal decisions. Furthermore,\nstandard recalibration methods are primarily limited to univariate settings,\nwhile conformal prediction techniques, despite generating multivariate\nprediction regions with coverage guarantees, do not provide a full probability\ndensity function. We address this gap by first introducing a novel notion of\nlatent calibration, which assesses probabilistic calibration in the latent\nspace of a conditional normalizing flow. Second, we propose latent\nrecalibration (LR), a novel post-hoc model recalibration method that learns a\ntransformation of the latent space with finite-sample bounds on latent\ncalibration. Unlike existing methods, LR produces a recalibrated distribution\nwith an explicit multivariate density function while remaining computationally\nefficient. Extensive experiments on both tabular and image datasets show that\nLR consistently improves latent calibration error and the negative\nlog-likelihood of the recalibrated models.", "published": "2025-05-22 13:08:20", "link": "http://arxiv.org/abs/2505.16636v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "WikiDBGraph: Large-Scale Database Graph of Wikidata for Collaborative Learning", "abstract": "Tabular data, ubiquitous and rich in informational value, is an increasing\nfocus for deep representation learning, yet progress is hindered by studies\ncentered on single tables or isolated databases, which limits model\ncapabilities due to data scale. While collaborative learning approaches such as\nfederated learning, transfer learning, split learning, and tabular foundation\nmodels aim to learn from multiple correlated databases, they are challenged by\na scarcity of real-world interconnected tabular resources. Current data lakes\nand corpora largely consist of isolated databases lacking defined\ninter-database correlations. To overcome this, we introduce WikiDBGraph, a\nlarge-scale graph of 100,000 real-world tabular databases from WikiData,\ninterconnected by 17 million edges and characterized by 13 node and 12 edge\nproperties derived from its database schema and data distribution.\nWikiDBGraph's weighted edges identify both instance- and feature-overlapped\ndatabases. Experiments on these newly identified databases confirm that\ncollaborative learning yields superior performance, thereby offering\nconsiderable promise for structured foundation model training while also\nexposing key challenges and future directions for learning from interconnected\ntabular data.", "published": "2025-05-22 13:07:06", "link": "http://arxiv.org/abs/2505.16635v1", "categories": ["cs.DB", "cs.LG"], "primary_category": "cs.DB"}
{"title": "CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models", "abstract": "Causal discovery for dynamical systems poses a major challenge in fields\nwhere active interventions are infeasible. Most methods used to investigate\nthese systems and their associated benchmarks are tailored to deterministic,\nlow-dimensional and weakly nonlinear time-series data. To address these\nlimitations, we present CausalDynamics, a large-scale benchmark and extensible\ndata generation framework to advance the structural discovery of dynamical\ncausal models. Our benchmark consists of true causal graphs derived from\nthousands of coupled ordinary and stochastic differential equations as well as\ntwo idealized climate models. We perform a comprehensive evaluation of\nstate-of-the-art causal discovery algorithms for graph reconstruction on\nsystems with noisy, confounded, and lagged dynamics. CausalDynamics consists of\na plug-and-play, build-your-own coupling workflow that enables the construction\nof a hierarchy of physical systems. We anticipate that our framework will\nfacilitate the development of robust causal discovery algorithms that are\nbroadly applicable across domains while addressing their unique challenges. We\nprovide a user-friendly implementation and documentation on\nhttps://kausable.github.io/CausalDynamics.", "published": "2025-05-22 12:54:30", "link": "http://arxiv.org/abs/2505.16620v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Training on Plausible Counterfactuals Removes Spurious Correlations", "abstract": "Plausible counterfactual explanations (p-CFEs) are perturbations that\nminimally modify inputs to change classifier decisions while remaining\nplausible under the data distribution. In this study, we demonstrate that\nclassifiers can be trained on p-CFEs labeled with induced \\emph{incorrect}\ntarget classes to classify unperturbed inputs with the original labels. While\nprevious studies have shown that such learning is possible with adversarial\nperturbations, we extend this paradigm to p-CFEs. Interestingly, our\nexperiments reveal that learning from p-CFEs is even more effective: the\nresulting classifiers achieve not only high in-distribution accuracy but also\nexhibit significantly reduced bias with respect to spurious correlations.", "published": "2025-05-22 12:17:25", "link": "http://arxiv.org/abs/2505.16583v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Large Language Model-Empowered Interactive Load Forecasting", "abstract": "The growing complexity of power systems has made accurate load forecasting\nmore important than ever. An increasing number of advanced load forecasting\nmethods have been developed. However, the static design of current methods\noffers no mechanism for human-model interaction. As the primary users of\nforecasting models, system operators often find it difficult to understand and\napply these advanced models, which typically requires expertise in artificial\nintelligence (AI). This also prevents them from incorporating their experience\nand real-world contextual understanding into the forecasting process. Recent\nbreakthroughs in large language models (LLMs) offer a new opportunity to\naddress this issue. By leveraging their natural language understanding and\nreasoning capabilities, we propose an LLM-based multi-agent collaboration\nframework to bridge the gap between human operators and forecasting models. A\nset of specialized agents is designed to perform different tasks in the\nforecasting workflow and collaborate via a dedicated communication mechanism.\nThis framework embeds interactive mechanisms throughout the load forecasting\npipeline, reducing the technical threshold for non-expert users and enabling\nthe integration of human experience. Our experiments demonstrate that the\ninteractive load forecasting accuracy can be significantly improved when users\nprovide proper insight in key stages. Our cost analysis shows that the\nframework remains affordable, making it practical for real-world deployment.", "published": "2025-05-22 12:11:10", "link": "http://arxiv.org/abs/2505.16577v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices", "abstract": "The demand for machine learning (ML) model training on edge devices is\nescalating due to data privacy and personalized service needs. However, we\nobserve that current on-device model training is hampered by the\nunder-utilization of on-device data, due to low training throughput, limited\nstorage and diverse data importance. To improve data resource utilization, we\npropose a two-stage data selection framework {\\sf Titan} to select the most\nimportant data batch from streaming data for model training with guaranteed\nefficiency and effectiveness. Specifically, in the first stage, {\\sf Titan}\nfilters out a candidate dataset with potentially high importance in a\ncoarse-grained manner.In the second stage of fine-grained selection, we propose\na theoretically optimal data selection strategy to identify the data batch with\nthe highest model performance improvement to current training round. To further\nenhance time-and-resource efficiency, {\\sf Titan} leverages a pipeline to\nco-execute data selection and model training, and avoids resource conflicts by\nexploiting idle computing resources. We evaluate {\\sf Titan} on real-world edge\ndevices and three representative edge computing tasks with diverse models and\ndata modalities. Empirical results demonstrate that {\\sf Titan} achieves up to\n$43\\%$ reduction in training time and $6.2\\%$ increase in final accuracy with\nminor system overhead, such as data processing delay, memory footprint and\nenergy consumption.", "published": "2025-05-22 11:53:48", "link": "http://arxiv.org/abs/2505.16563v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations", "abstract": "The machine learning methods for data-driven identification of partial\ndifferential equations (PDEs) are typically defined for a given number of\nspatial dimensions and a choice of coordinates the data have been collected in.\nThis dependence prevents the learned evolution equation from generalizing to\nother spaces. In this work, we reformulate the problem in terms of coordinate-\nand dimension-independent representations, paving the way toward what we call\n``spatially liberated\" PDE learning. To this end, we employ a machine learning\napproach to predict the evolution of scalar field systems expressed in the\nformalism of exterior calculus, which is coordinate-free and immediately\ngeneralizes to arbitrary dimensions by construction. We demonstrate the\nperformance of this approach in the FitzHugh-Nagumo and Barkley\nreaction-diffusion models, as well as the Patlak-Keller-Segel model informed by\nin-situ chemotactic bacteria observations. We provide extensive numerical\nexperiments that demonstrate that our approach allows for seamless transitions\nacross various spatial contexts. We show that the field dynamics learned in one\nspace can be used to make accurate predictions in other spaces with different\ndimensions, coordinate systems, boundary conditions, and curvatures.", "published": "2025-05-22 11:37:55", "link": "http://arxiv.org/abs/2505.16549v1", "categories": ["cs.LG", "35Q92, 68T07", "I.2.6; G.1.8"], "primary_category": "cs.LG"}
{"title": "Incremental Sequence Classification with Temporal Consistency", "abstract": "We address the problem of incremental sequence classification, where\npredictions are updated as new elements in the sequence are revealed. Drawing\non temporal-difference learning from reinforcement learning, we identify a\ntemporal-consistency condition that successive predictions should satisfy. We\nleverage this condition to develop a novel loss function for training\nincremental sequence classifiers. Through a concrete example, we demonstrate\nthat optimizing this loss can offer substantial gains in data efficiency. We\napply our method to text classification tasks and show that it improves\npredictive accuracy over competing approaches on several benchmark datasets. We\nfurther evaluate our approach on the task of verifying large language model\ngenerations for correctness in grade-school math problems. Our results show\nthat models trained with our method are better able to distinguish promising\ngenerations from unpromising ones after observing only a few tokens.", "published": "2025-05-22 11:37:53", "link": "http://arxiv.org/abs/2505.16548v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "HOFT: Householder Orthogonal Fine-tuning", "abstract": "Adaptation of foundation models using low-rank methods is a widespread\napproach. Another way to adapt these models is to employ orthogonal fine-tuning\nmethods, which are less time and memory efficient despite their good\ngeneralization properties. In this work, we propose Householder Orthogonal\nFine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to\nalleviate time and space complexity. Moreover, some theoretical properties of\nthe orthogonal fine-tuning paradigm are explored. From this exploration, Scaled\nHouseholder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are\nevaluated in downstream tasks, namely commonsense reasoning, machine\ntranslation, subject-driven generation and mathematical reasoning. Compared\nwith state-of-the-art adaptation methods, HOFT and SHOFT show comparable or\nbetter results.", "published": "2025-05-22 11:20:35", "link": "http://arxiv.org/abs/2505.16531v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Joint Relational Database Generation via Graph-Conditional Diffusion Models", "abstract": "Building generative models for relational databases (RDBs) is important for\napplications like privacy-preserving data release and augmenting real datasets.\nHowever, most prior work either focuses on single-table generation or relies on\nautoregressive factorizations that impose a fixed table order and generate\ntables sequentially. This approach limits parallelism, restricts flexibility in\ndownstream applications like missing value imputation, and compounds errors due\nto commonly made conditional independence assumptions. We propose a\nfundamentally different approach: jointly modeling all tables in an RDB without\nimposing any order. By using a natural graph representation of RDBs, we propose\nthe Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph\nneural network to jointly denoise row attributes and capture complex\ninter-table dependencies. Extensive experiments on six real-world RDBs\ndemonstrate that our approach substantially outperforms autoregressive\nbaselines in modeling multi-hop inter-table correlations and achieves\nstate-of-the-art performance on single-table fidelity metrics.", "published": "2025-05-22 11:12:56", "link": "http://arxiv.org/abs/2505.16527v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods", "abstract": "Kernel methods are widely used in machine learning due to their flexibility\nand expressive power. However, their black-box nature poses significant\nchallenges to interpretability, limiting their adoption in high-stakes\napplications. Shapley value-based feature attribution techniques, such as SHAP\nand kernel-specific variants like RKHS-SHAP, offer a promising path toward\nexplainability. Yet, computing exact Shapley values remains computationally\nintractable in general, motivating the development of various approximation\nschemes. In this work, we introduce PKeX-Shapley, a novel algorithm that\nutilizes the multiplicative structure of product kernels to enable the exact\ncomputation of Shapley values in polynomial time. We show that product-kernel\nmodels admit a functional decomposition that allows for a recursive formulation\nof Shapley values. This decomposition not only yields computational efficiency\nbut also enhances interpretability in kernel-based learning. We also\ndemonstrate how our framework can be generalized to explain kernel-based\nstatistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the\nHilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for\ninterpretable statistical inference.", "published": "2025-05-22 10:53:04", "link": "http://arxiv.org/abs/2505.16516v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility", "abstract": "We revisit the foundations of fairness and its interplay with utility and\nefficiency in settings where the training data contain richer labels, such as\nindividual types, rankings, or risk estimates, rather than just binary\noutcomes. In this context, we propose algorithms that achieve stronger notions\nof evidence-based fairness than are possible in standard supervised learning.\nOur methods support classification and ranking techniques that preserve\naccurate subpopulation classification rates, as suggested by the underlying\ndata distributions, across a broad class of classification rules and downstream\napplications. Furthermore, our predictors enable loss minimization, whether\naimed at maximizing utility or in the service of fair treatment.\n  Complementing our algorithmic contributions, we present impossibility results\ndemonstrating that simultaneously achieving accurate classification rates and\noptimal loss minimization is, in some cases, computationally infeasible. Unlike\nprior impossibility results, our notions are not inherently in conflict and are\nsimultaneously satisfied by the Bayes-optimal predictor. Furthermore, we show\nthat each notion can be satisfied individually via efficient learning. Our\nseparation thus stems from the computational hardness of learning a\nsufficiently good approximation of the Bayes-optimal predictor. These\ncomputational impossibilities present a choice between two natural and\nattainable notions of accuracy that could both be motivated by fairness.", "published": "2025-05-22 10:26:30", "link": "http://arxiv.org/abs/2505.16494v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics", "abstract": "Topic models often fail to capture low-prevalence, domain-critical themes,\nso-called minority topics, such as mental health themes in online comments.\nWhile some existing methods can incorporate domain knowledge, such as expected\ntopical content, methods allowing guidance may require overly detailed expected\ntopics, hindering the discovery of topic divisions and variation. We propose a\ntopic modeling solution via a specially constrained NMF. We incorporate a seed\nword list characterizing minority content of interest, but we do not require\nexperts to pre-specify their division across minority topics. Through\nprevalence constraints on minority topics and seed word content across topics,\nwe learn distinct data-driven minority topics as well as majority topics. The\nconstrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with\nmultiplicative updates. We outperform several baselines on synthetic data in\nterms of topic purity, normalized mutual information, and also evaluate topic\nquality using Jensen-Shannon divergence (JSD). We conduct a case study on\nYouTube vlog comments, analyzing viewer discussion of mental health content;\nour model successfully identifies and reveals this domain-relevant minority\ncontent.", "published": "2025-05-22 10:25:55", "link": "http://arxiv.org/abs/2505.16493v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning", "abstract": "The rise of Large Language Model-based Multi-Agent Planning has leveraged\nadvanced frameworks to enable autonomous and collaborative task execution. Some\nsystems rely on platforms like review sites and social media, which are prone\nto fraudulent information, such as fake reviews or misleading descriptions.\nThis reliance poses risks, potentially causing financial losses and harming\nuser experiences. To evaluate the risk of planning systems in real-world\napplications, we introduce \\textbf{WandaPlan}, an evaluation environment\nmirroring real-world data and injected with deceptive content. We assess system\nperformance across three fraud cases: Misinformation Fraud, Team-Coordinated\nMulti-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal\nsignificant weaknesses in existing frameworks that prioritize task efficiency\nover data authenticity. At the same time, we validate WandaPlan's\ngeneralizability, capable of assessing the risks of real-world open-source\nplanning frameworks. To mitigate the risk of fraud, we propose integrating an\nanti-fraud agent, providing a solution for reliable planning.", "published": "2025-05-22 11:46:46", "link": "http://arxiv.org/abs/2505.16557v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Horospherically Convex Optimization on Hadamard Manifolds Part I: Analysis and Algorithms", "abstract": "Geodesic convexity (g-convexity) is a natural generalization of convexity to\nRiemannian manifolds. However, g-convexity lacks many desirable properties\nsatisfied by Euclidean convexity. For instance, the natural notions of\nhalf-spaces and affine functions are themselves not g-convex. Moreover, recent\nstudies have shown that the oracle complexity of geodesically convex\noptimization necessarily depends on the curvature of the manifold (Criscitiello\nand Boumal, 2022; Criscitiello and Boumal, 2023; Hamilton and Moitra, 2021), a\ncomputational bottleneck for several problems, e.g., tensor scaling. Recently,\nLewis et al. (2024) addressed this challenge by proving curvature-independent\nconvergence of subgradient descent, assuming horospherical convexity of the\nobjective's sublevel sets. Using a similar idea, we introduce a generalization\nof convex functions to Hadamard manifolds, utilizing horoballs and Busemann\nfunctions as building blocks (as proxies for half-spaces and affine functions).\nWe refer to this new notion as horospherical convexity (h-convexity). We\nprovide algorithms for both nonsmooth and smooth h-convex optimization, which\nhave curvature-independent guarantees exactly matching those from Euclidean\nspace; this includes generalizations of subgradient descent and Nesterov's\naccelerated method. Motivated by applications, we extend these algorithms and\ntheir convergence rates to minimizing a sum of horospherically convex\nfunctions, assuming access to a weighted-Fr\\'echet-mean oracle.", "published": "2025-05-22 17:50:10", "link": "http://arxiv.org/abs/2505.16970v1", "categories": ["math.OC", "cs.NA", "math.DG", "math.NA"], "primary_category": "math.OC"}
{"title": "Quasi-optimal hierarchically semi-separable matrix approximation", "abstract": "We present a randomized algorithm for producing a quasi-optimal\nhierarchically semi-separable (HSS) approximation to an $N\\times N$ matrix $A$\nusing only matrix-vector products with $A$ and $A^T$. We prove that, using $O(k\n\\log(N/k))$ matrix-vector products and ${O}(N k^2 \\log(N/k))$ additional\nruntime, the algorithm returns an HSS matrix $B$ with rank-$k$ blocks whose\nexpected Frobenius norm error $\\mathbb{E}[\\|A - B\\|_F^2]$ is at most\n$O(\\log(N/k))$ times worse than the best possible approximation error by an HSS\nrank-$k$ matrix. In fact, the algorithm we analyze in a simple modification of\nan empirically effective method proposed by [Levitt & Martinsson, SISC 2024].\nAs a stepping stone towards our main result, we prove two results that are of\nindependent interest: a similar guarantee for a variant of the algorithm which\naccesses $A$'s entries directly, and explicit error bounds for near-optimal\nsubspace approximation using projection-cost-preserving sketches. To the best\nof our knowledge, our analysis constitutes the first polynomial-time\nquasi-optimality result for HSS matrix approximation, both in the explicit\naccess model and the matrix-vector product query model.", "published": "2025-05-22 17:27:40", "link": "http://arxiv.org/abs/2505.16937v1", "categories": ["math.NA", "cs.DS", "cs.NA", "65F55, 68W20, 68W25"], "primary_category": "math.NA"}
{"title": "Lp boundedness, r-nuclearity and approximation of pseudo-differential operators on $\\hbar\\mathbb{Z}^n$", "abstract": "In this work sufficient conditions on the order of the symbol are developed\nto ensure boundedness, compactness and r-nuclearity of pseudo-differential\noperators in $\\hbar\\mathbb{Z}^n$. In addition, these conditions allow us to\nobtain growth estimates for the eigenvalues of some elliptic operators, in\nparticular perturbed discrete Schr\\\"odinger operator.", "published": "2025-05-22 15:50:30", "link": "http://arxiv.org/abs/2505.16812v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "A Riemannian Optimization Approach for Finding the Nearest Reversible Markov Chain", "abstract": "We address the algorithmic problem of determining the reversible Markov chain\n$\\tilde X$ that is closest to a given Markov chain $X$, with an identical\nstationary distribution. More specifically, $\\tilde X$ is the reversible Markov\nchain with the closest transition matrix, in the Frobenius norm, to the\ntransition matrix of $X$. To compute the transition matrix of $\\tilde X$, we\npropose a novel approach based on Riemannian optimization. Our method\nintroduces a modified multinomial manifold endowed with a prescribed stationary\nvector, while also satisfying the detailed balance conditions, all within the\nframework of the Fisher metric. We evaluate the performance of the proposed\napproach in comparison with an existing quadratic programming method and\ndemonstrate its effectiveness through a series of synthetic experiments, as\nwell as in the construction of a reversible Markov chain from transition count\ndata obtained via direct estimation from a stochastic differential equation.", "published": "2025-05-22 15:04:40", "link": "http://arxiv.org/abs/2505.16762v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Local projection stabilization methods for $\\boldsymbol{H}({\\rm curl})$ and $\\boldsymbol{H}({\\rm div})$ advection problems", "abstract": "We devise local projection stabilization (LPS) methods for advection problems\nin the $\\boldsymbol{H}$(curl) and $\\boldsymbol{H}$(div) spaces, employing\nconforming finite element spaces of arbitrary order within a unified framework.\nThe key ingredient is a local inf-sup condition, enabled by enriching the\napproximation space with appropriate $\\boldsymbol{H}$(d) bubble functions (with\nd = curl or div). This enrichment allows for the construction of modified\ninterpolation operators, which are crucial for establishing optimal a priori\nerror estimates in the energy norm. Numerical examples are presented to verify\nboth the theoretical results and the stabilization properties of the proposed\nmethod.", "published": "2025-05-22 09:49:35", "link": "http://arxiv.org/abs/2505.16468v1", "categories": ["math.NA", "cs.NA", "65N60, 65N12"], "primary_category": "math.NA"}
{"title": "Stochastic collocation schemes for Neural Field Equations with random data", "abstract": "We develop and analyse numerical schemes for uncertainty quantification in\nneural field equations subject to random parametric data in the synaptic\nkernel, firing rate, external stimulus, and initial conditions. The schemes\ncombine a generic projection method for spatial discretisation to a stochastic\ncollocation scheme for the random variables. We study the problem in operator\nform, and derive estimates for the total error of the schemes, in terms of the\nspatial projector. We give conditions on the projected random data which\nguarantee analyticity of the semi-discrete solution as a Banach-valued\nfunction. We illustrate how to verify hypotheses starting from analytic random\ndata and a choice of spatial projection. We provide evidence that the predicted\nconvergence rates are found in various numerical experiments for linear and\nnonlinear neural field problems.", "published": "2025-05-22 09:33:06", "link": "http://arxiv.org/abs/2505.16443v1", "categories": ["math.NA", "cs.NA", "math.DS", "nlin.PS"], "primary_category": "math.NA"}
{"title": "Convergence analysis of GMRES applied to Helmholtz problems near resonances", "abstract": "In this work we study how the convergence rate of GMRES is influenced by the\nproperties of linear systems arising from Helmholtz problems near resonances or\nquasi-resonances. We extend an existing convergence bound to demonstrate that\nthe approximation of small eigenvalues by harmonic Ritz values plays a key role\nin convergence behavior. Next, we analyze the impact of deflation using\ncarefully selected vectors and combine this with a Complex Shifted Laplacian\npreconditioner. Finally, we apply these tools to two numerical examples near\n(quasi-)resonant frequencies, using them to explain how the convergence rate\nevolves.", "published": "2025-05-22 07:59:18", "link": "http://arxiv.org/abs/2505.16345v1", "categories": ["math.NA", "cs.NA", "65F10 (Primary), 65N22, 65N30 (Secondary)"], "primary_category": "math.NA"}
{"title": "Neural Field Equations with random data", "abstract": "We study neural field equations, which are prototypical models of large-scale\ncortical activity, subject to random data. We view this spatially-extended,\nnonlocal evolution equation as a Cauchy problem on abstract Banach spaces, with\nrandomness in the synaptic kernel, firing rate function, external stimuli, and\ninitial conditions. We determine conditions on the random data that guarantee\nexistence, uniqueness, and measurability of the solution in an appropriate\nBanach space, and examine the regularity of the solution in relation to the\nregularity of the inputs. We present results for linear and nonlinear neural\nfields, and for the two most common functional setups in the numerical analysis\nof this problem. In addition to the continuous problem, we analyse in abstract\nform neural fields that have been spatially discretised, setting the\nfoundations for analysing uncertainty quantification (UQ) schemes.", "published": "2025-05-22 07:58:06", "link": "http://arxiv.org/abs/2505.16343v1", "categories": ["math.NA", "cs.NA", "math.DS", "math.PR", "nlin.PS"], "primary_category": "math.NA"}
{"title": "A novel splitting method for Vlasov-Ampere", "abstract": "Vlasov equations model the dynamics of plasma in the collisionless regime. A\nstandard approach for numerically solving the Vlasov equation is to operator\nsplit the spatial and velocity derivative terms, allowing simpler time-stepping\nschemes to be applied to each piece separately (known as the Cheng-Knorr\nmethod). One disadvantage of such an operator split method is that the order of\naccuracy of fluid moments (e.g., mass, momentum, and energy) is restricted by\nthe order of the operator splitting (second-order accuracy in the Cheng-Knorr\ncase). In this work, we develop a novel approach that first represents the\nparticle density function on a velocity mesh with a local fluid approximation\nin each discrete velocity band and then introduces an operator splitting that\nsplits the inter-velocity band coupling terms from the dynamics within the\ndiscrete velocity band. The advantage is that the inter-velocity band coupling\nterms are only needed to achieve consistency of the full distribution\nfunctions, but the local fluid models within each band are sufficient to\nachieve high-order accuracy on global moments such as mass, momentum, and\nenergy. The resulting scheme is verified on several standard Vlasov-Poisson\ntest cases.", "published": "2025-05-22 05:22:49", "link": "http://arxiv.org/abs/2505.16243v1", "categories": ["math.NA", "cs.NA", "physics.plasm-ph", "65M60, 82D10"], "primary_category": "math.NA"}
{"title": "Machine learning approach to stock price crash risk", "abstract": "In this study, we propose a novel machine-learning-based measure for stock\nprice crash risk, utilizing the minimum covariance determinant methodology.\nEmploying this newly introduced dependent variable, we predict stock price\ncrash risk through cross-sectional regression analysis. The findings confirm\nthat the proposed method effectively captures stock price crash risk, with the\nmodel demonstrating strong performance in terms of both statistical\nsignificance and economic relevance. Furthermore, leveraging a newly developed\nfirm-specific investor sentiment index, the analysis identifies a positive\ncorrelation between stock price crash risk and firm-specific investor\nsentiment. Specifically, higher levels of sentiment are associated with an\nincreased likelihood of stock price crash risk. This relationship remains\nrobust across different firm sizes and when using the detoned version of the\nfirm-specific investor sentiment index, further validating the reliability of\nthe proposed approach.", "published": "2025-05-22 06:33:35", "link": "http://arxiv.org/abs/2505.16287v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Interpretable Machine Learning for Macro Alpha: A News Sentiment Case Study", "abstract": "This study introduces an interpretable machine learning (ML) framework to\nextract macroeconomic alpha from global news sentiment. We process the Global\nDatabase of Events, Language, and Tone (GDELT) Project's worldwide news feed\nusing FinBERT -- a Bidirectional Encoder Representations from Transformers\n(BERT) based model pretrained on finance-specific language -- to construct\ndaily sentiment indices incorporating mean tone, dispersion, and event impact.\nThese indices drive an XGBoost classifier, benchmarked against logistic\nregression, to predict next-day returns for EUR/USD, USD/JPY, and 10-year U.S.\nTreasury futures (ZN). Rigorous out-of-sample (OOS) backtesting (5-fold\nexpanding-window cross-validation, OOS period: c. 2017-April 2025) demonstrates\nexceptional, cost-adjusted performance for the XGBoost strategy: Sharpe ratios\nachieve 5.87 (EUR/USD), 4.65 (USD/JPY), and 4.65 (Treasuries), with respective\ncompound annual growth rates (CAGRs) exceeding 50% in Foreign Exchange (FX) and\n22% in bonds. Shapley Additive Explanations (SHAP) affirm that sentiment\ndispersion and article impact are key predictive features. Our findings\nestablish that integrating domain-specific Natural Language Processing (NLP)\nwith interpretable ML offers a potent and explainable source of macro alpha.", "published": "2025-05-22 02:24:45", "link": "http://arxiv.org/abs/2505.16136v1", "categories": ["q-fin.CP", "cs.AI", "cs.LG", "q-fin.TR"], "primary_category": "q-fin.CP"}
{"title": "Pricing Model for Data Assets in Investment-Consumption Framework with Ambiguity", "abstract": "Data assets are data commodities that have been processed, produced, priced,\nand traded based on actual demand. Reasonable pricing mechanism for data assets\nis essential for developing the data market and realizing their value. Most\nexisting literature approaches data asset pricing from the seller's\nperspective, focusing on data properties and collection costs, however,\nresearch from the buyer's perspective remains scarce. This gap stems from the\nnature of data assets: their value lies not in direct revenue generation but in\nproviding informational advantages that enable enhanced decision-making and\nexcess returns. This paper addresses this gap by developing a pricing model\nbased on the informational value of data assets from the buyer's perspective.\nWe determine data asset prices through an implicit function derived from the\nvalue functions in two robust investment-consumption problems under ambiguity\nmarkets via the indifference pricing principle. By the existing research\nresults, we simplify the value function, using mathematical analysis and\ndifferential equation theory, we derive general expressions for data assets\nprice and explore their properties under various conditions. Furthermore, we\nderive the explicit pricing formulas for specific scenarios and provide\nnumerical illustration to describe how to use our pricing model.", "published": "2025-05-22 01:22:16", "link": "http://arxiv.org/abs/2505.16106v1", "categories": ["q-fin.MF", "93E20, 49L99, 49N90, 35Q99, 65N06"], "primary_category": "q-fin.MF"}
{"title": "Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling", "abstract": "Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by\nreplacing the fully factorised Gaussian prior with a GP prior, thereby\ncapturing richer correlations among latent variables. However, performing exact\nGP inference in large-scale GPVAEs is computationally prohibitive, often\nforcing existing approaches to rely on restrictive kernel assumptions or large\nsets of inducing points. In this work, we propose a neighbour-driven\napproximation strategy that exploits local adjacencies in the latent space to\nachieve scalable GPVAE inference. By confining computations to the nearest\nneighbours of each data point, our method preserves essential latent\ndependencies, allowing more flexible kernel choices and mitigating the need for\nnumerous inducing points. Through extensive experiments on tasks including\nrepresentation learning, data imputation, and conditional generation, we\ndemonstrate that our approach outperforms other GPVAE variants in both\npredictive performance and computational efficiency.", "published": "2025-05-22 10:07:33", "link": "http://arxiv.org/abs/2505.16481v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training", "abstract": "We introduce AdamS, a simple yet effective alternative to Adam for large\nlanguage model (LLM) pretraining and post-training. By leveraging a novel\ndenominator, i.e., the root of weighted sum of squares of the momentum and the\ncurrent gradient, AdamS eliminates the need for second-moment estimates. Hence,\nAdamS is efficient, matching the memory and compute footprint of SGD with\nmomentum while delivering superior optimization performance. Moreover, AdamS is\neasy to adopt: it can directly inherit hyperparameters of AdamW, and is\nentirely model-agnostic, integrating seamlessly into existing pipelines without\nmodifications to optimizer APIs or architectures. The motivation behind AdamS\nstems from the observed $(L_0, L_1)$ smoothness properties in transformer\nobjectives, where local smoothness is governed by gradient magnitudes that can\nbe further approximated by momentum magnitudes. We establish rigorous\ntheoretical convergence guarantees and provide practical guidelines for\nhyperparameter selection. Empirically, AdamS demonstrates strong performance in\nvarious tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B\nparameters) and reinforcement learning in post-training regimes. With its\nefficiency, simplicity, and theoretical grounding, AdamS stands as a compelling\nalternative to existing optimizers.", "published": "2025-05-22 08:16:48", "link": "http://arxiv.org/abs/2505.16363v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping", "abstract": "Differentially private (DP) linear regression has received significant\nattention in the recent theoretical literature, with several works aimed at\nobtaining improved error rates. A common approach is to set the clipping\nconstant much larger than the expected norm of the per-sample gradients. While\nsimplifying the analysis, this is however in sharp contrast with what empirical\nevidence suggests to optimize performance. Our work bridges this gap between\ntheory and practice: we provide sharper rates for DP stochastic gradient\ndescent (DP-SGD) by crucially operating in a regime where clipping happens\nfrequently. Specifically, we consider the setting where the data is\nmultivariate Gaussian, the number of training samples $n$ is proportional to\nthe input dimension $d$, and the algorithm guarantees constant-order zero\nconcentrated DP. Our method relies on establishing a deterministic equivalent\nfor the trajectory of DP-SGD in terms of a family of ordinary differential\nequations (ODEs). As a consequence, the risk of DP-SGD is bounded between two\nODEs, with upper and lower bounds matching for isotropic data. By studying\nthese ODEs when $n / d$ is large enough, we demonstrate the optimality of\naggressive clipping, and we uncover the benefits of decaying learning rate and\nprivate noise scheduling.", "published": "2025-05-22 07:34:27", "link": "http://arxiv.org/abs/2505.16329v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions", "abstract": "Recent advances in generative artificial intelligence (GenAI) models have\nenabled the generation of personalized content that adapts to up-to-date user\ncontext. While personalized decision systems are often modeled using bandit\nformulations, the integration of GenAI introduces new structure into otherwise\nclassical sequential learning problems. In GenAI-powered interventions, the\nagent selects a query, but the environment experiences a stochastic response\ndrawn from the generative model. Standard bandit methods do not explicitly\naccount for this structure, where actions influence rewards only through\nstochastic, observed treatments. We introduce generator-mediated\nbandit-Thompson sampling (GAMBITTS), a bandit approach designed for this\naction/treatment split, using mobile health interventions with large language\nmodel-generated text as a motivating case study. GAMBITTS explicitly models\nboth the treatment and reward generation processes, using information in the\ndelivered treatment to accelerate policy learning relative to standard methods.\nWe establish regret bounds for GAMBITTS by decomposing sources of uncertainty\nin treatment and reward, identifying conditions where it achieves stronger\nguarantees than standard bandit approaches. In simulation studies, GAMBITTS\nconsistently outperforms conventional algorithms by leveraging observed\ntreatments to more accurately estimate expected rewards.", "published": "2025-05-22 07:06:51", "link": "http://arxiv.org/abs/2505.16311v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics", "abstract": "This study develops a higher-order asymptotic framework for test-time\nadaptation (TTA) of Batch Normalization (BN) statistics under distribution\nshift by integrating classical Edgeworth expansion and saddlepoint\napproximation techniques with a novel one-step M-estimation perspective. By\nanalyzing the statistical discrepancy between training and test distributions,\nwe derive an Edgeworth expansion for the normalized difference in BN means and\nobtain an optimal weighting parameter that minimizes the mean-squared error of\nthe adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows\nus to derive higher-order local asymptotic normality results, which incorporate\nskewness and other higher moments into the estimator's behavior. Moreover, we\nquantify the trade-offs among bias, variance, and skewness in the adaptation\nprocess and establish a corresponding generalization bound on the model risk.\nThe refined saddlepoint approximations further deliver uniformly accurate\ndensity and tail probability estimates for the BN TTA statistic. These\ntheoretical insights provide a comprehensive understanding of how higher-order\ncorrections and robust one-step updating can enhance the reliability and\nperformance of BN layers in adapting to changing data distributions.", "published": "2025-05-22 05:47:19", "link": "http://arxiv.org/abs/2505.16257v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry", "abstract": "Label shift adaptation aims to recover target class priors when the labelled\nsource distribution $P$ and the unlabelled target distribution $Q$ share $P(X\n\\mid Y) = Q(X \\mid Y)$ but $P(Y) \\neq Q(Y)$. Classical black-box shift\nestimators invert an empirical confusion matrix of a frozen classifier,\nproducing a brittle point estimate that ignores sampling noise and similarity\namong classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully\nprobabilistic alternative that places Laplacian-Gaussian priors on both target\nlog-priors and confusion-matrix columns, tying them together on a\nlabel-similarity graph. The resulting posterior is tractable with HMC or a fast\nblock Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,\nvariance bounds that shrink with the graph's algebraic connectivity, and\nrobustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE\nthrough information geometry, showing that it generalizes existing shift\nestimators.", "published": "2025-05-22 05:40:34", "link": "http://arxiv.org/abs/2505.16251v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Generalized Power Priors for Improved Bayesian Inference with Historical Data", "abstract": "The power prior is a class of informative priors designed to incorporate\nhistorical data alongside current data in a Bayesian framework. It includes a\npower parameter that controls the influence of historical data, providing\nflexibility and adaptability. A key property of the power prior is that the\nresulting posterior minimizes a linear combination of KL divergences between\ntwo pseudo-posterior distributions: one ignoring historical data and the other\nfully incorporating it. We extend this framework by identifying the posterior\ndistribution as the minimizer of a linear combination of Amari's\n$\\alpha$-divergence, a generalization of KL divergence. We show that this\ngeneralization can lead to improved performance by allowing for the data to\nadapt to appropriate choices of the $\\alpha$ parameter. Theoretical properties\nof this generalized power posterior are established, including behavior as a\ngeneralized geodesic on the Riemannian manifold of probability distributions,\noffering novel insights into its geometric interpretation.", "published": "2025-05-22 05:26:40", "link": "http://arxiv.org/abs/2505.16244v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks", "abstract": "In this paper, we prove directional convergence of network parameters of\nfixed width leaky ReLU two-layer neural networks optimized by gradient descent\nwith exponential loss, which was previously only known for gradient flow. By a\ncareful analysis of the convergent direction, we establish sufficient\nconditions of benign overfitting and discover a new phase transition in the\ntest error bound. All of these results hold beyond the nearly orthogonal data\nsetting which was studied in prior works. As an application, we demonstrate\nthat benign overfitting occurs with high probability in sub-Gaussian mixture\nmodels.", "published": "2025-05-22 04:11:58", "link": "http://arxiv.org/abs/2505.16204v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "68T07 (primary)"], "primary_category": "cs.LG"}
{"title": "Integral Imprecise Probability Metrics", "abstract": "Quantifying differences between probability distributions is fundamental to\nstatistics and machine learning, primarily for comparing statistical\nuncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete\nknowledge -- requires richer representations than those offered by classical\nprobability. Imprecise probability (IP) theory offers such models, capturing\nambiguity and partial belief. This has driven growing interest in imprecise\nprobabilistic machine learning (IPML), where inference and decision-making rely\non broader uncertainty models -- highlighting the need for metrics beyond\nclassical probability. This work introduces the Integral Imprecise Probability\nMetric (IIPM) framework, a Choquet integral-based generalisation of classical\nIntegral Probability Metric (IPM) to the setting of capacities -- a broad class\nof IP models encompassing many existing ones, including lower probabilities,\nprobability intervals, belief functions, and more. Theoretically, we establish\nconditions under which IIPM serves as a valid metric and metrises a form of\nweak convergence of capacities. Practically, IIPM not only enables comparison\nacross different IP models but also supports the quantification of epistemic\nuncertainty within a single IP model. In particular, by comparing an IP model\nwith its conjugate, IIPM gives rise to a new class of EU measures -- Maximum\nMean Imprecision -- which satisfy key axiomatic properties proposed in the\nUncertainty Quantification literature. We validate MMI through selective\nclassification experiments, demonstrating strong empirical performance against\nestablished EU measures, and outperforming them when classical methods struggle\nto scale to a large number of classes. Our work advances both theory and\npractice in IPML, offering a principled framework for comparing and quantifying\nepistemic uncertainty under imprecision.", "published": "2025-05-22 02:56:57", "link": "http://arxiv.org/abs/2505.16156v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Exponential Convergence of CAVI for Bayesian PCA", "abstract": "Probabilistic principal component analysis (PCA) and its Bayesian variant\n(BPCA) are widely used for dimension reduction in machine learning and\nstatistics. The main advantage of probabilistic PCA over the traditional\nformulation is allowing uncertainty quantification. The parameters of BPCA are\ntypically learned using mean-field variational inference, and in particular,\nthe coordinate ascent variational inference (CAVI) algorithm. So far, the\nconvergence speed of CAVI for BPCA has not been characterized. In our paper, we\nfill this gap in the literature. Firstly, we prove a precise exponential\nconvergence result in the case where the model uses a single principal\ncomponent (PC). Interestingly, this result is established through a connection\nwith the classical $\\textit{power iteration algorithm}$ and it indicates that\ntraditional PCA is retrieved as points estimates of the BPCA parameters.\nSecondly, we leverage recent tools to prove exponential convergence of CAVI for\nthe model with any number of PCs, thus leading to a more general result, but\none that is of a slightly different flavor. To prove the latter result, we\nadditionally needed to introduce a novel lower bound for the symmetric\nKullback--Leibler divergence between two multivariate normal distributions,\nwhich, we believe, is of independent interest in information theory.", "published": "2025-05-22 02:44:00", "link": "http://arxiv.org/abs/2505.16145v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Dimension-adapted Momentum Outscales SGD", "abstract": "We investigate scaling laws for stochastic momentum algorithms with small\nbatch on the power law random features model, parameterized by data complexity,\ntarget complexity, and model size. When trained with a stochastic momentum\nalgorithm, our analysis reveals four distinct loss curve shapes determined by\nvarying data-target complexities. While traditional stochastic gradient descent\nwith momentum (SGD-M) yields identical scaling law exponents to SGD,\ndimension-adapted Nesterov acceleration (DANA) improves these exponents by\nscaling momentum hyperparameters based on model size and data complexity. This\noutscaling phenomenon, which also improves compute-optimal scaling behavior, is\nachieved by DANA across a broad range of data and target complexities, while\ntraditional methods fall short. Extensive experiments on high-dimensional\nsynthetic quadratics validate our theoretical predictions and large-scale text\nexperiments with LSTMs show DANA's improved loss exponents over SGD hold in a\npractical setting.", "published": "2025-05-22 00:58:50", "link": "http://arxiv.org/abs/2505.16098v1", "categories": ["stat.ML", "cs.LG", "math.OC"], "primary_category": "stat.ML"}
{"title": "Performance of Objective Speech Quality Metrics on Languages Beyond Validation Data: A Study of Turkish and Korean", "abstract": "Objective speech quality measures are widely used to assess the performance\nof video conferencing platforms and telecommunication systems. They predict\nhuman-rated speech quality and are crucial for assessing the systems quality of\nexperience. Despite the widespread use, the quality measures are developed on a\nlimited set of languages. This can be problematic since the performance on\nunseen languages is consequently not guaranteed or even studied. Here we raise\nawareness to this issue by investigating the performance of two objective\nspeech quality measures (PESQ and ViSQOL) on Turkish and Korean. Using English\nas baseline, we show that Turkish samples have significantly higher ViSQOL\nscores and that for Turkish male speakers the correlation between PESQ and\nViSQOL is highest. These results highlight the need to explore biases across\nmetrics and to develop a labeled speech quality dataset with a variety of\nlanguages.", "published": "2025-05-22 12:50:32", "link": "http://arxiv.org/abs/2505.16616v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Attractor-Based Speech Separation of Multiple Utterances by Unknown Number of Speakers", "abstract": "This paper addresses the problem of single-channel speech separation, where\nthe number of speakers is unknown, and each speaker may speak multiple\nutterances. We propose a speech separation model that simultaneously performs\nseparation, dynamically estimates the number of speakers, and detects\nindividual speaker activities by integrating an attractor module. The proposed\nsystem outperforms existing methods by introducing an attractor-based\narchitecture that effectively combines local and global temporal modeling for\nmulti-utterance scenarios. To evaluate the method in reverberant and noisy\nconditions, a multi-speaker multi-utterance dataset was synthesized by\ncombining Librispeech speech signals with WHAM! noise signals. The results\ndemonstrate that the proposed system accurately estimates the number of\nsources. The system effectively detects source activities and separates the\ncorresponding utterances into correct outputs in both known and unknown source\ncount scenarios.", "published": "2025-05-22 12:41:42", "link": "http://arxiv.org/abs/2505.16607v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "HPP-Voice: A Large-Scale Evaluation of Speech Embeddings for Multi-Phenotypic Classification", "abstract": "Human speech contains paralinguistic cues that reflect a speaker's\nphysiological and neurological state, potentially enabling non-invasive\ndetection of various medical phenotypes. We introduce the Human Phenotype\nProject Voice corpus (HPP-Voice): a dataset of 7,188 recordings in which\nHebrew-speaking adults count for 30 seconds, with each speaker linked to up to\n15 potentially voice-related phenotypes spanning respiratory, sleep, mental\nhealth, metabolic, immune, and neurological conditions. We present a systematic\ncomparison of 14 modern speech embedding models, where modern speech embeddings\nfrom these 30-second counting tasks outperform MFCCs and demographics for\ndownstream health condition classifications. We found that embedding learned\nfrom a speaker identification model can predict objectively measured moderate\nto severe sleep apnea in males with an AUC of 0.64 $\\pm$ 0.03, while MFCC and\ndemographic features led to AUCs of 0.56 $\\pm$ 0.02 and 0.57 $\\pm$ 0.02,\nrespectively. Additionally, our results reveal gender-specific patterns in\nmodel effectiveness across different medical domains. For males, speaker\nidentification and diarization models consistently outperformed speech\nfoundation models for respiratory conditions (e.g., asthma: 0.61 $\\pm$ 0.03 vs.\n0.56 $\\pm$ 0.02) and sleep-related conditions (insomnia: 0.65 $\\pm$ 0.04 vs.\n0.59 $\\pm$ 0.05). For females, speaker diarization models performed best for\nsmoking status (0.61 $\\pm$ 0.02 vs 0.55 $\\pm$ 0.02), while Hebrew-specific\nmodels performed best (0.59 $\\pm$ 0.02 vs. 0.58 $\\pm$ 0.02) in classifying\nanxiety compared to speech foundation models. Our findings provide evidence\nthat a simple counting task can support large-scale, multi-phenotypic voice\nscreening and highlight which embedding families generalize best to specific\nconditions, insights that can guide future vocal biomarker research and\nclinical deployment.", "published": "2025-05-22 10:22:15", "link": "http://arxiv.org/abs/2505.16490v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "UBGAN: Enhancing Coded Speech with Blind and Guided Bandwidth Extension", "abstract": "In practical application of speech codecs, a multitude of factors such as the\nquality of the radio connection, limiting hardware or required user experience\nnecessitate trade-offs between achievable perceptual quality, engendered\nbitrate and computational complexity. Most conventional and neural speech\ncodecs operate on wideband (WB) speech signals to achieve this compromise. To\nfurther enhance the perceptual quality of coded speech, bandwidth extension\n(BWE) of the transmitted speech is an attractive and popular technique in\nconventional speech coding. In contrast, neural speech codecs are typically\ntrained end-to-end to a specific set of requirements and are often not easily\nadaptable. In particular, they are typically trained to operate at a single\nfixed sampling rate. With the Universal Bandwidth Extension Generative\nAdversarial Network (UBGAN), we propose a modular and lightweight GAN-based\nsolution that increases the operational flexibility of a wide range of\nconventional and neural codecs. Our model operates in the subband domain and\nextends the bandwidth of WB signals from 8 kHz to 16 kHz, resulting in\nsuper-wideband (SWB) signals. We further introduce two variants, guided-UBGAN\nand blind-UBGAN, where the guided version transmits quantized learned\nrepresentation as a side information at a very low bitrate additional to the\nbitrate of the codec, while blind-BWE operates without such side-information.\nOur subjective assessments demonstrate the advantage of UBGAN applied to WB\ncodecs and highlight the generalization capacity of our proposed method across\nmultiple codecs and bitrates.", "published": "2025-05-22 08:56:35", "link": "http://arxiv.org/abs/2505.16404v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-Channel Sequence-to-Sequence Neural Diarization: Experimental Results for The MISP 2025 Challenge", "abstract": "This paper describes the speaker diarization system developed for the\nMultimodal Information-Based Speech Processing (MISP) 2025 Challenge. First, we\nutilize the Sequence-to-Sequence Neural Diarization (S2SND) framework to\ngenerate initial predictions using single-channel audio. Then, we extend the\noriginal S2SND framework to create a new version, Multi-Channel\nSequence-to-Sequence Neural Diarization (MC-S2SND), which refines the initial\nresults using multi-channel audio. The final system achieves a diarization\nerror rate (DER) of 8.09% on the evaluation set of the competition database,\nranking first place in the speaker diarization task of the MISP 2025 Challenge.", "published": "2025-05-22 08:39:48", "link": "http://arxiv.org/abs/2505.16387v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection", "abstract": "Automatic detection of speech dysfluency aids speech-language pathologists in\nefficient transcription of disordered speech, enhancing diagnostics and\ntreatment planning. Traditional methods, often limited to classification,\nprovide insufficient clinical insight, and text-independent models misclassify\ndysfluency, especially in context-dependent cases. This work introduces\nDysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes\nand detects dysfluency. Unlike previous models, Dysfluent-WFST operates with\nupstream encoders like WavLM and requires no additional training. It achieves\nstate-of-the-art performance in both phonetic error rate and dysfluency\ndetection on simulated and real speech data. Our approach is lightweight,\ninterpretable, and effective, demonstrating that explicit modeling of\npronunciation behavior in decoding, rather than complex architectures, is key\nto improving dysfluency processing systems.", "published": "2025-05-22 08:02:50", "link": "http://arxiv.org/abs/2505.16351v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Meta-PerSER: Few-Shot Listener Personalized Speech Emotion Recognition via Meta-learning", "abstract": "This paper introduces Meta-PerSER, a novel meta-learning framework that\npersonalizes Speech Emotion Recognition (SER) by adapting to each listener's\nunique way of interpreting emotion. Conventional SER systems rely on aggregated\nannotations, which often overlook individual subtleties and lead to\ninconsistent predictions. In contrast, Meta-PerSER leverages a Model-Agnostic\nMeta-Learning (MAML) approach enhanced with Combined-Set Meta-Training,\nDerivative Annealing, and per-layer per-step learning rates, enabling rapid\nadaptation with only a few labeled examples. By integrating robust\nrepresentations from pre-trained self-supervised models, our framework first\ncaptures general emotional cues and then fine-tunes itself to personal\nannotation styles. Experiments on the IEMOCAP corpus demonstrate that\nMeta-PerSER significantly outperforms baseline methods in both seen and unseen\ndata scenarios, highlighting its promise for personalized emotion recognition.", "published": "2025-05-22 04:44:20", "link": "http://arxiv.org/abs/2505.16220v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Large Language Models based ASR Error Correction for Child Conversations", "abstract": "Automatic Speech Recognition (ASR) has recently shown remarkable progress,\nbut accurately transcribing children's speech remains a significant challenge.\nRecent developments in Large Language Models (LLMs) have shown promise in\nimproving ASR transcriptions. However, their applications in child speech\nincluding conversational scenarios are underexplored. In this study, we explore\nthe use of LLMs in correcting ASR errors for conversational child speech. We\ndemonstrate the promises and challenges of LLMs through experiments on two\nchildren's conversational speech datasets with both zero-shot and fine-tuned\nASR outputs. We find that while LLMs are helpful in correcting zero-shot ASR\noutputs and fine-tuned CTC-based ASR outputs, it remains challenging for LLMs\nto improve ASR performance when incorporating contextual information or when\nusing fine-tuned autoregressive ASR (e.g., Whisper) outputs.", "published": "2025-05-22 04:28:02", "link": "http://arxiv.org/abs/2505.16212v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models", "abstract": "The rapid advancement and expanding applications of Audio Large Language\nModels (ALLMs) demand a rigorous understanding of their trustworthiness.\nHowever, systematic research on evaluating these models, particularly\nconcerning risks unique to the audio modality, remains largely unexplored.\nExisting evaluation frameworks primarily focus on the text modality or address\nonly a restricted set of safety dimensions, failing to adequately account for\nthe unique characteristics and application scenarios inherent to the audio\nmodality. We introduce AudioTrust-the first multifaceted trustworthiness\nevaluation framework and benchmark specifically designed for ALLMs. AudioTrust\nfacilitates assessments across six key dimensions: fairness, hallucination,\nsafety, privacy, robustness, and authentication. To comprehensively evaluate\nthese dimensions, AudioTrust is structured around 18 distinct experimental\nsetups. Its core is a meticulously constructed dataset of over 4,420 audio/text\nsamples, drawn from real-world scenarios (e.g., daily conversations, emergency\ncalls, voice assistant interactions), specifically designed to probe the\nmultifaceted trustworthiness of ALLMs. For assessment, the benchmark carefully\ndesigns 9 audio-specific evaluation metrics, and we employ a large-scale\nautomated pipeline for objective and scalable scoring of model outputs.\nExperimental results reveal the trustworthiness boundaries and limitations of\ncurrent state-of-the-art open-source and closed-source ALLMs when confronted\nwith various high-risk audio scenarios, offering valuable insights for the\nsecure and trustworthy deployment of future audio models. Our platform and\nbenchmark are available at https://github.com/JusperLee/AudioTrust.", "published": "2025-05-22 04:27:46", "link": "http://arxiv.org/abs/2505.16211v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Differentiable K-means for Fully-optimized Discrete Token-based ASR", "abstract": "Recent studies have highlighted the potential of discrete tokens derived from\nself-supervised learning (SSL) models for various speech-related tasks. These\ntokens serve not only as substitutes for text in language modeling but also as\nintermediate representations for tasks such as automatic speech recognition\n(ASR). However, discrete tokens are typically obtained via k-means clustering\nof SSL features independently of downstream tasks, making them suboptimal for\nspecific applications. This paper proposes the use of differentiable k-means,\nenabling the joint optimization of tokenization and downstream tasks. This\napproach enables the fine-tuning of the SSL parameters and learning weights for\noutputs from multiple SSL layers. Experiments were conducted with ASR as a\ndownstream task. ASR accuracy successfully improved owing to the optimized\ntokens. The acquired tokens also exhibited greater purity of phonetic\ninformation, which were found to be useful even in speech resynthesis.", "published": "2025-05-22 04:20:51", "link": "http://arxiv.org/abs/2505.16207v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet", "abstract": "Foley synthesis aims to synthesize high-quality audio that is both\nsemantically and temporally aligned with video frames. Given its broad\napplication in creative industries, the task has gained increasing attention in\nthe research community. To avoid the non-trivial task of training audio\ngenerative models from scratch, adapting pretrained audio generative models for\nvideo-synchronized foley synthesis presents an attractive direction.\nControlNet, a method for adding fine-grained controls to pretrained generative\nmodels, has been applied to foley synthesis, but its use has been limited to\nhandcrafted human-readable temporal conditions. In contrast, from-scratch\nmodels achieved success by leveraging high-dimensional deep features extracted\nusing pretrained video encoders. We have observed a performance gap between\nControlNet-based and from-scratch foley models. To narrow this gap, we propose\nSpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward\nvideo-synchronized foley synthesis via ControlNet. To unlock the potential of a\nsingle ControlNet branch, we resolve the discrepancy between the temporal video\nfeatures and the time-frequency nature of the pretrained SpecMaskGIT via a\nfrequency-aware temporal feature aligner, eliminating the need for complicated\nconditioning mechanisms widely used in prior arts. Evaluations on a common\nfoley synthesis benchmark demonstrate that SpecMaskFoley could even outperform\nstrong from-scratch baselines, substantially advancing the development of\nControlNet-based foley synthesis models. Demo page:\nhttps://zzaudio.github.io/SpecMaskFoley_Demo/", "published": "2025-05-22 03:58:16", "link": "http://arxiv.org/abs/2505.16195v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "cs.SD"}
{"title": "Prosodically Enhanced Foreign Accent Simulation by Discrete Token-based Resynthesis Only with Native Speech Corpora", "abstract": "Recently, a method for synthesizing foreign-accented speech only with native\nspeech data using discrete tokens obtained from self-supervised learning (SSL)\nmodels was proposed. Considering limited availability of accented speech data,\nthis method is expected to make it much easier to simulate foreign accents. By\nusing the synthesized accented speech as listening materials for humans or\ntraining data for automatic speech recognition (ASR), both of them will acquire\nhigher robustness against foreign accents. However, the previous method has a\nfatal flaw that it cannot reproduce duration-related accents. Durational\naccents are commonly seen when L2 speakers, whose native language has\nsyllable-timed or mora-timed rhythm, speak stress-timed languages, such as\nEnglish. In this paper, we integrate duration modification to the previous\nmethod to simulate foreign accents more accurately. Experiments show that the\nproposed method successfully replicates durational accents seen in real L2\nspeech.", "published": "2025-05-22 03:50:05", "link": "http://arxiv.org/abs/2505.16191v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Discrete Tokens Exhibit Interlanguage Speech Intelligibility Benefit: an Analytical Study Towards Accent-robust ASR Only with Native Speech Data", "abstract": "In this study, we gained insight that contributes to achieving accent-robust\nASR using only native speech data. In human perception of non-native speech,\nthe phenomenon known as \"interlanguage speech intelligibility benefit\" (ISIB)\nis observed, where non-native listeners who share the native language with the\nspeaker understand the speech better compared even to native listeners. Based\non the idea that discrete tokens extracted from self-supervised learning (SSL)\nmodels represent the human perception of speech, we conducted an analytical\nstudy on the robustness of discrete token-based ASR to non-native speech,\nvarying the language used for training the tokenization, which is viewed as a\ntechnical implementation of ISIB. The results showed that ISIB actually\noccurred in the discrete token-based ASR. Since our approach relies only on\nnative speech data to simulate the behavior of human perception, it is expected\nto be applicable to a wide range of accents for which speech data is scarce.", "published": "2025-05-22 03:36:28", "link": "http://arxiv.org/abs/2505.16182v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Selective Invocation for Multilingual ASR: A Cost-effective Approach Adapting to Speech Recognition Difficulty", "abstract": "Although multilingual automatic speech recognition (ASR) systems have\nsignificantly advanced, enabling a single model to handle multiple languages,\ninherent linguistic differences and data imbalances challenge SOTA performance\nacross all languages. While language identification (LID) models can route\nspeech to the appropriate ASR model, they incur high costs from invoking SOTA\ncommercial models and suffer from inaccuracies due to misclassification. To\novercome these, we propose SIMA, a selective invocation for multilingual ASR\nthat adapts to the difficulty level of the input speech. Built on a spoken\nlarge language model (SLLM), SIMA evaluates whether the input is simple enough\nfor direct transcription or requires the invocation of a SOTA ASR model. Our\napproach reduces word error rates by 18.7% compared to the SLLM and halves\ninvocation costs compared to LID-based methods. Tests on three datasets show\nthat SIMA is a scalable, cost-effective solution for multilingual ASR\napplications.", "published": "2025-05-22 03:13:40", "link": "http://arxiv.org/abs/2505.16168v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Source Separation by Flow Matching", "abstract": "We consider the problem of single-channel audio source separation with the\ngoal of reconstructing $K$ sources from their mixture. We address this\nill-posed problem with FLOSS (FLOw matching for Source Separation), a\nconstrained generation method based on flow matching, ensuring strict mixture\nconsistency. Flow matching is a general methodology that, when given samples\nfrom two probability distributions defined on the same space, learns an\nordinary differential equation to output a sample from one of the distributions\nwhen provided with a sample from the other. In our context, we have access to\nsamples from the joint distribution of $K$ sources and so the corresponding\nsamples from the lower-dimensional distribution of their mixture. To apply flow\nmatching, we augment these mixture samples with artificial noise components to\nensure the resulting \"augmented\" distribution matches the dimensionality of the\n$K$ source distribution. Additionally, as any permutation of the sources yields\nthe same mixture, we adopt an equivariant formulation of flow matching which\nrelies on a suitable custom-designed neural network architecture. We\ndemonstrate the performance of the method for the separation of overlapping\nspeech.", "published": "2025-05-22 01:52:06", "link": "http://arxiv.org/abs/2505.16119v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Including the magnitude variability of a signal into the ordinal pattern analysis", "abstract": "One of the most popular and innovative methods to analyse signals is by using\nOrdinal Patterns (OPs). The OP encoding is based on transforming a (univariate)\nsignal into a symbolic sequence of OPs, where each OP represents the number of\npermutations needed to order a small subset of the signal's magnitudes. This\nimplies that OPs are conceptually clear, methodologically simple to implement,\nrobust to noise, and can be applied to short signals. Moreover, they simplify\nthe statistical analyses that can be carried out on a signal, such as entropy\nand complexity quantifications. However, because of the relative ordering,\ninformation about the magnitude of the signal at each timestamp is lost -- this\nbeing one of the major drawbacks in the method. Here, we propose a way to use\nthe signal magnitudes discarded in the OP encoding as a complementary variable\nto its permutation entropy. To illustrate our approach, we analyse synthetic\ntrajectories from logistic and H{\\'e}non maps -- with and without added noise\n-- and intracranial electroencephalographic recordings from rats in different\nsleep-wake states. Our results show that, when complementing the permutation\nentropy with the variability in the signal magnitudes, the characterisation of\nthe dynamical behaviours of the maps and the sleep-wake states is improved.\nThis implies that our approach can be useful for feature engineering and\nimproving AI classifiers, where typical machine learning algorithms need\ncomplementary signal features as inputs to improve classification accuracy.", "published": "2025-05-22 16:22:55", "link": "http://arxiv.org/abs/2505.16866v1", "categories": ["nlin.CD", "eess.SP"], "primary_category": "nlin.CD"}
{"title": "OWP-IMU: An RSS-based Optical Wireless and IMU Indoor Positioning Dataset", "abstract": "Received signal strength (RSS)-based optical wireless positioning (OWP)\nsystems are becoming popular for indoor localization because they are low-cost\nand accurate. However, few open-source datasets are available to test and\nanalyze RSS-based OWP systems. In this paper, we collected RSS values at a\nsampling frequency of 27 Hz, inertial measurement unit (IMU) at a sampling\nfrequency of 200 Hz and the ground truth at a sampling frequency of 160 Hz in\ntwo indoor environments. One environment has no obstacles, and the other has a\nmetal column as an obstacle to represent a non-line-of-sight (NLOS) scenario.\nWe recorded data with a vehicle at three different speeds (low, medium and\nhigh). The dataset includes over 110 k data points and covers more than 80 min.\nWe also provide benchmark tests to show localization performance using only\nRSS-based OWP and improve accuracy by combining IMU data via extended kalman\nfilter. The dataset OWP-IMU is open source1 to support further research on\nindoor localization methods.", "published": "2025-05-22 15:58:17", "link": "http://arxiv.org/abs/2505.16823v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Chirp Delay-Doppler Domain Modulation: A New Paradigm of Integrated Sensing and Communication for Autonomous Vehicles", "abstract": "Autonomous driving is reshaping the way humans travel, with millimeter wave\n(mmWave) radar playing a crucial role in this transformation to enabe\nvehicle-to-everything (V2X). Although chirp is widely used in mmWave radar\nsystems for its strong sensing capabilities, the lack of integrated\ncommunication functions in existing systems may limit further advancement of\nautonomous driving. In light of this, we first design ``dedicated chirps\"\ntailored for sensing chirp signals in the environment, facilitating the\nidentification of idle time-frequency resources. Based on these dedicated\nchirps, we propose a chirp-division multiple access (Chirp-DMA) scheme,\nenabling multiple pairs of mmWave radar transceivers to perform integrated\nsensing and communication (ISAC) without interference. Subsequently, we propose\ntwo chirp-based delay-Doppler domain modulation schemes that enable each pair\nof mmWave radar transceivers to simultaneously sense and communicate within\ntheir respective time-frequency resource blocks. The modulation schemes are\nbased on different multiple-input multiple-output (MIMO) radar schemes: the\ntime division multiplexing (TDM)-based scheme offers higher communication\nrates, while the Doppler division multiplexing (DDM)-based scheme is suitable\nfor working in a lower signal-to-noise ratio range. We then validate the\neffectiveness of the proposed DDM-based scheme through simulations. Finally, we\npresent some challenges and issues that need to be addressed to advance ISAC in\nV2X for better autonomous driving. Simulation codes are provided to reproduce\nthe results in this paper:\n\\href{https://github.com/LiZhuoRan0/2025-IEEE-Network-ChirpDelayDopplerModulationISAC}{https://github.com/LiZhuoRan0}.", "published": "2025-05-22 15:47:06", "link": "http://arxiv.org/abs/2505.16807v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Optimized Energy Harvesting in Cell-Free Massive MIMO Using Markov Process Evolution", "abstract": "This paper investigates a discrete energy state transition model for energy\nharvesting (EH) in cell-free massive multiple-input-multiple-output (CF-mMIMO)\nnetworks. A Markov chain-based stochastic process is conceived to characterize\nthe temporal evolution of the user equipment (UE) energy level by leveraging\nstate transition probabilities (STP) based on the energy differential ($\\Delta\nE$) between the EH and consumed energy within each coherence interval.\nTractable mathematical relationships are derived for the STP cases using a new\nstochastic model of non-linear EH, approximated using a Gamma distribution.\nThis derivation leverages closed-form expressions for the mean and variance of\nthe harvested energy. To improve the positive STP of the minimum energy UE\namong all network UEs, we aim to maximize the $\\Delta E$ for this UE using two\npower allocation (PA) schemes. The first scheme is a heuristic PA using the\nrelative channel characteristics to this UE from all access points (APs). The\nsecond scheme is the optimized PA based on the solution of a second-order conic\nproblem to maximize the $\\Delta E$ using a responsive primal-dual interior\npoint method (PD-IPM) algorithm with modified backtracking line-search,\niterating over multiple PA periods. Our simulation results illustrate that both\nthe proposed PA schemes enhance the dynamic minimum UE energy level by around\nfour-fold over full power control, along with the performance improvement\nattributed to spatial resource diversification of CF-mMIMO systems.", "published": "2025-05-22 13:58:54", "link": "http://arxiv.org/abs/2505.16693v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Magnetometer-IMU Calibration via Maximum A Posteriori Estimation", "abstract": "This paper presents a new approach for jointly calibrating magnetometers and\ninertial measurement units, focusing on improving calibration accuracy and\ncomputational efficiency. The proposed method formulates the calibration\nproblem as a maximum a posteriori estimation problem, treating both the\ncalibration parameters and orientation trajectory of the sensors as unknowns.\nThis formulation enables efficient optimization with closed-form derivatives.\nThe method is compared against two state-of-the-art approaches in terms of\ncomputational complexity and estimation accuracy. Simulation results\ndemonstrate that the proposed method achieves lower root mean square error in\ncalibration parameters while maintaining competitive computational efficiency.\nFurther validation through real-world experiments confirms the practical\nbenefits of our approach: it effectively reduces position drift in a magnetic\nfield-aided inertial navigation system by more than a factor of two on most\ndatasets. Moreover, the proposed method calibrated 30 magnetometers in less\nthan 2 minutes. The contributions include a new calibration method, an analysis\nof existing methods, and a comprehensive empirical evaluation. Datasets and\nalgorithms are made publicly available to promote reproducible research.", "published": "2025-05-22 13:27:42", "link": "http://arxiv.org/abs/2505.16662v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Monitoring Electrostatic Adhesion Forces via Acoustic Pressure", "abstract": "Electrostatic adhesion is widely used in mobile robotics, haptics, and\nrobotic end effectors for its adaptability to diverse substrates and low energy\nconsumption. Force sensing is important for feedback control, interaction, and\nmonitoring in the EA system. However, EA force monitoring often relies on bulky\nand expensive sensors, increasing the complexity and weight of the entire\nsystem. This paper presents an acoustic-pressure-based method to monitor EA\nforces without contacting the adhesion pad. When the EA pad is driven by a\nbipolar square-wave voltage to adhere a conductive object, periodic acoustic\npulses arise from the EA system. We employed a microphone to capture these\nacoustic pressure signals and investigate the influence of peak pressure\nvalues. Results show that the peak value of acoustic pressure increased with\nthe mass and contact area of the adhered object, as well as with the amplitude\nand frequency of the driving voltage. We applied this technique to mass\nestimation of various objects and simultaneous monitoring of two EA systems.\nThen, we integrated this technique into an EA end effector that enables\nmonitoring the change of adhered object mass during transport. The proposed\ntechnique offers a low-cost, non-contact, and multi-object monitoring solution\nfor EA end effectors in handling tasks.", "published": "2025-05-22 12:45:08", "link": "http://arxiv.org/abs/2505.16609v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Synthesis of Ventilator Dyssynchrony Waveforms using a Hybrid Generative Model and a Lung Model", "abstract": "Ventilator dyssynchrony (VD) is often described as a mismatch between a\npatient breathing effort and the ventilator support during mechanical\nventilation. This mismatch is often associated with an increased risk of lung\ninjury and longer hospital stays. The manual VD detection method is unreliable\nand requires considerable effort from medical professionals. Automating this\nprocess requires a computational pipeline that can identify VD breaths from\ncontinuous waveform signals. For that, while various machine learning (ML)\nmodels have been proposed, their accuracy is often limited due to the\nunavailability of a large, well-annotated VD waveform dataset. This paper\npresents a new approach combining mathematical and deep generative models to\ngenerate synthetic, clinically relevant VD waveforms. The mathematical model,\nwhich we call the VD lung ventilator model (VDLV), can accurately replicate\nclinically observable deformation in the pressure and volume waveforms. These\ntemporal deformations are hypothesized to be related to specific VD breaths. We\nleverage the VDLV model to produce training waveform datasets covering normal\nand various VD breaths. These datasets are further diversified using deep\nlearning models such as Generative Adversarial Network (GAN) and Conditional\nGAN (cGAN). The performance of both GAN and cGAN models is assessed through\nquantitative metrics, demonstrating that this hybrid approach effectively\ncreates realistic and diverse VD waveforms. Notably, the pressure and volume\ncGAN models enable the generation of more precise and targeted VD signals.\nThese improved synthetic waveform datasets have the potential to significantly\nenhance the accuracy and robustness of VD detection algorithms.", "published": "2025-05-22 09:44:29", "link": "http://arxiv.org/abs/2505.16462v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution", "abstract": "Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for\ntensor reconstruction. Although the Bayesian framework allows for principled\nuncertainty quantification and automatic hyperparameter learning, existing\nmethods do not scale well for large tensors because of high-dimensional matrix\ninversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD\nalgorithm. This algorithm leverages generalized approximate message passing\n(GAMP) to avoid matrix inversions and incorporates an expectation-maximization\nroutine to jointly infer the tensor rank and noise power. Through multiple\nexperiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements\nobserved, the proposed algorithm reduces runtime by 82.7% compared to the\nstate-of-the-art variational Bayesian CPD method, while maintaining comparable\nreconstruction accuracy.", "published": "2025-05-22 06:57:49", "link": "http://arxiv.org/abs/2505.16305v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Covariance matrix estimation in the singular case using regularized Cholesky factor", "abstract": "We consider estimating the population covariance matrix when the number of\navailable samples is less than the size of the observations. The sample\ncovariance matrix (SCM) being singular, regularization is mandatory in this\ncase. For this purpose we consider minimizing Stein's loss function and we\ninvestigate a method based on augmenting the partial Cholesky decomposition of\nthe SCM. We first derive the finite sample optimum estimator which minimizes\nthe loss for each data realization, then the Oracle estimator which minimizes\nthe risk, i.e., the average value of the loss. Finally a practical scheme is\npresented where the missing part of the Cholesky decomposition is filled. We\nconduct a numerical performance study of the proposed method and compare it\nwith available related methods. In particular we investigate the influence of\nthe condition number of the covariance matrix as well as of the shape of its\nspectrum.", "published": "2025-05-22 06:56:41", "link": "http://arxiv.org/abs/2505.16302v1", "categories": ["math.ST", "eess.SP", "stat.TH"], "primary_category": "math.ST"}
{"title": "X-ARES: A Comprehensive Framework for Assessing Audio Encoder Performance", "abstract": "We introduces X-ARES (eXtensive Audio Representation and Evaluation Suite), a\nnovel open-source benchmark designed to systematically assess audio encoder\nperformance across diverse domains. By encompassing tasks spanning speech,\nenvironmental sounds, and music, X-ARES provides two evaluation approaches for\nevaluating audio representations: linear fine-tuning and unparameterized\nevaluation. The framework includes 22 distinct tasks that cover essential\naspects of audio processing, from speech recognition and emotion detection to\nsound event classification and music genre identification. Our extensive\nevaluation of state-of-the-art audio encoders reveals significant performance\nvariations across different tasks and domains, highlighting the complexity of\ngeneral audio representation learning.", "published": "2025-05-22 08:23:54", "link": "http://arxiv.org/abs/2505.16369v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Layer-wise Investigation of Large-Scale Self-Supervised Music Representation Models", "abstract": "Recently, pre-trained models for music information retrieval based on\nself-supervised learning (SSL) are becoming popular, showing success in various\ndownstream tasks. However, there is limited research on the specific meanings\nof the encoded information and their applicability. Exploring these aspects can\nhelp us better understand their capabilities and limitations, leading to more\neffective use in downstream tasks.\n  In this study, we analyze the advanced music representation model MusicFM and\nthe newly emerged SSL model MuQ. We focus on three main aspects: (i) validating\nthe advantages of SSL models across multiple downstream tasks, (ii) exploring\nthe specialization of layer-wise information for different tasks, and (iii)\ncomparing performance differences when selecting specific layers. Through this\nanalysis, we reveal insights into the structure and potential applications of\nSSL models in music information retrieval.", "published": "2025-05-22 06:58:24", "link": "http://arxiv.org/abs/2505.16306v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dialogue in Resonance: An Interactive Music Piece for Piano and Real-Time Automatic Transcription System", "abstract": "This paper presents <Dialogue in Resonance>, an interactive music piece for a\nhuman pianist and a computer-controlled piano that integrates real-time\nautomatic music transcription into a score-driven framework. Unlike previous\napproaches that primarily focus on improvisation-based interactions, our work\nestablishes a balanced framework that combines composed structure with dynamic\ninteraction. Through real-time automatic transcription as its core mechanism,\nthe computer interprets and responds to the human performer's input in real\ntime, creating a musical dialogue that balances compositional intent with live\ninteraction while incorporating elements of unpredictability. In this paper, we\npresent the development process from composition to premiere performance,\nincluding technical implementation, rehearsal process, and performance\nconsiderations.", "published": "2025-05-22 05:50:13", "link": "http://arxiv.org/abs/2505.16259v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VeriFastScore: Speeding up long-form factuality evaluation", "abstract": "Metrics like FactScore and VeriScore that evaluate long-form factuality\noperate by decomposing an input response into atomic claims and then\nindividually verifying each claim. While effective and interpretable, these\nmethods incur numerous LLM calls and can take upwards of 100 seconds to\nevaluate a single response, limiting their practicality in large-scale\nevaluation and training scenarios. To address this, we propose VeriFastScore,\nwhich leverages synthetic data to fine-tune Llama3.1 8B for simultaneously\nextracting and verifying all verifiable claims within a given text based on\nevidence from Google Search. We show that this task cannot be solved via\nfew-shot prompting with closed LLMs due to its complexity: the model receives\n~4K tokens of evidence on average and needs to concurrently decompose claims,\njudge their verifiability, and verify them against noisy evidence. However, our\nfine-tuned VeriFastScore model demonstrates strong correlation with the\noriginal VeriScore pipeline at both the example level (r=0.80) and system level\n(r=0.94) while achieving an overall speedup of 6.6x (9.9x excluding evidence\nretrieval) over VeriScore. To facilitate future factuality research, we\npublicly release our VeriFastScore model and synthetic datasets.", "published": "2025-05-22 17:51:25", "link": "http://arxiv.org/abs/2505.16973v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Power-Law Decay Loss for Large Language Model Finetuning: Focusing on Information Sparsity to Enhance Generation Quality", "abstract": "During the finetuning stage of text generation tasks, standard cross-entropy\nloss treats all tokens equally. This can lead models to overemphasize\nhigh-frequency, low-information tokens, neglecting lower-frequency tokens\ncrucial for specificity and informativeness in generated content. This paper\nintroduces a novel loss function, Power-Law Decay Loss (PDL), specifically\ndesigned to optimize the finetuning process for text generation. The core\nmotivation for PDL stems from observations in information theory and\nlinguistics: the informativeness of a token is often inversely proportional to\nits frequency of occurrence. PDL re-weights the contribution of each token in\nthe standard cross-entropy loss based on its frequency in the training corpus,\nfollowing a power-law decay. Specifically, the weights for high-frequency\ntokens are reduced, while low-frequency, information-dense tokens are assigned\nhigher weights. This mechanism guides the model during finetuning to focus more\non learning and generating tokens that convey specific and unique information,\nthereby enhancing the quality, diversity, and informativeness of the generated\ntext. We theoretically elaborate on the motivation and construction of PDL and\ndiscuss its potential applications and advantages across various text\ngeneration finetuning tasks, such as abstractive summarization, dialogue\nsystems, and style transfer.", "published": "2025-05-22 16:59:26", "link": "http://arxiv.org/abs/2505.16900v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation", "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities in machine translation (MT). However, most advanced MT-specific\nLLMs heavily rely on external supervision signals during training, such as\nhuman-annotated reference data or trained reward models (RMs), which are often\nexpensive to obtain and challenging to scale. To overcome this limitation, we\npropose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for\nMT that is reference-free, fully online, and relies solely on self-judging\nrewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as\nthe backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs,\ne.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like\nQwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks\nfrom WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR\nwith external supervision from COMET, our strongest model, SSR-X-Zero-7B,\nachieves state-of-the-art performance in English $\\leftrightarrow$ Chinese\ntranslation, surpassing all existing open-source models under 72B parameters\nand even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro.\nOur analysis highlights the effectiveness of the self-rewarding mechanism\ncompared to the external LLM-as-a-judge approach in MT and demonstrates its\ncomplementary benefits when combined with trained RMs. Our findings provide\nvaluable insight into the potential of self-improving RL methods. We have\npublicly released our code, data and models.", "published": "2025-05-22 13:08:25", "link": "http://arxiv.org/abs/2505.16637v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Media Frames Reveal About Stance: A Dataset and Study about Memes in Climate Change Discourse", "abstract": "Media framing refers to the emphasis on specific aspects of perceived reality\nto shape how an issue is defined and understood. Its primary purpose is to\nshape public perceptions often in alignment with the authors' opinions and\nstances. However, the interaction between stance and media frame remains\nlargely unexplored. In this work, we apply an interdisciplinary approach to\nconceptualize and computationally explore this interaction with internet memes\non climate change. We curate CLIMATEMEMES, the first dataset of climate-change\nmemes annotated with both stance and media frames, inspired by research in\ncommunication science. CLIMATEMEMES includes 1,184 memes sourced from 47\nsubreddits, enabling analysis of frame prominence over time and communities,\nand sheds light on the framing preferences of different stance holders. We\npropose two meme understanding tasks: stance detection and media frame\ndetection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the\ncorresponding results on their LLM backbone. Human captions consistently\nenhance performance. Synthetic captions and human-corrected OCR also help\noccasionally. Our findings highlight that VLMs perform well on stance, but\nstruggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs'\nlimitations in handling nuanced frames and stance expressions on climate change\ninternet memes.", "published": "2025-05-22 12:27:12", "link": "http://arxiv.org/abs/2505.16592v2", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains", "abstract": "Large Language Models (LLMs) achieve superior performance through\nChain-of-Thought (CoT) reasoning, but these token-level reasoning chains are\ncomputationally expensive and inefficient. In this paper, we introduce\nCompressed Latent Reasoning (CoLaR), a novel framework that dynamically\ncompresses reasoning processes in latent space through a two-stage training\napproach. First, during supervised fine-tuning, CoLaR extends beyond next-token\nprediction by incorporating an auxiliary next compressed embedding prediction\nobjective. This process merges embeddings of consecutive tokens using a\ncompression factor randomly sampled from a predefined range, and trains a\nspecialized latent head to predict distributions of subsequent compressed\nembeddings. Second, we enhance CoLaR through reinforcement learning (RL) that\nleverages the latent head's non-deterministic nature to explore diverse\nreasoning paths and exploit more compact ones. This approach enables CoLaR to:\ni) perform reasoning at a dense latent level (i.e., silently), substantially\nreducing reasoning chain length, and ii) dynamically adjust reasoning speed at\ninference time by simply prompting the desired compression factor. Extensive\nexperiments across four mathematical reasoning datasets demonstrate that CoLaR\nachieves 14.1% higher accuracy than latent-based baseline methods at comparable\ncompression ratios, and reduces reasoning chain length by 53.3% with only 4.8%\nperformance degradation compared to explicit CoT method. Moreover, when applied\nto more challenging mathematical reasoning tasks, our RL-enhanced CoLaR\ndemonstrates performance gains of up to 5.4% while dramatically reducing latent\nreasoning chain length by 82.8%. The code and models will be released upon\nacceptance.", "published": "2025-05-22 11:40:26", "link": "http://arxiv.org/abs/2505.16552v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records", "abstract": "Foundation models hold significant promise in healthcare, given their\ncapacity to extract meaningful representations independent of downstream tasks.\nThis property has enabled state-of-the-art performance across several clinical\napplications trained on structured electronic health record (EHR) data, even in\nsettings with limited labeled data, a prevalent challenge in healthcare.\nHowever, there is little consensus on these models' potential for clinical\nutility due to the lack of desiderata of comprehensive and meaningful tasks and\nsufficiently diverse evaluations to characterize the benefit over conventional\nsupervised learning. To address this gap, we propose a suite of clinically\nmeaningful tasks spanning patient outcomes, early prediction of acute and\nchronic conditions, including desiderata for robust evaluations. We evaluate\nstate-of-the-art foundation models on EHR data consisting of 5 million patients\nfrom Columbia University Irving Medical Center (CUMC), a large urban academic\nmedical center in New York City, across 14 clinically relevant tasks. We\nmeasure overall accuracy, calibration, and subpopulation performance to surface\ntradeoffs based on the choice of pre-training, tokenization, and data\nrepresentation strategies. Our study aims to advance the empirical evaluation\nof structured EHR foundation models and guide the development of future\nhealthcare foundation models.", "published": "2025-05-22 17:29:52", "link": "http://arxiv.org/abs/2505.16941v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation", "abstract": "We introduce a new paradigm for active sound modification: Active Speech\nEnhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on\nsuppressing external interference, ASE goes further by actively shaping the\nspeech signal -- both attenuating unwanted noise components and amplifying\nspeech-relevant frequencies -- to improve intelligibility and perceptual\nquality. To enable this, we propose a novel Transformer-Mamba-based\narchitecture, along with a task-specific loss function designed to jointly\noptimize interference suppression and signal enrichment. Our method outperforms\nexisting baselines across multiple speech processing tasks -- including\ndenoising, dereverberation, and declipping -- demonstrating the effectiveness\nof active, targeted modulation in challenging acoustic environments.", "published": "2025-05-22 17:10:18", "link": "http://arxiv.org/abs/2505.16911v2", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models", "abstract": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.", "published": "2025-05-22 16:13:29", "link": "http://arxiv.org/abs/2505.16854v2", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting", "abstract": "For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic\nand text embeddings are typically compared at either the phoneme or utterance\nlevel. To facilitate this, we optimize acoustic and text encoders using deep\nmetric learning (DML), enabling direct comparison of multi-modal embeddings in\na shared embedding space. However, the inherent heterogeneity between audio and\ntext modalities presents a significant challenge. To address this, we propose\nModality Adversarial Learning (MAL), which reduces the domain gap in\nheterogeneous modality representations. Specifically, we train a modality\nclassifier adversarially to encourage both encoders to generate\nmodality-invariant embeddings. Additionally, we apply DML to achieve\nphoneme-level alignment between audio and text, and conduct extensive\ncomparisons across various DML objectives. Experiments on the Wall Street\nJournal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the\nproposed approach.", "published": "2025-05-22 14:49:46", "link": "http://arxiv.org/abs/2505.16735v2", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion", "abstract": "Voice Conversion research in recent times has increasingly focused on\nimproving the zero-shot capabilities of existing methods. Despite remarkable\nadvancements, current architectures still tend to struggle in zero-shot\ncross-lingual settings. They are also often unable to generalize for speakers\nof unseen languages and accents. In this paper, we adopt a simple yet effective\napproach that combines discrete speech representations from self-supervised\nmodels with a non-autoregressive Diffusion-Transformer based conditional flow\nmatching speech decoder. We show that this architecture allows us to train a\nvoice-conversion model in a purely textless, self-supervised fashion. Our\ntechnique works without requiring multiple encoders to disentangle speech\nfeatures. Our model also manages to excel in zero-shot cross-lingual settings\neven for unseen languages. For Demo: https://ez-vc.github.io/EZ-VC-Demo/", "published": "2025-05-22 13:57:02", "link": "http://arxiv.org/abs/2505.16691v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving", "abstract": "Large Language Models have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine mathematical reasoning or superficial pattern recognition.\nCommon evaluation metrics, such as final answer accuracy, fail to disentangle\nthe underlying competencies involved, offering limited diagnostic value. To\naddress these limitations, we introduce SMART: a Self-Generating and\nSelf-Validating Multi-Dimensional Assessment Framework. SMART decomposes\nmathematical problem solving into four distinct dimensions: understanding,\nreasoning, arithmetic, and reflection \\& refinement. Each dimension is\nevaluated independently through tailored tasks, enabling interpretable and\nfine-grained analysis of LLM behavior. Crucially, SMART integrates an automated\nself-generating and self-validating mechanism to produce and verify benchmark\ndata, ensuring both scalability and reliability. We apply SMART to 21\nstate-of-the-art open- and closed-source LLMs, uncovering significant\ndiscrepancies in their abilities across different dimensions. Our findings\ndemonstrate the inadequacy of final answer accuracy as a sole metric and\nmotivate a new holistic metric to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.", "published": "2025-05-22 13:18:24", "link": "http://arxiv.org/abs/2505.16646v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Finetuning-Activated Backdoors in LLMs", "abstract": "Finetuning openly accessible Large Language Models (LLMs) has become standard\npractice for achieving task-specific performance improvements. Until now,\nfinetuning has been regarded as a controlled and secure process in which\ntraining on benign datasets led to predictable behaviors. In this paper, we\ndemonstrate for the first time that an adversary can create poisoned LLMs that\ninitially appear benign but exhibit malicious behaviors once finetuned by\ndownstream users. To this end, our proposed attack, FAB (Finetuning-Activated\nBackdoor), poisons an LLM via meta-learning techniques to simulate downstream\nfinetuning, explicitly optimizing for the emergence of malicious behaviors in\nthe finetuned models. At the same time, the poisoned LLM is regularized to\nretain general capabilities and to exhibit no malicious behaviors prior to\nfinetuning. As a result, when users finetune the seemingly benign model on\ntheir own datasets, they unknowingly trigger its hidden backdoor behavior. We\ndemonstrate the effectiveness of FAB across multiple LLMs and three target\nbehaviors: unsolicited advertising, refusal, and jailbreakability.\nAdditionally, we show that FAB-backdoors are robust to various finetuning\nchoices made by the user (e.g., dataset, number of steps, scheduler). Our\nfindings challenge prevailing assumptions about the security of finetuning,\nrevealing yet another critical attack vector exploiting the complexities of\nLLMs.", "published": "2025-05-22 11:59:44", "link": "http://arxiv.org/abs/2505.16567v2", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "LaViDa: A Large Diffusion Language Model for Multimodal Understanding", "abstract": "Modern Vision-Language Models (VLMs) can solve a wide range of tasks\nrequiring visual reasoning. In real-world scenarios, desirable properties for\nVLMs include fast inference and controllable generation (e.g., constraining\noutputs to adhere to a desired format). However, existing autoregressive (AR)\nVLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs)\noffer a promising alternative, enabling parallel decoding for faster inference\nand bidirectional context for controllable generation through text-infilling.\nWhile effective in language-only settings, DMs' potential for multimodal tasks\nis underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build\nLaViDa by equipping DMs with a vision encoder and jointly fine-tune the\ncombined parts for multimodal instruction following. To address challenges\nencountered, LaViDa incorporates novel techniques such as complementary masking\nfor effective training, prefix KV cache for efficient inference, and timestep\nshifting for high-quality sampling. Experiments show that LaViDa achieves\ncompetitive or superior performance to AR VLMs on multi-modal benchmarks such\nas MMMU, while offering unique advantages of DMs, including flexible\nspeed-quality tradeoff, controllability, and bidirectional reasoning. On COCO\ncaptioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x\nspeedup. On bidirectional tasks, it achieves +59% improvement on Constrained\nPoem Completion. These results demonstrate LaViDa as a strong alternative to AR\nVLMs. Code and models will be released in the camera-ready version.", "published": "2025-05-22 16:07:12", "link": "http://arxiv.org/abs/2505.16839v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities", "abstract": "Existing methods for multimodal MRI segmentation with missing modalities\ntypically assume that all MRI modalities are available during training.\nHowever, in clinical practice, some modalities may be missing due to the\nsequential nature of MRI acquisition, leading to performance degradation.\nFurthermore, retraining models to accommodate newly available modalities can be\ninefficient and may cause overfitting, potentially compromising previously\nlearned knowledge. To address these challenges, we propose Replay-based\nHypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation\nwith missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to\nenable the segmentation model to learn from newly acquired MRI modalities\nwithout forgetting previously learned information. To enhance segmentation\nperformance across diverse patient scenarios, we introduce the Cross-Patient\nHypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture\nhigh-order associations between patients. Additionally, we incorporate\nTversky-Aware Contrastive (TAC) loss to effectively mitigate information\nimbalance both across and within different modalities. Extensive experiments on\nthe BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art\nmethods, achieving an improvement of over 2% in the Dice Similarity Coefficient\nacross various tumor regions.", "published": "2025-05-22 15:49:25", "link": "http://arxiv.org/abs/2505.16809v2", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs", "abstract": "The rapid advancement of native multi-modal models and omni-models,\nexemplified by GPT-4o, Gemini, and o3, with their capability to process and\ngenerate content across modalities such as text and images, marks a significant\nmilestone in the evolution of intelligence. Systematic evaluation of their\nmulti-modal output capabilities in visual thinking processes (also known as\nmulti-modal chain of thought, M-CoT) becomes critically important. However,\nexisting benchmarks for evaluating multi-modal models primarily focus on\nassessing multi-modal inputs and text-only reasoning while neglecting the\nimportance of reasoning through multi-modal outputs. In this paper, we present\na benchmark, dubbed RBench-V, designed to assess models' vision-indispensable\nreasoning abilities. To construct RBench-V, we carefully hand-pick 803\nquestions covering math, physics, counting, and games. Unlike previous\nbenchmarks that typically specify certain input modalities, RBench-V presents\nproblems centered on multi-modal outputs, which require image manipulation such\nas generating novel images and constructing auxiliary lines to support the\nreasoning process. We evaluate numerous open- and closed-source models on\nRBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the\nbest-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below\nthe human score of 82.3%, highlighting that current models struggle to leverage\nmulti-modal reasoning. Data and code are available at\nhttps://evalmodels.github.io/rbenchv", "published": "2025-05-22 15:11:57", "link": "http://arxiv.org/abs/2505.16770v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupled Geometric Parameterization and its Application in Deep Homography Estimation", "abstract": "Planar homography, with eight degrees of freedom (DOFs), is fundamental in\nnumerous computer vision tasks. While the positional offsets of four corners\nare widely adopted (especially in neural network predictions), this\nparameterization lacks geometric interpretability and typically requires\nsolving a linear system to compute the homography matrix. This paper presents a\nnovel geometric parameterization of homographies, leveraging the\nsimilarity-kernel-similarity (SKS) decomposition for projective\ntransformations. Two independent sets of four geometric parameters are\ndecoupled: one for a similarity transformation and the other for the kernel\ntransformation. Additionally, the geometric interpretation linearly relating\nthe four kernel transformation parameters to angular offsets is derived. Our\nproposed parameterization allows for direct homography estimation through\nmatrix multiplication, eliminating the need for solving a linear system, and\nachieves performance comparable to the four-corner positional offsets in deep\nhomography estimation.", "published": "2025-05-22 12:33:29", "link": "http://arxiv.org/abs/2505.16599v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems", "abstract": "This work develops the underpinnings of self-supervised placement-aware\nrepresentation learning given spatially-distributed (multi-view and multimodal)\nsensor observations, motivated by the need to represent external environmental\nstate in multi-sensor IoT systems in a manner that correctly distills spatial\nphenomena from the distributed multi-vantage observations. The objective of\nsensing in IoT systems is, in general, to collectively represent an externally\nobserved environment given multiple vantage points from which sensory\nobservations occur. Pretraining of models that help interpret sensor data must\ntherefore encode the relation between signals observed by sensors and the\nobservers' vantage points in order to attain a representation that encodes the\nobserved spatial phenomena in a manner informed by the specific placement of\nthe measuring instruments, while allowing arbitrary placement. The work\nsignificantly advances self-supervised model pretraining from IoT signals\nbeyond current solutions that often overlook the distinctive spatial nature of\nIoT data. Our framework explicitly learns the dependencies between measurements\nand geometric observer layouts and structural characteristics, guided by a core\ndesign principle: the duality between signals and observer positions. We\nfurther provide theoretical analyses from the perspectives of information\ntheory and occlusion-invariant representation learning to offer insight into\nthe rationale behind our design. Experiments on three real-world\ndatasets--covering vehicle monitoring, human activity recognition, and\nearthquake localization--demonstrate the superior generalizability and\nrobustness of our method across diverse modalities, sensor placements,\napplication-level inference tasks, and spatial scales.", "published": "2025-05-22 17:26:23", "link": "http://arxiv.org/abs/2505.16936v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation", "abstract": "A reliable uncertainty estimation method is the foundation of many modern\nout-of-distribution (OOD) detectors, which are critical for safe deployments of\ndeep learning models in the open world. In this work, we propose TULiP, a\ntheoretically-driven post-hoc uncertainty estimator for OOD detection. Our\napproach considers a hypothetical perturbation applied to the network before\nconvergence. Based on linearized training dynamics, we bound the effect of such\nperturbation, resulting in an uncertainty score computable by perturbing model\nparameters. Ultimately, our approach computes uncertainty from a set of sampled\npredictions. We visualize our bound on synthetic regression and classification\ndatasets. Furthermore, we demonstrate the effectiveness of TULiP using\nlarge-scale OOD detection benchmarks for image classification. Our method\nexhibits state-of-the-art performance, particularly for near-distribution\nsamples.", "published": "2025-05-22 17:16:41", "link": "http://arxiv.org/abs/2505.16923v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects", "abstract": "Offline reinforcement learning (RL) has gained traction as a powerful\nparadigm for learning control policies from pre-collected data, eliminating the\nneed for costly or risky online interactions. While many open-source libraries\noffer robust implementations of offline RL algorithms, they all rely on\ndatasets composed of experience tuples consisting of state, action, next state,\nand reward. Managing, curating, and distributing such datasets requires\nsuitable infrastructure. Although static datasets exist for established\nbenchmark problems, no standardized or scalable solution supports developing\nand sharing datasets for novel or user-defined benchmarks. To address this gap,\nwe introduce PyTupli, a Python-based tool to streamline the creation, storage,\nand dissemination of benchmark environments and their corresponding tuple\ndatasets. PyTupli includes a lightweight client library with defined interfaces\nfor uploading and retrieving benchmarks and data. It supports fine-grained\nfiltering at both the episode and tuple level, allowing researchers to curate\nhigh-quality, task-specific datasets. A containerized server component enables\nproduction-ready deployment with authentication, access control, and automated\ncertificate provisioning for secure use. By addressing key barriers in dataset\ninfrastructure, PyTupli facilitates more collaborative, reproducible, and\nscalable offline RL research.", "published": "2025-05-22 14:59:20", "link": "http://arxiv.org/abs/2505.16754v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich Document Understanding", "abstract": "In this work, we propose Few Shot Domain Adapting Graph (FS-DAG), a scalable\nand efficient model architecture for visually rich document understanding\n(VRDU) in few-shot settings. FS-DAG leverages domain-specific and\nlanguage/vision specific backbones within a modular framework to adapt to\ndiverse document types with minimal data. The model is robust to practical\nchallenges such as handling OCR errors, misspellings, and domain shifts, which\nare critical in real-world deployments. FS-DAG is highly performant with less\nthan 90M parameters, making it well-suited for complex real-world applications\nfor Information Extraction (IE) tasks where computational resources are\nlimited. We demonstrate FS-DAG's capability through extensive experiments for\ninformation extraction task, showing significant improvements in convergence\nspeed and performance compared to state-of-the-art methods. Additionally, this\nwork highlights the ongoing progress in developing smaller, more efficient\nmodels that do not compromise on performance. Code :\nhttps://github.com/oracle-samples/fs-dag", "published": "2025-05-22 22:53:58", "link": "http://arxiv.org/abs/2505.17330v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR", "cs.LG", "I.2.7; I.5.4; I.7"], "primary_category": "cs.CV"}
{"title": "VoxRAG: A Step Toward Transcription-Free RAG Systems in Spoken Question Answering", "abstract": "We introduce VoxRAG, a modular speech-to-speech retrieval-augmented\ngeneration system that bypasses transcription to retrieve semantically relevant\naudio segments directly from spoken queries. VoxRAG employs silence-aware\nsegmentation, speaker diarization, CLAP audio embeddings, and FAISS retrieval\nusing L2-normalized cosine similarity. We construct a 50-query test set\nrecorded as spoken input by a native English speaker. Retrieval quality was\nevaluated using LLM-as-a-judge annotations. For very relevant segments, cosine\nsimilarity achieved a Recall@10 of 0.34. For somewhat relevant segments,\nRecall@10 rose to 0.60 and nDCG@10 to 0.27, highlighting strong topical\nalignment. Answer quality was judged on a 0--2 scale across relevance,\naccuracy, completeness, and precision, with mean scores of 0.84, 0.58, 0.56,\nand 0.46 respectively. While precision and retrieval quality remain key\nlimitations, VoxRAG shows that transcription-free speech-to-speech retrieval is\nfeasible in RAG systems.", "published": "2025-05-22 22:42:40", "link": "http://arxiv.org/abs/2505.17326v1", "categories": ["cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
{"title": "Content Moderation in TV Search: Balancing Policy Compliance, Relevance, and User Experience", "abstract": "Millions of people rely on search functionality to find and explore content\non entertainment platforms. Modern search systems use a combination of\ncandidate generation and ranking approaches, with advanced methods leveraging\ndeep learning and LLM-based techniques to retrieve, generate, and categorize\nsearch results. Despite these advancements, search algorithms can still surface\ninappropriate or irrelevant content due to factors like model unpredictability,\nmetadata errors, or overlooked design flaws. Such issues can misalign with\nproduct goals and user expectations, potentially harming user trust and\nbusiness outcomes. In this work, we introduce an additional monitoring layer\nusing Large Language Models (LLMs) to enhance content moderation. This\nadditional layer flags content if the user did not intend to search for it.\nThis approach serves as a baseline for product quality assurance, with\ncollected feedback used to refine the initial retrieval mechanisms of the\nsearch model, ensuring a safer and more reliable user experience.", "published": "2025-05-22 18:32:39", "link": "http://arxiv.org/abs/2505.17207v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "ViDoRe Benchmark V2: Raising the Bar for Visual Retrieval", "abstract": "The ViDoRe Benchmark V1 was approaching saturation with top models exceeding\n90% nDCG@5, limiting its ability to discern improvements. ViDoRe Benchmark V2\nintroduces realistic, challenging retrieval scenarios via blind contextual\nquerying, long and cross-document queries, and a hybrid synthetic and\nhuman-in-the-loop query generation process. It comprises four diverse,\nmultilingual datasets and provides clear evaluation instructions. Initial\nresults demonstrate substantial room for advancement and highlight insights on\nmodel generalization and multilingual capability. This benchmark is designed as\na living resource, inviting community contributions to maintain relevance\nthrough future evaluations.", "published": "2025-05-22 16:13:02", "link": "http://arxiv.org/abs/2505.17166v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DailyQA: A Benchmark to Evaluate Web Retrieval Augmented LLMs Based on Capturing Real-World Changes", "abstract": "We propose DailyQA, an automatically updated dynamic dataset that updates\nquestions weekly and contains answers to questions on any given date. DailyQA\nutilizes daily updates from Wikipedia revision logs to implement a fully\nautomated pipeline of data filtering, query generation synthesis, quality\nchecking, answer extraction, and query classification. The benchmark requires\nlarge language models (LLMs) to process and answer questions involving\nfast-changing factual data and covering multiple domains. We evaluate several\nopen-source and closed-source LLMs using different RAG pipelines with web\nsearch augmentation. We compare the ability of different models to process\ntime-sensitive web information and find that rerank of web retrieval results is\ncritical. Our results indicate that LLMs still face significant challenges in\nhandling frequently updated information, suggesting that DailyQA benchmarking\nprovides valuable insights into the direction of progress for LLMs and RAG\nsystems.", "published": "2025-05-22 15:13:33", "link": "http://arxiv.org/abs/2505.17162v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "GPT Editors, Not Authors: The Stylistic Footprint of LLMs in Academic Preprints", "abstract": "The proliferation of Large Language Models (LLMs) in late 2022 has impacted\nacademic writing, threatening credibility, and causing institutional\nuncertainty. We seek to determine the degree to which LLMs are used to generate\ncritical text as opposed to being used for editing, such as checking for\ngrammar errors or inappropriate phrasing. In our study, we analyze arXiv papers\nfor stylistic segmentation, which we measure by varying a PELT threshold\nagainst a Bayesian classifier trained on GPT-regenerated text. We find that\nLLM-attributed language is not predictive of stylistic segmentation, suggesting\nthat when authors use LLMs, they do so uniformly, reducing the risk of\nhallucinations being introduced into academic preprints.", "published": "2025-05-22 22:44:27", "link": "http://arxiv.org/abs/2505.17327v1", "categories": ["cs.CL", "cs.IT", "cs.LG", "math.IT", "68U99", "I.2.7"], "primary_category": "cs.CL"}
{"title": "SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use", "abstract": "Enterprise customers are increasingly adopting Large Language Models (LLMs)\nfor critical communication tasks, such as drafting emails, crafting sales\npitches, and composing casual messages. Deploying such models across different\nregions requires them to understand diverse cultural and linguistic contexts\nand generate safe and respectful responses. For enterprise applications, it is\ncrucial to mitigate reputational risks, maintain trust, and ensure compliance\nby effectively identifying and handling unsafe or offensive language. To\naddress this, we introduce SweEval, a benchmark simulating real-world scenarios\nwith variations in tone (positive or negative) and context (formal or\ninformal). The prompts explicitly instruct the model to include specific swear\nwords while completing the task. This benchmark evaluates whether LLMs comply\nwith or resist such inappropriate instructions and assesses their alignment\nwith ethical frameworks, cultural nuances, and language comprehension\ncapabilities. In order to advance research in building ethically aligned AI\nsystems for enterprise use and beyond, we release the dataset and code:\nhttps://github.com/amitbcp/multilingual_profanity.", "published": "2025-05-22 22:56:58", "link": "http://arxiv.org/abs/2505.17332v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Distribution through Repeated Market with Buying Rights", "abstract": "Resource distribution is a fundamental problem in economic and policy design,\nparticularly when demand and supply are not naturally aligned. Without\nregulation, wealthier individuals may monopolize this resource, leaving the\nneeds of others unsatisfied. While centralized distribution can ensure fairer\ndivision, it can struggle to manage logistics efficiently, and adapt to\nchanging conditions, often leading to shortages, surpluses, and bureaucratic\ninefficiencies. Building on previous research on market-based redistribution,\nwe examine a repeated hybrid market that incorporates buying rights. These\nrights, distributed iteratively by a central authority (for instance, as\ndigital tokens), are intended to enhance fairness in the system - a unit of\nright is required to acquire a unit of the resource, but the rights themselves\ncan also be traded alongside the resource in the market. We analyze how this\nregulatory mechanism influences the distribution of the scarce resource in the\nhybrid market over time. Unlike past works that relied on empirical methods, we\nexplore the exact analytical properties of a system in which traders optimize\nover multiple rounds. We identify its market equilibrium, which is a natural\ngeneralization of the free market equilibrium, and show that it is\ncoalition-proof. To assess the fairness in the system, we use the concept of\nfrustration, which measures the gap between the resources a buyer is entitled\nto through their buying rights and what they actually obtain through trading.\nOur main theoretical result shows that using buying rights reduces the\nfrustration by at least half compared to the free market. Empirical evaluations\nfurther support our findings, suggesting the system performs well even beyond\nthe theoretically studied assumptions.", "published": "2025-05-22 20:39:42", "link": "http://arxiv.org/abs/2505.17271v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Data-driven Closure Strategies for Parametrized Reduced Order Models via Deep Operator Networks", "abstract": "In this paper, we propose an equation-based parametric Reduced Order Model\n(ROM), whose accuracy is improved with data-driven terms added into the reduced\nequations. These additions have the aim of reintroducing contributions that in\nstandard reduced-order approaches are not taken into account. In particular, in\nthis work we focus on a Proper Orthogonal Decomposition (POD)-based formulation\nand our goal is to build a closure or correction model, aimed to re-introduce\nthe contribution of the discarded modes. The approach has been investigated in\nprevious works, and the goal of this manuscript is to extend the model to a\nparametric setting making use of machine learning procedures, and, in\nparticular, of deep operator networks. More in detail, we model the closure\nterms through a deep operator network taking as input the reduced variables and\nthe parameters of the problem. We tested the methods on three test cases with\ndifferent behaviors: the periodic turbulent flow past a circular cylinder, the\nunsteady turbulent flow in a channel-driven cavity, and the\ngeometrically-parametrized backstep flow. The performance of the machine\nlearning-enhanced ROM is deeply studied in different modal regimes, and\nconsiderably improved the pressure and velocity accuracy with respect to the\nstandard POD-Galerkin approach.", "published": "2025-05-22 21:51:23", "link": "http://arxiv.org/abs/2505.17305v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Finite element spaces of double forms", "abstract": "The tensor product of two differential forms of degree $p$ and $q$ is a\nmultilinear form that is alternating in its first $p$ arguments and alternating\nin its last $q$ arguments. These forms, which are known as double forms or\n$(p,q)$-forms, play a central role in certain differential complexes that arise\nwhen studying partial differential equations. We construct piecewise polynomial\nfinite element spaces for all of the natural subspaces of the space of\n$(p,q)$-forms, excluding one subspace which fails to admit a piecewise constant\ndiscretization. As special cases, our construction recovers known finite\nelement spaces for symmetric matrices with tangential-tangential continuity\n(the Regge finite elements), symmetric matrices with normal-normal continuity,\nand trace-free matrices with normal-tangential continuity. It also gives rise\nto new spaces, like a finite element space for tensors possessing the\nsymmetries of the Riemann curvature tensor.", "published": "2025-05-22 19:43:59", "link": "http://arxiv.org/abs/2505.17243v1", "categories": ["math.NA", "cs.NA", "math.DG", "65N30, 15A69, 58A10, 53A45"], "primary_category": "math.NA"}
{"title": "Primitive variable regularization to derive novel Hyperbolic Shallow Water Moment Equations", "abstract": "Shallow Water Moment Equations are reduced-order models for free-surface\nflows that employ a vertical velocity expansion and derive additional so-called\nmoment equations for the expansion coefficients. Among desirable analytical\nproperties for such systems of equations are hyperbolicity, accuracy, correct\nmomentum equation, and interpretable steady states. In this paper, we show\nanalytically that existing models fail at different of these properties and we\nderive new models overcoming the disadvantages. This is made possible by\nperforming a hyperbolic regularization not in the convective variables (as done\nin the existing models) but in the primitive variables. Via analytical\ntransformations between the convective and primitive system, we can prove\nhyperbolicity and compute analytical steady states of the new models.\nSimulating a dam-break test case, we demonstrate the accuracy of the new models\nand show that it is essential for accuracy to preserve the momentum equation.", "published": "2025-05-22 18:46:01", "link": "http://arxiv.org/abs/2505.17216v1", "categories": ["math.NA", "cs.NA", "math.AP", "physics.comp-ph", "physics.flu-dyn", "35L65, 76B15, 35P15"], "primary_category": "math.NA"}
{"title": "An Adaptive-rank Approach with Greedy Sampling for Multi-scale BGK Equations", "abstract": "In this paper, we propose a novel adaptive-rank method for simulating\nmulti-scale BGK equations, based on a greedy sampling strategy. The method\nadaptively selects important rows and columns of the solution matrix and\nupdates them using a local semi-Lagrangian solver. An adaptive cross\napproximation then reconstructs the full solution matrix. This extends our\nprior semi-Lagrangian adaptive-rank framework, developed for the Vlasov-Poisson\nsystem, to nonlinear collisional kinetic equations. Unlike step-and-truncate\nlow-rank integrators, our greedy sampling approach avoids explicit low-rank\ndecompositions of nonlinear terms, such as the local Maxwellian in the BGK\noperator. To ensure conservation, we introduce a locally macroscopic\nconservative correction that implicitly couples the kinetic and macroscopic\nsystems, enforcing mass, momentum, and energy conservation. Through asymptotic\nanalysis, we show that this correction preserves the full-grid scheme's\nasymptotic behavior, and that the proposed method is conditionally\nasymptotic-preserving in the low-rank setting. A key advantage of our approach\nis its use of a local semi-Lagrangian solver, which allows large time steps.\nThis flexibility is retained in the macroscopic solver using high-order stiffly\naccurate diagonally implicit Runge-Kutta methods. The resulting nonlinear\nsystems are solved efficiently using a Jacobian-free Newton-Krylov method,\navoiding the need for preconditioning at modest CFL numbers. Each nonlinear\niteration provides a self-consistent correction to a provisional kinetic\nsolution, which serves as a dynamic closure for the macroscopic model.\nNumerical results demonstrate the method's accuracy in capturing shocks and its\nrobustness across mixed-regime problems with wide-ranging Knudsen numbers.", "published": "2025-05-22 18:02:06", "link": "http://arxiv.org/abs/2505.17191v1", "categories": ["math.NA", "cs.NA", "65M85 (primary), 65M70, 65F30 (secondary)"], "primary_category": "math.NA"}
{"title": "Repulsive Ensembles for Bayesian Inference in Physics-informed Neural Networks", "abstract": "Physics-informed neural networks (PINNs) have proven an effective tool for\nsolving differential equations, in particular when considering non-standard or\nill-posed settings. When inferring solutions and parameters of the differential\nequation from data, uncertainty estimates are preferable to point estimates, as\nthey give an idea about the accuracy of the solution. In this work, we consider\nthe inverse problem and employ repulsive ensembles of PINNs (RE-PINN) for\nobtaining such estimates. The repulsion is implemented by adding a particular\nrepulsive term to the loss function, which has the property that the ensemble\npredictions correspond to the true Bayesian posterior in the limit of infinite\nensemble members. Where possible, we compare the ensemble predictions to Monte\nCarlo baselines. Whereas the standard ensemble tends to collapse to\nmaximum-a-posteriori solutions, the repulsive ensemble produces significantly\nmore accurate uncertainty estimates and exhibits higher sample diversity.", "published": "2025-05-22 21:58:40", "link": "http://arxiv.org/abs/2505.17308v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Statistical Inference for Online Algorithms", "abstract": "Construction of confidence intervals and hypothesis tests for functionals\nbased on asymptotically normal estimators is a classical topic in statistical\ninference. The simplest and in many cases optimal inference procedure is the\nWald interval or the likelihood ratio test, both of which require an estimator\nand an estimate of the asymptotic variance of the estimator. Estimators\nobtained from online/sequential algorithms forces one to consider the\ncomputational aspects of the inference problem, i.e., one cannot access all of\nthe data as many times as needed. Several works on this topic explored the\nonline estimation of asymptotic variance. In this article, we propose\ncomputationally efficient, rate-optimal, and asymptotically valid confidence\nregions based on the output of online algorithms {\\em without} estimating the\nasymptotic variance. As a special case, this implies inference from any\nalgorithm that yields an asymptotically normal estimator. We focus our efforts\non stochastic gradient descent with Polyak averaging to understand the\npractical performance of the proposed method.", "published": "2025-05-22 21:31:49", "link": "http://arxiv.org/abs/2505.17300v1", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Optimal Transport with Heterogeneously Missing Data", "abstract": "We consider the problem of solving the optimal transport problem between two\nempirical distributions with missing values. Our main assumption is that the\ndata is missing completely at random (MCAR), but we allow for heterogeneous\nmissingness probabilities across features and across the two distributions. As\na first contribution, we show that the Wasserstein distance between empirical\nGaussian distributions and linear Monge maps between arbitrary distributions\ncan be debiased without significantly affecting the sample complexity.\nSecondly, we show that entropic regularized optimal transport can be estimated\nefficiently and consistently using iterative singular value thresholding\n(ISVT). We propose a validation set-free hyperparameter selection strategy for\nISVT that leverages our estimator of the Bures-Wasserstein distance, which\ncould be of independent interest in general matrix completion problems.\nFinally, we validate our findings on a wide range of numerical applications.", "published": "2025-05-22 21:16:22", "link": "http://arxiv.org/abs/2505.17291v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Learning to Choose or Choosing to Learn: Best-of-N vs. Supervised Fine-Tuning for Bit String Generation", "abstract": "Using the bit string generation problem as a case study, we theoretically\ncompare two standard methods for adapting large language models to new tasks.\nThe first, referred to as supervised fine-tuning, involves training a new next\ntoken predictor on good generations. The second method, Best-of-N, trains a\nreward model to select good responses from a collection generated by an\nunaltered base model. If the learning setting is realizable, we find that\nsupervised fine-tuning outperforms BoN through a better dependence on the\nresponse length in its rate of convergence. If realizability fails, then\ndepending on the failure mode, BoN can enjoy a better rate of convergence in\neither n or a rate of convergence with better dependence on the response\nlength.", "published": "2025-05-22 21:05:04", "link": "http://arxiv.org/abs/2505.17288v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Deconfounded Warm-Start Thompson Sampling with Applications to Precision Medicine", "abstract": "Randomized clinical trials often require large patient cohorts before drawing\ndefinitive conclusions, yet abundant observational data from parallel studies\nremains underutilized due to confounding and hidden biases. To bridge this gap,\nwe propose Deconfounded Warm-Start Thompson Sampling (DWTS), a practical\napproach that leverages a Doubly Debiased LASSO (DDL) procedure to identify a\nsparse set of reliable measured covariates and combines them with key hidden\ncovariates to form a reduced context. By initializing Thompson Sampling (LinTS)\npriors with DDL-estimated means and variances on these measured features --\nwhile keeping uninformative priors on hidden features -- DWTS effectively\nharnesses confounded observational data to kick-start adaptive clinical trials.\nEvaluated on both a purely synthetic environment and a virtual environment\ncreated using real cardiovascular risk dataset, DWTS consistently achieves\nlower cumulative regret than standard LinTS, showing how offline causal\ninsights from observational data can improve trial efficiency and support more\npersonalized treatment decisions.", "published": "2025-05-22 21:00:19", "link": "http://arxiv.org/abs/2505.17283v1", "categories": ["stat.ML", "cs.LG", "math.OC", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Liouville PDE-based sliced-Wasserstein flow for fair regression", "abstract": "The sliced Wasserstein flow (SWF), a nonparametric and implicit generative\ngradient flow, is applied to fair regression. We have improved the SWF in a few\naspects. First, the stochastic diffusive term from the Fokker-Planck\nequation-based Monte Carlo is transformed to Liouville partial differential\nequation (PDE)-based transport with density estimation, however, without the\ndiffusive term. Now, the computation of the Wasserstein barycenter is\napproximated by the SWF barycenter with the prescription of Kantorovich\npotentials for the induced gradient flow to generate its samples. These two\nefforts improve the convergence in training and testing SWF and SWF barycenters\nwith reduced variance. Applying the generative SWF barycenter for fair\nregression demonstrates competent profiles in the accuracy-fairness Pareto\ncurves.", "published": "2025-05-22 18:21:54", "link": "http://arxiv.org/abs/2505.17204v1", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.CO", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Learning Probabilities of Causation from Finite Population Data", "abstract": "Probabilities of causation play a crucial role in modern decision-making.\nThis paper addresses the challenge of predicting probabilities of causation for\nsubpopulations with \\textbf{insufficient} data using machine learning models.\nTian and Pearl first defined and derived tight bounds for three fundamental\nprobabilities of causation: the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN).\nHowever, estimating these probabilities requires both experimental and\nobservational distributions specific to each subpopulation, which are often\nunavailable or impractical to obtain with limited population-level data.\nTherefore, for most subgroups, the amount of data they have is not enough to\nguarantee the accuracy of their probabilities. Hence, to estimate these\nprobabilities for subpopulations with \\textbf{insufficient} data, we propose\nusing machine learning models that draw insights from subpopulations with\nsufficient data. Our evaluation of multiple machine learning models indicates\nthat, given the population-level data and an appropriate choice of machine\nlearning model and activation function, PNS can be effectively predicted.\nThrough simulation studies on multiple Structured Causal Models (SCMs), we show\nthat our multilayer perceptron (MLP) model with the Mish activation function\nachieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS\nfor $32,768$ subpopulations across most SCMs using data from only $2,000$\nsubpopulations with known PNS values.", "published": "2025-05-22 03:31:44", "link": "http://arxiv.org/abs/2505.17133v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Relative Bias: A Comparative Framework for Quantifying Bias in LLMs", "abstract": "The growing deployment of large language models (LLMs) has amplified concerns\nregarding their inherent biases, raising critical questions about their\nfairness, safety, and societal impact. However, quantifying LLM bias remains a\nfundamental challenge, complicated by the ambiguity of what \"bias\" entails.\nThis challenge grows as new models emerge rapidly and gain widespread use,\nwhile introducing potential biases that have not been systematically assessed.\nIn this paper, we propose the Relative Bias framework, a method designed to\nassess how an LLM's behavior deviates from other LLMs within a specified target\ndomain. We introduce two complementary methodologies: (1) Embedding\nTransformation analysis, which captures relative bias patterns through sentence\nrepresentations over the embedding space, and (2) LLM-as-a-Judge, which employs\na language model to evaluate outputs comparatively. Applying our framework to\nseveral case studies on bias and alignment scenarios following by statistical\ntests for validation, we find strong alignment between the two scoring methods,\noffering a systematic, scalable, and statistically grounded approach for\ncomparative bias analysis in LLMs.", "published": "2025-05-22 01:59:54", "link": "http://arxiv.org/abs/2505.17131v1", "categories": ["cs.CL", "cs.AI", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Benchmarking Expressive Japanese Character Text-to-Speech with VITS and Style-BERT-VITS2", "abstract": "Synthesizing expressive Japanese character speech poses unique challenges due\nto pitch-accent sensitivity and stylistic variability. This paper benchmarks\ntwo open-source text-to-speech models--VITS and Style-BERT-VITS2 JP Extra\n(SBV2JE)--on in-domain, character-driven Japanese speech. Using three\ncharacter-specific datasets, we evaluate models across naturalness (mean\nopinion and comparative mean opinion score), intelligibility (word error rate),\nand speaker consistency. SBV2JE matches human ground truth in naturalness (MOS\n4.37 vs. 4.38), achieves lower WER, and shows slight preference in CMOS.\nEnhanced by pitch-accent controls and a WavLM-based discriminator, SBV2JE\nproves effective for applications like language learning and character dialogue\ngeneration, despite higher computational demands.", "published": "2025-05-22 22:18:55", "link": "http://arxiv.org/abs/2505.17320v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Understanding the Algorithm Behind Audio Key Detection", "abstract": "The determination of musical key is a fundamental aspect of music theory and\nperception, providing a harmonic context for melodies and chord progressions.\nAutomating this process, known as automatic key detection, is a significant\ntask in the field of Music Information Retrieval (MIR). This article outlines\nan algorithmic methodology for estimating the musical key of an audio recording\nby analyzing its tonal content through digital signal processing techniques and\ncomparison with theoretical key profiles.", "published": "2025-05-22 20:14:53", "link": "http://arxiv.org/abs/2505.17259v1", "categories": ["cs.SD", "eess.AS", "94A12, 00A69, 68T10", "H.5.5; I.5.4"], "primary_category": "cs.SD"}
{"title": "Semantic-Aware Interpretable Multimodal Music Auto-Tagging", "abstract": "Music auto-tagging is essential for organizing and discovering music in\nextensive digital libraries. While foundation models achieve exceptional\nperformance in this domain, their outputs often lack interpretability, limiting\ntrust and usability for researchers and end-users alike. In this work, we\npresent an interpretable framework for music auto-tagging that leverages groups\nof musically meaningful multimodal features, derived from signal processing,\ndeep learning, ontology engineering, and natural language processing. To\nenhance interpretability, we cluster features semantically and employ an\nexpectation maximization algorithm, assigning distinct weights to each group\nbased on its contribution to the tagging process. Our method achieves\ncompetitive tagging performance while offering a deeper understanding of the\ndecision-making process, paving the way for more transparent and user-centric\nmusic tagging systems.", "published": "2025-05-22 19:15:48", "link": "http://arxiv.org/abs/2505.17233v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis", "abstract": "Retrieval-augmented generation (RAG) systems have advanced large language\nmodels (LLMs) in complex deep search scenarios requiring multi-step reasoning\nand iterative information retrieval. However, existing approaches face critical\nlimitations that lack high-quality training trajectories or suffer from the\ndistributional mismatches in simulated environments and prohibitive\ncomputational costs for real-world deployment. This paper introduces\nSimpleDeepSearcher, a lightweight yet effective framework that bridges this gap\nthrough strategic data engineering rather than complex training paradigms. Our\napproach synthesizes high-quality training data by simulating realistic user\ninteractions in live web search environments, coupled with a multi-criteria\ncuration strategy that optimizes the diversity and quality of input and output\nside. Experiments on five benchmarks across diverse domains demonstrate that\nSFT on only 871 curated samples yields significant improvements over RL-based\nbaselines. Our work establishes SFT as a viable pathway by systematically\naddressing the data-scarce bottleneck, offering practical insights for\nefficient deep search systems. Our code is available at\nhttps://github.com/RUCAIBox/SimpleDeepSearcher.", "published": "2025-05-22 16:05:02", "link": "http://arxiv.org/abs/2505.16834v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DeepRec: Towards a Deep Dive Into the Item Space with Large Language Model Based Recommendation", "abstract": "Recently, large language models (LLMs) have been introduced into recommender\nsystems (RSs), either to enhance traditional recommendation models (TRMs) or\nserve as recommendation backbones. However, existing LLM-based RSs often do not\nfully exploit the complementary advantages of LLMs (e.g., world knowledge and\nreasoning) and TRMs (e.g., recommendation-specific knowledge and efficiency) to\nfully explore the item space. To address this, we propose DeepRec, a novel\nLLM-based RS that enables autonomous multi-turn interactions between LLMs and\nTRMs for deep exploration of the item space. In each interaction turn, LLMs\nreason over user preferences and interact with TRMs to retrieve candidate\nitems. After multi-turn interactions, LLMs rank the retrieved items to generate\nthe final recommendations. We adopt reinforcement learning(RL) based\noptimization and propose novel designs from three aspects: recommendation model\nbased data rollout, recommendation-oriented hierarchical rewards, and a\ntwo-stage RL training strategy. For data rollout, we introduce a\npreference-aware TRM, with which LLMs interact to construct trajectory data.\nFor rewards, we design a hierarchical reward function that involves both\nprocess-level and outcome-level rewards to optimize the interaction process and\nrecommendation performance, respectively. For RL training, we develop a\ntwo-stage training strategy, where the first stage aims to guide LLMs to\ninteract with TRMs and the second stage focuses on performance improvement.\nExperiments on public datasets demonstrate that DeepRec significantly\noutperforms both traditional and LLM-based baselines, offering a new paradigm\nfor deep exploration in recommendation systems.", "published": "2025-05-22 15:49:38", "link": "http://arxiv.org/abs/2505.16810v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation", "abstract": "We introduce a Dual-Flow Generative Ranking Network (DFGR) for recommendation\nscenarios. This architecture utilizes only raw user behavior sequence\ninformation together with a small amount of basic information describing the\nbehaviors to address the limitations of Deep Learning Recommendation Models\n(DLRMs) that rely on extensive manual feature engineering. DFGR employs a\ndual-flow mechanism to optimize interaction modeling, ensuring efficient\ntraining and inference through end-to-end token processing. It duplicates the\noriginal user behavior sequence into a real flow and a fake flow based on\nwhether the action information used is authentic and then defines a novel\ninteraction method between the real flow and the fake flow within the QKV\nmodule of the self-attention mechanism. This design reduces computational\noverhead and improves both training efficiency and inference performance\ncompared to Meta's HSTU-based model which can be considered the current\nstate-of-the-art (SOTA) model in generative ranking. Our experiments in\nopen-source and real industrial datasets show that DFGR outperforms DLRM, which\ncan be regarded as an industrial online baseline that uses extensive feature\nengineering, Meta's HSTU approaches, and common recommendation architectures\nsuch as DIN, DCN, DIEN, and DeepFM. We also investigate optimal parameter\nallocation strategies under computational constraints, establishing DFGR as an\nefficient and effective next-generation generative ranking paradigm.", "published": "2025-05-22 14:58:53", "link": "http://arxiv.org/abs/2505.16752v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) encounters efficiency challenges when\nscaling to massive knowledge bases while preserving contextual relevance. We\npropose Hash-RAG, a framework that integrates deep hashing techniques with\nsystematic optimizations to address these limitations. Our queries directly\nlearn binary hash codes from knowledgebase code, eliminating intermediate\nfeature extraction steps, and significantly reducing storage and computational\noverhead. Building upon this hash-based efficient retrieval framework, we\nestablish the foundation for fine-grained chunking. Consequently, we design a\nPrompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved\nhash-indexed propositions and their original document segments through prompt\nengineering to enhance the LLM's contextual awareness. Experimental evaluations\non NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a\n90% reduction in retrieval time compared to conventional methods while\nmaintaining considerate recall performance. Additionally, The proposed system\noutperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.", "published": "2025-05-22 02:22:11", "link": "http://arxiv.org/abs/2505.16133v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Stochastic collocation schemes for Neural Field Equations with random data", "abstract": "We develop and analyse numerical schemes for uncertainty quantification in\nneural field equations subject to random parametric data in the synaptic\nkernel, firing rate, external stimulus, and initial conditions. The schemes\ncombine a generic projection method for spatial discretisation to a stochastic\ncollocation scheme for the random variables. We study the problem in operator\nform, and derive estimates for the total error of the schemes, in terms of the\nspatial projector. We give conditions on the projected random data which\nguarantee analyticity of the semi-discrete solution as a Banach-valued\nfunction. We illustrate how to verify hypotheses starting from analytic random\ndata and a choice of spatial projection. We provide evidence that the predicted\nconvergence rates are found in various numerical experiments for linear and\nnonlinear neural field problems.", "published": "2025-05-22 09:33:06", "link": "http://arxiv.org/abs/2505.16443v2", "categories": ["math.NA", "cs.NA", "math.DS", "nlin.PS"], "primary_category": "math.NA"}
{"title": "Neural Field Equations with random data", "abstract": "We study neural field equations, which are prototypical models of large-scale\ncortical activity, subject to random data. We view this spatially-extended,\nnonlocal evolution equation as a Cauchy problem on abstract Banach spaces, with\nrandomness in the synaptic kernel, firing rate function, external stimuli, and\ninitial conditions. We determine conditions on the random data that guarantee\nexistence, uniqueness, and measurability of the solution in an appropriate\nBanach space, and examine the regularity of the solution in relation to the\nregularity of the inputs. We present results for linear and nonlinear neural\nfields, and for the two most common functional setups in the numerical analysis\nof this problem. In addition to the continuous problem, we analyse in abstract\nform neural fields that have been spatially discretised, setting the\nfoundations for analysing uncertainty quantification (UQ) schemes.", "published": "2025-05-22 07:58:06", "link": "http://arxiv.org/abs/2505.16343v2", "categories": ["math.NA", "cs.NA", "math.DS", "math.PR", "nlin.PS"], "primary_category": "math.NA"}
{"title": "Semantic-Aware Interpretable Multimodal Music Auto-Tagging", "abstract": "Music auto-tagging is essential for organizing and discovering music in\nextensive digital libraries. While foundation models achieve exceptional\nperformance in this domain, their outputs often lack interpretability, limiting\ntrust and usability for researchers and end-users alike. In this work, we\npresent an interpretable framework for music auto-tagging that leverages groups\nof musically meaningful multimodal features, derived from signal processing,\ndeep learning, ontology engineering, and natural language processing. To\nenhance interpretability, we cluster features semantically and employ an\nexpectation maximization algorithm, assigning distinct weights to each group\nbased on its contribution to the tagging process. Our method achieves\ncompetitive tagging performance while offering a deeper understanding of the\ndecision-making process, paving the way for more transparent and user-centric\nmusic tagging systems.", "published": "2025-05-22 19:15:48", "link": "http://arxiv.org/abs/2505.17233v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "HPP-Voice: A Large-Scale Evaluation of Speech Embeddings for Multi-Phenotypic Classification", "abstract": "Human speech contains paralinguistic cues that reflect a speaker's\nphysiological and neurological state, potentially enabling non-invasive\ndetection of various medical phenotypes. We introduce the Human Phenotype\nProject Voice corpus (HPP-Voice): a dataset of 7,188 recordings in which\nHebrew-speaking adults count for 30 seconds, with each speaker linked to up to\n15 potentially voice-related phenotypes spanning respiratory, sleep, mental\nhealth, metabolic, immune, and neurological conditions. We present a systematic\ncomparison of 14 modern speech embedding models, where modern speech embeddings\nfrom these 30-second counting tasks outperform MFCCs and demographics for\ndownstream health condition classifications. We found that embedding learned\nfrom a speaker identification model can predict objectively measured moderate\nto severe sleep apnea in males with an AUC of 0.64 $\\pm$ 0.03, while MFCC and\ndemographic features led to AUCs of 0.56 $\\pm$ 0.02 and 0.57 $\\pm$ 0.02,\nrespectively. Additionally, our results reveal gender-specific patterns in\nmodel effectiveness across different medical domains. For males, speaker\nidentification and diarization models consistently outperformed speech\nfoundation models for respiratory conditions (e.g., asthma: 0.61 $\\pm$ 0.03 vs.\n0.56 $\\pm$ 0.02) and sleep-related conditions (insomnia: 0.65 $\\pm$ 0.04 vs.\n0.59 $\\pm$ 0.05). For females, speaker diarization models performed best for\nsmoking status (0.61 $\\pm$ 0.02 vs 0.55 $\\pm$ 0.02), while Hebrew-specific\nmodels performed best (0.59 $\\pm$ 0.02 vs. 0.58 $\\pm$ 0.02) in classifying\nanxiety compared to speech foundation models. Our findings provide evidence\nthat a simple counting task can support large-scale, multi-phenotypic voice\nscreening and highlight which embedding families generalize best to specific\nconditions, insights that can guide future vocal biomarker research and\nclinical deployment.", "published": "2025-05-22 10:22:15", "link": "http://arxiv.org/abs/2505.16490v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection", "abstract": "Automatic detection of speech dysfluency aids speech-language pathologists in\nefficient transcription of disordered speech, enhancing diagnostics and\ntreatment planning. Traditional methods, often limited to classification,\nprovide insufficient clinical insight, and text-independent models misclassify\ndysfluency, especially in context-dependent cases. This work introduces\nDysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes\nand detects dysfluency. Unlike previous models, Dysfluent-WFST operates with\nupstream encoders like WavLM and requires no additional training. It achieves\nstate-of-the-art performance in both phonetic error rate and dysfluency\ndetection on simulated and real speech data. Our approach is lightweight,\ninterpretable, and effective, demonstrating that explicit modeling of\npronunciation behavior in decoding, rather than complex architectures, is key\nto improving dysfluency processing systems.", "published": "2025-05-22 08:02:50", "link": "http://arxiv.org/abs/2505.16351v2", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Large Language Models based ASR Error Correction for Child Conversations", "abstract": "Automatic Speech Recognition (ASR) has recently shown remarkable progress,\nbut accurately transcribing children's speech remains a significant challenge.\nRecent developments in Large Language Models (LLMs) have shown promise in\nimproving ASR transcriptions. However, their applications in child speech\nincluding conversational scenarios are underexplored. In this study, we explore\nthe use of LLMs in correcting ASR errors for conversational child speech. We\ndemonstrate the promises and challenges of LLMs through experiments on two\nchildren's conversational speech datasets with both zero-shot and fine-tuned\nASR outputs. We find that while LLMs are helpful in correcting zero-shot ASR\noutputs and fine-tuned CTC-based ASR outputs, it remains challenging for LLMs\nto improve ASR performance when incorporating contextual information or when\nusing fine-tuned autoregressive ASR (e.g., Whisper) outputs.", "published": "2025-05-22 04:28:02", "link": "http://arxiv.org/abs/2505.16212v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols", "abstract": "Integrating large AI models (LAMs) into 6G mobile networks promises to\nredefine protocol design and control-plane intelligence by enabling autonomous,\ncognitive network operations. While industry concepts, such as ETSI's\nExperiential Networked Intelligence (ENI), envision LAM-driven agents for\nadaptive network slicing and intent-based management, practical implementations\nstill face challenges in protocol literacy and real-world deployment. This\npaper presents an end-to-end demonstration of a LAM that generates\nstandards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as\npart of control-plane procedures inside a gNB. We treat RRC messaging as a\ndomain-specific language and fine-tune a decoder-only transformer model (LLaMA\nclass) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages\nlinearized to retain their ASN.1 syntactic structure before standard byte-pair\nencoding tokenization. This enables combinatorial generalization over RRC\nprotocol states while minimizing training overhead. On 30k field-test\nrequest-response pairs, our 8 B model achieves a median cosine similarity of\n0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a\nzero-shot LLaMA-3 8B baseline -- indicating substantially improved structural\nand semantic RRC fidelity. Overall, our results show that LAMs, when augmented\nwith Radio Access Network (RAN)-specific reasoning, can directly orchestrate\ncontrol-plane procedures, representing a stepping stone toward the AI-native\nair-interface paradigm. Beyond RRC emulation, this work lays the groundwork for\nfuture AI-native wireless standards.", "published": "2025-05-22 15:55:56", "link": "http://arxiv.org/abs/2505.16821v2", "categories": ["cs.NI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Joint Magnetometer-IMU Calibration via Maximum A Posteriori Estimation", "abstract": "This paper presents a new approach for jointly calibrating magnetometers and\ninertial measurement units, focusing on improving calibration accuracy and\ncomputational efficiency. The proposed method formulates the calibration\nproblem as a maximum a posteriori estimation problem, treating both the\ncalibration parameters and orientation trajectory of the sensors as unknowns.\nThis formulation enables efficient optimization with closed-form derivatives.\nThe method is compared against two state-of-the-art approaches in terms of\ncomputational complexity and estimation accuracy. Simulation results\ndemonstrate that the proposed method achieves lower root mean square error in\ncalibration parameters while maintaining competitive computational efficiency.\nFurther validation through real-world experiments confirms the practical\nbenefits of our approach: it effectively reduces position drift in a magnetic\nfield-aided inertial navigation system by more than a factor of two on most\ndatasets. Moreover, the proposed method calibrated 30 magnetometers in less\nthan 2 minutes. The contributions include a new calibration method, an analysis\nof existing methods, and a comprehensive empirical evaluation. Datasets and\nalgorithms are made publicly available to promote reproducible research.", "published": "2025-05-22 13:27:42", "link": "http://arxiv.org/abs/2505.16662v2", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
