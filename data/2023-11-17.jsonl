{"title": "Diagnosing and Debiasing Corpus-Based Political Bias and Insults in GPT2", "abstract": "The training of large language models (LLMs) on extensive, unfiltered corpora\nsourced from the internet is a common and advantageous practice. Consequently,\nLLMs have learned and inadvertently reproduced various types of biases,\nincluding violent, offensive, and toxic language. However, recent research\nshows that generative pretrained transformer (GPT) language models can\nrecognize their own biases and detect toxicity in generated content, a process\nreferred to as self-diagnosis. In response, researchers have developed a\ndecoding algorithm that allows LLMs to self-debias, or reduce their likelihood\nof generating harmful text. This study investigates the efficacy of the\ndiagnosing-debiasing approach in mitigating two additional types of biases:\ninsults and political bias. These biases are often used interchangeably in\ndiscourse, despite exhibiting potentially dissimilar semantic and syntactic\nproperties. We aim to contribute to the ongoing effort of investigating the\nethical and social implications of human-AI interaction.", "published": "2023-11-17 01:20:08", "link": "http://arxiv.org/abs/2311.10266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt Pool based Class-Incremental Continual Learning for Dialog State\n  Tracking", "abstract": "Continual learning is crucial for dialog state tracking (DST) in dialog\nsystems, since requirements from users for new functionalities are often\nencountered. However, most of existing continual learning methods for DST\nrequire task identities during testing, which is a severe limit in real-world\napplications. In this paper, we aim to address continual learning of DST in the\nclass-incremental scenario (namely the task identity is unknown in testing).\nInspired by the recently emerging prompt tuning method that performs well on\ndialog systems, we propose to use the prompt pool method, where we maintain a\npool of key-value paired prompts and select prompts from the pool according to\nthe distance between the dialog history and the prompt keys. The proposed\nmethod can automatically identify tasks and select appropriate prompts during\ntesting. We conduct experiments on Schema-Guided Dialog dataset (SGD) and\nanother dataset collected from a real-world dialog application. Experiment\nresults show that the prompt pool method achieves much higher joint goal\naccuracy than the baseline. After combining with a rehearsal buffer, the model\nperformance can be further improved.", "published": "2023-11-17 01:33:05", "link": "http://arxiv.org/abs/2311.10271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complementary Advantages of ChatGPTs and Human Readers in Reasoning:\n  Evidence from English Text Reading Comprehension", "abstract": "ChatGPT has shown its great power in text processing, including its reasoning\nability from text reading. However, there has not been any direct comparison\nbetween human readers and ChatGPT in reasoning ability related to text reading.\nThis study was undertaken to investigate how ChatGPTs (i.e., ChatGPT and\nChatGPT Plus) and Chinese senior school students as ESL learners exhibited\ntheir reasoning ability from English narrative texts. Additionally, we compared\nthe two ChatGPTs in the reasoning performances when commands were updated\nelaborately. The whole study was composed of three reasoning tests: Test 1 for\ncommonsense inference, Test 2 for emotional inference, and Test 3 for causal\ninference. The results showed that in Test 1, the students outdid the two\nChatGPT versions in local-culture-related inferences but performed worse than\nthe chatbots in daily-life inferences. In Test 2, ChatGPT Plus excelled whereas\nChatGPT lagged behind in accuracy. In association with both accuracy and\nfrequency of correct responses, the students were inferior to the two chatbots.\nCompared with ChatGPTs' better performance in positive emotions, the students\nshowed their superiority in inferring negative emotions. In Test 3, the\nstudents demonstrated better logical analysis, outdoing both chatbots. In\nupdating command condition, ChatGPT Plus displayed good causal reasoning\nability while ChatGPT kept unchanged. Our study reveals that human readers and\nChatGPTs have their respective advantages and disadvantages in drawing\ninferences from text reading comprehension, unlocking a complementary\nrelationship in text-based reasoning.", "published": "2023-11-17 06:13:02", "link": "http://arxiv.org/abs/2311.10344v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Relationship between In-Context Learning and Instruction\n  Tuning", "abstract": "In-Context Learning (ICL) and Instruction Tuning (IT) are two primary\nparadigms of adopting Large Language Models (LLMs) to downstream applications.\nHowever, they are significantly different. In ICL, a set of demonstrations are\nprovided at inference time but the LLM's parameters are not updated. In IT, a\nset of demonstrations are used to tune LLM's parameters in training time but no\ndemonstrations are used at inference time. Although a growing body of\nliterature has explored ICL and IT, studies on these topics have largely been\nconducted in isolation, leading to a disconnect between these two paradigms. In\nthis work, we explore the relationship between ICL and IT by examining how the\nhidden states of LLMs change in these two paradigms. Through carefully designed\nexperiments conducted with LLaMA-2 (7B and 13B), we find that ICL is implicit\nIT. In other words, ICL changes an LLM's hidden states as if the demonstrations\nwere used to instructionally tune the model. Furthermore, the convergence\nbetween ICL and IT is largely contingent upon several factors related to the\nprovided demonstrations. Overall, this work offers a unique perspective to\nexplore the connection between ICL and IT and sheds light on understanding the\nbehaviors of LLM.", "published": "2023-11-17 07:40:46", "link": "http://arxiv.org/abs/2311.10367v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FOAL: Fine-grained Contrastive Learning for Cross-domain Aspect\n  Sentiment Triplet Extraction", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) has achieved promising results\nwhile relying on sufficient annotation data in a specific domain. However, it\nis infeasible to annotate data for each individual domain. We propose to\nexplore ASTE in the cross-domain setting, which transfers knowledge from a\nresource-rich source domain to a resource-poor target domain, thereby\nalleviating the reliance on labeled data in the target domain. To effectively\ntransfer the knowledge across domains and extract the sentiment triplets\naccurately, we propose a method named Fine-grained cOntrAstive Learning (FOAL)\nto reduce the domain discrepancy and preserve the discriminability of each\ncategory. Experiments on six transfer pairs show that FOAL achieves 6%\nperformance gains and reduces the domain discrepancy significantly compared\nwith strong baselines. Our code will be publicly available once accepted.", "published": "2023-11-17 07:56:01", "link": "http://arxiv.org/abs/2311.10373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bias A-head? Analyzing Bias in Transformer-Based Language Model\n  Attention Heads", "abstract": "Transformer-based pretrained large language models (PLM) such as BERT and GPT\nhave achieved remarkable success in NLP tasks. However, PLMs are prone to\nencoding stereotypical biases. Although a burgeoning literature has emerged on\nstereotypical bias mitigation in PLMs, such as work on debiasing gender and\nracial stereotyping, how such biases manifest and behave internally within PLMs\nremains largely unknown. Understanding the internal stereotyping mechanisms may\nallow better assessment of model fairness and guide the development of\neffective mitigation strategies. In this work, we focus on attention heads, a\nmajor component of the Transformer architecture, and propose a bias analysis\nframework to explore and identify a small set of biased heads that are found to\ncontribute to a PLM's stereotypical bias. We conduct extensive experiments to\nvalidate the existence of these biased heads and to better understand how they\nbehave. We investigate gender and racial bias in the English language in two\ntypes of Transformer-based PLMs: the encoder-based BERT model and the\ndecoder-based autoregressive GPT model. Overall, the results shed light on\nunderstanding the bias behavior in pretrained language models.", "published": "2023-11-17 08:56:13", "link": "http://arxiv.org/abs/2311.10395v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human\n  Narrative Processing", "abstract": "Understanding how humans process natural language has long been a vital\nresearch direction. The field of natural language processing (NLP) has recently\nexperienced a surge in the development of powerful language models. These\nmodels have proven to be invaluable tools for studying another complex system\nknown to process human language: the brain. Previous studies have demonstrated\nthat the features of language models can be mapped to fMRI brain activity. This\nraises the question: is there a commonality between information processing in\nlanguage models and the human brain? To estimate information flow patterns in a\nlanguage model, we examined the causal relationships between different layers.\nDrawing inspiration from the workspace framework for consciousness, we\nhypothesized that features integrating more information would more accurately\npredict higher hierarchical brain activity. To validate this hypothesis, we\nclassified language model features into two categories based on causal network\nmeasures: 'low in-degree' and 'high in-degree'. We subsequently compared the\nbrain prediction accuracy maps for these two groups. Our results reveal that\nthe difference in prediction accuracy follows a hierarchical pattern,\nconsistent with the cortical hierarchy map revealed by activity time constants.\nThis finding suggests a parallel between how language models and the human\nbrain process linguistic information.", "published": "2023-11-17 10:09:12", "link": "http://arxiv.org/abs/2311.10431v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sinhala-English Word Embedding Alignment: Introducing Datasets and\n  Benchmark for a Low Resource Language", "abstract": "Since their inception, embeddings have become a primary ingredient in many\nflavours of Natural Language Processing (NLP) tasks supplanting earlier types\nof representation. Even though multilingual embeddings have been used for the\nincreasing number of multilingual tasks, due to the scarcity of parallel\ntraining data, low-resource languages such as Sinhala, tend to focus more on\nmonolingual embeddings. Then when it comes to the aforementioned multi-lingual\ntasks, it is challenging to utilize these monolingual embeddings given that\neven if the embedding spaces have a similar geometric arrangement due to an\nidentical training process, the embeddings of the languages considered are not\naligned. This is solved by the embedding alignment task. Even in this,\nhigh-resource language pairs are in the limelight while low-resource languages\nsuch as Sinhala which is in dire need of help seem to have fallen by the\nwayside. In this paper, we try to align Sinhala and English word embedding\nspaces based on available alignment techniques and introduce a benchmark for\nSinhala language embedding alignment. In addition to that, to facilitate the\nsupervised alignment, as an intermediate task, we also introduce\nSinhala-English alignment datasets. These datasets serve as our anchor datasets\nfor supervised word embedding alignment. Even though we do not obtain results\ncomparable to the high-resource languages such as French, German, or Chinese,\nwe believe our work lays the groundwork for more specialized alignment between\nEnglish and Sinhala embeddings.", "published": "2023-11-17 10:14:45", "link": "http://arxiv.org/abs/2311.10436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When a Language Question Is at Stake. A Revisited Approach to Label\n  Sensitive Content", "abstract": "Many under-resourced languages require high-quality datasets for specific\ntasks such as offensive language detection, disinformation, or misinformation\nidentification. However, the intricacies of the content may have a detrimental\neffect on the annotators. The article aims to revisit an approach of\npseudo-labeling sensitive data on the example of Ukrainian tweets covering the\nRussian-Ukrainian war. Nowadays, this acute topic is in the spotlight of\nvarious language manipulations that cause numerous disinformation and profanity\non social media platforms. The conducted experiment highlights three main\nstages of data annotation and underlines the main obstacles during machine\nannotation. Ultimately, we provide a fundamental statistical analysis of the\nobtained data, evaluation of models used for pseudo-labelling, and set further\nguidelines on how the scientists can leverage the corpus to execute more\nadvanced research and extend the existing data samples without annotators'\nengagement.", "published": "2023-11-17 13:35:10", "link": "http://arxiv.org/abs/2311.10514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detection and Analysis of Offensive Online Content in Hausa Language", "abstract": "Hausa, a major Chadic language spoken by over 100 million people mostly in\nWest Africa is considered a low-resource language from a computational\nlinguistic perspective. This classification indicates a scarcity of linguistic\nresources and tools necessary for handling various natural language processing\n(NLP) tasks, including the detection of offensive content. To address this gap,\nwe conducted two set of studies (1) a user study (n=101) to explore\ncyberbullying in Hausa and (2) an empirical study that led to the creation of\nthe first dataset of offensive terms in the Hausa language. We developed\ndetection systems trained on this dataset and compared their performance\nagainst relevant multilingual models, including Google Translate. Our detection\nsystem successfully identified over 70% of offensive, whereas baseline models\nfrequently mistranslated such terms. We attribute this discrepancy to the\nnuanced nature of the Hausa language and the reliance of baseline models on\ndirect or literal translation due to limited data to build purposive detection\nsystems. These findings highlight the importance of incorporating cultural\ncontext and linguistic nuances when developing NLP models for low-resource\nlanguages such as Hausa. A post hoc analysis further revealed that offensive\nlanguage is particularly prevalent in discussions related to religion and\npolitics. To foster a safer online environment, we recommend involving diverse\nstakeholders with expertise in local contexts and demographics. Their insights\nwill be crucial in developing more accurate detection systems and targeted\nmoderation strategies that align with cultural sensitivities.", "published": "2023-11-17 14:08:44", "link": "http://arxiv.org/abs/2311.10541v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Countering Misinformation via Emotional Response Generation", "abstract": "The proliferation of misinformation on social media platforms (SMPs) poses a\nsignificant danger to public health, social cohesion and ultimately democracy.\nPrevious research has shown how social correction can be an effective way to\ncurb misinformation, by engaging directly in a constructive dialogue with users\nwho spread -- often in good faith -- misleading messages. Although professional\nfact-checkers are crucial to debunking viral claims, they usually do not engage\nin conversations on social media. Thereby, significant effort has been made to\nautomate the use of fact-checker material in social correction; however, no\nprevious work has tried to integrate it with the style and pragmatics that are\ncommonly employed in social media communication. To fill this gap, we present\nVerMouth, the first large-scale dataset comprising roughly 12 thousand\nclaim-response pairs (linked to debunking articles), accounting for both\nSMP-style and basic emotions, two factors which have a significant role in\nmisinformation credibility and spreading. To collect this dataset we used a\ntechnique based on an author-reviewer pipeline, which efficiently combines LLMs\nand human annotators to obtain high-quality data. We also provide comprehensive\nexperiments showing how models trained on our proposed dataset have significant\nimprovements in terms of output quality and generalization capabilities.", "published": "2023-11-17 15:37:18", "link": "http://arxiv.org/abs/2311.10587v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2", "abstract": "Since the release of T\\\"ULU [Wang et al., 2023b], open resources for\ninstruction tuning have developed quickly, from better base models to new\nfinetuning techniques. We test and incorporate a number of these advances into\nT\\\"ULU, resulting in T\\\"ULU 2, a suite of improved T\\\"ULU models for advancing\nthe understanding and best practices of adapting pretrained language models to\ndownstream tasks and user preferences. Concretely, we release: (1)\nT\\\"ULU-V2-mix, an improved collection of high-quality instruction datasets; (2)\nT\\\"ULU 2, LLAMA-2 models finetuned on the V2 mixture; (3) T\\\"ULU 2+DPO, T\\\"ULU\n2 models trained with direct preference optimization (DPO), including the\nlargest DPO-trained model to date (T\\\"ULU 2+DPO 70B); (4) CODE T\\\"ULU 2, CODE\nLLAMA models finetuned on our V2 mix that outperform CODE LLAMA and its\ninstruction-tuned variant, CODE LLAMA-Instruct. Our evaluation from multiple\nperspectives shows that the T\\\"ULU 2 suite achieves state-of-the-art\nperformance among open models and matches or exceeds the performance of\nGPT-3.5-turbo-0301 on several benchmarks. We release all the checkpoints, data,\ntraining and evaluation code to facilitate future open efforts on adapting\nlarge language models.", "published": "2023-11-17 18:45:45", "link": "http://arxiv.org/abs/2311.10702v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Energy and Carbon Considerations of Fine-Tuning BERT", "abstract": "Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP\ncommunity, existing work quantifying energy costs and associated carbon\nemissions has largely focused on language model pre-training. Although a single\npre-training run draws substantially more energy than fine-tuning, fine-tuning\nis performed more frequently by many more individual actors, and thus must be\naccounted for when considering the energy and carbon footprint of NLP. In order\nto better characterize the role of fine-tuning in the landscape of energy and\ncarbon emissions in NLP, we perform a careful empirical study of the\ncomputational costs of fine-tuning across tasks, datasets, hardware\ninfrastructure and measurement modalities. Our experimental results allow us to\nplace fine-tuning energy and carbon costs into perspective with respect to\npre-training and inference, and outline recommendations to NLP researchers and\npractitioners who wish to improve their fine-tuning energy efficiency.", "published": "2023-11-17 01:27:01", "link": "http://arxiv.org/abs/2311.10267v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hashing it Out: Predicting Unhealthy Conversations on Twitter", "abstract": "Personal attacks in the context of social media conversations often lead to\nfast-paced derailment, leading to even more harmful exchanges being made.\nState-of-the-art systems for the detection of such conversational derailment\noften make use of deep learning approaches for prediction purposes. In this\npaper, we show that an Attention-based BERT architecture, pre-trained on a\nlarge Twitter corpus and fine-tuned on our task, is efficient and effective in\nmaking such predictions. This model shows clear advantages in performance to\nthe existing LSTM model we use as a baseline. Additionally, we show that this\nimpressive performance can be attained through fine-tuning on a relatively\nsmall, novel dataset, particularly after mitigating overfitting issues through\nsynthetic oversampling techniques. By introducing the first transformer based\nmodel for forecasting conversational events on Twitter, this work lays the\nfoundation for a practical tool to encourage better interactions on one of the\nmost ubiquitous social media platforms.", "published": "2023-11-17 15:49:11", "link": "http://arxiv.org/abs/2311.10596v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Self-enhancement Approach for Domain-specific Chatbot Training via\n  Knowledge Mining and Digest", "abstract": "Large Language Models (LLMs), despite their great power in language\ngeneration, often encounter challenges when dealing with intricate and\nknowledge-demanding queries in specific domains. This paper introduces a novel\napproach to enhance LLMs by effectively extracting the relevant knowledge from\ndomain-specific textual sources, and the adaptive training of a chatbot with\ndomain-specific inquiries. Our two-step approach starts from training a\nknowledge miner, namely LLMiner, which autonomously extracts Question-Answer\npairs from relevant documents through a chain-of-thought reasoning process.\nSubsequently, we blend the mined QA pairs with a conversational dataset to\nfine-tune the LLM as a chatbot, thereby enriching its domain-specific expertise\nand conversational capabilities. We also developed a new evaluation benchmark\nwhich comprises four domain-specific text corpora and associated human-crafted\nQA pairs for testing. Our model shows remarkable performance improvement over\ngenerally aligned LLM and surpasses domain-adapted models directly fine-tuned\non domain corpus. In particular, LLMiner achieves this with minimal human\nintervention, requiring only 600 seed instances, thereby providing a pathway\ntowards self-improvement of LLMs through model-synthesized training data.", "published": "2023-11-17 16:09:10", "link": "http://arxiv.org/abs/2311.10614v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers", "abstract": "This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.", "published": "2023-11-17 16:58:52", "link": "http://arxiv.org/abs/2311.10642v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in\n  LLMs through Translation-Assisted Chain-of-Thought Processes", "abstract": "Creating multilingual LLMs poses a significant challenge. Pretraining or\nfine-tuning LLMs to adopt new languages is evidently very costly. Furthermore,\nthere exist limitations concerning benchmark datasets and the metrics used to\nmeasure model performance in multilingual settings. This paper proposes\ncost-effective solutions to both aforementioned challenges. Firstly, we\nintroduce the Multilingual Instruction-Tuning Dataset (MITS), comprised of\nAlpaca-52K, Dolly-15K, and Vicuna Benchmark translations into 132 languages.\nSecondly, we propose a new method called \\emph{TaCo: Translation-Assisted\nCross-Linguality}, which utilizes translations in a chain-of-thought process to\ninstruction-tune LLMs on new languages through a curriculum-learning process.\nAs a proof of concept, we experimented with the instruction-tuned Guanaco-33B\nmodel, performing further instruction tuning using our proposed TaCo method in\nthree low-resource languages and one high-resource language. Our results\nindicate that the TaCo method impresses GPT-4 with an 82\\% score for a\nlow-resource language in the Vicuna Benchmark dataset, doubling the performance\nin contrast to instruction tuning alone. Furthermore, TaCo shows promise in\ncreating multilingual LLMs, even for low-resource languages. We have released\nour datasets and model adapters\\footnote{https://github.com/UNHSAILLab/TaCo} ,\nencouraging the research community to utilize these resources to advance work\non multilingual LLMs.", "published": "2023-11-17 06:55:32", "link": "http://arxiv.org/abs/2311.10797v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Study on Altering the Latent Space of Pretrained Text to Speech Models\n  for Improved Expressiveness", "abstract": "This report explores the challenge of enhancing expressiveness control in\nText-to-Speech (TTS) models by augmenting a frozen pretrained model with a\nDiffusion Model that is conditioned on joint semantic audio/text embeddings.\nThe paper identifies the challenges encountered when working with a VAE-based\nTTS model and evaluates different image-to-image methods for altering latent\nspeech features. Our results offer valuable insights into the complexities of\nadding expressiveness control to TTS systems and open avenues for future\nresearch in this direction.", "published": "2023-11-17 13:07:00", "link": "http://arxiv.org/abs/2311.10804v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Use GPT-J Prompt Generation with RoBERTa for NER Models on Diagnosis\n  Extraction of Periodontal Diagnosis from Electronic Dental Records", "abstract": "This study explored the usability of prompt generation on named entity\nrecognition (NER) tasks and the performance in different settings of the\nprompt. The prompt generation by GPT-J models was utilized to directly test the\ngold standard as well as to generate the seed and further fed to the RoBERTa\nmodel with the spaCy package. In the direct test, a lower ratio of negative\nexamples with higher numbers of examples in prompt achieved the best results\nwith a F1 score of 0.72. The performance revealed consistency, 0.92-0.97 in the\nF1 score, in all settings after training with the RoBERTa model. The study\nhighlighted the importance of seed quality rather than quantity in feeding NER\nmodels. This research reports on an efficient and accurate way to mine clinical\nnotes for periodontal diagnoses, allowing researchers to easily and quickly\nbuild a NER model with the prompt generation approach.", "published": "2023-11-17 18:14:08", "link": "http://arxiv.org/abs/2311.10810v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Token-Level Adaptation of LoRA Adapters for Downstream Task\n  Generalization", "abstract": "This paper introduces a method for adapting LoRA adapters in smaller-sized\nlanguage models to arbitrary downstream tasks. Unlike standard\nmixture-of-expert architectures, our method employs a gradient-free routing\nfunction to choose a weighted combination of experts without increasing the\ncompute requirements for training or inference. The results show that\ntoken-level adaptation of LoRA adapters outperforms the base Llama-2-7b model\nacross mathematical (GSM8K), scientific (ARC-Challenge), reading comprehension\n(SQuAD), and coding (CodeAlpaca-20k) tasks. Further evaluations also show that\nthe average performance of token-level adaptation outperforms individual models\nfine-tuned for each of the tasks with the best performance observed in\nadaptation of every-other token during inference. The code for this study is\nmade available through a public repository.", "published": "2023-11-17 20:07:54", "link": "http://arxiv.org/abs/2311.10847v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Flexible Model Interpretability through Natural Language Model Editing", "abstract": "Model interpretability and model editing are crucial goals in the age of\nlarge language models. Interestingly, there exists a link between these two\ngoals: if a method is able to systematically edit model behavior with regard to\na human concept of interest, this editor method can help make internal\nrepresentations more interpretable by pointing towards relevant representations\nand systematically manipulating them.", "published": "2023-11-17 23:02:42", "link": "http://arxiv.org/abs/2311.10905v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CNL2ASP: converting controlled natural language sentences into ASP", "abstract": "Answer Set Programming (ASP) is a popular declarative programming language\nfor solving hard combinatorial problems. Although ASP has gained widespread\nacceptance in academic and industrial contexts, there are certain user groups\nwho may find it more advantageous to employ a higher-level language that\nclosely resembles natural language when specifying ASP programs. In this paper,\nwe propose a novel tool, called CNL2ASP, for translating English sentences\nexpressed in a controlled natural language (CNL) form into ASP. In particular,\nwe first provide a definition of the type of sentences allowed by our CNL and\ntheir translation as ASP rules, and then exemplify the usage of the CNL for the\nspecification of both synthetic and real-world combinatorial problems. Finally,\nwe report the results of an experimental analysis conducted on the real-world\nproblems to compare the performance of automatically generated encodings with\nthe ones written by ASP practitioners, showing that our tool can obtain\nsatisfactory performance on these benchmarks. Under consideration in Theory and\nPractice of Logic Programming (TPLP).", "published": "2023-11-17 13:10:58", "link": "http://arxiv.org/abs/2311.10505v1", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "PEFT-MedAware: Large Language Model for Medical Awareness", "abstract": "Chat models are capable of answering a wide range of questions, however, the\naccuracy of their responses is highly uncertain. In this research, we propose a\nspecialized PEFT-MedAware model where we utilize parameter-efficient\nfine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized\nMedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of\nits trainable parameters to enhance computational efficiency. The paper adopts\ndata preprocessing and PEFT to optimize model performance, complemented by a\nBitsAndBytesConfig for efficient transformer training. The resulting model was\ncapable of outperforming other LLMs in medical question-answering tasks in\nspecific domains with greater accuracy utilizing limited computational\nresources making it suitable for deployment in resource-constrained\nenvironments. We propose further improvements through expanded datasets, larger\nmodels, and feedback mechanisms for sustained medical relevancy. Our work\nhighlights the efficiency gains and specialized capabilities of PEFT in medical\nAI, outpacing standard models in precision without extensive resource demands.\nThe proposed model and data are released for research purposes only.", "published": "2023-11-17 18:32:17", "link": "http://arxiv.org/abs/2311.10697v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Language Agent for Autonomous Driving", "abstract": "Human-level driving is an ultimate goal of autonomous driving. Conventional\napproaches formulate autonomous driving as a perception-prediction-planning\nframework, yet their systems do not capitalize on the inherent reasoning\nability and experiential knowledge of humans. In this paper, we propose a\nfundamental paradigm shift from current pipelines, exploiting Large Language\nModels (LLMs) as a cognitive agent to integrate human-like intelligence into\nautonomous driving systems. Our approach, termed Agent-Driver, transforms the\ntraditional autonomous driving pipeline by introducing a versatile tool library\naccessible via function calls, a cognitive memory of common sense and\nexperiential knowledge for decision-making, and a reasoning engine capable of\nchain-of-thought reasoning, task planning, motion planning, and\nself-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive\ncommon sense and robust reasoning capabilities, thus enabling a more nuanced,\nhuman-like approach to autonomous driving. We evaluate our approach on the\nlarge-scale nuScenes benchmark, and extensive experiments substantiate that our\nAgent-Driver significantly outperforms the state-of-the-art driving methods by\na large margin. Our approach also demonstrates superior interpretability and\nfew-shot learning ability to these methods.", "published": "2023-11-17 18:59:56", "link": "http://arxiv.org/abs/2311.10813v4", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Formal concept analysis for evaluating intrinsic dimension of a natural\n  language", "abstract": "Some results of a computational experiment for determining the intrinsic\ndimension of linguistic varieties for the Bengali and Russian languages are\npresented. At the same time, both sets of words and sets of bigrams in these\nlanguages were considered separately. The method used to solve this problem was\nbased on formal concept analysis algorithms. It was found that the intrinsic\ndimensions of these languages are significantly less than the dimensions used\nin popular neural network models in natural language processing.", "published": "2023-11-17 20:48:58", "link": "http://arxiv.org/abs/2311.10862v1", "categories": ["cs.CL", "cs.AI", "math.AT"], "primary_category": "cs.CL"}
{"title": "Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models", "abstract": "The image annotation stage is a critical and often the most time-consuming\npart required for training and evaluating object detection and semantic\nsegmentation models. Deployment of the existing models in novel environments\noften requires detecting novel semantic classes not present in the training\ndata. Furthermore, indoor scenes contain significant viewpoint variations,\nwhich need to be handled properly by trained perception models. We propose to\nleverage the recent advancements in state-of-the-art models for bottom-up\nsegmentation (SAM), object detection (Detic), and semantic segmentation\n(MaskFormer), all trained on large-scale datasets. We aim to develop a\ncost-effective labeling approach to obtain pseudo-labels for semantic\nsegmentation and object instance detection in indoor environments, with the\nultimate goal of facilitating the training of lightweight models for various\ndownstream tasks. We also propose a multi-view labeling fusion stage, which\nconsiders the setting where multiple views of the scenes are available and can\nbe used to identify and rectify single-view inconsistencies. We demonstrate the\neffectiveness of the proposed approach on the Active Vision dataset and the\nADE20K dataset. We evaluate the quality of our labeling process by comparing it\nwith human annotations. Also, we demonstrate the effectiveness of the obtained\nlabels in downstream tasks such as object goal navigation and part discovery.\nIn the context of object goal navigation, we depict enhanced performance using\nthis fusion approach compared to a zero-shot baseline that utilizes large\nmonolithic vision-language pre-trained models.", "published": "2023-11-17 21:58:26", "link": "http://arxiv.org/abs/2311.10883v1", "categories": ["cs.CV", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning", "abstract": "With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.", "published": "2023-11-17 22:44:05", "link": "http://arxiv.org/abs/2311.10899v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.2.10"], "primary_category": "cs.CV"}
{"title": "LE-SSL-MOS: Self-Supervised Learning MOS Prediction with Listener\n  Enhancement", "abstract": "Recently, researchers have shown an increasing interest in automatically\npredicting the subjective evaluation for speech synthesis systems. This\nprediction is a challenging task, especially on the out-of-domain test set. In\nthis paper, we proposed a novel fusion model for MOS prediction that combines\nsupervised and unsupervised approaches. In the supervised aspect, we developed\nan SSL-based predictor called LE-SSL-MOS. The LE-SSL-MOS utilizes pre-trained\nself-supervised learning models and further improves prediction accuracy by\nutilizing the opinion scores of each utterance in the listener enhancement\nbranch. In the unsupervised aspect, two steps are contained: we fine-tuned the\nunit language model (ULM) using highly intelligible domain data to improve the\ncorrelation of an unsupervised metric - SpeechLMScore. Another is that we\nutilized ASR confidence as a new metric with the help of ensemble learning. To\nour knowledge, this is the first architecture that fuses supervised and\nunsupervised methods for MOS prediction. With these approaches, our\nexperimental results on the VoiceMOS Challenge 2023 show that LE-SSL-MOS\nperforms better than the baseline. Our fusion system achieved an absolute\nimprovement of 13% over LE-SSL-MOS on the noisy and enhanced speech track. Our\nsystem ranked 1st and 2nd, respectively, in the French speech synthesis track\nand the challenge's noisy and enhanced speech track.", "published": "2023-11-17 17:20:45", "link": "http://arxiv.org/abs/2311.10656v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Reprogramming Self-supervised Learning-based Speech Representations for\n  Speaker Anonymization", "abstract": "Current speaker anonymization methods, especially with self-supervised\nlearning (SSL) models, require massive computational resources when hiding\nspeaker identity. This paper proposes an effective and parameter-efficient\nspeaker anonymization method based on recent End-to-End model reprogramming\ntechnology. To improve the anonymization performance, we first extract speaker\nrepresentation from large SSL models as the speaker identifies. To hide the\nspeaker's identity, we reprogram the speaker representation by adapting the\nspeaker to a pseudo domain. Extensive experiments are carried out on the\nVoicePrivacy Challenge (VPC) 2022 datasets to demonstrate the effectiveness of\nour proposed parameter-efficient learning anonymization methods. Additionally,\nwhile achieving comparable performance with the VPC 2022 strong baseline 1.b,\nour approach consumes less computational resources during anonymization.", "published": "2023-11-17 17:35:25", "link": "http://arxiv.org/abs/2311.10664v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "GhostVec: A New Threat to Speaker Privacy of End-to-End Speech\n  Recognition System", "abstract": "Speaker adaptation systems face privacy concerns, for such systems are\ntrained on private datasets and often overfitting. This paper demonstrates that\nan attacker can extract speaker information by querying speaker-adapted speech\nrecognition (ASR) systems. We focus on the speaker information of a\ntransformer-based ASR and propose GhostVec, a simple and efficient attack\nmethod to extract the speaker information from an encoder-decoder-based ASR\nsystem without any external speaker verification system or natural human voice\nas a reference. To make our results quantitative, we pre-process GhostVec using\nsingular value decomposition (SVD) and synthesize it into waveform. Experiment\nresults show that the synthesized audio of GhostVec reaches 10.83\\% EER and\n0.47 minDCF with target speakers, which suggests the effectiveness of the\nproposed method. We hope the preliminary discovery in this study to catalyze\nfuture speech recognition research on privacy-preserving topics.", "published": "2023-11-17 18:20:19", "link": "http://arxiv.org/abs/2311.10689v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Retrieval Augmented Generation of Symbolic Music with LLMs", "abstract": "We explore the use of large language models (LLMs) for music generation using\na retrieval system to select relevant examples. We find promising initial\nresults for music generation in a dialogue with the user, especially\nconsidering the ease with which such a system can be implemented. The code is\navailable online.", "published": "2023-11-17 08:21:56", "link": "http://arxiv.org/abs/2311.10384v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MSPB: a longitudinal multi-sensor dataset with phenotypic trait\n  measurements from honey bees", "abstract": "We present a longitudinal multi-sensor dataset collected from honey bee\ncolonies (Apis mellifera) with rich phenotypic measurements. Data were\ncontinuously collected between May-2020 and April-2021 from 53 hives located at\ntwo apiaries in Qu\\'ebec, Canada. The sensor data included audio features,\ntemperature, and relative humidity. The phenotypic measurements contained\nbeehive population, number of brood cells (eggs, larva and pupa), Varroa\ndestructor infestation levels, defensive and hygienic behaviors, honey yield,\nand winter mortality. Our study is amongst the first to provide a wide variety\nof phenotypic trait measurements annotated by apicultural science experts,\nwhich facilitate a broader scope of analysis. We first summarize the data\ncollection procedure, sensor data pre-processing steps, and data composition.\nWe then provide an overview of the phenotypic data distribution as well as a\nvisualization of the sensor data patterns. Lastly, we showcase several hive\nmonitoring applications based on sensor data analysis and machine learning,\nsuch as winter mortality prediction, hive population estimation, and the\npresence of an active and laying queen.", "published": "2023-11-17 21:35:09", "link": "http://arxiv.org/abs/2311.10876v1", "categories": ["eess.AS", "cs.SD", "q-bio.QM"], "primary_category": "eess.AS"}
{"title": "Talent-Interview: Web-Client Cheating Detection for Online Exams", "abstract": "Online exams are more attractive after the Covid-19 pandemic. Furthermore,\nduring recruitment, online exams are used. However, there are more cheating\npossibilities for online exams. Assigning a proctor for each exam increases\ncost. At this point, automatic proctor systems detect possible cheating status.\nThis article proposes an end-to-end system and submodules to get better results\nfor online proctoring. Object detection, face recognition, human voice\ndetection, and segmentation are used in our system. Furthermore, our proposed\nmodel works on the PCs of users, meaning a client-based system. So, server cost\nis eliminated. As far as we know, it is the first time the client-based online\nproctoring system has been used for recruitment. Online exams are more\nattractive after the Covid-19 pandemic. Furthermore, during recruitment, online\nexams are used. However, there are more cheating possibilities for online\nexams. Assigning a proctor for each exam increases cost. At this point,\nautomatic proctor systems detect possible cheating status. This article\nproposes an end-to-end system and submodules to get better results for online\nproctoring. Object detection, face recognition, human voice detection, and\nsegmentation are used in our system. Furthermore, our proposed model works on\nthe PCs of users, meaning a client-based system. So, server cost is eliminated.\nAs far as we know, it is the first time the client-based online proctoring\nsystem has been used for recruitment. Furthermore, this cheating system works\nat https://www.talent-interview.com/tr/.", "published": "2023-11-17 12:59:28", "link": "http://arxiv.org/abs/2312.00795v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
