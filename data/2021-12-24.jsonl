{"title": "Spoiler in a Textstack: How Much Can Transformers Help?", "abstract": "This paper presents our research regarding spoiler detection in reviews. In\nthis use case, we describe the method of fine-tuning and organizing the\navailable text-based model tasks with the latest deep learning achievements and\ntechniques to interpret the models' results.\n  Until now, spoiler research has been rarely described in the literature. We\ntested the transfer learning approach and different latest transformer\narchitectures on two open datasets with annotated spoilers (ROC AUC above 81\\%\non TV Tropes Movies dataset, and Goodreads dataset above 88\\%). We also\ncollected data and assembled a new dataset with fine-grained annotations. To\nthat end, we employed interpretability techniques and measures to assess the\nmodels' reliability and explain their results.", "published": "2021-12-24 02:42:44", "link": "http://arxiv.org/abs/2112.12913v1", "categories": ["cs.CL", "cs.LG", "68T50, 68T07", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Analyzing Scientific Publications using Domain-Specific Word Embedding\n  and Topic Modelling", "abstract": "The scientific world is changing at a rapid pace, with new technology being\ndeveloped and new trends being set at an increasing frequency. This paper\npresents a framework for conducting scientific analyses of academic\npublications, which is crucial to monitor research trends and identify\npotential innovations. This framework adopts and combines various techniques of\nNatural Language Processing, such as word embedding and topic modelling. Word\nembedding is used to capture semantic meanings of domain-specific words. We\npropose two novel scientific publication embedding, i.e., PUB-G and PUB-W,\nwhich are capable of learning semantic meanings of general as well as\ndomain-specific words in various research fields. Thereafter, topic modelling\nis used to identify clusters of research topics within these larger research\nfields. We curated a publication dataset consisting of two conferences and two\njournals from 1995 to 2020 from two research domains. Experimental results show\nthat our PUB-G and PUB-W embeddings are superior in comparison to other\nbaseline embeddings by a margin of ~0.18-1.03 based on topic coherence.", "published": "2021-12-24 04:25:34", "link": "http://arxiv.org/abs/2112.12940v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Distinguishing Transformative from Incremental Clinical Evidence: A\n  Classifier of Clinical Research using Textual features from Abstracts and\n  Citing Sentences", "abstract": "In clinical research and clinical decision-making, it is important to know if\na study changes or only supports the current standards of care for specific\ndisease management. We define such a change as transformative and a support as\nincremental research. It usually requires a huge amount of domain expertise and\ntime for humans to finish such tasks. Faculty Opinions provides us with a\nwell-annotated corpus on whether a research challenges or only confirms\nestablished research. In this study, a machine learning approach is proposed to\ndistinguishing transformative from incremental clinical evidence. The texts\nfrom both abstract and a 2-year window of citing sentences are collected for a\ntraining set of clinical studies recommended and labeled by Faculty Opinions\nexperts. We achieve the best performance with an average AUC of 0.755\n(0.705-0.875) using Random Forest as the classifier and citing sentences as the\nfeature. The results showed that transformative research has typical language\npatterns in citing sentences unlike abstract sentences. We provide an efficient\ntool for identifying those clinical evidence challenging or only confirming\nestablished claims for clinicians and researchers.", "published": "2021-12-24 08:35:18", "link": "http://arxiv.org/abs/2112.12996v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Counterfactual Memorization in Neural Language Models", "abstract": "Modern neural language models that are widely used in various NLP tasks risk\nmemorizing sensitive information from their training data. Understanding this\nmemorization is important in real world applications and also from a\nlearning-theoretical perspective. An open question in previous studies of\nlanguage model memorization is how to filter out \"common\" memorization. In\nfact, most memorization criteria strongly correlate with the number of\noccurrences in the training set, capturing memorized familiar phrases, public\nknowledge, templated texts, or other repeated data. We formulate a notion of\ncounterfactual memorization which characterizes how a model's predictions\nchange if a particular document is omitted during training. We identify and\nstudy counterfactually-memorized training examples in standard text datasets.\nWe estimate the influence of each memorized training example on the validation\nset and on generated texts, showing how this can provide direct evidence of the\nsource of memorization at test time.", "published": "2021-12-24 04:20:57", "link": "http://arxiv.org/abs/2112.12938v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enabling Real-time On-chip Audio Super Resolution for Bone Conduction\n  Microphones", "abstract": "Voice communication using the air conduction microphone in noisy environments\nsuffers from the degradation of speech audibility. Bone conduction microphones\n(BCM) are robust against ambient noises but suffer from limited effective\nbandwidth due to their sensing mechanism. Although existing audio super\nresolution algorithms can recover the high frequency loss to achieve\nhigh-fidelity audio, they require considerably more computational resources\nthan available in low-power hearable devices. This paper proposes the\nfirst-ever real-time on-chip speech audio super resolution system for BCM. To\naccomplish this, we built and compared a series of lightweight audio super\nresolution deep learning models. Among all these models, ATS-UNet is the most\ncost-efficient because the proposed novel Audio Temporal Shift Module (ATSM)\nreduces the network's dimensionality while maintaining sufficient temporal\nfeatures from speech audios. Then we quantized and deployed the ATS-UNet to\nlow-end ARM micro-controller units for real-time embedded prototypes.\nEvaluation results show that our system achieved real-time inference speed on\nCortex-M7 and higher quality than the baseline audio super resolution method.\nFinally, we conducted a user study with ten experts and ten amateur listeners\nto evaluate our method's effectiveness to human ears. Both groups perceived a\nsignificantly higher speech quality with our method when compared to the\nsolutions with the original BCM or air conduction microphone with cutting-edge\nnoise reduction algorithms.", "published": "2021-12-24 23:03:04", "link": "http://arxiv.org/abs/2112.13156v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
