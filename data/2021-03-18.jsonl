{"title": "Model Extraction and Adversarial Transferability, Your BERT is\n  Vulnerable!", "abstract": "Natural language processing (NLP) tasks, ranging from text classification to\ntext generation, have been revolutionised by the pre-trained language models,\nsuch as BERT. This allows corporations to easily build powerful APIs by\nencapsulating fine-tuned BERT models for downstream tasks. However, when a\nfine-tuned BERT model is deployed as a service, it may suffer from different\nattacks launched by malicious users. In this work, we first present how an\nadversary can steal a BERT-based API service (the victim/target model) on\nmultiple benchmark datasets with limited prior knowledge and queries. We\nfurther show that the extracted model can lead to highly transferable\nadversarial attacks against the victim model. Our studies indicate that the\npotential vulnerabilities of BERT-based API services still hold, even when\nthere is an architectural mismatch between the victim model and the attack\nmodel. Finally, we investigate two defence strategies to protect the victim\nmodel and find that unless the performance of the victim model is sacrificed,\nboth model ex-traction and adversarial transferability can effectively\ncompromise the target models", "published": "2021-03-18 04:23:21", "link": "http://arxiv.org/abs/2103.10013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quinductor: a multilingual data-driven method for generating\n  reading-comprehension questions using Universal Dependencies", "abstract": "We propose a multilingual data-driven method for generating reading\ncomprehension questions using dependency trees. Our method provides a strong,\nmostly deterministic, and inexpensive-to-train baseline for less-resourced\nlanguages. While a language-specific corpus is still required, its size is\nnowhere near those required by modern neural question generation (QG)\narchitectures. Our method surpasses QG baselines previously reported in the\nliterature and shows a good performance in terms of human evaluation.", "published": "2021-03-18 09:49:56", "link": "http://arxiv.org/abs/2103.10121v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language", "abstract": "Online misogyny has become an increasing worry for Arab women who experience\ngender-based online abuse on a daily basis. Misogyny automatic detection\nsystems can assist in the prohibition of anti-women Arabic toxic content.\nDeveloping such systems is hindered by the lack of the Arabic misogyny\nbenchmark datasets. In this paper, we introduce an Arabic Levantine Twitter\ndataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset\nfor Arabic misogyny. We further provide a detailed review of the dataset\ncreation and annotation phases. The consistency of the annotations for the\nproposed dataset was emphasized through inter-rater agreement evaluation\nmeasures. Moreover, Let-Mi was used as an evaluation dataset through\nbinary/multi-/target classification tasks conducted by several state-of-the-art\nmachine learning systems along with Multi-Task Learning (MTL) configuration.\nThe obtained results indicated that the performances achieved by the used\nsystems are consistent with state-of-the-art results for languages other than\nArabic, while employing MTL improved the performance of the misogyny/target\nclassification tasks.", "published": "2021-03-18 12:01:13", "link": "http://arxiv.org/abs/2103.10195v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Smoothing and Shrinking the Sparse Seq2Seq Search Space", "abstract": "Current sequence-to-sequence models are trained to minimize cross-entropy and\nuse softmax to compute the locally normalized probabilities over target\nsequences. While this setup has led to strong results in a variety of tasks,\none unsatisfying aspect is its length bias: models give high scores to short,\ninadequate hypotheses and often make the empty string the argmax -- the\nso-called cat got your tongue problem. Recently proposed entmax-based sparse\nsequence-to-sequence models present a possible solution, since they can shrink\nthe search space by assigning zero probability to bad hypotheses, but their\nability to handle word-level tasks with transformers has never been tested. In\nthis work, we show that entmax-based models effectively solve the cat got your\ntongue problem, removing a major source of model error for neural machine\ntranslation. In addition, we generalize label smoothing, a critical\nregularization technique, to the broader family of Fenchel-Young losses, which\nincludes both cross-entropy and the entmax losses. Our resulting label-smoothed\nentmax loss models set a new state of the art on multilingual\ngrapheme-to-phoneme conversion and deliver improvements and better calibration\nproperties on cross-lingual morphological inflection and machine translation\nfor 6 language pairs.", "published": "2021-03-18 14:45:38", "link": "http://arxiv.org/abs/2103.10291v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Biasing of Language Models for Speech Recognition in\n  Goal-Oriented Conversational Agents", "abstract": "Goal-oriented conversational interfaces are designed to accomplish specific\ntasks and typically have interactions that tend to span multiple turns adhering\nto a pre-defined structure and a goal. However, conventional neural language\nmodels (NLM) in Automatic Speech Recognition (ASR) systems are mostly trained\nsentence-wise with limited context. In this paper, we explore different ways to\nincorporate context into a LSTM based NLM in order to model long range\ndependencies and improve speech recognition. Specifically, we use context carry\nover across multiple turns and use lexical contextual cues such as system\ndialog act from Natural Language Understanding (NLU) models and the user\nprovided structure of the chatbot. We also propose a new architecture that\nutilizes context embeddings derived from BERT on sample utterances provided\nduring inference time. Our experiments show a word error rate (WER) relative\nreduction of 7% over non-contextual utterance-level NLM rescorers on\ngoal-oriented audio datasets.", "published": "2021-03-18 15:38:08", "link": "http://arxiv.org/abs/2103.10325v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decomposing and Recomposing Event Structure", "abstract": "We present an event structure classification empirically derived from\ninferential properties annotated on sentence- and document-level Universal\nDecompositional Semantics (UDS) graphs. We induce this classification jointly\nwith semantic role, entity, and event-event relation classifications using a\ndocument-level generative model structured by these graphs. To support this\ninduction, we augment existing annotations found in the UDS1.0 dataset, which\ncovers the entirety of the English Web Treebank, with an array of inferential\nproperties capturing fine-grained aspects of the temporal and aspectual\nstructure of events. The resulting dataset (available at decomp.io) is the\nlargest annotation of event structure and (partial) event coreference to date.", "published": "2021-03-18 17:16:43", "link": "http://arxiv.org/abs/2103.10387v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving the Lexical Ability of Pretrained Language Models for\n  Unsupervised Neural Machine Translation", "abstract": "Successful methods for unsupervised neural machine translation (UNMT) employ\ncrosslingual pretraining via self-supervision, often in the form of a masked\nlanguage modeling or a sequence generation task, which requires the model to\nalign the lexical- and high-level representations of the two languages. While\ncross-lingual pretraining works for similar languages with abundant corpora, it\nperforms poorly in low-resource and distant languages. Previous research has\nshown that this is because the representations are not sufficiently aligned. In\nthis paper, we enhance the bilingual masked language model pretraining with\nlexical-level information by using type-level cross-lingual subword embeddings.\nEmpirical results demonstrate improved performance both on UNMT (up to 4.5\nBLEU) and bilingual lexicon induction using our method compared to a UNMT\nbaseline.", "published": "2021-03-18 21:17:58", "link": "http://arxiv.org/abs/2103.10531v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender and Racial Fairness in Depression Research using Social Media", "abstract": "Multiple studies have demonstrated that behavior on internet-based social\nmedia platforms can be indicative of an individual's mental health status. The\nwidespread availability of such data has spurred interest in mental health\nresearch from a computational lens. While previous research has raised concerns\nabout possible biases in models produced from this data, no study has\nquantified how these biases actually manifest themselves with respect to\ndifferent demographic groups, such as gender and racial/ethnic groups. Here, we\nanalyze the fairness of depression classifiers trained on Twitter data with\nrespect to gender and racial demographic groups. We find that model performance\nsystematically differs for underrepresented groups and that these discrepancies\ncannot be fully explained by trivial data representation issues. Our study\nconcludes with recommendations on how to avoid these biases in future research.", "published": "2021-03-18 22:34:41", "link": "http://arxiv.org/abs/2103.10550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Situated Language Learning via Interactive Narratives", "abstract": "This paper provides a roadmap that explores the question of how to imbue\nlearning agents with the ability to understand and generate contextually\nrelevant natural language in service of achieving a goal. We hypothesize that\ntwo key components in creating such agents are interactivity and environment\ngrounding, shown to be vital parts of language learning in humans, and posit\nthat interactive narratives should be the environments of choice for such\ntraining these agents. These games are simulations in which an agent interacts\nwith the world through natural language -- \"perceiving\", \"acting upon\", and\n\"talking to\" the world using textual descriptions, commands, and dialogue --\nand as such exist at the intersection of natural language processing,\nstorytelling, and sequential decision making. We discuss the unique challenges\na text games' puzzle-like structure combined with natural language\nstate-and-action spaces provides: knowledge representation, commonsense\nreasoning, and exploration. Beyond the challenges described so far, progress in\nthe realm of interactive narratives can be applied in adjacent problem domains.\nThese applications provide interesting challenges of their own as well as\nextensions to those discussed so far. We describe three of them in detail: (1)\nevaluating AI system's commonsense understanding by automatically creating\ninteractive narratives; (2) adapting abstract text-based policies to include\nother modalities such as vision; and (3) enabling multi-agent and human-AI\ncollaboration in shared, situated worlds.", "published": "2021-03-18 01:55:16", "link": "http://arxiv.org/abs/2103.09977v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Constructive and Toxic Speech Detection for Open-domain Social Media\n  Comments in Vietnamese", "abstract": "The rise of social media has led to the increasing of comments on online\nforums. However, there still exists invalid comments which are not informative\nfor users. Moreover, those comments are also quite toxic and harmful to people.\nIn this paper, we create a dataset for constructive and toxic speech detection,\nnamed UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset)\nwith 10,000 human-annotated comments. For these tasks, we propose a system for\nconstructive and toxic speech detection with the state-of-the-art transfer\nlearning model in Vietnamese NLP as PhoBERT. With this system, we obtain\nF1-scores of 78.59% and 59.40% for classifying constructive and toxic comments,\nrespectively. Besides, we implement various baseline models as traditional\nMachine Learning and Deep Neural Network-Based models to evaluate the dataset.\nWith the results, we can solve several tasks on the online discussions and\ndevelop the framework for identifying constructiveness and toxicity of\nVietnamese social media comments automatically.", "published": "2021-03-18 08:04:12", "link": "http://arxiv.org/abs/2103.10069v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Document Coherence Modelling", "abstract": "While pretrained language models (\"LM\") have driven impressive gains over\nmorpho-syntactic and semantic tasks, their ability to model discourse and\npragmatic phenomena is less clear. As a step towards a better understanding of\ntheir discourse modelling capabilities, we propose a sentence intrusion\ndetection task. We examine the performance of a broad range of pretrained LMs\non this detection task for English. Lacking a dataset for the task, we\nintroduce INSteD, a novel intruder sentence detection dataset, containing\n170,000+ documents constructed from English Wikipedia and CNN news articles.\nOur experiments show that pretrained LMs perform impressively in in-domain\nevaluation, but experience a substantial drop in the cross-domain setting,\nindicating limited generalisation capacity. Further results over a novel\nlinguistic probe dataset show that there is substantial room for improvement,\nespecially in the cross-domain setting.", "published": "2021-03-18 10:05:06", "link": "http://arxiv.org/abs/2103.10133v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling the Second Player in Distributionally Robust Optimization", "abstract": "Distributionally robust optimization (DRO) provides a framework for training\nmachine learning models that are able to perform well on a collection of\nrelated data distributions (the \"uncertainty set\"). This is done by solving a\nmin-max game: the model is trained to minimize its maximum expected loss among\nall distributions in the uncertainty set. While careful design of the\nuncertainty set is critical to the success of the DRO procedure, previous work\nhas been limited to relatively simple alternatives that keep the min-max\noptimization problem exactly tractable, such as $f$-divergence balls. In this\npaper, we argue instead for the use of neural generative models to characterize\nthe worst-case distribution, allowing for more flexible and problem-specific\nselection of the uncertainty set. However, while simple conceptually, this\napproach poses a number of implementation and optimization challenges. To\ncircumvent these issues, we propose a relaxation of the KL-constrained inner\nmaximization objective that makes the DRO problem more amenable to\ngradient-based optimization of large scale generative models, and develop model\nselection heuristics to guide hyper-parameter search. On both toy settings and\nrealistic NLP tasks, we find that the proposed approach yields models that are\nmore robust than comparable baselines.", "published": "2021-03-18 14:26:26", "link": "http://arxiv.org/abs/2103.10282v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GPT Understands, Too", "abstract": "Prompting a pretrained language model with natural language patterns has been\nproved effective for natural language understanding (NLU). However, our\npreliminary study reveals that manual discrete prompts often lead to unstable\nperformance -- e.g., changing a single word in the prompt might result in\nsubstantial performance drop. We propose a novel method P-Tuning that employs\ntrainable continuous prompt embeddings in concatenation with discrete prompts.\nEmpirically, P-Tuning not only stabilizes training by minimizing the gap\nbetween various discrete prompts, but also improves performance by a sizeable\nmargin on a wide range of NLU tasks including LAMA and SuperGLUE. P-Tuning is\ngenerally effective for both frozen and tuned language models, under both the\nfully-supervised and few-shot settings.", "published": "2021-03-18 17:13:50", "link": "http://arxiv.org/abs/2103.10385v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Refining Language Models with Compositional Explanations", "abstract": "Pre-trained language models have been successful on text classification\ntasks, but are prone to learning spurious correlations from biased datasets,\nand are thus vulnerable when making inferences in a new domain. Prior work\nreveals such spurious patterns via post-hoc explanation algorithms which\ncompute the importance of input features. Further, the model is regularized to\nalign the importance scores with human knowledge, so that the unintended model\nbehaviors are eliminated. However, such a regularization technique lacks\nflexibility and coverage, since only importance scores towards a pre-defined\nlist of features are adjusted, while more complex human knowledge such as\nfeature interaction and pattern generalization can hardly be incorporated. In\nthis work, we propose to refine a learned language model for a target domain by\ncollecting human-provided compositional explanations regarding observed biases.\nBy parsing these explanations into executable logic rules, the human-specified\nrefinement advice from a small set of explanations can be generalized to more\ntraining examples. We additionally introduce a regularization term allowing\nadjustments for both importance and interaction of features to better rectify\nmodel behavior. We demonstrate the effectiveness of the proposed approach on\ntwo text classification tasks by showing improved performance in target domain\nas well as improved model fairness after refinement.", "published": "2021-03-18 17:48:54", "link": "http://arxiv.org/abs/2103.10415v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Addressing Hate Speech with Data Science: An Overview from Computer\n  Science Perspective", "abstract": "From a computer science perspective, addressing on-line hate speech is a\nchallenging task that is attracting the attention of both industry (mainly\nsocial media platform owners) and academia. In this chapter, we provide an\noverview of state-of-the-art data-science approaches - how they define hate\nspeech, which tasks they solve to mitigate the phenomenon, and how they address\nthese tasks. We limit our investigation mostly to (semi-)automatic detection of\nhate speech, which is the task that the majority of existing computer science\nworks focus on. Finally, we summarize the challenges and the open problems in\nthe current data-science research and the future directions in this field. Our\naim is to prepare an easily understandable report, capable to promote the\nmultidisciplinary character of hate speech research. Researchers from other\ndomains (e.g., psychology and sociology) can thus take advantage of the\nknowledge achieved in the computer science domain but also contribute back and\nhelp improve how computer science is addressing that urgent and socially\nrelevant issue which is the prevalence of hate speech in social media.", "published": "2021-03-18 19:19:44", "link": "http://arxiv.org/abs/2103.10489v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Phylogenetic typology", "abstract": "In this article we propose a novel method to estimate the frequency\ndistribution of linguistic variables while controlling for statistical\nnon-independence due to shared ancestry. Unlike previous approaches, our\ntechnique uses all available data, from language families large and small as\nwell as from isolates, while controlling for different degrees of relatedness\non a continuous scale estimated from the data. Our approach involves three\nsteps: First, distributions of phylogenies are inferred from lexical data.\nSecond, these phylogenies are used as part of a statistical model to\nstatistically estimate transition rates between parameter states. Finally, the\nlong-term equilibrium of the resulting Markov process is computed. As a case\nstudy, we investigate a series of potential word-order correlations across the\nlanguages of the world.", "published": "2021-03-18 12:03:49", "link": "http://arxiv.org/abs/2103.10198v2", "categories": ["q-bio.PE", "cs.CL", "q-bio.QM"], "primary_category": "q-bio.PE"}
{"title": "GLM: General Language Model Pretraining with Autoregressive Blank\n  Infilling", "abstract": "There have been various types of pretraining architectures including\nautoencoding models (e.g., BERT), autoregressive models (e.g., GPT), and\nencoder-decoder models (e.g., T5). However, none of the pretraining frameworks\nperforms the best for all tasks of three main categories including natural\nlanguage understanding (NLU), unconditional generation, and conditional\ngeneration. We propose a General Language Model (GLM) based on autoregressive\nblank infilling to address this challenge. GLM improves blank filling\npretraining by adding 2D positional encodings and allowing an arbitrary order\nto predict spans, which results in performance gains over BERT and T5 on NLU\ntasks. Meanwhile, GLM can be pretrained for different types of tasks by varying\nthe number and lengths of blanks. On a wide range of tasks across NLU,\nconditional and unconditional generation, GLM outperforms BERT, T5, and GPT\ngiven the same model sizes and data, and achieves the best performance from a\nsingle pretrained model with 1.25x parameters of BERT Large , demonstrating its\ngeneralizability to different downstream tasks.", "published": "2021-03-18 16:30:26", "link": "http://arxiv.org/abs/2103.10360v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reading Isn't Believing: Adversarial Attacks On Multi-Modal Neurons", "abstract": "With Open AI's publishing of their CLIP model (Contrastive Language-Image\nPre-training), multi-modal neural networks now provide accessible models that\ncombine reading with visual recognition. Their network offers novel ways to\nprobe its dual abilities to read text while classifying visual objects. This\npaper demonstrates several new categories of adversarial attacks, spanning\nbasic typographical, conceptual, and iconographic inputs generated to fool the\nmodel into making false or absurd classifications. We demonstrate that\ncontradictory text and image signals can confuse the model into choosing false\n(visual) options. Like previous authors, we show by example that the CLIP model\ntends to read first, look later, a phenomenon we describe as reading isn't\nbelieving.", "published": "2021-03-18 18:56:51", "link": "http://arxiv.org/abs/2103.10480v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Pretraining the Noisy Channel Model for Task-Oriented Dialogue", "abstract": "Direct decoding for task-oriented dialogue is known to suffer from the\nexplaining-away effect, manifested in models that prefer short and generic\nresponses. Here we argue for the use of Bayes' theorem to factorize the\ndialogue task into two models, the distribution of the context given the\nresponse, and the prior for the response itself. This approach, an\ninstantiation of the noisy channel model, both mitigates the explaining-away\neffect and allows the principled incorporation of large pretrained models for\nthe response prior. We present extensive experiments showing that a noisy\nchannel model decodes better responses compared to direct decoding and that a\ntwo stage pretraining strategy, employing both open-domain and task-oriented\ndialogue data, improves over randomly initialized models.", "published": "2021-03-18 20:52:49", "link": "http://arxiv.org/abs/2103.10518v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TSTNN: Two-stage Transformer based Neural Network for Speech Enhancement\n  in the Time Domain", "abstract": "In this paper, we propose a transformer-based architecture, called two-stage\ntransformer neural network (TSTNN) for end-to-end speech denoising in the time\ndomain. The proposed model is composed of an encoder, a two-stage transformer\nmodule (TSTM), a masking module and a decoder. The encoder maps input noisy\nspeech into feature representation. The TSTM exploits four stacked two-stage\ntransformer blocks to efficiently extract local and global information from the\nencoder output stage by stage. The masking module creates a mask which will be\nmultiplied with the encoder output. Finally, the decoder uses the masked\nencoder feature to reconstruct the enhanced speech. Experimental results on the\nbenchmark dataset show that the TSTNN outperforms most state-of-the-art models\nin time or frequency domain while having significantly lower model complexity.", "published": "2021-03-18 00:38:17", "link": "http://arxiv.org/abs/2103.09963v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Audio Description from Image by Modal Translation Network", "abstract": "Audio is the main form for the visually impaired to obtain information. In\nreality, all kinds of visual data always exist, but audio data does not exist\nin many cases. In order to help the visually impaired people to better perceive\nthe information around them, an image-to-audio-description (I2AD) task is\nproposed to generate audio descriptions from images in this paper. To complete\nthis totally new task, a modal translation network (MT-Net) from visual to\nauditory sense is proposed. The proposed MT-Net includes three progressive\nsub-networks: 1) feature learning, 2) cross-modal mapping, and 3) audio\ngeneration. First, the feature learning sub-network aims to learn semantic\nfeatures from image and audio, including image feature learning and audio\nfeature learning. Second, the cross-modal mapping sub-network transforms the\nimage feature into a cross-modal representation with the same semantic concept\nas the audio feature. In this way, the correlation of inter-modal data is\neffectively mined for easing the heterogeneous gap between image and audio.\nFinally, the audio generation sub-network is designed to generate the audio\nwaveform from the cross-modal representation. The generated audio waveform is\ninterpolated to obtain the corresponding audio file according to the sample\nfrequency. Being the first attempt to explore the I2AD task, three large-scale\ndatasets with plenty of manual audio descriptions are built. Experiments on the\ndatasets verify the feasibility of generating intelligible audio from an image\ndirectly and the effectiveness of proposed method.", "published": "2021-03-18 04:48:29", "link": "http://arxiv.org/abs/2103.10018v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Discriminative Singular Spectrum Classifier with Applications on\n  Bioacoustic Signal Recognition", "abstract": "Automatic analysis of bioacoustic signals is a fundamental tool to evaluate\nthe vitality of our planet. Frogs and bees, for instance, may act like\nbiological sensors providing information about environmental changes. This task\nis fundamental for ecological monitoring still includes many challenges such as\nnonuniform signal length processing, degraded target signal due to\nenvironmental noise, and the scarcity of the labeled samples for training\nmachine learning. To tackle these challenges, we present a bioacoustic signal\nclassifier equipped with a discriminative mechanism to extract useful features\nfor analysis and classification efficiently. The proposed classifier does not\nrequire a large amount of training data and handles nonuniform signal length\nnatively. Unlike current bioacoustic recognition methods, which are\ntask-oriented, the proposed model relies on transforming the input signals into\nvector subspaces generated by applying Singular Spectrum Analysis (SSA). Then,\na subspace is designed to expose discriminative features. The proposed model\nshares end-to-end capabilities, which is desirable in modern machine learning\nsystems. This formulation provides a segmentation-free and noise-tolerant\napproach to represent and classify bioacoustic signals and a highly compact\nsignal descriptor inherited from SSA. The validity of the proposed method is\nverified using three challenging bioacoustic datasets containing anuran, bee,\nand mosquito species. Experimental results on three bioacoustic datasets have\nshown the competitive performance of the proposed method compared to commonly\nemployed methods for bioacoustics signal classification in terms of accuracy.", "published": "2021-03-18 11:01:21", "link": "http://arxiv.org/abs/2103.10166v1", "categories": ["q-bio.QM", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "q-bio.QM"}
