{"title": "Argumentative Stance Prediction: An Exploratory Study on Multimodality\n  and Few-Shot Learning", "abstract": "To advance argumentative stance prediction as a multimodal problem, the First\nShared Task in Multimodal Argument Mining hosted stance prediction in crucial\nsocial topics of gun control and abortion. Our exploratory study attempts to\nevaluate the necessity of images for stance prediction in tweets and compare\nout-of-the-box text-based large-language models (LLM) in few-shot settings\nagainst fine-tuned unimodal and multimodal models. Our work suggests an\nensemble of fine-tuned text-based language models (0.817 F1-score) outperforms\nboth the multimodal (0.677 F1-score) and text-based few-shot prediction using a\nrecent state-of-the-art LLM (0.550 F1-score). In addition to the differences in\nperformance, our findings suggest that the multimodal models tend to perform\nbetter when image content is summarized as natural language over their native\npixel structure and, using in-context examples improves few-shot performance of\nLLMs.", "published": "2023-10-11 00:18:29", "link": "http://arxiv.org/abs/2310.07093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Styles across Languages: A Cross-Cultural Exploration of\n  Politeness", "abstract": "Understanding how styles differ across languages is advantageous for training\nboth humans and computers to generate culturally appropriate text. We introduce\nan explanation framework to extract stylistic differences from multilingual LMs\nand compare styles across languages. Our framework (1) generates comprehensive\nstyle lexica in any language and (2) consolidates feature importances from LMs\ninto comparable lexical categories. We apply this framework to compare\npoliteness, creating the first holistic multilingual politeness dataset and\nexploring how politeness varies across four languages. Our approach enables an\neffective evaluation of how distinct linguistic categories contribute to\nstylistic variations and provides interpretable insights into how people\ncommunicate differently around the world.", "published": "2023-10-11 02:16:12", "link": "http://arxiv.org/abs/2310.07135v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empowering Psychotherapy with Large Language Models: Cognitive\n  Distortion Detection through Diagnosis of Thought Prompting", "abstract": "Mental illness remains one of the most critical public health issues of our\ntime, due to the severe scarcity and accessibility limit of professionals.\nPsychotherapy requires high-level expertise to conduct deep, complex reasoning\nand analysis on the cognition modeling of the patients. In the era of Large\nLanguage Models, we believe it is the right time to develop AI assistance for\ncomputational psychotherapy. We study the task of cognitive distortion\ndetection and propose the Diagnosis of Thought (DoT) prompting. DoT performs\ndiagnosis on the patient's speech via three stages: subjectivity assessment to\nseparate the facts and the thoughts; contrastive reasoning to elicit the\nreasoning processes supporting and contradicting the thoughts; and schema\nanalysis to summarize the cognition schemas. The generated diagnosis rationales\nthrough the three stages are essential for assisting the professionals.\nExperiments demonstrate that DoT obtains significant improvements over ChatGPT\nfor cognitive distortion detection, while generating high-quality rationales\napproved by human experts.", "published": "2023-10-11 02:47:21", "link": "http://arxiv.org/abs/2310.07146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"A Tale of Two Movements\": Identifying and Comparing Perspectives in\n  #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly\n  Supervised Graph-based Structured Prediction", "abstract": "Social media has become a major driver of social change, by facilitating the\nformation of online social movements. Automatically understanding the\nperspectives driving the movement and the voices opposing it, is a challenging\ntask as annotated data is difficult to obtain. We propose a weakly supervised\ngraph-based approach that explicitly models perspectives in\n#BackLivesMatter-related tweets. Our proposed approach utilizes a\nsocial-linguistic representation of the data. We convert the text to a graph by\nbreaking it into structured elements and connect it with the social network of\nauthors, then structured prediction is done over the elements for identifying\nperspectives. Our approach uses a small seed set of labeled examples. We\nexperiment with large language models for generating artificial training\nexamples, compare them to manual annotation, and find that it achieves\ncomparable performance. We perform quantitative and qualitative analyses using\na human-annotated test set. Our model outperforms multitask baselines by a\nlarge margin, successfully characterizing the perspectives supporting and\nopposing #BLM.", "published": "2023-10-11 03:01:42", "link": "http://arxiv.org/abs/2310.07155v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PHALM: Building a Knowledge Graph from Scratch by Prompting Humans and a\n  Language Model", "abstract": "Despite the remarkable progress in natural language understanding with\npretrained Transformers, neural language models often do not handle commonsense\nknowledge well. Toward commonsense-aware models, there have been attempts to\nobtain knowledge, ranging from automatic acquisition to crowdsourcing. However,\nit is difficult to obtain a high-quality knowledge base at a low cost,\nespecially from scratch. In this paper, we propose PHALM, a method of building\na knowledge graph from scratch, by prompting both crowdworkers and a large\nlanguage model (LLM). We used this method to build a Japanese event knowledge\ngraph and trained Japanese commonsense generation models. Experimental results\nrevealed the acceptability of the built graph and inferences generated by the\ntrained models. We also report the difference in prompting humans and an LLM.\nOur code, data, and models are available at\ngithub.com/nlp-waseda/comet-atomic-ja.", "published": "2023-10-11 03:39:46", "link": "http://arxiv.org/abs/2310.07170v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models have Shared Weaknesses in Medical Question\n  Answering?", "abstract": "Large language models (LLMs) have made rapid improvement on medical\nbenchmarks, but their unreliability remains a persistent challenge for safe\nreal-world uses. To design for the use LLMs as a category, rather than for\nspecific models, requires developing an understanding of shared strengths and\nweaknesses which appear across models. To address this challenge, we benchmark\na range of top LLMs and identify consistent patterns across models. We test\n$16$ well-known LLMs on $874$ newly collected questions from Polish medical\nlicensing exams. For each question, we score each model on the top-1 accuracy\nand the distribution of probabilities assigned. We then compare these results\nwith factors such as question difficulty for humans, question length, and the\nscores of the other models. LLM accuracies were positively correlated pairwise\n($0.39$ to $0.58$). Model performance was also correlated with human\nperformance ($0.09$ to $0.13$), but negatively correlated to the difference\nbetween the question-level accuracy of top-scoring and bottom-scoring humans\n($-0.09$ to $-0.14$). The top output probability and question length were\npositive and negative predictors of accuracy respectively (p$< 0.05$). The top\nscoring LLM, GPT-4o Turbo, scored $84\\%$, with Claude Opus, Gemini 1.5 Pro and\nLlama 3/3.1 between $74\\%$ and $79\\%$. We found evidence of similarities\nbetween models in which questions they answer correctly, as well as\nsimilarities with human test takers. Larger models typically performed better,\nbut differences in training, architecture, and data were also highly impactful.\nModel accuracy was positively correlated with confidence, but negatively\ncorrelated with question length. We find similar results with older models, and\nargue that these patterns are likely to persist across future models using\nsimilar training methods.", "published": "2023-10-11 06:26:19", "link": "http://arxiv.org/abs/2310.07225v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models\n  as Knowledge Generators", "abstract": "Large language models (LLMs) outperform information retrieval techniques for\ndownstream knowledge-intensive tasks when being prompted to generate world\nknowledge. However, community concerns abound regarding the factuality and\npotential implications of using this uncensored knowledge. In light of this, we\nintroduce CONNER, a COmpreheNsive kNowledge Evaluation fRamework, designed to\nsystematically and automatically evaluate generated knowledge from six\nimportant perspectives -- Factuality, Relevance, Coherence, Informativeness,\nHelpfulness and Validity. We conduct an extensive empirical analysis of the\ngenerated knowledge from three different types of LLMs on two widely studied\nknowledge-intensive tasks, i.e., open-domain question answering and\nknowledge-grounded dialogue. Surprisingly, our study reveals that the\nfactuality of generated knowledge, even if lower, does not significantly hinder\ndownstream tasks. Instead, the relevance and coherence of the outputs are more\nimportant than small factual mistakes. Further, we show how to use CONNER to\nimprove knowledge-intensive tasks by designing two strategies: Prompt\nEngineering and Knowledge Selection. Our evaluation code and LLM-generated\nknowledge with human annotations will be released to facilitate future\nresearch.", "published": "2023-10-11 08:22:37", "link": "http://arxiv.org/abs/2310.07289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parrot: Enhancing Multi-Turn Instruction Following for Large Language\n  Models", "abstract": "Humans often interact with large language models (LLMs) in multi-turn\ninteraction to obtain desired answers or more information. However, most\nexisting studies overlook the multi-turn instruction following ability of LLMs,\nin terms of training dataset, training method, and evaluation benchmark. In\nthis paper, we introduce Parrot, a solution aiming to enhance multi-turn\ninstruction following for LLMs. First, we introduce an efficient but effective\nmethod for collecting multi-turn instructions that feature human-like queries,\nsuch as anaphora and ellipsis. Second, we propose a context-aware preference\noptimization strategy to further enhance LLMs for complex queries in multi-turn\ninteraction. Moreover, to quantitatively evaluate LLMs in multi-turn\ninstruction following, we manually build a multi-turn benchmark derived from\nexisting ones. Extensive experiments show that Parrot improves current LLMs by\nup to 7.2% in multi-turn instruction following. Our dataset and codes will be\nopen-sourced to facilitate future research.", "published": "2023-10-11 08:36:43", "link": "http://arxiv.org/abs/2310.07301v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Do Large Language Models Capture the Ever-changing World Knowledge?\n  A Review of Recent Advances", "abstract": "Although large language models (LLMs) are impressive in solving various\ntasks, they can quickly be outdated after deployment. Maintaining their\nup-to-date status is a pressing concern in the current era. This paper provides\na comprehensive review of recent advances in aligning LLMs with the\never-changing world knowledge without re-training from scratch. We categorize\nresearch works systemically and provide in-depth comparisons and discussion. We\nalso discuss existing challenges and highlight future directions to facilitate\nresearch in this field. We release the paper list at\nhttps://github.com/hyintell/awesome-refreshing-llms", "published": "2023-10-11 09:46:32", "link": "http://arxiv.org/abs/2310.07343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cognate Transformer for Automated Phonological Reconstruction and\n  Cognate Reflex Prediction", "abstract": "Phonological reconstruction is one of the central problems in historical\nlinguistics where a proto-word of an ancestral language is determined from the\nobserved cognate words of daughter languages. Computational approaches to\nhistorical linguistics attempt to automate the task by learning models on\navailable linguistic data. Several ideas and techniques drawn from\ncomputational biology have been successfully applied in the area of\ncomputational historical linguistics. Following these lines, we adapt MSA\nTransformer, a protein language model, to the problem of automated phonological\nreconstruction. MSA Transformer trains on multiple sequence alignments as input\nand is, thus, apt for application on aligned cognate words. We, hence, name our\nmodel as Cognate Transformer. We also apply the model on another associated\ntask, namely, cognate reflex prediction, where a reflex word in a daughter\nlanguage is predicted based on cognate words from other daughter languages. We\nshow that our model outperforms the existing models on both tasks, especially\nwhen it is pre-trained on masked word prediction task.", "published": "2023-10-11 13:34:22", "link": "http://arxiv.org/abs/2310.07487v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and\n  Domain-Specificity", "abstract": "This survey addresses the crucial issue of factuality in Large Language\nModels (LLMs). As LLMs find applications across diverse domains, the\nreliability and accuracy of their outputs become vital. We define the\nFactuality Issue as the probability of LLMs to produce content inconsistent\nwith established facts. We first delve into the implications of these\ninaccuracies, highlighting the potential consequences and challenges posed by\nfactual errors in LLM outputs. Subsequently, we analyze the mechanisms through\nwhich LLMs store and process facts, seeking the primary causes of factual\nerrors. Our discussion then transitions to methodologies for evaluating LLM\nfactuality, emphasizing key metrics, benchmarks, and studies. We further\nexplore strategies for enhancing LLM factuality, including approaches tailored\nfor specific domains. We focus two primary LLM configurations standalone LLMs\nand Retrieval-Augmented LLMs that utilizes external data, we detail their\nunique challenges and potential enhancements. Our survey offers a structured\nguide for researchers aiming to fortify the factual reliability of LLMs.", "published": "2023-10-11 14:18:03", "link": "http://arxiv.org/abs/2310.07521v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QACHECK: A Demonstration System for Question-Guided Multi-Hop\n  Fact-Checking", "abstract": "Fact-checking real-world claims often requires complex, multi-step reasoning\ndue to the absence of direct evidence to support or refute them. However,\nexisting fact-checking systems often lack transparency in their\ndecision-making, making it challenging for users to comprehend their reasoning\nprocess. To address this, we propose the Question-guided Multi-hop\nFact-Checking (QACHECK) system, which guides the model's reasoning process by\nasking a series of questions critical for verifying a claim. QACHECK has five\nkey modules: a claim verifier, a question generator, a question-answering\nmodule, a QA validator, and a reasoner. Users can input a claim into QACHECK,\nwhich then predicts its veracity and provides a comprehensive report detailing\nits reasoning process, guided by a sequence of (question, answer) pairs.\nQACHECK also provides the source of evidence supporting each question,\nfostering a transparent, explainable, and user-friendly fact-checking process.\nA recorded video of QACHECK is at https://www.youtube.com/watch?v=ju8kxSldM64", "published": "2023-10-11 15:51:53", "link": "http://arxiv.org/abs/2310.07609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for\n  Knowledge-Grounded Dialogue", "abstract": "Accurate knowledge selection is critical in knowledge-grounded dialogue\nsystems. Towards a closer look at it, we offer a novel perspective to organize\nexisting literature, i.e., knowledge selection coupled with, after, and before\ngeneration. We focus on the third under-explored category of study, which can\nnot only select knowledge accurately in advance, but has the advantage to\nreduce the learning, adjustment, and interpretation burden of subsequent\nresponse generation models, especially LLMs. We propose GATE, a\ngenerator-agnostic knowledge selection method, to prepare knowledge for\nsubsequent response generation models by selecting context-related knowledge\namong different knowledge structures and variable knowledge requirements.\nExperimental results demonstrate the superiority of GATE, and indicate that\nknowledge selection before generation is a lightweight yet effective way to\nfacilitate LLMs (e.g., ChatGPT) to generate more informative responses.", "published": "2023-10-11 17:00:29", "link": "http://arxiv.org/abs/2310.07659v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-enhanced Memory Model for Emotional Support Conversation", "abstract": "The prevalence of mental disorders has become a significant issue, leading to\nthe increased focus on Emotional Support Conversation as an effective\nsupplement for mental health support. Existing methods have achieved compelling\nresults, however, they still face three challenges: 1) variability of emotions,\n2) practicality of the response, and 3) intricate strategy modeling. To address\nthese challenges, we propose a novel knowledge-enhanced Memory mODEl for\nemotional suppoRt coNversation (MODERN). Specifically, we first devise a\nknowledge-enriched dialogue context encoding to perceive the dynamic emotion\nchange of different periods of the conversation for coherent user state\nmodeling and select context-related concepts from ConceptNet for practical\nresponse generation. Thereafter, we implement a novel memory-enhanced strategy\nmodeling module to model the semantic patterns behind the strategy categories.\nExtensive experiments on a widely used large-scale dataset verify the\nsuperiority of our model over cutting-edge baselines.", "published": "2023-10-11 17:51:28", "link": "http://arxiv.org/abs/2310.07700v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ontology Enrichment for Effective Fine-grained Entity Typing", "abstract": "Fine-grained entity typing (FET) is the task of identifying specific entity\ntypes at a fine-grained level for entity mentions based on their contextual\ninformation. Conventional methods for FET require extensive human annotation,\nwhich is time-consuming and costly. Recent studies have been developing weakly\nsupervised or zero-shot approaches. We study the setting of zero-shot FET where\nonly an ontology is provided. However, most existing ontology structures lack\nrich supporting information and even contain ambiguous relations, making them\nineffective in guiding FET. Recently developed language models, though\npromising in various few-shot and zero-shot NLP tasks, may face challenges in\nzero-shot FET due to their lack of interaction with task-specific ontology. In\nthis study, we propose OnEFET, where we (1) enrich each node in the ontology\nstructure with two types of extra information: instance information for\ntraining sample augmentation and topic information to relate types to contexts,\nand (2) develop a coarse-to-fine typing algorithm that exploits the enriched\ninformation by training an entailment model with contrasting topics and\ninstance-based augmented training samples. Our experiments show that OnEFET\nachieves high-quality fine-grained entity typing without human annotation,\noutperforming existing zero-shot methods by a large margin and rivaling\nsupervised methods.", "published": "2023-10-11 18:30:37", "link": "http://arxiv.org/abs/2310.07795v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-autoregressive Text Editing with Copy-aware Latent Alignments", "abstract": "Recent work has witnessed a paradigm shift from Seq2Seq to Seq2Edit in the\nfield of text editing, with the aim of addressing the slow autoregressive\ninference problem posed by the former. Despite promising results, Seq2Edit\napproaches still face several challenges such as inflexibility in generation\nand difficulty in generalizing to other languages. In this work, we propose a\nnovel non-autoregressive text editing method to circumvent the above issues, by\nmodeling the edit process with latent CTC alignments. We make a crucial\nextension to CTC by introducing the copy operation into the edit space, thus\nenabling more efficient management of textual overlap in editing. We conduct\nextensive experiments on GEC and sentence fusion tasks, showing that our\nproposed method significantly outperforms existing Seq2Edit models and achieves\nsimilar or even better results than Seq2Seq with over $4\\times$ speedup.\nMoreover, it demonstrates good generalizability on German and Russian. In-depth\nanalyses reveal the strengths of our method in terms of the robustness under\nvarious scenarios and generating fluent and flexible outputs.", "published": "2023-10-11 19:02:57", "link": "http://arxiv.org/abs/2310.07821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language\n  Annotation", "abstract": "One of the primary obstacles in the advancement of Natural Language\nProcessing (NLP) technologies for low-resource languages is the lack of\nannotated datasets for training and testing machine learning models. In this\npaper, we present Antarlekhaka, a tool for manual annotation of a comprehensive\nset of tasks relevant to NLP. The tool is Unicode-compatible,\nlanguage-agnostic, Web-deployable and supports distributed annotation by\nmultiple simultaneous annotators. The system sports user-friendly interfaces\nfor 8 categories of annotation tasks. These, in turn, enable the annotation of\na considerably larger set of NLP tasks. The task categories include two\nlinguistic tasks not handled by any other tool, namely, sentence boundary\ndetection and deciding canonical word order, which are important tasks for text\nthat is in the form of poetry. We propose the idea of sequential annotation\nbased on small text units, where an annotator performs several tasks related to\na single text unit before proceeding to the next unit. The research\napplications of the proposed mode of multi-task annotation are also discussed.\nAntarlekhaka outperforms other annotation tools in objective evaluation. It has\nbeen also used for two real-life annotation tasks on two different languages,\nnamely, Sanskrit and Bengali. The tool is available at\nhttps://github.com/Antarlekhaka/code.", "published": "2023-10-11 19:09:07", "link": "http://arxiv.org/abs/2310.07826v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Framework for Question-Answering in Sanskrit through Automated\n  Construction of Knowledge Graphs", "abstract": "Sanskrit (sa\\d{m}sk\\d{r}ta) enjoys one of the largest and most varied\nliterature in the whole world. Extracting the knowledge from it, however, is a\nchallenging task due to multiple reasons including complexity of the language\nand paucity of standard natural language processing tools. In this paper, we\ntarget the problem of building knowledge graphs for particular types of\nrelationships from sa\\d{m}sk\\d{r}ta texts. We build a natural language\nquestion-answering system in sa\\d{m}sk\\d{r}ta that uses the knowledge graph to\nanswer factoid questions. We design a framework for the overall system and\nimplement two separate instances of the system on human relationships from\nmah\\=abh\\=arata and r\\=am\\=aya\\d{n}a, and one instance on synonymous\nrelationships from bh\\=avaprak\\=a\\'sa nigha\\d{n}\\d{t}u, a technical text from\n\\=ayurveda. We show that about 50% of the factoid questions can be answered\ncorrectly by the system. More importantly, we analyse the shortcomings of the\nsystem in detail for each step, and discuss the possible ways forward.", "published": "2023-10-11 19:50:59", "link": "http://arxiv.org/abs/2310.07848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pit One Against Many: Leveraging Attention-head Embeddings for\n  Parameter-efficient Multi-head Attention", "abstract": "Scaling pre-trained language models has resulted in large performance gains\nin various natural language processing tasks but comes with a large cost in\nmemory requirements. Inspired by the position embeddings in transformers, we\naim to simplify and reduce the memory footprint of the multi-head attention\n(MHA) mechanism. We propose an alternative module that uses only a single\nshared projection matrix and multiple head embeddings (MHE), i.e. one per head.\nWe empirically demonstrate that our MHE attention is substantially more memory\nefficient compared to alternative attention mechanisms while achieving high\npredictive performance retention ratio to vanilla MHA on several downstream\ntasks. MHE attention only requires a negligible fraction of additional\nparameters ($3nd$, where $n$ is the number of attention heads and $d$ the size\nof the head embeddings) compared to a single-head attention, while MHA requires\n$(3n^2-3n)d^2-3nd$ additional parameters.", "published": "2023-10-11 21:38:40", "link": "http://arxiv.org/abs/2310.07911v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crosslingual Structural Priming and the Pre-Training Dynamics of\n  Bilingual Language Models", "abstract": "Do multilingual language models share abstract grammatical representations\nacross languages, and if so, when do these develop? Following Sinclair et al.\n(2022), we use structural priming to test for abstract grammatical\nrepresentations with causal effects on model outputs. We extend the approach to\na Dutch-English bilingual setting, and we evaluate a Dutch-English language\nmodel during pre-training. We find that crosslingual structural priming effects\nemerge early after exposure to the second language, with less than 1M tokens of\ndata in that language. We discuss implications for data contamination,\nlow-resource transfer, and how abstract grammatical representations emerge in\nmultilingual models.", "published": "2023-10-11 22:57:03", "link": "http://arxiv.org/abs/2310.07929v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diversity of Thought Improves Reasoning Abilities of LLMs", "abstract": "Large language models (LLMs) are documented to struggle in settings that\nrequire complex reasoning. Nevertheless, instructing the model to break down\nthe problem into smaller reasoning steps, or ensembling various generations\nthrough modifying decoding steps boosts performance. However, these methods\nassume that the input prompt is fixed and expect the decoding strategies to\nintroduce the diversity needed for ensembling. In this work, we discuss how one\ncan create and leverage variations of the input prompt as a means of diversity\nof thought. We propose a method that automatically improves prompt diversity by\nsoliciting feedback from the LLM to ideate approaches that are apt for the\nproblem. We then ensemble the diverse prompts in our method DIVSE (DIVerse\nreasoning path Self-Ensemble) across multiple inference calls, or use diverse\napproaches within a single inference call; we call the latter IDIV-SE (In-call\nDIVerse reasoning path Self-Ensemble). Apart from our approaches outperforming\nprior work, DIV-SE(in particular) advances state-of-the-art performance on the\nchallenging planning and graph coloring benchmarks. Our results improve the\nPareto frontier of the accuracy-cost trade-off.", "published": "2023-10-11 00:01:41", "link": "http://arxiv.org/abs/2310.07088v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Jaeger: A Concatenation-Based Multi-Transformer VQA Model", "abstract": "Document-based Visual Question Answering poses a challenging task between\nlinguistic sense disambiguation and fine-grained multimodal retrieval. Although\nthere has been encouraging progress in document-based question answering due to\nthe utilization of large language and open-world prior models\\cite{1}, several\nchallenges persist, including prolonged response times, extended inference\ndurations, and imprecision in matching. In order to overcome these challenges,\nwe propose Jaegar, a concatenation-based multi-transformer VQA model. To derive\nquestion features, we leverage the exceptional capabilities of RoBERTa\nlarge\\cite{2} and GPT2-xl\\cite{3} as feature extractors. Subsequently, we\nsubject the outputs from both models to a concatenation process. This operation\nallows the model to consider information from diverse sources concurrently,\nstrengthening its representational capability. By leveraging pre-trained models\nfor feature extraction, our approach has the potential to amplify the\nperformance of these models through concatenation. After concatenation, we\napply dimensionality reduction to the output features, reducing the model's\ncomputational effectiveness and inference time. Empirical results demonstrate\nthat our proposed model achieves competitive performance on Task C of the\nPDF-VQA Dataset. If the user adds any new data, they should make sure to style\nit as per the instructions provided in previous sections.", "published": "2023-10-11 00:14:40", "link": "http://arxiv.org/abs/2310.07091v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sparse Universal Transformer", "abstract": "The Universal Transformer (UT) is a variant of the Transformer that shares\nparameters across its layers. Empirical evidence shows that UTs have better\ncompositional generalization than Vanilla Transformers (VTs) in formal language\ntasks. The parameter-sharing also affords it better parameter efficiency than\nVTs. Despite its many advantages, scaling UT parameters is much more compute\nand memory intensive than scaling up a VT. This paper proposes the Sparse\nUniversal Transformer (SUT), which leverages Sparse Mixture of Experts (SMoE)\nand a new stick-breaking-based dynamic halting mechanism to reduce UT's\ncomputation complexity while retaining its parameter efficiency and\ngeneralization ability. Experiments show that SUT achieves the same performance\nas strong baseline models while only using half computation and parameters on\nWMT'14 and strong generalization results on formal language tasks (Logical\ninference and CFQ). The new halting mechanism also enables around 50\\%\nreduction in computation during inference with very little performance decrease\non formal language tasks.", "published": "2023-10-11 00:38:57", "link": "http://arxiv.org/abs/2310.07096v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources", "abstract": "Large Language Models (LLMs) have showcased remarkable impacts across a wide\nspectrum of natural language processing tasks. Fine-tuning these pre-trained\nmodels on downstream datasets provides further significant performance gains,\nbut this process has been challenging due to its extraordinary resource\nrequirements. To this end, existing efforts focus on parameter-efficient\nfine-tuning, which, unfortunately, fail to capitalize on the powerful potential\nof full-parameter fine-tuning. In this work, we propose QFT, a novel Quantized\nFull-parameter Tuning framework for LLMs that enables memory-efficient\nfine-tuning without harming performance. Our framework incorporates two novel\nideas: (i) we adopt the efficient Lion optimizer, which only keeps track of the\nmomentum and has consistent update magnitudes for each parameter, an inherent\nadvantage for robust quantization; and (ii) we quantize all model states and\nstore them as integer values, and present a gradient flow and parameter update\nscheme for the quantized weights. As a result, QFT reduces the model state\nmemory to 21% of the standard solution while achieving comparable performance,\ne.g., tuning a LLaMA-7B model requires only <30GB of memory, satisfied by a\nsingle A6000 GPU.", "published": "2023-10-11 02:47:40", "link": "http://arxiv.org/abs/2310.07147v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive Gating in Mixture-of-Experts based Language Models", "abstract": "Large language models, such as OpenAI's ChatGPT, have demonstrated\nexceptional language understanding capabilities in various NLP tasks. Sparsely\nactivated mixture-of-experts (MoE) has emerged as a promising solution for\nscaling models while maintaining a constant number of computational operations.\nExisting MoE model adopts a fixed gating network where each token is computed\nby the same number of experts. However, this approach contradicts our intuition\nthat the tokens in each sequence vary in terms of their linguistic complexity\nand, consequently, require different computational costs. Little is discussed\nin prior research on the trade-off between computation per token and model\nperformance. This paper introduces adaptive gating in MoE, a flexible training\nstrategy that allows tokens to be processed by a variable number of experts\nbased on expert probability distribution. The proposed framework preserves\nsparsity while improving training efficiency. Additionally, curriculum learning\nis leveraged to further reduce training time. Extensive experiments on diverse\nNLP tasks show that adaptive gating reduces at most 22.5% training time while\nmaintaining inference quality. Moreover, we conduct a comprehensive analysis of\nthe routing decisions and present our insights when adaptive gating is used.", "published": "2023-10-11 04:30:18", "link": "http://arxiv.org/abs/2310.07188v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ethical Reasoning over Moral Alignment: A Case and Framework for\n  In-Context Ethical Policies in LLMs", "abstract": "In this position paper, we argue that instead of morally aligning LLMs to\nspecific set of ethical principles, we should infuse generic ethical reasoning\ncapabilities into them so that they can handle value pluralism at a global\nscale. When provided with an ethical policy, an LLM should be capable of making\ndecisions that are ethically consistent to the policy. We develop a framework\nthat integrates moral dilemmas with moral principles pertaining to different\nforamlisms of normative ethics, and at different levels of abstractions.\nInitial experiments with GPT-x models shows that while GPT-4 is a nearly\nperfect ethical reasoner, the models still have bias towards the moral values\nof Western and English speaking societies.", "published": "2023-10-11 07:27:34", "link": "http://arxiv.org/abs/2310.07251v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Analysis on Large Language Models in Healthcare: A Case Study of\n  BioBERT", "abstract": "This paper conducts a comprehensive investigation into applying large\nlanguage models, particularly on BioBERT, in healthcare. It begins with\nthoroughly examining previous natural language processing (NLP) approaches in\nhealthcare, shedding light on the limitations and challenges these methods\nface. Following that, this research explores the path that led to the\nincorporation of BioBERT into healthcare applications, highlighting its\nsuitability for addressing the specific requirements of tasks related to\nbiomedical text mining. The analysis outlines a systematic methodology for\nfine-tuning BioBERT to meet the unique needs of the healthcare domain. This\napproach includes various components, including the gathering of data from a\nwide range of healthcare sources, data annotation for tasks like identifying\nmedical entities and categorizing them, and the application of specialized\npreprocessing techniques tailored to handle the complexities found in\nbiomedical texts. Additionally, the paper covers aspects related to model\nevaluation, with a focus on healthcare benchmarks and functions like processing\nof natural language in biomedical, question-answering, clinical document\nclassification, and medical entity recognition. It explores techniques to\nimprove the model's interpretability and validates its performance compared to\nexisting healthcare-focused language models. The paper thoroughly examines\nethical considerations, particularly patient privacy and data security. It\nhighlights the benefits of incorporating BioBERT into healthcare contexts,\nincluding enhanced clinical decision support and more efficient information\nretrieval. Nevertheless, it acknowledges the impediments and complexities of\nthis integration, encompassing concerns regarding data privacy, transparency,\nresource-intensive requirements, and the necessity for model customization to\nalign with diverse healthcare domains.", "published": "2023-10-11 08:16:35", "link": "http://arxiv.org/abs/2310.07282v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Typing to Listen at the Cocktail Party: Text-Guided Target Speaker\n  Extraction", "abstract": "Humans can easily isolate a single speaker from a complex acoustic\nenvironment, a capability referred to as the \"Cocktail Party Effect.\" However,\nreplicating this ability has been a significant challenge in the field of\ntarget speaker extraction (TSE). Traditional TSE approaches predominantly rely\non voiceprints, which raise privacy concerns and face issues related to the\nquality and availability of enrollment samples, as well as intra-speaker\nvariability. To address these issues, this work introduces a novel text-guided\nTSE paradigm named LLM-TSE. In this paradigm, a state-of-the-art large language\nmodel, LLaMA 2, processes typed text input from users to extract semantic cues.\nWe demonstrate that textual descriptions alone can effectively serve as cues\nfor extraction, thus addressing privacy concerns and reducing dependency on\nvoiceprints. Furthermore, our approach offers flexibility by allowing the user\nto specify the extraction or suppression of a speaker and enhances robustness\nagainst intra-speaker variability by incorporating context-dependent textual\ninformation. Experimental results show competitive performance with text-based\ncues alone and demonstrate the effectiveness of using text as a task selector.\nAdditionally, they achieve a new state-of-the-art when combining text-based\ncues with pre-registered cues. This work represents the first integration of\nLLMs with TSE, potentially establishing a new benchmark in solving the cocktail\nparty problem and expanding the scope of TSE applications by providing a\nversatile, privacy-conscious solution.", "published": "2023-10-11 08:17:54", "link": "http://arxiv.org/abs/2310.07284v4", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "RobustGEC: Robust Grammatical Error Correction Against Subtle Context\n  Perturbation", "abstract": "Grammatical Error Correction (GEC) systems play a vital role in assisting\npeople with their daily writing tasks. However, users may sometimes come across\na GEC system that initially performs well but fails to correct errors when the\ninputs are slightly modified. To ensure an ideal user experience, a reliable\nGEC system should have the ability to provide consistent and accurate\nsuggestions when encountering irrelevant context perturbations, which we refer\nto as context robustness. In this paper, we introduce RobustGEC, a benchmark\ndesigned to evaluate the context robustness of GEC systems. RobustGEC comprises\n5,000 GEC cases, each with one original error-correct sentence pair and five\nvariants carefully devised by human annotators. Utilizing RobustGEC, we reveal\nthat state-of-the-art GEC systems still lack sufficient robustness against\ncontext perturbations. In addition, we propose a simple yet effective method\nfor remitting this issue.", "published": "2023-10-11 08:33:23", "link": "http://arxiv.org/abs/2310.07299v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SNOiC: Soft Labeling and Noisy Mixup based Open Intent Classification\n  Model", "abstract": "This paper presents a Soft Labeling and Noisy Mixup-based open intent\nclassification model (SNOiC). Most of the previous works have used\nthreshold-based methods to identify open intents, which are prone to\noverfitting and may produce biased predictions. Additionally, the need for more\navailable data for an open intent class presents another limitation for these\nexisting models. SNOiC combines Soft Labeling and Noisy Mixup strategies to\nreduce the biasing and generate pseudo-data for open intent class. The\nexperimental results on four benchmark datasets show that the SNOiC model\nachieves a minimum and maximum performance of 68.72\\% and 94.71\\%,\nrespectively, in identifying open intents. Moreover, compared to\nstate-of-the-art models, the SNOiC model improves the performance of\nidentifying open intents by 0.93\\% (minimum) and 12.76\\% (maximum). The model's\nefficacy is further established by analyzing various parameters used in the\nproposed model. An ablation study is also conducted, which involves creating\nthree model variants to validate the effectiveness of the SNOiC model.", "published": "2023-10-11 08:40:06", "link": "http://arxiv.org/abs/2310.07306v1", "categories": ["cs.LG", "cs.CL", "ACM-class: F.2.2, I.2.7"], "primary_category": "cs.LG"}
{"title": "An Empirical Study of Instruction-tuning Large Language Models in\n  Chinese", "abstract": "The success of ChatGPT validates the potential of large language models\n(LLMs) in artificial general intelligence (AGI). Subsequently, the release of\nLLMs has sparked the open-source community's interest in instruction-tuning,\nwhich is deemed to accelerate ChatGPT's replication process. However, research\non instruction-tuning LLMs in Chinese, the world's most spoken language, is\nstill in its early stages. Therefore, this paper makes an in-depth empirical\nstudy of instruction-tuning LLMs in Chinese, which can serve as a cookbook that\nprovides valuable findings for effectively customizing LLMs that can better\nrespond to Chinese instructions. Specifically, we systematically explore the\nimpact of LLM bases, parameter-efficient methods, instruction data types, which\nare the three most important elements for instruction-tuning. Besides, we also\nconduct experiment to study the impact of other factors, e.g., chain-of-thought\ndata and human-value alignment. We hope that this empirical study can make a\nmodest contribution to the open Chinese version of ChatGPT. This paper will\nrelease a powerful Chinese LLMs that is comparable to ChatGLM. The code and\ndata are available at https://github.com/PhoebusSi/Alpaca-CoT.", "published": "2023-10-11 09:18:09", "link": "http://arxiv.org/abs/2310.07328v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Linguistic laws in biology", "abstract": "Linguistic laws, the common statistical patterns of human language, have been\ninvestigated by quantitative linguists for nearly a century. Recently,\nbiologists from a range of disciplines have started to explore the prevalence\nof these laws beyond language, finding patterns consistent with linguistic laws\nacross multiple levels of biological organisation, from molecular (genomes,\ngenes, and proteins) to organismal (animal behaviour) to ecological\n(populations and ecosystems). We propose a new conceptual framework for the\nstudy of linguistic laws in biology, comprising and integrating distinct levels\nof analysis, from description to prediction to theory building. Adopting this\nframework will provide critical new insights into the fundamental rules of\norganisation underpinning natural systems, unifying linguistic laws and core\ntheory in biology.", "published": "2023-10-11 11:08:20", "link": "http://arxiv.org/abs/2310.07387v1", "categories": ["cs.CL", "physics.bio-ph"], "primary_category": "cs.CL"}
{"title": "Target-oriented Proactive Dialogue Systems with Personalization: Problem\n  Formulation and Dataset Curation", "abstract": "Target-oriented dialogue systems, designed to proactively steer conversations\ntoward predefined targets or accomplish specific system-side goals, are an\nexciting area in conversational AI. In this work, by formulating a <dialogue\nact, topic> pair as the conversation target, we explore a novel problem of\npersonalized target-oriented dialogue by considering personalization during the\ntarget accomplishment process. However, there remains an emergent need for\nhigh-quality datasets, and building one from scratch requires tremendous human\neffort. To address this, we propose an automatic dataset curation framework\nusing a role-playing approach. Based on this framework, we construct a\nlarge-scale personalized target-oriented dialogue dataset, TopDial, which\ncomprises about 18K multi-turn dialogues. The experimental results show that\nthis dataset is of high quality and could contribute to exploring personalized\ntarget-oriented dialogue.", "published": "2023-10-11 11:32:57", "link": "http://arxiv.org/abs/2310.07397v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Past, Present and Better Future of Feedback Learning in Large\n  Language Models for Subjective Human Preferences and Values", "abstract": "Human feedback is increasingly used to steer the behaviours of Large Language\nModels (LLMs). However, it is unclear how to collect and incorporate feedback\nin a way that is efficient, effective and unbiased, especially for highly\nsubjective human preferences and values. In this paper, we survey existing\napproaches for learning from human feedback, drawing on 95 papers primarily\nfrom the ACL and arXiv repositories.First, we summarise the past, pre-LLM\ntrends for integrating human feedback into language models. Second, we give an\noverview of present techniques and practices, as well as the motivations for\nusing feedback; conceptual frameworks for defining values and preferences; and\nhow feedback is collected and from whom. Finally, we encourage a better future\nof feedback learning in LLMs by raising five unresolved conceptual and\npractical challenges.", "published": "2023-10-11 16:18:13", "link": "http://arxiv.org/abs/2310.07629v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models at Evaluating Instruction Following", "abstract": "As research in large language models (LLMs) continues to accelerate,\nLLM-based evaluation has emerged as a scalable and cost-effective alternative\nto human evaluations for comparing the ever increasing list of models. This\npaper investigates the efficacy of these ``LLM evaluators'', particularly in\nusing them to assess instruction following, a metric that gauges how closely\ngenerated text adheres to the given instruction. We introduce a challenging\nmeta-evaluation benchmark, LLMBar, designed to test the ability of an LLM\nevaluator in discerning instruction-following outputs. The authors manually\ncurated 419 pairs of outputs, one adhering to instructions while the other\ndiverging, yet may possess deceptive qualities that mislead an LLM evaluator,\ne.g., a more engaging tone. Contrary to existing meta-evaluation, we discover\nthat different evaluators (i.e., combinations of LLMs and prompts) exhibit\ndistinct performance on LLMBar and even the highest-scoring ones have\nsubstantial room for improvement. We also present a novel suite of prompting\nstrategies that further close the gap between LLM and human evaluators. With\nLLMBar, we hope to offer more insight into LLM evaluators and foster future\nresearch in developing better instruction-following models.", "published": "2023-10-11 16:38:11", "link": "http://arxiv.org/abs/2310.07641v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM4Vis: Explainable Visualization Recommendation using ChatGPT", "abstract": "Data visualization is a powerful tool for exploring and communicating\ninsights in various domains. To automate visualization choice for datasets, a\ntask known as visualization recommendation has been proposed. Various\nmachine-learning-based approaches have been developed for this purpose, but\nthey often require a large corpus of dataset-visualization pairs for training\nand lack natural explanations for their results. To address this research gap,\nwe propose LLM4Vis, a novel ChatGPT-based prompting approach to perform\nvisualization recommendation and return human-like explanations using very few\ndemonstration examples. Our approach involves feature description,\ndemonstration example selection, explanation generation, demonstration example\nconstruction, and inference steps. To obtain demonstration examples with\nhigh-quality explanations, we propose a new explanation generation\nbootstrapping to iteratively refine generated explanations by considering the\nprevious generation and template-based hint. Evaluations on the VizML dataset\nshow that LLM4Vis outperforms or performs similarly to supervised learning\nmodels like Random Forest, Decision Tree, and MLP in both few-shot and\nzero-shot settings. The qualitative evaluation also shows the effectiveness of\nexplanations generated by LLM4Vis. We make our code publicly available at\n\\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.", "published": "2023-10-11 16:51:46", "link": "http://arxiv.org/abs/2310.07652v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity", "abstract": "We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of\nunderstanding spatial referring of any shape or granularity within an image and\naccurately grounding open-vocabulary descriptions. To unify referring and\ngrounding in the LLM paradigm, Ferret employs a novel and powerful hybrid\nregion representation that integrates discrete coordinates and continuous\nfeatures jointly to represent a region in the image. To extract the continuous\nfeatures of versatile regions, we propose a spatial-aware visual sampler, adept\nat handling varying sparsity across different shapes. Consequently, Ferret can\naccept diverse region inputs, such as points, bounding boxes, and free-form\nshapes. To bolster the desired capability of Ferret, we curate GRIT, a\ncomprehensive refer-and-ground instruction tuning dataset including 1.1M\nsamples that contain rich hierarchical spatial knowledge, with 95K hard\nnegative data to promote model robustness. The resulting model not only\nachieves superior performance in classical referring and grounding tasks, but\nalso greatly outperforms existing MLLMs in region-based and\nlocalization-demanded multimodal chatting. Our evaluations also reveal a\nsignificantly improved capability of describing image details and a remarkable\nalleviation in object hallucination. Code and data will be available at\nhttps://github.com/apple/ml-ferret", "published": "2023-10-11 17:55:15", "link": "http://arxiv.org/abs/2310.07704v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Found in the Middle: Permutation Self-Consistency Improves Listwise\n  Ranking in Large Language Models", "abstract": "Large language models (LLMs) exhibit positional bias in how they use context,\nwhich especially complicates listwise ranking. To address this, we propose\npermutation self-consistency, a form of self-consistency over ranking list\noutputs of black-box LLMs. Our key idea is to marginalize out different list\norders in the prompt to produce an order-independent ranking with less\npositional bias. First, given some input prompt, we repeatedly shuffle the list\nin the prompt and pass it through the LLM while holding the instructions the\nsame. Next, we aggregate the resulting sample of rankings by computing the\ncentral ranking closest in distance to all of them, marginalizing out prompt\norder biases in the process. Theoretically, we prove the robustness of our\nmethod, showing convergence to the true ranking in the presence of random\nperturbations. Empirically, on five list-ranking datasets in sorting and\npassage reranking, our approach improves scores from conventional inference by\nup to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous\nstate of the art in passage reranking. Our code is at\nhttps://github.com/castorini/perm-sc.", "published": "2023-10-11 17:59:02", "link": "http://arxiv.org/abs/2310.07712v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "To Build Our Future, We Must Know Our Past: Contextualizing Paradigm\n  Shifts in Natural Language Processing", "abstract": "NLP is in a period of disruptive change that is impacting our methodologies,\nfunding sources, and public perception. In this work, we seek to understand how\nto shape our future by better understanding our past. We study factors that\nshape NLP as a field, including culture, incentives, and infrastructure by\nconducting long-form interviews with 26 NLP researchers of varying seniority,\nresearch area, institution, and social identity. Our interviewees identify\ncyclical patterns in the field, as well as new shifts without historical\nparallel, including changes in benchmark culture and software infrastructure.\nWe complement this discussion with quantitative analysis of citation,\nauthorship, and language use in the ACL Anthology over time. We conclude by\ndiscussing shared visions, concerns, and hopes for the future of NLP. We hope\nthat this study of our field's past and present can prompt informed discussion\nof our community's implicit norms and more deliberate action to consciously\nshape the future.", "published": "2023-10-11 17:59:36", "link": "http://arxiv.org/abs/2310.07715v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A general mechanism of humor: reformulating the semantic overlap", "abstract": "This article proposes a cognitive mechanism of humour of general\napplicability, not restricted to verbal communication. It is indebted to\nRaskin's concept of script overlap, and conforms to the incongruity-resolution\ntheoretical framework, but it is built on the notion of constraint, an abstract\ncorrespondence between sets of data. Under this view, script overlap is an\noutcome of a more abstractly described phenomenon, constraint overlap. The\nimportant concept of the overlooked argument is introduced to characterise the\ntwo overlapping constraints -- overt and covert. Their inputs and outputs are\nnot directly encoded in utterances, but implicated by them, and their overlap\nresults in another overlap at the level of the communicated utterances, that\nthe incongruity reveals. Our hypothesis assumes as a given that the evocation\nof such constraints is a cognitive effect of the inferential process by which a\nhearer interprets utterances. We base this assumption on Hofstadter's theory of\nanalogy-making as the essence of human thought. By substituting \"stimuli\" of\nany kind for \"utterances\" in this model, we obtain a mechanism as easily\napplicable to non-verbal communication -- slapstick, cartoons -- and we propose\nit describes the necessary and sufficient conditions for a communicative act in\nany modality to carry humour.", "published": "2023-10-11 18:36:13", "link": "http://arxiv.org/abs/2310.07803v1", "categories": ["cs.CL", "cs.AI", "I.2.m; J.5"], "primary_category": "cs.CL"}
{"title": "On the Relationship between Sentence Analogy Identification and Sentence\n  Structure Encoding in Large Language Models", "abstract": "The ability of Large Language Models (LLMs) to encode syntactic and semantic\nstructures of language is well examined in NLP. Additionally, analogy\nidentification, in the form of word analogies are extensively studied in the\nlast decade of language modeling literature. In this work we specifically look\nat how LLMs' abilities to capture sentence analogies (sentences that convey\nanalogous meaning to each other) vary with LLMs' abilities to encode syntactic\nand semantic structures of sentences. Through our analysis, we find that LLMs'\nability to identify sentence analogies is positively correlated with their\nability to encode syntactic and semantic structures of sentences. Specifically,\nwe find that the LLMs which capture syntactic structures better, also have\nhigher abilities in identifying sentence analogies.", "published": "2023-10-11 18:59:48", "link": "http://arxiv.org/abs/2310.07818v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Faithfulness Measurable Masked Language Models", "abstract": "A common approach to explaining NLP models is to use importance measures that\nexpress which tokens are important for a prediction. Unfortunately, such\nexplanations are often wrong despite being persuasive. Therefore, it is\nessential to measure their faithfulness. One such metric is if tokens are truly\nimportant, then masking them should result in worse model performance. However,\ntoken masking introduces out-of-distribution issues, and existing solutions\nthat address this are computationally expensive and employ proxy models.\nFurthermore, other metrics are very limited in scope. This work proposes an\ninherently faithfulness measurable model that addresses these challenges. This\nis achieved using a novel fine-tuning method that incorporates masking, such\nthat masking tokens become in-distribution by design. This differs from\nexisting approaches, which are completely model-agnostic but are inapplicable\nin practice. We demonstrate the generality of our approach by applying it to 16\ndifferent datasets and validate it using statistical in-distribution tests. The\nfaithfulness is then measured with 9 different importance measures. Because\nmasking is in-distribution, importance measures that themselves use masking\nbecome consistently more faithful. Additionally, because the model makes\nfaithfulness cheap to measure, we can optimize explanations towards maximal\nfaithfulness; thus, our model becomes indirectly inherently explainable.", "published": "2023-10-11 19:00:40", "link": "http://arxiv.org/abs/2310.07819v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Synthetic Data Generation with Large Language Models for Text\n  Classification: Potential and Limitations", "abstract": "The collection and curation of high-quality training data is crucial for\ndeveloping text classification models with superior performance, but it is\noften associated with significant costs and time investment. Researchers have\nrecently explored using large language models (LLMs) to generate synthetic\ndatasets as an alternative approach. However, the effectiveness of the\nLLM-generated synthetic data in supporting model training is inconsistent\nacross different classification tasks. To better understand factors that\nmoderate the effectiveness of the LLM-generated synthetic data, in this study,\nwe look into how the performance of models trained on these synthetic data may\nvary with the subjectivity of classification. Our results indicate that\nsubjectivity, at both the task level and instance level, is negatively\nassociated with the performance of the model trained on synthetic data. We\nconclude by discussing the implications of our work on the potential and\nlimitations of leveraging LLM for synthetic data generation.", "published": "2023-10-11 19:51:13", "link": "http://arxiv.org/abs/2310.07849v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Assessing Evaluation Metrics for Neural Test Oracle Generation", "abstract": "In this work, we revisit existing oracle generation studies plus ChatGPT to\nempirically investigate the current standing of their performance in both\nNLG-based and test adequacy metrics. Specifically, we train and run four\nstate-of-the-art test oracle generation models on five NLG-based and two test\nadequacy metrics for our analysis. We apply two different correlation analyses\nbetween these two different sets of metrics. Surprisingly, we found no\nsignificant correlation between the NLG-based metrics and test adequacy\nmetrics. For instance, oracles generated from ChatGPT on the project\nactivemq-artemis had the highest performance on all the NLG-based metrics among\nthe studied NOGs, however, it had the most number of projects with a decrease\nin test adequacy metrics compared to all the studied NOGs. We further conduct a\nqualitative analysis to explore the reasons behind our observations, we found\nthat oracles with high NLG-based metrics but low test adequacy metrics tend to\nhave complex or multiple chained method invocations within the oracle's\nparameters, making it hard for the model to generate completely, affecting the\ntest adequacy metrics. On the other hand, oracles with low NLG-based metrics\nbut high test adequacy metrics tend to have to call different assertion types\nor a different method that functions similarly to the ones in the ground truth.\nOverall, this work complements prior studies on test oracle generation with an\nextensive performance evaluation with both NLG and test adequacy metrics and\nprovides guidelines for better assessment of deep learning applications in\nsoftware test generation in the future.", "published": "2023-10-11 19:58:07", "link": "http://arxiv.org/abs/2310.07856v1", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "The Temporal Structure of Language Processing in the Human Brain\n  Corresponds to The Layered Hierarchy of Deep Language Models", "abstract": "Deep Language Models (DLMs) provide a novel computational paradigm for\nunderstanding the mechanisms of natural language processing in the human brain.\nUnlike traditional psycholinguistic models, DLMs use layered sequences of\ncontinuous numerical vectors to represent words and context, allowing a\nplethora of emerging applications such as human-like text generation. In this\npaper we show evidence that the layered hierarchy of DLMs may be used to model\nthe temporal dynamics of language comprehension in the brain by demonstrating a\nstrong correlation between DLM layer depth and the time at which layers are\nmost predictive of the human brain. Our ability to temporally resolve\nindividual layers benefits from our use of electrocorticography (ECoG) data,\nwhich has a much higher temporal resolution than noninvasive methods like fMRI.\nUsing ECoG, we record neural activity from participants listening to a\n30-minute narrative while also feeding the same narrative to a high-performing\nDLM (GPT2-XL). We then extract contextual embeddings from the different layers\nof the DLM and use linear encoding models to predict neural activity. We first\nfocus on the Inferior Frontal Gyrus (IFG, or Broca's area) and then extend our\nmodel to track the increasing temporal receptive window along the linguistic\nprocessing hierarchy from auditory to syntactic and semantic areas. Our results\nreveal a connection between human language processing and DLMs, with the DLM's\nlayer-by-layer accumulation of contextual information mirroring the timing of\nneural activity in high-order language areas.", "published": "2023-10-11 01:03:42", "link": "http://arxiv.org/abs/2310.07106v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "cs.CL"}
{"title": "AE-smnsMLC: Multi-Label Classification with Semantic Matching and\n  Negative Label Sampling for Product Attribute Value Extraction", "abstract": "Product attribute value extraction plays an important role for many\nreal-world applications in e-Commerce such as product search and\nrecommendation. Previous methods treat it as a sequence labeling task that\nneeds more annotation for position of values in the product text. This limits\ntheir application to real-world scenario in which only attribute values are\nweakly-annotated for each product without their position. Moreover, these\nmethods only use product text (i.e., product title and description) and do not\nconsider the semantic connection between the multiple attribute values of a\ngiven product and its text, which can help attribute value extraction. In this\npaper, we reformulate this task as a multi-label classification task that can\nbe applied for real-world scenario in which only annotation of attribute values\nis available to train models (i.e., annotation of positional information of\nattribute values is not available). We propose a classification model with\nsemantic matching and negative label sampling for attribute value extraction.\nSemantic matching aims to capture semantic interactions between attribute\nvalues of a given product and its text. Negative label sampling aims to enhance\nthe model's ability of distinguishing similar values belonging to the same\nattribute. Experimental results on three subsets of a large real-world\ne-Commerce dataset demonstrate the effectiveness and superiority of our\nproposed model.", "published": "2023-10-11 02:22:28", "link": "http://arxiv.org/abs/2310.07137v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms", "abstract": "Within the ambit of VoIP (Voice over Internet Protocol) telecommunications,\nthe complexities introduced by acoustic transformations merit rigorous\nanalysis. This research, rooted in the exploration of proprietary sender-side\ndenoising effects, meticulously evaluates platforms such as Google Meets and\nZoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset,\nensuring a structured examination tailored to various denoising settings and\nreceiver interfaces. A methodological novelty is introduced via Blinder-Oaxaca\ndecomposition, traditionally an econometric tool, repurposed herein to analyze\nacoustic-phonetic perturbations within VoIP systems. To further ground the\nimplications of these transformations, psychoacoustic metrics, specifically\nPESQ and STOI, were used to explain of perceptual quality and intelligibility.\nCumulatively, the insights garnered underscore the intricate landscape of\nVoIP-influenced acoustic dynamics. In addition to the primary findings, a\nmultitude of metrics are reported, extending the research purview. Moreover,\nout-of-domain benchmarking for both time and time-frequency domain speech\nenhancement models is included, thereby enhancing the depth and applicability\nof this inquiry.", "published": "2023-10-11 03:19:22", "link": "http://arxiv.org/abs/2310.07161v3", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Online Speculative Decoding", "abstract": "Speculative decoding is a pivotal technique to accelerate the inference of\nlarge language models (LLMs) by employing a smaller draft model to predict the\ntarget model's outputs. However, its efficacy can be limited due to the low\npredictive accuracy of the draft model, particularly when faced with diverse\ntext inputs and a significant capability gap between the draft and target\nmodels. We introduce online speculative decoding to address this challenge. The\nmain idea is to continuously update the (multiple) draft model(s) on observed\nuser query data. Adapting to query distribution mitigates the shifts between\nthe training distribution of the draft model and the query distribution,\nenabling the draft model to more accurately predict the target model's outputs.\nWe develop a prototype of online speculative decoding based on knowledge\ndistillation and evaluate it using both synthetic and real query data. The\nresults show a substantial increase in the token acceptance rate by 0.1 to\n0.65, bringing 1.42x to 2.17x latency reduction. Our code is available at\nhttps://github.com/LiuXiaoxuanPKU/OSD.", "published": "2023-10-11 04:03:42", "link": "http://arxiv.org/abs/2310.07177v4", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "BioT5: Enriching Cross-modal Integration in Biology with Chemical\n  Knowledge and Natural Language Associations", "abstract": "Recent advancements in biological research leverage the integration of\nmolecules, proteins, and natural language to enhance drug discovery. However,\ncurrent models exhibit several limitations, such as the generation of invalid\nmolecular SMILES, underutilization of contextual information, and equal\ntreatment of structured and unstructured knowledge. To address these issues, we\npropose $\\mathbf{BioT5}$, a comprehensive pre-training framework that enriches\ncross-modal integration in biology with chemical knowledge and natural language\nassociations. $\\mathbf{BioT5}$ utilizes SELFIES for $100%$ robust molecular\nrepresentations and extracts knowledge from the surrounding context of\nbio-entities in unstructured biological literature. Furthermore,\n$\\mathbf{BioT5}$ distinguishes between structured and unstructured knowledge,\nleading to more effective utilization of information. After fine-tuning, BioT5\nshows superior performance across a wide range of tasks, demonstrating its\nstrong capability of capturing underlying relations and properties of\nbio-entities. Our code is available at\n$\\href{https://github.com/QizhiPei/BioT5}{Github}$.", "published": "2023-10-11 07:57:08", "link": "http://arxiv.org/abs/2310.07276v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "q-bio.BM"], "primary_category": "cs.CL"}
{"title": "Enhancing expressivity transfer in textless speech-to-speech translation", "abstract": "Textless speech-to-speech translation systems are rapidly advancing, thanks\nto the integration of self-supervised learning techniques. However, existing\nstate-of-the-art systems fall short when it comes to capturing and transferring\nexpressivity accurately across different languages. Expressivity plays a vital\nrole in conveying emotions, nuances, and cultural subtleties, thereby enhancing\ncommunication across diverse languages. To address this issue this study\npresents a novel method that operates at the discrete speech unit level and\nleverages multilingual emotion embeddings to capture language-agnostic\ninformation. Specifically, we demonstrate how these embeddings can be used to\neffectively predict the pitch and duration of speech units in the target\nlanguage. Through objective and subjective experiments conducted on a\nFrench-to-English translation task, our findings highlight the superior\nexpressivity transfer achieved by our approach compared to current\nstate-of-the-art systems.", "published": "2023-10-11 08:07:22", "link": "http://arxiv.org/abs/2310.07279v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Impact of Cross-Domain Data on German Language Models", "abstract": "Traditionally, large language models have been either trained on general web\ncrawls or domain-specific data. However, recent successes of generative large\nlanguage models, have shed light on the benefits of cross-domain datasets. To\nexamine the significance of prioritizing data diversity over quality, we\npresent a German dataset comprising texts from five domains, along with another\ndataset aimed at containing high-quality data. Through training a series of\nmodels ranging between 122M and 750M parameters on both datasets, we conduct a\ncomprehensive benchmark on multiple downstream tasks. Our findings demonstrate\nthat the models trained on the cross-domain dataset outperform those trained on\nquality data alone, leading to improvements up to $4.45\\%$ over the previous\nstate-of-the-art. The models are available at\nhttps://huggingface.co/ikim-uk-essen", "published": "2023-10-11 09:09:55", "link": "http://arxiv.org/abs/2310.07321v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating the Effect of Language Models in Sequence Discriminative\n  Training for Neural Transducers", "abstract": "In this work, we investigate the effect of language models (LMs) with\ndifferent context lengths and label units (phoneme vs. word) used in sequence\ndiscriminative training for phoneme-based neural transducers. Both lattice-free\nand N-best-list approaches are examined. For lattice-free methods with\nphoneme-level LMs, we propose a method to approximate the context history to\nemploy LMs with full-context dependency. This approximation can be extended to\narbitrary context length and enables the usage of word-level LMs in\nlattice-free methods. Moreover, a systematic comparison is conducted across\nlattice-free and N-best-list-based methods. Experimental results on Librispeech\nshow that using the word-level LM in training outperforms the phoneme-level LM.\nBesides, we find that the context size of the LM used for probability\ncomputation has a limited effect on performance. Moreover, our results reveal\nthe pivotal importance of the hypothesis space quality in sequence\ndiscriminative training.", "published": "2023-10-11 09:53:17", "link": "http://arxiv.org/abs/2310.07345v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Fast-ELECTRA for Efficient Pre-training", "abstract": "ELECTRA pre-trains language models by detecting tokens in a sequence that\nhave been replaced by an auxiliary model. Although ELECTRA offers a significant\nboost in efficiency, its potential is constrained by the training cost brought\nby the auxiliary model. Notably, this model, which is jointly trained with the\nmain model, only serves to assist the training of the main model and is\ndiscarded post-training. This results in a substantial amount of training cost\nbeing expended in vain. To mitigate this issue, we propose Fast-ELECTRA, which\nleverages an existing language model as the auxiliary model. To construct a\nlearning curriculum for the main model, we smooth its output distribution via\ntemperature scaling following a descending schedule. Our approach rivals the\nperformance of state-of-the-art ELECTRA-style pre-training methods, while\nsignificantly eliminating the computation and memory cost brought by the joint\ntraining of the auxiliary model. Our method also reduces the sensitivity to\nhyper-parameters and enhances the pre-training stability.", "published": "2023-10-11 09:55:46", "link": "http://arxiv.org/abs/2310.07347v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DASpeech: Directed Acyclic Transformer for Fast and High-quality\n  Speech-to-Speech Translation", "abstract": "Direct speech-to-speech translation (S2ST) translates speech from one\nlanguage into another using a single model. However, due to the presence of\nlinguistic and acoustic diversity, the target speech follows a complex\nmultimodal distribution, posing challenges to achieving both high-quality\ntranslations and fast decoding speeds for S2ST models. In this paper, we\npropose DASpeech, a non-autoregressive direct S2ST model which realizes both\nfast and high-quality S2ST. To better capture the complex distribution of the\ntarget speech, DASpeech adopts the two-pass architecture to decompose the\ngeneration process into two steps, where a linguistic decoder first generates\nthe target text, and an acoustic decoder then generates the target speech based\non the hidden states of the linguistic decoder. Specifically, we use the\ndecoder of DA-Transformer as the linguistic decoder, and use FastSpeech 2 as\nthe acoustic decoder. DA-Transformer models translations with a directed\nacyclic graph (DAG). To consider all potential paths in the DAG during\ntraining, we calculate the expected hidden states for each target token via\ndynamic programming, and feed them into the acoustic decoder to predict the\ntarget mel-spectrogram. During inference, we select the most probable path and\ntake hidden states on that path as input to the acoustic decoder. Experiments\non the CVSS Fr-En benchmark demonstrate that DASpeech can achieve comparable or\neven better performance than the state-of-the-art S2ST model Translatotron 2,\nwhile preserving up to 18.53x speedup compared to the autoregressive baseline.\nCompared with the previous non-autoregressive S2ST model, DASpeech does not\nrely on knowledge distillation and iterative decoding, achieving significant\nimprovements in both translation quality and decoding speed. Furthermore,\nDASpeech shows the ability to preserve the speaker's voice of the source speech\nduring translation.", "published": "2023-10-11 11:39:36", "link": "http://arxiv.org/abs/2310.07403v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adapting the adapters for code-switching in multilingual ASR", "abstract": "Recently, large pre-trained multilingual speech models have shown potential\nin scaling Automatic Speech Recognition (ASR) to many low-resource languages.\nSome of these models employ language adapters in their formulation, which helps\nto improve monolingual performance and avoids some of the drawbacks of\nmulti-lingual modeling on resource-rich languages. However, this formulation\nrestricts the usability of these models on code-switched speech, where two\nlanguages are mixed together in the same utterance. In this work, we propose\nways to effectively fine-tune such models on code-switched speech, by\nassimilating information from both language adapters at each language\nadaptation point in the network. We also model code-switching as a sequence of\nlatent binary sequences that can be used to guide the flow of information from\neach language adapter at the frame level. The proposed approaches are evaluated\non three code-switched datasets encompassing Arabic, Mandarin, and Hindi\nlanguages paired with English, showing consistent improvements in\ncode-switching performance with at least 10\\% absolute reduction in CER across\nall test sets.", "published": "2023-10-11 12:15:24", "link": "http://arxiv.org/abs/2310.07423v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "KwaiYiiMath: Technical Report", "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable abilities in handling a variety of natural language processing (NLP)\ndownstream tasks, even on mathematical tasks requiring multi-step reasoning. In\nthis report, we introduce the KwaiYiiMath which enhances the mathematical\nreasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT)\nand Reinforced Learning from Human Feedback (RLHF), including on both English\nand Chinese mathematical tasks. Meanwhile, we also constructed a small-scale\nChinese primary school mathematics test set (named KMath), consisting of 188\nexamples to evaluate the correctness of the problem-solving process generated\nby the models. Empirical studies demonstrate that KwaiYiiMath can achieve\nstate-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with\nthe similar size models, respectively.", "published": "2023-10-11 13:35:05", "link": "http://arxiv.org/abs/2310.07488v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Accurate Use of Label Dependency in Multi-Label Text Classification\n  Through the Lens of Causality", "abstract": "Multi-Label Text Classification (MLTC) aims to assign the most relevant\nlabels to each given text. Existing methods demonstrate that label dependency\ncan help to improve the model's performance. However, the introduction of label\ndependency may cause the model to suffer from unwanted prediction bias. In this\nstudy, we attribute the bias to the model's misuse of label dependency, i.e.,\nthe model tends to utilize the correlation shortcut in label dependency rather\nthan fusing text information and label dependency for prediction. Motivated by\ncausal inference, we propose a CounterFactual Text Classifier (CFTC) to\neliminate the correlation bias, and make causality-based predictions.\nSpecifically, our CFTC first adopts the predict-then-modify backbone to extract\nprecise label information embedded in label dependency, then blocks the\ncorrelation shortcut through the counterfactual de-bias technique with the help\nof the human causal graph. Experimental results on three datasets demonstrate\nthat our CFTC significantly outperforms the baselines and effectively\neliminates the correlation bias in datasets.", "published": "2023-10-11 15:28:44", "link": "http://arxiv.org/abs/2310.07588v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in\n  Self-Refined Open-Source Models", "abstract": "The dominance of proprietary LLMs has led to restricted access and raised\ninformation privacy concerns. High-performing open-source alternatives are\ncrucial for information-sensitive and high-volume applications but often lag\nbehind in performance. To address this gap, we propose (1) A untargeted variant\nof iterative self-critique and self-refinement devoid of external influence.\n(2) A novel ranking metric - Performance, Refinement, and Inference Cost Score\n(PeRFICS) - to find the optimal model for a given task considering refined\nperformance and cost. Our experiments show that SoTA open source models of\nvarying sizes from 7B - 65B, on average, improve 8.2% from their baseline\nperformance. Strikingly, even models with extremely small memory footprints,\nsuch as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39%\nimprovement in high-creativity, open ended tasks on the Vicuna benchmark.\nVicuna-13B takes it a step further and outperforms ChatGPT post-refinement.\nThis work has profound implications for resource-constrained and\ninformation-sensitive environments seeking to leverage LLMs without incurring\nprohibitive costs, compromising on performance and privacy. The domain-agnostic\nself-refinement process coupled with our novel ranking metric facilitates\ninformed decision-making in model selection, thereby reducing costs and\ndemocratizing access to high-performing language models, as evidenced by case\nstudies.", "published": "2023-10-11 15:56:00", "link": "http://arxiv.org/abs/2310.07611v2", "categories": ["cs.CL", "cs.AI", "cs.PF", "68T50 (Primary)", "I.2.7; A.2; H.3.4; K.4.1; C.4"], "primary_category": "cs.CL"}
{"title": "Toward Understanding BERT-Like Pre-Training for DNA Foundation Models", "abstract": "With the success of large-scale pre-training in language tasks, there is an\nincreasing trend of applying it to the domain of life sciences. In particular,\npre-training methods based on DNA sequences have received increasing attention\nbecause of their potential to capture general information about genes. However,\nexisting pre-training methods for DNA sequences largely rely on direct\nadoptions of BERT pre-training from NLP, lacking a comprehensive understanding\nand a specifically tailored approach. To address this research gap, we provide\nthe first empirical study with three insightful observations. Based on the\nempirical study, we notice that overlapping tokenizer can benefit the\nfine-tuning of downstream tasks but leads to inadequate pre-training with fast\nconvergence. To unleash the pre-training potential, we introduce a novel\napproach called RandomMask, which gradually increases the task difficulty of\nBERT-like pre-training by continuously expanding its mask boundary, forcing the\nmodel to learn more knowledge. RandomMask is simple but effective, achieving\nstate-of-the-art performance across 6 downstream tasks. RandomMask achieves a\nstaggering 68.16\\% in Matthew's correlation coefficient for Epigenetic Mark\nPrediction, a groundbreaking increase of 19.85\\% over the baseline and a\nremarkable 3.69\\% improvement over the previous state-of-the-art result.", "published": "2023-10-11 16:40:57", "link": "http://arxiv.org/abs/2310.07644v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Audio-Visual Neural Syntax Acquisition", "abstract": "We study phrase structure induction from visually-grounded speech. The core\nidea is to first segment the speech waveform into sequences of word segments,\nand subsequently induce phrase structure using the inferred segment-level\ncontinuous representations. We present the Audio-Visual Neural Syntax Learner\n(AV-NSL) that learns phrase structure by listening to audio and looking at\nimages, without ever being exposed to text. By training on paired images and\nspoken captions, AV-NSL exhibits the capability to infer meaningful phrase\nstructures that are comparable to those derived by naturally-supervised text\nparsers, for both English and German. Our findings extend prior work in\nunsupervised language acquisition from speech and grounded grammar induction,\nand present one approach to bridge the gap between the two topics.", "published": "2023-10-11 16:54:57", "link": "http://arxiv.org/abs/2310.07654v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Composite Backdoor Attacks Against Large Language Models", "abstract": "Large language models (LLMs) have demonstrated superior performance compared\nto previous methods on various tasks, and often serve as the foundation models\nfor many researches and services. However, the untrustworthy third-party LLMs\nmay covertly introduce vulnerabilities for downstream tasks. In this paper, we\nexplore the vulnerability of LLMs through the lens of backdoor attacks.\nDifferent from existing backdoor attacks against LLMs, ours scatters multiple\ntrigger keys in different prompt components. Such a Composite Backdoor Attack\n(CBA) is shown to be stealthier than implanting the same multiple trigger keys\nin only a single component. CBA ensures that the backdoor is activated only\nwhen all trigger keys appear. Our experiments demonstrate that CBA is effective\nin both natural language processing (NLP) and multimodal tasks. For instance,\nwith $3\\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset,\nour attack achieves a $100\\%$ Attack Success Rate (ASR) with a False Triggered\nRate (FTR) below $2.06\\%$ and negligible model accuracy degradation. Our work\nhighlights the necessity of increased security research on the trustworthiness\nof foundation LLMs.", "published": "2023-10-11 17:21:03", "link": "http://arxiv.org/abs/2310.07676v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "MatFormer: Nested Transformer for Elastic Inference", "abstract": "Foundation models are applied in a broad spectrum of settings with different\ninference constraints, from massive multi-accelerator clusters to\nresource-constrained standalone mobile devices. However, the substantial costs\nassociated with training these models often limit the number of unique model\nsizes that can be offered. Consequently, practitioners are compelled to select\na model that may not be optimally aligned with their specific latency and cost\nrequirements. We present MatFormer, a novel Transformer architecture designed\nto provide elastic inference across diverse deployment constraints. MatFormer\nachieves this by incorporating a nested Feed Forward Network (FFN) block\nstructure within a standard Transformer model. During training, we optimize the\nparameters of multiple nested FFN blocks with varying sizes, enabling the\nextraction of hundreds of accurate smaller models without incurring additional\ncomputational costs. We empirically validate the efficacy of MatFormer across\ndifferent model classes (decoders and encoders) and modalities (language and\nvision), demonstrating its potential for real-world deployment. We show that a\n850M decoder-only MatFormer language model (MatLM) allows us to extract\nmultiple smaller models spanning from 582M to 850M parameters, each exhibiting\nbetter validation loss and one-shot downstream evaluations than independently\ntrained counterparts. Furthermore, we observe that smaller encoders extracted\nfrom a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space\nstructure for adaptive large-scale retrieval. Finally, we showcase that\nspeculative decoding with the accurate and consistent submodels extracted from\nMatFormer can lead to significant reduction in inference latency. Project\nwebsite: https://devvrit.github.io/matformer/", "published": "2023-10-11 17:57:14", "link": "http://arxiv.org/abs/2310.07707v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A Resilient and Accessible Distribution-Preserving Watermark for Large\n  Language Models", "abstract": "Watermarking techniques offer a promising way to identify machine-generated\ncontent via embedding covert information into the contents generated from\nlanguage models. A challenge in the domain lies in preserving the distribution\nof original generated content after watermarking. Our research extends and\nimproves upon existing watermarking framework, placing emphasis on the\nimportance of a \\textbf{Di}stribution-\\textbf{P}reserving (DiP) watermark.\nContrary to the current strategies, our proposed DiPmark simultaneously\npreserves the original token distribution during watermarking\n(distribution-preserving), is detectable without access to the language model\nAPI and prompts (accessible), and is provably robust to moderate changes of\ntokens (resilient). DiPmark operates by selecting a random set of tokens prior\nto the generation of a word, then modifying the token distribution through a\ndistribution-preserving reweight function to enhance the probability of these\nselected tokens during the sampling process. Extensive empirical evaluation on\nvarious language models and tasks demonstrates our approach's\ndistribution-preserving property, accessibility, and resilience, making it a\neffective solution for watermarking tasks that demand impeccable quality\npreservation.", "published": "2023-10-11 17:57:35", "link": "http://arxiv.org/abs/2310.07710v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining", "abstract": "Pretraining auto-regressive large language models~(LLMs) with retrieval\ndemonstrates better perplexity and factual accuracy by leveraging external\ndatabases. However, the size of existing pretrained retrieval-augmented LLM is\nstill limited (e.g., Retro has 7.5B parameters), which limits the effectiveness\nof instruction tuning and zero-shot generalization. In this work, we introduce\nRetro 48B, the largest LLM pretrained with retrieval. Specifically, we continue\nto pretrain a 43B GPT model on additional 100 billion tokens using the Retro\naugmentation method by retrieving from 1.2 trillion tokens. Notably, the\nobtained foundation model, Retro 48B, largely outperforms the counterpart GPT\n43B trained on 1.2T tokens in terms of perplexity with only 2.58% additional\nGPU hours, demonstrating the significant scaling potential of the method. After\ninstruction tuning on Retro, InstructRetro demonstrates significant improvement\nover the instruction tuned GPT on a wide range of zero-shot tasks.\nSpecifically, the average improvement of InstructRetro is 7% over its GPT\ncounterpart across 8 short-form QA and reading comprehension tasks, 10% over\nGPT across 4 challenging long-form QA tasks, and 16% over GPT across 3\nsummarization tasks. Surprisingly, we find that one can ablate the encoder from\nInstructRetro architecture and directly use its decoder backbone, while\nachieving comparable results. Our results highlight the promising direction to\nobtain a better GPT decoder through continued pretraining with retrieval before\ninstruction tuning. Our code and checkpoints are publicly available at:\nhttps://huggingface.co/nvidia/retro-48b-instruct-4k.", "published": "2023-10-11 17:59:05", "link": "http://arxiv.org/abs/2310.07713v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large\n  Language Models", "abstract": "The rapid advancements in large language models (LLMs) have ignited interest\nin the temporal knowledge graph (tKG) domain, where conventional\nembedding-based and rule-based methods dominate. The question remains open of\nwhether pre-trained LLMs can understand structured temporal relational data and\nreplace them as the foundation model for temporal relational forecasting.\nTherefore, we bring temporal knowledge forecasting into the generative setting.\nHowever, challenges occur in the huge chasms between complex temporal graph\ndata structure and sequential natural expressions LLMs can handle, and between\nthe enormous data sizes of tKGs and heavy computation costs of finetuning LLMs.\nTo address these challenges, we propose a novel retrieval-augmented generation\nframework named GenTKG combining a temporal logical rule-based retrieval\nstrategy and few-shot parameter-efficient instruction tuning to solve the above\nchallenges, respectively. Extensive experiments have shown that GenTKG\noutperforms conventional methods of temporal relational forecasting with low\ncomputation resources using extremely limited training data as few as 16\nsamples. GenTKG also highlights remarkable cross-domain generalizability with\noutperforming performance on unseen datasets without re-training, and in-domain\ngeneralizability regardless of time split in the same dataset. Our work reveals\nthe huge potential of LLMs in the tKG domain and opens a new frontier for\ngenerative forecasting on tKGs. Code and data are released here:\nhttps://github.com/mayhugotong/GenTKG.", "published": "2023-10-11 18:27:12", "link": "http://arxiv.org/abs/2310.07793v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language Models As Semantic Indexers", "abstract": "Semantic identifier (ID) is an important concept in information retrieval\nthat aims to preserve the semantics of objects such as documents and items\ninside their IDs. Previous studies typically adopt a two-stage pipeline to\nlearn semantic IDs by first procuring embeddings using off-the-shelf text\nencoders and then deriving IDs based on the embeddings. However, each step\nintroduces potential information loss, and there is usually an inherent\nmismatch between the distribution of embeddings within the latent space\nproduced by text encoders and the anticipated distribution required for\nsemantic indexing. It is non-trivial to design a method that can learn the\ndocument's semantic representations and its hierarchical structure\nsimultaneously, given that semantic IDs are discrete and sequentially\nstructured, and the semantic supervision is deficient. In this paper, we\nintroduce LMIndexer, a self-supervised framework to learn semantic IDs with a\ngenerative language model. We tackle the challenge of sequential discrete ID by\nintroducing a semantic indexer capable of generating neural sequential discrete\nrepresentations with progressive training and contrastive learning. In response\nto the semantic supervision deficiency, we propose to train the model with a\nself-supervised document reconstruction objective. We show the high quality of\nthe learned IDs and demonstrate their effectiveness on three tasks including\nrecommendation, product search, and document retrieval on five datasets from\nvarious domains. Code is available at\nhttps://github.com/PeterGriffinJin/LMIndexer.", "published": "2023-10-11 18:56:15", "link": "http://arxiv.org/abs/2310.07815v3", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Does Synthetic Data Make Large Language Models More Efficient?", "abstract": "Natural Language Processing (NLP) has undergone transformative changes with\nthe advent of deep learning methodologies. One challenge persistently\nconfronting researchers is the scarcity of high-quality, annotated datasets\nthat drive these models. This paper explores the nuances of synthetic data\ngeneration in NLP, with a focal point on template-based question generation. By\nassessing its advantages, including data augmentation potential and the\nintroduction of structured variety, we juxtapose these benefits against\ninherent limitations, such as the risk of overfitting and the constraints posed\nby pre-defined templates. Drawing from empirical evaluations, we demonstrate\nthe impact of template-based synthetic data on the performance of modern\ntransformer models. We conclude by emphasizing the delicate balance required\nbetween synthetic and real-world data, and the future trajectories of\nintegrating synthetic data in model training pipelines. The findings aim to\nguide NLP practitioners in harnessing synthetic data's potential, ensuring\noptimal model performance in diverse applications.", "published": "2023-10-11 19:16:09", "link": "http://arxiv.org/abs/2310.07830v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TabLib: A Dataset of 627M Tables with Context", "abstract": "It is well-established that large, diverse datasets play a pivotal role in\nthe performance of modern AI systems for text and image modalities. However,\nthere are no datasets for tabular data of comparable size and diversity to\nthose available for text and images. Thus we present \"TabLib'', a compilation\nof 627 million tables totaling 69 TiB, along with 867B tokens of context.\nTabLib was extracted from numerous file formats, including CSV, HTML, SQLite,\nPDF, Excel, and others, sourced from GitHub and Common Crawl. The size and\ndiversity of TabLib offer considerable promise in the table modality,\nreminiscent of the original promise of foundational datasets for text and\nimages, such as The Pile and LAION.", "published": "2023-10-11 20:34:42", "link": "http://arxiv.org/abs/2310.07875v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LangNav: Language as a Perceptual Representation for Navigation", "abstract": "We explore the use of language as a perceptual representation for\nvision-and-language navigation (VLN), with a focus on low-data settings. Our\napproach uses off-the-shelf vision systems for image captioning and object\ndetection to convert an agent's egocentric panoramic view at each time step\ninto natural language descriptions. We then finetune a pretrained language\nmodel to select an action, based on the current view and the trajectory\nhistory, that would best fulfill the navigation instructions. In contrast to\nthe standard setup which adapts a pretrained language model to work directly\nwith continuous visual features from pretrained vision models, our approach\ninstead uses (discrete) language as the perceptual representation. We explore\nseveral use cases of our language-based navigation (LangNav) approach on the\nR2R VLN benchmark: generating synthetic trajectories from a prompted language\nmodel (GPT-4) with which to finetune a smaller language model; domain transfer\nwhere we transfer a policy learned on one simulated environment (ALFRED) to\nanother (more realistic) environment (R2R); and combining both vision- and\nlanguage-based representations for VLN. Our approach is found to improve upon\nbaselines that rely on visual features in settings where only a few expert\ntrajectories (10-100) are available, demonstrating the potential of language as\na perceptual representation for navigation.", "published": "2023-10-11 20:52:30", "link": "http://arxiv.org/abs/2310.07889v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.CV"}
{"title": "The Expressive Power of Transformers with Chain of Thought", "abstract": "Recent theoretical work has identified surprisingly simple reasoning\nproblems, such as checking if two nodes in a graph are connected or simulating\nfinite-state machines, that are provably unsolvable by standard transformers\nthat answer immediately after reading their input. However, in practice,\ntransformers' reasoning can be improved by allowing them to use a \"chain of\nthought\" or \"scratchpad\", i.e., generate and condition on a sequence of\nintermediate tokens before answering. Motivated by this, we ask: Does such\nintermediate generation fundamentally extend the computational power of a\ndecoder-only transformer? We show that the answer is yes, but the amount of\nincrease depends crucially on the amount of intermediate generation. For\ninstance, we find that transformer decoders with a logarithmic number of\ndecoding steps (w.r.t. the input length) push the limits of standard\ntransformers only slightly, while a linear number of decoding steps, assuming\nprojected pre-norm (a slight generalization of standard pre-norm), adds a clear\nnew ability (under standard complexity conjectures): recognizing all regular\nlanguages. Our results also imply that linear steps keep transformer decoders\nwithin context-sensitive languages, and polynomial steps with generalized\npre-norm make them recognize exactly the class of polynomial-time solvable\nproblems -- the first exact characterization of a type of transformers in terms\nof standard complexity classes. Together, this provides a nuanced framework for\nunderstanding how the length of a transformer's chain of thought or scratchpad\nimpacts its reasoning power.", "published": "2023-10-11 22:35:18", "link": "http://arxiv.org/abs/2310.07923v5", "categories": ["cs.LG", "cs.CC", "cs.CL", "cs.LO"], "primary_category": "cs.LG"}
{"title": "D2 Pruning: Message Passing for Balancing Diversity and Difficulty in\n  Data Pruning", "abstract": "Analytical theories suggest that higher-quality data can lead to lower test\nerrors in models trained on a fixed data budget. Moreover, a model can be\ntrained on a lower compute budget without compromising performance if a dataset\ncan be stripped of its redundancies. Coreset selection (or data pruning) seeks\nto select a subset of the training data so as to maximize the performance of\nmodels trained on this subset, also referred to as coreset. There are two\ndominant approaches: (1) geometry-based data selection for maximizing data\ndiversity in the coreset, and (2) functions that assign difficulty scores to\nsamples based on training dynamics. Optimizing for data diversity leads to a\ncoreset that is biased towards easier samples, whereas, selection by difficulty\nranking omits easy samples that are necessary for the training of deep learning\nmodels. This demonstrates that data diversity and importance scores are two\ncomplementary factors that need to be jointly considered during coreset\nselection. We represent a dataset as an undirected graph and propose a novel\npruning algorithm, D2 Pruning, that uses forward and reverse message passing\nover this dataset graph for coreset selection. D2 Pruning updates the\ndifficulty scores of each example by incorporating the difficulty of its\nneighboring examples in the dataset graph. Then, these updated difficulty\nscores direct a graph-based sampling method to select a coreset that\nencapsulates both diverse and difficult regions of the dataset space. We\nevaluate supervised and self-supervised versions of our method on various\nvision and language datasets. Results show that D2 Pruning improves coreset\nselection over previous state-of-the-art methods for up to 70% pruning rates.\nAdditionally, we find that using D2 Pruning for filtering large multimodal\ndatasets leads to increased diversity in the dataset and improved\ngeneralization of pretrained models.", "published": "2023-10-11 23:01:29", "link": "http://arxiv.org/abs/2310.07931v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "VSANet: Real-time Speech Enhancement Based on Voice Activity Detection\n  and Causal Spatial Attention", "abstract": "The deep learning-based speech enhancement (SE) methods always take the clean\nspeech's waveform or time-frequency spectrum feature as the learning target,\nand train the deep neural network (DNN) by reducing the error loss between the\nDNN's output and the target. This is a conventional single-task learning\nparadigm, which has been proven to be effective, but we find that the\nmulti-task learning framework can improve SE performance. Specifically, we\ndesign a framework containing a SE module and a voice activity detection (VAD)\nmodule, both of which share the same encoder, and the whole network is\noptimized by the weighted loss of the two modules. Moreover, we design a causal\nspatial attention (CSA) block to promote the representation capability of DNN.\nCombining the VAD aided multi-task learning framework and CSA block, our SE\nnetwork is named VSANet. The experimental results prove the benefits of\nmulti-task learning and the CSA block, which give VSANet an excellent SE\nperformance.", "published": "2023-10-11 08:30:28", "link": "http://arxiv.org/abs/2310.07295v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Magnitude-and-phase-aware Speech Enhancement with Parallel Sequence\n  Modeling", "abstract": "In speech enhancement (SE), phase estimation is important for perceptual\nquality, so many methods take clean speech's complex short-time Fourier\ntransform (STFT) spectrum or the complex ideal ratio mask (cIRM) as the\nlearning target. To predict these complex targets, the common solution is to\ndesign a complex neural network, or use a real network to separately predict\nthe real and imaginary parts of the target. But in this paper, we propose to\nuse a real network to estimate the magnitude mask and normalized cIRM, which\nnot only avoids the significant increase of the model complexity caused by\ncomplex networks, but also shows better performance than previous phase\nestimation methods. Meanwhile, we devise a parallel sequence modeling (PSM)\nblock to improve the RNN block in the convolutional recurrent network\n(CRN)-based SE model. We name our method as magnitude-and-phase-aware and\nPSM-based CRN (MPCRN). The experimental results illustrate that our MPCRN has\nsuperior SE performance.", "published": "2023-10-11 09:03:42", "link": "http://arxiv.org/abs/2310.07316v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Damping Density of an Absorptive Shoebox Room Derived from the\n  Image-Source Method", "abstract": "The image-source method is widely applied to compute room impulse responses\n(RIRs) of shoebox rooms with arbitrary absorption. However, with increasing RIR\nlengths, the number of image sources grows rapidly, leading to slow\ncomputation. In this paper, we derive a closed-form expression for the damping\ndensity, which characterizes the overall multi-slope energy decay. The\nomnidirectional energy decay over time is directly derived from the damping\ndensity. The resulting energy decay model accurately matches the late\nreverberation simulated via the image-source method. The proposed model allows\nthe fast stochastic synthesis of late reverberation by shaping noise with the\nenergy envelope. Simulations of various wall damping coefficients demonstrate\nthe model's accuracy. The proposed model consistently outperforms the energy\ndecay prediction accuracy compared to a state-of-the-art approximation method.\nThe paper elaborates on the proposed damping density's applicability to\nmodeling multi-sloped sound energy decay, predicting reverberation time in\nnon-diffuse sound fields, and fast frequency-dependent RIR synthesis.", "published": "2023-10-11 10:25:35", "link": "http://arxiv.org/abs/2310.07363v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Vec-Tok Speech: speech vectorization and tokenization for neural speech\n  generation", "abstract": "Language models (LMs) have recently flourished in natural language processing\nand computer vision, generating high-fidelity texts or images in various tasks.\nIn contrast, the current speech generative models are still struggling\nregarding speech quality and task generalization. This paper presents Vec-Tok\nSpeech, an extensible framework that resembles multiple speech generation\ntasks, generating expressive and high-fidelity speech. Specifically, we propose\na novel speech codec based on speech vectors and semantic tokens. Speech\nvectors contain acoustic details contributing to high-fidelity speech\nreconstruction, while semantic tokens focus on the linguistic content of\nspeech, facilitating language modeling. Based on the proposed speech codec,\nVec-Tok Speech leverages an LM to undertake the core of speech generation.\nMoreover, Byte-Pair Encoding (BPE) is introduced to reduce the token length and\nbit rate for lower exposure bias and longer context coverage, improving the\nperformance of LMs. Vec-Tok Speech can be used for intra- and cross-lingual\nzero-shot voice conversion (VC), zero-shot speaking style transfer\ntext-to-speech (TTS), speech-to-speech translation (S2ST), speech denoising,\nand speaker de-identification and anonymization. Experiments show that Vec-Tok\nSpeech, built on 50k hours of speech, performs better than other SOTA models.\nCode will be available at https://github.com/BakerBunker/VecTok .", "published": "2023-10-11 07:23:27", "link": "http://arxiv.org/abs/2310.07246v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LLark: A Multimodal Instruction-Following Language Model for Music", "abstract": "Music has a unique and complex structure which is challenging for both expert\nhumans and existing AI systems to understand, and presents unique challenges\nrelative to other forms of audio. We present LLark, an instruction-tuned\nmultimodal model for \\emph{music} understanding. We detail our process for\ndataset creation, which involves augmenting the annotations of diverse\nopen-source music datasets and converting them to a unified instruction-tuning\nformat. We propose a multimodal architecture for LLark, integrating a\npretrained generative model for music with a pretrained language model. In\nevaluations on three types of tasks (music understanding, captioning,\nreasoning), we show that LLark matches or outperforms existing baselines in\nmusic understanding, and that humans show a high degree of agreement with its\nresponses in captioning and reasoning tasks. LLark is trained entirely from\nopen-source music data and models, and we make our training code available\nalong with the release of this paper. Additional results and audio examples are\nat https://bit.ly/llark, and our source code is available at\nhttps://github.com/spotify-research/llark .", "published": "2023-10-11 03:12:47", "link": "http://arxiv.org/abs/2310.07160v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Video Inpainting Guided by Audio-Visual Self-Supervision", "abstract": "Humans can easily imagine a scene from auditory information based on their\nprior knowledge of audio-visual events. In this paper, we mimic this innate\nhuman ability in deep learning models to improve the quality of video\ninpainting. To implement the prior knowledge, we first train the audio-visual\nnetwork, which learns the correspondence between auditory and visual\ninformation. Then, the audio-visual network is employed as a guider that\nconveys the prior knowledge of audio-visual correspondence to the video\ninpainting network. This prior knowledge is transferred through our proposed\ntwo novel losses: audio-visual attention loss and audio-visual pseudo-class\nconsistency loss. These two losses further improve the performance of the video\ninpainting by encouraging the inpainting result to have a high correspondence\nto its synchronized audio. Experimental results demonstrate that our proposed\nmethod can restore a wider domain of video scenes and is particularly effective\nwhen the sounding object in the scene is partially blinded.", "published": "2023-10-11 17:03:21", "link": "http://arxiv.org/abs/2310.07663v1", "categories": ["eess.AS", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
