{"title": "Matching Natural Language Sentences with Hierarchical Sentence\n  Factorization", "abstract": "Semantic matching of natural language sentences or identifying the\nrelationship between two sentences is a core research problem underlying many\nnatural language tasks. Depending on whether training data is available, prior\nresearch has proposed both unsupervised distance-based schemes and supervised\ndeep learning schemes for sentence matching. However, previous approaches\neither omit or fail to fully utilize the ordered, hierarchical, and flexible\nstructures of language objects, as well as the interactions between them. In\nthis paper, we propose Hierarchical Sentence Factorization---a technique to\nfactorize a sentence into a hierarchical representation, with the components at\neach different scale reordered into a \"predicate-argument\" form. The proposed\nsentence factorization technique leads to the invention of: 1) a new\nunsupervised distance metric which calculates the semantic distance between a\npair of text snippets by solving a penalized optimal transport problem while\npreserving the logical relationship of words in the reordered sentences, and 2)\nnew multi-scale deep learning models for supervised semantic training, based on\nfactorized sentence hierarchies. We apply our techniques to text-pair\nsimilarity estimation and text-pair relationship classification tasks, based on\nmultiple datasets such as STSbenchmark, the Microsoft Research paraphrase\nidentification (MSRP) dataset, the SICK dataset, etc. Extensive experiments\nshow that the proposed hierarchical sentence factorization can be used to\nsignificantly improve the performance of existing unsupervised distance-based\nmetrics as well as multiple supervised deep learning models based on the\nconvolutional neural network (CNN) and long short-term memory (LSTM).", "published": "2018-03-01 02:48:47", "link": "http://arxiv.org/abs/1803.00179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XNMT: The eXtensible Neural Machine Translation Toolkit", "abstract": "This paper describes XNMT, the eXtensible Neural Machine Translation toolkit.\nXNMT distin- guishes itself from other open-source NMT toolkits by its focus on\nmodular code design, with the purpose of enabling fast iteration in research\nand replicable, reliable results. In this paper we describe the design of XNMT\nand its experiment configuration system, and demonstrate its utility on the\ntasks of machine translation, speech recognition, and multi-tasked machine\ntranslation/parsing. XNMT is available open-source at\nhttps://github.com/neulab/xnmt", "published": "2018-03-01 03:14:54", "link": "http://arxiv.org/abs/1803.00188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Yuanfudao at SemEval-2018 Task 11: Three-way Attention and Relational\n  Knowledge for Commonsense Machine Comprehension", "abstract": "This paper describes our system for SemEval-2018 Task 11: Machine\nComprehension using Commonsense Knowledge. We use Three-way Attentive Networks\n(TriAN) to model interactions between the passage, question and answers. To\nincorporate commonsense knowledge, we augment the input with relation embedding\nfrom the graph of general knowledge ConceptNet (Speer et al., 2017). As a\nresult, our system achieves state-of-the-art performance with 83.95% accuracy\non the official test data. Code is publicly available at\nhttps://github.com/intfloat/commonsense-rc", "published": "2018-03-01 03:23:55", "link": "http://arxiv.org/abs/1803.00191v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Training for Neural Machine Translation Models with Monolingual\n  Data", "abstract": "Monolingual data have been demonstrated to be helpful in improving\ntranslation quality of both statistical machine translation (SMT) systems and\nneural machine translation (NMT) systems, especially in resource-poor or domain\nadaptation tasks where parallel data are not rich enough. In this paper, we\npropose a novel approach to better leveraging monolingual data for neural\nmachine translation by jointly learning source-to-target and target-to-source\nNMT models for a language pair with a joint EM optimization method. The\ntraining process starts with two initial NMT models pre-trained on parallel\ndata for each direction, and these two models are iteratively updated by\nincrementally decreasing translation losses on training data. In each iteration\nstep, both NMT models are first used to translate monolingual data from one\nlanguage to the other, forming pseudo-training data of the other NMT model.\nThen two new NMT models are learnt from parallel data together with the pseudo\ntraining data. Both NMT models are expected to be improved and better\npseudo-training data can be generated in next step. Experiment results on\nChinese-English and English-German translation tasks show that our approach can\nsimultaneously improve translation quality of source-to-target and\ntarget-to-source models, significantly outperforming strong baseline systems\nwhich are enhanced with monolingual data for model training including\nback-translation.", "published": "2018-03-01 13:14:35", "link": "http://arxiv.org/abs/1803.00353v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual and Multilingual Speech Emotion Recognition on English and\n  French", "abstract": "Research on multilingual speech emotion recognition faces the problem that\nmost available speech corpora differ from each other in important ways, such as\nannotation methods or interaction scenarios. These inconsistencies complicate\nbuilding a multilingual system. We present results for cross-lingual and\nmultilingual emotion recognition on English and French speech data with similar\ncharacteristics in terms of interaction (human-human conversations). Further,\nwe explore the possibility of fine-tuning a pre-trained cross-lingual model\nwith only a small number of samples from the target language, which is of great\ninterest for low-resource languages. To gain more insights in what is learned\nby the deployed convolutional neural network, we perform an analysis on the\nattention mechanism inside the network.", "published": "2018-03-01 13:40:04", "link": "http://arxiv.org/abs/1803.00357v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Growing Story Forest Online from Massive Breaking News", "abstract": "We describe our experience of implementing a news content organization system\nat Tencent that discovers events from vast streams of breaking news and evolves\nnews story structures in an online fashion. Our real-world system has distinct\nrequirements in contrast to previous studies on topic detection and tracking\n(TDT) and event timeline or graph generation, in that we 1) need to accurately\nand quickly extract distinguishable events from massive streams of long text\ndocuments that cover diverse topics and contain highly redundant information,\nand 2) must develop the structures of event stories in an online manner,\nwithout repeatedly restructuring previously formed stories, in order to\nguarantee a consistent user viewing experience. In solving these challenges, we\npropose Story Forest, a set of online schemes that automatically clusters\nstreaming documents into events, while connecting related events in growing\ntrees to tell evolving stories. We conducted extensive evaluation based on 60\nGB of real-world Chinese news data, although our ideas are not\nlanguage-dependent and can easily be extended to other languages, through\ndetailed pilot user experience studies. The results demonstrate the superior\ncapability of Story Forest to accurately identify events and organize news text\ninto a logical structure that is appealing to human readers, compared to\nmultiple existing algorithm frameworks.", "published": "2018-03-01 03:15:10", "link": "http://arxiv.org/abs/1803.00189v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Collaborative Metric Learning Recommendation System: Application to\n  Theatrical Movie Releases", "abstract": "Product recommendation systems are important for major movie studios during\nthe movie greenlight process and as part of machine learning personalization\npipelines. Collaborative Filtering (CF) models have proved to be effective at\npowering recommender systems for online streaming services with explicit\ncustomer feedback data. CF models do not perform well in scenarios in which\nfeedback data is not available, in cold start situations like new product\nlaunches, and situations with markedly different customer tiers (e.g., high\nfrequency customers vs. casual customers). Generative natural language models\nthat create useful theme-based representations of an underlying corpus of\ndocuments can be used to represent new product descriptions, like new movie\nplots. When combined with CF, they have shown to increase the performance in\ncold start situations. Outside of those cases though in which explicit customer\nfeedback is available, recommender engines must rely on binary purchase data,\nwhich materially degrades performance. Fortunately, purchase data can be\ncombined with product descriptions to generate meaningful representations of\nproducts and customer trajectories in a convenient product space in which\nproximity represents similarity. Learning to measure the distance between\npoints in this space can be accomplished with a deep neural network that trains\non customer histories and on dense vectorizations of product descriptions. We\ndeveloped a system based on Collaborative (Deep) Metric Learning (CML) to\npredict the purchase probabilities of new theatrical releases. We trained and\nevaluated the model using a large dataset of customer histories, and tested the\nmodel for a set of movies that were released outside of the training window.\nInitial experiments show gains relative to models that do not train on\ncollaborative preferences.", "published": "2018-03-01 04:04:35", "link": "http://arxiv.org/abs/1803.00202v1", "categories": ["cs.IR", "cs.CL", "68T05, 68T50"], "primary_category": "cs.IR"}
{"title": "A Deep Learning Approach for Multimodal Deception Detection", "abstract": "Automatic deception detection is an important task that has gained momentum\nin computational linguistics due to its potential applications. In this paper,\nwe propose a simple yet tough to beat multi-modal neural model for deception\ndetection. By combining features from different modalities such as video,\naudio, and text along with Micro-Expression features, we show that detecting\ndeception in real life videos can be more accurate. Experimental results on a\ndataset of real-life deception videos show that our model outperforms existing\ntechniques for deception detection with an accuracy of 96.14% and ROC-AUC of\n0.9799.", "published": "2018-03-01 12:38:13", "link": "http://arxiv.org/abs/1803.00344v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Mode Domain Spatial Active Noise Control Using Sparse Signal\n  Representation", "abstract": "Active noise control (ANC) over a sizeable space requires a large number of\nreference and error microphones to satisfy the spatial Nyquist sampling\ncriterion, which limits the feasibility of practical realization of such\nsystems. This paper proposes a mode-domain feedforward ANC method to attenuate\nthe noise field over a large space while reducing the number of microphones\nrequired. We adopt a sparse reference signal representation to precisely\ncalculate the reference mode coefficients. The proposed system consists of\ncircular reference and error microphone arrays, which capture the reference\nnoise signal and residual error signal, respectively, and a circular\nloudspeaker array to drive the anti-noise signal. Experimental results indicate\nthat above the spatial Nyquist frequency,our proposed method can perform well\ncompared to a conventional methods. Moreover, the proposed method can even\nreduce the number of reference microphones while achieving better noise\nattenuation.", "published": "2018-03-01 03:12:15", "link": "http://arxiv.org/abs/1803.00187v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
