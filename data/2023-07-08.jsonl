{"title": "Answering Ambiguous Questions via Iterative Prompting", "abstract": "In open-domain question answering, due to the ambiguity of questions,\nmultiple plausible answers may exist. To provide feasible answers to an\nambiguous question, one approach is to directly predict all valid answers, but\nthis can struggle with balancing relevance and diversity. An alternative is to\ngather candidate answers and aggregate them, but this method can be\ncomputationally costly and may neglect dependencies among answers. In this\npaper, we present AmbigPrompt to address the imperfections of existing\napproaches to answering ambiguous questions. Specifically, we integrate an\nanswering model with a prompting model in an iterative manner. The prompting\nmodel adaptively tracks the reading process and progressively triggers the\nanswering model to compose distinct and relevant answers. Additionally, we\ndevelop a task-specific post-pretraining approach for both the answering model\nand the prompting model, which greatly improves the performance of our\nframework. Empirical studies on two commonly-used open benchmarks show that\nAmbigPrompt achieves state-of-the-art or competitive results while using less\nmemory and having a lower inference latency than competing approaches.\nAdditionally, AmbigPrompt also performs well in low-resource settings. The code\nare available at: https://github.com/sunnweiwei/AmbigPrompt.", "published": "2023-07-08 04:32:17", "link": "http://arxiv.org/abs/2307.03897v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is ChatGPT a Good Personality Recognizer? A Preliminary Study", "abstract": "In recent years, personality has been regarded as a valuable personal factor\nbeing incorporated into numerous tasks such as sentiment analysis and product\nrecommendation. This has led to widespread attention to text-based personality\nrecognition task, which aims to identify an individual's personality based on\ngiven text. Considering that ChatGPT has recently exhibited remarkable\nabilities on various natural language processing tasks, we provide a\npreliminary evaluation of ChatGPT on text-based personality recognition task\nfor generating effective personality data. Concretely, we employ a variety of\nprompting strategies to explore ChatGPT's ability in recognizing personality\nfrom given text, especially the level-oriented prompting strategy we designed\nfor guiding ChatGPT in analyzing given text at a specified level. The\nexperimental results on two representative real-world datasets reveal that\nChatGPT with zero-shot chain-of-thought prompting exhibits impressive\npersonality recognition ability and is capable to provide natural language\nexplanations through text-based logical reasoning. Furthermore, by employing\nthe level-oriented prompting strategy to optimize zero-shot chain-of-thought\nprompting, the performance gap between ChatGPT and corresponding\nstate-of-the-art model has been narrowed even more. However, we observe that\nChatGPT shows unfairness towards certain sensitive demographic attributes such\nas gender and age. Additionally, we discover that eliciting the personality\nrecognition ability of ChatGPT helps improve its performance on\npersonality-related downstream tasks such as sentiment classification and\nstress prediction.", "published": "2023-07-08 11:02:02", "link": "http://arxiv.org/abs/2307.03952v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Capability of Large-scale Language Models on Chinese\n  Grammatical Error Correction Task", "abstract": "Large-scale language models (LLMs) has shown remarkable capability in various\nof Natural Language Processing (NLP) tasks and attracted lots of attention\nrecently. However, some studies indicated that large language models fail to\nachieve promising result beyond the state-of-the-art models in English\ngrammatical error correction (GEC) tasks. In this report, we aim to explore the\nhow large language models perform on Chinese grammatical error correction tasks\nand provide guidance for future work. We conduct experiments with 3 different\nLLMs of different model scale on 4 Chinese GEC dataset. Our experimental\nresults indicate that the performances of LLMs on automatic evaluation metrics\nfalls short of the previous sota models because of the problem of\nover-correction. Furthermore, we also discover notable variations in the\nperformance of LLMs when evaluated on different data distributions. Our\nfindings demonstrates that further investigation is required for the\napplication of LLMs on Chinese GEC task.", "published": "2023-07-08 13:10:59", "link": "http://arxiv.org/abs/2307.03972v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of\n  LLMs by Validating Low-Confidence Generation", "abstract": "Recently developed large language models have achieved remarkable success in\ngenerating fluent and coherent text. However, these models often tend to\n'hallucinate' which critically hampers their reliability. In this work, we\naddress this crucial problem and propose an approach that actively detects and\nmitigates hallucinations during the generation process. Specifically, we first\nidentify the candidates of potential hallucination leveraging the model's logit\noutput values, check their correctness through a validation procedure, mitigate\nthe detected hallucinations, and then continue with the generation process.\nThrough extensive experiments with GPT-3.5 (text-davinci-003) on the 'article\ngeneration task', we first demonstrate the individual efficacy of our detection\nand mitigation techniques. Specifically, the detection technique achieves a\nrecall of ~88% and the mitigation technique successfully mitigates 57.6% of the\ncorrectly detected hallucinations. Importantly, our mitigation technique does\nnot introduce new hallucinations even in the case of incorrectly detected\nhallucinations, i.e., false positives. Then, we show that the proposed active\ndetection and mitigation approach successfully reduces the hallucinations of\nthe GPT-3.5 model from 47.5% to 14.5% on average. We further demonstrate the\neffectiveness and wide applicability of our approach through additional studies\nincluding performance on different types of questions (multi-hop and false\npremise questions) and with another LLM from a different model family (Vicuna).\nIn summary, our work contributes to improving the reliability and\ntrustworthiness of large language models, a crucial step en route to enabling\ntheir widespread adoption in real-world applications.", "published": "2023-07-08 14:25:57", "link": "http://arxiv.org/abs/2307.03987v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Interactive Dictation", "abstract": "Voice dictation is an increasingly important text input modality. Existing\nsystems that allow both dictation and editing-by-voice restrict their command\nlanguage to flat templates invoked by trigger words. In this work, we study the\nfeasibility of allowing users to interrupt their dictation with spoken editing\ncommands in open-ended natural language. We introduce a new task and dataset,\nTERTiUS, to experiment with such systems. To support this flexibility in\nreal-time, a system must incrementally segment and classify spans of speech as\neither dictation or command, and interpret the spans that are commands. We\nexperiment with using large pre-trained language models to predict the edited\ntext, or alternatively, to predict a small text-editing program. Experiments\nshow a natural trade-off between model accuracy and latency: a smaller model\nachieves 30% end-state accuracy with 1.3 seconds of latency, while a larger\nmodel achieves 55% end-state accuracy with 7 seconds of latency.", "published": "2023-07-08 16:30:13", "link": "http://arxiv.org/abs/2307.04008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting Cross-Lingual Summarization: A Corpus-based Study and A New\n  Benchmark with Improved Annotation", "abstract": "Most existing cross-lingual summarization (CLS) work constructs CLS corpora\nby simply and directly translating pre-annotated summaries from one language to\nanother, which can contain errors from both summarization and translation\nprocesses. To address this issue, we propose ConvSumX, a cross-lingual\nconversation summarization benchmark, through a new annotation schema that\nexplicitly considers source input context. ConvSumX consists of 2 sub-tasks\nunder different real-world scenarios, with each covering 3 language directions.\nWe conduct thorough analysis on ConvSumX and 3 widely-used manually annotated\nCLS corpora and empirically find that ConvSumX is more faithful towards input\ntext. Additionally, based on the same intuition, we propose a 2-Step method,\nwhich takes both conversation and summary as input to simulate human annotation\nprocess. Experimental results show that 2-Step method surpasses strong\nbaselines on ConvSumX under both automatic and human evaluation. Analysis shows\nthat both source input text and summary are crucial for modeling cross-lingual\nsummaries.", "published": "2023-07-08 17:20:56", "link": "http://arxiv.org/abs/2307.04018v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How is Fatherhood Framed Online in Singapore?", "abstract": "The proliferation of discussion about fatherhood in Singapore attests to its\nsignificance, indicating the need for an exploration of how fatherhood is\nframed, aiding policy-making around fatherhood in Singapore. Sound and holistic\npolicy around fatherhood in Singapore may reduce stigma and apprehension around\nbeing a parent, critical to improving the nations flagging birth rate. We\nanalyzed 15,705 articles and 56,221 posts to study how fatherhood is framed in\nSingapore across a range of online platforms (news outlets, parenting forums,\nTwitter). We used NLP techniques to understand these differences. While\nfatherhood was framed in a range of ways on the Singaporean online environment,\nit did not seem that fathers were framed as central to the Singaporean family\nunit. A strength of our work is how the different techniques we have applied\nvalidate each other.", "published": "2023-07-08 22:03:00", "link": "http://arxiv.org/abs/2307.04053v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Opening up ChatGPT: Tracking openness, transparency, and accountability\n  in instruction-tuned text generators", "abstract": "Large language models that exhibit instruction-following behaviour represent\none of the biggest recent upheavals in conversational interfaces, a trend in\nlarge part fuelled by the release of OpenAI's ChatGPT, a proprietary large\nlanguage model for text generation fine-tuned through reinforcement learning\nfrom human feedback (LLM+RLHF). We review the risks of relying on proprietary\nsoftware and survey the first crop of open-source projects of comparable\narchitecture and functionality. The main contribution of this paper is to show\nthat openness is differentiated, and to offer scientific documentation of\ndegrees of openness in this fast-moving field. We evaluate projects in terms of\nopenness of code, training data, model weights, RLHF data, licensing,\nscientific documentation, and access methods. We find that while there is a\nfast-growing list of projects billing themselves as 'open source', many inherit\nundocumented data of dubious legality, few share the all-important\ninstruction-tuning (a key site where human annotation labour is involved), and\ncareful scientific documentation is exceedingly rare. Degrees of openness are\nrelevant to fairness and accountability at all points, from data collection and\ncuration to model architecture, and from training and fine-tuning to release\nand deployment.", "published": "2023-07-08 07:08:20", "link": "http://arxiv.org/abs/2307.05532v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancements in Scientific Controllable Text Generation Methods", "abstract": "The previous work on controllable text generation is organized using a new\nschema we provide in this study. Seven components make up the schema, and each\none is crucial to the creation process. To accomplish controlled generation for\nscientific literature, we describe the various modulation strategies utilised\nto modulate each of the seven components. We also offer a theoretical study and\nqualitative examination of these methods. This insight makes possible new\narchitectures based on combinations of these components. Future research will\ncompare these methods empirically to learn more about their strengths and\nutility.", "published": "2023-07-08 15:22:29", "link": "http://arxiv.org/abs/2307.05538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs be Good Financial Advisors?: An Initial Study in Personal\n  Decision Making for Optimized Outcomes", "abstract": "Increasingly powerful Large Language Model (LLM) based chatbots, like ChatGPT\nand Bard, are becoming available to users that have the potential to\nrevolutionize the quality of decision-making achieved by the public. In this\ncontext, we set out to investigate how such systems perform in the personal\nfinance domain, where financial inclusion has been an overarching stated aim of\nbanks for decades. We asked 13 questions representing banking products in\npersonal finance: bank account, credit card, and certificate of deposits and\ntheir inter-product interactions, and decisions related to high-value\npurchases, payment of bank dues, and investment advice, and in different\ndialects and languages (English, African American Vernacular English, and\nTelugu). We find that although the outputs of the chatbots are fluent and\nplausible, there are still critical gaps in providing accurate and reliable\nfinancial information using LLM-based chatbots.", "published": "2023-07-08 17:21:55", "link": "http://arxiv.org/abs/2307.07422v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embedding Mental Health Discourse for Community Recommendation", "abstract": "Our paper investigates the use of discourse embedding techniques to develop a\ncommunity recommendation system that focuses on mental health support groups on\nsocial media. Social media platforms provide a means for users to anonymously\nconnect with communities that cater to their specific interests. However, with\nthe vast number of online communities available, users may face difficulties in\nidentifying relevant groups to address their mental health concerns. To address\nthis challenge, we explore the integration of discourse information from\nvarious subreddit communities using embedding techniques to develop an\neffective recommendation system. Our approach involves the use of content-based\nand collaborative filtering techniques to enhance the performance of the\nrecommendation system. Our findings indicate that the proposed approach\noutperforms the use of each technique separately and provides interpretability\nin the recommendation process.", "published": "2023-07-08 03:59:58", "link": "http://arxiv.org/abs/2307.03892v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Incomplete Utterance Rewriting as Sequential Greedy Tagging", "abstract": "The task of incomplete utterance rewriting has recently gotten much\nattention. Previous models struggled to extract information from the dialogue\ncontext, as evidenced by the low restoration scores. To address this issue, we\npropose a novel sequence tagging-based model, which is more adept at extracting\ninformation from context. Meanwhile, we introduce speaker-aware embedding to\nmodel speaker variation. Experiments on multiple public datasets show that our\nmodel achieves optimal results on all nine restoration scores while having\nother metric scores comparable to previous state-of-the-art models.\nFurthermore, benefitting from the model's simplicity, our approach outperforms\nmost previous models on inference speed.", "published": "2023-07-08 04:05:04", "link": "http://arxiv.org/abs/2307.06337v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Models for Supply Chain Optimization", "abstract": "Supply chain operations traditionally involve a variety of complex decision\nmaking problems. Over the last few decades, supply chains greatly benefited\nfrom advances in computation, which allowed the transition from manual\nprocessing to automation and cost-effective optimization. Nonetheless, business\noperators still need to spend substantial efforts in explaining and\ninterpreting the optimization outcomes to stakeholders. Motivated by the recent\nadvances in Large Language Models (LLMs), we study how this disruptive\ntechnology can help bridge the gap between supply chain automation and human\ncomprehension and trust thereof. We design OptiGuide -- a framework that\naccepts as input queries in plain text, and outputs insights about the\nunderlying optimization outcomes. Our framework does not forgo the\nstate-of-the-art combinatorial optimization technology, but rather leverages it\nto quantitatively answer what-if scenarios (e.g., how would the cost change if\nwe used supplier B instead of supplier A for a given demand?). Importantly, our\ndesign does not require sending proprietary data over to LLMs, which can be a\nprivacy concern in some circumstances. We demonstrate the effectiveness of our\nframework on a real server placement scenario within Microsoft's cloud supply\nchain. Along the way, we develop a general evaluation benchmark, which can be\nused to evaluate the accuracy of the LLM output in other scenarios.", "published": "2023-07-08 01:42:22", "link": "http://arxiv.org/abs/2307.03875v2", "categories": ["cs.AI", "cs.CL", "cs.DM", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ScriptWorld: Text Based Environment For Learning Procedural Knowledge", "abstract": "Text-based games provide a framework for developing natural language\nunderstanding and commonsense knowledge about the world in reinforcement\nlearning based agents. Existing text-based environments often rely on fictional\nsituations and characters to create a gaming framework and are far from\nreal-world scenarios. In this paper, we introduce ScriptWorld: a text-based\nenvironment for teaching agents about real-world daily chores and hence\nimparting commonsense knowledge. To the best of our knowledge, it is the first\ninteractive text-based gaming framework that consists of daily real-world human\nactivities designed using scripts dataset. We provide gaming environments for\n10 daily activities and perform a detailed analysis of the proposed\nenvironment. We develop RL-based baseline models/agents to play the games in\nScriptworld. To understand the role of language models in such environments, we\nleverage features obtained from pre-trained language models in the RL agents.\nOur experiments show that prior knowledge obtained from a pre-trained language\nmodel helps to solve real-world text-based gaming environments. We release the\nenvironment via Github: https://github.com/Exploration-Lab/ScriptWorld", "published": "2023-07-08 05:43:03", "link": "http://arxiv.org/abs/2307.03906v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "On decoder-only architecture for speech-to-text and large language model\n  integration", "abstract": "Large language models (LLMs) have achieved remarkable success in the field of\nnatural language processing, enabling better human-computer interaction using\nnatural language. However, the seamless integration of speech signals into LLMs\nhas not been explored well. The \"decoder-only\" architecture has also not been\nwell studied for speech processing tasks. In this research, we introduce\nSpeech-LLaMA, a novel approach that effectively incorporates acoustic\ninformation into text-based large language models. Our method leverages\nConnectionist Temporal Classification and a simple audio encoder to map the\ncompressed acoustic features to the continuous semantic space of the LLM. In\naddition, we further probe the decoder-only architecture for speech-to-text\ntasks by training a smaller scale randomly initialized speech-LLaMA model from\nspeech-text paired data alone. We conduct experiments on multilingual\nspeech-to-text translation tasks and demonstrate a significant improvement over\nstrong baselines, highlighting the potential advantages of decoder-only models\nfor speech-to-text conversion.", "published": "2023-07-08 06:47:58", "link": "http://arxiv.org/abs/2307.03917v3", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Right to be Forgotten in the Era of Large Language Models: Implications,\n  Challenges, and Solutions", "abstract": "The Right to be Forgotten (RTBF) was first established as the result of the\nruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\\'alez, and\nwas later included as the Right to Erasure under the General Data Protection\nRegulation (GDPR) of European Union to allow individuals the right to request\npersonal data be deleted by organizations. Specifically for search engines,\nindividuals can send requests to organizations to exclude their information\nfrom the query results. It was a significant emergent right as the result of\nthe evolution of technology. With the recent development of Large Language\nModels (LLMs) and their use in chatbots, LLM-enabled software systems have\nbecome popular. But they are not excluded from the RTBF. Compared with the\nindexing approach used by search engines, LLMs store, and process information\nin a completely different way. This poses new challenges for compliance with\nthe RTBF. In this paper, we explore these challenges and provide our insights\non how to implement technical solutions for the RTBF, including the use of\ndifferential privacy, machine unlearning, model editing, and guardrails. With\nthe rapid advancement of AI and the increasing need of regulating this powerful\ntechnology, learning from the case of RTBF can provide valuable lessons for\ntechnical practitioners, legal experts, organizations, and authorities.", "published": "2023-07-08 09:28:50", "link": "http://arxiv.org/abs/2307.03941v4", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Bidirectional Attention as a Mixture of Continuous Word Experts", "abstract": "Bidirectional attention $\\unicode{x2013}$ composed of self-attention with\npositional encodings and the masked language model (MLM) objective\n$\\unicode{x2013}$ has emerged as a key component of modern large language\nmodels (LLMs). Despite its empirical success, few studies have examined its\nstatistical underpinnings: What statistical model is bidirectional attention\nimplicitly fitting? What sets it apart from its non-attention predecessors? We\nexplore these questions in this paper. The key observation is that fitting a\nsingle-layer single-head bidirectional attention, upon reparameterization, is\nequivalent to fitting a continuous bag of words (CBOW) model with\nmixture-of-experts (MoE) weights. Further, bidirectional attention with\nmultiple heads and multiple layers is equivalent to stacked MoEs and a mixture\nof MoEs, respectively. This statistical viewpoint reveals the distinct use of\nMoE in bidirectional attention, which aligns with its practical effectiveness\nin handling heterogeneous data. It also suggests an immediate extension to\ncategorical tabular data, if we view each word location in a sentence as a\ntabular feature. Across empirical studies, we find that this extension\noutperforms existing tabular extensions of transformers in out-of-distribution\n(OOD) generalization. Finally, this statistical perspective of bidirectional\nattention enables us to theoretically characterize when linear word analogies\nare present in its word embeddings. These analyses show that bidirectional\nattention can require much stronger assumptions to exhibit linear word\nanalogies than its non-attention predecessors.", "published": "2023-07-08 23:25:55", "link": "http://arxiv.org/abs/2307.04057v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Anti-noise window: Subjective perception of active noise reduction and\n  effect of informational masking", "abstract": "Reviving natural ventilation (NV) for urban sustainability presents\nchallenges for indoor acoustic comfort. Active control and interference-based\nnoise mitigation strategies, such as the use of loudspeakers, offer potential\nsolutions to achieve acoustic comfort while maintaining NV. However, these\napproaches are not commonly integrated or evaluated from a perceptual\nstandpoint. This study examines the perceptual and objective aspects of an\nactive-noise-control (ANC)-based \"anti-noise\" window (ANW) and its integration\nwith informational masking (IM) in a model bedroom. Forty participants assessed\nthe ANW in a three-way interaction involving noise types (traffic, train, and\naircraft), maskers (bird, water), and ANC (on, off). The evaluation focused on\nperceived annoyance (PAY; ISO/TS 15666), perceived affective quality (ISO/TS\n12913-2), loudness (PLN), and included an open-ended qualitative assessment.\nDespite minimal objective reduction in decibel-based indicators and a slight\nincrease in psychoacoustic sharpness, the ANW alone demonstrated significant\nreductions in PAY and PLN, as well as an improvement in ISO pleasantness across\nall noise types. The addition of maskers generally enhanced overall acoustic\ncomfort, although water masking led to increased PLN. Furthermore, the\ncombination of ANC with maskers showed interaction effects, with both maskers\nsignificantly reducing PAY compared to ANC alone.", "published": "2023-07-08 07:39:23", "link": "http://arxiv.org/abs/2307.05533v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Emotion-Guided Music Accompaniment Generation Based on Variational\n  Autoencoder", "abstract": "Music accompaniment generation is a crucial aspect in the composition\nprocess. Deep neural networks have made significant strides in this field, but\nit remains a challenge for AI to effectively incorporate human emotions to\ncreate beautiful accompaniments. Existing models struggle to effectively\ncharacterize human emotions within neural network models while composing music.\nTo address this issue, we propose the use of an easy-to-represent emotion flow\nmodel, the Valence/Arousal Curve, which allows for the compatibility of\nemotional information within the model through data transformation and enhances\ninterpretability of emotional factors by utilizing a Variational Autoencoder as\nthe model structure. Further, we used relative self-attention to maintain the\nstructure of the music at music phrase level and to generate a richer\naccompaniment when combined with the rules of music theory.", "published": "2023-07-08 16:47:31", "link": "http://arxiv.org/abs/2307.04015v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
