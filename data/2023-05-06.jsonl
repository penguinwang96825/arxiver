{"title": "NorBench -- A Benchmark for Norwegian Language Models", "abstract": "We present NorBench: a streamlined suite of NLP tasks and probes for\nevaluating Norwegian language models (LMs) on standardized data splits and\nevaluation metrics. We also introduce a range of new Norwegian language models\n(both encoder and encoder-decoder based). Finally, we compare and analyze their\nperformance, along with other existing LMs, across the different benchmark\ntests of NorBench.", "published": "2023-05-06 00:20:24", "link": "http://arxiv.org/abs/2305.03880v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Label-Free Multi-Domain Machine Translation with Stage-wise Training", "abstract": "Most multi-domain machine translation models rely on domain-annotated data.\nUnfortunately, domain labels are usually unavailable in both training processes\nand real translation scenarios. In this work, we propose a label-free\nmulti-domain machine translation model which requires only a few or no\ndomain-annotated data in training and no domain labels in inference. Our model\nis composed of three parts: a backbone model, a domain discriminator taking\nresponsibility to discriminate data from different domains, and a set of\nexperts that transfer the decoded features from generic to specific. We design\na stage-wise training strategy and train the three parts sequentially. To\nleverage the extra domain knowledge and improve the training stability, in the\ndiscriminator training stage, domain differences are modeled explicitly with\nclustering and distilled into the discriminator through a multi-classification\ntask. Meanwhile, the Gumbel-Max sampling is adopted as the routing scheme in\nthe expert training stage to achieve the balance of each expert in\nspecialization and generalization. Experimental results on the\nGerman-to-English translation task show that our model significantly improves\nBLEU scores on six different domains and even outperforms most of the models\ntrained with domain-annotated data.", "published": "2023-05-06 06:30:29", "link": "http://arxiv.org/abs/2305.03949v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NER-to-MRC: Named-Entity Recognition Completely Solving as Machine\n  Reading Comprehension", "abstract": "Named-entity recognition (NER) detects texts with predefined semantic labels\nand is an essential building block for natural language processing (NLP).\nNotably, recent NER research focuses on utilizing massive extra data, including\npre-training corpora and incorporating search engines. However, these methods\nsuffer from high costs associated with data collection and pre-training, and\nadditional training process of the retrieved data from search engines. To\naddress the above challenges, we completely frame NER as a machine reading\ncomprehension (MRC) problem, called NER-to-MRC, by leveraging MRC with its\nability to exploit existing data efficiently. Several prior works have been\ndedicated to employing MRC-based solutions for tackling the NER problem,\nseveral challenges persist: i) the reliance on manually designed prompts; ii)\nthe limited MRC approaches to data reconstruction, which fails to achieve\nperformance on par with methods utilizing extensive additional data. Thus, our\nNER-to-MRC conversion consists of two components: i) transform the NER task\ninto a form suitable for the model to solve with MRC in a efficient manner; ii)\napply the MRC reasoning strategy to the model. We experiment on 6 benchmark\ndatasets from three domains and achieve state-of-the-art performance without\nexternal data, up to 11.24% improvement on the WNUT-16 dataset.", "published": "2023-05-06 08:05:22", "link": "http://arxiv.org/abs/2305.03970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse\n  Relation Recognition", "abstract": "Implicit Discourse Relation Recognition (IDRR) is a sophisticated and\nchallenging task to recognize the discourse relations between the arguments\nwith the absence of discourse connectives. The sense labels for each discourse\nrelation follow a hierarchical classification scheme in the annotation process\n(Prasad et al., 2008), forming a hierarchy structure. Most existing works do\nnot well incorporate the hierarchy structure but focus on the syntax features\nand the prior knowledge of connectives in the manner of pure text\nclassification. We argue that it is more effective to predict the paths inside\nthe hierarchical tree (e.g., \"Comparison -> Contrast -> however\") rather than\nflat labels (e.g., Contrast) or connectives (e.g., however). We propose a\nprompt-based path prediction method to utilize the interactive information and\nintrinsic senses among the hierarchy in IDRR. This is the first work that\ninjects such structure information into pre-trained language models via prompt\ntuning, and the performance of our solution shows significant and consistent\nimprovement against competitive baselines.", "published": "2023-05-06 08:16:07", "link": "http://arxiv.org/abs/2305.03973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unlocking the Power of GANs in Non-Autoregressive Text Generation", "abstract": "Generative Adversarial Networks (GANs) have been studied in text generation\nto tackle the exposure bias problem. Despite their remarkable development, they\nadopt autoregressive structures so suffering from high latency in both training\nand inference stages. Although GANs have potential to support efficient\ngeneration by adopting non-autoregressive (NAR) structures, their explorations\nin NAR models are extremely limited. In this work, we conduct pioneering study\nof building language GANs based on NAR structures. We identify two issues that\nconstrain the performance of GAN-based NAR models. Firstly, existing methods of\nincorporating latent variables provide highly similar representations which\ncannot describe the diversity of different words in sentences. We tackle this\nproblem by proposing Position-Aware Self-Modulation, providing more diverse and\neffective representations. Secondly, the attention mechanism in Transformer\ncannot accurately build word dependencies in the unstable training of GANs, and\nwe adopt Dependency Feed Forward Network to enhance the model capacity in\ndependency modeling. Armed with these two facilities, we propose a GAN-based\nNAR model, Adversarial Non-autoregressive Transformer (ANT). The experimental\nresults demonstrate that ANT can achieve comparable performance with mainstream\nmodels in a single forward pass and has great potential in various applications\nlike latent interpolation and semi-supervised learning.", "published": "2023-05-06 08:43:33", "link": "http://arxiv.org/abs/2305.03977v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-training Language Model as a Multi-perspective Course Learner", "abstract": "ELECTRA, the generator-discriminator pre-training framework, has achieved\nimpressive semantic construction capability among various downstream tasks.\nDespite the convincing performance, ELECTRA still faces the challenges of\nmonotonous training and deficient interaction. Generator with only masked\nlanguage modeling (MLM) leads to biased learning and label imbalance for\ndiscriminator, decreasing learning efficiency; no explicit feedback loop from\ndiscriminator to generator results in the chasm between these two components,\nunderutilizing the course learning. In this study, a multi-perspective course\nlearning (MCL) method is proposed to fetch a many degrees and visual angles for\nsample-efficient pre-training, and to fully leverage the relationship between\ngenerator and discriminator. Concretely, three self-supervision courses are\ndesigned to alleviate inherent flaws of MLM and balance the label in a\nmulti-perspective way. Besides, two self-correction courses are proposed to\nbridge the chasm between the two encoders by creating a \"correction notebook\"\nfor secondary-supervision. Moreover, a course soups trial is conducted to solve\nthe \"tug-of-war\" dynamics problem of MCL, evolving a stronger pre-trained\nmodel. Experimental results show that our method significantly improves\nELECTRA's average performance by 2.8% and 3.2% absolute points respectively on\nGLUE and SQuAD 2.0 benchmarks, and overshadows recent advanced ELECTRA-style\nmodels under the same settings. The pre-trained MCL model is available at\nhttps://huggingface.co/McmanusChen/MCL-base.", "published": "2023-05-06 09:02:10", "link": "http://arxiv.org/abs/2305.03981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive\n  Text Generation", "abstract": "Recently, continuous diffusion models (CDM) have been introduced into\nnon-autoregressive (NAR) text-to-text generation. However, the discrete nature\nof text increases the difficulty of CDM to generate coherent and fluent texts,\nand also causes the incompatibility problem between CDM and advanced NLP\ntechniques, especially the popular pre-trained language models~(PLMs). To solve\nit, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM)\ninto NAR text-to-text generation and integrates BART to improve the\nperformance. By revising the decoding process of BART and the typical settings\nof DDM, we unify the inference process of BART and the denoising process of DDM\ninto the same NAR masked tokens recovering task. In this way, DDM can rely on\nBART to perform denoising, which can benefit from both the rich pre-learned\nknowledge of BART and the iterative refining paradigm of DDM. Besides, we also\npropose the iterative self-prompting strategy to further improve the generation\nquality. Experimental results on 7 datasets show that our approach can\noutperform competitive NAR methods, and even surpass autoregressive methods.\nOur code and data will be publicly released.", "published": "2023-05-06 13:20:31", "link": "http://arxiv.org/abs/2305.04044v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Actively Discovering New Slots for Task-oriented Conversation", "abstract": "Existing task-oriented conversational search systems heavily rely on domain\nontologies with pre-defined slots and candidate value sets. In practical\napplications, these prerequisites are hard to meet, due to the emerging new\nuser requirements and ever-changing scenarios. To mitigate these issues for\nbetter interaction performance, there are efforts working towards detecting\nout-of-vocabulary values or discovering new slots under unsupervised or\nsemi-supervised learning paradigm. However, overemphasizing on the conversation\ndata patterns alone induces these methods to yield noisy and arbitrary slot\nresults. To facilitate the pragmatic utility, real-world systems tend to\nprovide a stringent amount of human labelling quota, which offers an\nauthoritative way to obtain accurate and meaningful slot assignments.\nNonetheless, it also brings forward the high requirement of utilizing such\nquota efficiently. Hence, we formulate a general new slot discovery task in an\ninformation extraction fashion and incorporate it into an active learning\nframework to realize human-in-the-loop learning. Specifically, we leverage\nexisting language tools to extract value candidates where the corresponding\nlabels are further leveraged as weak supervision signals. Based on these, we\npropose a bi-criteria selection scheme which incorporates two major strategies,\nnamely, uncertainty-based sampling and diversity-based sampling to efficiently\nidentify terms of interest. We conduct extensive experiments on several public\ndatasets and compare with a bunch of competitive baselines to demonstrate the\neffectiveness of our method. We have made the code and data used in this paper\npublicly available.", "published": "2023-05-06 13:33:33", "link": "http://arxiv.org/abs/2305.04049v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Best Defense is Attack: Repairing Semantics in Textual Adversarial\n  Examples", "abstract": "Recent studies have revealed the vulnerability of pre-trained language models\nto adversarial attacks. Existing adversarial defense techniques attempt to\nreconstruct adversarial examples within feature or text spaces. However, these\nmethods struggle to effectively repair the semantics in adversarial examples,\nresulting in unsatisfactory performance and limiting their practical utility.\nTo repair the semantics in adversarial examples, we introduce a novel approach\nnamed Reactive Perturbation Defocusing (Rapid). Rapid employs an adversarial\ndetector to identify fake labels of adversarial examples and leverage\nadversarial attackers to repair the semantics in adversarial examples. Our\nextensive experimental results conducted on four public datasets, convincingly\ndemonstrate the effectiveness of Rapid in various adversarial attack scenarios.\nTo address the problem of defense performance validation in previous works, we\nprovide a demonstration of adversarial detection and repair based on our work,\nwhich can be easily evaluated at https://tinyurl.com/22ercuf8.", "published": "2023-05-06 15:14:11", "link": "http://arxiv.org/abs/2305.04067v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning\n  by Large Language Models", "abstract": "Large language models (LLMs) have recently been shown to deliver impressive\nperformance in various NLP tasks. To tackle multi-step reasoning tasks,\nfew-shot chain-of-thought (CoT) prompting includes a few manually crafted\nstep-by-step reasoning demonstrations which enable LLMs to explicitly generate\nreasoning steps and improve their reasoning task accuracy. To eliminate the\nmanual effort, Zero-shot-CoT concatenates the target problem statement with\n\"Let's think step by step\" as an input prompt to LLMs. Despite the success of\nZero-shot-CoT, it still suffers from three pitfalls: calculation errors,\nmissing-step errors, and semantic misunderstanding errors. To address the\nmissing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of\ntwo components: first, devising a plan to divide the entire task into smaller\nsubtasks, and then carrying out the subtasks according to the plan. To address\nthe calculation errors and improve the quality of generated reasoning steps, we\nextend PS prompting with more detailed instructions and derive PS+ prompting.\nWe evaluate our proposed prompting strategy on ten datasets across three\nreasoning problems. The experimental results over GPT-3 show that our proposed\nzero-shot prompting consistently outperforms Zero-shot-CoT across all datasets\nby a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought\nPrompting, and has comparable performance with 8-shot CoT prompting on the math\nreasoning problem. The code can be found at\nhttps://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.", "published": "2023-05-06 16:34:37", "link": "http://arxiv.org/abs/2305.04091v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rhetorical Role Labeling of Legal Documents using Transformers and Graph\n  Neural Networks", "abstract": "A legal document is usually long and dense requiring human effort to parse\nit. It also contains significant amounts of jargon which make deriving insights\nfrom it using existing models a poor approach. This paper presents the\napproaches undertaken to perform the task of rhetorical role labelling on\nIndian Court Judgements as part of SemEval Task 6: understanding legal texts,\nshared subtask A. We experiment with graph based approaches like Graph\nConvolutional Networks and Label Propagation Algorithm, and transformer-based\napproaches including variants of BERT to improve accuracy scores on text\nclassification of complex legal documents.", "published": "2023-05-06 17:04:51", "link": "http://arxiv.org/abs/2305.04100v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"When Words Fail, Emojis Prevail\": Generating Sarcastic Utterances with\n  Emoji Using Valence Reversal and Semantic Incongruity", "abstract": "Sarcasm is a form of figurative language that serves as a humorous tool for\nmockery and ridicule. We present a novel architecture for sarcasm generation\nwith emoji from a non-sarcastic input sentence in English. We divide the\ngeneration task into two sub tasks: one for generating textual sarcasm and\nanother for collecting emojis associated with those sarcastic sentences. Two\nkey elements of sarcasm are incorporated into the textual sarcasm generation\ntask: valence reversal and semantic incongruity with context, where the context\nmay involve shared commonsense or general knowledge between the speaker and\ntheir audience. The majority of existing sarcasm generation works have focused\non this textual form. However, in the real world, when written texts fall short\nof effectively capturing the emotional cues of spoken and face-to-face\ncommunication, people often opt for emojis to accurately express their\nemotions. Due to the wide range of applications of emojis, incorporating\nappropriate emojis to generate textual sarcastic sentences helps advance\nsarcasm generation. We conclude our study by evaluating the generated sarcastic\nsentences using human judgement. All the codes and data used in this study has\nbeen made publicly available.", "published": "2023-05-06 17:49:41", "link": "http://arxiv.org/abs/2305.04105v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Human-Like Translation Strategy with Large Language Models", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\ngeneral scenarios, exhibiting a level of aptitude that approaches, in some\naspects even surpasses, human-level intelligence. Among their numerous skills,\nthe translation abilities of LLMs have received considerable attention.\nCompared to typical machine translation that focuses solely on source-to-target\nmapping, LLM-based translation can potentially mimic the human translation\nprocess which might take preparatory steps to ensure high-quality translation.\nThis work explores this possibility by proposing the MAPS framework, which\nstands for Multi-Aspect Prompting and Selection. Specifically, we enable LLMs\nfirst to analyze the given source sentence and induce three aspects of\ntranslation-related knowledge: keywords, topics, and relevant demonstrations to\nguide the final translation process. Moreover, we employ a selection mechanism\nbased on quality estimation to filter out noisy and unhelpful knowledge. Both\nautomatic (3 LLMs x 11 directions x 2 automatic metrics) and human evaluation\n(preference study and MQM) demonstrate the effectiveness of MAPS. Further\nanalysis shows that by mimicking the human translation process, MAPS reduces\nvarious translation errors such as hallucination, ambiguity, mistranslation,\nawkward style, untranslated text, and omission. Source code is available at\nhttps://github.com/zwhe99/MAPS-mt.", "published": "2023-05-06 19:03:12", "link": "http://arxiv.org/abs/2305.04118v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Active Continual Learning: On Balancing Knowledge Retention and\n  Learnability", "abstract": "Acquiring new knowledge without forgetting what has been learned in a\nsequence of tasks is the central focus of continual learning (CL). While tasks\narrive sequentially, the training data are often prepared and annotated\nindependently, leading to the CL of incoming supervised learning tasks. This\npaper considers the under-explored problem of active continual learning (ACL)\nfor a sequence of active learning (AL) tasks, where each incoming task includes\na pool of unlabelled data and an annotation budget. We investigate the\neffectiveness and interplay between several AL and CL algorithms in the domain,\nclass and task-incremental scenarios. Our experiments reveal the trade-off\nbetween two contrasting goals of not forgetting the old knowledge and the\nability to quickly learn new knowledge in CL and AL, respectively. While\nconditioning the AL query strategy on the annotations collected for the\nprevious tasks leads to improved task performance on the domain and task\nincremental learning, our proposed forgetting-learning profile suggests a gap\nin balancing the effect of AL and CL for the class-incremental scenario.", "published": "2023-05-06 04:11:03", "link": "http://arxiv.org/abs/2305.03923v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Residual Prompt Tuning: Improving Prompt Tuning with Residual\n  Reparameterization", "abstract": "Prompt tuning is one of the successful approaches for parameter-efficient\ntuning of pre-trained language models. Despite being arguably the most\nparameter-efficient (tuned soft prompts constitute <0.1% of total parameters),\nit typically performs worse than other efficient tuning methods and is quite\nsensitive to hyper-parameters. In this work, we introduce Residual Prompt\nTuning - a simple and efficient method that significantly improves the\nperformance and stability of prompt tuning. We propose to reparameterize soft\nprompt embeddings using a shallow network with a residual connection. Our\nexperiments show that Residual Prompt Tuning significantly outperforms prompt\ntuning on SuperGLUE benchmark. Notably, our method reaches +7 points\nimprovement over prompt tuning with T5-Base and allows to reduce the prompt\nlength by 10x without hurting performance. In addition, we show that our\napproach is robust to the choice of learning rate and prompt initialization,\nand is effective in few-shot settings.", "published": "2023-05-06 05:35:14", "link": "http://arxiv.org/abs/2305.03937v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Rule-based Named Entity Recognition and Relation Extraction for\n  Process Model Generation from Natural Language Text", "abstract": "Process-aware information systems offer extensive advantages to companies,\nfacilitating planning, operations, and optimization of day-to-day business\nactivities. However, the time-consuming but required step of designing formal\nbusiness process models often hampers the potential of these systems. To\novercome this challenge, automated generation of business process models from\nnatural language text has emerged as a promising approach to expedite this\nstep. Generally two crucial subtasks have to be solved: extracting\nprocess-relevant information from natural language and creating the actual\nmodel. Approaches towards the first subtask are rule based methods, highly\noptimized for specific domains, but hard to adapt to related applications. To\nsolve this issue, we present an extension to an existing pipeline, to make it\nentirely data driven. We demonstrate the competitiveness of our improved\npipeline, which not only eliminates the substantial overhead associated with\nfeature engineering and rule definition, but also enables adaptation to\ndifferent datasets, entity and relation types, and new domains. Additionally,\nthe largest available dataset (PET) for the first subtask, contains no\ninformation about linguistic references between mentions of entities in the\nprocess description. Yet, the resolution of these mentions into a single visual\nelement is essential for high quality process models. We propose an extension\nto the PET dataset that incorporates information about linguistic references\nand a corresponding method for resolving them. Finally, we provide a detailed\nanalysis of the inherent challenges in the dataset at hand.", "published": "2023-05-06 07:06:47", "link": "http://arxiv.org/abs/2305.03960v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adaptive loose optimization for robust question answering", "abstract": "Question answering methods are well-known for leveraging data bias, such as\nthe language prior in visual question answering and the position bias in\nmachine reading comprehension (extractive question answering). Current\ndebiasing methods often come at the cost of significant in-distribution\nperformance to achieve favorable out-of-distribution generalizability, while\nnon-debiasing methods sacrifice a considerable amount of out-of-distribution\nperformance in order to obtain high in-distribution performance. Therefore, it\nis challenging for them to deal with the complicated changing real-world\nsituations. In this paper, we propose a simple yet effective novel loss\nfunction with adaptive loose optimization, which seeks to make the best of both\nworlds for question answering. Our main technical contribution is to reduce the\nloss adaptively according to the ratio between the previous and current\noptimization state on mini-batch training data. This loose optimization can be\nused to prevent non-debiasing methods from overlearning data bias while\nenabling debiasing methods to maintain slight bias learning. Experiments on the\nvisual question answering datasets, including VQA v2, VQA-CP v1, VQA-CP v2,\nGQA-OOD, and the extractive question answering dataset SQuAD demonstrate that\nour approach enables QA methods to obtain state-of-the-art in- and\nout-of-distribution performance in most cases. The source code has been\nreleased publicly in \\url{https://github.com/reml-group/ALO}.", "published": "2023-05-06 08:09:46", "link": "http://arxiv.org/abs/2305.03971v3", "categories": ["cs.CL", "cs.CV", "H.3.4"], "primary_category": "cs.CL"}
{"title": "Replicating Complex Dialogue Policy of Humans via Offline Imitation\n  Learning with Supervised Regularization", "abstract": "Policy learning (PL) is a module of a task-oriented dialogue system that\ntrains an agent to make actions in each dialogue turn. Imitating human action\nis a fundamental problem of PL. However, both supervised learning (SL) and\nreinforcement learning (RL) frameworks cannot imitate humans well. Training RL\nmodels require online interactions with user simulators, while simulating\ncomplex human policy is hard. Performances of SL-based models are restricted\nbecause of the covariate shift problem. Specifically, a dialogue is a\nsequential decision-making process where slight differences in current\nutterances and actions will cause significant differences in subsequent\nutterances. Therefore, the generalize ability of SL models is restricted\nbecause statistical characteristics of training and testing dialogue data\ngradually become different. This study proposed an offline imitation learning\nmodel that learns policy from real dialogue datasets and does not require user\nsimulators. It also utilizes state transition information, which alleviates the\ninfluence of the covariate shift problem. We introduced a regularization trick\nto make our model can be effectively optimized. We investigated the performance\nof our model on four independent public dialogue datasets. The experimental\nresult showed that our model performed better in the action prediction task.", "published": "2023-05-06 09:27:58", "link": "http://arxiv.org/abs/2305.03987v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Refining the Responses of LLMs by Themselves", "abstract": "In this paper, we propose a simple yet efficient approach based on prompt\nengineering that leverages the large language model itself to optimize its\nanswers without relying on auxiliary models. We introduce an iterative\nself-evaluating optimization mechanism, with the potential for improved output\nquality as iterations progress, removing the need for manual intervention. The\nexperiment's findings indicate that utilizing our response refinement framework\non the GPT-3.5 model yields results that are on par with, or even surpass,\nthose generated by the cutting-edge GPT-4 model. Detailed implementation\nstrategies and illustrative examples are provided to demonstrate the\nsuperiority of our proposed solution.", "published": "2023-05-06 13:03:45", "link": "http://arxiv.org/abs/2305.04039v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SANTA: Separate Strategies for Inaccurate and Incomplete Annotation\n  Noise in Distantly-Supervised Named Entity Recognition", "abstract": "Distantly-Supervised Named Entity Recognition effectively alleviates the\nburden of time-consuming and expensive annotation in the supervised setting.\nBut the context-free matching process and the limited coverage of knowledge\nbases introduce inaccurate and incomplete annotation noise respectively.\nPrevious studies either considered only incomplete annotation noise or\nindiscriminately handle two types of noise with the same strategy. In this\npaper, we argue that the different causes of two types of noise bring up the\nrequirement of different strategies in model architecture. Therefore, we\npropose the SANTA to handle these two types of noise separately with (1)\nMemory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity\nproblem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate\ndecision boundary shifting problem caused by incomplete annotation and a\nnoise-tolerant loss to improve the robustness. Benefiting from our separate\ntailored strategies, we confirm in the experiment that the two types of noise\nare well mitigated. SANTA also achieves a new state-of-the-art on five public\ndatasets.", "published": "2023-05-06 15:48:24", "link": "http://arxiv.org/abs/2305.04076v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Minimal Approach for Natural Language Action Space in Text-based Games", "abstract": "Text-based games (TGs) are language-based interactive environments for\nreinforcement learning. While language models (LMs) and knowledge graphs (KGs)\nare commonly used for handling large action space in TGs, it is unclear whether\nthese techniques are necessary or overused. In this paper, we revisit the\nchallenge of exploring the action space in TGs and propose $\n\\epsilon$-admissible exploration, a minimal approach of utilizing admissible\nactions, for training phase. Additionally, we present a text-based actor-critic\n(TAC) agent that produces textual commands for game, solely from game\nobservations, without requiring any KG or LM. Our method, on average across 10\ngames from Jericho, outperforms strong baselines and state-of-the-art agents\nthat use LM and KG. Our approach highlights that a much lighter model design,\nwith a fresh perspective on utilizing the information within the environments,\nsuffices for an effective exploration of exponentially large action spaces.", "published": "2023-05-06 16:05:27", "link": "http://arxiv.org/abs/2305.04082v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Self-Edit: Fault-Aware Code Editor for Code Generation", "abstract": "Large language models (LLMs) have demonstrated an impressive ability to\ngenerate codes on competitive programming tasks. However, with limited sample\nnumbers, LLMs still suffer from poor accuracy. Inspired by the process of human\nprogramming, we propose a generate-and-edit approach named Self-Edit that\nutilizes execution results of the generated code from LLMs to improve the code\nquality on the competitive programming task. We execute the generated code on\nthe example test case provided in the question and wrap execution results into\na supplementary comment. Utilizing this comment as guidance, our fault-aware\ncode editor is employed to correct errors in the generated code. We perform\nextensive evaluations across two competitive programming datasets with nine\ndifferent LLMs. Compared to directly generating from LLMs, our approach can\nimprove the average of pass@1 by 89\\% on APPS-dev, 31\\% on APPS-test, and 48\\%\non HumanEval over nine popular code generation LLMs with parameter sizes\nranging from 110M to 175B. Compared to other post-processing methods, our\nmethod demonstrates superior accuracy and efficiency.", "published": "2023-05-06 16:12:19", "link": "http://arxiv.org/abs/2305.04087v5", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Fairness in Image Search: A Study of Occupational Stereotyping in Image\n  Retrieval and its Debiasing", "abstract": "Multi-modal search engines have experienced significant growth and widespread\nuse in recent years, making them the second most common internet use. While\nsearch engine systems offer a range of services, the image search field has\nrecently become a focal point in the information retrieval community, as the\nadage goes, \"a picture is worth a thousand words\". Although popular search\nengines like Google excel at image search accuracy and agility, there is an\nongoing debate over whether their search results can be biased in terms of\ngender, language, demographics, socio-cultural aspects, and stereotypes. This\npotential for bias can have a significant impact on individuals' perceptions\nand influence their perspectives.\n  In this paper, we present our study on bias and fairness in web search, with\na focus on keyword-based image search. We first discuss several kinds of biases\nthat exist in search systems and why it is important to mitigate them. We\nnarrow down our study to assessing and mitigating occupational stereotypes in\nimage search, which is a prevalent fairness issue in image retrieval. For the\nassessment of stereotypes, we take gender as an indicator. We explore various\nopen-source and proprietary APIs for gender identification from images. With\nthese, we examine the extent of gender bias in top-tanked image search results\nobtained for several occupational keywords. To mitigate the bias, we then\npropose a fairness-aware re-ranking algorithm that optimizes (a) relevance of\nthe search result with the keyword and (b) fairness w.r.t genders identified.\nWe experiment on 100 top-ranked images obtained for 10 occupational keywords\nand consider random re-ranking and re-ranking based on relevance as baselines.\nOur experimental results show that the fairness-aware re-ranking algorithm\nproduces rankings with better fairness scores and competitive relevance scores\nthan the baselines.", "published": "2023-05-06 00:24:44", "link": "http://arxiv.org/abs/2305.03881v2", "categories": ["cs.IR", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "HateMM: A Multi-Modal Dataset for Hate Video Classification", "abstract": "Hate speech has become one of the most significant issues in modern society,\nhaving implications in both the online and the offline world. Due to this, hate\nspeech research has recently gained a lot of traction. However, most of the\nwork has primarily focused on text media with relatively little work on images\nand even lesser on videos. Thus, early stage automated video moderation\ntechniques are needed to handle the videos that are being uploaded to keep the\nplatform safe and healthy. With a view to detect and remove hateful content\nfrom the video sharing platforms, our work focuses on hate video detection\nusing multi-modalities. To this end, we curate ~43 hours of videos from\nBitChute and manually annotate them as hate or non-hate, along with the frame\nspans which could explain the labelling decision. To collect the relevant\nvideos we harnessed search keywords from hate lexicons. We observe various cues\nin images and audio of hateful videos. Further, we build deep learning\nmulti-modal models to classify the hate videos and observe that using all the\nmodalities of the videos improves the overall hate speech detection performance\n(accuracy=0.798, macro F1-score=0.790) by ~5.7% compared to the best uni-modal\nmodel in terms of macro F1 score. In summary, our work takes the first step\ntoward understanding and modeling hateful videos on video hosting platforms\nsuch as BitChute.", "published": "2023-05-06 03:39:00", "link": "http://arxiv.org/abs/2305.03915v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for\n  Verification", "abstract": "Verification of machine learning models used in Natural Language Processing\n(NLP) is known to be a hard problem. In particular, many known neural network\nverification methods that work for computer vision and other numeric datasets\ndo not work for NLP. Here, we study technical reasons that underlie this\nproblem. Based on this analysis, we propose practical methods and heuristics\nfor preparing NLP datasets and models in a way that renders them amenable to\nknown verification methods based on abstract interpretation. We implement these\nmethods as a Python library called ANTONIO that links to the neural network\nverifiers ERAN and Marabou. We perform evaluation of the tool using an NLP\ndataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP\napplications. We hope that, thanks to its general applicability, this work will\nopen novel possibilities for including NLP verification problems into neural\nnetwork verification competitions, and will popularise NLP problems within this\ncommunity.", "published": "2023-05-06 10:36:39", "link": "http://arxiv.org/abs/2305.04003v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Controllable Mixed-Initiative Dialogue Generation through Prompting", "abstract": "Mixed-initiative dialogue tasks involve repeated exchanges of information and\nconversational control. Conversational agents gain control by generating\nresponses that follow particular dialogue intents or strategies, prescribed by\na policy planner. The standard approach has been fine-tuning pre-trained\nlanguage models to perform generation conditioned on these intents. However,\nthese supervised generation models are limited by the cost and quality of data\nannotation. We instead prompt large language models as a drop-in replacement to\nfine-tuning on conditional generation. We formalize prompt construction for\ncontrollable mixed-initiative dialogue. Our findings show improvements over\nfine-tuning and ground truth responses according to human evaluation and\nautomatic metrics for two tasks: PersuasionForGood and Emotional Support\nConversations.", "published": "2023-05-06 23:11:25", "link": "http://arxiv.org/abs/2305.04147v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Structure-CLIP: Towards Scene Graph Knowledge to Enhance Multi-modal\n  Structured Representations", "abstract": "Large-scale vision-language pre-training has achieved significant performance\nin multi-modal understanding and generation tasks. However, existing methods\noften perform poorly on image-text matching tasks that require structured\nrepresentations, i.e., representations of objects, attributes, and relations.\nAs illustrated in Fig.~reffig:case (a), the models cannot make a distinction\nbetween ``An astronaut rides a horse\" and ``A horse rides an astronaut\". This\nis because they fail to fully leverage structured knowledge when learning\nrepresentations in multi-modal scenarios. In this paper, we present an\nend-to-end framework Structure-CLIP, which integrates Scene Graph Knowledge\n(SGK) to enhance multi-modal structured representations. Firstly, we use scene\ngraphs to guide the construction of semantic negative examples, which results\nin an increased emphasis on learning structured representations. Moreover, a\nKnowledge-Enhance Encoder (KEE) is proposed to leverage SGK as input to further\nenhance structured representations. To verify the effectiveness of the proposed\nframework, we pre-train our model with the aforementioned approaches and\nconduct experiments on downstream tasks. Experimental results demonstrate that\nStructure-CLIP achieves state-of-the-art (SOTA) performance on VG-Attribution\nand VG-Relation datasets, with 12.5% and 4.1% ahead of the multi-modal SOTA\nmodel respectively. Meanwhile, the results on MSCOCO indicate that\nStructure-CLIP significantly enhances the structured representations while\nmaintaining the ability of general representations. Our code is available at\nhttps://github.com/zjukg/Structure-CLIP.", "published": "2023-05-06 03:57:05", "link": "http://arxiv.org/abs/2305.06152v3", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Analysis of Climate Campaigns on Social Media using Bayesian Model\n  Averaging", "abstract": "Climate change is the defining issue of our time, and we are at a defining\nmoment. Various interest groups, social movement organizations, and individuals\nengage in collective action on this issue on social media. In addition, issue\nadvocacy campaigns on social media often arise in response to ongoing societal\nconcerns, especially those faced by energy industries. Our goal in this paper\nis to analyze how those industries, their advocacy group, and climate advocacy\ngroup use social media to influence the narrative on climate change. In this\nwork, we propose a minimally supervised model soup [57] approach combined with\nmessaging themes to identify the stances of climate ads on Facebook. Finally,\nwe release our stance dataset, model, and set of themes related to climate\ncampaigns for future work on opinion mining and the automatic detection of\nclimate change stances.", "published": "2023-05-06 16:43:29", "link": "http://arxiv.org/abs/2305.06174v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Pitch Estimation by Denoising Preprocessor and Hybrid Estimation Model", "abstract": "Pitch estimation is to estimate the fundamental frequency and the midi number\nand plays a critical role in music signal analysis and vocal signal processing.\nIn this work, we proposed a new architecture based on a learning-based\nenhancement preprocessor and a combination of several traditional and deep\nlearning pitch estimation methods to achieve better pitch estimation\nperformance in both noisy and clean scenarios. We test 17 different types of\nnoise and 4 SNRdb noise levels. The results show that the proposed pitch\nestimation can perform better in both noisy and clean scenarios with short\nresponse time.", "published": "2023-05-06 09:05:11", "link": "http://arxiv.org/abs/2305.03982v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
