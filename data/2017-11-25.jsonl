{"title": "Towards Accurate Deceptive Opinion Spam Detection based on Word\n  Order-preserving CNN", "abstract": "Nowadays, deep learning has been widely used. In natural language learning,\nthe analysis of complex semantics has been achieved because of its high degree\nof flexibility. The deceptive opinions detection is an important application\narea in deep learning model, and related mechanisms have been given attention\nand researched. On-line opinions are quite short, varied types and content. In\norder to effectively identify deceptive opinions, we need to comprehensively\nstudy the characteristics of deceptive opinions, and explore novel\ncharacteristics besides the textual semantics and emotional polarity that have\nbeen widely used in text analysis. The detection mechanism based on deep\nlearning has better self-adaptability and can effectively identify all kinds of\ndeceptive opinions. In this paper, we optimize the convolution neural network\nmodel by embedding the word order characteristics in its convolution layer and\npooling layer, which makes convolution neural network more suitable for various\ntext classification and deceptive opinions detection. The TensorFlow-based\nexperiments demonstrate that the detection mechanism proposed in this paper\nachieve more accurate deceptive opinion detection results.", "published": "2017-11-25 02:58:59", "link": "http://arxiv.org/abs/1711.09181v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acronym Disambiguation: A Domain Independent Approach", "abstract": "Acronyms are omnipresent. They usually express information that is repetitive\nand well known. But acronyms can also be ambiguous because there can be\nmultiple expansions for the same acronym. In this paper, we propose a general\nsystem for acronym disambiguation that can work on any acronym given some\ncontext information. We present methods for retrieving all the possible\nexpansions of an acronym from Wikipedia and AcronymsFinder.com. We propose to\nuse these expansions to collect all possible contexts in which these acronyms\nare used and then score them using a paragraph embedding technique called\nDoc2Vec. This method collectively led to achieving an accuracy of 90.9% in\nselecting the correct expansion for given acronym, on a dataset we scraped from\nWikipedia with 707 distinct acronyms and 14,876 disambiguations.", "published": "2017-11-25 18:44:00", "link": "http://arxiv.org/abs/1711.09271v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experiential, Distributional and Dependency-based Word Embeddings have\n  Complementary Roles in Decoding Brain Activity", "abstract": "We evaluate 8 different word embedding models on their usefulness for\npredicting the neural activation patterns associated with concrete nouns. The\nmodels we consider include an experiential model, based on crowd-sourced\nassociation data, several popular neural and distributional models, and a model\nthat reflects the syntactic context of words (based on dependency parses). Our\ngoal is to assess the cognitive plausibility of these various embedding models,\nand understand how we can further improve our methods for interpreting brain\nimaging data.\n  We show that neural word embedding models exhibit superior performance on the\ntasks we consider, beating experiential word representation model. The\nsyntactically informed model gives the overall best performance when predicting\nbrain activation patterns from word embeddings; whereas the GloVe\ndistributional method gives the overall best performance when predicting in the\nreverse direction (words vectors from brain images). Interestingly, however,\nthe error patterns of these different models are markedly different. This may\nsupport the idea that the brain uses different systems for processing different\nkinds of words. Moreover, we suggest that taking the relative strengths of\ndifferent embedding models into account will lead to better models of the brain\nactivity associated with words.", "published": "2017-11-25 20:36:39", "link": "http://arxiv.org/abs/1711.09285v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complex Structure Leads to Overfitting: A Structure Regularization\n  Decoding Method for Natural Language Processing", "abstract": "Recent systems on structured prediction focus on increasing the level of\nstructural dependencies within the model. However, our study suggests that\ncomplex structures entail high overfitting risks. To control the\nstructure-based overfitting, we propose to conduct structure regularization\ndecoding (SR decoding). The decoding of the complex structure model is\nregularized by the additionally trained simple structure model. We\ntheoretically analyze the quantitative relations between the structural\ncomplexity and the overfitting risk. The analysis shows that complex structure\nmodels are prone to the structure-based overfitting. Empirical evaluations show\nthat the proposed method improves the performance of the complex structure\nmodels by reducing the structure-based overfitting. On the sequence labeling\ntasks, the proposed method substantially improves the performance of the\ncomplex neural network models. The maximum F1 error rate reduction is 36.4% for\nthe third-order model. The proposed method also works for the parsing task. The\nmaximum UAS improvement is 5.5% for the tri-sibling model. The results are\ncompetitive with or better than the state-of-the-art results.", "published": "2017-11-25 07:47:02", "link": "http://arxiv.org/abs/1711.10331v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Assessment of sound spatialisation algorithms for sonic rendering with\n  headsets", "abstract": "Given an input sound signal and a target virtual sound source, sound\nspatialisation algorithms manipulate the signal so that a listener perceives it\nas though it were emitted from the target source. There exist several\nestablished spatialisation approaches that deliver satisfactory results when\nloudspeakers are used to playback the manipulated signal. As headphones have a\nnumber of desirable characteristics over loudspeakers, such as portability,\nisolation from the surrounding environment, cost and ease of use, it is\ninteresting to explore how a sense of acoustic space can be conveyed through\nthem. This article first surveys traditional spatialisation approaches intended\nfor loudspeakers, and then reviews them with regard to their adaptability to\nheadphones.", "published": "2017-11-25 12:33:13", "link": "http://arxiv.org/abs/1711.09234v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
