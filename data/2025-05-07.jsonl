{"title": "ZeroSearch: Incentivize the Search Capability of LLMs without Searching", "abstract": "Effective information searching is essential for enhancing the reasoning and\ngeneration capabilities of large language models (LLMs). Recent research has\nexplored using reinforcement learning (RL) to improve LLMs' search capabilities\nby interacting with live search engines in real-world environments. While these\napproaches show promising results, they face two major challenges: (1)\nUncontrolled Document Quality: The quality of documents returned by search\nengines is often unpredictable, introducing noise and instability into the\ntraining process. (2) Prohibitively High API Costs: RL training requires\nfrequent rollouts, potentially involving hundreds of thousands of search\nrequests, which incur substantial API expenses and severely constrain\nscalability. To address these challenges, we introduce ZeroSearch, a\nreinforcement learning framework that incentivizes the search capabilities of\nLLMs without interacting with real search engines. Our approach begins with\nlightweight supervised fine-tuning to transform the LLM into a retrieval module\ncapable of generating both relevant and noisy documents in response to a query.\nDuring RL training, we employ a curriculum-based rollout strategy that\nincrementally degrades the quality of generated documents, progressively\neliciting the model's reasoning ability by exposing it to increasingly\nchallenging retrieval scenarios. Extensive experiments demonstrate that\nZeroSearch effectively incentivizes the search capabilities of LLMs using a 3B\nLLM as the retrieval module. Remarkably, a 7B retrieval module achieves\ncomparable performance to the real search engine, while a 14B retrieval module\neven surpasses it. Furthermore, it generalizes well across both base and\ninstruction-tuned models of various parameter sizes and is compatible with a\nwide range of RL algorithms.", "published": "2025-05-07 17:30:22", "link": "http://arxiv.org/abs/2505.04588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review", "abstract": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies.", "published": "2025-05-07 16:04:45", "link": "http://arxiv.org/abs/2505.04531v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving", "abstract": "As a seemingly self-explanatory task, problem-solving has been a significant\ncomponent of science and engineering. However, a general yet concrete\nformulation of problem-solving itself is missing. With the recent development\nof AI-based problem-solving agents, the demand for process-level verifiability\nis rapidly increasing yet underexplored. To fill these gaps, we present a\nprincipled formulation of problem-solving as a deterministic Markov decision\nprocess; a novel framework, FPS (Formal Problem-Solving), which utilizes\nexisting FTP (formal theorem proving) environments to perform process-verified\nproblem-solving; and D-FPS (Deductive FPS), decoupling solving and answer\nverification for better human-alignment. The expressiveness, soundness and\ncompleteness of the frameworks are proven. We construct three benchmarks on\nproblem-solving: FormalMath500, a formalization of a subset of the MATH500\nbenchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP\nbenchmarks MiniF2F and PutnamBench. For faithful, interpretable, and\nhuman-aligned evaluation, we propose RPE (Restricted Propositional\nEquivalence), a symbolic approach to determine the correctness of answers by\nformal verification. We evaluate four prevalent FTP models and two prompting\nmethods as baselines, solving at most 23.77% of FormalMath500, 27.47% of\nMiniF2F-Solving, and 0.31% of PutnamBench-Solving.", "published": "2025-05-07 16:02:14", "link": "http://arxiv.org/abs/2505.04528v1", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs", "abstract": "Sparse large language models (LLMs) with Mixture of Experts (MoE) and close\nto a trillion parameters are dominating the realm of most capable language\nmodels. However, the massive model scale poses significant challenges for the\nunderlying software and hardware systems. In this paper, we aim to uncover a\nrecipe to harness such scale on Ascend NPUs. The key goals are better usage of\nthe computing resources under the dynamic sparse model structures and\nmaterializing the expected performance gain on the actual hardware. To select\nmodel configurations suitable for Ascend NPUs without repeatedly running the\nexpensive experiments, we leverage simulation to compare the trade-off of\nvarious model hyperparameters. This study led to Pangu Ultra MoE, a sparse LLM\nwith 718 billion parameters, and we conducted experiments on the model to\nverify the simulation results. On the system side, we dig into Expert\nParallelism to optimize the communication between NPU devices to reduce the\nsynchronization overhead. We also optimize the memory efficiency within the\ndevices to further reduce the parameter and activation management overhead. In\nthe end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with\nperformance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and\ndemonstrate that the Ascend system is capable of harnessing all the training\nstages of the state-of-the-art language models. Extensive experiments indicate\nthat our recipe can lead to efficient training of large-scale sparse language\nmodels with MoE. We also study the behaviors of such models for future\nreference.", "published": "2025-05-07 15:46:36", "link": "http://arxiv.org/abs/2505.04519v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Spelling and Grammatical Anomalies in Russian Poetry Texts", "abstract": "The quality of natural language texts in fine-tuning datasets plays a\ncritical role in the performance of generative models, particularly in\ncomputational creativity tasks such as poem or song lyric generation. Fluency\ndefects in generated poems significantly reduce their value. However, training\ntexts are often sourced from internet-based platforms without stringent quality\ncontrol, posing a challenge for data engineers to manage defect levels\neffectively.\n  To address this issue, we propose the use of automated linguistic anomaly\ndetection to identify and filter out low-quality texts from training datasets\nfor creative models. In this paper, we present a comprehensive comparison of\nunsupervised and supervised text anomaly detection approaches, utilizing both\nsynthetic and human-labeled datasets. We also introduce the RUPOR dataset, a\ncollection of Russian-language human-labeled poems designed for cross-sentence\ngrammatical error detection, and provide the full evaluation code. Our work\naims to empower the community with tools and insights to improve the quality of\ntraining datasets for generative models in creative domains.", "published": "2025-05-07 15:27:59", "link": "http://arxiv.org/abs/2505.04507v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "abstract": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaneFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators.", "published": "2025-05-07 14:27:46", "link": "http://arxiv.org/abs/2505.04457v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models", "abstract": "Large language models (LLMs) trained over extensive corpora risk memorizing\nsensitive, copyrighted, or toxic content. To address this, we propose\nOBLIVIATE, a robust unlearning framework that removes targeted data while\npreserving model utility. The framework follows a structured process:\nextracting target tokens, building retain sets, and fine-tuning with a tailored\nloss function comprising three components -- masking, distillation, and world\nfact. Using low-rank adapters (LoRA), it ensures efficiency without\ncompromising unlearning quality. We conduct experiments on multiple datasets,\nincluding the Harry Potter series, WMDP, and TOFU, using a comprehensive suite\nof metrics: forget quality (new document-level memorization score), model\nutility, and fluency. Results demonstrate its effectiveness in resisting\nmembership inference attacks, minimizing the impact on retained data, and\nmaintaining robustness across diverse scenarios.", "published": "2025-05-07 13:51:42", "link": "http://arxiv.org/abs/2505.04416v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "YABLoCo: Yet Another Benchmark for Long Context Code Generation", "abstract": "Large Language Models demonstrate the ability to solve various programming\ntasks, including code generation. Typically, the performance of LLMs is\nmeasured on benchmarks with small or medium-sized context windows of thousands\nof lines of code. At the same time, in real-world software projects,\nrepositories can span up to millions of LoC. This paper closes this gap by\ncontributing to the long context code generation benchmark (YABLoCo). The\nbenchmark featured a test set of 215 functions selected from four large\nrepositories with thousands of functions. The dataset contained metadata of\nfunctions, contexts of the functions with different levels of dependencies,\ndocstrings, functions bodies, and call graphs for each repository. This paper\npresents three key aspects of the contribution. First, the benchmark aims at\nfunction body generation in large repositories in C and C++, two languages not\ncovered by previous benchmarks. Second, the benchmark contains large\nrepositories from 200K to 2,000K LoC. Third, we contribute a scalable\nevaluation pipeline for efficient computing of the target metrics and a tool\nfor visual analysis of generated code. Overall, these three aspects allow for\nevaluating code generation in large repositories in C and C++.", "published": "2025-05-07 13:42:23", "link": "http://arxiv.org/abs/2505.04406v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters", "abstract": "With the increasing prevalence of artificial intelligence, careful evaluation\nof inherent biases needs to be conducted to form the basis for alleviating the\neffects these predispositions can have on users. Large language models (LLMs)\nare predominantly used by many as a primary source of information for various\ntopics. LLMs frequently make factual errors, fabricate data (hallucinations),\nor present biases, exposing users to misinformation and influencing opinions.\nEducating users on their risks is key to responsible use, as bias, unlike\nhallucinations, cannot be caught through data verification. We quantify the\npolitical bias of popular LLMs in the context of the recent vote of the German\nBundestag using the score produced by the Wahl-O-Mat. This metric measures the\nalignment between an individual's political views and the positions of German\npolitical parties. We compare the models' alignment scores to identify factors\ninfluencing their political preferences. Doing so, we discover a bias toward\nleft-leaning parties, most dominant in larger LLMs. Also, we find that the\nlanguage we use to communicate with the models affects their political views.\nAdditionally, we analyze the influence of a model's origin and release date and\ncompare the results to the outcome of the recent vote of the Bundestag. Our\nresults imply that LLMs are prone to exhibiting political bias. Large\ncorporations with the necessary means to develop LLMs, thus, knowingly or\nunknowingly, have a responsibility to contain these biases, as they can\ninfluence each voter's decision-making process and inform public opinion in\ngeneral and at scale.", "published": "2025-05-07 13:18:41", "link": "http://arxiv.org/abs/2505.04393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs", "abstract": "Purpose: With advancements in Large Language Models (LLMs) for healthcare,\nthe need arises for competitive open-source models to protect the public\ninterest. This work contributes to the field of open medical LLMs by optimizing\nkey stages of data preprocessing and training, while showing how to improve\nmodel safety (through DPO) and efficacy (through RAG). The evaluation\nmethodology used, which includes four different types of tests, defines a new\nstandard for the field. The resultant models, shown to be competitive with the\nbest private alternatives, are released with a permisive license.\n  Methods: Building on top of strong base models like Llama 3.1 and Qwen 2.5,\nAloe Beta uses a custom dataset to enhance public data with synthetic Chain of\nThought examples. The models undergo alignment with Direct Preference\nOptimization, emphasizing ethical and policy-aligned performance in the\npresence of jailbreaking attacks. Evaluation includes close-ended, open-ended,\nsafety and human assessments, to maximize the reliability of results.\n  Results: Recommendations are made across the entire pipeline, backed by the\nsolid performance of the Aloe Family. These models deliver competitive\nperformance across healthcare benchmarks and medical fields, and are often\npreferred by healthcare professionals. On bias and toxicity, the Aloe Beta\nmodels significantly improve safety, showing resilience to unseen jailbreaking\nattacks. For a responsible release, a detailed risk assessment specific to\nhealthcare is attached to the Aloe Family models.\n  Conclusion: The Aloe Beta models, and the recipe that leads to them, are a\nsignificant contribution to the open-source medical LLM field, offering\ntop-of-the-line performance while maintaining high ethical requirements. This\nwork sets a new standard for developing and reporting aligned LLMs in\nhealthcare.", "published": "2025-05-07 13:13:14", "link": "http://arxiv.org/abs/2505.04388v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking LLMs' Swarm intelligence", "abstract": "Large Language Models (LLMs) show potential for complex reasoning, yet their\ncapacity for emergent coordination in Multi-Agent Systems (MAS) when operating\nunder strict constraints-such as limited local perception and communication,\ncharacteristic of natural swarms-remains largely unexplored, particularly\nconcerning the nuances of swarm intelligence. Existing benchmarks often do not\nfully capture the unique challenges of decentralized coordination that arise\nwhen agents operate with incomplete spatio-temporal information. To bridge this\ngap, we introduce SwarmBench, a novel benchmark designed to systematically\nevaluate the swarm intelligence capabilities of LLMs acting as decentralized\nagents. SwarmBench features five foundational MAS coordination tasks within a\nconfigurable 2D grid environment, forcing agents to rely primarily on local\nsensory input (k x k view) and local communication. We propose metrics for\ncoordination effectiveness and analyze emergent group dynamics. Evaluating\nseveral leading LLMs in a zero-shot setting, we find significant performance\nvariations across tasks, highlighting the difficulties posed by local\ninformation constraints. While some coordination emerges, results indicate\nlimitations in robust planning and strategy formation under uncertainty in\nthese decentralized scenarios. Assessing LLMs under swarm-like conditions is\ncrucial for realizing their potential in future decentralized systems. We\nrelease SwarmBench as an open, extensible toolkit-built upon a customizable and\nscalable physical system with defined mechanical properties. It provides\nenvironments, prompts, evaluation scripts, and the comprehensive experimental\ndatasets generated, aiming to foster reproducible research into LLM-based MAS\ncoordination and the theoretical underpinnings of Embodied MAS. Our code\nrepository is available at https://github.com/x66ccff/swarmbench.", "published": "2025-05-07 12:32:01", "link": "http://arxiv.org/abs/2505.04364v1", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "GASCADE: Grouped Summarization of Adverse Drug Event for Enhanced Cancer Pharmacovigilance", "abstract": "In the realm of cancer treatment, summarizing adverse drug events (ADEs)\nreported by patients using prescribed drugs is crucial for enhancing\npharmacovigilance practices and improving drug-related decision-making. While\nthe volume and complexity of pharmacovigilance data have increased, existing\nresearch in this field has predominantly focused on general diseases rather\nthan specifically addressing cancer. This work introduces the task of grouped\nsummarization of adverse drug events reported by multiple patients using the\nsame drug for cancer treatment. To address the challenge of limited resources\nin cancer pharmacovigilance, we present the MultiLabeled Cancer Adverse Drug\nReaction and Summarization (MCADRS) dataset. This dataset includes\npharmacovigilance posts detailing patient concerns regarding drug efficacy and\nadverse effects, along with extracted labels for drug names, adverse drug\nevents, severity, and adversity of reactions, as well as summaries of ADEs for\neach drug. Additionally, we propose the Grouping and Abstractive Summarization\nof Cancer Adverse Drug events (GASCADE) framework, a novel pipeline that\ncombines the information extraction capabilities of Large Language Models\n(LLMs) with the summarization power of the encoder-decoder T5 model. Our work\nis the first to apply alignment techniques, including advanced algorithms like\nDirect Preference Optimization, to encoder-decoder models using synthetic\ndatasets for summarization tasks. Through extensive experiments, we demonstrate\nthe superior performance of GASCADE across various metrics, validated through\nboth automated assessments and human evaluations. This multitasking approach\nenhances drug-related decision-making and fosters a deeper understanding of\npatient concerns, paving the way for advancements in personalized and\nresponsive cancer care. The code and dataset used in this work are publicly\navailable.", "published": "2025-05-07 09:40:18", "link": "http://arxiv.org/abs/2505.04284v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLM-Independent Adaptive RAG: Let the Question Speak for Itself", "abstract": "Large Language Models~(LLMs) are prone to hallucinations, and\nRetrieval-Augmented Generation (RAG) helps mitigate this, but at a high\ncomputational cost while risking misinformation. Adaptive retrieval aims to\nretrieve only when necessary, but existing approaches rely on LLM-based\nuncertainty estimation, which remain inefficient and impractical. In this\nstudy, we introduce lightweight LLM-independent adaptive retrieval methods\nbased on external information. We investigated 27 features, organized into 7\ngroups, and their hybrid combinations. We evaluated these methods on 6 QA\ndatasets, assessing the QA performance and efficiency. The results show that\nour approach matches the performance of complex LLM-based methods while\nachieving significant efficiency gains, demonstrating the potential of external\ninformation for adaptive retrieval.", "published": "2025-05-07 08:58:52", "link": "http://arxiv.org/abs/2505.04253v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VideoPath-LLaVA: Pathology Diagnostic Reasoning Through Video Instruction Tuning", "abstract": "We present VideoPath-LLaVA, the first large multimodal model (LMM) in\ncomputational pathology that integrates three distinct image scenarios, single\npatch images, automatically keyframe-extracted clips, and manually segmented\nvideo pathology images, to mimic the natural diagnostic process of\npathologists. By generating detailed histological descriptions and culminating\nin a definitive sign-out diagnosis, VideoPath-LLaVA bridges visual narratives\nwith diagnostic reasoning.\n  Central to our approach is the VideoPath-Instruct dataset, comprising 4278\nvideo and diagnosis-specific chain-of-thought instructional pairs sourced from\neducational histopathology videos on YouTube. Although high-quality data is\ncritical for enhancing diagnostic reasoning, its creation is time-intensive and\nlimited in volume. To overcome this challenge, we transfer knowledge from\nexisting single-image instruction datasets to train on weakly annotated,\nkeyframe-extracted clips, followed by fine-tuning on manually segmented videos.\nVideoPath-LLaVA establishes a new benchmark in pathology video analysis and\noffers a promising foundation for future AI systems that support clinical\ndecision-making through integrated visual and diagnostic reasoning. Our code,\ndata, and model are publicly available at\nhttps://github.com/trinhvg/VideoPath-LLaVA.", "published": "2025-05-07 07:41:19", "link": "http://arxiv.org/abs/2505.04192v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Large Language Models are often politically extreme, usually ideologically inconsistent, and persuasive even in informational contexts", "abstract": "Large Language Models (LLMs) are a transformational technology, fundamentally\nchanging how people obtain information and interact with the world. As people\nbecome increasingly reliant on them for an enormous variety of tasks, a body of\nacademic research has developed to examine these models for inherent biases,\nespecially political biases, often finding them small. We challenge this\nprevailing wisdom. First, by comparing 31 LLMs to legislators, judges, and a\nnationally representative sample of U.S. voters, we show that LLMs' apparently\nsmall overall partisan preference is the net result of offsetting extreme views\non specific topics, much like moderate voters. Second, in a randomized\nexperiment, we show that LLMs can promulgate their preferences into political\npersuasiveness even in information-seeking contexts: voters randomized to\ndiscuss political issues with an LLM chatbot are as much as 5 percentage points\nmore likely to express the same preferences as that chatbot. Contrary to\nexpectations, these persuasive effects are not moderated by familiarity with\nLLMs, news consumption, or interest in politics. LLMs, especially those\ncontrolled by private companies or governments, may become a powerful and\ntargeted vector for political influence.", "published": "2025-05-07 06:53:59", "link": "http://arxiv.org/abs/2505.04171v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Can Language Models Understand Social Behavior in Clinical Conversations?", "abstract": "Effective communication between providers and their patients influences\nhealth and care outcomes. The effectiveness of such conversations has been\nlinked not only to the exchange of clinical information, but also to a range of\ninterpersonal behaviors; commonly referred to as social signals, which are\noften conveyed through non-verbal cues and shape the quality of the\npatient-provider relationship. Recent advances in large language models (LLMs)\nhave demonstrated an increasing ability to infer emotional and social behaviors\neven when analyzing only textual information. As automation increases also in\nclinical settings, such as for transcription of patient-provider conversations,\nthere is growing potential for LLMs to automatically analyze and extract social\nbehaviors from these interactions. To explore the foundational capabilities of\nLLMs in tracking social signals in clinical dialogue, we designed task-specific\nprompts and evaluated model performance across multiple architectures and\nprompting styles using a highly imbalanced, annotated dataset spanning 20\ndistinct social signals such as provider dominance, patient warmth, etc. We\npresent the first system capable of tracking all these 20 coded signals, and\nuncover patterns in LLM behavior. Further analysis of model configurations and\nclinical context provides insights for enhancing LLM performance on social\nsignal processing tasks in healthcare settings.", "published": "2025-05-07 06:03:37", "link": "http://arxiv.org/abs/2505.04152v1", "categories": ["cs.CL", "cs.CY", "cs.HC", "H.5.2; H.1.2; I.2.7; I.2.m; J.3"], "primary_category": "cs.CL"}
{"title": "Unmasking the Canvas: A Dynamic Benchmark for Image Generation Jailbreaking and LLM Content Safety", "abstract": "Existing large language models (LLMs) are advancing rapidly and produce\noutstanding results in image generation tasks, yet their content safety checks\nremain vulnerable to prompt-based jailbreaks. Through preliminary testing on\nplatforms such as ChatGPT, MetaAI, and Grok, we observed that even short,\nnatural prompts could lead to the generation of compromising images ranging\nfrom realistic depictions of forged documents to manipulated images of public\nfigures.\n  We introduce Unmasking the Canvas (UTC Benchmark; UTCB), a dynamic and\nscalable benchmark dataset to evaluate LLM vulnerability in image generation.\nOur methodology combines structured prompt engineering, multilingual\nobfuscation (e.g., Zulu, Gaelic, Base64), and evaluation using Groq-hosted\nLLaMA-3. The pipeline supports both zero-shot and fallback prompting\nstrategies, risk scoring, and automated tagging. All generations are stored\nwith rich metadata and curated into Bronze (non-verified), Silver (LLM-aided\nverification), and Gold (manually verified) tiers. UTCB is designed to evolve\nover time with new data sources, prompt templates, and model behaviors.\n  Warning: This paper includes visual examples of adversarial inputs designed\nto test model safety. All outputs have been redacted to ensure responsible\ndisclosure.", "published": "2025-05-07 05:54:04", "link": "http://arxiv.org/abs/2505.04146v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Enhancing Granular Sentiment Classification with Chain-of-Thought Prompting in Large Language Models", "abstract": "We explore the use of Chain-of-Thought (CoT) prompting with large language\nmodels (LLMs) to improve the accuracy of granular sentiment categorization in\napp store reviews. Traditional numeric and polarity-based ratings often fail to\ncapture the nuanced sentiment embedded in user feedback. We evaluated the\neffectiveness of CoT prompting versus simple prompting on 2000 Amazon app\nreviews by comparing each method's predictions to human judgements. CoT\nprompting improved classification accuracy from 84% to 93% highlighting the\nbenefit of explicit reasoning in enhancing sentiment analysis performance.", "published": "2025-05-07 05:13:15", "link": "http://arxiv.org/abs/2505.04135v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bringing legal knowledge to the public by constructing a legal question bank using large-scale pre-trained language model", "abstract": "Access to legal information is fundamental to access to justice. Yet\naccessibility refers not only to making legal documents available to the\npublic, but also rendering legal information comprehensible to them. A vexing\nproblem in bringing legal information to the public is how to turn formal legal\ndocuments such as legislation and judgments, which are often highly technical,\nto easily navigable and comprehensible knowledge to those without legal\neducation. In this study, we formulate a three-step approach for bringing legal\nknowledge to laypersons, tackling the issues of navigability and\ncomprehensibility. First, we translate selected sections of the law into\nsnippets (called CLIC-pages), each being a small piece of article that focuses\non explaining certain technical legal concept in layperson's terms. Second, we\nconstruct a Legal Question Bank (LQB), which is a collection of legal questions\nwhose answers can be found in the CLIC-pages. Third, we design an interactive\nCLIC Recommender (CRec). Given a user's verbal description of a legal situation\nthat requires a legal solution, CRec interprets the user's input and shortlists\nquestions from the question bank that are most likely relevant to the given\nlegal situation and recommends their corresponding CLIC pages where relevant\nlegal knowledge can be found. In this paper we focus on the technical aspects\nof creating an LQB. We show how large-scale pre-trained language models, such\nas GPT-3, can be used to generate legal questions. We compare machine-generated\nquestions (MGQs) against human-composed questions (HCQs) and find that MGQs are\nmore scalable, cost-effective, and more diversified, while HCQs are more\nprecise. We also show a prototype of CRec and illustrate through an example how\nour 3-step approach effectively brings relevant legal knowledge to the public.", "published": "2025-05-07 05:07:38", "link": "http://arxiv.org/abs/2505.04132v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language Generation in Healthcare: A Review of Methods and Applications", "abstract": "Natural language generation (NLG) is the key technology to achieve generative\nartificial intelligence (AI). With the breakthroughs in large language models\n(LLMs), NLG has been widely used in various medical applications, demonstrating\nthe potential to enhance clinical workflows, support clinical decision-making,\nand improve clinical documentation. Heterogeneous and diverse medical data\nmodalities, such as medical text, images, and knowledge bases, are utilized in\nNLG. Researchers have proposed many generative models and applied them in a\nnumber of healthcare applications. There is a need for a comprehensive review\nof NLG methods and applications in the medical domain. In this study, we\nsystematically reviewed 113 scientific publications from a total of 3,988\nNLG-related articles identified using a literature search, focusing on data\nmodality, model architecture, clinical applications, and evaluation methods.\nFollowing PRISMA (Preferred Reporting Items for Systematic reviews and\nMeta-Analyses) guidelines, we categorize key methods, identify clinical\napplications, and assess their capabilities, limitations, and emerging\nchallenges. This timely review covers the key NLG technologies and medical\napplications and provides valuable insights for future studies to leverage NLG\nto transform medical discovery and healthcare.", "published": "2025-05-07 02:25:29", "link": "http://arxiv.org/abs/2505.04073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing and Benchmarking Personalized Tool Invocation for LLMs", "abstract": "Tool invocation is a crucial mechanism for extending the capabilities of\nLarge Language Models (LLMs) and has recently garnered significant attention.\nIt enables LLMs to solve complex problems through tool calls while accessing\nup-to-date world knowledge. However, existing work primarily focuses on the\nfundamental ability of LLMs to invoke tools for problem-solving, without\nconsidering personalized constraints in tool invocation. In this work, we\nintroduce the concept of Personalized Tool Invocation and define two key tasks:\nTool Preference and Profile-dependent Query. Tool Preference addresses user\npreferences when selecting among functionally similar tools, while\nProfile-dependent Query considers cases where a user query lacks certain tool\nparameters, requiring the model to infer them from the user profile. To tackle\nthese challenges, we propose PTool, a data synthesis framework designed for\npersonalized tool invocation. Additionally, we construct \\textbf{PTBench}, the\nfirst benchmark for evaluating personalized tool invocation. We then fine-tune\nvarious open-source models, demonstrating the effectiveness of our framework\nand providing valuable insights. Our benchmark is public at\nhttps://github.com/hyfshadow/PTBench.", "published": "2025-05-07 02:25:20", "link": "http://arxiv.org/abs/2505.04072v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLAMAPIE: Proactive In-Ear Conversation Assistants", "abstract": "We introduce LlamaPIE, the first real-time proactive assistant designed to\nenhance human conversations through discreet, concise guidance delivered via\nhearable devices. Unlike traditional language models that require explicit user\ninvocation, this assistant operates in the background, anticipating user needs\nwithout interrupting conversations. We address several challenges, including\ndetermining when to respond, crafting concise responses that enhance\nconversations, leveraging knowledge of the user for context-aware assistance,\nand real-time, on-device processing. To achieve this, we construct a\nsemi-synthetic dialogue dataset and propose a two-model pipeline: a small model\nthat decides when to respond and a larger model that generates the response. We\nevaluate our approach on real-world datasets, demonstrating its effectiveness\nin providing helpful, unobtrusive assistance. User studies with our assistant,\nimplemented on Apple Silicon M2 hardware, show a strong preference for the\nproactive assistant over both a baseline with no assistance and a reactive\nmodel, highlighting the potential of LlamaPie to enhance live conversations.", "published": "2025-05-07 02:08:56", "link": "http://arxiv.org/abs/2505.04066v1", "categories": ["cs.LG", "cs.CL", "eess.AS"], "primary_category": "cs.LG"}
{"title": "EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning", "abstract": "Multimodal large language models (MLLMs) have advanced perception across\ntext, vision, and audio, yet they often struggle with structured cross-modal\nreasoning, particularly when integrating audio and visual signals. We introduce\nEchoInk-R1, a reinforcement learning framework that enhances such reasoning in\nMLLMs. Built upon the Qwen2.5-Omni-7B foundation and optimized with Group\nRelative Policy Optimization (GRPO), EchoInk-R1 tackles multiple-choice\nquestion answering over synchronized audio-image pairs. To enable this, we\ncurate AVQA-R1-6K, a dataset pairing such audio-image inputs with\nmultiple-choice questions derived from OmniInstruct-v1. EchoInk-R1-7B achieves\n85.77% accuracy on the validation set, outperforming the base model, which\nscores 80.53%, using only 562 reinforcement learning steps. Beyond accuracy,\nEchoInk-R1 demonstrates reflective reasoning by revisiting initial\ninterpretations and refining responses when facing ambiguous multimodal inputs.\nThese results suggest that lightweight reinforcement learning fine-tuning\nenhances cross-modal reasoning in MLLMs. EchoInk-R1 is the first framework to\nunify audio, visual, and textual modalities for general open-world reasoning\nvia reinforcement learning. Code and data are publicly released to facilitate\nfurther research.", "published": "2025-05-07 17:59:49", "link": "http://arxiv.org/abs/2505.04623v1", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond", "abstract": "We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS)\nto text-conditioned audio diffusion models. While SDS was initially designed\nfor text-to-3D generation using image diffusion, its core idea of distilling a\npowerful generative prior into a separate parametric representation extends to\nthe audio domain. Leveraging a single pretrained model, Audio-SDS enables a\nbroad range of tasks without requiring specialized datasets. In particular, we\ndemonstrate how Audio-SDS can guide physically informed impact sound\nsimulations, calibrate FM-synthesis parameters, and perform prompt-specified\nsource separation. Our findings illustrate the versatility of\ndistillation-based methods across modalities and establish a robust foundation\nfor future work using generative priors in audio tasks.", "published": "2025-05-07 17:59:38", "link": "http://arxiv.org/abs/2505.04621v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS", "68T07", "I.2.6; H.5.5; H.5.1"], "primary_category": "cs.SD"}
{"title": "WATCH: Weighted Adaptive Testing for Changepoint Hypotheses via Weighted-Conformal Martingales", "abstract": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria,'' such as data shifts that violate\ncertain exchangeability assumptions, or do not allow for online adaptation in\nresponse to shifts. In this paper, we expand the scope of these monitoring\nmethods by proposing a weighted generalization of conformal test martingales\n(WCTMs), which lay a theoretical foundation for online monitoring for any\nunexpected changepoints in the data distribution while controlling\nfalse-alarms. For practical applications, we propose specific WCTM algorithms\nthat accommodate online adaptation to mild covariate shifts (in the marginal\ninput distribution) while raising alarms in response to more severe shifts,\nsuch as concept shifts (in the conditional label distribution) or extreme\n(out-of-support) covariate shifts that cannot be easily adapted to. On\nreal-world datasets, we demonstrate improved performance relative to\nstate-of-the-art baselines.", "published": "2025-05-07 17:53:47", "link": "http://arxiv.org/abs/2505.04608v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions", "abstract": "Humanity appears to be on course to soon develop AI systems that\nsubstantially outperform human experts in all cognitive domains and activities.\nWe believe the default trajectory has a high likelihood of catastrophe,\nincluding human extinction. Risks come from failure to control powerful AI\nsystems, misuse of AI by malicious rogue actors, war between great powers, and\nauthoritarian lock-in. This research agenda has two aims: to describe the\nstrategic landscape of AI development and to catalog important governance\nresearch questions. These questions, if answered, would provide important\ninsight on how to successfully reduce catastrophic risks.\n  We describe four high-level scenarios for the geopolitical response to\nadvanced AI development, cataloging the research questions most relevant to\neach. Our favored scenario involves building the technical, legal, and\ninstitutional infrastructure required to internationally restrict dangerous AI\ndevelopment and deployment (which we refer to as an Off Switch), which leads\ninto an internationally coordinated Halt on frontier AI activities at some\npoint in the future. The second scenario we describe is a US National Project\nfor AI, in which the US Government races to develop advanced AI systems and\nestablish unilateral control over global AI development. We also describe two\nadditional scenarios: a Light-Touch world similar to that of today and a Threat\nof Sabotage situation where countries use sabotage and deterrence to slow AI\ndevelopment.\n  In our view, apart from the Off Switch and Halt scenario, all of these\ntrajectories appear to carry an unacceptable risk of catastrophic harm. Urgent\naction is needed from the US National Security community and AI governance\necosystem to answer key research questions, build the capability to halt\ndangerous AI activities, and prepare for international AI agreements.", "published": "2025-05-07 17:35:36", "link": "http://arxiv.org/abs/2505.04592v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization", "abstract": "Reinforcement learning (RL) fine-tuning transforms large language models\nwhile creating a vulnerability we experimentally verify: Our experiment shows\nthat malicious RL fine-tuning dismantles safety guardrails with remarkable\nefficiency, requiring only 50 steps and minimal adversarial prompts, with\nharmful escalating from 0-2 to 7-9. This attack vector particularly threatens\nopen-source models with parameter-level access. Existing defenses targeting\nsupervised fine-tuning prove ineffective against RL's dynamic feedback\nmechanisms. We introduce Reward Neutralization, the first defense framework\nspecifically designed against RL fine-tuning attacks, establishing concise\nrejection patterns that render malicious reward signals ineffective. Our\napproach trains models to produce minimal-information rejections that attackers\ncannot exploit, systematically neutralizing attempts to optimize toward harmful\noutputs. Experiments validate that our approach maintains low harmful scores\n(no greater than 2) after 200 attack steps, while standard models rapidly\ndeteriorate. This work provides the first constructive proof that robust\ndefense against increasingly accessible RL attacks is achievable, addressing a\ncritical security gap for open-weight models.", "published": "2025-05-07 17:18:48", "link": "http://arxiv.org/abs/2505.04578v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Purity Law for Generalizable Neural TSP Solvers", "abstract": "Achieving generalization in neural approaches across different scales and\ndistributions remains a significant challenge for the Traveling Salesman\nProblem~(TSP). A key obstacle is that neural networks often fail to learn\nrobust principles for identifying universal patterns and deriving optimal\nsolutions from diverse instances. In this paper, we first uncover Purity Law\n(PuLa), a fundamental structural principle for optimal TSP solutions, defining\nthat edge prevalence grows exponentially with the sparsity of surrounding\nvertices. Statistically validated across diverse instances, PuLa reveals a\nconsistent bias toward local sparsity in global optima. Building on this\ninsight, we propose Purity Policy Optimization~(PUPO), a novel training\nparadigm that explicitly aligns characteristics of neural solutions with PuLa\nduring the solution construction process to enhance generalization. Extensive\nexperiments demonstrate that PUPO can be seamlessly integrated with popular\nneural solvers, significantly enhancing their generalization performance\nwithout incurring additional computational overhead during inference.", "published": "2025-05-07 16:46:48", "link": "http://arxiv.org/abs/2505.04558v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Risk-sensitive Reinforcement Learning Based on Convex Scoring Functions", "abstract": "We propose a reinforcement learning (RL) framework under a broad class of\nrisk objectives, characterized by convex scoring functions. This class covers\nmany common risk measures, such as variance, Expected Shortfall, entropic\nValue-at-Risk, and mean-risk utility. To resolve the time-inconsistency issue,\nwe consider an augmented state space and an auxiliary variable and recast the\nproblem as a two-state optimization problem. We propose a customized\nActor-Critic algorithm and establish some theoretical approximation guarantees.\nA key theoretical contribution is that our results do not require the Markov\ndecision process to be continuous. Additionally, we propose an auxiliary\nvariable sampling method inspired by the alternating minimization algorithm,\nwhich is convergent under certain conditions. We validate our approach in\nsimulation experiments with a financial application in statistical arbitrage\ntrading, demonstrating the effectiveness of the algorithm.", "published": "2025-05-07 16:31:42", "link": "http://arxiv.org/abs/2505.04553v1", "categories": ["q-fin.MF", "cs.AI", "q-fin.RM"], "primary_category": "q-fin.MF"}
{"title": "Qualitative Analysis of $\u03c9$-Regular Objectives on Robust MDPs", "abstract": "Robust Markov Decision Processes (RMDPs) generalize classical MDPs that\nconsider uncertainties in transition probabilities by defining a set of\npossible transition functions. An objective is a set of runs (or infinite\ntrajectories) of the RMDP, and the value for an objective is the maximal\nprobability that the agent can guarantee against the adversarial environment.\nWe consider (a) reachability objectives, where given a target set of states,\nthe goal is to eventually arrive at one of them; and (b) parity objectives,\nwhich are a canonical representation for $\\omega$-regular objectives. The\nqualitative analysis problem asks whether the objective can be ensured with\nprobability 1.\n  In this work, we study the qualitative problem for reachability and parity\nobjectives on RMDPs without making any assumption over the structures of the\nRMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first\npresent efficient algorithms with oracle access to uncertainty sets that solve\nqualitative problems of reachability and parity objectives. We then report\nexperimental results demonstrating the effectiveness of our oracle-based\napproach on classical RMDP examples from the literature scaling up to thousands\nof states.", "published": "2025-05-07 16:15:40", "link": "http://arxiv.org/abs/2505.04539v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once", "abstract": "Visible and infrared image fusion is one of the most crucial tasks in the\nfield of image fusion, aiming to generate fused images with clear structural\ninformation and high-quality texture features for high-level vision tasks.\nHowever, when faced with severe illumination degradation in visible images, the\nfusion results of existing image fusion methods often exhibit blurry and dim\nvisual effects, posing major challenges for autonomous driving. To this end, a\nDarkness-Free network is proposed to handle Visible and infrared image\ndisentanglement and fusion all at Once (DFVO), which employs a cascaded\nmulti-task approach to replace the traditional two-stage cascaded training\n(enhancement and fusion), addressing the issue of information entropy loss\ncaused by hierarchical data transmission. Specifically, we construct a\nlatent-common feature extractor (LCFE) to obtain latent features for the\ncascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised\nto acquire high-frequency semantic information. Secondly, we design a hyper\ncross-attention module (HCAM) to extract low-frequency information and preserve\ntexture features from source images. Finally, a relevant loss function is\ndesigned to guide the holistic network learning, thereby achieving better image\nfusion. Extensive experiments demonstrate that our proposed approach\noutperforms state-of-the-art alternatives in terms of qualitative and\nquantitative evaluations. Particularly, DFVO can generate clearer, more\ninformative, and more evenly illuminated fusion results in the dark\nenvironments, achieving best performance on the LLVIP dataset with 63.258 dB\nPSNR and 0.724 CC, providing more effective information for high-level vision\ntasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.", "published": "2025-05-07 15:59:45", "link": "http://arxiv.org/abs/2505.04526v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On some improvements to Unbounded Minimax", "abstract": "This paper presents the first experimental evaluation of four previously\nuntested modifications of Unbounded Best-First Minimax algorithm. This\nalgorithm explores the game tree by iteratively expanding the most promising\nsequences of actions based on the current partial game tree. We first evaluate\nthe use of transposition tables, which convert the game tree into a directed\nacyclic graph by merging duplicate states. Second, we compare the original\nalgorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which\ndiffers in its backpropagation strategy: instead of stopping when a stable\nvalue is encountered, it updates values up to the root. This change slightly\nimproves performance when value ties or transposition tables are involved.\nThird, we assess replacing the exact terminal evaluation function with the\nlearned heuristic function. While beneficial when exact evaluations are costly,\nthis modification reduces performance in inexpensive settings. Finally, we\nexamine the impact of the completion technique that prioritizes resolved\nwinning states and avoids resolved losing states. This technique also improves\nperformance. Overall, our findings highlight how targeted modifications can\nenhance the efficiency of Unbounded Best-First Minimax.", "published": "2025-05-07 15:59:19", "link": "http://arxiv.org/abs/2505.04525v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Defining and Quantifying Creative Behavior in Popular Image Generators", "abstract": "Creativity of generative AI models has been a subject of scientific debate in\nthe last years, without a conclusive answer. In this paper, we study creativity\nfrom a practical perspective and introduce quantitative measures that help the\nuser to choose a suitable AI model for a given task. We evaluated our measures\non a number of popular image-to-image generation models, and the results of\nthis suggest that our measures conform to human intuition.", "published": "2025-05-07 15:20:17", "link": "http://arxiv.org/abs/2505.04497v1", "categories": ["cs.CV", "cs.AI", "I.4.m; I.2.m"], "primary_category": "cs.CV"}
{"title": "Model-Based AI planning and Execution Systems for Robotics", "abstract": "Model-based planning and execution systems offer a principled approach to\nbuilding flexible autonomous robots that can perform diverse tasks by\nautomatically combining a host of basic skills. This idea is almost as old as\nmodern robotics. Yet, while diverse general-purpose reasoning architectures\nhave been proposed since, general-purpose systems that are integrated with\nmodern robotic platforms have emerged only recently, starting with the\ninfluential ROSPlan system. Since then, a growing number of model-based systems\nfor robot task-level control have emerged. In this paper, we consider the\ndiverse design choices and issues existing systems attempt to address, the\ndifferent solutions proposed so far, and suggest avenues for future\ndevelopment.", "published": "2025-05-07 15:17:38", "link": "http://arxiv.org/abs/2505.04493v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments", "abstract": "The visually impaired population, especially the severely visually impaired,\nis currently large in scale, and daily activities pose significant challenges\nfor them. Although many studies use large language and vision-language models\nto assist the blind, most focus on static content and fail to meet real-time\nperception needs in dynamic and complex environments, such as daily activities.\nTo provide them with more effective intelligent assistance, it is imperative to\nincorporate advanced visual understanding technologies. Although real-time\nvision and speech interaction VideoLLMs demonstrate strong real-time visual\nunderstanding, no prior work has systematically evaluated their effectiveness\nin assisting visually impaired individuals. In this work, we conduct the first\nsuch evaluation. First, we construct a benchmark dataset (VisAssistDaily),\ncovering three categories of assistive tasks for visually impaired individuals:\nBasic Skills, Home Life Tasks, and Social Life Tasks. The results show that\nGPT-4o achieves the highest task success rate. Next, we conduct a user study to\nevaluate the models in both closed-world and open-world scenarios, further\nexploring the practical challenges of applying VideoLLMs in assistive contexts.\nOne key issue we identify is the difficulty current models face in perceiving\npotential hazards in dynamic environments. To address this, we build an\nenvironment-awareness dataset named SafeVid and introduce a polling mechanism\nthat enables the model to proactively detect environmental risks. We hope this\nwork provides valuable insights and inspiration for future research in this\nfield.", "published": "2025-05-07 15:03:16", "link": "http://arxiv.org/abs/2505.04488v1", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Efficient Flow Matching using Latent Variables", "abstract": "Flow matching models have shown great potential in image generation tasks\namong probabilistic generative models. Building upon the ideas of continuous\nnormalizing flows, flow matching models generalize the transport path of the\ndiffusion models from a simple prior distribution to the data. Most flow\nmatching models in the literature do not explicitly model the underlying\nstructure/manifold in the target data when learning the flow from a simple\nsource distribution like the standard Gaussian. This leads to inefficient\nlearning, especially for many high-dimensional real-world datasets, which often\nreside in a low-dimensional manifold. Existing strategies of incorporating\nmanifolds, including data with underlying multi-modal distribution, often\nrequire expensive training and hence frequently lead to suboptimal performance.\nTo this end, we present \\texttt{Latent-CFM}, which provides simplified\ntraining/inference strategies to incorporate multi-modal data structures using\npretrained deep latent variable models. Through experiments on multi-modal\nsynthetic data and widely used image benchmark datasets, we show that\n\\texttt{Latent-CFM} exhibits improved generation quality with significantly\nless training ($\\sim 50\\%$ less in some cases) and computation than\nstate-of-the-art flow matching models. Using a 2d Darcy flow dataset, we\ndemonstrate that our approach generates more physically accurate samples than\ncompetitive approaches. In addition, through latent space analysis, we\ndemonstrate that our approach can be used for conditional image generation\nconditioned on latent features.", "published": "2025-05-07 14:59:23", "link": "http://arxiv.org/abs/2505.04486v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution", "abstract": "Trajectory prediction is a crucial task in modeling human behavior,\nespecially in fields as social robotics and autonomous vehicle navigation.\nTraditional heuristics based on handcrafted rules often lack accuracy, while\nrecently proposed deep learning approaches suffer from computational cost, lack\nof explainability, and generalization issues that limit their practical\nadoption. In this paper, we introduce TrajEvo, a framework that leverages Large\nLanguage Models (LLMs) to automatically design trajectory prediction\nheuristics. TrajEvo employs an evolutionary algorithm to generate and refine\nprediction heuristics from past trajectory data. We introduce a\nCross-Generation Elite Sampling to promote population diversity and a\nStatistics Feedback Loop allowing the LLM to analyze alternative predictions.\nOur evaluations show TrajEvo outperforms previous heuristic methods on the\nETH-UCY datasets, and remarkably outperforms both heuristics and deep learning\nmethods when generalizing to the unseen SDD dataset. TrajEvo represents a first\nstep toward automated design of fast, explainable, and generalizable trajectory\nprediction heuristics. We make our source code publicly available to foster\nfuture research at https://github.com/ai4co/trajevo.", "published": "2025-05-07 14:51:43", "link": "http://arxiv.org/abs/2505.04480v1", "categories": ["cs.AI", "cs.NE", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Spectral and Temporal Denoising for Differentially Private Optimization", "abstract": "This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a\ndifferentially private optimization method that addresses the challenge of\npreserving performance in DP-SGD, where added noise typically degrades model\nutility. FFTKF integrates frequency-domain noise shaping with Kalman filtering\nto enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP\nguarantees. It employs a high-frequency shaping mask in the Fourier domain to\nconcentrate differential privacy noise in less informative spectral components,\npreserving low-frequency gradient signals. A scalar-gain Kalman filter with\nfinite-difference Hessian approximation further refines the denoised gradients.\nWith a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates\nimproved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100,\nand Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers.\nTheoretical analysis confirms that FFTKF maintains equivalent privacy\nguarantees while achieving a tighter privacy-utility trade-off through reduced\nnoise and controlled bias.", "published": "2025-05-07 14:38:58", "link": "http://arxiv.org/abs/2505.04468v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.NE", "math.IT"], "primary_category": "cs.LG"}
{"title": "Discriminative Ordering Through Ensemble Consensus", "abstract": "Evaluating the performance of clustering models is a challenging task where\nthe outcome depends on the definition of what constitutes a cluster. Due to\nthis design, current existing metrics rarely handle multiple clustering models\nwith diverse cluster definitions, nor do they comply with the integration of\nconstraints when available. In this work, we take inspiration from consensus\nclustering and assume that a set of clustering models is able to uncover hidden\nstructures in the data. We propose to construct a discriminative ordering\nthrough ensemble clustering based on the distance between the connectivity of a\nclustering model and the consensus matrix. We first validate the proposed\nmethod with synthetic scenarios, highlighting that the proposed score ranks the\nmodels that best match the consensus first. We then show that this simple\nranking score significantly outperforms other scoring methods when comparing\nsets of different clustering algorithms that are not restricted to a fixed\nnumber of clusters and is compatible with clustering constraints.", "published": "2025-05-07 14:35:39", "link": "http://arxiv.org/abs/2505.04464v1", "categories": ["cs.LG", "cs.AI", "62H30", "G.3"], "primary_category": "cs.LG"}
{"title": "A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities", "abstract": "Temporal interaction graphs (TIGs), defined by sequences of timestamped\ninteraction events, have become ubiquitous in real-world applications due to\ntheir capability to model complex dynamic system behaviors. As a result,\ntemporal interaction graph representation learning (TIGRL) has garnered\nsignificant attention in recent years. TIGRL aims to embed nodes in TIGs into\nlow-dimensional representations that effectively preserve both structural and\ntemporal information, thereby enhancing the performance of downstream tasks\nsuch as classification, prediction, and clustering within constantly evolving\ndata environments. In this paper, we begin by introducing the foundational\nconcepts of TIGs and emphasize the critical role of temporal dependencies. We\nthen propose a comprehensive taxonomy of state-of-the-art TIGRL methods,\nsystematically categorizing them based on the types of information utilized\nduring the learning process to address the unique challenges inherent to TIGs.\nTo facilitate further research and practical applications, we curate the source\nof datasets and benchmarks, providing valuable resources for empirical\ninvestigations. Finally, we examine key open challenges and explore promising\nresearch directions in TIGRL, laying the groundwork for future advancements\nthat have the potential to shape the evolution of this field.", "published": "2025-05-07 14:31:10", "link": "http://arxiv.org/abs/2505.04461v1", "categories": ["cs.LG", "cs.AI", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform", "abstract": "Automatic music transcription (AMT) is the problem of analyzing an audio\nrecording of a musical piece and detecting notes that are being played. AMT is\na challenging problem, particularly when it comes to polyphonic music. The goal\nof AMT is to produce a score representation of a music piece, by analyzing a\nsound signal containing multiple notes played simultaneously. In this work, we\ndesign a processing pipeline that can transform classical piano audio files in\n.wav format into a music score representation. The features from the audio\nsignals are extracted using the constant-Q transform, and the resulting\ncoefficients are used as an input to the convolutional neural network (CNN)\nmodel.", "published": "2025-05-07 14:20:43", "link": "http://arxiv.org/abs/2505.04451v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FedBWO: Enhancing Communication Efficiency in Federated Learning", "abstract": "Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a\nshared model is collaboratively trained by various clients using their local\ndatasets while keeping the data private. Considering resource-constrained\ndevices, FL clients often suffer from restricted transmission capacity. Aiming\nto enhance the system performance, the communication between clients and server\nneeds to be diminished. Current FL strategies transmit a tremendous amount of\ndata (model weights) within the FL process, which needs a high communication\nbandwidth. Considering resource constraints, increasing the number of clients\nand, consequently, the amount of data (model weights) can lead to a bottleneck.\nIn this paper, we introduce the Federated Black Widow Optimization (FedBWO)\ntechnique to decrease the amount of transmitted data by transmitting only a\nperformance score rather than the local model weights from clients. FedBWO\nemploys the BWO algorithm to improve local model updates. The conducted\nexperiments prove that FedBWO remarkably improves the performance of the global\nmodel and the communication efficiency of the overall system. According to the\nexperimental outcomes, FedBWO enhances the global model accuracy by an average\nof 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically\ndecreases the communication cost compared to other methods.", "published": "2025-05-07 14:02:35", "link": "http://arxiv.org/abs/2505.04435v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Recognizing Ornaments in Vocal Indian Art Music with Active Annotation", "abstract": "Ornamentations, embellishments, or microtonal inflections are essential to\nmelodic expression across many musical traditions, adding depth, nuance, and\nemotional impact to performances. Recognizing ornamentations in singing voices\nis key to MIR, with potential applications in music pedagogy, singer\nidentification, genre classification, and controlled singing voice generation.\nHowever, the lack of annotated datasets and specialized modeling approaches\nremains a major obstacle for progress in this research area. In this work, we\nintroduce R\\=aga Ornamentation Detection (ROD), a novel dataset comprising\nIndian classical music recordings curated by expert musicians. The dataset is\nannotated using a custom Human-in-the-Loop tool for six vocal ornaments marked\nas event-based labels. Using this dataset, we develop an ornamentation\ndetection model based on deep time-series analysis, preserving ornament\nboundaries during the chunking of long audio recordings. We conduct experiments\nusing different train-test configurations within the ROD dataset and also\nevaluate our approach on a separate, manually annotated dataset of Indian\nclassical concert recordings. Our experimental results support the superior\nperformance of our proposed approach over the baseline CRNN.", "published": "2025-05-07 13:52:50", "link": "http://arxiv.org/abs/2505.04419v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "High-speed multiwavelength photonic temporal integration using silicon photonics", "abstract": "Optical systems have been pivotal for energy-efficient computing, performing\nhigh-speed, parallel operations in low-loss carriers. While these predominantly\nanalog optical accelerators bypass digitization to perform parallel\nfloating-point computations, scaling optical hardware to map large-vector sizes\nfor AI tasks remains challenging. Here, we overcome this limitation by\nunfolding scalar operations in time and introducing a\nphotonic-heater-in-lightpath (PHIL) unit for all-optical temporal integration.\nCounterintuitively, we exploit a slow heat dissipation process to integrate\noptical signals modulated at 50 GHz bridging the speed gap between the widely\napplied thermo-optic effects and ultrafast photonics. This architecture\nsupports optical end-to-end signal processing, eliminates inefficient\nelectro-optical conversions, and enables both linear and nonlinear operations\nwithin a unified framework. Our results demonstrate a scalable path towards\nhigh-speed photonic computing through thermally driven integration.", "published": "2025-05-07 13:39:18", "link": "http://arxiv.org/abs/2505.04405v1", "categories": ["physics.optics", "cs.AI", "physics.app-ph"], "primary_category": "physics.optics"}
{"title": "In-Context Adaptation to Concept Drift for Learned Database Operations", "abstract": "Machine learning has demonstrated transformative potential for database\noperations, such as query optimization and in-database data analytics. However,\ndynamic database environments, characterized by frequent updates and evolving\ndata distributions, introduce concept drift, which leads to performance\ndegradation for learned models and limits their practical applicability.\nAddressing this challenge requires efficient frameworks capable of adapting to\nshifting concepts while minimizing the overhead of retraining or fine-tuning.\n  In this paper, we propose FLAIR, an online adaptation framework that\nintroduces a new paradigm called \\textit{in-context adaptation} for learned\ndatabase operations. FLAIR leverages the inherent property of data systems,\ni.e., immediate availability of execution results for predictions, to enable\ndynamic context construction. By formalizing adaptation as $f:(\\mathbf{x} \\,|\n\\,\\mathcal{C}_t) \\to \\mathbf{y}$, with $\\mathcal{C}_t$ representing a dynamic\ncontext memory, FLAIR delivers predictions aligned with the current concept,\neliminating the need for runtime parameter optimization. To achieve this, FLAIR\nintegrates two key modules: a Task Featurization Module for encoding\ntask-specific features into standardized representations, and a Dynamic\nDecision Engine, pre-trained via Bayesian meta-training, to adapt seamlessly\nusing contextual information at runtime. Extensive experiments across key\ndatabase tasks demonstrate that FLAIR outperforms state-of-the-art baselines,\nachieving up to 5.2x faster adaptation and reducing error by 22.5% for\ncardinality estimation.", "published": "2025-05-07 13:36:59", "link": "http://arxiv.org/abs/2505.04404v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Deep residual learning with product units", "abstract": "We propose a deep product-unit residual neural network (PURe) that integrates\nproduct units into residual blocks to improve the expressiveness and parameter\nefficiency of deep convolutional networks. Unlike standard summation neurons,\nproduct units enable multiplicative feature interactions, potentially offering\na more powerful representation of complex patterns. PURe replaces conventional\nconvolutional layers with 2D product units in the second layer of each residual\nblock, eliminating nonlinear activation functions to preserve structural\ninformation. We validate PURe on three benchmark datasets. On Galaxy10 DECaLS,\nPURe34 achieves the highest test accuracy of 84.89%, surpassing the much deeper\nResNet152, while converging nearly five times faster and demonstrating strong\nrobustness to Poisson noise. On ImageNet, PURe architectures outperform\nstandard ResNet models at similar depths, with PURe34 achieving a top-1\naccuracy of 80.27% and top-5 accuracy of 95.78%, surpassing deeper ResNet\nvariants (ResNet50, ResNet101) while utilizing significantly fewer parameters\nand computational resources. On CIFAR-10, PURe consistently outperforms ResNet\nvariants across varying depths, with PURe272 reaching 95.01% test accuracy,\ncomparable to ResNet1001 but at less than half the model size. These results\ndemonstrate that PURe achieves a favorable balance between accuracy,\nefficiency, and robustness. Compared to traditional residual networks, PURe not\nonly achieves competitive classification performance with faster convergence\nand fewer parameters, but also demonstrates greater robustness to noise. Its\neffectiveness across diverse datasets highlights the potential of\nproduct-unit-based architectures for scalable and reliable deep learning in\ncomputer vision.", "published": "2025-05-07 13:21:25", "link": "http://arxiv.org/abs/2505.04397v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic", "abstract": "Transportation systems have long been shaped by complexity and heterogeneity,\ndriven by the interdependency of agent actions and traffic outcomes. The\ndeployment of automated vehicles (AVs) in such systems introduces a new\nchallenge: achieving consensus across safety, interaction quality, and traffic\nperformance. In this work, we position consensus as a fundamental property of\nthe traffic system and aim to quantify it. We use high-resolution trajectory\ndata from the Third Generation Simulation (TGSIM) dataset to empirically\nanalyze AV and human-driven vehicle (HDV) behavior at a signalized urban\nintersection and around vulnerable road users (VRUs). Key metrics, including\nTime-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns,\nheadways, and string stability, are evaluated across the three performance\ndimensions. Results show that full consensus across safety, interaction, and\nperformance is rare, with only 1.63% of AV-VRU interaction frames meeting all\nthree conditions. These findings highlight the need for AV models that\nexplicitly balance multi-dimensional performance in mixed-traffic environments.\nFull reproducibility is supported via our open-source codebase on\nhttps://github.com/wissamkontar/Consensus-AV-Analysis.", "published": "2025-05-07 12:59:59", "link": "http://arxiv.org/abs/2505.04379v1", "categories": ["cs.MA", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "Balancing Accuracy, Calibration, and Efficiency in Active Learning with Vision Transformers Under Label Noise", "abstract": "Fine-tuning pre-trained convolutional neural networks on ImageNet for\ndownstream tasks is well-established. Still, the impact of model size on the\nperformance of vision transformers in similar scenarios, particularly under\nlabel noise, remains largely unexplored. Given the utility and versatility of\ntransformer architectures, this study investigates their practicality under\nlow-budget constraints and noisy labels. We explore how classification accuracy\nand calibration are affected by symmetric label noise in active learning\nsettings, evaluating four vision transformer configurations (Base and Large\nwith 16x16 and 32x32 patch sizes) and three Swin Transformer configurations\n(Tiny, Small, and Base) on CIFAR10 and CIFAR100 datasets, under varying label\nnoise rates. Our findings show that larger ViT models (ViTl32 in particular)\nconsistently outperform their smaller counterparts in both accuracy and\ncalibration, even under moderate to high label noise, while Swin Transformers\nexhibit weaker robustness across all noise levels. We find that smaller patch\nsizes do not always lead to better performance, as ViTl16 performs consistently\nworse than ViTl32 while incurring a higher computational cost. We also find\nthat information-based Active Learning strategies only provide meaningful\naccuracy improvements at moderate label noise rates, but they result in poorer\ncalibration compared to models trained on randomly acquired labels, especially\nat high label noise rates. We hope these insights provide actionable guidance\nfor practitioners looking to deploy vision transformers in resource-constrained\nenvironments, where balancing model complexity, label noise, and compute\nefficiency is critical in model fine-tuning or distillation.", "published": "2025-05-07 12:53:13", "link": "http://arxiv.org/abs/2505.04375v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows", "abstract": "This position paper argues that optimization problem solving can transition\nfrom expert-dependent to evolutionary agentic workflows. Traditional\noptimization practices rely on human specialists for problem formulation,\nalgorithm selection, and hyperparameter tuning, creating bottlenecks that\nimpede industrial adoption of cutting-edge methods. We contend that an\nevolutionary agentic workflow, powered by foundation models and evolutionary\nsearch, can autonomously navigate the optimization space, comprising problem,\nformulation, algorithm, and hyperparameter spaces. Through case studies in\ncloud resource scheduling and ADMM parameter adaptation, we demonstrate how\nthis approach can bridge the gap between academic innovation and industrial\nimplementation. Our position challenges the status quo of human-centric\noptimization workflows and advocates for a more scalable, adaptive approach to\nsolving real-world optimization problems.", "published": "2025-05-07 12:07:49", "link": "http://arxiv.org/abs/2505.04354v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "Uncertain Machine Ethics Planning", "abstract": "Machine Ethics decisions should consider the implications of uncertainty over\ndecisions. Decisions should be made over sequences of actions to reach\npreferable outcomes long term. The evaluation of outcomes, however, may invoke\none or more moral theories, which might have conflicting judgements. Each\ntheory will require differing representations of the ethical situation. For\nexample, Utilitarianism measures numerical values, Deontology analyses duties,\nand Virtue Ethics emphasises moral character. While balancing potentially\nconflicting moral considerations, decisions may need to be made, for example,\nto achieve morally neutral goals with minimal costs. In this paper, we\nformalise the problem as a Multi-Moral Markov Decision Process and a\nMulti-Moral Stochastic Shortest Path Problem. We develop a heuristic algorithm\nbased on Multi-Objective AO*, utilising Sven-Ove Hansson's Hypothetical\nRetrospection procedure for ethical reasoning under uncertainty. Our approach\nis validated by a case study from Machine Ethics literature: the problem of\nwhether to steal insulin for someone who needs it.", "published": "2025-05-07 12:03:15", "link": "http://arxiv.org/abs/2505.04352v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Multi-Granular Attention based Heterogeneous Hypergraph Neural Network", "abstract": "Heterogeneous graph neural networks (HeteGNNs) have demonstrated strong\nabilities to learn node representations by effectively extracting complex\nstructural and semantic information in heterogeneous graphs. Most of the\nprevailing HeteGNNs follow the neighborhood aggregation paradigm, leveraging\nmeta-path based message passing to learn latent node representations. However,\ndue to the pairwise nature of meta-paths, these models fail to capture\nhigh-order relations among nodes, resulting in suboptimal performance.\nAdditionally, the challenge of ``over-squashing'', where long-range message\npassing in HeteGNNs leads to severe information distortion, further limits the\nefficacy of these models. To address these limitations, this paper proposes\nMGA-HHN, a Multi-Granular Attention based Heterogeneous Hypergraph Neural\nNetwork for heterogeneous graph representation learning. MGA-HHN introduces two\nkey innovations: (1) a novel approach for constructing meta-path based\nheterogeneous hypergraphs that explicitly models higher-order semantic\ninformation in heterogeneous graphs through multiple views, and (2) a\nmulti-granular attention mechanism that operates at both the node and hyperedge\nlevels. This mechanism enables the model to capture fine-grained interactions\namong nodes sharing the same semantic context within a hyperedge type, while\npreserving the diversity of semantics across different hyperedge types. As\nsuch, MGA-HHN effectively mitigates long-range message distortion and generates\nmore expressive node representations. Extensive experiments on real-world\nbenchmark datasets demonstrate that MGA-HHN outperforms state-of-the-art\nmodels, showcasing its effectiveness in node classification, node clustering\nand visualization tasks.", "published": "2025-05-07 11:42:00", "link": "http://arxiv.org/abs/2505.04340v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Detecting Concept Drift in Neural Networks Using Chi-squared Goodness of Fit Testing", "abstract": "As the adoption of deep learning models has grown beyond human capacity for\nverification, meta-algorithms are needed to ensure reliable model inference.\nConcept drift detection is a field dedicated to identifying statistical shifts\nthat is underutilized in monitoring neural networks that may encounter\ninference data with distributional characteristics diverging from their\ntraining data. Given the wide variety of model architectures, applications, and\ndatasets, it is important that concept drift detection algorithms are adaptable\nto different inference scenarios. In this paper, we introduce an application of\nthe $\\chi^2$ Goodness of Fit Hypothesis Test as a drift detection\nmeta-algorithm applied to a multilayer perceptron, a convolutional neural\nnetwork, and a transformer trained for machine vision as they are exposed to\nsimulated drift during inference. To that end, we demonstrate how unexpected\ndrops in accuracy due to concept drift can be detected without directly\nexamining the inference outputs. Our approach enhances safety by ensuring\nmodels are continually evaluated for reliability across varying conditions.", "published": "2025-05-07 11:04:47", "link": "http://arxiv.org/abs/2505.04318v1", "categories": ["cs.LG", "cs.AI", "eess.IV"], "primary_category": "cs.LG"}
{"title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning", "abstract": "In this paper, we tackle the problem of learning to play 3v3 multi-drone\nvolleyball, a new embodied competitive task that requires both high-level\nstrategic coordination and low-level agile control. The task is turn-based,\nmulti-agent, and physically grounded, posing significant challenges due to its\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\n(HCSP), a hierarchical reinforcement learning framework that separates\ncentralized high-level strategic decision-making from decentralized low-level\nmotion control. We design a three-stage population-based training pipeline to\nenable both strategy and skill to emerge from scratch without expert\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\nstrategy via self-play with fixed low-level controllers, and (III) joint\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\nperformance, outperforming non-hierarchical self-play and rule-based\nhierarchical baselines with an average 82.9\\% win rate and a 71.5\\% win rate\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\nbehaviors such as role switching and coordinated formations, demonstrating the\neffectiveness of our hierarchical design and training scheme.", "published": "2025-05-07 11:04:36", "link": "http://arxiv.org/abs/2505.04317v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "KERAIA: An Adaptive and Explainable Framework for Dynamic Knowledge Representation and Reasoning", "abstract": "In this paper, we introduce KERAIA, a novel framework and software platform\nfor symbolic knowledge engineering designed to address the persistent\nchallenges of representing, reasoning with, and executing knowledge in dynamic,\ncomplex, and context-sensitive environments. The central research question that\nmotivates this work is: How can unstructured, often tacit, human expertise be\neffectively transformed into computationally tractable algorithms that AI\nsystems can efficiently utilise? KERAIA seeks to bridge this gap by building on\nfoundational concepts such as Minsky's frame-based reasoning and K-lines, while\nintroducing significant innovations. These include Clouds of Knowledge for\ndynamic aggregation, Dynamic Relations (DRels) for context-sensitive\ninheritance, explicit Lines of Thought (LoTs) for traceable reasoning, and\nCloud Elaboration for adaptive knowledge transformation. This approach moves\nbeyond the limitations of traditional, often static, knowledge representation\nparadigms. KERAIA is designed with Explainable AI (XAI) as a core principle,\nensuring transparency and interpretability, particularly through the use of\nLoTs. The paper details the framework's architecture, the KSYNTH representation\nlanguage, and the General Purpose Paradigm Builder (GPPB) to integrate diverse\ninference methods within a unified structure. We validate KERAIA's versatility,\nexpressiveness, and practical applicability through detailed analysis of\nmultiple case studies spanning naval warfare simulation, industrial diagnostics\nin water treatment plants, and strategic decision-making in the game of RISK.\nFurthermore, we provide a comparative analysis against established knowledge\nrepresentation paradigms (including ontologies, rule-based systems, and\nknowledge graphs) and discuss the implementation aspects and computational\nconsiderations of the KERAIA platform.", "published": "2025-05-07 10:56:05", "link": "http://arxiv.org/abs/2505.04313v1", "categories": ["cs.AI", "cs.ET", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning", "abstract": "We introduce a new architecture for Distributional Reinforcement Learning\n(DistRL) that models return distributions using normalizing flows. This\napproach enables flexible, unbounded support for return distributions, in\ncontrast to categorical approaches like C51 that rely on fixed or bounded\nrepresentations. It also offers richer modeling capacity to capture\nmulti-modality, skewness, and tail behavior than quantile based approaches. Our\nmethod is significantly more parameter-efficient than categorical approaches.\nStandard metrics used to train existing models like KL divergence or\nWasserstein distance either are scale insensitive or have biased sample\ngradients, especially when return supports do not overlap. To address this, we\npropose a novel surrogate for the Cram\\`er distance, that is geometry-aware and\ncomputable directly from the return distribution's PDF, avoiding the costly CDF\ncomputation. We test our model on the ATARI-5 sub-benchmark and show that our\napproach outperforms PDF based models while remaining competitive with quantile\nbased methods.", "published": "2025-05-07 10:49:53", "link": "http://arxiv.org/abs/2505.04310v1", "categories": ["cs.AI", "math.OC"], "primary_category": "cs.AI"}
{"title": "Guardians of the Web: The Evolution and Future of Website Information Security", "abstract": "Website information security has become a critical concern in the digital\nage. This article explores the evolution of website information security,\nexamining its historical development, current practices, and future directions.\nThe early beginnings from the 1960s to the 1980s laid the groundwork for modern\ncybersecurity, with the development of ARPANET, TCP/IP, public-key\ncryptography, and the first antivirus programs. The 1990s marked a\ntransformative era, driven by the commercialization of the Internet and the\nemergence of web-based services. As the Internet grew, so did the range and\nsophistication of cyber threats, leading to advancements in security\ntechnologies such as the Secure Sockets Layer (SSL) protocol, password\nprotection, and firewalls. Current practices in website information security\ninvolve a multi-layered approach, including encryption, secure coding\npractices, regular security audits, and user education. The future of website\ninformation security is expected to be shaped by emerging technologies such as\nartificial intelligence, blockchain, and quantum computing, as well as the\nincreasing importance of international cooperation and standardization efforts.\nAs cyber threats continue to evolve, ongoing research and innovation in website\ninformation security will be essential to protect sensitive information and\nmaintain trust in the digital world.", "published": "2025-05-07 10:46:33", "link": "http://arxiv.org/abs/2505.04308v1", "categories": ["cs.CR", "cs.AI", "F.2.2, I.2.7"], "primary_category": "cs.CR"}
{"title": "Sparsity is All You Need: Rethinking Biological Pathway-Informed Approaches in Deep Learning", "abstract": "Biologically-informed neural networks typically leverage pathway annotations\nto enhance performance in biomedical applications. We hypothesized that the\nbenefits of pathway integration does not arise from its biological relevance,\nbut rather from the sparsity it introduces. We conducted a comprehensive\nanalysis of all relevant pathway-based neural network models for predictive\ntasks, critically evaluating each study's contributions. From this review, we\ncurated a subset of methods for which the source code was publicly available.\nThe comparison of the biologically informed state-of-the-art deep learning\nmodels and their randomized counterparts showed that models based on randomized\ninformation performed equally well as biologically informed ones across\ndifferent metrics and datasets. Notably, in 3 out of the 15 analyzed models,\nthe randomized versions even outperformed their biologically informed\ncounterparts. Moreover, pathway-informed models did not show any clear\nadvantage in interpretability, as randomized models were still able to identify\nrelevant disease biomarkers despite lacking explicit pathway information. Our\nfindings suggest that pathway annotations may be too noisy or inadequately\nexplored by current methods. Therefore, we propose a methodology that can be\napplied to different domains and can serve as a robust benchmark for\nsystematically comparing novel pathway-informed models against their randomized\ncounterparts. This approach enables researchers to rigorously determine whether\nobserved performance improvements can be attributed to biological insights.", "published": "2025-05-07 10:14:31", "link": "http://arxiv.org/abs/2505.04300v1", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting", "abstract": "Due to the dynamics of underlying physics and external influences, the\nuncertainty of time series often varies over time. However, existing Denoising\nDiffusion Probabilistic Models (DDPMs) often fail to capture this\nnon-stationary nature, constrained by their constant variance assumption from\nthe additive noise model (ANM). In this paper, we innovatively utilize the\nLocation-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of\nANM. A diffusion-based probabilistic forecasting framework, termed\nNon-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of\nmodeling the changing pattern of uncertainty. Specifically, NsDiff combines a\ndenoising diffusion-based conditional generative model with a pre-trained\nconditional mean and variance estimator, enabling adaptive endpoint\ndistribution modeling. Furthermore, we propose an uncertainty-aware noise\nschedule, which dynamically adjusts the noise levels to accurately reflect the\ndata uncertainty at each step and integrates the time-varying variances into\nthe diffusion process. Extensive experiments conducted on nine real-world and\nsynthetic datasets demonstrate the superior performance of NsDiff compared to\nexisting approaches. Code is available at https://github.com/wwy155/NsDiff.", "published": "2025-05-07 09:29:39", "link": "http://arxiv.org/abs/2505.04278v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Object-Shot Enhanced Grounding Network for Egocentric Video", "abstract": "Egocentric video grounding is a crucial task for embodied intelligence\napplications, distinct from exocentric video moment localization. Existing\nmethods primarily focus on the distributional differences between egocentric\nand exocentric videos but often neglect key characteristics of egocentric\nvideos and the fine-grained information emphasized by question-type queries. To\naddress these limitations, we propose OSGNet, an Object-Shot enhanced Grounding\nNetwork for egocentric video. Specifically, we extract object information from\nvideos to enrich video representation, particularly for objects highlighted in\nthe textual query but not directly captured in the video features.\nAdditionally, we analyze the frequent shot movements inherent to egocentric\nvideos, leveraging these features to extract the wearer's attention\ninformation, which enhances the model's ability to perform modality alignment.\nExperiments conducted on three datasets demonstrate that OSGNet achieves\nstate-of-the-art performance, validating the effectiveness of our approach. Our\ncode can be found at https://github.com/Yisen-Feng/OSGNet.", "published": "2025-05-07 09:20:12", "link": "http://arxiv.org/abs/2505.04270v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Weaponizing Language Models for Cybersecurity Offensive Operations: Automating Vulnerability Assessment Report Validation; A Review Paper", "abstract": "This, with the ever-increasing sophistication of cyberwar, calls for novel\nsolutions. In this regard, Large Language Models (LLMs) have emerged as a\nhighly promising tool for defensive and offensive cybersecurity-related\nstrategies. While existing literature has focused much on the defensive use of\nLLMs, when it comes to their offensive utilization, very little has been\nreported-namely, concerning Vulnerability Assessment (VA) report validation.\nConsequentially, this paper tries to fill that gap by investigating the\ncapabilities of LLMs in automating and improving the validation process of the\nreport of the VA. From the critical review of the related literature, this\npaper hereby proposes a new approach to using the LLMs in the automation of the\nanalysis and within the validation process of the report of the VA that could\npotentially reduce the number of false positives and generally enhance\nefficiency. These results are promising for LLM automatization for improving\nvalidation on reports coming from VA in order to improve accuracy while\nreducing human effort and security postures. The contribution of this paper\nprovides further evidence about the offensive and defensive LLM capabilities\nand therefor helps in devising more appropriate cybersecurity strategies and\ntools accordingly.", "published": "2025-05-07 09:14:55", "link": "http://arxiv.org/abs/2505.04265v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering", "abstract": "As large language models (LLMs) improve in their capacity to serve as\npersonal AI assistants, their ability to output uniquely tailored, personalized\nresponses that align with the soft preferences of their users is essential for\nenhancing user satisfaction and retention. However, untrained lay users have\npoor prompt specification abilities and often struggle with conveying their\nlatent preferences to AI assistants. To address this, we leverage activation\nsteering to guide LLMs to align with interpretable preference dimensions during\ninference. In contrast to memory-based personalization methods that require\nlonger user history, steering is extremely lightweight and can be easily\ncontrolled by the user via an linear strength factor. We embed steering into\nthree different interactive chatbot interfaces and conduct a within-subjects\nuser study (n=14) to investigate how end users prefer to personalize their\nconversations. The results demonstrate the effectiveness of preference-based\nsteering for aligning real-world conversations with hidden user preferences,\nand highlight further insights on how diverse values around control, usability,\nand transparency lead users to prefer different interfaces.", "published": "2025-05-07 09:10:51", "link": "http://arxiv.org/abs/2505.04260v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering", "abstract": "Multi-agent autonomous systems (MAS) are better at addressing challenges that\nspans across multiple domains than singular autonomous agents. This holds true\nwithin the field of software engineering (SE) as well. The state-of-the-art\nresearch on MAS within SE focuses on integrating LLMs at the core of autonomous\nagents to create LLM-based multi-agent autonomous (LMA) systems. However, the\nintroduction of LMA systems into SE brings a plethora of challenges. One of the\nmajor challenges is the strategic allocation of tasks between humans and the\nLMA system in a trustworthy manner. To address this challenge, a RACI-based\nframework is proposed in this work in progress article, along with\nimplementation guidelines and an example implementation of the framework. The\nproposed framework can facilitate efficient collaboration, ensure\naccountability, and mitigate potential risks associated with LLM-driven\nautomation while aligning with the Trustworthy AI guidelines. The future steps\nfor this work delineating the planned empirical validation method are also\npresented.", "published": "2025-05-07 08:55:15", "link": "http://arxiv.org/abs/2505.04251v1", "categories": ["cs.SE", "cs.AI", "cs.MA"], "primary_category": "cs.SE"}
{"title": "FRAIN to Train: A Fast-and-Reliable Solution for Decentralized Federated Learning", "abstract": "Federated learning (FL) enables collaborative model training across\ndistributed clients while preserving data locality. Although FedAvg pioneered\nsynchronous rounds for global model averaging, slower devices can delay\ncollective progress. Asynchronous FL (e.g., FedAsync) addresses stragglers by\ncontinuously integrating client updates, yet naive implementations risk client\ndrift due to non-IID data and stale contributions. Some Blockchain-based FL\napproaches (e.g., BRAIN) employ robust weighting or scoring of updates to\nresist malicious or misaligned proposals. However, performance drops can still\npersist under severe data heterogeneity or high staleness, and synchronization\noverhead has emerged as a new concern due to its aggregator-free architectures.\n  We introduce Fast-and-Reliable AI Network, FRAIN, a new asynchronous FL\nmethod that mitigates these limitations by incorporating two key ideas. First,\nour FastSync strategy eliminates the need to replay past model versions,\nenabling newcomers and infrequent participants to efficiently approximate the\nglobal model. Second, we adopt spherical linear interpolation (SLERP) when\nmerging parameters, preserving models' directions and alleviating destructive\ninterference from divergent local training.\n  Experiments with a CNN image-classification model and a Transformer-based\nlanguage model demonstrate that FRAIN achieves more stable and robust\nconvergence than FedAvg, FedAsync, and BRAIN, especially under harsh\nenvironments: non-IID data distributions, networks that experience delays and\nrequire frequent re-synchronization, and the presence of malicious nodes.", "published": "2025-05-07 08:20:23", "link": "http://arxiv.org/abs/2505.04223v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "To Judge or not to Judge: Using LLM Judgements for Advertiser Keyphrase Relevance at eBay", "abstract": "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks/sales). The relevance\nof advertiser keyphrases plays an important role in preventing the inundation\nof search systems with numerous irrelevant items that compete for attention in\nauctions, in addition to maintaining a healthy seller perception. In this work,\nwe describe the shortcomings of training Advertiser keyphrase relevance filter\nmodels on click/sales/search relevance signals and the importance of aligning\nwith human judgment, as sellers have the power to adopt or reject said\nkeyphrase recommendations. In this study, we frame Advertiser keyphrase\nrelevance as a complex interaction between 3 dynamical systems -- seller\njudgment, which influences seller adoption of our product, Advertising, which\nprovides the keyphrases to bid on, and Search, who holds the auctions for the\nsame keyphrases. This study discusses the practicalities of using human\njudgment via a case study at eBay Advertising and demonstrate that using\nLLM-as-a-judge en-masse as a scalable proxy for seller judgment to train our\nrelevance models achieves a better harmony across the three systems -- provided\nthat they are bound by a meticulous evaluation framework grounded in business\nmetrics.", "published": "2025-05-07 08:03:25", "link": "http://arxiv.org/abs/2505.04209v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "An Enhanced YOLOv8 Model for Real-Time and Accurate Pothole Detection and Measurement", "abstract": "Potholes cause vehicle damage and traffic accidents, creating serious safety\nand economic problems. Therefore, early and accurate detection of potholes is\ncrucial. Existing detection methods are usually only based on 2D RGB images and\ncannot accurately analyze the physical characteristics of potholes. In this\npaper, a publicly available dataset of RGB-D images (PothRGBD) is created and\nan improved YOLOv8-based model is proposed for both pothole detection and\npothole physical features analysis. The Intel RealSense D415 depth camera was\nused to collect RGB and depth data from the road surfaces, resulting in a\nPothRGBD dataset of 1000 images. The data was labeled in YOLO format suitable\nfor segmentation. A novel YOLO model is proposed based on the YOLOv8n-seg\narchitecture, which is structurally improved with Dynamic Snake Convolution\n(DSConv), Simple Attention Module (SimAM) and Gaussian Error Linear Unit\n(GELU). The proposed model segmented potholes with irregular edge structure\nmore accurately, and performed perimeter and depth measurements on depth maps\nwith high accuracy. The standard YOLOv8n-seg model achieved 91.9% precision,\n85.2% recall and 91.9% mAP@50. With the proposed model, the values increased to\n93.7%, 90.4% and 93.8% respectively. Thus, an improvement of 1.96% in\nprecision, 6.13% in recall and 2.07% in mAP was achieved. The proposed model\nperforms pothole detection as well as perimeter and depth measurement with high\naccuracy and is suitable for real-time applications due to its low model\ncomplexity. In this way, a lightweight and effective model that can be used in\ndeep learning-based intelligent transportation solutions has been acquired.", "published": "2025-05-07 07:58:57", "link": "http://arxiv.org/abs/2505.04207v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "S3D: Sketch-Driven 3D Model Generation", "abstract": "Generating high-quality 3D models from 2D sketches is a challenging task due\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\npresent S3D, a novel framework that converts simple hand-drawn sketches into\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\narchitecture to convert sketches into face segmentation masks, which are then\nused to generate a 3D representation that can be rendered from novel views. To\nensure robust consistency between the sketch domain and the 3D output, we\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\nfeatures with the initial encoder outputs of the 3D generation module,\nsignificantly enhancing reconstruction fidelity. To further enhance the\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\nThis streamlined framework demonstrates the effectiveness of S3D in generating\nhigh-quality 3D models from sketch inputs. The source code for this project is\npublicly available at https://github.com/hailsong/S3D.", "published": "2025-05-07 07:34:37", "link": "http://arxiv.org/abs/2505.04185v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation", "abstract": "Text recognition in natural images remains a challenging yet essential task,\nwith broad applications spanning computer vision and natural language\nprocessing. This paper introduces a novel end-to-end framework that combines\nResNet and Vision Transformer backbones with advanced methodologies, including\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\nFields (CRF). These innovations collectively enhance feature representation and\nimprove Optical Character Recognition (OCR) performance. Specifically, the\nframework substitutes standard convolution layers in the third and fourth\nblocks with Deformable Convolutions, leverages adaptive dropout for\nregularization, and incorporates CRF for more refined sequence modeling.\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\nof 77.77%. These results establish a new state-of-the-art for text recognition,\ndemonstrating the robustness of the approach across diverse and challenging\ndatasets.", "published": "2025-05-07 07:06:04", "link": "http://arxiv.org/abs/2505.04175v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "On-Device LLM for Context-Aware Wi-Fi Roaming", "abstract": "Wireless roaming is a critical yet challenging task for maintaining seamless\nconnectivity in dynamic mobile environments. Conventional threshold-based or\nheuristic schemes often fail, leading to either sticky or excessive handovers.\nWe introduce the first cross-layer use of an on-device large language model\n(LLM): high-level reasoning in the application layer that issues real-time\nactions executed in the PHY/MAC stack. The LLM addresses two tasks: (i)\ncontext-aware AP selection, where structured prompts fuse environmental cues\n(e.g., location, time) to choose the best BSSID; and (ii) dynamic threshold\nadjustment, where the model adaptively decides when to roam. To satisfy the\ntight latency and resource budgets of edge hardware, we apply a suite of\noptimizations-chain-of-thought prompting, parameter-efficient fine-tuning, and\nquantization. Experiments on indoor and outdoor datasets show that our approach\nsurpasses legacy heuristics and DRL baselines, achieving a strong balance\nbetween roaming stability and signal quality. These findings underscore the\npromise of application-layer LLM reasoning for lower-layer wireless control in\nfuture edge systems.", "published": "2025-05-07 07:04:49", "link": "http://arxiv.org/abs/2505.04174v1", "categories": ["cs.LG", "cs.AI", "cs.NI", "eess.SP"], "primary_category": "cs.LG"}
{"title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.", "published": "2025-05-07 06:34:34", "link": "http://arxiv.org/abs/2505.04165v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning", "abstract": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.", "published": "2025-05-07 05:55:45", "link": "http://arxiv.org/abs/2505.04147v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Polynomial-Time Relational Probabilistic Inference in Open Universes", "abstract": "Reasoning under uncertainty is a fundamental challenge in Artificial\nIntelligence. As with most of these challenges, there is a harsh dilemma\nbetween the expressive power of the language used, and the tractability of the\ncomputational problem posed by reasoning. Inspired by human reasoning, we\nintroduce a method of first-order relational probabilistic inference that\nsatisfies both criteria, and can handle hybrid (discrete and continuous)\nvariables. Specifically, we extend sum-of-squares logic of expectation to\nrelational settings, demonstrating that lifted reasoning in the bounded-degree\nfragment for knowledge bases of bounded quantifier rank can be performed in\npolynomial time, even with an a priori unknown and/or countably infinite set of\nobjects. Crucially, our notion of tractability is framed in proof-theoretic\nterms, which extends beyond the syntactic properties of the language or\nqueries. We are able to derive the tightest bounds provable by proofs of a\ngiven degree and size and establish completeness in our sum-of-squares\nrefutations for fixed degrees.", "published": "2025-05-07 04:14:03", "link": "http://arxiv.org/abs/2505.04115v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLMs' Suitability for Network Security: A Case Study of STRIDE Threat Modeling", "abstract": "Artificial Intelligence (AI) is expected to be an integral part of\nnext-generation AI-native 6G networks. With the prevalence of AI, researchers\nhave identified numerous use cases of AI in network security. However, there\nare almost nonexistent studies that analyze the suitability of Large Language\nModels (LLMs) in network security. To fill this gap, we examine the suitability\nof LLMs in network security, particularly with the case study of STRIDE threat\nmodeling. We utilize four prompting techniques with five LLMs to perform STRIDE\nclassification of 5G threats. From our evaluation results, we point out key\nfindings and detailed insights along with the explanation of the possible\nunderlying factors influencing the behavior of LLMs in the modeling of certain\nthreats. The numerical results and the insights support the necessity for\nadjusting and fine-tuning LLMs for network security use cases.", "published": "2025-05-07 03:37:49", "link": "http://arxiv.org/abs/2505.04101v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "An Empirical Study of OpenAI API Discussions on Stack Overflow", "abstract": "The rapid advancement of large language models (LLMs), represented by\nOpenAI's GPT series, has significantly impacted various domains such as natural\nlanguage processing, software development, education, healthcare, finance, and\nscientific research. However, OpenAI APIs introduce unique challenges that\ndiffer from traditional APIs, such as the complexities of prompt engineering,\ntoken-based cost management, non-deterministic outputs, and operation as black\nboxes. To the best of our knowledge, the challenges developers encounter when\nusing OpenAI APIs have not been explored in previous empirical studies. To fill\nthis gap, we conduct the first comprehensive empirical study by analyzing 2,874\nOpenAI API-related discussions from the popular Q&A forum Stack Overflow. We\nfirst examine the popularity and difficulty of these posts. After manually\ncategorizing them into nine OpenAI API-related categories, we identify specific\nchallenges associated with each category through topic modeling analysis. Based\non our empirical findings, we finally propose actionable implications for\ndevelopers, LLM vendors, and researchers.", "published": "2025-05-07 02:51:32", "link": "http://arxiv.org/abs/2505.04084v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Plexus: Taming Billion-edge Graphs with 3D Parallel GNN Training", "abstract": "Graph neural networks have emerged as a potent class of neural networks\ncapable of leveraging the connectivity and structure of real-world graphs to\nlearn intricate properties and relationships between nodes. Many real-world\ngraphs exceed the memory capacity of a GPU due to their sheer size, and using\nGNNs on them requires techniques such as mini-batch sampling to scale. However,\nthis can lead to reduced accuracy in some cases, and sampling and data transfer\nfrom the CPU to the GPU can also slow down training. On the other hand,\ndistributed full-graph training suffers from high communication overhead and\nload imbalance due to the irregular structure of graphs. We propose Plexus, a\nthree-dimensional (3D) parallel approach for full-graph training that tackles\nthese issues and scales to billion-edge graphs. Additionally, we introduce\noptimizations such as a permutation scheme for load balancing, and a\nperformance model to predict the optimal 3D configuration. We evaluate Plexus\non several graph datasets and show scaling results for up to 2048 GPUs on\nPerlmutter, which is 33% of the machine, and 2048 GCDs on Frontier. Plexus\nachieves unprecedented speedups of 2.3x-12.5x over existing methods and a\nreduction in the time to solution by 5.2-8.7x on Perlmutter and 7-54.2x on\nFrontier.", "published": "2025-05-07 02:49:52", "link": "http://arxiv.org/abs/2505.04083v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "LLM-e Guess: Can LLMs Capabilities Advance Without Hardware Progress?", "abstract": "This paper examines whether large language model (LLM) capabilities can\ncontinue to advance without additional compute by analyzing the development and\nrole of algorithms used in state-of-the-art LLMs. Motivated by regulatory\nefforts that have largely focused on restricting access to high-performance\nhardware, we ask: Can LLMs progress in a compute-constrained environment, and\nhow do algorithmic innovations perform under such conditions?\n  To address these questions, we introduce a novel classification framework\nthat distinguishes between compute-dependent innovations -- which yield\ndisproportionate benefits at high compute levels (e.g., the Transformer\narchitecture and mixture-of-experts models) and compute-independent\ninnovations, which improve efficiency across all compute scales (e.g., rotary\npositional encoding, FlashAttention, or layer normalization). We quantify these\ncontributions using a metric called compute-equivalent gain (CEG), which\nestimates the additional compute that would be required to achieve similar\nimprovements without these algorithmic advancements.\n  To validate this framework, we conduct small-scale training experiments with\na scaled-down GPT-2 model. Our results confirm that compute-independent\nadvancements yield meaningful performance gains even in resource-constrained\nsettings, with a CEG of up to $3.5\\times$ over a baseline model. By contrast,\ncompute-dependent advancements provided little benefit or even degraded\nperformance at the small scale, reinforcing the importance of compute\navailability for certain algorithmic gains.", "published": "2025-05-07 02:26:17", "link": "http://arxiv.org/abs/2505.04075v1", "categories": ["cs.LG", "cs.AI", "I.2"], "primary_category": "cs.LG"}
{"title": "Izhikevich-Inspired Temporal Dynamics for Enhancing Privacy, Efficiency, and Transferability in Spiking Neural Networks", "abstract": "Biological neurons exhibit diverse temporal spike patterns, which are\nbelieved to support efficient, robust, and adaptive neural information\nprocessing. While models such as Izhikevich can replicate a wide range of these\nfiring dynamics, their complexity poses challenges for directly integrating\nthem into scalable spiking neural networks (SNN) training pipelines. In this\nwork, we propose two probabilistically driven, input-level temporal spike\ntransformations: Poisson-Burst and Delayed-Burst that introduce biologically\ninspired temporal variability directly into standard Leaky Integrate-and-Fire\n(LIF) neurons. This enables scalable training and systematic evaluation of how\nspike timing dynamics affect privacy, generalization, and learning performance.\nPoisson-Burst modulates burst occurrence based on input intensity, while\nDelayed-Burst encodes input strength through burst onset timing. Through\nextensive experiments across multiple benchmarks, we demonstrate that\nPoisson-Burst maintains competitive accuracy and lower resource overhead while\nexhibiting enhanced privacy robustness against membership inference attacks,\nwhereas Delayed-Burst provides stronger privacy protection at a modest accuracy\ntrade-off. These findings highlight the potential of biologically grounded\ntemporal spike dynamics in improving the privacy, generalization and biological\nplausibility of neuromorphic learning systems.", "published": "2025-05-07 00:27:00", "link": "http://arxiv.org/abs/2505.04034v1", "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "cs.NE"}
{"title": "PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer", "abstract": "Shape primitive abstraction, which decomposes complex 3D shapes into simple\ngeometric elements, plays a crucial role in human visual cognition and has\nbroad applications in computer vision and graphics. While recent advances in 3D\ncontent generation have shown remarkable progress, existing primitive\nabstraction methods either rely on geometric optimization with limited semantic\nunderstanding or learn from small-scale, category-specific datasets, struggling\nto generalize across diverse shape categories. We present PrimitiveAnything, a\nnovel framework that reformulates shape primitive abstraction as a primitive\nassembly generation task. PrimitiveAnything includes a shape-conditioned\nprimitive transformer for auto-regressive generation and an ambiguity-free\nparameterization scheme to represent multiple types of primitives in a unified\nmanner. The proposed framework directly learns the process of primitive\nassembly from large-scale human-crafted abstractions, enabling it to capture\nhow humans decompose complex shapes into primitive elements. Through extensive\nexperiments, we demonstrate that PrimitiveAnything can generate high-quality\nprimitive assemblies that better align with human perception while maintaining\ngeometric fidelity across diverse shape categories. It benefits various 3D\napplications and shows potential for enabling primitive-based user-generated\ncontent (UGC) in games. Project page: https://primitiveanything.github.io", "published": "2025-05-07 17:59:46", "link": "http://arxiv.org/abs/2505.04622v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "On Path to Multimodal Generalist: General-Level and General-Bench", "abstract": "The Multimodal Large Language Model (MLLM) is currently experiencing rapid\ngrowth, driven by the advanced capabilities of LLMs. Unlike earlier\nspecialists, existing MLLMs are evolving towards a Multimodal Generalist\nparadigm. Initially limited to understanding multiple modalities, these models\nhave advanced to not only comprehend but also generate across modalities. Their\ncapabilities have expanded from coarse-grained to fine-grained multimodal\nunderstanding and from supporting limited modalities to arbitrary ones. While\nmany benchmarks exist to assess MLLMs, a critical question arises: Can we\nsimply assume that higher performance across tasks indicates a stronger MLLM\ncapability, bringing us closer to human-level AI? We argue that the answer is\nnot as straightforward as it seems. This project introduces General-Level, an\nevaluation framework that defines 5-scale levels of MLLM performance and\ngenerality, offering a methodology to compare MLLMs and gauge the progress of\nexisting systems towards more robust multimodal generalists and, ultimately,\ntowards AGI. At the core of the framework is the concept of Synergy, which\nmeasures whether models maintain consistent capabilities across comprehension\nand generation, and across multiple modalities. To support this evaluation, we\npresent General-Bench, which encompasses a broader spectrum of skills,\nmodalities, formats, and capabilities, including over 700 tasks and 325,800\ninstances. The evaluation results that involve over 100 existing\nstate-of-the-art MLLMs uncover the capability rankings of generalists,\nhighlighting the challenges in reaching genuine AI. We expect this project to\npave the way for future research on next-generation multimodal foundation\nmodels, providing a robust infrastructure to accelerate the realization of AGI.\nProject page: https://generalist.top/", "published": "2025-05-07 17:59:32", "link": "http://arxiv.org/abs/2505.04620v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "abstract": "Vision is well-known for its use in manipulation, especially using visual\nservoing. To make it robust, multiple cameras are needed to expand the field of\nview. That is computationally challenging. Merging multiple views and using\nQ-learning allows the design of more effective representations and optimization\nof sample efficiency. Such a solution might be expensive to deploy. To mitigate\nthis, we introduce a Merge And Disentanglement (MAD) algorithm that efficiently\nmerges views to increase sample efficiency while augmenting with single-view\nfeatures to allow lightweight deployment and ensure robust policies. We\ndemonstrate the efficiency and robustness of our approach using Meta-World and\nManiSkill3. For project website and code, see https://aalmuzairee.github.io/mad", "published": "2025-05-07 17:59:28", "link": "http://arxiv.org/abs/2505.04619v1", "categories": ["cs.LG", "cs.CV", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Person Recognition at Altitude and Range: Fusion of Face, Body Shape and Gait", "abstract": "We address the problem of whole-body person recognition in unconstrained\nenvironments. This problem arises in surveillance scenarios such as those in\nthe IARPA Biometric Recognition and Identification at Altitude and Range\n(BRIAR) program, where biometric data is captured at long standoff distances,\nelevated viewing angles, and under adverse atmospheric conditions (e.g.,\nturbulence and high wind velocity). To this end, we propose FarSight, a unified\nend-to-end system for person recognition that integrates complementary\nbiometric cues across face, gait, and body shape modalities. FarSight\nincorporates novel algorithms across four core modules: multi-subject detection\nand tracking, recognition-aware video restoration, modality-specific biometric\nfeature encoding, and quality-guided multi-modal fusion. These components are\ndesigned to work cohesively under degraded image conditions, large pose and\nscale variations, and cross-domain gaps. Extensive experiments on the BRIAR\ndataset, one of the most comprehensive benchmarks for long-range, multi-modal\nbiometric recognition, demonstrate the effectiveness of FarSight. Compared to\nour preliminary system, this system achieves a 34.1% absolute gain in 1:1\nverification accuracy (TAR@0.1% FAR), a 17.8% increase in closed-set\nidentification (Rank-20), and a 34.3% reduction in open-set identification\nerrors (FNIR@1% FPIR). Furthermore, FarSight was evaluated in the 2025 NIST RTE\nFace in Video Evaluation (FIVE), which conducts standardized face recognition\ntesting on the BRIAR dataset. These results establish FarSight as a\nstate-of-the-art solution for operational biometric recognition in challenging\nreal-world conditions.", "published": "2025-05-07 17:58:25", "link": "http://arxiv.org/abs/2505.04616v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FastMap: Revisiting Dense and Scalable Structure from Motion", "abstract": "We propose FastMap, a new global structure from motion method focused on\nspeed and simplicity. Previous methods like COLMAP and GLOMAP are able to\nestimate high-precision camera poses, but suffer from poor scalability when the\nnumber of matched keypoint pairs becomes large. We identify two key factors\nleading to this problem: poor parallelization and computationally expensive\noptimization steps. To overcome these issues, we design an SfM framework that\nrelies entirely on GPU-friendly operations, making it easily parallelizable.\nMoreover, each optimization step runs in time linear to the number of image\npairs, independent of keypoint pairs or 3D points. Through extensive\nexperiments, we show that FastMap is one to two orders of magnitude faster than\nCOLMAP and GLOMAP on large-scale scenes with comparable pose accuracy.", "published": "2025-05-07 17:56:15", "link": "http://arxiv.org/abs/2505.04612v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning", "abstract": "OpenAI's CLIP, released in early 2021, have long been the go-to choice of\nvision encoder for building multimodal foundation models. Although recent\nalternatives such as SigLIP have begun to challenge this status quo, to our\nknowledge none are fully open: their training data remains proprietary and/or\ntheir training recipes are not released. This paper fills this gap with\nOpenVision, a fully-open, cost-effective family of vision encoders that match\nor surpass the performance of OpenAI's CLIP when integrated into multimodal\nframeworks like LLaVA. OpenVision builds on existing works -- e.g., CLIPS for\ntraining framework and Recap-DataComp-1B for training data -- while revealing\nmultiple key insights in enhancing encoder quality and showcasing practical\nbenefits in advancing multimodal models. By releasing vision encoders spanning\nfrom 5.9M to 632.1M parameters, OpenVision offers practitioners a flexible\ntrade-off between capacity and efficiency in building multimodal models: larger\nmodels deliver enhanced multimodal performance, while smaller versions enable\nlightweight, edge-ready multimodal deployments.", "published": "2025-05-07 17:48:35", "link": "http://arxiv.org/abs/2505.04601v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamic Network Flow Optimization for Task Scheduling in PTZ Camera Surveillance Systems", "abstract": "This paper presents a novel approach for optimizing the scheduling and\ncontrol of Pan-Tilt-Zoom (PTZ) cameras in dynamic surveillance environments.\nThe proposed method integrates Kalman filters for motion prediction with a\ndynamic network flow model to enhance real-time video capture efficiency. By\nassigning Kalman filters to tracked objects, the system predicts future\nlocations, enabling precise scheduling of camera tasks. This prediction-driven\napproach is formulated as a network flow optimization, ensuring scalability and\nadaptability to various surveillance scenarios. To further reduce redundant\nmonitoring, we also incorporate group-tracking nodes, allowing multiple objects\nto be captured within a single camera focus when appropriate. In addition, a\nvalue-based system is introduced to prioritize camera actions, focusing on the\ntimely capture of critical events. By adjusting the decay rates of these values\nover time, the system ensures prompt responses to tasks with imminent\ndeadlines. Extensive simulations demonstrate that this approach improves\ncoverage, reduces average wait times, and minimizes missed events compared to\ntraditional master-slave camera systems. Overall, our method significantly\nenhances the efficiency, scalability, and effectiveness of surveillance\nsystems, particularly in dynamic and crowded environments.", "published": "2025-05-07 17:37:53", "link": "http://arxiv.org/abs/2505.04596v1", "categories": ["math.OC", "cs.CV", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection", "abstract": "Accurately predicting 3D attributes is crucial for monocular 3D object\ndetection (Mono3D), with depth estimation posing the greatest challenge due to\nthe inherent ambiguity in mapping 2D images to 3D space. While existing methods\nleverage multiple depth cues (e.g., estimating depth uncertainty, modeling\ndepth error) to improve depth accuracy, they overlook that accurate depth\nprediction requires conditioning on other 3D attributes, as these attributes\nare intrinsically inter-correlated through the 3D to 2D projection, which\nultimately limits overall accuracy and stability. Inspired by Chain-of-Thought\n(CoT) in large language models (LLMs), this paper proposes MonoCoP, which\nleverages a Chain-of-Prediction (CoP) to predict attributes sequentially and\nconditionally via three key designs. First, it employs a lightweight\nAttributeNet (AN) for each 3D attribute to learn attribute-specific features.\nNext, MonoCoP constructs an explicit chain to propagate these learned features\nfrom one attribute to the next. Finally, MonoCoP uses a residual connection to\naggregate features for each attribute along the chain, ensuring that later\nattribute predictions are conditioned on all previously processed attributes\nwithout forgetting the features of earlier ones. Experimental results show that\nour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI\nleaderboard without requiring additional data and further surpasses existing\nmethods on the Waymo and nuScenes frontal datasets.", "published": "2025-05-07 17:37:23", "link": "http://arxiv.org/abs/2505.04594v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization", "abstract": "We introduce TetWeave, a novel isosurface representation for gradient-based\nmesh optimization that jointly optimizes the placement of a tetrahedral grid\nused for Marching Tetrahedra and a novel directional signed distance at each\npoint. TetWeave constructs tetrahedral grids on-the-fly via Delaunay\ntriangulation, enabling increased flexibility compared to predefined grids. The\nextracted meshes are guaranteed to be watertight, two-manifold and\nintersection-free. The flexibility of TetWeave enables a resampling strategy\nthat places new points where reconstruction error is high and allows to\nencourage mesh fairness without compromising on reconstruction error. This\nleads to high-quality, adaptive meshes that require minimal memory usage and\nfew parameters to optimize. Consequently, TetWeave exhibits near-linear memory\nscaling relative to the vertex count of the output mesh - a substantial\nimprovement over predefined grids. We demonstrate the applicability of TetWeave\nto a broad range of challenging tasks in computer graphics and vision, such as\nmulti-view 3D reconstruction, mesh compression and geometric texture\ngeneration.", "published": "2025-05-07 17:32:49", "link": "http://arxiv.org/abs/2505.04590v1", "categories": ["cs.GR", "cs.CV", "I.3.5"], "primary_category": "cs.GR"}
{"title": "Active Sampling for MRI-based Sequential Decision Making", "abstract": "Despite the superior diagnostic capability of Magnetic Resonance Imaging\n(MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and\ncomplexity. To enable such a future by reducing the magnetic field strength,\none key approach will be to improve sampling strategies. Previous work has\nshown that it is possible to make diagnostic decisions directly from k-space\nwith fewer samples. Such work shows that single diagnostic decisions can be\nmade, but if we aspire to see MRI as a true PoC, multiple and sequential\ndecisions are necessary while minimizing the number of samples acquired. We\npresent a novel multi-objective reinforcement learning framework enabling\ncomprehensive, sequential, diagnostic evaluation from undersampled k-space\ndata. Our approach during inference actively adapts to sequential decisions to\noptimally sample. To achieve this, we introduce a training methodology that\nidentifies the samples that contribute the best to each diagnostic objective\nusing a step-wise weighting reward function. We evaluate our approach in two\nsequential knee pathology assessment tasks: ACL sprain detection and cartilage\nthickness loss assessment. Our framework achieves diagnostic performance\ncompetitive with various policy-based benchmarks on disease detection, severity\nquantification, and overall sequential diagnosis, while substantially saving\nk-space samples. Our approach paves the way for the future of MRI as a\ncomprehensive and affordable PoC device. Our code is publicly available at\nhttps://github.com/vios-s/MRI_Sequential_Active_Sampling", "published": "2025-05-07 17:27:51", "link": "http://arxiv.org/abs/2505.04586v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Componential Prompt-Knowledge Alignment for Domain Incremental Learning", "abstract": "Domain Incremental Learning (DIL) aims to learn from non-stationary data\nstreams across domains while retaining and utilizing past knowledge. Although\nprompt-based methods effectively store multi-domain knowledge in prompt\nparameters and obtain advanced performance through cross-domain prompt fusion,\nwe reveal an intrinsic limitation: component-wise misalignment between\ndomain-specific prompts leads to conflicting knowledge integration and degraded\npredictions. This arises from the random positioning of knowledge components\nwithin prompts, where irrelevant component fusion introduces interference.To\naddress this, we propose Componential Prompt-Knowledge Alignment (KA-Prompt), a\nnovel prompt-based DIL method that introduces component-aware prompt-knowledge\nalignment during training, significantly improving both the learning and\ninference capacity of the model. KA-Prompt operates in two phases: (1) Initial\nComponential Structure Configuring, where a set of old prompts containing\nknowledge relevant to the new domain are mined via greedy search, which is then\nexploited to initialize new prompts to achieve reusable knowledge transfer and\nestablish intrinsic alignment between new and old prompts. (2) Online Alignment\nPreservation, which dynamically identifies the target old prompts and applies\nadaptive componential consistency constraints as new prompts evolve. Extensive\nexperiments on DIL benchmarks demonstrate the effectiveness of our KA-Prompt.\nOur source code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-KA-Prompt", "published": "2025-05-07 17:12:15", "link": "http://arxiv.org/abs/2505.04575v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Registration of 3D Point Sets Using Exponential-based Similarity Matrix", "abstract": "Point cloud registration is a fundamental problem in computer vision and\nrobotics, involving the alignment of 3D point sets captured from varying\nviewpoints using depth sensors such as LiDAR or structured light. In modern\nrobotic systems, especially those focused on mapping, it is essential to merge\nmultiple views of the same environment accurately. However, state-of-the-art\nregistration techniques often struggle when large rotational differences exist\nbetween point sets or when the data is significantly corrupted by sensor noise.\nThese challenges can lead to misalignments and, consequently, to inaccurate or\ndistorted 3D reconstructions. In this work, we address both these limitations\nby proposing a robust modification to the classic Iterative Closest Point (ICP)\nalgorithm. Our method, termed Exponential Similarity Matrix ICP (ESM-ICP),\nintegrates a Gaussian-inspired exponential weighting scheme to construct a\nsimilarity matrix that dynamically adapts across iterations. This matrix\nfacilitates improved estimation of both rotational and translational components\nduring alignment. We demonstrate the robustness of ESM-ICP in two challenging\nscenarios: (i) large rotational discrepancies between the source and target\npoint clouds, and (ii) data corrupted by non-Gaussian noise. Our results show\nthat ESM-ICP outperforms traditional geometric registration techniques as well\nas several recent learning-based methods. To encourage reproducibility and\ncommunity engagement, our full implementation is made publicly available on\nGitHub. https://github.com/aralab-unr/ESM_ICP", "published": "2025-05-07 16:17:54", "link": "http://arxiv.org/abs/2505.04540v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RAFT: Robust Augmentation of FeaTures for Image Segmentation", "abstract": "Image segmentation is a powerful computer vision technique for scene\nunderstanding. However, real-world deployment is stymied by the need for\nhigh-quality, meticulously labeled datasets. Synthetic data provides\nhigh-quality labels while reducing the need for manual data collection and\nannotation. However, deep neural networks trained on synthetic data often face\nthe Syn2Real problem, leading to poor performance in real-world deployments.\n  To mitigate the aforementioned gap in image segmentation, we propose RAFT, a\nnovel framework for adapting image segmentation models using minimal labeled\nreal-world data through data and feature augmentations, as well as active\nlearning. To validate RAFT, we perform experiments on the synthetic-to-real\n\"SYNTHIA->Cityscapes\" and \"GTAV->Cityscapes\" benchmarks. We managed to surpass\nthe previous state of the art, HALO. SYNTHIA->Cityscapes experiences an\nimprovement in mIoU* upon domain adaptation of 2.1%/79.9%, and GTAV->Cityscapes\nexperiences a 0.4%/78.2% improvement in mIoU. Furthermore, we test our approach\non the real-to-real benchmark of \"Cityscapes->ACDC\", and again surpass HALO,\nwith a gain in mIoU upon adaptation of 1.3%/73.2%. Finally, we examine the\neffect of the allocated annotation budget and various components of RAFT upon\nthe final transfer mIoU.", "published": "2025-05-07 16:02:46", "link": "http://arxiv.org/abs/2505.04529v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Edge-GPU Based Face Tracking for Face Detection and Recognition Acceleration", "abstract": "Cost-effective machine vision systems dedicated to real-time and accurate\nface detection and recognition in public places are crucial for many modern\napplications. However, despite their high performance, which could be reached\nusing specialized edge or cloud AI hardware accelerators, there is still room\nfor improvement in throughput and power consumption. This paper aims to suggest\na combined hardware-software approach that optimizes face detection and\nrecognition systems on one of the latest edge GPUs, namely NVIDIA Jetson AGX\nOrin. First, it leverages the simultaneous usage of all its hardware engines to\nimprove processing time. This offers an improvement over previous works where\nthese tasks were mainly allocated automatically and exclusively to the CPU or,\nto a higher extent, to the GPU core. Additionally, the paper suggests\nintegrating a face tracker module to avoid redundantly running the face\nrecognition algorithm for every frame but only when a new face appears in the\nscene. The results of extended experiments suggest that simultaneous usage of\nall the hardware engines that are available in the Orin GPU and tracker\nintegration into the pipeline yield an impressive throughput of 290 FPS (frames\nper second) on 1920 x 1080 input size frames containing in average of 6\nfaces/frame. Additionally, a substantial saving of power consumption of around\n800 mW was achieved when compared to running the task on the CPU/GPU engines\nonly and without integrating a tracker into the Orin GPU\\'92s pipeline. This\nhardware-codesign approach can pave the way to design high-performance machine\nvision systems at the edge, critically needed in video monitoring in public\nplaces where several nearby cameras are usually deployed for a same scene.", "published": "2025-05-07 15:57:53", "link": "http://arxiv.org/abs/2505.04524v1", "categories": ["cs.CV", "cs.AR", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Text2CT: Towards 3D CT Volume Generation from Free-text Descriptions Using Diffusion Model", "abstract": "Generating 3D CT volumes from descriptive free-text inputs presents a\ntransformative opportunity in diagnostics and research. In this paper, we\nintroduce Text2CT, a novel approach for synthesizing 3D CT volumes from textual\ndescriptions using the diffusion model. Unlike previous methods that rely on\nfixed-format text input, Text2CT employs a novel prompt formulation that\nenables generation from diverse, free-text descriptions. The proposed framework\nencodes medical text into latent representations and decodes them into\nhigh-resolution 3D CT scans, effectively bridging the gap between semantic text\ninputs and detailed volumetric representations in a unified 3D framework. Our\nmethod demonstrates superior performance in preserving anatomical fidelity and\ncapturing intricate structures as described in the input text. Extensive\nevaluations show that our approach achieves state-of-the-art results, offering\npromising potential applications in diagnostics, and data augmentation.", "published": "2025-05-07 15:53:56", "link": "http://arxiv.org/abs/2505.04522v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation", "abstract": "Customized video generation aims to produce videos featuring specific\nsubjects under flexible user-defined conditions, yet existing methods often\nstruggle with identity consistency and limited input modalities. In this paper,\nwe propose HunyuanCustom, a multi-modal customized video generation framework\nthat emphasizes subject consistency while supporting image, audio, video, and\ntext conditions. Built upon HunyuanVideo, our model first addresses the\nimage-text conditioned generation task by introducing a text-image fusion\nmodule based on LLaVA for enhanced multi-modal understanding, along with an\nimage ID enhancement module that leverages temporal concatenation to reinforce\nidentity features across frames. To enable audio- and video-conditioned\ngeneration, we further propose modality-specific condition injection\nmechanisms: an AudioNet module that achieves hierarchical alignment via spatial\ncross-attention, and a video-driven injection module that integrates\nlatent-compressed conditional video through a patchify-based feature-alignment\nnetwork. Extensive experiments on single- and multi-subject scenarios\ndemonstrate that HunyuanCustom significantly outperforms state-of-the-art open-\nand closed-source methods in terms of ID consistency, realism, and text-video\nalignment. Moreover, we validate its robustness across downstream tasks,\nincluding audio and video-driven customized video generation. Our results\nhighlight the effectiveness of multi-modal conditioning and identity-preserving\nstrategies in advancing controllable video generation. All the code and models\nare available at https://hunyuancustom.github.io.", "published": "2025-05-07 15:33:18", "link": "http://arxiv.org/abs/2505.04512v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Simultaneous Usage of Edge GPU Hardware Engines for Video Face Detection and Recognition", "abstract": "Video face detection and recognition in public places at the edge is required\nin several applications, such as security reinforcement and contactless access\nto authorized venues. This paper aims to maximize the simultaneous usage of\nhardware engines available in edge GPUs nowadays by leveraging the concurrency\nand pipelining of tasks required for face detection and recognition. This also\nincludes the video decoding task, which is required in most face monitoring\napplications as the video streams are usually carried via Gbps Ethernet\nnetwork. This constitutes an improvement over previous works where the tasks\nare usually allocated to a single engine due to the lack of a unified and\nautomated framework that simultaneously explores all hardware engines. In\naddition, previously, the input faces were usually embedded in still images or\nwithin raw video streams that overlook the burst delay caused by the decoding\nstage. The results on real-life video streams suggest that simultaneously using\nall the hardware engines available in the recent NVIDIA edge Orin GPU, higher\nthroughput, and a slight saving of power consumption of around 300 mW,\naccounting for around 5%, have been achieved while satisfying the real-time\nperformance constraint. The performance gets even higher by considering several\nvideo streams simultaneously. Further performance improvement could have been\nobtained if the number of shuffle layers that were created by the tensor RT\nframework for the face recognition task was lower. Thus, the paper suggests\nsome hardware improvements to the existing edge GPU processors to enhance their\nperformance even higher.", "published": "2025-05-07 15:22:17", "link": "http://arxiv.org/abs/2505.04502v1", "categories": ["cs.CV", "cs.AR", "eess.IV"], "primary_category": "cs.CV"}
{"title": "FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging", "abstract": "We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural\nnetwork architecture built on top of the well-known KPConv, a widely adopted\nbackbone for 3D point cloud analysis. Even though invariance and/or\nequivariance to Euclidean transformations are required for many common tasks,\nKPConv-based networks can only approximately achieve such properties when\ntraining on large datasets or with significant data augmentations. Using Frame\nAveraging, we allow to flexibly customize point cloud neural networks built\nwith KPConv layers, by making them exactly invariant and/or equivariant to\ntranslations, rotations and/or reflections of the input point clouds. By simply\nwrapping around an existing KPConv-based network, FA-KPConv embeds geometrical\nprior knowledge into it while preserving the number of learnable parameters and\nnot compromising any input information. We showcase the benefit of such an\nintroduced bias for point cloud classification and point cloud registration,\nespecially in challenging cases such as scarce training data or randomly\nrotated test data.", "published": "2025-05-07 14:58:04", "link": "http://arxiv.org/abs/2505.04485v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation", "abstract": "Recently, Large Language Models (LLMs) have achieved significant success,\nprompting increased interest in expanding their generative capabilities beyond\ngeneral text into domain-specific areas. This study investigates the generation\nof parametric sequences for computer-aided design (CAD) models using LLMs. This\nendeavor represents an initial step towards creating parametric 3D shapes with\nLLMs, as CAD model parameters directly correlate with shapes in\nthree-dimensional space. Despite the formidable generative capacities of LLMs,\nthis task remains challenging, as these models neither encounter parametric\nsequences during their pretraining phase nor possess direct awareness of 3D\nstructures. To address this, we present CAD-Llama, a framework designed to\nenhance pretrained LLMs for generating parametric 3D CAD models. Specifically,\nwe develop a hierarchical annotation pipeline and a code-like format to\ntranslate parametric 3D CAD command sequences into Structured Parametric CAD\nCode (SPCC), incorporating hierarchical semantic descriptions. Furthermore, we\npropose an adaptive pretraining approach utilizing SPCC, followed by an\ninstruction tuning process aligned with CAD-specific guidelines. This\nmethodology aims to equip LLMs with the spatial knowledge inherent in\nparametric sequences. Experimental results demonstrate that our framework\nsignificantly outperforms prior autoregressive methods and existing LLM\nbaselines.", "published": "2025-05-07 14:52:02", "link": "http://arxiv.org/abs/2505.04481v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Real Facial Concepts for Independent Deepfake Detection", "abstract": "Deepfake detection models often struggle with generalization to unseen\ndatasets, manifesting as misclassifying real instances as fake in target\ndomains. This is primarily due to an overreliance on forgery artifacts and a\nlimited understanding of real faces. To address this challenge, we propose a\nnovel approach RealID to enhance generalization by learning a comprehensive\nconcept of real faces while assessing the probabilities of belonging to the\nreal and fake classes independently. RealID comprises two key modules: the Real\nConcept Capture Module (RealC2) and the Independent Dual-Decision Classifier\n(IDC). With the assistance of a MultiReal Memory, RealC2 maintains various\nprototypes for real faces, allowing the model to capture a comprehensive\nconcept of real class. Meanwhile, IDC redefines the classification strategy by\nmaking independent decisions based on the concept of the real class and the\npresence of forgery artifacts. Through the combined effect of the above\nmodules, the influence of forgery-irrelevant patterns is alleviated, and\nextensive experiments on five widely used datasets demonstrate that RealID\nsignificantly outperforms existing state-of-the-art methods, achieving a 1.74%\nimprovement in average accuracy.", "published": "2025-05-07 14:31:04", "link": "http://arxiv.org/abs/2505.04460v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RLMiniStyler: Light-weight RL Style Agent for Arbitrary Sequential Neural Style Generation", "abstract": "Arbitrary style transfer aims to apply the style of any given artistic image\nto another content image. Still, existing deep learning-based methods often\nrequire significant computational costs to generate diverse stylized results.\nMotivated by this, we propose a novel reinforcement learning-based framework\nfor arbitrary style transfer RLMiniStyler. This framework leverages a unified\nreinforcement learning policy to iteratively guide the style transfer process\nby exploring and exploiting stylization feedback, generating smooth sequences\nof stylized results while achieving model lightweight. Furthermore, we\nintroduce an uncertainty-aware multi-task learning strategy that automatically\nadjusts loss weights to adapt to the content and style balance requirements at\ndifferent training stages, thereby accelerating model convergence. Through a\nseries of experiments across image various resolutions, we have validated the\nadvantages of RLMiniStyler over other state-of-the-art methods in generating\nhigh-quality, diverse artistic image sequences at a lower cost. Codes are\navailable at https://github.com/fengxiaoming520/RLMiniStyler.", "published": "2025-05-07 13:57:42", "link": "http://arxiv.org/abs/2505.04424v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception", "abstract": "Dense visual prediction tasks have been constrained by their reliance on\npredefined categories, limiting their applicability in real-world scenarios\nwhere visual concepts are unbounded. While Vision-Language Models (VLMs) like\nCLIP have shown promise in open-vocabulary tasks, their direct application to\ndense prediction often leads to suboptimal performance due to limitations in\nlocal feature representation. In this work, we present our observation that\nCLIP's image tokens struggle to effectively aggregate information from\nspatially or semantically related regions, resulting in features that lack\nlocal discriminability and spatial consistency. To address this issue, we\npropose DeCLIP, a novel framework that enhances CLIP by decoupling the\nself-attention module to obtain ``content'' and ``context'' features\nrespectively. The ``content'' features are aligned with image crop\nrepresentations to improve local discriminability, while ``context'' features\nlearn to retain the spatial correlations under the guidance of vision\nfoundation models, such as DINO. Extensive experiments demonstrate that DeCLIP\nsignificantly outperforms existing methods across multiple open-vocabulary\ndense prediction tasks, including object detection and semantic segmentation.\nCode is available at \\textcolor{magenta}{https://github.com/xiaomoguhz/DeCLIP}.", "published": "2025-05-07 13:46:34", "link": "http://arxiv.org/abs/2505.04410v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MFSeg: Efficient Multi-frame 3D Semantic Segmentation", "abstract": "We propose MFSeg, an efficient multi-frame 3D semantic segmentation\nframework. By aggregating point cloud sequences at the feature level and\nregularizing the feature extraction and aggregation process, MFSeg reduces\ncomputational overhead while maintaining high accuracy. Moreover, by employing\na lightweight MLP-based point decoder, our method eliminates the need to\nupsample redundant points from past frames. Experiments on the nuScenes and\nWaymo datasets show that MFSeg outperforms existing methods, demonstrating its\neffectiveness and efficiency.", "published": "2025-05-07 13:46:10", "link": "http://arxiv.org/abs/2505.04408v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SwinLip: An Efficient Visual Speech Encoder for Lip Reading Using Swin Transformer", "abstract": "This paper presents an efficient visual speech encoder for lip reading. While\nmost recent lip reading studies have been based on the ResNet architecture and\nhave achieved significant success, they are not sufficiently suitable for\nefficiently capturing lip reading features due to high computational complexity\nin modeling spatio-temporal information. Additionally, using a complex visual\nmodel not only increases the complexity of lip reading models but also induces\ndelays in the overall network for multi-modal studies (e.g., audio-visual\nspeech recognition, speech enhancement, and speech separation). To overcome the\nlimitations of Convolutional Neural Network (CNN)-based models, we apply the\nhierarchical structure and window self-attention of the Swin Transformer to lip\nreading. We configure a new lightweight scale of the Swin Transformer suitable\nfor processing lip reading data and present the SwinLip visual speech encoder,\nwhich efficiently reduces computational load by integrating modified\nConvolution-augmented Transformer (Conformer) temporal embeddings with\nconventional spatial embeddings in the hierarchical structure. Through\nextensive experiments, we have validated that our SwinLip successfully improves\nthe performance and inference speed of the lip reading network when applied to\nvarious backbones for word and sentence recognition, reducing computational\nload. In particular, our SwinLip demonstrated robust performance in both\nEnglish LRW and Mandarin LRW-1000 datasets and achieved state-of-the-art\nperformance on the Mandarin LRW-1000 dataset with less computation compared to\nthe existing state-of-the-art model.", "published": "2025-05-07 13:18:43", "link": "http://arxiv.org/abs/2505.04394v1", "categories": ["cs.CV", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Predicting Road Surface Anomalies by Visual Tracking of a Preceding Vehicle", "abstract": "A novel approach to detect road surface anomalies by visual tracking of a\npreceding vehicle is proposed. The method is versatile, predicting any kind of\nroad anomalies, such as potholes, bumps, debris, etc., unlike direct\nobservation methods that rely on training visual detectors of those cases. The\nmethod operates in low visibility conditions or in dense traffic where the\nanomaly is occluded by a preceding vehicle. Anomalies are detected\npredictively, i.e., before a vehicle encounters them, which allows to\npre-configure low-level vehicle systems (such as chassis) or to plan an\navoidance maneuver in case of autonomous driving. A challenge is that the\nsignal coming from camera-based tracking of a preceding vehicle may be weak and\ndisturbed by camera ego motion due to vibrations affecting the ego vehicle.\nTherefore, we propose an efficient method to compensate camera pitch rotation\nby an iterative robust estimator. Our experiments on both controlled setup and\nnormal traffic conditions show that road anomalies can be detected reliably at\na distance even in challenging cases where the ego vehicle traverses imperfect\nroad surfaces. The method is effective and performs in real time on standard\nconsumer hardware.", "published": "2025-05-07 13:17:05", "link": "http://arxiv.org/abs/2505.04392v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Geometry-Aware Texture Generation for 3D Head Modeling with Artist-driven Control", "abstract": "Creating realistic 3D head assets for virtual characters that match a precise\nartistic vision remains labor-intensive. We present a novel framework that\nstreamlines this process by providing artists with intuitive control over\ngenerated 3D heads. Our approach uses a geometry-aware texture synthesis\npipeline that learns correlations between head geometry and skin texture maps\nacross different demographics. The framework offers three levels of artistic\ncontrol: manipulation of overall head geometry, adjustment of skin tone while\npreserving facial characteristics, and fine-grained editing of details such as\nwrinkles or facial hair. Our pipeline allows artists to make edits to a single\ntexture map using familiar tools, with our system automatically propagating\nthese changes coherently across the remaining texture maps needed for realistic\nrendering. Experiments demonstrate that our method produces diverse results\nwith clean geometries. We showcase practical applications focusing on intuitive\ncontrol for artists, including skin tone adjustments and simplified editing\nworkflows for adding age-related details or removing unwanted features from\nscanned models. This integrated approach aims to streamline the artistic\nworkflow in virtual character creation.", "published": "2025-05-07 13:11:35", "link": "http://arxiv.org/abs/2505.04387v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "DATA: Multi-Disentanglement based Contrastive Learning for Open-World Semi-Supervised Deepfake Attribution", "abstract": "Deepfake attribution (DFA) aims to perform multiclassification on different\nfacial manipulation techniques, thereby mitigating the detrimental effects of\nforgery content on the social order and personal reputations. However, previous\nmethods focus only on method-specific clues, which easily lead to overfitting,\nwhile overlooking the crucial role of common forgery features. Additionally,\nthey struggle to distinguish between uncertain novel classes in more practical\nopen-world scenarios. To address these issues, in this paper we propose an\ninnovative multi-DisentAnglement based conTrastive leArning framework, DATA, to\nenhance the generalization ability on novel classes for the open-world\nsemi-supervised deepfake attribution (OSS-DFA) task. Specifically, since all\ngeneration techniques can be abstracted into a similar architecture, DATA\ndefines the concept of 'Orthonormal Deepfake Basis' for the first time and\nutilizes it to disentangle method-specific features, thereby reducing the\noverfitting on forgery-irrelevant information. Furthermore, an augmented-memory\nmechanism is designed to assist in novel class discovery and contrastive\nlearning, which aims to obtain clear class boundaries for the novel classes\nthrough instance-level disentanglements. Additionally, to enhance the\nstandardization and discrimination of features, DATA uses bases contrastive\nloss and center contrastive loss as auxiliaries for the aforementioned modules.\nExtensive experimental evaluations show that DATA achieves state-of-the-art\nperformance on the OSS-DFA benchmark, e.g., there are notable accuracy\nimprovements in 2.55% / 5.7% under different settings, compared with the\nexisting methods.", "published": "2025-05-07 13:05:32", "link": "http://arxiv.org/abs/2505.04384v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Tetrahedron-Net for Medical Image Registration", "abstract": "Medical image registration plays a vital role in medical image processing.\nExtracting expressive representations for medical images is crucial for\nimproving the registration quality. One common practice for this end is\nconstructing a convolutional backbone to enable interactions with skip\nconnections among feature extraction layers. The de facto structure, U-Net-like\nnetworks, has attempted to design skip connections such as nested or full-scale\nones to connect one single encoder and one single decoder to improve its\nrepresentation capacity. Despite being effective, it still does not fully\nexplore interactions with a single encoder and decoder architectures. In this\npaper, we embrace this observation and introduce a simple yet effective\nalternative strategy to enhance the representations for registrations by\nappending one additional decoder. The new decoder is designed to interact with\nboth the original encoder and decoder. In this way, it not only reuses feature\npresentation from corresponding layers in the encoder but also interacts with\nthe original decoder to corporately give more accurate registration results.\nThe new architecture is concise yet generalized, with only one encoder and two\ndecoders forming a ``Tetrahedron'' structure, thereby dubbed Tetrahedron-Net.\nThree instantiations of Tetrahedron-Net are further constructed regarding the\ndifferent structures of the appended decoder. Our extensive experiments prove\nthat superior performance can be obtained on several representative benchmarks\nof medical image registration. Finally, such a ``Tetrahedron'' design can also\nbe easily integrated into popular U-Net-like architectures including\nVoxelMorph, ViT-V-Net, and TransMorph, leading to consistent performance gains.", "published": "2025-05-07 13:00:49", "link": "http://arxiv.org/abs/2505.04380v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Label-efficient Single Photon Images Classification via Active Learning", "abstract": "Single-photon LiDAR achieves high-precision 3D imaging in extreme\nenvironments through quantum-level photon detection technology. Current\nresearch primarily focuses on reconstructing 3D scenes from sparse photon\nevents, whereas the semantic interpretation of single-photon images remains\nunderexplored, due to high annotation costs and inefficient labeling\nstrategies. This paper presents the first active learning framework for\nsingle-photon image classification. The core contribution is an imaging\ncondition-aware sampling strategy that integrates synthetic augmentation to\nmodel variability across imaging conditions. By identifying samples where the\nmodel is both uncertain and sensitive to these conditions, the proposed method\nselectively annotates only the most informative examples. Experiments on both\nsynthetic and real-world datasets show that our approach outperforms all\nbaselines and achieves high classification accuracy with significantly fewer\nlabeled samples. Specifically, our approach achieves 97% accuracy on synthetic\nsingle-photon data using only 1.5% labeled samples. On real-world data, we\nmaintain 90.63% accuracy with just 8% labeled samples, which is 4.51% higher\nthan the best-performing baseline. This illustrates that active learning\nenables the same level of classification performance on single-photon images as\non classical images, opening doors to large-scale integration of single-photon\ndata in real-world applications.", "published": "2025-05-07 12:57:40", "link": "http://arxiv.org/abs/2505.04376v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WDMamba: When Wavelet Degradation Prior Meets Vision Mamba for Image Dehazing", "abstract": "In this paper, we reveal a novel haze-specific wavelet degradation prior\nobserved through wavelet transform analysis, which shows that haze-related\ninformation predominantly resides in low-frequency components. Exploiting this\ninsight, we propose a novel dehazing framework, WDMamba, which decomposes the\nimage dehazing task into two sequential stages: low-frequency restoration\nfollowed by detail enhancement. This coarse-to-fine strategy enables WDMamba to\neffectively capture features specific to each stage of the dehazing process,\nresulting in high-quality restored images. Specifically, in the low-frequency\nrestoration stage, we integrate Mamba blocks to reconstruct global structures\nwith linear complexity, efficiently removing overall haze and producing a\ncoarse restored image. Thereafter, the detail enhancement stage reinstates\nfine-grained information that may have been overlooked during the previous\nphase, culminating in the final dehazed output. Furthermore, to enhance detail\nretention and achieve more natural dehazing, we introduce a self-guided\ncontrastive regularization during network training. By utilizing the coarse\nrestored output as a hard negative example, our model learns more\ndiscriminative representations, substantially boosting the overall dehazing\nperformance. Extensive evaluations on public dehazing benchmarks demonstrate\nthat our method surpasses state-of-the-art approaches both qualitatively and\nquantitatively. Code is available at https://github.com/SunJ000/WDMamba.", "published": "2025-05-07 12:37:01", "link": "http://arxiv.org/abs/2505.04369v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CountDiffusion: Text-to-Image Synthesis with Training-Free Counting-Guidance Diffusion", "abstract": "Stable Diffusion has advanced text-to-image synthesis, but training models to\ngenerate images with accurate object quantity is still difficult due to the\nhigh computational cost and the challenge of teaching models the abstract\nconcept of quantity. In this paper, we propose CountDiffusion, a training-free\nframework aiming at generating images with correct object quantity from textual\ndescriptions. CountDiffusion consists of two stages. In the first stage, an\nintermediate denoising result is generated by the diffusion model to predict\nthe final synthesized image with one-step denoising, and a counting model is\nused to count the number of objects in this image. In the second stage, a\ncorrection module is used to correct the object quantity by changing the\nattention map of the object with universal guidance. The proposed\nCountDiffusion can be plugged into any diffusion-based text-to-image (T2I)\ngeneration models without further training. Experiment results demonstrate the\nsuperiority of our proposed CountDiffusion, which improves the accurate object\nquantity generation ability of T2I models by a large margin.", "published": "2025-05-07 11:47:35", "link": "http://arxiv.org/abs/2505.04347v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-turn Consistent Image Editing", "abstract": "Many real-world applications, such as interactive photo retouching, artistic\ncontent creation, and product design, require flexible and iterative image\nediting. However, existing image editing methods primarily focus on achieving\nthe desired modifications in a single step, which often struggles with\nambiguous user intent, complex transformations, or the need for progressive\nrefinements. As a result, these methods frequently produce inconsistent\noutcomes or fail to meet user expectations. To address these challenges, we\npropose a multi-turn image editing framework that enables users to iteratively\nrefine their edits, progressively achieving more satisfactory results. Our\napproach leverages flow matching for accurate image inversion and a\ndual-objective Linear Quadratic Regulators (LQR) for stable sampling,\neffectively mitigating error accumulation. Additionally, by analyzing the\nlayer-wise roles of transformers, we introduce a adaptive attention\nhighlighting method that enhances editability while preserving multi-turn\ncoherence. Extensive experiments demonstrate that our framework significantly\nimproves edit success rates and visual fidelity compared to existing methods.", "published": "2025-05-07 11:11:23", "link": "http://arxiv.org/abs/2505.04320v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MoDE: Mixture of Diffusion Experts for Any Occluded Face Recognition", "abstract": "With the continuous impact of epidemics, people have become accustomed to\nwearing masks. However, most current occluded face recognition (OFR) algorithms\nlack prior knowledge of occlusions, resulting in poor performance when dealing\nwith occluded faces of varying types and severity in reality. Recognizing\noccluded faces is still a significant challenge, which greatly affects the\nconvenience of people's daily lives. In this paper, we propose an\nidentity-gated mixture of diffusion experts (MoDE) for OFR. Each\ndiffusion-based generative expert estimates one possible complete image for\noccluded faces. Considering the random sampling process of the diffusion model,\nwhich introduces inevitable differences and variations between the inpainted\nfaces and the real ones. To ensemble effective information from\nmulti-reconstructed faces, we introduce an identity-gating network to evaluate\nthe contribution of each reconstructed face to the identity and adaptively\nintegrate the predictions in the decision space. Moreover, our MoDE is a\nplug-and-play module for most existing face recognition models. Extensive\nexperiments on three public face datasets and two datasets in the wild validate\nour advanced performance for various occlusions in comparison with the\ncompeting methods.", "published": "2025-05-07 10:29:39", "link": "http://arxiv.org/abs/2505.04306v1", "categories": ["cs.CV", "I.4.8; I.5.4; I.2.10"], "primary_category": "cs.CV"}
{"title": "TS-Diff: Two-Stage Diffusion Model for Low-Light RAW Image Enhancement", "abstract": "This paper presents a novel Two-Stage Diffusion Model (TS-Diff) for enhancing\nextremely low-light RAW images. In the pre-training stage, TS-Diff synthesizes\nnoisy images by constructing multiple virtual cameras based on a noise space.\nCamera Feature Integration (CFI) modules are then designed to enable the model\nto learn generalizable features across diverse virtual cameras. During the\naligning stage, CFIs are averaged to create a target-specific CFI$^T$, which is\nfine-tuned using a small amount of real RAW data to adapt to the noise\ncharacteristics of specific cameras. A structural reparameterization technique\nfurther simplifies CFI$^T$ for efficient deployment. To address color shifts\nduring the diffusion process, a color corrector is introduced to ensure color\nconsistency by dynamically adjusting global color distributions. Additionally,\na novel dataset, QID, is constructed, featuring quantifiable illumination\nlevels and a wide dynamic range, providing a comprehensive benchmark for\ntraining and evaluation under extreme low-light conditions. Experimental\nresults demonstrate that TS-Diff achieves state-of-the-art performance on\nmultiple datasets, including QID, SID, and ELD, excelling in denoising,\ngeneralization, and color consistency across various cameras and illumination\nlevels. These findings highlight the robustness and versatility of TS-Diff,\nmaking it a practical solution for low-light imaging applications. Source codes\nand models are available at https://github.com/CircccleK/TS-Diff", "published": "2025-05-07 09:35:05", "link": "http://arxiv.org/abs/2505.04281v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HDiffTG: A Lightweight Hybrid Diffusion-Transformer-GCN Architecture for 3D Human Pose Estimation", "abstract": "We propose HDiffTG, a novel 3D Human Pose Estimation (3DHPE) method that\nintegrates Transformer, Graph Convolutional Network (GCN), and diffusion model\ninto a unified framework. HDiffTG leverages the strengths of these techniques\nto significantly improve pose estimation accuracy and robustness while\nmaintaining a lightweight design. The Transformer captures global\nspatiotemporal dependencies, the GCN models local skeletal structures, and the\ndiffusion model provides step-by-step optimization for fine-tuning, achieving a\ncomplementary balance between global and local features. This integration\nenhances the model's ability to handle pose estimation under occlusions and in\ncomplex scenarios. Furthermore, we introduce lightweight optimizations to the\nintegrated model and refine the objective function design to reduce\ncomputational overhead without compromising performance. Evaluation results on\nthe Human3.6M and MPI-INF-3DHP datasets demonstrate that HDiffTG achieves\nstate-of-the-art (SOTA) performance on the MPI-INF-3DHP dataset while excelling\nin both accuracy and computational efficiency. Additionally, the model exhibits\nexceptional robustness in noisy and occluded environments. Source codes and\nmodels are available at https://github.com/CirceJie/HDiffTG", "published": "2025-05-07 09:26:37", "link": "http://arxiv.org/abs/2505.04276v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Bridging Geometry-Coherent Text-to-3D Generation with Multi-View Diffusion Priors and Gaussian Splatting", "abstract": "Score Distillation Sampling (SDS) leverages pretrained 2D diffusion models to\nadvance text-to-3D generation but neglects multi-view correlations, being prone\nto geometric inconsistencies and multi-face artifacts in the generated 3D\ncontent. In this work, we propose Coupled Score Distillation (CSD), a framework\nthat couples multi-view joint distribution priors to ensure geometrically\nconsistent 3D generation while enabling the stable and direct optimization of\n3D Gaussian Splatting. Specifically, by reformulating the optimization as a\nmulti-view joint optimization problem, we derive an effective optimization rule\nthat effectively couples multi-view priors to guide optimization across\ndifferent viewpoints while preserving the diversity of generated 3D assets.\nAdditionally, we propose a framework that directly optimizes 3D Gaussian\nSplatting (3D-GS) with random initialization to generate geometrically\nconsistent 3D content. We further employ a deformable tetrahedral grid,\ninitialized from 3D-GS and refined through CSD, to produce high-quality,\nrefined meshes. Quantitative and qualitative experimental results demonstrate\nthe efficiency and competitive quality of our approach.", "published": "2025-05-07 09:12:45", "link": "http://arxiv.org/abs/2505.04262v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RGB-Event Fusion with Self-Attention for Collision Prediction", "abstract": "Ensuring robust and real-time obstacle avoidance is critical for the safe\noperation of autonomous robots in dynamic, real-world environments. This paper\nproposes a neural network framework for predicting the time and collision\nposition of an unmanned aerial vehicle with a dynamic object, using RGB and\nevent-based vision sensors. The proposed architecture consists of two separate\nencoder branches, one for each modality, followed by fusion by self-attention\nto improve prediction accuracy. To facilitate benchmarking, we leverage the\nABCD [8] dataset collected that enables detailed comparisons of single-modality\nand fusion-based approaches. At the same prediction throughput of 50Hz, the\nexperimental results show that the fusion-based model offers an improvement in\nprediction accuracy over single-modality approaches of 1% on average and 10%\nfor distances beyond 0.5m, but comes at the cost of +71% in memory and + 105%\nin FLOPs. Notably, the event-based model outperforms the RGB model by 4% for\nposition and 26% for time error at a similar computational cost, making it a\ncompetitive alternative. Additionally, we evaluate quantized versions of the\nevent-based models, applying 1- to 8-bit quantization to assess the trade-offs\nbetween predictive performance and computational efficiency. These findings\nhighlight the trade-offs of multi-modal perception using RGB and event-based\ncameras in robotic applications.", "published": "2025-05-07 09:03:26", "link": "http://arxiv.org/abs/2505.04258v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "A Weak Supervision Learning Approach Towards an Equitable Parking Lot Occupancy Estimation", "abstract": "The scarcity and high cost of labeled high-resolution imagery have long\nchallenged remote sensing applications, particularly in low-income regions\nwhere high-resolution data are scarce. In this study, we propose a weak\nsupervision framework that estimates parking lot occupancy using 3m resolution\nsatellite imagery. By leveraging coarse temporal labels -- based on the\nassumption that parking lots of major supermarkets and hardware stores in\nGermany are typically full on Saturdays and empty on Sundays -- we train a\npairwise comparison model that achieves an AUC of 0.92 on large parking lots.\nThe proposed approach minimizes the reliance on expensive high-resolution\nimages and holds promise for scalable urban mobility analysis. Moreover, the\nmethod can be adapted to assess transit patterns and resource allocation in\nvulnerable communities, providing a data-driven basis to improve the well-being\nof those most in need.", "published": "2025-05-07 08:27:18", "link": "http://arxiv.org/abs/2505.04229v1", "categories": ["cs.CV", "cs.CY"], "primary_category": "cs.CV"}
{"title": "CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models", "abstract": "The automatic extraction of key-value information from handwritten documents\nis a key challenge in document analysis. A reliable extraction is a\nprerequisite for the mass digitization efforts of many archives. Large Vision\nLanguage Models (LVLM) are a promising technology to tackle this problem\nespecially in scenarios where little annotated training data is available. In\nthis work, we present a novel dataset specifically designed to evaluate the\nfew-shot capabilities of LVLMs. The CM1 documents are a historic collection of\nforms with handwritten entries created in Europe to administer the Care and\nMaintenance program after World War Two. The dataset establishes three\nbenchmarks on extracting name and birthdate information and, furthermore,\nconsiders different training set sizes. We provide baseline results for two\ndifferent LVLMs and compare performances to an established full-page extraction\nmodel. While the traditional full-page model achieves highly competitive\nperformances, our experiments show that when only a few training samples are\navailable the considered LVLMs benefit from their size and heavy pretraining\nand outperform the classical approach.", "published": "2025-05-07 08:08:58", "link": "http://arxiv.org/abs/2505.04214v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SToLa: Self-Adaptive Touch-Language Framework with Tactile Commonsense Reasoning in Open-Ended Scenarios", "abstract": "This paper explores the challenges of integrating tactile sensing into\nintelligent systems for multimodal reasoning, particularly in enabling\ncommonsense reasoning about the open-ended physical world. We identify two key\nchallenges: modality discrepancy, where existing large touch-language models\noften treat touch as a mere sub-modality of language, and open-ended tactile\ndata scarcity, where current datasets lack the diversity, open-endness and\ncomplexity needed for reasoning. To overcome these challenges, we introduce\nSToLa, a Self-Adaptive Touch-Language framework. SToLa utilizes Mixture of\nExperts (MoE) to dynamically process, unify, and manage tactile and language\nmodalities, capturing their unique characteristics. Crucially, we also present\na comprehensive tactile commonsense reasoning dataset and benchmark featuring\nfree-form questions and responses, 8 physical properties, 4 interactive\ncharacteristics, and diverse commonsense knowledge. Experiments show SToLa\nexhibits competitive performance compared to existing models on the PhysiCLeAR\nbenchmark and self-constructed datasets, proving the effectiveness of the\nMixture of Experts architecture in multimodal management and the performance\nadvantages for open-scenario tactile commonsense reasoning tasks.", "published": "2025-05-07 07:55:35", "link": "http://arxiv.org/abs/2505.04201v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning from Similarity Proportion Loss for Classifying Skeletal Muscle Recovery Stages", "abstract": "Evaluating the regeneration process of damaged muscle tissue is a fundamental\nanalysis in muscle research to measure experimental effect sizes and uncover\nmechanisms behind muscle weakness due to aging and disease. The conventional\napproach to assessing muscle tissue regeneration involves whole-slide imaging\nand expert visual inspection of the recovery stages based on the morphological\ninformation of cells and fibers. There is a need to replace these tasks with\nautomated methods incorporating machine learning techniques to ensure a\nquantitative and objective analysis. Given the limited availability of fully\nlabeled data, a possible approach is Learning from Label Proportions (LLP), a\nweakly supervised learning method using class label proportions. However,\ncurrent LLP methods have two limitations: (1) they cannot adapt the feature\nextractor for muscle tissues, and (2) they treat the classes representing\nrecovery stages and cell morphological changes as nominal, resulting in the\nloss of ordinal information. To address these issues, we propose Ordinal Scale\nLearning from Similarity Proportion (OSLSP), which uses a similarity proportion\nloss derived from two bag combinations. OSLSP can update the feature extractor\nby using class proportion attention to the ordinal scale of the class. Our\nmodel with OSLSP outperforms large-scale pre-trained and fine-tuning models in\nclassification tasks of skeletal muscle recovery stages.", "published": "2025-05-07 06:02:27", "link": "http://arxiv.org/abs/2505.04150v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Vision Graph Prompting via Semantic Low-Rank Decomposition", "abstract": "Vision GNN (ViG) demonstrates superior performance by representing images as\ngraph structures, providing a more natural way to capture irregular semantic\npatterns beyond traditional grid or sequence-based representations. To\nefficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning\ntechniques like visual prompting become increasingly essential. However,\nexisting prompting methods are primarily designed for Transformer-based models,\nneglecting the rich topological relationships among nodes and edges in\ngraph-based representations, limiting their capacity to model complex\nsemantics. In this paper, we propose Vision Graph Prompting (VGP), a novel\nframework tailored for vision graph structures. Our core insight reveals that\nsemantically connected components in the graph exhibit low-rank properties.\nBuilding on this observation, we introduce a semantic low-rank prompting method\nthat decomposes low-rank semantic features and integrates them with prompts on\nvision graph topologies, capturing both global structural patterns and\nfine-grained semantic dependencies. Extensive experiments demonstrate our\nmethod significantly improves ViG's transfer performance on diverse downstream\ntasks, achieving results comparable to full fine-tuning while maintaining\nparameter efficiency. Our code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-VGP.", "published": "2025-05-07 04:29:29", "link": "http://arxiv.org/abs/2505.04121v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model", "abstract": "Pre-trained 3D vision models have gained significant attention for their\npromising performance on point cloud data. However, fully fine-tuning these\nmodels for downstream tasks is computationally expensive and storage-intensive.\nExisting parameter-efficient fine-tuning (PEFT) approaches, which focus\nprimarily on input token prompting, struggle to achieve competitive performance\ndue to their limited ability to capture the geometric information inherent in\npoint clouds. To address this challenge, we propose a novel Geometry-Aware\nPoint Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the\nadaptability of 3D vision models. First, we introduce a Point Prompt that\nserves as an auxiliary input alongside the original point cloud, explicitly\nguiding the model to capture fine-grained geometric details. Additionally, we\npresent a Point Shift Prompter designed to extract global shape information\nfrom the point cloud, enabling instance-specific geometric adjustments at the\ninput level. Moreover, our proposed Prompt Propagation mechanism incorporates\nthe shape information into the model's feature extraction process, further\nstrengthening its ability to capture essential geometric characteristics.\nExtensive experiments demonstrate that GAPrompt significantly outperforms\nstate-of-the-art PEFT methods and achieves competitive results compared to full\nfine-tuning on various benchmarks, while utilizing only 2.19% of trainable\nparameters. Our code is available at\nhttps://github.com/zhoujiahuan1991/ICML2025-VGP.", "published": "2025-05-07 04:29:09", "link": "http://arxiv.org/abs/2505.04119v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "One2Any: One-Reference 6D Pose Estimation for Any Object", "abstract": "6D object pose estimation remains challenging for many applications due to\ndependencies on complete 3D models, multi-view images, or training limited to\nspecific object categories. These requirements make generalization to novel\nobjects difficult for which neither 3D models nor multi-view images may be\navailable. To address this, we propose a novel method One2Any that estimates\nthe relative 6-degrees of freedom (DOF) object pose using only a single\nreference-single query RGB-D image, without prior knowledge of its 3D model,\nmulti-view data, or category constraints. We treat object pose estimation as an\nencoding-decoding process, first, we obtain a comprehensive Reference Object\nPose Embedding (ROPE) that encodes an object shape, orientation, and texture\nfrom a single reference view. Using this embedding, a U-Net-based pose decoding\nmodule produces Reference Object Coordinate (ROC) for new views, enabling fast\nand accurate pose estimation. This simple encoding-decoding framework allows\nour model to be trained on any pair-wise pose data, enabling large-scale\ntraining and demonstrating great scalability. Experiments on multiple benchmark\ndatasets demonstrate that our model generalizes well to novel objects,\nachieving state-of-the-art accuracy and robustness even rivaling methods that\nrequire multi-view or CAD inputs, at a fraction of compute.", "published": "2025-05-07 03:54:59", "link": "http://arxiv.org/abs/2505.04109v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAISY: Motion-Aware Image SYnthesis for MedicalImage Motion Correction", "abstract": "Patient motion during medical image acquisition causes blurring, ghosting,\nand distorts organs, which makes image interpretation challenging.Current\nstate-of-the-art algorithms using Generative Adversarial Network (GAN)-based\nmethods with their ability to learn the mappings between corrupted images and\ntheir ground truth via Structural Similarity Index Measure (SSIM) loss\neffectively generate motion-free images. However, we identified the following\nlimitations: (i) they mainly focus on global structural characteristics and\ntherefore overlook localized features that often carry critical pathological\ninformation, and (ii) the SSIM loss function struggles to handle images with\nvarying pixel intensities, luminance factors, and variance. In this study, we\npropose Motion-Aware Image SYnthesis (MAISY) which initially characterize\nmotion and then uses it for correction by: (a) leveraging the foundation model\nSegment Anything Model (SAM), to dynamically learn spatial patterns along\nanatomical boundaries where motion artifacts are most pronounced and, (b)\nintroducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively\nemphasizes spatial regions with high pixel variance to preserve essential\nanatomical details during artifact correction. Experiments on chest and head CT\ndatasets demonstrate that our model outperformed the state-of-the-art\ncounterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by\n10%, and Dice by 16%.", "published": "2025-05-07 03:44:28", "link": "http://arxiv.org/abs/2505.04105v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Brain MRI Classification for Alzheimer Diagnosis Using CNN with Data Augmentation", "abstract": "A three-dimensional convolutional neural network was developed to classify\nT1-weighted brain MRI scans as healthy or Alzheimer. The network comprises 3D\nconvolution, pooling, batch normalization, dense ReLU layers, and a sigmoid\noutput. Using stochastic noise injection and five-fold cross-validation, the\nmodel achieved test set accuracy of 0.912 and area under the ROC curve of\n0.961, an improvement of approximately 0.027 over resizing alone. Sensitivity\nand specificity both exceeded 0.90. These results align with prior work\nreporting up to 0.10 gain via synthetic augmentation. The findings demonstrate\nthe effectiveness of simple augmentation for 3D MRI classification and motivate\nfuture exploration of advanced augmentation methods and architectures such as\n3D U-Net and vision transformers.", "published": "2025-05-07 03:32:25", "link": "http://arxiv.org/abs/2505.04097v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Scalable Aerial GNSS Localization for Marine Robots", "abstract": "Accurate localization is crucial for water robotics, yet traditional onboard\nGlobal Navigation Satellite System (GNSS) approaches are difficult or\nineffective due to signal reflection on the water's surface and its high cost\nof aquatic GNSS receivers. Existing approaches, such as inertial navigation,\nDoppler Velocity Loggers (DVL), SLAM, and acoustic-based methods, face\nchallenges like error accumulation and high computational complexity.\nTherefore, a more efficient and scalable solution remains necessary. This paper\nproposes an alternative approach that leverages an aerial drone equipped with\nGNSS localization to track and localize a marine robot once it is near the\nsurface of the water. Our results show that this novel adaptation enables\naccurate single and multi-robot marine robot localization.", "published": "2025-05-07 03:18:59", "link": "http://arxiv.org/abs/2505.04095v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking", "abstract": "Thermal infrared (TIR) object tracking often suffers from challenges such as\ntarget occlusion, motion blur, and background clutter, which significantly\ndegrade the performance of trackers. To address these issues, this paper\npro-poses a novel Siamese Motion Mamba Tracker (SMMT), which integrates a\nbidirectional state-space model and a self-attention mechanism. Specifically,\nwe introduce the Motion Mamba module into the Siamese architecture to ex-tract\nmotion features and recover overlooked edge details using bidirectional\nmodeling and self-attention. We propose a Siamese parameter-sharing strate-gy\nthat allows certain convolutional layers to share weights. This approach\nreduces computational redundancy while preserving strong feature\nrepresen-tation. In addition, we design a motion edge-aware regression loss to\nimprove tracking accuracy, especially for motion-blurred targets. Extensive\nexperi-ments are conducted on four TIR tracking benchmarks, including\nLSOTB-TIR, PTB-TIR, VOT-TIR2015, and VOT-TIR 2017. The results show that SMMT\nachieves superior performance in TIR target tracking.", "published": "2025-05-07 03:02:04", "link": "http://arxiv.org/abs/2505.04088v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SEVA: Leveraging Single-Step Ensemble of Vicinal Augmentations for Test-Time Adaptation", "abstract": "Test-Time adaptation (TTA) aims to enhance model robustness against\ndistribution shifts through rapid model adaptation during inference. While\nexisting TTA methods often rely on entropy-based unsupervised training and\nachieve promising results, the common practice of a single round of entropy\ntraining is typically unable to adequately utilize reliable samples, hindering\nadaptation efficiency. In this paper, we discover augmentation strategies can\neffectively unleash the potential of reliable samples, but the rapidly growing\ncomputational cost impedes their real-time application. To address this\nlimitation, we propose a novel TTA approach named Single-step Ensemble of\nVicinal Augmentations (SEVA), which can take advantage of data augmentations\nwithout increasing the computational burden. Specifically, instead of\nexplicitly utilizing the augmentation strategy to generate new data, SEVA\ndevelops a theoretical framework to explore the impacts of multiple\naugmentations on model adaptation and proposes to optimize an upper bound of\nthe entropy loss to integrate the effects of multiple rounds of augmentation\ntraining into a single step. Furthermore, we discover and verify that using the\nupper bound as the loss is more conducive to the selection mechanism, as it can\neffectively filter out harmful samples that confuse the model. Combining these\ntwo key advantages, the proposed efficient loss and a complementary selection\nstrategy can simultaneously boost the potential of reliable samples and meet\nthe stringent time requirements of TTA. The comprehensive experiments on\nvarious network architectures across challenging testing scenarios demonstrate\nimpressive performances and the broad adaptability of SEVA. The code will be\npublicly available.", "published": "2025-05-07 02:58:37", "link": "http://arxiv.org/abs/2505.04087v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding", "abstract": "3D visual grounding aims to localize the unique target described by natural\nlanguages in 3D scenes. The significant gap between 3D and language modalities\nmakes it a notable challenge to distinguish multiple similar objects through\nthe described spatial relationships. Current methods attempt to achieve\ncross-modal understanding in complex scenes via a target-centered learning\nmechanism, ignoring the perception of referred objects. We propose a novel\n2D-assisted 3D visual grounding framework that constructs semantic-spatial\nscene graphs with referred object discrimination for relationship perception.\nThe framework incorporates a dual-branch visual encoder that utilizes 2D\npre-trained attributes to guide the multi-modal object encoding. Furthermore,\nour cross-modal interaction module uses graph attention to facilitate\nrelationship-oriented information fusion. The enhanced object representation\nand iterative relational learning enable the model to establish effective\nalignment between 3D vision and referential descriptions. Experimental results\non the popular benchmarks demonstrate our superior performance compared to\nstate-of-the-art methods, especially in addressing the challenges of multiple\nsimilar distractors.", "published": "2025-05-07 02:02:15", "link": "http://arxiv.org/abs/2505.04058v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FoodTrack: Estimating Handheld Food Portions with Egocentric Video", "abstract": "Accurately tracking food consumption is crucial for nutrition and health\nmonitoring. Traditional approaches typically require specific camera angles,\nnon-occluded images, or rely on gesture recognition to estimate intake, making\nassumptions about bite size rather than directly measuring food volume. We\npropose the FoodTrack framework for tracking and measuring the volume of\nhand-held food items using egocentric video which is robust to hand occlusions\nand flexible with varying camera and object poses. FoodTrack estimates food\nvolume directly, without relying on intake gestures or fixed assumptions about\nbite size, offering a more accurate and adaptable solution for tracking food\nconsumption. We achieve absolute percentage loss of approximately 7.01% on a\nhandheld food object, improving upon a previous approach that achieved a 16.40%\nmean absolute percentage error in its best case, under less flexible\nconditions.", "published": "2025-05-07 01:53:16", "link": "http://arxiv.org/abs/2505.04055v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Person-In-Situ: Scene-Consistent Human Image Insertion with Occlusion-Aware Pose Control", "abstract": "Compositing human figures into scene images has broad applications in areas\nsuch as entertainment and advertising. However, existing methods often cannot\nhandle occlusion of the inserted person by foreground objects and unnaturally\nplace the person in the frontmost layer. Moreover, they offer limited control\nover the inserted person's pose. To address these challenges, we propose two\nmethods. Both allow explicit pose control via a 3D body model and leverage\nlatent diffusion models to synthesize the person at a contextually appropriate\ndepth, naturally handling occlusions without requiring occlusion masks. The\nfirst is a two-stage approach: the model first learns a depth map of the scene\nwith the person through supervised learning, and then synthesizes the person\naccordingly. The second method learns occlusion implicitly and synthesizes the\nperson directly from input data without explicit depth supervision.\nQuantitative and qualitative evaluations show that both methods outperform\nexisting approaches by better preserving scene consistency while accurately\nreflecting occlusions and user-specified poses.", "published": "2025-05-07 01:47:15", "link": "http://arxiv.org/abs/2505.04052v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "TerraFusion: Joint Generation of Terrain Geometry and Texture Using Latent Diffusion Models", "abstract": "3D terrain models are essential in fields such as video game development and\nfilm production. Since surface color often correlates with terrain geometry,\ncapturing this relationship is crucial to achieving realism. However, most\nexisting methods generate either a heightmap or a texture, without sufficiently\naccounting for the inherent correlation. In this paper, we propose a method\nthat jointly generates terrain heightmaps and textures using a latent diffusion\nmodel. First, we train the model in an unsupervised manner to randomly generate\npaired heightmaps and textures. Then, we perform supervised learning of an\nexternal adapter to enable user control via hand-drawn sketches. Experiments\nshow that our approach allows intuitive terrain generation while preserving the\ncorrelation between heightmaps and textures.", "published": "2025-05-07 01:41:12", "link": "http://arxiv.org/abs/2505.04050v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "New bounds for proper $h$-conflict-free colourings", "abstract": "A proper $k$-colouring of a graph $G$ is called $h$-conflict-free if every\nvertex $v$ has at least $\\min\\, \\{h, {\\rm deg}(v)\\}$ colours appearing exactly\nonce in its neighbourhood. Let $\\chi_{\\rm pcf}^h(G)$ denote the minimum $k$\nsuch that such a colouring exists. We show that for every fixed $h\\ge 1$, every\ngraph $G$ of maximum degree $\\Delta$ satisfies $\\chi_{\\rm pcf}^h(G) \\le h\\Delta\n+ \\mathcal{O}(\\log \\Delta)$. This expands on the work of Cho et al., and\nimproves a recent result of Liu and Reed in the case $h=1$. We conjecture that\nfor every $h\\ge 1$ and every graph $G$ of maximum degree $\\Delta$ sufficiently\nlarge, the bound $\\chi_{\\rm pcf}^h(G) \\le h\\Delta + 1$ should hold, which would\nbe tight. When the minimum degree $\\delta$ of $G$ is sufficiently large, namely\n$\\delta \\ge \\max\\{100h, 3000\\log \\Delta\\}$, we show that this upper bound can\nbe further reduced to $\\chi_{\\rm{pcf}}^h(G) \\le \\Delta +\n\\mathcal{O}(\\sqrt{h\\Delta})$. This improves a recent bound from Kamyczura and\nPrzyby{\\l}o when $\\delta \\le \\sqrt{h\\Delta}$.", "published": "2025-05-07 16:25:12", "link": "http://arxiv.org/abs/2505.04543v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Improved bounds on the zeros of the chromatic polynomial of graphs and claw-free graphs", "abstract": "We prove that for any graph $G$ the (complex) zeros of its chromatic\npolynomial, $\\chi_G(x)$, lie inside the disk centered at $0$ of radius $4.25\n\\Delta(G)$, where $\\Delta(G)$ denote the maximum degree of $G$. This improves\non a recent result of Jenssen, Patel and the second author, who proved a bound\nof $5.94\\Delta(G)$. We moreover show that for graphs of sufficiently large\ngirth we can replace $4.25$ by $3.60$ and for claw-free graphs we can replace\n$4.25$ by $3.81$.\n  Our proofs build on the ideas developed by Jenssen, Patel and the second\nauthor, adding some new ideas. A key novel ingredient for claw-free graphs is\nto use a representation of the coefficients of the chromatic polynomial in\nterms of the number of certain partial acyclic orientations.", "published": "2025-05-07 12:34:30", "link": "http://arxiv.org/abs/2505.04366v1", "categories": ["math.CO", "cs.DM", "cs.DS"], "primary_category": "math.CO"}
{"title": "On the mutiplicities of interpoint distances", "abstract": "Given a set $X\\subseteq\\mathbb{R}^2$ of $n$ points and a distance $d>0$, the\nmultiplicity of $d$ is the number of times the distance $d$ appears between\npoints in $X$. Let $a_1(X) \\geq a_2(X) \\geq \\cdots \\geq a_m(X)$ denote the\nmultiplicities of the $m$ distances determined by $X$ and let\n$a(X)=\\left(a_1(X),\\dots,a_m(X)\\right)$. In this paper, we study several\nquestions from Erd\\H{o}s's time regarding distance multiplicities. Among other\nresults, we show that:\n  (1) If $X$ is convex or ``not too convex'', then there exists a distance\nother than the diameter that has multiplicity at most $n$.\n  (2) There exists a set $X \\subseteq \\mathbb{R}^2$ of $n$ points, such that\nmany distances occur with high multiplicity. In particular, at least\n$n^{\\Omega(1/\\log\\log{n})}$ distances have superlinear multiplicity in $n$.\n  (3) For any (not necessarily fixed) integer $1\\leq k\\leq\\log{n}$, there\nexists $X\\subseteq\\mathbb{R}^2$ of $n$ points, such that the difference between\nthe $k^{\\text{th}}$ and $(k+1)^{\\text{th}}$ largest multiplicities is at least\n$\\Omega(\\frac{n\\log{n}}{k})$. Moreover, the distances in $X$ with the largest\n$k$ multiplicities can be prescribed.\n  (4) For every $n\\in\\mathbb{N}$, there exists $X\\subseteq\\mathbb{R}^2$ of $n$\npoints, not all collinear or cocircular, such that $a(X)= (n-1,n-2,\\ldots,1)$.\nThere also exists $Y\\subseteq\\mathbb{R}^2$ of $n$ points with pairwise distinct\ndistance multiplicities and $a(Y) \\neq (n-1,n-2,\\ldots,1)$.", "published": "2025-05-07 09:37:27", "link": "http://arxiv.org/abs/2505.04283v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Learning-Based Approaches for Job Shop Scheduling Problems: A Review", "abstract": "Job Shop Scheduling (JSS) is one of the most studied combinatorial\noptimization problems. It involves scheduling a set of jobs with predefined\nprocessing constraints on a set of machines to achieve a desired objective,\nsuch as minimizing makespan, tardiness, or flowtime. Since it introduction, JSS\nhas become an attractive research area. Many approaches have been successfully\nused to address this problem, including exact methods, heuristics, and\nmeta-heuristics. Furthermore, various learning-based approaches have been\nproposed to solve the JSS problem. However, these approaches are still limited\nwhen compared to the more established methods. This paper summarizes and\nevaluates the most important works in the literature on machine learning\napproaches for the JSSP. We present models, analyze their benefits and\nlimitations, and propose future research directions.", "published": "2025-05-07 08:49:42", "link": "http://arxiv.org/abs/2505.04246v1", "categories": ["cs.DC", "cs.DM"], "primary_category": "cs.DC"}
{"title": "User and Recommender Behavior Over Time: Contextualizing Activity, Effectiveness, Diversity, and Fairness in Book Recommendation", "abstract": "Data is an essential resource for studying recommender systems. While there\nhas been significant work on improving and evaluating state-of-the-art models\nand measuring various properties of recommender system outputs, less attention\nhas been given to the data itself, particularly how data has changed over time.\nSuch documentation and analysis provide guidance and context for designing and\nevaluating recommender systems, particularly for evaluation designs making use\nof time (e.g., temporal splitting). In this paper, we present a temporal\nexplanatory analysis of the UCSD Book Graph dataset scraped from Goodreads, a\nsocial reading and recommendation platform active since 2006. We measure the\nbook interaction data using a set of activity, diversity, and fairness metrics;\nwe then train a set of collaborative filtering algorithms on rolling training\nwindows to observe how the same measures evolve over time in the\nrecommendations. Additionally, we explore whether the introduction of\nalgorithmic recommendations in 2011 was followed by observable changes in user\nor recommender system behavior.", "published": "2025-05-07 15:45:04", "link": "http://arxiv.org/abs/2505.04518v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "M2Rec: Multi-scale Mamba for Efficient Sequential Recommendation", "abstract": "Sequential recommendation systems aim to predict users' next preferences\nbased on their interaction histories, but existing approaches face critical\nlimitations in efficiency and multi-scale pattern recognition. While\nTransformer-based methods struggle with quadratic computational complexity,\nrecent Mamba-based models improve efficiency but fail to capture periodic user\nbehaviors, leverage rich semantic information, or effectively fuse multimodal\nfeatures. To address these challenges, we propose \\model, a novel sequential\nrecommendation framework that integrates multi-scale Mamba with Fourier\nanalysis, Large Language Models (LLMs), and adaptive gating. First, we enhance\nMamba with Fast Fourier Transform (FFT) to explicitly model periodic patterns\nin the frequency domain, separating meaningful trends from noise. Second, we\nincorporate LLM-based text embeddings to enrich sparse interaction data with\nsemantic context from item descriptions. Finally, we introduce a learnable gate\nmechanism to dynamically balance temporal (Mamba), frequency (FFT), and\nsemantic (LLM) features, ensuring harmonious multimodal fusion. Extensive\nexperiments demonstrate that \\model\\ achieves state-of-the-art performance,\nimproving Hit Rate@10 by 3.2\\% over existing Mamba-based models while\nmaintaining 20\\% faster inference than Transformer baselines. Our results\nhighlight the effectiveness of combining frequency analysis, semantic\nunderstanding, and adaptive fusion for sequential recommendation. Code and\ndatasets are available at: https://anonymous.4open.science/r/M2Rec.", "published": "2025-05-07 14:14:29", "link": "http://arxiv.org/abs/2505.04445v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Theoretical Guarantees for LT-TTD: A Unified Transformer-based Architecture for Two-Level Ranking Systems", "abstract": "Modern recommendation and search systems typically employ multi-stage ranking\narchitectures to efficiently handle billions of candidates. The conventional\napproach uses distinct L1 (candidate retrieval) and L2 (re-ranking) models with\ndifferent optimization objectives, introducing critical limitations including\nirreversible error propagation and suboptimal ranking. This paper identifies\nand analyzes the fundamental limitations of this decoupled paradigm and\nproposes LT-TTD (Listwise Transformer with Two-Tower Distillation), a novel\nunified architecture that bridges retrieval and ranking phases. Our approach\ncombines the computational efficiency of two-tower models with the expressivity\nof transformers in a unified listwise learning framework. We provide a\ncomprehensive theoretical analysis of our architecture and establish formal\nguarantees regarding error propagation mitigation, ranking quality\nimprovements, and optimization convergence. We derive theoretical bounds\nshowing that LT-TTD reduces the upper limit on irretrievable relevant items by\na factor that depends on the knowledge distillation strength, and prove that\nour multi-objective optimization framework achieves a provably better global\noptimum than disjoint training. Additionally, we analyze the computational\ncomplexity of our approach, demonstrating that the asymptotic complexity\nremains within practical bounds for real-world applications. We also introduce\nUPQE, a novel evaluation metric specifically designed for unified ranking\narchitectures that holistically captures retrieval quality, ranking\nperformance, and computational efficiency.", "published": "2025-05-07 14:01:22", "link": "http://arxiv.org/abs/2505.04434v1", "categories": ["cs.IR", "stat.ML"], "primary_category": "cs.IR"}
{"title": "LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders", "abstract": "Modeling ultra-long user behavior sequences is critical for capturing both\nlong- and short-term preferences in industrial recommender systems. Existing\nsolutions typically rely on two-stage retrieval or indirect modeling paradigms,\nincuring upstream-downstream inconsistency and computational inefficiency. In\nthis paper, we present LONGER, a Long-sequence Optimized traNsformer for\nGPU-Efficient Recommenders. LONGER incorporates (i) a global token mechanism\nfor stabilizing attention over long contexts, (ii) a token merge module with\nlightweight InnerTransformers and hybrid attention strategy to reduce quadratic\ncomplexity, and (iii) a series of engineering optimizations, including training\nwith mixed-precision and activation recomputation, KV cache serving, and the\nfully synchronous model training and serving framework for unified GPU-based\ndense and sparse parameter updates. LONGER consistently outperforms strong\nbaselines in both offline metrics and online A/B testing in both advertising\nand e-commerce services at ByteDance, validating its consistent effectiveness\nand industrial-level scaling laws. Currently, LONGER has been fully deployed at\nmore than 10 influential scenarios at ByteDance, serving billion users.", "published": "2025-05-07 13:54:26", "link": "http://arxiv.org/abs/2505.04421v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CDE-Mapper: Using Retrieval-Augmented Language Models for Linking Clinical Data Elements to Controlled Vocabularies", "abstract": "The standardization of clinical data elements (CDEs) aims to ensure\nconsistent and comprehensive patient information across various healthcare\nsystems. Existing methods often falter when standardizing CDEs of varying\nrepresentation and complex structure, impeding data integration and\ninteroperability in clinical research. We introduce CDE-Mapper, an innovative\nframework that leverages Retrieval-Augmented Generation approach combined with\nLarge Language Models to automate the linking of CDEs to controlled\nvocabularies. Our modular approach features query decomposition to manage\nvarying levels of CDEs complexity, integrates expert-defined rules within\nprompt engineering, and employs in-context learning alongside multiple\nretriever components to resolve terminological ambiguities. In addition, we\npropose a knowledge reservoir validated by a human-in-loop approach, achieving\naccurate concept linking for future applications while minimizing computational\ncosts. For four diverse datasets, CDE-Mapper achieved an average of 7.2\\%\nhigher accuracy improvement compared to baseline methods. This work highlights\nthe potential of advanced language models in improving data harmonization and\nsignificantly advancing capabilities in clinical decision support systems and\nresearch.", "published": "2025-05-07 12:32:05", "link": "http://arxiv.org/abs/2505.04365v1", "categories": ["cs.IR", "J.3"], "primary_category": "cs.IR"}
{"title": "Towards Large-scale Generative Ranking", "abstract": "Generative recommendation has recently emerged as a promising paradigm in\ninformation retrieval. However, generative ranking systems are still\nunderstudied, particularly with respect to their effectiveness and feasibility\nin large-scale industrial settings. This paper investigates this topic at the\nranking stage of Xiaohongshu's Explore Feed, a recommender system that serves\nhundreds of millions of users. Specifically, we first examine how generative\nranking outperforms current industrial recommenders. Through theoretical and\nempirical analyses, we find that the primary improvement in effectiveness stems\nfrom the generative architecture, rather than the training paradigm. To\nfacilitate efficient deployment of generative ranking, we introduce RankGPT, a\nnovel generative architecture for ranking. We validate the effectiveness and\nefficiency of our solution through online A/B experiments. The results show\nthat RankGPT achieves significant improvements in user satisfaction with nearly\nequivalent computational resources compared to the existing production system.", "published": "2025-05-07 07:25:46", "link": "http://arxiv.org/abs/2505.04180v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Retrieval Augmented Time Series Forecasting", "abstract": "Time series forecasting uses historical data to predict future trends,\nleveraging the relationships between past observations and available features.\nIn this paper, we propose RAFT, a retrieval-augmented time series forecasting\nmethod to provide sufficient inductive biases and complement the model's\nlearning capacity. When forecasting the subsequent time frames, we directly\nretrieve historical data candidates from the training dataset with patterns\nmost similar to the input, and utilize the future values of these candidates\nalongside the inputs to obtain predictions. This simple approach augments the\nmodel's capacity by externally providing information about past patterns via\nretrieval modules. Our empirical evaluations on ten benchmark datasets show\nthat RAFT consistently outperforms contemporary baselines with an average win\nratio of 86%.", "published": "2025-05-07 06:26:11", "link": "http://arxiv.org/abs/2505.04163v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Uncovering Key Features for Model-Driven Engineering of Complex Performance Indicators: A Scoping Review", "abstract": "This paper addresses challenges of designing and managing Complex Performance\nIndicators (CPI), which amalgamate individual indicators to measure latent, yet\ncrucial business factors like customer satisfaction or sustainability indices.\nDespite their significant value, designing and managing CPI is intricate; they\nevolve with rapidly changing business contexts and present comprehension and\nexplanation challenges for end-users. Model-Driven Engineering (MDE) emerges as\na potent solution to overcome these hurdles and ensure CPI adoption, though its\napplication to CPI remains an understudied research area. While prior efforts\ntargeted specific CPI modeling objectives, a comprehensive overview of\nliterature advancements is lacking. This study addresses this gap by conducting\na scoping review yielding dual outcomes: (1) a comprehensive mapping of\nmodeling features in the literature and (2) a comparative analysis of the\ncoverage offered by the modeling frameworks. These outcomes enhance CPI\nunderstanding in academic and practitioner circles and offer insights for\nfuture MDE CPI advancements.", "published": "2025-05-07 15:20:52", "link": "http://arxiv.org/abs/2505.04498v1", "categories": ["cs.SE", "cs.IT", "math.IT"], "primary_category": "cs.SE"}
{"title": "The minimum distance of the antiprimitive BCH code with designed distance 3", "abstract": "Let $\\mathcal{C}_{(q,q^m+1,3,h)}$ denote the antiprimitive BCH code with\ndesigned distance 3. In this paper, we demonstrate that the minimum distance\n$d$ of $\\mathcal{C}_{(q,q^m+1,3,h)}$ equals 3 if and only if\n$\\gcd(2h+1,q+1,q^m+1)\\ne1$. When both $q$ and $m$ are odd, we determine the\nsufficient and necessary condition for $d=4$ and fully characterize the minimum\ndistance in this case. Based on these conditions, we investigate the parameters\nof $\\mathcal{C}_{(q,q^m+1,3,h)}$ for certain $h$. Additionally, two infinite\nfamilies of distance-optimal codes and several linear codes with the best known\nparameters are presented.", "published": "2025-05-07 11:02:46", "link": "http://arxiv.org/abs/2505.04315v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Massive MIMO: Instantaneous versus Statistical CSI-Based Power Allocation", "abstract": "The deployment of instantaneous CSI-based power control schemes necessitates\ncomputationally intensive signal processing operations, requiring substantial\nresources to handle real-time CSI updates and the associated overhead.\nConversely, statistical CSIbased schemes enable efficient implementation of\nadvanced power allocation algorithms within large-scale massive MIMO (mMIMO)\nsystems, where the algorithms are updated much less frequently. Nevertheless,\nthese schemes may deviate from optimal results in certain practical mMIMO\nconfigurations, necessitating the adoption of instantaneous CSI-based schemes.\nIn addition, they may be limited in practical implementation where\ninstantaneous CSI-based resource allocation and management schemes are widely\nadopted. This lecture provides a comprehensive comparison between the\nstatistical CSI-based power allocation and instantaneous CSI-based power\nallocation designs for mMIMO systems from performance, complexity, and\npractical implementation aspects.", "published": "2025-05-07 10:05:23", "link": "http://arxiv.org/abs/2505.04294v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Binary Reconstruction Codes for Correcting One Deletion and One Substitution", "abstract": "In this paper, we investigate binary reconstruction codes capable of\ncorrecting one deletion and one substitution. We define the\n\\emph{single-deletion single-substitution ball} function $ \\mathcal{B} $ as a\nmapping from a sequence to the set of sequences that can be derived from it by\nperforming one deletion and one substitution. A binary\n\\emph{$(n,N;\\mathcal{B})$-reconstruction code} is defined as a collection of\nbinary sequences of length $ n $ such that the intersection size between the\nsingle-deletion single-substitution balls of any two distinct codewords is\nstrictly less than $ N $. This property ensures that each codeword can be\nuniquely reconstructed from $ N $ distinct elements in its single-deletion\nsingle-substitution ball. Our main contribution is to demonstrate that when $ N\n$ is set to $ 4n - 8 $, $ 3n - 4 $, $2n+9$, $ n+21 $, $31$, and $7$, the\nredundancy of binary $(n,N;\\mathcal{B})$-reconstruction codes can be $0$, $1$,\n$2$, $ \\log\\log n + 3 $, $\\log n + 1 $, and $ 3\\log n + 4 $, respectively,\nwhere the logarithm is on base two.", "published": "2025-05-07 08:34:06", "link": "http://arxiv.org/abs/2505.04232v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The stability of generalized phase retrieval problem over compact groups", "abstract": "The generalized phase retrieval problem over compact groups aims to recover a\nset of matrices, representing an unknown signal, from their associated Gram\nmatrices, leveraging prior structural knowledge about the signal. This\nframework generalizes the classical phase retrieval problem, which reconstructs\na signal from the magnitudes of its Fourier transform, to a richer setting\ninvolving non-abelian compact groups. In this broader context, the unknown\nphases in Fourier space are replaced by unknown orthogonal matrices that arise\nfrom the action of a compact group on a finite-dimensional vector space. This\nproblem is primarily motivated by advances in electron microscopy to\ndetermining the 3D structure of biological macromolecules from highly noisy\nobservations. To capture realistic assumptions from machine learning and signal\nprocessing, we model the signal as belonging to one of several broad structural\nfamilies: a generic linear subspace, a sparse representation in a generic\nbasis, the output of a generic ReLU neural network, or a generic\nlow-dimensional manifold. Our main result shows that, under mild conditions,\nthe generalized phase retrieval problem not only admits a unique solution (up\nto inherent group symmetries), but also satisfies a bi-Lipschitz property. This\nimplies robustness to both noise and model mismatch, an essential requirement\nfor practical use, especially when measurements are severely corrupted by\nnoise. These findings provide theoretical support for a wide class of\nscientific problems under modern structural assumptions, and they offer strong\nfoundations for developing robust algorithms in high-noise regimes.", "published": "2025-05-07 07:39:46", "link": "http://arxiv.org/abs/2505.04190v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Reinforcement Learning-Aided Design of Efficient Polarization Kernels", "abstract": "Polar codes with large kernels achieve optimal error exponents but are\ndifficult to construct when low decoding complexity is also required. We\naddress this challenge under recursive maximum likelihood decoding (RMLD) using\na rein-forcement learning approach based on the Gumbel AlphaZero algorithm. The\nresulting method, PolarZero, consistently matches exhaustive search in\nidentifying low-complexity kernels, and discovers a size-16 kernel with\ncomplexity comparable to handcrafted designs. Our results suggest that\nPolarZero is a scalable tool for large-kernel design, where brute-force search\nis no longer feasible.", "published": "2025-05-07 04:48:26", "link": "http://arxiv.org/abs/2505.04127v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Secret Sharing Schemes from Correlated Random Variables and Rate-Limited Public Communication", "abstract": "A dealer aims to share a secret with participants so that only predefined\nsubsets can reconstruct it, while others learn nothing. The dealer and\nparticipants access correlated randomness and communicate over a one-way,\npublic, rate-limited channel. For this problem, we propose the first explicit\ncoding scheme able to handle arbitrary access structures and achieve the best\nknown achievable rates, previously obtained non-constructively. Our\nconstruction relies on lossy source coding coupled with distribution\napproximation to handle the reliability constraints, followed by universal\nhashing to handle the security constraints. We stress that our coding scheme\ndoes not require symmetry or degradation assumptions on the correlated random\nvariables, and does not need a pre-shared secret among the participants and\ndealer. As a by-product, our construction also yields explicit coding schemes\nfor secret-key generation under one-way, rate-limited public communication\nthat, unlike prior work, achieves the capacity for arbitrary source\ncorrelations and do not require a pre-shared secret to ensure strong secrecy.", "published": "2025-05-07 02:26:46", "link": "http://arxiv.org/abs/2505.04076v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Is the end of Insight in Sight ?", "abstract": "It is shown that the weight matrices of a Physics-informed neural network\n(PINN)-based deep learning application to a rarefied gas dynamics problem\ndescribed by the Boltzmann equation bear no evident link to the mathematical\nstructure of the physical problem. Instead, the weights appear close to\nGaussian distributed random matrices. Although significantly more work is\nneeded to support a robust assessment in this direction, these results suggest\nthat deep-learning and the numerical solution of the Boltzmann equation\nrepresent two equivalent, but largely distinct paths to the same physical\nknowledge. If so, Explainable AI might be an unrealistic target and possibly\neven an ill-posed one.", "published": "2025-05-07 19:57:36", "link": "http://arxiv.org/abs/2505.04627v1", "categories": ["physics.comp-ph", "cs.LG", "physics.data-an"], "primary_category": "physics.comp-ph"}
{"title": "From Two Sample Testing to Singular Gaussian Discrimination", "abstract": "We establish that testing for the equality of two probability measures on a\ngeneral separable and compact metric space is equivalent to testing for the\nsingularity between two corresponding Gaussian measures on a suitable\nReproducing Kernel Hilbert Space. The corresponding Gaussians are defined via\nthe notion of kernel mean and covariance embedding of a probability measure.\nDiscerning two singular Gaussians is fundamentally simpler from an\ninformation-theoretic perspective than non-parametric two-sample testing,\nparticularly in high-dimensional settings. Our proof leverages the\nFeldman-Hajek criterion for singularity/equivalence of Gaussians on Hilbert\nspaces, and shows that discrepancies between distributions are heavily\nmagnified through their corresponding Gaussian embeddings: at a population\nlevel, distinct probability measures lead to essentially separated Gaussian\nembeddings. This appears to be a new instance of the blessing of dimensionality\nthat can be harnessed for the design of efficient inference tools in great\ngenerality.", "published": "2025-05-07 17:56:19", "link": "http://arxiv.org/abs/2505.04613v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62G10, 46E22, 60G15"], "primary_category": "stat.ML"}
{"title": "Testing Juntas Optimally with Samples", "abstract": "We prove tight upper and lower bounds of\n$\\Theta\\left(\\tfrac{1}{\\epsilon}\\left( \\sqrt{2^k \\log\\binom{n}{k} } +\n\\log\\binom{n}{k} \\right)\\right)$ on the number of samples required for\ndistribution-free $k$-junta testing. This is the first tight bound for testing\na natural class of Boolean functions in the distribution-free sample-based\nmodel. Our bounds also hold for the feature selection problem, showing that a\njunta tester must learn the set of relevant variables. For tolerant junta\ntesting, we prove a sample lower bound of $\\Omega(2^{(1-o(1)) k} +\n\\log\\binom{n}{k})$ showing that, unlike standard testing, there is no large gap\nbetween tolerant testing and learning.", "published": "2025-05-07 17:50:15", "link": "http://arxiv.org/abs/2505.04604v1", "categories": ["cs.LG", "cs.CC", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Likelihood-Free Adaptive Bayesian Inference via Nonparametric Distribution Matching", "abstract": "When the likelihood is analytically unavailable and computationally\nintractable, approximate Bayesian computation (ABC) has emerged as a widely\nused methodology for approximate posterior inference; however, it suffers from\nsevere computational inefficiency in high-dimensional settings or under diffuse\npriors. To overcome these limitations, we propose Adaptive Bayesian Inference\n(ABI), a framework that bypasses traditional data-space discrepancies and\ninstead compares distributions directly in posterior space through\nnonparametric distribution matching. By leveraging a novel Marginally-augmented\nSliced Wasserstein (MSW) distance on posterior measures and exploiting its\nquantile representation, ABI transforms the challenging problem of measuring\ndivergence between posterior distributions into a tractable sequence of\none-dimensional conditional quantile regression tasks. Moreover, we introduce a\nnew adaptive rejection sampling scheme that iteratively refines the posterior\napproximation by updating the proposal distribution via generative density\nestimation. Theoretically, we establish parametric convergence rates for the\ntrimmed MSW distance and prove that the ABI posterior converges to the true\nposterior as the tolerance threshold vanishes. Through extensive empirical\nevaluation, we demonstrate that ABI significantly outperforms data-based\nWasserstein ABC, summary-based ABC, and state-of-the-art likelihood-free\nsimulators, especially in high-dimensional or dependent observation regimes.", "published": "2025-05-07 17:50:14", "link": "http://arxiv.org/abs/2505.04603v1", "categories": ["stat.ME", "cs.LG", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Complexity Lower Bounds of Adaptive Gradient Algorithms for Non-convex Stochastic Optimization under Relaxed Smoothness", "abstract": "Recent results in non-convex stochastic optimization demonstrate the\nconvergence of popular adaptive algorithms (e.g., AdaGrad) under the $(L_0,\nL_1)$-smoothness condition, but the rate of convergence is a higher-order\npolynomial in terms of problem parameters like the smoothness constants. The\ncomplexity guaranteed by such algorithms to find an $\\epsilon$-stationary point\nmay be significantly larger than the optimal complexity of $\\Theta \\left(\n\\Delta L \\sigma^2 \\epsilon^{-4} \\right)$ achieved by SGD in the $L$-smooth\nsetting, where $\\Delta$ is the initial optimality gap, $\\sigma^2$ is the\nvariance of stochastic gradient. However, it is currently not known whether\nthese higher-order dependencies can be tightened. To answer this question, we\ninvestigate complexity lower bounds for several adaptive optimization\nalgorithms in the $(L_0, L_1)$-smooth setting, with a focus on the dependence\nin terms of problem parameters $\\Delta, L_0, L_1$. We provide complexity bounds\nfor three variations of AdaGrad, which show at least a quadratic dependence on\nproblem parameters $\\Delta, L_0, L_1$. Notably, we show that the decorrelated\nvariant of AdaGrad-Norm requires at least $\\Omega \\left( \\Delta^2 L_1^2\n\\sigma^2 \\epsilon^{-4} \\right)$ stochastic gradient queries to find an\n$\\epsilon$-stationary point. We also provide a lower bound for SGD with a broad\nclass of adaptive stepsizes. Our results show that, for certain adaptive\nalgorithms, the $(L_0, L_1)$-smooth setting is fundamentally more difficult\nthan the standard smooth setting, in terms of the initial optimality gap and\nthe smoothness constants.", "published": "2025-05-07 17:40:12", "link": "http://arxiv.org/abs/2505.04599v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Modeling Personalized Difficulty of Rehabilitation Exercises Using Causal Trees", "abstract": "Rehabilitation robots are often used in game-like interactions for\nrehabilitation to increase a person's motivation to complete rehabilitation\nexercises. By adjusting exercise difficulty for a specific user throughout the\nexercise interaction, robots can maximize both the user's rehabilitation\noutcomes and the their motivation throughout the exercise. Previous approaches\nhave assumed exercises have generic difficulty values that apply to all users\nequally, however, we identified that stroke survivors have varied and unique\nperceptions of exercise difficulty. For example, some stroke survivors found\nreaching vertically more difficult than reaching farther but lower while others\nfound reaching farther more challenging than reaching vertically. In this\npaper, we formulate a causal tree-based method to calculate exercise difficulty\nbased on the user's performance. We find that this approach accurately models\nexercise difficulty and provides a readily interpretable model of why that\nexercise is difficult for both users and caretakers.", "published": "2025-05-07 17:21:45", "link": "http://arxiv.org/abs/2505.04583v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Implicitly Aligning Humans and Autonomous Agents through Shared Task Abstractions", "abstract": "In collaborative tasks, autonomous agents fall short of humans in their\ncapability to quickly adapt to new and unfamiliar teammates. We posit that a\nlimiting factor for zero-shot coordination is the lack of shared task\nabstractions, a mechanism humans rely on to implicitly align with teammates. To\naddress this gap, we introduce HA$^2$: Hierarchical Ad Hoc Agents, a framework\nleveraging hierarchical reinforcement learning to mimic the structured approach\nhumans use in collaboration. We evaluate HA$^2$ in the Overcooked environment,\ndemonstrating statistically significant improvement over existing baselines\nwhen paired with both unseen agents and humans, providing better resilience to\nenvironmental shifts, and outperforming all state-of-the-art methods.", "published": "2025-05-07 17:19:17", "link": "http://arxiv.org/abs/2505.04579v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Multitask LSTM for Arboviral Outbreak Prediction Using Public Health Data", "abstract": "This paper presents a multitask learning approach based on long-short-term\nmemory (LSTM) networks for the joint prediction of arboviral outbreaks and case\ncounts of dengue, chikungunya, and Zika in Recife, Brazil. Leveraging\nhistorical public health data from DataSUS (2017-2023), the proposed model\nconcurrently performs binary classification (outbreak detection) and regression\n(case forecasting) tasks. A sliding window strategy was adopted to construct\ntemporal features using varying input lengths (60, 90, and 120 days), with\nhyperparameter optimization carried out using Keras Tuner. Model evaluation\nused time series cross-validation for robustness and a held-out test from 2023\nfor generalization assessment. The results show that longer windows improve\ndengue regression accuracy, while classification performance peaked at\nintermediate windows, suggesting an optimal trade-off between sequence length\nand generalization. The multitask architecture delivers competitive performance\nacross diseases and tasks, demonstrating the feasibility and advantages of\nunified modeling strategies for scalable epidemic forecasting in data-limited\npublic health scenarios.", "published": "2025-05-07 16:58:18", "link": "http://arxiv.org/abs/2505.04566v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via $\u03b1$-$\u03b2$-Divergence", "abstract": "Knowledge Distillation (KD) transfers knowledge from a large teacher model to\na smaller student model by minimizing the divergence between their output\ndistributions, typically using forward Kullback-Leibler divergence (FKLD) or\nreverse KLD (RKLD). It has become an effective training paradigm due to the\nbroader supervision information provided by the teacher distribution compared\nto one-hot labels. We identify that the core challenge in KD lies in balancing\ntwo mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}}\neffect, which refers to focusing on modes with large errors, and the\n\\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on\nmodes with high student confidence. Through an analysis of how probabilities\nare reassigned during gradient updates, we observe that these two effects are\nentangled in FKLD and RKLD, but in extreme forms. Specifically, both are too\nweak in FKLD, causing the student to fail to concentrate on the target class.\nIn contrast, both are too strong in RKLD, causing the student to overly\nemphasize the target class while ignoring the broader distributional\ninformation from the teacher. To address this imbalance, we propose ABKD, a\ngeneric framework with $\\alpha$-$\\beta$-divergence. Our theoretical results\nshow that ABKD offers a smooth interpolation between FKLD and RKLD, achieving\nan effective trade-off between these effects. Extensive experiments on 17\nlanguage/vision datasets with 12 teacher-student settings confirm its efficacy.\nThe code is available at https://github.com/ghwang-s/abkd.", "published": "2025-05-07 16:48:49", "link": "http://arxiv.org/abs/2505.04560v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules", "abstract": "Federated learning (FL) makes it possible to train models on data that would\notherwise remain untapped and inaccessible. Simultaneously, pre-trained\nlanguage models (LMs) have emerged as indispensable tools in modern workflows.\nThese models exhibit extraordinary capabilities and are easily adapted to\ndownstream tasks. This opens one of the most exciting frontiers in FL:\nfine-tuning LMs. However, a persistent challenge in FL is the frequent, rigid\ncommunication of parameters, a problem which is magnified by the sheer size of\nthese modern models. Currently, the FedOpt family of algorithms is the\nprevailing approach in FL, though it relies on fixed, heuristic intervals for\nmodel synchronization. Recently, the FDA algorithm introduced a dynamic\nalternative by monitoring training progress, but it came with its own\ndrawbacks; namely, a hard-to-tune threshold parameter and a rigid\nsynchronization scheme. In this work, we introduce the FDA-Opt family of\nalgorithms -- a unified generalization that extends the principles behind both\nFDA and FedOpt, while resolving their core limitations. We evaluate our\napproach on fine-tuning LMs across a range of downstream NLP tasks, and\ndemonstrate that it consistently outperforms FedOpt -- even when FDA-Opt\noperates under hyper-parameter settings originally optimized for its\ncompetitors. In other words, we show that FDA-Opt is a practical, drop-in\nreplacement for FedOpt in modern FL libraries and systems: it requires no\nadditional configuration and delivers superior performance out of the box.", "published": "2025-05-07 16:13:21", "link": "http://arxiv.org/abs/2505.04535v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Two-Timescale Primal-Dual Framework for Reinforcement Learning via Online Dual Variable Guidance", "abstract": "We study reinforcement learning by combining recent advances in regularized\nlinear programming formulations with the classical theory of stochastic\napproximation. Motivated by the challenge of designing algorithms that leverage\noff-policy data while maintaining on-policy exploration, we propose PGDA-RL, a\nnovel primal-dual Projected Gradient Descent-Ascent algorithm for solving\nregularized Markov Decision Processes (MDPs). PGDA-RL integrates experience\nreplay-based gradient estimation with a two-timescale decomposition of the\nunderlying nested optimization problem. The algorithm operates asynchronously,\ninteracts with the environment through a single trajectory of correlated data,\nand updates its policy online in response to the dual variable associated with\nthe occupation measure of the underlying MDP. We prove that PGDA-RL converges\nalmost surely to the optimal value function and policy of the regularized MDP.\nOur convergence analysis relies on tools from stochastic approximation theory\nand holds under weaker assumptions than those required by existing primal-dual\nRL approaches, notably removing the need for a simulator or a fixed behavioral\npolicy.", "published": "2025-05-07 15:18:43", "link": "http://arxiv.org/abs/2505.04494v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "A Tutorial on Discriminative Clustering and Mutual Information", "abstract": "To cluster data is to separate samples into distinctive groups that should\nideally have some cohesive properties. Today, numerous clustering algorithms\nexist, and their differences lie essentially in what can be perceived as\n``cohesive properties''. Therefore, hypotheses on the nature of clusters must\nbe set: they can be either generative or discriminative. As the last decade\nwitnessed the impressive growth of deep clustering methods that involve neural\nnetworks to handle high-dimensional data often in a discriminative manner; we\nconcentrate mainly on the discriminative hypotheses. In this paper, our aim is\nto provide an accessible historical perspective on the evolution of\ndiscriminative clustering methods and notably how the nature of assumptions of\nthe discriminative models changed over time: from decision boundaries to\ninvariance critics. We notably highlight how mutual information has been a\nhistorical cornerstone of the progress of (deep) discriminative clustering\nmethods. We also show some known limitations of mutual information and how\ndiscriminative clustering methods tried to circumvent those. We then discuss\nthe challenges that discriminative clustering faces with respect to the\nselection of the number of clusters. Finally, we showcase these techniques\nusing the dedicated Python package, GemClus, that we have developed for\ndiscriminative clustering.", "published": "2025-05-07 14:54:36", "link": "http://arxiv.org/abs/2505.04484v1", "categories": ["stat.ML", "cs.LG", "62H30", "G.3"], "primary_category": "stat.ML"}
{"title": "Hamiltonian Normalizing Flows as kinetic PDE solvers: application to the 1D Vlasov-Poisson Equations", "abstract": "Many conservative physical systems can be described using the Hamiltonian\nformalism. A notable example is the Vlasov-Poisson equations, a set of partial\ndifferential equations that govern the time evolution of a phase-space density\nfunction representing collisionless particles under a self-consistent\npotential. These equations play a central role in both plasma physics and\ncosmology. Due to the complexity of the potential involved, analytical\nsolutions are rarely available, necessitating the use of numerical methods such\nas Particle-In-Cell. In this work, we introduce a novel approach based on\nHamiltonian-informed Normalizing Flows, specifically a variant of Fixed-Kinetic\nNeural Hamiltonian Flows. Our method transforms an initial Gaussian\ndistribution in phase space into the final distribution using a sequence of\ninvertible, volume-preserving transformations derived from Hamiltonian\ndynamics. The model is trained on a dataset comprising initial and final states\nat a fixed time T, generated via numerical simulations. After training, the\nmodel enables fast sampling of the final distribution from any given initial\nstate. Moreover, by automatically learning an interpretable physical potential,\nit can generalize to intermediate states not seen during training, offering\ninsights into the system's evolution across time.", "published": "2025-05-07 14:40:15", "link": "http://arxiv.org/abs/2505.04471v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs", "abstract": "Large Language Models (LLMs) show promising performance on various\nprogramming tasks, including Automatic Program Repair (APR). However, most\napproaches to LLM-based APR are limited to the static analysis of the programs,\nwhile disregarding their runtime behavior. Inspired by knowledge-augmented NLP,\nin this work, we aim to remedy this potential blind spot by augmenting standard\nAPR prompts with program execution traces. We evaluate our approach using the\nGPT family of models on three popular APR datasets. Our findings suggest that\nsimply incorporating execution traces into the prompt provides a limited\nperformance improvement over trace-free baselines, in only 2 out of 6 tested\ndataset / model configurations. We further find that the effectiveness of\nexecution traces for APR diminishes as their complexity increases. We explore\nseveral strategies for leveraging traces in prompts and demonstrate that\nLLM-optimized prompts help outperform trace-free prompts more consistently.\nAdditionally, we show trace-based prompting to be superior to finetuning a\nsmaller LLM on a small-scale dataset; and conduct probing studies reinforcing\nthe notion that execution traces can complement the reasoning abilities of the\nLLMs.", "published": "2025-05-07 14:12:41", "link": "http://arxiv.org/abs/2505.04441v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Initialization-Agnostic Clustering with Iterative Adaptive Resonance Theory", "abstract": "The clustering performance of Fuzzy Adaptive Resonance Theory (Fuzzy ART) is\nhighly dependent on the preset vigilance parameter, where deviations in its\nvalue can lead to significant fluctuations in clustering results, severely\nlimiting its practicality for non-expert users. Existing approaches generally\nenhance vigilance parameter robustness through adaptive mechanisms such as\nparticle swarm optimization and fuzzy logic rules. However, they often\nintroduce additional hyperparameters or complex frameworks that contradict the\noriginal simplicity of the algorithm. To address this, we propose Iterative\nRefinement Adaptive Resonance Theory (IR-ART), which integrates three key\nphases into a unified iterative framework: (1) Cluster Stability Detection: A\ndynamic stability detection module that identifies unstable clusters by\nanalyzing the change of sample size (number of samples in the cluster) in\niteration. (2) Unstable Cluster Deletion: An evolutionary pruning module that\neliminates low-quality clusters. (3) Vigilance Region Expansion: A vigilance\nregion expansion mechanism that adaptively adjusts similarity thresholds.\nIndependent of the specific execution of clustering, these three phases\nsequentially focus on analyzing the implicit knowledge within the iterative\nprocess, adjusting weights and vigilance parameters, thereby laying a\nfoundation for the next iteration. Experimental evaluation on 15 datasets\ndemonstrates that IR-ART improves tolerance to suboptimal vigilance parameter\nvalues while preserving the parameter simplicity of Fuzzy ART. Case studies\nvisually confirm the algorithm's self-optimization capability through iterative\nrefinement, making it particularly suitable for non-expert users in\nresource-constrained scenarios.", "published": "2025-05-07 14:12:39", "link": "http://arxiv.org/abs/2505.04440v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Localized Diffusion Models for High Dimensional Distributions Generation", "abstract": "Diffusion models are the state-of-the-art tools for various generative tasks.\nHowever, estimating high-dimensional score functions makes them potentially\nsuffer from the curse of dimensionality (CoD). This underscores the importance\nof better understanding and exploiting low-dimensional structure in the target\ndistribution. In this work, we consider locality structure, which describes\nsparse dependencies between model components. Under locality structure, the\nscore function is effectively low-dimensional, so that it can be estimated by a\nlocalized neural network with significantly reduced sample complexity. This\nmotivates the localized diffusion model, where a localized score matching loss\nis used to train the score function within a localized hypothesis space. We\nprove that such localization enables diffusion models to circumvent CoD, at the\nprice of additional localization error. Under realistic sample size scaling, we\nshow both theoretically and numerically that a moderate localization radius can\nbalance the statistical and localization error, leading to a better overall\nperformance. The localized structure also facilitates parallel training of\ndiffusion models, making it potentially more efficient for large-scale\napplications.", "published": "2025-05-07 13:51:50", "link": "http://arxiv.org/abs/2505.04417v1", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Latent Manifold Reconstruction and Representation with Topological and Geometrical Regularization", "abstract": "Manifold learning aims to discover and represent low-dimensional structures\nunderlying high-dimensional data while preserving critical topological and\ngeometric properties. Existing methods often fail to capture local details with\nglobal topological integrity from noisy data or construct a balanced\ndimensionality reduction, resulting in distorted or fractured embeddings. We\npresent an AutoEncoder-based method that integrates a manifold reconstruction\nlayer, which uncovers latent manifold structures from noisy point clouds, and\nfurther provides regularizations on topological and geometric properties during\ndimensionality reduction, whereas the two components promote each other during\ntraining. Experiments on point cloud datasets demonstrate that our method\noutperforms baselines like t-SNE, UMAP, and Topological AutoEncoders in\ndiscovering manifold structures from noisy data and preserving them through\ndimensionality reduction, as validated by visualization and quantitative\nmetrics. This work demonstrates the significance of combining manifold\nreconstruction with manifold learning to achieve reliable representation of the\nlatent manifold, particularly when dealing with noisy real-world data. Code\nrepository: https://github.com/Thanatorika/mrtg.", "published": "2025-05-07 13:47:22", "link": "http://arxiv.org/abs/2505.04412v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Heuristic-Integrated DRL Approach for Phase Optimization in Large-Scale RISs", "abstract": "Optimizing discrete phase shifts in large-scale reconfigurable intelligent\nsurfaces (RISs) is challenging due to their non-convex and non-linear nature.\nIn this letter, we propose a heuristic-integrated deep reinforcement learning\n(DRL) framework that (1) leverages accumulated actions over multiple steps in\nthe double deep Q-network (DDQN) for RIS column-wise control and (2) integrates\na greedy algorithm (GA) into each DRL step to refine the state via\nfine-grained, element-wise optimization of RIS configurations. By learning from\nGA-included states, the proposed approach effectively addresses RIS\noptimization within a small DRL action space, demonstrating its capability to\noptimize phase-shift configurations of large-scale RISs.", "published": "2025-05-07 13:34:12", "link": "http://arxiv.org/abs/2505.04401v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Supporting renewable energy planning and operation with data-driven high-resolution ensemble weather forecast", "abstract": "The planning and operation of renewable energy, especially wind power, depend\ncrucially on accurate, timely, and high-resolution weather information.\nCoarse-grid global numerical weather forecasts are typically downscaled to meet\nthese requirements, introducing challenges of scale inconsistency, process\nrepresentation error, computation cost, and entanglement of distinct\nuncertainty sources from chaoticity, model bias, and large-scale forcing. We\naddress these challenges by learning the climatological distribution of a\ntarget wind farm using its high-resolution numerical weather simulations. An\noptimal combination of this learned high-resolution climatological prior with\ncoarse-grid large scale forecasts yields highly accurate, fine-grained,\nfull-variable, large ensemble of weather pattern forecasts. Using observed\nmeteorological records and wind turbine power outputs as references, the\nproposed methodology verifies advantageously compared to existing\nnumerical/statistical forecasting-downscaling pipelines, regarding either\ndeterministic/probabilistic skills or economic gains. Moreover, a 100-member,\n10-day forecast with spatial resolution of 1 km and output frequency of 15 min\ntakes < 1 hour on a moderate-end GPU, as contrast to $\\mathcal{O}(10^3)$ CPU\nhours for conventional numerical simulation. By drastically reducing\ncomputational costs while maintaining accuracy, our method paves the way for\nmore efficient and reliable renewable energy planning and operation.", "published": "2025-05-07 13:20:36", "link": "http://arxiv.org/abs/2505.04396v1", "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "Clust-Splitter $-$ an Efficient Nonsmooth Optimization-Based Algorithm for Clustering Large Datasets", "abstract": "Clustering is a fundamental task in data mining and machine learning,\nparticularly for analyzing large-scale data. In this paper, we introduce\nClust-Splitter, an efficient algorithm based on nonsmooth optimization,\ndesigned to solve the minimum sum-of-squares clustering problem in very large\ndatasets. The clustering task is approached through a sequence of three\nnonsmooth optimization problems: two auxiliary problems used to generate\nsuitable starting points, followed by a main clustering formulation. To solve\nthese problems effectively, the limited memory bundle method is combined with\nan incremental approach to develop the Clust-Splitter algorithm. We evaluate\nClust-Splitter on real-world datasets characterized by both a large number of\nattributes and a large number of data points and compare its performance with\nseveral state-of-the-art large-scale clustering algorithms. Experimental\nresults demonstrate the efficiency of the proposed method for clustering very\nlarge datasets, as well as the high quality of its solutions, which are on par\nwith those of the best existing methods.", "published": "2025-05-07 13:13:46", "link": "http://arxiv.org/abs/2505.04389v1", "categories": ["cs.LG", "90C90, 90C26"], "primary_category": "cs.LG"}
{"title": "Discrete Optimal Transport and Voice Conversion", "abstract": "In this work, we address the voice conversion (VC) task using a vector-based\ninterface. To align audio embeddings between speakers, we employ discrete\noptimal transport mapping. Our evaluation results demonstrate the high quality\nand effectiveness of this method. Additionally, we show that applying discrete\noptimal transport as a post-processing step in audio generation can lead to the\nincorrect classification of synthetic audio as real.", "published": "2025-05-07 13:04:29", "link": "http://arxiv.org/abs/2505.04382v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Extending a Quantum Reinforcement Learning Exploration Policy with Flags to Connect Four", "abstract": "Action selection based on flags is a Reinforcement Learning (RL) exploration\npolicy that improves the exploration of the state space through the use of\nflags, which can identify the most promising actions to take in each state. The\nquantum counterpart of this exploration policy further improves upon this by\ntaking advantage of a quadratic speedup for sampling flagged actions. This\napproach has already been successfully employed for the game of Checkers. In\nthis work, we describe the application of this method to the context of Connect\nFour, in order to study its performance in a different setting, which can lead\nto a better generalization of the technique. We also kept track of a metric\nthat wasn't taken into account in previous work: the average number of\niterations to obtain a flagged action. Since going second is a significant\ndisadvantage in Connect Four, we also had the intent of exploring how this more\ncomplex scenario would impact the performance of our approach. The experiments\ninvolved training and testing classical and quantum RL agents that played\neither going first or going second against a Randomized Negamax opponent. The\nresults showed that both flagged exploration policies were clearly superior to\na simple epsilon-greedy policy. Furthermore, the quantum agents did in fact\nsample flagged actions in less iterations. Despite obtaining tagged actions\nmore consistently, the win rates between the classical and quantum versions of\nthe approach were identical, which could be due to the simplicity of the\ntraining scenario chosen.", "published": "2025-05-07 12:44:59", "link": "http://arxiv.org/abs/2505.04371v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Learning Innovations for Energy Efficiency: Advances in Non-Intrusive Load Monitoring and EV Charging Optimization for a Sustainable Grid", "abstract": "The global energy landscape is undergoing a profound transformation, often\nreferred to as the energy transition, driven by the urgent need to mitigate\nclimate change, reduce greenhouse gas emissions, and ensure sustainable energy\nsupplies. However, the undoubted complexity of new investments in renewables,\nas well as the phase out of high CO2-emission energy sources, hampers the pace\nof the energy transition and raises doubts as to whether new renewable energy\nsources are capable of solely meeting the climate target goals. This highlights\nthe need to investigate alternative pathways to accelerate the energy\ntransition, by identifying human activity domains with higher/excessive energy\ndemands. Two notable examples where there is room for improvement, in the sense\nof reducing energy consumption and consequently CO2 emissions, are residential\nenergy consumption and road transport. This dissertation investigates the\ndevelopment of novel Deep Learning techniques to create tools which solve\nlimitations in these two key energy domains. Reduction of residential energy\nconsumption can be achieved by empowering end-users with the user of\nNon-Intrusive Load Monitoring, whereas optimization of EV charging with Deep\nReinforcement Learning can tackle road transport decarbonization.", "published": "2025-05-07 12:36:19", "link": "http://arxiv.org/abs/2505.04367v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Topology-Driven Clustering: Enhancing Performance with Betti Number Filtration", "abstract": "Clustering aims to form groups of similar data points in an unsupervised\nregime. Yet, clustering complex datasets containing critically intertwined\nshapes poses significant challenges. The prevailing clustering algorithms\nwidely depend on evaluating similarity measures based on Euclidean metrics.\nExploring topological characteristics to perform clustering of complex datasets\ninevitably presents a better scope. The topological clustering algorithms\npredominantly perceive the point set through the lens of Simplicial complexes\nand Persistent homology. Despite these approaches, the existing topological\nclustering algorithms cannot somehow fully exploit topological structures and\nshow inconsistent performances on some highly complicated datasets. This work\naims to mitigate the limitations by identifying topologically similar neighbors\nthrough the Vietoris-Rips complex and Betti number filtration. In addition, we\nintroduce the concept of the Betti sequences to capture flexibly essential\nfeatures from the topological structures. Our proposed algorithm is adept at\nclustering complex, intertwined shapes contained in the datasets. We carried\nout experiments on several synthetic and real-world datasets. Our algorithm\ndemonstrated commendable performances across the datasets compared to some of\nthe well-known topology-based clustering algorithms.", "published": "2025-05-07 11:46:02", "link": "http://arxiv.org/abs/2505.04346v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive and Robust DBSCAN with Multi-agent Reinforcement Learning", "abstract": "DBSCAN, a well-known density-based clustering algorithm, has gained\nwidespread popularity and usage due to its effectiveness in identifying\nclusters of arbitrary shapes and handling noisy data. However, it encounters\nchallenges in producing satisfactory cluster results when confronted with\ndatasets of varying density scales, a common scenario in real-world\napplications. In this paper, we propose a novel Adaptive and Robust DBSCAN with\nMulti-agent Reinforcement Learning cluster framework, namely AR-DBSCAN. First,\nwe model the initial dataset as a two-level encoding tree and categorize the\ndata vertices into distinct density partitions according to the information\nuncertainty determined in the encoding tree. Each partition is then assigned to\nan agent to find the best clustering parameters without manual assistance. The\nallocation is density-adaptive, enabling AR-DBSCAN to effectively handle\ndiverse density distributions within the dataset by utilizing distinct agents\nfor different partitions. Second, a multi-agent deep reinforcement learning\nguided automatic parameter searching process is designed. The process of\nadjusting the parameter search direction by perceiving the clustering\nenvironment is modeled as a Markov decision process. Using a weakly-supervised\nreward training policy network, each agent adaptively learns the optimal\nclustering parameters by interacting with the clusters. Third, a recursive\nsearch mechanism adaptable to the data's scale is presented, enabling efficient\nand controlled exploration of large parameter spaces. Extensive experiments are\nconducted on nine artificial datasets and a real-world dataset. The results of\noffline and online tasks show that AR-DBSCAN not only improves clustering\naccuracy by up to 144.1% and 175.3% in the NMI and ARI metrics, respectively,\nbut also is capable of robustly finding dominant parameters.", "published": "2025-05-07 11:37:23", "link": "http://arxiv.org/abs/2505.04339v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Riemannian Denoising Diffusion Probabilistic Models", "abstract": "We propose Riemannian Denoising Diffusion Probabilistic Models (RDDPMs) for\nlearning distributions on submanifolds of Euclidean space that are level sets\nof functions, including most of the manifolds relevant to applications.\nExisting methods for generative modeling on manifolds rely on substantial\ngeometric information such as geodesic curves or eigenfunctions of the\nLaplace-Beltrami operator and, as a result, they are limited to manifolds where\nsuch information is available. In contrast, our method, built on a projection\nscheme, can be applied to more general manifolds, as it only requires being\nable to evaluate the value and the first order derivatives of the function that\ndefines the submanifold. We provide a theoretical analysis of our method in the\ncontinuous-time limit, which elucidates the connection between our RDDPMs and\nscore-based generative models on manifolds. The capability of our method is\ndemonstrated on datasets from previous studies and on new datasets sampled from\ntwo high-dimensional manifolds, i.e. $\\mathrm{SO}(10)$ and the configuration\nspace of molecular system alanine dipeptide with fixed dihedral angle.", "published": "2025-05-07 11:37:16", "link": "http://arxiv.org/abs/2505.04338v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Hyperbolic Fuzzy $C$-Means with Adaptive Weight-based Filtering for Clustering in Non-Euclidean Spaces", "abstract": "Clustering algorithms play a pivotal role in unsupervised learning by\nidentifying and grouping similar objects based on shared characteristics. While\ntraditional clustering techniques, such as hard and fuzzy center-based\nclustering, have been widely used, they struggle with complex,\nhigh-dimensional, and non-Euclidean datasets. In particular, the Fuzzy\n$C$-Means (FCM) algorithm, despite its efficiency and popularity, exhibits\nnotable limitations in non-Euclidean spaces. Euclidean spaces assume linear\nseparability and uniform distance scaling, limiting their effectiveness in\ncapturing complex, hierarchical, or non-Euclidean structures in fuzzy\nclustering. To overcome these challenges, we introduce Filtration-based\nHyperbolic Fuzzy $C$-Means (HypeFCM), a novel clustering algorithm tailored for\nbetter representation of data relationships in non-Euclidean spaces. HypeFCM\nintegrates the principles of fuzzy clustering with hyperbolic geometry and\nemploys a weight-based filtering mechanism to improve performance. The\nalgorithm initializes weights using a Dirichlet distribution and iteratively\nrefines cluster centroids and membership assignments based on a hyperbolic\nmetric in the Poincar\\'e Disc model. Extensive experimental evaluations\ndemonstrate that HypeFCM significantly outperforms conventional fuzzy\nclustering methods in non-Euclidean settings, underscoring its robustness and\neffectiveness.", "published": "2025-05-07 11:32:53", "link": "http://arxiv.org/abs/2505.04335v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Physics-Informed DeepONets for drift-diffusion on metric graphs: simulation and parameter identification", "abstract": "We develop a novel physics informed deep learning approach for solving\nnonlinear drift-diffusion equations on metric graphs. These models represent an\nimportant model class with a large number of applications in areas ranging from\ntransport in biological cells to the motion of human crowds. While traditional\nnumerical schemes require a large amount of tailoring, especially in the case\nof model design or parameter identification problems, physics informed deep\noperator networks (DeepONet) have emerged as a versatile tool for the solution\nof partial differential equations with the particular advantage that they\neasily incorporate parameter identification questions. We here present an\napproach where we first learn three DeepONet models for representative inflow,\ninner and outflow edges, resp., and then subsequently couple these models for\nthe solution of the drift-diffusion metric graph problem by relying on an\nedge-based domain decomposition approach. We illustrate that our framework is\napplicable for the accurate evaluation of graph-coupled physics models and is\nwell suited for solving optimization or inverse problems on these coupled\nnetworks.", "published": "2025-05-07 09:13:00", "link": "http://arxiv.org/abs/2505.04263v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Technology prediction of a 3D model using Neural Network", "abstract": "Accurate estimation of production times is critical for effective\nmanufacturing scheduling, yet traditional methods relying on expert analysis or\nhistorical data often fall short in dynamic or customized production\nenvironments. This paper introduces a data-driven approach that predicts\nmanufacturing steps and their durations directly from a product's 3D model. By\nrendering the model into multiple 2D images and leveraging a neural network\ninspired by the Generative Query Network, the method learns to map geometric\nfeatures into time estimates for predefined production steps enabling scalable,\nadaptive, and precise process planning across varied product types.", "published": "2025-05-07 08:45:44", "link": "http://arxiv.org/abs/2505.04241v1", "categories": ["cs.LG", "I.2.10"], "primary_category": "cs.LG"}
{"title": "Cyber Security Data Science: Machine Learning Methods and their Performance on Imbalanced Datasets", "abstract": "Cybersecurity has become essential worldwide and at all levels, concerning\nindividuals, institutions, and governments. A basic principle in cybersecurity\nis to be always alert. Therefore, automation is imperative in processes where\nthe volume of daily operations is large. Several cybersecurity applications can\nbe addressed as binary classification problems, including anomaly detection,\nfraud detection, intrusion detection, spam detection, or malware detection. We\npresent three experiments. In the first experiment, we evaluate single\nclassifiers including Random Forests, Light Gradient Boosting Machine, eXtreme\nGradient Boosting, Logistic Regression, Decision Tree, and Gradient Boosting\nDecision Tree. In the second experiment, we test different sampling techniques\nincluding over-sampling, under-sampling, Synthetic Minority Over-sampling\nTechnique, and Self-Paced Ensembling. In the last experiment, we evaluate\nSelf-Paced Ensembling and its number of base classifiers. We found that\nimbalance learning techniques had positive and negative effects, as reported in\nrelated studies. Thus, these techniques should be applied with caution.\nBesides, we found different best performers for each dataset. Therefore, we\nrecommend testing single classifiers and imbalance learning techniques for each\nnew dataset and application involving imbalanced datasets as is the case in\nseveral cyber security applications.", "published": "2025-05-07 07:57:33", "link": "http://arxiv.org/abs/2505.04204v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Estimating Causal Effects in Networks with Cluster-Based Bandits", "abstract": "The gold standard for estimating causal effects is randomized controlled\ntrial (RCT) or A/B testing where a random group of individuals from a\npopulation of interest are given treatment and the outcome is compared to a\nrandom group of individuals from the same population. However, A/B testing is\nchallenging in the presence of interference, commonly occurring in social\nnetworks, where individuals can impact each others outcome. Moreover, A/B\ntesting can incur a high performance loss when one of the treatment arms has a\npoor performance and the test continues to treat individuals with it.\nTherefore, it is important to design a strategy that can adapt over time and\nefficiently learn the total treatment effect in the network. We introduce two\ncluster-based multi-armed bandit (MAB) algorithms to gradually estimate the\ntotal treatment effect in a network while maximizing the expected reward by\nmaking a tradeoff between exploration and exploitation. We compare the\nperformance of our MAB algorithms with a vanilla MAB algorithm that ignores\nclusters and the corresponding RCT methods on semi-synthetic data with\nsimulated interference. The vanilla MAB algorithm shows higher reward-action\nratio at the cost of higher treatment effect error due to undesired spillover.\nThe cluster-based MAB algorithms show higher reward-action ratio compared to\ntheir corresponding RCT methods without sacrificing much accuracy in treatment\neffect estimation.", "published": "2025-05-07 07:54:33", "link": "http://arxiv.org/abs/2505.04200v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "A Large Language Model for Feasible and Diverse Population Synthesis", "abstract": "Generating a synthetic population that is both feasible and diverse is\ncrucial for ensuring the validity of downstream activity schedule simulation in\nactivity-based models (ABMs). While deep generative models (DGMs), such as\nvariational autoencoders and generative adversarial networks, have been applied\nto this task, they often struggle to balance the inclusion of rare but\nplausible combinations (i.e., sampling zeros) with the exclusion of implausible\nones (i.e., structural zeros). To improve feasibility while maintaining\ndiversity, we propose a fine-tuning method for large language models (LLMs)\nthat explicitly controls the autoregressive generation process through\ntopological orderings derived from a Bayesian Network (BN). Experimental\nresults show that our hybrid LLM-BN approach outperforms both traditional DGMs\nand proprietary LLMs (e.g., ChatGPT-4o) with few-shot learning. Specifically,\nour approach achieves approximately 95% feasibility, significantly higher than\nthe ~80% observed in DGMs, while maintaining comparable diversity, making it\nwell-suited for practical applications. Importantly, the method is based on a\nlightweight open-source LLM, enabling fine-tuning and inference on standard\npersonal computing environments. This makes the approach cost-effective and\nscalable for large-scale applications, such as synthesizing populations in\nmegacities, without relying on expensive infrastructure. By initiating the ABM\npipeline with high-quality synthetic populations, our method improves overall\nsimulation reliability and reduces downstream error propagation. The source\ncode for these methods is available for research and practical application.", "published": "2025-05-07 07:50:12", "link": "http://arxiv.org/abs/2505.04196v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Trajectory Entropy Reinforcement Learning for Predictable and Robust Control", "abstract": "Simplicity is a critical inductive bias for designing data-driven\ncontrollers, especially when robustness is important. Despite the impressive\nresults of deep reinforcement learning in complex control tasks, it is prone to\ncapturing intricate and spurious correlations between observations and actions,\nleading to failure under slight perturbations to the environment. To tackle\nthis problem, in this work we introduce a novel inductive bias towards simple\npolicies in reinforcement learning. The simplicity inductive bias is introduced\nby minimizing the entropy of entire action trajectories, corresponding to the\nnumber of bits required to describe information in action trajectories after\nthe agent observes state trajectories. Our reinforcement learning agent,\nTrajectory Entropy Reinforcement Learning, is optimized to minimize the\ntrajectory entropy while maximizing rewards. We show that the trajectory\nentropy can be effectively estimated by learning a variational parameterized\naction prediction model, and use the prediction model to construct an\ninformation-regularized reward function. Furthermore, we construct a practical\nalgorithm that enables the joint optimization of models, including the policy\nand the prediction model. Experimental evaluations on several high-dimensional\nlocomotion tasks show that our learned policies produce more cyclical and\nconsistent action trajectories, and achieve superior performance, and\nrobustness to noise and dynamic changes than the state-of-the-art.", "published": "2025-05-07 07:41:29", "link": "http://arxiv.org/abs/2505.04193v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "DiffPattern-Flex: Efficient Layout Pattern Generation via Discrete Diffusion", "abstract": "Recent advancements in layout pattern generation have been dominated by deep\ngenerative models. However, relying solely on neural networks for legality\nguarantees raises concerns in many practical applications. In this paper, we\npresent \\tool{DiffPattern}-Flex, a novel approach designed to generate reliable\nlayout patterns efficiently. \\tool{DiffPattern}-Flex incorporates a new method\nfor generating diverse topologies using a discrete diffusion model while\nmaintaining a lossless and compute-efficient layout representation. To ensure\nlegal pattern generation, we employ {an} optimization-based, white-box pattern\nassessment process based on specific design rules. Furthermore, fast sampling\nand efficient legalization technologies are employed to accelerate the\ngeneration process. Experimental results across various benchmarks demonstrate\nthat \\tool{DiffPattern}-Flex significantly outperforms existing methods and\nexcels at producing reliable layout patterns.", "published": "2025-05-07 07:04:11", "link": "http://arxiv.org/abs/2505.04173v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "STRGCN: Capturing Asynchronous Spatio-Temporal Dependencies for Irregular Multivariate Time Series Forecasting", "abstract": "Irregular multivariate time series (IMTS) are prevalent in real-world\napplications across many fields, where varying sensor frequencies and\nasynchronous measurements pose significant modeling challenges. Existing\nsolutions often rely on a pre-alignment strategy to normalize data, which can\ndistort intrinsic patterns and escalate computational and memory demands.\nAddressing these limitations, we introduce STRGCN, a Spatio-Temporal Relational\nGraph Convolutional Network that avoids pre-alignment and directly captures the\ncomplex interdependencies in IMTS by representing them as a fully connected\ngraph. Each observation is represented as a node, allowing the model to\neffectively handle misaligned timestamps by mapping all inter-node\nrelationships, thus faithfully preserving the asynchronous nature of the data.\nMoreover, we enhance this model with a hierarchical ``Sandwich'' structure that\nstrategically aggregates nodes to optimize graph embeddings, reducing\ncomputational overhead while maintaining detailed local and global context.\nExtensive experiments on four public datasets demonstrate that STRGCN achieves\nstate-of-the-art accuracy, competitive memory usage and training speed.", "published": "2025-05-07 06:41:33", "link": "http://arxiv.org/abs/2505.04167v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Optimization of Infectious Disease Intervention Measures Based on Reinforcement Learning -- Empirical analysis based on UK COVID-19 epidemic data", "abstract": "Globally, the outbreaks of infectious diseases have exerted an extremely\nprofound and severe influence on health security and the economy. During the\ncritical phases of epidemics, devising effective intervention measures poses a\nsignificant challenge to both the academic and practical arenas. There is\nnumerous research based on reinforcement learning to optimize intervention\nmeasures of infectious diseases. Nevertheless, most of these efforts have been\nconfined within the differential equation based on infectious disease models.\nAlthough a limited number of studies have incorporated reinforcement learning\nmethodologies into individual-based infectious disease models, the models\nemployed therein have entailed simplifications and limitations, rendering it\nincapable of modeling the complexity and dynamics inherent in infectious\ndisease transmission. We establish a decision-making framework based on an\nindividual agent-based transmission model, utilizing reinforcement learning to\ncontinuously explore and develop a strategy function. The framework's validity\nis verified through both experimental and theoretical approaches. Covasim, a\ndetailed and widely used agent-based disease transmission model, was modified\nto support reinforcement learning research. We conduct an exhaustive\nexploration of the application efficacy of multiple algorithms across diverse\naction spaces. Furthermore, we conduct an innovative preliminary theoretical\nanalysis concerning the issue of \"time coverage\". The results of the experiment\nrobustly validate the effectiveness and feasibility of the methodological\nframework of this study. The coping strategies gleaned therefrom prove highly\nefficacious in suppressing the expansion of the epidemic scale and safeguarding\nthe stability of the economic system, thereby providing crucial reference\nperspectives for the formulation of global public health security strategies.", "published": "2025-05-07 06:23:26", "link": "http://arxiv.org/abs/2505.04161v1", "categories": ["cs.LG", "cs.CY", "cs.MA", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "FilterTS: Comprehensive Frequency Filtering for Multivariate Time Series Forecasting", "abstract": "Multivariate time series forecasting is crucial across various industries,\nwhere accurate extraction of complex periodic and trend components can\nsignificantly enhance prediction performance. However, existing models often\nstruggle to capture these intricate patterns. To address these challenges, we\npropose FilterTS, a novel forecasting model that utilizes specialized filtering\ntechniques based on the frequency domain. FilterTS introduces a Dynamic\nCross-Variable Filtering Module, a key innovation that dynamically leverages\nother variables as filters to extract and reinforce shared variable frequency\ncomponents across variables in multivariate time series. Additionally, a Static\nGlobal Filtering Module captures stable frequency components, identified\nthroughout the entire training set. Moreover, the model is built in the\nfrequency domain, converting time-domain convolutions into frequency-domain\nmultiplicative operations to enhance computational efficiency. Extensive\nexperimental results on eight real-world datasets have demonstrated that\nFilterTS significantly outperforms existing methods in terms of prediction\naccuracy and computational efficiency.", "published": "2025-05-07 06:19:00", "link": "http://arxiv.org/abs/2505.04158v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LHT: Statistically-Driven Oblique Decision Trees for Interpretable Classification", "abstract": "We introduce the Learning Hyperplane Tree (LHT), a novel oblique decision\ntree model designed for expressive and interpretable classification. LHT\nfundamentally distinguishes itself through a non-iterative,\nstatistically-driven approach to constructing splitting hyperplanes. Unlike\nmethods that rely on iterative optimization or heuristics, LHT directly\ncomputes the hyperplane parameters, which are derived from feature weights\nbased on the differences in feature expectations between classes within each\nnode. This deterministic mechanism enables a direct and well-defined hyperplane\nconstruction process. Predictions leverage a unique piecewise linear membership\nfunction within leaf nodes, obtained via local least-squares fitting. We\nformally analyze the convergence of the LHT splitting process, ensuring that\neach split yields meaningful, non-empty partitions. Furthermore, we establish\nthat the time complexity for building an LHT up to depth $d$ is $O(mnd)$,\ndemonstrating the practical feasibility of constructing trees with powerful\noblique splits using this methodology. The explicit feature weighting at each\nsplit provides inherent interpretability. Experimental results on benchmark\ndatasets demonstrate LHT's competitive accuracy, positioning it as a practical,\ntheoretically grounded, and interpretable alternative in the landscape of\ntree-based models. The implementation of the proposed method is available at\nhttps://github.com/Hongyi-Li-sz/LHT_model.", "published": "2025-05-07 05:25:44", "link": "http://arxiv.org/abs/2505.04139v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Alpha Excel Benchmark", "abstract": "This study presents a novel benchmark for evaluating Large Language Models\n(LLMs) using challenges derived from the Financial Modeling World Cup (FMWC)\nExcel competitions. We introduce a methodology for converting 113 existing FMWC\nchallenges into programmatically evaluable JSON formats and use this dataset to\ncompare the performance of several leading LLMs. Our findings demonstrate\nsignificant variations in performance across different challenge categories,\nwith models showing specific strengths in pattern recognition tasks but\nstruggling with complex numerical reasoning. The benchmark provides a\nstandardized framework for assessing LLM capabilities in realistic\nbusiness-oriented tasks rather than abstract academic problems. This research\ncontributes to the growing field of AI benchmarking by establishing proficiency\namong the 1.5 billion people who daily use Microsoft Excel as a meaningful\nevaluation metric that bridges the gap between academic AI benchmarks and\npractical business applications.", "published": "2025-05-07 03:56:26", "link": "http://arxiv.org/abs/2505.04110v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Position: We need responsible, application-driven (RAD) AI research", "abstract": "This position paper argues that achieving meaningful scientific and societal\nadvances with artificial intelligence (AI) requires a responsible,\napplication-driven approach (RAD) to AI research. As AI is increasingly\nintegrated into society, AI researchers must engage with the specific contexts\nwhere AI is being applied. This includes being responsive to ethical and legal\nconsiderations, technical and societal constraints, and public discourse. We\npresent the case for RAD-AI to drive research through a three-staged approach:\n(1) building transdisciplinary teams and people-centred studies; (2) addressing\ncontext-specific methods, ethical commitments, assumptions, and metrics; and\n(3) testing and sustaining efficacy through staged testbeds and a community of\npractice. We present a vision for the future of application-driven AI research\nto unlock new value through technically feasible methods that are adaptive to\nthe contextual needs and values of the communities they ultimately serve.", "published": "2025-05-07 03:43:52", "link": "http://arxiv.org/abs/2505.04104v1", "categories": ["cs.LG", "cs.CY", "I.2.0; K.4.1; J.4"], "primary_category": "cs.LG"}
{"title": "Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks", "abstract": "Recently, trustworthy multi-view learning has attracted extensive attention\nbecause evidence learning can provide reliable uncertainty estimation to\nenhance the credibility of multi-view predictions. Existing trusted multi-view\nlearning methods implicitly assume that multi-view data is secure. In practice,\nhowever, in safety-sensitive applications such as autonomous driving and\nsecurity monitoring, multi-view data often faces threats from adversarial\nperturbations, thereby deceiving or disrupting multi-view learning models. This\ninevitably leads to the adversarial unreliability problem (AUP) in trusted\nmulti-view learning. To overcome this tricky problem, we propose a novel\nmulti-view learning framework, namely Reliable Disentanglement Multi-view\nLearning (RDML). Specifically, we first propose evidential disentanglement\nlearning to decompose each view into clean and adversarial parts under the\nguidance of corresponding evidences, which is extracted by a pretrained\nevidence extractor. Then, we employ the feature recalibration module to\nmitigate the negative impact of adversarial perturbations and extract potential\ninformative features from them. Finally, to further ignore the irreparable\nadversarial interferences, a view-level evidential attention mechanism is\ndesigned. Extensive experiments on multi-view classification tasks with\nadversarial attacks show that our RDML outperforms the state-of-the-art\nmulti-view learning methods by a relatively large margin.", "published": "2025-05-07 01:12:00", "link": "http://arxiv.org/abs/2505.04046v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Learning based convex approximation for constrained parametric optimization", "abstract": "We propose an input convex neural network (ICNN)-based self-supervised\nlearning framework to solve continuous constrained optimization problems. By\nintegrating the augmented Lagrangian method (ALM) with the constraint\ncorrection mechanism, our framework ensures \\emph{non-strict constraint\nfeasibility}, \\emph{better optimality gap}, and \\emph{best convergence rate}\nwith respect to the state-of-the-art learning-based methods. We provide a\nrigorous convergence analysis, showing that the algorithm converges to a\nKarush-Kuhn-Tucker (KKT) point of the original problem even when the internal\nsolver is a neural network, and the approximation error is bounded. We test our\napproach on a range of benchmark tasks including quadratic programming (QP),\nnonconvex programming, and large-scale AC optimal power flow problems. The\nresults demonstrate that compared to existing solvers (e.g., \\texttt{OSQP},\n\\texttt{IPOPT}) and the latest learning-based methods (e.g., DC3, PDL), our\napproach achieves a superior balance among accuracy, feasibility, and\ncomputational efficiency.", "published": "2025-05-07 00:33:14", "link": "http://arxiv.org/abs/2505.04037v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Runtime Advocates: A Persona-Driven Framework for Requirements@Runtime Decision Support", "abstract": "Complex systems, such as small Uncrewed Aerial Systems (sUAS) swarms\ndispatched for emergency response, often require dynamic reconfiguration at\nruntime under the supervision of human operators. This introduces\nhuman-on-the-loop requirements, where evolving needs shape ongoing system\nfunctionality and behaviors. While traditional personas support upfront, static\nrequirements elicitation, we propose a persona-based advocate framework for\nruntime requirements engineering to provide ethically informed, safety-driven,\nand regulatory-aware decision support. Our approach extends standard personas\ninto event-driven personas. When triggered by events such as adverse\nenvironmental conditions, evolving mission state, or operational constraints,\nthe framework updates the sUAS operator's view of the personas, ensuring\nrelevance to current conditions. We create three key advocate personas, namely\nSafety Controller, Ethical Governor, and Regulatory Auditor, to manage\ntrade-offs among risk, ethical considerations, and regulatory compliance. We\nperform a proof-of-concept validation in an emergency response scenario using\nsUAS, showing how our advocate personas provide context-aware guidance grounded\nin safety, regulatory, and ethical constraints. By evolving static, design-time\npersonas into adaptive, event-driven advocates, the framework surfaces\nmission-critical runtime requirements in response to changing conditions. These\nrequirements shape operator decisions in real time, aligning actions with the\noperational demands of the moment.", "published": "2025-05-07 16:31:38", "link": "http://arxiv.org/abs/2505.04551v1", "categories": ["cs.SE", "cs.HC", "cs.MA"], "primary_category": "cs.SE"}
{"title": "Multi-Agent Reinforcement Learning-based Cooperative Autonomous Driving in Smart Intersections", "abstract": "Unsignalized intersections pose significant safety and efficiency challenges\ndue to complex traffic flows. This paper proposes a novel roadside unit\n(RSU)-centric cooperative driving system leveraging global perception and\nvehicle-to-infrastructure (V2I) communication. The core of the system is an\nRSU-based decision-making module using a two-stage hybrid reinforcement\nlearning (RL) framework. At first, policies are pre-trained offline using\nconservative Q-learning (CQL) combined with behavior cloning (BC) on collected\ndataset. Subsequently, these policies are fine-tuned in the simulation using\nmulti-agent proximal policy optimization (MAPPO), aligned with a self-attention\nmechanism to effectively solve inter-agent dependencies. RSUs perform real-time\ninference based on the trained models to realize vehicle control via V2I\ncommunications. Extensive experiments in CARLA environment demonstrate high\neffectiveness of the proposed system, by: \\textit{(i)} achieving failure rates\nbelow 0.03\\% in coordinating three connected and autonomous vehicles (CAVs)\nthrough complex intersection scenarios, significantly outperforming the\ntraditional Autoware control method, and \\textit{(ii)} exhibiting strong\nrobustness across varying numbers of controlled agents and shows promising\ngeneralization capabilities on other maps.", "published": "2025-05-07 08:27:52", "link": "http://arxiv.org/abs/2505.04231v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Duality-Based Algorithm and Numerical Analysis for Optimal Insulation Problems on Non-Smooth Domains", "abstract": "This article develops a numerical approximation of a convex non-local and\nnon-smooth minimization problem. The physical problem involves determining the\noptimal distribution, given by $h\\colon \\Gamma_I\\to [0,+\\infty)$, of a given\namount $m\\in \\mathbb{N}$ of insulating material attached to a boundary part\n$\\Gamma_I\\subseteq \\partial\\Omega$ of a thermally conducting body $\\Omega\n\\subseteq \\mathbb{R}^d$, $d \\in \\mathbb{N}$, subject to conductive heat\ntransfer. To tackle the non-local and non-smooth character of the problem, the\narticle introduces a (Fenchel) duality framework: (a) At the continuous level,\nusing (Fenchel) duality relations, we derive an a posteriori error identity\nthat can handle arbitrary admissible approximations of the primal and dual\nformulations of the convex non-local and non-smooth minimization problem; (b)\nAt the discrete level, using discrete (Fenchel) duality relations, we derive an\na priori error identity that applies to a Crouzeix--Raviart discretization of\nthe primal formulation and a Raviart--Thomas discretization of the dual\nformulation. The proposed framework leads to error decay rates that are optimal\nwith respect to the specific regularity of a minimizer. In addition, we prove\nconvergence of the numerical approximation under minimal regularity\nassumptions. Since the discrete dual formulation can be written as a quadratic\nprogram, it is solved using a primal-dual active set strategy interpreted as\nsemismooth Newton method. A solution of the discrete primal formulation is\nreconstructed from the solution of the discrete dual formulation by means of an\ninverse generalized Marini formula. This is the first such formula for this\nclass of convex non-local and non-smooth minimization problems.", "published": "2025-05-07 17:07:03", "link": "http://arxiv.org/abs/2505.04571v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.OC", "35J20, 49J40, 49M29, 65N30, 65N15, 65N50"], "primary_category": "math.NA"}
{"title": "Adaptive finite element method for an unregularized semilinear optimal control problem", "abstract": "We devise an a posteriori error estimator for an affine optimal control\nproblem subject to a semilinear elliptic PDE and control constraints. To\napproximate the problem, we consider a semidiscrete scheme based on the\nvariational discretization approach. For this solution technique, we design an\na posteriori error estimator that accounts for the discretization of the state\nand adjoint equations, and prove, under suitable local growth conditions of\noptimal controls, reliability and efficiency properties of such error\nestimator. A simple adaptive strategy based on the devised estimator is\ndesigned and its performance is illustrated with numerical examples.", "published": "2025-05-07 14:07:27", "link": "http://arxiv.org/abs/2505.04439v1", "categories": ["math.OC", "cs.NA", "math.NA", "35J61, 49M25, 65N15, 65N30"], "primary_category": "math.OC"}
{"title": "Fast Bellman algorithm for real Monge-Amp\u00e8re equation", "abstract": "In this paper, we introduce a new numerical algorithm for solving the\nDirichlet\n  problem for the real Monge-Amp\\`ere equation. The idea is to represent the\n  Monge-Amp\\`ere operator as an infimum of a class of linear elliptic operators\n  and use Bellman's principle to construct a numeric scheme for approximating\n  the operator attaining this infimum.\n  We discuss the strengths and weaknesses of the proposed algorithm and\ndemonstrate\n  the performance of the method on several examples with various degrees of\n  degeneracy and compare the results to two existing methods. Our method runs\nconsiderably faster than the ones\n  used for comparison, improving the running time by a factor of 3-10 for\nsmooth,\n  strictly convex examples, and by a factor of 20-100 or more for mildly\ndegenerate\n  examples.", "published": "2025-05-07 12:42:23", "link": "http://arxiv.org/abs/2505.04370v1", "categories": ["math.NA", "cs.NA", "math.AP", "Primary 65N06, Secondary 35J60, 35J96, 65N12"], "primary_category": "math.NA"}
{"title": "On the one-dimensional SPH approximation of fractional-order operators", "abstract": "This work presents a theoretical formalism and the corresponding numerical\ntechniques to obtain the approximation of fractional-order operators over a 1D\ndomain via the smoothed particle hydrodynamics (SPH) method. The method is\npresented for both constant- and variable-order operators, in either integral\nor differential forms. Several numerical examples are presented in order to\nvalidate the theory against analytical results and to evaluate the performance\nof the methodology. This formalism paves the way for the solution of\nfractional-order continuum mechanics models via the SPH method.", "published": "2025-05-07 11:55:12", "link": "http://arxiv.org/abs/2505.04350v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Quantum Circuits for the Black-Scholes equations via Schr\u00f6dingerisation", "abstract": "In this paper, we construct quantum circuits for the Black-Scholes equations,\na cornerstone of financial modeling, based on a quantum algorithm that overcome\nthe cure of high dimensionality. Our approach leverages the\nSchr\\\"odingerisation technique, which converts linear partial and ordinary\ndifferential equations with non-unitary dynamics into a system evolved by\nunitary dynamics. This is achieved through a warped phase transformation that\nlifts the problem into a higher-dimensional space, enabling the simulation of\nthe Black-Scholes equation on a quantum computer. We will conduct a thorough\ncomplexity analysis to highlight the quantum advantages of our approach\ncompared to existing algorithms. The effectiveness of our quantum circuit is\nsubstantiated through extensive numerical experiments.", "published": "2025-05-07 10:21:12", "link": "http://arxiv.org/abs/2505.04304v1", "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "quant-ph"}
{"title": "A hybridizable discontinuous Galerkin method with transmission variables for time-harmonic electromagnetic problems", "abstract": "The CHDG method is a hybridizable discontinuous Galerkin (HDG) finite element\nmethod suitable for the iterative solution of time-harmonic wave propagation\nproblems. Hybrid unknowns corresponding to transmission variables are\nintroduced at the element interfaces and the physical unknowns inside the\nelements are eliminated, resulting in a hybridized system with favorable\nproperties for fast iterative solution. In this paper, we extend the CHDG\nmethod, initially studied for the Helmholtz equation, to the time-harmonic\nMaxwell equations. We prove that the local problems stemming from hybridization\nare well-posed and that the fixed-point iteration naturally associated to the\nhybridized system is contractive. We propose a 3D implementation with a\ndiscrete scheme based on nodal basis functions. The resulting solver and\ndifferent iterative strategies are studied with several numerical examples\nusing a high-performance parallel C++ code.", "published": "2025-05-07 09:47:49", "link": "http://arxiv.org/abs/2505.04288v1", "categories": ["math.NA", "cs.NA", "65F08, 65N22, 65N30"], "primary_category": "math.NA"}
{"title": "A block preconditioner for thermo-poromechanics with frictional deformation of fractures", "abstract": "The numerical modeling of fracture contact thermo-poromechanics is crucial\nfor advancing subsurface engineering applications, including CO2 sequestration,\nproduction of geo-energy resources, energy storage and wastewater disposal\noperations. Accurately modeling this problem presents substantial challenges\ndue to the complex physics involved in strongly coupled thermo-poromechanical\nprocesses and the frictional contact mechanics of fractures. To resolve process\ncouplings in the resulting mathematical model, it is common to apply fully\nimplicit time stepping. This necessitates the use of an iterative linear solver\nto run the model. The solver's efficiency primarily depends on a robust\npreconditioner, which is particularly challenging to develop because it must\nhandle the mutual couplings between linearized contact mechanics and energy,\nmomentum, and mass balance. In this work, we introduce a preconditioner for the\nproblem based on the nested approximations of Schur complements. To decouple\nthe momentum balance, we utilize the fixed-stress approximation, extended to\naccount for both the porous media and fracture subdomains. The singularity of\nthe contact mechanics submatrix is resolved by a linear transformation. Two\nvariations of the algorithm are proposed to address the coupled mass and energy\nbalance submatrix: either the Constrained Pressure Residual or the System-AMG\napproach. The preconditioner is evaluated through numerical experiments of\nfluid injection into fractured porous media, which causes thermal contraction\nand subsequent sliding and opening of fractures. The experiments show that the\npreconditioner performs robustly for a wide range of simulation regimes\ngoverned by various fracture states, friction coefficients and Peclet number.\nThe grid refinement experiments demonstrate that the preconditioner scales well\nin terms of GMRES iterations, in both two and three dimensions.", "published": "2025-05-07 08:49:49", "link": "http://arxiv.org/abs/2505.04247v1", "categories": ["math.NA", "cs.NA", "65F08, 65M08, 76S05, 35Q74, 74S10, 74M15", "G.1.3; G.1.8; G.4"], "primary_category": "math.NA"}
{"title": "Modeling of thin plate flexural vibrations by Partition of Unity Finite Element Method", "abstract": "This paper presents a conforming thin plate bending element based on the\nPartition of Unity Finite Element Method (PUFEM), for the simulation of\nsteady-state forced vibration. The issue of ensuring the continuity of\ndisplacement and slope between elements is addressed by the use of cubic\nHermite-type Partition of Unity (PU) functions. With appropriate PU functions,\nthe PUFEM allows the incorporation of the special enrichment functions into the\nfinite elements to better cope with plate oscillations in a broad frequency\nband. The enrichment strategies consist of the sum of a power series up to a\ngiven order and a combination of progressive flexural wave solutions with\npolynomials. The applicability and the effectiveness of the PUFEM plate\nelements is first verified via the structural frequency response. Investigation\nis then carried out to analyze the role of polynomial enrichment orders and\nenriched plane wave distributions for achieving good computational performance\nin terms of accuracy and data reduction. Numerical results show that the PUFEM\nwith high-order polynomials and hybrid wave-polynomial combinations can provide\nhighly accurate prediction results by using reduced degrees of freedom and\nimproved rate of convergence, as compared with the classical FEM.", "published": "2025-05-07 08:25:46", "link": "http://arxiv.org/abs/2505.04227v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Adaptive Mixed Precision and Dynamically Scaled Preconditioned Conjugate Gradient Algorithm", "abstract": "We propose an adaptive mixed precision and dynamically scaled preconditioned\nconjugate gradient algorithm (AMP-PCG). It dynamically adjusts the precision\nfor storing vectors and computing, exploiting low precision when appropriate,\nwhile maintaining a convergence rate and accuracy comparable to that of double\nprecision PCG. Our mixed precision strategy consists of three main components:\n(1) The residual and matrix-vector product are initially computed in double\nprecision, and the algorithm switches these to single precision based on the\nchosen convergence tolerance and an estimate of the residual gap. (2) Depending\non the eigenvalue distribution, the preconditioned residual and search\ndirection are either in half precision throughout the iterations or initially\nin double precision and then stepwise reduced to single and half precision. (3)\nA dynamically scaled residual is used at every iteration to mitigate underflow\nin half precision. We provide theoretical support for our estimates and we\ndemonstrate the effectiveness of AMP-PCG through numerical experiments,\nhighlighting both its robustness and the significant performance gains (1.63x\nspeedup) achieved compared to double precision PCG on a GPU.", "published": "2025-05-07 06:11:49", "link": "http://arxiv.org/abs/2505.04155v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the Crouzeix-Raviart Finite Element Approximation of Phase-Field Dependent Topology Optimization in Stokes Flow", "abstract": "In this work, we investigate a nonconforming finite element approximation of\nphase-field parameterized topology optimization governed by the Stokes flow.\nThe phase field, the velocity field and the pressure field are approximated by\nconforming linear finite elements, nonconforming linear finite elements\n(Crouzeix-Raviart elements) and piecewise constants, respectively. When\ncompared with the standard conforming counterpart, the nonconforming FEM can\nprovide an approximation with fewer degrees of freedom, leading to improved\ncomputational efficiency. We establish the convergence of the resulting\nnumerical scheme in the sense that the sequences of phase-field functions and\ndiscrete velocity fields contain subsequences that converge to a minimizing\npair of the continuous problem in the $H^1$-norm and a mesh-dependent norm,\nrespectively. We present extensive numerical results to illustrate the\nperformance of the approach, including a comparison with the popular\nTaylor-Hood elements.", "published": "2025-05-07 04:29:22", "link": "http://arxiv.org/abs/2505.04120v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Tensor robust principal component analysis via the tensor nuclear over Frobenius norm", "abstract": "We address the problem of tensor robust principal component analysis (TRPCA),\nwhich entails decomposing a given tensor into the sum of a low-rank tensor and\na sparse tensor. By leveraging the tensor singular value decomposition (t-SVD),\nwe introduce the ratio of the tensor nuclear norm to the tensor Frobenius norm\n(TNF) as a nonconvex approximation of the tensor's tubal rank in TRPCA.\nAdditionally, we utilize the traditional L1 norm to identify the sparse tensor.\nFor brevity, we refer to the combination of TNF and L1 as simply TNF. Under a\nseries of incoherence conditions, we prove that a pair of tensors serves as a\nlocal minimizer of the proposed TNF-based TRPCA model if one tensor is\nsufficiently low in rank and the other tensor is sufficiently sparse. In\naddition, we propose replacing the L1 norm with the ratio of the L1 and\nFrobenius norm for tensors, the latter denoted as the LF norm. We refer to the\ncombination of TNF and L1/LF as the TNF+ model in short. To solve both TNF and\nTNF+ models, we employ the alternating direction method of multipliers (ADMM)\nand prove subsequential convergence under certain conditions. Finally,\nextensive experiments on synthetic data, real color images, and videos are\nconducted to demonstrate the superior performance of our proposed models in\ncomparison to state-of-the-art methods in TRPCA.", "published": "2025-05-07 02:06:04", "link": "http://arxiv.org/abs/2505.04063v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Multilevel Sampling in Algebraic Statistics", "abstract": "This paper proposes a multilevel sampling algorithm for fiber sampling\nproblems in algebraic statistics, inspired by Henry Wynn's suggestion to adapt\nmultilevel Monte Carlo (MLMC) ideas to discrete models. Focusing on log-linear\nmodels, we sample from high-dimensional lattice fibers defined by algebraic\nconstraints. Building on Markov basis methods and results from Diaconis and\nSturmfels, our algorithm uses variable step sizes to accelerate exploration and\nreduce the need for long burn-in. We introduce a novel Fiber Coverage Score\n(FCS) based on Voronoi partitioning to assess sample quality, and highlight the\nutility of the Maximum Mean Discrepancy (MMD) quality metric. Simulations on\nbenchmark fibers show that multilevel sampling outperforms naive MCMC\napproaches. Our results demonstrate that multilevel methods, when properly\napplied, provide practical benefits for discrete sampling in algebraic\nstatistics.", "published": "2025-05-07 02:05:19", "link": "http://arxiv.org/abs/2505.04062v1", "categories": ["stat.CO", "cs.NA", "math.NA", "62R01 (Primary) 62-08, 52B20 (Secondary)"], "primary_category": "stat.CO"}
{"title": "Bayesian Estimation of Extreme Quantiles and the Exceedance Distribution for Paretian Tails", "abstract": "Estimating extreme quantiles is an important task in many applications,\nincluding financial risk management and climatology. More important than\nestimating the quantile itself is to insure zero coverage error, which implies\nthe quantile estimate should, on average, reflect the desired probability of\nexceedance. In this research, we show that for unconditional distributions\nisomorphic to the exponential, a Bayesian quantile estimate results in zero\ncoverage error. This compares to the traditional maximum likelihood method,\nwhere the coverage error can be significant under small sample sizes even\nthough the quantile estimate is unbiased. More generally, we prove a sufficient\ncondition for an unbiased quantile estimator to result in coverage error.\nInterestingly, our results hold by virtue of using a Jeffreys prior for the\nunknown parameters and is independent of the true prior. We also derive an\nexpression for the distribution, and moments, of future exceedances which is\nvital for risk assessment. We extend our results to the conditional tail of\ndistributions with asymptotic Paretian tails and, in particular, those in the\nFr\\'echet maximum domain of attraction. We illustrate our results using\nsimulations for a variety of light and heavy-tailed distributions.", "published": "2025-05-07 15:21:17", "link": "http://arxiv.org/abs/2505.04501v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "PAC-Bayesian risk bounds for fully connected deep neural network with Gaussian priors", "abstract": "Deep neural networks (DNNs) have emerged as a powerful methodology with\nsignificant practical successes in fields such as computer vision and natural\nlanguage processing. Recent works have demonstrated that sparsely connected\nDNNs with carefully designed architectures can achieve minimax estimation rates\nunder classical smoothness assumptions. However, subsequent studies revealed\nthat simple fully connected DNNs can achieve comparable convergence rates,\nchallenging the necessity of sparsity. Theoretical advances in Bayesian neural\nnetworks (BNNs) have been more fragmented. Much of those work has concentrated\non sparse networks, leaving the theoretical properties of fully connected BNNs\nunderexplored. In this paper, we address this gap by investigating fully\nconnected Bayesian DNNs with Gaussian prior using PAC-Bayes bounds. We\nestablish upper bounds on the prediction risk for a probabilistic deep neural\nnetwork method, showing that these bounds match (up to logarithmic factors) the\nminimax-optimal rates in Besov space, for both nonparametric regression and\nbinary classification with logistic loss. Importantly, our results hold for a\nbroad class of practical activation functions that are Lipschitz continuous.", "published": "2025-05-07 11:42:18", "link": "http://arxiv.org/abs/2505.04341v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Accelerating Audio Research with Robotic Dummy Heads", "abstract": "This work introduces a robotic dummy head that fuses the acoustic realism of\nconventional audiological mannequins with the mobility of robots. The proposed\ndevice is capable of moving, talking, and listening as people do, and can be\nused to automate spatially-stationary audio experiments, thus accelerating the\npace of audio research. Critically, the device may also be used as a moving\nsound source in dynamic experiments, due to its quiet motor. This feature\ndifferentiates our work from previous robotic acoustic research platforms.\nValidation that the robot enables high quality audio data collection is\nprovided through various experiments and acoustic measurements. These\nexperiments also demonstrate how the robot might be used to study adaptive\nbinaural beamforming. Design files are provided as open-source to stimulate\nnovel audio research.", "published": "2025-05-07 16:30:56", "link": "http://arxiv.org/abs/2505.04548v1", "categories": ["eess.AS", "cs.HC", "cs.RO", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust Speech Recognition with Schr\u00f6dinger Bridge-Based Speech Enhancement", "abstract": "In this work, we investigate application of generative speech enhancement to\nimprove the robustness of ASR models in noisy and reverberant conditions. We\nemploy a recently-proposed speech enhancement model based on Schr\\\"odinger\nbridge, which has been shown to perform well compared to diffusion-based\napproaches. We analyze the impact of model scaling and different sampling\nmethods on the ASR performance. Furthermore, we compare the considered model\nwith predictive and diffusion-based baselines and analyze the speech\nrecognition performance when using different pre-trained ASR models. The\nproposed approach significantly reduces the word error rate, reducing it by\napproximately 40% relative to the unprocessed speech signals and by\napproximately 8% relative to a similarly sized predictive approach.", "published": "2025-05-07 08:40:50", "link": "http://arxiv.org/abs/2505.04237v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "ELGAR: Expressive Cello Performance Motion Generation for Audio Rendition", "abstract": "The art of instrument performance stands as a vivid manifestation of human\ncreativity and emotion. Nonetheless, generating instrument performance motions\nis a highly challenging task, as it requires not only capturing intricate\nmovements but also reconstructing the complex dynamics of the\nperformer-instrument interaction. While existing works primarily focus on\nmodeling partial body motions, we propose Expressive ceLlo performance motion\nGeneration for Audio Rendition (ELGAR), a state-of-the-art diffusion-based\nframework for whole-body fine-grained instrument performance motion generation\nsolely from audio. To emphasize the interactive nature of the instrument\nperformance, we introduce Hand Interactive Contact Loss (HICL) and Bow\nInteractive Contact Loss (BICL), which effectively guarantee the authenticity\nof the interplay. Moreover, to better evaluate whether the generated motions\nalign with the semantic context of the music audio, we design novel metrics\nspecifically for string instrument performance motion generation, including\nfinger-contact distance, bow-string distance, and bowing score. Extensive\nevaluations and ablation studies are conducted to validate the efficacy of the\nproposed methods. In addition, we put forward a motion generation dataset\nSPD-GEN, collated and normalized from the MoCap dataset SPD. As demonstrated,\nELGAR has shown great potential in generating instrument performance motions\nwith complicated and fast interactions, which will promote further development\nin areas such as animation, music education, interactive art creation, etc.", "published": "2025-05-07 07:57:08", "link": "http://arxiv.org/abs/2505.04203v1", "categories": ["cs.GR", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
{"title": "Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment", "abstract": "Modern zero-shot text-to-speech (TTS) systems, despite using extensive\npre-training, often struggle in challenging scenarios such as tongue twisters,\nrepeated words, code-switching, and cross-lingual synthesis, leading to\nintelligibility issues. To address these limitations, this paper leverages\npreference alignment techniques, which enable targeted construction of\nout-of-pretraining-distribution data to enhance performance. We introduce a new\ndataset, named the Intelligibility Preference Speech Dataset (INTP), and extend\nthe Direct Preference Optimization (DPO) framework to accommodate diverse TTS\narchitectures. After INTP alignment, in addition to intelligibility, we observe\noverall improvements including naturalness, similarity, and audio quality for\nmultiple TTS models across diverse domains. Based on that, we also verify the\nweak-to-strong generalization ability of INTP for more intelligible models such\nas CosyVoice 2 and Ints. Moreover, we showcase the potential for further\nimprovements through iterative alignment based on Ints. Audio samples are\navailable at https://intalign.github.io/.", "published": "2025-05-07 04:04:31", "link": "http://arxiv.org/abs/2505.04113v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Aliasing Reduction in Neural Amp Modeling by Smoothing Activations", "abstract": "The increasing demand for high-quality digital emulations of analog audio\nhardware such as vintage guitar amplifiers has led to numerous works in\nneural-network-based black-box modeling, with deep learning architectures like\nWaveNet showing promising results. However, a key limitation in all of these\nmodels is the aliasing artifacts that arise from the use of nonlinear\nactivation functions in neural networks. In this paper, we investigate novel\nand modified activation functions aimed at mitigating aliasing within neural\namplifier models. Supporting this, we introduce a novel metric, the\nAliasing-to-Signal Ratio (ASR), which quantitatively assesses the level of\naliasing with high accuracy. Measuring also the conventional Error-to-Signal\nRatio (ESR), we conducted studies on a range of preexisting and modern\nactivation functions with varying stretch factors. Our findings confirmed that\nactivation functions with smoother curves tend to achieve lower ASR values,\nindicating a noticeable reduction in aliasing. Notably, this improvement in\naliasing reduction was achievable without a substantial increase in ESR,\ndemonstrating the potential for high modeling accuracy with reduced aliasing in\nneural amp models.", "published": "2025-05-07 02:49:45", "link": "http://arxiv.org/abs/2505.04082v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Particle Gibbs without the Gibbs bit", "abstract": "Exact parameter and trajectory inference in state-space models is typically\nachieved by one of two methods: particle marginal Metropolis-Hastings (PMMH) or\nparticle Gibbs (PGibbs). PMMH is a pseudo-marginal algorithm which jointly\nproposes a new trajectory and parameter, and accepts or rejects both at once.\nPGibbs instead alternates between sampling from the trajectory, using an\nalgorithm known as conditional sequential Monte Carlo (CSMC) and the parameter\nin a Hastings-within-Gibbs fashion. While particle independent Metropolis\nHastings (PIMH), the parameter-free version of PMMH, is known to be\nstatistically worse than CSMC, PGibbs can induce a slow mixing if the parameter\nand the state trajectory are very correlated. This has made PMMH the method of\nchoice for many practitioners, despite theory and experiments favouring CSMC\nover PIMH for the parameter-free problem. In this article, we describe a\nformulation of PGibbs which bypasses the Gibbs step, essentially marginalizing\nover the trajectory distribution in a fashion similar to PMMH. This is achieved\nby considering the implementation of a CSMC algortihm for the state-space model\nintegrated over the joint distribution of the current parameter and the\nparameter proposal. We illustrate the benefits of method on a simple example\nknown to be challenging for PMMH.", "published": "2025-05-07 17:55:32", "link": "http://arxiv.org/abs/2505.04611v1", "categories": ["stat.CO", "eess.SP", "stat.ME"], "primary_category": "stat.CO"}
{"title": "Image Steganography For Securing Intellicise Wireless Networks: \"Invisible Encryption\" Against Eavesdroppers", "abstract": "As one of the most promising technologies for intellicise (intelligent and\nconsice) wireless networks, Semantic Communication (SemCom) significantly\nimproves communication efficiency by extracting, transmitting, and recovering\nsemantic information, while reducing transmission delay. However, an\nintegration of communication and artificial intelligence (AI) also exposes\nSemCom to security and privacy threats posed by intelligent eavesdroppers. To\naddress this challenge, image steganography in SemCom embeds secret semantic\nfeatures within cover semantic features, allowing intelligent eavesdroppers to\ndecode only the cover image. This technique offers a form of \"invisible\nencryption\" for SemCom. Motivated by these advancements, this paper conducts a\ncomprehensive exploration of integrating image steganography into SemCom.\nFirstly, we review existing encryption techniques in SemCom and assess the\npotential of image steganography in enhancing its security. Secondly, we delve\ninto various image steganographic paradigms designed to secure SemCom,\nencompassing three categories of joint source-channel coding (JSCC) models\ntailored for image steganography SemCom, along with multiple training\nstrategies. Thirdly, we present a case study to illustrate the effectiveness of\ncoverless steganography SemCom. Finally, we propose future research directions\nfor image steganography SemCom.", "published": "2025-05-07 14:38:15", "link": "http://arxiv.org/abs/2505.04467v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Meta-Learning Driven Lightweight Phase Shift Compression for IRS-Assisted Wireless Systems", "abstract": "The phase shift information (PSI) overhead poses a critical challenge to\nenabling real-time intelligent reflecting surface (IRS)-assisted wireless\nsystems, particularly under dynamic and resource-constrained conditions. In\nthis paper, we propose a lightweight PSI compression framework, termed\nmeta-learning-driven compression and reconstruction network (MCRNet). By\nleveraging a few-shot adaptation strategy via model-agnostic meta-learning\n(MAML), MCRNet enables rapid generalization across diverse IRS configurations\nwith minimal retraining overhead. Furthermore, a novel depthwise convolutional\ngating (DWCG) module is incorporated into the decoder to achieve adaptive local\nfeature modulation with low computational cost, significantly improving\ndecoding efficiency. Extensive simulations demonstrate that MCRNet achieves\ncompetitive normalized mean square error performance compared to\nstate-of-the-art baselines across various compression ratios, while\nsubstantially reducing model size and inference latency. These results validate\nthe effectiveness of the proposed asymmetric architecture and highlight the\npractical scalability and real-time applicability of MCRNet for dynamic\nIRS-assisted wireless deployments.", "published": "2025-05-07 14:25:47", "link": "http://arxiv.org/abs/2505.04453v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Phase Shift Information Compression in IRS-aided Wireless Systems: Challenges and Opportunities", "abstract": "Intelligent reflecting surfaces (IRS) have emerged as a promising technology\nfor future 6G wireless networks, offering programmable control of the wireless\nenvironment by adjusting the phase shifts of reflecting elements. However, IRS\nperformance relies on accurately configuring the phase shifts of reflecting\nelements, which introduces substantial phase shift information (PSI) delivery\noverhead, especially in large-scale or rapidly changing environments. This\npaper first introduces the architecture of IRS-assisted systems and highlights\nreal-world use cases where PSI delivery becomes a critical bottleneck. It then\nreviews current PSI compression approaches, outlining their limitations in\nadaptability and scalability. To address these gaps, we propose a prompt-guided\nPSI compression framework that leverages task-aware prompts and meta-learning\nto achieve efficient and real-time PSI delivery under diverse conditions.\nSimulation results show improved reconstruction accuracy and robustness\ncompared to the baseline method. Finally, we discuss open challenges and\noutline promising directions for future research.", "published": "2025-05-07 14:19:57", "link": "http://arxiv.org/abs/2505.04449v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SwinLSTM Autoencoder for Temporal-Spatial-Frequency Domain CSI Compression in Massive MIMO Systems", "abstract": "This study presents a parameter-light, low-complexity artificial\nintelligence/machine learning (AI/ML) model that enhances channel state\ninformation (CSI) feedback in wireless systems by jointly exploiting temporal,\nspatial, and frequency (TSF) domain correlations. While traditional frameworks\nuse autoencoders for CSI compression at the user equipment (UE) and\nreconstruction at the network (NW) side in spatial-frequency (SF), massive\nmultiple-input multiple-output (mMIMO) systems in low mobility scenarios\nexhibit strong temporal correlation alongside frequency and spatial\ncorrelations. An autoencoder architecture alone is insufficient to exploit the\nTSF domain correlation in CSI; a recurrent element is also required. To address\nthe vanishing gradients problem, researchers in recent works have proposed\nstate-of-the-art TSF domain CSI compression architectures that combine\nrecurrent networks for temporal correlation exploitation with deep pre-trained\nautoencoder that handle SF domain CSI compression. However, this approach\nincreases the number of parameters and computational complexity. To jointly\nutilize correlations across the TSF domain, we propose a novel,\nparameter-light, low-complexity AI/ML-based recurrent autoencoder architecture\nto compress CSI at the UE side and reconstruct it on the NW side while\nminimizing CSI feedback overhead.", "published": "2025-05-07 14:00:59", "link": "http://arxiv.org/abs/2505.04432v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field MIMO Channel Acquisition: Geometry-Aided Feedback and Transmission Design", "abstract": "Near-field (NF) line-of-sight (LoS) MIMO systems enable efficient channel\nstate information (CSI) acquisition and precoding by exploiting known antenna\ngeometries at both the base station (BS) and user equipment (UE). This paper\nintroduces a compact parameterization of the NF LoS MIMO channel using two\nangles of departure (AoDs) and a BS-UE relative rotation angle. The inclusion\nof the second AoD removes the need for fine-grained distance grids imposed by\nconventional NF channel parametrization. To address the user-specific uplink\npilot overhead in multiuser NF CSI acquisition, we propose a scheme that uses a\nfixed, UE-independent set of downlink pilots transmitted from a carefully\nselected subset of BS antennas. In dominant LoS conditions, as few as four\npilots suffice, with Cram\\'er-Rao bound (CRB) analysis confirming that\nincreased antenna spacing improves estimation accuracy. Each UE estimates and\nquantizes its angular parameters and feeds them back to the BS for\ngeometry-based CSI reconstruction, eliminating the need for full channel\nfeedback. To enhance robustness against noise, quantization errors, and\nnon-line-of-sight (NLoS) components, we introduce a two-stage precoding method.\nThe initial precoding is computed from estimated LoS CSI and refined through\nbidirectional over-the-air (OTA) training. Furthermore, a two-step stream\nallocation strategy reduces pilot and computational overhead. Simulations\ndemonstrate that the proposed approach achieves high data rates with\nsignificantly fewer OTA iterations, approaching the performance of perfect CSI.", "published": "2025-05-07 10:24:13", "link": "http://arxiv.org/abs/2505.04305v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Model-based learning for joint channel estimationand hybrid MIMO precoding", "abstract": "Hybrid precoding is a key ingredient of cost-effective massive multiple-input\nmultiple-output transceivers. However, setting jointly digital and analog\nprecoders to optimally serve multiple users is a difficult optimization\nproblem. Moreover, it relies heavily on precise knowledge of the channels,\nwhich is difficult to obtain, especially when considering realistic systems\ncomprising hardware impairments. In this paper, a joint channel estimation and\nhybrid precoding method is proposed, which consists in an end-to-end\narchitecture taking received pilots as inputs and outputting precoders. The\nresulting neural network is fully model-based, making it lightweight and\ninterpretable with very few learnable parameters. The channel estimation step\nis performed using the unfolded matching pursuit algorithm, accounting for\nimperfect knowledge of the antenna system, while the precoding step is done via\nunfolded projected gradient ascent. The great potential of the proposed method\nis empirically demonstrated on realistic synthetic channels.", "published": "2025-05-07 09:00:34", "link": "http://arxiv.org/abs/2505.04255v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Energy Efficient RSMA-Based LEO Satellite Communications Assisted by UAV-Mounted BD-Active RIS: A DRL Approach", "abstract": "This paper proposes an advanced non-terrestrial communication architecture\nthat integrates Rate-Splitting Multiple Access (RSMA) with a Beyond-Diagonal\nActive Reconfigurable Intelligent Surface (BD-ARIS) mounted on a UAV under the\ncoverage of a Low Earth Orbit (LEO) satellite. The BD-ARIS adopts a\ngroup-connected structure to enhance signal amplification and adaptability,\nwhile RSMA enables efficient multi-user access by dividing messages into common\nand private components. The system jointly optimizes satellite beamforming, UAV\npositioning, power allocation, and rate-splitting ratios to maximize the\noverall energy efficiency (EE). To solve the resulting non-convex and\nhigh-dimensional problem, we employ three state-of-the-art deep reinforcement\nlearning (DRL) algorithms: Trust Region Policy Optimization (TRPO), Twin\nDelayed Deep Deterministic Policy Gradient (TD3), and Asynchronous Advantage\nActor-Critic (A3C). Moreover, realistic models for the power consumption of\nboth the UAV and the BD-ARIS are considered. Simulation results reveal that\nTRPO consistently achieves the best performance in terms of EE and sum rate,\nespecially under high transmit powers and challenging deployment scenarios. TD3\nconverges faster and performs competitively in moderate settings, while A3C\nsuffers from instability due to its high variance. Additionally, the robustness\nof each algorithm under channel state information (CSI) uncertainty is\nevaluated, confirming TRPO resilience to imperfect observations. Overall, the\nproposed RSMA-BD-ARIS framework significantly outperforms conventional\nRIS-assisted designs and provides a scalable, energy-efficient solution for 6G\nand massive IoT applications in non-terrestrial networks.", "published": "2025-05-07 05:58:31", "link": "http://arxiv.org/abs/2505.04148v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "UX-aware Rate Allocation for Real-Time Media", "abstract": "Immersive communications is a key use case for 6G where applications require\nreliable latency-bound media traffic at a certain data rate to deliver an\nacceptable User Experience (UX) or Quality-of-Experience (QoE). The\nQuality-of-Service (QoS) framework of current cellular systems (4G and 5G) and\nprevalent network congestion control algorithms for latency-bound traffic like\nL4S typically target network-related Key Performance Indicators (KPIs) such as\ndata rates and latencies. Network capacity is based on the number of users that\nattain these KPIs. However, the UX of an immersive application for a given data\nrate and latency is not the same across users, since it depends on other\nfactors such as the complexity of the media being transmitted and the encoder\nformat. This implies that guarantees on network KPIs do not necessarily\ntranslate to guarantees on the UX.\n  In this paper, we propose a framework in which the communication network can\nprovide guarantees on the UX. The framework requires application servers to\nshare real-time information on UX dependency on data rate to the network, which\nin turn, uses this information to maximize a UX-based network utility function.\nOur framework is motivated by the recent industry trends of increasing\napplication awareness at the network, and pushing application servers towards\nthe edge, allowing for tighter coordination between the servers and the 6G\nsystem. Our simulation results show that the proposed framework substantially\nimproves the UX capacity of the network, which is the number of users above a\ncertain UX threshold, compared to conventional rate control algorithms.", "published": "2025-05-07 04:10:38", "link": "http://arxiv.org/abs/2505.04114v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Device-Free Localization Using Multi-Link MIMO Channels in Distributed Antenna Networks", "abstract": "This paper presented a novel device-free localization (DFL) framework based\non distributed antenna networks (DANs), targeting integrated sensing and\ncommunication (ISAC) in future 6G radio access networks (RANs). In the proposed\napproach, radio tomographic imaging (RTI) leverages the spatial and temporal\ndiversity of multi-link multiple-input multiple-output (MIMO) channels in DANs\nto improve localization accuracy. Furthermore, a prototype system was developed\nusing software-defined radios (SDRs) operating in the sub-6 GHz band, and\ncomprehensive evaluations were conducted under indoor conditions involving\nvarying node densities and target types. The results demonstrate that the\nframework achieves sub-meter localization accuracy in most scenarios and\nmaintains robust performance under complex multipath environments. In addition,\nthe use of Bayesian optimization to fine-tune key parameters, such as sparsity\nand path thickness, led to significant improvements in image reconstruction\nquality and target estimation accuracy. These results demonstrate the\nfeasibility and effectiveness of DAN-based DFL systems for accurate, robust,\nand scalable localization.", "published": "2025-05-07 02:54:00", "link": "http://arxiv.org/abs/2505.04085v1", "categories": ["eess.SP", "eess.IV"], "primary_category": "eess.SP"}
{"title": "Defining and Quantifying Creative Behavior in Popular Image Generators", "abstract": "Creativity of generative AI models has been a subject of scientific debate in\nthe last years, without a conclusive answer. In this paper, we study creativity\nfrom a practical perspective and introduce quantitative measures that help the\nuser to choose a suitable AI model for a given task. We evaluated our measures\non a number of popular image-to-image generation models, and the results of\nthis suggest that our measures conform to human intuition.", "published": "2025-05-07 15:20:17", "link": "http://arxiv.org/abs/2505.04497v2", "categories": ["cs.CV", "cs.AI", "I.4.m; I.2.m"], "primary_category": "cs.CV"}
{"title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.", "published": "2025-05-07 06:34:34", "link": "http://arxiv.org/abs/2505.04165v2", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection", "abstract": "Accurately predicting 3D attributes is crucial for monocular 3D object\ndetection (Mono3D), with depth estimation posing the greatest challenge due to\nthe inherent ambiguity in mapping 2D images to 3D space. While existing methods\nleverage multiple depth cues (e.g., estimating depth uncertainty, modeling\ndepth error) to improve depth accuracy, they overlook that accurate depth\nprediction requires conditioning on other 3D attributes, as these attributes\nare intrinsically inter-correlated through the 3D to 2D projection, which\nultimately limits overall accuracy and stability. Inspired by Chain-of-Thought\n(CoT) in large language models (LLMs), this paper proposes MonoCoP, which\nleverages a Chain-of-Prediction (CoP) to predict attributes sequentially and\nconditionally via three key designs. First, it employs a lightweight\nAttributeNet (AN) for each 3D attribute to learn attribute-specific features.\nNext, MonoCoP constructs an explicit chain to propagate these learned features\nfrom one attribute to the next. Finally, MonoCoP uses a residual connection to\naggregate features for each attribute along the chain, ensuring that later\nattribute predictions are conditioned on all previously processed attributes\nwithout forgetting the features of earlier ones. Experimental results show that\nour MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI\nleaderboard without requiring additional data and further surpasses existing\nmethods on the Waymo and nuScenes frontal datasets.", "published": "2025-05-07 17:37:23", "link": "http://arxiv.org/abs/2505.04594v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization", "abstract": "We introduce TetWeave, a novel isosurface representation for gradient-based\nmesh optimization that jointly optimizes the placement of a tetrahedral grid\nused for Marching Tetrahedra and a novel directional signed distance at each\npoint. TetWeave constructs tetrahedral grids on-the-fly via Delaunay\ntriangulation, enabling increased flexibility compared to predefined grids. The\nextracted meshes are guaranteed to be watertight, two-manifold and\nintersection-free. The flexibility of TetWeave enables a resampling strategy\nthat places new points where reconstruction error is high and allows to\nencourage mesh fairness without compromising on reconstruction error. This\nleads to high-quality, adaptive meshes that require minimal memory usage and\nfew parameters to optimize. Consequently, TetWeave exhibits near-linear memory\nscaling relative to the vertex count of the output mesh - a substantial\nimprovement over predefined grids. We demonstrate the applicability of TetWeave\nto a broad range of challenging tasks in computer graphics and vision, such as\nmulti-view 3D reconstruction, mesh compression and geometric texture\ngeneration.", "published": "2025-05-07 17:32:49", "link": "http://arxiv.org/abs/2505.04590v2", "categories": ["cs.GR", "cs.CV", "I.3.5"], "primary_category": "cs.GR"}
{"title": "HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation", "abstract": "Customized video generation aims to produce videos featuring specific\nsubjects under flexible user-defined conditions, yet existing methods often\nstruggle with identity consistency and limited input modalities. In this paper,\nwe propose HunyuanCustom, a multi-modal customized video generation framework\nthat emphasizes subject consistency while supporting image, audio, video, and\ntext conditions. Built upon HunyuanVideo, our model first addresses the\nimage-text conditioned generation task by introducing a text-image fusion\nmodule based on LLaVA for enhanced multi-modal understanding, along with an\nimage ID enhancement module that leverages temporal concatenation to reinforce\nidentity features across frames. To enable audio- and video-conditioned\ngeneration, we further propose modality-specific condition injection\nmechanisms: an AudioNet module that achieves hierarchical alignment via spatial\ncross-attention, and a video-driven injection module that integrates\nlatent-compressed conditional video through a patchify-based feature-alignment\nnetwork. Extensive experiments on single- and multi-subject scenarios\ndemonstrate that HunyuanCustom significantly outperforms state-of-the-art open-\nand closed-source methods in terms of ID consistency, realism, and text-video\nalignment. Moreover, we validate its robustness across downstream tasks,\nincluding audio and video-driven customized video generation. Our results\nhighlight the effectiveness of multi-modal conditioning and identity-preserving\nstrategies in advancing controllable video generation. All the code and models\nare available at https://hunyuancustom.github.io.", "published": "2025-05-07 15:33:18", "link": "http://arxiv.org/abs/2505.04512v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging", "abstract": "We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural\nnetwork architecture built on top of the well-known KPConv, a widely adopted\nbackbone for 3D point cloud analysis. Even though invariance and/or\nequivariance to Euclidean transformations are required for many common tasks,\nKPConv-based networks can only approximately achieve such properties when\ntraining on large datasets or with significant data augmentations. Using Frame\nAveraging, we allow to flexibly customize point cloud neural networks built\nwith KPConv layers, by making them exactly invariant and/or equivariant to\ntranslations, rotations and/or reflections of the input point clouds. By simply\nwrapping around an existing KPConv-based network, FA-KPConv embeds geometrical\nprior knowledge into it while preserving the number of learnable parameters and\nnot compromising any input information. We showcase the benefit of such an\nintroduced bias for point cloud classification and point cloud registration,\nespecially in challenging cases such as scarce training data or randomly\nrotated test data.", "published": "2025-05-07 14:58:04", "link": "http://arxiv.org/abs/2505.04485v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning from Similarity Proportion Loss for Classifying Skeletal Muscle Recovery Stages", "abstract": "Evaluating the regeneration process of damaged muscle tissue is a fundamental\nanalysis in muscle research to measure experimental effect sizes and uncover\nmechanisms behind muscle weakness due to aging and disease. The conventional\napproach to assessing muscle tissue regeneration involves whole-slide imaging\nand expert visual inspection of the recovery stages based on the morphological\ninformation of cells and fibers. There is a need to replace these tasks with\nautomated methods incorporating machine learning techniques to ensure a\nquantitative and objective analysis. Given the limited availability of fully\nlabeled data, a possible approach is Learning from Label Proportions (LLP), a\nweakly supervised learning method using class label proportions. However,\ncurrent LLP methods have two limitations: (1) they cannot adapt the feature\nextractor for muscle tissues, and (2) they treat the classes representing\nrecovery stages and cell morphological changes as nominal, resulting in the\nloss of ordinal information. To address these issues, we propose Ordinal Scale\nLearning from Similarity Proportion (OSLSP), which uses a similarity proportion\nloss derived from two bag combinations. OSLSP can update the feature extractor\nby using class proportion attention to the ordinal scale of the class. Our\nmodel with OSLSP outperforms large-scale pre-trained and fine-tuning models in\nclassification tasks of skeletal muscle recovery stages.", "published": "2025-05-07 06:02:27", "link": "http://arxiv.org/abs/2505.04150v2", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MAISY: Motion-Aware Image SYnthesis for Medical Image Motion Correction", "abstract": "Patient motion during medical image acquisition causes blurring, ghosting,\nand distorts organs, which makes image interpretation challenging. Current\nstate-of-the-art algorithms using Generative Adversarial Network (GAN)-based\nmethods with their ability to learn the mappings between corrupted images and\ntheir ground truth via Structural Similarity Index Measure (SSIM) loss\neffectively generate motion-free images. However, we identified the following\nlimitations: (i) they mainly focus on global structural characteristics and\ntherefore overlook localized features that often carry critical pathological\ninformation, and (ii) the SSIM loss function struggles to handle images with\nvarying pixel intensities, luminance factors, and variance. In this study, we\npropose Motion-Aware Image SYnthesis (MAISY) which initially characterize\nmotion and then uses it for correction by: (a) leveraging the foundation model\nSegment Anything Model (SAM), to dynamically learn spatial patterns along\nanatomical boundaries where motion artifacts are most pronounced and, (b)\nintroducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively\nemphasizes spatial regions with high pixel variance to preserve essential\nanatomical details during artifact correction. Experiments on chest and head CT\ndatasets demonstrate that our model outperformed the state-of-the-art\ncounterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by\n10%, and Dice by 16%.", "published": "2025-05-07 03:44:28", "link": "http://arxiv.org/abs/2505.04105v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Large-scale Generative Ranking", "abstract": "Generative recommendation has recently emerged as a promising paradigm in\ninformation retrieval. However, generative ranking systems are still\nunderstudied, particularly with respect to their effectiveness and feasibility\nin large-scale industrial settings. This paper investigates this topic at the\nranking stage of Xiaohongshu's Explore Feed, a recommender system that serves\nhundreds of millions of users. Specifically, we first examine how generative\nranking outperforms current industrial recommenders. Through theoretical and\nempirical analyses, we find that the primary improvement in effectiveness stems\nfrom the generative architecture, rather than the training paradigm. To\nfacilitate efficient deployment of generative ranking, we introduce GenRank, a\nnovel generative architecture for ranking. We validate the effectiveness and\nefficiency of our solution through online A/B experiments. The results show\nthat GenRank achieves significant improvements in user satisfaction with nearly\nequivalent computational resources compared to the existing production system.", "published": "2025-05-07 07:25:46", "link": "http://arxiv.org/abs/2505.04180v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Reinforcement Learning-Aided Design of Efficient Polarization Kernels", "abstract": "Polar codes with large kernels achieve optimal error exponents but are\ndifficult to construct when low decoding complexity is also required. We\naddress this challenge under recursive maximum likelihood decoding (RMLD) using\na rein-forcement learning approach based on the Gumbel AlphaZero algorithm. The\nresulting method, PolarZero, consistently matches exhaustive search in\nidentifying low-complexity kernels, and discovers a size-16 kernel with\ncomplexity comparable to handcrafted designs. Our results suggest that\nPolarZero is a scalable tool for large-kernel design, where brute-force search\nis no longer feasible.", "published": "2025-05-07 04:48:26", "link": "http://arxiv.org/abs/2505.04127v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Particle Gibbs without the Gibbs bit", "abstract": "Exact parameter and trajectory inference in state-space models is typically\nachieved by one of two methods: particle marginal Metropolis-Hastings (PMMH) or\nparticle Gibbs (PGibbs). PMMH is a pseudo-marginal algorithm which jointly\nproposes a new trajectory and parameter, and accepts or rejects both at once.\nPGibbs instead alternates between sampling from the trajectory, using an\nalgorithm known as conditional sequential Monte Carlo (CSMC) and the parameter\nin a Hastings-within-Gibbs fashion. While particle independent Metropolis\nHastings (PIMH), the parameter-free version of PMMH, is known to be\nstatistically worse than CSMC, PGibbs can induce a slow mixing if the parameter\nand the state trajectory are very correlated. This has made PMMH the method of\nchoice for many practitioners, despite theory and experiments favouring CSMC\nover PIMH for the parameter-free problem. In this article, we describe a\nformulation of PGibbs which bypasses the Gibbs step, essentially marginalizing\nover the trajectory distribution in a fashion similar to PMMH. This is achieved\nby considering the implementation of a CSMC algortihm for the state-space model\nintegrated over the joint distribution of the current parameter and the\nparameter proposal. We illustrate the benefits of method on a simple example\nknown to be challenging for PMMH.", "published": "2025-05-07 17:55:32", "link": "http://arxiv.org/abs/2505.04611v2", "categories": ["stat.CO", "eess.SP", "stat.ME"], "primary_category": "stat.CO"}
{"title": "CRAFT: Cultural Russian-Oriented Dataset Adaptation for Focused Text-to-Image Generation", "abstract": "Despite the fact that popular text-to-image generation models cope well with\ninternational and general cultural queries, they have a significant knowledge\ngap regarding individual cultures. This is due to the content of existing large\ntraining datasets collected on the Internet, which are predominantly based on\nWestern European or American popular culture. Meanwhile, the lack of cultural\nadaptation of the model can lead to incorrect results, a decrease in the\ngeneration quality, and the spread of stereotypes and offensive content. In an\neffort to address this issue, we examine the concept of cultural code and\nrecognize the critical importance of its understanding by modern image\ngeneration models, an issue that has not been sufficiently addressed in the\nresearch community to date. We propose the methodology for collecting and\nprocessing the data necessary to form a dataset based on the cultural code, in\nparticular the Russian one. We explore how the collected data affects the\nquality of generations in the national domain and analyze the effectiveness of\nour approach using the Kandinsky 3.1 text-to-image model. Human evaluation\nresults demonstrate an increase in the level of awareness of Russian culture in\nthe model.", "published": "2025-05-07 23:29:28", "link": "http://arxiv.org/abs/2505.04851v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce\nhallucinations by grounding responses in contexts. However, even when provided\ncontext, LLMs still frequently introduce unsupported information or\ncontradictions. This paper presents our efforts to measure LLM hallucinations\nwith a focus on summarization tasks, assessing how often various LLMs introduce\nhallucinations when summarizing documents. We discuss Vectara's existing LLM\nhallucination leaderboard, based on the Hughes Hallucination Evaluation Model\n(HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great\nresearch interest, we examine challenges faced by HHEM and current\nhallucination detection methods by analyzing the effectiveness of these methods\non existing hallucination datasets. To address these limitations, we propose\nFaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination\nannotations, which substantially improves automated LLM hallucination\nevaluation over current methods. We introduce an enhanced hallucination\nleaderboard centered on FaithJudge, alongside our current hallucination\nleaderboard, enabling more reliable benchmarking of LLMs for hallucinations in\nRAG.", "published": "2025-05-07 22:50:33", "link": "http://arxiv.org/abs/2505.04847v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights", "abstract": "The volume of scientific literature is growing exponentially, leading to\nunderutilized discoveries, duplicated efforts, and limited cross-disciplinary\ncollaboration. Retrieval Augmented Generation (RAG) offers a way to assist\nscientists by improving the factuality of Large Language Models (LLMs) in\nprocessing this influx of information. However, scaling RAG to handle millions\nof articles introduces significant challenges, including the high computational\ncosts associated with parsing documents and embedding scientific knowledge, as\nwell as the algorithmic complexity of aligning these representations with the\nnuanced semantics of scientific content. To address these issues, we introduce\nHiPerRAG, a RAG workflow powered by high performance computing (HPC) to index\nand retrieve knowledge from more than 3.6 million scientific articles. At its\ncore are Oreo, a high-throughput model for multimodal document parsing, and\nColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval\naccuracy by using contrastive learning and late-interaction techniques.\nHiPerRAG delivers robust performance on existing scientific question answering\nbenchmarks and two new benchmarks introduced in this work, achieving 90%\naccuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models\nlike PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs\non the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million\ndocument-scale RAG workflows for unifying scientific knowledge and fostering\ninterdisciplinary innovation.", "published": "2025-05-07 22:50:23", "link": "http://arxiv.org/abs/2505.04846v1", "categories": ["cs.IR", "cs.CE", "cs.CL", "cs.DC", "cs.LG", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Osiris: A Lightweight Open-Source Hallucination Detection System", "abstract": "Retrieval-Augmented Generation (RAG) systems have gained widespread adoption\nby application builders because they leverage sources of truth to enable Large\nLanguage Models (LLMs) to generate more factually sound responses. However,\nhallucinations, instances of LLM responses that are unfaithful to the provided\ncontext, often prevent these systems from being deployed in production\nenvironments. Current hallucination detection methods typically involve human\nevaluation or the use of closed-source models to review RAG system outputs for\nhallucinations. Both human evaluators and closed-source models suffer from\nscaling issues due to their high costs and slow inference speeds. In this work,\nwe introduce a perturbed multi-hop QA dataset with induced hallucinations. Via\nsupervised fine-tuning on our dataset, we achieve better recall with a 7B model\nthan GPT-4o on the RAGTruth hallucination detection benchmark and offer\ncompetitive performance on precision and accuracy, all while using a fraction\nof the parameters. Code is released at our repository.", "published": "2025-05-07 22:45:59", "link": "http://arxiv.org/abs/2505.04844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs", "abstract": "Large Language Models (LLMs) are increasingly integrated into consumer and\nenterprise applications. Despite their capabilities, they remain susceptible to\nadversarial attacks such as prompt injection and jailbreaks that override\nalignment safeguards. This paper provides a systematic investigation of\njailbreak strategies against various state-of-the-art LLMs. We categorize over\n1,400 adversarial prompts, analyze their success against GPT-4, Claude 2,\nMistral 7B, and Vicuna, and examine their generalizability and construction\nlogic. We further propose layered mitigation strategies and recommend a hybrid\nred-teaming and sandboxing approach for robust LLM security.", "published": "2025-05-07 21:15:40", "link": "http://arxiv.org/abs/2505.04806v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Flower Across Time and Media: Sentiment Analysis of Tang Song Poetry and Visual Correspondence", "abstract": "The Tang (618 to 907) and Song (960 to 1279) dynasties witnessed an\nextraordinary flourishing of Chinese cultural expression, where floral motifs\nserved as a dynamic medium for both poetic sentiment and artistic design. While\nprevious scholarship has examined these domains independently, the systematic\ncorrelation between evolving literary emotions and visual culture remains\nunderexplored. This study addresses that gap by employing BERT-based sentiment\nanalysis to quantify emotional patterns in floral imagery across Tang Song\npoetry, then validating these patterns against contemporaneous developments in\ndecorative arts.Our approach builds upon recent advances in computational\nhumanities while remaining grounded in traditional sinological methods. By\napplying a fine tuned BERT model to analyze peony and plum blossom imagery in\nclassical poetry, we detect measurable shifts in emotional connotations between\nthe Tang and Song periods. These textual patterns are then cross berenced with\nvisual evidence from textiles, ceramics, and other material culture, revealing\npreviously unrecognized synergies between literary expression and artistic\nrepresentation.", "published": "2025-05-07 20:27:38", "link": "http://arxiv.org/abs/2505.04785v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When Bad Data Leads to Good Models", "abstract": "In large language model (LLM) pretraining, data quality is believed to\ndetermine model quality. In this paper, we re-examine the notion of \"quality\"\nfrom the perspective of pre- and post-training co-design. Specifically, we\nexplore the possibility that pre-training on more toxic data can lead to better\ncontrol in post-training, ultimately decreasing a model's output toxicity.\nFirst, we use a toy experiment to study how data composition affects the\ngeometry of features in the representation space. Next, through controlled\nexperiments with Olmo-1B models trained on varying ratios of clean and toxic\ndata, we find that the concept of toxicity enjoys a less entangled linear\nrepresentation as the proportion of toxic data increases. Furthermore, we show\nthat although toxic data increases the generational toxicity of the base model,\nit also makes the toxicity easier to remove. Evaluations on Toxigen and Real\nToxicity Prompts demonstrate that models trained on toxic data achieve a better\ntrade-off between reducing generational toxicity and preserving general\ncapabilities when detoxifying techniques such as inference-time intervention\n(ITI) are applied. Our findings suggest that, with post-training taken into\naccount, bad data may lead to good models.", "published": "2025-05-07 19:17:49", "link": "http://arxiv.org/abs/2505.04741v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding", "abstract": "This study addresses key challenges in developing domain-specific large\nlanguage models (LLMs) for Chinese state-owned assets and enterprises (SOAEs),\nwhere current approaches face three limitations: 1) constrained model capacity\nthat limits knowledge integration and cross-task adaptability; 2) excessive\nreliance on domain-specific supervised fine-tuning (SFT) data, which neglects\nthe broader applicability of general language patterns; and 3) inefficient\ninference acceleration for large models processing long contexts. In this work,\nwe propose SOAEsV2-7B/72B, a specialized LLM series developed via a three-phase\nframework: 1) continual pre-training integrates domain knowledge while\nretaining base capabilities; 2) domain-progressive SFT employs curriculum-based\nlearning strategy, transitioning from weakly relevant conversational data to\nexpert-annotated SOAEs datasets to optimize domain-specific tasks; 3)\ndistillation-enhanced speculative decoding accelerates inference via logit\ndistillation between 72B target and 7B draft models, achieving\n1.39-1.52$\\times$ speedup without quality loss. Experimental results\ndemonstrate that our domain-specific pre-training phase maintains 99.8% of\noriginal general language capabilities while significantly improving domain\nperformance, resulting in a 1.08$\\times$ improvement in Rouge-1 score and a\n1.17$\\times$ enhancement in BLEU-4 score. Ablation studies further show that\ndomain-progressive SFT outperforms single-stage training, achieving\n1.02$\\times$ improvement in Rouge-1 and 1.06$\\times$ in BLEU-4. Our work\nintroduces a comprehensive, full-pipeline approach for optimizing SOAEs LLMs,\nbridging the gap between general language capabilities and domain-specific\nexpertise.", "published": "2025-05-07 18:21:47", "link": "http://arxiv.org/abs/2505.04723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advanced Deep Learning Approaches for Automated Recognition of Cuneiform Symbols", "abstract": "This paper presents a thoroughly automated method for identifying and\ninterpreting cuneiform characters via advanced deep-learning algorithms. Five\ndistinct deep-learning models were trained on a comprehensive dataset of\ncuneiform characters and evaluated according to critical performance metrics,\nincluding accuracy and precision. Two models demonstrated outstanding\nperformance and were subsequently assessed using cuneiform symbols from the\nHammurabi law acquisition, notably Hammurabi Law 1. Each model effectively\nrecognized the relevant Akkadian meanings of the symbols and delivered precise\nEnglish translations. Future work will investigate ensemble and stacking\napproaches to optimize performance, utilizing hybrid architectures to improve\ndetection accuracy and reliability. This research explores the linguistic\nrelationships between Akkadian, an ancient Mesopotamian language, and Arabic,\nemphasizing their historical and cultural linkages. This study demonstrates the\ncapability of deep learning to decipher ancient scripts by merging\ncomputational linguistics with archaeology, therefore providing significant\ninsights for the comprehension and conservation of human history.", "published": "2025-05-07 12:05:23", "link": "http://arxiv.org/abs/2505.04678v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM", "abstract": "Vision Large Language Models (VLLMs) represent a significant advancement in\nartificial intelligence by integrating image-processing capabilities with\ntextual understanding, thereby enhancing user interactions and expanding\napplication domains. However, their increased complexity introduces novel\nsafety and ethical challenges, particularly in multi-modal and multi-turn\nconversations. Traditional safety evaluation frameworks, designed for\ntext-based, single-turn interactions, are inadequate for addressing these\ncomplexities. To bridge this gap, we introduce the REVEAL (Responsible\nEvaluation of Vision-Enabled AI LLMs) Framework, a scalable and automated\npipeline for evaluating image-input harms in VLLMs. REVEAL includes automated\nimage mining, synthetic adversarial data generation, multi-turn conversational\nexpansion using crescendo attack strategies, and comprehensive harm assessment\nthrough evaluators like GPT-4o.\n  We extensively evaluated five state-of-the-art VLLMs, GPT-4o, Llama-3.2,\nQwen2-VL, Phi3.5V, and Pixtral, across three important harm categories: sexual\nharm, violence, and misinformation. Our findings reveal that multi-turn\ninteractions result in significantly higher defect rates compared to\nsingle-turn evaluations, highlighting deeper vulnerabilities in VLLMs. Notably,\nGPT-4o demonstrated the most balanced performance as measured by our\nSafety-Usability Index (SUI) followed closely by Pixtral. Additionally,\nmisinformation emerged as a critical area requiring enhanced contextual\ndefenses. Llama-3.2 exhibited the highest MT defect rate ($16.55 \\%$) while\nQwen2-VL showed the highest MT refusal rate ($19.1 \\%$).", "published": "2025-05-07 10:09:55", "link": "http://arxiv.org/abs/2505.04673v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards", "abstract": "Recent advances in large language models (LLMs) have significantly improved\nperformance on the Text-to-SQL task by leveraging their powerful reasoning\ncapabilities. To enhance accuracy during the reasoning process, external\nProcess Reward Models (PRMs) can be introduced during training and inference to\nprovide fine-grained supervision. However, if misused, PRMs may distort the\nreasoning trajectory and lead to suboptimal or incorrect SQL generation.To\naddress this challenge, we propose Reward-SQL, a framework that systematically\nexplores how to incorporate PRMs into the Text-to-SQL reasoning process\neffectively. Our approach follows a \"cold start, then PRM supervision\"\nparadigm. Specifically, we first train the model to decompose SQL queries into\nstructured stepwise reasoning chains using common table expressions\n(Chain-of-CTEs), establishing a strong and interpretable reasoning baseline.\nThen, we investigate four strategies for integrating PRMs, and find that\ncombining PRM as an online training signal (GRPO) with PRM-guided inference\n(e.g., best-of-N sampling) yields the best results. Empirically, on the BIRD\nbenchmark, Reward-SQL enables models supervised by a 7B PRM to achieve a 13.1%\nperformance gain across various guidance strategies. Notably, our GRPO-aligned\npolicy model based on Qwen2.5-Coder-7B-Instruct achieves 68.9% accuracy on the\nBIRD development set, outperforming all baseline methods under the same model\nsize. These results demonstrate the effectiveness of Reward-SQL in leveraging\nreward-based supervision for Text-to-SQL reasoning. Our code is publicly\navailable.", "published": "2025-05-07 08:32:22", "link": "http://arxiv.org/abs/2505.04671v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes", "abstract": "Building codes are regulations that establish standards for the design,\nconstruction, and safety of buildings to ensure structural integrity, fire\nprotection, and accessibility. They are often extensive, complex, and subject\nto frequent updates, making manual querying challenging and time-consuming. Key\ndifficulties include navigating large volumes of text, interpreting technical\nlanguage, and identifying relevant clauses across different sections. A\npotential solution is to build a Question-Answering (QA) system that answers\nuser queries based on building codes. Among the various methods for building a\nQA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG\nconsists of two components: a retriever and a language model. This study\nfocuses on identifying a suitable retriever method for building codes and\noptimizing the generational capability of the language model using fine-tuning\ntechniques. We conducted a detailed evaluation of various retrieval methods by\nperforming the retrieval on the National Building Code of Canada (NBCC) and\nexplored the impact of domain-specific fine-tuning on several language models\nusing the dataset derived from NBCC. Our analysis included a comparative\nassessment of different retrievers and the performance of both pre-trained and\nfine-tuned models to determine the efficacy and domain-specific adaptation of\nlanguage models using fine-tuning on the NBCC dataset. Experimental results\nshowed that Elasticsearch proved to be the most robust retriever among all. The\nfindings also indicate that fine-tuning language models on an NBCC-specific\ndataset can enhance their ability to generate contextually relevant responses.\nWhen combined with context retrieved by a powerful retriever like\nElasticsearch, this improvement in LLM performance can optimize the RAG system,\nenabling it to better navigate the complexities of the NBCC.", "published": "2025-05-07 05:04:30", "link": "http://arxiv.org/abs/2505.04666v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising", "abstract": "Although large language models have demonstrated the potential for\npersonalized advertising recommendations in experimental environments, in\nactual operations, how advertising recommendation systems can be combined with\nmeasures such as user privacy protection and data security is still an area\nworthy of in-depth discussion. To this end, this paper studies the personalized\nrisks and regulatory strategies of large language models in digital\nadvertising. This study first outlines the principles of Large Language Model\n(LLM), especially the self-attention mechanism based on the Transformer\narchitecture, and how to enable the model to understand and generate natural\nlanguage text. Then, the BERT (Bidirectional Encoder Representations from\nTransformers) model and the attention mechanism are combined to construct an\nalgorithmic model for personalized advertising recommendations and user factor\nrisk protection. The specific steps include: data collection and preprocessing,\nfeature selection and construction, using large language models such as BERT\nfor advertising semantic embedding, and ad recommendations based on user\nportraits. Then, local model training and data encryption are used to ensure\nthe security of user privacy and avoid the leakage of personal data. This paper\ndesigns an experiment for personalized advertising recommendation based on a\nlarge language model of BERT and verifies it with real user data. The\nexperimental results show that BERT-based advertising push can effectively\nimprove the click-through rate and conversion rate of advertisements. At the\nsame time, through local model training and privacy protection mechanisms, the\nrisk of user privacy leakage can be reduced to a certain extent.", "published": "2025-05-07 04:25:41", "link": "http://arxiv.org/abs/2505.04665v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AI-Generated Fall Data: Assessing LLMs and Diffusion Model for Wearable Fall Detection", "abstract": "Training fall detection systems is challenging due to the scarcity of\nreal-world fall data, particularly from elderly individuals. To address this,\nwe explore the potential of Large Language Models (LLMs) for generating\nsynthetic fall data. This study evaluates text-to-motion (T2M, SATO, ParCo) and\ntext-to-text models (GPT4o, GPT4, Gemini) in simulating realistic fall\nscenarios. We generate synthetic datasets and integrate them with four\nreal-world baseline datasets to assess their impact on fall detection\nperformance using a Long Short-Term Memory (LSTM) model. Additionally, we\ncompare LLM-generated synthetic data with a diffusion-based method to evaluate\ntheir alignment with real accelerometer distributions. Results indicate that\ndataset characteristics significantly influence the effectiveness of synthetic\ndata, with LLM-generated data performing best in low-frequency settings (e.g.,\n20Hz) while showing instability in high-frequency datasets (e.g., 200Hz). While\ntext-to-motion models produce more realistic biomechanical data than\ntext-to-text models, their impact on fall detection varies. Diffusion-based\nsynthetic data demonstrates the closest alignment to real data but does not\nconsistently enhance model performance. An ablation study further confirms that\nthe effectiveness of synthetic data depends on sensor placement and fall\nrepresentation. These findings provide insights into optimizing synthetic data\ngeneration for fall detection models.", "published": "2025-05-07 02:30:33", "link": "http://arxiv.org/abs/2505.04660v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust", "abstract": "There has been a growing interest in translating C code to Rust due to Rust's\nrobust memory and thread safety guarantees. Tools such as C2RUST enable\nsyntax-guided transpilation from C to semantically equivalent Rust code.\nHowever, the resulting Rust programs often rely heavily on unsafe\nconstructs--particularly raw pointers--which undermines Rust's safety\nguarantees. This paper aims to improve the memory safety of Rust programs\ngenerated by C2RUST by eliminating raw pointers. Specifically, we propose a\npeephole raw pointer rewriting technique that lifts raw pointers in individual\nfunctions to appropriate Rust data structures. Technically, PR2 employs\ndecision-tree-based prompting to guide the pointer lifting process.\nAdditionally, it leverages code change analysis to guide the repair of errors\nintroduced during rewriting, effectively addressing errors encountered during\ncompilation and test case execution. We implement PR2 as a prototype and\nevaluate it using gpt-4o-mini on 28 real-world C projects. The results show\nthat PR2 successfully eliminates 13.22% of local raw pointers across these\nprojects, significantly enhancing the safety of the translated Rust code. On\naverage, PR2 completes the transformation of a project in 5.44 hours, at an\naverage cost of $1.46.", "published": "2025-05-07 23:30:27", "link": "http://arxiv.org/abs/2505.04852v1", "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Large Language Models are Autonomous Cyber Defenders", "abstract": "Fast and effective incident response is essential to prevent adversarial\ncyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response\nthrough Artificial Intelligence (AI) agents that plan and execute actions. Most\nACD approaches focus on single-agent scenarios and leverage Reinforcement\nLearning (RL). However, ACD RL-trained agents depend on costly training, and\ntheir reasoning is not always explainable or transferable. Large Language\nModels (LLMs) can address these concerns by providing explainable actions in\ngeneral security contexts. Researchers have explored LLM agents for ACD but\nhave not evaluated them on multi-agent scenarios or interacting with other ACD\nagents. In this paper, we show the first study on how LLMs perform in\nmulti-agent ACD environments by proposing a new integration to the CybORG CAGE\n4 environment. We examine how ACD teams of LLM and RL agents can interact by\nproposing a novel communication protocol. Our results highlight the strengths\nand weaknesses of LLMs and RL and help us identify promising research\ndirections to create, train, and deploy future teams of ACD agents.", "published": "2025-05-07 22:42:37", "link": "http://arxiv.org/abs/2505.04843v1", "categories": ["cs.AI", "cs.CR", "I.2.0"], "primary_category": "cs.AI"}
{"title": "Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers", "abstract": "Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners,\nsuch as GRPO or Leave-one-out PPO, abandon the learned value function in favor\nof empirically estimated returns. This hinders test-time compute scaling that\nrelies on using the value-function for verification. In this work, we propose\nRL$^V$ that augments any ``value-free'' RL method by jointly training the LLM\nas both a reasoner and a generative verifier using RL-generated data, adding\nverification capabilities without significant overhead. Empirically, RL$^V$\nboosts MATH accuracy by over 20\\% with parallel sampling and enables\n$8-32\\times$ efficient test-time compute scaling compared to the base RL\nmethod. RL$^V$ also exhibits strong generalization capabilities for both\neasy-to-hard and out-of-domain tasks. Furthermore, RL$^V$ achieves\n$1.2-1.6\\times$ higher performance when jointly scaling parallel and sequential\ntest-time compute with a long reasoning R1 model.", "published": "2025-05-07 22:41:26", "link": "http://arxiv.org/abs/2505.04842v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Quantum-Inspired Optimization Process for Data Imputation", "abstract": "Data imputation is a critical step in data pre-processing, particularly for\ndatasets with missing or unreliable values. This study introduces a novel\nquantum-inspired imputation framework evaluated on the UCI Diabetes dataset,\nwhich contains biologically implausible missing values across several clinical\nfeatures. The method integrates Principal Component Analysis (PCA) with\nquantum-assisted rotations, optimized through gradient-free classical\noptimizers -COBYLA, Simulated Annealing, and Differential Evolution to\nreconstruct missing values while preserving statistical fidelity. Reconstructed\nvalues are constrained within +/-2 standard deviations of original feature\ndistributions, avoiding unrealistic clustering around central tendencies. This\napproach achieves a substantial and statistically significant improvement,\nincluding an average reduction of over 85% in Wasserstein distance and\nKolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values >\n0.99 in classical methods such as Mean, KNN, and MICE. The method also\neliminates zero-value artifacts and enhances the realism and variability of\nimputed data. By combining quantum-inspired transformations with a scalable\nclassical framework, this methodology provides a robust solution for imputation\ntasks in domains such as healthcare and AI pipelines, where data quality and\nintegrity are crucial.", "published": "2025-05-07 22:37:07", "link": "http://arxiv.org/abs/2505.04841v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Is there Value in Reinforcement Learning?", "abstract": "Action-values play a central role in popular Reinforcement Learing (RL)\nmodels of behavior. Yet, the idea that action-values are explicitly represented\nhas been extensively debated. Critics had therefore repeatedly suggested that\npolicy-gradient (PG) models should be favored over value-based (VB) ones, as a\npotential solution for this dilemma. Here we argue that this solution is\nunsatisfying. This is because PG methods are not, in fact, \"Value-free\" --\nwhile they do not rely on an explicit representation of Value for acting\n(stimulus-response mapping), they do require it for learning. Hence, switching\nto PG models is, per se, insufficient for eliminating Value from models of\nbehavior. More broadly, the requirement for a representation of Value stems\nfrom the underlying assumptions regarding the optimization objective posed by\nthe standard RL framework, not from the particular algorithm chosen to solve\nit. Previous studies mostly took these standard RL assumptions for granted, as\npart of their conceptualization or problem modeling, while debating the\ndifferent methods used to optimize it (i.e., PG or VB). We propose that,\ninstead, the focus of the debate should shift to critically evaluating the\nunderlying modeling assumptions. Such evaluation is particularly important from\nan experimental perspective. Indeed, the very notion of Value must be\nreconsidered when standard assumptions (e.g., risk neutrality,\nfull-observability, Markovian environment, exponential discounting) are\nrelaxed, as is likely in natural settings. Finally, we use the Value debate as\na case study to argue in favor of a more nuanced, algorithmic rather than\nstatistical, view of what constitutes \"a model\" in cognitive sciences. Our\nanalysis suggests that besides \"parametric\" statistical complexity, additional\naspects such as computational complexity must also be taken into account when\nevaluating model complexity.", "published": "2025-05-07 21:50:27", "link": "http://arxiv.org/abs/2505.04822v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Piecewise Constant Spectral Graph Neural Network", "abstract": "Graph Neural Networks (GNNs) have achieved significant success across various\ndomains by leveraging graph structures in data. Existing spectral GNNs, which\nuse low-degree polynomial filters to capture graph spectral properties, may not\nfully identify the graph's spectral characteristics because of the polynomial's\nsmall degree. However, increasing the polynomial degree is computationally\nexpensive and beyond certain thresholds leads to performance plateaus or\ndegradation. In this paper, we introduce the Piecewise Constant Spectral Graph\nNeural Network(PieCoN) to address these challenges. PieCoN combines constant\nspectral filters with polynomial filters to provide a more flexible way to\nleverage the graph structure. By adaptively partitioning the spectrum into\nintervals, our approach increases the range of spectral properties that can be\neffectively learned. Experiments on nine benchmark datasets, including both\nhomophilic and heterophilic graphs, demonstrate that PieCoN is particularly\neffective on heterophilic datasets, highlighting its potential for a wide range\nof applications.", "published": "2025-05-07 21:17:06", "link": "http://arxiv.org/abs/2505.04808v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling", "abstract": "Sparse observations and coarse-resolution climate models limit effective\nregional decision-making, underscoring the need for robust downscaling.\nHowever, existing AI methods struggle with generalization across variables and\ngeographies and are constrained by the quadratic complexity of Vision\nTransformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation\nmodel for global, hyper-resolution climate downscaling. ORBIT-2 incorporates\ntwo key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture\nwith residual learning and Bayesian regularization for efficient, robust\nprediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces\nself-attention complexity from quadratic to linear, enabling long-sequence\nprocessing and massive parallelism. ORBIT-2 scales to 10 billion parameters\nacross 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and\n92-98% strong scaling efficiency. It supports downscaling to 0.9 km global\nresolution and processes sequences up to 4.2 billion tokens. On 7 km resolution\nbenchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98\nto 0.99 against observation data.", "published": "2025-05-07 21:09:00", "link": "http://arxiv.org/abs/2505.04802v1", "categories": ["cs.LG", "astro-ph.EP", "cs.AI", "cs.DC", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "Confabulation dynamics in a reservoir computer: Filling in the gaps with untrained attractors", "abstract": "Artificial Intelligence has advanced significantly in recent years thanks to\ninnovations in the design and training of artificial neural networks (ANNs).\nDespite these advancements, we still understand relatively little about how\nelementary forms of ANNs learn, fail to learn, and generate false information\nwithout the intent to deceive, a phenomenon known as `confabulation'. To\nprovide some foundational insight, in this paper we analyse how confabulation\noccurs in reservoir computers (RCs): a dynamical system in the form of an ANN.\nRCs are particularly useful to study as they are known to confabulate in a\nwell-defined way: when RCs are trained to reconstruct the dynamics of a given\nattractor, they sometimes construct an attractor that they were not trained to\nconstruct, a so-called `untrained attractor' (UA). This paper sheds light on\nthe role played by UAs when reconstruction fails and their influence when\nmodelling transitions between reconstructed attractors. Based on our results,\nwe conclude that UAs are an intrinsic feature of learning systems whose state\nspaces are bounded, and that this means of confabulation may be present in\nsystems beyond RCs.", "published": "2025-05-07 20:38:44", "link": "http://arxiv.org/abs/2505.04792v1", "categories": ["math.DS", "cs.AI", "cs.LG"], "primary_category": "math.DS"}
{"title": "Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay", "abstract": "Continual Learning entails progressively acquiring knowledge from new data\nwhile retaining previously acquired knowledge, thereby mitigating\n``Catastrophic Forgetting'' in neural networks. Our work presents a novel\nuncertainty-driven Unsupervised Continual Learning framework using Generative\nReplay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture\nefficiently uses unlabelled and synthetic labelled data in a balanced\nproportion using a cluster-level uncertainty-driven feedback mechanism and a\nVLM-powered generative replay module. Unlike traditional memory-buffer methods\nthat depend on pretrained models and pseudo-labels, our R2R framework operates\nwithout any prior training. It leverages visual features from unlabeled data\nand adapts continuously using clustering-based uncertainty estimation coupled\nwith dynamic thresholding. Concurrently, a generative replay mechanism along\nwith DeepSeek-R1 powered CLIP VLM produces labelled synthetic data\nrepresentative of past experiences, resembling biological visual thinking that\nreplays memory to remember and act in new, unseen tasks. Extensive experimental\nanalyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and\nTinyImageNet datasets. Our proposed R2R approach improves knowledge retention,\nachieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,\n59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.", "published": "2025-05-07 20:29:31", "link": "http://arxiv.org/abs/2505.04787v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models", "abstract": "The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has\nenabled more advanced chatbots capable of human-like interactions. However,\nthese conversational agents introduce a broader set of operational risks that\nextend beyond traditional cybersecurity considerations. In this work, we\npropose a novel, instrumented risk-assessment metric that simultaneously\nevaluates potential threats to three key stakeholders: the service-providing\norganization, end users, and third parties. Our approach incorporates the\ntechnical complexity required to induce erroneous behaviors in the\nchatbot--ranging from non-induced failures to advanced prompt-injection\nattacks--as well as contextual factors such as the target industry, user age\nrange, and vulnerability severity. To validate our metric, we leverage Garak,\nan open-source framework for LLM vulnerability testing. We further enhance\nGarak to capture a variety of threat vectors (e.g., misinformation, code\nhallucinations, social engineering, and malicious code generation). Our\nmethodology is demonstrated in a scenario involving chatbots that employ\nretrieval-augmented generation (RAG), showing how the aggregated risk scores\nguide both short-term mitigation and longer-term improvements in model design\nand deployment. The results underscore the importance of multi-dimensional risk\nassessments in operationalizing secure, reliable AI-driven conversational\nsystems.", "published": "2025-05-07 20:26:45", "link": "http://arxiv.org/abs/2505.04784v1", "categories": ["cs.CR", "cs.AI", "cs.CY"], "primary_category": "cs.CR"}
{"title": "Exploring Zero-Shot App Review Classification with ChatGPT: Challenges and Potential", "abstract": "App reviews are a critical source of user feedback, offering valuable\ninsights into an app's performance, features, usability, and overall user\nexperience. Effectively analyzing these reviews is essential for guiding app\ndevelopment, prioritizing feature updates, and enhancing user satisfaction.\nClassifying reviews into functional and non-functional requirements play a\npivotal role in distinguishing feedback related to specific app features\n(functional requirements) from feedback concerning broader quality attributes,\nsuch as performance, usability, and reliability (non-functional requirements).\nBoth categories are integral to informed development decisions. Traditional\napproaches to classifying app reviews are hindered by the need for large,\ndomain-specific datasets, which are often costly and time-consuming to curate.\nThis study explores the potential of zero-shot learning with ChatGPT for\nclassifying app reviews into four categories: functional requirement,\nnon-functional requirement, both, or neither. We evaluate ChatGPT's performance\non a benchmark dataset of 1,880 manually annotated reviews from ten diverse\napps spanning multiple domains. Our findings demonstrate that ChatGPT achieves\na robust F1 score of 0.842 in review classification, despite certain challenges\nand limitations. Additionally, we examine how factors such as review\nreadability and length impact classification accuracy and conduct a manual\nanalysis to identify review categories more prone to misclassification.", "published": "2025-05-07 19:39:04", "link": "http://arxiv.org/abs/2505.04759v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems", "abstract": "Intelligent tutoring systems have demonstrated effectiveness in teaching\nformal propositional logic proofs, but their reliance on template-based\nexplanations limits their ability to provide personalized student feedback.\nWhile large language models (LLMs) offer promising capabilities for dynamic\nfeedback generation, they risk producing hallucinations or pedagogically\nunsound explanations. We evaluated the stepwise accuracy of LLMs in\nconstructing multi-step symbolic logic proofs, comparing six prompting\ntechniques across four state-of-the-art LLMs on 358 propositional logic\nproblems. Results show that DeepSeek-V3 achieved superior performance with\n84.4% accuracy on stepwise proof construction and excelled particularly in\nsimpler rules. We further used the best-performing LLM to generate explanatory\nhints for 1,050 unique student problem-solving states from a logic ITS and\nevaluated them on 4 criteria with both an LLM grader and human expert ratings\non a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate\nand rated highly by human evaluators on consistency and clarity, but did not\nperform as well explaining why the hint was provided or its larger context. Our\nresults demonstrate that LLMs may be used to augment tutoring systems with\nlogic tutoring hints, but requires additional modifications to ensure accuracy\nand pedagogical appropriateness.", "published": "2025-05-07 18:48:23", "link": "http://arxiv.org/abs/2505.04736v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort", "abstract": "The Query-By-Document (QBD) problem is an information retrieval problem where\nthe query is a document, and the retrieved candidates are documents that match\nthe query document, often in a domain or query specific manner. This can be\ncrucial for tasks such as patent matching, legal or compliance case retrieval,\nand academic literature review. Existing retrieval methods, including keyword\nsearch and document embeddings, can be optimized with domain-specific datasets\nto improve QBD search performance. However, creating these domain-specific\ndatasets is often costly and time-consuming. Our work introduces a process to\ngenerate custom QBD-search datasets and compares a set of methods to use in\nthis problem, which we refer to as QBD-RankedDatagen. We provide a comparative\nanalysis of our proposed methods in terms of cost, speed, and the human\ninterface with the domain experts. The methods we compare leverage Large\nLanguage Models (LLMs) which can incorporate domain expert input to produce\ndocument scores and rankings, as well as explanations for human review. The\nprocess and methods for it that we present can significantly reduce human\neffort in dataset creation for custom domains while still obtaining sufficient\nexpert knowledge for tuning retrieval models. We evaluate our methods on QBD\ndatasets from the Text Retrieval Conference (TREC) and finetune the parameters\nof the BM25 model -- which is used in many industrial-strength search engines\nlike OpenSearch -- using the generated data.", "published": "2025-05-07 18:43:57", "link": "http://arxiv.org/abs/2505.04732v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups", "abstract": "We present a geometric neural network-based tracking controller for systems\nevolving on matrix Lie groups under unknown dynamics, actuator faults, and\nbounded disturbances. Leveraging the left-invariance of the tangent bundle of\nmatrix Lie groups, viewed as an embedded submanifold of the vector space\n$\\R^{N\\times N}$, we propose a set of learning rules for neural network weights\nthat are intrinsically compatible with the Lie group structure and do not\nrequire explicit parameterization. Exploiting the geometric properties of Lie\ngroups, this approach circumvents parameterization singularities and enables a\nglobal search for optimal weights. The ultimate boundedness of all error\nsignals -- including the neural network weights, the coordinate-free\nconfiguration error function, and the tracking velocity error -- is established\nusing Lyapunov's direct method. To validate the effectiveness of the proposed\nmethod, we provide illustrative simulation results for decentralized formation\ncontrol of multi-agent systems on the Special Euclidean group.", "published": "2025-05-07 18:33:23", "link": "http://arxiv.org/abs/2505.04725v1", "categories": ["eess.SY", "cs.AI", "cs.RO", "cs.SY", "math.DS"], "primary_category": "eess.SY"}
{"title": "ORXE: Orchestrating Experts for Dynamically Configurable Efficiency", "abstract": "This paper presents ORXE, a modular and adaptable framework for achieving\nreal-time configurable efficiency in AI models. By leveraging a collection of\npre-trained experts with diverse computational costs and performance levels,\nORXE dynamically adjusts inference pathways based on the complexity of input\nsamples. Unlike conventional approaches that require complex metamodel\ntraining, ORXE achieves high efficiency and flexibility without complicating\nthe development process. The proposed system utilizes a confidence-based gating\nmechanism to allocate appropriate computational resources for each input. ORXE\nalso supports adjustments to the preference between inference cost and\nprediction performance across a wide range during runtime. We implemented a\ntraining-free ORXE system for image classification tasks, evaluating its\nefficiency and accuracy across various devices. The results demonstrate that\nORXE achieves superior performance compared to individual experts and other\ndynamic models in most cases. This approach can be extended to other\napplications, providing a scalable solution for diverse real-world deployment\nscenarios.", "published": "2025-05-07 23:16:56", "link": "http://arxiv.org/abs/2505.04850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Seeing Cells Clearly: Evaluating Machine Vision Strategies for Microglia Centroid Detection in 3D Images", "abstract": "Microglia are important cells in the brain, and their shape can tell us a lot\nabout brain health. In this project, I test three different tools for finding\nthe center points of microglia in 3D microscope images. The tools include\nilastik, 3D Morph, and Omnipose. I look at how well each one finds the cells\nand how their results compare. My findings show that each tool sees the cells\nin its own way, and this can affect the kind of information we get from the\nimages.", "published": "2025-05-07 22:35:48", "link": "http://arxiv.org/abs/2505.04838v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Integrated Image Reconstruction and Target Recognition based on Deep Learning Technique", "abstract": "Computational microwave imaging (CMI) has gained attention as an alternative\ntechnique for conventional microwave imaging techniques, addressing their\nlimitations such as hardware-intensive physical layer and slow data collection\nacquisition speed to name a few. Despite these advantages, CMI still encounters\nnotable computational bottlenecks, especially during the image reconstruction\nstage. In this setting, both image recovery and object classification present\nsignificant processing demands. To address these challenges, our previous work\nintroduced ClassiGAN, which is a generative deep learning model designed to\nsimultaneously reconstruct images and classify targets using only\nback-scattered signals. In this study, we build upon that framework by\nincorporating attention gate modules into ClassiGAN. These modules are intended\nto refine feature extraction and improve the identification of relevant\ninformation. By dynamically focusing on important features and suppressing\nirrelevant ones, the attention mechanism enhances the overall model\nperformance. The proposed architecture, named Att-ClassiGAN, significantly\nreduces the reconstruction time compared to traditional CMI approaches.\nFurthermore, it outperforms current advanced methods, delivering improved\nNormalized Mean Squared Error (NMSE), higher Structural Similarity Index\n(SSIM), and better classification outcomes for the reconstructed targets.", "published": "2025-05-07 22:34:32", "link": "http://arxiv.org/abs/2505.04836v1", "categories": ["eess.SP", "cs.CV"], "primary_category": "eess.SP"}
{"title": "Are Synthetic Corruptions A Reliable Proxy For Real-World Corruptions?", "abstract": "Deep learning (DL) models are widely used in real-world applications but\nremain vulnerable to distribution shifts, especially due to weather and\nlighting changes. Collecting diverse real-world data for testing the robustness\nof DL models is resource-intensive, making synthetic corruptions an attractive\nalternative for robustness testing. However, are synthetic corruptions a\nreliable proxy for real-world corruptions? To answer this, we conduct the\nlargest benchmarking study on semantic segmentation models, comparing\nperformance on real-world corruptions and synthetic corruptions datasets. Our\nresults reveal a strong correlation in mean performance, supporting the use of\nsynthetic corruptions for robustness evaluation. We further analyze\ncorruption-specific correlations, providing key insights to understand when\nsynthetic corruptions succeed in representing real-world corruptions.\nOpen-source Code:\nhttps://github.com/shashankskagnihotri/benchmarking_robustness/tree/segmentation_david/semantic_segmentation", "published": "2025-05-07 22:19:55", "link": "http://arxiv.org/abs/2505.04835v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "WIR3D: Visually-Informed and Geometry-Aware 3D Shape Abstraction", "abstract": "We present WIR3D, a technique for abstracting 3D shapes through a sparse set\nof visually meaningful curves in 3D. We optimize the parameters of Bezier\ncurves such that they faithfully represent both the geometry and salient visual\nfeatures (e.g. texture) of the shape from arbitrary viewpoints. We leverage the\nintermediate activations of a pre-trained foundation model (CLIP) to guide our\noptimization process. We divide our optimization into two phases: one for\ncapturing the coarse geometry of the shape, and the other for representing\nfine-grained features. Our second phase supervision is spatially guided by a\nnovel localized keypoint loss. This spatial guidance enables user control over\nabstracted features. We ensure fidelity to the original surface through a\nneural SDF loss, which allows the curves to be used as intuitive deformation\nhandles. We successfully apply our method for shape abstraction over a broad\ndataset of shapes with varying complexity, geometric structure, and texture,\nand demonstrate downstream applications for feature control and shape\ndeformation.", "published": "2025-05-07 21:28:05", "link": "http://arxiv.org/abs/2505.04813v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "DetReIDX: A Stress-Test Dataset for Real-World UAV-Based Person Recognition", "abstract": "Person reidentification (ReID) technology has been considered to perform\nrelatively well under controlled, ground-level conditions, but it breaks down\nwhen deployed in challenging real-world settings. Evidently, this is due to\nextreme data variability factors such as resolution, viewpoint changes, scale\nvariations, occlusions, and appearance shifts from clothing or session drifts.\nMoreover, the publicly available data sets do not realistically incorporate\nsuch kinds and magnitudes of variability, which limits the progress of this\ntechnology. This paper introduces DetReIDX, a large-scale aerial-ground person\ndataset, that was explicitly designed as a stress test to ReID under real-world\nconditions. DetReIDX is a multi-session set that includes over 13 million\nbounding boxes from 509 identities, collected in seven university campuses from\nthree continents, with drone altitudes between 5.8 and 120 meters. More\nimportant, as a key novelty, DetReIDX subjects were recorded in (at least) two\nsessions on different days, with changes in clothing, daylight and location,\nmaking it suitable to actually evaluate long-term person ReID. Plus, data were\nannotated from 16 soft biometric attributes and multitask labels for detection,\ntracking, ReID, and action recognition. In order to provide empirical evidence\nof DetReIDX usefulness, we considered the specific tasks of human detection and\nReID, where SOTA methods catastrophically degrade performance (up to 80% in\ndetection accuracy and over 70% in Rank-1 ReID) when exposed to DetReIDXs\nconditions. The dataset, annotations, and official evaluation protocols are\npublicly available at https://www.it.ubi.pt/DetReIDX/", "published": "2025-05-07 20:41:06", "link": "http://arxiv.org/abs/2505.04793v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World", "abstract": "Determining the vanishing points (VPs) in a Manhattan world, as a fundamental\ntask in many 3D vision applications, consists of jointly inferring the line-VP\nassociation and locating each VP. Existing methods are, however, either\nsub-optimal solvers or pursuing global optimality at a significant cost of\ncomputing time. In contrast to prior works, we introduce convex relaxation\ntechniques to solve this task for the first time. Specifically, we employ a\n``soft'' association scheme, realized via a truncated multi-selection error,\nthat allows for joint estimation of VPs' locations and line-VP associations.\nThis approach leads to a primal problem that can be reformulated into a\nquadratically constrained quadratic programming (QCQP) problem, which is then\nrelaxed into a convex semidefinite programming (SDP) problem. To solve this SDP\nproblem efficiently, we present a globally optimal outlier-robust iterative\nsolver (called \\textbf{GlobustVP}), which independently searches for one VP and\nits associated lines in each iteration, treating other lines as outliers. After\neach independent update of all VPs, the mutual orthogonality between the three\nVPs in a Manhattan world is reinforced via local refinement. Extensive\nexperiments on both synthetic and real-world data demonstrate that\n\\textbf{GlobustVP} achieves a favorable balance between efficiency, robustness,\nand global optimality compared to previous works. The code is publicly\navailable at https://github.com/WU-CVGL/GlobustVP.", "published": "2025-05-07 20:30:08", "link": "http://arxiv.org/abs/2505.04788v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Retrieval Augmented Generation Evaluation for Health Documents", "abstract": "Safe and trustworthy use of Large Language Models (LLM) in the processing of\nhealthcare documents and scientific papers could substantially help clinicians,\nscientists and policymakers in overcoming information overload and focusing on\nthe most relevant information at a given moment. Retrieval Augmented Generation\n(RAG) is a promising method to leverage the potential of LLMs while enhancing\nthe accuracy of their outcomes. This report assesses the potentials and\nshortcomings of such approaches in the automatic knowledge synthesis of\ndifferent types of documents in the health domain. To this end, it describes:\n(1) an internally developed proof of concept pipeline that employs\nstate-of-the-art practices to deliver safe and trustable analysis for\nhealthcare documents and scientific papers called RAGEv (Retrieval Augmented\nGeneration Evaluation); (2) a set of evaluation tools for LLM-based document\nretrieval and generation; (3) a benchmark dataset to verify the accuracy and\nveracity of the results called RAGEv-Bench. It concludes that careful\nimplementations of RAG techniques could minimize most of the common problems in\nthe use of LLMs for document processing in the health domain, obtaining very\nhigh scores both on short yes/no answers and long answers. There is a high\npotential for incorporating it into the day-to-day work of policy support\ntasks, but additional efforts are required to obtain a consistent and\ntrustworthy tool.", "published": "2025-05-07 16:12:53", "link": "http://arxiv.org/abs/2505.04680v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Hybrid-Field 6D Movable Antenna for Terahertz Communications: Channel Modeling and Estimation", "abstract": "In this work, we study a six-dimensional movable antenna (6DMA)-enhanced\nTerahertz (THz) network that supports a large number of users with a few\nantennas by controlling the three-dimensional (3D) positions and 3D rotations\nof antenna surfaces/subarrays at the base station (BS). However, the short\nwavelength of THz signals combined with a large 6DMA movement range extends the\nnear-field region. As a result, a user can be in the far-field region relative\nto the antennas on one 6DMA surface, while simultaneously residing in the\nnear-field region relative to other 6DMA surfaces. Moreover, 6DMA THz channel\nestimation suffers from increased computational complexity and pilot overhead\ndue to uneven power distribution across the large number of candidate\nposition-rotation pairs, as well as the limited number of radio frequency (RF)\nchains in THz bands. To address these issues, we propose an efficient\nhybrid-field generalized 6DMA THz channel model, which accounts for planar wave\npropagation within individual 6DMA surfaces and spherical waves among different\n6DMA surfaces. Furthermore, we propose a low-overhead channel estimation\nalgorithm that leverages directional sparsity to construct a complete channel\nmap for all potential antenna position-rotation pairs.\n  Numerical results show that the proposed hybrid-field channel model achieves\na sum rate close to that of the ground-truth near-field channel model and\nconfirm that the channel estimation method yields accurate results with low\ncomplexity.", "published": "2025-05-07 19:33:08", "link": "http://arxiv.org/abs/2505.04753v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Comparative Study of Generative Models for Early Detection of Failures in Medical Devices", "abstract": "The medical device industry has significantly advanced by integrating\nsophisticated electronics like microchips and field-programmable gate arrays\n(FPGAs) to enhance the safety and usability of life-saving devices. These\ncomplex electro-mechanical systems, however, introduce challenging failure\nmodes that are not easily detectable with conventional methods. Effective fault\ndetection and mitigation become vital as reliance on such electronics grows.\nThis paper explores three generative machine learning-based approaches for\nfault detection in medical devices, leveraging sensor data from surgical\nstaplers,a class 2 medical device. Historically considered low-risk, these\ndevices have recently been linked to an increasing number of injuries and\nfatalities. The study evaluates the performance and data requirements of these\nmachine-learning approaches, highlighting their potential to enhance device\nsafety.", "published": "2025-05-07 22:49:53", "link": "http://arxiv.org/abs/2505.04845v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Steerable Scene Generation with Post Training and Inference-Time Search", "abstract": "Training robots in simulation requires diverse 3D scenes that reflect the\nspecific challenges of downstream tasks. However, scenes that satisfy strict\ntask requirements, such as high-clutter environments with plausible spatial\narrangement, are rare and costly to curate manually. Instead, we generate\nlarge-scale scene data using procedural models that approximate realistic\nenvironments for robotic manipulation, and adapt it to task-specific goals. We\ndo this by training a unified diffusion-based generative model that predicts\nwhich objects to place from a fixed asset library, along with their SE(3)\nposes. This model serves as a flexible scene prior that can be adapted using\nreinforcement learning-based post training, conditional generation, or\ninference-time search, steering generation toward downstream objectives even\nwhen they differ from the original data distribution. Our method enables\ngoal-directed scene synthesis that respects physical feasibility and scales\nacross scene types. We introduce a novel MCTS-based inference-time search\nstrategy for diffusion models, enforce feasibility via projection and\nsimulation, and release a dataset of over 44 million SE(3) scenes spanning five\ndiverse environments. Website with videos, code, data, and model weights:\nhttps://steerable-scene-generation.github.io/", "published": "2025-05-07 22:07:42", "link": "http://arxiv.org/abs/2505.04831v1", "categories": ["cs.RO", "cs.GR", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Guide your favorite protein sequence generative model", "abstract": "Generative machine learning models have begun to transform protein\nengineering, yet no principled framework for conditioning on auxiliary\ninformation in a plug-and-play manner exists; one may want to iteratively\nincorporate experimental feedback, or make use of an existing classifier --\nsuch as for predicting enzyme commission number -- in order to guide the\nsampling of the generative model to generate sequences with desired properties.\nHerein, we present ProteinGuide, a rigorous and general framework to achieve\njust that: through unifying a broad class of protein generative models that\nincludes masked language, (order-agnostic) autoregressive, diffusion and\nflow-matching models, we provide an approach to statistically condition\npre-trained protein generative models. We demonstrate applicability of our\napproach by guiding each of two commonly used protein generative models,\nProteinMPNN and ESM3, to generate amino acid and structure token sequences\nconditioned on several user-specified properties, namely, enhanced stability\nand CATH-labeled fold generation.", "published": "2025-05-07 21:56:50", "link": "http://arxiv.org/abs/2505.04823v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Convergent Complex Quasi-Newton Proximal Methods for Gradient-Driven Denoisers in Compressed Sensing MRI Reconstruction", "abstract": "In compressed sensing (CS) MRI, model-based methods are pivotal to achieving\naccurate reconstruction. One of the main challenges in model-based methods is\nfinding an effective prior to describe the statistical distribution of the\ntarget image. Plug-and-Play (PnP) and REgularization by Denoising (RED) are two\ngeneral frameworks that use denoisers as the prior. While PnP/RED methods with\nconvolutional neural networks (CNNs) based denoisers outperform classical\nhand-crafted priors in CS MRI, their convergence theory relies on assumptions\nthat do not hold for practical CNNs. The recently developed gradient-driven\ndenoisers offer a framework that bridges the gap between practical performance\nand theoretical guarantees. However, the numerical solvers for the associated\nminimization problem remain slow for CS MRI reconstruction. This paper proposes\na complex quasi-Newton proximal method that achieves faster convergence than\nexisting approaches. To address the complex domain in CS MRI, we propose a\nmodified Hessian estimation method that guarantees Hermitian positive\ndefiniteness. Furthermore, we provide a rigorous convergence analysis of the\nproposed method for nonconvex settings. Numerical experiments on both Cartesian\nand non-Cartesian sampling trajectories demonstrate the effectiveness and\nefficiency of our approach.", "published": "2025-05-07 21:47:40", "link": "http://arxiv.org/abs/2505.04820v1", "categories": ["eess.IV", "cs.NA", "math.NA", "math.OC"], "primary_category": "eess.IV"}
{"title": "Numerical stabilization for a mixture system with kind damping", "abstract": "In this paper, we conduct a numerical analysis of the strong stabilization\nand polynomial decay of solutions for the initial boundary value problem\nassociated with a system that models the dynamics of a mixture of two rigid\nsolids with porosity. This mathematical model accounts for the complex\ninteractions between the rigid components and their porous structure, providing\nvaluable information on the mechanical behavior of such systems. Our primary\nobjective is to establish conditions under which stabilization is ensured and\nto rigorously quantify the rate of decay of the solutions. Using numerical\nsimulations, we assess the effectiveness of different stabilization mechanisms\nand analyze the influence of key system parameters on the overall dynamics.", "published": "2025-05-07 19:02:52", "link": "http://arxiv.org/abs/2505.04739v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.OC", "35Q40, 93D15, 47D03, 74D05"], "primary_category": "math.NA"}
{"title": "Data Standards in Audiology: A Mixed-Methods Exploration of Community Perspectives and Implementation Considerations", "abstract": "Objective: The purpose of this study was to explore options for data\nstandardisation in audiology and document the global audiology community's\ncurrent knowledge and views of data standards, explore their needs and\npreferences, and develop recommendations for data standardisation as a result.\n  Design: A mixed-methods approach, combining a structured survey with an\nin-depth exploration of themes by experts during a special session on \"Big Data\nand Data Standards in Audiology\" at the 2024 Virtual Conference of\nComputational Audiology.\n  Study Sample: The survey sample consisted of 82 members of the global\naudiology community; five experts joined the panel discussion.\n  Results: Survey results emphasized the need for data standardisation in\naudiology aimed at facilitating research and improving patient care. Knowledge\nof existing initiatives was low: 38% were aware of initiatives. Yet, 90%\nenvisioned contributing to them moving forward. The panel discussion explored\nemerging standardisation initiatives in audiology (OMOP, openEHR, HIMSA's Noah\nstandard), challenges (e.g., data quality and privacy), and opportunities\n(e.g., conversion between approaches and synergies with other medical fields).\n  Conclusions: The community support identified in this study could be\nleveraged to further develop standardisation initiatives for audiology,\nensuring alignment between initiatives and with other medical fields.", "published": "2025-05-07 18:36:39", "link": "http://arxiv.org/abs/2505.04728v1", "categories": ["cs.SD", "eess.AS", "physics.med-ph"], "primary_category": "cs.SD"}
{"title": "Impact of Weather on Satellite Communication: Evaluating Starlink Resilience", "abstract": "Satellite communications have emerged as one of the most feasible solutions\nto provide global wireless coverage and connect the unconnected. Starlink\ndominates the market with over 7,000 operational satellites in low Earth orbit\n(LEO) and offers global high-speed and low-latency Internet service for\nstationary and mobile use cases, including in-motion connectivity for vehicles,\nvessels, and aircraft. Starlink terminals are designed to handle extreme\nweather conditions. Starlink recommends a flat high performance (FHP) terminal\nfor users living in areas with extreme weather conditions. The earlier studies\nevaluated Starlink's FHP throughput for stationary and in-motion users without\nproviding a detailed analysis of how weather affects its performance. There\nremains a need to investigate the impact of weather on FHP's throughput. In\nthis paper, we address this shortcoming by analyzing the impact of weather on\nStarlink's performance in Oulu, Finland, a city located in Northern Europe near\nthe Arctic Circle. Our measurements reveal that rain degrades median uplink and\ndownlink throughput by 52.27% and 37.84%, respectively. On the contrary, there\nwas no noticeable impact on the round-trip time. Additionally, we also examine\nthe impact of cloud cover on the Starlink throughput. The linear regression\nanalysis reveals the negative relationship between throughput and cloud cover.\nThe cloud cover of up to 12.5% has around 20% greater throughput than the cloud\ncover of 87.5%", "published": "2025-05-07 19:48:36", "link": "http://arxiv.org/abs/2505.04772v1", "categories": ["cs.ET", "cs.NI", "eess.SP"], "primary_category": "cs.ET"}
{"title": "Shadow Wireless Intelligence: Large Language Model-Driven Reasoning in Covert Communications", "abstract": "Covert Communications (CC) can secure sensitive transmissions in industrial,\nmilitary, and mission-critical applications within 6G wireless networks.\nHowever, traditional optimization methods based on Artificial Noise (AN), power\ncontrol, and channel manipulation might not adapt to dynamic and adversarial\nenvironments due to the high dimensionality, nonlinearity, and stringent\nreal-time covertness requirements. To bridge this gap, we introduce Shadow\nWireless Intelligence (SWI), which integrates the reasoning capabilities of\nLarge Language Models (LLMs) with retrieval-augmented generation to enable\nintelligent decision-making in covert wireless systems. Specifically, we\nutilize DeepSeek-R1, a mixture-of-experts-based LLM with RL-enhanced reasoning,\ncombined with real-time retrieval of domain-specific knowledge to improve\ncontext accuracy and mitigate hallucinations. Our approach develops a\nstructured CC knowledge base, supports context-aware retrieval, and performs\nsemantic optimization, allowing LLMs to generate and adapt CC strategies in\nreal time. In a case study on optimizing AN power in a full-duplex CC scenario,\nDeepSeek-R1 achieves 85% symbolic derivation accuracy and 94% correctness in\nthe generation of simulation code, outperforming baseline models. These results\nvalidate SWI as a robust, interpretable, and adaptive foundation for LLM-driven\nintelligent covert wireless systems in 6G networks.", "published": "2025-05-07 02:11:43", "link": "http://arxiv.org/abs/2505.04068v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Joint Task Offloading and Channel Allocation in Spatial-Temporal Dynamic for MEC Networks", "abstract": "Computation offloading and resource allocation are critical in mobile edge\ncomputing (MEC) systems to handle the massive and complex requirements of\napplications restricted by limited resources. In a multi-user multi-server MEC\nnetwork, the mobility of terminals causes computing requests to be dynamically\ndistributed in space. At the same time, the non-negligible dependencies among\ntasks in some specific applications impose temporal correlation constraints on\nthe solution as well, leading the time-adjacent tasks to experience varying\nresource availability and competition from parallel counterparts. To address\nsuch dynamic spatial-temporal characteristics as a challenge in the allocation\nof communication and computation resources, we formulate a long-term\ndelay-energy trade-off cost minimization problem in the view of jointly\noptimizing task offloading and resource allocation. We begin by designing a\npriority evaluation scheme to decouple task dependencies and then develop a\ngrouped Knapsack problem for channel allocation considering the current data\nload and channel status. Afterward, in order to meet the rapid response needs\nof MEC systems, we exploit the double duel deep Q network (D3QN) to make\noffloading decisions and integrate channel allocation results into the reward\nas part of the dynamic environment feedback in D3QN, constituting the joint\noptimization of task offloading and channel allocation. Finally, comprehensive\nsimulations demonstrate the performance of the proposed algorithm in the\ndelay-energy trade-off cost and its adaptability for various applications.", "published": "2025-05-07 09:21:54", "link": "http://arxiv.org/abs/2505.04272v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Satellite-Assisted Low-Altitude Economy Networking: Concepts, Applications, and Opportunities", "abstract": "The low-altitude economy (LAE) is a new economic paradigm that leverages\nlow-altitude vehicles (LAVs) to perform diverse missions across diverse areas.\nTo support the operations of LAE, it is essential to establish LAE networks\nthat enable LAV management and communications.Existing studies mainly reuse\nterrestrial networks to construct LAE networks. However, the limited coverage\nof terrestrial networks poses challenges for serving LAVs in remote areas.\nBesides, efficient LAV operations also require support such as localization and\nnavigation, which terrestrial networks designed for communications cannot fully\nprovide. Due to ubiquitous coverage and diverse functions, satellites are a\npromising technology to support LAVs. Therefore, this article investigates\nsatellite-assisted LAE networking. First, we introduce an overview of LAE and\nsatellites, discussing their features, applications, and architectures. Next,\nwe investigate opportunities for satellites to assist LAE from aspects of\ncommunication, control, and computation. As all assistance depends on reliable\nsatellite-LAV communications, we propose a satellite-assisted LAE framework to\ntackle issues caused by the severe path loss and high dynamics in\nsatellite-assisted LAE networks.The case study demonstrates that the\ndistributed MIMO architecture efficiently reduces the required transmission\npower and extends service duration, while the two-timescale optimization scheme\nbalances the performance and control signaling overheads. Specifically, the\nproposed framework comprises distributed satellite MIMO, distributed LAV MIMO,\nand a two-timescale optimization scheme.", "published": "2025-05-07 03:34:34", "link": "http://arxiv.org/abs/2505.04098v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "abstract": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaveFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators.", "published": "2025-05-07 14:27:46", "link": "http://arxiv.org/abs/2505.04457v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust", "abstract": "There has been a growing interest in translating C code to Rust due to Rust's\nrobust memory and thread safety guarantees. Tools such as C2RUST enable\nsyntax-guided transpilation from C to semantically equivalent Rust code.\nHowever, the resulting Rust programs often rely heavily on unsafe\nconstructs--particularly raw pointers--which undermines Rust's safety\nguarantees. This paper aims to improve the memory safety of Rust programs\ngenerated by C2RUST by eliminating raw pointers. Specifically, we propose a\npeephole raw pointer rewriting technique that lifts raw pointers in individual\nfunctions to appropriate Rust data structures. Technically, PR2 employs\ndecision-tree-based prompting to guide the pointer lifting process.\nAdditionally, it leverages code change analysis to guide the repair of errors\nintroduced during rewriting, effectively addressing errors encountered during\ncompilation and test case execution. We implement PR2 as a prototype and\nevaluate it using gpt-4o-mini on 28 real-world C projects. The results show\nthat PR2 successfully eliminates 13.22% of local raw pointers across these\nprojects, significantly enhancing the safety of the translated Rust code. On\naverage, PR2 completes the transformation of a project in 5.44 hours, at an\naverage cost of $1.46.", "published": "2025-05-07 23:30:27", "link": "http://arxiv.org/abs/2505.04852v2", "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay", "abstract": "Continual Learning entails progressively acquiring knowledge from new data\nwhile retaining previously acquired knowledge, thereby mitigating\n``Catastrophic Forgetting'' in neural networks. Our work presents a novel\nuncertainty-driven Unsupervised Continual Learning framework using Generative\nReplay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture\nefficiently uses unlabelled and synthetic labelled data in a balanced\nproportion using a cluster-level uncertainty-driven feedback mechanism and a\nVLM-powered generative replay module. Unlike traditional memory-buffer methods\nthat depend on pretrained models and pseudo-labels, our R2R framework operates\nwithout any prior training. It leverages visual features from unlabeled data\nand adapts continuously using clustering-based uncertainty estimation coupled\nwith dynamic thresholding. Concurrently, a generative replay mechanism along\nwith DeepSeek-R1 powered CLIP VLM produces labelled synthetic data\nrepresentative of past experiences, resembling biological visual thinking that\nreplays memory to remember and act in new, unseen tasks. Extensive experimental\nanalyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and\nTinyImageNet datasets. Our proposed R2R approach improves knowledge retention,\nachieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,\n59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.", "published": "2025-05-07 20:29:31", "link": "http://arxiv.org/abs/2505.04787v2", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "On multiplicities of interpoint distances", "abstract": "Given a set $X\\subseteq\\mathbb{R}^2$ of $n$ points and a distance $d>0$, the\nmultiplicity of $d$ is the number of times the distance $d$ appears between\npoints in $X$. Let $a_1(X) \\geq a_2(X) \\geq \\cdots \\geq a_m(X)$ denote the\nmultiplicities of the $m$ distances determined by $X$ and let\n$a(X)=\\left(a_1(X),\\dots,a_m(X)\\right)$. In this paper, we study several\nquestions from Erd\\H{o}s's time regarding distance multiplicities. Among other\nresults, we show that:\n  (1) If $X$ is convex or ``not too convex'', then there exists a distance\nother than the diameter that has multiplicity at most $n$.\n  (2) There exists a set $X \\subseteq \\mathbb{R}^2$ of $n$ points, such that\nmany distances occur with high multiplicity. In particular, at least\n$n^{\\Omega(1/\\log\\log{n})}$ distances have superlinear multiplicity in $n$.\n  (3) For any (not necessarily fixed) integer $1\\leq k\\leq\\log{n}$, there\nexists $X\\subseteq\\mathbb{R}^2$ of $n$ points, such that the difference between\nthe $k^{\\text{th}}$ and $(k+1)^{\\text{th}}$ largest multiplicities is at least\n$\\Omega(\\frac{n\\log{n}}{k})$. Moreover, the distances in $X$ with the largest\n$k$ multiplicities can be prescribed.\n  (4) For every $n\\in\\mathbb{N}$, there exists $X\\subseteq\\mathbb{R}^2$ of $n$\npoints, not all collinear or cocircular, such that $a(X)= (n-1,n-2,\\ldots,1)$.\nThere also exists $Y\\subseteq\\mathbb{R}^2$ of $n$ points with pairwise distinct\ndistance multiplicities and $a(Y) \\neq (n-1,n-2,\\ldots,1)$.", "published": "2025-05-07 09:37:27", "link": "http://arxiv.org/abs/2505.04283v2", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "The stability of generalized phase retrieval problem over compact groups", "abstract": "The generalized phase retrieval problem over compact groups aims to recover a\nset of matrices, representing an unknown signal, from their associated Gram\nmatrices, leveraging prior structural knowledge about the signal. This\nframework generalizes the classical phase retrieval problem, which reconstructs\na signal from the magnitudes of its Fourier transform, to a richer setting\ninvolving non-abelian compact groups. In this broader context, the unknown\nphases in Fourier space are replaced by unknown orthogonal matrices that arise\nfrom the action of a compact group on a finite-dimensional vector space. This\nproblem is primarily motivated by advances in electron microscopy to\ndetermining the 3D structure of biological macromolecules from highly noisy\nobservations. To capture realistic assumptions from machine learning and signal\nprocessing, we model the signal as belonging to one of several broad structural\nfamilies: a generic linear subspace, a sparse representation in a generic\nbasis, the output of a generic ReLU neural network, or a generic\nlow-dimensional manifold. Our main result shows that, under mild conditions,\nthe generalized phase retrieval problem not only admits a unique solution (up\nto inherent group symmetries), but also satisfies a bi-Lipschitz property. This\nimplies robustness to both noise and model mismatch, an essential requirement\nfor practical use, especially when measurements are severely corrupted by\nnoise. These findings provide theoretical support for a wide class of\nscientific problems under modern structural assumptions, and they offer strong\nfoundations for developing robust algorithms in high-noise regimes.", "published": "2025-05-07 07:39:46", "link": "http://arxiv.org/abs/2505.04190v2", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "WATCH: Adaptive Monitoring for AI Deployments via Weighted-Conformal Martingales", "abstract": "Responsibly deploying artificial intelligence (AI) / machine learning (ML)\nsystems in high-stakes settings arguably requires not only proof of system\nreliability, but moreover continual, post-deployment monitoring to quickly\ndetect and address any unsafe behavior. Statistical methods for nonparametric\nchange-point detection -- especially the tools of conformal test martingales\n(CTMs) and anytime-valid inference -- offer promising approaches to this\nmonitoring task. However, existing methods are restricted to monitoring limited\nhypothesis classes or ``alarm criteria'' (such as data shifts that violate\ncertain exchangeability assumptions), do not allow for online adaptation in\nresponse to shifts, and/or do not enable root-cause analysis of any\ndegradation. In this paper, we expand the scope of these monitoring methods by\nproposing a weighted generalization of conformal test martingales (WCTMs),\nwhich lay a theoretical foundation for online monitoring for any unexpected\nchangepoints in the data distribution while controlling false-alarms. For\npractical applications, we propose specific WCTM algorithms that adapt online\nto mild covariate shifts (in the marginal input distribution) while quickly\ndetecting and diagnosing more severe shifts, such as concept shifts (in the\nconditional label distribution) or extreme (out-of-support) covariate shifts\nthat cannot be easily adapted to. On real-world datasets, we demonstrate\nimproved performance relative to state-of-the-art baselines.", "published": "2025-05-07 17:53:47", "link": "http://arxiv.org/abs/2505.04608v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Particle Gibbs without the Gibbs bit", "abstract": "Exact parameter and trajectory inference in state-space models is typically\nachieved by one of two methods: particle marginal Metropolis-Hastings (PMMH) or\nparticle Gibbs (PGibbs). PMMH is a pseudo-marginal algorithm which jointly\nproposes a new trajectory and parameter, and accepts or rejects both at once.\nPGibbs instead alternates between sampling from the trajectory, using an\nalgorithm known as conditional sequential Monte Carlo (CSMC) and the parameter\nin a Hastings-within-Gibbs fashion. While particle independent Metropolis\nHastings (PIMH), the parameter-free version of PMMH, is known to be\nstatistically worse than CSMC, PGibbs can induce a slow mixing if the parameter\nand the state trajectory are very correlated. This has made PMMH the method of\nchoice for many practitioners, despite theory and experiments favouring CSMC\nover PIMH for the parameter-free problem. In this article, we describe a\nformulation of PGibbs which bypasses the Gibbs step, essentially marginalizing\nover the trajectory distribution in a fashion similar to PMMH. This is achieved\nby considering the implementation of a CSMC algortihm for the state-space model\nintegrated over the joint distribution of the current parameter and the\nparameter proposal. We illustrate the benefits of method on a simple example\nknown to be challenging for PMMH.", "published": "2025-05-07 17:55:32", "link": "http://arxiv.org/abs/2505.04611v3", "categories": ["stat.CO", "eess.SP", "stat.ME"], "primary_category": "stat.CO"}
