{"title": "Going Beneath the Surface: Evaluating Image Captioning for\n  Grammaticality, Truthfulness and Diversity", "abstract": "Image captioning as a multimodal task has drawn much interest in recent\nyears. However, evaluation for this task remains a challenging problem.\nExisting evaluation metrics focus on surface similarity between a candidate\ncaption and a set of reference captions, and do not check the actual relation\nbetween a caption and the underlying visual content. We introduce a new\ndiagnostic evaluation framework for the task of image captioning, with the goal\nof directly assessing models for grammaticality, truthfulness and diversity\n(GTD) of generated captions. We demonstrate the potential of our evaluation\nframework by evaluating existing image captioning models on a wide ranging set\nof synthetic datasets that we construct for diagnostic evaluation. We\nempirically show how the GTD evaluation framework, in combination with\ndiagnostic datasets, can provide insights into model capabilities and\nlimitations to supplement standard evaluations.", "published": "2019-12-19 00:27:40", "link": "http://arxiv.org/abs/1912.08960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Adversarial Sentences by Analyzing Text Complexity", "abstract": "Attackers create adversarial text to deceive both human perception and the\ncurrent AI systems to perform malicious purposes such as spam product reviews\nand fake political posts. We investigate the difference between the adversarial\nand the original text to prevent the risk. We prove that the text written by a\nhuman is more coherent and fluent. Moreover, the human can express the idea\nthrough the flexible text with modern words while a machine focuses on\noptimizing the generated text by the simple and common words. We also suggest a\nmethod to identify the adversarial text by extracting the features related to\nour findings. The proposed method achieves high performance with 82.0% of\naccuracy and 18.4% of equal error rate, which is better than the existing\nmethods whose the best accuracy is 77.0% corresponding to the error rate 22.8%.", "published": "2019-12-19 01:45:36", "link": "http://arxiv.org/abs/1912.08981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discriminative Sentence Modeling for Story Ending Prediction", "abstract": "Story Ending Prediction is a task that needs to select an appropriate ending\nfor the given story, which requires the machine to understand the story and\nsometimes needs commonsense knowledge. To tackle this task, we propose a new\nneural network called Diff-Net for better modeling the differences of each\nending in this task. The proposed model could discriminate two endings in three\nsemantic levels: contextual representation, story-aware representation, and\ndiscriminative representation. Experimental results on the Story Cloze Test\ndataset show that the proposed model siginificantly outperforms various systems\nby a large margin, and detailed ablation studies are given for better\nunderstanding our model. We also carefully examine the traditional and\nBERT-based models on both SCT v1.0 and v1.5 with interesting findings that may\npotentially help future studies.", "published": "2019-12-19 03:48:05", "link": "http://arxiv.org/abs/1912.09008v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Simile Recognition with Cyclic Multitask Learning and Local\n  Attention", "abstract": "Simile recognition is to detect simile sentences and to extract simile\ncomponents, i.e., tenors and vehicles. It involves two subtasks: {\\it simile\nsentence classification} and {\\it simile component extraction}. Recent work has\nshown that standard multitask learning is effective for Chinese simile\nrecognition, but it is still uncertain whether the mutual effects between the\nsubtasks have been well captured by simple parameter sharing. We propose a\nnovel cyclic multitask learning framework for neural simile recognition, which\nstacks the subtasks and makes them into a loop by connecting the last to the\nfirst. It iteratively performs each subtask, taking the outputs of the previous\nsubtask as additional inputs to the current one, so that the interdependence\nbetween the subtasks can be better explored. Extensive experiments show that\nour framework significantly outperforms the current state-of-the-art model and\nour carefully designed baselines, and the gains are still remarkable using\nBERT.", "published": "2019-12-19 09:40:19", "link": "http://arxiv.org/abs/1912.09084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Annotating and normalizing biomedical NEs with limited knowledge", "abstract": "Named entity recognition (NER) is the very first step in the linguistic\nprocessing of any new domain. It is currently a common process in BioNLP on\nEnglish clinical text. However, it is still in its infancy in other major\nlanguages, as it is the case for Spanish. Presented under the umbrella of the\nPharmaCoNER shared task, this paper describes a very simple method for the\nannotation and normalization of pharmacological, chemical and, ultimately,\nbiomedical named entities in clinical cases. The system developed for the\nshared task is based on limited knowledge, collected, structured and munged in\na way that clearly outperforms scores obtained by similar dictionary-based\nsystems for English in the past. Along with this recovering of the\nknowledge-based methods for NER in subdomains, the paper also highlights the\nkey contribution of resource-based systems in the validation and consolidation\nof both the annotation guidelines and the human annotation practices. In this\nsense, some of the authors discoverings on the overall quality of human\nannotated datasets question the above-mentioned `official' results obtained by\nthis system, that ranked second (0.91 F1-score) and first (0.916 F1-score),\nrespectively, in the two PharmaCoNER subtasks.", "published": "2019-12-19 12:05:36", "link": "http://arxiv.org/abs/1912.09152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An End-to-End Dialogue State Tracking System with Machine Reading\n  Comprehension and Wide & Deep Classification", "abstract": "This paper describes our approach in DSTC 8 Track 4: Schema-Guided Dialogue\nState Tracking. The goal of this task is to predict the intents and slots in\neach user turn to complete the dialogue state tracking (DST) based on the\ninformation provided by the task's schema. Different from traditional\nstage-wise DST, we propose an end-to-end DST system to avoid error accumulation\nbetween the dialogue turns. The DST system consists of a machine reading\ncomprehension (MRC) model for non-categorical slots and a Wide & Deep model for\ncategorical slots. As far as we know, this is the first time that MRC and Wide\n& Deep model are applied to DST problem in a fully end-to-end way. Experimental\nresults show that our framework achieves an excellent performance on the test\ndataset including 50% zero-shot services with a joint goal accuracy of 0.8652\nand a slot tagging F1-Score of 0.9835.", "published": "2019-12-19 15:32:19", "link": "http://arxiv.org/abs/1912.09297v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RIMAX: Ranking Semantic Rhymes by calculating Definition Similarity", "abstract": "This paper presents RIMAX, a new system for detecting semantic rhymes, using\na Comprehensive Mexican Spanish Dictionary (DEM) and its Rhyming Dictionary\n(REM). We use the Vector Space Model to calculate the similarity of the\ndefinition of a query with the definitions corresponding to the assonant and\nconsonant rhymes of the query. The preliminary results using a manual\nevaluation are very encouraging.", "published": "2019-12-19 21:47:08", "link": "http://arxiv.org/abs/1912.09558v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERTje: A Dutch BERT Model", "abstract": "The transformer-based pre-trained language model BERT has helped to improve\nstate-of-the-art performance on many natural language processing (NLP) tasks.\nUsing the same architecture and parameters, we developed and evaluated a\nmonolingual Dutch BERT model called BERTje. Compared to the multilingual BERT\nmodel, which includes Dutch but is only based on Wikipedia text, BERTje is\nbased on a large and diverse dataset of 2.4 billion tokens. BERTje consistently\noutperforms the equally-sized multilingual BERT model on downstream NLP tasks\n(part-of-speech tagging, named-entity recognition, semantic role labeling, and\nsentiment analysis). Our pre-trained Dutch BERT model is made available at\nhttps://github.com/wietsedv/bertje.", "published": "2019-12-19 22:59:26", "link": "http://arxiv.org/abs/1912.09582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial\n  Reading Comprehension", "abstract": "We present a Chinese judicial reading comprehension (CJRC) dataset which\ncontains approximately 10K documents and almost 50K questions with answers. The\ndocuments come from judgment documents and the questions are annotated by law\nexperts. The CJRC dataset can help researchers extract elements by reading\ncomprehension technology. Element extraction is an important task in the legal\nfield. However, it is difficult to predefine the element types completely due\nto the diversity of document types and causes of action. By contrast, machine\nreading comprehension technology can quickly extract elements by answering\nvarious questions from the long document. We build two strong baseline models\nbased on BERT and BiDAF. The experimental results show that there is enough\nspace for improvement compared to human annotators.", "published": "2019-12-19 12:17:38", "link": "http://arxiv.org/abs/1912.09156v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Summary and Distance between Sets of Texts based on Topological Data\n  Analysis", "abstract": "In this paper, we use topological data analysis (TDA) tools such as\npersistent homology, persistent entropy and bottleneck distance, to provide a\n{\\it TDA-based summary} of any given set of texts and a general method for\ncomputing a distance between any two literary styles, authors or periods. To\nthis aim, deep-learning word-embedding techniques are combined with these tools\nin order to study the topological properties of texts embedded in a metric\nspace. As a case of study, we use the written texts of three poets of the\nSpanish Golden Age: Francisco de Quevedo, Luis de G\\'ongora and Lope de Vega.\nAs far as we know, this is the first time that word embedding, bottleneck\ndistance, persistent homology and persistent entropy are used together to\ncharacterize texts and to compare different literary styles.", "published": "2019-12-19 15:04:24", "link": "http://arxiv.org/abs/1912.09253v4", "categories": ["cs.CL", "math.AT"], "primary_category": "cs.CL"}
{"title": "LSTM-TDNN with convolutional front-end for Dialect Identification in the\n  2019 Multi-Genre Broadcast Challenge", "abstract": "This paper presents a novel Dialect Identification (DID) system developed for\nthe Fifth Edition of the Multi-Genre Broadcast challenge, the task of\nFine-grained Arabic Dialect Identification (MGB-5 ADI Challenge). The system\nimproves upon traditional DNN x-vector performance by employing a Convolutional\nand Long Short Term Memory-Recurrent (CLSTM) architecture to combine the\nbenefits of a convolutional neural network front-end for feature extraction and\na back-end recurrent neural to capture longer temporal dependencies.\nFurthermore we investigate intensive augmentation of one low resource dialect\nin the highly unbalanced training set using time-scale modification (TSM). This\nconverts an utterance to several time-stretched or time-compressed versions,\nsubsequently used to train the CLSTM system without using any other corpus. In\nthis paper, we also investigate speech augmentation using MUSAN and the RIR\ndatasets to increase the quantity and diversity of the existing training data\nin the normal way. Results show firstly that the CLSTM architecture outperforms\na traditional DNN x-vector implementation. Secondly, adopting TSM-based speed\nperturbation yields a small performance improvement for the unbalanced data,\nfinally that traditional data augmentation techniques yield further benefit, in\nline with evidence from related speaker and language recognition tasks. Our\nsystem achieved 2nd place ranking out of 15 entries in the MGB-5 ADI challenge,\npresented at ASRU 2019.", "published": "2019-12-19 03:20:33", "link": "http://arxiv.org/abs/1912.09003v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Generating Synthetic Audio Data for Attention-Based Speech Recognition\n  Systems", "abstract": "Recent advances in text-to-speech (TTS) led to the development of flexible\nmulti-speaker end-to-end TTS systems. We extend state-of-the-art\nattention-based automatic speech recognition (ASR) systems with synthetic audio\ngenerated by a TTS system trained only on the ASR corpora itself. ASR and TTS\nsystems are built separately to show that text-only data can be used to enhance\nexisting end-to-end ASR systems without the necessity of parameter or\narchitecture changes. We compare our method with language model integration of\nthe same text data and with simple data augmentation methods like SpecAugment\nand show that performance improvements are mostly independent. We achieve\nimprovements of up to 33% relative in word-error-rate (WER) over a strong\nbaseline with data-augmentation in a low-resource environment\n(LibriSpeech-100h), closing the gap to a comparable oracle experiment by more\nthan 50\\%. We also show improvements of up to 5% relative WER over our most\nrecent ASR baseline on LibriSpeech-960h.", "published": "2019-12-19 15:09:07", "link": "http://arxiv.org/abs/1912.09257v2", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Deep Exemplar Networks for VQA and VQG", "abstract": "In this paper, we consider the problem of solving semantic tasks such as\n`Visual Question Answering' (VQA), where one aims to answers related to an\nimage and `Visual Question Generation' (VQG), where one aims to generate a\nnatural question pertaining to an image. Solutions for VQA and VQG tasks have\nbeen proposed using variants of encoder-decoder deep learning based frameworks\nthat have shown impressive performance. Humans however often show\ngeneralization by relying on exemplar based approaches. For instance, the work\nby Tversky and Kahneman suggests that humans use exemplars when making\ncategorizations and decisions. In this work, we propose the incorporation of\nexemplar based approaches towards solving these problems. Specifically, we\nincorporate exemplar based approaches and show that an exemplar based module\ncan be incorporated in almost any of the deep learning architectures proposed\nin the literature and the addition of such a block results in improved\nperformance for solving these tasks. Thus, just as the incorporation of\nattention is now considered de facto useful for solving these tasks, similarly,\nincorporating exemplars also can be considered to improve any proposed\narchitecture for solving this task. We provide extensive empirical analysis for\nthe same through various architectures, ablations, and state of the art\ncomparisons.", "published": "2019-12-19 21:29:22", "link": "http://arxiv.org/abs/1912.09551v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Gaussianity and typicality in matrix distributional semantics", "abstract": "Constructions in type-driven compositional distributional semantics associate\nlarge collections of matrices of size $D$ to linguistic corpora. We develop the\nproposal of analysing the statistical characteristics of this data in the\nframework of permutation invariant matrix models. The observables in this\nframework are permutation invariant polynomial functions of the matrix entries,\nwhich correspond to directed graphs. Using the general 13-parameter permutation\ninvariant Gaussian matrix models recently solved, we find, using a dataset of\nmatrices constructed via standard techniques in distributional semantics, that\nthe expectation values of a large class of cubic and quartic observables show\nhigh gaussianity at levels between 90 to 99 percent. Beyond expectation values,\nwhich are averages over words, the dataset allows the computation of standard\ndeviations for each observable, which can be viewed as a measure of typicality\nfor each observable. There is a wide range of magnitudes in the measures of\ntypicality. The permutation invariant matrix models, considered as functions of\nrandom couplings, give a very good prediction of the magnitude of the\ntypicality for different observables. We find evidence that observables with\nsimilar matrix model characteristics of Gaussianity and typicality also have\nhigh degrees of correlation between the ranked lists of words associated to\nthese observables.", "published": "2019-12-19 15:55:42", "link": "http://arxiv.org/abs/1912.10839v1", "categories": ["hep-th", "cs.CL", "math-ph", "math.MP"], "primary_category": "hep-th"}
{"title": "CNN-LSTM models for Multi-Speaker Source Separation using Bayesian Hyper\n  Parameter Optimization", "abstract": "In recent years there have been many deep learning approaches towards the\nmulti-speaker source separation problem. Most use Long Short-Term Memory -\nRecurrent Neural Networks (LSTM-RNN) or Convolutional Neural Networks (CNN) to\nmodel the sequential behavior of speech. In this paper we propose a novel\nnetwork for source separation using an encoder-decoder CNN and LSTM in\nparallel. Hyper parameters have to be chosen for both parts of the network and\nthey are potentially mutually dependent. Since hyper parameter grid search has\na high computational burden, random search is often preferred. However, when\nsampling a new point in the hyper parameter space, it can potentially be very\nclose to a previously evaluated point and thus give little additional\ninformation. Furthermore, random sampling is as likely to sample in a promising\narea as in an hyper space area dominated with poor performing models.\nTherefore, we use a Bayesian hyper parameter optimization technique and find\nthat the parallel CNN-LSTM outperforms the LSTM-only and CNN-only model.", "published": "2019-12-19 15:04:34", "link": "http://arxiv.org/abs/1912.09254v1", "categories": ["cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Practical applicability of deep neural networks for overlapping speaker\n  separation", "abstract": "This paper examines the applicability in realistic scenarios of two deep\nlearning based solutions to the overlapping speaker separation problem.\nFirstly, we present experiments that show that these methods are applicable for\na broad range of languages. Further experimentation indicates limited\nperformance loss for untrained languages, when these have common features with\nthe trained language(s). Secondly, it investigates how the methods deal with\nrealistic background noise and proposes some modifications to better cope with\nthese disturbances. The deep learning methods that will be examined are deep\nclustering and deep attractor networks.", "published": "2019-12-19 15:13:36", "link": "http://arxiv.org/abs/1912.09261v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Statistical Testing on ASR Performance via Blockwise Bootstrap", "abstract": "A common question being raised in automatic speech recognition (ASR)\nevaluations is how reliable is an observed word error rate (WER) improvement\ncomparing two ASR systems, where statistical hypothesis testing and confidence\ninterval (CI) can be utilized to tell whether this improvement is real or only\ndue to random chance. The bootstrap resampling method has been popular for such\nsignificance analysis which is intuitive and easy to use. However, this method\nfails in dealing with dependent data, which is prevalent in speech world - for\nexample, ASR performance on utterances from the same speaker could be\ncorrelated. In this paper we present blockwise bootstrap approach - by dividing\nevaluation utterances into nonoverlapping blocks, this method resamples these\nblocks instead of original data. We show that the resulting variance estimator\nof absolute WER difference between two ASR systems is consistent under mild\nconditions. We also demonstrate the validity of blockwise bootstrap method on\nboth synthetic and real-world speech data.", "published": "2019-12-19 19:20:09", "link": "http://arxiv.org/abs/1912.09508v2", "categories": ["stat.ML", "cs.LG", "eess.AS"], "primary_category": "stat.ML"}
