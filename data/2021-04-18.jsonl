{"title": "Worst of Both Worlds: Biases Compound in Pre-trained Vision-and-Language\n  Models", "abstract": "Numerous works have analyzed biases in vision and pre-trained language models\nindividually - however, less attention has been paid to how these biases\ninteract in multimodal settings. This work extends text-based bias analysis\nmethods to investigate multimodal language models, and analyzes intra- and\ninter-modality associations and biases learned by these models. Specifically,\nwe demonstrate that VL-BERT (Su et al., 2020) exhibits gender biases, often\npreferring to reinforce a stereotype over faithfully describing the visual\nscene. We demonstrate these findings on a controlled case-study and extend them\nfor a larger set of stereotypically gendered entities.", "published": "2021-04-18 00:02:32", "link": "http://arxiv.org/abs/2104.08666v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Related Work", "abstract": "Communicating new research ideas involves highlighting similarities and\ndifferences with past work. Authors write fluent, often long sections to survey\nthe distinction of a new paper with related work. In this work we model\ngenerating related work sections while being cognisant of the motivation behind\nciting papers. Our content planning model generates a tree of cited papers\nbefore a surface realization model lexicalizes this skeleton. Our model\noutperforms several strong state-of-the-art summarization and multi-document\nsummarization models on generating related work on an ACL Anthology (AA) based\ndataset which we contribute.", "published": "2021-04-18 00:19:37", "link": "http://arxiv.org/abs/2104.08668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Does Pretraining Help? Assessing Self-Supervised Learning for Law\n  and the CaseHOLD Dataset", "abstract": "While self-supervised learning has made rapid advances in natural language\nprocessing, it remains unclear when researchers should engage in\nresource-intensive domain-specific pretraining (domain pretraining). The law,\npuzzlingly, has yielded few documented instances of substantial gains to domain\npretraining in spite of the fact that legal language is widely seen to be\nunique. We hypothesize that these existing results stem from the fact that\nexisting legal NLP tasks are too easy and fail to meet conditions for when\ndomain pretraining can help. To address this, we first present CaseHOLD (Case\nHoldings On Legal Decisions), a new dataset comprised of over 53,000+ multiple\nchoice questions to identify the relevant holding of a cited case. This dataset\npresents a fundamental task to lawyers and is both legally meaningful and\ndifficult from an NLP perspective (F1 of 0.4 with a BiLSTM baseline). Second,\nwe assess performance gains on CaseHOLD and existing legal NLP datasets. While\na Transformer architecture (BERT) pretrained on a general corpus (Google Books\nand Wikipedia) improves performance, domain pretraining (using corpus of\napproximately 3.5M decisions across all courts in the U.S. that is larger than\nBERT's) with a custom legal vocabulary exhibits the most substantial\nperformance gains with CaseHOLD (gain of 7.2% on F1, representing a 12%\nimprovement on BERT) and consistent performance gains across two other legal\ntasks. Third, we show that domain pretraining may be warranted when the task\nexhibits sufficient similarity to the pretraining corpus: the level of\nperformance increase in three legal tasks was directly tied to the domain\nspecificity of the task. Our findings inform when researchers should engage\nresource-intensive pretraining and show that Transformer-based architectures,\ntoo, learn embeddings suggestive of distinct legal language.", "published": "2021-04-18 00:57:16", "link": "http://arxiv.org/abs/2104.08671v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guilt by Association: Emotion Intensities in Lexical Representations", "abstract": "What do word vector representations reveal about the emotions associated with\nwords? In this study, we consider the task of estimating word-level emotion\nintensity scores for specific emotions, exploring unsupervised, supervised, and\nfinally a self-supervised method of extracting emotional associations from word\nvector representations. Overall, we find that word vectors carry substantial\npotential for inducing fine-grained emotion intensity scores, showing a far\nhigher correlation with human ground truth ratings than achieved by\nstate-of-the-art emotion lexicons.", "published": "2021-04-18 02:03:52", "link": "http://arxiv.org/abs/2104.08679v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Power of Scale for Parameter-Efficient Prompt Tuning", "abstract": "In this work, we explore \"prompt tuning\", a simple yet effective mechanism\nfor learning \"soft prompts\" to condition frozen language models to perform\nspecific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft\nprompts are learned through backpropagation and can be tuned to incorporate\nsignal from any number of labeled examples. Our end-to-end learned approach\noutperforms GPT-3's \"few-shot\" learning by a large margin. More remarkably,\nthrough ablations on model size using T5, we show that prompt tuning becomes\nmore competitive with scale: as models exceed billions of parameters, our\nmethod \"closes the gap\" and matches the strong performance of model tuning\n(where all model weights are tuned). This finding is especially relevant in\nthat large models are costly to share and serve, and the ability to reuse one\nfrozen model for multiple downstream tasks can ease this burden. Our method can\nbe seen as a simplification of the recently proposed \"prefix tuning\" of Li and\nLiang (2021), and we provide a comparison to this and other similar approaches.\nFinally, we show that conditioning a frozen model with soft prompts confers\nbenefits in robustness to domain transfer, as compared to full model tuning.", "published": "2021-04-18 03:19:26", "link": "http://arxiv.org/abs/2104.08691v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MT6: Multilingual Pretrained Text-to-Text Transformer with Translation\n  Pairs", "abstract": "Multilingual T5 (mT5) pretrains a sequence-to-sequence model on massive\nmonolingual texts, which has shown promising results on many cross-lingual\ntasks. In this paper, we improve multilingual text-to-text transfer Transformer\nwith translation pairs (mT6). Specifically, we explore three cross-lingual\ntext-to-text pre-training tasks, namely, machine translation, translation pair\nspan corruption, and translation span corruption. In addition, we propose a\npartially non-autoregressive objective for text-to-text pre-training. We\nevaluate the methods on eight multilingual benchmark datasets, including\nsentence classification, named entity recognition, question answering, and\nabstractive summarization. Experimental results show that the proposed mT6\nimproves cross-lingual transferability over mT5.", "published": "2021-04-18 03:24:07", "link": "http://arxiv.org/abs/2104.08692v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Neurons in Pretrained Transformers", "abstract": "Large-scale pretrained language models are surprisingly good at recalling\nfactual knowledge presented in the training corpus. In this paper, we present\npreliminary studies on how factual knowledge is stored in pretrained\nTransformers by introducing the concept of knowledge neurons. Specifically, we\nexamine the fill-in-the-blank cloze task for BERT. Given a relational fact, we\npropose a knowledge attribution method to identify the neurons that express the\nfact. We find that the activation of such knowledge neurons is positively\ncorrelated to the expression of their corresponding facts. In our case studies,\nwe attempt to leverage knowledge neurons to edit (such as update, and erase)\nspecific factual knowledge without fine-tuning. Our results shed light on\nunderstanding the storage of knowledge within pretrained Transformers. The code\nis available at https://github.com/Hunter-DDM/knowledge-neurons.", "published": "2021-04-18 03:38:26", "link": "http://arxiv.org/abs/2104.08696v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Intent Features for Rich Natural Language Understanding", "abstract": "Complex natural language understanding modules in dialog systems have a\nricher understanding of user utterances, and thus are critical in providing a\nbetter user experience. However, these models are often created from scratch,\nfor specific clients and use cases, and require the annotation of large\ndatasets. This encourages the sharing of annotated data across multiple\nclients. To facilitate this we introduce the idea of intent features: domain\nand topic agnostic properties of intents that can be learned from the syntactic\ncues only, and hence can be shared. We introduce a new neural network\narchitecture, the Global-Local model, that shows significant improvement over\nstrong baselines for identifying these features in a deployed, multi-intent\nnatural language understanding module, and, more generally, in a classification\nsetting where a part of an utterance has to be classified utilizing the whole\ncontext.", "published": "2021-04-18 03:57:02", "link": "http://arxiv.org/abs/2104.08701v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple and Efficient ways to Improve REALM", "abstract": "Dense retrieval has been shown to be effective for retrieving relevant\ndocuments for Open Domain QA, surpassing popular sparse retrieval methods like\nBM25. REALM (Guu et al., 2020) is an end-to-end dense retrieval system that\nrelies on MLM based pretraining for improved downstream QA efficiency across\nmultiple datasets. We study the finetuning of REALM on various QA tasks and\nexplore the limits of various hyperparameter and supervision choices. We find\nthat REALM was significantly undertrained when finetuning and simple\nimprovements in the training, supervision, and inference setups can\nsignificantly benefit QA results and exceed the performance of other models\npublished post it. Our best model, REALM++, incorporates all the best working\nfindings and achieves significant QA accuracy improvements over baselines\n(~5.5% absolute accuracy) without any model design changes. Additionally,\nREALM++ matches the performance of large Open Domain QA models which have 3x\nmore parameters demonstrating the efficiency of the setup.", "published": "2021-04-18 04:32:33", "link": "http://arxiv.org/abs/2104.08710v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PaCo: Preconditions Attributed to Commonsense Knowledge", "abstract": "Humans can seamlessly reason with circumstantial preconditions of commonsense\nknowledge. We understand that a glass is used for drinking water, unless the\nglass is broken or the water is toxic. Despite state-of-the-art (SOTA) language\nmodels' (LMs) impressive performance on inferring commonsense knowledge, it is\nunclear whether they understand the circumstantial preconditions. To address\nthis gap, we propose a novel challenge of reasoning with circumstantial\npreconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand\npreconditions of commonsense statements expressed in natural language. Based on\nthis dataset, we create three canonical evaluation tasks and use them to\nexamine the capability of existing LMs to understand situational preconditions.\nOur results reveal a 10-30% gap between machine and human performance on our\ntasks, which shows that reasoning with preconditions is an open challenge.", "published": "2021-04-18 04:37:54", "link": "http://arxiv.org/abs/2104.08712v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Embedding-Enhanced Giza++: Improving Alignment in Low- and High-\n  Resource Scenarios Using Embedding Space Geometry", "abstract": "A popular natural language processing task decades ago, word alignment has\nbeen dominated until recently by GIZA++, a statistical method based on the\n30-year-old IBM models. New methods that outperform GIZA++ primarily rely on\nlarge machine translation models, massively multilingual language models, or\nsupervision from GIZA++ alignments itself. We introduce Embedding-Enhanced\nGIZA++, and outperform GIZA++ without any of the aforementioned factors. Taking\nadvantage of monolingual embedding spaces of source and target language only,\nwe exceed GIZA++'s performance in every tested scenario for three languages\npairs. In the lowest-resource setting, we outperform GIZA++ by 8.5, 10.9, and\n12 AER for Ro-En, De-En, and En-Fr, respectively. We release our code at\nhttps://github.com/kellymarchisio/ee-giza.", "published": "2021-04-18 05:21:50", "link": "http://arxiv.org/abs/2104.08721v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "News Meets Microblog: Hashtag Annotation via Retriever-Generator", "abstract": "Hashtag annotation for microblog posts has been recently formulated as a\nsequence generation problem to handle emerging hashtags that are unseen in the\ntraining set. The state-of-the-art method leverages conversations initiated by\nposts to enrich contextual information for the short posts. However, it is\nunrealistic to assume the existence of conversations before the hashtag\nannotation itself. Therefore, we propose to leverage news articles published\nbefore the microblog post to generate hashtags following a Retriever-Generator\nframework. Extensive experiments on English Twitter datasets demonstrate\nsuperior performance and significant advantages of leveraging news articles to\ngenerate hashtags.", "published": "2021-04-18 05:28:13", "link": "http://arxiv.org/abs/2104.08723v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extract, Denoise and Enforce: Evaluating and Improving Concept\n  Preservation for Text-to-Text Generation", "abstract": "Prior studies on text-to-text generation typically assume that the model\ncould figure out what to attend to in the input and what to include in the\noutput via seq2seq learning, with only the parallel training data and no\nadditional guidance. However, it remains unclear whether current models can\npreserve important concepts in the source input, as seq2seq learning does not\nhave explicit focus on the concepts and commonly used evaluation metrics also\ntreat concepts equally important as other tokens. In this paper, we present a\nsystematic analysis that studies whether current seq2seq models, especially\npre-trained language models, are good enough for preserving important input\nconcepts and to what extent explicitly guiding generation with the concepts as\nlexical constraints is beneficial. We answer the above questions by conducting\nextensive analytical experiments on four representative text-to-text generation\ntasks. Based on the observations, we then propose a simple yet effective\nframework to automatically extract, denoise, and enforce important input\nconcepts as lexical constraints. This new method performs comparably or better\nthan its unconstrained counterpart on automatic metrics, demonstrates higher\ncoverage for concept preservation, and receives better ratings in the human\nevaluation. Our code is available at https://github.com/morningmoni/EDE.", "published": "2021-04-18 05:29:02", "link": "http://arxiv.org/abs/2104.08724v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AmericasNLI: Evaluating Zero-shot Natural Language Understanding of\n  Pretrained Multilingual Models in Truly Low-resource Languages", "abstract": "Pretrained multilingual models are able to perform cross-lingual transfer in\na zero-shot setting, even for languages unseen during pretraining. However,\nprior work evaluating performance on unseen languages has largely been limited\nto low-level, syntactic tasks, and it remains unclear if zero-shot learning of\nhigh-level, semantic tasks is possible for unseen languages. To explore this\nquestion, we present AmericasNLI, an extension of XNLI (Conneau et al., 2018)\nto 10 indigenous languages of the Americas. We conduct experiments with XLM-R,\ntesting multiple zero-shot and translation-based approaches. Additionally, we\nexplore model adaptation via continued pretraining and provide an analysis of\nthe dataset by considering hypothesis-only models. We find that XLM-R's\nzero-shot performance is poor for all 10 languages, with an average performance\nof 38.62%. Continued pretraining offers improvements, with an average accuracy\nof 44.05%. Surprisingly, training on poorly translated data by far outperforms\nall other methods with an accuracy of 48.72%.", "published": "2021-04-18 05:32:28", "link": "http://arxiv.org/abs/2104.08726v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revealing Persona Biases in Dialogue Systems", "abstract": "Dialogue systems in the form of chatbots and personal assistants are being\nincreasingly integrated into people's lives. Modern dialogue systems may\nconsider adopting anthropomorphic personas, mimicking societal demographic\ngroups to appear more approachable and trustworthy to users. However, the\nadoption of a persona can result in the adoption of biases. In this paper, we\npresent the first large-scale study on persona biases in dialogue systems and\nconduct analyses on personas of different social classes, sexual orientations,\nraces, and genders. We define persona biases as harmful differences in\nresponses (e.g., varying levels of offensiveness, agreement with harmful\nstatements) generated from adopting different demographic personas.\nFurthermore, we introduce an open-source framework, UnitPersonaBias, to explore\nand aggregate persona biases in dialogue systems. By analyzing the Blender and\nDialoGPT dialogue systems, we observe that adopting personas can actually\ndecrease harmful responses, compared to not using any personas. Additionally,\nwe find that persona choices can affect the degree of harms in generated\nresponses and thus should be systematically evaluated before deployment. We\nalso analyze how personas can result in different amounts of harm towards\nspecific demographics.", "published": "2021-04-18 05:44:41", "link": "http://arxiv.org/abs/2104.08728v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning with Instance Bundles for Reading Comprehension", "abstract": "When training most modern reading comprehension models, all the questions\nassociated with a context are treated as being independent from each other.\nHowever, closely related questions and their corresponding answers are not\nindependent, and leveraging these relationships could provide a strong\nsupervision signal to a model. Drawing on ideas from contrastive estimation, we\nintroduce several new supervision techniques that compare question-answer\nscores across multiple related instances. Specifically, we normalize these\nscores across various neighborhoods of closely contrasting questions and/or\nanswers, adding another cross entropy loss term that is used in addition to\ntraditional maximum likelihood estimation. Our techniques require bundles of\nrelated question-answer pairs, which we can either mine from within existing\ndata or create using various automated heuristics. We empirically demonstrate\nthe effectiveness of training with instance bundles on two datasets -- HotpotQA\nand ROPES -- showing up to 11% absolute gains in accuracy.", "published": "2021-04-18 06:17:54", "link": "http://arxiv.org/abs/2104.08735v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CEAR: Cross-Entity Aware Reranker for Knowledge Base Completion", "abstract": "Pre-trained language models (LMs) like BERT have shown to store factual\nknowledge about the world. This knowledge can be used to augment the\ninformation present in Knowledge Bases, which tend to be incomplete. However,\nprior attempts at using BERT for task of Knowledge Base Completion (KBC)\nresulted in performance worse than embedding based techniques that rely only on\nthe graph structure. In this work we develop a novel model, Cross-Entity Aware\nReranker (CEAR), that uses BERT to re-rank the output of existing KBC models\nwith cross-entity attention. Unlike prior work that scores each entity\nindependently, CEAR uses BERT to score the entities together, which is\neffective for exploiting its factual knowledge. CEAR achieves a new state of\nart for the OLPBench dataset.", "published": "2021-04-18 06:56:00", "link": "http://arxiv.org/abs/2104.08741v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Go Forth and Prosper: Language Modeling with Ancient Textual History", "abstract": "We introduce a technique for improving document-level language models (LM) by\nleveraging \"ancient history\": text that is outside the LM's current context\nwindow. We learn an auxiliary function to select spans from the ancient history\nwhich can help the LM to predict future text. The selected text spans are then\ncopied directly into the LM's context window, replacing less predictive spans.\nThis method can improve perplexity of pretrained LMs with no updates to the\nLM's own parameters. We further observe that an auxiliary function trained in a\nspecific textual domain like Wikipedia will also work in a substantially\ndifferent domain such as scientific publications. With this technique we see a\n7 percent perplexity reduction on Wikipedia articles, and a 12 percent\nperplexity reduction on scientific texts.", "published": "2021-04-18 06:57:30", "link": "http://arxiv.org/abs/2104.08742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generative Context Pair Selection for Multi-hop Question Answering", "abstract": "Compositional reasoning tasks like multi-hop question answering, require\nmaking latent decisions to get the final answer, given a question. However,\ncrowdsourced datasets often capture only a slice of the underlying task\ndistribution, which can induce unanticipated biases in models performing\ncompositional reasoning. Furthermore, discriminatively trained models exploit\nsuch biases to get a better held-out performance, without learning the right\nway to reason, as they do not necessitate paying attention to the question\nrepresentation (conditioning variable) in its entirety, to estimate the answer\nlikelihood. In this work, we propose a generative context selection model for\nmulti-hop question answering that reasons about how the given question could\nhave been generated given a context pair. While being comparable to the\nstate-of-the-art answering performance, our proposed generative passage\nselection model has a better performance (4.9% higher than baseline) on\nadversarial held-out set which tests robustness of model's multi-hop reasoning\ncapabilities.", "published": "2021-04-18 07:00:48", "link": "http://arxiv.org/abs/2104.08744v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot Cross-lingual Transfer of Neural Machine Translation with\n  Multilingual Pretrained Encoders", "abstract": "Previous work mainly focuses on improving cross-lingual transfer for NLU\ntasks with a multilingual pretrained encoder (MPE), or improving the\nperformance on supervised machine translation with BERT. However, it is\nunder-explored that whether the MPE can help to facilitate the cross-lingual\ntransferability of NMT model. In this paper, we focus on a zero-shot\ncross-lingual transfer task in NMT. In this task, the NMT model is trained with\nparallel dataset of only one language pair and an off-the-shelf MPE, then it is\ndirectly tested on zero-shot language pairs. We propose SixT, a simple yet\neffective model for this task. SixT leverages the MPE with a two-stage training\nschedule and gets further improvement with a position disentangled encoder and\na capacity-enhanced decoder. Using this method, SixT significantly outperforms\nmBART, a pretrained multilingual encoder-decoder model explicitly designed for\nNMT, with an average improvement of 7.1 BLEU on zero-shot any-to-English test\nsets across 14 source languages. Furthermore, with much less training\ncomputation cost and training data, our model achieves better performance on 15\nany-to-English test sets than CRISS and m2m-100, two strong multilingual NMT\nbaselines.", "published": "2021-04-18 07:42:45", "link": "http://arxiv.org/abs/2104.08757v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Neural Model Performance through Natural Language Feedback on\n  Their Explanations", "abstract": "A class of explainable NLP models for reasoning tasks support their decisions\nby generating free-form or structured explanations, but what happens when these\nsupporting structures contain errors? Our goal is to allow users to\ninteractively correct explanation structures through natural language feedback.\nWe introduce MERCURIE - an interactive system that refines its explanations for\na given reasoning task by getting human feedback in natural language. Our\napproach generates graphs that have 40% fewer inconsistencies as compared with\nthe off-the-shelf system. Further, simply appending the corrected explanation\nstructures to the output leads to a gain of 1.2 points on accuracy on\ndefeasible reasoning across all three domains. We release a dataset of over\n450k graphs for defeasible reasoning generated by our system at\nhttps://tinyurl.com/mercurie .", "published": "2021-04-18 08:10:01", "link": "http://arxiv.org/abs/2104.08765v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constrained Language Models Yield Few-Shot Semantic Parsers", "abstract": "We explore the use of large pretrained language models as few-shot semantic\nparsers. The goal in semantic parsing is to generate a structured meaning\nrepresentation given a natural language input. However, language models are\ntrained to generate natural language. To bridge the gap, we use language models\nto paraphrase inputs into a controlled sublanguage resembling English that can\nbe automatically mapped to a target meaning representation. Our results\ndemonstrate that with only a small amount of data and very little code to\nconvert into English-like representations, our blueprint for rapidly\nbootstrapping semantic parsers leads to surprisingly effective performance on\nmultiple community tasks, greatly exceeding baseline methods also trained on\nthe same limited data.", "published": "2021-04-18 08:13:06", "link": "http://arxiv.org/abs/2104.08768v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Attention is All You Need: Adapting Pretrained Transformers for\n  Machine Translation", "abstract": "We study the power of cross-attention in the Transformer architecture within\nthe context of transfer learning for machine translation, and extend the\nfindings of studies into cross-attention when training from scratch. We conduct\na series of experiments through fine-tuning a translation model on data where\neither the source or target language has changed. These experiments reveal that\nfine-tuning only the cross-attention parameters is nearly as effective as\nfine-tuning all parameters (i.e., the entire translation model). We provide\ninsights into why this is the case and observe that limiting fine-tuning in\nthis manner yields cross-lingually aligned embeddings. The implications of this\nfinding for researchers and practitioners include a mitigation of catastrophic\nforgetting, the potential for zero-shot translation, and the ability to extend\nmachine translation models to several new language pairs with reduced parameter\nstorage overhead.", "published": "2021-04-18 08:41:01", "link": "http://arxiv.org/abs/2104.08771v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Sensitivity and Stability of Model Interpretations in NLP", "abstract": "Recent years have witnessed the emergence of a variety of post-hoc\ninterpretations that aim to uncover how natural language processing (NLP)\nmodels make predictions. Despite the surge of new interpretation methods, it\nremains an open problem how to define and quantitatively measure the\nfaithfulness of interpretations, i.e., to what extent interpretations reflect\nthe reasoning process by a model. We propose two new criteria, sensitivity and\nstability, that provide complementary notions of faithfulness to the existed\nremoval-based criteria. Our results show that the conclusion for how faithful\ninterpretations are could vary substantially based on different notions.\nMotivated by the desiderata of sensitivity and stability, we introduce a new\nclass of interpretation methods that adopt techniques from adversarial\nrobustness. Empirical results show that our proposed methods are effective\nunder the new criteria and overcome limitations of gradient-based methods on\nremoval-based criteria. Besides text classification, we also apply\ninterpretation methods and metrics to dependency parsing. Our results shed\nlight on understanding the diverse set of interpretations.", "published": "2021-04-18 09:19:44", "link": "http://arxiv.org/abs/2104.08782v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese Sentences Similarity via Cross-Attention Based Siamese Network", "abstract": "Measuring sentence similarity is a key research area nowadays as it allows\nmachines to better understand human languages. In this paper, we proposed a\nCross-Attention Siamese Network (CATsNet) to carry out the task of learning the\nsemantic meanings of Chinese sentences and comparing the similarity between two\nsentences. This novel model is capable of catching non-local features.\nAdditionally, we also tried to apply the long short-term memory (LSTM) network\nin the model to improve its performance. The experiments were conducted on the\nLCQMC dataset and the results showed that our model could achieve a higher\naccuracy than previous work.", "published": "2021-04-18 09:35:58", "link": "http://arxiv.org/abs/2104.08787v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Misinfo Reaction Frames: Reasoning about Readers' Reactions to News\n  Headlines", "abstract": "Even to a simple and short news headline, readers react in a multitude of\nways: cognitively (e.g. inferring the writer's intent), emotionally (e.g.\nfeeling distrust), and behaviorally (e.g. sharing the news with their friends).\nSuch reactions are instantaneous and yet complex, as they rely on factors that\ngo beyond interpreting factual content of news. We propose Misinfo Reaction\nFrames (MRF), a pragmatic formalism for modeling how readers might react to a\nnews headline. In contrast to categorical schema, our free-text dimensions\nprovide a more nuanced way of understanding intent beyond being benign or\nmalicious. We also introduce a Misinfo Reaction Frames corpus, a crowdsourced\ndataset of reactions to over 25k news headlines focusing on global crises: the\nCovid-19 pandemic, climate change, and cancer. Empirical results confirm that\nit is indeed possible for neural models to predict the prominent patterns of\nreaders' reactions to previously unseen news headlines. Additionally, our user\nstudy shows that displaying machine-generated MRF implications alongside news\nheadlines to readers can increase their trust in real news while decreasing\ntheir trust in misinformation. Our work demonstrates the feasibility and\nimportance of pragmatic inferences on news headlines to help enhance AI-guided\nmisinformation detection and mitigation.", "published": "2021-04-18 09:50:11", "link": "http://arxiv.org/abs/2104.08790v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keyphrase Generation with Fine-Grained Evaluation-Guided Reinforcement\n  Learning", "abstract": "Aiming to generate a set of keyphrases, Keyphrase Generation (KG) is a\nclassical task for capturing the central idea from a given document. Based on\nSeq2Seq models, the previous reinforcement learning framework on KG tasks\nutilizes the evaluation metrics to further improve the well-trained neural\nmodels. However, these KG evaluation metrics such as $F_1@5$ and $F_1@M$ are\nonly aware of the exact correctness of predictions on phrase-level and ignore\nthe semantic similarities between similar predictions and targets, which\ninhibits the model from learning deep linguistic patterns. In response to this\nproblem, we propose a new fine-grained evaluation metric to improve the RL\nframework, which considers different granularities: token-level $F_1$ score,\nedit distance, duplication, and prediction quantities. On the whole, the new\nframework includes two reward functions: the fine-grained evaluation score and\nthe vanilla $F_1$ score. This framework helps the model identifying some\npartial match phrases which can be further optimized as the exact match ones.\nExperiments on KG benchmarks show that our proposed training framework\noutperforms the previous RL training frameworks among all evaluation scores. In\naddition, our method can effectively ease the synonym problem and generate a\nhigher quality prediction. The source code is available at\n\\url{https://github.com/xuyige/FGRL4KG}.", "published": "2021-04-18 10:13:46", "link": "http://arxiv.org/abs/2104.08799v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation\n  for Few-shot Learning", "abstract": "The ability to continuously expand knowledge over time and utilize it to\nrapidly generalize to new tasks is a key feature of human linguistic\nintelligence. Existing models that pursue rapid generalization to new tasks\n(e.g., few-shot learning methods), however, are mostly trained in a single shot\non fixed datasets, unable to dynamically expand their knowledge; while\ncontinual learning algorithms are not specifically designed for rapid\ngeneralization. We present a new learning setup, Continual Learning of Few-Shot\nLearners (CLIF), to address the challenges of both learning settings in a\nunified setup. CLIF assumes a model learns from a sequence of diverse NLP tasks\narriving sequentially, accumulating knowledge for improved generalization to\nnew tasks, while also retaining performance on the tasks learned earlier. We\nexamine how the generalization ability is affected in the continual learning\nsetup, evaluate a number of continual learning algorithms, and propose a novel\nregularized adapter generation approach. We find that catastrophic forgetting\naffects generalization ability to a less degree than performance on seen tasks;\nwhile continual learning algorithms can still bring considerable benefit to the\ngeneralization ability.", "published": "2021-04-18 10:41:56", "link": "http://arxiv.org/abs/2104.08808v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contrastive Out-of-Distribution Detection for Pretrained Transformers", "abstract": "Pretrained Transformers achieve remarkable performance when training and test\ndata are from the same distribution. However, in real-world scenarios, the\nmodel often faces out-of-distribution (OOD) instances that can cause severe\nsemantic shift problems at inference time. Therefore, in practice, a reliable\nmodel should identify such instances, and then either reject them during\ninference or pass them over to models that handle another distribution. In this\npaper, we develop an unsupervised OOD detection method, in which only the\nin-distribution (ID) data are used in training. We propose to fine-tune the\nTransformers with a contrastive loss, which improves the compactness of\nrepresentations, such that OOD instances can be better differentiated from ID\nones. These OOD instances can then be accurately detected using the Mahalanobis\ndistance in the model's penultimate layer. We experiment with comprehensive\nsettings and achieve near-perfect OOD detection performance, outperforming\nbaselines drastically. We further investigate the rationales behind the\nimprovement, finding that more compact representations through margin-based\ncontrastive learning bring the improvement. We release our code to the\ncommunity for future research.", "published": "2021-04-18 10:51:47", "link": "http://arxiv.org/abs/2104.08812v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stream-level Latency Evaluation for Simultaneous Machine Translation", "abstract": "Simultaneous machine translation has recently gained traction thanks to\nsignificant quality improvements and the advent of streaming applications.\nSimultaneous translation systems need to find a trade-off between translation\nquality and response time, and with this purpose multiple latency measures have\nbeen proposed. However, latency evaluations for simultaneous translation are\nestimated at the sentence level, not taking into account the sequential nature\nof a streaming scenario. Indeed, these sentence-level latency measures are not\nwell suited for continuous stream translation resulting in figures that are not\ncoherent with the simultaneous translation policy of the system being assessed.\nThis work proposes a stream-level adaptation of the current latency measures\nbased on a re-segmentation approach applied to the output translation, that is\nsuccessfully evaluated on streaming conditions for a reference IWSLT task.", "published": "2021-04-18 11:16:17", "link": "http://arxiv.org/abs/2104.08817v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich\n  Document Understanding", "abstract": "Multimodal pre-training with text, layout, and image has achieved SOTA\nperformance for visually-rich document understanding tasks recently, which\ndemonstrates the great potential for joint learning across different\nmodalities. In this paper, we present LayoutXLM, a multimodal pre-trained model\nfor multilingual document understanding, which aims to bridge the language\nbarriers for visually-rich document understanding. To accurately evaluate\nLayoutXLM, we also introduce a multilingual form understanding benchmark\ndataset named XFUND, which includes form understanding samples in 7 languages\n(Chinese, Japanese, Spanish, French, Italian, German, Portuguese), and\nkey-value pairs are manually labeled for each language. Experiment results show\nthat the LayoutXLM model has significantly outperformed the existing SOTA\ncross-lingual pre-trained models on the XFUND dataset. The pre-trained\nLayoutXLM model and the XFUND dataset are publicly available at\nhttps://aka.ms/layoutxlm.", "published": "2021-04-18 12:16:00", "link": "http://arxiv.org/abs/2104.08836v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotion-Regularized Conditional Variational Autoencoder for Emotional\n  Response Generation", "abstract": "This paper presents an emotion-regularized conditional variational\nautoencoder (Emo-CVAE) model for generating emotional conversation responses.\nIn conventional CVAE-based emotional response generation, emotion labels are\nsimply used as additional conditions in prior, posterior and decoder networks.\nConsidering that emotion styles are naturally entangled with semantic contents\nin the language space, the Emo-CVAE model utilizes emotion labels to regularize\nthe CVAE latent space by introducing an extra emotion prediction network. In\nthe training stage, the estimated latent variables are required to predict the\nemotion labels and token sequences of the input responses simultaneously.\nExperimental results show that our Emo-CVAE model can learn a more informative\nand structured latent space than a conventional CVAE model and output responses\nwith better content and emotion performance than baseline CVAE and\nsequence-to-sequence (Seq2Seq) models.", "published": "2021-04-18 13:53:20", "link": "http://arxiv.org/abs/2104.08857v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language in a (Search) Box: Grounding Language Learning in Real-World\n  Human-Machine Interaction", "abstract": "We investigate grounded language learning through real-world data, by\nmodelling a teacher-learner dynamics through the natural interactions occurring\nbetween users and search engines; in particular, we explore the emergence of\nsemantic generalization from unsupervised dense representations outside of\nsynthetic environments. A grounding domain, a denotation function and a\ncomposition function are learned from user data only. We show how the resulting\nsemantics for noun phrases exhibits compositional properties while being fully\nlearnable without any explicit labelling. We benchmark our grounded semantics\non compositionality and zero-shot inference tasks, and we show that it provides\nbetter results and better generalizations than SOTA non-grounded models, such\nas word2vec and BERT.", "published": "2021-04-18 15:03:16", "link": "http://arxiv.org/abs/2104.08874v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Preposition Project", "abstract": "Prepositions are an important vehicle for indicating semantic roles. Their\nmeanings are difficult to analyze and they are often discarded in processing\ntext. The Preposition Project is designed to provide a comprehensive database\nof preposition senses suitable for use in natural language processing\napplications. In the project, prepositions in the FrameNet corpus are\ndisambiguated using a sense inventory from a current dictionary, guided by a\ncomprehensive treatment of preposition meaning. The methodology provides a\nframework for identifying and characterizing semantic roles, a gold standard\ncorpus of instances for further analysis, and an account of semantic role\nalternation patterns. By adhering to this methodology, it is hoped that a\ncomprehensive and improved characterization of preposition behavior (semantic\nrole identification, and syntactic and semantic properties of the preposition\ncomplement and attachment point) will be developed. The databases generated in\nthe project are publicly available for further use by researchers and\napplication developers.", "published": "2021-04-18 17:45:30", "link": "http://arxiv.org/abs/2104.08922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SIMMC 2.0: A Task-oriented Dialog Dataset for Immersive Multimodal\n  Conversations", "abstract": "Next generation task-oriented dialog systems need to understand\nconversational contexts with their perceived surroundings, to effectively help\nusers in the real-world multimodal environment. Existing task-oriented dialog\ndatasets aimed towards virtual assistance fall short and do not situate the\ndialog in the user's multimodal context. To overcome, we present a new dataset\nfor Situated and Interactive Multimodal Conversations, SIMMC 2.0, which\nincludes 11K task-oriented user<->assistant dialogs (117K utterances) in the\nshopping domain, grounded in immersive and photo-realistic scenes.\n  The dialogs are collected using a two-phase pipeline: (1) A novel multimodal\ndialog simulator generates simulated dialog flows, with an emphasis on\ndiversity and richness of interactions, (2) Manual paraphrasing of the\ngenerated utterances to collect diverse referring expressions. We provide an\nin-depth analysis of the collected dataset, and describe in detail the four\nmain benchmark tasks we propose. Our baseline model, powered by the\nstate-of-the-art language model, shows promising results, and highlights new\nchallenges and directions for the community to study.", "published": "2021-04-18 00:14:29", "link": "http://arxiv.org/abs/2104.08667v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"Average\" Approximates \"First Principal Component\"? An Empirical\n  Analysis on Representations from Neural Language Models", "abstract": "Contextualized representations based on neural language models have furthered\nthe state of the art in various NLP tasks. Despite its great success, the\nnature of such representations remains a mystery. In this paper, we present an\nempirical property of these representations -- \"average\" approximates \"first\nprincipal component\". Specifically, experiments show that the average of these\nrepresentations shares almost the same direction as the first principal\ncomponent of the matrix whose columns are these representations. We believe\nthis explains why the average representation is always a simple yet strong\nbaseline. Our further examinations show that this property also holds in more\nchallenging scenarios, for example, when the representations are from a model\nright after its random initialization. Therefore, we conjecture that this\nproperty is intrinsic to the distribution of representations and not\nnecessarily related to the input structure. We realize that these\nrepresentations empirically follow a normal distribution for each dimension,\nand by assuming this is true, we demonstrate that the empirical property can be\nin fact derived mathematically.", "published": "2021-04-18 01:15:40", "link": "http://arxiv.org/abs/2104.08673v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dual-View Distilled BERT for Sentence Embedding", "abstract": "Recently, BERT realized significant progress for sentence matching via\nword-level cross sentence attention. However, the performance significantly\ndrops when using siamese BERT-networks to derive two sentence embeddings, which\nfall short in capturing the global semantic since the word-level attention\nbetween two sentences is absent. In this paper, we propose a Dual-view\ndistilled BERT~(DvBERT) for sentence matching with sentence embeddings. Our\nmethod deals with a sentence pair from two distinct views, i.e., Siamese View\nand Interaction View. Siamese View is the backbone where we generate sentence\nembeddings. Interaction View integrates the cross sentence interaction as\nmultiple teachers to boost the representation ability of sentence embeddings.\nExperiments on six STS tasks show that our method outperforms the\nstate-of-the-art sentence embedding methods significantly.", "published": "2021-04-18 01:20:11", "link": "http://arxiv.org/abs/2104.08675v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "From Fully Trained to Fully Random Embeddings: Improving Neural Machine\n  Translation with Compact Word Embedding Tables", "abstract": "Embedding matrices are key components in neural natural language processing\n(NLP) models that are responsible to provide numerical representations of input\ntokens.\\footnote{In this paper words and subwords are referred to as\n\\textit{tokens} and the term \\textit{embedding} only refers to embeddings of\ninputs.} In this paper, we analyze the impact and utility of such matrices in\nthe context of neural machine translation (NMT). We show that detracting\nsyntactic and semantic information from word embeddings and running NMT systems\nwith random embeddings is not as damaging as it initially sounds. We also show\nhow incorporating only a limited amount of task-specific knowledge from\nfully-trained embeddings can boost the performance NMT systems. Our findings\ndemonstrate that in exchange for negligible deterioration in performance, any\nNMT model can be run with partially random embeddings. Working with such\nstructures means a minimal memory requirement as there is no longer need to\nstore large embedding tables, which is a significant gain in industrial and\non-device settings. We evaluated our embeddings in translating {English} into\n{German} and {French} and achieved a $5.3$x compression rate. Despite having a\nconsiderably smaller architecture, our models in some cases are even able to\noutperform state-of-the-art baselines.", "published": "2021-04-18 01:57:38", "link": "http://arxiv.org/abs/2104.08677v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Question Answering Model Robustness with Synthetic Adversarial\n  Data Generation", "abstract": "Despite recent progress, state-of-the-art question answering models remain\nvulnerable to a variety of adversarial attacks. While dynamic adversarial data\ncollection, in which a human annotator tries to write examples that fool a\nmodel-in-the-loop, can improve model robustness, this process is expensive\nwhich limits the scale of the collected data. In this work, we are the first to\nuse synthetic adversarial data generation to make question answering models\nmore robust to human adversaries. We develop a data generation pipeline that\nselects source passages, identifies candidate answers, generates questions,\nthen finally filters or re-labels them to improve quality. Using this approach,\nwe amplify a smaller human-written adversarial dataset to a much larger set of\nsynthetic question-answer pairs. By incorporating our synthetic data, we\nimprove the state-of-the-art on the AdversarialQA dataset by 3.7F1 and improve\nmodel generalisation on nine of the twelve MRQA datasets. We further conduct a\nnovel human-in-the-loop evaluation to show that our models are considerably\nmore robust to new human-written adversarial examples: crowdworkers can fool\nour model only 8.8% of the time on average, compared to 17.6% for a model\ntrained without synthetic data.", "published": "2021-04-18 02:00:06", "link": "http://arxiv.org/abs/2104.08678v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Network Pruning -- under the Pre-train and Fine-tune Paradigm", "abstract": "Transformer-based pre-trained language models have significantly improved the\nperformance of various natural language processing (NLP) tasks in the recent\nyears. While effective and prevalent, these models are usually prohibitively\nlarge for resource-limited deployment scenarios. A thread of research has thus\nbeen working on applying network pruning techniques under the\npretrain-then-finetune paradigm widely adopted in NLP. However, the existing\npruning results on benchmark transformers, such as BERT, are not as remarkable\nas the pruning results in the literature of convolutional neural networks\n(CNNs). In particular, common wisdom in pruning CNN states that sparse pruning\ntechnique compresses a model more than that obtained by reducing number of\nchannels and layers (Elsen et al., 2020; Zhu and Gupta, 2017), while existing\nworks on sparse pruning of BERT yields inferior results than its small-dense\ncounterparts such as TinyBERT (Jiao et al., 2020). In this work, we aim to fill\nthis gap by studying how knowledge are transferred and lost during the\npre-train, fine-tune, and pruning process, and proposing a knowledge-aware\nsparse pruning process that achieves significantly superior results than\nexisting literature. We show for the first time that sparse pruning compresses\na BERT model significantly more than reducing its number of channels and\nlayers. Experiments on multiple data sets of GLUE benchmark show that our\nmethod outperforms the leading competitors with a 20-times weight/FLOPs\ncompression and neglectable loss in prediction accuracy.", "published": "2021-04-18 02:20:37", "link": "http://arxiv.org/abs/2104.08682v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Simple and Effective Positional Encoding for Transformers", "abstract": "Transformer models are permutation equivariant. To supply the order and type\ninformation of the input tokens, position and segment embeddings are usually\nadded to the input. Recent works proposed variations of positional encodings\nwith relative position encodings achieving better performance. Our analysis\nshows that the gain actually comes from moving positional information to\nattention layer from the input. Motivated by this, we introduce Decoupled\nPositional Attention for Transformers (DIET), a simple yet effective mechanism\nto encode position and segment information into the Transformer models. The\nproposed method has faster training and inference time, while achieving\ncompetitive performance on GLUE, XTREME and WMT benchmarks. We further\ngeneralize our method to long-range transformers and show performance gain.", "published": "2021-04-18 03:44:57", "link": "http://arxiv.org/abs/2104.08698v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Token-level Reference-free Hallucination Detection Benchmark for\n  Free-form Text Generation", "abstract": "Large pretrained generative models like GPT-3 often suffer from hallucinating\nnon-existent or incorrect content, which undermines their potential merits in\nreal applications. Existing work usually attempts to detect these\nhallucinations based on a corresponding oracle reference at a sentence or\ndocument level. However ground-truth references may not be readily available\nfor many free-form text generation applications, and sentence- or\ndocument-level detection may fail to provide the fine-grained signals that\nwould prevent fallacious content in real time. As a first step to addressing\nthese issues, we propose a novel token-level, reference-free hallucination\ndetection task and an associated annotated dataset named HaDes (HAllucination\nDEtection dataSet). To create this dataset, we first perturb a large number of\ntext segments extracted from English language Wikipedia, and then verify these\nwith crowd-sourced annotations. To mitigate label imbalance during annotation,\nwe utilize an iterative model-in-loop strategy. We conduct comprehensive data\nanalyses and create multiple baseline models.", "published": "2021-04-18 04:09:48", "link": "http://arxiv.org/abs/2104.08704v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning", "abstract": "Image captioning has conventionally relied on reference-based automatic\nevaluations, where machine captions are compared against captions written by\nhumans. This is in contrast to the reference-free manner in which humans assess\ncaption quality.\n  In this paper, we report the surprising empirical finding that CLIP (Radford\net al., 2021), a cross-modal model pretrained on 400M image+caption pairs from\nthe web, can be used for robust automatic evaluation of image captioning\nwithout the need for references. Experiments spanning several corpora\ndemonstrate that our new reference-free metric, CLIPScore, achieves the highest\ncorrelation with human judgements, outperforming existing reference-based\nmetrics like CIDEr and SPICE. Information gain experiments demonstrate that\nCLIPScore, with its tight focus on image-text compatibility, is complementary\nto existing reference-based metrics that emphasize text-text similarities.\nThus, we also present a reference-augmented version, RefCLIPScore, which\nachieves even higher correlation. Beyond literal description tasks, several\ncase studies reveal domains where CLIPScore performs well (clip-art images,\nalt-text rating), but also where it is relatively weaker in comparison to\nreference-based metrics, e.g., news captions that require richer contextual\nknowledge.", "published": "2021-04-18 05:00:29", "link": "http://arxiv.org/abs/2104.08718v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GooAQ: Open Question Answering with Diverse Answer Types", "abstract": "While day-to-day questions come with a variety of answer types, the current\nquestion-answering (QA) literature has failed to adequately address the answer\ndiversity of questions. To this end, we present GooAQ, a large-scale dataset\nwith a variety of answer types. This dataset contains over 5 million questions\nand 3 million answers collected from Google. GooAQ questions are collected\nsemi-automatically from the Google search engine using its autocomplete\nfeature. This results in naturalistic questions of practical interest that are\nnonetheless short and expressed using simple language. GooAQ answers are mined\nfrom Google's responses to our collected questions, specifically from the\nanswer boxes in the search results. This yields a rich space of answer types,\ncontaining both textual answers (short and long) as well as more structured\nones such as collections. We benchmarkT5 models on GooAQ and observe that: (a)\nin line with recent work, LM's strong performance on GooAQ's short-answer\nquestions heavily benefit from annotated data; however, (b) their quality in\ngenerating coherent and accurate responses for questions requiring long\nresponses (such as 'how' and 'why' questions) is less reliant on observing\nannotated data and mainly supported by their pre-training. We release GooAQ to\nfacilitate further research on improving QA with diverse response types.", "published": "2021-04-18 05:40:39", "link": "http://arxiv.org/abs/2104.08727v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Deep Keyphrase Generation", "abstract": "Keyphrase generation aims to summarize long documents with a collection of\nsalient phrases. Deep neural models have demonstrated a remarkable success in\nthis task, capable of predicting keyphrases that are even absent from a\ndocument. However, such abstractiveness is acquired at the expense of a\nsubstantial amount of annotated data. In this paper, we present a novel method\nfor keyphrase generation, AutoKeyGen, without the supervision of any human\nannotation. Motivated by the observation that an absent keyphrase in one\ndocument can appear in other places, in whole or in part, we first construct a\nphrase bank by pooling all phrases in a corpus. With this phrase bank, we then\ndraw candidate absent keyphrases for each document through a partial matching\nprocess. To rank both types of candidates, we combine their lexical- and\nsemantic-level similarities to the input document. Moreover, we utilize these\ntop-ranked candidates as to train a deep generative model for more absent\nkeyphrases. Extensive experiments demonstrate that AutoKeyGen outperforms all\nunsupervised baselines and can even beat strong supervised methods in certain\ncases.", "published": "2021-04-18 05:53:19", "link": "http://arxiv.org/abs/2104.08729v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can NLI Models Verify QA Systems' Predictions?", "abstract": "To build robust question answering systems, we need the ability to verify\nwhether answers to questions are truly correct, not just \"good enough\" in the\ncontext of imperfect QA datasets. We explore the use of natural language\ninference (NLI) as a way to achieve this goal, as NLI inherently requires the\npremise (document context) to contain all necessary information to support the\nhypothesis (proposed answer to the question). We leverage large pre-trained\nmodels and recent prior datasets to construct powerful question converter and\ndecontextualization modules, which can reformulate QA instances as\npremise-hypothesis pairs with very high reliability. Then, by combining\nstandard NLI datasets with NLI examples automatically derived from QA training\ndata, we can train NLI models to judge the correctness of QA models' proposed\nanswers. We show that our NLI approach can generally improve the confidence\nestimation of a QA model across different domains, evaluated in a selective QA\nsetting. Careful manual analysis over the predictions of our NLI model shows\nthat it can further identify cases where the QA model produces the right answer\nfor the wrong reason, or where the answer cannot be verified as addressing all\naspects of the question.", "published": "2021-04-18 06:03:07", "link": "http://arxiv.org/abs/2104.08731v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean\n  Crawled Corpus", "abstract": "Large language models have led to remarkable progress on many NLP tasks, and\nresearchers are turning to ever-larger text corpora to train them. Some of the\nlargest corpora available are made by scraping significant portions of the\ninternet, and are frequently introduced with only minimal documentation. In\nthis work we provide some of the first documentation for the Colossal Clean\nCrawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set\nof filters to a single snapshot of Common Crawl. We begin by investigating\nwhere the data came from, and find a significant amount of text from unexpected\nsources like patents and US military websites. Then we explore the content of\nthe text itself, and find machine-generated text (e.g., from machine\ntranslation systems) and evaluation examples from other benchmark NLP datasets.\nTo understand the impact of the filters applied to create this dataset, we\nevaluate the text that was removed, and show that blocklist filtering\ndisproportionately removes text from and about minority individuals. Finally,\nwe conclude with some recommendations for how to created and document web-scale\ndatasets from a scrape of the internet.", "published": "2021-04-18 07:42:52", "link": "http://arxiv.org/abs/2104.08758v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Making Attention Mechanisms More Robust and Interpretable with Virtual\n  Adversarial Training", "abstract": "Although attention mechanisms have become fundamental components of deep\nlearning models, they are vulnerable to perturbations, which may degrade the\nprediction performance and model interpretability. Adversarial training (AT)\nfor attention mechanisms has successfully reduced such drawbacks by considering\nadversarial perturbations. However, this technique requires label information,\nand thus, its use is limited to supervised settings. In this study, we explore\nthe concept of incorporating virtual AT (VAT) into the attention mechanisms, by\nwhich adversarial perturbations can be computed even from unlabeled data. To\nrealize this approach, we propose two general training techniques, namely VAT\nfor attention mechanisms (Attention VAT) and \"interpretable\" VAT for attention\nmechanisms (Attention iVAT), which extend AT for attention mechanisms to a\nsemi-supervised setting. In particular, Attention iVAT focuses on the\ndifferences in attention; thus, it can efficiently learn clearer attention and\nimprove model interpretability, even with unlabeled data. Empirical experiments\nbased on six public datasets revealed that our techniques provide better\nprediction performance than conventional AT-based as well as VAT-based\ntechniques, and stronger agreement with evidence that is provided by humans in\ndetecting important words in sentences. Moreover, our proposal offers these\nadvantages without needing to add the careful selection of unlabeled data. That\nis, even if the model using our VAT-based technique is trained on unlabeled\ndata from a source other than the target task, both the prediction performance\nand model interpretability can be improved.", "published": "2021-04-18 07:51:45", "link": "http://arxiv.org/abs/2104.08763v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Variational Weakly Supervised Sentiment Analysis with Posterior\n  Regularization", "abstract": "Sentiment analysis is an important task in natural language processing (NLP).\nMost of existing state-of-the-art methods are under the supervised learning\nparadigm. However, human annotations can be scarce. Thus, we should leverage\nmore weak supervision for sentiment analysis. In this paper, we propose a\nposterior regularization framework for the variational approach to the weakly\nsupervised sentiment analysis to better control the posterior distribution of\nthe label assignment. The intuition behind the posterior regularization is that\nif extracted opinion words from two documents are semantically similar, the\nposterior distributions of two documents should be similar. Our experimental\nresults show that the posterior regularization can improve the original\nvariational approach to the weakly supervised sentiment analysis and the\nperformance is more stable with smaller prediction variance.", "published": "2021-04-18 09:05:31", "link": "http://arxiv.org/abs/2104.08779v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming\n  Few-Shot Prompt Order Sensitivity", "abstract": "When primed with only a handful of training samples, very large, pretrained\nlanguage models such as GPT-3 have shown competitive results when compared to\nfully-supervised, fine-tuned, large, pretrained language models. We demonstrate\nthat the order in which the samples are provided can make the difference\nbetween near state-of-the-art and random guess performance: essentially some\npermutations are \"fantastic\" and some not. We analyse this phenomenon in\ndetail, establishing that: it is present across model sizes (even for the\nlargest current models), it is not related to a specific subset of samples, and\nthat a given good permutation for one model is not transferable to another.\nWhile one could use a development set to determine which permutations are\nperformant, this would deviate from the true few-shot setting as it requires\nadditional annotated data. Instead, we use the generative nature of language\nmodels to construct an artificial development set and based on entropy\nstatistics of the candidate permutations on this set, we identify performant\nprompts. Our method yields a 13% relative improvement for GPT-family models\nacross eleven different established text classification tasks.", "published": "2021-04-18 09:29:16", "link": "http://arxiv.org/abs/2104.08786v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Human-Imitating Metrics for Training and Evaluating Privacy Preserving\n  Emotion Recognition Models Using Sociolinguistic Knowledge", "abstract": "Privacy preservation is a crucial component of any real-world application.\nBut, in applications relying on machine learning backends, privacy is\nchallenging because models often capture more than what the model was initially\ntrained for, resulting in the potential leakage of sensitive information. In\nthis paper, we propose an automatic and quantifiable metric that allows us to\nevaluate humans' perception of a model's ability to preserve privacy with\nrespect to sensitive variables. In this paper, we focus on saliency-based\nexplanations, explanations that highlight regions of the input text, to infer\ninternal workings of a black box model. We use the degree with which\ndifferences in interpretation of general vs privacy preserving models correlate\nwith sociolinguistic biases to inform metric design. We show how certain\ncommonly-used methods that seek to preserve privacy do not align with human\nperception of privacy preservation leading to distrust about model's claims. We\ndemonstrate the versatility of our proposed metric by validating its utility\nfor measuring cross corpus generalization for both privacy and emotion.\nFinally, we conduct crowdsourcing experiments to evaluate the inclination of\nthe evaluators to choose a particular model for a given purpose when model\nexplanations are provided, and show a positive relationship with the proposed\nmetric. To the best of our knowledge, we take the first step in proposing\nautomatic and quantifiable metrics that best align with human perception of\nmodel's ability for privacy preservation, allowing for cost-effective model\ndevelopment.", "published": "2021-04-18 09:56:41", "link": "http://arxiv.org/abs/2104.08792v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Human Schema Curation via Causal Association Rule Mining", "abstract": "Event schemas are structured knowledge sources defining typical real-world\nscenarios (e.g., going to an airport). We present a framework for efficient\nhuman-in-the-loop construction of a schema library, based on a novel script\ninduction system and a well-crafted interface that allows non-experts to\n\"program\" complex event structures. Associated with this work we release a\nschema library: a machine readable resource of 232 detailed event schemas, each\nof which describe a distinct typical scenario in terms of its relevant\nsub-event structure (what happens in the scenario), participants (who plays a\nrole in the scenario), fine-grained typing of each participant, and the implied\nrelational constraints between them. We make our schema library and the\nSchemaBlocks interface available online.", "published": "2021-04-18 10:48:26", "link": "http://arxiv.org/abs/2104.08811v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings", "abstract": "This paper presents SimCSE, a simple contrastive learning framework that\ngreatly advances state-of-the-art sentence embeddings. We first describe an\nunsupervised approach, which takes an input sentence and predicts itself in a\ncontrastive objective, with only standard dropout used as noise. This simple\nmethod works surprisingly well, performing on par with previous supervised\ncounterparts. We find that dropout acts as minimal data augmentation, and\nremoving it leads to a representation collapse. Then, we propose a supervised\napproach, which incorporates annotated pairs from natural language inference\ndatasets into our contrastive learning framework by using \"entailment\" pairs as\npositives and \"contradiction\" pairs as hard negatives. We evaluate SimCSE on\nstandard semantic textual similarity (STS) tasks, and our unsupervised and\nsupervised models using BERT base achieve an average of 76.3% and 81.6%\nSpearman's correlation respectively, a 4.2% and 2.2% improvement compared to\nthe previous best results. We also show -- both theoretically and empirically\n-- that the contrastive learning objective regularizes pre-trained embeddings'\nanisotropic space to be more uniform, and it better aligns positive pairs when\nsupervised signals are available.", "published": "2021-04-18 11:27:08", "link": "http://arxiv.org/abs/2104.08821v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Flexible Generation of Natural Language Deductions", "abstract": "An interpretable system for open-domain reasoning needs to express its\nreasoning process in a transparent form. Natural language is an attractive\nrepresentation for this purpose -- it is both highly expressive and easy for\nhumans to understand. However, manipulating natural language statements in\nlogically consistent ways is hard: models must cope with variation in how\nmeaning is expressed while remaining precise. In this paper, we describe\nParaPattern, a method for building models to generate deductive inferences from\ndiverse natural language inputs without direct human supervision. We train\nBART-based models (Lewis et al., 2020) to generate the result of applying a\nparticular logical operation to one or more premise statements. Crucially, we\ndevelop a largely automated pipeline for constructing suitable training\nexamples from Wikipedia. We evaluate our models using out-of-domain sentence\ncompositions from the QASC (Khot et al., 2020) and EntailmentBank (Dalvi et\nal., 2021) datasets as well as targeted perturbation sets. Our results show\nthat our models are substantially more accurate and flexible than baseline\nsystems. ParaPattern achieves 85% validity on examples of the 'substitution'\noperation from EntailmentBank without the use of any in-domain training data,\nmatching the performance of a model fine-tuned for EntailmentBank. The full\nsource code for our method is publicly available.", "published": "2021-04-18 11:36:26", "link": "http://arxiv.org/abs/2104.08825v2", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.3"], "primary_category": "cs.CL"}
{"title": "GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation", "abstract": "Large-scale language models such as GPT-3 are excellent few-shot learners,\nallowing them to be controlled via natural text prompts. Recent studies report\nthat prompt-based direct classification eliminates the need for fine-tuning but\nlacks data and inference scalability. This paper proposes a novel data\naugmentation technique that leverages large-scale language models to generate\nrealistic text samples from a mixture of real samples. We also propose\nutilizing soft-labels predicted by the language models, effectively distilling\nknowledge from the large-scale language models and creating textual\nperturbations simultaneously. We perform data augmentation experiments on\ndiverse classification tasks and show that our method hugely outperforms\nexisting text augmentation methods. Ablation studies and a qualitative analysis\nprovide more insights into our approach.", "published": "2021-04-18 11:39:33", "link": "http://arxiv.org/abs/2104.08826v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in\n  NLP", "abstract": "Humans can learn a new language task efficiently with only few examples, by\nleveraging their knowledge obtained when learning prior tasks. In this paper,\nwe explore whether and how such cross-task generalization ability can be\nacquired, and further applied to build better few-shot learners across diverse\nNLP tasks. We introduce CrossFit, a problem setup for studying cross-task\ngeneralization ability, which standardizes seen/unseen task partitions, data\naccess during different learning stages, and the evaluation protocols. To\ninstantiate different seen/unseen task partitions in CrossFit and facilitate\nin-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse\nfew-shot NLP tasks created from open-access NLP datasets and converted to a\nunified text-to-text format. Our analysis reveals that the few-shot learning\nability on unseen tasks can be improved via an upstream learning stage using a\nset of seen tasks. We also observe that the selection of upstream learning\ntasks can significantly influence few-shot performance on unseen tasks, asking\nfurther analysis on task similarity and transferability.", "published": "2021-04-18 12:14:46", "link": "http://arxiv.org/abs/2104.08835v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Influence of Masking Policies in Intermediate Pre-training", "abstract": "Current NLP models are predominantly trained through a two-stage \"pre-train\nthen fine-tune\" pipeline. Prior work has shown that inserting an intermediate\npre-training stage, using heuristic masking policies for masked language\nmodeling (MLM), can significantly improve final performance. However, it is\nstill unclear (1) in what cases such intermediate pre-training is helpful, (2)\nwhether hand-crafted heuristic objectives are optimal for a given task, and (3)\nwhether a masking policy designed for one task is generalizable beyond that\ntask. In this paper, we perform a large-scale empirical study to investigate\nthe effect of various masking policies in intermediate pre-training with nine\nselected tasks across three categories. Crucially, we introduce methods to\nautomate the discovery of optimal masking policies via direct supervision or\nmeta-learning. We conclude that the success of intermediate pre-training is\ndependent on appropriate pre-train corpus, selection of output format (i.e.,\nmasked spans or full sentence), and clear understanding of the role that MLM\nplays for the downstream task. In addition, we find our learned masking\npolicies outperform the heuristic of masking named entities on TriviaQA, and\npolicies learned from one task can positively transfer to other tasks in\ncertain cases, inviting future research in this direction.", "published": "2021-04-18 12:32:23", "link": "http://arxiv.org/abs/2104.08840v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Anchored Information-Extraction for Domain-Specific\n  Insights", "abstract": "The growing quantity and complexity of data pose challenges for humans to\nconsume information and respond in a timely manner. For businesses in domains\nwith rapidly changing rules and regulations, failure to identify changes can be\ncostly. In contrast to expert analysis or the development of domain-specific\nontology and taxonomies, we use a task-based approach for fulfilling specific\ninformation needs within a new domain. Specifically, we propose to extract\ntask-based information from incoming instance data. A pipeline constructed of\nstate of the art NLP technologies, including a bi-LSTM-CRF model for entity\nextraction, attention-based deep Semantic Role Labeling, and an automated\nverb-based relationship extractor, is used to automatically extract an instance\nlevel semantic structure. Each instance is then combined with a larger,\ndomain-specific knowledge graph to produce new and timely insights. Preliminary\nresults, validated manually, show the methodology to be effective for\nextracting specific information to complete end use-cases.", "published": "2021-04-18 19:28:10", "link": "http://arxiv.org/abs/2104.08936v2", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "A recipe for annotating grounded clarifications", "abstract": "In order to interpret the communicative intents of an utterance, it needs to\nbe grounded in something that is outside of language; that is, grounded in\nworld modalities. In this paper, we argue that dialogue clarification\nmechanisms make explicit the process of interpreting the communicative intents\nof the speaker's utterances by grounding them in the various modalities in\nwhich the dialogue is situated. This paper frames dialogue clarification\nmechanisms as an understudied research problem and a key missing piece in the\ngiant jigsaw puzzle of natural language understanding. We discuss both the\ntheoretical background and practical challenges posed by this problem and\npropose a recipe for obtaining grounding annotations. We conclude by\nhighlighting ethical issues that need to be addressed in future work.", "published": "2021-04-18 21:47:48", "link": "http://arxiv.org/abs/2104.08964v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Clustering with Measure Propagation", "abstract": "Deep models have improved state-of-the-art for both supervised and\nunsupervised learning. For example, deep embedded clustering (DEC) has greatly\nimproved the unsupervised clustering performance, by using stacked autoencoders\nfor representation learning. However, one weakness of deep modeling is that the\nlocal neighborhood structure in the original space is not necessarily preserved\nin the latent space. To preserve local geometry, various methods have been\nproposed in the supervised and semi-supervised learning literature (e.g.,\nspectral clustering and label propagation) using graph Laplacian\nregularization. In this paper, we combine the strength of deep representation\nlearning with measure propagation (MP), a KL-divergence based graph\nregularization method originally used in the semi-supervised scenario. The main\nassumption of MP is that if two data points are close in the original space,\nthey are likely to belong to the same class, measured by KL-divergence of class\nmembership distribution. By taking the same assumption in the unsupervised\nlearning scenario, we propose our Deep Embedded Clustering Aided by Measure\nPropagation (DECAMP) model. We evaluate DECAMP on short text clustering tasks.\nOn three public datasets, DECAMP performs competitively with other\nstate-of-the-art baselines, including baselines using additional data to\ngenerate word embeddings used in the clustering process. As an example, on the\nStackoverflow dataset, DECAMP achieved a clustering accuracy of 79%, which is\nabout 5% higher than all existing baselines. These empirical results suggest\nthat DECAMP is a very effective method for unsupervised learning.", "published": "2021-04-18 22:02:43", "link": "http://arxiv.org/abs/2104.08967v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Distributed NLI: Learning to Predict Human Opinion Distributions for\n  Language Reasoning", "abstract": "We introduce distributed NLI, a new NLU task with a goal to predict the\ndistribution of human judgements for natural language inference. We show that\nby applying additional distribution estimation methods, namely, Monte Carlo\n(MC) Dropout, Deep Ensemble, Re-Calibration, and Distribution Distillation,\nmodels can capture human judgement distribution more effectively than the\nsoftmax baseline. We show that MC Dropout is able to achieve decent performance\nwithout any distribution annotations while Re-Calibration can give further\nimprovements with extra distribution annotations, suggesting the value of\nmultiple annotations for one example in modeling the distribution of human\njudgements. Despite these improvements, the best results are still far below\nthe estimated human upper-bound, indicating that predicting the distribution of\nhuman judgements is still an open, challenging problem with a large room for\nimprovements. We showcase the common errors for MC Dropout and Re-Calibration.\nFinally, we give guidelines on the usage of these methods with different levels\nof data availability and encourage future work on modeling the human opinion\ndistribution for language reasoning. Our code and data are publicly available\nat https://github.com/easonnie/ChaosNLI", "published": "2021-04-18 01:25:19", "link": "http://arxiv.org/abs/2104.08676v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Linguistic Dependencies and Statistical Dependence", "abstract": "Are pairs of words that tend to occur together also likely to stand in a\nlinguistic dependency? This empirical question is motivated by a long history\nof literature in cognitive science, psycholinguistics, and NLP. In this work we\ncontribute an extensive analysis of the relationship between linguistic\ndependencies and statistical dependence between words. Improving on previous\nwork, we introduce the use of large pretrained language models to compute\ncontextualized estimates of the pointwise mutual information between words\n(CPMI). For multiple models and languages, we extract dependency trees which\nmaximize CPMI, and compare to gold standard linguistic dependencies. Overall,\nwe find that CPMI dependencies achieve an unlabelled undirected attachment\nscore of at most $\\approx 0.5$. While far above chance, and consistently above\na non-contextualized PMI baseline, this score is generally comparable to a\nsimple baseline formed by connecting adjacent words. We analyze which kinds of\nlinguistic dependencies are best captured in CPMI dependencies, and also find\nmarked differences between the estimates of the large pretrained language\nmodels, illustrating how their different training schemes affect the type of\ndependencies they capture.", "published": "2021-04-18 02:43:37", "link": "http://arxiv.org/abs/2104.08685v3", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Low-Rank Subspaces for Unsupervised Entity Linking", "abstract": "Entity linking is an important problem with many applications. Most previous\nsolutions were designed for settings where annotated training data is\navailable, which is, however, not the case in numerous domains. We propose a\nlight-weight and scalable entity linking method, Eigenthemes, that relies\nsolely on the availability of entity names and a referent knowledge base.\nEigenthemes exploits the fact that the entities that are truly mentioned in a\ndocument (the \"gold entities\") tend to form a semantically dense subset of the\nset of all candidate entities in the document. Geometrically speaking, when\nrepresenting entities as vectors via some given embedding, the gold entities\ntend to lie in a low-rank subspace of the full embedding space. Eigenthemes\nidentifies this subspace using the singular value decomposition and scores\ncandidate entities according to their proximity to the subspace. On the\nempirical front, we introduce multiple strong baselines that compare favorably\nto (and sometimes even outperform) the existing state of the art. Extensive\nexperiments on benchmark datasets from a variety of real-world domains showcase\nthe effectiveness of our approach.", "published": "2021-04-18 06:24:48", "link": "http://arxiv.org/abs/2104.08737v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DCH-2: A Parallel Customer-Helpdesk Dialogue Corpus with Distributions\n  of Annotators' Labels", "abstract": "We introduce a data set called DCH-2, which contains 4,390 real\ncustomer-helpdesk dialogues in Chinese and their English translations. DCH-2\nalso contains dialogue-level annotations and turn-level annotations obtained\nindependently from either 19 or 20 annotators. The data set was built through\nour effort as organisers of the NTCIR-14 Short Text Conversation and NTCIR-15\nDialogue Evaluation tasks, to help researchers understand what constitutes an\neffective customer-helpdesk dialogue, and thereby build efficient and helpful\nhelpdesk systems that are available to customers at all times. In addition,\nDCH-2 may be utilised for other purposes, for example, as a repository for\nretrieval-based dialogue systems, or as a parallel corpus for machine\ntranslation in the helpdesk domain.", "published": "2021-04-18 07:35:15", "link": "http://arxiv.org/abs/2104.08755v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Case-based Reasoning for Natural Language Queries over Knowledge Bases", "abstract": "It is often challenging to solve a complex problem from scratch, but much\neasier if we can access other similar problems with their solutions -- a\nparadigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR\napproach (CBR-KBQA) for question answering over large knowledge bases. CBR-KBQA\nconsists of a nonparametric memory that stores cases (question and logical\nforms) and a parametric model that can generate a logical form for a new\nquestion by retrieving cases that are relevant to it. On several KBQA datasets\nthat contain complex questions, CBR-KBQA achieves competitive performance. For\nexample, on the ComplexWebQuestions dataset, CBR-KBQA outperforms the current\nstate of the art by 11\\% on accuracy. Furthermore, we show that CBR-KBQA is\ncapable of using new cases \\emph{without} any further training: by\nincorporating a few human-labeled examples in the case memory, CBR-KBQA is able\nto successfully generate logical forms containing unseen KB entities as well as\nrelations.", "published": "2021-04-18 07:50:31", "link": "http://arxiv.org/abs/2104.08762v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Cross-Task Generalization via Natural Language Crowdsourcing\n  Instructions", "abstract": "Humans (e.g., crowdworkers) have a remarkable ability in solving different\ntasks, by simply reading textual instructions that define them and looking at a\nfew examples. Despite the success of the conventional supervised learning on\nindividual datasets, such models often struggle with generalization across\ntasks (e.g., a question-answering system cannot solve classification tasks). A\nlong-standing challenge in AI is to build a model that learns a new task by\nunderstanding the human-readable instructions that define it. To study this, we\nintroduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their\nhuman-authored instructions, and 193k task instances (input-output pairs). The\ninstructions are obtained from crowdsourcing instructions used to create\nexisting NLP datasets and mapped to a unified schema. Using this meta-dataset,\nwe measure cross-task generalization by training models on seen tasks and\nmeasuring generalization to the remaining unseen ones. We adopt generative\npre-trained language models to encode task-specific instructions along with\ninput and generate task output. Our results indicate that models benefit from\ninstructions when evaluated in terms of generalization to unseen tasks (19%\nbetter for models utilizing instructions). These models, however, are far\nbehind an estimated performance upperbound indicating significant room for more\nprogress in this direction.", "published": "2021-04-18 08:44:56", "link": "http://arxiv.org/abs/2104.08773v4", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamically Addressing Unseen Rumor via Continual Learning", "abstract": "Rumors are often associated with newly emerging events, thus, an ability to\ndeal with unseen rumors is crucial for a rumor veracity classification model.\nPrevious works address this issue by improving the model's generalizability,\nwith an assumption that the model will stay unchanged even after the new\noutbreak of an event. In this work, we propose an alternative solution to\ncontinuously update the model in accordance with the dynamics of rumor domain\ncreations. The biggest technical challenge associated with this new approach is\nthe catastrophic forgetting of previous learnings due to new learnings. We\nadopt continual learning strategies that control the new learnings to avoid\ncatastrophic forgetting and propose an additional strategy that can jointly be\nused to strengthen the forgetting alleviation.", "published": "2021-04-18 08:50:10", "link": "http://arxiv.org/abs/2104.08775v1", "categories": ["cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.AI"}
{"title": "SalKG: Learning From Knowledge Graph Explanations for Commonsense\n  Reasoning", "abstract": "Augmenting pre-trained language models with knowledge graphs (KGs) has\nachieved success on various commonsense reasoning tasks. However, for a given\ntask instance, the KG, or certain parts of the KG, may not be useful. Although\nKG-augmented models often use attention to focus on specific KG components, the\nKG is still always used, and the attention mechanism is never explicitly taught\nwhich KG components should be used. Meanwhile, saliency methods can measure how\nmuch a KG feature (e.g., graph, node, path) influences the model to make the\ncorrect prediction, thus explaining which KG features are useful. This paper\nexplores how saliency explanations can be used to improve KG-augmented models'\nperformance. First, we propose to create coarse (Is the KG useful?) and fine\n(Which nodes/paths in the KG are useful?) saliency explanations. Second, to\nmotivate saliency-based supervision, we analyze oracle KG-augmented models\nwhich directly use saliency explanations as extra inputs for guiding their\nattention. Third, we propose SalKG, a framework for KG-augmented models to\nlearn from coarse and/or fine saliency explanations. Given saliency\nexplanations created from a task's training set, SalKG jointly trains the model\nto predict the explanations, then solve the task by attending to KG features\nhighlighted by the predicted explanations. On three commonsense QA benchmarks\n(CSQA, OBQA, CODAH) and a range of KG-augmented models, we show that SalKG can\nyield considerable performance gains -- up to 2.76% absolute improvement on\nCSQA.", "published": "2021-04-18 09:59:46", "link": "http://arxiv.org/abs/2104.08793v5", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Back-Training excels Self-Training at Unsupervised Domain Adaptation of\n  Question Generation and Passage Retrieval", "abstract": "In this work, we introduce back-training, an alternative to self-training for\nunsupervised domain adaptation (UDA) from source to target domain. While\nself-training generates synthetic training data where natural inputs are\naligned with noisy outputs, back-training results in natural outputs aligned\nwith noisy inputs. This significantly reduces the gap between the target domain\nand synthetic data distribution, and reduces model overfitting to the source\ndomain. We run UDA experiments on question generation and passage retrieval\nfrom the \\textit{Natural Questions} domain to machine learning and biomedical\ndomains. We find that back-training vastly outperforms self-training by a mean\nimprovement of 7.8 BLEU-4 points on generation, and 17.6\\% top-20 retrieval\naccuracy across both domains. We further propose consistency filters to remove\nlow-quality synthetic data before training. We also release a new\ndomain-adaptation dataset- \\textit{MLQuestions} containing 35K unaligned\nquestions, 50K unaligned passages, and 3K aligned question-passage pairs.", "published": "2021-04-18 10:20:07", "link": "http://arxiv.org/abs/2104.08801v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Consistent Accelerated Inference via Confident Adaptive Transformers", "abstract": "We develop a novel approach for confidently accelerating inference in the\nlarge and expensive multilayer Transformers that are now ubiquitous in natural\nlanguage processing (NLP). Amortized or approximate computational methods\nincrease efficiency, but can come with unpredictable performance costs. In this\nwork, we present CATs -- Confident Adaptive Transformers -- in which we\nsimultaneously increase computational efficiency, while guaranteeing a\nspecifiable degree of consistency with the original model with high confidence.\nOur method trains additional prediction heads on top of intermediate layers,\nand dynamically decides when to stop allocating computational effort to each\ninput using a meta consistency classifier. To calibrate our early prediction\nstopping rule, we formulate a unique extension of conformal prediction. We\ndemonstrate the effectiveness of this approach on four classification and\nregression tasks.", "published": "2021-04-18 10:22:28", "link": "http://arxiv.org/abs/2104.08803v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multilingual Knowledge Graph Completion with Joint Relation and Entity\n  Alignment", "abstract": "Knowledge Graph Completion (KGC) predicts missing facts in an incomplete\nKnowledge Graph. Almost all of existing KGC research is applicable to only one\nKG at a time, and in one language only. However, different language speakers\nmay maintain separate KGs in their language and no individual KG is expected to\nbe complete. Moreover, common entities or relations in these KGs have different\nsurface forms and IDs, leading to ID proliferation. Entity alignment (EA) and\nrelation alignment (RA) tasks resolve this by recognizing pairs of entity\n(relation) IDs in different KGs that represent the same entity (relation). This\ncan further help prediction of missing facts, since knowledge from one KG is\nlikely to benefit completion of another. High confidence predictions may also\nadd valuable information for the alignment tasks. In response, we study the\nnovel task of jointly training multilingual KGC, relation alignment and entity\nalignment models. We present ALIGNKGC, which uses some seed alignments to\njointly optimize all three of KGC, EA and RA losses. A key component of\nALIGNKGC is an embedding based soft notion of asymmetric overlap defined on the\n(subject, object) set signatures of relations this aids in better predicting\nrelations that are equivalent to or implied by other relations. Extensive\nexperiments with DBPedia in five languages establish the benefits of joint\ntraining for all tasks, achieving 10-32 MRR improvements of ALIGNKGC over a\nstrong state-of-the-art single-KGC system completion model over each\nmonolingual KG . Further, ALIGNKGC achieves reasonable gains in EA and RA tasks\nover a vanilla completion model over a KG that combines all facts without\nalignment, underscoring the value of joint training for these tasks.", "published": "2021-04-18 10:27:44", "link": "http://arxiv.org/abs/2104.08804v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SciCo: Hierarchical Cross-Document Coreference for Scientific Concepts", "abstract": "Determining coreference of concept mentions across multiple documents is a\nfundamental task in natural language understanding. Previous work on\ncross-document coreference resolution (CDCR) typically considers mentions of\nevents in the news, which seldom involve abstract technical concepts that are\nprevalent in science and technology. These complex concepts take diverse or\nambiguous forms and have many hierarchical levels of granularity (e.g., tasks\nand subtasks), posing challenges for CDCR. We present a new task of\nHierarchical CDCR (H-CDCR) with the goal of jointly inferring coreference\nclusters and hierarchy between them. We create SciCo, an expert-annotated\ndataset for H-CDCR in scientific papers, 3X larger than the prominent ECB+\nresource. We study strong baseline models that we customize for H-CDCR, and\nhighlight challenges for future work.", "published": "2021-04-18 10:42:20", "link": "http://arxiv.org/abs/2104.08809v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FedNLP: Benchmarking Federated Learning Methods for Natural Language\n  Processing Tasks", "abstract": "Increasing concerns and regulations about data privacy and sparsity\nnecessitate the study of privacy-preserving, decentralized learning methods for\nnatural language processing (NLP) tasks. Federated learning (FL) provides\npromising approaches for a large number of clients (e.g., personal devices or\norganizations) to collaboratively learn a shared global model to benefit all\nclients while allowing users to keep their data locally. Despite interest in\nstudying FL methods for NLP tasks, a systematic comparison and analysis is\nlacking in the literature. Herein, we present the FedNLP, a benchmarking\nframework for evaluating federated learning methods on four different task\nformulations: text classification, sequence tagging, question answering, and\nseq2seq. We propose a universal interface between Transformer-based language\nmodels (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under\nvarious non-IID partitioning strategies. Our extensive experiments with FedNLP\nprovide empirical comparisons between FL methods and helps us better understand\nthe inherent challenges of this direction. The comprehensive analysis points to\nintriguing and exciting future research aimed at developing FL methods for NLP\ntasks.", "published": "2021-04-18 11:04:49", "link": "http://arxiv.org/abs/2104.08815v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modeling Ideological Salience and Framing in Polarized Online Groups\n  with Graph Neural Networks and Structured Sparsity", "abstract": "The increasing polarization of online political discourse calls for\ncomputational tools that automatically detect and monitor ideological divides\nin social media. We introduce a minimally supervised method that leverages the\nnetwork structure of online discussion forums, specifically Reddit, to detect\npolarized concepts. We model polarization along the dimensions of salience and\nframing, drawing upon insights from moral psychology. Our architecture combines\ngraph neural networks with structured sparsity learning and results in\nrepresentations for concepts and subreddits that capture temporal ideological\ndynamics such as right-wing and left-wing radicalization.", "published": "2021-04-18 11:48:25", "link": "http://arxiv.org/abs/2104.08829v3", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Group-Sparse Matrix Factorization for Transfer Learning of Word\n  Embeddings", "abstract": "Unstructured text provides decision-makers with a rich data source in many\ndomains, ranging from product reviews in retail to nursing notes in healthcare.\nTo leverage this information, words are typically translated into word\nembeddings -- vectors that encode the semantic relationships between words --\nthrough unsupervised learning algorithms such as matrix factorization. However,\nlearning word embeddings from new domains with limited training data can be\nchallenging, because the meaning/usage may be different in the new domain,\ne.g., the word ``positive'' typically has positive sentiment, but often has\nnegative sentiment in medical notes since it may imply that a patient tested\npositive for a disease. In practice, we expect that only a small number of\ndomain-specific words may have new meanings. We propose an intuitive two-stage\nestimator that exploits this structure via a group-sparse penalty to\nefficiently transfer learn domain-specific word embeddings by combining\nlarge-scale text corpora (such as Wikipedia) with limited domain-specific text\ndata. We bound the generalization error of our transfer learning estimator,\nproving that it can achieve high accuracy with substantially less\ndomain-specific data when only a small number of embeddings are altered between\ndomains. Furthermore, we prove that all local minima identified by our\nnonconvex objective function are statistically indistinguishable from the\nglobal minimum under standard regularization conditions, implying that our\nestimator can be computed efficiently. Our results provide the first bounds on\ngroup-sparse matrix factorization, which may be of independent interest. We\nempirically evaluate our approach compared to state-of-the-art fine-tuning\nheuristics from natural language processing.", "published": "2021-04-18 18:19:03", "link": "http://arxiv.org/abs/2104.08928v3", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Attention-based Clinical Note Summarization", "abstract": "In recent years, the trend of deploying digital systems in numerous\nindustries has hiked. The health sector has observed an extensive adoption of\ndigital systems and services that generate significant medical records.\nElectronic health records contain valuable information for prospective and\nretrospective analysis that is often not entirely exploited because of the\ncomplicated dense information storage. The crude purpose of condensing health\nrecords is to select the information that holds most characteristics of the\noriginal documents based on a reported disease. These summaries may boost\ndiagnosis and save a doctor's time during a saturated workload situation like\nthe COVID-19 pandemic. In this paper, we are applying a multi-head\nattention-based mechanism to perform extractive summarization of meaningful\nphrases on clinical notes. Our method finds major sentences for a summary by\ncorrelating tokens, segments, and positional embeddings of sentences in a\nclinical note. The model outputs attention scores that are statistically\ntransformed to extract critical phrases for visualization on the heat-mapping\ntool and for human use.", "published": "2021-04-18 19:40:26", "link": "http://arxiv.org/abs/2104.08942v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reference-based Weak Supervision for Answer Sentence Selection using Web\n  Data", "abstract": "Answer sentence selection (AS2) modeling requires annotated data, i.e.,\nhand-labeled question-answer pairs. We present a strategy to collect weakly\nsupervised answers for a question based on its reference to improve AS2\nmodeling. Specifically, we introduce Reference-based Weak Supervision (RWS), a\nfully automatic large-scale data pipeline that harvests high-quality\nweakly-supervised answers from abundant Web data requiring only a\nquestion-reference pair as input. We study the efficacy and robustness of RWS\nin the setting of TANDA, a recent state-of-the-art fine-tuning approach\nspecialized for AS2. Our experiments indicate that the produced data\nconsistently bolsters TANDA. We achieve the state of the art in terms of P@1,\n90.1%, and MAP, 92.9%, on WikiQA.", "published": "2021-04-18 19:41:17", "link": "http://arxiv.org/abs/2104.08943v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On the Use of Context for Predicting Citation Worthiness of Sentences in\n  Scholarly Articles", "abstract": "In this paper, we study the importance of context in predicting the citation\nworthiness of sentences in scholarly articles. We formulate this problem as a\nsequence labeling task solved using a hierarchical BiLSTM model. We contribute\na new benchmark dataset containing over two million sentences and their\ncorresponding labels. We preserve the sentence order in this dataset and\nperform document-level train/test splits, which importantly allows\nincorporating contextual information in the modeling process. We evaluate the\nproposed approach on three benchmark datasets. Our results quantify the\nbenefits of using context and contextual embeddings for citation worthiness.\nLastly, through error analysis, we provide insights into cases where context\nplays an essential role in predicting citation worthiness.", "published": "2021-04-18 21:47:30", "link": "http://arxiv.org/abs/2104.08962v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Best Practices for Noise-Based Augmentation to Improve the Performance\n  of Deployable Speech-Based Emotion Recognition Systems", "abstract": "Speech emotion recognition is an important component of any human centered\nsystem. But speech characteristics produced and perceived by a person can be\ninfluenced by a multitude of reasons, both desirable such as emotion, and\nundesirable such as noise. To train robust emotion recognition models, we need\na large, yet realistic data distribution, but emotion datasets are often small\nand hence are augmented with noise. Often noise augmentation makes one\nimportant assumption, that the prediction label should remain the same in\npresence or absence of noise, which is true for automatic speech recognition\nbut not necessarily true for perception based tasks. In this paper we make\nthree novel contributions. We validate through crowdsourcing that the presence\nof noise does change the annotation label and hence may alter the original\nground truth label. We then show how disregarding this knowledge and assuming\nconsistency in ground truth labels propagates to downstream evaluation of ML\nmodels, both for performance evaluation and robustness testing. We end the\npaper with a set of recommendations for noise augmentations in speech emotion\nrecognition datasets.", "published": "2021-04-18 10:33:38", "link": "http://arxiv.org/abs/2104.08806v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-Frequency Characterization of Music Sounds -- Ultra-Bass Richness\n  from the Sound Wave Beats", "abstract": "The orchestra performance is full of sublime rich sounds. In particular, the\nunison of violins sounds different from the solo violin. We try to clarify this\ndifference and similarity of unison and solo numerically analyzing the beat of\n`violins` with timbre, vibrato, melody, and resonance. Characteristic\nproperties appear in the very low-frequency part in the power spectrum of the\nwave amplitude squared. This ultra-buss richness (UBR) can be a new\ncharacteristic of sound on top of the well-known pitch, loudness, and timbre,\nalthough being inaudible directly. We find this UBR is always characterized by\na power-law at low-frequency with the index around -1 and appears everywhere in\nmusic and thus being universal. Furthermore, we explore this power-law property\ntowards much smaller frequency regions and suggest possible relation to the 1/f\nnoise often found in music and many other fields in nature.", "published": "2021-04-18 14:54:06", "link": "http://arxiv.org/abs/2104.08872v1", "categories": ["cs.SD", "eess.AS", "physics.gen-ph"], "primary_category": "cs.SD"}
{"title": "Many-Speakers Single Channel Speech Separation with Optimal Permutation\n  Training", "abstract": "Single channel speech separation has experienced great progress in the last\nfew years. However, training neural speech separation for a large number of\nspeakers (e.g., more than 10 speakers) is out of reach for the current methods,\nwhich rely on the Permutation Invariant Loss (PIT). In this work, we present a\npermutation invariant training that employs the Hungarian algorithm in order to\ntrain with an $O(C^3)$ time complexity, where $C$ is the number of speakers, in\ncomparison to $O(C!)$ of PIT based methods. Furthermore, we present a modified\narchitecture that can handle the increased number of speakers. Our approach\nseparates up to $20$ speakers and improves the previous results for large $C$\nby a wide margin.", "published": "2021-04-18 20:56:12", "link": "http://arxiv.org/abs/2104.08955v4", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
