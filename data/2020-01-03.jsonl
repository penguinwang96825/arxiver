{"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling\n  and Denoising", "abstract": "Text summarization aims to extract essential information from a piece of text\nand transform the text into a concise version. Existing unsupervised\nabstractive summarization models leverage recurrent neural networks framework\nwhile the recently proposed transformer exhibits much more capability.\nMoreover, most of previous summarization models ignore abundant unlabeled\ncorpora resources available for pretraining. In order to address these issues,\nwe propose TED, a transformer-based unsupervised abstractive summarization\nsystem with pretraining on large-scale data. We first leverage the lead bias in\nnews articles to pretrain the model on millions of unlabeled corpora. Next, we\nfinetune TED on target domains through theme modeling and a denoising\nautoencoder to enhance the quality of generated summaries. Notably, TED\noutperforms all unsupervised abstractive baselines on NYT, CNN/DM and English\nGigaword datasets with various document styles. Further analysis shows that the\nsummaries generated by TED are highly abstractive, and each component in the\nobjective function of TED is highly effective.", "published": "2020-01-03 05:15:41", "link": "http://arxiv.org/abs/2001.00725v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Two-Level Transformer and Auxiliary Coherence Modeling for Improved Text\n  Segmentation", "abstract": "Breaking down the structure of long texts into semantically coherent segments\nmakes the texts more readable and supports downstream applications like\nsummarization and retrieval. Starting from an apparent link between text\ncoherence and segmentation, we introduce a novel supervised model for text\nsegmentation with simple but explicit coherence modeling. Our model -- a neural\narchitecture consisting of two hierarchically connected Transformer networks --\nis a multi-task learning model that couples the sentence-level segmentation\nobjective with the coherence objective that differentiates correct sequences of\nsentences from corrupt ones. The proposed model, dubbed Coherence-Aware Text\nSegmentation (CATS), yields state-of-the-art segmentation performance on a\ncollection of benchmark datasets. Furthermore, by coupling CATS with\ncross-lingual word embeddings, we demonstrate its effectiveness in zero-shot\nlanguage transfer: it can successfully segment texts in languages unseen in\ntraining.", "published": "2020-01-03 17:06:41", "link": "http://arxiv.org/abs/2001.00891v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Read Beyond the Lines: Understanding the Implied Textual Meaning via a\n  Skim and Intensive Reading Model", "abstract": "The nonliteral interpretation of a text is hard to be understood by machine\nmodels due to its high context-sensitivity and heavy usage of figurative\nlanguage. In this study, inspired by human reading comprehension, we propose a\nnovel, simple, and effective deep neural framework, called Skim and Intensive\nReading Model (SIRM), for figuring out implied textual meaning. The proposed\nSIRM consists of two main components, namely the skim reading component and\nintensive reading component. N-gram features are quickly extracted from the\nskim reading component, which is a combination of several convolutional neural\nnetworks, as skim (entire) information. An intensive reading component enables\na hierarchical investigation for both local (sentence) and global (paragraph)\nrepresentation, which encapsulates the current embedding and the contextual\ninformation with a dense connection. More specifically, the contextual\ninformation includes the near-neighbor information and the skim information\nmentioned above. Finally, besides the normal training loss function, we employ\nan adversarial loss function as a penalty over the skim reading component to\neliminate noisy information arisen from special figurative words in the\ntraining data. To verify the effectiveness, robustness, and efficiency of the\nproposed architecture, we conduct extensive comparative experiments on several\nsarcasm benchmarks and an industrial spam dataset with metaphors. Experimental\nresults indicate that (1) the proposed model, which benefits from context\nmodeling and consideration of figurative language, outperforms existing\nstate-of-the-art solutions, with comparable parameter scale and training speed;\n(2) the SIRM yields superior robustness in terms of parameter size sensitivity;\n(3) compared with ablation and addition variants of the SIRM, the final\nframework is efficient enough.", "published": "2020-01-03 03:43:35", "link": "http://arxiv.org/abs/2001.00572v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"Love is as Complex as Math\": Metaphor Generation System for Social\n  Chatbot", "abstract": "As the wide adoption of intelligent chatbot in human daily life, user demands\nfor such systems evolve from basic task-solving conversations to more casual\nand friend-like communication. To meet the user needs and build emotional bond\nwith users, it is essential for social chatbots to incorporate more human-like\nand advanced linguistic features. In this paper, we investigate the usage of a\ncommonly used rhetorical device by human -- metaphor for social chatbot. Our\nwork first designs a metaphor generation framework, which generates topic-aware\nand novel figurative sentences. By embedding the framework into a chatbot\nsystem, we then enables the chatbot to communicate with users using figurative\nlanguage. Human annotators validate the novelty and properness of the generated\nmetaphors. More importantly, we evaluate the effects of employing metaphors in\nhuman-chatbot conversations. Experiments indicate that our system effectively\narouses user interests in communicating with our chatbot, resulting in\nsignificantly longer human-chatbot conversations.", "published": "2020-01-03 05:56:13", "link": "http://arxiv.org/abs/2001.00733v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Meaning updating of density matrices", "abstract": "The DisCoCat model of natural language meaning assigns meaning to a sentence\ngiven: (i) the meanings of its words, and, (ii) its grammatical structure. The\nrecently introduced DisCoCirc model extends this to text consisting of multiple\nsentences. While in DisCoCat all meanings are fixed, in DisCoCirc each sentence\nupdates meanings of words. In this paper we explore different update mechanisms\nfor DisCoCirc, in the case where meaning is encoded in density matrices---which\ncome with several advantages as compared to vectors.\n  Our starting point are two non-commutative update mechanisms, borrowing one\nfrom quantum foundations research, from Leifer and Spekkens. Unfortunately,\nneither of these satisfies any desirable algebraic properties, nor are internal\nto the meaning category. By passing to double density matrices we do get an\nelegant internal diagrammatic update mechanism.\n  We also show that (commutative) spiders can be cast as an instance of the\nLeifer-Spekkens update mechanism. This result is of interest to quantum\nfoundations, as it bridges the work in Categorical Quantum Mechanics (CQM) with\nthat on conditional quantum states. Our work also underpins implementation of\ntext-level natural language processing on quantum hardware (a.k.a. QNLP), for\nwhich exponential space-gain and quadratic speed-up have previously been\nidentified.", "published": "2020-01-03 15:28:52", "link": "http://arxiv.org/abs/2001.00862v1", "categories": ["quant-ph", "cs.CL"], "primary_category": "quant-ph"}
{"title": "Question Type Classification Methods Comparison", "abstract": "The paper presents a comparative study of state-of-the-art approaches for\nquestion classification task: Logistic Regression, Convolutional Neural\nNetworks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent\nNeural Networks (QRNN). All models use pre-trained GLoVe word embeddings and\ntrained on human-labeled data. The best accuracy is achieved using CNN model\nwith five convolutional layers and various kernel sizes stacked in parallel,\nfollowed by one fully connected layer. The model reached 90.7% accuracy on TREC\n10 test set. All the model architectures in this paper were developed from\nscratch on PyTorch, in few cases based on reliable open-source implementation.", "published": "2020-01-03 00:16:46", "link": "http://arxiv.org/abs/2001.00571v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the comparability of Pre-trained Language Models", "abstract": "Recent developments in unsupervised representation learning have successfully\nestablished the concept of transfer learning in NLP. Mainly three forces are\ndriving the improvements in this area of research: More elaborated\narchitectures are making better use of contextual information. Instead of\nsimply plugging in static pre-trained representations, these are learned based\non surrounding context in end-to-end trainable models with more intelligently\ndesigned language modelling objectives. Along with this, larger corpora are\nused as resources for pre-training large language models in a self-supervised\nfashion which are afterwards fine-tuned on supervised tasks. Advances in\nparallel computing as well as in cloud computing, made it possible to train\nthese models with growing capacities in the same or even in shorter time than\npreviously established models. These three developments agglomerate in new\nstate-of-the-art (SOTA) results being revealed in a higher and higher\nfrequency. It is not always obvious where these improvements originate from, as\nit is not possible to completely disentangle the contributions of the three\ndriving forces. We set ourselves to providing a clear and concise overview on\nseveral large pre-trained language models, which achieved SOTA results in the\nlast two years, with respect to their use of new architectures and resources.\nWe want to clarify for the reader where the differences between the models are\nand we furthermore attempt to gain some insight into the single contributions\nof lexical/computational improvements as well as of architectural changes. We\nexplicitly do not intend to quantify these contributions, but rather see our\nwork as an overview in order to identify potential starting points for\nbenchmark comparisons. Furthermore, we tentatively want to point at potential\npossibilities for improvement in the field of open-sourcing and reproducible\nresearch.", "published": "2020-01-03 10:53:35", "link": "http://arxiv.org/abs/2001.00781v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Learning Accurate Integer Transformer Machine-Translation Models", "abstract": "We describe a method for training accurate Transformer machine-translation\nmodels to run inference using 8-bit integer (INT8) hardware matrix multipliers,\nas opposed to the more costly single-precision floating-point (FP32) hardware.\nUnlike previous work, which converted only 85 Transformer matrix\nmultiplications to INT8, leaving 48 out of 133 of them in FP32 because of\nunacceptable accuracy loss, we convert them all to INT8 without compromising\naccuracy. Tested on the newstest2014 English-to-German translation task, our\nINT8 Transformer Base and Transformer Big models yield BLEU scores that are\n99.3% to 100% relative to those of the corresponding FP32 models. Our approach\nconverts all matrix-multiplication tensors from an existing FP32 model into\nINT8 tensors by automatically making range-precision trade-offs during\ntraining. To demonstrate the robustness of this approach, we also include\nresults from INT6 Transformer models.", "published": "2020-01-03 18:40:35", "link": "http://arxiv.org/abs/2001.00926v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Information Extraction based on Named Entity for Tourism Corpus", "abstract": "Tourism information is scattered around nowadays. To search for the\ninformation, it is usually time consuming to browse through the results from\nsearch engine, select and view the details of each accommodation. In this\npaper, we present a methodology to extract particular information from full\ntext returned from the search engine to facilitate the users. Then, the users\ncan specifically look to the desired relevant information. The approach can be\nused for the same task in other domains. The main steps are 1) building\ntraining data and 2) building recognition model. First, the tourism data is\ngathered and the vocabularies are built. The raw corpus is used to train for\ncreating vocabulary embedding. Also, it is used for creating annotated data.\nThe process of creating named entity annotation is presented. Then, the\nrecognition model of a given entity type can be built. From the experiments,\ngiven hotel description, the model can extract the desired entity,i.e, name,\nlocation, facility. The extracted data can further be stored as a structured\ninformation, e.g., in the ontology format, for future querying and inference.\nThe model for automatic named entity identification, based on machine learning,\nyields the error ranging 8%-25%.", "published": "2020-01-03 17:16:28", "link": "http://arxiv.org/abs/2001.01588v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2, I.7", "I.2; I.7"], "primary_category": "cs.CL"}
{"title": "Discoverability in Satellite Imagery: A Good Sentence is Worth a\n  Thousand Pictures", "abstract": "Small satellite constellations provide daily global coverage of the earth's\nlandmass, but image enrichment relies on automating key tasks like change\ndetection or feature searches. For example, to extract text annotations from\nraw pixels requires two dependent machine learning models, one to analyze the\noverhead image and the other to generate a descriptive caption. We evaluate\nseven models on the previously largest benchmark for satellite image captions.\nWe extend the labeled image samples five-fold, then augment, correct and prune\nthe vocabulary to approach a rough min-max (minimum word, maximum description).\nThis outcome compares favorably to previous work with large pre-trained image\nmodels but offers a hundred-fold reduction in model size without sacrificing\noverall accuracy (when measured with log entropy loss). These smaller models\nprovide new deployment opportunities, particularly when pushed to edge\nprocessors, on-board satellites, or distributed ground stations. To quantify a\ncaption's descriptiveness, we introduce a novel multi-class confusion or error\nmatrix to score both human-labeled test data and never-labeled images that\ninclude bounding box detection but lack full sentence captions. This work\nsuggests future captioning strategies, particularly ones that can enrich the\nclass coverage beyond land use applications and that lessen color-centered and\nadjacency adjectives (\"green\", \"near\", \"between\", etc.). Many modern language\ntransformers present novel and exploitable models with world knowledge gleaned\nfrom training from their vast online corpus. One interesting, but easy example\nmight learn the word association between wind and waves, thus enriching a beach\nscene with more than just color descriptions that otherwise might be accessed\nfrom raw pixels without text annotation.", "published": "2020-01-03 20:41:18", "link": "http://arxiv.org/abs/2001.05839v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Predicting Personalized Academic and Career Roads: First Steps Toward a\n  Multi-Uses Recommender System", "abstract": "Nobody knows what one's do in the future and everyone will have had a\ndifferent answer to the question : how do you see yourself in five years after\nyour current job/diploma? In this paper we introduce concepts, large categories\nof fields of studies or job domains in order to represent the vision of the\nfuture of the user's trajectory. Then, we show how they can influence the\nprediction when proposing him a set of next steps to take.", "published": "2020-01-03 11:00:54", "link": "http://arxiv.org/abs/2001.10613v1", "categories": ["cs.CY", "cs.CL", "cs.IR"], "primary_category": "cs.CY"}
{"title": "A Pilot Study on Mandarin Chinese Cued Speech", "abstract": "Cued Speech (CS) is a communication system developed for deaf people, which\nexploits hand cues to complement speechreading at the phonetic level.\nCurrently, it is estimated that CS has been adapted to over 60 languages;\nhowever, no official CS system is available for Mandarin Chinese. This article\nproposes a novel and efficient Mandarin Chinese CS system, satisfying the main\ncriterion that the hand coding constitutes a complement to the lips movements.\nWe propose to code vowels [i, u, y] as semiconsonants when they are followed by\nother Mandarin finals, which reduces the number of Mandarin finals to be coded\nfrom 36 to 16. We establish a coherent similarity between Mandarin Chinese and\nFrench vowels for the remaining 16 vowels, which allows us to take advantage of\nthe French CS system. Furthermore, by investigating the lips viseme\ndistribution based on a new corpus, an optimal allocation of the 16 Mandarin\nvowels to different hand positions is obtained. A Gaussian classifier was used\nto evaluate the average separability of different allocated vowel groups, which\ngives 92.08\\%, 92.33\\%, and 92.73\\% for the three speakers, respectively. The\nconsonants are mainly designed according to their similarities with the French\nCS system, as well as some considerations on the special Mandarin consonants.\nIn our system, the tones of Mandarin are coded with head movements.", "published": "2020-01-03 05:39:16", "link": "http://arxiv.org/abs/2001.00731v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Re-synchronization using the Hand Preceding Model for Multi-modal Fusion\n  in Automatic Continuous Cued Speech Recognition", "abstract": "Cued Speech (CS) is an augmented lip reading complemented by hand coding, and\nit is very helpful to the deaf people. Automatic CS recognition can help\ncommunications between the deaf people and others. Due to the asynchronous\nnature of lips and hand movements, fusion of them in automatic CS recognition\nis a challenging problem. In this work, we propose a novel re-synchronization\nprocedure for multi-modal fusion, which aligns the hand features with lips\nfeature. It is realized by delaying hand position and hand shape with their\noptimal hand preceding time which is derived by investigating the temporal\norganizations of hand position and hand shape movements in CS. This\nre-synchronization procedure is incorporated into a practical continuous CS\nrecognition system that combines convolutional neural network (CNN) with\nmulti-stream hidden markov model (MSHMM). A significant improvement of about\n4.6\\% has been achieved retaining 76.6\\% CS phoneme recognition correctness\ncompared with the state-of-the-art architecture (72.04\\%), which did not take\ninto account the asynchrony of multi-modal fusion in CS. To our knowledge, this\nis the first work to tackle the asynchronous multi-modal fusion in the\nautomatic continuous CS recognition.", "published": "2020-01-03 14:52:33", "link": "http://arxiv.org/abs/2001.00854v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
