{"title": "Draft, Command, and Edit: Controllable Text Editing in E-Commerce", "abstract": "Product description generation is a challenging and under-explored task. Most\nsuch work takes a set of product attributes as inputs then generates a\ndescription from scratch in a single pass. However, this widespread paradigm\nmight be limited when facing the dynamic wishes of users on constraining the\ndescription, such as deleting or adding the content of a user-specified\nattribute based on the previous version. To address this challenge, we explore\na new draft-command-edit manner in description generation, leading to the\nproposed new task-controllable text editing in E-commerce. More specifically,\nwe allow systems to receive a command (deleting or adding) from the user and\nthen generate a description by flexibly modifying the content based on the\nprevious version. It is easier and more practical to meet the new needs by\nmodifying previous versions than generating from scratch. Furthermore, we\ndesign a data augmentation method to remedy the low resource challenge in this\ntask, which contains a model-based and a rule-based strategy to imitate the\nedit by humans. To accompany this new task, we present a human-written\ndraft-command-edit dataset called E-cEdits and a new metric \"Attribute Edit\".\nOur experimental results show that using the new data augmentation method\noutperforms baselines to a greater extent in both automatic and human\nevaluations.", "published": "2022-08-11 03:48:08", "link": "http://arxiv.org/abs/2208.05623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of CTC 2021: Chinese Text Correction for Native Speakers", "abstract": "In this paper, we present an overview of the CTC 2021, a Chinese text\ncorrection task for native speakers. We give detailed descriptions of the task\ndefinition and the data for training as well as evaluation. We also summarize\nthe approaches investigated by the participants of this task. We hope the data\nsets collected and annotated for this task can facilitate and expedite future\ndevelopment in this research area. Therefore, the pseudo training data, gold\nstandards validation data, and entire leaderboard is publicly available online\nat https://destwang.github.io/CTC2021-explorer/.", "published": "2022-08-11 07:58:48", "link": "http://arxiv.org/abs/2208.05681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing the Unitary RNN as an End-to-End Compositional Model of Syntax", "abstract": "We show that both an LSTM and a unitary-evolution recurrent neural network\n(URN) can achieve encouraging accuracy on two types of syntactic patterns:\ncontext-free long distance agreement, and mildly context-sensitive cross serial\ndependencies. This work extends recent experiments on deeply nested\ncontext-free long distance dependencies, with similar results. URNs differ from\nLSTMs in that they avoid non-linear activation functions, and they apply matrix\nmultiplication to word embeddings encoded as unitary matrices. This permits\nthem to retain all information in the processing of an input string over\narbitrary distances. It also causes them to satisfy strict compositionality.\nURNs constitute a significant advance in the search for explainable models in\ndeep learning applied to NLP.", "published": "2022-08-11 09:30:49", "link": "http://arxiv.org/abs/2208.05719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey of Natural Language Generation Advances from the\n  Perspective of Digital Deception", "abstract": "In recent years there has been substantial growth in the capabilities of\nsystems designed to generate text that mimics the fluency and coherence of\nhuman language. From this, there has been considerable research aimed at\nexamining the potential uses of these natural language generators (NLG) towards\na wide number of tasks. The increasing capabilities of powerful text generators\nto mimic human writing convincingly raises the potential for deception and\nother forms of dangerous misuse. As these systems improve, and it becomes ever\nharder to distinguish between human-written and machine-generated text,\nmalicious actors could leverage these powerful NLG systems to a wide variety of\nends, including the creation of fake news and misinformation, the generation of\nfake online product reviews, or via chatbots as means of convincing users to\ndivulge private information. In this paper, we provide an overview of the NLG\nfield via the identification and examination of 119 survey-like papers focused\non NLG research. From these identified papers, we outline a proposed high-level\ntaxonomy of the central concepts that constitute NLG, including the methods\nused to develop generalised NLG systems, the means by which these systems are\nevaluated, and the popular NLG tasks and subtasks that exist. In turn, we\nprovide an overview and discussion of each of these items with respect to\ncurrent research and offer an examination of the potential roles of NLG in\ndeception and detection systems to counteract these threats. Moreover, we\ndiscuss the broader challenges of NLG, including the risks of bias that are\noften exhibited by existing text generation systems. This work offers a broad\noverview of the field of NLG with respect to its potential for misuse, aiming\nto provide a high-level understanding of this rapidly developing area of\nresearch.", "published": "2022-08-11 11:27:38", "link": "http://arxiv.org/abs/2208.05757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain-Specific Text Generation for Machine Translation", "abstract": "Preservation of domain knowledge from the source to target is crucial in any\ntranslation workflow. It is common in the translation industry to receive\nhighly specialized projects, where there is hardly any parallel in-domain data.\nIn such scenarios where there is insufficient in-domain data to fine-tune\nMachine Translation (MT) models, producing translations that are consistent\nwith the relevant context is challenging. In this work, we propose a novel\napproach to domain adaptation leveraging state-of-the-art pretrained language\nmodels (LMs) for domain-specific data augmentation for MT, simulating the\ndomain characteristics of either (a) a small bilingual dataset, or (b) the\nmonolingual source text to be translated. Combining this idea with\nback-translation, we can generate huge amounts of synthetic bilingual in-domain\ndata for both use cases. For our investigation, we use the state-of-the-art\nTransformer architecture. We employ mixed fine-tuning to train models that\nsignificantly improve translation of in-domain texts. More specifically, in\nboth scenarios, our proposed methods achieve improvements of approximately 5-6\nBLEU and 2-3 BLEU, respectively, on the Arabic-to-English and English-to-Arabic\nlanguage pairs. Furthermore, the outcome of human evaluation corroborates the\nautomatic evaluation results.", "published": "2022-08-11 16:22:16", "link": "http://arxiv.org/abs/2208.05909v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structural Biases for Improving Transformers on Translation into\n  Morphologically Rich Languages", "abstract": "Machine translation has seen rapid progress with the advent of\nTransformer-based models. These models have no explicit linguistic structure\nbuilt into them, yet they may still implicitly learn structured relationships\nby attending to relevant tokens. We hypothesize that this structural learning\ncould be made more robust by explicitly endowing Transformers with a structural\nbias, and we investigate two methods for building in such a bias. One method,\nthe TP-Transformer, augments the traditional Transformer architecture to\ninclude an additional component to represent structure. The second method\nimbues structure at the data level by segmenting the data with morphological\ntokenization. We test these methods on translating from English into\nmorphologically rich languages, Turkish and Inuktitut, and consider both\nautomatic metrics and human evaluations. We find that each of these two\napproaches allows the network to achieve better performance, but this\nimprovement is dependent on the size of the dataset. In sum, structural\nencoding methods make Transformers more sample-efficient, enabling them to\nperform better from smaller amounts of data.", "published": "2022-08-11 22:42:24", "link": "http://arxiv.org/abs/2208.06061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Searching for chromate replacements using natural language processing\n  and machine learning algorithms", "abstract": "The past few years has seen the application of machine learning utilised in\nthe exploration of new materials. As in many fields of research - the vast\nmajority of knowledge is published as text, which poses challenges in either a\nconsolidated or statistical analysis across studies and reports. Such\nchallenges include the inability to extract quantitative information, and in\naccessing the breadth of non-numerical information. To address this issue, the\napplication of natural language processing (NLP) has been explored in several\nstudies to date. In NLP, assignment of high-dimensional vectors, known as\nembeddings, to passages of text preserves the syntactic and semantic\nrelationship between words. Embeddings rely on machine learning algorithms and\nin the present work, we have employed the Word2Vec model, previously explored\nby others, and the BERT model - applying them towards a unique challenge in\nmaterials engineering. That challenge is the search for chromate replacements\nin the field of corrosion protection. From a database of over 80 million\nrecords, a down-selection of 5990 papers focused on the topic of corrosion\nprotection were examined using NLP. This study demonstrates it is possible to\nextract knowledge from the automated interpretation of the scientific\nliterature and achieve expert human level insights.", "published": "2022-08-11 07:21:18", "link": "http://arxiv.org/abs/2208.05672v1", "categories": ["cs.CL", "cond-mat.mtrl-sci"], "primary_category": "cs.CL"}
{"title": "Language Tokens: A Frustratingly Simple Approach Improves Zero-Shot\n  Performance of Multilingual Translation", "abstract": "This paper proposes a simple yet effective method to improve direct (X-to-Y)\ntranslation for both cases: zero-shot and when direct data is available. We\nmodify the input tokens at both the encoder and decoder to include signals for\nthe source and target languages. We show a performance gain when training from\nscratch, or finetuning a pretrained model with the proposed setup. In the\nexperiments, our method shows nearly 10.0 BLEU points gain on in-house datasets\ndepending on the checkpoint selection criteria. In a WMT evaluation campaign,\nFrom-English performance improves by 4.17 and 2.87 BLEU points, in the\nzero-shot setting, and when direct data is available for training,\nrespectively. While X-to-Y improves by 1.29 BLEU over the zero-shot baseline,\nand 0.44 over the many-to-many baseline. In the low-resource setting, we see a\n1.5~1.7 point improvement when finetuning on X-to-Y domain data.", "published": "2022-08-11 14:42:42", "link": "http://arxiv.org/abs/2208.05852v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech Synthesis with Mixed Emotions", "abstract": "Emotional speech synthesis aims to synthesize human voices with various\nemotional effects. The current studies are mostly focused on imitating an\naveraged style belonging to a specific emotion type. In this paper, we seek to\ngenerate speech with a mixture of emotions at run-time. We propose a novel\nformulation that measures the relative difference between the speech samples of\ndifferent emotions. We then incorporate our formulation into a\nsequence-to-sequence emotional text-to-speech framework. During the training,\nthe framework does not only explicitly characterize emotion styles, but also\nexplores the ordinal nature of emotions by quantifying the differences with\nother emotions. At run-time, we control the model to produce the desired\nemotion mixture by manually defining an emotion attribute vector. The objective\nand subjective evaluations have validated the effectiveness of the proposed\nframework. To our best knowledge, this research is the first study on\nmodelling, synthesizing, and evaluating mixed emotions in speech.", "published": "2022-08-11 15:45:58", "link": "http://arxiv.org/abs/2208.05890v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Figure Descriptive Text Extraction using Ontological Representation", "abstract": "Experimental research publications provide figure form resources including\ngraphs, charts, and any type of images to effectively support and convey\nmethods and results. To describe figures, authors add captions, which are often\nincomplete, and more descriptions reside in body text. This work presents a\nmethod to extract figure descriptive text from the body of scientific articles.\nWe adopted ontological semantics to aid concept recognition of figure-related\ninformation, which generates human- and machine-readable knowledge\nrepresentations from sentences. Our results show that conceptual models bring\nan improvement in figure descriptive sentence classification over word-based\napproaches.", "published": "2022-08-11 21:09:58", "link": "http://arxiv.org/abs/2208.06040v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Twitter-Driven Deep Learning Mechanism for the Determination of\n  Vehicle Hijacking Spots in Cities", "abstract": "Vehicle hijacking is one of the leading crimes in many cities. For instance,\nin South Africa, drivers must constantly remain vigilant on the road in order\nto ensure that they do not become hijacking victims. This work is aimed at\ndeveloping a map depicting hijacking spots in a city by using Twitter data.\nTweets, which include the keyword \"hijacking\", are obtained in a designated\ncity of Cape Town, in this work. In order to extract relevant tweets, these\ntweets are analyzed by using the following machine learning techniques: 1) a\nMulti-layer Feed-forward Neural Network (MLFNN); 2) Convolutional Neural\nNetwork; and Bidirectional Encoder Representations from Transformers (BERT).\nThrough training and testing, CNN achieved an accuracy of 99.66%, while MLFNN\nand BERT achieve accuracies of 98.99% and 73.99% respectively. In terms of\nRecall, Precision and F1-score, CNN also achieved the best results. Therefore,\nCNN was used for the identification of relevant tweets. The relevant reports\nthat it generates are visually presented on a points map of the City of Cape\nTown. This work used a small dataset of 426 tweets. In future, the use of\nevolutionary computation will be explored for purposes of optimizing the deep\nlearning models. A mobile application is under development to make this\ninformation usable by the general public.", "published": "2022-08-11 21:56:34", "link": "http://arxiv.org/abs/2208.10280v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language-independence of DisCoCirc's Text Circuits: English and Urdu", "abstract": "DisCoCirc is a newly proposed framework for representing the grammar and\nsemantics of texts using compositional, generative circuits. While it\nconstitutes a development of the Categorical Distributional Compositional\n(DisCoCat) framework, it exposes radically new features. In particular, [14]\nsuggested that DisCoCirc goes some way toward eliminating grammatical\ndifferences between languages. In this paper we provide a sketch that this is\nindeed the case for restricted fragments of English and Urdu. We first develop\nDisCoCirc for a fragment of Urdu, as it was done for English in [14]. There is\na simple translation from English grammar to Urdu grammar, and vice versa. We\nthen show that differences in grammatical structure between English and Urdu -\nprimarily relating to the ordering of words and phrases - vanish when passing\nto DisCoCirc circuits.", "published": "2022-08-11 09:32:00", "link": "http://arxiv.org/abs/2208.10281v1", "categories": ["cs.CL", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Heterogeneous Line Graph Transformer for Math Word Problems", "abstract": "This paper describes the design and implementation of a new machine learning\nmodel for online learning systems. We aim at improving the intelligent level of\nthe systems by enabling an automated math word problem solver which can support\na wide range of functions such as homework correction, difficulty estimation,\nand priority recommendation. We originally planned to employ existing models\nbut realized that they processed a math word problem as a sequence or a\nhomogeneous graph of tokens. Relationships between the multiple types of tokens\nsuch as entity, unit, rate, and number were ignored. We decided to design and\nimplement a novel model to use such relational data to bridge the information\ngap between human-readable language and machine-understandable logical form. We\npropose a heterogeneous line graph transformer (HLGT) model that constructs a\nheterogeneous line graph via semantic role labeling on math word problems and\nthen perform node representation learning aware of edge types. We add numerical\ncomparison as an auxiliary task to improve model training for real-world use.\nExperimental results show that the proposed model achieves a better performance\nthan existing models and suggest that it is still far below human performance.\nInformation utilization and knowledge discovery is continuously needed to\nimprove the online learning systems.", "published": "2022-08-11 05:27:05", "link": "http://arxiv.org/abs/2208.05645v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Top Gear or Black Mirror: Inferring Political Leaning From Non-Political\n  Content", "abstract": "Polarization and echo chambers are often studied in the context of explicitly\npolitical events such as elections, and little scholarship has examined the\nmixing of political groups in non-political contexts. A major obstacle to\nstudying political polarization in non-political contexts is that political\nleaning (i.e., left vs right orientation) is often unknown. Nonetheless,\npolitical leaning is known to correlate (sometimes quite strongly) with many\nlifestyle choices leading to stereotypes such as the \"latte-drinking liberal.\"\nWe develop a machine learning classifier to infer political leaning from\nnon-political text and, optionally, the accounts a user follows on social\nmedia. We use Voter Advice Application results shared on Twitter as our\ngroundtruth and train and test our classifier on a Twitter dataset comprising\nthe 3,200 most recent tweets of each user after removing any tweets with\npolitical text. We correctly classify the political leaning of most users (F1\nscores range from 0.70 to 0.85 depending on coverage). We find no relationship\nbetween the level of political activity and our classification results. We\napply our classifier to a case study of news sharing in the UK and discover\nthat, in general, the sharing of political news exhibits a distinctive\nleft-right divide while sports news does not.", "published": "2022-08-11 06:41:23", "link": "http://arxiv.org/abs/2208.05662v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "A Model of Anaphoric Ambiguities using Sheaf Theoretic Quantum-like\n  Contextuality and BERT", "abstract": "Ambiguities of natural language do not preclude us from using it and context\nhelps in getting ideas across. They, nonetheless, pose a key challenge to the\ndevelopment of competent machines to understand natural language and use it as\nhumans do. Contextuality is an unparalleled phenomenon in quantum mechanics,\nwhere different mathematical formalisms have been put forwards to understand\nand reason about it. In this paper, we construct a schema for anaphoric\nambiguities that exhibits quantum-like contextuality. We use a recently\ndeveloped criterion of sheaf-theoretic contextuality that is applicable to\nsignalling models. We then take advantage of the neural word embedding engine\nBERT to instantiate the schema to natural language examples and extract\nprobability distributions for the instances. As a result, plenty of\nsheaf-contextual examples were discovered in the natural language corpora BERT\nutilises. Our hope is that these examples will pave the way for future research\nand for finding ways to extend applications of quantum computing to natural\nlanguage processing.", "published": "2022-08-11 09:31:15", "link": "http://arxiv.org/abs/2208.05720v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Word-Embeddings Distinguish Denominal and Root-Derived Verbs in Semitic", "abstract": "Proponents of the Distributed Morphology framework have posited the existence\nof two levels of morphological word formation: a lower one, leading to loose\ninput-output semantic relationships; and an upper one, leading to tight\ninput-output semantic relationships. In this work, we propose to test the\nvalidity of this assumption in the context of Hebrew word embeddings. If the\ntwo-level hypothesis is borne out, we expect state-of-the-art Hebrew word\nembeddings to encode (1) a noun, (2) a denominal derived from it (via an\nupper-level operation), and (3) a verb related to the noun (via a lower-level\noperation on the noun's root), in such a way that the denominal (2) should be\ncloser in the embedding space to the noun (1) than the related verb (3) is to\nthe same noun (1). We report that this hypothesis is verified by four embedding\nmodels of Hebrew: fastText, GloVe, Word2Vec and AlephBERT. This suggests that\nword embedding models are able to capture complex and fine-grained semantic\nproperties that are morphologically motivated.", "published": "2022-08-11 09:31:37", "link": "http://arxiv.org/abs/2208.05721v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Disentangled Modeling of Domain and Relevance for Adaptable Dense\n  Retrieval", "abstract": "Recent advance in Dense Retrieval (DR) techniques has significantly improved\nthe effectiveness of first-stage retrieval. Trained with large-scale supervised\ndata, DR models can encode queries and documents into a low-dimensional dense\nspace and conduct effective semantic matching. However, previous studies have\nshown that the effectiveness of DR models would drop by a large margin when the\ntrained DR models are adopted in a target domain that is different from the\ndomain of the labeled data. One of the possible reasons is that the DR model\nhas never seen the target corpus and thus might be incapable of mitigating the\ndifference between the training and target domains. In practice, unfortunately,\ntraining a DR model for each target domain to avoid domain shift is often a\ndifficult task as it requires additional time, storage, and domain-specific\ndata labeling, which are not always available. To address this problem, in this\npaper, we propose a novel DR framework named Disentangled Dense Retrieval (DDR)\nto support effective and flexible domain adaptation for DR models. DDR consists\nof a Relevance Estimation Module (REM) for modeling domain-invariant matching\npatterns and several Domain Adaption Modules (DAMs) for modeling\ndomain-specific features of multiple target corpora. By making the REM and DAMs\ndisentangled, DDR enables a flexible training paradigm in which REM is trained\nwith supervision once and DAMs are trained with unsupervised data.\nComprehensive experiments in different domains and languages show that DDR\nsignificantly improves ranking performance compared to strong DR baselines and\nsubstantially outperforms traditional retrieval methods in most scenarios.", "published": "2022-08-11 11:18:50", "link": "http://arxiv.org/abs/2208.05753v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "MILAN: Masked Image Pretraining on Language Assisted Representation", "abstract": "Self-attention based transformer models have been dominating many computer\nvision tasks in the past few years. Their superb model qualities heavily depend\non the excessively large labeled image datasets. In order to reduce the\nreliance on large labeled datasets, reconstruction based masked autoencoders\nare gaining popularity, which learn high quality transferable representations\nfrom unlabeled images. For the same purpose, recent weakly supervised image\npretraining methods explore language supervision from text captions\naccompanying the images. In this work, we propose masked image pretraining on\nlanguage assisted representation, dubbed as MILAN. Instead of predicting raw\npixels or low level features, our pretraining objective is to reconstruct the\nimage features with substantial semantic signals that are obtained using\ncaption supervision. Moreover, to accommodate our reconstruction target, we\npropose a more effective prompting decoder architecture and a semantic aware\nmask sampling mechanism, which further advance the transfer performance of the\npretrained model. Experimental results demonstrate that MILAN delivers higher\naccuracy than the previous works. When the masked autoencoder is pretrained and\nfinetuned on ImageNet-1K dataset with an input resolution of 224x224, MILAN\nachieves a top-1 accuracy of 85.4% on ViT-Base, surpassing previous\nstate-of-the-arts by 1%. In the downstream semantic segmentation task, MILAN\nachieves 52.7 mIoU using ViT-Base on ADE20K dataset, outperforming previous\nmasked pretraining results by 4 points.", "published": "2022-08-11 21:58:36", "link": "http://arxiv.org/abs/2208.06049v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Chewing Detection from Commercial Smart-glasses", "abstract": "Automatic dietary monitoring has progressed significantly during the last\nyears, offering a variety of solutions, both in terms of sensors and algorithms\nas well as in terms of what aspect or parameters of eating behavior are\nmeasured and monitored. Automatic detection of eating based on chewing sounds\nhas been studied extensively, however, it requires a microphone to be mounted\non the subject's head for capturing the relevant sounds. In this work, we\nevaluate the feasibility of using an off-the-shelf commercial device, the Razer\nAnzu smart-glasses, for automatic chewing detection. The smart-glasses are\nequipped with stereo speakers and microphones that communicate with\nsmart-phones via Bluetooth. The microphone placement is not optimal for\ncapturing chewing sounds, however, we find that it does not significantly\naffect the detection effectiveness. We apply an algorithm from literature with\nsome adjustments on a challenging dataset that we have collected in house.\nLeave-one-subject-out experiments yield promising results, with an F1-score of\n0.96 for the best case of duration-based evaluation of eating time.", "published": "2022-08-11 10:01:09", "link": "http://arxiv.org/abs/2208.05735v1", "categories": ["eess.AS", "J.3"], "primary_category": "eess.AS"}
{"title": "Symbolic Music Loop Generation with Neural Discrete Representations", "abstract": "Since most of music has repetitive structures from motifs to phrases,\nrepeating musical ideas can be a basic operation for music composition. The\nbasic block that we focus on is conceptualized as loops which are essential\ningredients of music. Furthermore, meaningful note patterns can be formed in a\nfinite space, so it is sufficient to represent them with combinations of\ndiscrete symbols as done in other domains. In this work, we propose symbolic\nmusic loop generation via learning discrete representations. We first extract\nloops from MIDI datasets using a loop detector and then learn an autoregressive\nmodel trained by discrete latent codes of the extracted loops. We show that our\nmodel outperforms well-known music generative models in terms of both fidelity\nand diversity, evaluating on random space. Our code and supplementary materials\nare available at https://github.com/sjhan91/Loop_VQVAE_Official.", "published": "2022-08-11 02:00:36", "link": "http://arxiv.org/abs/2208.05605v3", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Re-creation of Creations: A New Paradigm for Lyric-to-Melody Generation", "abstract": "Lyric-to-melody generation is an important task in songwriting, and is also\nquite challenging due to its unique characteristics: the generated melodies\nshould not only follow good musical patterns, but also align with features in\nlyrics such as rhythms and structures. These characteristics cannot be well\nhandled by neural generation models that learn lyric-to-melody mapping in an\nend-to-end way, due to several issues: (1) lack of aligned lyric-melody\ntraining data to sufficiently learn lyric-melody feature alignment; (2) lack of\ncontrollability in generation to better and explicitly align the lyric-melody\nfeatures. In this paper, we propose Re-creation of Creations (ROC), a new\nparadigm for lyric-to-melody generation. ROC generates melodies according to\ngiven lyrics and also conditions on user-designated chord progression. It\naddresses the above issues through a generation-retrieval pipeline.\nSpecifically, our paradigm has two stages: (1) creation stage, where a huge\namount of music fragments generated by a neural melody language model are\nindexed in a database through several key features (e.g., chords, tonality,\nrhythm, and structural information); (2) re-creation stage, where melodies are\nre-created by retrieving music fragments from the database according to the key\nfeatures from lyrics and concatenating best music fragments based on\ncomposition guidelines and melody language model scores. ROC has several\nadvantages: (1) It only needs unpaired melody data to train melody language\nmodel, instead of paired lyric-melody data in previous models. (2) It achieves\ngood lyric-melody feature alignment in lyric-to-melody generation. Tested by\nEnglish and Chinese lyrics, ROC outperforms previous neural based\nlyric-to-melody generation models on both objective and subjective metrics.", "published": "2022-08-11 08:44:47", "link": "http://arxiv.org/abs/2208.05697v4", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Enhancement and Dereverberation with Diffusion-based Generative\n  Models", "abstract": "In this work, we build upon our previous publication and use diffusion-based\ngenerative models for speech enhancement. We present a detailed overview of the\ndiffusion process that is based on a stochastic differential equation and delve\ninto an extensive theoretical examination of its implications. Opposed to usual\nconditional generation tasks, we do not start the reverse process from pure\nGaussian noise but from a mixture of noisy speech and Gaussian noise. This\nmatches our forward process which moves from clean speech to noisy speech by\nincluding a drift term. We show that this procedure enables using only 30\ndiffusion steps to generate high-quality clean speech estimates. By adapting\nthe network architecture, we are able to significantly improve the speech\nenhancement performance, indicating that the network, rather than the\nformalism, was the main limitation of our original approach. In an extensive\ncross-dataset evaluation, we show that the improved method can compete with\nrecent discriminative models and achieves better generalization when evaluating\non a different corpus than used for training. We complement the results with an\ninstrumental evaluation using real-world noisy recordings and a listening\nexperiment, in which our proposed method is rated best. Examining different\nsampler configurations for solving the reverse process allows us to balance the\nperformance and computational speed of the proposed method. Moreover, we show\nthat the proposed method is also suitable for dereverberation and thus not\nlimited to additive background noise removal. Code and audio examples are\navailable online, see https://github.com/sp-uhh/sgmse", "published": "2022-08-11 13:55:12", "link": "http://arxiv.org/abs/2208.05830v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
