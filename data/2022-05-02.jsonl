{"title": "POLITICS: Pretraining with Same-story Article Comparison for Ideology\n  Prediction and Stance Detection", "abstract": "Ideology is at the core of political science research. Yet, there still does\nnot exist general-purpose tools to characterize and predict ideology across\ndifferent genres of text. To this end, we study Pretrained Language Models\nusing novel ideology-driven pretraining objectives that rely on the comparison\nof articles on the same story written by media of different ideologies. We\nfurther collect a large-scale dataset, consisting of more than 3.6M political\nnews articles, for pretraining. Our model POLITICS outperforms strong baselines\nand the previous state-of-the-art models on ideology prediction and stance\ndetection tasks. Further analyses show that POLITICS is especially good at\nunderstanding long or formally written texts, and is also robust in few-shot\nlearning scenarios.", "published": "2022-05-02 02:10:05", "link": "http://arxiv.org/abs/2205.00619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching BERT to Wait: Balancing Accuracy and Latency for Streaming\n  Disfluency Detection", "abstract": "In modern interactive speech-based systems, speech is consumed and\ntranscribed incrementally prior to having disfluencies removed. This\npost-processing step is crucial for producing clean transcripts and high\nperformance on downstream tasks (e.g. machine translation). However, most\ncurrent state-of-the-art NLP models such as the Transformer operate\nnon-incrementally, potentially causing unacceptable delays. We propose a\nstreaming BERT-based sequence tagging model that, combined with a novel\ntraining objective, is capable of detecting disfluencies in real-time while\nbalancing accuracy and latency. This is accomplished by training the model to\ndecide whether to immediately output a prediction for the current input or to\nwait for further context. Essentially, the model learns to dynamically size its\nlookahead window. Our results demonstrate that our model produces comparably\naccurate predictions and does so sooner than our baselines, with lower flicker.\nFurthermore, the model attains state-of-the-art latency and stability scores\nwhen compared with recent work on incremental disfluency detection.", "published": "2022-05-02 02:13:24", "link": "http://arxiv.org/abs/2205.00620v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Fine-tuning via Perturbation and Interpolation from In-batch\n  Instances", "abstract": "Fine-tuning pretrained language models (PLMs) on downstream tasks has become\ncommon practice in natural language processing. However, most of the PLMs are\nvulnerable, e.g., they are brittle under adversarial attacks or imbalanced\ndata, which hinders the application of the PLMs on some downstream tasks,\nespecially in safe-critical scenarios. In this paper, we propose a simple yet\neffective fine-tuning method called Match-Tuning to force the PLMs to be more\nrobust. For each instance in a batch, we involve other instances in the same\nbatch to interact with it. To be specific, regarding the instances with other\nlabels as a perturbation, Match-Tuning makes the model more robust to noise at\nthe beginning of training. While nearing the end, Match-Tuning focuses more on\nperforming an interpolation among the instances with the same label for better\ngeneralization. Extensive experiments on various tasks in GLUE benchmark show\nthat Match-Tuning consistently outperforms the vanilla fine-tuning by $1.64$\nscores. Moreover, Match-Tuning exhibits remarkable robustness to adversarial\nattacks and data imbalance.", "published": "2022-05-02 03:21:35", "link": "http://arxiv.org/abs/2205.00633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Two Parameters Equation for Word Rank-Frequency Relation", "abstract": "Let $f (\\cdot)$ be the absolute frequency of words and $r$ be the rank of\nwords in decreasing order of frequency, then the following function can fit the\nrank-frequency relation \\[ f (r;s,t) = \\left(\\frac{r_{\\tt max}}{r}\\right)^{1-s}\n\\left(\\frac{r_{\\tt max}+t \\cdot r_{\\tt exp}}{r+t \\cdot r_{\\tt\nexp}}\\right)^{1+(1+t)s} \\] where $r_{\\tt max}$ and $r_{\\tt exp}$ are the\nmaximum and the expectation of the rank, respectively; $s>0$ and $t>0$ are\nparameters estimated from data. On well-behaved data, there should be $s<1$ and\n$s \\cdot t < 1$.", "published": "2022-05-02 04:07:59", "link": "http://arxiv.org/abs/2205.00638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Debiased Contrastive Learning of Unsupervised Sentence Representations", "abstract": "Recently, contrastive learning has been shown to be effective in improving\npre-trained language models (PLM) to derive high-quality sentence\nrepresentations. It aims to pull close positive examples to enhance the\nalignment while push apart irrelevant negatives for the uniformity of the whole\nrepresentation space. However, previous works mostly adopt in-batch negatives\nor sample from training data at random. Such a way may cause the sampling bias\nthat improper negatives (e.g. false negatives and anisotropy representations)\nare used to learn sentence representations, which will hurt the uniformity of\nthe representation space. To address it, we present a new framework\n\\textbf{DCLR} (\\underline{D}ebiased \\underline{C}ontrastive\n\\underline{L}earning of unsupervised sentence \\underline{R}epresentations) to\nalleviate the influence of these improper negatives. In DCLR, we design an\ninstance weighting method to punish false negatives and generate noise-based\nnegatives to guarantee the uniformity of the representation space. Experiments\non seven semantic textual similarity tasks show that our approach is more\neffective than competitive baselines. Our code and data are publicly available\nat the link: \\textcolor{blue}{\\url{https://github.com/RUCAIBox/DCLR}}.", "published": "2022-05-02 05:07:43", "link": "http://arxiv.org/abs/2205.00656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Implicit Length Bias of Label Smoothing on Beam Search Decoding", "abstract": "Label smoothing is ubiquitously applied in Neural Machine Translation (NMT)\ntraining. While label smoothing offers a desired regularization effect during\nmodel training, in this paper we demonstrate that it nevertheless introduces\nlength biases in the beam search decoding procedure. Our analysis shows that\nlabel smoothing implicitly applies a length penalty term to output sequence,\ncausing a bias towards shorter translations. We also show that for a model\nfully optimized with label smoothing, translation length is implicitly upper\nbounded by a fixed constant independent of input. We verify our theory by\napplying a simple rectification function at inference time to restore the\nunbiased distributions from the label-smoothed model predictions. This\nrectification method led to consistent quality improvements on WMT\nEnglish-German, English-French, English-Czech and English-Chinese tasks, up to\n+0.3 BLEU at beam size 4 and +2.8 BLEU at beam size 200.", "published": "2022-05-02 05:25:56", "link": "http://arxiv.org/abs/2205.00659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Jam or Cream First? Modeling Ambiguity in Neural Machine Translation\n  with SCONES", "abstract": "The softmax layer in neural machine translation is designed to model the\ndistribution over mutually exclusive tokens. Machine translation, however, is\nintrinsically uncertain: the same source sentence can have multiple\nsemantically equivalent translations. Therefore, we propose to replace the\nsoftmax activation with a multi-label classification layer that can model\nambiguity more effectively. We call our loss function Single-label Contrastive\nObjective for Non-Exclusive Sequences (SCONES). We show that the multi-label\noutput layer can still be trained on single reference training data using the\nSCONES loss function. SCONES yields consistent BLEU score gains across six\ntranslation directions, particularly for medium-resource language pairs and\nsmall beam sizes. By using smaller beam sizes we can speed up inference by a\nfactor of 3.9x and still match or improve the BLEU score obtained using\nsoftmax. Furthermore, we demonstrate that SCONES can be used to train NMT\nmodels that assign the highest probability to adequate translations, thus\nmitigating the \"beam search curse\". Additional experiments on synthetic\nlanguage pairs with varying levels of uncertainty suggest that the improvements\nfrom SCONES can be attributed to better handling of ambiguity.", "published": "2022-05-02 07:51:37", "link": "http://arxiv.org/abs/2205.00704v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Logiformer: A Two-Branch Graph Transformer Network for Interpretable\n  Logical Reasoning", "abstract": "Machine reading comprehension has aroused wide concerns, since it explores\nthe potential of model for text understanding. To further equip the machine\nwith the reasoning capability, the challenging task of logical reasoning is\nproposed. Previous works on logical reasoning have proposed some strategies to\nextract the logical units from different aspects. However, there still remains\na challenge to model the long distance dependency among the logical units.\nAlso, it is demanding to uncover the logical structures of the text and further\nfuse the discrete logic to the continuous text embedding. To tackle the above\nissues, we propose an end-to-end model Logiformer which utilizes a two-branch\ngraph transformer network for logical reasoning of text. Firstly, we introduce\ndifferent extraction strategies to split the text into two sets of logical\nunits, and construct the logical graph and the syntax graph respectively. The\nlogical graph models the causal relations for the logical branch while the\nsyntax graph captures the co-occurrence relations for the syntax branch.\nSecondly, to model the long distance dependency, the node sequence from each\ngraph is fed into the fully connected graph transformer structures. The two\nadjacent matrices are viewed as the attention biases for the graph transformer\nlayers, which map the discrete logical structures to the continuous text\nembedding space. Thirdly, a dynamic gate mechanism and a question-aware\nself-attention module are introduced before the answer prediction to update the\nfeatures. The reasoning process provides the interpretability by employing the\nlogical units, which are consistent with human cognition. The experimental\nresults show the superiority of our model, which outperforms the\nstate-of-the-art single model on two logical reasoning benchmarks.", "published": "2022-05-02 08:34:59", "link": "http://arxiv.org/abs/2205.00731v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neutral Utterances are Also Causes: Enhancing Conversational Causal\n  Emotion Entailment with Social Commonsense Knowledge", "abstract": "Conversational Causal Emotion Entailment aims to detect causal utterances for\na non-neutral targeted utterance from a conversation. In this work, we build\nconversations as graphs to overcome implicit contextual modelling of the\noriginal entailment style. Following the previous work, we further introduce\nthe emotion information into graphs. Emotion information can markedly promote\nthe detection of causal utterances whose emotion is the same as the targeted\nutterance. However, it is still hard to detect causal utterances with different\nemotions, especially neutral ones. The reason is that models are limited in\nreasoning causal clues and passing them between utterances. To alleviate this\nproblem, we introduce social commonsense knowledge (CSK) and propose a\nKnowledge Enhanced Conversation graph (KEC). KEC propagates the CSK between two\nutterances. As not all CSK is emotionally suitable for utterances, we therefore\npropose a sentiment-realized knowledge selecting strategy to filter CSK. To\nprocess KEC, we further construct the Knowledge Enhanced Directed Acyclic Graph\nnetworks. Experimental results show that our method outperforms baselines and\ninfers more causes with different emotions from the targeted utterance.", "published": "2022-05-02 09:12:32", "link": "http://arxiv.org/abs/2205.00759v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TuGeBiC: A Turkish German Bilingual Code-Switching Corpus", "abstract": "In this paper we describe the process of collection, transcription, and\nannotation of recordings of spontaneous speech samples from Turkish-German\nbilinguals, and the compilation of a corpus called TuGeBiC. Participants in the\nstudy were adult Turkish-German bilinguals living in Germany or Turkey at the\ntime of recording in the first half of the 1990s. The data were manually\ntokenised and normalised, and all proper names (names of participants and\nplaces mentioned in the conversations) were replaced with pseudonyms.\nToken-level automatic language identification was performed, which made it\npossible to establish the proportions of words from each language. The corpus\nis roughly balanced between both languages. We also present quantitative\ninformation about the number of code-switches, and give examples of different\ntypes of code-switching found in the data. The resulting corpus has been made\nfreely available to the research community.", "published": "2022-05-02 12:53:05", "link": "http://arxiv.org/abs/2205.00868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COSPLAY: Concept Set Guided Personalized Dialogue Generation Across Both\n  Party Personas", "abstract": "Maintaining a consistent persona is essential for building a human-like\nconversational model. However, the lack of attention to the partner makes the\nmodel more egocentric: they tend to show their persona by all means such as\ntwisting the topic stiffly, pulling the conversation to their own interests\nregardless, and rambling their persona with little curiosity to the partner. In\nthis work, we propose COSPLAY(COncept Set guided PersonaLized dialogue\ngeneration Across both partY personas) that considers both parties as a \"team\":\nexpressing self-persona while keeping curiosity toward the partner, leading\nresponses around mutual personas, and finding the common ground. Specifically,\nwe first represent self-persona, partner persona and mutual dialogue all in the\nconcept sets. Then, we propose the Concept Set framework with a suite of\nknowledge-enhanced operations to process them such as set algebras, set\nexpansion, and set distance. Based on these operations as medium, we train the\nmodel by utilizing 1) concepts of both party personas, 2) concept relationship\nbetween them, and 3) their relationship to the future dialogue. Extensive\nexperiments on a large public dataset, Persona-Chat, demonstrate that our model\noutperforms state-of-the-art baselines for generating less egocentric, more\nhuman-like, and higher quality responses in both automatic and human\nevaluations.", "published": "2022-05-02 12:55:40", "link": "http://arxiv.org/abs/2205.00872v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "State-of-the-art in Open-domain Conversational AI: A Survey", "abstract": "We survey SoTA open-domain conversational AI models with the purpose of\npresenting the prevailing challenges that still exist to spur future research.\nIn addition, we provide statistics on the gender of conversational AI in order\nto guide the ethics discussion surrounding the issue. Open-domain\nconversational AI are known to have several challenges, including bland\nresponses and performance degradation when prompted with figurative language,\namong others. First, we provide some background by discussing some topics of\ninterest in conversational AI. We then discuss the method applied to the two\ninvestigations carried out that make up this study. The first investigation\ninvolves a search for recent SoTA open-domain conversational AI models while\nthe second involves the search for 100 conversational AI to assess their\ngender. Results of the survey show that progress has been made with recent SoTA\nconversational AI, but there are still persistent challenges that need to be\nsolved, and the female gender is more common than the male for conversational\nAI. One main take-away is that hybrid models of conversational AI offer more\nadvantages than any single architecture. The key contributions of this survey\nare 1) the identification of prevailing challenges in SoTA open-domain\nconversational AI, 2) the unusual discussion about open-domain conversational\nAI for low-resource languages, and 3) the discussion about the ethics\nsurrounding the gender of conversational AI.", "published": "2022-05-02 15:08:18", "link": "http://arxiv.org/abs/2205.00965v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quality-Aware Decoding for Neural Machine Translation", "abstract": "Despite the progress in machine translation quality estimation and evaluation\nin the last years, decoding in neural machine translation (NMT) is mostly\noblivious to this and centers around finding the most probable translation\naccording to the model (MAP decoding), approximated with beam search. In this\npaper, we bring together these two lines of research and propose quality-aware\ndecoding for NMT, by leveraging recent breakthroughs in reference-free and\nreference-based MT evaluation through various inference methods like $N$-best\nreranking and minimum Bayes risk decoding. We perform an extensive comparison\nof various possible candidate generation and ranking methods across four\ndatasets and two model classes and find that quality-aware decoding\nconsistently outperforms MAP-based decoding according both to state-of-the-art\nautomatic metrics (COMET and BLEURT) and to human assessments. Our code is\navailable at https://github.com/deep-spin/qaware-decode.", "published": "2022-05-02 15:26:28", "link": "http://arxiv.org/abs/2205.00978v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Factors Should Paper-Reviewer Assignments Rely On? Community\n  Perspectives on Issues and Ideals in Conference Peer-Review", "abstract": "Both scientific progress and individual researcher careers depend on the\nquality of peer review, which in turn depends on paper-reviewer matching.\nSurprisingly, this problem has been mostly approached as an automated\nrecommendation problem rather than as a matter where different stakeholders\n(area chairs, reviewers, authors) have accumulated experience worth taking into\naccount. We present the results of the first survey of the NLP community,\nidentifying common issues and perspectives on what factors should be considered\nby paper-reviewer matching systems. This study contributes actionable\nrecommendations for improving future NLP conferences, and desiderata for\ninterpretable peer review assignments.", "published": "2022-05-02 16:07:02", "link": "http://arxiv.org/abs/2205.01005v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paragraph-based Transformer Pre-training for Multi-Sentence Inference", "abstract": "Inference tasks such as answer sentence selection (AS2) or fact verification\nare typically solved by fine-tuning transformer-based models as individual\nsentence-pair classifiers. Recent studies show that these tasks benefit from\nmodeling dependencies across multiple candidate sentences jointly. In this\npaper, we first show that popular pre-trained transformers perform poorly when\nused for fine-tuning on multi-candidate inference tasks. We then propose a new\npre-training objective that models the paragraph-level semantics across\nmultiple input sentences. Our evaluation on three AS2 and one fact verification\ndatasets demonstrates the superiority of our pre-training technique over the\ntraditional ones for transformers used as joint models for multi-candidate\ninference tasks, as well as when used as cross-encoders for sentence-pair\nformulations of these tasks. Our code and pre-trained models are released at\nhttps://github.com/amazon-research/wqa-multi-sentence-inference .", "published": "2022-05-02 21:41:14", "link": "http://arxiv.org/abs/2205.01228v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantically Informed Slang Interpretation", "abstract": "Slang is a predominant form of informal language making flexible and extended\nuse of words that is notoriously hard for natural language processing systems\nto interpret. Existing approaches to slang interpretation tend to rely on\ncontext but ignore semantic extensions common in slang word usage. We propose a\nsemantically informed slang interpretation (SSI) framework that considers\njointly the contextual and semantic appropriateness of a candidate\ninterpretation for a query slang. We perform rigorous evaluation on two\nlarge-scale online slang dictionaries and show that our approach not only\nachieves state-of-the-art accuracy for slang interpretation in English, but\nalso does so in zero-shot and few-shot scenarios where training data is sparse.\nFurthermore, we show how the same framework can be applied to enhancing machine\ntranslation of slang from English to other languages. Our work creates\nopportunities for the automated interpretation and translation of informal\nlanguage.", "published": "2022-05-02 01:51:49", "link": "http://arxiv.org/abs/2205.00616v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Library Perspective on Nearly-Unsupervised Information Extraction\n  Workflows in Digital Libraries", "abstract": "Information extraction can support novel and effective access paths for\ndigital libraries. Nevertheless, designing reliable extraction workflows can be\ncost-intensive in practice. On the one hand, suitable extraction methods rely\non domain-specific training data. On the other hand, unsupervised and open\nextraction methods usually produce not-canonicalized extraction results. This\npaper tackles the question how digital libraries can handle such extractions\nand if their quality is sufficient in practice. We focus on unsupervised\nextraction workflows by analyzing them in case studies in the domains of\nencyclopedias (Wikipedia), pharmacy and political sciences. We report on\nopportunities and limitations. Finally we discuss best practices for\nunsupervised extraction workflows.", "published": "2022-05-02 08:11:32", "link": "http://arxiv.org/abs/2205.00716v1", "categories": ["cs.CL", "cs.DL", "H.4"], "primary_category": "cs.CL"}
{"title": "Entity-aware Transformers for Entity Search", "abstract": "Pre-trained language models such as BERT have been a key ingredient to\nachieve state-of-the-art results on a variety of tasks in natural language\nprocessing and, more recently, also in information retrieval.Recent research\neven claims that BERT is able to capture factual knowledge about entity\nrelations and properties, the information that is commonly obtained from\nknowledge graphs. This paper investigates the following question: Do BERT-based\nentity retrieval models benefit from additional entity information stored in\nknowledge graphs? To address this research question, we map entity embeddings\ninto the same input space as a pre-trained BERT model and inject these entity\nembeddings into the BERT model. This entity-enriched language model is then\nemployed on the entity retrieval task. We show that the entity-enriched BERT\nmodel improves effectiveness on entity-oriented queries over a regular BERT\nmodel, establishing a new state-of-the-art result for the entity retrieval\ntask, with substantial improvements for complex natural language queries and\nqueries requesting a list of entities with a certain property. Additionally, we\nshow that the entity information provided by our entity-enriched model\nparticularly helps queries related to less popular entities. Last, we observe\nempirically that the entity-enriched BERT models enable fine-tuning on limited\ntraining data, which otherwise would not be feasible due to the known\ninstabilities of BERT in few-sample fine-tuning, thereby contributing to\ndata-efficient training of BERT for entity search.", "published": "2022-05-02 11:53:59", "link": "http://arxiv.org/abs/2205.00820v1", "categories": ["cs.IR", "cs.CL", "H.3.3"], "primary_category": "cs.IR"}
{"title": "OPT: Open Pre-trained Transformer Language Models", "abstract": "Large language models, which are often trained for hundreds of thousands of\ncompute days, have shown remarkable capabilities for zero- and few-shot\nlearning. Given their computational cost, these models are difficult to\nreplicate without significant capital. For the few that are available through\nAPIs, no access is granted to the full model weights, making them difficult to\nstudy. We present Open Pre-trained Transformers (OPT), a suite of decoder-only\npre-trained transformers ranging from 125M to 175B parameters, which we aim to\nfully and responsibly share with interested researchers. We show that OPT-175B\nis comparable to GPT-3, while requiring only 1/7th the carbon footprint to\ndevelop. We are also releasing our logbook detailing the infrastructure\nchallenges we faced, along with code for experimenting with all of the released\nmodels.", "published": "2022-05-02 17:49:50", "link": "http://arxiv.org/abs/2205.01068v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning for Improving ASR Robustness in Spoken Language\n  Understanding", "abstract": "Spoken language understanding (SLU) is an essential task for machines to\nunderstand human speech for better interactions. However, errors from the\nautomatic speech recognizer (ASR) usually hurt the understanding performance.\nIn reality, ASR systems may not be easy to adjust for the target scenarios.\nTherefore, this paper focuses on learning utterance representations that are\nrobust to ASR errors using a contrastive objective, and further strengthens the\ngeneralization ability by combining supervised contrastive learning and\nself-distillation in model fine-tuning. Experiments on three benchmark datasets\ndemonstrate the effectiveness of our proposed approach.", "published": "2022-05-02 07:21:21", "link": "http://arxiv.org/abs/2205.00693v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Wav2Seq: Pre-training Speech-to-Text Encoder-Decoder Models Using Pseudo\n  Languages", "abstract": "We introduce Wav2Seq, the first self-supervised approach to pre-train both\nparts of encoder-decoder models for speech data. We induce a pseudo language as\na compact discrete representation, and formulate a self-supervised pseudo\nspeech recognition task -- transcribing audio inputs into pseudo subword\nsequences. This process stands on its own, or can be applied as low-cost\nsecond-stage pre-training. We experiment with automatic speech recognition\n(ASR), spoken named entity recognition, and speech-to-text translation. We set\nnew state-of-the-art results for end-to-end spoken named entity recognition,\nand show consistent improvements on 20 language pairs for speech-to-text\ntranslation, even when competing methods use additional text data for training.\nFinally, on ASR, our approach enables encoder-decoder methods to benefit from\npre-training for all parts of the network, and shows comparable performance to\nhighly optimized recent methods.", "published": "2022-05-02 17:59:02", "link": "http://arxiv.org/abs/2205.01086v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine\n  Translation", "abstract": "Multi-modal Machine Translation (MMT) enables the use of visual information\nto enhance the quality of translations. The visual information can serve as a\nvaluable piece of context information to decrease the ambiguity of input\nsentences. Despite the increasing popularity of such a technique, good and\nsizeable datasets are scarce, limiting the full extent of their potential.\nHausa, a Chadic language, is a member of the Afro-Asiatic language family. It\nis estimated that about 100 to 150 million people speak the language, with more\nthan 80 million indigenous speakers. This is more than any of the other Chadic\nlanguages. Despite a large number of speakers, the Hausa language is considered\nlow-resource in natural language processing (NLP). This is due to the absence\nof sufficient resources to implement most NLP tasks. While some datasets exist,\nthey are either scarce, machine-generated, or in the religious domain.\nTherefore, there is a need to create training and evaluation data for\nimplementing machine learning tasks and bridging the research gap in the\nlanguage. This work presents the Hausa Visual Genome (HaVG), a dataset that\ncontains the description of an image or a section within the image in Hausa and\nits equivalent in English. To prepare the dataset, we started by translating\nthe English description of the images in the Hindi Visual Genome (HVG) into\nHausa automatically. Afterward, the synthetic Hausa data was carefully\npost-edited considering the respective images. The dataset comprises 32,923\nimages and their descriptions that are divided into training, development,\ntest, and challenge test set. The Hausa Visual Genome is the first dataset of\nits kind and can be used for Hausa-English machine translation, multi-modal\nresearch, and image description, among various other natural language\nprocessing and generation tasks.", "published": "2022-05-02 18:05:35", "link": "http://arxiv.org/abs/2205.01133v2", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Task Text Classification using Graph Convolutional Networks for\n  Large-Scale Low Resource Language", "abstract": "Graph Convolutional Networks (GCN) have achieved state-of-art results on\nsingle text classification tasks like sentiment analysis, emotion detection,\netc. However, the performance is achieved by testing and reporting on\nresource-rich languages like English. Applying GCN for multi-task text\nclassification is an unexplored area. Moreover, training a GCN or adopting an\nEnglish GCN for Indian languages is often limited by data availability, rich\nmorphological variation, syntax, and semantic differences. In this paper, we\nstudy the use of GCN for the Telugu language in single and multi-task settings\nfor four natural language processing (NLP) tasks, viz. sentiment analysis (SA),\nemotion identification (EI), hate-speech (HS), and sarcasm detection (SAR). In\norder to evaluate the performance of GCN with one of the Indian languages,\nTelugu, we analyze the GCN based models with extensive experiments on four\ndownstream tasks. In addition, we created an annotated Telugu dataset, TEL-NLP,\nfor the four NLP tasks. Further, we propose a supervised graph reconstruction\nmethod, Multi-Task Text GCN (MT-Text GCN) on the Telugu that leverages to\nsimultaneously (i) learn the low-dimensional word and sentence graph embeddings\nfrom word-sentence graph reconstruction using graph autoencoder (GAE) and (ii)\nperform multi-task text classification using these latent sentence graph\nembeddings. We argue that our proposed MT-Text GCN achieves significant\nimprovements on TEL-NLP over existing Telugu pretrained word embeddings, and\nmultilingual pretrained Transformer models: mBERT, and XLM-R. On TEL-NLP, we\nachieve a high F1-score for four NLP tasks: SA (0.84), EI (0.55), HS (0.83) and\nSAR (0.66). Finally, we show our model's quantitative and qualitative analysis\non the four NLP tasks in Telugu.", "published": "2022-05-02 20:44:12", "link": "http://arxiv.org/abs/2205.01204v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrieval-Enhanced Machine Learning", "abstract": "Although information access systems have long supported people in\naccomplishing a wide range of tasks, we propose broadening the scope of users\nof information access systems to include task-driven machines, such as machine\nlearning models. In this way, the core principles of indexing, representation,\nretrieval, and ranking can be applied and extended to substantially improve\nmodel generalization, scalability, robustness, and interpretability. We\ndescribe a generic retrieval-enhanced machine learning (REML) framework, which\nincludes a number of existing models as special cases. REML challenges\ninformation retrieval conventions, presenting opportunities for novel advances\nin core areas, including optimization. The REML research agenda lays a\nfoundation for a new style of information access research and paves a path\ntowards advancing machine learning and artificial intelligence.", "published": "2022-05-02 21:42:45", "link": "http://arxiv.org/abs/2205.01230v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "The Limits of Word Level Differential Privacy", "abstract": "As the issues of privacy and trust are receiving increasing attention within\nthe research community, various attempts have been made to anonymize textual\ndata. A significant subset of these approaches incorporate differentially\nprivate mechanisms to perturb word embeddings, thus replacing individual words\nin a sentence. While these methods represent very important contributions, have\nvarious advantages over other techniques and do show anonymization\ncapabilities, they have several shortcomings. In this paper, we investigate\nthese weaknesses and demonstrate significant mathematical constraints\ndiminishing the theoretical privacy guarantee as well as major practical\nshortcomings with regard to the protection against deanonymization attacks, the\npreservation of content of the original sentences as well as the quality of the\nlanguage output. Finally, we propose a new method for text anonymization based\non transformer based language models fine-tuned for paraphrasing that\ncircumvents most of the identified weaknesses and also offers a formal privacy\nguarantee. We evaluate the performance of our method via thorough\nexperimentation and demonstrate superior performance over the discussed\nmechanisms.", "published": "2022-05-02 21:53:10", "link": "http://arxiv.org/abs/2205.02130v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "A Meeting Transcription System for an Ad-Hoc Acoustic Sensor Network", "abstract": "We propose a system that transcribes the conversation of a typical meeting\nscenario that is captured by a set of initially unsynchronized microphone\narrays at unknown positions. It consists of subsystems for signal\nsynchronization, including both sampling rate and sampling time offset\nestimation, diarization based on speaker and microphone array position\nestimation, multi-channel speech enhancement, and automatic speech recognition.\nWith the estimated diarization information, a spatial mixture model is\ninitialized that is used to estimate beamformer coefficients for source\nseparation. Simulations show that the speech recognition accuracy can be\nimproved by synchronizing and combining multiple distributed microphone arrays\ncompared to a single compact microphone array. Furthermore, the proposed\ninformed initialization of the spatial mixture model delivers a clear\nperformance advantage over random initialization.", "published": "2022-05-02 14:43:52", "link": "http://arxiv.org/abs/2205.00944v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Music Interpretation Analysis. A Multimodal Approach To Score-Informed\n  Resynthesis of Piano Recordings", "abstract": "This Thesis discusses the development of technologies for the automatic\nresynthesis of music recordings using digital synthesizers. First, the main\nissue is identified in the understanding of how Music Information Processing\n(MIP) methods can take into consideration the influence of the acoustic context\non the music performance. For this, a novel conceptual and mathematical\nframework named \"Music Interpretation Analysis\" (MIA) is presented. In the\nproposed framework, a distinction is made between the \"performance\" - the\nphysical action of playing - and the \"interpretation\" - the action that the\nperformer wishes to achieve. Second, the Thesis describes further works aiming\nat the democratization of music production tools via automatic resynthesis: 1)\nit elaborates software and file formats for historical music archiving and\nmultimodal machine-learning datasets; 2) it explores and extends MIP\ntechnologies; 3) it presents the mathematical foundations of the MIA framework\nand shows preliminary evaluations to demonstrate the effectiveness of the\napproach", "published": "2022-05-02 14:40:44", "link": "http://arxiv.org/abs/2205.00941v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "HarmoF0: Logarithmic Scale Dilated Convolution For Pitch Estimation", "abstract": "Sounds, especially music, contain various harmonic components scattered in\nthe frequency dimension. It is difficult for normal convolutional neural\nnetworks to observe these overtones. This paper introduces a multiple rates\ndilated causal convolution (MRDC-Conv) method to capture the harmonic structure\nin logarithmic scale spectrograms efficiently. The harmonic is helpful for\npitch estimation, which is important for many sound processing applications. We\npropose HarmoF0, a fully convolutional network, to evaluate the MRDC-Conv and\nother dilated convolutions in pitch estimation. The results show that this\nmodel outperforms the DeepF0, yields state-of-the-art performance in three\ndatasets, and simultaneously reduces more than 90% parameters. We also find\nthat it has stronger noise resistance and fewer octave errors. The code and\npre-trained model are available at https://github.com/WX-Wei/HarmoF0.", "published": "2022-05-02 16:45:20", "link": "http://arxiv.org/abs/2205.01019v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PSCNN: A 885.86 TOPS/W Programmable SRAM-based Computing-In-Memory\n  Processor for Keyword Spotting", "abstract": "Computing-in-memory (CIM) has attracted significant attentions in recent\nyears due to its massive parallelism and low power consumption. However,\ncurrent CIM designs suffer from large area overhead of small CIM macros and bad\nprogrammablity for model execution. This paper proposes a programmable CIM\nprocessor with a single large sized CIM macro instead of multiple smaller ones\nfor power efficient computation and a flexible instruction set to support\nvarious binary 1-D convolution Neural Network (CNN) models in an easy way.\nFurthermore, the proposed architecture adopts the pooling write-back method to\nsupport fused or independent convolution/pooling operations to reduce 35.9\\% of\nlatency, and the flexible ping-pong feature SRAM to fit different feature map\nsizes during layer-by-layer execution.The design fabricated in TSMC 28nm\ntechnology achieves 150.8 GOPS throughput and 885.86 TOPS/W power efficiency at\n10 MHz when executing our binary keyword spotting model, which has higher power\nefficiency and flexibility than previous designs.", "published": "2022-05-02 09:58:18", "link": "http://arxiv.org/abs/2205.01569v1", "categories": ["cs.AR", "cs.LG", "eess.AS"], "primary_category": "cs.AR"}
{"title": "A Novel Speech-Driven Lip-Sync Model with CNN and LSTM", "abstract": "Generating synchronized and natural lip movement with speech is one of the\nmost important tasks in creating realistic virtual characters. In this paper,\nwe present a combined deep neural network of one-dimensional convolutions and\nLSTM to generate vertex displacement of a 3D template face model from\nvariable-length speech input. The motion of the lower part of the face, which\nis represented by the vertex movement of 3D lip shapes, is consistent with the\ninput speech. In order to enhance the robustness of the network to different\nsound signals, we adapt a trained speech recognition model to extract speech\nfeature, and a velocity loss term is adopted to reduce the jitter of generated\nfacial animation. We recorded a series of videos of a Chinese adult speaking\nMandarin and created a new speech-animation dataset to compensate the lack of\nsuch public data. Qualitative and quantitative evaluations indicate that our\nmodel is able to generate smooth and natural lip movements synchronized with\nspeech.", "published": "2022-05-02 13:57:50", "link": "http://arxiv.org/abs/2205.00916v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.GR", "eess.AS", "68T07, 68T45", "I.2.10; I.3.7"], "primary_category": "cs.SD"}
