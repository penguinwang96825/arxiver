{"title": "Replication issues in syntax-based aspect extraction for opinion mining", "abstract": "Reproducing experiments is an important instrument to validate previous work\nand build upon existing approaches. It has been tackled numerous times in\ndifferent areas of science. In this paper, we introduce an empirical\nreplicability study of three well-known algorithms for syntactic centric\naspect-based opinion mining. We show that reproducing results continues to be a\ndifficult endeavor, mainly due to the lack of details regarding preprocessing\nand parameter setting, as well as due to the absence of available\nimplementations that clarify these details. We consider these are important\nthreats to validity of the research on the field, specifically when compared to\nother problems in NLP where public datasets and code availability are critical\nvalidity components. We conclude by encouraging code-based research, which we\nthink has a key role in helping researchers to understand the meaning of the\nstate-of-the-art better and to generate continuous advances.", "published": "2017-01-06 08:18:38", "link": "http://arxiv.org/abs/1701.01565v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Real Multi-Sense or Pseudo Multi-Sense: An Approach to Improve Word\n  Representation", "abstract": "Previous researches have shown that learning multiple representations for\npolysemous words can improve the performance of word embeddings on many tasks.\nHowever, this leads to another problem. Several vectors of a word may actually\npoint to the same meaning, namely pseudo multi-sense. In this paper, we\nintroduce the concept of pseudo multi-sense, and then propose an algorithm to\ndetect such cases. With the consideration of the detected pseudo multi-sense\ncases, we try to refine the existing word embeddings to eliminate the influence\nof pseudo multi-sense. Moreover, we apply our algorithm on previous released\nmulti-sense word embeddings and tested it on artificial word similarity tasks\nand the analogy task. The result of the experiments shows that diminishing\npseudo multi-sense can improve the quality of word representations. Thus, our\nmethod is actually an efficient way to reduce linguistic complexity.", "published": "2017-01-06 08:52:41", "link": "http://arxiv.org/abs/1701.01574v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enumeration of Extractive Oracle Summaries", "abstract": "To analyze the limitations and the future directions of the extractive\nsummarization paradigm, this paper proposes an Integer Linear Programming (ILP)\nformulation to obtain extractive oracle summaries in terms of ROUGE-N. We also\npropose an algorithm that enumerates all of the oracle summaries for a set of\nreference summaries to exploit F-measures that evaluate which system summaries\ncontain how many sentences that are extracted as an oracle summary. Our\nexperimental results obtained from Document Understanding Conference (DUC)\ncorpora demonstrated the following: (1) room still exists to improve the\nperformance of extractive summarization; (2) the F-measures derived from the\nenumerated oracle summaries have significantly stronger correlations with human\njudgment than those derived from single oracle summaries.", "published": "2017-01-06 12:28:15", "link": "http://arxiv.org/abs/1701.01614v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Dependency Parsing with Late Decoding for Truly\n  Low-Resource Languages", "abstract": "In cross-lingual dependency annotation projection, information is often lost\nduring transfer because of early decoding. We present an end-to-end graph-based\nneural network dependency parser that can be trained to reproduce matrices of\nedge scores, which can be directly projected across word alignments. We show\nthat our approach to cross-lingual dependency parsing is not only simpler, but\nalso achieves an absolute improvement of 2.25% averaged across 10 languages\ncompared to the previous state of the art.", "published": "2017-01-06 12:54:48", "link": "http://arxiv.org/abs/1701.01623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
