{"title": "Word sense disambiguation: a survey", "abstract": "In this paper, we made a survey on Word Sense Disambiguation (WSD). Near\nabout in all major languages around the world, research in WSD has been\nconducted upto different extents. In this paper, we have gone through a survey\nregarding the different approaches adopted in different research works, the\nState of the Art in the performance in this domain, recent works in different\nIndian languages and finally a survey in Bengali language. We have made a\nsurvey on different competitions in this field and the bench mark results,\nobtained from those competitions.", "published": "2015-08-06 10:15:51", "link": "http://arxiv.org/abs/1508.01346v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic classification of bengali sentences based on sense definitions\n  present in bengali wordnet", "abstract": "Based on the sense definition of words available in the Bengali WordNet, an\nattempt is made to classify the Bengali sentences automatically into different\ngroups in accordance with their underlying senses. The input sentences are\ncollected from 50 different categories of the Bengali text corpus developed in\nthe TDIL project of the Govt. of India, while information about the different\nsenses of particular ambiguous lexical item is collected from Bengali WordNet.\nIn an experimental basis we have used Naive Bayes probabilistic model as a\nuseful classifier of sentences. We have applied the algorithm over 1747\nsentences that contain a particular Bengali lexical item which, because of its\nambiguous nature, is able to trigger different senses that render sentences in\ndifferent meanings. In our experiment we have achieved around 84% accurate\nresult on the sense classification over the total input sentences. We have\nanalyzed those residual sentences that did not comply with our experiment and\ndid affect the results to note that in many cases, wrong syntactic structures\nand less semantic information are the main hurdles in semantic classification\nof sentences. The applicational relevance of this study is attested in\nautomatic text classification, machine learning, information extraction, and\nword sense disambiguation.", "published": "2015-08-06 10:26:40", "link": "http://arxiv.org/abs/1508.01349v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hyponymy extraction of domain ontology concept based on ccrfs and\n  hierarchy clustering", "abstract": "Concept hierarchy is the backbone of ontology, and the concept hierarchy\nacquisition has been a hot topic in the field of ontology learning. this paper\nproposes a hyponymy extraction method of domain ontology concept based on\ncascaded conditional random field(CCRFs) and hierarchy clustering. It takes\nfree text as extracting object, adopts CCRFs identifying the domain concepts.\nFirst the low layer of CCRFs is used to identify simple domain concept, then\nthe results are sent to the high layer, in which the nesting concepts are\nrecognized. Next we adopt hierarchy clustering to identify the hyponymy\nrelation between domain ontology concepts. The experimental results demonstrate\nthe proposed method is efficient.", "published": "2015-08-06 18:02:54", "link": "http://arxiv.org/abs/1508.01476v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Gobbledygook and Mood of the Philippine Senate: An Exploratory Study\n  on the Readability and Sentiment of Selected Philippine Senators' Microposts", "abstract": "This paper presents the findings of a readability assessment and sentiment\nanalysis of selected six Philippine senators' microposts over the popular\nTwitter microblog. Using the Simple Measure of Gobbledygook (SMOG), tweets of\nSenators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and\nEscudero were assessed. A sentiment analysis was also done to determine the\npolarity of the senators' respective microposts. Results showed that on the\naverage, the six senators are tweeting at an eight to ten SMOG level. This\nmeans that, at least a sixth grader will be able to understand the senators'\ntweets. Moreover, their tweets are mostly neutral and their sentiments vary in\nunison at some period of time. This could mean that a senator's tweet sentiment\nis affected by specific Philippine-based events.", "published": "2015-08-06 08:39:20", "link": "http://arxiv.org/abs/1508.01321v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Mood-based Genre Classification of Television Content", "abstract": "The classification of television content helps users organise and navigate\nthrough the large list of channels and programs now available. In this paper,\nwe address the problem of television content classification by exploiting text\ninformation extracted from program transcriptions. We present an analysis which\nadapts a model for sentiment that has been widely and successfully applied in\nother fields such as music or blog posts. We use a real-world dataset obtained\nfrom the Boxfish API to compare the performance of classifiers trained on a\nnumber of different feature sets. Our experiments show that, over a large\ncollection of television content, program genres can be represented in a\nthree-dimensional space of valence, arousal and dominance, and that promising\nclassification results can be achieved using features based on this\nrepresentation. This finding supports the use of the proposed representation of\ntelevision content as a feature space for similarity computation and\nrecommendation generation.", "published": "2015-08-06 23:53:30", "link": "http://arxiv.org/abs/1508.01571v1", "categories": ["cs.IR", "cs.CL", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Replication and Generalization of PRECISE", "abstract": "This report describes an initial replication study of the PRECISE system and\ndevelops a clearer, more formal description of the approach. Based on our\nevaluation, we conclude that the PRECISE results do not fully replicate.\nHowever the formalization developed here suggests a road map to further enhance\nand extend the approach pioneered by PRECISE.\n  After a long, productive discussion with Ana-Maria Popescu (one of the\nauthors of PRECISE) we got more clarity on the PRECISE approach and how the\nlexicon was authored for the GEO evaluation. Based on this we built a more\ndirect implementation over a repaired formalism. Although our new evaluation is\nnot yet complete, it is clear that the system is performing much better now. We\nwill continue developing our ideas and implementation and generate a future\nreport/publication that more accurately evaluates PRECISE like approaches.", "published": "2015-08-06 07:56:59", "link": "http://arxiv.org/abs/1508.01306v2", "categories": ["cs.CL", "cs.AI", "cs.DB", "H.5.2; I.2.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "Privacy-Preserving Multi-Document Summarization", "abstract": "State-of-the-art extractive multi-document summarization systems are usually\ndesigned without any concern about privacy issues, meaning that all documents\nare open to third parties. In this paper we propose a privacy-preserving\napproach to multi-document summarization. Our approach enables other parties to\nobtain summaries without learning anything else about the original documents'\ncontent. We use a hashing scheme known as Secure Binary Embeddings to convert\ndocuments representation containing key phrases and bag-of-words into bit\nstrings, allowing the computation of approximate distances, instead of exact\nones. Our experiments indicate that our system yields similar results to its\nnon-private counterpart on standard multi-document evaluation datasets.", "published": "2015-08-06 14:30:47", "link": "http://arxiv.org/abs/1508.01420v1", "categories": ["cs.IR", "cs.CL", "cs.CR", "H.3; I.2.7; K.4.1"], "primary_category": "cs.IR"}
{"title": "Using Linguistic Analysis to Translate Arabic Natural Language Queries\n  to SPARQL", "abstract": "The logic-based machine-understandable framework of the Semantic Web often\nchallenges naive users when they try to query ontology-based knowledge bases.\nExisting research efforts have approached this problem by introducing Natural\nLanguage (NL) interfaces to ontologies. These NL interfaces have the ability to\nconstruct SPARQL queries based on NL user queries. However, most efforts were\nrestricted to queries expressed in English, and they often benefited from the\nadvancement of English NLP tools. However, little research has been done to\nsupport querying the Arabic content on the Semantic Web by using NL queries.\nThis paper presents a domain-independent approach to translate Arabic NL\nqueries to SPARQL by leveraging linguistic analysis. Based on a special\nconsideration on Noun Phrases (NPs), our approach uses a language parser to\nextract NPs and the relations from Arabic parse trees and match them to the\nunderlying ontology. It then utilizes knowledge in the ontology to group NPs\ninto triple-based representations. A SPARQL query is finally generated by\nextracting targets and modifiers, and interpreting them into SPARQL. The\ninterpretation of advanced semantic features including negation, conjunctive\nand disjunctive modifiers is also supported. The approach was evaluated by\nusing two datasets consisting of OWL test data and queries, and the obtained\nresults have confirmed its feasibility to translate Arabic NL queries to\nSPARQL.", "published": "2015-08-06 16:10:21", "link": "http://arxiv.org/abs/1508.01447v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
