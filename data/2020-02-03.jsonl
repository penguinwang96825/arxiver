{"title": "Learning Contextualized Document Representations for Healthcare Answer\n  Retrieval", "abstract": "We present Contextual Discourse Vectors (CDV), a distributed document\nrepresentation for efficient answer retrieval from long healthcare documents.\nOur approach is based on structured query tuples of entities and aspects from\nfree text and medical taxonomies. Our model leverages a dual encoder\narchitecture with hierarchical LSTM layers and multi-task training to encode\nthe position of clinical entities and aspects alongside the document discourse.\nWe use our continuous representations to resolve queries with short latency\nusing approximate nearest neighbor search on sentence level. We apply the CDV\nmodel for retrieving coherent answer passages from nine English public health\nresources from the Web, addressing both patients and medical professionals.\nBecause there is no end-to-end training data available for all application\nscenarios, we train our model with self-supervised data from Wikipedia. We show\nthat our generalized model significantly outperforms several state-of-the-art\nbaselines for healthcare passage ranking and is able to adapt to heterogeneous\ndomains without additional fine-tuning.", "published": "2020-02-03 15:47:19", "link": "http://arxiv.org/abs/2002.00835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phylogenetic signal in phonotactics", "abstract": "Phylogenetic methods have broad potential in linguistics beyond tree\ninference. Here, we show how a phylogenetic approach opens the possibility of\ngaining historical insights from entirely new kinds of linguistic data--in this\ninstance, statistical phonotactics. We extract phonotactic data from 111\nPama-Nyungan vocabularies and apply tests for phylogenetic signal, quantifying\nthe degree to which the data reflect phylogenetic history. We test three\ndatasets: (1) binary variables recording the presence or absence of biphones\n(two-segment sequences) in a lexicon (2) frequencies of transitions between\nsegments, and (3) frequencies of transitions between natural sound classes.\nAustralian languages have been characterized as having a high degree of\nphonotactic homogeneity. Nevertheless, we detect phylogenetic signal in all\ndatasets. Phylogenetic signal is greater in finer-grained frequency data than\nin binary data, and greatest in natural-class-based data. These results\ndemonstrate the viability of employing a new source of readily extractable data\nin historical and comparative linguistics.", "published": "2020-02-03 01:23:41", "link": "http://arxiv.org/abs/2002.00527v2", "categories": ["cs.CL", "q-bio.PE", "J.5"], "primary_category": "cs.CL"}
{"title": "IART: Intent-aware Response Ranking with Transformers in\n  Information-seeking Conversation Systems", "abstract": "Personal assistant systems, such as Apple Siri, Google Assistant, Amazon\nAlexa, and Microsoft Cortana, are becoming ever more widely used. Understanding\nuser intent such as clarification questions, potential answers and user\nfeedback in information-seeking conversations is critical for retrieving good\nresponses. In this paper, we analyze user intent patterns in\ninformation-seeking conversations and propose an intent-aware neural response\nranking model \"IART\", which refers to \"Intent-Aware Ranking with Transformers\".\nIART is built on top of the integration of user intent modeling and language\nrepresentation learning with the Transformer architecture, which relies\nentirely on a self-attention mechanism instead of recurrent nets. It\nincorporates intent-aware utterance attention to derive an importance weighting\nscheme of utterances in conversation context with the aim of better\nconversation history understanding. We conduct extensive experiments with three\ninformation-seeking conversation data sets including both standard benchmarks\nand commercial data. Our proposed model outperforms all baseline methods with\nrespect to a variety of metrics. We also perform case studies and analysis of\nlearned user intent and its impact on response ranking in information-seeking\nconversations to provide interpretation of results.", "published": "2020-02-03 05:59:52", "link": "http://arxiv.org/abs/2002.00571v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "CoTK: An Open-Source Toolkit for Fast Development and Fair Evaluation of\n  Text Generation", "abstract": "In text generation evaluation, many practical issues, such as inconsistent\nexperimental settings and metric implementations, are often ignored but lead to\nunfair evaluation and untenable conclusions. We present CoTK, an open-source\ntoolkit aiming to support fast development and fair evaluation of text\ngeneration. In model development, CoTK helps handle the cumbersome issues, such\nas data processing, metric implementation, and reproduction. It standardizes\nthe development steps and reduces human errors which may lead to inconsistent\nexperimental settings. In model evaluation, CoTK provides implementation for\nmany commonly used metrics and benchmark models across different experimental\nsettings. As a unique feature, CoTK can signify when and which metric cannot be\nfairly compared. We demonstrate that it is convenient to use CoTK for model\ndevelopment and evaluation, particularly across different experimental\nsettings.", "published": "2020-02-03 07:15:29", "link": "http://arxiv.org/abs/2002.00583v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "How Far are We from Effective Context Modeling? An Exploratory Study on\n  Semantic Parsing in Context", "abstract": "Recently semantic parsing in context has received considerable attention,\nwhich is challenging since there are complex contextual phenomena. Previous\nworks verified their proposed methods in limited scenarios, which motivates us\nto conduct an exploratory study on context modeling methods under real-world\nsemantic parsing in context. We present a grammar-based decoding semantic\nparser and adapt typical context modeling methods on top of it. We evaluate 13\ncontext modeling methods on two large complex cross-domain datasets, and our\nbest model achieves state-of-the-art performances on both datasets with\nsignificant improvements. Furthermore, we summarize the most frequent\ncontextual phenomena, with a fine-grained analysis on representative models,\nwhich may shed light on potential research directions. Our code is available at\nhttps://github.com/microsoft/ContextualSP.", "published": "2020-02-03 11:28:10", "link": "http://arxiv.org/abs/2002.00652v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Detecting Fake News with Capsule Neural Networks", "abstract": "Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.", "published": "2020-02-03 22:13:07", "link": "http://arxiv.org/abs/2002.01030v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "An experiment exploring the theoretical and methodological challenges in\n  developing a semi-automated approach to analysis of small-N qualitative data", "abstract": "This paper experiments with designing a semi-automated qualitative data\nanalysis (QDA) algorithm to analyse 20 transcripts by using freeware.\nText-mining (TM) and QDA were guided by frequency and association measures,\nbecause these statistics remain robust when the sample size is small. The\nrefined TM algorithm split the text into various sizes based on a manually\nrevised dictionary. This lemmatisation approach may reflect the context of the\ntext better than uniformly tokenising the text into one single size. TM results\nwere used for initial coding. Code repacking was guided by association measures\nand external data to implement a general inductive QDA approach. The\ninformation retrieved by TM and QDA was depicted in subgraphs for comparisons.\nThe analyses were completed in 6-7 days. Both algorithms retrieved contextually\nconsistent and relevant information. However, the QDA algorithm retrieved more\nspecific information than TM alone. The QDA algorithm does not strictly comply\nwith the convention of TM or of QDA, but becomes a more efficient, systematic\nand transparent text analysis approach than a conventional QDA approach.\nScaling up QDA to reliably discover knowledge from text was exactly the\nresearch purpose. This paper also sheds light on understanding the relations\nbetween information technologies, theory and methodologies.", "published": "2020-02-03 17:55:19", "link": "http://arxiv.org/abs/2002.04513v2", "categories": ["cs.IR", "cs.CL", "I.1.2; I.1.4; I.2.7"], "primary_category": "cs.IR"}
{"title": "End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice\n  Activity Detection", "abstract": "This paper integrates a voice activity detection (VAD) function with\nend-to-end automatic speech recognition toward an online speech interface and\ntranscribing very long audio recordings. We focus on connectionist temporal\nclassification (CTC) and its extension of CTC/attention architectures. As\nopposed to an attention-based architecture, input-synchronous label prediction\ncan be performed based on a greedy search with the CTC (pre-)softmax output.\nThis prediction includes consecutive long blank labels, which can be regarded\nas a non-speech region. We use the labels as a cue for detecting speech\nsegments with simple thresholding. The threshold value is directly related to\nthe length of a non-speech region, which is more intuitive and easier to\ncontrol than conventional VAD hyperparameters. Experimental results on\nunsegmented data show that the proposed method outperformed the baseline\nmethods using the conventional energy-based and neural-network-based VAD\nmethods and achieved an RTF less than 0.2. The proposed method is publicly\navailable.", "published": "2020-02-03 03:36:34", "link": "http://arxiv.org/abs/2002.00551v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker", "abstract": "To access data stored in relational databases, users need to understand the\ndatabase schema and write a query using a query language such as SQL. To\nsimplify this task, text-to-SQL models attempt to translate a user's natural\nlanguage question to corresponding SQL query. Recently, several generative\ntext-to-SQL models have been developed. We propose a novel discriminative\nre-ranker to improve the performance of generative text-to-SQL models by\nextracting the best SQL query from the beam output predicted by the text-to-SQL\ngenerator, resulting in improved performance in the cases where the best query\nwas in the candidate list, but not at the top of the list. We build the\nre-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative\nstrengths of the text-to-SQL and re-ranker models across different query\nhardness levels, and suggest how to combine the two models for optimal\nperformance. We demonstrate the effectiveness of the re-ranker by applying it\nto two state-of-the-art text-to-SQL models, and achieve top 4 score on the\nSpider leaderboard at the time of writing this article.", "published": "2020-02-03 04:52:47", "link": "http://arxiv.org/abs/2002.00557v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion\n  Networks", "abstract": "Spoken dialogue systems typically use a list of top-N ASR hypotheses for\ninferring the semantic meaning and tracking the state of the dialogue. However\nASR graphs, such as confusion networks (confnets), provide a compact\nrepresentation of a richer hypothesis space than a top-N ASR list. In this\npaper, we study the benefits of using confusion networks with a\nstate-of-the-art neural dialogue state tracker (DST). We encode the\n2-dimensional confnet into a 1-dimensional sequence of embeddings using an\nattentional confusion network encoder which can be used with any DST system.\nOur confnet encoder is plugged into the state-of-the-art 'Global-locally\nSelf-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains\nsignificant improvements in both accuracy and inference time compared to using\ntop-N ASR hypotheses.", "published": "2020-02-03 14:11:48", "link": "http://arxiv.org/abs/2002.00768v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Torch-Struct: Deep Structured Prediction Library", "abstract": "The literature on structured prediction for NLP describes a rich collection\nof distributions and algorithms over sequences, segmentations, alignments, and\ntrees; however, these algorithms are difficult to utilize in deep learning\nframeworks. We introduce Torch-Struct, a library for structured prediction\ndesigned to take advantage of and integrate with vectorized,\nauto-differentiation based frameworks. Torch-Struct includes a broad collection\nof probabilistic structures accessed through a simple and flexible\ndistribution-based API that connects to any deep learning model. The library\nutilizes batched, vectorized operations and exploits auto-differentiation to\nproduce readable, fast, and testable code. Internally, we also include a number\nof general-purpose optimizations to provide cross-algorithm efficiency.\nExperiments show significant performance gains over fast baselines and\ncase-studies demonstrate the benefits of the library. Torch-Struct is available\nat https://github.com/harvardnlp/pytorch-struct.", "published": "2020-02-03 16:43:02", "link": "http://arxiv.org/abs/2002.00876v1", "categories": ["cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Twitter Bot Detection Using Bidirectional Long Short-term Memory Neural\n  Networks and Word Embeddings", "abstract": "Twitter is a web application playing dual roles of online social networking\nand micro-blogging. The popularity and open structure of Twitter have attracted\na large number of automated programs, known as bots. Legitimate bots generate a\nlarge amount of benign contextual content, i.e., tweets delivering news and\nupdating feeds, while malicious bots spread spam or malicious contents. To\nassist human users in identifying who they are interacting with, this paper\nfocuses on the classification of human and spambot accounts on Twitter, by\nemploying recurrent neural networks, specifically bidirectional Long Short-term\nMemory (BiLSTM), to efficiently capture features across tweets. To the best of\nour knowledge, our work is the first that develops a recurrent neural model\nwith word embeddings to distinguish Twitter bots from human accounts, that\nrequires no prior knowledge or assumption about users' profiles, friendship\nnetworks, or historical behavior on the target account. Moreover, our model\ndoes not require any handcrafted features. The preliminary simulation results\nare very encouraging. Experiments on the cresci-2017 dataset show that our\napproach can achieve competitive performance compared with existing\nstate-of-the-art bot detection systems.", "published": "2020-02-03 17:07:03", "link": "http://arxiv.org/abs/2002.01336v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "On-Device Information Extraction from SMS using Hybrid Hierarchical\n  Classification", "abstract": "Cluttering of SMS inbox is one of the serious problems that users today face\nin the digital world where every online login, transaction, along with\npromotions generate multiple SMS. This problem not only prevents users from\nsearching and navigating messages efficiently but often results in users\nmissing out the relevant information associated with the corresponding SMS like\noffer codes, payment reminders etc. In this paper, we propose a unique\narchitecture to organize and extract the appropriate information from SMS and\nfurther display it in an intuitive template. In the proposed architecture, we\nuse a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural\nNetwork (CNN) to categorize SMS into multiple classes followed by a set of\nentity parsers used to extract the relevant information from the classified\nmessage. The architecture using its preprocessing techniques not only takes\ninto account the enormous variations observed in SMS data but also makes it\nefficient for its on-device (mobile phone) functionalities in terms of\ninference timing and size.", "published": "2020-02-03 09:24:45", "link": "http://arxiv.org/abs/2002.02755v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tensor-to-Vector Regression for Multi-channel Speech Enhancement based\n  on Tensor-Train Network", "abstract": "We propose a tensor-to-vector regression approach to multi-channel speech\nenhancement in order to address the issue of input size explosion and\nhidden-layer size expansion. The key idea is to cast the conventional deep\nneural network (DNN) based vector-to-vector regression formulation under a\ntensor-train network (TTN) framework. TTN is a recently emerged solution for\ncompact representation of deep models with fully connected hidden layers. Thus\nTTN maintains DNN's expressive power yet involves a much smaller amount of\ntrainable parameters. Furthermore, TTN can handle a multi-dimensional tensor\ninput by design, which exactly matches the desired setting in multi-channel\nspeech enhancement. We first provide a theoretical extension from DNN to TTN\nbased regression. Next, we show that TTN can attain speech enhancement quality\ncomparable with that for DNN but with much fewer parameters, e.g., a reduction\nfrom 27 million to only 5 million parameters is observed in a single-channel\nscenario. TTN also improves PESQ over DNN from 2.86 to 2.96 by slightly\nincreasing the number of trainable parameters. Finally, in 8-channel\nconditions, a PESQ of 3.12 is achieved using 20 million parameters for TTN,\nwhereas a DNN with 68 million parameters can only attain a PESQ of 3.06. Our\nimplementation is available online\nhttps://github.com/uwjunqi/Tensor-Train-Neural-Network.", "published": "2020-02-03 02:58:00", "link": "http://arxiv.org/abs/2002.00544v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.NE", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Regularized Fast Multichannel Nonnegative Matrix Factorization with\n  ILRMA-based Prior Distribution of Joint-Diagonalization Process", "abstract": "In this paper, we address a convolutive blind source separation (BSS) problem\nand propose a new extended framework of FastMNMF by introducing prior\ninformation for joint diagonalization of the spatial covariance matrix model.\nRecently, FastMNMF has been proposed as a fast version of multichannel\nnonnegative matrix factorization under the assumption that the spatial\ncovariance matrices of multiple sources can be jointly diagonalized. However,\nits source-separation performance was not improved and the physical meaning of\nthe joint-diagonalization process was unclear. To resolve these problems, we\nfirst reveal a close relationship between the joint-diagonalization process and\nthe demixing system used in independent low-rank matrix analysis (ILRMA). Next,\nmotivated by this fact, we propose a new regularized FastMNMF supported by\nILRMA and derive convergence-guaranteed parameter update rules. From BSS\nexperiments, we show that the proposed method outperforms the conventional\nFastMNMF in source-separation accuracy with almost the same computation time.", "published": "2020-02-03 06:55:37", "link": "http://arxiv.org/abs/2002.00579v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Time Difference of Arrival Estimation from Frequency-Sliding Generalized\n  Cross-Correlations Using Convolutional Neural Networks", "abstract": "The interest in deep learning methods for solving traditional signal\nprocessing tasks has been steadily growing in the last years. Time delay\nestimation (TDE) in adverse scenarios is a challenging problem, where classical\napproaches based on generalized cross-correlations (GCCs) have been widely used\nfor decades. Recently, the frequency-sliding GCC (FS-GCC) was proposed as a\nnovel technique for TDE based on a sub-band analysis of the cross-power\nspectrum phase, providing a structured two-dimensional representation of the\ntime delay information contained across different frequency bands. Inspired by\ndeep-learning-based image denoising solutions, we propose in this paper the use\nof convolutional neural networks (CNNs) to learn the time-delay patterns\ncontained in FS-GCCs extracted in adverse acoustic conditions. Our experiments\nconfirm that the proposed approach provides excellent TDE performance while\nbeing able to generalize to different room and sensor setups.", "published": "2020-02-03 10:42:49", "link": "http://arxiv.org/abs/2002.00641v1", "categories": ["eess.AS", "cs.SD", "94A12, 68T10", "I.2.0; I.5.4"], "primary_category": "eess.AS"}
{"title": "Within-sample variability-invariant loss for robust speaker recognition\n  under noisy environments", "abstract": "Despite the significant improvements in speaker recognition enabled by deep\nneural networks, unsatisfactory performance persists under noisy environments.\nIn this paper, we train the speaker embedding network to learn the \"clean\"\nembedding of the noisy utterance. Specifically, the network is trained with the\noriginal speaker identification loss with an auxiliary within-sample\nvariability-invariant loss. This auxiliary variability-invariant loss is used\nto learn the same embedding among the clean utterance and its noisy copies and\nprevents the network from encoding the undesired noises or variabilities into\nthe speaker representation. Furthermore, we investigate the data preparation\nstrategy for generating clean and noisy utterance pairs on-the-fly. The\nstrategy generates different noisy copies for the same clean utterance at each\ntraining step, helping the speaker embedding network generalize better under\nnoisy environments. Experiments on VoxCeleb1 indicate that the proposed\ntraining framework improves the performance of the speaker verification system\nin both clean and noisy conditions.", "published": "2020-02-03 18:10:58", "link": "http://arxiv.org/abs/2002.00924v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speech Emotion Recognition using Support Vector Machine", "abstract": "In this project, we aim to classify the speech taken as one of the four\nemotions namely, sadness, anger, fear and happiness. The samples that have been\ntaken to complete this project are taken from Linguistic Data Consortium (LDC)\nand UGA database. The important characteristics determined from the samples are\nenergy, pitch, MFCC coefficients, LPCC coefficients and speaker rate. The\nclassifier used to classify these emotional states is Support Vector Machine\n(SVM) and this is done using two classification strategies: One against All\n(OAA) and Gender Dependent Classification. Furthermore, a comparative analysis\nhas been conducted between the two and LPCC and MFCC algorithms as well.", "published": "2020-02-03 09:56:56", "link": "http://arxiv.org/abs/2002.07590v1", "categories": ["eess.AS", "cs.IR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Performance Analysis of Adaptive Noise Cancellation for Speech Signal", "abstract": "This paper gives a broader insight on the application of adaptive filter in\nnoise cancellation during various processes where signal is transmitted.\nAdaptive filtering techniques like RLS, LMS and normalized LMS are used to\nfilter the input signal using the concept of negative feedback to predict its\nnature and remove it effectively from the input. In this paper a comparative\nstudy between the effectiveness of RLS, LMS and normalized LMS is done based on\nparameters like SNR (Signal to Noise ratio), MSE (Mean squared error) and cross\ncorrelation. Implementation and analysis of the filters are done by taking\ndifferent step sizes on different orders of the filters.", "published": "2020-02-03 10:01:14", "link": "http://arxiv.org/abs/2002.07677v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
