{"title": "Context-Aware Cross-Lingual Mapping", "abstract": "Cross-lingual word vectors are typically obtained by fitting an orthogonal\nmatrix that maps the entries of a bilingual dictionary from a source to a\ntarget vector space. Word vectors, however, are most commonly used for sentence\nor document-level representations that are calculated as the weighted average\nof word embeddings. In this paper, we propose an alternative to word-level\nmapping that better reflects sentence-level cross-lingual similarity. We\nincorporate context in the transformation matrix by directly mapping the\naveraged embeddings of aligned sentences in a parallel corpus. We also\nimplement cross-lingual mapping of deep contextualized word embeddings using\nparallel sentences with word alignments. In our experiments, both approaches\nresulted in cross-lingual sentence embeddings that outperformed\ncontext-independent word mapping in sentence translation retrieval.\nFurthermore, the sentence-level transformation could be used for word-level\nmapping without loss in word translation quality.", "published": "2019-03-08 01:46:37", "link": "http://arxiv.org/abs/1903.03243v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Language Models as Psycholinguistic Subjects: Representations of\n  Syntactic State", "abstract": "We deploy the methods of controlled psycholinguistic experimentation to shed\nlight on the extent to which the behavior of neural network language models\nreflects incremental representations of syntactic state. To do so, we examine\nmodel behavior on artificial sentences containing a variety of syntactically\ncomplex structures. We test four models: two publicly available LSTM sequence\nmodels of English (Jozefowicz et al., 2016; Gulordava et al., 2018) trained on\nlarge datasets; an RNNG (Dyer et al., 2016) trained on a small, parsed dataset;\nand an LSTM trained on the same small corpus as the RNNG. We find evidence that\nthe LSTMs trained on large datasets represent syntactic state over large spans\nof text in a way that is comparable to the RNNG, while the LSTM trained on the\nsmall dataset does not or does so only weakly.", "published": "2019-03-08 03:02:28", "link": "http://arxiv.org/abs/1903.03260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Filling Gender & Number Gaps in Neural Machine Translation with\n  Black-box Context Injection", "abstract": "When translating from a language that does not morphologically mark\ninformation such as gender and number into a language that does, translation\nsystems must \"guess\" this missing information, often leading to incorrect\ntranslations in the given context. We propose a black-box approach for\ninjecting the missing information to a pre-trained neural machine translation\nsystem, allowing to control the morphological variations in the generated\ntranslations without changing the underlying model or training data. We\nevaluate our method on an English to Hebrew translation task, and show that it\nis effective in injecting the gender and number information and that supplying\nthe correct information improves the translation accuracy in up to 2.3 BLEU on\na female-speaker test set for a state-of-the-art online black-box system.\nFinally, we perform a fine-grained syntactic analysis of the generated\ntranslations that shows the effectiveness of our method.", "published": "2019-03-08 14:33:34", "link": "http://arxiv.org/abs/1903.03467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Prototyping a Dialogue Comprehension System for Nurse-Patient\n  Conversations on Symptom Monitoring", "abstract": "Data for human-human spoken dialogues for research and development are\ncurrently very limited in quantity, variety, and sources; such data are even\nscarcer in healthcare. In this work, we investigate fast prototyping of a\ndialogue comprehension system by leveraging on minimal nurse-to-patient\nconversations. We propose a framework inspired by nurse-initiated clinical\nsymptom monitoring conversations to construct a simulated human-human dialogue\ndataset, embodying linguistic characteristics of spoken interactions like\nthinking aloud, self-contradiction, and topic drift. We then adopt an\nestablished bidirectional attention pointer network on this simulated dataset,\nachieving more than 80% F1 score on a held-out test set from real-world\nnurse-to-patient conversations. The ability to automatically comprehend\nconversations in the healthcare domain by exploiting only limited data has\nimplications for improving clinical workflows through red flag symptom\ndetection and triaging capabilities. We demonstrate the feasibility for\nefficient and effective extraction, retrieval and comprehension of symptom\nchecking information discussed in multi-turn human-human spoken conversations.", "published": "2019-03-08 16:20:42", "link": "http://arxiv.org/abs/1903.03530v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attribute Acquisition in Ontology based on Representation Learning of\n  Hierarchical Classes and Attributes", "abstract": "Attribute acquisition for classes is a key step in ontology construction,\nwhich is often achieved by community members manually. This paper investigates\nan attention-based automatic paradigm called TransATT for attribute\nacquisition, by learning the representation of hierarchical classes and\nattributes in Chinese ontology. The attributes of an entity can be acquired by\nmerely inspecting its classes, because the entity can be regard as the instance\nof its classes and inherit their attributes. For explicitly describing of the\nclass of an entity unambiguously, we propose class-path to represent the\nhierarchical classes in ontology, instead of the terminal class word of the\nhypernym-hyponym relation (i.e., is-a relation) based hierarchy. The high\nperformance of TransATT on attribute acquisition indicates the promising\nability of the learned representation of class-paths and attributes. Moreover,\nwe construct a dataset named \\textbf{BigCilin11k}. To the best of our\nknowledge, this is the first Chinese dataset with abundant hierarchical classes\nand entities with attributes.", "published": "2019-03-08 04:44:59", "link": "http://arxiv.org/abs/1903.03282v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Towards Time-Aware Distant Supervision for Relation Extraction", "abstract": "Distant supervision for relation extraction heavily suffers from the wrong\nlabeling problem. To alleviate this issue in news data with the timestamp, we\ntake a new factor time into consideration and propose a novel time-aware\ndistant supervision framework (Time-DS). Time-DS is composed of a time series\ninstance-popularity and two strategies. Instance-popularity is to encode the\nstrong relevance of time and true relation mention. Therefore,\ninstance-popularity would be an effective clue to reduce the noises generated\nthrough distant supervision labeling. The two strategies, i.e., hard filter and\ncurriculum learning are both ways to implement instance-popularity for better\nrelation extraction in the manner of Time-DS. The curriculum learning is a more\nsophisticated and flexible way to exploit instance-popularity to eliminate the\nbad effects of noises, thus get better relation extraction performance.\nExperiments on our collected multi-source news corpus show that Time-DS\nachieves significant improvements for relation extraction.", "published": "2019-03-08 05:10:00", "link": "http://arxiv.org/abs/1903.03289v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Source codes in human communication", "abstract": "Although information theoretic characterizations of human communication have\nbecome increasingly popular in linguistics, to date they have largely involved\ngrafting probabilistic constructs onto older ideas about grammar. Similarities\nbetween human and digital communication have been strongly emphasized, and\ndifferences largely ignored. However, some of these differences matter:\ncommunication systems are based on predefined codes shared by every\nsender-receiver, whereas the distributions of words in natural languages\nguarantee that no speaker-hearer ever has access to an entire linguistic code,\nwhich seemingly undermines the idea that natural languages are probabilistic\nsystems in any meaningful sense. This paper describes how the distributional\nproperties of languages meet the various challenges arising from the\ndifferences between information systems and natural languages, along with the\nvery different view of human communication these properties suggest.", "published": "2019-03-08 14:45:53", "link": "http://arxiv.org/abs/1904.03991v1", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Fast Multichannel Source Separation Based on Jointly Diagonalizable\n  Spatial Covariance Matrices", "abstract": "This paper describes a versatile method that accelerates multichannel source\nseparation methods based on full-rank spatial modeling. A popular approach to\nmultichannel source separation is to integrate a spatial model with a source\nmodel for estimating the spatial covariance matrices (SCMs) and power spectral\ndensities (PSDs) of each sound source in the time-frequency domain. One of the\nmost successful examples of this approach is multichannel nonnegative matrix\nfactorization (MNMF) based on a full-rank spatial model and a low-rank source\nmodel. MNMF, however, is computationally expensive and often works poorly due\nto the difficulty of estimating the unconstrained full-rank SCMs. Instead of\nrestricting the SCMs to rank-1 matrices with the severe loss of the spatial\nmodeling ability as in independent low-rank matrix analysis (ILRMA), we\nrestrict the SCMs of each frequency bin to jointly-diagonalizable but still\nfull-rank matrices. For such a fast version of MNMF, we propose a\ncomputationally-efficient and convergence-guaranteed algorithm that is similar\nin form to that of ILRMA. Similarly, we propose a fast version of a\nstate-of-the-art speech enhancement method based on a deep speech model and a\nlow-rank noise model. Experimental results showed that the fast versions of\nMNMF and the deep speech enhancement method were several times faster and\nperformed even better than the original versions of those methods,\nrespectively.", "published": "2019-03-08 01:17:23", "link": "http://arxiv.org/abs/1903.03237v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "A Deep Generative Model of Speech Complex Spectrograms", "abstract": "This paper proposes an approach to the joint modeling of the short-time\nFourier transform magnitude and phase spectrograms with a deep generative\nmodel. We assume that the magnitude follows a Gaussian distribution and the\nphase follows a von Mises distribution. To improve the consistency of the phase\nvalues in the time-frequency domain, we also apply the von Mises distribution\nto the phase derivatives, i.e., the group delay and the instantaneous\nfrequency. Based on these assumptions, we explore and compare several\ncombinations of loss functions for training our models. Built upon the\nvariational autoencoder framework, our model consists of three convolutional\nneural networks acting as an encoder, a magnitude decoder, and a phase decoder.\nIn addition to the latent variables, we propose to also condition the phase\nestimation on the estimated magnitude. Evaluated for a time-domain speech\nreconstruction task, our models could generate speech with a high perceptual\nquality and a high intelligibility.", "published": "2019-03-08 03:57:30", "link": "http://arxiv.org/abs/1903.03269v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
