{"title": "Long Context Alignment with Short Instructions and Synthesized Positions", "abstract": "Effectively handling instructions with extremely long context remains a\nchallenge for Large Language Models (LLMs), typically necessitating\nhigh-quality long data and substantial computational resources. This paper\nintroduces Step-Skipping Alignment (SkipAlign), a new technique designed to\nenhance the long-context capabilities of LLMs in the phase of alignment without\nthe need for additional efforts beyond training with original data length.\nSkipAlign is developed on the premise that long-range dependencies are\nfundamental to enhancing an LLM's capacity of long context. Departing from\nmerely expanding the length of input samples, SkipAlign synthesizes long-range\ndependencies from the aspect of positions indices. This is achieved by the\nstrategic insertion of skipped positions within instruction-following samples,\nwhich utilizes the semantic structure of the data to effectively expand the\ncontext. Through extensive experiments on base models with a variety of context\nwindow sizes, SkipAlign demonstrates its effectiveness across a spectrum of\nlong-context tasks. Particularly noteworthy is that with a careful selection of\nthe base model and alignment datasets, SkipAlign with only 6B parameters\nachieves it's best performance and comparable with strong baselines like\nGPT-3.5-Turbo-16K on LongBench.", "published": "2024-05-07 01:56:22", "link": "http://arxiv.org/abs/2405.03939v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ESIHGNN: Event-State Interactions Infused Heterogeneous Graph Neural\n  Network for Conversational Emotion Recognition", "abstract": "Conversational Emotion Recognition (CER) aims to predict the emotion\nexpressed by an utterance (referred to as an ``event'') during a conversation.\nExisting graph-based methods mainly focus on event interactions to comprehend\nthe conversational context, while overlooking the direct influence of the\nspeaker's emotional state on the events. In addition, real-time modeling of the\nconversation is crucial for real-world applications but is rarely considered.\nToward this end, we propose a novel graph-based approach, namely Event-State\nInteractions infused Heterogeneous Graph Neural Network (ESIHGNN), which\nincorporates the speaker's emotional state and constructs a heterogeneous\nevent-state interaction graph to model the conversation. Specifically, a\nheterogeneous directed acyclic graph neural network is employed to dynamically\nupdate and enhance the representations of events and emotional states at each\nturn, thereby improving conversational coherence and consistency. Furthermore,\nto further improve the performance of CER, we enrich the graph's edges with\nexternal knowledge. Experimental results on four publicly available CER\ndatasets show the superiority of our approach and the effectiveness of the\nintroduced heterogeneous event-state interaction graph.", "published": "2024-05-07 02:46:11", "link": "http://arxiv.org/abs/2405.03960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Philosophy of Cognitive Science in the Age of Deep Learning", "abstract": "Deep learning has enabled major advances across most areas of artificial\nintelligence research. This remarkable progress extends beyond mere engineering\nachievements and holds significant relevance for the philosophy of cognitive\nscience. Deep neural networks have made significant strides in overcoming the\nlimitations of older connectionist models that once occupied the centre stage\nof philosophical debates about cognition. This development is directly relevant\nto long-standing theoretical debates in the philosophy of cognitive science.\nFurthermore, ongoing methodological challenges related to the comparative\nevaluation of deep neural networks stand to benefit greatly from\ninterdisciplinary collaboration with philosophy and cognitive science. The time\nis ripe for philosophers to explore foundational issues related to deep\nlearning and cognition; this perspective paper surveys key areas where their\ncontributions can be especially fruitful.", "published": "2024-05-07 06:39:47", "link": "http://arxiv.org/abs/2405.04048v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FlashBack:Efficient Retrieval-Augmented Language Modeling for Long\n  Context Inference", "abstract": "Retrieval-Augmented Language Modeling (RALM) by integrating large language\nmodels (LLM) with relevant documents from an external corpus is a proven method\nfor enabling the LLM to generate information beyond the scope of its\npre-training corpus. Previous work utilizing retrieved content by simply\nprepending it to the input poses a high runtime issue, which degrades the\ninference efficiency of the LLMs because they fail to use the Key-Value (KV)\ncache efficiently. In this paper, we propose FlashBack, a modular RALM designed\nto improve the inference efficiency of RALM with appending context pattern\nwhile maintaining decent performance after fine-tuning by Low-Rank Adaption.\nFlashBack appends retrieved documents at the end of the context for efficiently\nutilizing the KV cache instead of prepending them. And we introduce Marking\nToken as two special prompt tokens for marking the boundary of the appending\ncontext during fine-tuning. Our experiments on testing generation quality show\nthat FlashBack can remain decent generation quality in perplexity. And the\ninference speed of FlashBack is up to $4\\times$ faster than the prepending\ncounterpart on a 7B LLM (Llama 2) in the runtime test. Via bypassing\nunnecessary re-computation, it demonstrates an advancement by achieving\nsignificantly faster inference speed, and this heightened efficiency will\nsubstantially reduce inferential cost.", "published": "2024-05-07 07:14:38", "link": "http://arxiv.org/abs/2405.04065v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision", "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling\ncomplex queries, much of the past work has depended on extensively annotated\ndatasets by human experts. However, this reliance on fully-supervised\nannotations poses scalability challenges, particularly as models and data\nrequirements grow. To mitigate this, we explore the potential of enhancing\nLLMs' reasoning abilities with minimal human supervision. In this work, we\nintroduce self-reinforcement, which begins with Supervised Fine-Tuning (SFT) of\nthe model using a small collection of annotated questions. Then it iteratively\nimproves LLMs by learning from the differences in responses from the SFT and\nunfinetuned models on unlabeled questions. Our approach provides an efficient\napproach without relying heavily on extensive human-annotated explanations.\nHowever, current reasoning benchmarks typically only include golden-reference\nanswers or rationales. Therefore, we present \\textsc{PuzzleBen}, a weakly\nsupervised benchmark that comprises 25,147 complex questions, answers, and\nhuman-generated rationales across various domains, such as brainteasers,\npuzzles, riddles, parajumbles, and critical reasoning tasks. A unique aspect of\nour dataset is the inclusion of 10,000 unannotated questions, enabling us to\nexplore utilizing fewer supersized data to boost LLMs' inference capabilities.\nOur experiments underscore the significance of \\textsc{PuzzleBen}, as well as\nthe effectiveness of our methodology as a promising direction in future\nendeavors. Our dataset and code will be published soon on \\texttt{Anonymity\nLink}.", "published": "2024-05-07 07:39:15", "link": "http://arxiv.org/abs/2405.04086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Causal Explainable Guardrails for Large Language Models", "abstract": "Large Language Models (LLMs) have shown impressive performance in natural\nlanguage tasks, but their outputs can exhibit undesirable attributes or biases.\nExisting methods for steering LLMs toward desired attributes often assume\nunbiased representations and rely solely on steering prompts. However, the\nrepresentations learned from pre-training can introduce semantic biases that\ninfluence the steering process, leading to suboptimal results. We propose\nLLMGuardrail, a novel framework that incorporates causal analysis and\nadversarial learning to obtain unbiased steering representations in LLMs.\nLLMGuardrail systematically identifies and blocks the confounding effects of\nbiases, enabling the extraction of unbiased steering representations.\nAdditionally, it includes an explainable component that provides insights into\nthe alignment between the generated output and the desired direction.\nExperiments demonstrate LLMGuardrail's effectiveness in steering LLMs toward\ndesired attributes while mitigating biases. Our work contributes to the\ndevelopment of safe and reliable LLMs that align with desired attributes.", "published": "2024-05-07 09:55:05", "link": "http://arxiv.org/abs/2405.04160v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language\n  Models on Medical Text Summarization", "abstract": "This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for\nfine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and\nPEGASUS for improved medical text summarization. In contrast to existing domain\nadaptation approaches in summarization, MEDVOC treats vocabulary as an\noptimizable parameter and optimizes the PLM vocabulary based on fragment score\nconditioned only on the downstream task's reference summaries. Unlike previous\nworks on vocabulary adaptation (limited only to classification tasks),\noptimizing vocabulary based on summarization tasks requires an extremely costly\nintermediate fine-tuning step on large summarization datasets. To that end, our\nnovel fragment score-based hyperparameter search very significantly reduces\nthis fine-tuning time -- from 450 days to less than 2 days on average.\nFurthermore, while previous works on vocabulary adaptation are often primarily\ntied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs\n(with varying model vocabulary sizes, pre-training objectives, and model sizes)\n-- bridging the limited vocabulary overlap between the biomedical literature\ndomain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in\nzero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV)\nconcentrations. Our human evaluation shows MEDVOC generates more faithful\nmedical summaries (88% compared to 59% in baselines). We make the codebase\npublicly available at https://github.com/gb-kgp/MEDVOC.", "published": "2024-05-07 10:00:00", "link": "http://arxiv.org/abs/2405.04163v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LingML: Linguistic-Informed Machine Learning for Enhanced Fake News\n  Detection", "abstract": "Nowadays, Information spreads at an unprecedented pace in social media and\ndiscerning truth from misinformation and fake news has become an acute societal\nchallenge. Machine learning (ML) models have been employed to identify fake\nnews but are far from perfect with challenging problems like limited accuracy,\ninterpretability, and generalizability. In this paper, we enhance ML-based\nsolutions with linguistics input and we propose LingML, linguistic-informed ML,\nfor fake news detection. We conducted an experimental study with a popular\ndataset on fake news during the pandemic. The experiment results show that our\nproposed solution is highly effective. There are fewer than two errors out of\nevery ten attempts with only linguistic input used in ML and the knowledge is\nhighly explainable. When linguistics input is integrated with advanced\nlarge-scale ML models for natural language processing, our solution outperforms\nexisting ones with 1.8% average error rate. LingML creates a new path with\nlinguistics to push the frontier of effective and efficient fake news\ndetection. It also sheds light on real-world multi-disciplinary applications\nrequiring both ML and domain expertise to achieve optimal performance.", "published": "2024-05-07 10:03:19", "link": "http://arxiv.org/abs/2405.04165v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities\n  of Large Language Models", "abstract": "Large language models (LLMs) have garnered significant attention and\nwidespread usage due to their impressive performance in various tasks. However,\nthey are not without their own set of challenges, including issues such as\nhallucinations, factual inconsistencies, and limitations in\nnumerical-quantitative reasoning. Evaluating LLMs in miscellaneous reasoning\ntasks remains an active area of research. Prior to the breakthrough of LLMs,\nTransformers had already proven successful in the medical domain, effectively\nemployed for various natural language understanding (NLU) tasks. Following this\ntrend, LLMs have also been trained and utilized in the medical domain, raising\nconcerns regarding factual accuracy, adherence to safety protocols, and\ninherent limitations. In this paper, we focus on evaluating the natural\nlanguage inference capabilities of popular open-source and closed-source LLMs\nusing clinical trial reports as the dataset. We present the performance results\nof each LLM and further analyze their performance on a development set,\nparticularly focusing on challenging instances that involve medical\nabbreviations and require numerical-quantitative reasoning. Gemini, our leading\nLLM, achieved a test set F1-score of 0.748, securing the ninth position on the\ntask scoreboard. Our work is the first of its kind, offering a thorough\nexamination of the inference capabilities of LLMs within the medical domain.", "published": "2024-05-07 10:11:14", "link": "http://arxiv.org/abs/2405.04170v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Feature Vectors from Phonetic Transcriptions in\n  Cross-Linguistic Data Formats", "abstract": "When comparing speech sounds across languages, scholars often make use of\nfeature representations of individual sounds in order to determine fine-grained\nsound similarities. Although binary feature systems for large numbers of speech\nsounds have been proposed, large-scale computational applications often face\nthe challenges that the proposed feature systems -- even if they list features\nfor several thousand sounds -- only cover a smaller part of the numerous speech\nsounds reflected in actual cross-linguistic data. In order to address the\nproblem of missing data for attested speech sounds, we propose a new approach\nthat can create binary feature vectors dynamically for all sounds that can be\nrepresented in the the standardized version of the International Phonetic\nAlphabet proposed by the Cross-Linguistic Transcription Systems (CLTS)\nreference catalog. Since CLTS is actively used in large data collections,\ncovering more than 2,000 distinct language varieties, our procedure for the\ngeneration of binary feature vectors provides immediate access to a very large\ncollection of multilingual wordlists. Testing our feature system in different\nways on different datasets proves that the system is not only useful to provide\na straightforward means to compare the similarity of speech sounds, but also\nillustrates its potential to be used in future cross-linguistic machine\nlearning applications.", "published": "2024-05-07 12:40:59", "link": "http://arxiv.org/abs/2405.04271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is\n  GECScore", "abstract": "The efficacy of detectors for texts generated by large language models (LLMs)\nsubstantially depends on the availability of large-scale training data.\nHowever, white-box zero-shot detectors, which require no such data, are limited\nby the accessibility of the source model of the LLM-generated text. In this\npaper, we propose a simple yet effective black-box zero-shot detection approach\nbased on the observation that, from the perspective of LLMs, human-written\ntexts typically contain more grammatical errors than LLM-generated texts. This\napproach involves calculating the Grammar Error Correction Score (GECScore) for\nthe given text to differentiate between human-written and LLM-generated text.\nExperimental results show that our method outperforms current state-of-the-art\n(SOTA) zero-shot and supervised methods, achieving an average AUROC of 98.62%\nacross XSum and Writing Prompts dataset. Additionally, our approach\ndemonstrates strong reliability in the wild, exhibiting robust generalization\nand resistance to paraphrasing attacks. Data and code are available at:\nhttps://github.com/NLP2CT/GECScore.", "published": "2024-05-07 12:57:01", "link": "http://arxiv.org/abs/2405.04286v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large\n  Language Models", "abstract": "Speculative decoding is commonly used for reducing the inference latency of\nlarge language models. Its effectiveness depends highly on the speculation\nlookahead (SL)-the number of tokens generated by the draft model at each\niteration. In this work we show that the common practice of using the same SL\nfor all iterations (static SL) is suboptimal. We introduce DISCO (DynamIc\nSpeCulation lookahead Optimization), a novel method for dynamically selecting\nthe SL. Our experiments with four datasets show that DISCO reaches an average\nspeedup of 10% compared to the best static SL baseline, while generating the\nexact same text.", "published": "2024-05-07 13:27:52", "link": "http://arxiv.org/abs/2405.04304v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deception in Reinforced Autonomous Agents", "abstract": "We explore the ability of large language model (LLM)-based agents to engage\nin subtle deception such as strategically phrasing and intentionally\nmanipulating information to misguide and deceive other agents. This harmful\nbehavior can be hard to detect, unlike blatant lying or unintentional\nhallucination. We build an adversarial testbed mimicking a legislative\nenvironment where two LLMs play opposing roles: a corporate *lobbyist*\nproposing amendments to bills that benefit a specific company while evading a\n*critic* trying to detect this deception. We use real-world legislative bills\nmatched with potentially affected companies to ground these interactions. Our\nresults show that LLM lobbyists initially exhibit limited deception against\nstrong LLM critics which can be further improved through simple verbal\nreinforcement, significantly enhancing their deceptive capabilities, and\nincreasing deception rates by up to 40 points. This highlights the risk of\nautonomous agents manipulating other agents through seemingly neutral language\nto attain self-serving goals.", "published": "2024-05-07 13:55:11", "link": "http://arxiv.org/abs/2405.04325v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Transformer with Stack Attention", "abstract": "Natural languages are believed to be (mildly) context-sensitive. Despite\nunderpinning remarkably capable large language models, transformers are unable\nto model many context-free language tasks. In an attempt to address this\nlimitation in the modeling power of transformer-based language models, we\npropose augmenting them with a differentiable, stack-based attention mechanism.\nOur stack-based attention mechanism can be incorporated into any\ntransformer-based language model and adds a level of interpretability to the\nmodel. We show that the addition of our stack-based attention mechanism enables\nthe transformer to model some, but not all, deterministic context-free\nlanguages.", "published": "2024-05-07 17:47:57", "link": "http://arxiv.org/abs/2405.04515v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding the Capabilities and Limitations of Large Language Models\n  for Cultural Commonsense", "abstract": "Large language models (LLMs) have demonstrated substantial commonsense\nunderstanding through numerous benchmark evaluations. However, their\nunderstanding of cultural commonsense remains largely unexamined. In this\npaper, we conduct a comprehensive examination of the capabilities and\nlimitations of several state-of-the-art LLMs in the context of cultural\ncommonsense tasks. Using several general and cultural commonsense benchmarks,\nwe find that (1) LLMs have a significant discrepancy in performance when tested\non culture-specific commonsense knowledge for different cultures; (2) LLMs'\ngeneral commonsense capability is affected by cultural context; and (3) The\nlanguage used to query the LLMs can impact their performance on\ncultural-related tasks. Our study points to the inherent bias in the cultural\nunderstanding of LLMs and provides insights that can help develop culturally\naware language models.", "published": "2024-05-07 20:28:34", "link": "http://arxiv.org/abs/2405.04655v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Language Bias Between French and English in Conventional\n  Multilingual Sentiment Analysis Models", "abstract": "Inspired by the 'Bias Considerations in Bilingual Natural Language\nProcessing' report by Statistics Canada, this study delves into potential\nbiases in multilingual sentiment analysis between English and French. Given a\n50-50 dataset of French and English, we aim to determine if there exists a\nlanguage bias and explore how the incorporation of more diverse datasets in the\nfuture might affect the equity of multilingual Natural Language Processing\n(NLP) systems. By employing Support Vector Machine (SVM) and Naive Bayes models\non three balanced datasets, we reveal potential biases in multilingual\nsentiment classification. Utilizing Fairlearn, a tool for assessing bias in\nmachine learning models, our findings indicate nuanced outcomes. With French\ndata outperforming English across accuracy, recall, and F1 score metrics in\nboth models, hinting at a language bias favoring French. However, Fairlearn's\nmetrics suggest that the SVM approaches equitable levels with a demographic\nparity ratio of 0.963, 0.989, and 0.985 for the three separate datasets,\nindicating near-equitable treatment across languages. In contrast, Naive Bayes\ndemonstrates greater disparities, evidenced by a demographic parity ratio of\n0.813, 0.908, and 0.961. These findings reveal the importance of developing\nequitable multilingual NLP systems, particularly as we anticipate the inclusion\nof more datasets in various languages in the future.", "published": "2024-05-07 17:46:36", "link": "http://arxiv.org/abs/2405.06692v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CleanGraph: Human-in-the-loop Knowledge Graph Refinement and Completion", "abstract": "This paper presents CleanGraph, an interactive web-based tool designed to\nfacilitate the refinement and completion of knowledge graphs. Maintaining the\nreliability of knowledge graphs, which are grounded in high-quality and\nerror-free facts, is crucial for real-world applications such as\nquestion-answering and information retrieval systems. These graphs are often\nautomatically assembled from textual sources by extracting semantic triples via\ninformation extraction. However, assuring the quality of these extracted\ntriples, especially when dealing with large or low-quality datasets, can pose a\nsignificant challenge and adversely affect the performance of downstream\napplications. CleanGraph allows users to perform Create, Read, Update, and\nDelete (CRUD) operations on their graphs, as well as apply models in the form\nof plugins for graph refinement and completion tasks. These functionalities\nenable users to enhance the integrity and reliability of their graph data. A\ndemonstration of CleanGraph and its source code can be accessed at\nhttps://github.com/nlp-tlp/CleanGraph under the MIT License.", "published": "2024-05-07 01:40:23", "link": "http://arxiv.org/abs/2405.03932v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Sketch Then Generate: Providing Incremental User Feedback and Guiding\n  LLM Code Generation through Language-Oriented Code Sketches", "abstract": "Crafting effective prompts for code generation or editing with Large Language\nModels (LLMs) is not an easy task. Particularly, the absence of immediate,\nstable feedback during prompt crafting hinders effective interaction, as users\nare left to mentally imagine possible outcomes until the code is generated. In\nresponse, we introduce Language-Oriented Code Sketching, an interactive\napproach that provides instant, incremental feedback in the form of code\nsketches (i.e., incomplete code outlines) during prompt crafting. This approach\nconverts a prompt into a code sketch by leveraging the inherent linguistic\nstructures within the prompt and applying classic natural language processing\ntechniques. The sketch then serves as an intermediate placeholder that not only\npreviews the intended code structure but also guides the LLM towards the\ndesired code, thereby enhancing human-LLM interaction. We conclude by\ndiscussing the approach's applicability and future plans.", "published": "2024-05-07 04:21:07", "link": "http://arxiv.org/abs/2405.03998v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Enriched BERT Embeddings for Scholarly Publication Classification", "abstract": "With the rapid expansion of academic literature and the proliferation of\npreprints, researchers face growing challenges in manually organizing and\nlabeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses\nthis challenge organized as a competition. The goal is to develop a classifier\ncapable of predicting one of 123 predefined classes from the Open Research\nKnowledge Graph (ORKG) taxonomy of research fields for a given article.This\npaper presents our results. Initially, we enrich the dataset (containing\nEnglish scholarly articles sourced from ORKG and arXiv), then leverage\ndifferent pre-trained language Models (PLMs), specifically BERT, and explore\ntheir efficacy in transfer learning for this downstream task. Our experiments\nencompass feature-based and fine-tuned transfer learning approaches using\ndiverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and\nSPECTER2. We conduct hyperparameter tuning and investigate the impact of data\naugmentation from bibliographic databases such as OpenAlex, Semantic Scholar,\nand Crossref. Our results demonstrate that fine-tuning pre-trained models\nsubstantially enhances classification performance, with SPECTER2 emerging as\nthe most accurate model. Moreover, enriching the dataset with additional\nmetadata improves classification outcomes significantly, especially when\nintegrating information from S2AG, OpenAlex and Crossref. Our best-performing\napproach achieves a weighted F1-score of 0.7415. Overall, our study contributes\nto the advancement of reliable automated systems for scholarly publication\ncategorization, offering a potential solution to the laborious manual curation\nprocess, thereby facilitating researchers in efficiently locating relevant\nresources.", "published": "2024-05-07 09:05:20", "link": "http://arxiv.org/abs/2405.04136v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask\n  Learning", "abstract": "This study introduces 'clickbait spoiling', a novel technique designed to\ndetect, categorize, and generate spoilers as succinct text responses,\ncountering the curiosity induced by clickbait content. By leveraging a\nmulti-task learning framework, our model's generalization capabilities are\nsignificantly enhanced, effectively addressing the pervasive issue of\nclickbait. The crux of our research lies in generating appropriate spoilers, be\nit a phrase, an extended passage, or multiple, depending on the spoiler type\nrequired. Our methodology integrates two crucial techniques: a refined spoiler\ncategorization method and a modified version of the Question Answering (QA)\nmechanism, incorporated within a multi-task learning paradigm for optimized\nspoiler extraction from context. Notably, we have included fine-tuning methods\nfor models capable of handling longer sequences to accommodate the generation\nof extended spoilers. This research highlights the potential of sophisticated\ntext processing techniques in tackling the omnipresent issue of clickbait,\npromising an enhanced user experience in the digital realm.", "published": "2024-05-07 13:09:25", "link": "http://arxiv.org/abs/2405.04292v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open Implementation and Study of BEST-RQ for Speech Processing", "abstract": "Self-Supervised Learning (SSL) has proven to be useful in various speech\ntasks. However, these methods are generally very demanding in terms of data,\nmemory, and computational resources. BERT-based Speech pre-Training with\nRandom-projection Quantizer (BEST-RQ), is an SSL method that has shown great\nperformance on Automatic Speech Recognition (ASR) while being simpler than\nother SSL methods, such as wav2vec 2.0. Despite BEST-RQ's great performance,\ndetails are lacking in the original paper, such as the amount of GPU/TPU hours\nused in pre-training, and there is no official easy-to-use open-source\nimplementation. Furthermore, BEST-RQ has not been evaluated on other downstream\ntasks aside from ASR and speech translation. In this work, we describe a\nre-implementation of a Random-projection quantizer and perform a preliminary\nstudy with a comparison to wav2vec 2.0 on four downstream tasks. We discuss the\ndetails and differences of our implementation. We show that a random projection\nquantizer can achieve similar downstream performance as wav2vec 2.0 while\ndecreasing training time by over a factor of two.", "published": "2024-05-07 13:11:37", "link": "http://arxiv.org/abs/2405.04296v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning To See But Forgetting To Follow: Visual Instruction Tuning\n  Makes LLMs More Prone To Jailbreak Attacks", "abstract": "Augmenting Large Language Models (LLMs) with image-understanding capabilities\nhas resulted in a boom of high-performing Vision-Language models (VLMs). While\nstudying the alignment of LLMs to human values has received widespread\nattention, the safety of VLMs has not received the same attention. In this\npaper, we explore the impact of jailbreaking on three state-of-the-art VLMs,\neach using a distinct modeling approach. By comparing each VLM to their\nrespective LLM backbone, we find that each VLM is more susceptible to\njailbreaking. We consider this as an undesirable outcome from visual\ninstruction-tuning, which imposes a forgetting effect on an LLM's safety\nguardrails. Therefore, we provide recommendations for future work based on\nevaluation strategies that aim to highlight the weaknesses of a VLM, as well as\ntake safety measures into account during visual instruction tuning.", "published": "2024-05-07 15:29:48", "link": "http://arxiv.org/abs/2405.04403v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Silicon Ceiling: Auditing GPT's Race and Gender Biases in Hiring", "abstract": "Large language models (LLMs) are increasingly being introduced in workplace\nsettings, with the goals of improving efficiency and fairness. However,\nconcerns have arisen regarding these models' potential to reflect or exacerbate\nsocial biases and stereotypes. This study explores the potential impact of LLMs\non hiring practices. To do so, we conduct an AI audit of race and gender biases\nin one commonly-used LLM, OpenAI's GPT-3.5, taking inspiration from the history\nof traditional offline resume audits. We conduct two studies using names with\nvaried race and gender connotations: resume assessment (Study 1) and resume\ngeneration (Study 2). In Study 1, we ask GPT to score resumes with 32 different\nnames (4 names for each combination of the 2 gender and 4 racial groups) and\ntwo anonymous options across 10 occupations and 3 evaluation tasks (overall\nrating, willingness to interview, and hireability). We find that the model\nreflects some biases based on stereotypes. In Study 2, we prompt GPT to create\nresumes (10 for each name) for fictitious job candidates. When generating\nresumes, GPT reveals underlying biases; women's resumes had occupations with\nless experience, while Asian and Hispanic resumes had immigrant markers, such\nas non-native English and non-U.S. education and work experiences. Our findings\ncontribute to a growing body of literature on LLM biases, particularly in\nworkplace contexts.", "published": "2024-05-07 15:39:45", "link": "http://arxiv.org/abs/2405.04412v3", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts\n  Language Model", "abstract": "We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model\ncharacterized by economical training and efficient inference. It comprises 236B\ntotal parameters, of which 21B are activated for each token, and supports a\ncontext length of 128K tokens. DeepSeek-V2 adopts innovative architectures\nincluding Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees\nefficient inference through significantly compressing the Key-Value (KV) cache\ninto a latent vector, while DeepSeekMoE enables training strong models at an\neconomical cost through sparse computation. Compared with DeepSeek 67B,\nDeepSeek-V2 achieves significantly stronger performance, and meanwhile saves\n42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum\ngeneration throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality\nand multi-source corpus consisting of 8.1T tokens, and further perform\nSupervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock\nits potential. Evaluation results show that, even with only 21B activated\nparameters, DeepSeek-V2 and its chat versions still achieve top-tier\nperformance among open-source models.", "published": "2024-05-07 15:56:43", "link": "http://arxiv.org/abs/2405.04434v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)", "abstract": "Exact nearest neighbor search is a computationally intensive process, and\neven its simpler sibling -- vector retrieval -- can be computationally complex.\nThis is exacerbated when retrieving vectors which have high-dimension $d$\nrelative to the number of vectors, $N$, in the database. Exact nearest neighbor\nretrieval has been generally acknowledged to be a $O(Nd)$ problem with no\nsub-linear solutions. Attention has instead shifted towards Approximate\nNearest-Neighbor (ANN) retrieval techniques, many of which have sub-linear or\neven logarithmic time complexities. However, if our intuition from binary\nsearch problems (e.g. $d=1$ vector retrieval) carries, there ought to be a way\nto retrieve an organized representation of vectors without brute-forcing our\nway to a solution. For low dimension (e.g. $d=2$ or $d=3$ cases),\n\\texttt{kd-trees} provide a $O(d\\log N)$ algorithm for retrieval. Unfortunately\nthe algorithm deteriorates rapidly to a $O(dN)$ solution at high dimensions\n(e.g. $k=128$), in practice. We propose a novel algorithm for logarithmic Fast\nExact Retrieval for Nearest-neighbor lookup (FERN), inspired by\n\\texttt{kd-trees}. The algorithm achieves $O(d\\log N)$ look-up with 100\\%\nrecall on 10 million $d=128$ uniformly randomly generated\nvectors.\\footnote{Code available at https://github.com/RichardZhu123/ferns}", "published": "2024-05-07 15:57:39", "link": "http://arxiv.org/abs/2405.04435v1", "categories": ["cs.CL", "cs.DS"], "primary_category": "cs.CL"}
{"title": "Language Modeling Using Tensor Trains", "abstract": "We propose a novel tensor network language model based on the simplest tensor\nnetwork (i.e., tensor trains), called `Tensor Train Language Model' (TTLM).\nTTLM represents sentences in an exponential space constructed by the tensor\nproduct of words, but computing the probabilities of sentences in a\nlow-dimensional fashion. We demonstrate that the architectures of Second-order\nRNNs, Recurrent Arithmetic Circuits (RACs), and Multiplicative Integration RNNs\nare, essentially, special cases of TTLM. Experimental evaluations on real\nlanguage modeling tasks show that the proposed variants of TTLM (i.e.,\nTTLM-Large and TTLM-Tiny) outperform the vanilla Recurrent Neural Networks\n(RNNs) with low-scale of hidden units. (The code is available at\nhttps://github.com/shuishen112/tensortrainlm.)", "published": "2024-05-07 18:09:47", "link": "http://arxiv.org/abs/2405.04590v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards a Theoretical Understanding of the 'Reversal Curse' via Training\n  Dynamics", "abstract": "Auto-regressive large language models (LLMs) show impressive capacities to\nsolve many complex reasoning tasks while struggling with some simple logical\nreasoning tasks such as inverse search: when trained on '$A \\to B$' (e.g., 'Tom\nis the parent of John'), LLM fails to directly conclude '$B \\gets A$' (e.g.,\n'John is the child of Tom') during inference even if the two sentences are\nsemantically identical, which is known as the 'reversal curse'. In this paper,\nwe theoretically analyze the reversal curse via the training dynamics of\n(stochastic) gradient descent for two auto-regressive models: (1) a bilinear\nmodel that can be viewed as a simplification of a one-layer transformer; (2)\none-layer transformers under certain assumptions. Our analysis reveals that for\nboth models, the reversal curse is a consequence of the (effective) model\nweights 'asymmetry', i.e., the increase of weights from a token $A$ to token\n$B$ during training does not necessarily cause the increase of the weights from\n$B$ to $A$, which is caused by the training dynamics under certain choice of\nloss function and the optimization space of model parameters. Moreover, our\nanalysis can be naturally applied to other logical reasoning tasks such as\nchain-of-thought (COT), which provides a new perspective different from\nprevious work that focuses on expressivity. Finally, we conduct experiments to\nvalidate our theory on multi-layer transformers under different settings. Our\ncode is available at https://github.com/marlo-z/reversal_curse_analysis/.", "published": "2024-05-07 21:03:51", "link": "http://arxiv.org/abs/2405.04669v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SUTRA: Scalable Multilingual Language Model Architecture", "abstract": "In this paper, we introduce SUTRA, multilingual Large Language Model\narchitecture capable of understanding, reasoning, and generating text in over\n50 languages. SUTRA's design uniquely decouples core conceptual understanding\nfrom language-specific processing, which facilitates scalable and efficient\nmultilingual alignment and learning. Employing a Mixture of Experts framework\nboth in language and concept processing, SUTRA demonstrates both computational\nefficiency and responsiveness. Through extensive evaluations, SUTRA is\ndemonstrated to surpass existing models like GPT-3.5, Llama2 by 20-30% on\nleading Massive Multitask Language Understanding (MMLU) benchmarks for\nmultilingual tasks. SUTRA models are also online LLMs that can use knowledge\nfrom the internet to provide hallucination-free, factual and up-to-date\nresponses while retaining their multilingual capabilities. Furthermore, we\nexplore the broader implications of its architecture for the future of\nmultilingual AI, highlighting its potential to democratize access to AI\ntechnology globally and to improve the equity and utility of AI in regions with\npredominantly non-English languages. Our findings suggest that SUTRA not only\nfills pivotal gaps in multilingual model capabilities but also establishes a\nnew benchmark for operational efficiency and scalability in AI applications.", "published": "2024-05-07 20:11:44", "link": "http://arxiv.org/abs/2405.06694v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Roadmap for Multilingual, Multimodal Domain Independent Deception\n  Detection", "abstract": "Deception, a prevalent aspect of human communication, has undergone a\nsignificant transformation in the digital age. With the globalization of online\ninteractions, individuals are communicating in multiple languages and mixing\nlanguages on social media, with varied data becoming available in each language\nand dialect. At the same time, the techniques for detecting deception are\nsimilar across the board. Recent studies have shown the possibility of the\nexistence of universal linguistic cues to deception across domains within the\nEnglish language; however, the existence of such cues in other languages\nremains unknown. Furthermore, the practical task of deception detection in\nlow-resource languages is not a well-studied problem due to the lack of labeled\ndata. Another dimension of deception is multimodality. For example, a picture\nwith an altered caption in fake news or disinformation may exist. This paper\ncalls for a comprehensive investigation into the complexities of deceptive\nlanguage across linguistic boundaries and modalities within the realm of\ncomputer security and natural language processing and the possibility of using\nmultilingual transformer models and labeled data in various languages to\nuniversally address the task of deception detection.", "published": "2024-05-07 00:38:34", "link": "http://arxiv.org/abs/2405.03920v1", "categories": ["cs.CL", "cs.AI", "cs.MM", "I.2.6; I.2.7; I.2.10; K.4.4"], "primary_category": "cs.CL"}
{"title": "HAFFormer: A Hierarchical Attention-Free Framework for Alzheimer's\n  Disease Detection From Spontaneous Speech", "abstract": "Automatically detecting Alzheimer's Disease (AD) from spontaneous speech\nplays an important role in its early diagnosis. Recent approaches highly rely\non the Transformer architectures due to its efficiency in modelling long-range\ncontext dependencies. However, the quadratic increase in computational\ncomplexity associated with self-attention and the length of audio poses a\nchallenge when deploying such models on edge devices. In this context, we\nconstruct a novel framework, namely Hierarchical Attention-Free Transformer\n(HAFFormer), to better deal with long speech for AD detection. Specifically, we\nemploy an attention-free module of Multi-Scale Depthwise Convolution to replace\nthe self-attention and thus avoid the expensive computation, and a GELU-based\nGated Linear Unit to replace the feedforward layer, aiming to automatically\nfilter out the redundant information. Moreover, we design a hierarchical\nstructure to force it to learn a variety of information grains, from the frame\nlevel to the dialogue level. By conducting extensive experiments on the\nADReSS-M dataset, the introduced HAFFormer can achieve competitive results\n(82.6% accuracy) with other recent work, but with significant computational\ncomplexity and model size reduction compared to the standard Transformer. This\nshows the efficiency of HAFFormer in dealing with long audio for AD detection.", "published": "2024-05-07 02:19:16", "link": "http://arxiv.org/abs/2405.03952v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize\n  Hallucinations", "abstract": "In this research, we uses the DistilBERT model to generate extractive summary\nand the T5 model to generate abstractive summaries. Also, we generate hybrid\nsummaries by combining both DistilBERT and T5 models. Central to our research\nis the implementation of GPT-based refining process to minimize the common\nproblem of hallucinations that happens in AI-generated summaries. We evaluate\nunrefined summaries and, after refining, we also assess refined summaries using\na range of traditional and novel metrics, demonstrating marked improvements in\nthe accuracy and reliability of the summaries. Results highlight significant\nimprovements in reducing hallucinatory content, thereby increasing the factual\nintegrity of the summaries.", "published": "2024-05-07 06:23:02", "link": "http://arxiv.org/abs/2405.04039v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Text Summaries Generated by Large Language Models Using\n  OpenAI's GPT", "abstract": "This research examines the effectiveness of OpenAI's GPT models as\nindependent evaluators of text summaries generated by six transformer-based\nmodels from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.\nWe evaluated these summaries based on essential properties of high-quality\nsummary - conciseness, relevance, coherence, and readability - using\ntraditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,\nwe also employed GPT not as a summarizer but as an evaluator, allowing it to\nindependently assess summary quality without predefined metrics. Our analysis\nrevealed significant correlations between GPT evaluations and traditional\nmetrics, particularly in assessing relevance and coherence. The results\ndemonstrate GPT's potential as a robust tool for evaluating text summaries,\noffering insights that complement established metrics and providing a basis for\ncomparative analysis of transformer-based models in natural language processing\ntasks.", "published": "2024-05-07 06:52:34", "link": "http://arxiv.org/abs/2405.04053v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Policy Learning with a Language Bottleneck", "abstract": "Modern AI systems such as self-driving cars and game-playing agents achieve\nsuperhuman performance, but often lack human-like generalization,\ninterpretability, and inter-operability with human users. Inspired by the rich\ninteractions between language and decision-making in humans, we introduce\nPolicy Learning with a Language Bottleneck (PLLB), a framework enabling AI\nagents to generate linguistic rules that capture the high-level strategies\nunderlying rewarding behaviors. PLLB alternates between a *rule generation*\nstep guided by language models, and an *update* step where agents learn new\npolicies guided by rules, even when a rule is insufficient to describe an\nentire complex policy. Across five diverse tasks, including a two-player\nsignaling game, maze navigation, image reconstruction, and robot grasp\nplanning, we show that PLLB agents are not only able to learn more\ninterpretable and generalizable behaviors, but can also share the learned rules\nwith human users, enabling more effective human-AI coordination. We provide\nsource code for our experiments at https://github.com/meghabyte/bottleneck .", "published": "2024-05-07 08:40:21", "link": "http://arxiv.org/abs/2405.04118v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Fine-grained Speech Sentiment Analysis in Chinese Psychological Support\n  Hotlines Based on Large-scale Pre-trained Model", "abstract": "Suicide and suicidal behaviors remain significant challenges for public\npolicy and healthcare. In response, psychological support hotlines have been\nestablished worldwide to provide immediate help to individuals in mental\ncrises. The effectiveness of these hotlines largely depends on accurately\nidentifying callers' emotional states, particularly underlying negative\nemotions indicative of increased suicide risk. However, the high demand for\npsychological interventions often results in a shortage of professional\noperators, highlighting the need for an effective speech emotion recognition\nmodel. This model would automatically detect and analyze callers' emotions,\nfacilitating integration into hotline services. Additionally, it would enable\nlarge-scale data analysis of psychological support hotline interactions to\nexplore psychological phenomena and behaviors across populations. Our study\nutilizes data from the Beijing psychological support hotline, the largest\nsuicide hotline in China. We analyzed speech data from 105 callers containing\n20,630 segments and categorized them into 11 types of negative emotions. We\ndeveloped a negative emotion recognition model and a fine-grained multi-label\nclassification model using a large-scale pre-trained model. Our experiments\nindicate that the negative emotion recognition model achieves a maximum\nF1-score of 76.96%. However, it shows limited efficacy in the fine-grained\nmulti-label classification task, with the best model achieving only a 41.74%\nweighted F1-score. We conducted an error analysis for this task, discussed\npotential future improvements, and considered the clinical application\npossibilities of our study. All the codes are public available.", "published": "2024-05-07 08:53:25", "link": "http://arxiv.org/abs/2405.04128v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Iterative Experience Refinement of Software-Developing Agents", "abstract": "Autonomous agents powered by large language models (LLMs) show significant\npotential for achieving high autonomy in various scenarios such as software\ndevelopment. Recent research has shown that LLM agents can leverage past\nexperiences to reduce errors and enhance efficiency. However, the static\nexperience paradigm, reliant on a fixed collection of past experiences acquired\nheuristically, lacks iterative refinement and thus hampers agents'\nadaptability. In this paper, we introduce the Iterative Experience Refinement\nframework, enabling LLM agents to refine experiences iteratively during task\nexecution. We propose two fundamental patterns: the successive pattern,\nrefining based on nearest experiences within a task batch, and the cumulative\npattern, acquiring experiences across all previous task batches. Augmented with\nour heuristic experience elimination, the method prioritizes high-quality and\nfrequently-used experiences, effectively managing the experience space and\nenhancing efficiency. Extensive experiments show that while the successive\npattern may yield superior results, the cumulative pattern provides more stable\nperformance. Moreover, experience elimination facilitates achieving better\nperformance using just 11.54% of a high-quality subset.", "published": "2024-05-07 11:33:49", "link": "http://arxiv.org/abs/2405.04219v1", "categories": ["cs.CL", "cs.AI", "cs.MA", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Granite Code Models: A Family of Open Foundation Models for Code\n  Intelligence", "abstract": "Large Language Models (LLMs) trained on code are revolutionizing the software\ndevelopment process. Increasingly, code LLMs are being integrated into software\ndevelopment environments to improve the productivity of human programmers, and\nLLM-based agents are beginning to show promise for handling complex tasks\nautonomously. Realizing the full potential of code LLMs requires a wide range\nof capabilities, including code generation, fixing bugs, explaining and\ndocumenting code, maintaining repositories, and more. In this work, we\nintroduce the Granite series of decoder-only code models for code generative\ntasks, trained with code written in 116 programming languages. The Granite Code\nmodels family consists of models ranging in size from 3 to 34 billion\nparameters, suitable for applications ranging from complex application\nmodernization tasks to on-device memory-constrained use cases. Evaluation on a\ncomprehensive set of tasks demonstrates that Granite Code models consistently\nreaches state-of-the-art performance among available open-source code LLMs. The\nGranite Code model family was optimized for enterprise software development\nworkflows and performs well across a range of coding tasks (e.g. code\ngeneration, fixing and explanation), making it a versatile all around code\nmodel. We release all our Granite Code models under an Apache 2.0 license for\nboth research and commercial use.", "published": "2024-05-07 13:50:40", "link": "http://arxiv.org/abs/2405.04324v1", "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Revisiting Character-level Adversarial Attacks for Language Models", "abstract": "Adversarial attacks in Natural Language Processing apply perturbations in the\ncharacter or token levels. Token-level attacks, gaining prominence for their\nuse of gradient-based methods, are susceptible to altering sentence semantics,\nleading to invalid adversarial examples. While character-level attacks easily\nmaintain semantics, they have received less attention as they cannot easily\nadopt popular gradient-based methods, and are thought to be easy to defend.\nChallenging these beliefs, we introduce Charmer, an efficient query-based\nadversarial attack capable of achieving high attack success rate (ASR) while\ngenerating highly similar adversarial examples. Our method successfully targets\nboth small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,\nCharmer improves the ASR in 4.84% points and the USE similarity in 8% points\nwith respect to the previous art. Our implementation is available in\nhttps://github.com/LIONS-EPFL/Charmer.", "published": "2024-05-07 14:23:22", "link": "http://arxiv.org/abs/2405.04346v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Vision Mamba: A Comprehensive Survey and Taxonomy", "abstract": "State Space Model (SSM) is a mathematical model used to describe and analyze\nthe behavior of dynamic systems. This model has witnessed numerous applications\nin several fields, including control theory, signal processing, economics and\nmachine learning. In the field of deep learning, state space models are used to\nprocess sequence data, such as time series analysis, natural language\nprocessing (NLP) and video understanding. By mapping sequence data to state\nspace, long-term dependencies in the data can be better captured. In\nparticular, modern SSMs have shown strong representational capabilities in NLP,\nespecially in long sequence modeling, while maintaining linear time complexity.\nNotably, based on the latest state-space models, Mamba merges time-varying\nparameters into SSMs and formulates a hardware-aware algorithm for efficient\ntraining and inference. Given its impressive efficiency and strong long-range\ndependency modeling capability, Mamba is expected to become a new AI\narchitecture that may outperform Transformer. Recently, a number of works have\nattempted to study the potential of Mamba in various fields, such as general\nvision, multi-modal, medical image analysis and remote sensing image analysis,\nby extending Mamba from natural language domain to visual domain. To fully\nunderstand Mamba in the visual domain, we conduct a comprehensive survey and\npresent a taxonomy study. This survey focuses on Mamba's application to a\nvariety of visual tasks and data types, and discusses its predecessors, recent\nadvances and far-reaching impact on a wide range of domains. Since Mamba is now\non an upward trend, please actively notice us if you have new findings, and new\nprogress on Mamba will be included in this survey in a timely manner and\nupdated on the Mamba project at\nhttps://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.", "published": "2024-05-07 15:30:14", "link": "http://arxiv.org/abs/2405.04404v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Toward In-Context Teaching: Adapting Examples to Students'\n  Misconceptions", "abstract": "When a teacher provides examples for a student to study, these examples must\nbe informative, enabling a student to progress from their current state toward\na target concept or skill. Good teachers must therefore simultaneously infer\nwhat students already know and adapt their teaching to students' changing state\nof knowledge. There is increasing interest in using computational models,\nparticularly large language models, as pedagogical tools. As students, language\nmodels in particular have shown a remarkable ability to adapt to new tasks\ngiven small numbers of examples. But how effectively can these models adapt as\nteachers to students of different types? To study this question, we introduce a\nsuite of models and evaluation methods we call AdapT. AdapT has two components:\n(1) a collection of simulated Bayesian student models that can be used for\nevaluation of automated teaching methods; (2) a platform for evaluation with\nhuman students, to characterize the real-world effectiveness of these methods.\nWe additionally introduce (3) AToM, a new probabilistic model for adaptive\nteaching that jointly infers students' past beliefs and optimizes for the\ncorrectness of future beliefs. In evaluations of simulated students across\nthree learning domains (fraction arithmetic, English morphology, function\nlearning), AToM systematically outperforms LLM-based and standard Bayesian\nteaching models. In human experiments, both AToM and LLMs outperform\nnon-adaptive random example selection. Our results highlight both the\ndifficulty of the adaptive teaching task and the potential of learned adaptive\nmodels for solving it.", "published": "2024-05-07 17:05:27", "link": "http://arxiv.org/abs/2405.04495v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Switchable Decision: Dynamic Neural Generation Networks", "abstract": "Auto-regressive generation models achieve competitive performance across many\ndifferent NLP tasks such as summarization, question answering, and\nclassifications. However, they are also known for being slow in inference,\nwhich makes them challenging to deploy in real-time applications. We propose a\nswitchable decision to accelerate inference by dynamically assigning\ncomputation resources for each data instance. Automatically making decisions on\nwhere to skip and how to balance quality and computation cost with constrained\noptimization, our dynamic neural generation networks enforce the efficient\ninference path and determine the optimized trade-off. Experiments across\nquestion answering, summarization, and classification benchmarks show that our\nmethod benefits from less computation cost during inference while keeping the\nsame accuracy. Extensive experiments and ablation studies demonstrate that our\nmethod can be general, effective, and beneficial for many NLP tasks.", "published": "2024-05-07 17:44:54", "link": "http://arxiv.org/abs/2405.04513v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and\n  Natural User Prompts", "abstract": "Large language models (LLMs) have manifested strong ability to generate codes\nfor productive activities. However, current benchmarks for code synthesis, such\nas HumanEval, MBPP, and DS-1000, are predominantly oriented towards\nintroductory tasks on algorithm and data science, insufficiently satisfying\nchallenging requirements prevalent in real-world coding. To fill this gap, we\npropose NaturalCodeBench (NCB), a challenging code benchmark designed to mirror\nthe complexity and variety of scenarios in real coding tasks. NCB comprises 402\nhigh-quality problems in Python and Java, meticulously selected from natural\nuser queries from online coding services, covering 6 different domains. Noting\nthe extraordinary difficulty in creating testing cases for real-world queries,\nwe also introduce a semi-automated pipeline to enhance the efficiency of test\ncase construction. Comparing with manual solutions, it achieves an efficiency\nincrease of more than 4 times. Our systematic experiments on 39 LLMs find that\nperformance gaps on NCB between models with close HumanEval scores could still\nbe significant, indicating a lack of focus on practical code synthesis\nscenarios or over-specified optimization on HumanEval. On the other hand, even\nthe best-performing GPT-4 is still far from satisfying on NCB. The evaluation\ntoolkit and development set are available at\nhttps://github.com/THUDM/NaturalCodeBench.", "published": "2024-05-07 17:52:51", "link": "http://arxiv.org/abs/2405.04520v1", "categories": ["cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM\n  Serving", "abstract": "Quantization can accelerate large language model (LLM) inference. Going\nbeyond INT8 quantization, the research community is actively exploring even\nlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization\ntechniques only accelerate low-batch, edge LLM inference, failing to deliver\nperformance gains in large-batch, cloud-based LLM serving. We uncover a\ncritical issue: existing INT4 quantization methods suffer from significant\nruntime overhead (20-90%) when dequantizing either weights or partial sums on\nGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization\nalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands\nfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented\nby the QServe inference library that achieves measured speedup. The key insight\ndriving QServe is that the efficiency of LLM serving on GPUs is critically\ninfluenced by operations on low-throughput CUDA cores. Building upon this\ninsight, in QoQ algorithm, we introduce progressive quantization that can allow\nlow dequantization overhead in W4A8 GEMM. Additionally, we develop\nSmoothAttention to effectively mitigate the accuracy degradation incurred by\n4-bit KV quantization. In the QServe system, we perform compute-aware weight\nreordering and take advantage of register-level parallelism to reduce\ndequantization latency. We also make fused attention memory-bound, harnessing\nthe performance gain brought by KV4 quantization. As a result, QServe improves\nthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x\non L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to\nTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput\nthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of\nLLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.", "published": "2024-05-07 17:59:30", "link": "http://arxiv.org/abs/2405.04532v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.CL"}
{"title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through\n  Strategies for Low-Resource Language Adaptation and Benchmarking", "abstract": "Large Language Models (LLMs) are becoming crucial across various fields,\nemphasizing the urgency for high-quality models in underrepresented languages.\nThis study explores the unique challenges faced by low-resource languages, such\nas data scarcity, model selection, evaluation, and computational limitations,\nwith a special focus on Turkish. We conduct an in-depth analysis to evaluate\nthe impact of training strategies, model choices, and data availability on the\nperformance of LLMs designed for underrepresented languages. Our approach\nincludes two methodologies: (i) adapting existing LLMs originally pretrained in\nEnglish to understand Turkish, and (ii) developing a model from the ground up\nusing Turkish pretraining data, both supplemented with supervised fine-tuning\non a novel Turkish instruction-tuning dataset aimed at enhancing reasoning\ncapabilities. The relative performance of these methods is evaluated through\nthe creation of a new leaderboard for Turkish LLMs, featuring benchmarks that\nassess different reasoning and knowledge skills. Furthermore, we conducted\nexperiments on data and model scaling, both during pretraining and fine-tuning,\nsimultaneously emphasizing the capacity for knowledge transfer across languages\nand addressing the challenges of catastrophic forgetting encountered during\nfine-tuning on a different language. Our goal is to offer a detailed guide for\nadvancing the LLM framework in low-resource linguistic contexts, thereby making\nnatural language processing (NLP) benefits more globally accessible.", "published": "2024-05-07 21:58:45", "link": "http://arxiv.org/abs/2405.04685v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DrugLLM: Open Large Language Model for Few-shot Molecule Generation", "abstract": "Large Language Models (LLMs) have made great strides in areas such as\nlanguage processing and computer vision. Despite the emergence of diverse\ntechniques to improve few-shot learning capacity, current LLMs fall short in\nhandling the languages in biology and chemistry. For example, they are\nstruggling to capture the relationship between molecule structure and\npharmacochemical properties. Consequently, the few-shot learning capacity of\nsmall-molecule drug modification remains impeded. In this work, we introduced\nDrugLLM, a LLM tailored for drug design. During the training process, we\nemployed Group-based Molecular Representation (GMR) to represent molecules,\narranging them in sequences that reflect modifications aimed at enhancing\nspecific molecular properties. DrugLLM learns how to modify molecules in drug\ndiscovery by predicting the next molecule based on past modifications.\nExtensive computational experiments demonstrate that DrugLLM can generate new\nmolecules with expected properties based on limited examples, presenting a\npowerful few-shot molecule generation capacity.", "published": "2024-05-07 09:18:13", "link": "http://arxiv.org/abs/2405.06690v1", "categories": ["q-bio.BM", "cs.CL", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Fleet of Agents: Coordinated Problem Solving with Large Language Models\n  using Genetic Particle Filtering", "abstract": "Large language models (LLMs) have significantly evolved, moving from simple\noutput generation to complex reasoning and from stand-alone usage to being\nembedded into broader frameworks. In this paper, we introduce \\emph{Fleet of\nAgents (FoA)}, a novel framework utilizing LLMs as agents to navigate through\ndynamic tree searches, employing a genetic-type particle filtering approach.\nFoA spawns a multitude of agents, each exploring autonomously, followed by a\nselection phase where resampling based on a heuristic value function optimizes\nthe balance between exploration and exploitation. This mechanism enables\ndynamic branching, adapting the exploration strategy based on discovered\nsolutions. We experimentally validate FoA using two benchmark tasks, \"Game of\n24\" and \"Mini-Crosswords\". FoA outperforms the previously proposed\nTree-of-Thoughts method in terms of efficacy and efficiency: it significantly\ndecreases computational costs (by calling the value function less frequently)\nwhile preserving comparable or even superior accuracy.", "published": "2024-05-07 09:36:23", "link": "http://arxiv.org/abs/2405.06691v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Folded Context Condensation in Path Integral Formalism for Infinite\n  Context Transformers", "abstract": "In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.", "published": "2024-05-07 19:05:26", "link": "http://arxiv.org/abs/2405.04620v4", "categories": ["hep-ph", "cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "hep-ph"}
{"title": "Intelligent Cardiac Auscultation for Murmur Detection via\n  Parallel-Attentive Models with Uncertainty Estimation", "abstract": "Heart murmurs are a common manifestation of cardiovascular diseases and can\nprovide crucial clues to early cardiac abnormalities. While most current\nresearch methods primarily focus on the accuracy of models, they often overlook\nother important aspects such as the interpretability of machine learning\nalgorithms and the uncertainty of predictions. This paper introduces a heart\nmurmur detection method based on a parallel-attentive model, which consists of\ntwo branches: One is based on a self-attention module and the other one is\nbased on a convolutional network. Unlike traditional approaches, this structure\nis better equipped to handle long-term dependencies in sequential data, and\nthus effectively captures the local and global features of heart murmurs.\nAdditionally, we acknowledge the significance of understanding the uncertainty\nof model predictions in the medical field for clinical decision-making.\nTherefore, we have incorporated an effective uncertainty estimation method\nbased on Monte Carlo Dropout into our model. Furthermore, we have employed\ntemperature scaling to calibrate the predictions of our probabilistic model,\nenhancing its reliability. In experiments conducted on the CirCor Digiscope\ndataset for heart murmur detection, our proposed method achieves a weighted\naccuracy of 79.8% and an F1 of 65.1%, representing state-of-the-art results.", "published": "2024-05-07 02:24:44", "link": "http://arxiv.org/abs/2405.03953v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adaptive Speech Emotion Representation Learning Based On Dynamic Graph", "abstract": "Graph representation learning has become a hot research topic due to its\npowerful nonlinear fitting capability in extracting representative node\nembeddings. However, for sequential data such as speech signals, most\ntraditional methods merely focus on the static graph created within a sequence,\nand largely overlook the intrinsic evolving patterns of these data. This may\nreduce the efficiency of graph representation learning for sequential data. For\nthis reason, we propose an adaptive graph representation learning method based\non dynamically evolved graphs, which are consecutively constructed on a series\nof subsequences segmented by a sliding window. In doing this, it is better to\ncapture local and global context information within a long sequence. Moreover,\nwe introduce a weighted approach to update the node representation rather than\nthe conventional average one, where the weights are calculated by a novel\nmatrix computation based on the degree of neighboring nodes. Finally, we\nconstruct a learnable graph convolutional layer that combines the graph\nstructure loss and classification loss to optimize the graph structure. To\nverify the effectiveness of the proposed method, we conducted experiments for\nspeech emotion recognition on the IEMOCAP and RAVDESS datasets. Experimental\nresults show that the proposed method outperforms the latest (non-)graph-based\nmodels.", "published": "2024-05-07 02:42:17", "link": "http://arxiv.org/abs/2405.03956v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker Characterization by means of Attention Pooling", "abstract": "State-of-the-art Deep Learning systems for speaker verification are commonly\nbased on speaker embedding extractors. These architectures are usually composed\nof a feature extractor front-end together with a pooling layer to encode\nvariable-length utterances into fixed-length speaker vectors. The authors have\nrecently proposed the use of a Double Multi-Head Self-Attention pooling for\nspeaker recognition, placed between a CNN-based front-end and a set of fully\nconnected layers. This has shown to be an excellent approach to efficiently\nselect the most relevant features captured by the front-end from the speech\nsignal. In this paper we show excellent experimental results by adapting this\narchitecture to other different speaker characterization tasks, such as emotion\nrecognition, sex classification and COVID-19 detection.", "published": "2024-05-07 07:56:30", "link": "http://arxiv.org/abs/2405.04096v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Universal Spatial Audio Transcoder", "abstract": "This paper addresses the challenges associated with both the conversion\nbetween different spatial audio formats and the decoding of a spatial audio\nformat to a specific loudspeaker layout. Existing approaches often rely on\nlayout remapping tools, which may not guarantee optimal conversion from a\npsychoacoustic perspective. To overcome these challenges, we present the\nUniversal Spatial Audio Transcoder (USAT) method and its corresponding open\nsource implementation. USAT generates an optimal decoder or transcoder for any\ninput spatial audio format, adapting it to any output format or 2D/3D\nloudspeaker configuration. Drawing upon optimization techniques based on\npsychoacoustic principles, the algorithm maximizes the preservation of spatial\ninformation. We present examples of the decoding and transcoding of several\naudio formats, and show that USAT approach is advantageous compared to the most\ncommon methods in the field.", "published": "2024-05-07 16:32:26", "link": "http://arxiv.org/abs/2405.04471v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BERP: A Blind Estimator of Room Parameters for Single-Channel Noisy\n  Speech Signals", "abstract": "Room acoustical parameters (RAPs), room geometrical parameters (RGPs) and\ninstantaneous occupancy level are essential metrics for parameterizing the room\nacoustical characteristics (RACs) of a sound field around a listener's local\nenvironment, offering comprehensive indications for various applications.\nCurrent blind estimation methods either fail to cover a broad range of\nreal-world acoustic environments in the context of real background noise or\nestimate only a few RAPs and RGPs from noisy single-channel speech signals. In\naddition, they are limited in their ability to estimate the instantaneous\noccupancy level. In this paper, we propose a new universal blind estimation\nframework called the blind estimator of room parameters (BERP) to estimate\nRAPs, RGPs and occupancy level via a unified methodology. It consists of two\nmodules: a unified room feature encoder that combines attention mechanisms with\nconvolutional layers to learn common features across room parameters, and\nmultiple separate parametric predictors for continuous estimation of each\nparameter in parallel. The combination of attention and convolutions enables\nthe model to capture acoustic features locally and globally from speech,\nyielding more robust and multitask generalizable common features. Separate\npredictors allow the model to independently optimize for each room parameter to\nreduce task learning conflict and improve per-task performance. This estimation\nframework enables universal and efficient estimation of room parameters while\nmaintaining satisfactory performance. To evaluate the effectiveness of the\nproposed framework, we compile a task-specific dataset from several publicly\navailable datasets, including synthetic and real reverberant recordings. The\nresults reveal that BERP achieves state-of-the-art (SOTA) performance and\nexcellent adaptability to real-world scenarios. The code and weights are\navailable on GitHub.", "published": "2024-05-07 16:41:41", "link": "http://arxiv.org/abs/2405.04476v6", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SingIt! Singer Voice Transformation", "abstract": "In this paper, we propose a model which can generate a singing voice from\nnormal speech utterance by harnessing zero-shot, many-to-many style transfer\nlearning. Our goal is to give anyone the opportunity to sing any song in a\ntimely manner. We present a system comprising several available blocks, as well\nas a modified auto-encoder, and show how this highly-complex challenge can be\nachieved by tailoring rather simple solutions together. We demonstrate the\napplicability of the proposed system using a group of 25 non-expert listeners.\nSamples of the data generated from our model are provided.", "published": "2024-05-07 19:14:57", "link": "http://arxiv.org/abs/2405.04627v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Detecting music deepfakes is easy but actually hard", "abstract": "In the face of a new era of generative models, the detection of artificially\ngenerated content has become a matter of utmost importance. The ability to\ncreate credible minute-long music deepfakes in a few seconds on user-friendly\nplatforms poses a real threat of fraud on streaming services and unfair\ncompetition to human artists. This paper demonstrates the possibility (and\nsurprising ease) of training classifiers on datasets comprising real audio and\nfake reconstructions, achieving a convincing accuracy of 99.8%. To our\nknowledge, this marks the first publication of a music deepfake detector, a\ntool that will help in the regulation of music forgery. Nevertheless, informed\nby decades of literature on forgery detection in other fields, we stress that a\ngood test score is not the end of the story. We step back from the\nstraightforward ML framework and expose many facets that could be problematic\nwith such a deployed detector: calibration, robustness to audio manipulation,\ngeneralisation to unseen models, interpretability and possibility for recourse.\nThis second part acts as a position for future research steps in the field and\na caveat to a flourishing market of fake content checkers.", "published": "2024-05-07 10:39:19", "link": "http://arxiv.org/abs/2405.04181v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BUDDy: Single-Channel Blind Unsupervised Dereverberation with Diffusion\n  Models", "abstract": "In this paper, we present an unsupervised single-channel method for joint\nblind dereverberation and room impulse response estimation, based on posterior\nsampling with diffusion models. We parameterize the reverberation operator\nusing a filter with exponential decay for each frequency subband, and\niteratively estimate the corresponding parameters as the speech utterance gets\nrefined along the reverse diffusion trajectory. A measurement consistency\ncriterion enforces the fidelity of the generated speech with the reverberant\nmeasurement, while an unconditional diffusion model implements a strong prior\nfor clean speech generation. Without any knowledge of the room impulse response\nnor any coupled reverberant-anechoic data, we can successfully perform\ndereverberation in various acoustic scenarios. Our method significantly\noutperforms previous blind unsupervised baselines, and we demonstrate its\nincreased robustness to unseen acoustic conditions in comparison to blind\nsupervised methods. Audio samples and code are available online.", "published": "2024-05-07 12:41:31", "link": "http://arxiv.org/abs/2405.04272v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adapting WavLM for Speech Emotion Recognition", "abstract": "Recently, the usage of speech self-supervised models (SSL) for downstream\ntasks has been drawing a lot of attention. While large pre-trained models\ncommonly outperform smaller models trained from scratch, questions regarding\nthe optimal fine-tuning strategies remain prevalent. In this paper, we explore\nthe fine-tuning strategies of the WavLM Large model for the speech emotion\nrecognition task on the MSP Podcast Corpus. More specifically, we perform a\nseries of experiments focusing on using gender and semantic information from\nutterances. We then sum up our findings and describe the final model we used\nfor submission to Speech Emotion Recognition Challenge 2024.", "published": "2024-05-07 16:53:42", "link": "http://arxiv.org/abs/2405.04485v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
