{"title": "Interest rate derivatives in a CTMC setting: pricing, replication and Ross recovery", "abstract": "We consider a financial market in which the short rate is modeled by a\ncontinuous time Markov chain (CTMC) with a finite state space. In this setting,\nwe show how to price any financial derivative whose payoff is a function of the\nstate of the underlying CTMC at the maturity date. We also show how to\nreplicate such claims by trading only a money market account and zero-coupon\nbonds. Finally, using an extension of Ross' Recovery Theorem due to Qin and\nLinetsky, we deduce the real-world dynamics of the CTMC.", "published": "2024-09-21 16:47:06", "link": "http://arxiv.org/abs/2409.14193v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Price predictability in limit order book with deep learning model", "abstract": "This study explores the prediction of high-frequency price changes using deep\nlearning models. Although state-of-the-art methods perform well, their\ncomplexity impedes the understanding of successful predictions. We found that\nan inadequately defined target price process may render predictions meaningless\nby incorporating past information. The commonly used three-class problem in\nasset price prediction can generally be divided into volatility and directional\nprediction. When relying solely on the price process, directional prediction\nperformance is not substantial. However, volume imbalance improves directional\nprediction performance.", "published": "2024-09-21 14:40:13", "link": "http://arxiv.org/abs/2409.14157v1", "categories": ["q-fin.ST", "q-fin.TR", "stat.ML"], "primary_category": "q-fin.ST"}
{"title": "Can Language Model Understand Word Semantics as A Chatbot? An Empirical\n  Study of Language Model Internal External Mismatch", "abstract": "Current common interactions with language models is through full inference.\nThis approach may not necessarily align with the model's internal knowledge.\nStudies show discrepancies between prompts and internal representations. Most\nfocus on sentence understanding. We study the discrepancy of word semantics\nunderstanding in internal and external mismatch across Encoder-only,\nDecoder-only, and Encoder-Decoder pre-trained language models.", "published": "2024-09-21 01:35:58", "link": "http://arxiv.org/abs/2409.13972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Role-Play Paradox in Large Language Models: Reasoning Performance Gains\n  and Ethical Dilemmas", "abstract": "Role-play in large language models (LLMs) enhances their ability to generate\ncontextually relevant and high-quality responses by simulating diverse\ncognitive perspectives. However, our study identifies significant risks\nassociated with this technique. First, we demonstrate that autotuning, a method\nused to auto-select models' roles based on the question, can lead to the\ngeneration of harmful outputs, even when the model is tasked with adopting\nneutral roles. Second, we investigate how different roles affect the likelihood\nof generating biased or harmful content. Through testing on benchmarks\ncontaining stereotypical and harmful questions, we find that role-play\nconsistently amplifies the risk of biased outputs. Our results underscore the\nneed for careful consideration of both role simulation and tuning processes\nwhen deploying LLMs in sensitive or high-stakes contexts.", "published": "2024-09-21 02:09:13", "link": "http://arxiv.org/abs/2409.13979v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SMART-RAG: Selection using Determinantal Matrices for Augmented\n  Retrieval", "abstract": "Retrieval-Augmented Generation (RAG) has greatly improved large language\nmodels (LLMs) by enabling them to generate accurate, contextually grounded\nresponses through the integration of external information. However,\nconventional RAG approaches, which prioritize top-ranked documents based solely\non query-context relevance, often introduce redundancy and conflicting\ninformation. This issue is particularly evident in unsupervised retrieval\nsettings, where there are no mechanisms to effectively mitigate these problems,\nleading to suboptimal context selection. To address this, we propose Selection\nusing Matrices for Augmented Retrieval (SMART) in question answering tasks, a\nfully unsupervised and training-free framework designed to optimize context\nselection in RAG. SMART leverages Determinantal Point Processes (DPPs) to\nsimultaneously model relevance, diversity and conflict, ensuring the selection\nof potentially high-quality contexts. Experimental results across multiple\ndatasets demonstrate that SMART significantly enhances QA performance and\nsurpasses previous unsupervised context selection methods, showing a promising\nstrategy for RAG.", "published": "2024-09-21 03:03:09", "link": "http://arxiv.org/abs/2409.13992v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co-occurrence is not Factual Association in Language Models", "abstract": "Pretrained language models can encode a large amount of knowledge and utilize\nit for various reasoning tasks, yet they can still struggle to learn novel\nfactual knowledge effectively from finetuning on limited textual\ndemonstrations. In this work, we show that the reason for this deficiency is\nthat language models are biased to learn word co-occurrence statistics instead\nof true factual associations. We identify the differences between two forms of\nknowledge representation in language models: knowledge in the form of\nco-occurrence statistics is encoded in the middle layers of the transformer\nmodel and does not generalize well to reasoning scenarios beyond simple\nquestion answering, while true factual associations are encoded in the lower\nlayers and can be freely utilized in various reasoning tasks. Based on these\nobservations, we propose two strategies to improve the learning of factual\nassociations in language models. We show that training on text with implicit\nrather than explicit factual associations can force the model to learn factual\nassociations instead of co-occurrence statistics, significantly improving the\ngeneralization of newly learned knowledge. We also propose a simple training\nmethod to actively forget the learned co-occurrence statistics, which unblocks\nand enhances the learning of factual associations when training on plain\nnarrative text. On both synthetic and real-world corpora, the two proposed\nstrategies improve the generalization of the knowledge learned during\nfinetuning to reasoning scenarios such as indirect and multi-hop question\nanswering.", "published": "2024-09-21 08:13:16", "link": "http://arxiv.org/abs/2409.14057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Context Localization of Polysemous Words in Pre-trained Language\n  Model Sub-Layers", "abstract": "In the era of high performing Large Language Models, researchers have widely\nacknowledged that contextual word representations are one of the key drivers in\nachieving top performances in downstream tasks. In this work, we investigate\nthe degree of contextualization encoded in the fine-grained sub-layer\nrepresentations of a Pre-trained Language Model (PLM) by empirical experiments\nusing linear probes. Unlike previous work, we are particularly interested in\nidentifying the strength of contextualization across PLM sub-layer\nrepresentations (i.e. Self-Attention, Feed-Forward Activation and Output\nsub-layers). To identify the main contributions of sub-layers to\ncontextualisation, we first extract the sub-layer representations of polysemous\nwords in minimally different sentence pairs, and compare how these\nrepresentations change through the forward pass of the PLM network. Second, by\nprobing on a sense identification classification task, we try to empirically\nlocalize the strength of contextualization information encoded in these\nsub-layer representations. With these probing experiments, we also try to gain\na better understanding of the influence of context length and context richness\non the degree of contextualization. Our main conclusion is cautionary: BERT\ndemonstrates a high degree of contextualization in the top sub-layers if the\nword in question is in a specific position in the sentence with a shorter\ncontext window, but this does not systematically generalize across different\nword positions and context sizes.", "published": "2024-09-21 10:42:07", "link": "http://arxiv.org/abs/2409.14097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Routing in Sparsely-gated Language Models responds to Context", "abstract": "Language Models (LMs) recently incorporate mixture-of-experts layers\nconsisting of a router and a collection of experts to scale up their parameter\ncount given a fixed computational budget. Building on previous efforts\nindicating that token-expert assignments are predominantly influenced by token\nidentities and positions, we trace routing decisions of similarity-annotated\ntext pairs to evaluate the context sensitivity of learned token-expert\nassignments. We observe that routing in encoder layers mainly depends on\n(semantic) associations, but contextual cues provide an additional layer of\nrefinement. Conversely, routing in decoder layers is more variable and markedly\nless sensitive to context.", "published": "2024-09-21 11:25:19", "link": "http://arxiv.org/abs/2409.14107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpreting Arithmetic Mechanism in Large Language Models through\n  Comparative Neuron Analysis", "abstract": "We find arithmetic ability resides within a limited number of attention\nheads, with each head specializing in distinct operations. To delve into the\nreason, we introduce the Comparative Neuron Analysis (CNA) method, which\nidentifies an internal logic chain consisting of four distinct stages from\ninput to prediction: feature enhancing with shallow FFN neurons, feature\ntransferring by shallow attention layers, feature predicting by arithmetic\nheads, and prediction enhancing among deep FFN neurons. Moreover, we identify\nthe human-interpretable FFN neurons within both feature-enhancing and\nfeature-predicting stages. These findings lead us to investigate the mechanism\nof LoRA, revealing that it enhances prediction probabilities by amplifying the\ncoefficient scores of FFN neurons related to predictions. Finally, we apply our\nmethod in model pruning for arithmetic tasks and model editing for reducing\ngender bias. Code is on https://github.com/zepingyu0512/arithmetic-mechanism.", "published": "2024-09-21 13:46:54", "link": "http://arxiv.org/abs/2409.14144v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Imperative of Conversation Analysis in the Era of LLMs: A Survey of\n  Tasks, Techniques, and Trends", "abstract": "In the era of large language models (LLMs), a vast amount of conversation\nlogs will be accumulated thanks to the rapid development trend of language UI.\nConversation Analysis (CA) strives to uncover and analyze critical information\nfrom conversation data, streamlining manual processes and supporting business\ninsights and decision-making. The need for CA to extract actionable insights\nand drive empowerment is becoming increasingly prominent and attracting\nwidespread attention. However, the lack of a clear scope for CA leads to a\ndispersion of various techniques, making it difficult to form a systematic\ntechnical synergy to empower business applications. In this paper, we perform a\nthorough review and systematize CA task to summarize the existing related work.\nSpecifically, we formally define CA task to confront the fragmented and chaotic\nlandscape in this field, and derive four key steps of CA from conversation\nscene reconstruction, to in-depth attribution analysis, and then to performing\ntargeted training, finally generating conversations based on the targeted\ntraining for achieving the specific goals. In addition, we showcase the\nrelevant benchmarks, discuss potential challenges and point out future\ndirections in both industry and academia. In view of current advancements, it\nis evident that the majority of efforts are still concentrated on the analysis\nof shallow conversation elements, which presents a considerable gap between the\nresearch and business, and with the assist of LLMs, recent work has shown a\ntrend towards research on causality and strategic tasks which are sophisticated\nand high-level. The analyzed experiences and insights will inevitably have\nbroader application value in business operations that target conversation logs.", "published": "2024-09-21 16:52:43", "link": "http://arxiv.org/abs/2409.14195v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction Following without Instruction Tuning", "abstract": "Instruction tuning commonly means finetuning a language model on\ninstruction-response pairs. We discover two forms of adaptation (tuning) that\nare deficient compared to instruction tuning, yet still yield instruction\nfollowing; we call this implicit instruction tuning. We first find that\ninstruction-response pairs are not necessary: training solely on responses,\nwithout any corresponding instructions, yields instruction following. This\nsuggests pretrained models have an instruction-response mapping which is\nrevealed by teaching the model the desired distribution of responses. However,\nwe then find it's not necessary to teach the desired distribution of responses:\ninstruction-response training on narrow-domain data like poetry still leads to\nbroad instruction-following behavior like recipe generation. In particular,\nwhen instructions are very different from those in the narrow finetuning\ndomain, models' responses do not adhere to the style of the finetuning domain.\nTo begin to explain implicit instruction tuning, we hypothesize that very\nsimple changes to a language model's distribution yield instruction following.\nWe support this by hand-writing a rule-based language model which yields\ninstruction following in a product-of-experts with a pretrained model. The\nrules are to slowly increase the probability of ending the sequence, penalize\nrepetition, and uniformly change 15 words' probabilities. In summary,\nadaptations made without being designed to yield instruction following can do\nso implicitly.", "published": "2024-09-21 22:36:22", "link": "http://arxiv.org/abs/2409.14254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What is a Digital Twin Anyway? Deriving the Definition for the Built\n  Environment from over 15,000 Scientific Publications", "abstract": "The concept of digital twins has attracted significant attention across\nvarious domains, particularly within the built environment. However, there is a\nsheer volume of definitions and the terminological consensus remains out of\nreach. The lack of a universally accepted definition leads to ambiguities in\ntheir conceptualization and implementation, and may cause miscommunication for\nboth researchers and practitioners. We employed Natural Language Processing\n(NLP) techniques to systematically extract and analyze definitions of digital\ntwins from a corpus of more than 15,000 full-text articles spanning diverse\ndisciplines. The study compares these findings with insights from an expert\nsurvey that included 52 experts. The study identifies concurrence on the\ncomponents that comprise a ``Digital Twin'' from a practical perspective across\nvarious domains, contrasting them with those that do not, to identify\ndeviations. We investigate the evolution of digital twin definitions over time\nand across different scales, including manufacturing, building, and\nurban/geospatial perspectives. We extracted the main components of Digital\nTwins using Text Frequency Analysis and N-gram analysis. Subsequently, we\nidentified components that appeared in the literature and conducted a\nChi-square test to assess the significance of each component in different\ndomains. Our analysis identified key components of digital twins and revealed\nsignificant variations in definitions based on application domains, such as\nmanufacturing, building, and urban contexts. The analysis of DT components\nreveal two major groups of DT types: High-Performance Real-Time (HPRT) DTs, and\nLong-Term Decision Support (LTDS) DTs. Contrary to common assumptions, we found\nthat components such as simulation, AI/ML, real-time capabilities, and\nbi-directional data flow are not yet fully mature in the digital twins of the\nbuilt environment.", "published": "2024-09-21 09:19:29", "link": "http://arxiv.org/abs/2409.19005v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rephrase and Contrast: Fine-Tuning Language Models for Enhanced\n  Understanding of Communication and Computer Networks", "abstract": "Large language models (LLMs) are being widely researched across various\ndisciplines, with significant recent efforts focusing on adapting LLMs for\nunderstanding of how communication networks operate. However, over-reliance on\nprompting techniques hinders the full exploitation of the generalization\nability of these models, and the lack of efficient fine-tuning methods prevents\nthe full realization of lightweight LLMs' potential. This paper addresses these\nchallenges by introducing our Rephrase and Contrast (RaC) framework, an\nefficient fine-tuning framework. RaC enhances LLMs' comprehension and critical\nthinking abilities by incorporating question reformulation and contrastive\nanalysis of correct and incorrect answers during the fine-tuning process.\nExperimental results demonstrate a 63.73% accuracy improvement over the\nfoundational model when tested on a comprehensive networking problem set.\nMoreover, to efficiently construct the dataset for RaC fine-tuning, we develop\na GPT-assisted data mining method for generating high-quality question-answer\n(QA) pairs; furthermore, we introduce ChoiceBoost, a data augmentation\ntechnique that expands dataset size while reducing answer-order bias. Apart\nfrom these technical innovations, we contribute to the networking community by\nopen-sourcing valuable research resources, including: 1) the fine-tuned\nnetworking model referred to as RaC-Net, 2) the training dataset used for\nfine-tuning the model, 3) three testing problem sets of different difficulties\nto serve as benchmarks for future research, and 4) code associated with the\nabove resources.", "published": "2024-09-21 16:04:43", "link": "http://arxiv.org/abs/2409.19007v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Automated Keyword Mnemonics Generation with Large Language\n  Models via Overgenerate-and-Rank", "abstract": "In this paper, we study an under-explored area of language and vocabulary\nlearning: keyword mnemonics, a technique for memorizing vocabulary through\nmemorable associations with a target word via a verbal cue. Typically, creating\nverbal cues requires extensive human effort and is quite time-consuming,\nnecessitating an automated method that is more scalable. We propose a novel\novergenerate-and-rank method via prompting large language models (LLMs) to\ngenerate verbal cues and then ranking them according to psycholinguistic\nmeasures and takeaways from a pilot user study. To assess cue quality, we\nconduct both an automated evaluation of imageability and coherence, as well as\na human evaluation involving English teachers and learners. Results show that\nLLM-generated mnemonics are comparable to human-generated ones in terms of\nimageability, coherence, and perceived usefulness, but there remains plenty of\nroom for improvement due to the diversity in background and preference among\nlanguage learners.", "published": "2024-09-21 00:00:18", "link": "http://arxiv.org/abs/2409.13952v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning for Knowledge-Based Question Generation in Large\n  Language Models", "abstract": "With the rapid development of artificial intelligence technology, especially\nthe increasingly widespread application of question-and-answer systems,\nhigh-quality question generation has become a key component in supporting the\ndevelopment of these systems. This article focuses on knowledge-based question\ngeneration technology, which aims to enable computers to simulate the human\nquestioning process based on understanding specific texts or knowledge bases.\nIn light of the issues of hallucination and knowledge gaps present in\nlarge-scale language models when applied to knowledge-intensive tasks, this\npaper proposes an enhanced question generation method that incorporates\ncontrastive learning. This method utilizes multiple models to jointly mine\ndomain knowledge and uses contrastive learning to guide the model in reducing\nnoise and hallucinations in generation. Experimental results show that by\ndesigning prompts containing contrasting examples, the model's performance in\nquestion generation improves considerably, particularly when contrasting\ninstructions and examples are used simultaneously, leading to the highest\nquality of generated questions and improved accuracy. These results demonstrate\nthat the method proposed in this study, which combines contrasting context and\nchain-of-thought prompts, can effectively improve both the quality and the\npracticality of question generation.", "published": "2024-09-21 03:09:10", "link": "http://arxiv.org/abs/2409.13994v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph Neural Network Framework for Sentiment Analysis Using Syntactic\n  Feature", "abstract": "Amidst the swift evolution of social media platforms and e-commerce\necosystems, the domain of opinion mining has surged as a pivotal area of\nexploration within natural language processing. A specialized segment within\nthis field focuses on extracting nuanced evaluations tied to particular\nelements within textual contexts. This research advances a composite framework\nthat amalgamates the positional cues of topical descriptors. The proposed\nsystem converts syntactic structures into a matrix format, leveraging\nconvolutions and attention mechanisms within a graph to distill salient\ncharacteristics. Incorporating the positional relevance of descriptors relative\nto lexical items enhances the sequential integrity of the input. Trials have\nsubstantiated that this integrated graph-centric scheme markedly elevates the\nefficacy of evaluative categorization, showcasing preeminence.", "published": "2024-09-21 03:30:59", "link": "http://arxiv.org/abs/2409.14000v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uncovering Latent Chain of Thought Vectors in Language Models", "abstract": "In this work, we examine how targeted perturbations in the activation space\nof Language Models (LMs) can encode complex reasoning patterns. We inject\nsteering vectors, derived from LM activations, into LMs during inference time\nand study whether these vectors can induce Chain-of-Thought (CoT) reasoning in\nLMs without the need for natural language prompting. We demonstrate this\napproach on Llama3 8B Instruct and Mistral 7B v0.2 Instruct and show that\nactivation-space interventions achieve competitive, if not superior,\nperformance compared to traditional CoT prompting across multiple reasoning\nbenchmarks, including GSM8k, MMLU, AGI Eval, and ARC AI2. These findings\nsuggest that neural network activations can encode reasoning patterns, offering\na new application of activation space manipulation as a tool for tuning model\nbehavior.", "published": "2024-09-21 05:58:07", "link": "http://arxiv.org/abs/2409.14026v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs\n  as Science Communicators", "abstract": "Large Language Models (LLMs) and AI assistants driven by these models are\nexperiencing exponential growth in usage among both expert and amateur users.\nIn this work, we focus on evaluating the reliability of current LLMs as science\ncommunicators. Unlike existing benchmarks, our approach emphasizes assessing\nthese models on scientific questionanswering tasks that require a nuanced\nunderstanding and awareness of answerability. We introduce a novel dataset,\nSCiPS-QA, comprising 742 Yes/No queries embedded in complex scientific\nconcepts, along with a benchmarking suite that evaluates LLMs for correctness\nand consistency across various criteria. We benchmark three proprietary LLMs\nfrom the OpenAI GPT family and 13 open-access LLMs from the Meta Llama-2,\nLlama-3, and Mistral families. While most open-access models significantly\nunderperform compared to GPT-4 Turbo, our experiments identify Llama-3-70B as a\nstrong competitor, often surpassing GPT-4 Turbo in various evaluation aspects.\nWe also find that even the GPT models exhibit a general incompetence in\nreliably verifying LLM responses. Moreover, we observe an alarming trend where\nhuman evaluators are deceived by incorrect responses from GPT-4 Turbo.", "published": "2024-09-21 06:48:32", "link": "http://arxiv.org/abs/2409.14037v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group\n  Discussion", "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across diverse NLP tasks. Extensive research has explored how to\nenhance the logical reasoning abilities such as Chain-of-Thought,\nChain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent\ndebates. In the context of multi-agent debates, significant performance\nimprovements can be achieved with an increasing number of agents and debate\nrounds. However, the escalation in the number of agents and debate rounds can\ndrastically raise the tokens cost of debates, thereby limiting the scalability\nof the multi-agent debate technique. To better harness the advantages of\nmulti-agent debates in logical reasoning tasks, this paper proposes a method to\nsignificantly reduce token cost in multi-agent debates. This approach involves\ndividing all agents into multiple debate groups, with agents engaging in\ndebates within their respective groups and sharing interim debate results\nbetween groups. Comparative experiments across multiple datasets have\ndemonstrated that this method can reduce the total tokens by up to 51.7% during\ndebates and while potentially enhancing accuracy by as much as 25%. Our method\nsignificantly enhances the performance and efficiency of interactions in the\nmulti-agent debate.", "published": "2024-09-21 07:49:38", "link": "http://arxiv.org/abs/2409.14051v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Temporally Consistent Factuality Probing for Large Language Models", "abstract": "The prolific use of Large Language Models (LLMs) as an alternate knowledge\nbase requires them to be factually consistent, necessitating both correctness\nand consistency traits for paraphrased queries. Recently, significant attempts\nhave been made to benchmark datasets and metrics to evaluate LLMs for these\ntraits. However, structural simplicity (subject-relation-object) and\ncontemporary association in their query formulation limit the broader\ndefinition of factuality and consistency. In this study, we introduce TeCFaP, a\nnovel Temporally Consistent Factuality Probe task to expand the consistent\nfactuality probe in the temporal dimension. To this end, we propose TEMP-COFAC,\na high-quality dataset of prefix-style English query paraphrases. Subsequently,\nwe extend the definitions of existing metrics to represent consistent\nfactuality across temporal dimension. We experiment with a diverse set of LLMs\nand find most of them performing poorly on TeCFaP. Next, we propose a novel\nsolution CoTSeLF (Consistent-Time-Sensitive Learning Framework) combining\nmulti-task instruction tuning (MT-IT) with consistent-time-sensitive\nreinforcement learning (CTSRL) to improve temporally consistent factuality in\nLLMs. Our experiments demonstrate the efficacy of CoTSeLF over several\nbaselines.", "published": "2024-09-21 08:41:08", "link": "http://arxiv.org/abs/2409.14065v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for Text-to-SQL\ntasks, exhibiting remarkable reasoning capabilities. Different from tasks such\nas math word problems and commonsense reasoning, SQL solutions have a\nrelatively fixed pattern. This facilitates the investigation of whether LLMs\ncan benefit from categorical thinking, mirroring how humans acquire knowledge\nthrough inductive reasoning based on comparable examples. In this study, we\npropose that employing query group partitioning allows LLMs to focus on\nlearning the thought processes specific to a single problem type, consequently\nenhancing their reasoning abilities across diverse difficulty levels and\nproblem categories. Our experiments reveal that multiple advanced LLMs, when\nequipped with PTD-SQL, can either surpass or match previous state-of-the-art\n(SOTA) methods on the Spider and BIRD datasets. Intriguingly, models with\nvarying initial performances have exhibited significant improvements, mainly at\nthe boundary of their capabilities after targeted drilling, suggesting a\nparallel with human progress. Code is available at\nhttps://github.com/lrlbbzl/PTD-SQL.", "published": "2024-09-21 09:33:14", "link": "http://arxiv.org/abs/2409.14082v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Importance of Pruning and Distillation for Efficient Low Resource NLP", "abstract": "The rise of large transformer models has revolutionized Natural Language\nProcessing, leading to significant advances in tasks like text classification.\nHowever, this progress demands substantial computational resources, escalating\ntraining duration, and expenses with larger model sizes. Efforts have been made\nto downsize and accelerate English models (e.g., Distilbert, MobileBert). Yet,\nresearch in this area is scarce for low-resource languages.\n  In this study, we explore the case of the low-resource Indic language\nMarathi. Leveraging the marathi-topic-all-doc-v2 model as our baseline, we\nimplement optimization techniques to reduce computation time and memory usage.\nOur focus is on enhancing the efficiency of Marathi transformer models while\nmaintaining top-tier accuracy and reducing computational demands. Using the\nMahaNews document classification dataset and the marathi-topic-all-doc-v2 model\nfrom L3Cube, we apply Block Movement Pruning, Knowledge Distillation, and Mixed\nPrecision methods individually and in combination to boost efficiency. We\ndemonstrate the importance of strategic pruning levels in achieving desired\nefficiency gains. Furthermore, we analyze the balance between efficiency\nimprovements and environmental impact, highlighting how optimized model\narchitectures can contribute to a more sustainable computational ecosystem.\nImplementing these techniques on a single GPU system, we determine that the\noptimal configuration is 25\\% pruning + knowledge distillation. This approach\nyielded a 2.56x speedup in computation time while maintaining baseline accuracy\nlevels.", "published": "2024-09-21 14:58:12", "link": "http://arxiv.org/abs/2409.14162v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Building Efficient Sentence BERT Models using Layer Pruning", "abstract": "This study examines the effectiveness of layer pruning in creating efficient\nSentence BERT (SBERT) models. Our goal is to create smaller sentence embedding\nmodels that reduce complexity while maintaining strong embedding similarity. We\nassess BERT models like Muril and MahaBERT-v2 before and after pruning,\ncomparing them with smaller, scratch-trained models like MahaBERT-Small and\nMahaBERT-Smaller. Through a two-phase SBERT fine-tuning process involving\nNatural Language Inference (NLI) and Semantic Textual Similarity (STS), we\nevaluate the impact of layer reduction on embedding quality. Our findings show\nthat pruned models, despite fewer layers, perform competitively with fully\nlayered versions. Moreover, pruned models consistently outperform similarly\nsized, scratch-trained models, establishing layer pruning as an effective\nstrategy for creating smaller, efficient embedding models. These results\nhighlight layer pruning as a practical approach for reducing computational\ndemand while preserving high-quality embeddings, making SBERT models more\naccessible for languages with limited technological resources.", "published": "2024-09-21 15:10:06", "link": "http://arxiv.org/abs/2409.14168v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Lexical Invariance on Multisets and Graphs", "abstract": "In this draft, we study a novel problem, called lexical invariance, using the\nmedium of multisets and graphs. Traditionally in the NLP domain, lexical\ninvariance indicates that the semantic meaning of a sentence should remain\nunchanged regardless of the specific lexical or word-based representation of\nthe input. For example, ``The movie was extremely entertaining'' would have the\nsame meaning as ``The film was very enjoyable''. In this paper, we study a more\nchallenging setting, where the output of a function is invariant to any\ninjective transformation applied to the input lexical space. For example,\nmultiset {1,2,3,2} is equivalent to multiset {a,b,c,b} if we specify an\ninjective transformation that maps 1 to a, 2 to b and 3 to c. We study the\nsufficient and necessary conditions for a most expressive lexical invariant\n(and permutation invariant) function on multisets and graphs, and proves that\nfor multisets, the function must have a form that only takes the multiset of\ncounts of the unique elements in the original multiset as input. For example, a\nmost expressive lexical invariant function on {a,b,c,b} must have a form that\nonly operates on {1,1,2} (meaning that there are 1, 1, 2 unique elements\ncorresponding to a,c,b). For graphs, we prove that a most expressive lexical\ninvariant and permutation invariant function must have a form that only takes\nthe adjacency matrix and a difference matrix as input, where the (i,j)th\nelement of the difference matrix is 1 if node i and node j have the same\nfeature and 0 otherwise. We perform synthetic experiments on TU datasets to\nverify our theorems.", "published": "2024-09-21 15:52:01", "link": "http://arxiv.org/abs/2409.14179v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic\n  Extraction", "abstract": "Integrating structured knowledge from tabular formats poses significant\nchallenges within natural language processing (NLP), mainly when dealing with\ncomplex, semi-structured tables like those found in the FeTaQA dataset. These\ntables require advanced methods to interpret and generate meaningful responses\naccurately. Traditional approaches, such as SQL and SPARQL, often fail to fully\ncapture the semantics of such data, especially in the presence of irregular\ntable structures like web tables. This paper addresses these challenges by\nproposing a novel approach that extracts triples straightforward from tabular\ndata and integrates it with a retrieval-augmented generation (RAG) model to\nenhance the accuracy, coherence, and contextual richness of responses generated\nby a fine-tuned GPT-3.5-turbo-0125 model. Our approach significantly\noutperforms existing baselines on the FeTaQA dataset, particularly excelling in\nSacre-BLEU and ROUGE metrics. It effectively generates contextually accurate\nand detailed long-form answers from tables, showcasing its strength in complex\ndata interpretation.", "published": "2024-09-21 16:46:15", "link": "http://arxiv.org/abs/2409.14192v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Repairs in a Block World: A New Benchmark for Handling User Corrections\n  with Multi-Modal Language Models", "abstract": "In dialogue, the addressee may initially misunderstand the speaker and\nrespond erroneously, often prompting the speaker to correct the\nmisunderstanding in the next turn with a Third Position Repair (TPR). The\nability to process and respond appropriately to such repair sequences is thus\ncrucial in conversational AI systems. In this paper, we first collect, analyse,\nand publicly release BlockWorld-Repairs: a dataset of multi-modal TPR sequences\nin an instruction-following manipulation task that is, by design, rife with\nreferential ambiguity. We employ this dataset to evaluate several\nstate-of-the-art Vision and Language Models (VLM) across multiple settings,\nfocusing on their capability to process and accurately respond to TPRs and thus\nrecover from miscommunication. We find that, compared to humans, all models\nsignificantly underperform in this task. We then show that VLMs can benefit\nfrom specialised losses targeting relevant tokens during fine-tuning, achieving\nbetter performance and generalising better to new scenarios. Our results\nsuggest that these models are not yet ready to be deployed in multi-modal\ncollaborative settings where repairs are common, and highlight the need to\ndesign training regimes and objectives that facilitate learning from\ninteraction. Our code and data are available at\nwww.github.com/JChiyah/blockworld-repairs", "published": "2024-09-21 21:06:25", "link": "http://arxiv.org/abs/2409.14247v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching", "abstract": "Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.", "published": "2024-09-21 06:49:34", "link": "http://arxiv.org/abs/2409.14038v5", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "MultiMed: Multilingual Medical Speech Recognition via Attention Encoder\n  Decoder", "abstract": "Multilingual automatic speech recognition (ASR) in the medical domain serves\nas a foundational task for various downstream applications such as speech\ntranslation, spoken language understanding, and voice-activated assistants.\nThis technology enhances patient care by enabling efficient communication\nacross language barriers, alleviating specialized workforce shortages, and\nfacilitating improved diagnosis and treatment, particularly during pandemics.\nIn this work, we introduce MultiMed, the first multilingual medical ASR\ndataset, along with the first collection of small-to-large end-to-end medical\nASR models, spanning five languages: Vietnamese, English, German, French, and\nMandarin Chinese. To our best knowledge, MultiMed stands as the world's largest\nmedical ASR dataset across all major benchmarks: total duration, number of\nrecording conditions, number of accents, and number of speaking roles.\nFurthermore, we present the first multilinguality study for medical ASR, which\nincludes reproducible empirical baselines, a monolinguality-multilinguality\nanalysis, Attention Encoder Decoder (AED) vs Hybrid comparative study, a\nlayer-wise ablation study for the AED, and a linguistic analysis for\nmultilingual medical ASR. All code, data, and models are available online:\nhttps://github.com/leduckhai/MultiMed/tree/master/MultiMed", "published": "2024-09-21 09:05:48", "link": "http://arxiv.org/abs/2409.14074v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Obliviate: Neutralizing Task-agnostic Backdoors within the\n  Parameter-efficient Fine-tuning Paradigm", "abstract": "Parameter-efficient fine-tuning (PEFT) has become a key training strategy for\nlarge language models. However, its reliance on fewer trainable parameters\nposes security risks, such as task-agnostic backdoors. Despite their severe\nimpact on a wide range of tasks, there is no practical defense solution\navailable that effectively counters task-agnostic backdoors within the context\nof PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor\ndefense. We develop two techniques aimed at amplifying benign neurons within\nPEFT layers and penalizing the influence of trigger tokens. Our evaluations\nacross three major PEFT architectures show that our method can significantly\nreduce the attack success rate of the state-of-the-art task-agnostic backdoors\n(83.6%$\\downarrow$). Furthermore, our method exhibits robust defense\ncapabilities against both task-specific backdoors and adaptive attacks. Source\ncode will be obtained at https://github.com/obliviateARR/Obliviate.", "published": "2024-09-21 12:20:18", "link": "http://arxiv.org/abs/2409.14119v3", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PromptTA: Prompt-driven Text Adapter for Source-free Domain\n  Generalization", "abstract": "Source-free domain generalization (SFDG) tackles the challenge of adapting\nmodels to unseen target domains without access to source domain data. To deal\nwith this challenging task, recent advances in SFDG have primarily focused on\nleveraging the text modality of vision-language models such as CLIP. These\nmethods involve developing a transferable linear classifier based on diverse\nstyle features extracted from the text and learned prompts or deriving\ndomain-unified text representations from domain banks. However, both style\nfeatures and domain banks have limitations in capturing comprehensive domain\nknowledge. In this work, we propose Prompt-Driven Text Adapter (PromptTA)\nmethod, which is designed to better capture the distribution of style features\nand employ resampling to ensure thorough coverage of domain knowledge. To\nfurther leverage this rich domain information, we introduce a text adapter that\nlearns from these style features for efficient domain information storage.\nExtensive experiments conducted on four benchmark datasets demonstrate that\nPromptTA achieves state-of-the-art performance. The code is available at\nhttps://github.com/zhanghr2001/PromptTA.", "published": "2024-09-21 15:02:13", "link": "http://arxiv.org/abs/2409.14163v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "QMOS: Enhancing LLMs for Telecommunication with Question Masked loss and\n  Option Shuffling", "abstract": "Large Language models (LLMs) have brought about substantial advancements in\nthe field of Question Answering (QA) systems. These models do remarkably well\nin addressing intricate inquiries in a variety of disciplines. However, because\nof domain-specific vocabulary, complex technological concepts, and the\nrequirement for exact responses applying LLMs to specialized sectors like\ntelecommunications presents additional obstacles. GPT-3.5 has been used in\nrecent work, to obtain noteworthy accuracy for telecom-related questions in a\nRetrieval Augmented Generation (RAG) framework. Notwithstanding these\ndevelopments, the practical use of models such as GPT-3.5 is restricted by\ntheir proprietary nature and high computing demands. This paper introduces\nQMOS, an innovative approach which uses a Question-Masked loss and Option\nShuffling trick to enhance the performance of LLMs in answering Multiple-Choice\nQuestions in the telecommunications domain. Our focus was on using opensource,\nsmaller language models (Phi-2 and Falcon-7B) within an enhanced RAG framework.\nOur multi-faceted approach involves several enhancements to the whole LLM-RAG\npipeline of finetuning, retrieval, prompt engineering and inference. Our\napproaches significantly outperform existing results, achieving accuracy\nimprovements from baselines of 24.70% to 49.30% with Falcon-7B and from 42.07%\nto 84.65% with Phi-2.", "published": "2024-09-21 15:32:10", "link": "http://arxiv.org/abs/2409.14175v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data-centric NLP Backdoor Defense from the Lens of Memorization", "abstract": "Backdoor attack is a severe threat to the trustworthiness of DNN-based\nlanguage models. In this paper, we first extend the definition of memorization\nof language models from sample-wise to more fine-grained sentence element-wise\n(e.g., word, phrase, structure, and style), and then point out that language\nmodel backdoors are a type of element-wise memorization. Through further\nanalysis, we find that the strength of such memorization is positively\ncorrelated to the frequency of duplicated elements in the training dataset. In\nconclusion, duplicated sentence elements are necessary for successful backdoor\nattacks. Based on this, we propose a data-centric defense. We first detect\ntrigger candidates in training data by finding memorizable elements, i.e.,\nduplicated elements, and then confirm real triggers by testing if the\ncandidates can activate backdoor behaviors (i.e., malicious elements). Results\nshow that our method outperforms state-of-the-art defenses in defending against\ndifferent types of NLP backdoors.", "published": "2024-09-21 17:12:18", "link": "http://arxiv.org/abs/2409.14200v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Adversarial Attacks on Parts of Speech: An Empirical Study in\n  Text-to-Image Generation", "abstract": "Recent studies show that text-to-image (T2I) models are vulnerable to\nadversarial attacks, especially with noun perturbations in text prompts. In\nthis study, we investigate the impact of adversarial attacks on different POS\ntags within text prompts on the images generated by T2I models. We create a\nhigh-quality dataset for realistic POS tag token swapping and perform\ngradient-based attacks to find adversarial suffixes that mislead T2I models\ninto generating images with altered tokens. Our empirical results show that the\nattack success rate (ASR) varies significantly among different POS tag\ncategories, with nouns, proper nouns, and adjectives being the easiest to\nattack. We explore the mechanism behind the steering effect of adversarial\nsuffixes, finding that the number of critical tokens and content fusion vary\namong POS tags, while features like suffix transferability are consistent\nacross categories. We have made our implementation publicly available at -\nhttps://github.com/shahariar-shibli/Adversarial-Attack-on-POS-Tags.", "published": "2024-09-21 09:19:55", "link": "http://arxiv.org/abs/2409.15381v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Automated Patent Workflows: AI-Orchestrated Multi-Agent\n  Framework for Intellectual Property Management and Analysis", "abstract": "Patents are the currency of innovation, and like any currency, they need to\nbe managed and protected (Gavin Potenza). Patents, as legal documents that\nsecure intellectual property rights, play a critical role in technological\ninnovation. The growing complexity of patent documents and the surge in patent\napplications have created a need for automated solutions in patent analysis. In\nthis work, we present PatExpert, an autonomous multi-agent conversational\nframework designed to streamline and optimize patent-related tasks. The\nframework consists of a metaagent that coordinates task-specific expert agents\nfor various patent-related tasks and a critique agent for error handling and\nfeedback provision. The meta-agent orchestrates specialized expert agents, each\nfine-tuned for specific tasks such as patent classification, acceptance, claim\ngeneration, abstractive summarization, multi-patent analysis, and scientific\nhypothesis generation. For multi-patent analysis, the framework incorporates\nadvanced methods like Graph Retrieval-Augmented Generation (GRAG) to enhance\nresponse accuracy and relevance by combining semantic similarity with knowledge\ngraphs. Error handling is managed by critique agents (Gold-LLM-as-a-Judge and\nReward-LLM-as-a-Judge), which evaluate output responses for accuracy and\nprovide iterative feedback. The framework also prioritizes explainability,\nensuring transparent justifications for decisions made during patent analysis.\nIts comprehensive capabilities make it a valuable tool for automating complex\npatent workflows, enhancing efficiency, accuracy, and compliance in\npatent-related tasks. Empirical evidence demonstrates significant improvements\nin patent processing tasks, concluding that the framework offers a robust\nsolution for automating and optimizing patent analysis.", "published": "2024-09-21 13:44:34", "link": "http://arxiv.org/abs/2409.19006v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "StateAct: Enhancing LLM Base Agents via Self-prompting and\n  State-tracking", "abstract": "Large language models (LLMs) are increasingly used as autonomous agents,\ntackling tasks from robotics to web navigation. Their performance depends on\nthe underlying base agent. Existing methods, however, struggle with\nlong-context reasoning and goal adherence. We introduce StateAct, a novel and\nefficient base agent that enhances decision-making through (1) self-prompting,\nwhich reinforces task goals at every step, and (2) chain-of-states, an\nextension of chain-of-thought that tracks state information over time. StateAct\noutperforms ReAct, the previous best base agent, by over 10% on Alfworld, 30%\non Textcraft, and 7% on Webshop across multiple frontier LLMs. We also\ndemonstrate that StateAct can be used as a drop-in replacement for ReAct with\nadvanced LLM agent methods such as test-time scaling, yielding an additional\n12% gain on Textcraft. By improving efficiency and long-range reasoning without\nrequiring additional training or retrieval, StateAct provides a scalable\nfoundation for LLM agents. We open source our code to support further research\nat https://github.com/ai-nikolai/stateact .", "published": "2024-09-21 05:54:35", "link": "http://arxiv.org/abs/2410.02810v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large\n  Language Models", "abstract": "There is a growing interest in the role that LLMs play in chemistry which\nlead to an increased focus on the development of LLMs benchmarks tailored to\nchemical domains to assess the performance of LLMs across a spectrum of\nchemical tasks varying in type and complexity. However, existing benchmarks in\nthis domain fail to adequately meet the specific requirements of chemical\nresearch professionals. To this end, we propose \\textbf{\\textit{ChemEval}},\nwhich provides a comprehensive assessment of the capabilities of LLMs across a\nwide range of chemical domain tasks. Specifically, ChemEval identified 4\ncrucial progressive levels in chemistry, assessing 12 dimensions of LLMs across\n42 distinct chemical tasks which are informed by open-source data and the data\nmeticulously crafted by chemical experts, ensuring that the tasks have\npractical value and can effectively evaluate the capabilities of LLMs. In the\nexperiment, we evaluate 12 mainstream LLMs on ChemEval under zero-shot and\nfew-shot learning contexts, which included carefully selected demonstration\nexamples and carefully designed prompts. The results show that while general\nLLMs like GPT-4 and Claude-3.5 excel in literature understanding and\ninstruction following, they fall short in tasks demanding advanced chemical\nknowledge. Conversely, specialized LLMs exhibit enhanced chemical competencies,\nalbeit with reduced literary comprehension. This suggests that LLMs have\nsignificant potential for enhancement when tackling sophisticated tasks in the\nfield of chemistry. We believe our work will facilitate the exploration of\ntheir potential to drive progress in chemistry. Our benchmark and analysis will\nbe available at {\\color{blue} \\url{https://github.com/USTC-StarTeam/ChemEval}}.", "published": "2024-09-21 02:50:43", "link": "http://arxiv.org/abs/2409.13989v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.chem-ph", "q-bio.BM"], "primary_category": "cs.CL"}
{"title": "A Survey on Large Language Model-empowered Autonomous Driving", "abstract": "Artificial intelligence (AI) plays a crucial role in autonomous driving (AD)\nresearch, propelling its development towards intelligence and efficiency.\nCurrently, the development of AD technology follows two main technical paths:\nmodularization and end-to-end. Modularization decompose the driving task into\nmodules such as perception, prediction, planning, and control, and train them\nseparately. Due to the inconsistency of training objectives between modules,\nthe integrated effect suffers from bias. End-to-end attempts to address this\nissue by utilizing a single model that directly maps from sensor data to\ncontrol signals. This path has limited learning capabilities in a comprehensive\nset of features and struggles to handle unpredictable long-tail events and\ncomplex urban traffic scenarios. In the face of challenges encountered in both\npaths, many researchers believe that large language models (LLMs) with powerful\nreasoning capabilities and extensive knowledge understanding may be the\nsolution, expecting LLMs to provide AD systems with deeper levels of\nunderstanding and decision-making capabilities. In light of the challenges\nfaced by both paths, many researchers believe that LLMs, with their powerful\nreasoning abilities and extensive knowledge, could offer a solution. To\nunderstand if LLMs could enhance AD, this paper conducts a thorough analysis of\nthe potential applications of LLMs in AD systems, including exploring their\noptimization strategies in both modular and end-to-end approaches, with a\nparticular focus on how LLMs can tackle the problems and challenges present in\ncurrent solutions. Furthermore, we discuss an important question: Can LLM-based\nartificial general intelligence (AGI) be a key to achieve high-level AD? We\nfurther analyze the potential limitations and challenges that LLMs may\nencounter in promoting the development of AD technology.", "published": "2024-09-21 15:07:37", "link": "http://arxiv.org/abs/2409.14165v3", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Semi-intrusive audio evaluation: Casting non-intrusive assessment as a\n  multi-modal text prediction task", "abstract": "Human perception has the unique ability to focus on specific events in a\nmixture of signals--a challenging task for existing non-intrusive assessment\nmethods. In this work, we introduce semi-intrusive assessment that emulates\nhuman attention by framing audio assessment as a text-prediction task with\naudio-text inputs. To this end, we extend the multi-modal PENGI model through\ninstruction fine-tuning for MOS and SNR estimation. For MOS, our approach\nachieves absolute Pearson correlation gains of 0.06 and 0.20 over the\nre-trained MOSRA model and the pre-trained PAM model, respectively. We further\npropose a novel SNR estimator that can focus on a specific audio source in a\nmixture, outperforming a random baseline and the fixed-prompt counterpart. Our\nfindings suggest that semi-intrusive assessment can effectively capture\nhuman-like selective listening capabilities. Samples are available at\nhttps://jozefcoldenhoff.github.io/semi-intrusive-assessment.", "published": "2024-09-21 08:52:24", "link": "http://arxiv.org/abs/2409.14069v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Codec-SUPERB @ SLT 2024: A lightweight benchmark for neural audio codec\n  models", "abstract": "Neural audio codec models are becoming increasingly important as they serve\nas tokenizers for audio, enabling efficient transmission or facilitating speech\nlanguage modeling. The ideal neural audio codec should maintain content,\nparalinguistics, speaker characteristics, and audio information even at low\nbitrates. Recently, numerous advanced neural codec models have been proposed.\nHowever, codec models are often tested under varying experimental conditions.\nAs a result, we introduce the Codec-SUPERB challenge at SLT 2024, designed to\nfacilitate fair and lightweight comparisons among existing codec models and\ninspire advancements in the field. This challenge brings together\nrepresentative speech applications and objective metrics, and carefully selects\nlicense-free datasets, sampling them into small sets to reduce evaluation\ncomputation costs. This paper presents the challenge's rules, datasets, five\nparticipant systems, results, and findings.", "published": "2024-09-21 09:39:36", "link": "http://arxiv.org/abs/2409.14085v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Strong Alone, Stronger Together: Synergizing Modality-Binding Foundation\n  Models with Optimal Transport for Non-Verbal Emotion Recognition", "abstract": "In this study, we investigate multimodal foundation models (MFMs) for emotion\nrecognition from non-verbal sounds. We hypothesize that MFMs, with their joint\npre-training across multiple modalities, will be more effective in non-verbal\nsounds emotion recognition (NVER) by better interpreting and differentiating\nsubtle emotional cues that may be ambiguous in audio-only foundation models\n(AFMs). To validate our hypothesis, we extract representations from\nstate-of-the-art (SOTA) MFMs and AFMs and evaluated them on benchmark NVER\ndatasets. We also investigate the potential of combining selected foundation\nmodel representations to enhance NVER further inspired by research in speech\nrecognition and audio deepfake detection. To achieve this, we propose a\nframework called MATA (Intra-Modality Alignment through Transport Attention).\nThrough MATA coupled with the combination of MFMs: LanguageBind and ImageBind,\nwe report the topmost performance with accuracies of 76.47%, 77.40%, 75.12% and\nF1-scores of 70.35%, 76.19%, 74.63% for ASVP-ESD, JNV, and VIVAE datasets\nagainst individual FMs and baseline fusion techniques and report SOTA on the\nbenchmark datasets.", "published": "2024-09-21 18:58:10", "link": "http://arxiv.org/abs/2409.14221v1", "categories": ["eess.AS", "cs.SD", "68T45", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Training Large ASR Encoders with Differential Privacy", "abstract": "Self-supervised learning (SSL) methods for large speech models have proven to\nbe highly effective at ASR. With the interest in public deployment of large\npre-trained models, there is a rising concern for unintended memorization and\nleakage of sensitive data points from the training data. In this paper, we\napply differentially private (DP) pre-training to a SOTA Conformer-based\nencoder, and study its performance on a downstream ASR task assuming the\nfine-tuning data is public. This paper is the first to apply DP to SSL for ASR,\ninvestigating the DP noise tolerance of the BEST-RQ pre-training method.\nNotably, we introduce a novel variant of model pruning called gradient-based\nlayer freezing that provides strong improvements in privacy-utility-compute\ntrade-offs. Our approach yields a LibriSpeech test-clean/other WER (%) of 3.78/\n8.41 with ($10$, 1e^-9)-DP for extrapolation towards low dataset scales, and\n2.81/ 5.89 with (10, 7.9e^-11)-DP for extrapolation towards high scales.", "published": "2024-09-21 00:01:49", "link": "http://arxiv.org/abs/2409.13953v1", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ECHO: Environmental Sound Classification with Hierarchical\n  Ontology-guided Semi-Supervised Learning", "abstract": "Environment Sound Classification has been a well-studied research problem in\nthe field of signal processing and up till now more focus has been laid on\nfully supervised approaches. Over the last few years, focus has moved towards\nsemi-supervised methods which concentrate on the utilization of unlabeled data,\nand self-supervised methods which learn the intermediate representation through\npretext task or contrastive learning. However, both approaches require a vast\namount of unlabelled data to improve performance. In this work, we propose a\nnovel framework called Environmental Sound Classification with Hierarchical\nOntology-guided semi-supervised Learning (ECHO) that utilizes label\nontology-based hierarchy to learn semantic representation by defining a novel\npretext task. In the pretext task, the model tries to predict coarse labels\ndefined by the Large Language Model (LLM) based on ground truth label ontology.\nThe trained model is further fine-tuned in a supervised way to predict the\nactual task. Our proposed novel semi-supervised framework achieves an accuracy\nimprovement in the range of 1\\% to 8\\% over baseline systems across three\ndatasets namely UrbanSound8K, ESC-10, and ESC-50.", "published": "2024-09-21 07:08:57", "link": "http://arxiv.org/abs/2409.14043v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AMT-APC: Automatic Piano Cover by Fine-Tuning an Automatic Music\n  Transcription Model", "abstract": "There have been several studies on automatically generating piano covers, and\nrecent advancements in deep learning have enabled the creation of more\nsophisticated covers. However, existing automatic piano cover models still have\nroom for improvement in terms of expressiveness and fidelity to the original.\nTo address these issues, we propose a learning algorithm called AMT-APC, which\nleverages the capabilities of automatic music transcription models. By\nutilizing the strengths of well-established automatic music transcription\nmodels, we aim to improve the accuracy of piano cover generation. Our\nexperiments demonstrate that the AMT-APC model reproduces original tracks more\naccurately than any existing models.", "published": "2024-09-21 09:51:22", "link": "http://arxiv.org/abs/2409.14086v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Are Music Foundation Models Better at Singing Voice Deepfake Detection?\n  Far-Better Fuse them with Speech Foundation Models", "abstract": "In this study, for the first time, we extensively investigate whether music\nfoundation models (MFMs) or speech foundation models (SFMs) work better for\nsinging voice deepfake detection (SVDD), which has recently attracted attention\nin the research community. For this, we perform a comprehensive comparative\nstudy of state-of-the-art (SOTA) MFMs (MERT variants and music2vec) and SFMs\n(pre-trained for general speech representation learning as well as speaker\nrecognition). We show that speaker recognition SFM representations perform the\nbest amongst all the foundation models (FMs), and this performance can be\nattributed to its higher efficacy in capturing the pitch, tone, intensity, etc,\ncharacteristics present in singing voices. To our end, we also explore the\nfusion of FMs for exploiting their complementary behavior for improved SVDD,\nand we propose a novel framework, FIONA for the same. With FIONA, through the\nsynchronization of x-vector (speaker recognition SFM) and MERT-v1-330M (MFM),\nwe report the best performance with the lowest Equal Error Rate (EER) of 13.74\n%, beating all the individual FMs as well as baseline FM fusions and achieving\nSOTA results.", "published": "2024-09-21 12:50:53", "link": "http://arxiv.org/abs/2409.14131v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "68T45", "I.2.7"], "primary_category": "eess.AS"}
{"title": "Generalization in birdsong classification: impact of transfer learning\n  methods and dataset characteristics", "abstract": "Animal sounds can be recognised automatically by machine learning, and this\nhas an important role to play in biodiversity monitoring. Yet despite\nincreasingly impressive capabilities, bioacoustic species classifiers still\nexhibit imbalanced performance across species and habitats, especially in\ncomplex soundscapes. In this study, we explore the effectiveness of transfer\nlearning in large-scale bird sound classification across various conditions,\nincluding single- and multi-label scenarios, and across different model\narchitectures such as CNNs and Transformers. Our experiments demonstrate that\nboth fine-tuning and knowledge distillation yield strong performance, with\ncross-distillation proving particularly effective in improving in-domain\nperformance on Xeno-canto data. However, when generalizing to soundscapes,\nshallow fine-tuning exhibits superior performance compared to knowledge\ndistillation, highlighting its robustness and constrained nature. Our study\nfurther investigates how to use multi-species labels, in cases where these are\npresent but incomplete. We advocate for more comprehensive labeling practices\nwithin the animal sound community, including annotating background species and\nproviding temporal details, to enhance the training of robust bird sound\nclassifiers. These findings provide insights into the optimal reuse of\npretrained models for advancing automatic bioacoustic recognition.", "published": "2024-09-21 11:33:12", "link": "http://arxiv.org/abs/2409.15383v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
