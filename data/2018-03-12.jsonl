{"title": "Entity-Aware Language Model as an Unsupervised Reranker", "abstract": "In language modeling, it is difficult to incorporate entity relationships\nfrom a knowledge-base. One solution is to use a reranker trained with global\nfeatures, in which global features are derived from n-best lists. However,\ntraining such a reranker requires manually annotated n-best lists, which is\nexpensive to obtain. We propose a method based on the contrastive estimation\nmethod that alleviates the need for such data. Experiments in the music domain\ndemonstrate that global features, as well as features extracted from an\nexternal knowledge-base, can be incorporated into our reranker. Our final\nmodel, a simple ensemble of a language model and reranker, achieves a 0.44\\%\nabsolute word error rate improvement over an LSTM language model on the blind\ntest data.", "published": "2018-03-12 14:47:43", "link": "http://arxiv.org/abs/1803.04291v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing Natural Language into SPARQL: Improving Target Language\n  Representation with Neural Attention", "abstract": "Semantic parsing is the process of mapping a natural language sentence into a\nformal representation of its meaning. In this work we use the neural network\napproach to transform natural language sentence into a query to an ontology\ndatabase in the SPARQL language. This method does not rely on handcraft-rules,\nhigh-quality lexicons, manually-built templates or other handmade complex\nstructures. Our approach is based on vector space model and neural networks.\nThe proposed model is based in two learning steps. The first step generates a\nvector representation for the sentence in natural language and SPARQL query.\nThe second step uses this vector representation as input to a neural network\n(LSTM with attention mechanism) to generate a model able to encode natural\nlanguage and decode SPARQL.", "published": "2018-03-12 15:59:10", "link": "http://arxiv.org/abs/1803.04329v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Feature-Rich Vietnamese Named-Entity Recognition Model", "abstract": "In this paper, we present a feature-based named-entity recognition (NER)\nmodel that achieves the start-of-the-art accuracy for Vietnamese language. We\ncombine word, word-shape features, PoS, chunk, Brown-cluster-based features,\nand word-embedding-based features in the Conditional Random Fields (CRF) model.\nWe also explore the effects of word segmentation, PoS tagging, and chunking\nresults of many popular Vietnamese NLP toolkits on the accuracy of the proposed\nfeature-based NER model. Up to now, our work is the first work that\nsystematically performs an extrinsic evaluation of basic Vietnamese NLP\ntoolkits on the downstream NER task. Experimental results show that while\nautomatically-generated word segmentation is useful, PoS and chunking\ninformation generated by Vietnamese NLP tools does not show their benefits for\nthe proposed feature-based NER model.", "published": "2018-03-12 17:07:40", "link": "http://arxiv.org/abs/1803.04375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concept2vec: Metrics for Evaluating Quality of Embeddings for\n  Ontological Concepts", "abstract": "Although there is an emerging trend towards generating embeddings for\nprimarily unstructured data and, recently, for structured data, no systematic\nsuite for measuring the quality of embeddings has been proposed yet. This\ndeficiency is further sensed with respect to embeddings generated for\nstructured data because there are no concrete evaluation metrics measuring the\nquality of the encoded structure as well as semantic patterns in the embedding\nspace. In this paper, we introduce a framework containing three distinct tasks\nconcerned with the individual aspects of ontological concepts: (i) the\ncategorization aspect, (ii) the hierarchical aspect, and (iii) the relational\naspect. Then, in the scope of each task, a number of intrinsic metrics are\nproposed for evaluating the quality of the embeddings. Furthermore, w.r.t. this\nframework, multiple experimental studies were run to compare the quality of the\navailable embedding models. Employing this framework in future research can\nreduce misjudgment and provide greater insight about quality comparisons of\nembeddings for ontological concepts. We positioned our sampled data and code at\nhttps://github.com/alshargi/Concept2vec under GNU General Public License v3.0.", "published": "2018-03-12 19:46:10", "link": "http://arxiv.org/abs/1803.04488v3", "categories": ["cs.CL", "cs.AI", "I.2.4; I.2.6"], "primary_category": "cs.CL"}
{"title": "It was the training data pruning too!", "abstract": "We study the current best model (KDG) for question answering on tabular data\nevaluated over the WikiTableQuestions dataset. Previous ablation studies\nperformed against this model attributed the model's performance to certain\naspects of its architecture. In this paper, we find that the model's\nperformance also crucially depends on a certain pruning of the data used to\ntrain the model. Disabling the pruning step drops the accuracy of the model\nfrom 43.3% to 36.3%. The large impact on the performance of the KDG model\nsuggests that the pruning may be a useful pre-processing step in training other\nsemantic parsers as well.", "published": "2018-03-12 23:59:37", "link": "http://arxiv.org/abs/1803.04579v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Convolutional Neural Networks and Language Embeddings for End-to-End\n  Dialect Recognition", "abstract": "Dialect identification (DID) is a special case of general language\nidentification (LID), but a more challenging problem due to the linguistic\nsimilarity between dialects. In this paper, we propose an end-to-end DID system\nand a Siamese neural network to extract language embeddings. We use both\nacoustic and linguistic features for the DID task on the Arabic dialectal\nspeech dataset: Multi-Genre Broadcast 3 (MGB-3). The end-to-end DID system was\ntrained using three kinds of acoustic features: Mel-Frequency Cepstral\nCoefficients (MFCCs), log Mel-scale Filter Bank energies (FBANK) and\nspectrogram energies. We also investigated a dataset augmentation approach to\nachieve robust performance with limited data resources. Our linguistic feature\nresearch focused on learning similarities and dissimilarities between dialects\nusing the Siamese network, so that we can reduce feature dimensionality as well\nas improve DID performance. The best system using a single feature set achieves\n73% accuracy, while a fusion system using multiple features yields 78% on the\nMGB-3 dialect test set consisting of 5 dialects. The experimental results\nindicate that FBANK features achieve slightly better results than MFCCs.\nDataset augmentation via speed perturbation appears to add significant\nrobustness to the system. Although the Siamese network with language embeddings\ndid not achieve as good a result as the end-to-end DID system, the two\napproaches had good synergy when combined together in a fused system.", "published": "2018-03-12 23:04:11", "link": "http://arxiv.org/abs/1803.04567v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Kernel estimation of the instantaneous frequency", "abstract": "We consider kernel estimators of the instantaneous frequency of a slowly\nevolving sinusoid in white noise. The expected estimation error consists of two\nterms. The systematic bias error grows as the kernel halfwidth increases while\nthe random error decreases. For a non-modulated signal, $g(t)$, the kernel\nhalfwidth which minimizes the expected error scales as$h \\sim \\left[{ \\sigma^2\n\\over\n  N| \\partial_t^2 g^{}|^2 } \\right]^{1/ 5}$, where %$A^{(\\ell)}$ is the\ncoherent signal at frequency, $f_{\\ell}$, $\\sigma^2$ is the noise variance and\n$N$ is the number of measurements per unit time. We show that estimating the\ninstantaneous frequency corresponds to estimating the first derivative of a\nmodulated signal, $A(t)\\exp(i\\phi(t))$. For instantaneous frequency estimation,\nthe halfwidth which minimizes the expected error is larger: $h_{1,3} \\sim\n\\left[{ \\sigma^2 \\over A^2N| \\partial_t^3 (e^{i \\tilde{\\phi}(t)} )|^2 }\n\\right]^{1/ 7}$. Since the optimal halfwidths depend on derivatives of the\nunknown function, we initially estimate these derivatives prior to estimating\nthe actual signal.", "published": "2018-03-12 00:43:32", "link": "http://arxiv.org/abs/1803.04075v1", "categories": ["stat.ME", "eess.AS", "eess.SP", "math.ST", "stat.AP", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Minimum bias multiple taper spectral estimation", "abstract": "Two families of orthonormal tapers are proposed for multi-taper spectral\nanalysis: minimum bias tapers, and sinusoidal tapers $\\{ \\bf{v}^{(k)}\\}$, where\n$v_n^{(k)}=\\sqrt{\\frac{2}{N+1}}\\sin\\frac{\\pi kn}{N+1}$, and $N$ is the number\nof points. The resulting sinusoidal multitaper spectral estimate is\n$\\hat{S}(f)=\\frac{1}{2K(N+1)} \\sum_{j=1}^K |y(f+\\frac{j}{2N+2})\n-y(f-\\frac{j}{2N+2})|^2$, where $y(f)$ is the Fourier transform of the\nstationary time series, $S(f)$ is the spectral density, and $K$ is the number\nof tapers. For fixed $j$, the sinusoidal tapers converge to the minimum bias\ntapers like $1/N$. Since the sinusoidal tapers have analytic expressions, no\nnumerical eigenvalue decomposition is necessary. Both the minimum bias and\nsinusoidal tapers have no additional parameter for the spectral bandwidth. The\nbandwidth of the $j$th taper is simply $\\frac{1}{N}$ centered about the\nfrequencies $\\frac{\\pm j}{2N+2}$. Thus the bandwidth of the multitaper spectral\nestimate can be adjusted locally by simply adding or deleting tapers. The band\nlimited spectral concentration, $\\int_{-w}^w |V(f)|^2 df$, of both the minimum\nbias and sinusoidal tapers is very close to the optimal concentration achieved\nby the Slepian tapers. In contrast, the Slepian tapers can have the local bias,\n$\\int_{-1/2}^{1/2} f^2 |V(f)|^2 df$, much larger than of the minimum bias\ntapers and the sinusoidal tapers.", "published": "2018-03-12 01:01:27", "link": "http://arxiv.org/abs/1803.04078v2", "categories": ["stat.ME", "eess.AS", "eess.SP", "math.ST", "physics.data-an", "stat.TH"], "primary_category": "stat.ME"}
