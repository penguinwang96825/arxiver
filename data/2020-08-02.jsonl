{"title": "A Survey on Text Classification: From Shallow to Deep Learning", "abstract": "Text classification is the most fundamental and essential task in natural\nlanguage processing. The last decade has seen a surge of research in this area\ndue to the unprecedented success of deep learning. Numerous methods, datasets,\nand evaluation metrics have been proposed in the literature, raising the need\nfor a comprehensive and updated survey. This paper fills the gap by reviewing\nthe state-of-the-art approaches from 1961 to 2021, focusing on models from\ntraditional models to deep learning. We create a taxonomy for text\nclassification according to the text involved and the models used for feature\nextraction and classification. We then discuss each of these categories in\ndetail, dealing with both the technical developments and benchmark datasets\nthat support tests of predictions. A comprehensive comparison between different\ntechniques, as well as identifying the pros and cons of various evaluation\nmetrics are also provided in this survey. Finally, we conclude by summarizing\nkey implications, future research directions, and the challenges facing the\nresearch area.", "published": "2020-08-02 00:09:03", "link": "http://arxiv.org/abs/2008.00364v6", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Translation with Extensible Multilingual Pretraining and\n  Finetuning", "abstract": "Recent work demonstrates the potential of multilingual pretraining of\ncreating one model that can be used for various tasks in different languages.\nPrevious work in multilingual pretraining has demonstrated that machine\ntranslation systems can be created by finetuning on bitext. In this work, we\nshow that multilingual translation models can be created through multilingual\nfinetuning. Instead of finetuning on one direction, a pretrained model is\nfinetuned on many directions at the same time. Compared to multilingual models\ntrained from scratch, starting from pretrained models incorporates the benefits\nof large quantities of unlabeled monolingual data, which is particularly\nimportant for low resource languages where bitext is not available. We\ndemonstrate that pretrained models can be extended to incorporate additional\nlanguages without loss of performance. We double the number of languages in\nmBART to support multilingual machine translation models of 50 languages.\nFinally, we create the ML50 benchmark, covering low, mid, and high resource\nlanguages, to facilitate reproducible research by standardizing training and\nevaluation data. On ML50, we demonstrate that multilingual finetuning improves\non average 1 BLEU over the strongest baselines (being either multilingual from\nscratch or bilingual finetuning) while improving 9.3 BLEU on average over\nbilingual baselines from scratch.", "published": "2020-08-02 05:36:55", "link": "http://arxiv.org/abs/2008.00401v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Extraction with Self-determined Graph Convolutional Network", "abstract": "Relation Extraction is a way of obtaining the semantic relationship between\nentities in text. The state-of-the-art methods use linguistic tools to build a\ngraph for the text in which the entities appear and then a Graph Convolutional\nNetwork (GCN) is employed to encode the pre-built graphs. Although their\nperformance is promising, the reliance on linguistic tools results in a non\nend-to-end process. In this work, we propose a novel model, the Self-determined\nGraph Convolutional Network (SGCN), which determines a weighted graph using a\nself-attention mechanism, rather using any linguistic tool. Then, the\nself-determined graph is encoded using a GCN. We test our model on the TACRED\ndataset and achieve the state-of-the-art result. Our experiments show that SGCN\noutperforms the traditional GCN, which uses dependency parsing tools to build\nthe graph.", "published": "2020-08-02 09:52:58", "link": "http://arxiv.org/abs/2008.00441v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the Effect of Emoji in Opinion Classification of Uzbek\n  Movie Review Comments", "abstract": "Opinion mining on social media posts has become more and more popular. Users\noften express their opinion on a topic not only with words but they also use\nimage symbols such as emoticons and emoji. In this paper, we investigate the\neffect of emoji-based features in opinion classification of Uzbek texts, and\nmore specifically movie review comments from YouTube. Several classification\nalgorithms are tested, and feature ranking is performed to evaluate the\ndiscriminative ability of the emoji-based features.", "published": "2020-08-02 13:50:47", "link": "http://arxiv.org/abs/2008.00482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SemEval-2020 Task 5: Counterfactual Recognition", "abstract": "We present a counterfactual recognition (CR) task, the shared Task 5 of\nSemEval-2020. Counterfactuals describe potential outcomes (consequents)\nproduced by actions or circumstances that did not happen or cannot happen and\nare counter to the facts (antecedent). Counterfactual thinking is an important\ncharacteristic of the human cognitive system; it connects antecedents and\nconsequents with causal relations. Our task provides a benchmark for\ncounterfactual recognition in natural language with two subtasks. Subtask-1\naims to determine whether a given sentence is a counterfactual statement or\nnot. Subtask-2 requires the participating systems to extract the antecedent and\nconsequent in a given counterfactual statement. During the SemEval-2020\nofficial evaluation period, we received 27 submissions to Subtask-1 and 11 to\nSubtask-2. The data, baseline code, and leaderboard can be found at\nhttps://competitions.codalab.org/competitions/21691. The data and baseline code\nare also available at https://zenodo.org/record/3932442.", "published": "2020-08-02 20:32:19", "link": "http://arxiv.org/abs/2008.00563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Domain Adaptation of Spoken Language Identification for Related\n  Languages: The Curious Case of Slavic Languages", "abstract": "State-of-the-art spoken language identification (LID) systems, which are\nbased on end-to-end deep neural networks, have shown remarkable success not\nonly in discriminating between distant languages but also between\nclosely-related languages or even different spoken varieties of the same\nlanguage. However, it is still unclear to what extent neural LID models\ngeneralize to speech samples with different acoustic conditions due to domain\nshift. In this paper, we present a set of experiments to investigate the impact\nof domain mismatch on the performance of neural LID systems for a subset of six\nSlavic languages across two domains (read speech and radio broadcast) and\nexamine two low-level signal descriptors (spectral and cepstral features) for\nthis task. Our experiments show that (1) out-of-domain speech samples severely\nhinder the performance of neural LID models, and (2) while both spectral and\ncepstral features show comparable performance within-domain, spectral features\nshow more robustness under domain mismatch. Moreover, we apply unsupervised\ndomain adaptation to minimize the discrepancy between the two domains in our\nstudy. We achieve relative accuracy improvements that range from 9% to 77%\ndepending on the diversity of acoustic conditions in the source domain.", "published": "2020-08-02 19:30:39", "link": "http://arxiv.org/abs/2008.00545v2", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Efficient Urdu Caption Generation using Attention based LSTM", "abstract": "Recent advancements in deep learning have created many opportunities to solve\nreal-world problems that remained unsolved for more than a decade. Automatic\ncaption generation is a major research field, and the research community has\ndone a lot of work on it in most common languages like English. Urdu is the\nnational language of Pakistan and also much spoken and understood in the\nsub-continent region of Pakistan-India, and yet no work has been done for Urdu\nlanguage caption generation. Our research aims to fill this gap by developing\nan attention-based deep learning model using techniques of sequence modeling\nspecialized for the Urdu language. We have prepared a dataset in the Urdu\nlanguage by translating a subset of the \"Flickr8k\" dataset containing 700 'man'\nimages. We evaluate our proposed technique on this dataset and show that it can\nachieve a BLEU score of 0.83 in the Urdu language. We improve on the previous\nstate-of-the-art by using better CNN architectures and optimization techniques.\nFurthermore, we provide a discussion on how the generated captions can be made\ncorrect grammar-wise.", "published": "2020-08-02 17:22:33", "link": "http://arxiv.org/abs/2008.01663v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bayesian Optimization for Selecting Efficient Machine Learning Models", "abstract": "The performance of many machine learning models depends on their\nhyper-parameter settings. Bayesian Optimization has become a successful tool\nfor hyper-parameter optimization of machine learning algorithms, which aims to\nidentify optimal hyper-parameters during an iterative sequential process.\nHowever, most of the Bayesian Optimization algorithms are designed to select\nmodels for effectiveness only and ignore the important issue of model training\nefficiency. Given that both model effectiveness and training time are important\nfor real-world applications, models selected for effectiveness may not meet the\nstrict training time requirements necessary to deploy in a production\nenvironment. In this work, we present a unified Bayesian Optimization framework\nfor jointly optimizing models for both prediction effectiveness and training\nefficiency. We propose an objective that captures the tradeoff between these\ntwo metrics and demonstrate how we can jointly optimize them in a principled\nBayesian Optimization framework. Experiments on model selection for\nrecommendation tasks indicate models selected this way significantly improves\nmodel training efficiency while maintaining strong effectiveness as compared to\nstate-of-the-art Bayesian Optimization algorithms.", "published": "2020-08-02 02:56:30", "link": "http://arxiv.org/abs/2008.00386v1", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Large-scale, Language-agnostic Discourse Classification of Tweets During\n  COVID-19", "abstract": "Quantifying the characteristics of public attention is an essential\nprerequisite for appropriate crisis management during severe events such as\npandemics. For this purpose, we propose language-agnostic tweet representations\nto perform large-scale Twitter discourse classification with machine learning.\nOur analysis on more than 26 million COVID-19 tweets shows that large-scale\nsurveillance of public discourse is feasible with computationally lightweight\nclassifiers by out-of-the-box utilization of these representations.", "published": "2020-08-02 11:12:56", "link": "http://arxiv.org/abs/2008.00461v2", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Video Question Answering on Screencast Tutorials", "abstract": "This paper presents a new video question answering task on screencast\ntutorials. We introduce a dataset including question, answer and context\ntriples from the tutorial videos for a software. Unlike other video question\nanswering works, all the answers in our dataset are grounded to the domain\nknowledge base. An one-shot recognition algorithm is designed to extract the\nvisual cues, which helps enhance the performance of video question answering.\nWe also propose several baseline neural network architectures based on various\naspects of video contexts from the dataset. The experimental results\ndemonstrate that our proposed models significantly improve the question\nanswering performances by incorporating multi-modal contexts and domain\nknowledge.", "published": "2020-08-02 19:27:42", "link": "http://arxiv.org/abs/2008.00544v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Chess Transformer: Mastering Play using Generative Language Models", "abstract": "This work demonstrates that natural language transformers can support more\ngeneric strategic modeling, particularly for text-archived games. In addition\nto learning natural language skills, the abstract transformer architecture can\ngenerate meaningful moves on a chessboard. With further fine-tuning, the\ntransformer learns complex gameplay by training on 2.8 million chess games in\nPortable Game Notation. After 30,000 training steps, OpenAI's Generative\nPre-trained Transformer (GPT-2) optimizes weights for 774 million parameters.\nThis fine-tuned Chess Transformer generates plausible strategies and displays\ngame formations identifiable as classic openings, such as English or the Slav\nExchange. Finally, in live play, the novel model demonstrates a\nhuman-to-transformer interface that correctly filters illegal moves and\nprovides a novel method to challenge the transformer's chess strategies. We\nanticipate future work will build on this transformer's promise, particularly\nin other strategy games where features can capture the underlying complex rule\nsyntax from simple but expressive player annotations.", "published": "2020-08-02 18:04:36", "link": "http://arxiv.org/abs/2008.04057v5", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LG"], "primary_category": "cs.AI"}
{"title": "audioLIME: Listenable Explanations Using Source Separation", "abstract": "Deep neural networks (DNNs) are successfully applied in a wide variety of\nmusic information retrieval (MIR) tasks but their predictions are usually not\ninterpretable. We propose audioLIME, a method based on Local Interpretable\nModel-agnostic Explanations (LIME) extended by a musical definition of\nlocality. The perturbations used in LIME are created by switching on/off\ncomponents extracted by source separation which makes our explanations\nlistenable. We validate audioLIME on two different music tagging systems and\nshow that it produces sensible explanations in situations where a competing\nmethod cannot.", "published": "2020-08-02 23:05:02", "link": "http://arxiv.org/abs/2008.00582v3", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
