{"title": "Incorporating Global Visual Features into Attention-Based Neural Machine\n  Translation", "abstract": "We introduce multi-modal, attention-based neural machine translation (NMT)\nmodels which incorporate visual features into different parts of both the\nencoder and the decoder. We utilise global image features extracted using a\npre-trained convolutional neural network and incorporate them (i) as words in\nthe source sentence, (ii) to initialise the encoder hidden state, and (iii) as\nadditional data to initialise the decoder hidden state. In our experiments, we\nevaluate how these different strategies to incorporate global image features\ncompare and which ones perform best. We also study the impact that adding\nsynthetic multi-modal, multilingual data brings and find that the additional\ndata have a positive impact on multi-modal models. We report new\nstate-of-the-art results and our best models also significantly improve on a\ncomparable phrase-based Statistical MT (PBSMT) model trained on the Multi30k\ndata set according to all metrics evaluated. To the best of our knowledge, it\nis the first time a purely neural model significantly improves over a PBSMT\nmodel on all metrics evaluated on this data set.", "published": "2017-01-23 17:43:23", "link": "http://arxiv.org/abs/1701.06521v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adversarial Learning for Neural Dialogue Generation", "abstract": "In this paper, drawing intuition from the Turing test, we propose using\nadversarial training for open-domain dialogue generation: the system is trained\nto produce sequences that are indistinguishable from human-generated dialogue\nutterances. We cast the task as a reinforcement learning (RL) problem where we\njointly train two systems, a generative model to produce response sequences,\nand a discriminator---analagous to the human evaluator in the Turing test--- to\ndistinguish between the human-generated dialogues and the machine-generated\nones. The outputs from the discriminator are then used as rewards for the\ngenerative model, pushing the system to generate dialogues that mostly resemble\nhuman dialogues.\n  In addition to adversarial training we describe a model for adversarial {\\em\nevaluation} that uses success in fooling an adversary as a dialogue evaluation\nmetric, while avoiding a number of potential pitfalls. Experimental results on\nseveral metrics, including adversarial evaluation, demonstrate that the\nadversarially-trained system generates higher-quality responses than previous\nbaselines.", "published": "2017-01-23 18:32:27", "link": "http://arxiv.org/abs/1701.06547v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Decode for Future Success", "abstract": "We introduce a simple, general strategy to manipulate the behavior of a\nneural decoder that enables it to generate outputs that have specific\nproperties of interest (e.g., sequences of a pre-specified length). The model\ncan be thought of as a simple version of the actor-critic model that uses an\ninterpolation of the actor (the MLE-based token generation policy) and the\ncritic (a value function that estimates the future values of the desired\nproperty) for decision making. We demonstrate that the approach is able to\nincorporate a variety of properties that cannot be handled by standard neural\nsequence decoders, such as sequence length and backward probability\n(probability of sources given targets), in addition to yielding consistent\nimprovements in abstractive summarization and machine translation when the\nproperty to be optimized is BLEU or ROUGE scores.", "published": "2017-01-23 18:36:37", "link": "http://arxiv.org/abs/1701.06549v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterisation of speech diversity using self-organising maps", "abstract": "We report investigations into speaker classification of larger quantities of\nunlabelled speech data using small sets of manually phonemically annotated\nspeech. The Kohonen speech typewriter is a semi-supervised method comprised of\nself-organising maps (SOMs) that achieves low phoneme error rates. A SOM is a\n2D array of cells that learn vector representations of the data based on\nneighbourhoods. In this paper, we report a method to evaluate pronunciation\nusing multilevel SOMs with /hVd/ single syllable utterances for the study of\nvowels, for Australian pronunciation.", "published": "2017-01-23 11:18:06", "link": "http://arxiv.org/abs/1702.02092v1", "categories": ["cs.CL", "cs.NE", "cs.SD"], "primary_category": "cs.CL"}
{"title": "A Multichannel Convolutional Neural Network For Cross-language Dialog\n  State Tracking", "abstract": "The fifth Dialog State Tracking Challenge (DSTC5) introduces a new\ncross-language dialog state tracking scenario, where the participants are asked\nto build their trackers based on the English training corpus, while evaluating\nthem with the unlabeled Chinese corpus. Although the computer-generated\ntranslations for both English and Chinese corpus are provided in the dataset,\nthese translations contain errors and careless use of them can easily hurt the\nperformance of the built trackers. To address this problem, we propose a\nmultichannel Convolutional Neural Networks (CNN) architecture, in which we\ntreat English and Chinese language as different input channels of one single\nCNN model. In the evaluation of DSTC5, we found that such multichannel\narchitecture can effectively improve the robustness against translation errors.\nAdditionally, our method for DSTC5 is purely machine learning based and\nrequires no prior knowledge about the target language. We consider this a\ndesirable property for building a tracker in the cross-language context, as not\nevery developer will be familiar with both languages.", "published": "2017-01-23 01:36:10", "link": "http://arxiv.org/abs/1701.06247v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "dna2vec: Consistent vector representations of variable-length k-mers", "abstract": "One of the ubiquitous representation of long DNA sequence is dividing it into\nshorter k-mer components. Unfortunately, the straightforward vector encoding of\nk-mer as a one-hot vector is vulnerable to the curse of dimensionality. Worse\nyet, the distance between any pair of one-hot vectors is equidistant. This is\nparticularly problematic when applying the latest machine learning algorithms\nto solve problems in biological sequence analysis. In this paper, we propose a\nnovel method to train distributed representations of variable-length k-mers.\nOur method is based on the popular word embedding model word2vec, which is\ntrained on a shallow two-layer neural network. Our experiments provide evidence\nthat the summing of dna2vec vectors is akin to nucleotides concatenation. We\nalso demonstrate that there is correlation between Needleman-Wunsch similarity\nscore and cosine similarity of dna2vec vectors.", "published": "2017-01-23 07:21:43", "link": "http://arxiv.org/abs/1701.06279v1", "categories": ["q-bio.QM", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "Outrageously Large Neural Networks: The Sparsely-Gated\n  Mixture-of-Experts Layer", "abstract": "The capacity of a neural network to absorb information is limited by its\nnumber of parameters. Conditional computation, where parts of the network are\nactive on a per-example basis, has been proposed in theory as a way of\ndramatically increasing model capacity without a proportional increase in\ncomputation. In practice, however, there are significant algorithmic and\nperformance challenges. In this work, we address these challenges and finally\nrealize the promise of conditional computation, achieving greater than 1000x\nimprovements in model capacity with only minor losses in computational\nefficiency on modern GPU clusters. We introduce a Sparsely-Gated\nMixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward\nsub-networks. A trainable gating network determines a sparse combination of\nthese experts to use for each example. We apply the MoE to the tasks of\nlanguage modeling and machine translation, where model capacity is critical for\nabsorbing the vast quantities of knowledge available in the training corpora.\nWe present model architectures in which a MoE with up to 137 billion parameters\nis applied convolutionally between stacked LSTM layers. On large language\nmodeling and machine translation benchmarks, these models achieve significantly\nbetter results than state-of-the-art at lower computational cost.", "published": "2017-01-23 18:10:00", "link": "http://arxiv.org/abs/1701.06538v1", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
