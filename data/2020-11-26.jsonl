{"title": "Automatic Distractor Generation for Multiple Choice Questions in\n  Standard Tests", "abstract": "To assess the knowledge proficiency of a learner, multiple choice question is\nan efficient and widespread form in standard tests. However, the composition of\nthe multiple choice question, especially the construction of distractors is\nquite challenging. The distractors are required to both incorrect and plausible\nenough to confuse the learners who did not master the knowledge. Currently, the\ndistractors are generated by domain experts which are both expensive and\ntime-consuming. This urges the emergence of automatic distractor generation,\nwhich can benefit various standard tests in a wide range of domains. In this\npaper, we propose a question and answer guided distractor generation (EDGE)\nframework to automate distractor generation. EDGE consists of three major\nmodules: (1) the Reforming Question Module and the Reforming Passage Module\napply gate layers to guarantee the inherent incorrectness of the generated\ndistractors; (2) the Distractor Generator Module applies attention mechanism to\ncontrol the level of plausibility. Experimental results on a large-scale public\ndataset demonstrate that our model significantly outperforms existing models\nand achieves a new state-of-the-art.", "published": "2020-11-26 02:58:24", "link": "http://arxiv.org/abs/2011.13100v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Causal Bayesian Networks from Text", "abstract": "Causal relationships form the basis for reasoning and decision-making in\nArtificial Intelligence systems. To exploit the large volume of textual data\navailable today, the automatic discovery of causal relationships from text has\nemerged as a significant challenge in recent years. Existing approaches in this\nrealm are limited to the extraction of low-level relations among individual\nevents. To overcome the limitations of the existing approaches, in this paper,\nwe propose a method for automatic inference of causal relationships from human\nwritten language at conceptual level. To this end, we leverage the\ncharacteristics of hierarchy of concepts and linguistic variables created from\ntext, and represent the extracted causal relationships in the form of a Causal\nBayesian Network. Our experiments demonstrate superiority of our approach over\nthe existing approaches in inferring complex causal reasoning from the text.", "published": "2020-11-26 03:57:56", "link": "http://arxiv.org/abs/2011.13115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer-Based Models for Automatic Identification of Argument\n  Relations: A Cross-Domain Evaluation", "abstract": "Argument Mining is defined as the task of automatically identifying and\nextracting argumentative components (e.g., premises, claims, etc.) and\ndetecting the existing relations among them (i.e., support, attack, rephrase,\nno relation). One of the main issues when approaching this problem is the lack\nof data, and the size of the publicly available corpora. In this work, we use\nthe recently annotated US2016 debate corpus. US2016 is the largest existing\nargument annotated corpus, which allows exploring the benefits of the most\nrecent advances in Natural Language Processing in a complex domain like\nArgument (relation) Mining. We present an exhaustive analysis of the behavior\nof transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT and ALBERT)\nwhen predicting argument relations. Finally, we evaluate the models in five\ndifferent domains, with the objective of finding the less domain dependent\nmodel. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus,\nand a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.", "published": "2020-11-26 09:04:07", "link": "http://arxiv.org/abs/2011.13187v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Braid: Weaving Symbolic and Neural Knowledge into Coherent Logical\n  Explanations", "abstract": "Traditional symbolic reasoning engines, while attractive for their precision\nand explicability, have a few major drawbacks: the use of brittle inference\nprocedures that rely on exact matching (unification) of logical terms, an\ninability to deal with uncertainty, and the need for a precompiled rule-base of\nknowledge (the \"knowledge acquisition\" problem). To address these issues, we\ndevise a novel logical reasoner called Braid, that supports probabilistic\nrules, and uses the notion of custom unification functions and dynamic rule\ngeneration to overcome the brittle matching and knowledge-gap problem prevalent\nin traditional reasoners. In this paper, we describe the reasoning algorithms\nused in Braid, and their implementation in a distributed task-based framework\nthat builds proof/explanation graphs for an input query. We use a simple QA\nexample from a children's story to motivate Braid's design and explain how the\nvarious components work together to produce a coherent logical explanation.\nFinally, we evaluate Braid on the ROC Story Cloze test and achieve close to\nstate-of-the-art results while providing frame-based explanations.", "published": "2020-11-26 15:36:06", "link": "http://arxiv.org/abs/2011.13354v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Analytics for Resilience-Enabled Extreme Events Reconnaissance", "abstract": "Post-hazard reconnaissance for natural disasters (e.g., earthquakes) is\nimportant for understanding the performance of the built environment, speeding\nup the recovery, enhancing resilience and making informed decisions related to\ncurrent and future hazards. Natural language processing (NLP) is used in this\nstudy for the purposes of increasing the accuracy and efficiency of natural\nhazard reconnaissance through automation. The study particularly focuses on (1)\nautomated data (news and social media) collection hosted by the Pacific\nEarthquake Engineering Research (PEER) Center server, (2) automatic generation\nof reconnaissance reports, and (3) use of social media to extract post-hazard\ninformation such as the recovery time. Obtained results are encouraging for\nfurther development and wider usage of various NLP methods in natural hazard\nreconnaissance.", "published": "2020-11-26 01:43:29", "link": "http://arxiv.org/abs/2011.13087v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Unsupervised Word Translation Pairing using Refinement based Point Set\n  Registration", "abstract": "Cross-lingual alignment of word embeddings play an important role in\nknowledge transfer across languages, for improving machine translation and\nother multi-lingual applications. Current unsupervised approaches rely on\nsimilarities in geometric structure of word embedding spaces across languages,\nto learn structure-preserving linear transformations using adversarial networks\nand refinement strategies. However, such techniques, in practice, tend to\nsuffer from instability and convergence issues, requiring tedious fine-tuning\nfor precise parameter setting. This paper proposes BioSpere, a novel framework\nfor unsupervised mapping of bi-lingual word embeddings onto a shared vector\nspace, by combining adversarial initialization and refinement procedure with\npoint set registration algorithm used in image processing. We show that our\nframework alleviates the shortcomings of existing methodologies, and is\nrelatively invariant to variable adversarial learning performance, depicting\nrobustness in terms of parameter choices and training losses. Experimental\nevaluation on parallel dictionary induction task demonstrates state-of-the-art\nresults for our framework on diverse language pairs.", "published": "2020-11-26 09:51:29", "link": "http://arxiv.org/abs/2011.13200v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SLURP: A Spoken Language Understanding Resource Package", "abstract": "Spoken Language Understanding infers semantic meaning directly from audio\ndata, and thus promises to reduce error propagation and misunderstandings in\nend-user applications. However, publicly available SLU resources are limited.\nIn this paper, we release SLURP, a new SLU package containing the following:\n(1) A new challenging dataset in English spanning 18 domains, which is\nsubstantially bigger and linguistically more diverse than existing datasets;\n(2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A\nnew transparent metric for entity labelling which enables a detailed error\nanalysis for identifying potential areas of improvement. SLURP is available at\nhttps: //github.com/pswietojanski/slurp.", "published": "2020-11-26 09:58:20", "link": "http://arxiv.org/abs/2011.13205v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Encoding Syntactic Constituency Paths for Frame-Semantic Parsing with\n  Graph Convolutional Networks", "abstract": "We study the problem of integrating syntactic information from constituency\ntrees into a neural model in Frame-semantic parsing sub-tasks, namely Target\nIdentification (TI), FrameIdentification (FI), and Semantic Role Labeling\n(SRL). We use a Graph Convolutional Network to learn specific representations\nof constituents, such that each constituent is profiled as the production\ngrammar rule it corresponds to. We leverage these representations to build\nsyntactic features for each word in a sentence, computed as the sum of all the\nconstituents on the path between a word and a task-specific node in the tree,\ne.g. the target predicate for SRL. Our approach improves state-of-the-art\nresults on the TI and SRL of ~1%and~3.5% points, respectively (+2.5% additional\npoints are gained with BERT as input), when tested on FrameNet 1.5, while\nyielding comparable results on the CoNLL05 dataset to other syntax-aware\nsystems.", "published": "2020-11-26 10:10:57", "link": "http://arxiv.org/abs/2011.13210v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unigram-Normalized Perplexity as a Language Model Performance Measure\n  with Different Vocabulary Sizes", "abstract": "Although Perplexity is a widely used performance metric for language models,\nthe values are highly dependent upon the number of words in the corpus and is\nuseful to compare performance of the same corpus only. In this paper, we\npropose a new metric that can be used to evaluate language model performance\nwith different vocabulary sizes. The proposed unigram-normalized Perplexity\nactually presents the performance improvement of the language models from that\nof simple unigram model, and is robust on the vocabulary size. Both theoretical\nanalysis and computational experiments are reported.", "published": "2020-11-26 10:39:03", "link": "http://arxiv.org/abs/2011.13220v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLPStatTest: A Toolkit for Comparing NLP System Performance", "abstract": "Statistical significance testing centered on p-values is commonly used to\ncompare NLP system performance, but p-values alone are insufficient because\nstatistical significance differs from practical significance. The latter can be\nmeasured by estimating effect size. In this paper, we propose a three-stage\nprocedure for comparing NLP system performance and provide a toolkit,\nNLPStatTest, that automates the process. Users can upload NLP system evaluation\nscores and the toolkit will analyze these scores, run appropriate significance\ntests, estimate effect size, and conduct power analysis to estimate Type II\nerror. The toolkit provides a convenient and systematic way to compare NLP\nsystem performance that goes beyond statistical significance testing", "published": "2020-11-26 10:59:23", "link": "http://arxiv.org/abs/2011.13231v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Towards Interpretable Multilingual Detection of Hate Speech against\n  Immigrants and Women in Twitter at SemEval-2019 Task 5", "abstract": "his paper describes our techniques to detect hate speech against women and\nimmigrants on Twitter in multilingual contexts, particularly in English and\nSpanish. The challenge was designed by SemEval-2019 Task 5, where the\nparticipants need to design algorithms to detect hate speech in English and\nSpanish language with a given target (e.g., women or immigrants). Here, we have\ndeveloped two deep neural networks (Bidirectional Gated Recurrent Unit (GRU),\nCharacter-level Convolutional Neural Network (CNN)), and one machine learning\nmodel by exploiting the linguistic features. Our proposed model obtained 57 and\n75 F1 scores for Task A in English and Spanish language respectively. For Task\nB, the F1 scores are 67 for English and 75.33 for Spanish. In the case of task\nA (Spanish) and task B (both English and Spanish), the F1 scores are improved\nby 2, 10, and 5 points respectively. Besides, we present visually interpretable\nmodels that can address the generalizability issues of the custom-designed\nmachine learning architecture by investigating the annotated dataset.", "published": "2020-11-26 11:11:44", "link": "http://arxiv.org/abs/2011.13238v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A question-answering system for aircraft pilots' documentation", "abstract": "The aerospace industry relies on massive collections of complex and technical\ndocuments covering system descriptions, manuals or procedures. This paper\npresents a question answering (QA) system that would help aircraft pilots\naccess information in this documentation by naturally interacting with the\nsystem and asking questions in natural language. After describing each module\nof the dialog system, we present a multi-task based approach for the QA module\nwhich enables performance improvement on a Flight Crew Operating Manual (FCOM)\ndataset. A method to combine scores from the retriever and the QA modules is\nalso presented.", "published": "2020-11-26 13:33:47", "link": "http://arxiv.org/abs/2011.13284v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Automatic coding of students' writing via Contrastive Representation\n  Learning in the Wasserstein space", "abstract": "Qualitative analysis of verbal data is of central importance in the learning\nsciences. It is labor-intensive and time-consuming, however, which limits the\namount of data researchers can include in studies. This work is a step towards\nbuilding a statistical machine learning (ML) method for achieving an automated\nsupport for qualitative analyses of students' writing, here specifically in\nscore laboratory reports in introductory biology for sophistication of\nargumentation and reasoning. We start with a set of lab reports from an\nundergraduate biology course, scored by a four-level scheme that considers the\ncomplexity of argument structure, the scope of evidence, and the care and\nnuance of conclusions. Using this set of labeled data, we show that a popular\nnatural language modeling processing pipeline, namely vector representation of\nwords, a.k.a word embeddings, followed by Long Short Term Memory (LSTM) model\nfor capturing language generation as a state-space model, is able to\nquantitatively capture the scoring, with a high Quadratic Weighted Kappa (QWK)\nprediction score, when trained in via a novel contrastive learning set-up. We\nshow that the ML algorithm approached the inter-rater reliability of human\nanalysis. Ultimately, we conclude, that machine learning (ML) for natural\nlanguage processing (NLP) holds promise for assisting learning sciences\nresearchers in conducting qualitative studies at much larger scales than is\ncurrently possible.", "published": "2020-11-26 16:52:48", "link": "http://arxiv.org/abs/2011.13384v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AutoNLU: An On-demand Cloud-based Natural Language Understanding System\n  for Enterprises", "abstract": "With the renaissance of deep learning, neural networks have achieved\npromising results on many natural language understanding (NLU) tasks. Even\nthough the source codes of many neural network models are publicly available,\nthere is still a large gap from open-sourced models to solving real-world\nproblems in enterprises. Therefore, to fill this gap, we introduce AutoNLU, an\non-demand cloud-based system with an easy-to-use interface that covers all\ncommon use-cases and steps in developing an NLU model. AutoNLU has supported\nmany product teams within Adobe with different use-cases and datasets, quickly\ndelivering them working models. To demonstrate the effectiveness of AutoNLU, we\npresent two case studies. i) We build a practical NLU model for handling\nvarious image-editing requests in Photoshop. ii) We build powerful keyphrase\nextraction models that achieve state-of-the-art results on two public\nbenchmarks. In both cases, end users only need to write a small amount of code\nto convert their datasets into a common format used by AutoNLU.", "published": "2020-11-26 20:51:57", "link": "http://arxiv.org/abs/2011.13470v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoding and Diversity in Machine Translation", "abstract": "Neural Machine Translation (NMT) systems are typically evaluated using\nautomated metrics that assess the agreement between generated translations and\nground truth candidates. To improve systems with respect to these metrics, NLP\nresearchers employ a variety of heuristic techniques, including searching for\nthe conditional mode (vs. sampling) and incorporating various training\nheuristics (e.g., label smoothing). While search strategies significantly\nimprove BLEU score, they yield deterministic outputs that lack the diversity of\nhuman translations. Moreover, search tends to bias the distribution of\ntranslated gender pronouns. This makes human-level BLEU a misleading benchmark\nin that modern MT systems cannot approach human-level BLEU while simultaneously\nmaintaining human-level translation diversity. In this paper, we characterize\ndistributional differences between generated and real translations, examining\nthe cost in diversity paid for the BLEU scores enjoyed by NMT. Moreover, our\nstudy implicates search as a salient source of known bias when translating\ngender pronouns.", "published": "2020-11-26 21:09:38", "link": "http://arxiv.org/abs/2011.13477v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Answering Ambiguous Questions through Generative Evidence Fusion and\n  Round-Trip Prediction", "abstract": "In open-domain question answering, questions are highly likely to be\nambiguous because users may not know the scope of relevant topics when\nformulating them. Therefore, a system needs to find possible interpretations of\nthe question, and predict one or multiple plausible answers. When multiple\nplausible answers are found, the system should rewrite the question for each\nanswer to resolve the ambiguity. In this paper, we present a model that\naggregates and combines evidence from multiple passages to adaptively predict a\nsingle answer or a set of question-answer pairs for ambiguous questions. In\naddition, we propose a novel round-trip prediction approach to iteratively\ngenerate additional interpretations that our model fails to find in the first\npass, and then verify and filter out the incorrect question-answer pairs to\narrive at the final disambiguated output. Our model, named Refuel, achieves a\nnew state-of-the-art performance on the AmbigQA dataset, and shows competitive\nperformance on NQ-Open and TriviaQA. The proposed round-trip prediction is a\nmodel-agnostic general approach for answering ambiguous open-domain questions,\nwhich improves our Refuel as well as several baseline models. We release source\ncode for our models and experiments at\nhttps://github.com/amzn/refuel-open-domain-qa.", "published": "2020-11-26 05:48:55", "link": "http://arxiv.org/abs/2011.13137v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Streaming end-to-end multi-talker speech recognition", "abstract": "End-to-end multi-talker speech recognition is an emerging research trend in\nthe speech community due to its vast potential in applications such as\nconversation and meeting transcriptions. To the best of our knowledge, all\nexisting research works are constrained in the offline scenario. In this work,\nwe propose the Streaming Unmixing and Recognition Transducer (SURT) for\nend-to-end multi-talker speech recognition. Our model employs the Recurrent\nNeural Network Transducer (RNN-T) as the backbone that can meet various latency\nconstraints. We study two different model architectures that are based on a\nspeaker-differentiator encoder and a mask encoder respectively. To train this\nmodel, we investigate the widely used Permutation Invariant Training (PIT)\napproach and the Heuristic Error Assignment Training (HEAT) approach. Based on\nexperiments on the publicly available LibriSpeechMix dataset, we show that HEAT\ncan achieve better accuracy compared with PIT, and the SURT model with 150\nmilliseconds algorithmic latency constraint compares favorably with the offline\nsequence-to-sequence based baseline model in terms of accuracy.", "published": "2020-11-26 06:28:04", "link": "http://arxiv.org/abs/2011.13148v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "abstract": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "published": "2020-11-26 11:50:45", "link": "http://arxiv.org/abs/2011.13253v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Domain Adaptation for Speech Recognition via Uncertainty\n  Driven Self-Training", "abstract": "The performance of automatic speech recognition (ASR) systems typically\ndegrades significantly when the training and test data domains are mismatched.\nIn this paper, we show that self-training (ST) combined with an\nuncertainty-based pseudo-label filtering approach can be effectively used for\ndomain adaptation. We propose DUST, a dropout-based uncertainty-driven\nself-training technique which uses agreement between multiple predictions of an\nASR system obtained for different dropout settings to measure the model's\nuncertainty about its prediction. DUST excludes pseudo-labeled data with high\nuncertainties from the training, which leads to substantially improved ASR\nresults compared to ST without filtering, and accelerates the training time due\nto a reduced training data set. Domain adaptation experiments using WSJ as a\nsource domain and TED-LIUM 3 as well as SWITCHBOARD as the target domains show\nthat up to 80% of the performance of a system trained on ground-truth data can\nbe recovered.", "published": "2020-11-26 18:51:26", "link": "http://arxiv.org/abs/2011.13439v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multi-QuartzNet: Multi-Resolution Convolution for Speech Recognition\n  with Multi-Layer Feature Fusion", "abstract": "In this paper, we propose an end-to-end speech recognition network based on\nNvidia's previous QuartzNet model. We try to promote the model performance, and\ndesign three components: (1) Multi-Resolution Convolution Module, replaces the\noriginal 1D time-channel separable convolution with multi-stream convolutions.\nEach stream has a unique dilated stride on convolutional operations. (2)\nChannel-Wise Attention Module, calculates the attention weight of each\nconvolutional stream by spatial channel-wise pooling. (3) Multi-Layer Feature\nFusion Module, reweights each convolutional block by global multi-layer feature\nmaps. Our experiments demonstrate that Multi-QuartzNet model achieves CER 6.77%\non AISHELL-1 data set, which outperforms original QuartzNet and is close to\nstate-of-art result.", "published": "2020-11-26 02:01:03", "link": "http://arxiv.org/abs/2011.13090v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving RNN Transducer With Target Speaker Extraction and Neural\n  Uncertainty Estimation", "abstract": "Target-speaker speech recognition aims to recognize target-speaker speech\nfrom noisy environments with background noise and interfering speakers. This\nwork presents a joint framework that combines time-domain target-speaker speech\nextraction and Recurrent Neural Network Transducer (RNN-T). To stabilize the\njoint-training, we propose a multi-stage training strategy that pre-trains and\nfine-tunes each module in the system before joint-training. Meanwhile, speaker\nidentity and speech enhancement uncertainty measures are proposed to compensate\nfor residual noise and artifacts from the target speech extraction module.\nCompared to a recognizer fine-tuned with a target speech extraction model, our\nexperiments show that adding the neural uncertainty module significantly\nreduces 17% relative Character Error Rate (CER) on multi-speaker signals with\nbackground noise. The multi-condition experiments indicate that our method can\nachieve 9% relative performance gain in the noisy condition while maintaining\nthe performance in the clean condition.", "published": "2020-11-26 17:13:34", "link": "http://arxiv.org/abs/2011.13393v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Movement Generation with Audio Features", "abstract": "Sound and movement are closely coupled, particularly in dance. Certain audio\nfeatures have been found to affect the way we move to music. Is this\nrelationship between sound and movement something which can be modelled using\nmachine learning? This work presents initial experiments wherein high-level\naudio features calculated from a set of music pieces are included in a movement\ngeneration model trained on motion capture recordings of improvised dance. Our\nresults indicate that the model learns to generate realistic dance movements\nwhich vary depending on the audio features.", "published": "2020-11-26 19:33:08", "link": "http://arxiv.org/abs/2011.13453v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-time error correction and performance aid for MIDI instruments", "abstract": "Making a slight mistake during live music performance can easily be spotted\nby an astute listener, even if the performance is an improvisation or an\nunfamiliar piece. An example might be a highly dissonant chord played by\nmistake in a classical-era sonata, or a sudden off-key note in a recurring\nmotif. The problem of identifying and correcting such errors can be approached\nwith artificial intelligence -- if a trained human can easily do it, maybe a\ncomputer can be trained to spot the errors quickly and just as accurately. The\nability to identify and auto-correct errors in real-time would be not only\nextremely useful to performing musicians, but also a valuable asset for\nproducers, allowing much fewer overdubs and re-recording of takes due to small\nimperfections. This paper examines state-of-the-art solutions to related\nproblems and explores novel solutions for music error detection and correction,\nfocusing on their real-time applicability. The explored approaches consider\nerror detection through music context and theory, as well as supervised\nlearning models with no predefined musical information or rules, trained on\nappropriate datasets. Focusing purely on correcting musical errors, the\npresented solutions operate on a high-level representation of the audio (MIDI)\ninstead of the raw audio domain, taking input from an electronic instrument\n(MIDI keyboard/piano) and altering it when needed before it is sent to the\nsampler. This work proposes multiple general recurrent neural network designs\nfor real-time error correction and performance aid for MIDI instruments,\ndiscusses the results, limitations, and possible future improvements. It also\nemphasizes on making the research results easily accessible to the end user -\nmusic enthusiasts, producers and performers -- by using the latest artificial\nintelligence platforms and tools.", "published": "2020-11-26 04:28:29", "link": "http://arxiv.org/abs/2011.13122v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Virufy: Global Applicability of Crowdsourced and Clinical Datasets for\n  AI Detection of COVID-19 from Cough", "abstract": "Rapid and affordable methods of testing for COVID-19 infections are essential\nto reduce infection rates and prevent medical facilities from becoming\noverwhelmed. Current approaches of detecting COVID-19 require in-person testing\nwith expensive kits that are not always easily accessible. This study\ndemonstrates that crowdsourced cough audio samples recorded and acquired on\nsmartphones from around the world can be used to develop an AI-based method\nthat accurately predicts COVID-19 infection with an ROC-AUC of 77.1%\n(75.2%-78.3%). Furthermore, we show that our method is able to generalize to\ncrowdsourced audio samples from Latin America and clinical samples from South\nAsia, without further training using the specific samples from those regions.\nAs more crowdsourced data is collected, further development can be implemented\nusing various respiratory audio samples to create a cough analysis-based\nmachine learning (ML) solution for COVID-19 detection that can likely\ngeneralize globally to all demographic groups in both clinical and non-clinical\nsettings.", "published": "2020-11-26 14:38:19", "link": "http://arxiv.org/abs/2011.13320v4", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
