{"title": "Monitoring Targeted Hate in Online Environments", "abstract": "Hateful comments, swearwords and sometimes even death threats are becoming a\nreality for many people today in online environments. This is especially true\nfor journalists, politicians, artists, and other public figures. This paper\ndescribes how hate directed towards individuals can be measured in online\nenvironments using a simple dictionary-based approach. We present a case study\non Swedish politicians, and use examples from this study to discuss\nshortcomings of the proposed dictionary-based approach. We also outline\npossibilities for potential refinements of the proposed approach.", "published": "2018-03-13 12:56:27", "link": "http://arxiv.org/abs/1803.04757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhanced Word Representations for Bridging Anaphora Resolution", "abstract": "Most current models of word representations(e.g.,GloVe) have successfully\ncaptured fine-grained semantics. However, semantic similarity exhibited in\nthese word embeddings is not suitable for resolving bridging anaphora, which\nrequires the knowledge of associative similarity (i.e., relatedness) instead of\nsemantic similarity information between synonyms or hypernyms. We create word\nembeddings (embeddings_PP) to capture such relatedness by exploring the\nsyntactic structure of noun phrases. We demonstrate that using embeddings_PP\nalone achieves around 30% of accuracy for bridging anaphora resolution on the\nISNotes corpus. Furthermore, we achieve a substantial gain over the\nstate-of-the-art system (Hou et al., 2013) for bridging antecedent selection.", "published": "2018-03-13 13:33:06", "link": "http://arxiv.org/abs/1803.04790v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Lattice Language Models", "abstract": "In this work, we propose a new language modeling paradigm that has the\nability to perform both prediction and moderation of information flow at\nmultiple granularities: neural lattice language models. These models construct\na lattice of possible paths through a sentence and marginalize across this\nlattice to calculate sequence probabilities or optimize parameters. This\napproach allows us to seamlessly incorporate linguistic intuitions - including\npolysemy and existence of multi-word lexical items - into our language model.\nExperiments on multiple language modeling tasks show that English neural\nlattice language models that utilize polysemous embeddings are able to improve\nperplexity by 9.95% relative to a word-level baseline, and that a Chinese model\nthat handles multi-character tokens is able to improve perplexity by 20.94%\nrelative to a character-level baseline.", "published": "2018-03-13 23:13:58", "link": "http://arxiv.org/abs/1803.05071v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Detection of Online Jihadist Hate Speech", "abstract": "We have developed a system that automatically detects online jihadist hate\nspeech with over 80% accuracy, by using techniques from Natural Language\nProcessing and Machine Learning. The system is trained on a corpus of 45,000\nsubversive Twitter messages collected from October 2014 to December 2016. We\npresent a qualitative and quantitative analysis of the jihadist rhetoric in the\ncorpus, examine the network of Twitter users, outline the technical procedure\nused to train the system, and discuss examples of use.", "published": "2018-03-13 02:09:06", "link": "http://arxiv.org/abs/1803.04596v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Hierarchical Learning of Cross-Language Mappings through Distributed\n  Vector Representations for Code", "abstract": "Translating a program written in one programming language to another can be\nuseful for software development tasks that need functionality implementations\nin different languages. Although past studies have considered this problem,\nthey may be either specific to the language grammars, or specific to certain\nkinds of code elements (e.g., tokens, phrases, API uses). This paper proposes a\nnew approach to automatically learn cross-language representations for various\nkinds of structural code elements that may be used for program translation. Our\nkey idea is two folded: First, we normalize and enrich code token streams with\nadditional structural and semantic information, and train cross-language vector\nrepresentations for the tokens (a.k.a. shared embeddings based on word2vec, a\nneural-network-based technique for producing word embeddings; Second,\nhierarchically from bottom up, we construct shared embeddings for code elements\nof higher levels of granularity (e.g., expressions, statements, methods) from\nthe embeddings for their constituents, and then build mappings among code\nelements across languages based on similarities among embeddings.\n  Our preliminary evaluations on about 40,000 Java and C# source files from 9\nsoftware projects show that our approach can automatically learn shared\nembeddings for various code elements in different languages and identify their\ncross-language mappings with reasonable Mean Average Precision scores. When\ncompared with an existing tool for mapping library API methods, our approach\nidentifies many more mappings accurately. The mapping results and code can be\naccessed at\nhttps://github.com/bdqnghi/hierarchical-programming-language-mapping. We\nbelieve that our idea for learning cross-language vector representations with\ncode structural information can be a useful step towards automated program\ntranslation.", "published": "2018-03-13 10:30:55", "link": "http://arxiv.org/abs/1803.04715v1", "categories": ["cs.LG", "cs.CL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "IDEL: In-Database Entity Linking with Neural Embeddings", "abstract": "We present a novel architecture, In-Database Entity Linking (IDEL), in which\nwe integrate the analytics-optimized RDBMS MonetDB with neural text mining\nabilities. Our system design abstracts core tasks of most neural entity linking\nsystems for MonetDB. To the best of our knowledge, this is the first defacto\nimplemented system integrating entity-linking in a database. We leverage the\nability of MonetDB to support in-database-analytics with user defined functions\n(UDFs) implemented in Python. These functions call machine learning libraries\nfor neural text mining, such as TensorFlow. The system achieves zero cost for\ndata shipping and transformation by utilizing MonetDB's ability to embed Python\nprocesses in the database kernel and exchange data in NumPy arrays. IDEL\nrepresents text and relational data in a joint vector space with neural\nembeddings and can compensate errors with ambiguous entity representations. For\ndetecting matching entities, we propose a novel similarity function based on\njoint neural embeddings which are learned via minimizing pairwise contrastive\nranking loss. This function utilizes a high dimensional index structures for\nfast retrieval of matching entities. Our first implementation and experiments\nusing the WebNLG corpus show the effectiveness and the potentials of IDEL.", "published": "2018-03-13 15:35:42", "link": "http://arxiv.org/abs/1803.04884v1", "categories": ["cs.DB", "cs.CL", "cs.NE"], "primary_category": "cs.DB"}
{"title": "Investigating the Effect of Music and Lyrics on Spoken-Word Recognition", "abstract": "Background music in social interaction settings can hinder conversation. Yet,\nlittle is known of how specific properties of music impact speech processing.\nThis paper addresses this knowledge gap by investigating 1) whether the masking\neffect of background music with lyrics is larger than that of music without\nlyrics, and 2) whether the masking effect is larger for more complex music. To\nanswer these questions, a word identification experiment was run in which Dutch\nparticipants listened to Dutch CVC words embedded in stretches of background\nmusic in two conditions, with and without lyrics, and at three SNRs. Three\nsongs were used of different genres and complexities. Music stretches with and\nwithout lyrics were sampled from the same song in order to control for factors\nbeyond the presence of lyrics. The results showed a clear negative impact of\nthe presence of lyrics in background music on spoken-word recognition. This\nimpact is independent of complexity. The results suggest that social spaces\n(e.g., restaurants, caf\\'es and bars) should make careful choices of music to\npromote conversation, and open a path for future work.", "published": "2018-03-13 21:40:59", "link": "http://arxiv.org/abs/1803.05058v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep CNN based feature extractor for text-prompted speaker recognition", "abstract": "Deep learning is still not a very common tool in speaker verification field.\nWe study deep convolutional neural network performance in the text-prompted\nspeaker verification task. The prompted passphrase is segmented into word\nstates - i.e. digits -to test each digit utterance separately. We train a\nsingle high-level feature extractor for all states and use cosine similarity\nmetric for scoring. The key feature of our network is the Max-Feature-Map\nactivation function, which acts as an embedded feature selector. By using\nmultitask learning scheme to train the high-level feature extractor we were\nable to surpass the classic baseline systems in terms of quality and achieved\nimpressive results for such a novice approach, getting 2.85% EER on the RSR2015\nevaluation set. Fusion of the proposed and the baseline systems improves this\nresult.", "published": "2018-03-13 10:59:24", "link": "http://arxiv.org/abs/1803.05307v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Music Genre Classification Using Spectral Analysis and Sparse\n  Representation of the Signals", "abstract": "In this paper, we proposed a robust music genre classification method based\non a sparse FFT based feature extraction method which extracted with\ndiscriminating power of spectral analysis of non-stationary audio signals, and\nthe capability of sparse representation based classifiers. Feature extraction\nmethod combines two sets of features namely short-term features (extracted from\nwindowed signals) and long-term features (extracted from combination of\nextracted short-time features). Experimental results demonstrate that the\nproposed feature extraction method leads to a sparse representation of audio\nsignals. As a result, a significant reduction in the dimensionality of the\nsignals is achieved. The extracted features are then fed into a sparse\nrepresentation based classifier (SRC). Our experimental results on the GTZAN\ndatabase demonstrate that the proposed method outperforms the other state of\nthe art SRC approaches. Moreover, the computational efficiency of the proposed\nmethod is better than that of the other Compressive Sampling (CS)-based\nclassifiers.", "published": "2018-03-13 06:39:49", "link": "http://arxiv.org/abs/1803.04652v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in\n  Music", "abstract": "The Variational Autoencoder (VAE) has proven to be an effective model for\nproducing semantically meaningful latent representations for natural data.\nHowever, it has thus far seen limited application to sequential data, and, as\nwe demonstrate, existing recurrent VAE models have difficulty modeling\nsequences with long-term structure. To address this issue, we propose the use\nof a hierarchical decoder, which first outputs embeddings for subsequences of\nthe input and then uses these embeddings to generate each subsequence\nindependently. This structure encourages the model to utilize its latent code,\nthereby avoiding the \"posterior collapse\" problem, which remains an issue for\nrecurrent VAEs. We apply this architecture to modeling sequences of musical\nnotes and find that it exhibits dramatically better sampling, interpolation,\nand reconstruction performance than a \"flat\" baseline model. An implementation\nof our \"MusicVAE\" is available online at http://g.co/magenta/musicvae-code.", "published": "2018-03-13 21:14:46", "link": "http://arxiv.org/abs/1803.05428v5", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning to Recognize Musical Genre from Audio", "abstract": "We here summarize our experience running a challenge with open data for\nmusical genre recognition. Those notes motivate the task and the challenge\ndesign, show some statistics about the submissions, and present the results.", "published": "2018-03-13 15:58:58", "link": "http://arxiv.org/abs/1803.05337v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
