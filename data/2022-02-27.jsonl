{"title": "Controllable Natural Language Generation with Contrastive Prefixes", "abstract": "To guide the generation of large pretrained language models (LM), previous\nwork has focused on directly fine-tuning the language model or utilizing an\nattribute discriminator. In this work, we propose a novel lightweight framework\nfor controllable GPT2 generation, which utilizes a set of small\nattribute-specific vectors, called prefixes, to steer natural language\ngeneration. Different from prefix-tuning, where each prefix is trained\nindependently, we take the relationship among prefixes into consideration and\ntrain multiple prefixes simultaneously. We propose a novel supervised method\nand also an unsupervised method to train the prefixes for single-aspect control\nwhile the combination of these two methods can achieve multi-aspect control.\nExperimental results on both single-aspect and multi-aspect control show that\nour methods can guide generation towards the desired attributes while keeping\nhigh linguistic quality.", "published": "2022-02-27 00:31:03", "link": "http://arxiv.org/abs/2202.13257v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OCR Improves Machine Translation for Low-Resource Languages", "abstract": "We aim to investigate the performance of current OCR systems on low resource\nlanguages and low resource scripts. We introduce and make publicly available a\nnovel benchmark, OCR4MT, consisting of real and synthetic data, enriched with\nnoise, for 60 low-resource languages in low resource scripts. We evaluate\nstate-of-the-art OCR systems on our benchmark and analyse most common errors.\nWe show that OCR monolingual data is a valuable resource that can increase\nperformance of Machine Translation models, when used in backtranslation. We\nthen perform an ablation study to investigate how OCR errors impact Machine\nTranslation performance and determine what is the minimum level of OCR quality\nneeded for the monolingual data to be useful for Machine Translation.", "published": "2022-02-27 02:36:45", "link": "http://arxiv.org/abs/2202.13274v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question\n  Answering", "abstract": "Recent works on knowledge base question answering (KBQA) retrieve subgraphs\nfor easier reasoning. A desired subgraph is crucial as a small one may exclude\nthe answer but a large one might introduce more noises. However, the existing\nretrieval is either heuristic or interwoven with the reasoning, causing\nreasoning on the partial subgraphs, which increases the reasoning bias when the\nintermediate supervision is missing. This paper proposes a trainable subgraph\nretriever (SR) decoupled from the subsequent reasoning process, which enables a\nplug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive\nexperiments demonstrate SR achieves significantly better retrieval and QA\nperformance than existing retrieval methods. Via weakly supervised pre-training\nas well as the end-to-end fine-tuning, SRl achieves new state-of-the-art\nperformance when combined with NSM, a subgraph-oriented reasoner, for\nembedding-based KBQA methods.", "published": "2022-02-27 05:25:20", "link": "http://arxiv.org/abs/2202.13296v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Variational Autoencoder with Disentanglement Priors for Low-Resource\n  Task-Specific Natural Language Generation", "abstract": "In this paper, we propose a variational autoencoder with disentanglement\npriors, VAE-DPRIOR, for task-specific natural language generation with none or\na handful of task-specific labeled examples. In order to tackle compositional\ngeneralization across tasks, our model performs disentangled representation\nlearning by introducing a conditional prior for the latent content space and\nanother conditional prior for the latent label space. Both types of priors\nsatisfy a novel property called $\\epsilon$-disentangled. We show both\nempirically and theoretically that the novel priors can disentangle\nrepresentations even without specific regularizations as in the prior work. The\ncontent prior enables directly sampling diverse content representations from\nthe content space learned from the seen tasks, and fuse them with the\nrepresentations of novel tasks for generating semantically diverse texts in the\nlow-resource settings. Our extensive experiments demonstrate the superior\nperformance of our model over competitive baselines in terms of i) data\naugmentation in continuous zero/few-shot learning, and ii) text style transfer\nin the few-shot setting.", "published": "2022-02-27 13:34:24", "link": "http://arxiv.org/abs/2202.13363v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Simple but Effective Pluggable Entity Lookup Table for Pre-trained\n  Language Models", "abstract": "Pre-trained language models (PLMs) cannot well recall rich factual knowledge\nof entities exhibited in large-scale corpora, especially those rare entities.\nIn this paper, we propose to build a simple but effective Pluggable Entity\nLookup Table (PELT) on demand by aggregating the entity's output\nrepresentations of multiple occurrences in the corpora. PELT can be compatibly\nplugged as inputs to infuse supplemental entity knowledge into PLMs. Compared\nto previous knowledge-enhanced PLMs, PELT only requires 0.2%-5% pre-computation\nwith capability of acquiring knowledge from out-of-domain corpora for domain\nadaptation scenario. The experiments on knowledge-related tasks demonstrate\nthat our method, PELT, can flexibly and effectively transfer entity knowledge\nfrom related corpora into PLMs with different architectures.", "published": "2022-02-27 16:30:22", "link": "http://arxiv.org/abs/2202.13392v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Candidate Retrieval with Entity Profile Generation for\n  Wikidata Entity Linking", "abstract": "Entity linking (EL) is the task of linking entity mentions in a document to\nreferent entities in a knowledge base (KB). Many previous studies focus on\nWikipedia-derived KBs. There is little work on EL over Wikidata, even though it\nis the most extensive crowdsourced KB. The scale of Wikidata can open up many\nnew real-world applications, but its massive number of entities also makes EL\nchallenging. To effectively narrow down the search space, we propose a novel\ncandidate retrieval paradigm based on entity profiling. Wikidata entities and\ntheir textual fields are first indexed into a text search engine (e.g.,\nElasticsearch). During inference, given a mention and its context, we use a\nsequence-to-sequence (seq2seq) model to generate the profile of the target\nentity, which consists of its title and description. We use the profile to\nquery the indexed search engine to retrieve candidate entities. Our approach\ncomplements the traditional approach of using a Wikipedia anchor-text\ndictionary, enabling us to further design a highly effective hybrid method for\ncandidate retrieval. Combined with a simple cross-attention reranker, our\ncomplete EL framework achieves state-of-the-art results on three Wikidata-based\ndatasets and strong performance on TACKBP-2010.", "published": "2022-02-27 17:38:53", "link": "http://arxiv.org/abs/2202.13404v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Legal Argument Mining with Domain Pre-training and Neural\n  Networks", "abstract": "The contextual word embedding model, BERT, has proved its ability on\ndownstream tasks with limited quantities of annotated data. BERT and its\nvariants help to reduce the burden of complex annotation work in many\ninterdisciplinary research areas, for example, legal argument mining in digital\nhumanities. Argument mining aims to develop text analysis tools that can\nautomatically retrieve arguments and identify relationships between\nargumentation clauses. Since argumentation is one of the key aspects of case\nlaw, argument mining tools for legal texts are applicable to both academic and\nnon-academic legal research. Domain-specific BERT variants (pre-trained with\ncorpora from a particular background) have also achieved strong performance in\nmany tasks. To our knowledge, previous machine learning studies of argument\nmining on judicial case law still heavily rely on statistical models. In this\npaper, we provide a broad study of both classic and contextual embedding models\nand their performance on practical case law from the European Court of Human\nRights (ECHR). During our study, we also explore a number of neural networks\nwhen being combined with different embeddings. Our experiments provide a\ncomprehensive overview of a variety of approaches to the legal argument mining\ntask. We conclude that domain pre-trained transformer models have great\npotential in this area, although traditional embeddings can also achieve strong\nperformance when combined with additional neural network layers.", "published": "2022-02-27 21:24:53", "link": "http://arxiv.org/abs/2202.13457v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HiCLRE: A Hierarchical Contrastive Learning Framework for Distantly\n  Supervised Relation Extraction", "abstract": "Distant supervision assumes that any sentence containing the same entity\npairs reflects identical relationships. Previous works of distantly supervised\nrelation extraction (DSRE) task generally focus on sentence-level or bag-level\nde-noising techniques independently, neglecting the explicit interaction with\ncross levels. In this paper, we propose a hierarchical contrastive learning\nFramework for Distantly Supervised relation extraction (HiCLRE) to reduce noisy\nsentences, which integrate the global structural information and local\nfine-grained interaction. Specifically, we propose a three-level hierarchical\nlearning framework to interact with cross levels, generating the de-noising\ncontext-aware representations via adapting the existing multi-head\nself-attention, named Multi-Granularity Recontextualization. Meanwhile, pseudo\npositive samples are also provided in the specific level for contrastive\nlearning via a dynamic gradient-based data augmentation strategy, named Dynamic\nGradient Adversarial Perturbation. Experiments demonstrate that HiCLRE\nsignificantly outperforms strong baselines in various mainstream DSRE datasets.", "published": "2022-02-27 12:48:26", "link": "http://arxiv.org/abs/2202.13352v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UCTopic: Unsupervised Contrastive Learning for Phrase Representations\n  and Topic Mining", "abstract": "High-quality phrase representations are essential to finding topics and\nrelated terms in documents (a.k.a. topic mining). Existing phrase\nrepresentation learning methods either simply combine unigram representations\nin a context-free manner or rely on extensive annotations to learn\ncontext-aware knowledge. In this paper, we propose UCTopic, a novel\nunsupervised contrastive learning framework for context-aware phrase\nrepresentations and topic mining. UCTopic is pretrained in a large scale to\ndistinguish if the contexts of two phrase mentions have the same semantics. The\nkey to pretraining is positive pair construction from our phrase-oriented\nassumptions. However, we find traditional in-batch negatives cause performance\ndecay when finetuning on a dataset with small topic numbers. Hence, we propose\ncluster-assisted contrastive learning(CCL) which largely reduces noisy\nnegatives by selecting negatives from clusters and further improves phrase\nrepresentations for topics accordingly. UCTopic outperforms the\nstate-of-the-art phrase representation model by 38.2% NMI in average on four\nentity cluster-ing tasks. Comprehensive evaluation on topic mining shows that\nUCTopic can extract coherent and diverse topical phrases.", "published": "2022-02-27 22:43:06", "link": "http://arxiv.org/abs/2202.13469v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multimodal German Dataset for Automatic Lip Reading Systems and\n  Transfer Learning", "abstract": "Large datasets as required for deep learning of lip reading do not exist in\nmany languages. In this paper we present the dataset GLips (German Lips)\nconsisting of 250,000 publicly available videos of the faces of speakers of the\nHessian Parliament, which was processed for word-level lip reading using an\nautomatic pipeline. The format is similar to that of the English language LRW\n(Lip Reading in the Wild) dataset, with each video encoding one word of\ninterest in a context of 1.16 seconds duration, which yields compatibility for\nstudying transfer learning between both datasets. By training a deep neural\nnetwork, we investigate whether lip reading has language-independent features,\nso that datasets of different languages can be used to improve lip reading\nmodels. We demonstrate learning from scratch and show that transfer learning\nfrom LRW to GLips and vice versa improves learning speed and performance, in\nparticular for the validation set.", "published": "2022-02-27 17:37:35", "link": "http://arxiv.org/abs/2202.13403v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning the Beauty in Songs: Neural Singing Voice Beautifier", "abstract": "We are interested in a novel task, singing voice beautifying (SVB). Given the\nsinging voice of an amateur singer, SVB aims to improve the intonation and\nvocal tone of the voice, while keeping the content and vocal timbre. Current\nautomatic pitch correction techniques are immature, and most of them are\nrestricted to intonation but ignore the overall aesthetic quality. Hence, we\nintroduce Neural Singing Voice Beautifier (NSVB), the first generative model to\nsolve the SVB task, which adopts a conditional variational autoencoder as the\nbackbone and learns the latent representations of vocal tone. In NSVB, we\npropose a novel time-warping approach for pitch correction: Shape-Aware Dynamic\nTime Warping (SADTW), which ameliorates the robustness of existing time-warping\napproaches, to synchronize the amateur recording with the template pitch curve.\nFurthermore, we propose a latent-mapping algorithm in the latent space to\nconvert the amateur vocal tone to the professional one. To achieve this, we\nalso propose a new dataset containing parallel singing recordings of both\namateur and professional versions. Extensive experiments on both Chinese and\nEnglish songs demonstrate the effectiveness of our methods in terms of both\nobjective and subjective metrics. Audio samples are available\nat~\\url{https://neuralsvb.github.io}. Codes:\n\\url{https://github.com/MoonInTheRiver/NeuralSVB}.", "published": "2022-02-27 03:10:12", "link": "http://arxiv.org/abs/2202.13277v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ICASSP 2022 Deep Noise Suppression Challenge", "abstract": "The Deep Noise Suppression (DNS) challenge is designed to foster innovation\nin the area of noise suppression to achieve superior perceptual speech quality.\nThis is the 4th DNS challenge, with the previous editions held at INTERSPEECH\n2020, ICASSP 2021, and INTERSPEECH 2021. We open-source datasets and test sets\nfor researchers to train their deep noise suppression models, as well as a\nsubjective evaluation framework based on ITU-T P.835 to rate and rank-order the\nchallenge entries. We provide access to DNSMOS P.835 and word accuracy (WAcc)\nAPIs to challenge participants to help with iterative model improvements. In\nthis challenge, we introduced the following changes: (i) Included mobile device\nscenarios in the blind test set; (ii) Included a personalized noise suppression\ntrack with baseline; (iii) Added WAcc as an objective metric; (iv) Included\nDNSMOS P.835; (v) Made the training datasets and test sets fullband (48 kHz).\nWe use an average of WAcc and subjective scores P.835 SIG, BAK, and OVRL to get\nthe final score for ranking the DNS models. We believe that as a research\ncommunity, we still have a long way to go in achieving excellent speech quality\nin challenging noisy real-world scenarios.", "published": "2022-02-27 04:28:57", "link": "http://arxiv.org/abs/2202.13288v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ICASSP 2022 Acoustic Echo Cancellation Challenge", "abstract": "The ICASSP 2022 Acoustic Echo Cancellation Challenge is intended to stimulate\nresearch in acoustic echo cancellation (AEC), which is an important area of\nspeech enhancement and still a top issue in audio communication. This is the\nthird AEC challenge and it is enhanced by including mobile scenarios, adding\nspeech recognition rate in the challenge goal metrics, and making the default\nsample rate 48 kHz. In this challenge, we open source two large datasets to\ntrain AEC models under both single talk and double talk scenarios. These\ndatasets consist of recordings from more than 10,000 real audio devices and\nhuman speakers in real environments, as well as a synthetic dataset. We also\nopen source an online subjective test framework and provide an online objective\nmetric service for researchers to quickly test their results. The winners of\nthis challenge are selected based on the average Mean Opinion Score achieved\nacross all different single talk and double talk scenarios, and the speech\nrecognition word acceptance rate.", "published": "2022-02-27 04:32:40", "link": "http://arxiv.org/abs/2202.13290v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hierarchical Linear Dynamical System for Representing Notes from\n  Recorded Audio", "abstract": "We seek to develop simultaneous segmentation and classification of notes from\naudio recordings in presence of outliers. The selected architecture for\nmodeling time series is hierarchical linear dynamical system (HLDS). We propose\na novel method for its parameter setting. HLDS can potentially be employed in\ntwo ways: 1) simultaneous segmentation and clustering for exploring data, i.e.\nfinding unknown notes, 2) simultaneous segmentation and classification of audio\nrecording for finding the notes of interest in the presence of outliers. We\nadapted HLDS for the second purpose since it is an easier task and still a\nchallenging problem, e.g. in the field of bioacoustics. Each test clip has the\nsame notes (but different instances) as of the training clip and also contain\noutlier notes. At test, it is automatically decided to which class of interest\na note belongs to if any. Two applications of this work are to the fields of\nbioacoustics for detection of animal sounds in audio field recordings and also\nto musicology. Experiments have been conducted for segmentation and\nclassification of both avian and musical notes from recorded audio.", "published": "2022-02-27 00:27:58", "link": "http://arxiv.org/abs/2202.13255v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
