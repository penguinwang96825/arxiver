{"title": "Jointly Modeling Hierarchical and Horizontal Features for Relational\n  Triple Extraction", "abstract": "Recent works on relational triple extraction have shown the superiority of\njointly extracting entities and relations over the pipelined extraction manner.\nHowever, most existing joint models fail to balance the modeling of entity\nfeatures and the joint decoding strategy, and thus the interactions between the\nentity level and triple level are not fully investigated. In this work, we\nfirst introduce the hierarchical dependency and horizontal commonality between\nthe two levels, and then propose an entity-enhanced dual tagging framework that\nenables the triple extraction (TE) task to utilize such interactions with\nself-learned entity features through an auxiliary entity extraction (EE) task,\nwithout breaking the joint decoding of relational triples. Specifically, we\nalign the EE and TE tasks in a position-wise manner by formulating them as two\nsequence labeling problems with identical encoder-decoder structure. Moreover,\nthe two tasks are organized in a carefully designed parameter sharing setting\nso that the learned entity features could be naturally shared via multi-task\nlearning. Empirical experiments on the NYT benchmark demonstrate the\neffectiveness of the proposed framework compared to the state-of-the-art\nmethods.", "published": "2019-08-23 05:36:45", "link": "http://arxiv.org/abs/1908.08672v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchically-Refined Label Attention Network for Sequence Labeling", "abstract": "CRF has been used as a powerful model for statistical sequence labeling. For\nneural sequence labeling, however, BiLSTM-CRF does not always lead to better\nresults compared with BiLSTM-softmax local classification. This can be because\nthe simple Markov label transition model of CRF does not give much information\ngain over strong neural encoding. For better representing label sequences, we\ninvestigate a hierarchically-refined label attention network, which explicitly\nleverages label embeddings and captures potential long-term label dependency by\ngiving each word incrementally refined label distributions with hierarchical\nattention. Results on POS tagging, NER and CCG supertagging show that the\nproposed model not only improves the overall tagging accuracy with similar\nnumber of parameters, but also significantly speeds up the training and testing\ncompared to BiLSTM-CRF.", "published": "2019-08-23 05:55:46", "link": "http://arxiv.org/abs/1908.08676v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Learning Based Chatbot Models", "abstract": "A conversational agent (chatbot) is a piece of software that is able to\ncommunicate with humans using natural language. Modeling conversation is an\nimportant task in natural language processing and artificial intelligence.\nWhile chatbots can be used for various tasks, in general they have to\nunderstand users' utterances and provide responses that are relevant to the\nproblem at hand.\n  In my work, I conduct an in-depth survey of recent literature, examining over\n70 publications related to chatbots published in the last 3 years. Then, I\nproceed to make the argument that the very nature of the general conversation\ndomain demands approaches that are different from current state-of-of-the-art\narchitectures. Based on several examples from the literature I show why current\nchatbot models fail to take into account enough priors when generating\nresponses and how this affects the quality of the conversation. In the case of\nchatbots, these priors can be outside sources of information that the\nconversation is conditioned on like the persona or mood of the conversers. In\naddition to presenting the reasons behind this problem, I propose several ideas\non how it could be remedied.\n  The next section focuses on adapting the very recent Transformer model to the\nchatbot domain, which is currently state-of-the-art in neural machine\ntranslation. I first present experiments with the vanilla model, using\nconversations extracted from the Cornell Movie-Dialog Corpus. Secondly, I\naugment the model with some of my ideas regarding the issues of encoder-decoder\narchitectures. More specifically, I feed additional features into the model\nlike mood or persona together with the raw conversation data. Finally, I\nconduct a detailed analysis of how the vanilla model performs on conversational\ndata by comparing it to previous chatbot models and how the additional features\naffect the quality of the generated responses.", "published": "2019-08-23 14:09:37", "link": "http://arxiv.org/abs/1908.08835v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Poetry: Learning to Generate Poems using Syllables", "abstract": "Motivated by the recent progresses on machine learning-based models that\nlearn artistic styles, in this paper we focus on the problem of poem\ngeneration. This is a challenging task in which the machine has to capture the\nlinguistic features that strongly characterize a certain poet, as well as the\nsemantics of the poet's production, that are influenced by his personal\nexperiences and by his literary background. Since poetry is constructed using\nsyllables, that regulate the form and structure of poems, we propose a\nsyllable-based neural language model, and we describe a poem generation\nmechanism that is designed around the poet style, automatically selecting the\nmost representative generations. The poetic work of a target author is usually\nnot enough to successfully train modern deep neural networks, so we propose a\nmulti-stage procedure that exploits non-poetic works of the same author, and\nalso other publicly available huge corpora to learn syntax and grammar of the\ntarget language. We focus on the Italian poet Dante Alighieri, widely famous\nfor his Divine Comedy. A quantitative and qualitative experimental analysis of\nthe generated tercets is reported, where we included expert judges with strong\nbackground in humanistic studies. The generated tercets are frequently\nconsidered to be real by a generic population of judges, with relative\ndifference of 56.25\\% with respect to the ones really authored by Dante, and\nexpert judges perceived Dante's style and rhymes in the generated text.", "published": "2019-08-23 15:09:07", "link": "http://arxiv.org/abs/1908.08861v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Text Summarization: A Critical Evaluation", "abstract": "Text summarization aims at compressing long documents into a shorter form\nthat conveys the most important parts of the original document. Despite\nincreased interest in the community and notable research effort, progress on\nbenchmark datasets has stagnated. We critically evaluate key ingredients of the\ncurrent research setup: datasets, evaluation metrics, and models, and highlight\nthree primary shortcomings: 1) automatically collected datasets leave the task\nunderconstrained and may contain noise detrimental to training and evaluation,\n2) current evaluation protocol is weakly correlated with human judgment and\ndoes not account for important characteristics such as factual correctness, 3)\nmodels overfit to layout biases of current datasets and offer limited diversity\nin their outputs.", "published": "2019-08-23 18:00:38", "link": "http://arxiv.org/abs/1908.08960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Well-Read Students Learn Better: On the Importance of Pre-training\n  Compact Models", "abstract": "Recent developments in natural language representations have been accompanied\nby large and expensive models that leverage vast amounts of general-domain text\nthrough self-supervised pre-training. Due to the cost of applying such models\nto down-stream tasks, several model compression techniques on pre-trained\nlanguage representations have been proposed (Sun et al., 2019; Sanh, 2019).\nHowever, surprisingly, the simple baseline of just pre-training and fine-tuning\ncompact models has been overlooked. In this paper, we first show that\npre-training remains important in the context of smaller architectures, and\nfine-tuning pre-trained compact models can be competitive to more elaborate\nmethods proposed in concurrent work. Starting with pre-trained compact models,\nwe then explore transferring task knowledge from large fine-tuned models\nthrough standard knowledge distillation. The resulting simple, yet effective\nand general algorithm, Pre-trained Distillation, brings further improvements.\nThrough extensive experiments, we more generally explore the interaction\nbetween pre-training and distillation under two variables that have been\nunder-studied: model size and properties of unlabeled task data. One surprising\nobservation is that they have a compound effect even when sequentially applied\non the same data. To accelerate future research, we will make our 24\npre-trained miniature BERT models publicly available.", "published": "2019-08-23 18:02:05", "link": "http://arxiv.org/abs/1908.08962v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deploying Technology to Save Endangered Languages", "abstract": "Computer scientists working on natural language processing, native speakers\nof endangered languages, and field linguists to discuss ways to harness\nAutomatic Speech Recognition, especially neural networks, to automate\nannotation, speech tagging, and text parsing on endangered languages.", "published": "2019-08-23 18:31:35", "link": "http://arxiv.org/abs/1908.08971v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Little Annotation does a Lot of Good: A Study in Bootstrapping\n  Low-resource Named Entity Recognizers", "abstract": "Most state-of-the-art models for named entity recognition (NER) rely on the\navailability of large amounts of labeled data, making them challenging to\nextend to new, lower-resourced languages. However, there are now several\nproposed approaches involving either cross-lingual transfer learning, which\nlearns from other highly resourced languages, or active learning, which\nefficiently selects effective training data based on model predictions. This\npaper poses the question: given this recent progress, and limited human\nannotation, what is the most effective method for efficiently creating\nhigh-quality entity recognizers in under-resourced languages? Based on\nextensive experimentation using both simulated and real human annotation, we\nfind a dual-strategy approach best, starting with a cross-lingual transferred\nmodel, then performing targeted annotation of only uncertain entity spans in\nthe target language, minimizing annotator effort. Results demonstrate that\ncross-lingual transfer is a powerful tool when very little data can be\nannotated, but an entity-targeted annotation strategy can achieve competitive\naccuracy quickly, with just one-tenth of training data.", "published": "2019-08-23 19:15:07", "link": "http://arxiv.org/abs/1908.08983v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural data-to-text generation: A comparison between pipeline and\n  end-to-end architectures", "abstract": "Traditionally, most data-to-text applications have been designed using a\nmodular pipeline architecture, in which non-linguistic input data is converted\ninto natural language through several intermediate transformations. In\ncontrast, recent neural models for data-to-text generation have been proposed\nas end-to-end approaches, where the non-linguistic input is rendered in natural\nlanguage with much less explicit intermediate representations in-between. This\nstudy introduces a systematic comparison between neural pipeline and end-to-end\ndata-to-text approaches for the generation of text from RDF triples. Both\narchitectures were implemented making use of state-of-the art deep learning\nmethods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer.\nAutomatic and human evaluations together with a qualitative analysis suggest\nthat having explicit intermediate steps in the generation process results in\nbetter texts than the ones generated by end-to-end approaches. Moreover, the\npipeline models generalize better to unseen inputs. Data and code are publicly\navailable.", "published": "2019-08-23 20:10:36", "link": "http://arxiv.org/abs/1908.09022v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reference Network for Neural Machine Translation", "abstract": "Neural Machine Translation (NMT) has achieved notable success in recent\nyears. Such a framework usually generates translations in isolation. In\ncontrast, human translators often refer to reference data, either rephrasing\nthe intricate sentence fragments with common terms in source language, or just\naccessing to the golden translation directly. In this paper, we propose a\nReference Network to incorporate referring process into translation decoding of\nNMT. To construct a \\emph{reference book}, an intuitive way is to store the\ndetailed translation history with extra memory, which is computationally\nexpensive. Instead, we employ Local Coordinates Coding (LCC) to obtain global\ncontext vectors containing monolingual and bilingual contextual information for\nNMT decoding. Experimental results on Chinese-English and English-German tasks\ndemonstrate that our proposed model is effective in improving the translation\nquality with lightweight computation cost.", "published": "2019-08-23 08:58:49", "link": "http://arxiv.org/abs/1908.09920v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training Optimus Prime, M.D.: Generating Medical Certification Items by\n  Fine-Tuning OpenAI's gpt2 Transformer Model", "abstract": "This article describes new results of an application using transformer-based\nlanguage models to automated item generation (AIG), an area of ongoing interest\nin the domain of certification testing as well as in educational measurement\nand psychological testing. OpenAI's gpt2 pre-trained 345M parameter language\nmodel was retrained using the public domain text mining set of PubMed articles\nand subsequently used to generate item stems (case vignettes) as well as\ndistractor proposals for multiple-choice items. This case study shows promise\nand produces draft text that can be used by human item writers as input for\nauthoring. Future experiments with more recent transformer models (such as\nGrover, TransformerXL) using existing item pools are expected to improve\nresults further and to facilitate the development of assessment materials.", "published": "2019-08-23 00:58:21", "link": "http://arxiv.org/abs/1908.08594v3", "categories": ["cs.CL", "cs.AI", "J.3; J.4"], "primary_category": "cs.CL"}
{"title": "Toward Dialogue Modeling: A Semantic Annotation Scheme for Questions and\n  Answers", "abstract": "The present study proposes an annotation scheme for classifying the content\nand discourse contribution of question-answer pairs. We propose detailed\nguidelines for using the scheme and apply them to dialogues in English,\nSpanish, and Dutch. Finally, we report on initial machine learning experiments\nfor automatic annotation.", "published": "2019-08-23 11:04:48", "link": "http://arxiv.org/abs/1908.09921v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A BLSTM Network for Printed Bengali OCR System with High Accuracy", "abstract": "This paper presents a printed Bengali and English text OCR system developed\nby us using a single hidden BLSTM-CTC architecture having 128 units. Here, we\ndid not use any peephole connection and dropout in the BLSTM, which helped us\nin getting better accuracy. This architecture was trained by 47,720 text lines\nthat include English words also. When tested over 20 different Bengali fonts,\nit has produced character level accuracy of 99.32% and word level accuracy of\n96.65%. A good Indic multi script OCR system is also developed by Google. It\nsometimes recognizes a character of Bengali into the same character of a\nnon-Bengali script, especially Assamese, which has no distinction from Bengali,\nexcept for a few characters. For example, Bengali character for 'RA' is\nsometimes recognized as that of Assamese, mainly in conjunct consonant forms.\nOur OCR is free from such errors. This OCR system is available online at\nhttps://banglaocr.nltr.org", "published": "2019-08-23 05:45:27", "link": "http://arxiv.org/abs/1908.08674v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Gender Representation in French Broadcast Corpora and Its Impact on ASR\n  Performance", "abstract": "This paper analyzes the gender representation in four major corpora of French\nbroadcast. These corpora being widely used within the speech processing\ncommunity, they are a primary material for training automatic speech\nrecognition (ASR) systems. As gender bias has been highlighted in numerous\nnatural language processing (NLP) applications, we study the impact of the\ngender imbalance in TV and radio broadcast on the performance of an ASR system.\nThis analysis shows that women are under-represented in our data in terms of\nspeakers and speech turns. We introduce the notion of speaker role to refine\nour analysis and find that women are even fewer within the Anchor category\ncorresponding to prominent speakers. The disparity of available data for both\ngender causes performance to decrease on women. However this global trend can\nbe counterbalanced for speaker who are used to speak in the media when\nsufficient amount of data is available.", "published": "2019-08-23 08:51:19", "link": "http://arxiv.org/abs/1908.08717v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Controlling for Confounders in Multimodal Emotion Classification via\n  Adversarial Learning", "abstract": "Various psychological factors affect how individuals express emotions. Yet,\nwhen we collect data intended for use in building emotion recognition systems,\nwe often try to do so by creating paradigms that are designed just with a focus\non eliciting emotional behavior. Algorithms trained with these types of data\nare unlikely to function outside of controlled environments because our\nemotions naturally change as a function of these other factors. In this work,\nwe study how the multimodal expressions of emotion change when an individual is\nunder varying levels of stress. We hypothesize that stress produces modulations\nthat can hide the true underlying emotions of individuals and that we can make\nemotion recognition algorithms more generalizable by controlling for variations\nin stress. To this end, we use adversarial networks to decorrelate stress\nmodulations from emotion representations. We study how stress alters acoustic\nand lexical emotional predictions, paying special attention to how modulations\ndue to stress affect the transferability of learned emotion recognition models\nacross domains. Our results show that stress is indeed encoded in trained\nemotion classifiers and that this encoding varies across levels of emotions and\nacross the lexical and acoustic modalities. Our results also show that emotion\nrecognition models that control for stress during training have better\ngeneralizability when applied to new domains, compared to models that do not\ncontrol for stress during training. We conclude that is is necessary to\nconsider the effect of extraneous psychological factors when building and\ntesting emotion recognition models.", "published": "2019-08-23 19:00:18", "link": "http://arxiv.org/abs/1908.08979v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Predicting Features of Quantum Systems from Very Few Measurements", "abstract": "Predicting features of complex, large-scale quantum systems is essential to\nthe characterization and engineering of quantum architectures. We present an\nefficient approach for constructing an approximate classical description,\ncalled the classical shadow, of a quantum system from very few quantum\nmeasurements that can later be used to predict a large collection of features.\nThis approach is guaranteed to accurately predict M linear functions with\nbounded Hilbert-Schmidt norm from only order of log(M) measurements. This is\ncompletely independent of the system size and saturates fundamental lower\nbounds from information theory. We support our theoretical findings with\nnumerical experiments over a wide range of problem sizes (2 to 162 qubits).\nThese highlight advantages compared to existing machine learning approaches.", "published": "2019-08-23 17:32:39", "link": "http://arxiv.org/abs/1908.08909v2", "categories": ["quant-ph", "cs.CL", "cs.IT", "cs.LG", "math.IT", "math.PR"], "primary_category": "quant-ph"}
{"title": "VOP Detection for Read and Conversation Speech using CWT Coefficients\n  and Phone Boundaries", "abstract": "In this paper, we propose a novel approach for accurate detection of the\nvowel onset points (VOPs). VOP is the instant at which the vowel begins in the\nspeech signal. Precise identification of VOPs is important for various speech\napplications such as speech segmentation and speech rate modification. The\nexisting methods detect the majority of VOPs within 40 ms deviation, and it may\nnot be appropriate for the above speech applications. To address this issue, we\nproposed a two-stage approach for accurate detection of VOPs. At the first\nstage, VOPs are detected using continuous wavelet transform coefficients, and\nthe position of the detected VOPs are corrected using the phone boundaries in\nthe second stage. The phone boundaries are detected by the spectral transition\nmeasure method. Experiments are done using TIMIT and Bengali speech corpora.\nPerformance of the proposed approach is compared with two standard signal\nprocessing based methods. The evaluation results show that the proposed method\nperforms better than the existing methods.", "published": "2019-08-23 05:14:37", "link": "http://arxiv.org/abs/1908.08668v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Lukthung Classification Using Neural Networks on Lyrics and Audios", "abstract": "Music genre classification is a widely researched topic in music information\nretrieval (MIR). Being able to automatically tag genres will benefit music\nstreaming service providers such as JOOX, Apple Music, and Spotify for their\ncontent-based recommendation. However, most studies on music classification\nhave been done on western songs which differ from Thai songs. Lukthung, a\ndistinctive and long-established type of Thai music, is one of the most popular\nmusic genres in Thailand and has a specific group of listeners. In this paper,\nwe develop neural networks to classify such Lukthung genre from others using\nboth lyrics and audios. Words used in Lukthung songs are particularly poetical,\nand their musical styles are uniquely composed of traditional Thai instruments.\nWe leverage these two main characteristics by building a lyrics model based on\nbag-of-words (BoW), and an audio model using a convolutional neural network\n(CNN) architecture. We then aggregate the intermediate features learned from\nboth models to build a final classifier. Our results show that the proposed\nthree models outperform all of the standard classifiers where the combined\nmodel yields the best $F_1$ score of 0.86, allowing Lukthung classification to\nbe applicable to personalized recommendation for Thai audience.", "published": "2019-08-23 11:55:13", "link": "http://arxiv.org/abs/1908.08769v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Incremental Binarization On Recurrent Neural Networks For Single-Channel\n  Source Separation", "abstract": "This paper proposes a Bitwise Gated Recurrent Unit (BGRU) network for the\nsingle-channel source separation task. Recurrent Neural Networks (RNN) require\nseveral sets of weights within its cells, which significantly increases the\ncomputational cost compared to the fully-connected networks. To mitigate this\nincreased computation, we focus on the GRU cells and quantize the feedforward\nprocedure with binarized values and bitwise operations. The BGRU network is\ntrained in two stages. The real-valued weights are pretrained and transferred\nto the bitwise network, which are then incrementally binarized to minimize the\npotential loss that can occur from a sudden introduction of quantization. As\nthe proposed binarization technique turns only a few randomly chosen parameters\ninto their binary versions, it gives the network training procedure a chance to\ngently adapt to the partly quantized version of the network. It eventually\nachieves the full binarization by incrementally increasing the amount of\nbinarization over the iterations. Our experiments show that the proposed BGRU\nmethod produces source separation results greater than that of a real-valued\nfully connected network, with 11-12 dB mean Signal-to-Distortion Ratio (SDR). A\nfully binarized BGRU still outperforms a Bitwise Neural Network (BNN) by 1-2 dB\neven with less number of layers.", "published": "2019-08-23 16:38:02", "link": "http://arxiv.org/abs/1908.08898v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Multilingual and Multimode Phone Recognition System for Indian Languages", "abstract": "The aim of this paper is to develop a flexible framework capable of\nautomatically recognizing phonetic units present in a speech utterance of any\nlanguage spoken in any mode. In this study, we considered two modes of speech:\nconversation, and read modes in four Indian languages, namely, Telugu, Kannada,\nOdia, and Bengali. The proposed approach consists of two stages: (1) Automatic\nspeech mode classification (SMC) and (2) Automatic phonetic recognition using\nmode-specific multilingual phone recognition system (MPRS). In this work, the\nvocal tract and excitation source features are considered for speech mode\nclassification (SMC) task. SMC systems are developed using multilayer\nperceptron (MLP). Further, vocal tract, excitation source, and tandem features\nare used to build the deep neural network (DNN)-based MPRSs. The performance of\nthe proposed approach is compared with mode-dependent MPRSs. Experimental\nresults show that the proposed approach which combines both SMC and MPRS into a\nsingle system outperforms the baseline mode-dependent MPRSs.", "published": "2019-08-23 06:16:53", "link": "http://arxiv.org/abs/1908.09634v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
