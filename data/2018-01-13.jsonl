{"title": "Simple Unsupervised Keyphrase Extraction using Sentence Embeddings", "abstract": "Keyphrase extraction is the task of automatically selecting a small set of\nphrases that best describe a given free text document. Supervised keyphrase\nextraction requires large amounts of labeled training data and generalizes very\npoorly outside the domain of the training data. At the same time, unsupervised\nsystems have poor accuracy, and often do not generalize well, as they require\nthe input document to belong to a larger corpus also given as input. Addressing\nthese drawbacks, in this paper, we tackle keyphrase extraction from single\ndocuments with EmbedRank: a novel unsupervised method, that leverages sentence\nembeddings. EmbedRank achieves higher F-scores than graph-based state of the\nart systems on standard datasets and is suitable for real-time processing of\nlarge amounts of Web data. With EmbedRank, we also explicitly increase coverage\nand diversity among the selected keyphrases by introducing an embedding-based\nmaximal marginal relevance (MMR) for new phrases. A user study including over\n200 votes showed that, although reducing the phrases' semantic overlap leads to\nno gains in F-score, our high diversity selection is preferred by humans.", "published": "2018-01-13 17:57:33", "link": "http://arxiv.org/abs/1801.04470v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Black-box Generation of Adversarial Text Sequences to Evade Deep\n  Learning Classifiers", "abstract": "Although various techniques have been proposed to generate adversarial\nsamples for white-box attacks on text, little attention has been paid to\nblack-box attacks, which are more realistic scenarios. In this paper, we\npresent a novel algorithm, DeepWordBug, to effectively generate small text\nperturbations in a black-box setting that forces a deep-learning classifier to\nmisclassify a text input. We employ novel scoring strategies to identify the\ncritical tokens that, if modified, cause the classifier to make an incorrect\nprediction. Simple character-level transformations are applied to the\nhighest-ranked tokens in order to minimize the edit distance of the\nperturbation, yet change the original classification. We evaluated DeepWordBug\non eight real-world text datasets, including text classification, sentiment\nanalysis, and spam detection. We compare the result of DeepWordBug with two\nbaselines: Random (Black-box) and Gradient (White-box). Our experimental\nresults indicate that DeepWordBug reduces the prediction accuracy of current\nstate-of-the-art deep-learning models, including a decrease of 68\\% on average\nfor a Word-LSTM model and 48\\% on average for a Char-CNN model.", "published": "2018-01-13 00:42:30", "link": "http://arxiv.org/abs/1801.04354v5", "categories": ["cs.CL", "cs.CR", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting Offensive Language in Tweets Using Deep Learning", "abstract": "This paper addresses the important problem of discerning hateful content in\nsocial media. We propose a detection scheme that is an ensemble of Recurrent\nNeural Network (RNN) classifiers, and it incorporates various features\nassociated with user-related information, such as the users' tendency towards\nracism or sexism. These data are fed as input to the above classifiers along\nwith the word frequency vectors derived from the textual content. Our approach\nhas been evaluated on a publicly available corpus of 16k tweets, and the\nresults demonstrate its effectiveness in comparison to existing state of the\nart solutions. More specifically, our scheme can successfully distinguish\nracism and sexism messages from normal text, and achieve higher classification\nquality than current state-of-the-art algorithms.", "published": "2018-01-13 12:58:43", "link": "http://arxiv.org/abs/1801.04433v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
