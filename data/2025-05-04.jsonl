{"title": "Demystifying optimized prompts in language models", "abstract": "Modern language models (LMs) are not robust to out-of-distribution inputs.\nMachine generated (``optimized'') prompts can be used to modulate LM outputs\nand induce specific behaviors while appearing completely uninterpretable. In\nthis work, we investigate the composition of optimized prompts, as well as the\nmechanisms by which LMs parse and build predictions from optimized prompts. We\nfind that optimized prompts primarily consist of punctuation and noun tokens\nwhich are more rare in the training data. Internally, optimized prompts are\nclearly distinguishable from natural language counterparts based on sparse\nsubsets of the model's activations. Across various families of\ninstruction-tuned models, optimized prompts follow a similar path in how their\nrepresentations form through the network.", "published": "2025-05-04 22:04:14", "link": "http://arxiv.org/abs/2505.02273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parameter-Efficient Transformer Embeddings", "abstract": "Embedding layers in transformer-based NLP models typically account for the\nlargest share of model parameters, scaling with vocabulary size but not\nyielding performance gains proportional to scale. We propose an alternative\napproach in which token embedding vectors are first generated\ndeterministically, directly from the token IDs using a Fourier expansion of\ntheir normalized values, followed by a lightweight multilayer perceptron (MLP)\nthat captures higher-order interactions. We train standard transformers and our\narchitecture on natural language inference tasks (SNLI and MNLI), and evaluate\nzero-shot performance on sentence textual similarity (STS-B). Our results\ndemonstrate that the proposed method achieves competitive performance using\nsignificantly fewer parameters, trains faster, and operates effectively without\nthe need for dropout. This proof-of-concept study highlights the potential for\nscalable, memory-efficient language models and motivates further large-scale\nexperimentation based on our findings.", "published": "2025-05-04 21:47:18", "link": "http://arxiv.org/abs/2505.02266v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07 (Primary) 68T50 (Secondary)"], "primary_category": "cs.CL"}
{"title": "Personalisation or Prejudice? Addressing Geographic Bias in Hate Speech Detection using Debias Tuning in Large Language Models", "abstract": "Commercial Large Language Models (LLMs) have recently incorporated memory\nfeatures to deliver personalised responses. This memory retains details such as\nuser demographics and individual characteristics, allowing LLMs to adjust their\nbehaviour based on personal information. However, the impact of integrating\npersonalised information into the context has not been thoroughly assessed,\nleading to questions about its influence on LLM behaviour. Personalisation can\nbe challenging, particularly with sensitive topics. In this paper, we examine\nvarious state-of-the-art LLMs to understand their behaviour in different\npersonalisation scenarios, specifically focusing on hate speech. We prompt the\nmodels to assume country-specific personas and use different languages for hate\nspeech detection. Our findings reveal that context personalisation\nsignificantly influences LLMs' responses in this sensitive area. To mitigate\nthese unwanted biases, we fine-tune the LLMs by penalising inconsistent hate\nspeech classifications made with and without country or language-specific\ncontext. The refined models demonstrate improved performance in both\npersonalised contexts and when no context is provided.", "published": "2025-05-04 21:22:20", "link": "http://arxiv.org/abs/2505.02252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SEval-Ex: A Statement-Level Framework for Explainable Summarization Evaluation", "abstract": "Evaluating text summarization quality remains a critical challenge in Natural\nLanguage Processing. Current approaches face a trade-off between performance\nand interpretability. We present SEval-Ex, a framework that bridges this gap by\ndecomposing summarization evaluation into atomic statements, enabling both high\nperformance and explainability. SEval-Ex employs a two-stage pipeline: first\nextracting atomic statements from text source and summary using LLM, then a\nmatching between generated statements. Unlike existing approaches that provide\nonly summary-level scores, our method generates detailed evidence for its\ndecisions through statement-level alignments. Experiments on the SummEval\nbenchmark demonstrate that SEval-Ex achieves state-of-the-art performance with\n0.580 correlation on consistency with human consistency judgments, surpassing\nGPT-4 based evaluators (0.521) while maintaining interpretability. Finally, our\nframework shows robustness against hallucination.", "published": "2025-05-04 20:16:08", "link": "http://arxiv.org/abs/2505.02235v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Interpretable Emergent Language Using Inter-Agent Transformers", "abstract": "This paper explores the emergence of language in multi-agent reinforcement\nlearning (MARL) using transformers. Existing methods such as RIAL, DIAL, and\nCommNet enable agent communication but lack interpretability. We propose\nDifferentiable Inter-Agent Transformers (DIAT), which leverage self-attention\nto learn symbolic, human-understandable communication protocols. Through\nexperiments, DIAT demonstrates the ability to encode observations into\ninterpretable vocabularies and meaningful embeddings, effectively solving\ncooperative tasks. These results highlight the potential of DIAT for\ninterpretable communication in complex multi-agent environments.", "published": "2025-05-04 18:57:57", "link": "http://arxiv.org/abs/2505.02215v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "DNAZEN: Enhanced Gene Sequence Representations via Mixed Granularities of Coding Units", "abstract": "Genome modeling conventionally treats gene sequence as a language, reflecting\nits structured motifs and long-range dependencies analogous to linguistic units\nand organization principles such as words and syntax. Recent studies utilize\nadvanced neural networks, ranging from convolutional and recurrent models to\nTransformer-based models, to capture contextual information of gene sequence,\nwith the primary goal of obtaining effective gene sequence representations and\nthus enhance the models' understanding of various running gene samples.\nHowever, these approaches often directly apply language modeling techniques to\ngene sequences and do not fully consider the intrinsic information organization\nin them, where they do not consider how units at different granularities\ncontribute to representation. In this paper, we propose DNAZEN, an enhanced\ngenomic representation framework designed to learn from various granularities\nin gene sequences, including small polymers and G-grams that are combinations\nof several contiguous polymers. Specifically, we extract the G-grams from\nlarge-scale genomic corpora through an unsupervised approach to construct the\nG-gram vocabulary, which is used to provide G-grams in the learning process of\nDNA sequences through dynamically matching from running gene samples. A\nTransformer-based G-gram encoder is also proposed and the matched G-grams are\nfed into it to compute their representations and integrated into the encoder\nfor basic unit (E4BU), which is responsible for encoding small units and\nmaintaining the learning and inference process. To further enhance the learning\nprocess, we propose whole G-gram masking to train DNAZEN, where the model\nlargely favors the selection of each entire G-gram to mask rather than an\nordinary masking mechanism performed on basic units. Experiments on benchmark\ndatasets demonstrate the effectiveness of DNAZEN on various downstream tasks.", "published": "2025-05-04 18:02:28", "link": "http://arxiv.org/abs/2505.02206v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Exploring new Approaches for Information Retrieval through Natural Language Processing", "abstract": "This review paper explores recent advancements and emerging approaches in\nInformation Retrieval (IR) applied to Natural Language Processing (NLP). We\nexamine traditional IR models such as Boolean, vector space, probabilistic, and\ninference network models, and highlight modern techniques including deep\nlearning, reinforcement learning, and pretrained transformer models like BERT.\nWe discuss key tools and libraries - Lucene, Anserini, and Pyserini - for\nefficient text indexing and search. A comparative analysis of sparse, dense,\nand hybrid retrieval methods is presented, along with applications in web\nsearch engines, cross-language IR, argument mining, private information\nretrieval, and hate speech detection. Finally, we identify open challenges and\nfuture research directions to enhance retrieval accuracy, scalability, and\nethical considerations.", "published": "2025-05-04 17:37:26", "link": "http://arxiv.org/abs/2505.02199v1", "categories": ["cs.IR", "cs.CL", "68T50", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Measuring Hong Kong Massive Multi-Task Language Understanding", "abstract": "Multilingual understanding is crucial for the cross-cultural applicability of\nLarge Language Models (LLMs). However, evaluation benchmarks designed for Hong\nKong's unique linguistic landscape, which combines Traditional Chinese script\nwith Cantonese as the spoken form and its cultural context, remain\nunderdeveloped. To address this gap, we introduce HKMMLU, a multi-task language\nunderstanding benchmark that evaluates Hong Kong's linguistic competence and\nsocio-cultural knowledge. The HKMMLU includes 26,698 multi-choice questions\nacross 66 subjects, organized into four categories: Science, Technology,\nEngineering, and Mathematics (STEM), Social Sciences, Humanities, and Other. To\nevaluate the multilingual understanding ability of LLMs, 90,550\nMandarin-Cantonese translation tasks were additionally included. We conduct\ncomprehensive experiments on GPT-4o, Claude 3.7 Sonnet, and 18 open-source LLMs\nof varying sizes on HKMMLU. The results show that the best-performing model,\nDeepSeek-V3, struggles to achieve an accuracy of 75\\%, significantly lower than\nthat of MMLU and CMMLU. This performance gap highlights the need to improve\nLLMs' capabilities in Hong Kong-specific language and knowledge domains.\nFurthermore, we investigate how question language, model size, prompting\nstrategies, and question and reasoning token lengths affect model performance.\nWe anticipate that HKMMLU will significantly advance the development of LLMs in\nmultilingual and cross-cultural contexts, thereby enabling broader and more\nimpactful applications.", "published": "2025-05-04 16:39:12", "link": "http://arxiv.org/abs/2505.02177v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization", "abstract": "As large language models (LLMs) continue to advance in capabilities, it is\nessential to assess how they perform on established benchmarks. In this study,\nwe present a suite of experiments to assess the performance of modern LLMs\n(ranging from 3B to 90B+ parameters) on CaseHOLD, a legal benchmark dataset for\nidentifying case holdings. Our experiments demonstrate ``scaling effects'' -\nperformance on this task improves with model size, with more capable models\nlike GPT4o and AmazonNovaPro achieving macro F1 scores of 0.744 and 0.720\nrespectively. These scores are competitive with the best published results on\nthis dataset, and do not require any technically sophisticated model training,\nfine-tuning or few-shot prompting. To ensure that these strong results are not\ndue to memorization of judicial opinions contained in the training data, we\ndevelop and utilize a novel citation anonymization test that preserves semantic\nmeaning while ensuring case names and citations are fictitious. Models maintain\nstrong performance under these conditions (macro F1 of 0.728), suggesting the\nperformance is not due to rote memorization. These findings demonstrate both\nthe promise and current limitations of LLMs for legal tasks with important\nimplications for the development and measurement of automated legal analytics\nand legal benchmarks.", "published": "2025-05-04 16:24:12", "link": "http://arxiv.org/abs/2505.02172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking", "abstract": "Document chunking fundamentally impacts Retrieval-Augmented Generation (RAG)\nby determining how source materials are segmented before indexing. Despite\nevidence that Large Language Models (LLMs) are sensitive to the layout and\nstructure of retrieved data, there is currently no framework to analyze the\nimpact of different chunking methods. In this paper, we introduce a novel\nmethodology that defines essential characteristics of the chunking process at\nthree levels: intrinsic passage properties, extrinsic passage properties, and\npassages-document coherence. We propose HOPE (Holistic Passage Evaluation), a\ndomain-agnostic, automatic evaluation metric that quantifies and aggregates\nthese characteristics. Our empirical evaluations across seven domains\ndemonstrate that the HOPE metric correlates significantly (p > 0.13) with\nvarious RAG performance indicators, revealing contrasts between the importance\nof extrinsic and intrinsic properties of passages. Semantic independence\nbetween passages proves essential for system performance with a performance\ngain of up to 56.2% in factual correctness and 21.1% in answer correctness. On\nthe contrary, traditional assumptions about maintaining concept unity within\npassages show minimal impact. These findings provide actionable insights for\noptimizing chunking strategies, thus improving RAG system design to produce\nmore factually correct responses.", "published": "2025-05-04 16:22:27", "link": "http://arxiv.org/abs/2505.02171v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use", "abstract": "This paper presents a domain-specific implementation of Retrieval-Augmented\nGeneration (RAG) tailored to the Fair Use Doctrine in U.S. copyright law.\nMotivated by the increasing prevalence of DMCA takedowns and the lack of\naccessible legal support for content creators, we propose a structured approach\nthat combines semantic search with legal knowledge graphs and court citation\nnetworks to improve retrieval quality and reasoning reliability. Our prototype\nmodels legal precedents at the statutory factor level (e.g., purpose, nature,\namount, market effect) and incorporates citation-weighted graph representations\nto prioritize doctrinally authoritative sources. We use Chain-of-Thought\nreasoning and interleaved retrieval steps to better emulate legal reasoning.\nPreliminary testing suggests this method improves doctrinal relevance in the\nretrieval process, laying groundwork for future evaluation and deployment of\nLLM-based legal assistance tools.", "published": "2025-05-04 15:53:49", "link": "http://arxiv.org/abs/2505.02164v1", "categories": ["cs.CL", "I.2.7; K.5; H.3.3"], "primary_category": "cs.CL"}
{"title": "Think on your Feet: Adaptive Thinking via Reinforcement Learning for Social Agents", "abstract": "Effective social intelligence simulation requires language agents to\ndynamically adjust reasoning depth, a capability notably absent in current\napproaches. While existing methods either lack this kind of reasoning\ncapability or enforce uniform long chain-of-thought reasoning across all\nscenarios, resulting in excessive token usage and inappropriate social\nsimulation. In this paper, we propose $\\textbf{A}$daptive $\\textbf{M}$ode\n$\\textbf{L}$earning ($\\textbf{AML}$) that strategically selects from four\nthinking modes (intuitive reaction $\\rightarrow$ deep contemplation) based on\nreal-time context. Our framework's core innovation, the $\\textbf{A}$daptive\n$\\textbf{M}$ode $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{AMPO}$)\nalgorithm, introduces three key advancements over existing methods: (1)\nMulti-granular thinking mode design, (2) Context-aware mode switching across\nsocial interaction, and (3) Token-efficient reasoning via depth-adaptive\nprocessing. Extensive experiments on social intelligence tasks confirm that AML\nachieves 15.6% higher task performance than state-of-the-art methods. Notably,\nour method outperforms GRPO by 7.0% with 32.8% shorter reasoning chains. These\nresults demonstrate that context-sensitive thinking mode selection, as\nimplemented in AMPO, enables more human-like adaptive reasoning than GRPO's\nfixed-depth approach", "published": "2025-05-04 15:39:58", "link": "http://arxiv.org/abs/2505.02156v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "QiMeng-Xpiler: Transcompiling Tensor Programs for Deep Learning Systems with a Neural-Symbolic Approach", "abstract": "Heterogeneous deep learning systems (DLS) such as GPUs and ASICs have been\nwidely deployed in industrial data centers, which requires to develop multiple\nlow-level tensor programs for different platforms. An attractive solution to\nrelieve the programming burden is to transcompile the legacy code of one\nplatform to others. However, current transcompilation techniques struggle with\neither tremendous manual efforts or functional incorrectness, rendering \"Write\nOnce, Run Anywhere\" of tensor programs an open question.\n  We propose a novel transcompiler, i.e., QiMeng-Xpiler, for automatically\ntranslating tensor programs across DLS via both large language models (LLMs)\nand symbolic program synthesis, i.e., neural-symbolic synthesis. The key\ninsight is leveraging the powerful code generation ability of LLM to make\ncostly search-based symbolic synthesis computationally tractable. Concretely,\nwe propose multiple LLM-assisted compilation passes via pre-defined\nmeta-prompts for program transformation. During each program transformation,\nefficient symbolic program synthesis is employed to repair incorrect code\nsnippets with a limited scale. To attain high performance, we propose a\nhierarchical auto-tuning approach to systematically explore both the parameters\nand sequences of transformation passes. Experiments on 4 DLS with distinct\nprogramming interfaces, i.e., Intel DL Boost with VNNI, NVIDIA GPU with CUDA,\nAMD MI with HIP, and Cambricon MLU with BANG, demonstrate that QiMeng-Xpiler\ncorrectly translates different tensor programs at the accuracy of 95% on\naverage, and the performance of translated programs achieves up to 2.0x over\nvendor-provided manually-optimized libraries. As a result, the programming\nproductivity of DLS is improved by up to 96.0x via transcompiling legacy tensor\nprograms.", "published": "2025-05-04 15:14:27", "link": "http://arxiv.org/abs/2505.02146v1", "categories": ["cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Exploring the Potential of Offline RL for Reasoning in LLMs: A Preliminary Study", "abstract": "Despite significant advances in long-context reasoning by large language\nmodels (LLMs), primarily through Online Reinforcement Learning (RL) methods,\nthese approaches incur substantial computational costs and complexity. In\ncontrast, simpler and more economical Offline RL methods remain underexplored.\nTo address this gap, we investigate the effectiveness of Offline RL methods,\nspecifically Direct Preference Optimization (DPO) and its length-desensitized\nvariant LD-DPO, in enhancing the reasoning capabilities of LLMs. Extensive\nexperiments across multiple reasoning benchmarks demonstrate that these simpler\nOffline RL methods substantially improve model performance, achieving an\naverage enhancement of 3.3\\%, with a particularly notable increase of 10.1\\% on\nthe challenging Arena-Hard benchmark. Furthermore, we analyze DPO's sensitivity\nto output length, emphasizing that increasing reasoning length should align\nwith semantic richness, as indiscriminate lengthening may adversely affect\nmodel performance. We provide comprehensive descriptions of our data processing\nand training methodologies, offering empirical evidence and practical insights\nfor developing more cost-effective Offline RL approaches.", "published": "2025-05-04 15:09:49", "link": "http://arxiv.org/abs/2505.02142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data", "abstract": "Attention mechanisms are critical to the success of large language models\n(LLMs), driving significant advancements in multiple fields. However, for\ngraph-structured data, which requires emphasis on topological connections, they\nfall short compared to message-passing mechanisms on fixed links, such as those\nemployed by Graph Neural Networks (GNNs). This raises a question: ``Does\nattention fail for graphs in natural language settings?'' Motivated by these\nobservations, we embarked on an empirical study from the perspective of\nattention mechanisms to explore how LLMs process graph-structured data. The\ngoal is to gain deeper insights into the attention behavior of LLMs over graph\nstructures. We uncovered unique phenomena regarding how LLMs apply attention to\ngraph-structured data and analyzed these findings to improve the modeling of\nsuch data by LLMs. The primary findings of our research are: 1) While LLMs can\nrecognize graph data and capture text-node interactions, they struggle to model\ninter-node relationships within graph structures due to inherent architectural\nconstraints. 2) The attention distribution of LLMs across graph nodes does not\nalign with ideal structural patterns, indicating a failure to adapt to graph\ntopology nuances. 3) Neither fully connected attention nor fixed connectivity\nis optimal; each has specific limitations in its application scenarios.\nInstead, intermediate-state attention windows improve LLM training performance\nand seamlessly transition to fully connected windows during inference. Source\ncode: \\href{https://github.com/millioniron/LLM_exploration}{LLM4Exploration}", "published": "2025-05-04 14:40:31", "link": "http://arxiv.org/abs/2505.02130v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications", "abstract": "Solving non-convex resource allocation problems poses significant challenges\nin wireless communication systems, often beyond the capability of traditional\noptimization techniques. To address this issue, we propose LLM-OptiRA, the\nfirst framework that leverages large language models (LLMs) to automatically\ndetect and transform non-convex components into solvable forms, enabling fully\nautomated resolution of non-convex resource allocation problems in wireless\ncommunication systems. LLM-OptiRA not only simplifies problem-solving by\nreducing reliance on expert knowledge, but also integrates error correction and\nfeasibility validation mechanisms to ensure robustness. Experimental results\nshow that LLM-OptiRA achieves an execution rate of 96% and a success rate of\n80% on GPT-4, significantly outperforming baseline approaches in complex\noptimization tasks across diverse scenarios.", "published": "2025-05-04 12:53:04", "link": "http://arxiv.org/abs/2505.02091v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning", "abstract": "Evaluating the quality of slide-based multimedia instruction is challenging.\nExisting methods like manual assessment, reference-based metrics, and large\nlanguage model evaluators face limitations in scalability, context capture, or\nbias. In this paper, we introduce LecEval, an automated metric grounded in\nMayer's Cognitive Theory of Multimedia Learning, to evaluate multimodal\nknowledge acquisition in slide-based learning. LecEval assesses effectiveness\nusing four rubrics: Content Relevance (CR), Expressive Clarity (EC), Logical\nStructure (LS), and Audience Engagement (AE). We curate a large-scale dataset\nof over 2,000 slides from more than 50 online course videos, annotated with\nfine-grained human ratings across these rubrics. A model trained on this\ndataset demonstrates superior accuracy and adaptability compared to existing\nmetrics, bridging the gap between automated and human assessments. We release\nour dataset and toolkits at https://github.com/JoylimJY/LecEval.", "published": "2025-05-04 12:06:47", "link": "http://arxiv.org/abs/2505.02078v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "What do Language Model Probabilities Represent? From Distribution Estimation to Response Prediction", "abstract": "The notion of language modeling has gradually shifted in recent years from a\ndistribution over finite-length strings to general-purpose prediction models\nfor textual inputs and outputs, following appropriate alignment phases. This\npaper analyzes the distinction between distribution estimation and response\nprediction in the context of LLMs, and their often conflicting goals. We\nexamine the training phases of LLMs, which include pretraining, in-context\nlearning, and preference tuning, and also the common use cases for their output\nprobabilities, which include completion probabilities and explicit\nprobabilities as output. We argue that the different settings lead to three\ndistinct intended output distributions. We demonstrate that NLP works often\nassume that these distributions should be similar, which leads to\nmisinterpretations of their experimental findings. Our work sets firmer formal\nfoundations for the interpretation of LLMs, which will inform ongoing work on\nthe interpretation and use of LLMs' induced distributions.", "published": "2025-05-04 11:46:48", "link": "http://arxiv.org/abs/2505.02072v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An overview of artificial intelligence in computer-assisted language learning", "abstract": "Computer-assisted language learning -- CALL -- is an established research\nfield. We review how artificial intelligence can be applied to support language\nlearning and teaching. The need for intelligent agents that assist language\nlearners and teachers is increasing: the human teacher's time is a scarce and\ncostly resource, which does not scale with growing demand. Further factors\ncontribute to the need for CALL: pandemics and increasing demand for distance\nlearning, migration of large populations, the need for sustainable and\naffordable support for learning, etc. CALL systems are made up of many\ncomponents that perform various functions, and AI is applied to many different\naspects in CALL, corresponding to their own expansive research areas. Most of\nwhat we find in the research literature and in practical use are prototypes or\npartial implementations -- systems that perform some aspects of the overall\ndesired functionality. Complete solutions -- most of them commercial -- are\nfew, because they require massive resources. Recent advances in AI should\nresult in improvements in CALL, yet there is a lack of surveys that focus on AI\nin the context of this research field. This paper aims to present a perspective\non the AI methods that can be employed for language learning from a position of\na developer of a CALL system. We also aim to connect work from different\ndisciplines, to build bridges for interdisciplinary work.", "published": "2025-05-04 08:43:00", "link": "http://arxiv.org/abs/2505.02032v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs", "abstract": "Large language models (LLMs) have become integral to various real-world\napplications, leveraging massive, web-sourced datasets like Common Crawl, C4,\nand FineWeb for pretraining. While these datasets provide linguistic data\nessential for high-quality natural language generation, they often contain\nharmful content, such as hate speech, misinformation, and biased narratives.\nTraining LLMs on such unfiltered data risks perpetuating toxic behaviors,\nspreading misinformation, and amplifying societal biases which can undermine\ntrust in LLM-driven applications and raise ethical concerns about their use.\nThis paper presents a large-scale analysis of inappropriate content across\nthese datasets, offering a comprehensive taxonomy that categorizes harmful\nwebpages into Topical and Toxic based on their intent. We also introduce a\nprompt evaluation dataset, a high-accuracy Topical and Toxic Prompt (TTP), and\na transformer-based model (HarmFormer) for content filtering. Additionally, we\ncreate a new multi-harm open-ended toxicity benchmark (HAVOC) and provide\ncrucial insights into how models respond to adversarial toxic inputs. Upon\npublishing, we will also opensource our model signal on the entire C4 dataset.\nOur work offers insights into ensuring safer LLM pretraining and serves as a\nresource for Responsible AI (RAI) compliance.", "published": "2025-05-04 06:37:20", "link": "http://arxiv.org/abs/2505.02009v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM-based Text Simplification and its Effect on User Comprehension and Cognitive Load", "abstract": "Information on the web, such as scientific publications and Wikipedia, often\nsurpasses users' reading level. To help address this, we used a self-refinement\napproach to develop a LLM capability for minimally lossy text simplification.\nTo validate our approach, we conducted a randomized study involving 4563\nparticipants and 31 texts spanning 6 broad subject areas: PubMed (biomedical\nscientific articles), biology, law, finance, literature/philosophy, and\naerospace/computer science. Participants were randomized to viewing original or\nsimplified texts in a subject area, and answered multiple-choice questions\n(MCQs) that tested their comprehension of the text. The participants were also\nasked to provide qualitative feedback such as task difficulty. Our results\nindicate that participants who read the simplified text answered more MCQs\ncorrectly than their counterparts who read the original text (3.9% absolute\nincrease, p<0.05). This gain was most striking with PubMed (14.6%), while more\nmoderate gains were observed for finance (5.5%), aerospace/computer science\n(3.8%) domains, and legal (3.5%). Notably, the results were robust to whether\nparticipants could refer back to the text while answering MCQs. The absolute\naccuracy decreased by up to ~9% for both original and simplified setups where\nparticipants could not refer back to the text, but the ~4% overall improvement\npersisted. Finally, participants' self-reported perceived ease based on a\nsimplified NASA Task Load Index was greater for those who read the simplified\ntext (absolute change on a 5-point scale 0.33, p<0.05). This randomized study,\ninvolving an order of magnitude more participants than prior works,\ndemonstrates the potential of LLMs to make complex information easier to\nunderstand. Our work aims to enable a broader audience to better learn and make\nuse of expert knowledge available on the web, improving information\naccessibility.", "published": "2025-05-04 04:00:53", "link": "http://arxiv.org/abs/2505.01980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analyzing Cognitive Differences Among Large Language Models through the Lens of Social Worldview", "abstract": "Large Language Models (LLMs) have become integral to daily life, widely\nadopted in communication, decision-making, and information retrieval, raising\ncritical questions about how these systems implicitly form and express\nsocio-cognitive attitudes or \"worldviews\". While existing research extensively\naddresses demographic and ethical biases, broader dimensions-such as attitudes\ntoward authority, equality, autonomy, and fate-remain under-explored. In this\npaper, we introduce the Social Worldview Taxonomy (SWT), a structured framework\ngrounded in Cultural Theory, operationalizing four canonical worldviews\n(Hierarchy, Egalitarianism, Individualism, Fatalism) into measurable\nsub-dimensions. Using SWT, we empirically identify distinct and interpretable\ncognitive profiles across 28 diverse LLMs. Further, inspired by Social\nReferencing Theory, we experimentally demonstrate that explicit social cues\nsystematically shape these cognitive attitudes, revealing both general response\npatterns and nuanced model-specific variations. Our findings enhance the\ninterpretability of LLMs by revealing implicit socio-cognitive biases and their\nresponsiveness to social feedback, thus guiding the development of more\ntransparent and socially responsible language technologies.", "published": "2025-05-04 02:35:24", "link": "http://arxiv.org/abs/2505.01967v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models", "abstract": "Large Vision-Language Models (LVLMs) demonstrate remarkable capabilities in\nmultimodal tasks, but visual object hallucination remains a persistent issue.\nIt refers to scenarios where models generate inaccurate visual object-related\ninformation based on the query input, potentially leading to misinformation and\nconcerns about safety and reliability. Previous works focus on the evaluation\nand mitigation of visual hallucinations, but the underlying causes have not\nbeen comprehensively investigated. In this paper, we analyze each component of\nLLaVA-like LVLMs -- the large language model, the vision backbone, and the\nprojector -- to identify potential sources of error and their impact. Based on\nour observations, we propose methods to mitigate hallucination for each\nproblematic component. Additionally, we developed two hallucination benchmarks:\nQA-VisualGenome, which emphasizes attribute and relation hallucinations, and\nQA-FB15k, which focuses on cognition-based hallucinations.", "published": "2025-05-04 01:47:58", "link": "http://arxiv.org/abs/2505.01958v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Universal Approximation Theorem of Deep Q-Networks", "abstract": "We establish a continuous-time framework for analyzing Deep Q-Networks (DQNs)\nvia stochastic control and Forward-Backward Stochastic Differential Equations\n(FBSDEs). Considering a continuous-time Markov Decision Process (MDP) driven by\na square-integrable martingale, we analyze DQN approximation properties. We\nshow that DQNs can approximate the optimal Q-function on compact sets with\narbitrary accuracy and high probability, leveraging residual network\napproximation theorems and large deviation bounds for the state-action process.\nWe then analyze the convergence of a general Q-learning algorithm for training\nDQNs in this setting, adapting stochastic approximation theorems. Our analysis\nemphasizes the interplay between DQN layer count, time discretization, and the\nrole of viscosity solutions (primarily for the value function $V^*$) in\naddressing potential non-smoothness of the optimal Q-function. This work\nbridges deep reinforcement learning and stochastic control, offering insights\ninto DQNs in continuous-time settings, relevant for applications with physical\nsystems or high-frequency data.", "published": "2025-05-04 22:57:33", "link": "http://arxiv.org/abs/2505.02288v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Minimisation of Quasar-Convex Functions Using Random Zeroth-Order Oracles", "abstract": "This study explores the performance of a random Gaussian smoothing\nzeroth-order (ZO) scheme for minimising quasar-convex (QC) and strongly\nquasar-convex (SQC) functions in both unconstrained and constrained settings.\nFor the unconstrained problem, we establish the ZO algorithm's convergence to a\nglobal minimum along with its complexity when applied to both QC and SQC\nfunctions. For the constrained problem, we introduce the new notion of\nproximal-quasar-convexity and prove analogous results to the unconstrained\ncase. Specifically, we show the complexity bounds and the convergence of the\nalgorithm to a neighbourhood of a global minimum whose size can be controlled\nunder a variance reduction scheme. Theoretical findings are illustrated through\ninvestigating the performance of the algorithm applied to a range of problems\nin machine learning and optimisation. Specifically, we observe scenarios where\nthe ZO method outperforms gradient descent. We provide a possible explanation\nfor this phenomenon.", "published": "2025-05-04 22:43:57", "link": "http://arxiv.org/abs/2505.02281v1", "categories": ["math.OC", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)", "abstract": "Large language model (LLM)-powered autonomous agents demand robust,\nstandardized protocols to integrate tools, share contextual data, and\ncoordinate tasks across heterogeneous systems. Ad-hoc integrations are\ndifficult to scale, secure, and generalize across domains. This survey examines\nfour emerging agent communication protocols: Model Context Protocol (MCP),\nAgent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent\nNetwork Protocol (ANP), each addressing interoperability in distinct deployment\ncontexts. MCP provides a JSON-RPC client-server interface for secure tool\ninvocation and typed data exchange. ACP introduces REST-native messaging via\nmulti-part messages and asynchronous streaming to support multimodal agent\nresponses. A2A enables peer-to-peer task outsourcing through capability-based\nAgent Cards, facilitating enterprise-scale workflows. ANP supports open-network\nagent discovery and secure collaboration using decentralized identifiers (DIDs)\nand JSON-LD graphs. The protocols are compared across multiple dimensions,\nincluding interaction modes, discovery mechanisms, communication patterns, and\nsecurity models. Based on the comparative analysis, a phased adoption roadmap\nis proposed: beginning with MCP for tool access, followed by ACP for multimodal\nmessaging, A2A for collaborative task execution, and extending to ANP for\ndecentralized agent marketplaces. This work provides a comprehensive foundation\nfor designing secure, interoperable, and scalable ecosystems of LLM-powered\nagents.", "published": "2025-05-04 22:18:27", "link": "http://arxiv.org/abs/2505.02279v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On the Need for a Statistical Foundation in Scenario-Based Testing of Autonomous Vehicles", "abstract": "Scenario-based testing has emerged as a common method for autonomous vehicles\n(AVs) safety, offering a more efficient alternative to mile-based testing by\nfocusing on high-risk scenarios. However, fundamental questions persist\nregarding its stopping rules, residual risk estimation, debug effectiveness,\nand the impact of simulation fidelity on safety claims. This paper argues that\na rigorous statistical foundation is essential to address these challenges and\nenable rigorous safety assurance. By drawing parallels between AV testing and\ntraditional software testing methodologies, we identify shared research gaps\nand reusable solutions. We propose proof-of-concept models to quantify the\nprobability of failure per scenario (pfs) and evaluate testing effectiveness\nunder varying conditions. Our analysis reveals that neither scenario-based nor\nmile-based testing universally outperforms the other. Furthermore, we introduce\nRisk Estimation Fidelity (REF), a novel metric to certify the alignment of\nsynthetic and real-world testing outcomes, ensuring simulation-based safety\nclaims are statistically defensible.", "published": "2025-05-04 22:06:23", "link": "http://arxiv.org/abs/2505.02274v1", "categories": ["cs.SE", "cs.AI", "cs.RO"], "primary_category": "cs.SE"}
{"title": "Robust Localization, Mapping, and Navigation for Quadruped Robots", "abstract": "Quadruped robots are currently a widespread platform for robotics research,\nthanks to powerful Reinforcement Learning controllers and the availability of\ncheap and robust commercial platforms. However, to broaden the adoption of the\ntechnology in the real world, we require robust navigation stacks relying only\non low-cost sensors such as depth cameras. This paper presents a first step\ntowards a robust localization, mapping, and navigation system for low-cost\nquadruped robots. In pursuit of this objective we combine contact-aided\nkinematic, visual-inertial odometry, and depth-stabilized vision, enhancing\nstability and accuracy of the system. Our results in simulation and two\ndifferent real-world quadruped platforms show that our system can generate an\naccurate 2D map of the environment, robustly localize itself, and navigate\nautonomously. Furthermore, we present in-depth ablation studies of the\nimportant components of the system and their impact on localization accuracy.\nVideos, code, and additional experiments can be found on the project website:\nhttps://sites.google.com/view/low-cost-quadruped-slam", "published": "2025-05-04 21:58:11", "link": "http://arxiv.org/abs/2505.02272v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Real-time Spatial Retrieval Augmented Generation for Urban Environments", "abstract": "The proliferation of Generative Artificial Ingelligence (AI), especially\nLarge Language Models, presents transformative opportunities for urban\napplications through Urban Foundation Models. However, base models face\nlimitations, as they only contain the knowledge available at the time of\ntraining, and updating them is both time-consuming and costly. Retrieval\nAugmented Generation (RAG) has emerged in the literature as the preferred\napproach for injecting contextual information into Foundation Models. It\nprevails over techniques such as fine-tuning, which are less effective in\ndynamic, real-time scenarios like those found in urban environments. However,\ntraditional RAG architectures, based on semantic databases, knowledge graphs,\nstructured data, or AI-powered web searches, do not fully meet the demands of\nurban contexts. Urban environments are complex systems characterized by large\nvolumes of interconnected data, frequent updates, real-time processing\nrequirements, security needs, and strong links to the physical world. This work\nproposes a real-time spatial RAG architecture that defines the necessary\ncomponents for the effective integration of generative AI into cities,\nleveraging temporal and spatial filtering capabilities through linked data. The\nproposed architecture is implemented using FIWARE, an ecosystem of software\ncomponents to develop smart city solutions and digital twins. The design and\nimplementation are demonstrated through the use case of a tourism assistant in\nthe city of Madrid. The use case serves to validate the correct integration of\nFoundation Models through the proposed RAG architecture.", "published": "2025-05-04 21:57:58", "link": "http://arxiv.org/abs/2505.02271v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing AI Face Realism: Cost-Efficient Quality Improvement in Distilled Diffusion Models with a Fully Synthetic Dataset", "abstract": "This study presents a novel approach to enhance the cost-to-quality ratio of\nimage generation with diffusion models. We hypothesize that differences between\ndistilled (e.g. FLUX.1-schnell) and baseline (e.g. FLUX.1-dev) models are\nconsistent and, therefore, learnable within a specialized domain, like portrait\ngeneration. We generate a synthetic paired dataset and train a fast\nimage-to-image translation head. Using two sets of low- and high-quality\nsynthetic images, our model is trained to refine the output of a distilled\ngenerator (e.g., FLUX.1-schnell) to a level comparable to a baseline model like\nFLUX.1-dev, which is more computationally intensive. Our results show that the\npipeline, which combines a distilled version of a large generative model with\nour enhancement layer, delivers similar photorealistic portraits to the\nbaseline version with up to an 82% decrease in computational cost compared to\nFLUX.1-dev. This study demonstrates the potential for improving the efficiency\nof AI solutions involving large-scale image generation.", "published": "2025-05-04 21:28:21", "link": "http://arxiv.org/abs/2505.02255v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RISE: Radius of Influence based Subgraph Extraction for 3D Molecular Graph Explanation", "abstract": "3D Geometric Graph Neural Networks (GNNs) have emerged as transformative\ntools for modeling molecular data. Despite their predictive power, these models\noften suffer from limited interpretability, raising concerns for scientific\napplications that require reliable and transparent insights. While existing\nmethods have primarily focused on explaining molecular substructures in 2D\nGNNs, the transition to 3D GNNs introduces unique challenges, such as handling\nthe implicit dense edge structures created by a cut-off radius. To tackle this,\nwe introduce a novel explanation method specifically designed for 3D GNNs,\nwhich localizes the explanation to the immediate neighborhood of each node\nwithin the 3D space. Each node is assigned an radius of influence, defining the\nlocalized region within which message passing captures spatial and structural\ninteractions crucial for the model's predictions. This method leverages the\nspatial and geometric characteristics inherent in 3D graphs. By constraining\nthe subgraph to a localized radius of influence, the approach not only enhances\ninterpretability but also aligns with the physical and structural dependencies\ntypical of 3D graph applications, such as molecular learning.", "published": "2025-05-04 21:01:45", "link": "http://arxiv.org/abs/2505.02247v1", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Improving Physical Object State Representation in Text-to-Image Generative Systems", "abstract": "Current text-to-image generative models struggle to accurately represent\nobject states (e.g., \"a table without a bottle,\" \"an empty tumbler\"). In this\nwork, we first design a fully-automatic pipeline to generate high-quality\nsynthetic data that accurately captures objects in varied states. Next, we\nfine-tune several open-source text-to-image models on this synthetic data. We\nevaluate the performance of the fine-tuned models by quantifying the alignment\nof the generated images to their prompts using GPT4o-mini, and achieve an\naverage absolute improvement of 8+% across four models on the public\nGenAI-Bench dataset. We also curate a collection of 200 prompts with a specific\nfocus on common objects in various physical states. We demonstrate a\nsignificant improvement of an average of 24+% over the baseline on this\ndataset. We release all evaluation prompts and code.", "published": "2025-05-04 20:24:57", "link": "http://arxiv.org/abs/2505.02236v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Prompt-responsive Object Retrieval with Memory-augmented Student-Teacher Learning", "abstract": "Building models responsive to input prompts represents a transformative shift\nin machine learning. This paradigm holds significant potential for robotics\nproblems, such as targeted manipulation amidst clutter. In this work, we\npresent a novel approach to combine promptable foundation models with\nreinforcement learning (RL), enabling robots to perform dexterous manipulation\ntasks in a prompt-responsive manner. Existing methods struggle to link\nhigh-level commands with fine-grained dexterous control. We address this gap\nwith a memory-augmented student-teacher learning framework. We use the\nSegment-Anything 2 (SAM 2) model as a perception backbone to infer an object of\ninterest from user prompts. While detections are imperfect, their temporal\nsequence provides rich information for implicit state estimation by\nmemory-augmented models. Our approach successfully learns prompt-responsive\npolicies, demonstrated in picking objects from cluttered scenes. Videos and\ncode are available at https://memory-student-teacher.github.io", "published": "2025-05-04 19:51:09", "link": "http://arxiv.org/abs/2505.02232v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "The GenAI Generation: Student Views of Awareness, Preparedness, and Concern", "abstract": "Generative AI (GenAI) is revolutionizing education and workforce development,\nprofoundly shaping how students learn, engage, and prepare for their future.\nOutpacing the development of uniform policies and structures, GenAI has\nheralded a unique era and given rise to the GenAI Generation: a cohort of\nstudents whose education has been increasingly shaped by the opportunities and\nchallenges GenAI presents during its widespread adoption within society. This\nstudy examines our students' perceptions of GenAI through a concise survey with\noptional open-ended questions, focusing on their awareness, preparedness, and\nconcerns. Evaluation of more than 250 responses with more than 40% providing\ndetailed qualitative feedback reveals a core dual sentiment: while most\nstudents express enthusiasm for GenAI, an even greater proportion voice a\nspectrum of concerns about ethics, job displacement, and the adequacy of\neducational structures given the highly transformative technology. These\nfindings offer critical insights into how students view the potential and\npitfalls of GenAI for future career impacts, with accompanying recommendations\nto guide educational institutions in navigating a future driven by GenAI.", "published": "2025-05-04 19:37:13", "link": "http://arxiv.org/abs/2505.02230v1", "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning", "abstract": "Imitation Learning (IL) has achieved remarkable success across various\ndomains, including robotics, autonomous driving, and healthcare, by enabling\nagents to learn complex behaviors from expert demonstrations. However, existing\nIL methods often face instability challenges, particularly when relying on\nadversarial reward or value formulations in world model frameworks. In this\nwork, we propose a novel approach to online imitation learning that addresses\nthese limitations through a reward model based on random network distillation\n(RND) for density estimation. Our reward model is built on the joint estimation\nof expert and behavioral distributions within the latent space of the world\nmodel. We evaluate our method across diverse benchmarks, including DMControl,\nMeta-World, and ManiSkill2, showcasing its ability to deliver stable\nperformance and achieve expert-level results in both locomotion and\nmanipulation tasks. Our approach demonstrates improved stability over\nadversarial methods while maintaining expert-level performance.", "published": "2025-05-04 19:32:48", "link": "http://arxiv.org/abs/2505.02228v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "LLM-Guided Probabilistic Program Induction for POMDP Model Estimation", "abstract": "Partially Observable Markov Decision Processes (POMDPs) model decision making\nunder uncertainty. While there are many approaches to approximately solving\nPOMDPs, we aim to address the problem of learning such models. In particular,\nwe are interested in a subclass of POMDPs wherein the components of the model,\nincluding the observation function, reward function, transition function, and\ninitial state distribution function, can be modeled as low-complexity\nprobabilistic graphical models in the form of a short probabilistic program.\nOur strategy to learn these programs uses an LLM as a prior, generating\ncandidate probabilistic programs that are then tested against the empirical\ndistribution and adjusted through feedback. We experiment on a number of\nclassical toy POMDP problems, simulated MiniGrid domains, and two real\nmobile-base robotics search domains involving partial observability. Our\nresults show that using an LLM to guide in the construction of a low-complexity\nPOMDP model can be more effective than tabular POMDP learning, behavior\ncloning, or direct LLM planning.", "published": "2025-05-04 18:59:07", "link": "http://arxiv.org/abs/2505.02216v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Student Perspectives on the Benefits and Risks of AI in Education", "abstract": "The use of chatbots equipped with artificial intelligence (AI) in educational\nsettings has increased in recent years, showing potential to support teaching\nand learning. However, the adoption of these technologies has raised concerns\nabout their impact on academic integrity, students' ability to problem-solve\nindependently, and potential underlying biases. To better understand students'\nperspectives and experiences with these tools, a survey was conducted at a\nlarge public university in the United States. Through thematic analysis, 262\nundergraduate students' responses regarding their perceived benefits and risks\nof AI chatbots in education were identified and categorized into themes.\n  The results discuss several benefits identified by the students, with\nfeedback and study support, instruction capabilities, and access to information\nbeing the most cited. Their primary concerns included risks to academic\nintegrity, accuracy of information, loss of critical thinking skills, the\npotential development of overreliance, and ethical considerations such as data\nprivacy, system bias, environmental impact, and preservation of human elements\nin education.\n  While student perceptions align with previously discussed benefits and risks\nof AI in education, they show heightened concerns about distinguishing between\nhuman and AI generated work - particularly in cases where authentic work is\nflagged as AI-generated. To address students' concerns, institutions can\nestablish clear policies regarding AI use and develop curriculum around AI\nliteracy. With these in place, practitioners can effectively develop and\nimplement educational systems that leverage AI's potential in areas such as\nimmediate feedback and personalized learning support. This approach can enhance\nthe quality of students' educational experiences while preserving the integrity\nof the learning process with AI.", "published": "2025-05-04 17:36:11", "link": "http://arxiv.org/abs/2505.02198v1", "categories": ["cs.CY", "cs.AI", "cs.ET", "K.3; K.4"], "primary_category": "cs.CY"}
{"title": "DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization", "abstract": "Customized text-to-video generation with pre-trained large-scale models has\nrecently garnered significant attention through focusing on identity and motion\nconsistency. Existing works typically follow the isolated customized paradigm,\nwhere the subject identity or motion dynamics are customized exclusively.\nHowever, this paradigm completely ignores the intrinsic mutual constraints and\nsynergistic interdependencies between identity and motion, resulting in\nidentity-motion conflicts throughout the generation process that systematically\ndegrades. To address this, we introduce DualReal, a novel framework that,\nemploys adaptive joint training to collaboratively construct interdependencies\nbetween dimensions. Specifically, DualReal is composed of two units: (1)\nDual-aware Adaptation dynamically selects a training phase (i.e., identity or\nmotion), learns the current information guided by the frozen dimension prior,\nand employs a regularization strategy to avoid knowledge leakage; (2)\nStageBlender Controller leverages the denoising stages and Diffusion\nTransformer depths to guide different dimensions with adaptive granularity,\navoiding conflicts at various stages and ultimately achieving lossless fusion\nof identity and motion patterns. We constructed a more comprehensive benchmark\nthan existing methods. The experimental results show that DualReal improves\nCLIP-I and DINO-I metrics by 21.7% and 31.8% on average, and achieves top\nperformance on nearly all motion quality metrics.", "published": "2025-05-04 17:19:20", "link": "http://arxiv.org/abs/2505.02192v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Leveraging LLMs to Automate Energy-Aware Refactoring of Parallel Scientific Codes", "abstract": "While large language models (LLMs) are increasingly used for generating\nparallel scientific code, most current efforts emphasize functional\ncorrectness, often overlooking performance and energy considerations. In this\nwork, we propose LASSI-EE, an automated LLM-based refactoring framework that\ngenerates energy-efficient parallel code on a target parallel system for a\ngiven parallel code as input. Through a multi-stage, iterative pipeline\nprocess, LASSI-EE achieved an average energy reduction of 47% across 85% of the\n20 HeCBench benchmarks tested on NVIDIA A100 GPUs. Our findings demonstrate the\nbroader potential of LLMs, not only for generating correct code but also for\nenabling energy-aware programming. We also address key insights and limitations\nwithin the framework, offering valuable guidance for future improvements.", "published": "2025-05-04 17:05:34", "link": "http://arxiv.org/abs/2505.02184v1", "categories": ["cs.AI", "cs.DC", "cs.PL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Data-Driven Team Selection in Fantasy Premier League Using Integer Programming and Predictive Modeling Approach", "abstract": "Fantasy football is a billion-dollar industry with millions of participants.\nConstrained by a fixed budget, decision-makers draft a squad whose players are\nexpected to perform well in the upcoming weeks to maximize total points. This\npaper proposes novel deterministic and robust integer programming models that\nselect the optimal starting eleven and the captain. A new hybrid scoring metric\nis constructed using an interpretable artificial intelligence framework and\nunderlying match performance data. Several objective functions and estimation\ntechniques are introduced for the programming model. To the best of my\nknowledge, this is the first study to approach fantasy football through this\nlens. The models' performance is evaluated using data from the 2023/24 Premier\nLeague season. Results indicate that the proposed hybrid method achieved the\nhighest score while maintaining consistent performance. Utilizing the Monte\nCarlo simulation, the strategic choice of averaging techniques for estimating\ncost vectors, and the proposed hybrid approach are shown to be effective during\nthe out-of-sample period. This paper also provides a thorough analysis of the\noptimal formations and players selected by the models, offering valuable\ninsights into effective fantasy football strategies.", "published": "2025-05-04 16:21:59", "link": "http://arxiv.org/abs/2505.02170v1", "categories": ["cs.CE", "cs.AI", "cs.LG", "math.OC"], "primary_category": "cs.CE"}
{"title": "Pickup & Delivery with Time Windows and Transfers: combining decomposition with metaheuristics", "abstract": "This paper examines the generalisation of the Pickup and Delivery Problem\nthat allows mid-route load exchanges among vehicles and obeys strict\ntime-windows at all locations. We propose a novel Logic-Based Benders\nDecomposition (LBBD) that improves optimality gaps for all benchmarks in the\nliterature and scales up to handle larger ones. To tackle even larger\ninstances, we introduce a refined Large Neighborhood Search (LNS) algorithm\nthat improves the adaptability of LNS beyond case-specific configurations\nappearing in related literature.\n  To bridge the gap in benchmark availability, we develop an instance generator\nthat allows for extensive experimentation. For moderate datasets (25 and 50\nrequests), we evaluate the performance of both LBBD and LNS, the former being\nable to close the gap and the latter capable of providing near-optimal\nsolutions. For larger instances (75 and 100 requests), we recreate indicative\nstate-of-the-art metaheuristics to highlight the improvements introduced by our\nLNS refinements, while establishing its scalability.", "published": "2025-05-04 15:45:09", "link": "http://arxiv.org/abs/2505.02158v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "Interpreting Multilingual and Document-Length Sensitive Relevance Computations in Neural Retrieval Models through Axiomatic Causal Interventions", "abstract": "This reproducibility study analyzes and extends the paper \"Axiomatic Causal\nInterventions for Reverse Engineering Relevance Computation in Neural Retrieval\nModels,\" which investigates how neural retrieval models encode task-relevant\nproperties such as term frequency. We reproduce key experiments from the\noriginal paper, confirming that information on query terms is captured in the\nmodel encoding. We extend this work by applying activation patching to Spanish\nand Chinese datasets and by exploring whether document-length information is\nencoded in the model as well. Our results confirm that the designed activation\npatching method can isolate the behavior to specific components and tokens in\nneural retrieval models. Moreover, our findings indicate that the location of\nterm frequency generalizes across languages and that in later layers, the\ninformation for sequence-level tasks is represented in the CLS token. The\nresults highlight the need for further research into interpretability in\ninformation retrieval and reproducibility in machine learning research. Our\ncode is available at\nhttps://github.com/OliverSavolainen/axiomatic-ir-reproduce.", "published": "2025-05-04 15:30:45", "link": "http://arxiv.org/abs/2505.02154v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Representation Learning of Limit Order Book: A Comprehensive Study and Benchmarking", "abstract": "The Limit Order Book (LOB), the mostly fundamental data of the financial\nmarket, provides a fine-grained view of market dynamics while poses significant\nchallenges in dealing with the esteemed deep models due to its strong\nautocorrelation, cross-feature constrains, and feature scale disparity.\nExisting approaches often tightly couple representation learning with specific\ndownstream tasks in an end-to-end manner, failed to analyze the learned\nrepresentations individually and explicitly, limiting their reusability and\ngeneralization. This paper conducts the first systematic comparative study of\nLOB representation learning, aiming to identify the effective way of extracting\ntransferable, compact features that capture essential LOB properties. We\nintroduce LOBench, a standardized benchmark with real China A-share market\ndata, offering curated datasets, unified preprocessing, consistent evaluation\nmetrics, and strong baselines. Extensive experiments validate the sufficiency\nand necessity of LOB representations for various downstream tasks and highlight\ntheir advantages over both the traditional task-specific end-to-end models and\nthe advanced representation learning models for general time series. Our work\nestablishes a reproducible framework and provides clear guidelines for future\nresearch. Datasets and code will be publicly available at\nhttps://github.com/financial-simulation-lab/LOBench.", "published": "2025-05-04 15:00:00", "link": "http://arxiv.org/abs/2505.02139v1", "categories": ["cs.CE", "cs.AI"], "primary_category": "cs.CE"}
{"title": "Continuous Normalizing Flows for Uncertainty-Aware Human Pose Estimation", "abstract": "Human Pose Estimation (HPE) is increasingly important for applications like\nvirtual reality and motion analysis, yet current methods struggle with\nbalancing accuracy, computational efficiency, and reliable uncertainty\nquantification (UQ). Traditional regression-based methods assume fixed\ndistributions, which might lead to poor UQ. Heatmap-based methods effectively\nmodel the output distribution using likelihood heatmaps, however, they demand\nsignificant resources. To address this, we propose Continuous Flow Residual\nEstimation (CFRE), an integration of Continuous Normalizing Flows (CNFs) into\nregression-based models, which allows for dynamic distribution adaptation.\nThrough extensive experiments, we show that CFRE leads to better accuracy and\nuncertainty quantification with retained computational efficiency on both 2D\nand 3D human pose estimation tasks.", "published": "2025-05-04 22:55:01", "link": "http://arxiv.org/abs/2505.02287v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Compositional Image-Text Matching and Retrieval by Grounding Entities", "abstract": "Vision-language pretraining on large datasets of images-text pairs is one of\nthe main building blocks of current Vision-Language Models. While with\nadditional training, these models excel in various downstream tasks, including\nvisual question answering, image captioning, and visual commonsense reasoning.\nHowever, a notable weakness of pretrained models like CLIP, is their inability\nto perform entity grounding and compositional image and text\nmatching~\\cite{Jiang2024ComCLIP, yang2023amc, Rajabi2023GroundedVSR,\nlearninglocalizeCVPR24}. In this work we propose a novel learning-free\nzero-shot augmentation of CLIP embeddings that has favorable compositional\nproperties. We compute separate embeddings of sub-images of object entities and\nrelations that are localized by the state of the art open vocabulary detectors\nand dynamically adjust the baseline global image embedding. % The final\nembedding is obtained by computing a weighted combination of the sub-image\nembeddings. The resulting embedding is then utilized for similarity computation\nwith text embedding, resulting in a average 1.5\\% improvement in image-text\nmatching accuracy on the Visual Genome and SVO Probes\ndatasets~\\cite{krishna2017visualgenome, svo}. Notably, the enhanced embeddings\ndemonstrate superior retrieval performance, thus achieving significant gains on\nthe Flickr30K and MS-COCO retrieval benchmarks~\\cite{flickr30ke, mscoco},\nimproving the state-of-the-art Recall@1 by 12\\% and 0.4\\%, respectively. Our\ncode is available at https://github.com/madhukarreddyvongala/GroundingCLIP.", "published": "2025-05-04 22:18:14", "link": "http://arxiv.org/abs/2505.02278v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cricket: A Self-Powered Chirping Pixel", "abstract": "We present a sensor that can measure light and wirelessly communicate the\nmeasurement, without the need for an external power source or a battery. Our\nsensor, called cricket, harvests energy from incident light. It is asleep for\nmost of the time and transmits a short and strong radio frequency chirp when\nits harvested energy reaches a specific level. The carrier frequency of each\ncricket is fixed and reveals its identity, and the duration between consecutive\nchirps is a measure of the incident light level. We have characterized the\nradiometric response function, signal-to-noise ratio and dynamic range of\ncricket. We have experimentally verified that cricket can be miniaturized at\nthe expense of increasing the duration between chirps. We show that a cube with\na cricket on each of its sides can be used to estimate the centroid of any\ncomplex illumination, which has value in applications such as solar tracking.\nWe also demonstrate the use of crickets for creating untethered sensor arrays\nthat can produce video and control lighting for energy conservation. Finally,\nwe modified cricket's circuit to develop battery-free electronic sunglasses\nthat can instantly adapt to environmental illumination.", "published": "2025-05-04 21:00:14", "link": "http://arxiv.org/abs/2505.02246v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quantizing Diffusion Models from a Sampling-Aware Perspective", "abstract": "Diffusion models have recently emerged as the dominant approach in visual\ngeneration tasks. However, the lengthy denoising chains and the computationally\nintensive noise estimation networks hinder their applicability in low-latency\nand resource-limited environments. Previous research has endeavored to address\nthese limitations in a decoupled manner, utilizing either advanced samplers or\nefficient model quantization techniques. In this study, we uncover that\nquantization-induced noise disrupts directional estimation at each sampling\nstep, further distorting the precise directional estimations of higher-order\nsamplers when solving the sampling equations through discretized numerical\nmethods, thereby altering the optimal sampling trajectory. To attain dual\nacceleration with high fidelity, we propose a sampling-aware quantization\nstrategy, wherein a Mixed-Order Trajectory Alignment technique is devised to\nimpose a more stringent constraint on the error bounds at each sampling step,\nfacilitating a more linear probability flow. Extensive experiments on\nsparse-step fast sampling across multiple datasets demonstrate that our\napproach preserves the rapid convergence characteristics of high-speed samplers\nwhile maintaining superior generation quality. Code will be made publicly\navailable soon.", "published": "2025-05-04 20:50:44", "link": "http://arxiv.org/abs/2505.02242v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CSASN: A Multitask Attention-Based Framework for Heterogeneous Thyroid Carcinoma Classification in Ultrasound Images", "abstract": "Heterogeneous morphological features and data imbalance pose significant\nchallenges in rare thyroid carcinoma classification using ultrasound imaging.\nTo address this issue, we propose a novel multitask learning framework,\nChannel-Spatial Attention Synergy Network (CSASN), which integrates a\ndual-branch feature extractor - combining EfficientNet for local spatial\nencoding and ViT for global semantic modeling, with a cascaded channel-spatial\nattention refinement module. A residual multiscale classifier and dynamically\nweighted loss function further enhance classification stability and accuracy.\nTrained on a multicenter dataset comprising more than 2000 patients from four\nclinical institutions, our framework leverages a residual multiscale classifier\nand dynamically weighted loss function to enhance classification stability and\naccuracy. Extensive ablation studies demonstrate that each module contributes\nsignificantly to model performance, particularly in recognizing rare subtypes\nsuch as FTC and MTC carcinomas. Experimental results show that CSASN\noutperforms existing single-stream CNN or Transformer-based models, achieving a\nsuperior balance between precision and recall under class-imbalanced\nconditions. This framework provides a promising strategy for AI-assisted\nthyroid cancer diagnosis.", "published": "2025-05-04 18:23:03", "link": "http://arxiv.org/abs/2505.02211v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Robust AI-Generated Face Detection with Imbalanced Data", "abstract": "Deepfakes, created using advanced AI techniques such as Variational\nAutoencoder and Generative Adversarial Networks, have evolved from research and\nentertainment applications into tools for malicious activities, posing\nsignificant threats to digital trust. Current deepfake detection techniques\nhave evolved from CNN-based methods focused on local artifacts to more advanced\napproaches using vision transformers and multimodal models like CLIP, which\ncapture global anomalies and improve cross-domain generalization. Despite\nrecent progress, state-of-the-art deepfake detectors still face major\nchallenges in handling distribution shifts from emerging generative models and\naddressing severe class imbalance between authentic and fake samples in\ndeepfake datasets, which limits their robustness and detection accuracy. To\naddress these challenges, we propose a framework that combines dynamic loss\nreweighting and ranking-based optimization, which achieves superior\ngeneralization and performance under imbalanced dataset conditions. The code is\navailable at https://github.com/Purdue-M2/SP_CUP.", "published": "2025-05-04 17:02:10", "link": "http://arxiv.org/abs/2505.02182v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ProDisc-VAD: An Efficient System for Weakly-Supervised Anomaly Detection in Video Surveillance Applications", "abstract": "Weakly-supervised video anomaly detection (WS-VAD) using Multiple Instance\nLearning (MIL) suffers from label ambiguity, hindering discriminative feature\nlearning. We propose ProDisc-VAD, an efficient framework tackling this via two\nsynergistic components. The Prototype Interaction Layer (PIL) provides\ncontrolled normality modeling using a small set of learnable prototypes,\nestablishing a robust baseline without being overwhelmed by dominant normal\ndata. The Pseudo-Instance Discriminative Enhancement (PIDE) loss boosts\nseparability by applying targeted contrastive learning exclusively to the most\nreliable extreme-scoring instances (highest/lowest scores). ProDisc-VAD\nachieves strong AUCs (97.98% ShanghaiTech, 87.12% UCF-Crime) using only 0.4M\nparameters, over 800x fewer than recent ViT-based methods like VadCLIP,\ndemonstrating exceptional efficiency alongside state-of-the-art performance.\nCode is available at https://github.com/modadundun/ProDisc-VAD.", "published": "2025-05-04 16:42:15", "link": "http://arxiv.org/abs/2505.02179v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sparfels: Fast Reconstruction from Sparse Unposed Imagery", "abstract": "We present a method for Sparse view reconstruction with surface element\nsplatting that runs within 3 minutes on a consumer grade GPU. While few methods\naddress sparse radiance field learning from noisy or unposed sparse cameras,\nshape recovery remains relatively underexplored in this setting. Several\nradiance and shape learning test-time optimization methods address the sparse\nposed setting by learning data priors or using combinations of external\nmonocular geometry priors. Differently, we propose an efficient and simple\npipeline harnessing a single recent 3D foundation model. We leverage its\nvarious task heads, notably point maps and camera initializations to\ninstantiate a bundle adjusting 2D Gaussian Splatting (2DGS) model, and image\ncorrespondences to guide camera optimization midst 2DGS training. Key to our\ncontribution is a novel formulation of splatted color variance along rays,\nwhich can be computed efficiently. Reducing this moment in training leads to\nmore accurate shape reconstructions. We demonstrate state-of-the-art\nperformances in the sparse uncalibrated setting in reconstruction and novel\nview benchmarks based on established multi-view datasets.", "published": "2025-05-04 16:40:24", "link": "http://arxiv.org/abs/2505.02178v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Saliency-Guided Training for Fingerprint Presentation Attack Detection", "abstract": "Saliency-guided training, which directs model learning to important regions\nof images, has demonstrated generalization improvements across various\nbiometric presentation attack detection (PAD) tasks. This paper presents its\nfirst application to fingerprint PAD. We conducted a 50-participant study to\ncreate a dataset of 800 human-annotated fingerprint perceptually-important\nmaps, explored alongside algorithmically-generated \"pseudosaliency,\" including\nminutiae-based, image quality-based, and autoencoder-based saliency maps.\nEvaluating on the 2021 Fingerprint Liveness Detection Competition testing set,\nwe explore various configurations within five distinct training scenarios to\nassess the impact of saliency-guided training on accuracy and generalization.\nOur findings demonstrate the effectiveness of saliency-guided training for\nfingerprint PAD in both limited and large data contexts, and we present a\nconfiguration capable of earning the first place on the LivDet-2021 benchmark.\nOur results highlight saliency-guided training's promise for increased model\ngeneralization capabilities, its effectiveness when data is limited, and its\npotential to scale to larger datasets in fingerprint PAD. All collected\nsaliency data and trained models are released with the paper to support\nreproducible research.", "published": "2025-05-04 16:35:13", "link": "http://arxiv.org/abs/2505.02176v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SparSplat: Fast Multi-View Reconstruction with Generalizable 2D Gaussian Splatting", "abstract": "Recovering 3D information from scenes via multi-view stereo reconstruction\n(MVS) and novel view synthesis (NVS) is inherently challenging, particularly in\nscenarios involving sparse-view setups. The advent of 3D Gaussian Splatting\n(3DGS) enabled real-time, photorealistic NVS. Following this, 2D Gaussian\nSplatting (2DGS) leveraged perspective accurate 2D Gaussian primitive\nrasterization to achieve accurate geometry representation during rendering,\nimproving 3D scene reconstruction while maintaining real-time performance.\nRecent approaches have tackled the problem of sparse real-time NVS using 3DGS\nwithin a generalizable, MVS-based learning framework to regress 3D Gaussian\nparameters. Our work extends this line of research by addressing the challenge\nof generalizable sparse 3D reconstruction and NVS jointly, and manages to\nperform successfully at both tasks. We propose an MVS-based learning pipeline\nthat regresses 2DGS surface element parameters in a feed-forward fashion to\nperform 3D shape reconstruction and NVS from sparse-view images. We further\nshow that our generalizable pipeline can benefit from preexisting foundational\nmulti-view deep visual features. The resulting model attains the\nstate-of-the-art results on the DTU sparse 3D reconstruction benchmark in terms\nof Chamfer distance to ground-truth, as-well as state-of-the-art NVS. It also\ndemonstrates strong generalization on the BlendedMVS and Tanks and Temples\ndatasets. We note that our model outperforms the prior state-of-the-art in\nfeed-forward sparse view reconstruction based on volume rendering of implicit\nrepresentations, while offering an almost 2 orders of magnitude higher\ninference speed.", "published": "2025-05-04 16:33:47", "link": "http://arxiv.org/abs/2505.02175v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Focus What Matters: Matchability-Based Reweighting for Local Feature Matching", "abstract": "Since the rise of Transformers, many semi-dense matching methods have adopted\nattention mechanisms to extract feature descriptors. However, the attention\nweights, which capture dependencies between pixels or keypoints, are often\nlearned from scratch. This approach can introduce redundancy and noisy\ninteractions from irrelevant regions, as it treats all pixels or keypoints\nequally. Drawing inspiration from keypoint selection processes, we propose to\nfirst classify all pixels into two categories: matchable and non-matchable.\nMatchable pixels are expected to receive higher attention weights, while\nnon-matchable ones are down-weighted. In this work, we propose a novel\nattention reweighting mechanism that simultaneously incorporates a learnable\nbias term into the attention logits and applies a matchability-informed\nrescaling to the input value features. The bias term, injected prior to the\nsoftmax operation, selectively adjusts attention scores based on the confidence\nof query-key interactions. Concurrently, the feature rescaling acts\npost-attention by modulating the influence of each value vector in the final\noutput. This dual design allows the attention mechanism to dynamically adjust\nboth its internal weighting scheme and the magnitude of its output\nrepresentations. Extensive experiments conducted on three benchmark datasets\nvalidate the effectiveness of our method, consistently outperforming existing\nstate-of-the-art approaches.", "published": "2025-05-04 15:50:28", "link": "http://arxiv.org/abs/2505.02161v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Small Clips, Big Gains: Learning Long-Range Refocused Temporal Information for Video Super-Resolution", "abstract": "Video super-resolution (VSR) can achieve better performance compared to\nsingle image super-resolution by additionally leveraging temporal information.\nIn particular, the recurrent-based VSR model exploits long-range temporal\ninformation during inference and achieves superior detail restoration. However,\neffectively learning these long-term dependencies within long videos remains a\nkey challenge. To address this, we propose LRTI-VSR, a novel training framework\nfor recurrent VSR that efficiently leverages Long-Range Refocused Temporal\nInformation. Our framework includes a generic training strategy that utilizes\ntemporal propagation features from long video clips while training on shorter\nvideo clips. Additionally, we introduce a refocused intra&inter-frame\ntransformer block which allows the VSR model to selectively prioritize useful\ntemporal information through its attention module while further improving\ninter-frame information utilization in the FFN module. We evaluate LRTI-VSR on\nboth CNN and transformer-based VSR architectures, conducting extensive ablation\nstudies to validate the contribution of each component. Experiments on\nlong-video test sets demonstrate that LRTI-VSR achieves state-of-the-art\nperformance while maintaining training and computational efficiency.", "published": "2025-05-04 15:46:34", "link": "http://arxiv.org/abs/2505.02159v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spotting the Unexpected (STU): A 3D LiDAR Dataset for Anomaly Segmentation in Autonomous Driving", "abstract": "To operate safely, autonomous vehicles (AVs) need to detect and handle\nunexpected objects or anomalies on the road. While significant research exists\nfor anomaly detection and segmentation in 2D, research progress in 3D is\nunderexplored. Existing datasets lack high-quality multimodal data that are\ntypically found in AVs. This paper presents a novel dataset for anomaly\nsegmentation in driving scenarios. To the best of our knowledge, it is the\nfirst publicly available dataset focused on road anomaly segmentation with\ndense 3D semantic labeling, incorporating both LiDAR and camera data, as well\nas sequential information to enable anomaly detection across various ranges.\nThis capability is critical for the safe navigation of autonomous vehicles. We\nadapted and evaluated several baseline models for 3D segmentation, highlighting\nthe challenges of 3D anomaly detection in driving environments. Our dataset and\nevaluation code will be openly available, facilitating the testing and\nperformance comparison of different approaches.", "published": "2025-05-04 15:15:35", "link": "http://arxiv.org/abs/2505.02148v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Local Herb Identification Using Transfer Learning: A CNN-Powered Mobile Application for Nepalese Flora", "abstract": "Herb classification presents a critical challenge in botanical research,\nparticularly in regions with rich biodiversity such as Nepal. This study\nintroduces a novel deep learning approach for classifying 60 different herb\nspecies using Convolutional Neural Networks (CNNs) and transfer learning\ntechniques. Using a manually curated dataset of 12,000 herb images, we\ndeveloped a robust machine learning model that addresses existing limitations\nin herb recognition methodologies. Our research employed multiple model\narchitectures, including DenseNet121, 50-layer Residual Network (ResNet50),\n16-layer Visual Geometry Group Network (VGG16), InceptionV3, EfficientNetV2,\nand Vision Transformer (VIT), with DenseNet121 ultimately demonstrating\nsuperior performance. Data augmentation and regularization techniques were\napplied to mitigate overfitting and enhance the generalizability of the model.\nThis work advances herb classification techniques, preserving traditional\nbotanical knowledge and promoting sustainable herb utilization.", "published": "2025-05-04 15:14:44", "link": "http://arxiv.org/abs/2505.02147v1", "categories": ["cs.LG", "cs.CV", "I.4.9"], "primary_category": "cs.LG"}
{"title": "HiLLIE: Human-in-the-Loop Training for Low-Light Image Enhancement", "abstract": "Developing effective approaches to generate enhanced results that align well\nwith human visual preferences for high-quality well-lit images remains a\nchallenge in low-light image enhancement (LLIE). In this paper, we propose a\nhuman-in-the-loop LLIE training framework that improves the visual quality of\nunsupervised LLIE model outputs through iterative training stages, named\nHiLLIE. At each stage, we introduce human guidance into the training process\nthrough efficient visual quality annotations of enhanced outputs. Subsequently,\nwe employ a tailored image quality assessment (IQA) model to learn human visual\npreferences encoded in the acquired labels, which is then utilized to guide the\ntraining process of an enhancement model. With only a small amount of pairwise\nranking annotations required at each stage, our approach continually improves\nthe IQA model's capability to simulate human visual assessment of enhanced\noutputs, thus leading to visually appealing LLIE results. Extensive experiments\ndemonstrate that our approach significantly improves unsupervised LLIE model\nperformance in terms of both quantitative and qualitative performance. The code\nand collected ranking dataset will be available at\nhttps://github.com/LabShuHangGU/HiLLIE.", "published": "2025-05-04 14:44:37", "link": "http://arxiv.org/abs/2505.02134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GarmentGS: Point-Cloud Guided Gaussian Splatting for High-Fidelity Non-Watertight 3D Garment Reconstruction", "abstract": "Traditional 3D garment creation requires extensive manual operations,\nresulting in time and labor costs. Recently, 3D Gaussian Splatting has achieved\nbreakthrough progress in 3D scene reconstruction and rendering, attracting\nwidespread attention and opening new pathways for 3D garment reconstruction.\nHowever, due to the unstructured and irregular nature of Gaussian primitives,\nit is difficult to reconstruct high-fidelity, non-watertight 3D garments. In\nthis paper, we present GarmentGS, a dense point cloud-guided method that can\nreconstruct high-fidelity garment surfaces with high geometric accuracy and\ngenerate non-watertight, single-layer meshes. Our method introduces a fast\ndense point cloud reconstruction module that can complete garment point cloud\nreconstruction in 10 minutes, compared to traditional methods that require\nseveral hours. Furthermore, we use dense point clouds to guide the movement,\nflattening, and rotation of Gaussian primitives, enabling better distribution\non the garment surface to achieve superior rendering effects and geometric\naccuracy. Through numerical and visual comparisons, our method achieves fast\ntraining and real-time rendering while maintaining competitive quality.", "published": "2025-05-04 14:23:45", "link": "http://arxiv.org/abs/2505.02126v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unaligned RGB Guided Hyperspectral Image Super-Resolution with Spatial-Spectral Concordance", "abstract": "Hyperspectral images super-resolution aims to improve the spatial resolution,\nyet its performance is often limited at high-resolution ratios. The recent\nadoption of high-resolution reference images for super-resolution is driven by\nthe poor spatial detail found in low-resolution HSIs, presenting it as a\nfavorable method. However, these approaches cannot effectively utilize\ninformation from the reference image, due to the inaccuracy of alignment and\nits inadequate interaction between alignment and fusion modules. In this paper,\nwe introduce a Spatial-Spectral Concordance Hyperspectral Super-Resolution\n(SSC-HSR) framework for unaligned reference RGB guided HSI SR to address the\nissues of inaccurate alignment and poor interactivity of the previous\napproaches. Specifically, to ensure spatial concordance, i.e., align images\nmore accurately across resolutions and refine textures, we construct a\nTwo-Stage Image Alignment with a synthetic generation pipeline in the image\nalignment module, where the fine-tuned optical flow model can produce a more\naccurate optical flow in the first stage and warp model can refine damaged\ntextures in the second stage. To enhance the interaction between alignment and\nfusion modules and ensure spectral concordance during reconstruction, we\npropose a Feature Aggregation module and an Attention Fusion module. In the\nfeature aggregation module, we introduce an Iterative Deformable Feature\nAggregation block to achieve significant feature matching and texture\naggregation with the fusion multi-scale results guidance, iteratively\ngenerating learnable offset. Besides, we introduce two basic spectral-wise\nattention blocks in the attention fusion module to model the inter-spectra\ninteractions. Extensive experiments on three natural or remote-sensing datasets\nshow that our method outperforms state-of-the-art approaches on both\nquantitative and qualitative evaluations.", "published": "2025-05-04 13:29:31", "link": "http://arxiv.org/abs/2505.02109v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SignSplat: Rendering Sign Language via Gaussian Splatting", "abstract": "State-of-the-art approaches for conditional human body rendering via Gaussian\nsplatting typically focus on simple body motions captured from many views. This\nis often in the context of dancing or walking. However, for more complex use\ncases, such as sign language, we care less about large body motion and more\nabout subtle and complex motions of the hands and face. The problems of\nbuilding high fidelity models are compounded by the complexity of capturing\nmulti-view data of sign. The solution is to make better use of sequence data,\nensuring that we can overcome the limited information from only a few views by\nexploiting temporal variability. Nevertheless, learning from sequence-level\ndata requires extremely accurate and consistent model fitting to ensure that\nappearance is consistent across complex motions. We focus on how to achieve\nthis, constraining mesh parameters to build an accurate Gaussian splatting\nframework from few views capable of modelling subtle human motion. We leverage\nregularization techniques on the Gaussian parameters to mitigate overfitting\nand rendering artifacts. Additionally, we propose a new adaptive control method\nto densify Gaussians and prune splat points on the mesh surface. To demonstrate\nthe accuracy of our approach, we render novel sequences of sign language video,\nbuilding on neural machine translation approaches to sign stitching. On\nbenchmark datasets, our approach achieves state-of-the-art performance; and on\nhighly articulated and complex sign language motion, we significantly\noutperform competing approaches.", "published": "2025-05-04 13:28:49", "link": "http://arxiv.org/abs/2505.02108v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SkillMimic-V2: Learning Robust and Generalizable Interaction Skills from Sparse and Noisy Demonstrations", "abstract": "We address a fundamental challenge in Reinforcement Learning from Interaction\nDemonstration (RLID): demonstration noise and coverage limitations. While\nexisting data collection approaches provide valuable interaction\ndemonstrations, they often yield sparse, disconnected, and noisy trajectories\nthat fail to capture the full spectrum of possible skill variations and\ntransitions. Our key insight is that despite noisy and sparse demonstrations,\nthere exist infinite physically feasible trajectories that naturally bridge\nbetween demonstrated skills or emerge from their neighboring states, forming a\ncontinuous space of possible skill variations and transitions. Building upon\nthis insight, we present two data augmentation techniques: a Stitched\nTrajectory Graph (STG) that discovers potential transitions between\ndemonstration skills, and a State Transition Field (STF) that establishes\nunique connections for arbitrary states within the demonstration neighborhood.\nTo enable effective RLID with augmented data, we develop an Adaptive Trajectory\nSampling (ATS) strategy for dynamic curriculum generation and a historical\nencoding mechanism for memory-dependent skill learning. Our approach enables\nrobust skill acquisition that significantly generalizes beyond the reference\ndemonstrations. Extensive experiments across diverse interaction tasks\ndemonstrate substantial improvements over state-of-the-art methods in terms of\nconvergence stability, generalization capability, and recovery robustness.", "published": "2025-05-04 13:00:29", "link": "http://arxiv.org/abs/2505.02094v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "HandOcc: NeRF-based Hand Rendering with Occupancy Networks", "abstract": "We propose HandOcc, a novel framework for hand rendering based upon\noccupancy. Popular rendering methods such as NeRF are often combined with\nparametric meshes to provide deformable hand models. However, in doing so, such\napproaches present a trade-off between the fidelity of the mesh and the\ncomplexity and dimensionality of the parametric model. The simplicity of\nparametric mesh structures is appealing, but the underlying issue is that it\nbinds methods to mesh initialization, making it unable to generalize to objects\nwhere a parametric model does not exist. It also means that estimation is tied\nto mesh resolution and the accuracy of mesh fitting. This paper presents a\npipeline for meshless 3D rendering, which we apply to the hands. By providing\nonly a 3D skeleton, the desired appearance is extracted via a convolutional\nmodel. We do this by exploiting a NeRF renderer conditioned upon an\noccupancy-based representation. The approach uses the hand occupancy to resolve\nhand-to-hand interactions further improving results, allowing fast rendering,\nand excellent hand appearance transfer. On the benchmark InterHand2.6M dataset,\nwe achieved state-of-the-art results.", "published": "2025-05-04 12:06:54", "link": "http://arxiv.org/abs/2505.02079v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Benchmarking Feature Upsampling Methods for Vision Foundation Models using Interactive Segmentation", "abstract": "Vision Foundation Models (VFMs) are large-scale, pre-trained models that\nserve as general-purpose backbones for various computer vision tasks. As VFMs'\npopularity grows, there is an increasing interest in understanding their\neffectiveness for dense prediction tasks. However, VFMs typically produce\nlow-resolution features, limiting their direct applicability in this context.\nOne way to tackle this limitation is by employing a task-agnostic feature\nupsampling module that refines VFM features resolution. To assess the\neffectiveness of this approach, we investigate Interactive Segmentation (IS) as\na novel benchmark for evaluating feature upsampling methods on VFMs. Due to its\ninherent multimodal input, consisting of an image and a set of user-defined\nclicks, as well as its dense mask output, IS creates a challenging environment\nthat demands comprehensive visual scene understanding. Our benchmarking\nexperiments show that selecting appropriate upsampling strategies significantly\nimproves VFM features quality. The code is released at\nhttps://github.com/havrylovv/iSegProbe", "published": "2025-05-04 11:59:26", "link": "http://arxiv.org/abs/2505.02075v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning", "abstract": "We propose the Compact Clustering Attention (COCA) layer, an effective\nbuilding block that introduces a hierarchical strategy for object-centric\nrepresentation learning, while solving the unsupervised object discovery task\non single images. COCA is an attention-based clustering module capable of\nextracting object-centric representations from multi-object scenes, when\ncascaded into a bottom-up hierarchical network architecture, referred to as\nCOCA-Net. At its core, COCA utilizes a novel clustering algorithm that\nleverages the physical concept of compactness, to highlight distinct object\ncentroids in a scene, providing a spatial inductive bias. Thanks to this\nstrategy, COCA-Net generates high-quality segmentation masks on both the\ndecoder side and, notably, the encoder side of its pipeline. Additionally,\nCOCA-Net is not bound by a predetermined number of object masks that it\ngenerates and handles the segmentation of background elements better than its\ncompetitors. We demonstrate COCA-Net's segmentation performance on six widely\nadopted datasets, achieving superior or competitive results against the\nstate-of-the-art models across nine different evaluation metrics.", "published": "2025-05-04 11:42:04", "link": "http://arxiv.org/abs/2505.02071v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video", "abstract": "Multimodal Large Language Models (MLLMs) increasingly excel at perception,\nunderstanding, and reasoning. However, current benchmarks inadequately evaluate\ntheir ability to perform these tasks continuously in dynamic, real-world\nenvironments. To bridge this gap, we introduce RTV-Bench, a fine-grained\nbenchmark for MLLM real-time video analysis. RTV-Bench uses three key\nprinciples: (1) Multi-Timestamp Question Answering (MTQA), where answers evolve\nwith scene changes; (2) Hierarchical Question Structure, combining basic and\nadvanced queries; and (3) Multi-dimensional Evaluation, assessing the ability\nof continuous perception, understanding, and reasoning. RTV-Bench contains 552\ndiverse videos (167.2 hours) and 4,631 high-quality QA pairs. We evaluated\nleading MLLMs, including proprietary (GPT-4o, Gemini 2.0), open-source offline\n(Qwen2.5-VL, VideoLLaMA3), and open-source real-time (VITA-1.5,\nInternLM-XComposer2.5-OmniLive) models. Experiment results show open-source\nreal-time models largely outperform offline ones but still trail top\nproprietary models. Our analysis also reveals that larger model size or higher\nframe sampling rates do not significantly boost RTV-Bench performance,\nsometimes causing slight decreases. This underscores the need for better model\narchitectures optimized for video stream processing and long sequences to\nadvance real-time video analysis with MLLMs. Our benchmark toolkit is available\nat: https://github.com/LJungang/RTV-Bench.", "published": "2025-05-04 10:55:21", "link": "http://arxiv.org/abs/2505.02064v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Transforming faces into video stories -- VideoFace2.0", "abstract": "Face detection and face recognition have been in the focus of vision\ncommunity since the very beginnings. Inspired by the success of the original\nVideoface digitizer, a pioneering device that allowed users to capture video\nsignals from any source, we have designed an advanced video analytics tool to\nefficiently create structured video stories, i.e. identity-based information\ncatalogs. VideoFace2.0 is the name of the developed system for spatial and\ntemporal localization of each unique face in the input video, i.e. face\nre-identification (ReID), which also allows their cataloging, characterization\nand creation of structured video outputs for later downstream tasks. Developed\nnear real-time solution is primarily designed to be utilized in application\nscenarios involving TV production, media analysis, and as an efficient tool for\ncreating large video datasets necessary for training machine learning (ML)\nmodels in challenging vision tasks such as lip reading and multimodal speech\nrecognition. Conducted experiments confirm applicability of the proposed face\nReID algorithm that is combining the concepts of face detection, face\nrecognition and passive tracking-by-detection in order to achieve robust and\nefficient face ReID. The system is envisioned as a compact and modular\nextensions of the existing video production equipment. We hope that the\npresented work and shared code will stimulate further interest in development\nof similar, application specific video analysis tools, and lower the entry\nbarrier for production of high-quality multi-modal ML datasets in the future.", "published": "2025-05-04 10:36:58", "link": "http://arxiv.org/abs/2505.02060v1", "categories": ["cs.CV", "68T07, 68T45, 68U10, 94A08, 68T05,", "I.2.10; I.5.4; I.5.5; I.4.8; C.3; J.7"], "primary_category": "cs.CV"}
{"title": "Handling Imbalanced Pseudolabels for Vision-Language Models with Concept Alignment and Confusion-Aware Calibrated Margin", "abstract": "Adapting vision-language models (VLMs) to downstream tasks with pseudolabels\nhas gained increasing attention. A major obstacle is that the pseudolabels\ngenerated by VLMs tend to be imbalanced, leading to inferior performance. While\nexisting methods have explored various strategies to address this, the\nunderlying causes of imbalance remain insufficiently investigated. To fill this\ngap, we delve into imbalanced pseudolabels and identify two primary\ncontributing factors: concept mismatch and concept confusion. To mitigate these\ntwo issues, we propose a novel framework incorporating concept alignment and\nconfusion-aware calibrated margin mechanisms. The core of our approach lies in\nenhancing underperforming classes and promoting balanced predictions across\ncategories, thus mitigating imbalance. Extensive experiments on six benchmark\ndatasets with three learning paradigms demonstrate that the proposed method\neffectively enhances the accuracy and balance of pseudolabels, achieving a\nrelative improvement of 6.29% over the SoTA method. Our code is avaliable at\nhttps://anonymous.4open.science/r/CAP-C642/", "published": "2025-05-04 10:24:34", "link": "http://arxiv.org/abs/2505.02056v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TxP: Reciprocal Generation of Ground Pressure Dynamics and Activity Descriptions for Improving Human Activity Recognition", "abstract": "Sensor-based human activity recognition (HAR) has predominantly focused on\nInertial Measurement Units and vision data, often overlooking the capabilities\nunique to pressure sensors, which capture subtle body dynamics and shifts in\nthe center of mass. Despite their potential for postural and balance-based\nactivities, pressure sensors remain underutilized in the HAR domain due to\nlimited datasets. To bridge this gap, we propose to exploit generative\nfoundation models with pressure-specific HAR techniques. Specifically, we\npresent a bidirectional Text$\\times$Pressure model that uses generative\nfoundation models to interpret pressure data as natural language. TxP\naccomplishes two tasks: (1) Text2Pressure, converting activity text\ndescriptions into pressure sequences, and (2) Pressure2Text, generating\nactivity descriptions and classifications from dynamic pressure maps.\nLeveraging pre-trained models like CLIP and LLaMA 2 13B Chat, TxP is trained on\nour synthetic PressLang dataset, containing over 81,100 text-pressure pairs.\nValidated on real-world data for activities such as yoga and daily tasks, TxP\nprovides novel approaches to data augmentation and classification grounded in\natomic actions. This consequently improved HAR performance by up to 12.4\\% in\nmacro F1 score compared to the state-of-the-art, advancing pressure-based HAR\nwith broader applications and deeper insights into human movement.", "published": "2025-05-04 10:07:38", "link": "http://arxiv.org/abs/2505.02052v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Regression s all you need for medical image translation", "abstract": "The acquisition of information-rich images within a limited time budget is\ncrucial in medical imaging. Medical image translation (MIT) can help enhance\nand supplement existing datasets by generating synthetic images from acquired\ndata. While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have\nachieved remarkable success in natural image generation, their benefits -\ncreativity and image realism - do not necessarily transfer to medical\napplications where highly accurate anatomical information is required. In fact,\nthe imitation of acquisition noise or content hallucination hinder clinical\nutility. Here, we introduce YODA (You Only Denoise once - or Average), a novel\n2.5D diffusion-based framework for volumetric MIT. YODA unites diffusion and\nregression paradigms to produce realistic or noise-free outputs. Furthermore,\nwe propose Expectation-Approximation (ExpA) DM sampling, which draws\ninspiration from MRI signal averaging. ExpA-sampling suppresses generated noise\nand, thus, eliminates noise from biasing the evaluation of image quality.\nThrough extensive experiments on four diverse multi-modal datasets - comprising\nmulti-contrast brain MRI and pelvic MRI-CT - we show that diffusion and\nregression sampling yield similar results in practice. As such, the\ncomputational overhead of diffusion sampling does not provide systematic\nbenefits in medical information translation. Building on these insights, we\ndemonstrate that YODA outperforms several state-of-the-art GAN and DM methods.\nNotably, YODA-generated images are shown to be interchangeable with, or even\nsuperior to, physical acquisitions for several downstream tasks. Our findings\nchallenge the presumed advantages of DMs in MIT and pave the way for the\npractical application of MIT in medical imaging.", "published": "2025-05-04 09:57:10", "link": "http://arxiv.org/abs/2505.02048v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A UNet Model for Accelerated Preprocessing of CRISM Hyperspectral Data for Mineral Identification on Mars", "abstract": "Accurate mineral identification on the Martian surface is critical for\nunderstanding the planet's geological history. This paper presents a UNet-based\nautoencoder model for efficient spectral preprocessing of CRISM MTRDR\nhyperspectral data, addressing the limitations of traditional methods that are\ncomputationally intensive and time-consuming. The proposed model automates key\npreprocessing steps, such as smoothing and continuum removal, while preserving\nessential mineral absorption features. Trained on augmented spectra from the\nMICA spectral library, the model introduces realistic variability to simulate\nMTRDR data conditions. By integrating this framework, preprocessing time for an\n800x800 MTRDR scene is reduced from 1.5 hours to just 5 minutes on an NVIDIA\nT1600 GPU. The preprocessed spectra are subsequently classified using MICAnet,\na deep learning model for Martian mineral identification. Evaluation on labeled\nCRISM TRDR data demonstrates that the proposed approach achieves competitive\naccuracy while significantly enhancing preprocessing efficiency. This work\nhighlights the potential of the UNet-based preprocessing framework to improve\nthe speed and reliability of mineral mapping on Mars.", "published": "2025-05-04 09:54:11", "link": "http://arxiv.org/abs/2505.02046v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Point2Primitive: CAD Reconstruction from Point Cloud by Direct Primitive Prediction", "abstract": "Recovering CAD models from point clouds, especially the sketch-extrusion\nprocess, can be seen as the process of rebuilding the topology and extrusion\nprimitives. Previous methods utilize implicit fields for sketch representation,\nleading to shape reconstruction of curved edges. In this paper, we proposed a\nCAD reconstruction network that produces editable CAD models from input point\nclouds (Point2Primitive) by directly predicting every element of the extrusion\nprimitives. Point2Primitive can directly detect and predict sketch curves (type\nand parameter) from point clouds based on an improved transformer. The sketch\ncurve parameters are formulated as position queries and optimized in an\nautoregressive way, leading to high parameter accuracy. The topology is rebuilt\nby extrusion segmentation, and each extrusion parameter (sketch and extrusion\noperation) is recovered by combining the predicted curves and the computed\nextrusion operation. Extensive experiments demonstrate that our method is\nsuperior in primitive prediction accuracy and CAD reconstruction. The\nreconstructed shapes are of high geometrical fidelity.", "published": "2025-05-04 09:42:03", "link": "http://arxiv.org/abs/2505.02043v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Birotation Solution for Relative Pose Problems", "abstract": "Relative pose estimation, a fundamental computer vision problem, has been\nextensively studied for decades. Existing methods either estimate and decompose\nthe essential matrix or directly estimate the rotation and translation to\nobtain the solution. In this article, we break the mold by tackling this\ntraditional problem with a novel birotation solution. We first introduce three\nbasis transformations, each associated with a geometric metric to quantify the\ndistance between the relative pose to be estimated and its corresponding basis\ntransformation. Three energy functions, designed based on these metrics, are\nthen minimized on the Riemannian manifold $\\mathrm{SO(3)}$ by iteratively\nupdating the two rotation matrices. The two rotation matrices and the basis\ntransformation corresponding to the minimum energy are ultimately utilized to\nrecover the relative pose. Extensive quantitative and qualitative evaluations\nacross diverse relative pose estimation tasks demonstrate the superior\nperformance of our proposed birotation solution. Source code, demo video, and\ndatasets will be available at\n\\href{https://mias.group/birotation-solution}{mias.group/birotation-solution}\nupon publication.", "published": "2025-05-04 08:24:14", "link": "http://arxiv.org/abs/2505.02025v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation", "abstract": "Reasoning stands as a cornerstone of intelligence, enabling the synthesis of\nexisting knowledge to solve complex problems. Despite remarkable progress,\nexisting reasoning benchmarks often fail to rigorously evaluate the nuanced\nreasoning capabilities required for complex, real-world problemsolving,\nparticularly in multi-disciplinary and multimodal contexts. In this paper, we\nintroduce a graduate-level, multi-disciplinary, EnglishChinese benchmark,\ndubbed as Reasoning Bench (R-Bench), for assessing the reasoning capability of\nboth language and multimodal models. RBench spans 1,094 questions across 108\nsubjects for language model evaluation and 665 questions across 83 subjects for\nmultimodal model testing in both English and Chinese. These questions are\nmeticulously curated to ensure rigorous difficulty calibration, subject\nbalance, and crosslinguistic alignment, enabling the assessment to be an\nOlympiad-level multi-disciplinary benchmark. We evaluate widely used models,\nincluding OpenAI o1, GPT-4o, DeepSeek-R1, etc. Experimental results indicate\nthat advanced models perform poorly on complex reasoning, especially multimodal\nreasoning. Even the top-performing model OpenAI o1 achieves only 53.2% accuracy\non our multimodal evaluation. Data and code are made publicly available at\nhere.", "published": "2025-05-04 07:48:36", "link": "http://arxiv.org/abs/2505.02018v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MLLM-Enhanced Face Forgery Detection: A Vision-Language Fusion Solution", "abstract": "Reliable face forgery detection algorithms are crucial for countering the\ngrowing threat of deepfake-driven disinformation. Previous research has\ndemonstrated the potential of Multimodal Large Language Models (MLLMs) in\nidentifying manipulated faces. However, existing methods typically depend on\neither the Large Language Model (LLM) alone or an external detector to generate\nclassification results, which often leads to sub-optimal integration of visual\nand textual modalities. In this paper, we propose VLF-FFD, a novel\nVision-Language Fusion solution for MLLM-enhanced Face Forgery Detection. Our\nkey contributions are twofold. First, we present EFF++, a frame-level,\nexplainability-driven extension of the widely used FaceForensics++ (FF++)\ndataset. In EFF++, each manipulated video frame is paired with a textual\nannotation that describes both the forgery artifacts and the specific\nmanipulation technique applied, enabling more effective and informative MLLM\ntraining. Second, we design a Vision-Language Fusion Network (VLF-Net) that\npromotes bidirectional interaction between visual and textual features,\nsupported by a three-stage training pipeline to fully leverage its potential.\nVLF-FFD achieves state-of-the-art (SOTA) performance in both cross-dataset and\nintra-dataset evaluations, underscoring its exceptional effectiveness in face\nforgery detection.", "published": "2025-05-04 06:58:21", "link": "http://arxiv.org/abs/2505.02013v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Noise Calculation in Deep Learning-based MRI Reconstructions", "abstract": "Accelerated MRI reconstruction involves solving an ill-posed inverse problem\nwhere noise in acquired data propagates to the reconstructed images. Noise\nanalyses are central to MRI reconstruction for providing an explicit measure of\nsolution fidelity and for guiding the design and deployment of novel\nreconstruction methods. However, deep learning (DL)-based reconstruction\nmethods have often overlooked noise propagation due to inherent analytical and\ncomputational challenges, despite its critical importance. This work proposes a\ntheoretically grounded, memory-efficient technique to calculate voxel-wise\nvariance for quantifying uncertainty due to acquisition noise in accelerated\nMRI reconstructions. Our approach approximates noise covariance using the DL\nnetwork's Jacobian, which is intractable to calculate. To circumvent this, we\nderive an unbiased estimator for the diagonal of this covariance matrix\n(voxel-wise variance) and introduce a Jacobian sketching technique to\nefficiently implement it. We evaluate our method on knee and brain MRI datasets\nfor both data- and physics-driven networks trained in supervised and\nunsupervised manners. Compared to empirical references obtained via Monte Carlo\nsimulations, our technique achieves near-equivalent performance while reducing\ncomputational and memory demands by an order of magnitude or more. Furthermore,\nour method is robust across varying input noise levels, acceleration factors,\nand diverse undersampling schemes, highlighting its broad applicability. Our\nwork reintroduces accurate and efficient noise analysis as a central tenet of\nreconstruction algorithms, holding promise to reshape how we evaluate and\ndeploy DL-based MRI. Our code will be made publicly available upon acceptance.", "published": "2025-05-04 06:28:06", "link": "http://arxiv.org/abs/2505.02007v1", "categories": ["cs.CV", "65C60, 94A08, 68T07", "I.4.5; I.2.10; G.1.2"], "primary_category": "cs.CV"}
{"title": "Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields", "abstract": "Recent NeRF methods on large-scale scenes have underlined the importance of\nscene decomposition for scalable NeRFs. Although achieving reasonable\nscalability, there are several critical problems remaining unexplored, i.e.,\nlearnable decomposition, modeling scene heterogeneity, and modeling efficiency.\nIn this paper, we introduce Switch-NeRF++, a Heterogeneous Mixture of Hash\nExperts (HMoHE) network that addresses these challenges within a unified\nframework. It is a highly scalable NeRF that learns heterogeneous decomposition\nand heterogeneous NeRFs efficiently for large-scale scenes in an end-to-end\nmanner. In our framework, a gating network learns to decomposes scenes and\nallocates 3D points to specialized NeRF experts. This gating network is\nco-optimized with the experts, by our proposed Sparsely Gated Mixture of\nExperts (MoE) NeRF framework. We incorporate a hash-based gating network and\ndistinct heterogeneous hash experts. The hash-based gating efficiently learns\nthe decomposition of the large-scale scene. The distinct heterogeneous hash\nexperts consist of hash grids of different resolution ranges, enabling\neffective learning of the heterogeneous representation of different scene\nparts. These design choices make our framework an end-to-end and highly\nscalable NeRF solution for real-world large-scale scene modeling to achieve\nboth quality and efficiency. We evaluate our accuracy and scalability on\nexisting large-scale NeRF datasets and a new dataset with very large-scale\nscenes ($>6.5km^2$) from UrbanBIS. Extensive experiments demonstrate that our\napproach can be easily scaled to various large-scale scenes and achieve\nstate-of-the-art scene rendering accuracy. Furthermore, our method exhibits\nsignificant efficiency, with an 8x acceleration in training and a 16x\nacceleration in rendering compared to Switch-NeRF. Codes will be released in\nhttps://github.com/MiZhenxing/Switch-NeRF.", "published": "2025-05-04 06:25:14", "link": "http://arxiv.org/abs/2505.02005v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hybrid Image Resolution Quality Metric (HIRQM):A Comprehensive Perceptual Image Quality Assessment Framework", "abstract": "Traditional image quality assessment metrics like Mean Squared Error and\nStructural Similarity Index often fail to reflect perceptual quality under\ncomplex distortions. We propose the Hybrid Image Resolution Quality Metric\n(HIRQM), integrating statistical, multi-scale, and deep learning-based methods\nfor a comprehensive quality evaluation. HIRQM combines three components:\nProbability Density Function for local pixel distribution analysis, Multi-scale\nFeature Similarity for structural integrity across resolutions, and\nHierarchical Deep Image Features using a pre-trained VGG16 network for semantic\nalignment with human perception. A dynamic weighting mechanism adapts component\ncontributions based on image characteristics like brightness and variance,\nenhancing flexibility across distortion types. Our contributions include a\nunified metric and dynamic weighting for better perceptual alignment. Evaluated\non TID2013 and LIVE datasets, HIRQM achieves Pearson and Spearman correlations\nof 0.92 and 0.90, outperforming traditional metrics. It excels in handling\nnoise, blur, and compression artifacts, making it valuable for image processing\napplications like compression and restoration.", "published": "2025-05-04 06:14:10", "link": "http://arxiv.org/abs/2505.02001v1", "categories": ["eess.IV", "cs.CV", "94A08", "I.4.0; I.4.9; I.2.10"], "primary_category": "eess.IV"}
{"title": "Always Skip Attention", "abstract": "We highlight a curious empirical result within modern Vision Transformers\n(ViTs). Specifically, self-attention catastrophically fails to train unless it\nis used in conjunction with a skip connection. This is in contrast to other\nelements of a ViT that continue to exhibit good performance (albeit suboptimal)\nwhen skip connections are removed. Further, we show that this critical\ndependence on skip connections is a relatively new phenomenon, with previous\ndeep architectures (\\eg, CNNs) exhibiting good performance in their absence. In\nthis paper, we theoretically characterize that the self-attention mechanism is\nfundamentally ill-conditioned and is, therefore, uniquely dependent on skip\nconnections for regularization. Additionally, we propose Token Graying -- a\nsimple yet effective complement (to skip connections) that further improves the\ncondition of input tokens. We validate our approach in both supervised and\nself-supervised training methods.", "published": "2025-05-04 05:42:21", "link": "http://arxiv.org/abs/2505.01996v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Drug classification based on X-ray spectroscopy combined with machine learning", "abstract": "The proliferation of new types of drugs necessitates the urgent development\nof faster and more accurate detection methods. Traditional detection methods\nhave high requirements for instruments and environments, making the operation\ncomplex. X-ray absorption spectroscopy, a non-destructive detection technique,\noffers advantages such as ease of operation, penetrative observation, and\nstrong substance differentiation capabilities, making it well-suited for\napplication in the field of drug detection and identification. In this study,\nwe constructed a classification model using Convolutional Neural Networks\n(CNN), Support Vector Machines (SVM), and Particle Swarm Optimization (PSO) to\nclassify and identify drugs based on their X-ray spectral profiles. In the\nexperiments, we selected 14 chemical reagents with chemical formulas similar to\ndrugs as samples. We utilized CNN to extract features from the spectral data of\nthese 14 chemical reagents and used the extracted features to train an SVM\nmodel. We also utilized PSO to optimize two critical initial parameters of the\nSVM. The experimental results demonstrate that this model achieved higher\nclassification accuracy compared to two other common methods, with a prediction\naccuracy of 99.14%. Additionally, the model exhibited fast execution speed,\nmitigating the drawback of a drastic increase in running time and efficiency\nreduction that may result from the direct fusion of PSO and SVM. Therefore, the\ncombined approach of X-ray absorption spectroscopy with CNN, PSO, and SVM\nprovides a rapid, highly accurate, and reliable classification and\nidentification method for the field of drug detection, holding promising\nprospects for widespread application.", "published": "2025-05-04 04:49:55", "link": "http://arxiv.org/abs/2505.01986v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Lifelong Whole Slide Image Analysis: Online Vision-Language Adaptation and Past-to-Present Gradient Distillation", "abstract": "Whole Slide Images (WSIs) play a crucial role in accurate cancer diagnosis\nand prognosis, as they provide tissue details at the cellular level. However,\nthe rapid growth of computational tasks involving WSIs poses significant\nchallenges. Given that WSIs are gigapixels in size, they present difficulties\nin terms of storage, processing, and model training. Therefore, it is essential\nto develop lifelong learning approaches for WSI analysis. In scenarios where\nslides are distributed across multiple institutes, we aim to leverage them to\ndevelop a unified online model as a computational tool for cancer diagnosis in\nclinical and hospital settings. In this study, we introduce ADaFGrad, a method\ndesigned to enhance lifelong learning for whole-slide image (WSI) analysis.\nFirst, we leverage pathology vision-language foundation models to develop a\nframework that enables interaction between a slide's regional tissue features\nand a predefined text-based prototype buffer. Additionally, we propose a\ngradient-distillation mechanism that mimics the gradient of a logit with\nrespect to the classification-head parameters across past and current\niterations in a continual-learning setting. We construct a sequence of six TCGA\ndatasets for training and evaluation. Experimental results show that ADaFGrad\noutperforms both state-of-the-art WSI-specific and conventional\ncontinual-learning methods after only a few training epochs, exceeding them by\nup to +5.068% in the class-incremental learning scenario while exhibiting the\nleast forgetting (i.e., retaining the most knowledge from previous tasks).\nMoreover, ADaFGrad surpasses its baseline by as much as +40.084% in accuracy,\nfurther demonstrating the effectiveness of the proposed modules.", "published": "2025-05-04 04:46:08", "link": "http://arxiv.org/abs/2505.01984v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Dominance and Emerging Multimodal Approaches in Distracted Driving Detection: A Review of Machine Learning Techniques", "abstract": "Distracted driving continues to be a significant cause of road traffic\ninjuries and fatalities worldwide, even with advancements in driver monitoring\ntechnologies. Recent developments in machine learning (ML) and deep learning\n(DL) have primarily focused on visual data to detect distraction, often\nneglecting the complex, multimodal nature of driver behavior. This systematic\nreview assesses 74 peer-reviewed studies from 2019 to 2024 that utilize ML/DL\ntechniques for distracted driving detection across visual, sensor-based,\nmultimodal, and emerging modalities. The review highlights a significant\nprevalence of visual-only models, particularly convolutional neural networks\n(CNNs) and temporal architectures, which achieve high accuracy but show limited\ngeneralizability in real-world scenarios. Sensor-based and physiological models\nprovide complementary strengths by capturing internal states and vehicle\ndynamics, while emerging techniques, such as auditory sensing and radio\nfrequency (RF) methods, offer privacy-aware alternatives. Multimodal\narchitecture consistently surpasses unimodal baselines, demonstrating enhanced\nrobustness, context awareness, and scalability by integrating diverse data\nstreams. These findings emphasize the need to move beyond visual-only\napproaches and adopt multimodal systems that combine visual, physiological, and\nvehicular cues while keeping in checking the need to balance computational\nrequirements. Future research should focus on developing lightweight,\ndeployable multimodal frameworks, incorporating personalized baselines, and\nestablishing cross-modality benchmarks to ensure real-world reliability in\nadvanced driver assistance systems (ADAS) and road safety interventions.", "published": "2025-05-04 02:51:00", "link": "http://arxiv.org/abs/2505.01973v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MC3D-AD: A Unified Geometry-aware Reconstruction Model for Multi-category 3D Anomaly Detection", "abstract": "3D Anomaly Detection (AD) is a promising means of controlling the quality of\nmanufactured products. However, existing methods typically require carefully\ntraining a task-specific model for each category independently, leading to high\ncost, low efficiency, and weak generalization. Therefore, this paper presents a\nnovel unified model for Multi-Category 3D Anomaly Detection (MC3D-AD) that aims\nto utilize both local and global geometry-aware information to reconstruct\nnormal representations of all categories. First, to learn robust and\ngeneralized features of different categories, we propose an adaptive\ngeometry-aware masked attention module that extracts geometry variation\ninformation to guide mask attention. Then, we introduce a local geometry-aware\nencoder reinforced by the improved mask attention to encode group-level feature\ntokens. Finally, we design a global query decoder that utilizes point cloud\nposition embeddings to improve the decoding process and reconstruction ability.\nThis leads to local and global geometry-aware reconstructed feature tokens for\nthe AD task. MC3D-AD is evaluated on two publicly available Real3D-AD and\nAnomaly-ShapeNet datasets, and exhibits significant superiority over current\nstate-of-the-art single-category methods, achieving 3.1\\% and 9.3\\% improvement\nin object-level AUROC over Real3D-AD and Anomaly-ShapeNet, respectively. The\nsource code will be released upon acceptance.", "published": "2025-05-04 02:38:10", "link": "http://arxiv.org/abs/2505.01969v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segment Any RGB-Thermal Model with Language-aided Distillation", "abstract": "The recent Segment Anything Model (SAM) demonstrates strong instance\nsegmentation performance across various downstream tasks. However, SAM is\ntrained solely on RGB data, limiting its direct applicability to RGB-thermal\n(RGB-T) semantic segmentation. Given that RGB-T provides a robust solution for\nscene understanding in adverse weather and lighting conditions, such as low\nlight and overexposure, we propose a novel framework, SARTM, which customizes\nthe powerful SAM for RGB-T semantic segmentation. Our key idea is to unleash\nthe potential of SAM while introduce semantic understanding modules for RGB-T\ndata pairs. Specifically, our framework first involves fine tuning the original\nSAM by adding extra LoRA layers, aiming at preserving SAM's strong\ngeneralization and segmentation capabilities for downstream tasks. Secondly, we\nintroduce language information as guidance for training our SARTM. To address\ncross-modal inconsistencies, we introduce a Cross-Modal Knowledge\nDistillation(CMKD) module that effectively achieves modality adaptation while\nmaintaining its generalization capabilities. This semantic module enables the\nminimization of modality gaps and alleviates semantic ambiguity, facilitating\nthe combination of any modality under any visual conditions. Furthermore, we\nenhance the segmentation performance by adjusting the segmentation head of SAM\nand incorporating an auxiliary semantic segmentation head, which integrates\nmulti-scale features for effective fusion. Extensive experiments are conducted\nacross three multi-modal RGBT semantic segmentation benchmarks: MFNET, PST900,\nand FMB. Both quantitative and qualitative results consistently demonstrate\nthat the proposed SARTM significantly outperforms state-of-the-art approaches\nacross a variety of conditions.", "published": "2025-05-04 00:24:17", "link": "http://arxiv.org/abs/2505.01950v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Minimally Supervised Hierarchical Domain Intent Learning for CRS", "abstract": "Modeling domain intent within an evolving domain structure presents a\nsignificant challenge for domain-specific conversational recommendation systems\n(CRS). The conventional approach involves training an intent model using\nutterance-intent pairs. However, as new intents and patterns emerge, the model\nmust be continuously updated while preserving existing relationships and\nmaintaining efficient retrieval. This process leads to substantial growth in\nutterance-intent pairs, making manual labeling increasingly costly and\nimpractical. In this paper, we propose an efficient solution for constructing a\ndynamic hierarchical structure that minimizes the number of user utterances\nrequired to achieve adequate domain knowledge coverage. To this end, we\nintroduce a neural network-based attention-driven hierarchical clustering\nalgorithm designed to optimize intent grouping using minimal data. The proposed\nmethod builds upon and integrates concepts from two existing flat clustering\nalgorithms DEC and NAM, both of which utilize neural attention mechanisms. We\napply our approach to a curated subset of 44,000 questions from the business\nfood domain. Experimental results demonstrate that constructing the hierarchy\nusing a stratified sampling strategy significantly reduces the number of\nquestions needed to represent the evolving intent structure. Our findings\nindicate that this approach enables efficient coverage of dynamic domain\nknowledge without frequent retraining, thereby enhancing scalability and\nadaptability in domain-specific CSRs.", "published": "2025-05-04 18:12:54", "link": "http://arxiv.org/abs/2505.02209v1", "categories": ["cs.IR", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Tricolore: Multi-Behavior User Profiling for Enhanced Candidate Generation in Recommender Systems", "abstract": "Online platforms aggregate extensive user feedback across diverse behaviors,\nproviding a rich source for enhancing user engagement. Traditional recommender\nsystems, however, typically optimize for a single target behavior and represent\nuser preferences with a single vector, limiting their ability to handle\nmultiple important behaviors or optimization objectives. This conventional\napproach also struggles to capture the full spectrum of user interests,\nresulting in a narrow item pool during candidate generation. To address these\nlimitations, we present Tricolore, a versatile multi-vector learning framework\nthat uncovers connections between different behavior types for more robust\ncandidate generation. Tricolore's adaptive multi-task structure is also\ncustomizable to specific platform needs. To manage the variability in sparsity\nacross behavior types, we incorporate a behavior-wise multi-view fusion module\nthat dynamically enhances learning. Moreover, a popularity-balanced strategy\nensures the recommendation list balances accuracy with item popularity,\nfostering diversity and improving overall performance. Extensive experiments on\npublic datasets demonstrate Tricolore's effectiveness across various\nrecommendation scenarios, from short video platforms to e-commerce. By\nleveraging a shared base embedding strategy, Tricolore also significantly\nimproves the performance for cold-start users. The source code is publicly\navailable at: https://github.com/abnering/Tricolore.", "published": "2025-05-04 14:04:22", "link": "http://arxiv.org/abs/2505.02120v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Design and Channel Modeling of Electromagnetically Reconfigurable Antennas", "abstract": "In this work, a novel design of electromagnetically reconfigurable antennas\n(ERAs) based on a fluid antenna system (FAS) is proposed, and the corresponding\nwireless channel model is established. Different from conventional antenna\narrays with static elements, the electromagnetic characteristics of each array\nelement in the proposed ERA can be flexibly reconfigured into various states,\nintroducing electromagnetic degrees of freedom to enhance wireless system\nperformance. Based on the proposed ERA design, the corresponding channel model\nis developed. Finally, full-wave simulations are conducted to validate the\noverall design concept. The results reveal that a gain enhancement of 2.5 dB is\nachieved at a beamforming direction.", "published": "2025-05-04 21:11:10", "link": "http://arxiv.org/abs/2505.02251v1", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "primary_category": "eess.SY"}
{"title": "Packaged Quantum States for Gauge-Invariant Quantum Computation and Communication", "abstract": "Packaged quantum states are gauge-invariant states in which all internal\nquantum numbers (IQNs) form an inseparable block. This feature gives rise to\nnovel packaged entanglements that encompass all IQNs, which is important both\nfor fundamental physics and for quantum technology. Here we develop a framework\nfor gauge-invariant quantum information processing based on packaged quantum\nstates. We propose the necessary and sufficient conditions for a valid packaged\nsuperposition state of a single particle and multi-particle. We then present\nthe details of constructing gauge-invariant packaged qubits (or qudits),\npackaged gates, and packaged circuits (which commute with the total charge\noperator). These serve as alternative foundation for gauge-invariant quantum\ninformation science. We then adapt conventional quantum error-correction codes,\nquantum algorithms, and quantum communication protocols to the ($d \\times\nD$)-dimensional hybrid-packaged subspace. This high-dimensional hybrid-packaged\nsubspace is flexible for pruning and scaling to match available physics\nsystems. Thus, packaged quantum information processing becomes feasible and\ntestable. Our results show that the gauge-invariant packaged quantum states may\nprovide a possible route toward robust, fault-tolerant, and secure quantum\ntechnologies.", "published": "2025-05-04 17:58:24", "link": "http://arxiv.org/abs/2505.02205v1", "categories": ["quant-ph", "cs.IT", "hep-th", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Alternating and non-alternating deterministic Markov games", "abstract": "Two variants of a deterministic multi-round, zero-sum, two-player game are\npresented: a turn-alternating version and an non-alternating version. The\nnon-alternating version occurs in the computation of the covering radius of\nconstrained systems, a quantity of interest in coding theory.", "published": "2025-05-04 17:04:05", "link": "http://arxiv.org/abs/2505.02183v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sparse Code Transceiver Design for Unsourced Random Access with Analytical Power Division in Gaussian MAC", "abstract": "In this work, we discuss the problem of unsourced random access (URA) over a\nGaussian multiple access channel (GMAC). To address the challenges posed by\nemerging massive machine-type connectivity, URA reframes multiple access as a\ncoding-theoretic problem. The sparse code-oriented schemes are highly valued\nbecause they are widely used in existing protocols, making their implementation\nrequire only minimal changes to current networks. However, drawbacks such as\nthe heavy reliance on extrinsic feedback from powerful channel codes and the\nlack of transmission robustness pose obstacles to the development of sparse\ncodes. To address these drawbacks, a novel sparse code structure based on a\nuniversally applicable power division strategy is proposed. Comprehensive\nnumerical results validate the effectiveness of the proposed scheme.\nSpecifically, by employing the proposed power division method, which is derived\nanalytically and does not require extensive simulations, a performance\nimprovement of approximately 2.8 dB is achieved compared to schemes with\nidentical channel code setups.", "published": "2025-05-04 04:56:32", "link": "http://arxiv.org/abs/2505.01988v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Epistemic Wrapping for Uncertainty Quantification", "abstract": "Uncertainty estimation is pivotal in machine learning, especially for\nclassification tasks, as it improves the robustness and reliability of models.\nWe introduce a novel `Epistemic Wrapping' methodology aimed at improving\nuncertainty estimation in classification. Our approach uses Bayesian Neural\nNetworks (BNNs) as a baseline and transforms their outputs into belief function\nposteriors, effectively capturing epistemic uncertainty and offering an\nefficient and general methodology for uncertainty quantification. Comprehensive\nexperiments employing a Bayesian Neural Network (BNN) baseline and an Interval\nNeural Network for inference on the MNIST, Fashion-MNIST, CIFAR-10 and\nCIFAR-100 datasets demonstrate that our Epistemic Wrapper significantly\nenhances generalisation and uncertainty quantification.", "published": "2025-05-04 22:15:56", "link": "http://arxiv.org/abs/2505.02277v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bayesian Federated Cause-of-Death Classification and Quantification Under Distribution Shift", "abstract": "In regions lacking medically certified causes of death, verbal autopsy (VA)\nis a critical and widely used tool to ascertain the cause of death through\ninterviews with caregivers. Data collected by VAs are often analyzed using\nprobabilistic algorithms. The performance of these algorithms often degrades\ndue to distributional shift across populations. Most existing VA algorithms\nrely on centralized training, requiring full access to training data for joint\nmodeling. This is often infeasible due to privacy and logistical constraints.\nIn this paper, we propose a novel Bayesian Federated Learning (BFL) framework\nthat avoids data sharing across multiple training sources. Our method enables\nreliable individual-level cause-of-death classification and population-level\nquantification of cause-specific mortality fractions (CSMFs), in a target\ndomain with limited or no local labeled data. The proposed framework is\nmodular, computationally efficient, and compatible with a wide range of\nexisting VA algorithms as candidate models, facilitating flexible deployment in\nreal-world mortality surveillance systems. We validate the performance of BFL\nthrough extensive experiments on two real-world VA datasets under varying\nlevels of distribution shift. Our results show that BFL significantly\noutperforms the base models built on a single domain and achieves comparable or\nbetter performance compared to joint modeling.", "published": "2025-05-04 21:29:59", "link": "http://arxiv.org/abs/2505.02257v1", "categories": ["stat.ME", "cs.LG", "stat.AP"], "primary_category": "stat.ME"}
{"title": "Heterosynaptic Circuits Are Universal Gradient Machines", "abstract": "We propose a design principle for the learning circuits of the biological\nbrain. The principle states that almost any dendritic weights updated via\nheterosynaptic plasticity can implement a generalized and efficient class of\ngradient-based meta-learning. The theory suggests that a broad class of\nbiologically plausible learning algorithms, together with the standard machine\nlearning optimizers, can be grounded in heterosynaptic circuit motifs. This\nprinciple suggests that the phenomenology of (anti-) Hebbian (HBP) and\nheterosynaptic plasticity (HSP) may emerge from the same underlying dynamics,\nthus providing a unifying explanation. It also suggests an alternative\nperspective of neuroplasticity, where HSP is promoted to the primary learning\nand memory mechanism, and HBP is an emergent byproduct. We present simulations\nthat show that (a) HSP can explain the metaplasticity of neurons, (b) HSP can\nexplain the flexibility of the biology circuits, and (c) gradient learning can\narise quickly from simple evolutionary dynamics that do not compute any\nexplicit gradient. While our primary focus is on biology, the principle also\nimplies a new approach to designing AI training algorithms and physically\nlearnable AI hardware. Conceptually, our result demonstrates that contrary to\nthe common belief, gradient computation may be extremely easy and common in\nnature.", "published": "2025-05-04 21:04:32", "link": "http://arxiv.org/abs/2505.02248v1", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cs.LG", "cs.NE", "q-bio.PE"], "primary_category": "q-bio.NC"}
{"title": "Federated Causal Inference in Healthcare: Methods, Challenges, and Applications", "abstract": "Federated causal inference enables multi-site treatment effect estimation\nwithout sharing individual-level data, offering a privacy-preserving solution\nfor real-world evidence generation. However, data heterogeneity across sites,\nmanifested in differences in covariate, treatment, and outcome, poses\nsignificant challenges for unbiased and efficient estimation. In this paper, we\npresent a comprehensive review and theoretical analysis of federated causal\neffect estimation across both binary/continuous and time-to-event outcomes. We\nclassify existing methods into weight-based strategies and optimization-based\nframeworks and further discuss extensions including personalized models,\npeer-to-peer communication, and model decomposition. For time-to-event\noutcomes, we examine federated Cox and Aalen-Johansen models, deriving\nasymptotic bias and variance under heterogeneity. Our analysis reveals that\nFedProx-style regularization achieves near-optimal bias-variance trade-offs\ncompared to naive averaging and meta-analysis. We review related software tools\nand conclude by outlining opportunities, challenges, and future directions for\nscalable, fair, and trustworthy federated causal inference in distributed\nhealthcare systems.", "published": "2025-05-04 20:30:11", "link": "http://arxiv.org/abs/2505.02238v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enhanced Outsourced and Secure Inference for Tall Sparse Decision Trees", "abstract": "A decision tree is an easy-to-understand tool that has been widely used for\nclassification tasks. On the one hand, due to privacy concerns, there has been\nan urgent need to create privacy-preserving classifiers that conceal the user's\ninput from the classifier. On the other hand, with the rise of cloud computing,\ndata owners are keen to reduce risk by outsourcing their model, but want\nsecurity guarantees that third parties cannot steal their decision tree model.\nTo address these issues, Joye and Salehi introduced a theoretical protocol that\nefficiently evaluates decision trees while maintaining privacy by leveraging\ntheir comparison protocol that is resistant to timing attacks. However, their\napproach was not only inefficient but also prone to side-channel attacks.\nTherefore, in this paper, we propose a new decision tree inference protocol in\nwhich the model is shared and evaluated among multiple entities. We partition\nour decision tree model by each level to be stored in a new entity we refer to\nas a \"level-site.\" Utilizing this approach, we were able to gain improved\naverage run time for classifier evaluation for a non-complete tree, while also\nhaving strong mitigations against side-channel attacks.", "published": "2025-05-04 19:15:27", "link": "http://arxiv.org/abs/2505.02224v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Practical Efficiency of Muon for Pretraining", "abstract": "We demonstrate that Muon, the simplest instantiation of a second-order\noptimizer, explicitly expands the Pareto frontier over AdamW on the\ncompute-time tradeoff. We find that Muon is more effective than AdamW in\nretaining data efficiency at large batch sizes, far beyond the so-called\ncritical batch size, while remaining computationally efficient, thus enabling\nmore economical training. We study the combination of Muon and the maximal\nupdate parameterization (muP) for efficient hyperparameter transfer and present\na simple telescoping algorithm that accounts for all sources of error in muP\nwhile introducing only a modest overhead in resources. We validate our findings\nthrough extensive experiments with model sizes up to four billion parameters\nand ablations on the data distribution and architecture.", "published": "2025-05-04 19:14:43", "link": "http://arxiv.org/abs/2505.02222v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Empirical Study of Qwen3 Quantization", "abstract": "The Qwen series has emerged as a leading family of open-source Large Language\nModels (LLMs), demonstrating remarkable capabilities in natural language\nunderstanding tasks. With the recent release of Qwen3, which exhibits superior\nperformance across diverse benchmarks, there is growing interest in deploying\nthese models efficiently in resource-constrained environments. Low-bit\nquantization presents a promising solution, yet its impact on Qwen3's\nperformance remains underexplored. This study conducts a systematic evaluation\nof Qwen3's robustness under various quantization settings, aiming to uncover\nboth opportunities and challenges in compressing this state-of-the-art model.\nWe rigorously assess 5 existing classic post-training quantization techniques\napplied to Qwen3, spanning bit-widths from 1 to 8 bits, and evaluate their\neffectiveness across multiple datasets. Our findings reveal that while Qwen3\nmaintains competitive performance at moderate bit-widths, it experiences\nnotable degradation in linguistic tasks under ultra-low precision, underscoring\nthe persistent hurdles in LLM compression. These results emphasize the need for\nfurther research to mitigate performance loss in extreme quantization\nscenarios. We anticipate that this empirical analysis will provide actionable\ninsights for advancing quantization methods tailored to Qwen3 and future LLMs,\nultimately enhancing their practicality without compromising accuracy. Our\nproject is released on https://github.com/Efficient-ML/Qwen3-Quantization and\nhttps://huggingface.co/collections/Efficient-ML/qwen3-quantization-68164450decb1c868788cb2b.", "published": "2025-05-04 18:43:44", "link": "http://arxiv.org/abs/2505.02214v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Exogenous Isomorphism for Counterfactual Identifiability", "abstract": "This paper investigates $\\sim_{\\mathcal{L}_3}$-identifiability, a form of\ncomplete counterfactual identifiability within the Pearl Causal Hierarchy (PCH)\nframework, ensuring that all Structural Causal Models (SCMs) satisfying the\ngiven assumptions provide consistent answers to all causal questions. To\nsimplify this problem, we introduce exogenous isomorphism and propose\n$\\sim_{\\mathrm{EI}}$-identifiability, reflecting the strength of model\nidentifiability required for $\\sim_{\\mathcal{L}_3}$-identifiability. We explore\nsufficient assumptions for achieving $\\sim_{\\mathrm{EI}}$-identifiability in\ntwo special classes of SCMs: Bijective SCMs (BSCMs), based on counterfactual\ntransport, and Triangular Monotonic SCMs (TM-SCMs), which extend\n$\\sim_{\\mathcal{L}_2}$-identifiability. Our results unify and generalize\nexisting theories, providing theoretical guarantees for practical applications.\nFinally, we leverage neural TM-SCMs to address the consistency problem in\ncounterfactual reasoning, with experiments validating both the effectiveness of\nour method and the correctness of the theory.", "published": "2025-05-04 18:24:15", "link": "http://arxiv.org/abs/2505.02212v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Latent Variable Estimation in Bayesian Black-Litterman Models", "abstract": "We revisit the Bayesian Black-Litterman (BL) portfolio model and remove its\nreliance on subjective investor views. Classical BL requires an investor\n\"view\": a forecast vector $q$ and its uncertainty matrix $\\Omega$ that describe\nhow much a chosen portfolio should outperform the market. Our key idea is to\ntreat $(q,\\Omega)$ as latent variables and learn them from market data within a\nsingle Bayesian network. Consequently, the resulting posterior estimation\nadmits closed-form expression, enabling fast inference and stable portfolio\nweights. Building on these, we propose two mechanisms to capture how features\ninteract with returns: shared-latent parametrization and feature-influenced\nviews; both recover classical BL and Markowitz portfolios as special cases.\nEmpirically, on 30-year Dow-Jones and 20-year sector-ETF data, we improve\nSharpe ratios by 50% and cut turnover by 55% relative to Markowitz and the\nindex baselines. This work turns BL into a fully data-driven, view-free, and\ncoherent Bayesian framework for portfolio optimization.", "published": "2025-05-04 17:05:59", "link": "http://arxiv.org/abs/2505.02185v1", "categories": ["q-fin.PM", "cs.LG", "econ.EM", "stat.ME", "stat.ML"], "primary_category": "q-fin.PM"}
{"title": "Efficient FPGA Implementation of Time-Domain Popcount for Low-Complexity Machine Learning", "abstract": "Population count (popcount) is a crucial operation for many low-complexity\nmachine learning (ML) algorithms, including Tsetlin Machine (TM)-a promising\nnew ML method, particularly well-suited for solving classification tasks. The\ninference mechanism in TM consists of propositional logic-based structures\nwithin each class, followed by a majority voting scheme, which makes the\nclassification decision. In TM, the voters are the outputs of Boolean clauses.\nThe voting mechanism comprises two operations: popcount for each class and\ndetermining the class with the maximum vote by means of an argmax operation.\n  While TMs offer a lightweight ML alternative, their performance is often\nlimited by the high computational cost of popcount and comparison required to\nproduce the argmax result. In this paper, we propose an innovative approach to\naccelerate and optimize these operations by performing them in the time domain.\nOur time-domain implementation uses programmable delay lines (PDLs) and\narbiters to efficiently manage these tasks through delay-based mechanisms. We\nalso present an FPGA design flow for practical implementation of the\ntime-domain popcount, addressing delay skew and ensuring that the behavior\nmatches that of the model's intended functionality. By leveraging the natural\ncompatibility of the proposed popcount with asynchronous architectures, we\ndemonstrate significant improvements in an asynchronous TM, including up to 38%\nreduction in latency, 43.1% reduction in dynamic power, and 15% savings in\nresource utilization, compared to synchronous TMs using adder-based popcount.", "published": "2025-05-04 16:44:15", "link": "http://arxiv.org/abs/2505.02181v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Ranked differences Pearson correlation dissimilarity with an application to electricity users time series clustering", "abstract": "Time series clustering is an unsupervised learning method for classifying\ntime series data into groups with similar behavior. It is used in applications\nsuch as healthcare, finance, economics, energy, and climate science. Several\ntime series clustering methods have been introduced and used for over four\ndecades. Most of them focus on measuring either Euclidean distances or\nassociation dissimilarities between time series. In this work, we propose a new\ndissimilarity measure called ranked Pearson correlation dissimilarity (RDPC),\nwhich combines a weighted average of a specified fraction of the largest\nelement-wise differences with the well-known Pearson correlation dissimilarity.\nIt is incorporated into hierarchical clustering. The performance is evaluated\nand compared with existing clustering algorithms. The results show that the\nRDPC algorithm outperforms others in complicated cases involving different\nseasonal patterns, trends, and peaks. Finally, we demonstrate our method by\nclustering a random sample of customers from a Thai electricity consumption\ntime series dataset into seven groups with unique characteristics.", "published": "2025-05-04 16:25:12", "link": "http://arxiv.org/abs/2505.02173v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Efficient Multivariate Time Series Forecasting via Calibrated Language Models with Privileged Knowledge Distillation", "abstract": "Multivariate time series forecasting (MTSF) endeavors to predict future\nobservations given historical data, playing a crucial role in time series data\nmanagement systems. With advancements in large language models (LLMs), recent\nstudies employ textual prompt tuning to infuse the knowledge of LLMs into MTSF.\nHowever, the deployment of LLMs often suffers from low efficiency during the\ninference phase. To address this problem, we introduce TimeKD, an efficient\nMTSF framework that leverages the calibrated language models and privileged\nknowledge distillation. TimeKD aims to generate high-quality future\nrepresentations from the proposed cross-modality teacher model and cultivate an\neffective student model. The cross-modality teacher model adopts calibrated\nlanguage models (CLMs) with ground truth prompts, motivated by the paradigm of\nLearning Under Privileged Information (LUPI). In addition, we design a\nsubtractive cross attention (SCA) mechanism to refine these representations. To\ncultivate an effective student model, we propose an innovative privileged\nknowledge distillation (PKD) mechanism including correlation and feature\ndistillation. PKD enables the student to replicate the teacher's behavior while\nminimizing their output discrepancy. Extensive experiments on real data offer\ninsight into the effectiveness, efficiency, and scalability of the proposed\nTimeKD.", "published": "2025-05-04 14:57:42", "link": "http://arxiv.org/abs/2505.02138v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "GRAIL: Graph Edit Distance and Node Alignment Using LLM-Generated Code", "abstract": "Graph Edit Distance (GED) is a widely used metric for measuring similarity\nbetween two graphs. Computing the optimal GED is NP-hard, leading to the\ndevelopment of various neural and non-neural heuristics. While neural methods\nhave achieved improved approximation quality compared to non-neural approaches,\nthey face significant challenges: (1) They require large amounts of ground\ntruth data, which is itself NP-hard to compute. (2) They operate as black\nboxes, offering limited interpretability. (3) They lack cross-domain\ngeneralization, necessitating expensive retraining for each new dataset. We\naddress these limitations with GRAIL, introducing a paradigm shift in this\ndomain. Instead of training a neural model to predict GED, GRAIL employs a\nnovel combination of large language models (LLMs) and automated prompt tuning\nto generate a program that is used to compute GED. This shift from predicting\nGED to generating programs imparts various advantages, including end-to-end\ninterpretability and an autonomous self-evolutionary learning mechanism without\nground-truth supervision. Extensive experiments on seven datasets confirm that\nGRAIL not only surpasses state-of-the-art GED approximation methods in\nprediction quality but also achieves robust cross-domain generalization across\ndiverse graph distributions.", "published": "2025-05-04 14:14:24", "link": "http://arxiv.org/abs/2505.02124v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Representation Learning for Electronic Design Automation", "abstract": "Representation learning has become an effective technique utilized by\nelectronic design automation (EDA) algorithms, which leverage the natural\nrepresentation of workflow elements as images, grids, and graphs. By addressing\nchallenges related to the increasing complexity of circuits and stringent\npower, performance, and area (PPA) requirements, representation learning\nfacilitates the automatic extraction of meaningful features from complex data\nformats, including images, grids, and graphs. This paper examines the\napplication of representation learning in EDA, covering foundational concepts\nand analyzing prior work and case studies on tasks that include timing\nprediction, routability analysis, and automated placement. Key techniques,\nincluding image-based methods, graph-based approaches, and hybrid multimodal\nsolutions, are presented to illustrate the improvements provided in routing,\ntiming, and parasitic prediction. The provided advancements demonstrate the\npotential of representation learning to enhance efficiency, accuracy, and\nscalability in current integrated circuit design flows.", "published": "2025-05-04 13:18:58", "link": "http://arxiv.org/abs/2505.02105v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Curvature-Aware Hypergradient Approximation for Bilevel Optimization", "abstract": "Bilevel optimization is a powerful tool for many machine learning problems,\nsuch as hyperparameter optimization and meta-learning. Estimating\nhypergradients (also known as implicit gradients) is crucial for developing\ngradient-based methods for bilevel optimization. In this work, we propose a\ncomputationally efficient technique for incorporating curvature information\ninto the approximation of hypergradients and present a novel algorithmic\nframework based on the resulting enhanced hypergradient computation. We provide\nconvergence rate guarantees for the proposed framework in both deterministic\nand stochastic scenarios, particularly showing improved computational\ncomplexity over popular gradient-based methods in the deterministic setting.\nThis improvement in complexity arises from a careful exploitation of the\nhypergradient structure and the inexact Newton method. In addition to the\ntheoretical speedup, numerical experiments demonstrate the significant\npractical performance benefits of incorporating curvature information.", "published": "2025-05-04 13:13:29", "link": "http://arxiv.org/abs/2505.02101v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "Learning Local Causal World Models with State Space Models and Attention", "abstract": "World modelling, i.e. building a representation of the rules that govern the\nworld so as to predict its evolution, is an essential ability for any agent\ninteracting with the physical world. Despite their impressive performance, many\nsolutions fail to learn a causal representation of the environment they are\ntrying to model, which would be necessary to gain a deep enough understanding\nof the world to perform complex tasks. With this work, we aim to broaden the\nresearch in the intersection of causality theory and neural world modelling by\nassessing the potential for causal discovery of the State Space Model (SSM)\narchitecture, which has been shown to have several advantages over the\nwidespread Transformer. We show empirically that, compared to an equivalent\nTransformer, a SSM can model the dynamics of a simple environment and learn a\ncausal model at the same time with equivalent or better performance, thus\npaving the way for further experiments that lean into the strength of SSMs and\nfurther enhance them with causal awareness.", "published": "2025-05-04 11:57:02", "link": "http://arxiv.org/abs/2505.02074v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Lightweight Defense Against Adversarial Attacks in Time Series Classification", "abstract": "As time series classification (TSC) gains prominence, ensuring robust TSC\nmodels against adversarial attacks is crucial. While adversarial defense is\nwell-studied in Computer Vision (CV), the TSC field has primarily relied on\nadversarial training (AT), which is computationally expensive. In this paper,\nfive data augmentation-based defense methods tailored for time series are\ndeveloped, with the most computationally intensive method among them increasing\nthe computational resources by only 14.07% compared to the original TSC model.\nMoreover, the deployment process for these methods is straightforward. By\nleveraging these advantages of our methods, we create two combined methods. One\nof these methods is an ensemble of all the proposed techniques, which not only\nprovides better defense performance than PGD-based AT but also enhances the\ngeneralization ability of TSC models. Moreover, the computational resources\nrequired for our ensemble are less than one-third of those required for\nPGD-based AT. These methods advance robust TSC in data mining. Furthermore, as\nfoundation models are increasingly explored for time series feature learning,\nour work provides insights into integrating data augmentation-based adversarial\ndefense with large-scale pre-trained models in future research.", "published": "2025-05-04 11:51:09", "link": "http://arxiv.org/abs/2505.02073v1", "categories": ["cs.LG", "cs.AI", "68T05, 62H30", "I.2.6; I.5.1; G.3"], "primary_category": "cs.LG"}
{"title": "Resolving Conflicting Constraints in Multi-Agent Reinforcement Learning with Layered Safety", "abstract": "Preventing collisions in multi-robot navigation is crucial for deployment.\nThis requirement hinders the use of learning-based approaches, such as\nmulti-agent reinforcement learning (MARL), on their own due to their lack of\nsafety guarantees. Traditional control methods, such as reachability and\ncontrol barrier functions, can provide rigorous safety guarantees when\ninteractions are limited only to a small number of robots. However, conflicts\nbetween the constraints faced by different agents pose a challenge to safe\nmulti-agent coordination.\n  To overcome this challenge, we propose a method that integrates multiple\nlayers of safety by combining MARL with safety filters. First, MARL is used to\nlearn strategies that minimize multiple agent interactions, where multiple\nindicates more than two. Particularly, we focus on interactions likely to\nresult in conflicting constraints within the engagement distance. Next, for\nagents that enter the engagement distance, we prioritize pairs requiring the\nmost urgent corrective actions. Finally, a dedicated safety filter provides\ntactical corrective actions to resolve these conflicts. Crucially, the design\ndecisions for all layers of this framework are grounded in reachability\nanalysis and a control barrier-value function-based filtering mechanism.\n  We validate our Layered Safe MARL framework in 1) hardware experiments using\nCrazyflie drones and 2) high-density advanced aerial mobility (AAM) operation\nscenarios, where agents navigate to designated waypoints while avoiding\ncollisions. The results show that our method significantly reduces conflict\nwhile maintaining safety without sacrificing much efficiency (i.e., shorter\ntravel time and distance) compared to baselines that do not incorporate layered\nsafety. The project website is available at\n\\href{https://dinamo-mit.github.io/Layered-Safe-MARL/}{[this https URL]}", "published": "2025-05-04 23:42:52", "link": "http://arxiv.org/abs/2505.02293v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents", "abstract": "Decentralized AI agents will soon interact across internet platforms,\ncreating security challenges beyond traditional cybersecurity and AI safety\nframeworks. Free-form protocols are essential for AI's task generalization but\nenable new threats like secret collusion and coordinated swarm attacks. Network\neffects can rapidly spread privacy breaches, disinformation, jailbreaks, and\ndata poisoning, while multi-agent dispersion and stealth optimization help\nadversaries evade oversightcreating novel persistent threats at a systemic\nlevel. Despite their critical importance, these security challenges remain\nunderstudied, with research fragmented across disparate fields including AI\nsecurity, multi-agent learning, complex systems, cybersecurity, game theory,\ndistributed systems, and technical AI governance. We introduce\n\\textbf{multi-agent security}, a new field dedicated to securing networks of\ndecentralized AI agents against threats that emerge or amplify through their\ninteractionswhether direct or indirect via shared environmentswith each other,\nhumans, and institutions, and characterize fundamental security-performance\ntrade-offs. Our preliminary work (1) taxonomizes the threat landscape arising\nfrom interacting AI agents, (2) surveys security-performance tradeoffs in\ndecentralized AI systems, and (3) proposes a unified research agenda addressing\nopen challenges in designing secure agent systems and interaction environments.\nBy identifying these gaps, we aim to guide research in this critical area to\nunlock the socioeconomic potential of large-scale agent deployment on the\ninternet, foster public trust, and mitigate national security risks in critical\ninfrastructure and defense contexts.", "published": "2025-05-04 12:03:29", "link": "http://arxiv.org/abs/2505.02077v1", "categories": ["cs.CR", "cs.AI", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants", "abstract": "Advances in Automation and Artificial Intelligence continue to enhance the\nautonomy of process plants in handling various operational scenarios. However,\ncertain tasks, such as fault handling, remain challenging, as they rely heavily\non human expertise. This highlights the need for systematic, knowledge-based\nmethods. To address this gap, we propose a methodological framework that\nintegrates Large Language Model (LLM) agents with a Digital Twin environment.\nThe LLM agents continuously interpret system states and initiate control\nactions, including responses to unexpected faults, with the goal of returning\nthe system to normal operation. In this context, the Digital Twin acts both as\na structured repository of plant-specific engineering knowledge for agent\nprompting and as a simulation platform for the systematic validation and\nverification of the generated corrective control actions. The evaluation using\na mixing module of a process plant demonstrates that the proposed framework is\ncapable not only of autonomously controlling the mixing module, but also of\ngenerating effective corrective actions to mitigate a pipe clogging with only a\nfew reprompts.", "published": "2025-05-04 12:02:21", "link": "http://arxiv.org/abs/2505.02076v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Phantom Domain Finite Element Method: A novel approach for heterogeneous materials", "abstract": "In this paper, we introduce the Phantom Domain Finite Element Method (PDFEM),\na novel computational approach tailored for the efficient analysis of\nheterogeneous and composite materials. Inspired by fictitious domain methods,\nthis method employs a structured mesh to discretize the entire material domain\nwhile utilizing separate, independent meshes for the inclusions. These\ninclusion meshes are coupled to the structured mesh via a substitution matrix,\nenabling them to act as phantom meshes that do not directly contribute to the\nfinal system of equations. This framework offers significant advantages,\nincluding enhanced flexibility in handling complex inclusion geometries and\nimproved computational efficiency. To assess the accuracy and robustness of the\nproposed method, numerical experiments are conducted on structures containing\ninclusions of various geometries. In order to emphasize the efficiency of the\nPDFEM method, a numerical simulation is presented to highlight its advantages\nin the case of long natural fibers, such as flax and linen. These simulations\nare compared against FEM calculations, demonstrating the efficiency of PDFEM.\nIndeed, meshing such fine structures requires an extremely high number of\nelements, and in some cases, meshing becomes particularly challenging due to\nthe complexity of the geometries.", "published": "2025-05-04 21:51:47", "link": "http://arxiv.org/abs/2505.02268v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Boundary value problem of magnetically insulated diode: existence of solutions and complex bifurcation", "abstract": "The paper focuses on the stationary self-consistent problem of magnetic\ninsulation for a vacuum diode with space-charge limitation, described by a\nsingularly perturbed Vlasov-Maxwell system of dimension 1.5. The case of\ninsulated diode when the electrons are deflected back towards the cathode at\nthe point $x^{*}$ is considered. First, the initial VM system is reduced to the\nnonlinear singular limit system of ODEs for the potentials of electric and\nmagnetic fields. The second step deals with the limit system's reduction to the\nnew nonlinear singular ODE equation for effective potential $\\Theta(x)$. The\nexistence of non-negative solutions is proved for the last equation on the\ninterval $[0, x^{*})$ where $\\Theta(x)>0$. The most interesting and unexplored\ncase is when $\\Theta(x)<0$ on the interval $(x^{*}, 1]$ and corresponds to the\ncase of an insulated diode. For the first time, a numerical analysis of complex\nbifurcation of solutions in insulated diode is considered for $\\Theta(x)<0$\ndepending on parameters and boundary conditions. Bifurcation diagrams of the\ndependence of solution $\\Theta(x)$ on a free point (free boundary) $x^{*}$ were\nconstructed. Insulated diode spacing is found.", "published": "2025-05-04 15:36:19", "link": "http://arxiv.org/abs/2505.02155v1", "categories": ["math.AP", "cs.NA", "math-ph", "math.DS", "math.MP", "math.NA", "35Q83 34A12"], "primary_category": "math.AP"}
{"title": "Compact difference method for Euler-Bernoulli beams and plates with nonlinear nonlocal strong damping", "abstract": "We investigate the numerical approximation to the Euler-Bernoulli (E-B) beams\nand plates with nonlinear nonlocal strong damping, which describes the damped\nmechanical behavior of beams and plates in real applications. We discretize the\ndamping term by the composite Simpson's rule and the six-point Simpson's\nformula in the beam and plate problems, respectively, and then construct the\nfully discrete compact difference scheme for these problems. To account for the\nnonlinear-nonlocal term, we design several novel discrete norms to facilitate\nthe error estimates of the damping term and the numerical scheme. The\nstability, convergence, and energy dissipation properties of the proposed\nscheme are proved, and numerical experiments are carried out to substantiate\nthe theoretical findings.", "published": "2025-05-04 14:42:57", "link": "http://arxiv.org/abs/2505.02132v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Collocation Methods for High-Order Well-Balanced Methods for Systems of Balance Laws", "abstract": "In some previous works, two of the authors introduced a technique to design\nhigh-order numerical methods for one-dimensional balance laws that preserve all\ntheir stationary solutions. The basis of these methods is a well-balanced\nreconstruction operator. Moreover, they introduced a procedure to modify any\nstandard reconstruction operator, like MUSCL, ENO, CWENO, etc., in order to be\nwell-balanced. This strategy involves a non-linear problem at every cell at\nevery time step that consists in finding the stationary solution whose average\nis the given cell value. In a recent paper, a fully well-balanced method is\npresented where the non-linear problems to be solved in the reconstruction\nprocedure are interpreted as control problems. The goal of this paper is to\nintroduce a new technique to solve these local non-linear problems based on the\napplication of the collocation RK methods. Special care is put to analyze the\neffects of computing the averages and the source terms using quadrature\nformulas. A general technique which allows us to deal with resonant problems is\nalso introduced. To check the efficiency of the methods and their well-balance\nproperty, they have been applied to a number of tests, ranging from easy\nacademic systems of balance laws consisting of Burgers equation with some\nnon-linear source terms to the shallow water equations -- with and without\nManning friction -- or Euler equations of gas dynamics with gravity effects.", "published": "2025-05-04 10:17:48", "link": "http://arxiv.org/abs/2505.02055v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "High-order well-balanced methods for systems of balance laws: a control-based approach", "abstract": "In some previous works, two of the authors have introduced a strategy to\ndevelop high-order numerical methods for systems of balance laws that preserve\nall the stationary solutions of the system. The key ingredient of these methods\nis a well-balanced reconstruction operator. A strategy has been also introduced\nto modify any standard reconstruction operator like MUSCL, ENO, CWENO, etc. in\norder to be well-balanced. This strategy involves a non-linear problem at every\ncell at every time step that consists in finding the stationary solution whose\naverage is the given cell value. So far this strategy has been only applied to\nsystems whose stationary solution are known either in explicit or implicit\nform. The goal of this paper is to present a general implementation of this\ntechnique that can be applied to any system of balance laws. To do this, the\nnonlinear problems to be solved in the reconstruction procedure are interpreted\nas control problems: they consist in finding a solution of an ODE system whose\naverage at the computation interval is given. These problems are written in\nfunctional form and the gradient of the functional is computed on the basis of\nthe adjoint problem. Newton's method is applied then to solve the problems.\nSpecial care is put to analyze the effects of computing the averages and the\nsource terms using quadrature formulas. To test their efficiency and\nwell-balancedness, the methods are applied to a number of systems of balance\nlaws, ranging from easy academic systems consisting of Burgers equation with\nsome nonlinear source terms to the shallow water equations or Euler equations\nof gas dynamics with gravity effects.", "published": "2025-05-04 09:56:25", "link": "http://arxiv.org/abs/2505.02047v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient computation of soliton gas primitive potentials", "abstract": "We consider the problem of computing a class of soliton gas primitive\npotentials for the Korteweg--de Vries equation that arise from the accumulation\nof solitons on an infinite interval in the physical domain, extending to\n$-\\infty$. This accumulation results in an associated Riemann--Hilbert problem\non a number of disjoint intervals. In the case where the jump matrices have\nspecific square-root behavior, we describe an efficient and accurate numerical\nmethod to solve this Riemann--Hilbert problem and extract the potential. The\nkeys to the method are, first, the deformation of the Riemann--Hilbert problem,\nmaking numerical use of the so-called $g$-function, and, second, the\nincorporation of endpoint singularities into the chosen basis to discretize and\nsolve the associated singular integral equation.", "published": "2025-05-04 08:36:39", "link": "http://arxiv.org/abs/2505.02029v1", "categories": ["nlin.SI", "cs.NA", "math-ph", "math.MP", "math.NA", "nlin.PS", "35C08, 35Q15, 65E05, 35Q53, 65M99, 37K15, 37K10"], "primary_category": "nlin.SI"}
{"title": "A Unified Perspective on Orthogonalization and Diagonalization", "abstract": "This paper makes a formal connection between two families of widely used\nmatrix factorization algorithms in numerical linear algebra. One family\nconsists of the Jacobi eigenvalue algorithm and its variants for computing the\nHermitian eigendecomposition and singular value decomposition. The other\nconsists of Gaussian elimination and the Gram-Schmidt procedure with various\npivoting rules for computing the Cholesky decomposition and QR decomposition\nrespectively.\n  Both families are cast as special cases of a more general class of\nfactorization algorithms. We provide a randomized pivoting rule that applies to\nthis general class (which differs substantially from the usual pivoting rules\nfor Gaussian elimination / Gram-Schmidt) which results in the same linear rate\nof convergence for each algorithm, irrespective of which factorization it\ncomputes.\n  A second important consequence of this randomized pivoting rule is a\nprovable, effective bound on the numerical stability of the Jacobi eigenvalue\nalgorithm, which addresses a longstanding open problem of Demmel and Veseli\\'c\n`92.", "published": "2025-05-04 08:22:11", "link": "http://arxiv.org/abs/2505.02023v1", "categories": ["math.NA", "cs.NA", "65F15, 65F25", "G.1.3"], "primary_category": "math.NA"}
{"title": "A Robust Monotonic Single-Index Model for Skewed and Heavy-Tailed Data: A Deep Neural Network Approach Applied to Periodontal Studies", "abstract": "Periodontal pocket depth is a widely used biomarker for diagnosing risk of\nperiodontal disease. However, pocket depth typically exhibits skewness and\nheavy-tailedness, and its relationship with clinical risk factors is often\nnonlinear. Motivated by periodontal studies, this paper develops a robust\nsingle-index modal regression framework for analyzing skewed and heavy-tailed\ndata. Our method has the following novel features: (1) a flexible two-piece\nscale Student-$t$ error distribution that generalizes both normal and two-piece\nscale normal distributions; (2) a deep neural network with guaranteed\nmonotonicity constraints to estimate the unknown single-index function; and (3)\ntheoretical guarantees, including model identifiability and a universal\napproximation theorem. Our single-index model combines the flexibility of\nneural networks and the two-piece scale Student-$t$ distribution, delivering\nrobust mode-based estimation that is resistant to outliers, while retaining\nclinical interpretability through parametric index coefficients. We demonstrate\nthe performance of our method through simulation studies and an application to\nperiodontal disease data from the HealthPartners Institute of Minnesota. The\nproposed methodology is implemented in the \\textsf{R} package\n\\href{https://doi.org/10.32614/CRAN.package.DNNSIM}{\\textsc{DNNSIM}}.", "published": "2025-05-04 15:26:35", "link": "http://arxiv.org/abs/2505.02153v1", "categories": ["stat.ME", "stat.ML", "62J99", "G.3"], "primary_category": "stat.ME"}
{"title": "Online Functional Principal Component Analysis on a Multidimensional Domain", "abstract": "Multidimensional functional data streams arise in diverse scientific fields,\nyet their analysis poses significant challenges. We propose a novel online\nframework for functional principal component analysis that enables efficient\nand scalable modeling of such data. Our method represents functional principal\ncomponents using tensor product splines, enforcing smoothness and\northonormality through a penalized framework on a Stiefel manifold. An\nefficient Riemannian stochastic gradient descent algorithm is developed, with\nextensions inspired by adaptive moment estimation and averaging techniques to\naccelerate convergence. Additionally, a dynamic tuning strategy for smoothing\nparameter selection is developed based on a rolling averaged block validation\nscore that adapts to the streaming nature of the data. Extensive simulations\nand real-world applications demonstrate the flexibility and effectiveness of\nthis framework for analyzing multidimensional functional data.", "published": "2025-05-04 14:41:02", "link": "http://arxiv.org/abs/2505.02131v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Neural Logistic Bandits", "abstract": "We study the problem of neural logistic bandits, where the main task is to\nlearn an unknown reward function within a logistic link function using a neural\nnetwork. Existing approaches either exhibit unfavorable dependencies on\n$\\kappa$, where $1/\\kappa$ represents the minimum variance of reward\ndistributions, or suffer from direct dependence on the feature dimension $d$,\nwhich can be huge in neural network-based settings. In this work, we introduce\na novel Bernstein-type inequality for self-normalized vector-valued martingales\nthat is designed to bypass a direct dependence on the ambient dimension. This\nlets us deduce a regret upper bound that grows with the effective dimension\n$\\widetilde{d}$, not the feature dimension, while keeping a minimal dependence\non $\\kappa$. Based on the concentration inequality, we propose two algorithms,\nNeuralLog-UCB-1 and NeuralLog-UCB-2, that guarantee regret upper bounds of\norder $\\widetilde{O}(\\widetilde{d}\\sqrt{\\kappa T})$ and\n$\\widetilde{O}(\\widetilde{d}\\sqrt{T/\\kappa})$, respectively, improving on the\nexisting results. Lastly, we report numerical results on both synthetic and\nreal datasets to validate our theoretical findings.", "published": "2025-05-04 11:23:16", "link": "http://arxiv.org/abs/2505.02069v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Secrets of GFlowNets' Learning Behavior: A Theoretical Study", "abstract": "Generative Flow Networks (GFlowNets) have emerged as a powerful paradigm for\ngenerating composite structures, demonstrating considerable promise across\ndiverse applications. While substantial progress has been made in exploring\ntheir modeling validity and connections to other generative frameworks, the\ntheoretical understanding of their learning behavior remains largely uncharted.\nIn this work, we present a rigorous theoretical investigation of GFlowNets'\nlearning behavior, focusing on four fundamental dimensions: convergence, sample\ncomplexity, implicit regularization, and robustness. By analyzing these\naspects, we seek to elucidate the intricate mechanisms underlying GFlowNet's\nlearning dynamics, shedding light on its strengths and limitations. Our\nfindings contribute to a deeper understanding of the factors influencing\nGFlowNet performance and provide insights into principled guidelines for their\neffective design and deployment. This study not only bridges a critical gap in\nthe theoretical landscape of GFlowNets but also lays the foundation for their\nevolution as a reliable and interpretable framework for generative modeling.\nThrough this, we aspire to advance the theoretical frontiers of GFlowNets and\ncatalyze their broader adoption in the AI community.", "published": "2025-05-04 09:04:25", "link": "http://arxiv.org/abs/2505.02035v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Wide & Deep Learning for Node Classification", "abstract": "Wide & Deep, a simple yet effective learning architecture for recommendation\nsystems developed by Google, has had a significant impact in both academia and\nindustry due to its combination of the memorization ability of generalized\nlinear models and the generalization ability of deep models. Graph\nconvolutional networks (GCNs) remain dominant in node classification tasks;\nhowever, recent studies have highlighted issues such as heterophily and\nexpressiveness, which focus on graph structure while seemingly neglecting the\npotential role of node features. In this paper, we propose a flexible framework\nGCNIII, which leverages the Wide & Deep architecture and incorporates three\ntechniques: Intersect memory, Initial residual and Identity mapping. We provide\ncomprehensive empirical evidence showing that GCNIII can more effectively\nbalance the trade-off between over-fitting and over-generalization on various\nsemi- and full- supervised tasks. Additionally, we explore the use of large\nlanguage models (LLMs) for node feature engineering to enhance the performance\nof GCNIII in cross-domain node classification tasks. Our implementation is\navailable at https://github.com/CYCUCAS/GCNIII.", "published": "2025-05-04 07:53:16", "link": "http://arxiv.org/abs/2505.02020v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning the Simplest Neural ODE", "abstract": "Since the advent of the ``Neural Ordinary Differential Equation (Neural\nODE)'' paper, learning ODEs with deep learning has been applied to system\nidentification, time-series forecasting, and related areas. Exploiting the\ndiffeomorphic nature of ODE solution maps, neural ODEs has also enabled their\nuse in generative modeling. Despite the rich potential to incorporate various\nkinds of physical information, training Neural ODEs remains challenging in\npractice. This study demonstrates, through the simplest one-dimensional linear\nmodel, why training Neural ODEs is difficult. We then propose a new\nstabilization method and provide an analytical convergence analysis. The\ninsights and techniques presented here serve as a concise tutorial for\nresearchers beginning work on Neural ODEs.", "published": "2025-05-04 07:49:56", "link": "http://arxiv.org/abs/2505.02019v1", "categories": ["stat.ML", "cs.LG", "math.DS"], "primary_category": "stat.ML"}
{"title": "Restoring Calibration for Aligned Large Language Models: A Calibration-Aware Fine-Tuning Approach", "abstract": "One of the key technologies for the success of Large Language Models (LLMs)\nis preference alignment. However, a notable side effect of preference alignment\nis poor calibration: while the pre-trained models are typically\nwell-calibrated, LLMs tend to become poorly calibrated after alignment with\nhuman preferences. In this paper, we investigate why preference alignment\naffects calibration and how to address this issue. For the first question, we\nobserve that the preference collapse issue in alignment undesirably generalizes\nto the calibration scenario, causing LLMs to exhibit overconfidence and poor\ncalibration. To address this, we demonstrate the importance of fine-tuning with\ndomain-specific knowledge to alleviate the overconfidence issue. To further\nanalyze whether this affects the model's performance, we categorize models into\ntwo regimes: calibratable and non-calibratable, defined by bounds of Expected\nCalibration Error (ECE). In the calibratable regime, we propose a\ncalibration-aware fine-tuning approach to achieve proper calibration without\ncompromising LLMs' performance. However, as models are further fine-tuned for\nbetter performance, they enter the non-calibratable regime. For this case, we\ndevelop an EM-algorithm-based ECE regularization for the fine-tuning loss to\nmaintain low calibration error. Extensive experiments validate the\neffectiveness of the proposed methods.", "published": "2025-05-04 05:42:51", "link": "http://arxiv.org/abs/2505.01997v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Extended Fiducial Inference for Individual Treatment Effects via Deep Neural Networks", "abstract": "Individual treatment effect estimation has gained significant attention in\nrecent data science literature. This work introduces the Double Neural Network\n(Double-NN) method to address this problem within the framework of extended\nfiducial inference (EFI). In the proposed method, deep neural networks are used\nto model the treatment and control effect functions, while an additional neural\nnetwork is employed to estimate their parameters. The universal approximation\ncapability of deep neural networks ensures the broad applicability of this\nmethod. Numerical results highlight the superior performance of the proposed\nDouble-NN method compared to the conformal quantile regression (CQR) method in\nindividual treatment effect estimation. From the perspective of statistical\ninference, this work advances the theory and methodology for statistical\ninference of large models. Specifically, it is theoretically proven that the\nproposed method permits the model size to increase with the sample size $n$ at\na rate of $O(n^{\\zeta})$ for some $0 \\leq \\zeta<1$, while still maintaining\nproper quantification of uncertainty in the model parameters. This result marks\na significant improvement compared to the range $0\\leq \\zeta < \\frac{1}{2}$\nrequired by the classical central limit theorem. Furthermore, this work\nprovides a rigorous framework for quantifying the uncertainty of deep neural\nnetworks under the neural scaling law, representing a substantial contribution\nto the statistical understanding of large-scale neural network models.", "published": "2025-05-04 05:40:45", "link": "http://arxiv.org/abs/2505.01995v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.CO", "stat.TH"], "primary_category": "stat.ML"}
{"title": "MaskClip: Detachable Clip-on Piezoelectric Sensing of Mask Surface Vibrations for Real-time Noise-Robust Speech Input", "abstract": "Masks are essential in medical settings and during infectious outbreaks but\nsignificantly impair speech communication, especially in environments with\nbackground noise. Existing solutions often require substantial computational\nresources or compromise hygiene and comfort. We propose a novel sensing\napproach that captures only the wearer's voice by detecting mask surface\nvibrations using a piezoelectric sensor. Our developed device, MaskClip,\nemploys a stainless steel clip with an optimally positioned piezoelectric\nsensor to selectively capture speech vibrations while inherently filtering out\nambient noise. Evaluation experiments demonstrated superior performance with a\nlow Character Error Rate of 6.1\\% in noisy environments compared to\nconventional microphones. Subjective evaluations by 102 participants also\nshowed high satisfaction scores. This approach shows promise for applications\nin settings where clear voice communication must be maintained while wearing\nprotective equipment, such as medical facilities, cleanrooms, and industrial\nenvironments.", "published": "2025-05-04 16:44:11", "link": "http://arxiv.org/abs/2505.02180v1", "categories": ["cs.SD", "cs.AR", "cs.HC", "eess.AS", "H.5.2; H.5.5; B.4.2; I.2.7"], "primary_category": "cs.SD"}
{"title": "Tri-Hybrid Multi-User Precoding Based on Electromagnetically Reconfigurable Antennas", "abstract": "The tri-hybrid precoding architecture based on electromagnetically\nreconfigurable antennas (ERAs) is a promising solution for overcoming key\nlimitations in multiple-input multiple-output communication systems. Aiming to\nfurther understand its potential, this paper investigates the tri-hybrid\nmulti-user precoding problem using pattern reconfigurable ERAs. To reduce model\ncomplexity and improve practicality, we characterize each antenna's radiation\npattern using a spherical harmonics decomposition. While mathematically\ntractable, this approach may lead to over-optimized patterns that are\nphysically unrealizable. To address this, we introduce a projection step that\nmaps the optimized patterns onto a realizable set. Simulation results\ndemonstrate that spherical harmonics-based radiation pattern optimization\nsignificantly enhances sum rate performance. However, after projection onto a\nrealizable set obtained from real ERA hardware, the performance gain is notably\nreduced or even negligible, underscoring the need for more effective projection\ntechniques and improved reconfigurable antenna hardware.", "published": "2025-05-04 21:27:33", "link": "http://arxiv.org/abs/2505.02254v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Spreading over OFDM for Integrated Sensing and Communications (ISAC) Ranging: Multi-user Interference Mitigation", "abstract": "In the context of communication-centric integrated sensing and communication\n(ISAC), the orthogonal frequency division multiplexing (OFDM) waveform was\nproven to be optimal in minimizing ranging sidelobes when random signaling is\nused. A typical assumption in OFDM-based ranging is that the max target delay\nis less than the cyclic prefix (CP) length, which is equivalent to performing a\n\\textit{periodic} correlation between the signal reflected from the target and\nthe transmitted signal. In the multi-user case, such as in Orthogonal Frequency\nDivision Multiple Access (OFDMA), users are assigned disjoint subsets of\nsubcarriers which eliminates mutual interference between the communication\nchannels of the different users. However, ranging involves an aperiodic\ncorrelation operation for target ranges with delays greater than the CP length.\nAperiodic correlation between signals from disjoint frequency bands will not be\nzero, resulting in mutual interference between different user bands. We refer\nto this as \\textit{inter-band} (IB) cross-correlation interference. In this\nwork, we analytically characterize IB interference and quantify its impact on\nthe integrated sidelobe levels (ISL). We introduce an orthogonal spreading\nlayer on top of OFDM that can reduce IB interference resulting in ISL levels\nsignificantly lower than for OFDM without spreading in the multi-user setup. We\nvalidate our claims through simulations, and using an upper bound on IB energy\nwhich we show that it can be minimized using our proposed spreading. However,\nfor orthogonal spreading to be effective, a price must be paid in terms of\nspectral utilization, which is yet another manifestation of the trade-off\nbetween sensing accuracy and data communication capacity", "published": "2025-05-04 15:50:22", "link": "http://arxiv.org/abs/2505.02160v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Think on your Feet: Adaptive Thinking via Reinforcement Learning for Social Agents", "abstract": "Effective social intelligence simulation requires language agents to\ndynamically adjust reasoning depth, a capability notably absent in current\napproaches. While existing methods either lack this kind of reasoning\ncapability or enforce uniform long chain-of-thought reasoning across all\nscenarios, resulting in excessive token usage and inappropriate social\nsimulation. In this paper, we propose $\\textbf{A}$daptive $\\textbf{M}$ode\n$\\textbf{L}$earning ($\\textbf{AML}$) that strategically selects from four\nthinking modes (intuitive reaction $\\rightarrow$ deep contemplation) based on\nreal-time context. Our framework's core innovation, the $\\textbf{A}$daptive\n$\\textbf{M}$ode $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{AMPO}$)\nalgorithm, introduces three key advancements over existing methods: (1)\nMulti-granular thinking mode design, (2) Context-aware mode switching across\nsocial interaction, and (3) Token-efficient reasoning via depth-adaptive\nprocessing. Extensive experiments on social intelligence tasks confirm that AML\nachieves 15.6% higher task performance than state-of-the-art methods. Notably,\nour method outperforms GRPO by 7.0% with 32.8% shorter reasoning chains. These\nresults demonstrate that context-sensitive thinking mode selection, as\nimplemented in AMPO, enables more human-like adaptive reasoning than GRPO's\nfixed-depth approach.", "published": "2025-05-04 15:39:58", "link": "http://arxiv.org/abs/2505.02156v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video", "abstract": "Multimodal Large Language Models (MLLMs) increasingly excel at perception,\nunderstanding, and reasoning. However, current benchmarks inadequately evaluate\ntheir ability to perform these tasks continuously in dynamic, real-world\nenvironments. To bridge this gap, we introduce RTV-Bench, a fine-grained\nbenchmark for MLLM real-time video analysis. RTV-Bench uses three key\nprinciples: (1) Multi-Timestamp Question Answering (MTQA), where answers evolve\nwith scene changes; (2) Hierarchical Question Structure, combining basic and\nadvanced queries; and (3) Multi-dimensional Evaluation, assessing the ability\nof continuous perception, understanding, and reasoning. RTV-Bench contains 552\ndiverse videos (167.2 hours) and 4,631 high-quality QA pairs. We evaluated\nleading MLLMs, including proprietary (GPT-4o, Gemini 2.0), open-source offline\n(Qwen2.5-VL, VideoLLaMA3), and open-source real-time (VITA-1.5,\nInternLM-XComposer2.5-OmniLive) models. Experiment results show open-source\nreal-time models largely outperform offline ones but still trail top\nproprietary models. Our analysis also reveals that larger model size or higher\nframe sampling rates do not significantly boost RTV-Bench performance,\nsometimes causing slight decreases. This underscores the need for better model\narchitectures optimized for video stream processing and long sequences to\nadvance real-time video analysis with MLLMs. Our benchmark toolkit is available\nat: https://github.com/LJungang/RTV-Bench.", "published": "2025-05-04 10:55:21", "link": "http://arxiv.org/abs/2505.02064v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Regression is all you need for medical image translation", "abstract": "The acquisition of information-rich images within a limited time budget is\ncrucial in medical imaging. Medical image translation (MIT) can help enhance\nand supplement existing datasets by generating synthetic images from acquired\ndata. While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have\nachieved remarkable success in natural image generation, their benefits -\ncreativity and image realism - do not necessarily transfer to medical\napplications where highly accurate anatomical information is required. In fact,\nthe imitation of acquisition noise or content hallucination hinder clinical\nutility. Here, we introduce YODA (You Only Denoise once - or Average), a novel\n2.5D diffusion-based framework for volumetric MIT. YODA unites diffusion and\nregression paradigms to produce realistic or noise-free outputs. Furthermore,\nwe propose Expectation-Approximation (ExpA) DM sampling, which draws\ninspiration from MRI signal averaging. ExpA-sampling suppresses generated noise\nand, thus, eliminates noise from biasing the evaluation of image quality.\nThrough extensive experiments on four diverse multi-modal datasets - comprising\nmulti-contrast brain MRI and pelvic MRI-CT - we show that diffusion and\nregression sampling yield similar results in practice. As such, the\ncomputational overhead of diffusion sampling does not provide systematic\nbenefits in medical information translation. Building on these insights, we\ndemonstrate that YODA outperforms several state-of-the-art GAN and DM methods.\nNotably, YODA-generated images are shown to be interchangeable with, or even\nsuperior to, physical acquisitions for several downstream tasks. Our findings\nchallenge the presumed advantages of DMs in MIT and pave the way for the\npractical application of MIT in medical imaging.", "published": "2025-05-04 09:57:10", "link": "http://arxiv.org/abs/2505.02048v2", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Efficient Multivariate Time Series Forecasting via Calibrated Language Models with Privileged Knowledge Distillation", "abstract": "Multivariate time series forecasting (MTSF) endeavors to predict future\nobservations given historical data, playing a crucial role in time series data\nmanagement systems. With advancements in large language models (LLMs), recent\nstudies employ textual prompt tuning to infuse the knowledge of LLMs into MTSF.\nHowever, the deployment of LLMs often suffers from low efficiency during the\ninference phase. To address this problem, we introduce TimeKD, an efficient\nMTSF framework that leverages the calibrated language models and privileged\nknowledge distillation. TimeKD aims to generate high-quality future\nrepresentations from the proposed cross-modality teacher model and cultivate an\neffective student model. The cross-modality teacher model adopts calibrated\nlanguage models (CLMs) with ground truth prompts, motivated by the paradigm of\nLearning Under Privileged Information (LUPI). In addition, we design a\nsubtractive cross attention (SCA) mechanism to refine these representations. To\ncultivate an effective student model, we propose an innovative privileged\nknowledge distillation (PKD) mechanism including correlation and feature\ndistillation. PKD enables the student to replicate the teacher's behavior while\nminimizing their output discrepancy. Extensive experiments on real data offer\ninsight into the effectiveness, efficiency, and scalability of the proposed\nTimeKD.", "published": "2025-05-04 14:57:42", "link": "http://arxiv.org/abs/2505.02138v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Decoding Open-Ended Information Seeking Goals from Eye Movements in Reading", "abstract": "When reading, we often have specific information that interests us in a text.\nFor example, you might be reading this paper because you are curious about LLMs\nfor eye movements in reading, the experimental design, or perhaps you only care\nabout the question ``but does it work?''. More broadly, in daily life, people\napproach texts with any number of text-specific goals that guide their reading\nbehavior. In this work, we ask, for the first time, whether open-ended reading\ngoals can be automatically decoded from eye movements in reading. To address\nthis question, we introduce goal classification and goal reconstruction tasks\nand evaluation frameworks, and use large-scale eye tracking for reading data in\nEnglish with hundreds of text-specific information seeking tasks. We develop\nand compare several discriminative and generative multimodal LLMs that combine\neye movements and text for goal classification and goal reconstruction. Our\nexperiments show considerable success on both tasks, suggesting that LLMs can\nextract valuable information about the readers' text-specific goals from eye\nmovements.", "published": "2025-05-04 13:23:48", "link": "http://arxiv.org/abs/2505.02872v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
