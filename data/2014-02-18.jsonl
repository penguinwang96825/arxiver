{"title": "A Comparative Study of Machine Learning Methods for Verbal Autopsy Text\n  Classification", "abstract": "A Verbal Autopsy is the record of an interview about the circumstances of an\nuncertified death. In developing countries, if a death occurs away from health\nfacilities, a field-worker interviews a relative of the deceased about the\ncircumstances of the death; this Verbal Autopsy can be reviewed off-site. We\nreport on a comparative study of the processes involved in Text Classification\napplied to classifying Cause of Death: feature value representation; machine\nlearning classification algorithms; and feature reduction strategies in order\nto identify the suitable approaches applicable to the classification of Verbal\nAutopsy text. We demonstrate that normalised term frequency and the standard\nTFiDF achieve comparable performance across a number of classifiers. The\nresults also show Support Vector Machine is superior to other classification\nalgorithms employed in this research. Finally, we demonstrate the effectiveness\nof employing a \"locally-semi-supervised\" feature reduction strategy in order to\nincrease performance accuracy.", "published": "2014-02-18 16:02:05", "link": "http://arxiv.org/abs/1402.4380v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Learners Surpass their Sources: Mathematical Modeling of Learning\n  from an Inconsistent Source", "abstract": "We present a new algorithm to model and investigate the learning process of a\nlearner mastering a set of grammatical rules from an inconsistent source. The\ncompelling interest of human language acquisition is that the learning succeeds\nin virtually every case, despite the fact that the input data are formally\ninadequate to explain the success of learning. Our model explains how a learner\ncan successfully learn from or even surpass its imperfect source without\npossessing any additional biases or constraints about the types of patterns\nthat exist in the language. We use the data collected by Singleton and Newport\n(2004) on the performance of a 7-year boy Simon, who mastered the American Sign\nLanguage (ASL) by learning it from his parents, both of whom were imperfect\nspeakers of ASL. We show that the algorithm possesses a frequency-boosting\nproperty, whereby the frequency of the most common form of the source is\nincreased by the learner. We also explain several key features of Simon's ASL.", "published": "2014-02-18 02:18:10", "link": "http://arxiv.org/abs/1402.4678v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Networks of Characters and Places from Written Works with\n  CHAPLIN", "abstract": "We are proposing a tool able to gather information on social networks from\nnarrative texts. Its name is CHAPLIN, CHAracters and PLaces Interaction\nNetwork, implemented in VB.NET. Characters and places of the narrative works\nare extracted in a list of raw words. Aided by the interface, the user selects\nnames out of them. After this choice, the tool allows the user to enter some\nparameters, and, according to them, creates a network where the nodes are the\ncharacters and places, and the edges their interactions. Edges are labelled by\nperformances. The output is a GV file, written in the DOT graph scripting\nlanguage, which is rendered by means of the free open source software Graphviz.", "published": "2014-02-18 09:35:19", "link": "http://arxiv.org/abs/1402.4259v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Ambiguity in language networks", "abstract": "Human language defines the most complex outcomes of evolution. The emergence\nof such an elaborated form of communication allowed humans to create extremely\nstructured societies and manage symbols at different levels including, among\nothers, semantics. All linguistic levels have to deal with an astronomic\ncombinatorial potential that stems from the recursive nature of languages. This\nrecursiveness is indeed a key defining trait. However, not all words are\nequally combined nor frequent. In breaking the symmetry between less and more\noften used and between less and more meaning-bearing units, universal scaling\nlaws arise. Such laws, common to all human languages, appear on different\nstages from word inventories to networks of interacting words. Among these\nseemingly universal traits exhibited by language networks, ambiguity appears to\nbe a specially relevant component. Ambiguity is avoided in most computational\napproaches to language processing, and yet it seems to be a crucial element of\nlanguage architecture. Here we review the evidence both from language network\narchitecture and from theoretical reasonings based on a least effort argument.\nAmbiguity is shown to play an essential role in providing a source of language\nefficiency, and is likely to be an inevitable byproduct of network growth.", "published": "2014-02-18 09:26:17", "link": "http://arxiv.org/abs/1402.4802v2", "categories": ["physics.soc-ph", "cs.CL", "q-bio.NC"], "primary_category": "physics.soc-ph"}
