{"title": "Zero-shot information extraction from radiological reports using ChatGPT", "abstract": "Electronic health records contain an enormous amount of valuable information,\nbut many are recorded in free text. Information extraction is the strategy to\ntransform the sequence of characters into structured data, which can be\nemployed for secondary analysis. However, the traditional information\nextraction components, such as named entity recognition and relation\nextraction, require annotated data to optimize the model parameters, which has\nbecome one of the major bottlenecks in building information extraction systems.\nWith the large language models achieving good performances on various\ndownstream NLP tasks without parameter tuning, it becomes possible to use large\nlanguage models for zero-shot information extraction. In this study, we aim to\nexplore whether the most popular large language model, ChatGPT, can extract\nuseful information from the radiological reports. We first design the prompt\ntemplate for the interested information in the CT reports. Then, we generate\nthe prompts by combining the prompt template with the CT reports as the inputs\nof ChatGPT to obtain the responses. A post-processing module is developed to\ntransform the responses into structured extraction results. We conducted the\nexperiments with 847 CT reports collected from Peking University Cancer\nHospital. The experimental results indicate that ChatGPT can achieve\ncompetitive performances for some extraction tasks compared with the baseline\ninformation extraction system, but some limitations need to be further\nimproved.", "published": "2023-09-04 07:00:26", "link": "http://arxiv.org/abs/2309.01398v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hateful Messages: A Conversational Data Set of Hate Speech produced by\n  Adolescents on Discord", "abstract": "With the rise of social media, a rise of hateful content can be observed.\nEven though the understanding and definitions of hate speech varies, platforms,\ncommunities, and legislature all acknowledge the problem. Therefore,\nadolescents are a new and active group of social media users. The majority of\nadolescents experience or witness online hate speech. Research in the field of\nautomated hate speech classification has been on the rise and focuses on\naspects such as bias, generalizability, and performance. To increase\ngeneralizability and performance, it is important to understand biases within\nthe data. This research addresses the bias of youth language within hate speech\nclassification and contributes by providing a modern and anonymized hate speech\nyouth language data set consisting of 88.395 annotated chat messages. The data\nset consists of publicly available online messages from the chat platform\nDiscord. ~6,42% of the messages were classified by a self-developed annotation\nschema as hate speech. For 35.553 messages, the user profiles provided age\nannotations setting the average author age to under 20 years old.", "published": "2023-09-04 07:48:52", "link": "http://arxiv.org/abs/2309.01413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Large Language Models in Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) is a promising approach for mitigating\nthe hallucination of large language models (LLMs). However, existing research\nlacks rigorous evaluation of the impact of retrieval-augmented generation on\ndifferent large language models, which make it challenging to identify the\npotential bottlenecks in the capabilities of RAG for different LLMs. In this\npaper, we systematically investigate the impact of Retrieval-Augmented\nGeneration on large language models. We analyze the performance of different\nlarge language models in 4 fundamental abilities required for RAG, including\nnoise robustness, negative rejection, information integration, and\ncounterfactual robustness. To this end, we establish Retrieval-Augmented\nGeneration Benchmark (RGB), a new corpus for RAG evaluation in both English and\nChinese. RGB divides the instances within the benchmark into 4 separate\ntestbeds based on the aforementioned fundamental abilities required to resolve\nthe case. Then we evaluate 6 representative LLMs on RGB to diagnose the\nchallenges of current LLMs when applying RAG. Evaluation reveals that while\nLLMs exhibit a certain degree of noise robustness, they still struggle\nsignificantly in terms of negative rejection, information integration, and\ndealing with false information. The aforementioned assessment outcomes indicate\nthat there is still a considerable journey ahead to effectively apply RAG to\nLLMs.", "published": "2023-09-04 08:28:44", "link": "http://arxiv.org/abs/2309.01431v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NumHG: A Dataset for Number-Focused Headline Generation", "abstract": "Headline generation, a key task in abstractive summarization, strives to\ncondense a full-length article into a succinct, single line of text. Notably,\nwhile contemporary encoder-decoder models excel based on the ROUGE metric, they\noften falter when it comes to the precise generation of numerals in headlines.\nWe identify the lack of datasets providing fine-grained annotations for\naccurate numeral generation as a major roadblock. To address this, we introduce\na new dataset, the NumHG, and provide over 27,000 annotated numeral-rich news\narticles for detailed investigation. Further, we evaluate five well-performing\nmodels from previous headline generation tasks using human evaluation in terms\nof numerical accuracy, reasonableness, and readability. Our study reveals a\nneed for improvement in numerical accuracy, demonstrating the potential of the\nNumHG dataset to drive progress in number-focused headline generation and\nstimulate further discussions in numeral-focused text generation.", "published": "2023-09-04 09:03:53", "link": "http://arxiv.org/abs/2309.01455v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM and Infrastructure as a Code use case", "abstract": "Cloud computing and the evolution of management methodologies such as Lean\nManagement or Agile entail a profound transformation in both system\nconstruction and maintenance approaches. These practices are encompassed within\nthe term \"DevOps.\" This descriptive approach to an information system or\napplication, alongside the configuration of its constituent components, has\nnecessitated the development of descriptive languages paired with specialized\nengines for automating systems administration tasks. Among these, the tandem of\nAnsible (engine) and YAML (descriptive language) stands out as the two most\nprevalent tools in the market, facing notable competition mainly from\nTerraform. The current document presents an inquiry into a solution for\ngenerating and managing Ansible YAML roles and playbooks, utilizing Generative\nLLMs (Language Models) to translate human descriptions into code. Our efforts\nare focused on identifying plausible directions and outlining the potential\nindustrial applications. Note: For the purpose of this experiment, we have\nopted against the use of Ansible Lightspeed. This is due to its reliance on an\nIBM Watson model, for which we have not found any publicly available\nreferences. Comprehensive information regarding this remarkable technology can\nbe found [1] directly on our partner's website, RedHat.", "published": "2023-09-04 09:05:17", "link": "http://arxiv.org/abs/2309.01456v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What are Public Concerns about ChatGPT? A Novel Self-Supervised Neural\n  Topic Model Tells You", "abstract": "The recently released artificial intelligence conversational agent, ChatGPT,\nhas gained significant attention in academia and real life. A multitude of\nearly ChatGPT users eagerly explore its capabilities and share their opinions\non it via social media. Both user queries and social media posts express public\nconcerns regarding this advanced dialogue system. To mine public concerns about\nChatGPT, a novel Self-Supervised neural Topic Model (SSTM), which formalizes\ntopic modeling as a representation learning procedure, is proposed in this\npaper. Extensive experiments have been conducted on Twitter posts about ChatGPT\nand queries asked by ChatGPT users. And experimental results demonstrate that\nthe proposed approach could extract higher quality public concerns with\nimproved interpretability and diversity, surpassing the performance of\nstate-of-the-art approaches.", "published": "2023-09-04 11:05:10", "link": "http://arxiv.org/abs/2309.01522v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Geo-Encoder: A Chunk-Argument Bi-Encoder Framework for Chinese\n  Geographic Re-Ranking", "abstract": "Chinese geographic re-ranking task aims to find the most relevant addresses\namong retrieved candidates, which is crucial for location-related services such\nas navigation maps. Unlike the general sentences, geographic contexts are\nclosely intertwined with geographical concepts, from general spans (e.g.,\nprovince) to specific spans (e.g., road). Given this feature, we propose an\ninnovative framework, namely Geo-Encoder, to more effectively integrate Chinese\ngeographical semantics into re-ranking pipelines. Our methodology begins by\nemploying off-the-shelf tools to associate text with geographical spans,\ntreating them as chunking units. Then, we present a multi-task learning module\nto simultaneously acquire an effective attention matrix that determines chunk\ncontributions to extra semantic representations. Furthermore, we put forth an\nasynchronous update mechanism for the proposed addition task, aiming to guide\nthe model capable of effectively focusing on specific chunks. Experiments on\ntwo distinct Chinese geographic re-ranking datasets, show that the Geo-Encoder\nachieves significant improvements when compared to state-of-the-art baselines.\nNotably, it leads to a substantial improvement in the Hit@1 score of MGEO-BERT,\nincreasing it by 6.22% from 62.76 to 68.98 on the GeoTES dataset.", "published": "2023-09-04 13:44:50", "link": "http://arxiv.org/abs/2309.01606v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Critical Behavioral Traits Foster Peer Engagement in Online Mental\n  Health Communities", "abstract": "Online Mental Health Communities (OMHCs), such as Reddit, have witnessed a\nsurge in popularity as go-to platforms for seeking information and support in\nmanaging mental health needs. Platforms like Reddit offer immediate\ninteractions with peers, granting users a vital space for seeking mental health\nassistance. However, the largely unregulated nature of these platforms\nintroduces intricate challenges for both users and society at large. This study\nexplores the factors that drive peer engagement within counseling threads,\naiming to enhance our understanding of this critical phenomenon. We introduce\nBeCOPE, a novel behavior encoded Peer counseling dataset comprising over 10,118\nposts and 58,279 comments sourced from 21 mental health-specific subreddits.\nThe dataset is annotated using three major fine-grained behavior labels: (a)\nintent, (b) criticism, and (c) readability, along with the emotion labels. Our\nanalysis indicates the prominence of ``self-criticism'' as the most prevalent\nform of criticism expressed by help-seekers, accounting for a significant 43%\nof interactions. Intriguingly, we observe that individuals who explicitly\nexpress their need for help are 18.01% more likely to receive assistance\ncompared to those who present ``surveys'' or engage in ``rants.'' Furthermore,\nwe highlight the pivotal role of well-articulated problem descriptions, showing\nthat superior readability effectively doubles the likelihood of receiving the\nsought-after support. Our study emphasizes the essential role of OMHCs in\noffering personalized guidance and unveils behavior-driven engagement patterns.", "published": "2023-09-04 14:00:12", "link": "http://arxiv.org/abs/2309.01618v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the effectiveness of ChatGPT-based feedback compared with\n  teacher feedback and self-feedback: Evidence from Chinese to English\n  translation", "abstract": "ChatGPT,a cutting-edge AI-powered Chatbot,can quickly generate responses on\ngiven commands. While it was reported that ChatGPT had the capacity to deliver\nuseful feedback, it is still unclear about its effectiveness compared with\nconventional feedback approaches,such as teacher feedback (TF) and\nself-feedback (SF). To address this issue, this study compared the revised\nChinese to English translation texts produced by Chinese Master of Translation\nand Interpretation (MTI) students,who learned English as a Second/Foreign\nLanguage (ESL/EFL), based on three feedback types (i.e., ChatGPT-based\nfeedback, TF and SF). The data was analyzed using BLEU score to gauge the\noverall translation quality as well as Coh-Metrix to examine linguistic\nfeatures across three dimensions: lexicon, syntax, and cohesion.The findings\nrevealed that TF- and SF-guided translation texts surpassed those with\nChatGPT-based feedback, as indicated by the BLEU score. In terms of linguistic\nfeatures,ChatGPT-based feedback demonstrated superiority, particularly in\nenhancing lexical capability and referential cohesion in the translation texts.\nHowever, TF and SF proved more effective in developing syntax-related skills,as\nit addressed instances of incorrect usage of the passive voice. These diverse\noutcomes indicate ChatGPT's potential as a supplementary resource,\ncomplementing traditional teacher-led methods in translation practice.", "published": "2023-09-04 14:54:39", "link": "http://arxiv.org/abs/2309.01645v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Donkii: Can Annotation Error Detection Methods Find Errors in\n  Instruction-Tuning Datasets?", "abstract": "Instruction tuning has become an integral part of training pipelines for\nLarge Language Models (LLMs) and has been shown to yield strong performance\ngains. In an orthogonal line of research, Annotation Error Detection (AED) has\nemerged as a tool for detecting quality problems in gold standard labels. So\nfar, however, the application of AED methods has been limited to classification\ntasks. It is an open question how well AED methods generalize to language\ngeneration settings, which are becoming more widespread via LLMs. In this\npaper, we present a first and novel benchmark for AED on instruction tuning\ndata: DONKII. It comprises three instruction-tuning datasets enriched with\nerror annotations by experts and semi-automatic methods. We also provide a\nnovel taxonomy of error types for instruction-tuning data. We find that all\nthree datasets contain clear errors, which sometimes propagate directly into\ninstruction-tuned LLMs. We propose four AED baselines for the generative\nsetting and evaluate them extensively on the newly introduced dataset. Our\nresults show that the choice of the right AED method and model size is indeed\ncrucial and derive practical recommendations for how to use AED methods to\nclean instruction-tuning data.", "published": "2023-09-04 15:34:02", "link": "http://arxiv.org/abs/2309.01669v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MathAttack: Attacking Large Language Models Towards Math Solving Ability", "abstract": "With the boom of Large Language Models (LLMs), the research of solving Math\nWord Problem (MWP) has recently made great progress. However, there are few\nstudies to examine the security of LLMs in math solving ability. Instead of\nattacking prompts in the use of LLMs, we propose a MathAttack model to attack\nMWP samples which are closer to the essence of security in solving math\nproblems. Compared to traditional text adversarial attack, it is essential to\npreserve the mathematical logic of original MWPs during the attacking. To this\nend, we propose logical entity recognition to identify logical entries which\nare then frozen. Subsequently, the remaining text are attacked by adopting a\nword-level attacker. Furthermore, we propose a new dataset RobustMath to\nevaluate the robustness of LLMs in math solving ability. Extensive experiments\non our RobustMath and two another math benchmark datasets GSM8K and MultiAirth\nshow that MathAttack could effectively attack the math solving ability of LLMs.\nIn the experiments, we observe that (1) Our adversarial samples from\nhigher-accuracy LLMs are also effective for attacking LLMs with lower accuracy\n(e.g., transfer from larger to smaller-size LLMs, or from few-shot to zero-shot\nprompts); (2) Complex MWPs (such as more solving steps, longer text, more\nnumbers) are more vulnerable to attack; (3) We can improve the robustness of\nLLMs by using our adversarial samples in few-shot prompts. Finally, we hope our\npractice and observation can serve as an important attempt towards enhancing\nthe robustness of LLMs in math solving ability. We will release our code and\ndataset.", "published": "2023-09-04 16:02:23", "link": "http://arxiv.org/abs/2309.01686v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Emergent Abilities in Large Language Models just In-Context\n  Learning?", "abstract": "Large language models, comprising billions of parameters and pre-trained on\nextensive web-scale corpora, have been claimed to acquire certain capabilities\nwithout having been specifically trained on them. These capabilities, referred\nto as \"emergent abilities,\" have been a driving force in discussions regarding\nthe potentials and risks of language models. A key challenge in evaluating\nemergent abilities is that they are confounded by model competencies that arise\nthrough alternative prompting techniques, including in-context learning, which\nis the ability of models to complete a task based on a few examples. We present\na novel theory that explains emergent abilities, taking into account their\npotential confounding factors, and rigorously substantiate this theory through\nover 1000 experiments. Our findings suggest that purported emergent abilities\nare not truly emergent, but result from a combination of in-context learning,\nmodel memory, and linguistic knowledge. Our work is a foundational step in\nexplaining language model performance, providing a template for their efficient\nuse and clarifying the paradox of their ability to excel in some instances\nwhile faltering in others. Thus, we demonstrate that their capabilities should\nnot be overestimated.", "published": "2023-09-04 20:54:11", "link": "http://arxiv.org/abs/2309.01809v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Into the Single Cell Multiverse: an End-to-End Dataset for Procedural\n  Knowledge Extraction in Biomedical Texts", "abstract": "Many of the most commonly explored natural language processing (NLP)\ninformation extraction tasks can be thought of as evaluations of declarative\nknowledge, or fact-based information extraction. Procedural knowledge\nextraction, i.e., breaking down a described process into a series of steps, has\nreceived much less attention, perhaps in part due to the lack of structured\ndatasets that capture the knowledge extraction process from end-to-end. To\naddress this unmet need, we present FlaMB\\'e (Flow annotations for Multiverse\nBiological entities), a collection of expert-curated datasets across a series\nof complementary tasks that capture procedural knowledge in biomedical texts.\nThis dataset is inspired by the observation that one ubiquitous source of\nprocedural knowledge that is described as unstructured text is within academic\npapers describing their methodology. The workflows annotated in FlaMB\\'e are\nfrom texts in the burgeoning field of single cell research, a research area\nthat has become notorious for the number of software tools and complexity of\nworkflows used. Additionally, FlaMB\\'e provides, to our knowledge, the largest\nmanually curated named entity recognition (NER) and disambiguation (NED)\ndatasets for tissue/cell type, a fundamental biological entity that is critical\nfor knowledge extraction in the biomedical research domain. Beyond providing a\nvaluable dataset to enable further development of NLP models for procedural\nknowledge extraction, automating the process of workflow mining also has\nimportant implications for advancing reproducibility in biomedical research.", "published": "2023-09-04 21:02:36", "link": "http://arxiv.org/abs/2309.01812v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-driven Grounding: Large Language Model Agents with Automatical\n  Language-aligned Skill Learning", "abstract": "Large language models (LLMs) show their powerful automatic reasoning and\nplanning capability with a wealth of semantic knowledge about the human world.\nHowever, the grounding problem still hinders the applications of LLMs in the\nreal-world environment. Existing studies try to fine-tune the LLM or utilize\npre-defined behavior APIs to bridge the LLMs and the environment, which not\nonly costs huge human efforts to customize for every single task but also\nweakens the generality strengths of LLMs. To autonomously ground the LLM onto\nthe environment, we proposed the Self-Driven Grounding (SDG) framework to\nautomatically and progressively ground the LLM with self-driven skill learning.\nSDG first employs the LLM to propose the hypothesis of sub-goals to achieve\ntasks and then verify the feasibility of the hypothesis via interacting with\nthe underlying environment. Once verified, SDG can then learn generalized\nskills with the guidance of these successfully grounded subgoals. These skills\ncan be further utilized to accomplish more complex tasks which fail to pass the\nverification phase. Verified in the famous instruction following task\nset-BabyAI, SDG achieves comparable performance in the most challenging tasks\ncompared with imitation learning methods that cost millions of demonstrations,\nproving the effectiveness of learned skills and showing the feasibility and\nefficiency of our framework.", "published": "2023-09-04 04:31:24", "link": "http://arxiv.org/abs/2309.01352v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChatRule: Mining Logical Rules with Large Language Models for Knowledge\n  Graph Reasoning", "abstract": "Logical rules are essential for uncovering the logical connections between\nrelations, which could improve reasoning performance and provide interpretable\nresults on knowledge graphs (KGs). Although there have been many efforts to\nmine meaningful logical rules over KGs, existing methods suffer from\ncomputationally intensive searches over the rule space and a lack of\nscalability for large-scale KGs. Besides, they often ignore the semantics of\nrelations which is crucial for uncovering logical connections. Recently, large\nlanguage models (LLMs) have shown impressive performance in the field of\nnatural language processing and various applications, owing to their emergent\nability and generalizability. In this paper, we propose a novel framework,\nChatRule, unleashing the power of large language models for mining logical\nrules over knowledge graphs. Specifically, the framework is initiated with an\nLLM-based rule generator, leveraging both the semantic and structural\ninformation of KGs to prompt LLMs to generate logical rules. To refine the\ngenerated rules, a rule ranking module estimates the rule quality by\nincorporating facts from existing KGs. Last, the ranked rules can be used to\nconduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,\nw.r.t. different rule quality metrics and downstream tasks, showing the\neffectiveness and scalability of our method.", "published": "2023-09-04 11:38:02", "link": "http://arxiv.org/abs/2309.01538v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Evolving linguistic divergence on polarizing social media", "abstract": "Language change is influenced by many factors, but often starts from\nsynchronic variation, where multiple linguistic patterns or forms coexist, or\nwhere different speech communities use language in increasingly different ways.\nBesides regional or economic reasons, communities may form and segregate based\non political alignment. The latter, referred to as political polarization, is\nof growing societal concern across the world. Here we map and quantify\nlinguistic divergence across the partisan left-right divide in the United\nStates, using social media data. We develop a general methodology to delineate\n(social) media users by their political preference, based on which (potentially\nbiased) news media accounts they do and do not follow on a given platform. Our\ndata consists of 1.5M short posts by 10k users (about 20M words) from the\nsocial media platform Twitter (now \"X\"). Delineating this sample involved\nmining the platform for the lists of followers (n=422M) of 72 large news media\naccounts. We quantify divergence in topics of conversation and word\nfrequencies, messaging sentiment, and lexical semantics of words and emoji. We\nfind signs of linguistic divergence across all these aspects, especially in\ntopics and themes of conversation, in line with previous research. While US\nAmerican English remains largely intelligible within its large speech\ncommunity, our findings point at areas where miscommunication may eventually\narise given ongoing polarization and therefore potential linguistic divergence.\nOur methodology - combining data mining, lexicostatistics, machine learning,\nlarge language models and a systematic human annotation approach - is largely\nlanguage and platform agnostic. In other words, while we focus here on US\npolitical divides and US English, the same approach is applicable to other\ncountries, languages, and social media platforms.", "published": "2023-09-04 15:21:55", "link": "http://arxiv.org/abs/2309.01659v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Unveiling Theory of Mind in Large Language Models: A Parallel to Single\n  Neurons in the Human Brain", "abstract": "With their recent development, large language models (LLMs) have been found\nto exhibit a certain level of Theory of Mind (ToM), a complex cognitive\ncapacity that is related to our conscious mind and that allows us to infer\nanother's beliefs and perspective. While human ToM capabilities are believed to\nderive from the neural activity of a broadly interconnected brain network,\nincluding that of dorsal medial prefrontal cortex (dmPFC) neurons, the precise\nprocesses underlying LLM's capacity for ToM or their similarities with that of\nhumans remains largely unknown. In this study, we drew inspiration from the\ndmPFC neurons subserving human ToM and employed a similar methodology to\nexamine whether LLMs exhibit comparable characteristics. Surprisingly, our\nanalysis revealed a striking resemblance between the two, as hidden embeddings\n(artificial neurons) within LLMs started to exhibit significant responsiveness\nto either true- or false-belief trials, suggesting their ability to represent\nanother's perspective. These artificial embedding responses were closely\ncorrelated with the LLMs' performance during the ToM tasks, a property that was\ndependent on the size of the models. Further, the other's beliefs could be\naccurately decoded using the entire embeddings, indicating the presence of the\nembeddings' ToM capability at the population level. Together, our findings\nrevealed an emergent property of LLMs' embeddings that modified their\nactivities in response to ToM features, offering initial evidence of a parallel\nbetween the artificial model and neurons in the human brain.", "published": "2023-09-04 15:26:15", "link": "http://arxiv.org/abs/2309.01660v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Prompting or Fine-tuning? A Comparative Study of Large Language Models\n  for Taxonomy Construction", "abstract": "Taxonomies represent hierarchical relations between entities, frequently\napplied in various software modeling and natural language processing (NLP)\nactivities. They are typically subject to a set of structural constraints\nrestricting their content. However, manual taxonomy construction can be\ntime-consuming, incomplete, and costly to maintain. Recent studies of large\nlanguage models (LLMs) have demonstrated that appropriate user inputs (called\nprompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks\nwithout explicit (re-)training. However, existing approaches for automated\ntaxonomy construction typically involve fine-tuning a language model by\nadjusting model parameters. In this paper, we present a general framework for\ntaxonomy construction that takes into account structural constraints. We\nsubsequently conduct a systematic comparison between the prompting and\nfine-tuning approaches performed on a hypernym taxonomy and a novel computer\nscience taxonomy dataset. Our result reveals the following: (1) Even without\nexplicit training on the dataset, the prompting approach outperforms\nfine-tuning-based approaches. Moreover, the performance gap between prompting\nand fine-tuning widens when the training dataset is small. However, (2)\ntaxonomies generated by the fine-tuning approach can be easily post-processed\nto satisfy all the constraints, whereas handling violations of the taxonomies\nproduced by the prompting approach can be challenging. These evaluation\nfindings provide guidance on selecting the appropriate method for taxonomy\nconstruction and highlight potential enhancements for both approaches.", "published": "2023-09-04 16:53:17", "link": "http://arxiv.org/abs/2309.01715v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interdisciplinary Fairness in Imbalanced Research Proposal Topic\n  Inference: A Hierarchical Transformer-based Method with Selective\n  Interpolation", "abstract": "The objective of topic inference in research proposals aims to obtain the\nmost suitable disciplinary division from the discipline system defined by a\nfunding agency. The agency will subsequently find appropriate peer review\nexperts from their database based on this division. Automated topic inference\ncan reduce human errors caused by manual topic filling, bridge the knowledge\ngap between funding agencies and project applicants, and improve system\nefficiency. Existing methods focus on modeling this as a hierarchical\nmulti-label classification problem, using generative models to iteratively\ninfer the most appropriate topic information. However, these methods overlook\nthe gap in scale between interdisciplinary research proposals and\nnon-interdisciplinary ones, leading to an unjust phenomenon where the automated\ninference system categorizes interdisciplinary proposals as\nnon-interdisciplinary, causing unfairness during the expert assignment. How can\nwe address this data imbalance issue under a complex discipline system and\nhence resolve this unfairness? In this paper, we implement a topic label\ninference system based on a Transformer encoder-decoder architecture.\nFurthermore, we utilize interpolation techniques to create a series of\npseudo-interdisciplinary proposals from non-interdisciplinary ones during\ntraining based on non-parametric indicators such as cross-topic probabilities\nand topic occurrence probabilities. This approach aims to reduce the bias of\nthe system during model training. Finally, we conduct extensive experiments on\na real-world dataset to verify the effectiveness of the proposed method. The\nexperimental results demonstrate that our training strategy can significantly\nmitigate the unfairness generated in the topic inference task.", "published": "2023-09-04 16:54:49", "link": "http://arxiv.org/abs/2309.01717v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "One Wide Feedforward is All You Need", "abstract": "The Transformer architecture has two main non-embedding components: Attention\nand the Feed Forward Network (FFN). Attention captures interdependencies\nbetween words regardless of their position, while the FFN non-linearly\ntransforms each input token independently. In this work we explore the role of\nthe FFN, and find that despite taking up a significant fraction of the model's\nparameters, it is highly redundant. Concretely, we are able to substantially\nreduce the number of parameters with only a modest drop in accuracy by removing\nthe FFN on the decoder layers and sharing a single FFN across the encoder.\nFinally we scale this architecture back to its original size by increasing the\nhidden dimension of the shared FFN, achieving substantial gains in both\naccuracy and latency with respect to the original Transformer Big.", "published": "2023-09-04 21:30:21", "link": "http://arxiv.org/abs/2309.01826v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Do androids dream of fictional references? A bibliographic dialogue with\n  ChatGPT3.5", "abstract": "This article focuses on bibliographic references generated by the ChatGPT3.5\ntool. Using this tool based on the trained GPT generation model ChatGPT3.5,\ndeveloped by the company OpenAI, we explored six different themes and analyzed\na sample of references generated by the model, in French and English. The\nresults revealed high percentages of fictitious references in several fields,\nunderlining the importance of carefully checking these references before using\nthem in research work. An improvement in results was nevertheless noted between\nMay and July with regard to English references for themes on which ChatGPR3.5\nhas been particularly trained, but the situation remains unsatisfactory in\nFrench, for example. It should also be pointed out that much of the text in\nthis article was generated by ChatGPT in a joint effort with the human author.", "published": "2023-09-04 08:11:59", "link": "http://arxiv.org/abs/2312.00789v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "UniSA: Unified Generative Framework for Sentiment Analysis", "abstract": "Sentiment analysis is a crucial task that aims to understand people's\nemotional states and predict emotional categories based on multimodal\ninformation. It consists of several subtasks, such as emotion recognition in\nconversation (ERC), aspect-based sentiment analysis (ABSA), and multimodal\nsentiment analysis (MSA). However, unifying all subtasks in sentiment analysis\npresents numerous challenges, including modality alignment, unified\ninput/output forms, and dataset bias. To address these challenges, we propose a\nTask-Specific Prompt method to jointly model subtasks and introduce a\nmultimodal generative framework called UniSA. Additionally, we organize the\nbenchmark datasets of main subtasks into a new Sentiment Analysis Evaluation\nbenchmark, SAEval. We design novel pre-training tasks and training methods to\nenable the model to learn generic sentiment knowledge among subtasks to improve\nthe model's multimodal sentiment perception ability. Our experimental results\nshow that UniSA performs comparably to the state-of-the-art on all subtasks and\ngeneralizes well to various subtasks in sentiment analysis.", "published": "2023-09-04 03:49:30", "link": "http://arxiv.org/abs/2309.01339v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "ReOnto: A Neuro-Symbolic Approach for Biomedical Relation Extraction", "abstract": "Relation Extraction (RE) is the task of extracting semantic relationships\nbetween entities in a sentence and aligning them to relations defined in a\nvocabulary, which is generally in the form of a Knowledge Graph (KG) or an\nontology. Various approaches have been proposed so far to address this task.\nHowever, applying these techniques to biomedical text often yields\nunsatisfactory results because it is hard to infer relations directly from\nsentences due to the nature of the biomedical relations. To address these\nissues, we present a novel technique called ReOnto, that makes use of neuro\nsymbolic knowledge for the RE task. ReOnto employs a graph neural network to\nacquire the sentence representation and leverages publicly accessible\nontologies as prior knowledge to identify the sentential relation between two\nentities. The approach involves extracting the relation path between the two\nentities from the ontology. We evaluate the effect of using symbolic knowledge\nfrom ontologies with graph neural networks. Experimental results on two public\nbiomedical datasets, BioRel and ADE, show that our method outperforms all the\nbaselines (approximately by 3\\%).", "published": "2023-09-04 05:36:58", "link": "http://arxiv.org/abs/2309.01370v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SememeASR: Boosting Performance of End-to-End Speech Recognition against\n  Domain and Long-Tailed Data Shift with Sememe Semantic Knowledge", "abstract": "Recently, excellent progress has been made in speech recognition. However,\npure data-driven approaches have struggled to solve the problem in\ndomain-mismatch and long-tailed data. Considering that knowledge-driven\napproaches can help data-driven approaches alleviate their flaws, we introduce\nsememe-based semantic knowledge information to speech recognition (SememeASR).\nSememe, according to the linguistic definition, is the minimum semantic unit in\na language and is able to represent the implicit semantic information behind\neach word very well. Our experiments show that the introduction of sememe\ninformation can improve the effectiveness of speech recognition. In addition,\nour further experiments show that sememe knowledge can improve the model's\nrecognition of long-tailed data and enhance the model's domain generalization\nability.", "published": "2023-09-04 08:35:05", "link": "http://arxiv.org/abs/2309.01437v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Open Sesame! Universal Black Box Jailbreaking of Large Language Models", "abstract": "Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.", "published": "2023-09-04 08:54:20", "link": "http://arxiv.org/abs/2309.01446v4", "categories": ["cs.CL", "cs.CV", "cs.NE"], "primary_category": "cs.CL"}
{"title": "A Comparative Analysis of Pretrained Language Models for Text-to-Speech", "abstract": "State-of-the-art text-to-speech (TTS) systems have utilized pretrained\nlanguage models (PLMs) to enhance prosody and create more natural-sounding\nspeech. However, while PLMs have been extensively researched for natural\nlanguage understanding (NLU), their impact on TTS has been overlooked. In this\nstudy, we aim to address this gap by conducting a comparative analysis of\ndifferent PLMs for two TTS tasks: prosody prediction and pause prediction.\nFirstly, we trained a prosody prediction model using 15 different PLMs. Our\nfindings revealed a logarithmic relationship between model size and quality, as\nwell as significant performance differences between neutral and expressive\nprosody. Secondly, we employed PLMs for pause prediction and found that the\ntask was less sensitive to small models. We also identified a strong\ncorrelation between our empirical results and the GLUE scores obtained for\nthese language models. To the best of our knowledge, this is the first study of\nits kind to investigate the impact of different PLMs on TTS.", "published": "2023-09-04 13:02:27", "link": "http://arxiv.org/abs/2309.01576v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Fine-grained Affective Processing Capabilities Emerging from Large\n  Language Models", "abstract": "Large language models, in particular generative pre-trained transformers\n(GPTs), show impressive results on a wide variety of language-related tasks. In\nthis paper, we explore ChatGPT's zero-shot ability to perform affective\ncomputing tasks using prompting alone. We show that ChatGPT a) performs\nmeaningful sentiment analysis in the Valence, Arousal and Dominance dimensions,\nb) has meaningful emotion representations in terms of emotion categories and\nthese affective dimensions, and c) can perform basic appraisal-based emotion\nelicitation of situations based on a prompt-based computational implementation\nof the OCC appraisal model. These findings are highly relevant: First, they\nshow that the ability to solve complex affect processing tasks emerges from\nlanguage-based token prediction trained on extensive data sets. Second, they\nshow the potential of large language models for simulating, processing and\nanalyzing human emotions, which has important implications for various\napplications such as sentiment analysis, socially interactive agents, and\nsocial robotics.", "published": "2023-09-04 15:32:47", "link": "http://arxiv.org/abs/2309.01664v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "CRUISE-Screening: Living Literature Reviews Toolbox", "abstract": "Keeping up with research and finding related work is still a time-consuming\ntask for academics. Researchers sift through thousands of studies to identify a\nfew relevant ones. Automation techniques can help by increasing the efficiency\nand effectiveness of this task. To this end, we developed CRUISE-Screening, a\nweb-based application for conducting living literature reviews - a type of\nliterature review that is continuously updated to reflect the latest research\nin a particular field. CRUISE-Screening is connected to several search engines\nvia an API, which allows for updating the search results periodically.\nMoreover, it can facilitate the process of screening for relevant publications\nby using text classification and question answering models. CRUISE-Screening\ncan be used both by researchers conducting literature reviews and by those\nworking on automating the citation screening process to validate their\nalgorithms. The application is open-source:\nhttps://github.com/ProjectDoSSIER/cruise-screening, and a demo is available\nunder this URL: https://citation-screening.ec.tuwien.ac.at. We discuss the\nlimitations of our tool in Appendix A.", "published": "2023-09-04 15:58:43", "link": "http://arxiv.org/abs/2309.01684v1", "categories": ["cs.IR", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "An Empirical Analysis for Zero-Shot Multi-Label Classification on\n  COVID-19 CT Scans and Uncurated Reports", "abstract": "The pandemic resulted in vast repositories of unstructured data, including\nradiology reports, due to increased medical examinations. Previous research on\nautomated diagnosis of COVID-19 primarily focuses on X-ray images, despite\ntheir lower precision compared to computed tomography (CT) scans. In this work,\nwe leverage unstructured data from a hospital and harness the fine-grained\ndetails offered by CT scans to perform zero-shot multi-label classification\nbased on contrastive visual language learning. In collaboration with human\nexperts, we investigate the effectiveness of multiple zero-shot models that aid\nradiologists in detecting pulmonary embolisms and identifying intricate lung\ndetails like ground glass opacities and consolidations. Our empirical analysis\nprovides an overview of the possible solutions to target such fine-grained\ntasks, so far overlooked in the medical multimodal pretraining literature. Our\ninvestigation promises future advancements in the medical image analysis\ncommunity by addressing some challenges associated with unstructured data and\nfine-grained multi-label classification.", "published": "2023-09-04 17:58:01", "link": "http://arxiv.org/abs/2309.01740v2", "categories": ["eess.IV", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Exploring Attention Mechanisms in Integration of Multi-Modal Information\n  for Sign Language Recognition and Translation", "abstract": "Understanding intricate and fast-paced movements of body parts is essential\nfor the recognition and translation of sign language. The inclusion of\nadditional information intended to identify and locate the moving body parts\nhas been an interesting research topic recently. However, previous works on\nusing multi-modal information raise concerns such as sub-optimal multi-modal\nfeature merging method, or the model itself being too computationally heavy. In\nour work, we have addressed such issues and used a plugin module based on\ncross-attention to properly attend to each modality with another. Moreover, we\nutilized 2-stage training to remove the dependency of separate feature\nextractors for additional modalities in an end-to-end approach, which reduces\nthe concern about computational complexity. Besides, our additional\ncross-attention plugin module is very lightweight which doesn't add significant\ncomputational overhead on top of the original baseline. We have evaluated the\nperformance of our approaches on the RWTH-PHOENIX-2014 dataset for sign\nlanguage recognition and the RWTH-PHOENIX-2014T dataset for the sign language\ntranslation task. Our approach reduced the WER by 0.9 on the recognition task\nand increased the BLEU-4 scores by 0.8 on the translation task.", "published": "2023-09-04 23:31:29", "link": "http://arxiv.org/abs/2309.01860v4", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Text-Only Domain Adaptation for End-to-End Speech Recognition through\n  Down-Sampling Acoustic Representation", "abstract": "Mapping two modalities, speech and text, into a shared representation space,\nis a research topic of using text-only data to improve end-to-end automatic\nspeech recognition (ASR) performance in new domains. However, the length of\nspeech representation and text representation is inconsistent. Although the\nprevious method up-samples the text representation to align with acoustic\nmodality, it may not match the expected actual duration. In this paper, we\nproposed novel representations match strategy through down-sampling acoustic\nrepresentation to align with text modality. By introducing a continuous\nintegrate-and-fire (CIF) module generating acoustic representations consistent\nwith token length, our ASR model can learn unified representations from both\nmodalities better, allowing for domain adaptation using text-only data of the\ntarget domain. Experiment results of new domain data demonstrate the\neffectiveness of the proposed method.", "published": "2023-09-04 08:52:59", "link": "http://arxiv.org/abs/2309.02459v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Foundational AI Models for Additive Manufacturing: Language\n  Models for G-Code Debugging, Manipulation, and Comprehension", "abstract": "3D printing or additive manufacturing is a revolutionary technology that\nenables the creation of physical objects from digital models. However, the\nquality and accuracy of 3D printing depend on the correctness and efficiency of\nthe G-code, a low-level numerical control programming language that instructs\n3D printers how to move and extrude material. Debugging G-code is a challenging\ntask that requires a syntactic and semantic understanding of the G-code format\nand the geometry of the part to be printed. In this paper, we present the first\nextensive evaluation of six state-of-the-art foundational large language models\n(LLMs) for comprehending and debugging G-code files for 3D printing. We design\neffective prompts to enable pre-trained LLMs to understand and manipulate\nG-code and test their performance on various aspects of G-code debugging and\nmanipulation, including detection and correction of common errors and the\nability to perform geometric transformations. We analyze their strengths and\nweaknesses for understanding complete G-code files. We also discuss the\nimplications and limitations of using LLMs for G-code comprehension.", "published": "2023-09-04 21:22:28", "link": "http://arxiv.org/abs/2309.02465v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Minimal Effective Theory for Phonotactic Memory: Capturing Local\n  Correlations due to Errors in Speech", "abstract": "Spoken language evolves constrained by the economy of speech, which depends\non factors such as the structure of the human mouth. This gives rise to local\nphonetic correlations in spoken words. Here we demonstrate that these local\ncorrelations facilitate the learning of spoken words by reducing their\ninformation content. We do this by constructing a locally-connected\ntensor-network model, inspired by similar variational models used for many-body\nphysics, which exploits these local phonetic correlations to facilitate the\nlearning of spoken words. The model is therefore a minimal model of phonetic\nmemory, where \"learning to pronounce\" and \"learning a word\" are one and the\nsame. A consequence of which is the learned ability to produce new words which\nare phonetically reasonable for the target language; as well as providing a\nhierarchy of the most likely errors that could be produced during the action of\nspeech. We test our model against Latin and Turkish words. (The code is\navailable on GitHub.)", "published": "2023-09-04 22:11:26", "link": "http://arxiv.org/abs/2309.02466v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learning a Patent-Informed Biomedical Knowledge Graph Reveals\n  Technological Potential of Drug Repositioning Candidates", "abstract": "Drug repositioning-a promising strategy for discovering new therapeutic uses\nfor existing drugs-has been increasingly explored in the computational science\nliterature using biomedical databases. However, the technological potential of\ndrug repositioning candidates has often been overlooked. This study presents a\nnovel protocol to comprehensively analyse various sources such as\npharmaceutical patents and biomedical databases, and identify drug\nrepositioning candidates with both technological potential and scientific\nevidence. To this end, first, we constructed a scientific biomedical knowledge\ngraph (s-BKG) comprising relationships between drugs, diseases, and genes\nderived from biomedical databases. Our protocol involves identifying drugs that\nexhibit limited association with the target disease but are closely located in\nthe s-BKG, as potential drug candidates. We constructed a patent-informed\nbiomedical knowledge graph (p-BKG) by adding pharmaceutical patent information.\nFinally, we developed a graph embedding protocol to ascertain the structure of\nthe p-BKG, thereby calculating the relevance scores of those candidates with\ntarget disease-related patents to evaluate their technological potential. Our\ncase study on Alzheimer's disease demonstrates its efficacy and feasibility,\nwhile the quantitative outcomes and systematic methods are expected to bridge\nthe gap between computational discoveries and successful market applications in\ndrug repositioning research.", "published": "2023-09-04 02:30:19", "link": "http://arxiv.org/abs/2309.03227v2", "categories": ["cs.AI", "cs.CL", "cs.LG", "q-bio.QM"], "primary_category": "cs.AI"}
{"title": "Code Representation Pre-training with Complements from Program\n  Executions", "abstract": "Large language models (LLMs) for natural language processing have been\ngrafted onto programming language modeling for advancing code intelligence.\nAlthough it can be represented in the text format, code is syntactically more\nrigorous in order to be properly compiled or interpreted to perform a desired\nset of behaviors given any inputs. In this case, existing works benefit from\nsyntactic representations to learn from code less ambiguously in the forms of\nabstract syntax tree, control-flow graph, etc. However, programs with the same\npurpose can be implemented in various ways showing different syntactic\nrepresentations while the ones with similar implementations can have distinct\nbehaviors. Though trivially demonstrated during executions, such semantics\nabout functionality are challenging to be learned directly from code,\nespecially in an unsupervised manner. Hence, in this paper, we propose\nFuzzPretrain to explore the dynamic information of programs revealed by their\ntest cases and embed it into the feature representations of code as\ncomplements. The test cases are obtained with the assistance of a customized\nfuzzer and are only required during pre-training. FuzzPretrain yielded more\nthan 6%/9% mAP improvements on code search over its counterparts trained with\nonly source code or AST, respectively. Our extensive experimental results show\nthe benefits of learning discriminative code representations with program\nexecutions.", "published": "2023-09-04 01:57:22", "link": "http://arxiv.org/abs/2309.09980v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Efficient Social Choice via NLP and Sampling", "abstract": "Attention-Aware Social Choice tackles the fundamental conflict faced by some\nagent communities between their desire to include all members in the decision\nmaking processes and the limited time and attention that are at the disposal of\nthe community members. Here, we investigate a combination of two techniques for\nattention-aware social choice, namely Natural Language Processing (NLP) and\nSampling. Essentially, we propose a system in which each governance proposal to\nchange the status quo is first sent to a trained NLP model that estimates the\nprobability that the proposal would pass if all community members directly vote\non it; then, based on such an estimation, a population sample of a certain size\nis being selected and the proposal is decided upon by taking the sample\nmajority. We develop several concrete algorithms following the scheme described\nabove and evaluate them using various data, including such from several\nDecentralized Autonomous Organizations (DAOs).", "published": "2023-09-04 13:30:31", "link": "http://arxiv.org/abs/2309.12360v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Working with Trouble and Failures in Conversation between Humans and\n  Robots (WTF 2023) & Is CUI Design Ready Yet?", "abstract": "Workshop proceedings of two co-located workshops \"Working with Troubles and\nFailures in Conversation with Humans and Robots\" (WTF 2023) and \"Is CUI Design\nReady Yet?\", both of which were part of the ACM conference on conversational\nuser interfaces 2023.\n  WTF 23 aimed at bringing together researchers from human-robot interaction,\ndialogue systems, human-computer interaction, and conversation analysis.\nDespite all progress, robotic speech interfaces continue to be brittle in a\nnumber of ways and the experience of failure of such interfaces is commonplace\namongst roboticists. However, the technical literature is positively skewed\ntoward their good performance. The workshop aims to provide a platform for\ndiscussing communicative troubles and failures in human-robot interactions and\nrelated failures in non-robotic speech interfaces. Aims include a scrupulous\ninvestigation into communicative failures, to begin working on a taxonomy of\nsuch failures, and enable a preliminary discussion on possible mitigating\nstrategies. Workshop website: https://sites.google.com/view/wtf2023/overview\n  Is CUI Design Ready Yet? As CUIs become more prevalent in both academic\nresearch and the commercial market, it becomes more essential to design usable\nand adoptable CUIs. While research has been growing on the methods for\ndesigning CUIs for commercial use, there has been little discussion on the\noverall community practice of developing design resources to aid in practical\nCUI design. The aim of this workshop, therefore, is to bring the CUI community\ntogether to discuss the current practices for developing tools and resources\nfor practical CUI design, the adoption (or non-adoption) of these tools and\nresources, and how these resources are utilized in the training and education\nof new CUI designers entering the field. Workshop website:\nhttps://speech-interaction.org/cui2023_design_workshop/index.html", "published": "2023-09-04 16:26:37", "link": "http://arxiv.org/abs/2401.04108v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.RO", "A.0; I.2.7; I.2.9"], "primary_category": "cs.HC"}
{"title": "Single-Channel Speech Enhancement with Deep Complex U-Networks and\n  Probabilistic Latent Space Models", "abstract": "In this paper, we propose to extend the deep, complex U-Network architecture\nfor speech enhancement by incorporating a probabilistic (i.e., variational)\nlatent space model. The proposed model is evaluated against several ablated\nversions of itself in order to study the effects of the variational latent\nspace model, complex-value processing, and self-attention. Evaluation on the\nMS-DNS 2020 and Voicebank+Demand datasets yields consistently high performance.\nE.g., the proposed model achieves an SI-SDR of up to 20.2 dB, about 0.5 to 1.4\ndB higher than its ablated version without probabilistic latent space, 2-2.4 dB\nhigher than WaveUNet, and 6.7 dB above PHASEN. Compared to real-valued\nmagnitude spectrogram processing with a variational U-Net, the complex U-Net\nachieves an improvement of up to 4.5 dB SI-SDR. Complex spectrum encoding as\nmagnitude and phase yields best performance in anechoic conditions whereas real\nand imaginary part representation results in better generalization to (novel)\nreverberation conditions, possibly due to the underlying physics of sound.", "published": "2023-09-04 11:30:32", "link": "http://arxiv.org/abs/2309.01535v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MDSC: Towards Evaluating the Style Consistency Between Music and Dance", "abstract": "We propose MDSC(Music-Dance-Style Consistency), the first evaluation metric\nthat assesses to what degree the dance moves and music match. Existing metrics\ncan only evaluate the motion fidelity and diversity and the degree of rhythmic\nmatching between music and dance. MDSC measures how stylistically correlated\nthe generated dance motion sequences and the conditioning music sequences are.\nWe found that directly measuring the embedding distance between motion and\nmusic is not an optimal solution. We instead tackle this through modeling it as\na clustering problem. Specifically, 1) we pre-train a music encoder and a\nmotion encoder, then 2) we learn to map and align the motion and music\nembedding in joint space by jointly minimizing the intra-cluster distance and\nmaximizing the inter-cluster distance, and 3) for evaluation purposes, we\nencode the dance moves into embedding and measure the intra-cluster and\ninter-cluster distances, as well as the ratio between them. We evaluate our\nmetric on the results of several music-conditioned motion generation methods,\ncombined with user study, we found that our proposed metric is a robust\nevaluation metric in measuring the music-dance style correlation.", "published": "2023-09-04 03:55:41", "link": "http://arxiv.org/abs/2309.01340v3", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EventTrojan: Manipulating Non-Intrusive Speech Quality Assessment via\n  Imperceptible Events", "abstract": "Non-Intrusive speech quality assessment (NISQA) has gained significant\nattention for predicting speech's mean opinion score (MOS) without requiring\nthe reference speech. Researchers have gradually started to apply NISQA to\nvarious practical scenarios. However, little attention has been paid to the\nsecurity of NISQA models. Backdoor attacks represent the most serious threat to\ndeep neural networks (DNNs) due to the fact that backdoors possess a very high\nattack success rate once embedded. However, existing backdoor attacks assume\nthat the attacker actively feeds samples containing triggers into the model\nduring the inference phase. This is not adapted to the specific scenario of\nNISQA. And current backdoor attacks on regression tasks lack an objective\nmetric to measure the attack performance. To address these issues, we propose a\nnovel backdoor triggering approach (EventTrojan) that utilizes an event during\nthe usage of the NISQA model as a trigger. Moreover, we innovatively provide an\nobjective metric for backdoor attacks on regression tasks. Extensive\nexperiments on four benchmark datasets demonstrate the effectiveness of the\nEventTrojan attack. Besides, it also has good resistance to several defense\nmethods.", "published": "2023-09-04 09:35:53", "link": "http://arxiv.org/abs/2309.01480v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RGI-Net: 3D Room Geometry Inference from Room Impulse Responses With\n  Hidden First-Order Reflections", "abstract": "Room geometry is important prior information for implementing realistic 3D\naudio rendering. For this reason, various room geometry inference (RGI) methods\nhave been developed by utilizing the time-of-arrival (TOA) or\ntime-difference-of-arrival (TDOA) information in room impulse responses (RIRs).\nHowever, the conventional RGI technique poses several assumptions, such as\nconvex room shapes, the number of walls known in priori, and the visibility of\nfirst-order reflections. In this work, we introduce the RGI-Net which can\nestimate room geometries without the aforementioned assumptions. RGI-Net learns\nand exploits complex relationships between low-order and high-order reflections\nin RIRs and, thus, can estimate room shapes even when the shape is non-convex\nor first-order reflections are missing in the RIRs. RGI-Net includes the\nevaluation network that separately evaluates the presence probability of walls,\nso the geometry inference is possible without prior knowledge of the number of\nwalls.", "published": "2023-09-04 10:45:53", "link": "http://arxiv.org/abs/2309.01513v4", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Quid Manumit -- Freeing the Qubit for Art", "abstract": "This paper describes how to `Free the Qubit' for art, by creating standalone\nquantum musical effects and instruments. Previously released quantum simulator\ncode for an ARM-based Raspberry Pi Pico embedded microcontroller is utilised\nhere, and several examples are built demonstrating different methods of\nutilising embedded resources: The first is a Quantum MIDI processor that\ngenerates additional notes for accompaniment and unique quantum generated\ninstruments based on the input notes, decoded and passed through a quantum\ncircuit in an embedded simulator. The second is a Quantum Distortion module\nthat changes an instrument's raw sound according to a quantum circuit, which is\npresented in two forms; a self-contained Quantum Stylophone, and an effect\nmodule plugin called 'QubitCrusher' for the Korg Nu:Tekt NTS-1. This paper also\ndiscusses future work and directions for quantum instruments, and provides all\nexamples as open source. This is, to the author's knowledge, the first example\nof embedded Quantum Simulators for Instruments of Music (another QSIM).", "published": "2023-09-04 11:19:51", "link": "http://arxiv.org/abs/2309.03104v1", "categories": ["quant-ph", "cs.ET", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "quant-ph"}
