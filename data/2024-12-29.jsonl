{"title": "Understanding the Impact of Confidence in Retrieval Augmented\n  Generation: A Case Study in the Medical Domain", "abstract": "Retrieval Augmented Generation (RAG) complements the knowledge of Large\nLanguage Models (LLMs) by leveraging external information to enhance response\naccuracy for queries. This approach is widely applied in several fields by\ntaking its advantage of injecting the most up-to-date information, and\nresearchers are focusing on understanding and improving this aspect to unlock\nthe full potential of RAG in such high-stakes applications. However, despite\nthe potential of RAG to address these needs, the mechanisms behind the\nconfidence levels of its outputs remain underexplored, although the confidence\nof information is very critical in some domains, such as finance, healthcare,\nand medicine. Our study focuses the impact of RAG on confidence within the\nmedical domain under various configurations and models. We evaluate confidence\nby treating the model's predicted probability as its output and calculating\nExpected Calibration Error (ECE) and Adaptive Calibration Error (ACE) scores\nbased on the probabilities and accuracy. In addition, we analyze whether the\norder of retrieved documents within prompts calibrates the confidence. Our\nfindings reveal large variation in confidence and accuracy depending on the\nmodel, settings, and the format of input prompts. These results underscore the\nnecessity of optimizing configurations based on the specific model and\nconditions.", "published": "2024-12-29 00:58:33", "link": "http://arxiv.org/abs/2412.20309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Entertainment Translation for Indian Languages using Adaptive\n  Context, Style and LLMs", "abstract": "We address the challenging task of neural machine translation (NMT) in the\nentertainment domain, where the objective is to automatically translate a given\ndialogue from a source language content to a target language. This task has\nvarious applications, particularly in automatic dubbing, subtitling, and other\ncontent localization tasks, enabling source content to reach a wider audience.\nTraditional NMT systems typically translate individual sentences in isolation,\nwithout facilitating knowledge transfer of crucial elements such as the context\nand style from previously encountered sentences. In this work, we emphasize the\nsignificance of these fundamental aspects in producing pertinent and\ncaptivating translations. We demonstrate their significance through several\nexamples and propose a novel framework for entertainment translation, which, to\nour knowledge, is the first of its kind. Furthermore, we introduce an algorithm\nto estimate the context and style of the current session and use these\nestimations to generate a prompt that guides a Large Language Model (LLM) to\ngenerate high-quality translations. Our method is both language and\nLLM-agnostic, making it a general-purpose tool. We demonstrate the\neffectiveness of our algorithm through various numerical studies and observe\nsignificant improvement in the COMET scores over various state-of-the-art LLMs.\nMoreover, our proposed method consistently outperforms baseline LLMs in terms\nof win-ratio.", "published": "2024-12-29 11:33:51", "link": "http://arxiv.org/abs/2412.20440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Utilizing Multimodal Data for Edge Case Robust Call-sign Recognition and\n  Understanding", "abstract": "Operational machine-learning based assistant systems must be robust in a wide\nrange of scenarios. This hold especially true for the air-traffic control (ATC)\ndomain. The robustness of an architecture is particularly evident in edge\ncases, such as high word error rate (WER) transcripts resulting from noisy ATC\nrecordings or partial transcripts due to clipped recordings. To increase the\nedge-case robustness of call-sign recognition and understanding (CRU), a core\ntasks in ATC speech processing, we propose the multimodal call-sign-command\nrecovery model (CCR). The CCR architecture leads to an increase in the edge\ncase performance of up to 15%. We demonstrate this on our second proposed\narchitecture, CallSBERT. A CRU model that has less parameters, can be\nfine-tuned noticeably faster and is more robust during fine-tuning than the\nstate of the art for CRU. Furthermore, we demonstrate that optimizing for edge\ncases leads to a significantly higher accuracy across a wide operational range.", "published": "2024-12-29 13:45:11", "link": "http://arxiv.org/abs/2412.20467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactual Samples Constructing and Training for Commonsense\n  Statements Estimation", "abstract": "Plausibility Estimation (PE) plays a crucial role for enabling language\nmodels to objectively comprehend the real world. While large language models\n(LLMs) demonstrate remarkable capabilities in PE tasks but sometimes produce\ntrivial commonsense errors due to the complexity of commonsense knowledge. They\nlack two key traits of an ideal PE model: a) Language-explainable: relying on\ncritical word segments for decisions, and b) Commonsense-sensitive: detecting\nsubtle linguistic variations in commonsense. To address these issues, we\npropose a novel model-agnostic method, referred to as Commonsense\nCounterfactual Samples Generating (CCSG). By training PE models with CCSG, we\nencourage them to focus on critical words, thereby enhancing both their\nlanguage-explainable and commonsense-sensitive capabilities. Specifically, CCSG\ngenerates counterfactual samples by strategically replacing key words and\nintroducing low-level dropout within sentences. These counterfactual samples\nare then incorporated into a sentence-level contrastive training framework to\nfurther enhance the model's learning process. Experimental results across nine\ndiverse datasets demonstrate the effectiveness of CCSG in addressing\ncommonsense reasoning challenges, with our CCSG method showing 3.07%\nimprovement against the SOTA methods.", "published": "2024-12-29 20:18:52", "link": "http://arxiv.org/abs/2412.20563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Neural No-Resource Language Translation: A Comparative\n  Evaluation of Approaches", "abstract": "No-resource languages - those with minimal or no digital representation -\npose unique challenges for machine translation (MT). Unlike low-resource\nlanguages, which rely on limited but existent corpora, no-resource languages\noften have fewer than 100 sentences available for training. This work explores\nthe problem of no-resource translation through three distinct workflows:\nfine-tuning of translation-specific models, in-context learning with large\nlanguage models (LLMs) using chain-of-reasoning prompting, and direct prompting\nwithout reasoning. Using Owens Valley Paiute as a case study, we demonstrate\nthat no-resource translation demands fundamentally different approaches from\nlow-resource scenarios, as traditional approaches to machine translation, such\nas those that work for low-resource languages, fail. Empirical results reveal\nthat, although traditional approaches fail, the in-context learning\ncapabilities of general-purpose large language models enable no-resource\nlanguage translation that outperforms low-resource translation approaches and\nrivals human translations (BLEU 0.45-0.6); specifically, chain-of-reasoning\nprompting outperforms other methods for larger corpora, while direct prompting\nexhibits advantages in smaller datasets. As these approaches are\nlanguage-agnostic, they have potential to be generalized to translation tasks\nfrom a wide variety of no-resource languages without expert input. These\nfindings establish no-resource translation as a distinct paradigm requiring\ninnovative solutions, providing practical and theoretical insights for language\npreservation.", "published": "2024-12-29 21:12:39", "link": "http://arxiv.org/abs/2412.20584v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GliLem: Leveraging GliNER for Contextualized Lemmatization in Estonian", "abstract": "We present GliLem -- a novel hybrid lemmatization system for Estonian that\nenhances the highly accurate rule-based morphological analyzer Vabamorf with an\nexternal disambiguation module based on GliNER -- an open vocabulary NER model\nthat is able to match text spans with text labels in natural language. We\nleverage the flexibility of a pre-trained GliNER model to improve the\nlemmatization accuracy of Vabamorf by 10% compared to its original\ndisambiguation module and achieve an improvement over the token\nclassification-based baseline. To measure the impact of improvements in\nlemmatization accuracy on the information retrieval downstream task, we first\ncreated an information retrieval dataset for Estonian by automatically\ntranslating the DBpedia-Entity dataset from English. We benchmark several token\nnormalization approaches, including lemmatization, on the created dataset using\nthe BM25 algorithm. We observe a substantial improvement in IR metrics when\nusing lemmatization over simplistic stemming. The benefits of improving lemma\ndisambiguation accuracy manifest in small but consistent improvement in the IR\nrecall measure, especially in the setting of high k.", "published": "2024-12-29 22:02:00", "link": "http://arxiv.org/abs/2412.20597v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLP-based Regulatory Compliance -- Using GPT 4.0 to Decode Regulatory\n  Documents", "abstract": "Large Language Models (LLMs) such as GPT-4.0 have shown significant promise\nin addressing the semantic complexities of regulatory documents, particularly\nin detecting inconsistencies and contradictions. This study evaluates GPT-4.0's\nability to identify conflicts within regulatory requirements by analyzing a\ncurated corpus with artificially injected ambiguities and contradictions,\ndesigned in collaboration with architects and compliance engineers. Using\nmetrics such as precision, recall, and F1 score, the experiment demonstrates\nGPT-4.0's effectiveness in detecting inconsistencies, with findings validated\nby human experts. The results highlight the potential of LLMs to enhance\nregulatory compliance processes, though further testing with larger datasets\nand domain-specific fine-tuning is needed to maximize accuracy and practical\napplicability. Future work will explore automated conflict resolution and\nreal-world implementation through pilot projects with industry partners.", "published": "2024-12-29 22:14:59", "link": "http://arxiv.org/abs/2412.20602v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HindiLLM: Large Language Model for Hindi", "abstract": "The advancements in the Large Language Model (LLM) have helped in solving\nseveral problems related to language processing. Most of the researches have\nfocused on the English language only, because of its popularity and abundance\non the internet. However, a high-performance language model for Hindi and other\nIndic languages is lacking in the literature. In this work, we have pre-trained\ntwo autoregressive LLM models for the Hindi language, namely HindiLLM-Small and\nHindiLLM-Medium. We use a two-step process comprising unsupervised pre-training\nand supervised fine-tuning. First, we create a large and high-quality text\ncorpus for unsupervised pre-training. Next, we train a Byte-Pair Encoding,\nnamed HindiLLM tokenizer, using the pre-training text data. We then perform\ntraining on the unlabeled data, known as the pre-training step, to get the\nHindiLLM base models. Furthermore, we perform fine-tuning of the HindiLLM base\nmodels for different tasks like sentiment analysis, text classification,\nnatural language inference, and multiple choice question-answer on popular\nlabeled datasets to measure the real-world performance. The evaluation shows\nthat the HindiLLM-based fine-tuned models outperform several models in most of\nthe language related tasks.", "published": "2024-12-29 05:28:15", "link": "http://arxiv.org/abs/2412.20357v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Code LLMs with Reinforcement Learning in Code Generation: A\n  Survey", "abstract": "With the rapid evolution of large language models (LLM), reinforcement\nlearning (RL) has emerged as a pivotal technique for code generation and\noptimization in various domains. This paper presents a systematic survey of the\napplication of RL in code optimization and generation, highlighting its role in\nenhancing compiler optimization, resource allocation, and the development of\nframeworks and tools. Subsequent sections first delve into the intricate\nprocesses of compiler optimization, where RL algorithms are leveraged to\nimprove efficiency and resource utilization. The discussion then progresses to\nthe function of RL in resource allocation, emphasizing register allocation and\nsystem optimization. We also explore the burgeoning role of frameworks and\ntools in code generation, examining how RL can be integrated to bolster their\ncapabilities. This survey aims to serve as a comprehensive resource for\nresearchers and practitioners interested in harnessing the power of RL to\nadvance code generation and optimization techniques.", "published": "2024-12-29 06:15:41", "link": "http://arxiv.org/abs/2412.20367v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "LLM2: Let Large Language Models Harness System 2 Reasoning", "abstract": "Large language models (LLMs) have exhibited impressive capabilities across a\nmyriad of tasks, yet they occasionally yield undesirable outputs. We posit that\nthese limitations are rooted in the foundational autoregressive architecture of\nLLMs, which inherently lacks mechanisms for differentiating between desirable\nand undesirable results. Drawing inspiration from the dual-process theory of\nhuman cognition, we introduce LLM2, a novel framework that combines an LLM\n(System 1) with a process-based verifier (System 2). Within LLM2, the LLM is\nresponsible for generating plausible candidates, while the verifier provides\ntimely process-based feedback to distinguish desirable and undesirable outputs.\nThe verifier is trained with a pairwise comparison loss on synthetic\nprocess-supervision data generated through our token quality exploration\nstrategy. Empirical results on mathematical reasoning benchmarks substantiate\nthe efficacy of LLM2, exemplified by an accuracy enhancement from 50.3 to 57.8\n(+7.5) for Llama3-1B on GSM8K. Furthermore, when combined with\nself-consistency, LLM2 achieves additional improvements, boosting major@20\naccuracy from 56.2 to 70.2 (+14.0).", "published": "2024-12-29 06:32:36", "link": "http://arxiv.org/abs/2412.20372v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Natural Language Fine-Tuning", "abstract": "Large language model fine-tuning techniques typically depend on extensive\nlabeled data, external guidance, and feedback, such as human alignment, scalar\nrewards, and demonstration. However, in practical application, the scarcity of\nspecific knowledge poses unprecedented challenges to existing fine-tuning\ntechniques. In this paper, focusing on fine-tuning tasks in specific domains\nwith limited data, we introduce Natural Language Fine-Tuning (NLFT), which\nutilizes natural language for fine-tuning for the first time. By leveraging the\nstrong language comprehension capability of the target LM, NLFT attaches the\nguidance of natural language to the token-level outputs. Then, saliency tokens\nare identified with calculated probabilities. Since linguistic information is\neffectively utilized in NLFT, our proposed method significantly reduces\ntraining costs. It markedly enhances training efficiency, comprehensively\noutperforming reinforcement fine-tuning algorithms in accuracy, time-saving,\nand resource conservation. Additionally, on the macro level, NLFT can be viewed\nas a token-level fine-grained optimization of SFT, thereby efficiently\nreplacing the SFT process without the need for warm-up (as opposed to ReFT\nrequiring multiple rounds of warm-up with SFT). Compared to SFT, NLFT does not\nincrease the algorithmic complexity, maintaining O(n). Extensive experiments on\nthe GSM8K dataset demonstrate that NLFT, with only 50 data instances, achieves\nan accuracy increase that exceeds SFT by 219%. Compared to ReFT, the time\ncomplexity and space complexity of NLFT are reduced by 78.27% and 92.24%,\nrespectively. The superior technique of NLFT is paving the way for the\ndeployment of various innovative LLM fine-tuning applications when resources\nare limited at network edges.\n  Our code has been released at https://github.com/Julia-LiuJ/NLFT.", "published": "2024-12-29 07:02:45", "link": "http://arxiv.org/abs/2412.20382v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cut the Deadwood Out: Post-Training Model Purification with Selective\n  Module Substitution", "abstract": "The success of DNNs often depends on training with large-scale datasets, but\nbuilding such datasets is both expensive and challenging. Consequently, public\ndatasets from open-source platforms like HuggingFace have become popular,\nposing significant risks of data poisoning attacks. Existing backdoor defenses\nin NLP primarily focus on identifying and removing poisoned samples; however,\npurifying a backdoored model with these sample-cleaning approaches typically\nrequires expensive retraining. Therefore, we propose Greedy Module Substitution\n(GMS), which identifies and substitutes ''deadwood'' modules (i.e., components\ncritical to backdoor pathways) in a backdoored model to purify it. Our method\nrelaxes the common dependency of prior model purification methods on clean\ndatasets or clean auxiliary models. When applied to RoBERTa-large under\nbackdoor attacks, GMS demonstrates strong effectiveness across various\nsettings, particularly against widely recognized challenging attacks like LWS,\nachieving a post-purification attack success rate (ASR) of 9.7% on SST-2\ncompared to 58.8% for the best baseline approach.", "published": "2024-12-29 14:29:34", "link": "http://arxiv.org/abs/2412.20476v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "SAFE-MEME: Structured Reasoning Framework for Robust Hate Speech\n  Detection in Memes", "abstract": "Memes act as cryptic tools for sharing sensitive ideas, often requiring\ncontextual knowledge to interpret. This makes moderating multimodal memes\nchallenging, as existing works either lack high-quality datasets on nuanced\nhate categories or rely on low-quality social media visuals. Here, we curate\ntwo novel multimodal hate speech datasets, MHS and MHS-Con, that capture\nfine-grained hateful abstractions in regular and confounding scenarios,\nrespectively. We benchmark these datasets against several competing baselines.\nFurthermore, we introduce SAFE-MEME (Structured reAsoning FramEwork), a novel\nmultimodal Chain-of-Thought-based framework employing Q&A-style reasoning\n(SAFE-MEME-QA) and hierarchical categorization (SAFE-MEME-H) to enable robust\nhate speech detection in memes. SAFE-MEME-QA outperforms existing baselines,\nachieving an average improvement of approximately 5% and 4% on MHS and MHS-Con,\nrespectively. In comparison, SAFE-MEME-H achieves an average improvement of 6%\nin MHS while outperforming only multimodal baselines in MHS-Con. We show that\nfine-tuning a single-layer adapter within SAFE-MEME-H outperforms fully\nfine-tuned models in regular fine-grained hateful meme detection. However, the\nfully fine-tuning approach with a Q&A setup is more effective for handling\nconfounding cases. We also systematically examine the error cases, offering\nvaluable insights into the robustness and limitations of the proposed\nstructured reasoning framework for analyzing hateful memes.", "published": "2024-12-29 18:16:28", "link": "http://arxiv.org/abs/2412.20541v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Controlling Out-of-Domain Gaps in LLMs for Genre Classification and\n  Generated Text Detection", "abstract": "This study demonstrates that the modern generation of Large Language Models\n(LLMs, such as GPT-4) suffers from the same out-of-domain (OOD) performance gap\nobserved in prior research on pre-trained Language Models (PLMs, such as BERT).\nWe demonstrate this across two non-topical classification tasks: 1) genre\nclassification and 2) generated text detection. Our results show that when\ndemonstration examples for In-Context Learning (ICL) come from one domain\n(e.g., travel) and the system is tested on another domain (e.g., history),\nclassification performance declines significantly.\n  To address this, we introduce a method that controls which predictive\nindicators are used and which are excluded during classification. For the two\ntasks studied here, this ensures that topical features are omitted, while the\nmodel is guided to focus on stylistic rather than content-based attributes.\nThis approach reduces the OOD gap by up to 20 percentage points in a few-shot\nsetup. Straightforward Chain-of-Thought (CoT) methods, used as the baseline,\nprove insufficient, while our approach consistently enhances domain transfer\nperformance.", "published": "2024-12-29 21:54:39", "link": "http://arxiv.org/abs/2412.20595v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ELECTRA and GPT-4o: Cost-Effective Partners for Sentiment Analysis", "abstract": "Bidirectional transformers excel at sentiment analysis, and Large Language\nModels (LLM) are effective zero-shot learners. Might they perform better as a\nteam? This paper explores collaborative approaches between ELECTRA and GPT-4o\nfor three-way sentiment classification. We fine-tuned (FT) four models (ELECTRA\nBase/Large, GPT-4o/4o-mini) using a mix of reviews from Stanford Sentiment\nTreebank (SST) and DynaSent. We provided input from ELECTRA to GPT as:\npredicted label, probabilities, and retrieved examples. Sharing ELECTRA Base FT\npredictions with GPT-4o-mini significantly improved performance over either\nmodel alone (82.74 macro F1 vs. 79.29 ELECTRA Base FT, 79.52 GPT-4o-mini) and\nyielded the lowest cost/performance ratio (\\$0.12/F1 point). However, when GPT\nmodels were fine-tuned, including predictions decreased performance. GPT-4o\nFT-M was the top performer (86.99), with GPT-4o-mini FT close behind (86.77) at\nmuch less cost (\\$0.38 vs. \\$1.59/F1 point). Our results show that augmenting\nprompts with predictions from fine-tuned encoders is an efficient way to boost\nperformance, and a fine-tuned GPT-4o-mini is nearly as good as GPT-4o FT at 76%\nless cost. Both are affordable options for projects with limited resources.", "published": "2024-12-29 05:29:52", "link": "http://arxiv.org/abs/2501.00062v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adversarial Negotiation Dynamics in Generative Language Models", "abstract": "Generative language models are increasingly used for contract drafting and\nenhancement, creating a scenario where competing parties deploy different\nlanguage models against each other. This introduces not only a game-theory\nchallenge but also significant concerns related to AI safety and security, as\nthe language model employed by the opposing party can be unknown. These\ncompetitive interactions can be seen as adversarial testing grounds, where\nmodels are effectively red-teamed to expose vulnerabilities such as generating\nbiased, harmful or legally problematic text. Despite the importance of these\nchallenges, the competitive robustness and safety of these models in\nadversarial settings remain poorly understood. In this small study, we approach\nthis problem by evaluating the performance and vulnerabilities of major\nopen-source language models in head-to-head competitions, simulating real-world\ncontract negotiations. We further explore how these adversarial interactions\ncan reveal potential risks, informing the development of more secure and\nreliable models. Our findings contribute to the growing body of research on AI\nsafety, offering insights into model selection and optimisation in competitive\nlegal contexts and providing actionable strategies for mitigating risks.", "published": "2024-12-29 18:17:55", "link": "http://arxiv.org/abs/2501.00069v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multidisciplinary Approach to Telegram Data Analysis", "abstract": "This paper presents a multidisciplinary approach to analyzing data from\nTelegram for early warning information regarding cyber threats. With the\nproliferation of hacktivist groups utilizing Telegram to disseminate\ninformation regarding future cyberattacks or to boast about successful ones,\nthe need for effective data analysis methods is paramount. The primary\nchallenge lies in the vast number of channels and the overwhelming volume of\ndata, necessitating advanced techniques for discerning pertinent risks amidst\nthe noise. To address this challenge, we employ a combination of neural network\narchitectures and traditional machine learning algorithms. These methods are\nutilized to classify and identify potential cyber threats within the Telegram\ndata. Additionally, sentiment analysis and entity recognition techniques are\nincorporated to provide deeper insights into the nature and context of the\ncommunicated information. The study evaluates the effectiveness of each method\nin detecting and categorizing cyber threats, comparing their performance and\nidentifying areas for improvement. By leveraging these diverse analytical\ntools, we aim to enhance early warning systems for cyber threats, enabling more\nproactive responses to potential security breaches. This research contributes\nto the ongoing efforts to bolster cybersecurity measures in an increasingly\ninterconnected digital landscape.", "published": "2024-12-29 09:10:52", "link": "http://arxiv.org/abs/2412.20406v1", "categories": ["cs.CR", "cs.CL", "cs.LG", "F.2.2; I.2.6; I.2.8; I.5.2"], "primary_category": "cs.CR"}
{"title": "Multi-Objective Large Language Model Unlearning", "abstract": "Machine unlearning in the domain of large language models (LLMs) has\nattracted great attention recently, which aims to effectively eliminate\nundesirable behaviors from LLMs without full retraining from scratch. In this\npaper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is\na proactive way to decrease the prediction probability of the model on the\ntarget data in order to remove their influence. We analyze two challenges that\nrender the process impractical: gradient explosion and catastrophic forgetting.\nTo address these issues, we propose Multi-Objective Large Language Model\nUnlearning (MOLLM) algorithm. We first formulate LLM unlearning as a\nmulti-objective optimization problem, in which the cross-entropy loss is\nmodified to the unlearning version to overcome the gradient explosion issue. A\ncommon descent update direction is then calculated, which enables the model to\nforget the target data while preserving the utility of the LLM. Our empirical\nresults verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods\nin terms of unlearning effect and model utility preservation. The source code\nis available at https://github.com/zibinpan/MOLLM.", "published": "2024-12-29 09:35:56", "link": "http://arxiv.org/abs/2412.20412v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparative Performance of Advanced NLP Models and LLMs in Multilingual\n  Geo-Entity Detection", "abstract": "The integration of advanced Natural Language Processing (NLP) methodologies\nand Large Language Models (LLMs) has significantly enhanced the extraction and\nanalysis of geospatial data from multilingual texts, impacting sectors such as\nnational and international security. This paper presents a comprehensive\nevaluation of leading NLP models -- SpaCy, XLM-RoBERTa, mLUKE, GeoLM -- and\nLLMs, specifically OpenAI's GPT 3.5 and GPT 4, within the context of\nmultilingual geo-entity detection. Utilizing datasets from Telegram channels in\nEnglish, Russian, and Arabic, we examine the performance of these models\nthrough metrics such as accuracy, precision, recall, and F1 scores, to assess\ntheir effectiveness in accurately identifying geospatial references. The\nanalysis exposes each model's distinct advantages and challenges, underscoring\nthe complexities involved in achieving precise geo-entity identification across\nvaried linguistic landscapes. The conclusions drawn from this experiment aim to\ndirect the enhancement and creation of more advanced and inclusive NLP tools,\nthus advancing the field of geospatial analysis and its application to global\nsecurity.", "published": "2024-12-29 09:47:14", "link": "http://arxiv.org/abs/2412.20414v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Integrating Natural Language Processing Techniques of Text Mining Into\n  Financial System: Applications and Limitations", "abstract": "The financial sector, a pivotal force in economic development, increasingly\nuses the intelligent technologies such as natural language processing to\nenhance data processing and insight extraction. This research paper through a\nreview process of the time span of 2018-2023 explores the use of text mining as\nnatural language processing techniques in various components of the financial\nsystem including asset pricing, corporate finance, derivatives, risk\nmanagement, and public finance and highlights the need to address the specific\nproblems in the discussion section. We notice that most of the research\nmaterials combined probabilistic with vector-space models, and text-data with\nnumerical ones. The most used technique regarding information processing is the\ninformation classification technique and the most used algorithms include the\nlong-short term memory and bidirectional encoder models. The research noticed\nthat new specific algorithms are developed and the focus of the financial\nsystem is mainly on asset pricing component. The research also proposes a path\nfrom engineering perspective for researchers who need to analyze financial\ntext. The challenges regarding text mining perspective such as data quality,\ncontext-adaption and model interpretability need to be solved so to integrate\nadvanced natural language processing models and techniques in enhancing\nfinancial analysis and prediction. Keywords: Financial System (FS), Natural\nLanguage Processing (NLP), Software and Text Engineering, Probabilistic,\nVector-Space, Models, Techniques, TextData, Financial Analysis.", "published": "2024-12-29 11:25:03", "link": "http://arxiv.org/abs/2412.20438v1", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video\n  Understanding", "abstract": "Video Large Language Models (VideoLLMs) have made significant strides in\nvideo understanding but struggle with long videos due to the limitations of\ntheir backbone LLMs. Existing solutions rely on length extrapolation, which is\nmemory-constrained, or visual token compression, which primarily leverages\nlow-level temporal redundancy while overlooking the more effective high-level\nknowledge redundancy. To address this, we propose $\\textbf{ReTaKe}$, a\ntraining-free method with two novel modules DPSelect and PivotKV, to jointly\nreduce both temporal visual redundancy and knowledge redundancy for video\ncompression. To align with the way of human temporal perception, DPSelect\nidentifies keyframes based on inter-frame distance peaks. To leverage LLMs'\nlearned prior knowledge, PivotKV marks the keyframes as pivots and compress\nnon-pivot frames by pruning low-attention tokens in their KV cache. ReTaKe\nenables VideoLLMs to process 8 times longer frames (up to 2048), outperforming\nsimilar-sized models by 3-5% and even rivaling much larger ones on VideoMME,\nMLVU, LongVideoBench, and LVBench. Moreover, by overlapping compression\noperations with prefilling, ReTaKe introduces only ~10% prefilling latency\noverhead while reducing decoding latency by ~20%. Our code is available at\nhttps://github.com/SCZwangxiao/video-ReTaKe.", "published": "2024-12-29 15:42:24", "link": "http://arxiv.org/abs/2412.20504v5", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "The Impact of Prompt Programming on Function-Level Code Generation", "abstract": "Large Language Models (LLMs) are increasingly used by software engineers for\ncode generation. However, limitations of LLMs such as irrelevant or incorrect\ncode have highlighted the need for prompt programming (or prompt engineering)\nwhere engineers apply specific prompt techniques (e.g., chain-of-thought or\ninput-output examples) to improve the generated code. Despite this, the impact\nof different prompt techniques -- and their combinations -- on code generation\nremains underexplored. In this study, we introduce CodePromptEval, a dataset of\n7072 prompts designed to evaluate five prompt techniques (few-shot, persona,\nchain-of-thought, function signature, list of packages) and their effect on the\ncorrectness, similarity, and quality of complete functions generated by three\nLLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt\ntechniques significantly influence the generated code, combining multiple\ntechniques does not necessarily improve the outcome. Additionally, we observed\na trade-off between correctness and quality when using prompt techniques. Our\ndataset and replication package enable future research on improving\nLLM-generated code and evaluating new prompt techniques.", "published": "2024-12-29 18:34:10", "link": "http://arxiv.org/abs/2412.20545v1", "categories": ["cs.SE", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.SE"}
{"title": "On Adversarial Robustness of Language Models in Transfer Learning", "abstract": "We investigate the adversarial robustness of LLMs in transfer learning\nscenarios. Through comprehensive experiments on multiple datasets (MBIB Hate\nSpeech, MBIB Political Bias, MBIB Gender Bias) and various model architectures\n(BERT, RoBERTa, GPT-2, Gemma, Phi), we reveal that transfer learning, while\nimproving standard performance metrics, often leads to increased vulnerability\nto adversarial attacks. Our findings demonstrate that larger models exhibit\ngreater resilience to this phenomenon, suggesting a complex interplay between\nmodel size, architecture, and adaptation methods. Our work highlights the\ncrucial need for considering adversarial robustness in transfer learning\nscenarios and provides insights into maintaining model security without\ncompromising performance. These findings have significant implications for the\ndevelopment and deployment of LLMs in real-world applications where both\nperformance and robustness are paramount.", "published": "2024-12-29 15:55:35", "link": "http://arxiv.org/abs/2501.00066v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ICLR: In-Context Learning of Representations", "abstract": "Recent work has demonstrated that semantics specified by pretraining data\ninfluence how representations of different concepts are organized in a large\nlanguage model (LLM). However, given the open-ended nature of LLMs, e.g., their\nability to in-context learn, we can ask whether models alter these pretraining\nsemantics to adopt alternative, context-specified ones. Specifically, if we\nprovide in-context exemplars wherein a concept plays a different role than what\nthe pretraining data suggests, do models reorganize their representations in\naccordance with these novel semantics? To answer this question, we take\ninspiration from the theory of conceptual role semantics and define a toy\n\"graph tracing\" task wherein the nodes of the graph are referenced via concepts\nseen during training (e.g., apple, bird, etc.) and the connectivity of the\ngraph is defined via some predefined structure (e.g., a square grid). Given\nexemplars that indicate traces of random walks on the graph, we analyze\nintermediate representations of the model and find that as the amount of\ncontext is scaled, there is a sudden re-organization from pretrained semantic\nrepresentations to in-context representations aligned with the graph structure.\nFurther, we find that when reference concepts have correlations in their\nsemantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure\nis still present in the representations, but is unable to dominate the\npretrained structure. To explain these results, we analogize our task to energy\nminimization for a predefined graph topology, providing evidence towards an\nimplicit optimization process to infer context-specified semantics. Overall,\nour findings indicate scaling context-size can flexibly re-organize model\nrepresentations, possibly unlocking novel capabilities.", "published": "2024-12-29 18:58:09", "link": "http://arxiv.org/abs/2501.00070v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Is Your Image a Good Storyteller?", "abstract": "Quantifying image complexity at the entity level is straightforward, but the\nassessment of semantic complexity has been largely overlooked. In fact, there\nare differences in semantic complexity across images. Images with richer\nsemantics can tell vivid and engaging stories and offer a wide range of\napplication scenarios. For example, the Cookie Theft picture is such a kind of\nimage and is widely used to assess human language and cognitive abilities due\nto its higher semantic complexity. Additionally, semantically rich images can\nbenefit the development of vision models, as images with limited semantics are\nbecoming less challenging for them. However, such images are scarce,\nhighlighting the need for a greater number of them. For instance, there is a\nneed for more images like Cookie Theft to cater to people from different\ncultural backgrounds and eras. Assessing semantic complexity requires human\nexperts and empirical evidence. Automatic evaluation of how semantically rich\nan image will be the first step of mining or generating more images with rich\nsemantics, and benefit human cognitive assessment, Artificial Intelligence, and\nvarious other applications. In response, we propose the Image Semantic\nAssessment (ISA) task to address this problem. We introduce the first ISA\ndataset and a novel method that leverages language to solve this vision\nproblem. Experiments on our dataset demonstrate the effectiveness of our\napproach.", "published": "2024-12-29 14:04:39", "link": "http://arxiv.org/abs/2501.01982v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Synergy of Automated Pipelines with Prompt Engineering and\n  Generative AI in Web Crawling", "abstract": "Web crawling is a critical technique for extracting online data, yet it poses\nchallenges due to webpage diversity and anti-scraping mechanisms. This study\ninvestigates the integration of generative AI tools Claude AI (Sonnet 3.5) and\nChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts,\nPROMPT I (general inference, tested on Yahoo News) and PROMPT II\n(element-specific, tested on Coupons.com), we evaluate the code quality and\nperformance of AI-generated scripts. Claude AI consistently outperformed\nChatGPT-4.0 in script quality and adaptability, as confirmed by predefined\nevaluation metrics, including functionality, readability, modularity, and\nrobustness. Performance data were collected through manual testing and\nstructured scoring by three evaluators. Visualizations further illustrate\nClaude AI's superiority. Anti-scraping solutions, including\nundetected_chromedriver, Selenium, and fake_useragent, were incorporated to\nenhance performance. This paper demonstrates how generative AI combined with\nprompt engineering can simplify and improve web scraping workflows.", "published": "2024-12-29 17:27:55", "link": "http://arxiv.org/abs/2502.15691v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "EmoReg: Directional Latent Vector Modeling for Emotional Intensity\n  Regularization in Diffusion-based Voice Conversion", "abstract": "The Emotional Voice Conversion (EVC) aims to convert the discrete emotional\nstate from the source emotion to the target for a given speech utterance while\npreserving linguistic content. In this paper, we propose regularizing emotion\nintensity in the diffusion-based EVC framework to generate precise speech of\nthe target emotion. Traditional approaches control the intensity of an\nemotional state in the utterance via emotion class probabilities or intensity\nlabels that often lead to inept style manipulations and degradations in\nquality. On the contrary, we aim to regulate emotion intensity using\nself-supervised learning-based feature representations and unsupervised\ndirectional latent vector modeling (DVM) in the emotional embedding space\nwithin a diffusion-based framework. These emotion embeddings can be modified\nbased on the given target emotion intensity and the corresponding direction\nvector. Furthermore, the updated embeddings can be fused in the reverse\ndiffusion process to generate the speech with the desired emotion and\nintensity. In summary, this paper aims to achieve high-quality emotional\nintensity regularization in the diffusion-based EVC framework, which is the\nfirst of its kind work. The effectiveness of the proposed method has been shown\nacross state-of-the-art (SOTA) baselines in terms of subjective and objective\nevaluations for the English and Hindi languages \\footnote{Demo samples are\navailable at the following URL: \\url{https://nirmesh-sony.github.io/EmoReg/}}.", "published": "2024-12-29 05:30:06", "link": "http://arxiv.org/abs/2412.20359v1", "categories": ["eess.AS", "cs.AI", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Tri-Ergon: Fine-grained Video-to-Audio Generation with Multi-modal\n  Conditions and LUFS Control", "abstract": "Video-to-audio (V2A) generation utilizes visual-only video features to\nproduce realistic sounds that correspond to the scene. However, current V2A\nmodels often lack fine-grained control over the generated audio, especially in\nterms of loudness variation and the incorporation of multi-modal conditions. To\novercome these limitations, we introduce Tri-Ergon, a diffusion-based V2A model\nthat incorporates textual, auditory, and pixel-level visual prompts to enable\ndetailed and semantically rich audio synthesis. Additionally, we introduce\nLoudness Units relative to Full Scale (LUFS) embedding, which allows for\nprecise manual control of the loudness changes over time for individual audio\nchannels, enabling our model to effectively address the intricate correlation\nof video and audio in real-world Foley workflows. Tri-Ergon is capable of\ncreating 44.1 kHz high-fidelity stereo audio clips of varying lengths up to 60\nseconds, which significantly outperforms existing state-of-the-art V2A methods\nthat typically generate mono audio for a fixed duration.", "published": "2024-12-29 06:46:24", "link": "http://arxiv.org/abs/2412.20378v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Audiopedia: Audio QA with Knowledge", "abstract": "In this paper, we introduce Audiopedia, a novel task called Audio Question\nAnswering with Knowledge, which requires both audio comprehension and external\nknowledge reasoning. Unlike traditional Audio Question Answering (AQA)\nbenchmarks that focus on simple queries answerable from audio alone, Audiopedia\ntargets knowledge-intensive questions. We define three sub-tasks: (i) Single\nAudio Question Answering (s-AQA), where questions are answered based on a\nsingle audio sample, (ii) Multi-Audio Question Answering (m-AQA), which\nrequires reasoning over multiple audio samples, and (iii) Retrieval-Augmented\nAudio Question Answering (r-AQA), which involves retrieving relevant audio to\nanswer the question. We benchmark large audio language models (LALMs) on these\nsub-tasks and observe suboptimal performance. To address this, we propose a\ngeneric framework that can be adapted to any LALM, equipping them with\nknowledge reasoning capabilities. Our framework has two components: (i) Audio\nEntity Linking (AEL) and (ii) Knowledge-Augmented Audio Large Multimodal Model\n(KA2LM), which together improve performance on knowledge-intensive AQA tasks.\nTo our knowledge, this is the first work to address advanced audio\nunderstanding via knowledge-intensive tasks like Audiopedia.", "published": "2024-12-29 23:48:35", "link": "http://arxiv.org/abs/2412.20619v1", "categories": ["cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Lungmix: A Mixup-Based Strategy for Generalization in Respiratory Sound\n  Classification", "abstract": "Respiratory sound classification plays a pivotal role in diagnosing\nrespiratory diseases. While deep learning models have shown success with\nvarious respiratory sound datasets, our experiments indicate that models\ntrained on one dataset often fail to generalize effectively to others, mainly\ndue to data collection and annotation \\emph{inconsistencies}. To address this\nlimitation, we introduce \\emph{Lungmix}, a novel data augmentation technique\ninspired by Mixup. Lungmix generates augmented data by blending waveforms using\nloudness and random masks while interpolating labels based on their semantic\nmeaning, helping the model learn more generalized representations.\nComprehensive evaluations across three datasets, namely ICBHI, SPR, and HF,\ndemonstrate that Lungmix significantly enhances model generalization to unseen\ndata. In particular, Lungmix boosts the 4-class classification score by up to\n3.55\\%, achieving performance comparable to models trained directly on the\ntarget dataset.", "published": "2024-12-29 12:44:13", "link": "http://arxiv.org/abs/2501.00064v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Ensemble of classifiers for speech evaluation", "abstract": "The article describes an attempt to apply an ensemble of binary classifiers\nto solve the problem of speech assessment in medicine. A dataset was compiled\nbased on quantitative and expert assessments of syllable pronunciation quality.\nQuantitative assessments of 7 selected metrics were used as features: dynamic\ntime warp distance, Minkowski distance, correlation coefficient, longest common\nsubsequence (LCSS), edit distance of real se-quence (EDR), edit distance with\nreal penalty (ERP), and merge split (MSM). Expert as-sessment of pronunciation\nquality was used as a class label: class 1 means high-quality speech, class 0\nmeans distorted. A comparison of training results was carried out for five\nclassification methods: logistic regression (LR), support vector machine (SVM),\nnaive Bayes (NB), decision trees (DT), and K-nearest neighbors (KNN). The\nresults of using the mixture method to build an ensemble of classifiers are\nalso presented. The use of an en-semble for the studied data sets allowed us to\nslightly increase the classification accuracy compared to the use of individual\nbinary classifiers.", "published": "2024-12-29 17:28:32", "link": "http://arxiv.org/abs/2501.00067v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
