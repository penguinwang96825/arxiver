{"title": "Self-Influence Guided Data Reweighting for Language Model Pre-training", "abstract": "Language Models (LMs) pre-trained with self-supervision on large text corpora\nhave become the default starting point for developing models for various NLP\ntasks. Once the pre-training corpus has been assembled, all data samples in the\ncorpus are treated with equal importance during LM pre-training. However, due\nto varying levels of relevance and quality of data, equal importance to all the\ndata samples may not be the optimal choice. While data reweighting has been\nexplored in the context of task-specific supervised learning and LM\nfine-tuning, model-driven reweighting for pre-training data has not been\nexplored. We fill this important gap and propose PRESENCE, a method for jointly\nreweighting samples by leveraging self-influence (SI) scores as an indicator of\nsample importance and pre-training. PRESENCE promotes novelty and stability for\nmodel pre-training. Through extensive analysis spanning multiple model sizes,\ndatasets, and tasks, we present PRESENCE as an important first step in the\nresearch direction of sample reweighting for pre-training language models.", "published": "2023-11-02 01:00:46", "link": "http://arxiv.org/abs/2311.00913v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task-Agnostic Low-Rank Adapters for Unseen English Dialects", "abstract": "Large Language Models (LLMs) are trained on corpora disproportionally\nweighted in favor of Standard American English. As a result, speakers of other\ndialects experience significantly more failures when interacting with these\ntechnologies. In practice, these speakers often accommodate their speech to be\nbetter understood. Our work shares the belief that language technologies should\nbe designed to accommodate the diversity in English dialects and not the other\nway around. However, prior works on dialect struggle with generalizing to\nevolving and emerging dialects in a scalable manner. To fill this gap, our\nmethod, HyperLoRA, leverages expert linguistic knowledge to enable\nresource-efficient adaptation via hypernetworks. By disentangling\ndialect-specific and cross-dialectal information, HyperLoRA improves\ngeneralization to unseen dialects in a task-agnostic fashion. Not only is\nHyperLoRA more scalable in the number of parameters, but it also achieves the\nbest or most competitive performance across 5 dialects in a zero-shot setting.\nIn this way, our approach facilitates access to language technology for\nbillions of English dialect speakers who are traditionally underrepresented.", "published": "2023-11-02 01:17:29", "link": "http://arxiv.org/abs/2311.00915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Blending Reward Functions via Few Expert Demonstrations for Faithful and\n  Accurate Knowledge-Grounded Dialogue Generation", "abstract": "The development of trustworthy conversational information-seeking systems\nrelies on dialogue models that can generate faithful and accurate responses\nbased on relevant knowledge texts. However, two main challenges hinder this\ntask. Firstly, language models may generate hallucinations due to data biases\npresent in their pretraining corpus. Secondly, knowledge texts often contain\nredundant and irrelevant information that distracts the model's attention from\nthe relevant text span. Previous works use additional data annotations on the\nknowledge texts to learn a knowledge identification module in order to bypass\nirrelevant information, but collecting such high-quality span annotations can\nbe costly. In this work, we leverage reinforcement learning algorithms to\novercome the above challenges by introducing a novel reward function. Our\nreward function combines an accuracy metric and a faithfulness metric to\nprovide a balanced quality judgment of generated responses, which can be used\nas a cost-effective approximation to a human preference reward model when only\na few preference annotations are available. Empirical experiments on two\nconversational information-seeking datasets demonstrate that our method can\ncompete with other strong supervised learning baselines.", "published": "2023-11-02 02:42:41", "link": "http://arxiv.org/abs/2311.00953v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances", "abstract": "We present COPAL-ID, a novel, public Indonesian language common sense\nreasoning dataset. Unlike the previous Indonesian COPA dataset (XCOPA-ID),\nCOPAL-ID incorporates Indonesian local and cultural nuances, and therefore,\nprovides a more natural portrayal of day-to-day causal reasoning within the\nIndonesian cultural sphere. Professionally written by natives from scratch,\nCOPAL-ID is more fluent and free from awkward phrases, unlike the translated\nXCOPA-ID. In addition, we present COPAL-ID in both standard Indonesian and in\nJakartan Indonesian-a dialect commonly used in daily conversation. COPAL-ID\nposes a greater challenge for existing open-sourced and closed state-of-the-art\nmultilingual language models, yet is trivially easy for humans. Our findings\nsuggest that general multilingual models struggle to perform well, achieving\n66.91% accuracy on COPAL-ID. South-East Asian-specific models achieve slightly\nbetter performance of 73.88% accuracy. Yet, this number still falls short of\nnear-perfect human performance. This shows that these language models are still\nway behind in comprehending the local nuances of Indonesian.", "published": "2023-11-02 06:14:41", "link": "http://arxiv.org/abs/2311.01012v3", "categories": ["cs.CL", "68T50"], "primary_category": "cs.CL"}
{"title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External\n  Guidance", "abstract": "Adopting a two-stage paradigm of pretraining followed by fine-tuning,\nPretrained Language Models (PLMs) have achieved substantial advancements in the\nfield of natural language processing. However, in real-world scenarios, data\nlabels are often noisy due to the complex annotation process, making it\nessential to develop strategies for fine-tuning PLMs with such noisy labels. To\nthis end, we introduce an innovative approach for fine-tuning PLMs using noisy\nlabels, which incorporates the guidance of Large Language Models (LLMs) like\nChatGPT. This guidance assists in accurately distinguishing between clean and\nnoisy samples and provides supplementary information beyond the noisy labels,\nthereby boosting the learning process during fine-tuning PLMs. Extensive\nexperiments on synthetic and real-world noisy datasets further demonstrate the\nsuperior advantages of our framework over the state-of-the-art baselines.", "published": "2023-11-02 09:20:38", "link": "http://arxiv.org/abs/2311.01108v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChineseWebText: Large-scale High-quality Chinese Web Text Extracted with\n  Effective Evaluation Model", "abstract": "During the development of large language models (LLMs), the scale and quality\nof the pre-training data play a crucial role in shaping LLMs' capabilities. To\naccelerate the research of LLMs, several large-scale datasets, such as C4 [1],\nPile [2], RefinedWeb [3] and WanJuan [4], have been released to the public.\nHowever, most of the released corpus focus mainly on English, and there is\nstill lack of complete tool-chain for extracting clean texts from web data.\nFurthermore, fine-grained information of the corpus, e.g. the quality of each\ntext, is missing. To address these challenges, we propose in this paper a new\ncomplete tool-chain EvalWeb to extract Chinese clean texts from noisy web data.\nFirst, similar to previous work, manually crafted rules are employed to discard\nexplicit noisy texts from the raw crawled web contents. Second, a well-designed\nevaluation model is leveraged to assess the remaining relatively clean data,\nand each text is assigned a specific quality score. Finally, we can easily\nutilize an appropriate threshold to select the high-quality pre-training data\nfor Chinese. Using our proposed approach, we release the largest and latest\nlarge-scale high-quality Chinese web text ChineseWebText, which consists of\n1.42 TB and each text is associated with a quality score, facilitating the LLM\nresearchers to choose the data according to the desired quality thresholds. We\nalso release a much cleaner subset of 600 GB Chinese data with the quality\nexceeding 90%.", "published": "2023-11-02 11:13:51", "link": "http://arxiv.org/abs/2311.01149v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Question-Answering Performance of Large Language Models\n  through Semantic Consistency", "abstract": "Semantic consistency of a language model is broadly defined as the model's\nability to produce semantically-equivalent outputs, given\nsemantically-equivalent inputs. We address the task of assessing\nquestion-answering (QA) semantic consistency of contemporary large language\nmodels (LLMs) by manually creating a benchmark dataset with high-quality\nparaphrases for factual questions, and release the dataset to the community.\n  We further combine the semantic consistency metric with additional\nmeasurements suggested in prior work as correlating with LLM QA accuracy, for\nbuilding and evaluating a framework for factual QA reference-less performance\nprediction -- predicting the likelihood of a language model to accurately\nanswer a question. Evaluating the framework on five contemporary LLMs, we\ndemonstrate encouraging, significantly outperforming baselines, results.", "published": "2023-11-02 11:27:21", "link": "http://arxiv.org/abs/2311.01152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ACES: Translation Accuracy Challenge Sets at WMT 2023", "abstract": "We benchmark the performance of segmentlevel metrics submitted to WMT 2023\nusing the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists\nof 36K examples representing challenges from 68 phenomena and covering 146\nlanguage pairs. The phenomena range from simple perturbations at the\nword/character level to more complex errors based on discourse and real-world\nknowledge. For each metric, we provide a detailed profile of performance over a\nrange of error categories as well as an overall ACES-Score for quick\ncomparison. We also measure the incremental performance of the metrics\nsubmitted to both WMT 2023 and 2022. We find that 1) there is no clear winner\namong the metrics submitted to WMT 2023, and 2) performance change between the\n2023 and 2022 versions of the metrics is highly variable. Our recommendations\nare similar to those from WMT 2022. Metric developers should focus on: building\nensembles of metrics from different design families, developing metrics that\npay more attention to the source and rely less on surface-level overlap, and\ncarefully determining the influence of multilingual embeddings on MT\nevaluation.", "published": "2023-11-02 11:29:09", "link": "http://arxiv.org/abs/2311.01153v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL", "abstract": "Existing Text-to-SQL generators require the entire schema to be encoded with\nthe user text. This is expensive or impractical for large databases with tens\nof thousands of columns. Standard dense retrieval techniques are inadequate for\nschema subsetting of a large structured database, where the correct semantics\nof retrieval demands that we rank sets of schema elements rather than\nindividual elements. In response, we propose a two-stage process for effective\ncoverage during retrieval. First, we instruct an LLM to hallucinate a minimal\nDB schema deemed adequate to answer the query. We use the hallucinated schema\nto retrieve a subset of the actual schema, by composing the results from\nmultiple dense retrievals. Remarkably, hallucination $\\unicode{x2013}$\ngenerally considered a nuisance $\\unicode{x2013}$ turns out to be actually\nuseful as a bridging mechanism. Since no existing benchmarks exist for schema\nsubsetting on large databases, we introduce three benchmarks. Two\nsemi-synthetic datasets are derived from the union of schemas in two well-known\ndatasets, SPIDER and BIRD, resulting in 4502 and 798 schema elements\nrespectively. A real-life benchmark called SocialDB is sourced from an actual\nlarge data warehouse comprising 17844 schema elements. We show that our method1\nleads to significantly higher recall than SOTA retrieval-based augmentation\nmethods.", "published": "2023-11-02 12:13:52", "link": "http://arxiv.org/abs/2311.01173v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding Common Ground: Annotating and Predicting Common Ground in Spoken\n  Conversations", "abstract": "When we communicate with other humans, we do not simply generate a sequence\nof words. Rather, we use our cognitive state (beliefs, desires, intentions) and\nour model of the audience's cognitive state to create utterances that affect\nthe audience's cognitive state in the intended manner. An important part of\ncognitive state is the common ground, which is the content the speaker\nbelieves, and the speaker believes the audience believes, and so on. While much\nattention has been paid to common ground in cognitive science, there has not\nbeen much work in natural language processing. In this paper, we introduce a\nnew annotation and corpus to capture common ground. We then describe some\ninitial experiments extracting propositions from dialog and tracking their\nstatus in the common ground from the perspective of each speaker.", "published": "2023-11-02 14:37:28", "link": "http://arxiv.org/abs/2311.01273v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual\n  Consistency of Language Models", "abstract": "Large Language Models (LLMs) make natural interfaces to factual knowledge,\nbut their usefulness is limited by their tendency to deliver inconsistent\nanswers to semantically equivalent questions. For example, a model might\npredict both \"Anne Redpath passed away in Edinburgh.\" and \"Anne Redpath's life\nended in London.\" In this work, we identify potential causes of inconsistency\nand evaluate the effectiveness of two mitigation strategies: up-scaling and\naugmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas\nmodels show that both strategies reduce inconsistency while retrieval\naugmentation is considerably more efficient. We further consider and\ndisentangle the consistency contributions of different components of Atlas. For\nall LMs evaluated we find that syntactical form and other evaluation task\nartifacts impact consistency. Taken together, our results provide a better\nunderstanding of the factors affecting the factual consistency of language\nmodels.", "published": "2023-11-02 15:20:11", "link": "http://arxiv.org/abs/2311.01307v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Language Models Be Tricked by Language Illusions? Easier with\n  Syntax, Harder with Semantics", "abstract": "Language models (LMs) have been argued to overlap substantially with human\nbeings in grammaticality judgment tasks. But when humans systematically make\nerrors in language processing, should we expect LMs to behave like cognitive\nmodels of language and mimic human behavior? We answer this question by\ninvestigating LMs' more subtle judgments associated with \"language illusions\"\n-- sentences that are vague in meaning, implausible, or ungrammatical but\nreceive unexpectedly high acceptability judgments by humans. We looked at three\nillusions: the comparative illusion (e.g. \"More people have been to Russia than\nI have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be\nignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who\nno villager believed to be trustworthy will ever shoot a bear\"). We found that\nprobabilities represented by LMs were more likely to align with human judgments\nof being \"tricked\" by the NPI illusion which examines a structural dependency,\ncompared to the comparative and the depth-charge illusions which require\nsophisticated semantic understanding. No single LM or metric yielded results\nthat are entirely consistent with human behavior. Ultimately, we show that LMs\nare limited both in their construal as cognitive models of human language\nprocessing and in their capacity to recognize nuanced but critical information\nin complicated language materials.", "published": "2023-11-02 16:44:24", "link": "http://arxiv.org/abs/2311.01386v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TopicGPT: A Prompt-based Topic Modeling Framework", "abstract": "Topic modeling is a well-established technique for exploring text corpora.\nConventional topic models (e.g., LDA) represent topics as bags of words that\noften require \"reading the tea leaves\" to interpret; additionally, they offer\nusers minimal control over the formatting and specificity of resulting topics.\nTo tackle these issues, we introduce TopicGPT, a prompt-based framework that\nuses large language models (LLMs) to uncover latent topics in a text\ncollection. TopicGPT produces topics that align better with human\ncategorizations compared to competing methods: it achieves a harmonic mean\npurity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for\nthe strongest baseline. Its topics are also interpretable, dispensing with\nambiguous bags of words in favor of topics with natural language labels and\nassociated free-form descriptions. Moreover, the framework is highly adaptable,\nallowing users to specify constraints and modify topics without the need for\nmodel retraining. By streamlining access to high-quality and interpretable\ntopics, TopicGPT represents a compelling, human-centered approach to topic\nmodeling.", "published": "2023-11-02 17:57:10", "link": "http://arxiv.org/abs/2311.01449v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for\n  Named Entity Recognition", "abstract": "Active learning, a widely adopted technique for enhancing machine learning\nmodels in text and image classification tasks with limited annotation\nresources, has received relatively little attention in the domain of Named\nEntity Recognition (NER). The challenge of data imbalance in NER has hindered\nthe effectiveness of active learning, as sequence labellers lack sufficient\nlearning signals. To address these challenges, this paper presents a novel\nreweighting-based active learning strategy that assigns dynamic smoothed\nweights to individual tokens. This adaptable strategy is compatible with\nvarious token-level acquisition functions and contributes to the development of\nrobust active learners. Experimental results on multiple corpora demonstrate\nthe substantial performance improvement achieved by incorporating our\nre-weighting strategy into existing acquisition functions, validating its\npractical efficacy.", "published": "2023-11-02 00:19:02", "link": "http://arxiv.org/abs/2311.00906v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End\n  Task-Oriented Dialogue Systems", "abstract": "Task-oriented dialogue (ToD) systems have been mostly created for\nhigh-resource languages, such as English and Chinese. However, there is a need\nto develop ToD systems for other regional or local languages to broaden their\nability to comprehend the dialogue contexts in various languages. This paper\nintroduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We\nextend two English ToD datasets to Indonesian, comprising four different\ndomains by delexicalization to efficiently reduce the size of annotations. To\nensure a high-quality data collection, we hire native speakers to manually\ntranslate the dialogues. Along with the original English datasets, these new\nIndonesian datasets serve as an effective benchmark for evaluating Indonesian\nand English ToD systems as well as exploring the potential benefits of\ncross-lingual and bilingual transfer learning approaches.", "published": "2023-11-02 03:01:53", "link": "http://arxiv.org/abs/2311.00958v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Replicable Benchmarking of Neural Machine Translation (NMT) on\n  Low-Resource Local Languages in Indonesia", "abstract": "Neural machine translation (NMT) for low-resource local languages in\nIndonesia faces significant challenges, including the need for a representative\nbenchmark and limited data availability. This work addresses these challenges\nby comprehensively analyzing training NMT systems for four low-resource local\nlanguages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our\nstudy encompasses various training approaches, paradigms, data sizes, and a\npreliminary study into using large language models for synthetic low-resource\nlanguages parallel data generation. We reveal specific trends and insights into\npractical strategies for low-resource language translation. Our research\ndemonstrates that despite limited computational resources and textual data,\nseveral of our NMT systems achieve competitive performances, rivaling the\ntranslation quality of zero-shot gpt-3.5-turbo. These findings significantly\nadvance NMT for low-resource languages, offering valuable guidance for\nresearchers in similar contexts.", "published": "2023-11-02 05:27:48", "link": "http://arxiv.org/abs/2311.00998v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Joint Learning of Local and Global Features for Aspect-based Sentiment\n  Classification", "abstract": "Aspect-based sentiment classification (ASC) aims to judge the sentiment\npolarity conveyed by the given aspect term in a sentence. The sentiment\npolarity is not only determined by the local context but also related to the\nwords far away from the given aspect term. Most recent efforts related to the\nattention-based models can not sufficiently distinguish which words they should\npay more attention to in some cases. Meanwhile, graph-based models are coming\ninto ASC to encode syntactic dependency tree information. But these models do\nnot fully leverage syntactic dependency trees as they neglect to incorporate\ndependency relation tag information into representation learning effectively.\nIn this paper, we address these problems by effectively modeling the local and\nglobal features. Firstly, we design a local encoder containing: a Gaussian mask\nlayer and a covariance self-attention layer. The Gaussian mask layer tends to\nadjust the receptive field around aspect terms adaptively to deemphasize the\neffects of unrelated words and pay more attention to local information. The\ncovariance self-attention layer can distinguish the attention weights of\ndifferent words more obviously. Furthermore, we propose a dual-level graph\nattention network as a global encoder by fully employing dependency tag\ninformation to capture long-distance information effectively. Our model\nachieves state-of-the-art performance on both SemEval 2014 and Twitter\ndatasets.", "published": "2023-11-02 06:43:50", "link": "http://arxiv.org/abs/2311.01030v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ATHENA: Mathematical Reasoning with Thought Expansion", "abstract": "Solving math word problems depends on how to articulate the problems, the\nlens through which models view human linguistic expressions. Real-world\nsettings count on such a method even more due to the diverse practices of the\nsame mathematical operations. Earlier works constrain available thinking\nprocesses by limited prediction strategies without considering their\nsignificance in acquiring mathematical knowledge. We introduce Attention-based\nTHought Expansion Network Architecture (ATHENA) to tackle the challenges of\nreal-world practices by mimicking human thought expansion mechanisms in the\nform of neural network propagation. A thought expansion recurrently generates\nthe candidates carrying the thoughts of possible math expressions driven from\nthe previous step and yields reasonable thoughts by selecting the valid\npathways to the goal. Our experiments show that ATHENA achieves a new\nstate-of-the-art stage toward the ideal model that is compelling in variant\nquestions even when the informativeness in training examples is restricted.", "published": "2023-11-02 07:03:25", "link": "http://arxiv.org/abs/2311.01036v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.3; F.4.1"], "primary_category": "cs.CL"}
{"title": "Learn to Refuse: Making Large Language Models More Controllable and\n  Reliable through Knowledge Scope Limitation and Refusal Mechanism", "abstract": "Large language models (LLMs) have demonstrated impressive language\nunderstanding and generation capabilities, enabling them to answer a wide range\nof questions across various domains. However, these models are not flawless and\noften produce responses that contain errors or misinformation. These\ninaccuracies, commonly referred to as hallucinations, render LLMs unreliable\nand even unusable in many scenarios. In this paper, our focus is on mitigating\nthe issue of hallucination in LLMs, particularly in the context of\nquestion-answering. Instead of attempting to answer all questions, we explore a\nrefusal mechanism that instructs LLMs to refuse to answer challenging questions\nin order to avoid errors. We then propose a simple yet effective solution\ncalled Learn to Refuse (L2R), which incorporates the refusal mechanism to\nenable LLMs to recognize and refuse to answer questions that they find\ndifficult to address. To achieve this, we utilize a structured knowledge base\nto represent all the LLM's understanding of the world, enabling it to provide\ntraceable gold knowledge. This knowledge base is separate from the LLM and\ninitially empty. It can be filled with validated knowledge and progressively\nexpanded. When an LLM encounters questions outside its domain, the system\nrecognizes its knowledge scope and determines whether it can answer the\nquestion independently. Additionally, we introduce a method for automatically\nand efficiently expanding the knowledge base of LLMs. Through qualitative and\nquantitative analysis, we demonstrate that our approach enhances the\ncontrollability and reliability of LLMs.", "published": "2023-11-02 07:20:49", "link": "http://arxiv.org/abs/2311.01041v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-dimensional data refining strategy for effective fine-tuning LLMs", "abstract": "Data is a cornerstone for fine-tuning large language models, yet acquiring\nsuitable data remains challenging. Challenges encompassed data scarcity,\nlinguistic diversity, and domain-specific content. This paper presents lessons\nlearned while crawling and refining data tailored for fine-tuning Vietnamese\nlanguage models. Crafting such a dataset, while accounting for linguistic\nintricacies and striking a balance between inclusivity and accuracy, demands\nmeticulous planning. Our paper presents a multidimensional strategy including\nleveraging existing datasets in the English language and developing customized\ndata-crawling scripts with the assistance of generative AI tools. A fine-tuned\nLLM model for the Vietnamese language, which was produced using resultant\ndatasets, demonstrated good performance while generating Vietnamese news\narticles from prompts. The study offers practical solutions and guidance for\nfuture fine-tuning models in languages like Vietnamese.", "published": "2023-11-02 07:50:43", "link": "http://arxiv.org/abs/2311.01049v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revisiting the Knowledge Injection Frameworks", "abstract": "In recent years, large language models (LLMs), such as GPTs, have attained\ngreat impact worldwide. However, how to adapt these LLMs to better suit the\nvertical domain-specific tasks by utilizing external knowledge remains not\ncompletely solved. Indeed, there have emerged a few works on this line where\nmost of them rely on an alignment heuristic that is built to inject the\ncorresponding knowledge tuple into the associated text sample.\n  However, despite the promise, we identify a pivotal problem in this work\nubiquitously. Simply put, we find that injecting unaligned (i.e., random)\nknowledge tuple into the LLMs achieves comparable (and sometimes better)\nresults than the aligned knowledge being injected. We therefore take a thorough\ninvestigation of this frustrating finding on a variety of related prior work\nand further provide a chain of potential interpretations for the phenomenon.\nBased on all that, we offer a simple remediated technique. Briefly, the core of\nthis technique is rooted in an ideological emphasis on the pruning and\npurification of the external knowledge base to be injected into LLMs. At last,\nwe show that by integrating this technique into most (if not all) knowledge\ninjection frameworks and recent LLMs, it manages to overcome the aforementioned\nsanity problem and further pushes the boundary of the performance of the\ndomain-adaptive LLMs.", "published": "2023-11-02 11:18:16", "link": "http://arxiv.org/abs/2311.01150v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Semantic Parsing with Execution-based Spurious Program\n  Filtering", "abstract": "The problem of spurious programs is a longstanding challenge when training a\nsemantic parser from weak supervision. To eliminate such programs that have\nwrong semantics but correct denotation, existing methods focus on exploiting\nsimilarities between examples based on domain-specific knowledge. In this\npaper, we propose a domain-agnostic filtering mechanism based on program\nexecution results. Specifically, for each program obtained through the search\nprocess, we first construct a representation that captures the program's\nsemantics as execution results under various inputs. Then, we run a majority\nvote on these representations to identify and filter out programs with\nsignificantly different semantics from the other programs. In particular, our\nmethod is orthogonal to the program search process so that it can easily\naugment any of the existing weakly supervised semantic parsing frameworks.\nEmpirical evaluations on the Natural Language Visual Reasoning and\nWikiTableQuestions demonstrate that applying our method to the existing\nsemantic parsers induces significantly improved performances.", "published": "2023-11-02 11:45:40", "link": "http://arxiv.org/abs/2311.01161v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative Input: Towards Next-Generation Input Methods Paradigm", "abstract": "Since the release of ChatGPT, generative models have achieved tremendous\nsuccess and become the de facto approach for various NLP tasks. However, its\napplication in the field of input methods remains under-explored. Many neural\nnetwork approaches have been applied to the construction of Chinese input\nmethod engines(IMEs).Previous research often assumed that the input pinyin was\ncorrect and focused on Pinyin-to-character(P2C) task, which significantly falls\nshort of meeting users' demands. Moreover, previous research could not leverage\nuser feedback to optimize the model and provide personalized results. In this\nstudy, we propose a novel Generative Input paradigm named GeneInput. It uses\nprompts to handle all input scenarios and other intelligent auxiliary input\nfunctions, optimizing the model with user feedback to deliver personalized\nresults. The results demonstrate that we have achieved state-of-the-art\nperformance for the first time in the Full-mode Key-sequence to\nCharacters(FK2C) task. We propose a novel reward model training method that\neliminates the need for additional manual annotations and the performance\nsurpasses GPT-4 in tasks involving intelligent association and conversational\nassistance. Compared to traditional paradigms, GeneInput not only demonstrates\nsuperior performance but also exhibits enhanced robustness, scalability, and\nonline learning capabilities.", "published": "2023-11-02 12:01:29", "link": "http://arxiv.org/abs/2311.01166v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Continual Learning Under Language Shift", "abstract": "The recent increase in data and model scale for language model pre-training\nhas led to huge training costs. In scenarios where new data become available\nover time, updating a model instead of fully retraining it would therefore\nprovide significant gains. We study the pros and cons of updating a language\nmodel when new data comes from new languages -- the case of continual learning\nunder language shift. Starting from a monolingual English language model, we\nincrementally add data from Danish, Icelandic, and Norwegian to investigate how\nforward and backward transfer effects depend on pre-training order and\ncharacteristics of languages, for three different model sizes. Our results show\nthat, while forward transfer is largely positive and independent of language\norder, backward transfer can be positive or negative depending on the order and\ncharacteristics of new languages. We explore a number of potentially\nexplanatory factors and find that a combination of language contamination and\nsyntactic similarity best fits our results.", "published": "2023-11-02 12:54:50", "link": "http://arxiv.org/abs/2311.01200v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated\n  Counterfactually Augmented Data for Harmful Language Detection", "abstract": "NLP models are used in a variety of critical social computing tasks, such as\ndetecting sexist, racist, or otherwise hateful content. Therefore, it is\nimperative that these models are robust to spurious features. Past work has\nattempted to tackle such spurious features using training data augmentation,\nincluding Counterfactually Augmented Data (CADs). CADs introduce minimal\nchanges to existing training data points and flip their labels; training on\nthem may reduce model dependency on spurious features. However, manually\ngenerating CADs can be time-consuming and expensive. Hence in this work, we\nassess if this task can be automated using generative NLP models. We\nautomatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate\ntheir usefulness in improving model robustness compared to manually-generated\nCADs. By testing both model performance on multiple out-of-domain test sets and\nindividual data point efficacy, our results show that while manual CADs are\nstill the most effective, CADs generated by ChatGPT come a close second. One\nkey reason for the lower performance of automated methods is that the changes\nthey introduce are often insufficient to flip the original label.", "published": "2023-11-02 14:31:25", "link": "http://arxiv.org/abs/2311.01270v3", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "FlashDecoding++: Faster Large Language Model Inference on GPUs", "abstract": "As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.", "published": "2023-11-02 14:57:03", "link": "http://arxiv.org/abs/2311.01282v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Better Together: Enhancing Generative Knowledge Graph Completion with\n  Language Models and Neighborhood Information", "abstract": "Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which\nlimits their potential performance. Knowledge Graph Completion (KGC) techniques\naim to address this issue. However, traditional KGC methods are computationally\nintensive and impractical for large-scale KGs, necessitating the learning of\ndense node embeddings and computing pairwise distances. Generative\ntransformer-based language models (e.g., T5 and recent KGT5) offer a promising\nsolution as they can predict the tail nodes directly. In this study, we propose\nto include node neighborhoods as additional information to improve KGC methods\nbased on language models. We examine the effects of this imputation and show\nthat, on both inductive and transductive Wikidata subsets, our method\noutperforms KGT5 and conventional KGC approaches. We also provide an extensive\nanalysis of the impact of neighborhood on model prediction and show its\nimportance. Furthermore, we point the way to significantly improve KGC through\nmore effective neighborhood selection.", "published": "2023-11-02 15:38:39", "link": "http://arxiv.org/abs/2311.01326v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks", "abstract": "Automatically evaluating vision-language tasks is challenging, especially\nwhen it comes to reflecting human judgments due to limitations in accounting\nfor fine-grained details. Although GPT-4V has shown promising results in\nvarious multi-modal tasks, leveraging GPT-4V as a generalist evaluator for\nthese tasks has not yet been systematically explored. We comprehensively\nvalidate GPT-4V's capabilities for evaluation purposes, addressing tasks\nranging from foundational image-to-text and text-to-image synthesis to\nhigh-level image-to-image translations and multi-images to text alignment. We\nemploy two evaluation methods, single-answer grading and pairwise comparison,\nusing GPT-4V. Notably, GPT-4V shows promising agreement with humans across\nvarious tasks and evaluation methods, demonstrating immense potential for\nmulti-modal LLMs as evaluators. Despite limitations like restricted visual\nclarity grading and real-world complex reasoning, its ability to provide\nhuman-aligned scores enriched with detailed explanations is promising for\nuniversal automatic evaluator.", "published": "2023-11-02 16:11:09", "link": "http://arxiv.org/abs/2311.01361v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "What Makes for Good Visual Instructions? Synthesizing Complex Visual\n  Reasoning Instructions for Visual Instruction Tuning", "abstract": "Visual instruction tuning is crucial for enhancing the zero-shot\ngeneralization capability of Multi-modal Large Language Models (MLLMs). In this\npaper, we aim to investigate a fundamental question: ''what makes for good\nvisual instructions''. Through a comprehensive empirical study, we find that\ninstructions focusing on complex visual reasoning tasks are particularly\neffective in improving the performance of MLLMs, with results correlating to\ninstruction complexity. Based on this insight, we develop a systematic approach\nto automatically create high-quality complex visual reasoning instructions. Our\napproach employs a synthesize-complicate-reformulate paradigm, leveraging\nmultiple stages to gradually increase the complexity of the instructions while\nguaranteeing quality. Based on this approach, we create the ComVint dataset\nwith 32K examples, and fine-tune four MLLMs on it. Experimental results\nconsistently demonstrate the enhanced performance of all compared MLLMs, such\nas a 27.86% and 27.60% improvement for LLaVA on MME-Perception and\nMME-Cognition, respectively. Our code and data are publicly available at the\nlink: https://github.com/RUCAIBox/ComVint.", "published": "2023-11-02 15:36:12", "link": "http://arxiv.org/abs/2311.01487v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Divergent Token Metrics: Measuring degradation to prune away LLM\n  components -- and optimize quantization", "abstract": "Large Language Models (LLMs) have reshaped natural language processing with\ntheir impressive capabilities. However, their ever-increasing size has raised\nconcerns about their effective deployment and the need for LLM compression.\nThis study introduces the Divergent Token Metrics (DTMs), a novel approach to\nassessing compressed LLMs, addressing the limitations of traditional perplexity\nor accuracy measures that fail to accurately reflect text generation quality.\nDTMs measure token divergences that allow deeper insights into the subtleties\nof model compression, in particular, when evaluating components' impacts\nindividually. Utilizing the First Divergent Token Metric (FDTM) in model\nsparsification reveals that 25% of all attention components can be pruned\nbeyond 90% on the Llama-2 model family, still keeping SOTA performance. For\nquantization, FDTM suggests that more than 80% of parameters can be naively\ntransformed to int8 without special outlier management. These evaluations\nindicate the necessity of choosing appropriate compressions for parameters\nindividually -- and that FDTM can identify those -- while standard metrics\nresult in deteriorated outcomes.", "published": "2023-11-02 18:55:53", "link": "http://arxiv.org/abs/2311.01544v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Instruction Distillation Makes Large Language Models Efficient Zero-shot\n  Rankers", "abstract": "Recent studies have demonstrated the great potential of Large Language Models\n(LLMs) serving as zero-shot relevance rankers. The typical approach involves\nmaking comparisons between pairs or lists of documents. Although effective,\nthese listwise and pairwise methods are not efficient and also heavily rely on\nintricate prompt engineering. To tackle this problem, we introduce a novel\ninstruction distillation method. The key idea is to distill the pairwise\nranking ability of open-sourced LLMs to a simpler but more efficient pointwise\nranking. Specifically, given the same LLM, we first rank documents using the\neffective pairwise approach with complex instructions, and then distill the\nteacher predictions to the pointwise approach with simpler instructions.\nEvaluation results on the BEIR, TREC, and ReDial datasets demonstrate that\ninstruction distillation can improve efficiency by 10 to 100x and also enhance\nthe ranking performance of LLMs. Furthermore, our approach surpasses the\nperformance of existing supervised methods like monoT5 and is on par with the\nstate-of-the-art zero-shot methods. The code to reproduce our results is\navailable at www.github.com/sunnweiwei/RankGPT.", "published": "2023-11-02 19:16:21", "link": "http://arxiv.org/abs/2311.01555v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "On Preserving the Knowledge of Long Clinical Texts", "abstract": "Clinical texts, such as admission notes, discharge summaries, and progress\nnotes, contain rich and valuable information that can be used for clinical\ndecision making. However, a severe bottleneck in using transformer encoders for\nprocessing clinical texts comes from the input length limit of these models:\ntransformer-based encoders use fixed-length inputs. Therefore, these models\ndiscard part of the inputs while processing medical text. There is a risk of\nlosing vital knowledge from clinical text if only part of it is processed. This\npaper proposes a novel method to preserve the knowledge of long clinical texts\nin the models using aggregated ensembles of transformer encoders. Previous\nstudies used either ensemble or aggregation, but we studied the effects of\nfusing these methods. We trained several pre-trained BERT-like transformer\nencoders on two clinical outcome tasks: mortality prediction and length of stay\nprediction. Our method achieved better results than all baseline models for\nprediction tasks on long clinical notes. We conducted extensive experiments on\nthe MIMIC-III clinical database's admission notes by combining multiple\nunstructured and high-dimensional datasets, demonstrating our method's\neffectiveness and superiority over existing approaches. This study shows that\nfusing ensemble and aggregation improves the model performance for clinical\nprediction tasks, particularly the mortality and the length of hospital stay.", "published": "2023-11-02 19:50:02", "link": "http://arxiv.org/abs/2311.01571v2", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MetaReVision: Meta-Learning with Retrieval for Visually Grounded\n  Compositional Concept Acquisition", "abstract": "Humans have the ability to learn novel compositional concepts by recalling\nand generalizing primitive concepts acquired from past experiences. Inspired by\nthis observation, in this paper, we propose MetaReVision, a retrieval-enhanced\nmeta-learning model to address the visually grounded compositional concept\nlearning problem. The proposed MetaReVision consists of a retrieval module and\na meta-learning module which are designed to incorporate retrieved primitive\nconcepts as a supporting set to meta-train vision-anguage models for grounded\ncompositional concept recognition. Through meta-learning from episodes\nconstructed by the retriever, MetaReVision learns a generic compositional\nrepresentation that can be fast updated to recognize novel compositional\nconcepts. We create CompCOCO and CompFlickr to benchmark the grounded\ncompositional concept learning. Our experimental results show that MetaReVision\noutperforms other competitive baselines and the retrieval module plays an\nimportant role in this compositional learning process.", "published": "2023-11-02 20:19:58", "link": "http://arxiv.org/abs/2311.01580v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life\n  Videos", "abstract": "Multimodal counterfactual reasoning is a vital yet challenging ability for AI\nsystems. It involves predicting the outcomes of hypothetical circumstances\nbased on vision and language inputs, which enables AI models to learn from\nfailures and explore hypothetical scenarios. Despite its importance, there are\nonly a few datasets targeting the counterfactual reasoning abilities of\nmultimodal models. Among them, they only cover reasoning over synthetic\nenvironments or specific types of events (e.g. traffic collisions), making them\nhard to reliably benchmark the model generalization ability in diverse\nreal-world scenarios and reasoning dimensions. To overcome these limitations,\nwe develop a video question answering dataset, ACQUIRED: it consists of 3.9K\nannotated videos, encompassing a wide range of event types and incorporating\nboth first and third-person viewpoints, which ensures a focus on real-world\ndiversity. In addition, each video is annotated with questions that span three\ndistinct dimensions of reasoning, including physical, social, and temporal,\nwhich can comprehensively evaluate the model counterfactual abilities along\nmultiple aspects. We benchmark our dataset against several state-of-the-art\nlanguage-only and multimodal models and experimental results demonstrate a\nsignificant performance gap (>13%) between models and humans. The findings\nsuggest that multimodal counterfactual reasoning remains an open challenge and\nACQUIRED is a comprehensive and reliable benchmark for inspiring future\nresearch in this direction.", "published": "2023-11-02 22:17:03", "link": "http://arxiv.org/abs/2311.01620v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Adapting Fake News Detection to the Era of Large Language Models", "abstract": "In the age of large language models (LLMs) and the widespread adoption of\nAI-driven content creation, the landscape of information dissemination has\nwitnessed a paradigm shift. With the proliferation of both human-written and\nmachine-generated real and fake news, robustly and effectively discerning the\nveracity of news articles has become an intricate challenge. While substantial\nresearch has been dedicated to fake news detection, this either assumes that\nall news articles are human-written or abruptly assumes that all\nmachine-generated news are fake. Thus, a significant gap exists in\nunderstanding the interplay between machine-(paraphrased) real news,\nmachine-generated fake news, human-written fake news, and human-written real\nnews. In this paper, we study this gap by conducting a comprehensive evaluation\nof fake news detectors trained in various scenarios. Our primary objectives\nrevolve around the following pivotal question: How to adapt fake news detectors\nto the era of LLMs? Our experiments reveal an interesting pattern that\ndetectors trained exclusively on human-written articles can indeed perform well\nat detecting machine-generated fake news, but not vice versa. Moreover, due to\nthe bias of detectors against machine-generated texts \\cite{su2023fake}, they\nshould be trained on datasets with a lower machine-generated news ratio than\nthe test set. Building on our findings, we provide a practical strategy for the\ndevelopment of robust fake news detectors.", "published": "2023-11-02 08:39:45", "link": "http://arxiv.org/abs/2311.04917v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization\n  Help?", "abstract": "Named entity recognition (NER), a task that identifies and categorizes named\nentities such as persons or organizations from text, is traditionally framed as\na multi-class classification problem. However, this approach often overlooks\nthe issues of imbalanced label distributions, particularly in low-resource\nsettings, which is common in certain NER contexts, like biomedical NER\n(bioNER). To address these issues, we propose an innovative reformulation of\nthe multi-class problem as a one-vs-all (OVA) learning problem and introduce a\nloss function based on the area under the receiver operating characteristic\ncurve (AUC). To enhance the efficiency of our OVA-based approach, we propose\ntwo training strategies: one groups labels with similar linguistic\ncharacteristics, and another employs meta-learning. The superiority of our\napproach is confirmed by its performance, which surpasses traditional NER\nlearning in varying NER settings.", "published": "2023-11-02 10:14:52", "link": "http://arxiv.org/abs/2311.04918v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "E3 TTS: Easy End-to-End Diffusion-based Text to Speech", "abstract": "We propose Easy End-to-End Diffusion-based Text to Speech, a simple and\nefficient end-to-end text-to-speech model based on diffusion. E3 TTS directly\ntakes plain text as input and generates an audio waveform through an iterative\nrefinement process. Unlike many prior work, E3 TTS does not rely on any\nintermediate representations like spectrogram features or alignment\ninformation. Instead, E3 TTS models the temporal structure of the waveform\nthrough the diffusion process. Without relying on additional conditioning\ninformation, E3 TTS could support flexible latent structure within the given\naudio. This enables E3 TTS to be easily adapted for zero-shot tasks such as\nediting without any additional training. Experiments show that E3 TTS can\ngenerate high-fidelity audio, approaching the performance of a state-of-the-art\nneural TTS system. Audio samples are available at https://e3tts.github.io.", "published": "2023-11-02 02:22:21", "link": "http://arxiv.org/abs/2311.00945v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Vision-Language Interpreter for Robot Task Planning", "abstract": "Large language models (LLMs) are accelerating the development of\nlanguage-guided robot planners. Meanwhile, symbolic planners offer the\nadvantage of interpretability. This paper proposes a new task that bridges\nthese two trends, namely, multimodal planning problem specification. The aim is\nto generate a problem description (PD), a machine-readable file used by the\nplanners to find a plan. By generating PDs from language instruction and scene\nobservation, we can drive symbolic planners in a language-guided framework. We\npropose a Vision-Language Interpreter (ViLaIn), a new framework that generates\nPDs using state-of-the-art LLM and vision-language models. ViLaIn can refine\ngenerated PDs via error message feedback from the symbolic planner. Our aim is\nto answer the question: How accurately can ViLaIn and the symbolic planner\ngenerate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset\ncalled the problem description generation (ProDG) dataset. The framework is\nevaluated with four new evaluation metrics. Experimental results show that\nViLaIn can generate syntactically correct problems with more than 99\\% accuracy\nand valid plans with more than 58\\% accuracy. Our code and dataset are\navailable at https://github.com/omron-sinicx/ViLaIn.", "published": "2023-11-02 03:32:30", "link": "http://arxiv.org/abs/2311.00967v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Multilingual DistilWhisper: Efficient Distillation of Multi-task Speech\n  Models via Language-Specific Experts", "abstract": "Whisper is a multitask and multilingual speech model covering 99 languages.\nIt yields commendable automatic speech recognition (ASR) results in a subset of\nits covered languages, but the model still underperforms on a non-negligible\nnumber of under-represented languages, a problem exacerbated in smaller model\nversions. In this work, we propose DistilWhisper, an approach able to bridge\nthe performance gap in ASR for these languages while retaining the advantages\nof multitask and multilingual capabilities. Our approach involves two key\nstrategies: lightweight modular ASR fine-tuning of whisper-small using\nlanguage-specific experts, and knowledge distillation from whisper-large-v2.\nThis dual approach allows us to effectively boost ASR performance while keeping\nthe robustness inherited from the multitask and multilingual pre-training.\nResults demonstrate that our approach is more effective than standard\nfine-tuning or LoRA adapters, boosting performance in the targeted languages\nfor both in- and out-of-domain test sets, while introducing only a negligible\nparameter overhead at inference.", "published": "2023-11-02 08:37:30", "link": "http://arxiv.org/abs/2311.01070v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An energy-based comparative analysis of common approaches to text\n  classification in the Legal domain", "abstract": "Most Machine Learning research evaluates the best solutions in terms of\nperformance. However, in the race for the best performing model, many important\naspects are often overlooked when, on the contrary, they should be carefully\nconsidered. In fact, sometimes the gaps in performance between different\napproaches are neglectable, whereas factors such as production costs, energy\nconsumption, and carbon footprint must take into consideration. Large Language\nModels (LLMs) are extensively adopted to address NLP problems in academia and\nindustry. In this work, we present a detailed quantitative comparison of LLM\nand traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes\ninto account both performance (standard indices) and alternative metrics such\nas timing, power consumption and cost, in a word: the carbon-footprint. In our\nanalysis, we considered the prototyping phase (model selection by\ntraining-validation-test iterations) and in-production phases separately, since\nthey follow different implementation procedures and also require different\nresources. The results indicate that very often, the simplest algorithms\nachieve performance very close to that of large LLMs but with very low power\nconsumption and lower resource demands. The results obtained could suggest\ncompanies to include additional evaluations in the choice of Machine Learning\n(ML) solutions.", "published": "2023-11-02 14:16:48", "link": "http://arxiv.org/abs/2311.01256v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.CL"}
{"title": "AWEQ: Post-Training Quantization with Activation-Weight Equalization for\n  Large Language Models", "abstract": "Large language models(LLMs) exhibit excellent performance across a variety of\ntasks, but they come with significant computational and storage costs.\nQuantizing these models is an effective way to alleviate this issue. However,\nexisting methods struggle to strike a balance between model accuracy and\nhardware efficiency. This is where we introduce AWEQ, a post-training method\nthat requires no additional training overhead. AWEQ excels in both\nultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.\nThere is an observation that weight quantization is less challenging than\nactivation quantization. AWEQ transfers the difficulty of activation\nquantization to weights using channel equalization, achieving a balance between\nthe quantization difficulties of both, and thereby maximizing performance. We\nhave further refined the equalization method to mitigate quantization bias\nerror, ensuring the robustness of the model. Extensive experiments on popular\nmodels such as LLaMA and OPT demonstrate that AWEQ outperforms all existing\npost-training quantization methods for large models.", "published": "2023-11-02 15:18:22", "link": "http://arxiv.org/abs/2311.01305v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Server-side Rescoring of Spoken Entity-centric Knowledge Queries for\n  Virtual Assistants", "abstract": "On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition\n(ASR) require effective knowledge integration for the challenging entity-rich\nquery recognition. In this paper, we conduct an empirical study of modeling\nstrategies for server-side rescoring of spoken information domain queries using\nvarious categories of Language Models (LMs) (N-gram word LMs, sub-word neural\nLMs). We investigate the combination of on-device and server-side signals, and\ndemonstrate significant WER improvements of 23%-35% on various entity-centric\nquery subpopulations by integrating various server-side LMs compared to\nperforming ASR on-device only. We also perform a comparison between LMs trained\non domain data and a GPT-3 variant offered by OpenAI as a baseline.\nFurthermore, we also show that model fusion of multiple server-side LMs trained\nfrom scratch most effectively combines complementary strengths of each model\nand integrates knowledge learned from domain-specific data to a VA ASR system.", "published": "2023-11-02 17:07:23", "link": "http://arxiv.org/abs/2311.01398v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Implicit Chain of Thought Reasoning via Knowledge Distillation", "abstract": "To augment language models with the ability to reason, researchers usually\nprompt or finetune them to produce chain of thought reasoning steps before\nproducing the final answer. However, although people use natural language to\nreason effectively, it may be that LMs could reason more effectively with some\nintermediate computation that is not in natural language. In this work, we\nexplore an alternative reasoning approach: instead of explicitly producing the\nchain of thought reasoning steps, we use the language model's internal hidden\nstates to perform implicit reasoning. The implicit reasoning steps are\ndistilled from a teacher model trained on explicit chain-of-thought reasoning,\nand instead of doing reasoning \"horizontally\" by producing intermediate words\none-by-one, we distill it such that the reasoning happens \"vertically\" among\nthe hidden states in different layers. We conduct experiments on a multi-digit\nmultiplication task and a grade school math problem dataset and find that this\napproach enables solving tasks previously not solvable without explicit\nchain-of-thought, at a speed comparable to no chain-of-thought.", "published": "2023-11-02 17:59:49", "link": "http://arxiv.org/abs/2311.01460v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FLAP: Fast Language-Audio Pre-training", "abstract": "We propose Fast Language-Audio Pre-training (FLAP), a self-supervised\napproach that efficiently and effectively learns aligned audio and language\nrepresentations through masking, contrastive learning and reconstruction. For\nefficiency, FLAP randomly drops audio spectrogram tokens, focusing solely on\nthe remaining ones for self-supervision. Through inter-modal contrastive\nlearning, FLAP learns to align paired audio and text representations in a\nshared latent space. Notably, FLAP leverages multiple augmented views via\nmasking for inter-modal contrast and learns to reconstruct the masked portion\nof audio tokens. Moreover, FLAP leverages large language models (LLMs) to\naugment the text inputs, contributing to improved performance. These approaches\nlead to more robust and informative audio-text representations, enabling FLAP\nto achieve state-of-the-art (SoTA) performance on audio-text retrieval tasks on\nAudioCaps (achieving 53.0% R@1) and Clotho (achieving 25.5% R@1).", "published": "2023-11-02 21:58:50", "link": "http://arxiv.org/abs/2311.01615v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Graph Neural Networks for Topological Feature Extraction in ECG\n  Classification", "abstract": "The electrocardiogram (ECG) is a dependable instrument for assessing the\nfunction of the cardiovascular system. There has recently been much emphasis on\nprecisely classifying ECGs. While ECG situations have numerous similarities,\nlittle attention has been paid to categorizing ECGs using graph neural\nnetworks. In this study, we offer three distinct techniques for classifying\nheartbeats using deep graph neural networks to classify the ECG signals\naccurately. We suggest using different methods to extract topological features\nfrom the ECG signal and then using a branch of the graph neural network named\ngraph isomorphism network for classifying the ECGs. On the PTB Diagnostics data\nset, we tested the three proposed techniques. According to the findings, the\nthree proposed techniques are capable of making arrhythmia classification\npredictions with the accuracy of 99.38, 98.76, and 91.93 percent, respectively.", "published": "2023-11-02 16:14:34", "link": "http://arxiv.org/abs/2311.04228v1", "categories": ["eess.SP", "cs.CL", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Chain of Empathy: Enhancing Empathetic Response of Large Language Models\n  Based on Psychotherapy Models", "abstract": "We present a novel method, the Chain of Empathy (CoE) prompting, that\nutilizes insights from psychotherapy to induce Large Language Models (LLMs) to\nreason about human emotional states. This method is inspired by various\npsychotherapy approaches including Cognitive Behavioral Therapy (CBT),\nDialectical Behavior Therapy (DBT), Person Centered Therapy (PCT), and Reality\nTherapy (RT), each leading to different patterns of interpreting clients'\nmental states. LLMs without reasoning generated predominantly exploratory\nresponses. However, when LLMs used CoE reasoning, we found a more comprehensive\nrange of empathetic responses aligned with the different reasoning patterns of\neach psychotherapy model. The CBT based CoE resulted in the most balanced\ngeneration of empathetic responses. The findings underscore the importance of\nunderstanding the emotional context and how it affects human and AI\ncommunication. Our research contributes to understanding how psychotherapeutic\nmodels can be incorporated into LLMs, facilitating the development of\ncontext-specific, safer, and empathetic AI.", "published": "2023-11-02 02:21:39", "link": "http://arxiv.org/abs/2311.04915v3", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "The Impact of Preference Agreement in Reinforcement Learning from Human\n  Feedback: A Case Study in Summarization", "abstract": "Reinforcement Learning from Human Feedback (RLHF) can be used to capture\ncomplex and nuanced properties of text generation quality. As a result, the\ntask of text summarization has been identified as a good candidate for this\nprocess. In this paper, we explore how preference agreement impacts the\nefficacy of RLHF for summarization. We show that sampling human preferences to\ninclude a range of annotator agreement results in (1) higher accuracy reward\nmodels and (2) alters the characteristics of quality captured. We additionally\nshow improvements in downstream generation when using a reward model trained\nwith a range of preference agreements. Our contributions have implications for\nthe design of synthetic datasets as well as the importance of considering\nquality differentials in comparison-based data.", "published": "2023-11-02 13:21:23", "link": "http://arxiv.org/abs/2311.04919v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Measuring Five Accountable Talk Moves to Improve Instruction at Scale", "abstract": "Providing consistent, individualized feedback to teachers on their\ninstruction can improve student learning outcomes. Such feedback can especially\nbenefit novice instructors who teach on online platforms and have limited\naccess to instructional training. To build scalable measures of instruction, we\nfine-tune RoBERTa and GPT models to identify five instructional talk moves\ninspired by accountable talk theory: adding on, connecting, eliciting, probing\nand revoicing students' ideas. We fine-tune these models on a newly annotated\ndataset of 2500 instructor utterances derived from transcripts of small group\ninstruction in an online computer science course, Code in Place. Although we\nfind that GPT-3 consistently outperforms RoBERTa in terms of precision, its\nrecall varies significantly. We correlate the instructors' use of each talk\nmove with indicators of student engagement and satisfaction, including\nstudents' section attendance, section ratings, and assignment completion rates.\nWe find that using talk moves generally correlates positively with student\noutcomes, and connecting student ideas has the largest positive impact. These\nresults corroborate previous research on the effectiveness of accountable talk\nmoves and provide exciting avenues for using these models to provide\ninstructors with useful, scalable feedback.", "published": "2023-11-02 03:04:50", "link": "http://arxiv.org/abs/2311.10749v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "ProAgent: From Robotic Process Automation to Agentic Process Automation", "abstract": "From ancient water wheels to robotic process automation (RPA), automation\ntechnology has evolved throughout history to liberate human beings from arduous\ntasks. Yet, RPA struggles with tasks needing human-like intelligence,\nespecially in elaborate design of workflow construction and dynamic\ndecision-making in workflow execution. As Large Language Models (LLMs) have\nemerged human-like intelligence, this paper introduces Agentic Process\nAutomation (APA), a groundbreaking automation paradigm using LLM-based agents\nfor advanced automation by offloading the human labor to agents associated with\nconstruction and execution. We then instantiate ProAgent, an LLM-based agent\ndesigned to craft workflows from human instructions and make intricate\ndecisions by coordinating specialized agents. Empirical experiments are\nconducted to detail its construction and execution procedure of workflow,\nshowcasing the feasibility of APA, unveiling the possibility of a new paradigm\nof automation driven by agents. Our code is public at\nhttps://github.com/OpenBMB/ProAgent.", "published": "2023-11-02 14:32:16", "link": "http://arxiv.org/abs/2311.10751v2", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Modular Blended Attention Network for Video Question Answering", "abstract": "In multimodal machine learning tasks, it is due to the complexity of the\nassignments that the network structure, in most cases, is assembled in a\nsophisticated way. The holistic architecture can be separated into several\nlogical parts according to the respective ends that the modules are devised to\nachieve. As the number of modalities of information representation increases,\nconstructing ad hoc subnetworks for processing the data from divergent\nmodalities while mediating the fusion of different information types has become\na cumbersome and expensive problem. In this paper, we present an approach to\nfacilitate the question with a reusable and composable neural unit; by\nconnecting the units in series or parallel, the arduous network constructing of\nmultimodal machine learning tasks will be accomplished in a much\nstraightforward way. Additionally, through parameter sharing (weights\nreplication) among the units, the space complexity will be significantly\nreduced. We have conducted experiments on three commonly used datasets; our\nmethod achieves impressive performance compared to several video QA baselines.", "published": "2023-11-02 14:22:17", "link": "http://arxiv.org/abs/2311.12866v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks", "abstract": "Islamophobic language on online platforms fosters intolerance, making\ndetection and elimination crucial for promoting harmony. Traditional hate\nspeech detection models rely on NLP techniques like tokenization,\npart-of-speech tagging, and encoder-decoder models. However, Graph Neural\nNetworks (GNNs), with their ability to utilize relationships between data\npoints, offer more effective detection and greater explainability. In this\nwork, we represent speeches as nodes and connect them with edges based on their\ncontext and similarity to develop the graph. This study introduces a novel\nparadigm using GNNs to identify and explain hate speech towards Islam. Our\nmodel leverages GNNs to understand the context and patterns of hate speech by\nconnecting texts via pretrained NLP-generated word embeddings, achieving\nstate-of-the-art performance and enhancing detection accuracy while providing\nvaluable explanations. This highlights the potential of GNNs in combating\nonline hate speech and fostering a safer, more inclusive online environment.", "published": "2023-11-02 04:01:04", "link": "http://arxiv.org/abs/2311.04916v4", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Adapting Frechet Audio Distance for Generative Music Evaluation", "abstract": "The growing popularity of generative music models underlines the need for\nperceptually relevant, objective music quality metrics. The Frechet Audio\nDistance (FAD) is commonly used for this purpose even though its correlation\nwith perceptual quality is understudied. We show that FAD performance may be\nhampered by sample size bias, poor choice of audio embeddings, or the use of\nbiased or low-quality reference sets. We propose reducing sample size bias by\nextrapolating scores towards an infinite sample size. Through comparisons with\nMusicCaps labels and a listening test we identify audio embeddings and music\nreference sets that yield FAD scores well-correlated with acoustic and musical\nquality. Our results suggest that per-song FAD can be useful to identify\noutlier samples and predict perceptual quality for a range of music sets and\ngenerative models. Finally, we release a toolkit that allows adapting FAD for\ngenerative music evaluation.", "published": "2023-11-02 21:58:55", "link": "http://arxiv.org/abs/2311.01616v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Video2Music: Suitable Music Generation from Videos using an Affective\n  Multimodal Transformer model", "abstract": "Numerous studies in the field of music generation have demonstrated\nimpressive performance, yet virtually no models are able to directly generate\nmusic to match accompanying videos. In this work, we develop a generative music\nAI framework, Video2Music, that can match a provided video. We first curated a\nunique collection of music videos. Then, we analysed the music videos to obtain\nsemantic, scene offset, motion, and emotion features. These distinct features\nare then employed as guiding input to our music generation model. We transcribe\nthe audio files into MIDI and chords, and extract features such as note density\nand loudness. This results in a rich multimodal dataset, called MuVi-Sync, on\nwhich we train a novel Affective Multimodal Transformer (AMT) model to generate\nmusic given a video. This model includes a novel mechanism to enforce affective\nsimilarity between video and music. Finally, post-processing is performed based\non a biGRU-based regression model to estimate note density and loudness based\non the video features. This ensures a dynamic rendering of the generated chords\nwith varying rhythm and volume. In a thorough experiment, we show that our\nproposed framework can generate music that matches the video content in terms\nof emotion. The musical quality, along with the quality of music-video matching\nis confirmed in a user study. The proposed AMT model, along with the new\nMuVi-Sync dataset, presents a promising step for the new task of music\ngeneration for videos.", "published": "2023-11-02 03:33:00", "link": "http://arxiv.org/abs/2311.00968v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Expressive TTS Driven by Natural Language Prompts Using Few Human\n  Annotations", "abstract": "Expressive text-to-speech (TTS) aims to synthesize speeches with human-like\ntones, moods, or even artistic attributes. Recent advancements in expressive\nTTS empower users with the ability to directly control synthesis style through\nnatural language prompts. However, these methods often require excessive\ntraining with a significant amount of style-annotated data, which can be\nchallenging to acquire. Moreover, they may have limited adaptability due to\nfixed style annotations. In this work, we present FreeStyleTTS (FS-TTS), a\ncontrollable expressive TTS model with minimal human annotations. Our approach\nutilizes a large language model (LLM) to transform expressive TTS into a style\nretrieval task. The LLM selects the best-matching style references from\nannotated utterances based on external style prompts, which can be raw input\ntext or natural language style descriptions. The selected reference guides the\nTTS pipeline to synthesize speeches with the intended style. This innovative\napproach provides flexible, versatile, and precise style control with minimal\nhuman workload. Experiments on a Mandarin storytelling corpus demonstrate\nFS-TTS's proficiency in leveraging LLM's semantic inference ability to retrieve\ndesired styles from either input text or user-defined descriptions. This\nresults in synthetic speeches that are closely aligned with the specified\nstyles.", "published": "2023-11-02 14:20:37", "link": "http://arxiv.org/abs/2311.01260v1", "categories": ["eess.AS", "cs.AI", "cs.HC", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ATGNN: Audio Tagging Graph Neural Network", "abstract": "Deep learning models such as CNNs and Transformers have achieved impressive\nperformance for end-to-end audio tagging. Recent works have shown that despite\nstacking multiple layers, the receptive field of CNNs remains severely limited.\nTransformers on the other hand are able to map global context through\nself-attention, but treat the spectrogram as a sequence of patches which is not\nflexible enough to capture irregular audio objects. In this work, we treat the\nspectrogram in a more flexible way by considering it as graph structure and\nprocess it with a novel graph neural architecture called ATGNN. ATGNN not only\ncombines the capability of CNNs with the global information sharing ability of\nGraph Neural Networks, but also maps semantic relationships between learnable\nclass embeddings and corresponding spectrogram regions. We evaluate ATGNN on\ntwo audio tagging tasks, where it achieves 0.585 mAP on the FSD50K dataset and\n0.335 mAP on the AudioSet-balanced dataset, achieving comparable results to\nTransformer based models with significantly lower number of learnable\nparameters.", "published": "2023-11-02 18:19:26", "link": "http://arxiv.org/abs/2311.01526v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
