{"title": "MeisterMorxrc at SemEval-2020 Task 9: Fine-Tune Bert and Multitask\n  Learning for Sentiment Analysis of Code-Mixed Tweets", "abstract": "Natural language processing (NLP) has been applied to various fields\nincluding text classification and sentiment analysis. In the shared task of\nsentiment analysis of code-mixed tweets, which is a part of the SemEval-2020\ncompetition~\\cite{patwa2020sentimix}, we preprocess datasets by replacing emoji\nand deleting uncommon characters and so on, and then fine-tune the\nBidirectional Encoder Representation from Transformers(BERT) to perform the\nbest. After exhausting top3 submissions, Our team MeisterMorxrc achieves an\naveraged F1 score of 0.730 in this task, and and our codalab username is\nMeisterMorxrc.", "published": "2020-12-15 10:42:14", "link": "http://arxiv.org/abs/2101.03028v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Writing Polishment with Simile: Task, Dataset and A Neural Approach", "abstract": "A simile is a figure of speech that directly makes a comparison, showing\nsimilarities between two different things, e.g. \"Reading papers can be dull\nsometimes,like watching grass grow\". Human writers often interpolate\nappropriate similes into proper locations of the plain text to vivify their\nwritings. However, none of existing work has explored neural simile\ninterpolation, including both locating and generation. In this paper, we\npropose a new task of Writing Polishment with Simile (WPS) to investigate\nwhether machines are able to polish texts with similes as we human do.\nAccordingly, we design a two-staged Locate&Gen model based on transformer\narchitecture. Our model firstly locates where the simile interpolation should\nhappen, and then generates a location-specific simile. We also release a\nlarge-scale Chinese Simile (CS) dataset containing 5 million similes with\ncontext. The experimental results demonstrate the feasibility of WPS task and\nshed light on the future research directions towards better automatic text\npolishment.", "published": "2020-12-15 06:39:54", "link": "http://arxiv.org/abs/2012.08117v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Check Contract Inconsistencies", "abstract": "Contract consistency is important in ensuring the legal validity of the\ncontract. In many scenarios, a contract is written by filling the blanks in a\nprecompiled form. Due to carelessness, two blanks that should be filled with\nthe same (or different)content may be incorrectly filled with different (or\nsame) content. This will result in the issue of contract inconsistencies, which\nmay severely impair the legal validity of the contract. Traditional methods to\naddress this issue mainly rely on manual contract review, which is\nlabor-intensive and costly. In this work, we formulate a novel Contract\nInconsistency Checking (CIC) problem, and design an end-to-end framework,\ncalled Pair-wise Blank Resolution (PBR), to solve the CIC problem with high\naccuracy. Our PBR model contains a novel BlankCoder to address the challenge of\nmodeling meaningless blanks. BlankCoder adopts a two-stage attention mechanism\nthat adequately associates a meaningless blank with its relevant descriptions\nwhile avoiding the incorporation of irrelevant context words. Experiments\nconducted on real-world datasets show the promising performance of our method\nwith a balanced accuracy of 94.05% and an F1 score of 90.90% in the CIC\nproblem.", "published": "2020-12-15 08:43:07", "link": "http://arxiv.org/abs/2012.08150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Homophone Noise for Robust Neural Machine Translation", "abstract": "In this paper, we propose a robust neural machine translation (NMT)\nframework. The framework consists of a homophone noise detector and a\nsyllable-aware NMT model to homophone errors. The detector identifies potential\nhomophone errors in a textual sentence and converts them into syllables to form\na mixed sequence that is then fed into the syllable-aware NMT. Extensive\nexperiments on Chinese->English translation demonstrate that our proposed\nmethod not only significantly outperforms baselines on noisy test sets with\nhomophone noise, but also achieves a substantial improvement on clean text.", "published": "2020-12-15 16:12:04", "link": "http://arxiv.org/abs/2012.08396v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Transfer Learning For End-to-End Spoken Language Understanding", "abstract": "Voice Assistants such as Alexa, Siri, and Google Assistant typically use a\ntwo-stage Spoken Language Understanding pipeline; first, an Automatic Speech\nRecognition (ASR) component to process customer speech and generate text\ntranscriptions, followed by a Natural Language Understanding (NLU) component to\nmap transcriptions to an actionable hypothesis. An end-to-end (E2E) system that\ngoes directly from speech to a hypothesis is a more attractive option. These\nsystems were shown to be smaller, faster, and better optimized. However, they\nrequire massive amounts of end-to-end training data and in addition, don't take\nadvantage of the already available ASR and NLU training data.\n  In this work, we propose an E2E system that is designed to jointly train on\nmultiple speech-to-text tasks, such as ASR (speech-transcription) and SLU\n(speech-hypothesis), and text-to-text tasks, such as NLU (text-hypothesis). We\ncall this the Audio-Text All-Task (AT-AT) Model and we show that it beats the\nperformance of E2E models trained on individual tasks, especially ones trained\non limited data. We show this result on an internal music dataset and two\npublic datasets, FluentSpeech and SNIPS Audio, where we achieve\nstate-of-the-art results. Since our model can process both speech and text\ninput sequences and learn to predict a target sequence, it also allows us to do\nzero-shot E2E SLU by training on only text-hypothesis data (without any speech)\nfrom a new domain. We evaluate this ability of our model on the Facebook TOP\ndataset and set a new benchmark for zeroshot E2E performance. We will soon\nrelease the audio data collected for the TOP dataset for future research.", "published": "2020-12-15 19:02:15", "link": "http://arxiv.org/abs/2012.08549v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pre-Training Transformers as Energy-Based Cloze Models", "abstract": "We introduce Electric, an energy-based cloze model for representation\nlearning over text. Like BERT, it is a conditional generative model of tokens\ngiven their contexts. However, Electric does not use masking or output a full\ndistribution over tokens that could occur in a context. Instead, it assigns a\nscalar energy score to each input token indicating how likely it is given its\ncontext. We train Electric using an algorithm based on noise-contrastive\nestimation and elucidate how this learning objective is closely related to the\nrecently proposed ELECTRA pre-training method. Electric performs well when\ntransferred to downstream tasks and is particularly effective at producing\nlikelihood scores for text: it re-ranks speech recognition n-best lists better\nthan language models and much faster than masked language models. Furthermore,\nit offers a clearer and more principled view of what ELECTRA learns during\npre-training.", "published": "2020-12-15 19:17:33", "link": "http://arxiv.org/abs/2012.08561v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LiteMuL: A Lightweight On-Device Sequence Tagger using Multi-task\n  Learning", "abstract": "Named entity detection and Parts-of-speech tagging are the key tasks for many\nNLP applications. Although the current state of the art methods achieved near\nperfection for long, formal, structured text there are hindrances in deploying\nthese models on memory-constrained devices such as mobile phones. Furthermore,\nthe performance of these models is degraded when they encounter short,\ninformal, and casual conversations. To overcome these difficulties, we present\nLiteMuL - a lightweight on-device sequence tagger that can efficiently process\nthe user conversations using a Multi-Task Learning (MTL) approach. To the best\nof our knowledge, the proposed model is the first on-device MTL neural model\nfor sequence tagging. Our LiteMuL model is about 2.39 MB in size and achieved\nan accuracy of 0.9433 (for NER), 0.9090 (for POS) on the CoNLL 2003 dataset.\nThe proposed LiteMuL not only outperforms the current state of the art results\nbut also surpasses the results of our proposed on-device task-specific models,\nwith accuracy gains of up to 11% and model-size reduction by 50%-56%. Our model\nis competitive with other MTL approaches for NER and POS tasks while outshines\nthem with a low memory footprint. We also evaluated our model on custom-curated\nuser conversations and observed impressive results.", "published": "2020-12-15 19:15:54", "link": "http://arxiv.org/abs/2101.03024v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EmpLite: A Lightweight Sequence Labeling Model for Emphasis Selection of\n  Short Texts", "abstract": "Word emphasis in textual content aims at conveying the desired intention by\nchanging the size, color, typeface, style (bold, italic, etc.), and other\ntypographical features. The emphasized words are extremely helpful in drawing\nthe readers' attention to specific information that the authors wish to\nemphasize. However, performing such emphasis using a soft keyboard for social\nmedia interactions is time-consuming and has an associated learning curve. In\nthis paper, we propose a novel approach to automate the emphasis word detection\non short written texts. To the best of our knowledge, this work presents the\nfirst lightweight deep learning approach for smartphone deployment of emphasis\nselection. Experimental results show that our approach achieves comparable\naccuracy at a much lower model size than existing models. Our best lightweight\nmodel has a memory footprint of 2.82 MB with a matching score of 0.716 on\nSemEval-2020 public benchmark dataset.", "published": "2020-12-15 19:00:44", "link": "http://arxiv.org/abs/2101.03025v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Graphs and Natural-Language Processing", "abstract": "Emergency-relevant data comes in many varieties. It can be high volume and\nhigh velocity, and reaction times are critical, calling for efficient and\npowerful techniques for data analysis and management. Knowledge graphs\nrepresent data in a rich, flexible, and uniform way that is well matched with\nthe needs of emergency management. They build on existing standards, resources,\ntechniques, and tools for semantic data and computing. This chapter explains\nthe most important semantic technologies and how they support knowledge graphs.\nWe proceed to discuss their benefits and challenges and give examples of\nrelevant semantic data sources and vocabularies. Natural-language texts -- in\nparticular those collected from social media such as Twitter -- is a type of\ndata source that poses particular analysis challenges. We therefore include an\noverview of techniques for processing natural-language texts.", "published": "2020-12-15 16:53:28", "link": "http://arxiv.org/abs/2101.06111v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Traditional IR rivals neural models on the MS MARCO Document Ranking\n  Leaderboard", "abstract": "This short document describes a traditional IR system that achieved MRR@100\nequal to 0.298 on the MS MARCO Document Ranking leaderboard (on 2020-12-06).\nAlthough inferior to most BERT-based models, it outperformed several neural\nruns (as well as all non-neural ones), including two submissions that used a\nlarge pretrained Transformer model for re-ranking. We provide software and data\nto reproduce our results.", "published": "2020-12-15 00:35:41", "link": "http://arxiv.org/abs/2012.08020v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Enriched Annotations for Tumor Attribute Classification from Pathology\n  Reports with Limited Labeled Data", "abstract": "Precision medicine has the potential to revolutionize healthcare, but much of\nthe data for patients is locked away in unstructured free-text, limiting\nresearch and delivery of effective personalized treatments. Generating large\nannotated datasets for information extraction from clinical notes is often\nchallenging and expensive due to the high level of expertise needed for high\nquality annotations. To enable natural language processing for small dataset\nsizes, we develop a novel enriched hierarchical annotation scheme and\nalgorithm, Supervised Line Attention (SLA), and apply this algorithm to\npredicting categorical tumor attributes from kidney and colon cancer pathology\nreports from the University of California San Francisco (UCSF). Whereas\nprevious work only annotated document level labels, we in addition ask the\nannotators to enrich the traditional label by asking them to also highlight the\nrelevant line or potentially lines for the final label, which leads to a 20%\nincrease of annotation time required per document. With the enriched\nannotations, we develop a simple and interpretable machine learning algorithm\nthat first predicts the relevant lines in the document and then predicts the\ntumor attribute. Our results show across the small dataset sizes of 32, 64,\n128, and 186 labeled documents per cancer, SLA only requires half the number of\nlabeled documents as state-of-the-art methods to achieve similar or better\nmicro-f1 and macro-f1 scores for the vast majority of comparisons that we made.\nAccounting for the increased annotation time, this leads to a 40% reduction in\ntotal annotation time over the state of the art.", "published": "2020-12-15 06:31:38", "link": "http://arxiv.org/abs/2012.08113v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Relation-Aware Neighborhood Matching Model for Entity Alignment", "abstract": "Entity alignment which aims at linking entities with the same meaning from\ndifferent knowledge graphs (KGs) is a vital step for knowledge fusion. Existing\nresearch focused on learning embeddings of entities by utilizing structural\ninformation of KGs for entity alignment. These methods can aggregate\ninformation from neighboring nodes but may also bring noise from neighbors.\nMost recently, several researchers attempted to compare neighboring nodes in\npairs to enhance the entity alignment. However, they ignored the relations\nbetween entities which are also important for neighborhood matching. In\naddition, existing methods paid less attention to the positive interactions\nbetween the entity alignment and the relation alignment. To deal with these\nissues, we propose a novel Relation-aware Neighborhood Matching model named RNM\nfor entity alignment. Specifically, we propose to utilize the neighborhood\nmatching to enhance the entity alignment. Besides comparing neighbor nodes when\nmatching neighborhood, we also try to explore useful information from the\nconnected relations. Moreover, an iterative framework is designed to leverage\nthe positive interactions between the entity alignment and the relation\nalignment in a semi-supervised manner. Experimental results on three real-world\ndatasets demonstrate that the proposed model RNM performs better than\nstate-of-the-art methods.", "published": "2020-12-15 07:22:39", "link": "http://arxiv.org/abs/2012.08128v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Response Retrieval Approach for Dialogue Using a Multi-Attentive\n  Transformer", "abstract": "This paper presents our work for the ninth edition of the Dialogue System\nTechnology Challenge (DSTC9). Our solution addresses the track number four:\nSimulated Interactive MultiModal Conversations. The task consists in providing\nan algorithm able to simulate a shopping assistant that supports the user with\nhis/her requests. We address the task of response retrieval, that is the task\nof retrieving the most appropriate agent response from a pool of response\ncandidates. Our approach makes use of a neural architecture based on\ntransformer with a multi-attentive structure that conditions the response of\nthe agent on the request made by the user and on the product the user is\nreferring to. Final experiments on the SIMMC Fashion Dataset show that our\napproach achieves the second best scores on all the retrieval metrics defined\nby the organizers. The source code is available at\nhttps://github.com/D2KLab/dstc9-SIMMC.", "published": "2020-12-15 08:35:58", "link": "http://arxiv.org/abs/2012.08148v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Efficient Clustering from Distributions over Topics", "abstract": "There are many scenarios where we may want to find pairs of textually similar\ndocuments in a large corpus (e.g. a researcher doing literature review, or an\nR&D project manager analyzing project proposals). To programmatically discover\nthose connections can help experts to achieve those goals, but brute-force\npairwise comparisons are not computationally adequate when the size of the\ndocument corpus is too large. Some algorithms in the literature divide the\nsearch space into regions containing potentially similar documents, which are\nlater processed separately from the rest in order to reduce the number of pairs\ncompared. However, this kind of unsupervised methods still incur in high\ntemporal costs. In this paper, we present an approach that relies on the\nresults of a topic modeling algorithm over the documents in a collection, as a\nmeans to identify smaller subsets of documents where the similarity function\ncan then be computed. This approach has proved to obtain promising results when\nidentifying similar documents in the domain of scientific publications. We have\ncompared our approach against state of the art clustering techniques and with\ndifferent configurations for the topic modeling algorithm. Results suggest that\nour approach outperforms (> 0.5) the other analyzed techniques in terms of\nefficiency.", "published": "2020-12-15 10:52:19", "link": "http://arxiv.org/abs/2012.08206v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional\n  Task", "abstract": "We present *-CFQ (\"star-CFQ\"): a suite of large-scale datasets of varying\nscope based on the CFQ semantic parsing benchmark, designed for principled\ninvestigation of the scalability of machine learning systems in a realistic\ncompositional task setting. Using this suite, we conduct a series of\nexperiments investigating the ability of Transformers to benefit from increased\ntraining size under conditions of fixed computational cost. We show that\ncompositional generalization remains a challenge at all training sizes, and we\nshow that increasing the scope of natural language leads to consistently higher\nerror rates, which are only partially offset by increased training data. We\nfurther show that while additional training data from a related domain improves\nthe accuracy in data-starved situations, this improvement is limited and\ndiminishes as the distance from the related domain to the target domain\nincreases.", "published": "2020-12-15 13:01:26", "link": "http://arxiv.org/abs/2012.08266v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhance Multimodal Transformer With External Label And In-Domain\n  Pretrain: Hateful Meme Challenge Winning Solution", "abstract": "Hateful meme detection is a new research area recently brought out that\nrequires both visual, linguistic understanding of the meme and some background\nknowledge to performing well on the task. This technical report summarises the\nfirst place solution of the Hateful Meme Detection Challenge 2020, which\nextending state-of-the-art visual-linguistic transformers to tackle this\nproblem. At the end of the report, we also point out the shortcomings and\npossible directions for improving the current methodology.", "published": "2020-12-15 13:57:21", "link": "http://arxiv.org/abs/2012.08290v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "CARE: Commonsense-Aware Emotional Response Generation with Latent\n  Concepts", "abstract": "Rationality and emotion are two fundamental elements of humans. Endowing\nagents with rationality and emotion has been one of the major milestones in AI.\nHowever, in the field of conversational AI, most existing models only\nspecialize in one aspect and neglect the other, which often leads to dull or\nunrelated responses. In this paper, we hypothesize that combining rationality\nand emotion into conversational agents can improve response quality. To test\nthe hypothesis, we focus on one fundamental aspect of rationality, i.e.,\ncommonsense, and propose CARE, a novel model for commonsense-aware emotional\nresponse generation. Specifically, we first propose a framework to learn and\nconstruct commonsense-aware emotional latent concepts of the response given an\ninput message and a desired emotion. We then propose three methods to\ncollaboratively incorporate the latent concepts into response generation.\nExperimental results on two large-scale datasets support our hypothesis and\nshow that our model can produce more accurate and commonsense-aware emotional\nresponses and achieve better human ratings than state-of-the-art models that\nonly specialize in one aspect.", "published": "2020-12-15 15:47:30", "link": "http://arxiv.org/abs/2012.08377v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Keyword-Guided Neural Conversational Model", "abstract": "We study the problem of imposing conversational goals/keywords on open-domain\nconversational agents, where the agent is required to lead the conversation to\na target keyword smoothly and fast. Solving this problem enables the\napplication of conversational agents in many real-world scenarios, e.g.,\nrecommendation and psychotherapy. The dominant paradigm for tackling this\nproblem is to 1) train a next-turn keyword classifier, and 2) train a\nkeyword-augmented response retrieval model. However, existing approaches in\nthis paradigm have two limitations: 1) the training and evaluation datasets for\nnext-turn keyword classification are directly extracted from conversations\nwithout human annotations, thus, they are noisy and have low correlation with\nhuman judgements, and 2) during keyword transition, the agents solely rely on\nthe similarities between word embeddings to move closer to the target keyword,\nwhich may not reflect how humans converse. In this paper, we assume that human\nconversations are grounded on commonsense and propose a keyword-guided neural\nconversational model that can leverage external commonsense knowledge graphs\n(CKG) for both keyword transition and response retrieval. Automatic evaluations\nsuggest that commonsense improves the performance of both next-turn keyword\nprediction and keyword-augmented response retrieval. In addition, both\nself-play and human evaluations show that our model produces responses with\nsmoother keyword transition and reaches the target keyword faster than\ncompetitive baselines.", "published": "2020-12-15 15:55:32", "link": "http://arxiv.org/abs/2012.08383v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Aspect Sentiment Analysis with Latent Sentiment-Aspect Attribution", "abstract": "In this paper, we introduce a new framework called the sentiment-aspect\nattribution module (SAAM). SAAM works on top of traditional neural networks and\nis designed to address the problem of multi-aspect sentiment classification and\nsentiment regression. The framework works by exploiting the correlations\nbetween sentence-level embedding features and variations of document-level\naspect rating scores. We demonstrate several variations of our framework on top\nof CNN and RNN based models. Experiments on a hotel review dataset and a beer\nreview dataset have shown SAAM can improve sentiment analysis performance over\ncorresponding base models. Moreover, because of the way our framework\nintuitively combines sentence-level scores into document-level scores, it is\nable to provide a deeper insight into data (e.g., semi-supervised sentence\naspect labeling). Hence, we end the paper with a detailed analysis that shows\nthe potential of our models for other applications such as sentiment snippet\nextraction.", "published": "2020-12-15 16:34:36", "link": "http://arxiv.org/abs/2012.08407v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Closer Look at the Robustness of Vision-and-Language Pre-trained\n  Models", "abstract": "Large-scale pre-trained multimodal transformers, such as ViLBERT and UNITER,\nhave propelled the state of the art in vision-and-language (V+L) research to a\nnew level. Although achieving impressive performance on standard tasks, to\ndate, it still remains unclear how robust these pre-trained models are. To\ninvestigate, we conduct a host of thorough evaluations on existing pre-trained\nmodels over 4 different types of V+L specific model robustness: (i) Linguistic\nVariation; (ii) Logical Reasoning; (iii) Visual Content Manipulation; and (iv)\nAnswer Distribution Shift. Interestingly, by standard model finetuning,\npre-trained V+L models already exhibit better robustness than many\ntask-specific state-of-the-art methods. To further enhance model robustness, we\npropose Mango, a generic and efficient approach that learns a Multimodal\nAdversarial Noise GeneratOr in the embedding space to fool pre-trained V+L\nmodels. Differing from previous studies focused on one specific type of\nrobustness, Mango is task-agnostic, and enables universal performance lift for\npre-trained models over diverse tasks designed to evaluate broad aspects of\nrobustness. Comprehensive experiments demonstrate that Mango achieves new state\nof the art on 7 out of 9 robustness benchmarks, surpassing existing methods by\na significant margin. As the first comprehensive study on V+L robustness, this\nwork puts robustness of pre-trained models into sharper focus, pointing new\ndirections for future study.", "published": "2020-12-15 23:41:42", "link": "http://arxiv.org/abs/2012.08673v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Scalable Cross-lingual Document Similarity through Language-specific\n  Concept Hierarchies", "abstract": "With the ongoing growth in number of digital articles in a wider set of\nlanguages and the expanding use of different languages, we need annotation\nmethods that enable browsing multi-lingual corpora. Multilingual probabilistic\ntopic models have recently emerged as a group of semi-supervised machine\nlearning models that can be used to perform thematic explorations on\ncollections of texts in multiple languages. However, these approaches require\ntheme-aligned training data to create a language-independent space. This\nconstraint limits the amount of scenarios that this technique can offer\nsolutions to train and makes it difficult to scale up to situations where a\nhuge collection of multi-lingual documents are required during the training\nphase. This paper presents an unsupervised document similarity algorithm that\ndoes not require parallel or comparable corpora, or any other type of\ntranslation resource. The algorithm annotates topics automatically created from\ndocuments in a single language with cross-lingual labels and describes\ndocuments by hierarchies of multi-lingual concepts from independently-trained\nmodels. Experiments performed on the English, Spanish and French editions of\nJCR-Acquis corpora reveal promising results on classifying and sorting\ndocuments by similar content.", "published": "2020-12-15 10:42:40", "link": "http://arxiv.org/abs/2101.03026v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "User-friendly automatic transcription of low-resource languages:\n  Plugging ESPnet into Elpis", "abstract": "This paper reports on progress integrating the speech recognition toolkit\nESPnet into Elpis, a web front-end originally designed to provide access to the\nKaldi automatic speech recognition toolkit. The goal of this work is to make\nend-to-end speech recognition models available to language workers via a\nuser-friendly graphical interface. Encouraging results are reported on (i)\ndevelopment of an ESPnet recipe for use in Elpis, with preliminary results on\ndata sets previously used for training acoustic models with the Persephone\ntoolkit along with a new data set that had not previously been used in speech\nrecognition, and (ii) incorporating ESPnet into Elpis along with UI\nenhancements and a CUDA-supported Dockerfile.", "published": "2020-12-15 09:06:21", "link": "http://arxiv.org/abs/2101.03027v2", "categories": ["cs.CL", "cs.AI", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Generation of complex database queries and API calls from natural\n  language utterances", "abstract": "Generating queries corresponding to natural language questions is a long\nstanding problem. Traditional methods lack language flexibility, while newer\nsequence-to-sequence models require large amount of data. Schema-agnostic\nsequence-to-sequence models can be fine-tuned for a specific schema using a\nsmall dataset but these models have relatively low accuracy. We present a\nmethod that transforms the query generation problem into an intent\nclassification and slot filling problem. This method can work using small\ndatasets. For questions similar to the ones in the training dataset, it\nproduces complex queries with high accuracy. For other questions, it can use a\ntemplate-based approach or predict query pieces to construct the queries, still\nat a higher accuracy than sequence-to-sequence models. On a real-world dataset,\na schema fine-tuned state-of-the-art generative model had 60\\% exact match\naccuracy for the query generation task, while our method resulted in 92\\% exact\nmatch accuracy.", "published": "2020-12-15 08:28:52", "link": "http://arxiv.org/abs/2012.08146v1", "categories": ["cs.LG", "cs.CL", "cs.DB"], "primary_category": "cs.LG"}
{"title": "QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech\n  Classification", "abstract": "Hate speech, quite common in the age of social media, at times harmless but\ncan also cause mental trauma to someone or even riots in communities. Image of\na religious symbol with derogatory comment or video of a man abusing a\nparticular community, all become hate speech with its every modality (such as\ntext, image, and audio) contributing towards it. Models based on a particular\nmodality of hate speech post on social media are not useful, rather, we need\nmodels like multi-modal fusion models that consider both image and text while\nclassifying hate speech. Text-image fusion models are heavily parameterized,\nhence we propose a quaternion neural network-based model having additional\nfusion components for each pair of modalities. The model is tested on the\nMMHS150K twitter dataset for hate speech classification. The model shows an\nalmost 75% reduction in parameters and also benefits us in terms of storage\nspace and training time while being at par in terms of performance as compared\nto its real counterpart.", "published": "2020-12-15 14:13:40", "link": "http://arxiv.org/abs/2012.08312v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs", "abstract": "Named entity recognition (NER) is a well-studied task in natural language\nprocessing. However, the widely-used sequence labeling framework is difficult\nto detect entities with nested structures. In this work, we view nested NER as\nconstituency parsing with partially-observed trees and model it with\npartially-observed TreeCRFs. Specifically, we view all labeled entity spans as\nobserved nodes in a constituency tree, and other spans as latent nodes. With\nthe TreeCRF we achieve a uniform way to jointly model the observed and the\nlatent nodes. To compute the probability of partial trees with partial\nmarginalization, we propose a variant of the Inside algorithm, the\n\\textsc{Masked Inside} algorithm, that supports different inference operations\nfor different nodes (evaluation for the observed, marginalization for the\nlatent, and rejection for nodes incompatible with the observed) with efficient\nparallelized implementation, thus significantly speeding up training and\ninference. Experiments show that our approach achieves the state-of-the-art\n(SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable\nperformance to SOTA models on the GENIA dataset. Our approach is implemented\nat: \\url{https://github.com/FranxYao/Partially-Observed-TreeCRFs}.", "published": "2020-12-15 18:20:36", "link": "http://arxiv.org/abs/2012.08478v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning from History: Modeling Temporal Knowledge Graphs with\n  Sequential Copy-Generation Networks", "abstract": "Large knowledge graphs often grow to store temporal facts that model the\ndynamic relations or interactions of entities along the timeline. Since such\ntemporal knowledge graphs often suffer from incompleteness, it is important to\ndevelop time-aware representation learning models that help to infer the\nmissing temporal facts. While the temporal facts are typically evolving, it is\nobserved that many facts often show a repeated pattern along the timeline, such\nas economic crises and diplomatic activities. This observation indicates that a\nmodel could potentially learn much from the known facts appeared in history. To\nthis end, we propose a new representation learning model for temporal knowledge\ngraphs, namely CyGNet, based on a novel timeaware copy-generation mechanism.\nCyGNet is not only able to predict future facts from the whole entity\nvocabulary, but also capable of identifying facts with repetition and\naccordingly predicting such future facts with reference to the known facts in\nthe past. We evaluate the proposed method on the knowledge graph completion\ntask using five benchmark datasets. Extensive experiments demonstrate the\neffectiveness of CyGNet for predicting future facts with repetition as well as\nde novo fact prediction.", "published": "2020-12-15 18:38:03", "link": "http://arxiv.org/abs/2012.08492v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Attention over learned object embeddings enables complex visual\n  reasoning", "abstract": "Neural networks have achieved success in a wide array of perceptual tasks but\noften fail at tasks involving both perception and higher-level reasoning. On\nthese more challenging tasks, bespoke approaches (such as modular symbolic\ncomponents, independent dynamics models or semantic parsers) targeted towards\nthat specific type of task have typically performed better. The downside to\nthese targeted approaches, however, is that they can be more brittle than\ngeneral-purpose neural networks, requiring significant modification or even\nredesign according to the particular task at hand. Here, we propose a more\ngeneral neural-network-based approach to dynamic visual reasoning problems that\nobtains state-of-the-art performance on three different domains, in each case\noutperforming bespoke modular approaches tailored specifically to the task. Our\nmethod relies on learned object-centric representations, self-attention and\nself-supervised dynamics learning, and all three elements together are required\nfor strong performance to emerge. The success of this combination suggests that\nthere may be no need to trade off flexibility for performance on problems\ninvolving spatio-temporal or causal-style reasoning. With the right soft biases\nand learning objectives in a neural network we may be able to attain the best\nof both worlds.", "published": "2020-12-15 18:57:40", "link": "http://arxiv.org/abs/2012.08508v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "F0-based Gammatone Filtering for Intelligibility Gain of Acoustic Noisy\n  Signals", "abstract": "This paper proposes a time-domain method to improve speech intelligibility in\nnoisy scenarios. In the proposed approach, a series of Gammatone filters are\nadopted to detect the harmonic components of speech. The filters outputs are\namplified to emphasize the first harmonics, reducing the masking effects of\nacoustic noises. The proposed GTFF0 solution and two baseline techniques are\nexamined considering four background noises with different non-stationarity\ndegrees. Three intelligibility measures (ESTOI, ESII and ASIIST) are adopted\nfor objective evaluation. The experiments results show that the proposed scheme\nleads to expressive speech intelligibility gain when compared to the competing\napproaches. Furthermore, the PESQ and WSS objective scores demonstrate that the\nproposed technique also provides interesting quality improvement.", "published": "2020-12-15 11:39:27", "link": "http://arxiv.org/abs/2012.08227v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Automatic Speech Verification Spoofing Detection", "abstract": "Automatic speech verification (ASV) is the technology to determine the\nidentity of a person based on their voice. While being convenient for identity\nverification, we should aim for the highest system security standard given that\nit is the safeguard of valuable digital assets. Bearing this in mind, we follow\nthe setup in ASVSpoof 2019 competition to develop potential countermeasures\nthat are robust and efficient. Two metrics, EER and t-DCF, will be used for\nsystem evaluation.", "published": "2020-12-15 05:18:09", "link": "http://arxiv.org/abs/2012.08095v1", "categories": ["cs.LG", "eess.AS"], "primary_category": "cs.LG"}
