{"title": "What's Mine becomes Yours: Defining, Annotating and Detecting\n  Context-Dependent Paraphrases in News Interview Dialogs", "abstract": "Best practices for high conflict conversations like counseling or customer\nsupport almost always include recommendations to paraphrase the previous\nspeaker. Although paraphrase classification has received widespread attention\nin NLP, paraphrases are usually considered independent from context, and common\nmodels and datasets are not applicable to dialog settings. In this work, we\ninvestigate paraphrases in dialog (e.g., Speaker 1: \"That book is mine.\"\nbecomes Speaker 2: \"That book is yours.\"). We provide an operationalization of\ncontext-dependent paraphrases, and develop a training for crowd-workers to\nclassify paraphrases in dialog. We introduce a dataset with utterance pairs\nfrom NPR and CNN news interviews annotated for context-dependent paraphrases.\nTo enable analyses on label variation, the dataset contains 5,581 annotations\non 600 utterance pairs. We present promising results with in-context learning\nand with token classification models for automatic paraphrase detection in\ndialog.", "published": "2024-04-10 01:14:12", "link": "http://arxiv.org/abs/2404.06670v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Onco-Retriever: Generative Classifier for Retrieval of EHR Records in\n  Oncology", "abstract": "Retrieving information from EHR systems is essential for answering specific\nquestions about patient journeys and improving the delivery of clinical care.\nDespite this fact, most EHR systems still rely on keyword-based searches. With\nthe advent of generative large language models (LLMs), retrieving information\ncan lead to better search and summarization capabilities. Such retrievers can\nalso feed Retrieval-augmented generation (RAG) pipelines to answer any query.\nHowever, the task of retrieving information from EHR real-world clinical data\ncontained within EHR systems in order to solve several downstream use cases is\nchallenging due to the difficulty in creating query-document support pairs. We\nprovide a blueprint for creating such datasets in an affordable manner using\nlarge language models. Our method results in a retriever that is 30-50 F-1\npoints better than propriety counterparts such as Ada and Mistral for oncology\ndata elements. We further compare our model, called Onco-Retriever, against\nfine-tuned PubMedBERT model as well. We conduct an extensive manual evaluation\non real-world EHR data along with latency analysis of the different models and\nprovide a path forward for healthcare organizations to build domain-specific\nretrievers.", "published": "2024-04-10 02:02:34", "link": "http://arxiv.org/abs/2404.06680v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CQIL: Inference Latency Optimization with Concurrent Computation of\n  Quasi-Independent Layers", "abstract": "The fast-growing large scale language models are delivering unprecedented\nperformance on almost all natural language processing tasks. However, the\neffectiveness of large language models are reliant on an exponentially\nincreasing number of parameters. The overwhelming computation complexity incurs\na high inference latency that negatively affects user experience. Existing\nmethods to improve inference efficiency, such as tensor parallelism and\nquantization, target to reduce per-layer computing latency, yet overlook the\ncumulative latency due to the number of layers. Recent works on reducing the\ncumulative latency through layer removing, however, lead to significant\nperformance drop. Motivated by the similarity of inputs among adjacent layers,\nwe propose to identify quasi-independent layers, which can be concurrently\ncomputed to significantly decrease inference latency. We also introduce a\nbypassing technique to mitigate the effect of information loss. Empirical\nexperiments of the proposed approach on the LLaMA models confirm that\nConcurrent Computation of Quasi-Independent Layers (CQIL) can reduce latency by\nup to 48.3% on LLaMA-33B, while maintaining a close level of performance.", "published": "2024-04-10 03:30:01", "link": "http://arxiv.org/abs/2404.06709v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transferable and Efficient Non-Factual Content Detection via Probe\n  Training with Offline Consistency Checking", "abstract": "Detecting non-factual content is a longstanding goal to increase the\ntrustworthiness of large language models (LLMs) generations. Current factuality\nprobes, trained using humanannotated labels, exhibit limited transferability to\nout-of-distribution content, while online selfconsistency checking imposes\nextensive computation burden due to the necessity of generating multiple\noutputs. This paper proposes PINOSE, which trains a probing model on offline\nself-consistency checking results, thereby circumventing the need for\nhuman-annotated data and achieving transferability across diverse data\ndistributions. As the consistency check process is offline, PINOSE reduces the\ncomputational burden of generating multiple responses by online consistency\nverification. Additionally, it examines various aspects of internal states\nprior to response decoding, contributing to more effective detection of factual\ninaccuracies. Experiment results on both factuality detection and question\nanswering benchmarks show that PINOSE achieves surpassing results than existing\nfactuality detection methods. Our code and datasets are publicly available on\nthis anonymized repository.", "published": "2024-04-10 05:00:35", "link": "http://arxiv.org/abs/2404.06742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation", "abstract": "The rapid development of large language models has led to the widespread\nadoption of Retrieval-Augmented Generation (RAG), which integrates external\nknowledge to alleviate knowledge bottlenecks and mitigate hallucinations.\nHowever, the existing RAG paradigm inevitably suffers from the impact of flawed\ninformation introduced during the retrieval phrase, thereby diminishing the\nreliability and correctness of the generated outcomes. In this paper, we\npropose Credibility-aware Generation (CAG), a universally applicable framework\ndesigned to mitigate the impact of flawed information in RAG. At its core, CAG\naims to equip models with the ability to discern and process information based\non its credibility. To this end, we propose an innovative data transformation\nframework that generates data based on credibility, thereby effectively\nendowing models with the capability of CAG. Furthermore, to accurately evaluate\nthe models' capabilities of CAG, we construct a comprehensive benchmark\ncovering three critical real-world scenarios. Experimental results demonstrate\nthat our model can effectively understand and utilize credibility for\ngeneration, significantly outperform other models with retrieval augmentation,\nand exhibit resilience against the disruption caused by noisy documents,\nthereby maintaining robust performance. Moreover, our model supports customized\ncredibility, offering a wide range of potential applications.", "published": "2024-04-10 07:56:26", "link": "http://arxiv.org/abs/2404.06809v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotion-cause pair extraction method based on multi-granularity\n  information and multi-module interaction", "abstract": "The purpose of emotion-cause pair extraction is to extract the pair of\nemotion clauses and cause clauses. On the one hand, the existing methods do not\ntake fully into account the relationship between the emotion extraction of two\nauxiliary tasks. On the other hand, the existing two-stage model has the\nproblem of error propagation. In addition, existing models do not adequately\naddress the emotion and cause-induced locational imbalance of samples. To solve\nthese problems, an end-to-end multitasking model (MM-ECPE) based on shared\ninteraction between GRU, knowledge graph and transformer modules is proposed.\nFurthermore, based on MM-ECPE, in order to use the encoder layer to better\nsolve the problem of imbalanced distribution of clause distances between\nclauses and emotion clauses, we propose a novel encoding based on BERT,\nsentiment lexicon, and position-aware interaction module layer of emotion motif\npair retrieval model (MM-ECPE(BERT)). The model first fully models the\ninteraction between different tasks through the multi-level sharing module, and\nmines the shared information between emotion-cause pair extraction and the\nemotion extraction and cause extraction. Second, to solve the imbalanced\ndistribution of emotion clauses and cause clauses problem, suitable labels are\nscreened out according to the knowledge graph path length and task-specific\nfeatures are constructed so that the model can focus on extracting pairs with\ncorresponding emotion-cause relationships. Experimental results on the ECPE\nbenchmark dataset show that the proposed model achieves good performance,\nespecially on position-imbalanced samples.", "published": "2024-04-10 08:00:26", "link": "http://arxiv.org/abs/2404.06812v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural\n  Knowledge", "abstract": "Recent studies have highlighted the presence of cultural biases in Large\nLanguage Models (LLMs), yet often lack a robust methodology to dissect these\nphenomena comprehensively. Our work aims to bridge this gap by delving into the\nFood domain, a universally relevant yet culturally diverse aspect of human\nlife. We introduce FmLAMA, a multilingual dataset centered on food-related\ncultural facts and variations in food practices. We analyze LLMs across various\narchitectures and configurations, evaluating their performance in both\nmonolingual and multilingual settings. By leveraging templates in six different\nlanguages, we investigate how LLMs interact with language-specific and cultural\nknowledge. Our findings reveal that (1) LLMs demonstrate a pronounced bias\ntowards food knowledge prevalent in the United States; (2) Incorporating\nrelevant cultural context significantly improves LLMs' ability to access\ncultural knowledge; (3) The efficacy of LLMs in capturing cultural nuances is\nhighly dependent on the interplay between the probing language, the specific\nmodel architecture, and the cultural context in question. This research\nunderscores the complexity of integrating cultural understanding into LLMs and\nemphasizes the importance of culturally diverse datasets to mitigate biases and\nenhance model performance across different cultural domains.", "published": "2024-04-10 08:49:27", "link": "http://arxiv.org/abs/2404.06833v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simpler becomes Harder: Do LLMs Exhibit a Coherent Behavior on\n  Simplified Corpora?", "abstract": "Text simplification seeks to improve readability while retaining the original\ncontent and meaning. Our study investigates whether pre-trained classifiers\nalso maintain such coherence by comparing their predictions on both original\nand simplified inputs. We conduct experiments using 11 pre-trained models,\nincluding BERT and OpenAI's GPT 3.5, across six datasets spanning three\nlanguages. Additionally, we conduct a detailed analysis of the correlation\nbetween prediction change rates and simplification types/strengths. Our\nfindings reveal alarming inconsistencies across all languages and models. If\nnot promptly addressed, simplified inputs can be easily exploited to craft\nzero-iteration model-agnostic adversarial attacks with success rates of up to\n50%", "published": "2024-04-10 09:02:33", "link": "http://arxiv.org/abs/2404.06838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Control-DAG: Constrained Decoding for Non-Autoregressive Directed\n  Acyclic T5 using Weighted Finite State Automata", "abstract": "The Directed Acyclic Transformer is a fast non-autoregressive (NAR) model\nthat performs well in Neural Machine Translation. Two issues prevent its\napplication to general Natural Language Generation (NLG) tasks: frequent\nOut-Of-Vocabulary (OOV) errors and the inability to faithfully generate entity\nnames. We introduce Control-DAG, a constrained decoding algorithm for our\nDirected Acyclic T5 (DA-T5) model which offers lexical, vocabulary and length\ncontrol. We show that Control-DAG significantly enhances DA-T5 on the Schema\nGuided Dialogue and the DART datasets, establishing strong NAR results for\nTask-Oriented Dialogue and Data-to-Text NLG.", "published": "2024-04-10 09:28:14", "link": "http://arxiv.org/abs/2404.06854v1", "categories": ["cs.CL", "I.2"], "primary_category": "cs.CL"}
{"title": "GraSAME: Injecting Token-Level Structural Information to Pretrained\n  Language Models via Graph-guided Self-Attention Mechanism", "abstract": "Pretrained Language Models (PLMs) benefit from external knowledge stored in\ngraph structures for various downstream tasks. However, bridging the modality\ngap between graph structures and text remains a significant challenge.\nTraditional methods like linearizing graphs for PLMs lose vital graph\nconnectivity, whereas Graph Neural Networks (GNNs) require cumbersome processes\nfor integration into PLMs. In this work, we propose a novel graph-guided\nself-attention mechanism, GraSAME. GraSAME seamlessly incorporates token-level\nstructural information into PLMs without necessitating additional alignment or\nconcatenation efforts. As an end-to-end, lightweight multimodal module, GraSAME\nfollows a multi-task learning strategy and effectively bridges the gap between\ngraph and textual modalities, facilitating dynamic interactions between GNNs\nand PLMs. Our experiments on the graph-to-text generation task demonstrate that\nGraSAME outperforms baseline models and achieves results comparable to\nstate-of-the-art (SOTA) models on WebNLG datasets. Furthermore, compared to\nSOTA models, GraSAME eliminates the need for extra pre-training tasks to adjust\ngraph inputs and reduces the number of trainable parameters by over 100\nmillion.", "published": "2024-04-10 11:03:57", "link": "http://arxiv.org/abs/2404.06911v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Accelerating Inference in Large Language Models with a Unified Layer\n  Skipping Strategy", "abstract": "Recently, dynamic computation methods have shown notable acceleration for\nLarge Language Models (LLMs) by skipping several layers of computations through\nelaborate heuristics or additional predictors. However, in the decoding process\nof existing approaches, different samples are assigned different computational\nbudgets, which cannot guarantee a stable and precise acceleration effect.\nFurthermore, existing approaches generally skip multiple contiguous layers at\nthe bottom or top of the layers, leading to a drastic change in the model's\nlayer-wise representations, and thus a consequent performance degeneration.\nTherefore, we propose a Unified Layer Skipping strategy, which selects the\nnumber of layers to skip computation based solely on the target speedup ratio,\nand then skips the corresponding number of intermediate layer computations in a\nbalanced manner. Since the Unified Layer Skipping strategy is independent of\ninput samples, it naturally supports popular acceleration techniques such as\nbatch decoding and KV caching, thus demonstrating more practicality for\nreal-world applications. Experimental results on two common tasks, i.e.,\nmachine translation and text summarization, indicate that given a target\nspeedup ratio, the Unified Layer Skipping strategy significantly enhances both\nthe inference performance and the actual model throughput over existing dynamic\napproaches.", "published": "2024-04-10 12:12:07", "link": "http://arxiv.org/abs/2404.06954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Charles Translator: A Machine Translation System between Ukrainian and\n  Czech", "abstract": "We present Charles Translator, a machine translation system between Ukrainian\nand Czech, developed as part of a society-wide effort to mitigate the impact of\nthe Russian-Ukrainian war on individuals and society. The system was developed\nin the spring of 2022 with the help of many language data providers in order to\nquickly meet the demand for such a service, which was not available at the time\nin the required quality. The translator was later implemented as an online web\ninterface and as an Android app with speech input, both featuring\nCyrillic-Latin script transliteration. The system translates directly, compared\nto other available systems that use English as a pivot, and thus take advantage\nof the typological similarity of the two languages. It uses the block\nback-translation method, which allows for efficient use of monolingual training\ndata. The paper describes the development process, including data collection\nand implementation, evaluation, mentions several use cases, and outlines\npossibilities for the further development of the system for educational\npurposes.", "published": "2024-04-10 12:22:32", "link": "http://arxiv.org/abs/2404.06964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware\n  Contrastive Learning", "abstract": "Few-shot named entity recognition can identify new types of named entities\nbased on a few labeled examples. Previous methods employing token-level or\nspan-level metric learning suffer from the computational burden and a large\nnumber of negative sample spans. In this paper, we propose the Hybrid\nMulti-stage Decoding for Few-shot NER with Entity-aware Contrastive Learning\n(MsFNER), which splits the general NER into two stages: entity-span detection\nand entity classification. There are 3 processes for introducing MsFNER:\ntraining, finetuning, and inference. In the training process, we train and get\nthe best entity-span detection model and the entity classification model\nseparately on the source domain using meta-learning, where we create a\ncontrastive learning module to enhance entity representations for entity\nclassification. During finetuning, we finetune the both models on the support\ndataset of target domain. In the inference process, for the unlabeled data, we\nfirst detect the entity-spans, then the entity-spans are jointly determined by\nthe entity classification model and the KNN. We conduct experiments on the open\nFewNERD dataset and the results demonstrate the advance of MsFNER.", "published": "2024-04-10 12:31:09", "link": "http://arxiv.org/abs/2404.06970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LM Transparency Tool: Interactive Tool for Analyzing Transformer\n  Language Models", "abstract": "We present the LM Transparency Tool (LM-TT), an open-source interactive\ntoolkit for analyzing the internal workings of Transformer-based language\nmodels. Differently from previously existing tools that focus on isolated parts\nof the decision-making process, our framework is designed to make the entire\nprediction process transparent, and allows tracing back model behavior from the\ntop-layer representation to very fine-grained parts of the model. Specifically,\nit (1) shows the important part of the whole input-to-output information flow,\n(2) allows attributing any changes done by a model block to individual\nattention heads and feed-forward neurons, (3) allows interpreting the functions\nof those heads or neurons. A crucial part of this pipeline is showing the\nimportance of specific model components at each step. As a result, we are able\nto look at the roles of model components only in cases where they are important\nfor a prediction. Since knowing which components should be inspected is key for\nanalyzing large models where the number of these components is extremely high,\nwe believe our tool will greatly support the interpretability community both in\nresearch settings and in practical applications.", "published": "2024-04-10 13:39:11", "link": "http://arxiv.org/abs/2404.07004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Computational Analysis of the Dehumanisation of Migrants from Syria\n  and Ukraine in Slovene News Media", "abstract": "Dehumanisation involves the perception and or treatment of a social group's\nmembers as less than human. This phenomenon is rarely addressed with\ncomputational linguistic techniques. We adapt a recently proposed approach for\nEnglish, making it easier to transfer to other languages and to evaluate,\nintroducing a new sentiment resource, the use of zero-shot cross-lingual\nvalence and arousal detection, and a new method for statistical significance\ntesting. We then apply it to study attitudes to migration expressed in Slovene\nnewspapers, to examine changes in the Slovene discourse on migration between\nthe 2015-16 migration crisis following the war in Syria and the 2022-23 period\nfollowing the war in Ukraine. We find that while this discourse became more\nnegative and more intense over time, it is less dehumanising when specifically\naddressing Ukrainian migrants compared to others.", "published": "2024-04-10 14:28:09", "link": "http://arxiv.org/abs/2404.07036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "We're Calling an Intervention: Exploring Fundamental Hurdles in Adapting\n  Language Models to Nonstandard Text", "abstract": "We present a suite of experiments that allow us to understand the underlying\nchallenges of language model adaptation to nonstandard text. We do so by\ndesigning interventions that approximate core features of user-generated text\nand their interactions with existing biases of language models. Applying our\ninterventions during language model adaptation to nonstandard text variations,\nwe gain important insights into when such adaptation is successful, as well as\nthe aspects of text variation and noise that are particularly difficult for\nlanguage models to handle. For instance, on text with character-level\nvariation, out-of-the-box performance improves even with a few additional\ntraining examples but approaches a plateau, suggesting that more data is not\nthe solution. In contrast, on text with variation involving new words or\nmeanings, far more data is needed, but it leads to a massive breakthrough in\nperformance. Our findings reveal that existing models lack the necessary\ninfrastructure to handle diverse forms of nonstandard text, guiding the\ndevelopment of more resilient language modeling techniques. We make the code\nfor our interventions, which can be applied to any English text data, publicly\navailable.", "published": "2024-04-10 18:56:53", "link": "http://arxiv.org/abs/2404.07304v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs in Biomedicine: A study on clinical Named Entity Recognition", "abstract": "Large Language Models (LLMs) demonstrate remarkable versatility in various\nNLP tasks but encounter distinct challenges in biomedical due to the\ncomplexities of language and data scarcity. This paper investigates LLMs\napplication in the biomedical domain by exploring strategies to enhance their\nperformance for the NER task. Our study reveals the importance of meticulously\ndesigned prompts in the biomedical. Strategic selection of in-context examples\nyields a marked improvement, offering ~15-20\\% increase in F1 score across all\nbenchmark datasets for biomedical few-shot NER. Additionally, our results\nindicate that integrating external biomedical knowledge via prompting\nstrategies can enhance the proficiency of general-purpose LLMs to meet the\nspecialized needs of biomedical NER. Leveraging a medical knowledge base, our\nproposed method, DiRAG, inspired by Retrieval-Augmented Generation (RAG), can\nboost the zero-shot F1 score of LLMs for biomedical NER. Code is released at\n\\url{https://github.com/masoud-monajati/LLM_Bio_NER}", "published": "2024-04-10 22:26:26", "link": "http://arxiv.org/abs/2404.07376v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MathVC: An LLM-Simulated Multi-Character Virtual Classroom for\n  Mathematics Education", "abstract": "Mathematical modeling (MM) is considered a fundamental skill for students in\nSTEM disciplines. Practicing the MM skill is often the most effective when\nstudents can engage in group discussion and collaborative problem-solving.\nHowever, due to unevenly distributed teachers and educational resources needed\nto monitor such group activities, students do not always receive equal\nopportunities for this practice. Excitingly, large language models (LLMs) have\nrecently demonstrated strong capability in both modeling mathematical problems\nand simulating characters with different traits and properties. Drawing\ninspiration from the advancement of LLMs, in this work, we present MATHVC, the\nvery first LLM-powered virtual classroom containing multiple LLM-simulated\nstudent characters, with whom a human student can practice their MM skill. To\nencourage each LLM character's behaviors to be aligned with their specified\nmath-relevant properties (termed \"characteristics alignment\") and the overall\nconversational procedure to be close to an authentic student MM discussion\n(termed \"conversational procedural alignment\"), we proposed three innovations:\nintegrating MM domain knowledge into the simulation, defining a symbolic schema\nas the ground for character simulation, and designing a meta planner at the\nplatform level to drive the conversational procedure. Through experiments and\nablation studies, we confirmed the effectiveness of our simulation approach and\nshowed the promise for MATHVC to benefit real-life students in the future.", "published": "2024-04-10 03:35:51", "link": "http://arxiv.org/abs/2404.06711v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Global Contrastive Training for Multimodal Electronic Health Records\n  with Language Supervision", "abstract": "Modern electronic health records (EHRs) hold immense promise in tracking\npersonalized patient health trajectories through sequential deep learning,\nowing to their extensive breadth, scale, and temporal granularity. Nonetheless,\nhow to effectively leverage multiple modalities from EHRs poses significant\nchallenges, given its complex characteristics such as high dimensionality,\nmultimodality, sparsity, varied recording frequencies, and temporal\nirregularities. To this end, this paper introduces a novel multimodal\ncontrastive learning framework, specifically focusing on medical time series\nand clinical notes. To tackle the challenge of sparsity and irregular time\nintervals in medical time series, the framework integrates temporal\ncross-attention transformers with a dynamic embedding and tokenization scheme\nfor learning multimodal feature representations. To harness the interconnected\nrelationships between medical time series and clinical notes, the framework\nequips a global contrastive loss, aligning a patient's multimodal feature\nrepresentations with the corresponding discharge summaries. Since discharge\nsummaries uniquely pertain to individual patients and represent a holistic view\nof the patient's hospital stay, machine learning models are led to learn\ndiscriminative multimodal features via global contrasting. Extensive\nexperiments with a real-world EHR dataset demonstrated that our framework\noutperformed state-of-the-art approaches on the exemplar task of predicting the\noccurrence of nine postoperative complications for more than 120,000 major\ninpatient surgeries using multimodal data from UF health system split among\nthree hospitals (UF Health Gainesville, UF Health Jacksonville, and UF Health\nJacksonville-North).", "published": "2024-04-10 04:19:59", "link": "http://arxiv.org/abs/2404.06723v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DiffusionDialog: A Diffusion Model for Diverse Dialog Generation with\n  Latent Space", "abstract": "In real-life conversations, the content is diverse, and there exists the\none-to-many problem that requires diverse generation. Previous studies\nattempted to introduce discrete or Gaussian-based continuous latent variables\nto address the one-to-many problem, but the diversity is limited. Recently,\ndiffusion models have made breakthroughs in computer vision, and some attempts\nhave been made in natural language processing. In this paper, we propose\nDiffusionDialog, a novel approach to enhance the diversity of dialogue\ngeneration with the help of diffusion model. In our approach, we introduce\ncontinuous latent variables into the diffusion model. The problem of using\nlatent variables in the dialog task is how to build both an effective prior of\nthe latent space and an inferring process to obtain the proper latent given the\ncontext. By combining the encoder and latent-based diffusion model, we encode\nthe response's latent representation in a continuous space as the prior,\ninstead of fixed Gaussian distribution or simply discrete ones. We then infer\nthe latent by denoising step by step with the diffusion model. The experimental\nresults show that our model greatly enhances the diversity of dialog responses\nwhile maintaining coherence. Furthermore, in further analysis, we find that our\ndiffusion model achieves high inference efficiency, which is the main challenge\nof applying diffusion models in natural language processing.", "published": "2024-04-10 05:56:46", "link": "http://arxiv.org/abs/2404.06760v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Personality-aware Student Simulation for Conversational Intelligent\n  Tutoring Systems", "abstract": "Intelligent Tutoring Systems (ITSs) can provide personalized and self-paced\nlearning experience. The emergence of large language models (LLMs) further\nenables better human-machine interaction, and facilitates the development of\nconversational ITSs in various disciplines such as math and language learning.\nIn dialogic teaching, recognizing and adapting to individual characteristics\ncan significantly enhance student engagement and learning efficiency. However,\ncharacterizing and simulating student's persona remain challenging in training\nand evaluating conversational ITSs. In this work, we propose a framework to\nconstruct profiles of different student groups by refining and integrating both\ncognitive and noncognitive aspects, and leverage LLMs for personality-aware\nstudent simulation in a language learning scenario. We further enhance the\nframework with multi-aspect validation, and conduct extensive analysis from\nboth teacher and student perspectives. Our experimental results show that\nstate-of-the-art LLMs can produce diverse student responses according to the\ngiven language ability and personality traits, and trigger teacher's adaptive\nscaffolding strategies.", "published": "2024-04-10 06:03:13", "link": "http://arxiv.org/abs/2404.06762v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM\n  Applications", "abstract": "Large Language Models (LLMs) are evolving beyond their classical role of\nproviding information within dialogue systems to actively engaging with tools\nand performing actions on real-world applications and services. Today, humans\nverify the correctness and appropriateness of the LLM-generated outputs (e.g.,\ncode, functions, or actions) before putting them into real-world execution.\nThis poses significant challenges as code comprehension is well known to be\nnotoriously difficult. In this paper, we study how humans can efficiently\ncollaborate with, delegate to, and supervise autonomous LLMs in the future. We\nargue that in many cases, \"post-facto validation\" - verifying the correctness\nof a proposed action after seeing the output - is much easier than the\naforementioned \"pre-facto validation\" setting. The core concept behind enabling\na post-facto validation system is the integration of an intuitive undo feature,\nand establishing a damage confinement for the LLM-generated actions as\neffective strategies to mitigate the associated risks. Using this, a human can\nnow either revert the effect of an LLM-generated output or be confident that\nthe potential risk is bounded. We believe this is critical to unlock the\npotential for LLM agents to interact with applications and services with\nlimited (post-facto) human involvement. We describe the design and\nimplementation of our open-source runtime for executing LLM actions, Gorilla\nExecution Engine (GoEX), and present open research questions towards realizing\nthe goal of LLMs and applications interacting with each other with minimal\nhuman supervision. We release GoEX at https://github.com/ShishirPatil/gorilla/.", "published": "2024-04-10 11:17:33", "link": "http://arxiv.org/abs/2404.06921v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MetaCheckGPT -- A Multi-task Hallucination Detector Using LLM\n  Uncertainty and Meta-models", "abstract": "Hallucinations in large language models (LLMs) have recently become a\nsignificant problem. A recent effort in this direction is a shared task at\nSemeval 2024 Task 6, SHROOM, a Shared-task on Hallucinations and Related\nObservable Overgeneration Mistakes. This paper describes our winning solution\nranked 1st and 2nd in the 2 sub-tasks of model agnostic and model aware tracks\nrespectively. We propose a meta-regressor framework of LLMs for model\nevaluation and integration that achieves the highest scores on the leaderboard.\nWe also experiment with various transformer-based models and black box methods\nlike ChatGPT, Vectara, and others. In addition, we perform an error analysis\ncomparing GPT4 against our best model which shows the limitations of the\nformer.", "published": "2024-04-10 11:56:01", "link": "http://arxiv.org/abs/2404.06948v2", "categories": ["cs.CL", "cs.AI", "68T07, 68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "XNLIeu: a dataset for cross-lingual NLI in Basque", "abstract": "XNLI is a popular Natural Language Inference (NLI) benchmark widely used to\nevaluate cross-lingual Natural Language Understanding (NLU) capabilities across\nlanguages. In this paper, we expand XNLI to include Basque, a low-resource\nlanguage that can greatly benefit from transfer-learning approaches. The new\ndataset, dubbed XNLIeu, has been developed by first machine-translating the\nEnglish XNLI corpus into Basque, followed by a manual post-edition step. We\nhave conducted a series of experiments using mono- and multilingual LLMs to\nassess a) the effect of professional post-edition on the MT system; b) the best\ncross-lingual strategy for NLI in Basque; and c) whether the choice of the best\ncross-lingual strategy is influenced by the fact that the dataset is built by\ntranslation. The results show that post-edition is necessary and that the\ntranslate-train cross-lingual strategy obtains better results overall, although\nthe gain is lower when tested in a dataset that has been built natively from\nscratch. Our code and datasets are publicly available under open licenses.", "published": "2024-04-10 13:19:56", "link": "http://arxiv.org/abs/2404.06996v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Event Grounded Criminal Court View Generation with Cooperative (Large)\n  Language Models", "abstract": "With the development of legal intelligence, Criminal Court View Generation\nhas attracted much attention as a crucial task of legal intelligence, which\naims to generate concise and coherent texts that summarize case facts and\nprovide explanations for verdicts. Existing researches explore the key\ninformation in case facts to yield the court views. Most of them employ a\ncoarse-grained approach that partitions the facts into broad segments (e.g.,\nverdict-related sentences) to make predictions. However, this approach fails to\ncapture the complex details present in the case facts, such as various criminal\nelements and legal events. To this end, in this paper, we propose an Event\nGrounded Generation (EGG) method for criminal court view generation with\ncooperative (Large) Language Models, which introduces the fine-grained event\ninformation into the generation. Specifically, we first design a LLMs-based\nextraction method that can extract events in case facts without massive\nannotated events. Then, we incorporate the extracted events into court view\ngeneration by merging case facts and events. Besides, considering the\ncomputational burden posed by the use of LLMs in the extraction phase of EGG,\nwe propose a LLMs-free EGG method that can eliminate the requirement for event\nextraction using LLMs in the inference phase. Extensive experimental results on\na real-world dataset clearly validate the effectiveness of our proposed method.", "published": "2024-04-10 13:31:07", "link": "http://arxiv.org/abs/2404.07001v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Language Model Reasoning with Self-motivated Learning", "abstract": "Large-scale high-quality training data is important for improving the\nperformance of models. After trained with data that has rationales (reasoning\nsteps), models gain reasoning capability. However, the dataset with\nhigh-quality rationales is relatively scarce due to the high annotation cost.\nTo address this issue, we propose \\textit{Self-motivated Learning} framework.\nThe framework motivates the model itself to automatically generate rationales\non existing datasets. Based on the inherent rank from correctness across\nmultiple rationales, the model learns to generate better rationales, leading to\nhigher reasoning capability. Specifically, we train a reward model with the\nrank to evaluate the quality of rationales, and improve the performance of\nreasoning through reinforcement learning. Experiment results of Llama2 7B on\nmultiple reasoning datasets show that our method significantly improves the\nreasoning ability of models, even outperforming text-davinci-002 in some\ndatasets.", "published": "2024-04-10 14:05:44", "link": "http://arxiv.org/abs/2404.07017v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Groundedness in Retrieval-augmented Long-form Generation: An Empirical\n  Study", "abstract": "We present an empirical study of groundedness in long-form question answering\n(LFQA) by retrieval-augmented large language models (LLMs). In particular, we\nevaluate whether every generated sentence is grounded in the retrieved\ndocuments or the model's pre-training data. Across 3 datasets and 4 model\nfamilies, our findings reveal that a significant fraction of generated\nsentences are consistently ungrounded, even when those sentences contain\ncorrect ground-truth answers. Additionally, we examine the impacts of factors\nsuch as model size, decoding strategy, and instruction tuning on groundedness.\nOur results show that while larger models tend to ground their outputs more\neffectively, a significant portion of correct answers remains compromised by\nhallucinations. This study provides novel insights into the groundedness\nchallenges in LFQA and underscores the necessity for more robust mechanisms in\nLLMs to mitigate the generation of ungrounded content.", "published": "2024-04-10 14:50:10", "link": "http://arxiv.org/abs/2404.07060v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Generation of Personalities with Large Language Models", "abstract": "In the realm of mimicking human deliberation, large language models (LLMs)\nshow promising performance, thereby amplifying the importance of this research\narea. Deliberation is influenced by both logic and personality. However,\nprevious studies predominantly focused on the logic of LLMs, neglecting the\nexploration of personality aspects. In this work, we introduce Dynamic\nPersonality Generation (DPG), a dynamic personality generation method based on\nHypernetworks. Initially, we embed the Big Five personality theory into GPT-4\nto form a personality assessment machine, enabling it to evaluate characters'\npersonality traits from dialogues automatically. We propose a new metric to\nassess personality generation capability based on this evaluation method. Then,\nwe use this personality assessment machine to evaluate dialogues in script\ndata, resulting in a personality-dialogue dataset. Finally, we fine-tune DPG on\nthe personality-dialogue dataset. Experiments prove that DPG's personality\ngeneration capability is stronger after fine-tuning on this dataset than\ntraditional fine-tuning methods, surpassing prompt-based GPT-4.", "published": "2024-04-10 15:17:17", "link": "http://arxiv.org/abs/2404.07084v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Model-centered to Human-Centered: Revision Distance as a Metric for\n  Text Evaluation in LLMs-based Applications", "abstract": "Evaluating large language models (LLMs) is fundamental, particularly in the\ncontext of practical applications. Conventional evaluation methods, typically\ndesigned primarily for LLM development, yield numerical scores that ignore the\nuser experience. Therefore, our study shifts the focus from model-centered to\nhuman-centered evaluation in the context of AI-powered writing assistance\napplications. Our proposed metric, termed ``Revision Distance,'' utilizes LLMs\nto suggest revision edits that mimic the human writing process. It is\ndetermined by counting the revision edits generated by LLMs. Benefiting from\nthe generated revision edit details, our metric can provide a self-explained\ntext evaluation result in a human-understandable manner beyond the\ncontext-independent score. Our results show that for the easy-writing task,\n``Revision Distance'' is consistent with established metrics (ROUGE,\nBert-score, and GPT-score), but offers more insightful, detailed feedback and\nbetter distinguishes between texts. Moreover, in the context of challenging\nacademic writing tasks, our metric still delivers reliable evaluations where\nother metrics tend to struggle. Furthermore, our metric also holds significant\npotential for scenarios lacking reference texts.", "published": "2024-04-10 15:46:08", "link": "http://arxiv.org/abs/2404.07108v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Continuous Language Model Interpolation for Dynamic and Controllable\n  Text Generation", "abstract": "As large language models (LLMs) have gained popularity for a variety of use\ncases, making them adaptable and controllable has become increasingly\nimportant, especially for user-facing applications. While the existing\nliterature on LLM adaptation primarily focuses on finding a model (or models)\nthat optimizes a single predefined objective, here we focus on the challenging\ncase where the model must dynamically adapt to diverse -- and often changing --\nuser preferences. For this, we leverage adaptation methods based on linear\nweight interpolation, casting them as continuous multi-domain interpolators\nthat produce models with specific prescribed generation characteristics\non-the-fly. Specifically, we use low-rank updates to fine-tune a base model to\nvarious different domains, yielding a set of anchor models with distinct\ngeneration profiles. Then, we use the weight updates of these anchor models to\nparametrize the entire (infinite) class of models contained within their convex\nhull. We empirically show that varying the interpolation weights yields\npredictable and consistent change in the model outputs with respect to all of\nthe controlled attributes. We find that there is little entanglement between\nmost attributes and identify and discuss the pairs of attributes for which this\nis not the case. Our results suggest that linearly interpolating between the\nweights of fine-tuned models facilitates predictable, fine-grained control of\nmodel outputs with respect to multiple stylistic characteristics\nsimultaneously.", "published": "2024-04-10 15:55:07", "link": "http://arxiv.org/abs/2404.07117v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Robustness of Text-to-Visualization Translation against Lexical\n  and Phrasal Variability", "abstract": "Text-to-Vis is an emerging task in the natural language processing (NLP) area\nthat aims to automatically generate data visualizations from natural language\nquestions (NLQs). Despite their progress, existing text-to-vis models often\nheavily rely on lexical matching between words in the questions and tokens in\ndata schemas. This overreliance on lexical matching may lead to a diminished\nlevel of model robustness against input variations. In this study, we\nthoroughly examine the robustness of current text-to-vis models, an area that\nhas not previously been explored. In particular, we construct the first\nrobustness dataset nvBench-Rob, which contains diverse lexical and phrasal\nvariations based on the original text-to-vis benchmark nvBench. Then, we found\nthat the performance of existing text-to-vis models on this new dataset\ndramatically drops, implying that these methods exhibit inadequate robustness\noverall. Finally, we propose a novel framework based on Retrieval-Augmented\nGeneration (RAG) technique, named GRED, specifically designed to address input\nperturbations in these two variants. The framework consists of three parts:\nNLQ-Retrieval Generator, Visualization Query-Retrieval Retuner and\nAnnotation-based Debugger, which are used to tackle the challenges posed by\nnatural language variants, programming style differences and data schema\nvariants, respectively. Extensive experimental evaluations show that, compared\nto the state-of-the-art model RGVisNet in the Text-to-Vis field, GRED performs\nbetter in terms of model robustness, with a 32% increase in accuracy on the\nproposed nvBench-Rob dataset.", "published": "2024-04-10 16:12:50", "link": "http://arxiv.org/abs/2404.07135v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lossless Acceleration of Large Language Model via Adaptive N-gram\n  Parallel Decoding", "abstract": "While Large Language Models (LLMs) have shown remarkable abilities, they are\nhindered by significant resource consumption and considerable latency due to\nautoregressive processing. In this study, we introduce Adaptive N-gram Parallel\nDecoding (ANPD), an innovative and lossless approach that accelerates inference\nby allowing the simultaneous generation of multiple tokens. ANPD incorporates a\ntwo-stage approach: it begins with a rapid drafting phase that employs an\nN-gram module, which adapts based on the current interactive context, followed\nby a verification phase, during which the original LLM assesses and confirms\nthe proposed tokens. Consequently, ANPD preserves the integrity of the LLM's\noriginal output while enhancing processing speed. We further leverage a\nmulti-level architecture for the N-gram module to enhance the precision of the\ninitial draft, consequently reducing inference latency. ANPD eliminates the\nneed for retraining or extra GPU memory, making it an efficient and\nplug-and-play enhancement. In our experiments, models such as LLaMA and its\nfine-tuned variants have shown speed improvements up to 3.67x, validating the\neffectiveness of our proposed ANPD.", "published": "2024-04-10 16:11:09", "link": "http://arxiv.org/abs/2404.08698v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs", "abstract": "LLMs acquire knowledge from massive data snapshots collected at different\ntimestamps. Their knowledge is then commonly evaluated using static benchmarks.\nHowever, factual knowledge is generally subject to time-sensitive changes, and\nstatic benchmarks cannot address those cases. We present an approach to\ndynamically evaluate the knowledge in LLMs and their time-sensitiveness against\nWikidata, a publicly available up-to-date knowledge graph. We evaluate the\ntime-sensitive knowledge in twenty-four private and open-source LLMs, as well\nas the effectiveness of four editing methods in updating the outdated facts.\nOur results show that 1) outdatedness is a critical problem across\nstate-of-the-art LLMs; 2) LLMs output inconsistent answers when prompted with\nslight variations of the question prompt; and 3) the performance of the\nstate-of-the-art knowledge editing algorithms is very limited, as they can not\nreduce the cases of outdatedness and output inconsistency.", "published": "2024-04-10 18:08:59", "link": "http://arxiv.org/abs/2404.08700v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CulturalTeaming: AI-Assisted Interactive Red-Teaming for Challenging\n  LLMs' (Lack of) Multicultural Knowledge", "abstract": "Frontier large language models (LLMs) are developed by researchers and\npractitioners with skewed cultural backgrounds and on datasets with skewed\nsources. However, LLMs' (lack of) multicultural knowledge cannot be effectively\nassessed with current methods for developing benchmarks. Existing multicultural\nevaluations primarily rely on expensive and restricted human annotations or\npotentially outdated internet resources. Thus, they struggle to capture the\nintricacy, dynamics, and diversity of cultural norms. LLM-generated benchmarks\nare promising, yet risk propagating the same biases they are meant to measure.\nTo synergize the creativity and expert cultural knowledge of human annotators\nand the scalability and standardizability of LLM-based automation, we introduce\nCulturalTeaming, an interactive red-teaming system that leverages human-AI\ncollaboration to build truly challenging evaluation dataset for assessing the\nmulticultural knowledge of LLMs, while improving annotators' capabilities and\nexperiences. Our study reveals that CulturalTeaming's various modes of AI\nassistance support annotators in creating cultural questions, that modern LLMs\nfail at, in a gamified manner. Importantly, the increased level of AI\nassistance (e.g., LLM-generated revision hints) empowers users to create more\ndifficult questions with enhanced perceived creativity of themselves, shedding\nlight on the promises of involving heavier AI assistance in modern evaluation\ndataset creation procedures. Through a series of 1-hour workshop sessions, we\ngather CULTURALBENCH-V0.1, a compact yet high-quality evaluation dataset with\nusers' red-teaming attempts, that different families of modern LLMs perform\nwith accuracy ranging from 37.7% to 72.2%, revealing a notable gap in LLMs'\nmulticultural proficiency.", "published": "2024-04-10 00:25:09", "link": "http://arxiv.org/abs/2404.06664v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "SafeGen: Mitigating Sexually Explicit Content Generation in\n  Text-to-Image Models", "abstract": "Text-to-image (T2I) models, such as Stable Diffusion, have exhibited\nremarkable performance in generating high-quality images from text descriptions\nin recent years. However, text-to-image models may be tricked into generating\nnot-safe-for-work (NSFW) content, particularly in sexually explicit scenarios.\nExisting countermeasures mostly focus on filtering inappropriate inputs and\noutputs, or suppressing improper text embeddings, which can block sexually\nexplicit content (e.g., naked) but may still be vulnerable to adversarial\nprompts -- inputs that appear innocent but are ill-intended. In this paper, we\npresent SafeGen, a framework to mitigate sexual content generation by\ntext-to-image models in a text-agnostic manner. The key idea is to eliminate\nexplicit visual representations from the model regardless of the text input. In\nthis way, the text-to-image model is resistant to adversarial prompts since\nsuch unsafe visual representations are obstructed from within. Extensive\nexperiments conducted on four datasets and large-scale user studies demonstrate\nSafeGen's effectiveness in mitigating sexually explicit content generation\nwhile preserving the high-fidelity of benign images. SafeGen outperforms eight\nstate-of-the-art baseline methods and achieves 99.4% sexual content removal\nperformance. Furthermore, our constructed benchmark of adversarial prompts\nprovides a basis for future development and evaluation of anti-NSFW-generation\nmethods.", "published": "2024-04-10 00:26:08", "link": "http://arxiv.org/abs/2404.06666v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness", "abstract": "Recent advancements in Natural Language Processing (NLP) have seen\nLarge-scale Language Models (LLMs) excel at producing high-quality text for\nvarious purposes. Notably, in Text-To-Speech (TTS) systems, the integration of\nBERT for semantic token generation has underscored the importance of semantic\ncontent in producing coherent speech outputs. Despite this, the specific\nutility of LLMs in enhancing TTS synthesis remains considerably limited. This\nresearch introduces an innovative approach, Llama-VITS, which enhances TTS\nsynthesis by enriching the semantic content of text using LLM. Llama-VITS\nintegrates semantic embeddings from Llama2 with the VITS model, a leading\nend-to-end TTS framework. By leveraging Llama2 for the primary speech synthesis\nprocess, our experiments demonstrate that Llama-VITS matches the naturalness of\nthe original VITS (ORI-VITS) and those incorporate BERT (BERT-VITS), on the\nLJSpeech dataset, a substantial collection of neutral, clear speech. Moreover,\nour method significantly enhances emotive expressiveness on the EmoV_DB_bea_sem\ndataset, a curated selection of emotionally consistent speech from the EmoV_DB\ndataset, highlighting its potential to generate emotive speech.", "published": "2024-04-10 03:46:03", "link": "http://arxiv.org/abs/2404.06714v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Language Generation in the Limit", "abstract": "Although current large language models are complex, the most basic\nspecifications of the underlying language generation problem itself are simple\nto state: given a finite set of training samples from an unknown language,\nproduce valid new strings from the language that don't already appear in the\ntraining data. Here we ask what we can conclude about language generation using\nonly this specification, without further assumptions. In particular, suppose\nthat an adversary enumerates the strings of an unknown target language L that\nis known only to come from one of a possibly infinite list of candidates. A\ncomputational agent is trying to learn to generate from this language; we say\nthat the agent generates from L in the limit if after some finite point in the\nenumeration of L, the agent is able to produce new elements that come\nexclusively from L and that have not yet been presented by the adversary. Our\nmain result is that there is an agent that is able to generate in the limit for\nevery countable list of candidate languages. This contrasts dramatically with\nnegative results due to Gold and Angluin in a well-studied model of language\nlearning where the goal is to identify an unknown language from samples; the\ndifference between these results suggests that identifying a language is a\nfundamentally different problem than generating from it.", "published": "2024-04-10 05:53:25", "link": "http://arxiv.org/abs/2404.06757v1", "categories": ["cs.DS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Superposition Prompting: Improving and Accelerating Retrieval-Augmented\n  Generation", "abstract": "Despite the successes of large language models (LLMs), they exhibit\nsignificant drawbacks, particularly when processing long contexts. Their\ninference cost scales quadratically with respect to sequence length, making it\nexpensive for deployment in some real-world text processing applications, such\nas retrieval-augmented generation (RAG). Additionally, LLMs also exhibit the\n\"distraction phenomenon\", where irrelevant context in the prompt degrades\noutput quality. To address these drawbacks, we propose a novel RAG prompting\nmethodology, *superposition prompting*, which can be directly applied to\npre-trained transformer-based LLMs *without the need for fine-tuning*. At a\nhigh level, superposition prompting allows the LLM to process input documents\nin parallel *prompt paths*, discarding paths once they are deemed irrelevant.\nWe demonstrate the capability of our method to simultaneously enhance time\nefficiency across a variety of question-answering benchmarks using multiple\npre-trained LLMs. Furthermore, our technique significantly improves accuracy\nwhen the retrieved context is large relative the context the model was trained\non. For example, our approach facilitates a 93x reduction in compute time while\n*improving* accuracy by 43% on the NaturalQuestions-Open dataset with the\nMPT-7B instruction-tuned model over naive RAG.", "published": "2024-04-10 11:03:17", "link": "http://arxiv.org/abs/2404.06910v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "WordDecipher: Enhancing Digital Workspace Communication with Explainable\n  AI for Non-native English Speakers", "abstract": "Non-native English speakers (NNES) face challenges in digital workspace\ncommunication (e.g., emails, Slack messages), often inadvertently translating\nexpressions from their native languages, which can lead to awkward or incorrect\nusage. Current AI-assisted writing tools are equipped with fluency enhancement\nand rewriting suggestions; however, NNES may struggle to grasp the subtleties\namong various expressions, making it challenging to choose the one that\naccurately reflects their intent. Such challenges are exacerbated in high-stake\ntext-based communications, where the absence of non-verbal cues heightens the\nrisk of misinterpretation. By leveraging the latest advancements in large\nlanguage models (LLM) and word embeddings, we propose WordDecipher, an\nexplainable AI-assisted writing tool to enhance digital workspace communication\nfor NNES. WordDecipher not only identifies the perceived social intentions\ndetected in users' writing, but also generates rewriting suggestions aligned\nwith users' intended messages, either numerically or by inferring from users'\nwriting in their native language. Then, WordDecipher provides an overview of\nnuances to help NNES make selections. Through a usage scenario, we demonstrate\nhow WordDecipher can significantly enhance an NNES's ability to communicate her\nrequest, showcasing its potential to transform workspace communication for\nNNES.", "published": "2024-04-10 13:40:29", "link": "http://arxiv.org/abs/2404.07005v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "A Mathematical Theory for Learning Semantic Languages by Abstract\n  Learners", "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated the\nemergence of capabilities (learned skills) when the number of system parameters\nand the size of training data surpass certain thresholds. The exact mechanisms\nbehind such phenomena are not fully understood and remain a topic of active\nresearch. Inspired by the skill-text bipartite graph model proposed by Arora\nand Goyal for modeling semantic languages, we develop a mathematical theory to\nexplain the emergence of learned skills, taking the learning (or training)\nprocess into account. Our approach models the learning process for skills in\nthe skill-text bipartite graph as an iterative decoding process in Low-Density\nParity Check (LDPC) codes and Irregular Repetition Slotted ALOHA (IRSA). Using\ndensity evolution analysis, we demonstrate the emergence of learned skills when\nthe ratio of the number of training texts to the number of skills exceeds a\ncertain threshold. Our analysis also yields a scaling law for testing errors\nrelative to this ratio. Upon completion of the training, the association of\nlearned skills can also be acquired to form a skill association graph. We use\nsite percolation analysis to derive the conditions for the existence of a giant\ncomponent in the skill association graph. Our analysis can also be extended to\nthe setting with a hierarchy of skills, where a fine-tuned model is built upon\na foundation model. It is also applicable to the setting with multiple classes\nof skills and texts. As an important application, we propose a method for\nsemantic compression and discuss its connections to semantic communication.", "published": "2024-04-10 13:50:46", "link": "http://arxiv.org/abs/2404.07009v3", "categories": ["cs.CL", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.CL"}
{"title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and\n  Interpretation", "abstract": "Metaphors, although occasionally unperceived, are ubiquitous in our everyday\nlanguage. Thus, it is crucial for Language Models to be able to grasp the\nunderlying meaning of this kind of figurative language. In this work, we\npresent Meta4XNLI, a novel parallel dataset for the tasks of metaphor detection\nand interpretation that contains metaphor annotations in both Spanish and\nEnglish. We investigate language models' metaphor identification and\nunderstanding abilities through a series of monolingual and cross-lingual\nexperiments by leveraging our proposed corpus. In order to comprehend how these\nnon-literal expressions affect models' performance, we look over the results\nand perform an error analysis. Additionally, parallel data offers many\npotential opportunities to investigate metaphor transferability between these\nlanguages and the impact of translation on the development of multilingual\nannotated resources.", "published": "2024-04-10 14:44:48", "link": "http://arxiv.org/abs/2404.07053v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Concept Depth: How Large Language Models Acquire Knowledge and\n  Concept at Different Layers?", "abstract": "Large language models (LLMs) have shown remarkable performances across a wide\nrange of tasks. However, the mechanisms by which these models encode tasks of\nvarying complexities remain poorly understood. In this paper, we explore the\nhypothesis that LLMs process concepts of varying complexities in different\nlayers, introducing the idea of \"Concept Depth\" to suggest that more complex\nconcepts are typically acquired in deeper layers. Specifically, we categorize\nconcepts based on their level of abstraction, defining them in the order of\nincreasing complexity within factual, emotional, and inferential tasks. We\nconduct extensive probing experiments using layer-wise representations across\nvarious LLM families (Gemma, LLaMA, Qwen) on various datasets spanning the\nthree domains of tasks. Our findings reveal that models could efficiently\nconduct probing for simpler tasks in shallow layers, and more complex tasks\ntypically necessitate deeper layers for accurate understanding. Additionally,\nwe examine how external factors, such as adding noise to the input and\nquantizing the model weights, might affect layer-wise representations. Our\nfindings suggest that these factors can impede the development of a conceptual\nunderstanding of LLMs until deeper layers are explored. We hope that our\nproposed concept and experimental insights will enhance the understanding of\nthe mechanisms underlying LLMs. Our codes are available at\nhttps://github.com/Luckfort/CD.", "published": "2024-04-10 14:56:40", "link": "http://arxiv.org/abs/2404.07066v7", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on\n  Graphs", "abstract": "Large language models (LLMs), while exhibiting exceptional performance,\nsuffer from hallucinations, especially on knowledge-intensive tasks. Existing\nworks propose to augment LLMs with individual text units retrieved from\nexternal knowledge corpora to alleviate the issue. However, in many domains,\ntexts are interconnected (e.g., academic papers in a bibliographic graph are\nlinked by citations and co-authorships) which form a (text-attributed) graph.\nThe knowledge in such graphs is encoded not only in single texts/nodes but also\nin their associated connections. To facilitate the research of augmenting LLMs\nwith graphs, we manually construct a Graph Reasoning Benchmark dataset called\nGRBench, containing 1,740 questions that can be answered with the knowledge\nfrom 10 domain graphs. Then, we propose a simple and effective framework called\nGraph Chain-of-thought (Graph-CoT) to augment LLMs with graphs by encouraging\nLLMs to reason on the graph iteratively. Each Graph-CoT iteration consists of\nthree sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. We\nconduct systematic experiments with three LLM backbones on GRBench, where\nGraph-CoT outperforms the baselines consistently. The code is available at\nhttps://github.com/PeterGriffinJin/Graph-CoT.", "published": "2024-04-10 15:41:53", "link": "http://arxiv.org/abs/2404.07103v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leave No Context Behind: Efficient Infinite Context Transformers with\n  Infini-attention", "abstract": "This work introduces an efficient method to scale Transformer-based Large\nLanguage Models (LLMs) to infinitely long inputs with bounded memory and\ncomputation. A key component in our proposed approach is a new attention\ntechnique dubbed Infini-attention. The Infini-attention incorporates a\ncompressive memory into the vanilla attention mechanism and builds in both\nmasked local attention and long-term linear attention mechanisms in a single\nTransformer block. We demonstrate the effectiveness of our approach on\nlong-context language modeling benchmarks, 1M sequence length passkey context\nblock retrieval and 500K length book summarization tasks with 1B and 8B LLMs.\nOur approach introduces minimal bounded memory parameters and enables fast\nstreaming inference for LLMs.", "published": "2024-04-10 16:18:42", "link": "http://arxiv.org/abs/2404.07143v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "UMBRAE: Unified Multimodal Brain Decoding", "abstract": "We address prevailing challenges of the brain-powered research, departing\nfrom the observation that the literature hardly recover accurate spatial\ninformation and require subject-specific models. To address these challenges,\nwe propose UMBRAE, a unified multimodal decoding of brain signals. First, to\nextract instance-level conceptual and spatial details from neural signals, we\nintroduce an efficient universal brain encoder for multimodal-brain alignment\nand recover object descriptions at multiple levels of granularity from\nsubsequent multimodal large language model (MLLM). Second, we introduce a\ncross-subject training strategy mapping subject-specific features to a common\nfeature space. This allows a model to be trained on multiple subjects without\nextra resources, even yielding superior results compared to subject-specific\nmodels. Further, we demonstrate this supports weakly-supervised adaptation to\nnew subjects, with only a fraction of the total training data. Experiments\ndemonstrate that UMBRAE not only achieves superior results in the newly\nintroduced tasks but also outperforms methods in well established tasks. To\nassess our method, we construct and share with the community a comprehensive\nbrain understanding benchmark BrainHub. Our code and benchmark are available at\nhttps://weihaox.github.io/UMBRAE.", "published": "2024-04-10 17:59:20", "link": "http://arxiv.org/abs/2404.07202v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Conformer-1: Robust ASR via Large-Scale Semisupervised Bootstrapping", "abstract": "This paper presents Conformer-1, an end-to-end Automatic Speech Recognition\n(ASR) model trained on an extensive dataset of 570k hours of speech audio data,\n91% of which was acquired from publicly available sources. To achieve this, we\nperform Noisy Student Training after generating pseudo-labels for the unlabeled\npublic data using a strong Conformer RNN-T baseline model. The addition of\nthese pseudo-labeled data results in remarkable improvements in relative Word\nError Rate (WER) by 11.5% and 24.3% for our asynchronous and realtime models,\nrespectively. Additionally, the model is more robust to background noise owing\nto the addition of these data. The results obtained in this study demonstrate\nthat the incorporation of pseudo-labeled publicly available data is a highly\neffective strategy for improving ASR accuracy and noise robustness.", "published": "2024-04-10 20:40:24", "link": "http://arxiv.org/abs/2404.07341v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sample-Efficient Human Evaluation of Large Language Models via Maximum\n  Discrepancy Competition", "abstract": "The past years have witnessed a proliferation of large language models\n(LLMs). Yet, automated and unbiased evaluation of LLMs is challenging due to\nthe inaccuracy of standard metrics in reflecting human preferences and the\ninefficiency in sampling informative and diverse test examples. While human\nevaluation remains the gold standard, it is expensive and time-consuming,\nespecially when dealing with a large number of testing samples. To address this\nproblem, we propose a sample-efficient human evaluation method based on MAximum\nDiscrepancy (MAD) competition. MAD automatically selects a small set of\ninformative and diverse instructions, each adapted to two LLMs, whose responses\nare subject to three-alternative forced choice by human subjects. The pairwise\ncomparison results are then aggregated into a global ranking using the Elo\nrating system. We select eight representative LLMs and compare them in terms of\nfour skills: knowledge understanding, mathematical reasoning, writing, and\ncoding. Experimental results show that the proposed method achieves a reliable\nand sensible ranking of LLMs' capabilities, identifies their relative strengths\nand weaknesses, and offers valuable insights for further LLM advancement.", "published": "2024-04-10 01:26:24", "link": "http://arxiv.org/abs/2404.08008v1", "categories": ["cs.LG", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Analyzing the Performance of Large Language Models on Code Summarization", "abstract": "Large language models (LLMs) such as Llama 2 perform very well on tasks that\ninvolve both natural language and source code, particularly code summarization\nand code generation. We show that for the task of code summarization, the\nperformance of these models on individual examples often depends on the amount\nof (subword) token overlap between the code and the corresponding reference\nnatural language descriptions in the dataset. This token overlap arises because\nthe reference descriptions in standard datasets (corresponding to docstrings in\nlarge code bases) are often highly similar to the names of the functions they\ndescribe. We also show that this token overlap occurs largely in the function\nnames of the code and compare the relative performance of these models after\nremoving function names versus removing code structure. We also show that using\nmultiple evaluation metrics like BLEU and BERTScore gives us very little\nadditional insight since these metrics are highly correlated with each other.", "published": "2024-04-10 22:42:18", "link": "http://arxiv.org/abs/2404.08018v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Apollonion: Profile-centric Dialog Agent", "abstract": "The emergence of Large Language Models (LLMs) has innovated the development\nof dialog agents. Specially, a well-trained LLM, as a central process unit, is\ncapable of providing fluent and reasonable response for user's request.\nBesides, auxiliary tools such as external knowledge retrieval, personalized\ncharacter for vivid response, short/long-term memory for ultra long context\nmanagement are developed, completing the usage experience for LLM-based dialog\nagents. However, the above-mentioned techniques does not solve the issue of\n\\textbf{personalization from user perspective}: agents response in a same\nfashion to different users, without consideration of their features, such as\nhabits, interests and past experience. In another words, current implementation\nof dialog agents fail in ``knowing the user''. The capacity of well-description\nand representation of user is under development. In this work, we proposed a\nframework for dialog agent to incorporate user profiling (initialization,\nupdate): user's query and response is analyzed and organized into a structural\nuser profile, which is latter served to provide personal and more precise\nresponse. Besides, we proposed a series of evaluation protocols for\npersonalization: to what extend the response is personal to the different\nusers.\n  The framework is named as \\method{}, inspired by inscription of ``Know\nYourself'' in the temple of Apollo (also known as \\method{}) in Ancient Greek.\nFew works have been conducted on incorporating personalization into LLM,\n\\method{} is a pioneer work on guiding LLM's response to meet individuation via\nthe application of dialog agents, with a set of evaluation methods for\nmeasurement in personalization.", "published": "2024-04-10 03:32:41", "link": "http://arxiv.org/abs/2404.08692v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Enhancing Question Answering for Enterprise Knowledge Bases using Large\n  Language Models", "abstract": "Efficient knowledge management plays a pivotal role in augmenting both the\noperational efficiency and the innovative capacity of businesses and\norganizations. By indexing knowledge through vectorization, a variety of\nknowledge retrieval methods have emerged, significantly enhancing the efficacy\nof knowledge management systems. Recently, the rapid advancements in generative\nnatural language processing technologies paved the way for generating precise\nand coherent answers after retrieving relevant documents tailored to user\nqueries. However, for enterprise knowledge bases, assembling extensive training\ndata from scratch for knowledge retrieval and generation is a formidable\nchallenge due to the privacy and security policies of private data, frequently\nentailing substantial costs. To address the challenge above, in this paper, we\npropose EKRG, a novel Retrieval-Generation framework based on large language\nmodels (LLMs), expertly designed to enable question-answering for Enterprise\nKnowledge bases with limited annotation costs. Specifically, for the retrieval\nprocess, we first introduce an instruction-tuning method using an LLM to\ngenerate sufficient document-question pairs for training a knowledge retriever.\nThis method, through carefully designed instructions, efficiently generates\ndiverse questions for enterprise knowledge bases, encompassing both\nfact-oriented and solution-oriented knowledge. Additionally, we develop a\nrelevance-aware teacher-student learning strategy to further enhance the\nefficiency of the training process. For the generation process, we propose a\nnovel chain of thought (CoT) based fine-tuning method to empower the LLM-based\ngenerator to adeptly respond to user questions using retrieved documents.\nFinally, extensive experiments on real-world datasets have demonstrated the\neffectiveness of our proposed framework.", "published": "2024-04-10 10:38:17", "link": "http://arxiv.org/abs/2404.08695v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "PoliTune: Analyzing the Impact of Data Selection and Fine-Tuning on\n  Economic and Political Biases in Large Language Models", "abstract": "In an era where language models are increasingly integrated into\ndecision-making and communication, understanding the biases within Large\nLanguage Models (LLMs) becomes imperative, especially when these models are\napplied in the economic and political domains. This work investigates the\nimpact of fine-tuning and data selection on economic and political biases in\nLLMs. In this context, we introduce PoliTune, a fine-tuning methodology to\nexplore the systematic aspects of aligning LLMs with specific ideologies,\nmindful of the biases that arise from their extensive training on diverse\ndatasets. Distinct from earlier efforts that either focus on smaller models or\nentail resource-intensive pre-training, PoliTune employs Parameter-Efficient\nFine-Tuning (PEFT) techniques, which allow for the alignment of LLMs with\ntargeted ideologies by modifying a small subset of parameters. We introduce a\nsystematic method for using the open-source LLM Llama3-70B for dataset\nselection, annotation, and synthesizing a preferences dataset for Direct\nPreference Optimization (DPO) to align the model with a given political\nideology. We assess the effectiveness of PoliTune through both quantitative and\nqualitative evaluations of aligning open-source LLMs (Llama3-8B and Mistral-7B)\nto different ideologies. Our work analyzes the potential of embedding specific\nbiases into LLMs and contributes to the dialogue on the ethical application of\nAI, highlighting the importance of deploying AI in a manner that aligns with\nsocietal values.", "published": "2024-04-10 16:30:09", "link": "http://arxiv.org/abs/2404.08699v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoVoMix: Advancing Zero-Shot Speech Generation for Human-like\n  Multi-talker Conversations", "abstract": "Recent advancements in zero-shot text-to-speech (TTS) modeling have led to\nsignificant strides in generating high-fidelity and diverse speech. However,\ndialogue generation, along with achieving human-like naturalness in speech,\ncontinues to be a challenge. In this paper, we introduce CoVoMix:\nConversational Voice Mixture Generation, a novel model for zero-shot,\nhuman-like, multi-speaker, multi-round dialogue speech generation. CoVoMix\nfirst converts dialogue text into multiple streams of discrete tokens, with\neach token stream representing semantic information for individual talkers.\nThese token streams are then fed into a flow-matching based acoustic model to\ngenerate mixed mel-spectrograms. Finally, the speech waveforms are produced\nusing a HiFi-GAN model. Furthermore, we devise a comprehensive set of metrics\nfor measuring the effectiveness of dialogue modeling and generation. Our\nexperimental results show that CoVoMix can generate dialogues that are not only\nhuman-like in their naturalness and coherence but also involve multiple talkers\nengaging in multiple rounds of conversation. This is exemplified by instances\ngenerated in a single channel where one speaker's utterance is seamlessly mixed\nwith another's interjections or laughter, indicating the latter's role as an\nattentive listener. Audio samples are available at https://aka.ms/covomix.", "published": "2024-04-10 02:32:58", "link": "http://arxiv.org/abs/2404.06690v3", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Generative Sampling in the Dual Divergence Space: A Data-efficient\n  & Interpretative Approach for Generative AI", "abstract": "Building on the remarkable achievements in generative sampling of natural\nimages, we propose an innovative challenge, potentially overly ambitious, which\ninvolves generating samples of entire multivariate time series that resemble\nimages. However, the statistical challenge lies in the small sample size,\nsometimes consisting of a few hundred subjects. This issue is especially\nproblematic for deep generative models that follow the conventional approach of\ngenerating samples from a canonical distribution and then decoding or denoising\nthem to match the true data distribution. In contrast, our method is grounded\nin information theory and aims to implicitly characterize the distribution of\nimages, particularly the (global and local) dependency structure between\npixels. We achieve this by empirically estimating its KL-divergence in the dual\nform with respect to the respective marginal distribution. This enables us to\nperform generative sampling directly in the optimized 1-D dual divergence\nspace. Specifically, in the dual space, training samples representing the data\ndistribution are embedded in the form of various clusters between two end\npoints. In theory, any sample embedded between those two end points is\nin-distribution w.r.t. the data distribution. Our key idea for generating novel\nsamples of images is to interpolate between the clusters via a walk as per\ngradients of the dual function w.r.t. the data dimensions. In addition to the\ndata efficiency gained from direct sampling, we propose an algorithm that\noffers a significant reduction in sample complexity for estimating the\ndivergence of the data distribution with respect to the marginal distribution.\nWe provide strong theoretical guarantees along with an extensive empirical\nevaluation using many real-world datasets from diverse domains, establishing\nthe superiority of our approach w.r.t. state-of-the-art deep learning methods.", "published": "2024-04-10 22:35:06", "link": "http://arxiv.org/abs/2404.07377v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Learning Multidimensional Disentangled Representations of Instrumental\n  Sounds for Musical Similarity Assessment", "abstract": "To achieve a flexible recommendation and retrieval system, it is desirable to\ncalculate music similarity by focusing on multiple partial elements of musical\npieces and allowing the users to select the element they want to focus on. A\nprevious study proposed using multiple individual networks for calculating\nmusic similarity based on each instrumental sound, but it is impractical to use\neach signal as a query in search systems. Using separated instrumental sounds\nalternatively resulted in less accuracy due to artifacts. In this paper, we\npropose a method to compute similarities focusing on each instrumental sound\nwith a single network that takes mixed sounds as input instead of individual\ninstrumental sounds. Specifically, we design a single similarity embedding\nspace with disentangled dimensions for each instrument, extracted by\nConditional Similarity Networks, which is trained by the triplet loss using\nmasks. Experimental results have shown that (1) the proposed method can obtain\nmore accurate feature representation than using individual networks using\nseparated sounds as input, (2) each sub-embedding space can hold the\ncharacteristics of the corresponding instrument, and (3) the selection of\nsimilar musical pieces focusing on each instrumental sound by the proposed\nmethod can obtain human consent, especially in drums and guitar.", "published": "2024-04-10 02:02:51", "link": "http://arxiv.org/abs/2404.06682v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Efficient Sound Field Reconstruction with Conditional Invertible Neural\n  Networks", "abstract": "In this study, we introduce a method for estimating sound fields in\nreverberant environments using a conditional invertible neural network (CINN).\nSound field reconstruction can be hindered by experimental errors, limited\nspatial data, model mismatches, and long inference times, leading to\npotentially flawed and prolonged characterizations. Further, the complexity of\nmanaging inherent uncertainties often escalates computational demands or is\nneglected in models. Our approach seeks to balance accuracy and computational\nefficiency, while incorporating uncertainty estimates to tailor reconstructions\nto specific needs. By training a CINN with Monte Carlo simulations of random\nwave fields, our method reduces the dependency on extensive datasets and\nenables inference from sparse experimental data. The CINN proves versatile at\nreconstructing Room Impulse Responses (RIRs), by acting either as a likelihood\nmodel for maximum a posteriori estimation or as an approximate posterior\ndistribution through amortized Bayesian inference. Compared to traditional\nBayesian methods, the CINN achieves similar accuracy with greater efficiency\nand without requiring its adaptation to distinct sound field conditions.", "published": "2024-04-10 11:27:06", "link": "http://arxiv.org/abs/2404.06928v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "VoiceShop: A Unified Speech-to-Speech Framework for Identity-Preserving\n  Zero-Shot Voice Editing", "abstract": "We present VoiceShop, a novel speech-to-speech framework that can modify\nmultiple attributes of speech, such as age, gender, accent, and speech style,\nin a single forward pass while preserving the input speaker's timbre. Previous\nworks have been constrained to specialized models that can only edit these\nattributes individually and suffer from the following pitfalls: the magnitude\nof the conversion effect is weak, there is no zero-shot capability for\nout-of-distribution speakers, or the synthesized outputs exhibit undesirable\ntimbre leakage. Our work proposes solutions for each of these issues in a\nsimple modular framework based on a conditional diffusion backbone model with\noptional normalizing flow-based and sequence-to-sequence speaker\nattribute-editing modules, whose components can be combined or removed during\ninference to meet a wide array of tasks without additional model finetuning.\nAudio samples are available at \\url{https://voiceshopai.github.io}.", "published": "2024-04-10 01:33:08", "link": "http://arxiv.org/abs/2404.06674v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "What is Learnt by the LEArnable Front-end (LEAF)? Adapting Per-Channel\n  Energy Normalisation (PCEN) to Noisy Conditions", "abstract": "There is increasing interest in the use of the LEArnable Front-end (LEAF) in\na variety of speech processing systems. However, there is a dearth of analyses\nof what is actually learnt and the relative importance of training the\ndifferent components of the front-end. In this paper, we investigate this\nquestion on keyword spotting, speech-based emotion recognition and language\nidentification tasks and find that the filters for spectral decomposition and\nthe low pass filter used to estimate spectral energy variations exhibit no\nlearning and the per-channel energy normalisation (PCEN) is the key component\nthat is learnt. Following this, we explore the potential of adapting only the\nPCEN layer with a small amount of noisy data to enable it to learn appropriate\ndynamic range compression that better suits the noise conditions. This in turn\nenables a system trained on clean speech to work more accurately on noisy test\ndata as demonstrated by the experimental results reported in this paper.", "published": "2024-04-10 03:19:03", "link": "http://arxiv.org/abs/2404.06702v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Towards Efficient and Real-Time Piano Transcription Using Neural\n  Autoregressive Models", "abstract": "In recent years, advancements in neural network designs and the availability\nof large-scale labeled datasets have led to significant improvements in the\naccuracy of piano transcription models. However, most previous work focused on\nhigh-performance offline transcription, neglecting deliberate consideration of\nmodel size. The goal of this work is to implement real-time inference for piano\ntranscription while ensuring both high performance and lightweight. To this\nend, we propose novel architectures for convolutional recurrent neural\nnetworks, redesigning an existing autoregressive piano transcription model.\nFirst, we extend the acoustic module by adding a frequency-conditioned FiLM\nlayer to the CNN module to adapt the convolutional filters on the frequency\naxis. Second, we improve note-state sequence modeling by using a pitchwise LSTM\nthat focuses on note-state transitions within a note. In addition, we augment\nthe autoregressive connection with an enhanced recursive context. Using these\ncomponents, we propose two types of models; one for high performance and the\nother for high compactness. Through extensive experiments, we show that the\nproposed models are comparable to state-of-the-art models in terms of note\naccuracy on the MAESTRO dataset. We also investigate the effective model size\nand real-time inference latency by gradually streamlining the architecture.\nFinally, we conduct cross-data evaluation on unseen piano datasets and in-depth\nanalysis to elucidate the effect of the proposed components in the view of note\nlength and pitch range.", "published": "2024-04-10 08:06:15", "link": "http://arxiv.org/abs/2404.06818v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "PEAVS: Perceptual Evaluation of Audio-Visual Synchrony Grounded in\n  Viewers' Opinion Scores", "abstract": "Recent advancements in audio-visual generative modeling have been propelled\nby progress in deep learning and the availability of data-rich benchmarks.\nHowever, the growth is not attributed solely to models and benchmarks.\nUniversally accepted evaluation metrics also play an important role in\nadvancing the field. While there are many metrics available to evaluate audio\nand visual content separately, there is a lack of metrics that offer a\nquantitative and interpretable measure of audio-visual synchronization for\nvideos \"in the wild\". To address this gap, we first created a large scale human\nannotated dataset (100+ hrs) representing nine types of synchronization errors\nin audio-visual content and how human perceive them. We then developed a PEAVS\n(Perceptual Evaluation of Audio-Visual Synchrony) score, a novel automatic\nmetric with a 5-point scale that evaluates the quality of audio-visual\nsynchronization. We validate PEAVS using a newly generated dataset, achieving a\nPearson correlation of 0.79 at the set level and 0.54 at the clip level when\ncompared to human labels. In our experiments, we observe a relative gain 50%\nover a natural extension of Fr\\'echet based metrics for Audio-Visual synchrony,\nconfirming PEAVS efficacy in objectively modeling subjective perceptions of\naudio-visual synchronization for videos \"in the wild\".", "published": "2024-04-10 20:32:24", "link": "http://arxiv.org/abs/2404.07336v1", "categories": ["cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Cochlear Wave Propagation and Dynamics in the Human Base and Apex:\n  Model-Based Estimates from Noninvasive Measurements", "abstract": "Cochlear wavenumber and impedance are mechanistic variables that encode\ninformation regarding how the cochlea works - specifically wave propagation and\nOrgan of Corti dynamics. These mechanistic variables underlie interesting\nfeatures of cochlear signal processing such as its place-based wavelet\nanalyzers, dispersivity and high-gain. Consequently, it is of interest to\nestimate these mechanistic variables in various species (particularly humans)\nand across various locations along the length of the cochlea. In this paper, we\ndevelop methods to estimate the mechanistic variables (wavenumber and\nimpedance) from noninvasive response characteristics (such as the quality\nfactors of psychophysical tuning curves) using an existing analytic shortwave\nsingle-partition model of the mammalian cochlea. We then apply these methods to\nestimate human mechanistic variables using reported values for quality factors\nfrom psychophysical tuning curves and a location-invariant ratio extrapolated\nfrom chinchilla. Our resultant estimates for human wavenumbers and impedances\nshow that the minimum wavelength (which occurs at the peak of the traveling\nwave) is smaller in base than the apex. The Organ of Corti is stiffness\ndominated rather than mass dominated, and there is negative effective damping\nprior to the peak followed by positive effective damping. The effective\nstiffness, and positive and negative effective damping are greater in the base\nthan the apex. The methods introduced here for estimating mechanistic variables\nfrom characteristics of invasive or noninvasive responses enable us to derive\nsuch estimates across various species and locations where the responses are\ndescribable by sharp filters. In addition to studying cochlear wave propagation\nand dynamics, the estimation methods developed here are also useful for\nauditory filter design.", "published": "2024-04-10 20:24:19", "link": "http://arxiv.org/abs/2407.00003v1", "categories": ["q-bio.QM", "cs.SD", "eess.AS", "q-bio.TO"], "primary_category": "q-bio.QM"}
