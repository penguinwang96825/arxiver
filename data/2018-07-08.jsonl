{"title": "A Deep Generative Model of Vowel Formant Typology", "abstract": "What makes some types of languages more probable than others? For instance,\nwe know that almost all spoken languages contain the vowel phoneme /i/; why\nshould that be? The field of linguistic typology seeks to answer these\nquestions and, thereby, divine the mechanisms that underlie human language. In\nour work, we tackle the problem of vowel system typology, i.e., we propose a\ngenerative probability model of which vowels a language contains. In contrast\nto previous work, we work directly with the acoustic information -- the first\ntwo formant values -- rather than modeling discrete sets of phonemic symbols\n(IPA). We develop a novel generative probability model and report results based\non a corpus of 233 languages.", "published": "2018-07-08 03:26:01", "link": "http://arxiv.org/abs/1807.02745v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Complexity and Typology of Inflectional Morphological Systems", "abstract": "We quantify the linguistic complexity of different languages' morphological\nsystems. We verify that there is an empirical trade-off between paradigm size\nand irregularity: a language's inflectional paradigms may be either large in\nsize or highly irregular, but never both. Our methodology measures paradigm\nirregularity as the entropy of the surface realization of a paradigm -- how\nhard it is to jointly predict all the surface forms of a paradigm. We estimate\nthis by a variational approximation. Our measurements are taken on large\nmorphological paradigms from 31 typologically diverse languages.", "published": "2018-07-08 03:32:45", "link": "http://arxiv.org/abs/1807.02747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Semantic Analysis Approach for Document Summarization Based on\n  Word Embeddings", "abstract": "Since the amount of information on the internet is growing rapidly, it is not\neasy for a user to find relevant information for his/her query. To tackle this\nissue, much attention has been paid to Automatic Document Summarization. The\nkey point in any successful document summarizer is a good document\nrepresentation. The traditional approaches based on word overlapping mostly\nfail to produce that kind of representation. Word embedding, distributed\nrepresentation of words, has shown an excellent performance that allows words\nto match on semantic level. Naively concatenating word embeddings makes the\ncommon word dominant which in turn diminish the representation quality. In this\npaper, we employ word embeddings to improve the weighting schemes for\ncalculating the input matrix of Latent Semantic Analysis method. Two\nembedding-based weighting schemes are proposed and then combined to calculate\nthe values of this matrix. The new weighting schemes are modified versions of\nthe augment weight and the entropy frequency. The new schemes combine the\nstrength of the traditional weighting schemes and word embedding. The proposed\napproach is experimentally evaluated on three well-known English datasets, DUC\n2002, DUC 2004 and Multilingual 2015 Single-document Summarization for English.\nThe proposed model performs comprehensively better compared to the\nstate-of-the-art methods, by at least 1% ROUGE points, leading to a conclusion\nthat it provides a better document representation and a better document summary\nas a result.", "published": "2018-07-08 03:39:37", "link": "http://arxiv.org/abs/1807.02748v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Video Captioning with Boundary-aware Hierarchical Language Decoding and\n  Joint Video Prediction", "abstract": "The explosion of video data on the internet requires effective and efficient\ntechnology to generate captions automatically for people who are not able to\nwatch the videos. Despite the great progress of video captioning research,\nparticularly on video feature encoding, the language decoder is still largely\nbased on the prevailing RNN decoder such as LSTM, which tends to prefer the\nfrequent word that aligns with the video. In this paper, we propose a\nboundary-aware hierarchical language decoder for video captioning, which\nconsists of a high-level GRU based language decoder, working as a global\n(caption-level) language model, and a low-level GRU based language decoder,\nworking as a local (phrase-level) language model. Most importantly, we\nintroduce a binary gate into the low-level GRU language decoder to detect the\nlanguage boundaries. Together with other advanced components including joint\nvideo prediction, shared soft attention, and boundary-aware video encoding, our\nintegrated video captioning framework can discover hierarchical language\ninformation and distinguish the subject and the object in a sentence, which are\nusually confusing during the language generation. Extensive experiments on two\nwidely-used video captioning datasets, MSR-Video-to-Text (MSR-VTT)\n\\cite{xu2016msr} and YouTube-to-Text (MSVD) \\cite{chen2011collecting} show that\nour method is highly competitive, compared with the state-of-the-art methods.", "published": "2018-07-08 08:49:34", "link": "http://arxiv.org/abs/1807.03658v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Replicated Siamese LSTM in Ticketing System for Similarity Learning and\n  Retrieval in Asymmetric Texts", "abstract": "The goal of our industrial ticketing system is to retrieve a relevant\nsolution for an input query, by matching with historical tickets stored in\nknowledge base. A query is comprised of subject and description, while a\nhistorical ticket consists of subject, description and solution. To retrieve a\nrelevant solution, we use textual similarity paradigm to learn similarity in\nthe query and historical tickets. The task is challenging due to significant\nterm mismatch in the query and ticket pairs of asymmetric lengths, where\nsubject is a short text but description and solution are multi-sentence texts.\nWe present a novel Replicated Siamese LSTM model to learn similarity in\nasymmetric text pairs, that gives 22% and 7% gain (Accuracy@10) for retrieval\ntask, respectively over unsupervised and supervised baselines. We also show\nthat the topic and distributed semantic features for short and long texts\nimproved both similarity learning and retrieval.", "published": "2018-07-08 17:33:43", "link": "http://arxiv.org/abs/1807.02854v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Densely Connected CNNs for Bird Audio Detection", "abstract": "Detecting bird sounds in audio recordings automatically, if accurate enough,\nis expected to be of great help to the research community working in bio- and\necoacoustics, interested in monitoring biodiversity based on audio field\nrecordings. To estimate how accurate the state-of-the-art machine learning\napproaches are, the Bird Audio Detection challenge involving large audio\ndatasets was recently organized. In this paper, experiments using several types\nof convolutional neural networks (i.e. standard CNNs, residual nets and densely\nconnected nets) are reported in the framework of this challenge. DenseNets were\nthe preferred solution since they were the best performing and most compact\nmodels, leading to a 88.22% area under the receiver operator curve score on the\ntest set of the challenge. Performance gains were obtained thank to data\naugmentation through time and frequency shifting, model parameter averaging\nduring training and ensemble methods using the geometric mean. On the contrary,\nthe attempts to enlarge the training dataset with samples of the test set with\nautomatic predictions used as pseudo-groundtruth labels consistently degraded\nperformance.", "published": "2018-07-08 08:16:33", "link": "http://arxiv.org/abs/1807.02776v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
