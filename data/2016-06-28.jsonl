{"title": "Recurrent Neural Networks for Dialogue State Tracking", "abstract": "This paper discusses models for dialogue state tracking using recurrent\nneural networks (RNN). We present experiments on the standard dialogue state\ntracking (DST) dataset, DSTC2. On the one hand, RNN models became the state of\nthe art models in DST, on the other hand, most state-of-the-art models are only\nturn-based and require dataset-specific preprocessing (e.g. DSTC2-specific) in\norder to achieve such results. We implemented two architectures which can be\nused in incremental settings and require almost no preprocessing. We compare\ntheir performance to the benchmarks on DSTC2 and discuss their properties. With\nonly trivial preprocessing, the performance of our models is close to the\nstate-of- the-art results.", "published": "2016-06-28 14:33:29", "link": "http://arxiv.org/abs/1606.08733v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generation and Pruning of Pronunciation Variants to Improve ASR Accuracy", "abstract": "Speech recognition, especially name recognition, is widely used in phone\nservices such as company directory dialers, stock quote providers or location\nfinders. It is usually challenging due to pronunciation variations. This paper\nproposes an efficient and robust data-driven technique which automatically\nlearns acceptable word pronunciations and updates the pronunciation dictionary\nto build a better lexicon without affecting recognition of other words similar\nto the target word. It generalizes well on datasets with various sizes, and\nreduces the error rate on a database with 13000+ human names by 42%, compared\nto a baseline with regular dictionaries already covering canonical\npronunciations of 97%+ words in names, plus a well-trained\nspelling-to-pronunciation (STP) engine.", "published": "2016-06-28 18:44:38", "link": "http://arxiv.org/abs/1606.08821v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Neural Language Models for Joint Representation of\n  Streaming Documents and their Content", "abstract": "We consider the problem of learning distributed representations for documents\nin data streams. The documents are represented as low-dimensional vectors and\nare jointly learned with distributed vector representations of word tokens\nusing a hierarchical framework with two embedded neural language models. In\nparticular, we exploit the context of documents in streams and use one of the\nlanguage models to model the document sequences, and the other to model word\nsequences within them. The models learn continuous vector representations for\nboth word tokens and documents such that semantically similar documents and\nwords are close in a common vector space. We discuss extensions to our model,\nwhich can be applied to personalized recommendation and social relationship\nmining by adding further user layers to the hierarchy, thus learning\nuser-specific vectors to represent individual preferences. We validated the\nlearned representations on a public movie rating data set from MovieLens, as\nwell as on a large-scale Yahoo News data comprising three months of user\nactivity logs collected on Yahoo servers. The results indicate that the\nproposed model can learn useful representations of both documents and word\ntokens, outperforming the current state-of-the-art by a large margin.", "published": "2016-06-28 13:32:08", "link": "http://arxiv.org/abs/1606.08689v1", "categories": ["cs.CL", "cs.IR", "I.2.7; I.5.4; I.7.m"], "primary_category": "cs.CL"}
{"title": "\"Show me the cup\": Reference with Continuous Representations", "abstract": "One of the most basic functions of language is to refer to objects in a\nshared scene. Modeling reference with continuous representations is challenging\nbecause it requires individuation, i.e., tracking and distinguishing an\narbitrary number of referents. We introduce a neural network model that, given\na definite description and a set of objects represented by natural images,\npoints to the intended object if the expression has a unique referent, or\nindicates a failure, if it does not. The model, directly trained on reference\nacts, is competitive with a pipeline manually engineered to perform the same\ntask, both when referents are purely visual, and when they are characterized by\na combination of visual and linguistic properties.", "published": "2016-06-28 16:31:50", "link": "http://arxiv.org/abs/1606.08777v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
