{"title": "Candidate Soups: Fusing Candidate Results Improves Translation Quality\n  for Non-Autoregressive Translation", "abstract": "Non-autoregressive translation (NAT) model achieves a much faster inference\nspeed than the autoregressive translation (AT) model because it can\nsimultaneously predict all tokens during inference. However, its translation\nquality suffers from degradation compared to AT. And existing NAT methods only\nfocus on improving the NAT model's performance but do not fully utilize it. In\nthis paper, we propose a simple but effective method called \"Candidate Soups,\"\nwhich can obtain high-quality translations while maintaining the inference\nspeed of NAT models. Unlike previous approaches that pick the individual result\nand discard the remainders, Candidate Soups (CDS) can fully use the valuable\ninformation in the different candidate translations through model uncertainty.\nExtensive experiments on two benchmarks (WMT'14 EN-DE and WMT'16 EN-RO)\ndemonstrate the effectiveness and generality of our proposed method, which can\nsignificantly improve the translation quality of various base models. More\nnotably, our best variant outperforms the AT model on three translation tasks\nwith 7.6 times speedup.", "published": "2023-01-27 02:39:42", "link": "http://arxiv.org/abs/2301.11503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Theme-driven Keyphrase Extraction to Analyze Social Media Discourse", "abstract": "Social media platforms are vital resources for sharing self-reported health\nexperiences, offering rich data on various health topics. Despite advancements\nin Natural Language Processing (NLP) enabling large-scale social media data\nanalysis, a gap remains in applying keyphrase extraction to health-related\ncontent. Keyphrase extraction is used to identify salient concepts in social\nmedia discourse without being constrained by predefined entity classes. This\npaper introduces a theme-driven keyphrase extraction framework tailored for\nsocial media, a pioneering approach designed to capture clinically relevant\nkeyphrases from user-generated health texts. Themes are defined as broad\ncategories determined by the objectives of the extraction task. We formulate\nthis novel task of theme-driven keyphrase extraction and demonstrate its\npotential for efficiently mining social media text for the use case of\ntreatment for opioid use disorder. This paper leverages qualitative and\nquantitative analysis to demonstrate the feasibility of extracting actionable\ninsights from social media data and efficiently extracting keyphrases using\nminimally supervised NLP models. Our contributions include the development of a\nnovel data collection and curation framework for theme-driven keyphrase\nextraction and the creation of MOUD-Keyphrase, the first dataset of its kind\ncomprising human-annotated keyphrases from a Reddit community. We also identify\nthe scope of minimally supervised NLP models to extract keyphrases from social\nmedia data efficiently. Lastly, we found that a large language model (ChatGPT)\noutperforms unsupervised keyphrase extraction models, and we evaluate its\nefficacy in this task.", "published": "2023-01-27 03:00:46", "link": "http://arxiv.org/abs/2301.11508v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Causality Extraction with Event Argument Correlations", "abstract": "Event Causality Identification (ECI), which aims to detect whether a\ncausality relation exists between two given textual events, is an important\ntask for event causality understanding. However, the ECI task ignores crucial\nevent structure and cause-effect causality component information, making it\nstruggle for downstream applications. In this paper, we explore a novel task,\nnamely Event Causality Extraction (ECE), aiming to extract the cause-effect\nevent causality pairs with their structured event information from plain texts.\nThe ECE task is more challenging since each event can contain multiple event\narguments, posing fine-grained correlations between events to decide the\ncauseeffect event pair. Hence, we propose a method with a dual grid tagging\nscheme to capture the intra- and inter-event argument correlations for ECE.\nFurther, we devise a event type-enhanced model architecture to realize the dual\ngrid tagging scheme. Experiments demonstrate the effectiveness of our method,\nand extensive analyses point out several future directions for ECE.", "published": "2023-01-27 09:48:31", "link": "http://arxiv.org/abs/2301.11621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Out-of-Distribution Robustness of Language Models with\n  Parameter-Efficient Transfer Learning", "abstract": "As the size of the pre-trained language model (PLM) continues to increase,\nnumerous parameter-efficient transfer learning methods have been proposed\nrecently to compensate for the tremendous cost of fine-tuning. Despite the\nimpressive results achieved by large pre-trained language models (PLMs) and\nvarious parameter-efficient transfer learning (PETL) methods on sundry\nbenchmarks, it remains unclear if they can handle inputs that have been\ndistributionally shifted effectively. In this study, we systematically explore\nhow the ability to detect out-of-distribution (OOD) changes as the size of the\nPLM grows or the transfer methods are altered. Specifically, we evaluated\nvarious PETL techniques, including fine-tuning, Adapter, LoRA, and\nprefix-tuning, on three different intention classification tasks, each\nutilizing various language models with different scales.", "published": "2023-01-27 11:27:40", "link": "http://arxiv.org/abs/2301.11660v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Network Model for Sign Language Comprehension", "abstract": "In this study, the authors propose a computational cognitive model for sign\nlanguage (SL) perception and comprehension with detailed algorithmic\ndescriptions based on cognitive functionalities in human language processing.\nThe semantic network model (SNM) that represents semantic relations between\nconcepts, it is used as a form of knowledge representation. The proposed model\nis applied in the comprehension of sign language for classifier predicates. The\nspreading activation search method is initiated by labeling a set of source\nnodes (e.g. concepts in the semantic network) with weights or \"activation\" and\nthen iteratively propagating or \"spreading\" that activation out to other nodes\nlinked to the source nodes. The results demonstrate that the proposed search\nmethod improves the performance of sign language comprehension in the SNM.", "published": "2023-01-27 13:43:02", "link": "http://arxiv.org/abs/2301.11709v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-task Multi-stage Transitional Training Framework for Neural Chat\n  Translation", "abstract": "Neural chat translation (NCT) aims to translate a cross-lingual chat between\nspeakers of different languages. Existing context-aware NMT models cannot\nachieve satisfactory performances due to the following inherent problems: 1)\nlimited resources of annotated bilingual dialogues; 2) the neglect of modelling\nconversational properties; 3) training discrepancy between different stages. To\naddress these issues, in this paper, we propose a multi-task multi-stage\ntransitional (MMT) training framework, where an NCT model is trained using the\nbilingual chat translation dataset and additional monolingual dialogues. We\nelaborately design two auxiliary tasks, namely utterance discrimination and\nspeaker discrimination, to introduce the modelling of dialogue coherence and\nspeaker characteristic into the NCT model. The training process consists of\nthree stages: 1) sentence-level pre-training on large-scale parallel corpus; 2)\nintermediate training with auxiliary tasks using additional monolingual\ndialogues; 3) context-aware fine-tuning with gradual transition. Particularly,\nthe second stage serves as an intermediate phase that alleviates the training\ndiscrepancy between the pre-training and fine-tuning stages. Moreover, to make\nthe stage transition smoother, we train the NCT model using a gradual\ntransition strategy, i.e., gradually transiting from using monolingual to\nbilingual dialogues. Extensive experiments on two language pairs demonstrate\nthe effectiveness and superiority of our proposed training framework.", "published": "2023-01-27 14:41:16", "link": "http://arxiv.org/abs/2301.11749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Call for Papers -- The BabyLM Challenge: Sample-efficient pretraining on\n  a developmentally plausible corpus", "abstract": "We present the call for papers for the BabyLM Challenge: Sample-efficient\npretraining on a developmentally plausible corpus. This shared task is intended\nfor participants with an interest in small scale language modeling, human\nlanguage acquisition, low-resource NLP, and cognitive modeling. In partnership\nwith CoNLL and CMCL, we provide a platform for approaches to pretraining with a\nlimited-size corpus sourced from data inspired by the input to children. The\ntask has three tracks, two of which restrict the training data to pre-released\ndatasets of 10M and 100M words and are dedicated to explorations of approaches\nsuch as architectural variations, self-supervised objectives, or curriculum\nlearning. The final track only restricts the amount of text used, allowing\ninnovation in the choice of the data, its domain, and even its modality (i.e.,\ndata from sources other than text is welcome). We will release a shared\nevaluation pipeline which scores models on a variety of benchmarks and tasks,\nincluding targeted syntactic evaluations and natural language understanding.", "published": "2023-01-27 15:52:50", "link": "http://arxiv.org/abs/2301.11796v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning the Effects of Physical Actions in a Multi-modal Environment", "abstract": "Large Language Models (LLMs) handle physical commonsense information\ninadequately. As a result of being trained in a disembodied setting, LLMs often\nfail to predict an action's outcome in a given environment. However, predicting\nthe effects of an action before it is executed is crucial in planning, where\ncoherent sequences of actions are often needed to achieve a goal. Therefore, we\nintroduce the multi-modal task of predicting the outcomes of actions solely\nfrom realistic sensory inputs (images and text). Next, we extend an LLM to\nmodel latent representations of objects to better predict action outcomes in an\nenvironment. We show that multi-modal models can capture physical commonsense\nwhen augmented with visual information. Finally, we evaluate our model's\nperformance on novel actions and objects and find that combining modalities\nhelp models to generalize and learn physical commonsense reasoning better.", "published": "2023-01-27 16:49:52", "link": "http://arxiv.org/abs/2301.11845v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting Sentence-Level Factuality of News and Bias of Media Outlets", "abstract": "Automated news credibility and fact-checking at scale require accurately\npredicting news factuality and media bias. This paper introduces a large\nsentence-level dataset, titled \"FactNews\", composed of 6,191 sentences expertly\nannotated according to factuality and media bias definitions proposed by\nAllSides. We use FactNews to assess the overall reliability of news sources, by\nformulating two text classification problems for predicting sentence-level\nfactuality of news reporting and bias of media outlets. Our experiments\ndemonstrate that biased sentences present a higher number of words compared to\nfactual sentences, besides having a predominance of emotions. Hence, the\nfine-grained analysis of subjectivity and impartiality of news articles\nprovided promising results for predicting the reliability of media outlets.\nFinally, due to the severity of fake news and political polarization in Brazil,\nand the lack of research for Portuguese, both dataset and baseline were\nproposed for Brazilian Portuguese.", "published": "2023-01-27 16:56:24", "link": "http://arxiv.org/abs/2301.11850v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding the Effectiveness of Very Large Language Models on Dialog\n  Evaluation", "abstract": "Language models have steadily increased in size over the past few years. They\nachieve a high level of performance on various natural language processing\n(NLP) tasks such as question answering and summarization. Large language models\n(LLMs) have been used for generation and can now output human-like text. Due to\nthis, there are other downstream tasks in the realm of dialog that can now\nharness the LLMs' language understanding capabilities. Dialog evaluation is one\ntask that this paper will explore. It concentrates on prompting with LLMs:\nBLOOM, OPT, GPT-3, Flan-T5, InstructDial and TNLGv2. The paper shows that the\nchoice of datasets used for training a model contributes to how well it\nperforms on a task as well as on how the prompt should be structured.\nSpecifically, the more diverse and relevant the group of datasets that a model\nis trained on, the better dialog evaluation performs. This paper also\ninvestigates how the number of examples in the prompt and the type of example\nselection used affect the model's performance.", "published": "2023-01-27 22:02:27", "link": "http://arxiv.org/abs/2301.12004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Talk the Walk: Synthetic Data Generation for Conversational Music\n  Recommendation", "abstract": "Recommender systems are ubiquitous yet often difficult for users to control,\nand adjust if recommendation quality is poor. This has motivated conversational\nrecommender systems (CRSs), with control provided through natural language\nfeedback. However, as with most application domains, building robust CRSs\nrequires training data that reflects system usage$\\unicode{x2014}$here\nconversations with user utterances paired with items that cover a wide range of\npreferences. This has proved challenging to collect scalably using conventional\nmethods. We address the question of whether it can be generated synthetically,\nbuilding on recent advances in natural language. We evaluate in the setting of\nitem set recommendation, noting the increasing attention to this task motivated\nby use cases like music, news, and recipe recommendation. We present\nTalkTheWalk, which synthesizes realistic high-quality conversational data by\nleveraging domain expertise encoded in widely available curated item\ncollections, generating a sequence of hypothetical yet plausible item sets,\nthen using a language model to produce corresponding user utterances. We\ngenerate over one million diverse playlist curation conversations in the music\ndomain, and show these contain consistent utterances with relevant item sets\nnearly matching the quality of an existing but small human-collected dataset\nfor this task. We demonstrate the utility of the generated synthetic dataset on\na conversational item retrieval task and show that it improves over both\nunsupervised baselines and systems trained on a real dataset.", "published": "2023-01-27 01:54:16", "link": "http://arxiv.org/abs/2301.11489v3", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "ThoughtSource: A central hub for large language model reasoning data", "abstract": "Large language models (LLMs) such as GPT-4 have recently demonstrated\nimpressive results across a wide range of tasks. LLMs are still limited,\nhowever, in that they frequently fail at complex reasoning, their reasoning\nprocesses are opaque, they are prone to 'hallucinate' facts, and there are\nconcerns about their underlying biases. Letting models verbalize reasoning\nsteps as natural language, a technique known as chain-of-thought prompting, has\nrecently been proposed as a way to address some of these issues. Here we\npresent ThoughtSource, a meta-dataset and software library for chain-of-thought\n(CoT) reasoning. The goal of ThoughtSource is to improve future artificial\nintelligence systems by facilitating qualitative understanding of CoTs,\nenabling empirical evaluations, and providing training data. This first release\nof ThoughtSource integrates seven scientific/medical, three general-domain and\nfive math word question answering datasets.", "published": "2023-01-27 08:45:53", "link": "http://arxiv.org/abs/2301.11596v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multi-View Joint Learning Framework for Embedding Clinical Codes and\n  Text Using Graph Neural Networks", "abstract": "Learning to represent free text is a core task in many clinical machine\nlearning (ML) applications, as clinical text contains observations and plans\nnot otherwise available for inference. State-of-the-art methods use large\nlanguage models developed with immense computational resources and training\ndata; however, applying these models is challenging because of the highly\nvarying syntax and vocabulary in clinical free text. Structured information\nsuch as International Classification of Disease (ICD) codes often succinctly\nabstracts the most important facts of a clinical encounter and yields good\nperformance, but is often not as available as clinical text in real-world\nscenarios. We propose a \\textbf{multi-view learning framework} that jointly\nlearns from codes and text to combine the availability and forward-looking\nnature of text and better performance of ICD codes. The learned text embeddings\ncan be used as inputs to predictive algorithms independent of the ICD codes\nduring inference. Our approach uses a Graph Neural Network (GNN) to process ICD\ncodes, and Bi-LSTM to process text. We apply Deep Canonical Correlation\nAnalysis (DCCA) to enforce the two views to learn a similar representation of\neach patient. In experiments using planned surgical procedure text, our model\noutperforms BERT models fine-tuned to clinical data, and in experiments using\ndiverse text in MIMIC-III, our model is competitive to a fine-tuned BERT at a\ntiny fraction of its computational effort.", "published": "2023-01-27 09:19:03", "link": "http://arxiv.org/abs/2301.11608v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can We Use Probing to Better Understand Fine-tuning and Knowledge\n  Distillation of the BERT NLU?", "abstract": "In this article, we use probing to investigate phenomena that occur during\nfine-tuning and knowledge distillation of a BERT-based natural language\nunderstanding (NLU) model. Our ultimate purpose was to use probing to better\nunderstand practical production problems and consequently to build better NLU\nmodels. We designed experiments to see how fine-tuning changes the linguistic\ncapabilities of BERT, what the optimal size of the fine-tuning dataset is, and\nwhat amount of information is contained in a distilled NLU based on a tiny\nTransformer. The results of the experiments show that the probing paradigm in\nits current form is not well suited to answer such questions. Structural, Edge\nand Conditional probes do not take into account how easy it is to decode probed\ninformation. Consequently, we conclude that quantification of information\ndecodability is critical for many practical applications of the probing\nparadigm.", "published": "2023-01-27 12:56:29", "link": "http://arxiv.org/abs/2301.11688v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SLCNN: Sentence-Level Convolutional Neural Network for Text\n  Classification", "abstract": "Text classification is a fundamental task in natural language processing\n(NLP). Several recent studies show the success of deep learning on text\nprocessing. Convolutional neural network (CNN), as a popular deep learning\nmodel, has shown remarkable success in the task of text classification. In this\npaper, new baseline models have been studied for text classification using CNN.\nIn these models, documents are fed to the network as a three-dimensional tensor\nrepresentation to provide sentence-level analysis. Applying such a method\nenables the models to take advantage of the positional information of the\nsentences in the text. Besides, analysing adjacent sentences allows extracting\nadditional features. The proposed models have been compared with the\nstate-of-the-art models using several datasets. The results have shown that the\nproposed models have better performance, particularly in the longer documents.", "published": "2023-01-27 13:16:02", "link": "http://arxiv.org/abs/2301.11696v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph Attention with Hierarchies for Multi-hop Question Answering", "abstract": "Multi-hop QA (Question Answering) is the task of finding the answer to a\nquestion across multiple documents. In recent years, a number of Deep\nLearning-based approaches have been proposed to tackle this complex task, as\nwell as a few standard benchmarks to assess models Multi-hop QA capabilities.\nIn this paper, we focus on the well-established HotpotQA benchmark dataset,\nwhich requires models to perform answer span extraction as well as support\nsentence prediction. We present two extensions to the SOTA Graph Neural Network\n(GNN) based model for HotpotQA, Hierarchical Graph Network (HGN): (i) we\ncomplete the original hierarchical structure by introducing new edges between\nthe query and context sentence nodes; (ii) in the graph propagation step, we\npropose a novel extension to Hierarchical Graph Attention Network GATH (Graph\nATtention with Hierarchies) that makes use of the graph hierarchy to update the\nnode representations in a sequential fashion. Experiments on HotpotQA\ndemonstrate the efficiency of the proposed modifications and support our\nassumptions about the effects of model related variables.", "published": "2023-01-27 15:49:50", "link": "http://arxiv.org/abs/2301.11792v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reading and Reasoning over Chart Images for Evidence-based Automated\n  Fact-Checking", "abstract": "Evidence data for automated fact-checking (AFC) can be in multiple modalities\nsuch as text, tables, images, audio, or video. While there is increasing\ninterest in using images for AFC, previous works mostly focus on detecting\nmanipulated or fake images. We propose a novel task, chart-based fact-checking,\nand introduce ChartBERT as the first model for AFC against chart evidence.\nChartBERT leverages textual, structural and visual information of charts to\ndetermine the veracity of textual claims. For evaluation, we create ChartFC, a\nnew dataset of 15, 886 charts. We systematically evaluate 75 different\nvision-language (VL) baselines and show that ChartBERT outperforms VL models,\nachieving 63.8% accuracy. Our results suggest that the task is complex yet\nfeasible, with many challenges ahead.", "published": "2023-01-27 16:47:45", "link": "http://arxiv.org/abs/2301.11843v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Pretrained Language Models for Long Clinical Text", "abstract": "Objective: Clinical knowledge enriched transformer models (e.g.,\nClinicalBERT) have state-of-the-art results on clinical NLP (natural language\nprocessing) tasks. One of the core limitations of these transformer models is\nthe substantial memory consumption due to their full self-attention mechanism,\nwhich leads to the performance degradation in long clinical texts. To overcome\nthis, we propose to leverage long-sequence transformer models (e.g., Longformer\nand BigBird), which extend the maximum input sequence length from 512 to 4096,\nto enhance the ability to model long-term dependencies in long clinical texts.\n  Materials and Methods: Inspired by the success of long sequence transformer\nmodels and the fact that clinical notes are mostly long, we introduce two\ndomain enriched language models, Clinical-Longformer and Clinical-BigBird,\nwhich are pre-trained on a large-scale clinical corpus. We evaluate both\nlanguage models using 10 baseline tasks including named entity recognition,\nquestion answering, natural language inference, and document classification\ntasks.\n  Results: The results demonstrate that Clinical-Longformer and\nClinical-BigBird consistently and significantly outperform ClinicalBERT and\nother short-sequence transformers in all 10 downstream tasks and achieve new\nstate-of-the-art results.\n  Discussion: Our pre-trained language models provide the bedrock for clinical\nNLP using long texts. We have made our source code available at\nhttps://github.com/luoyuanlab/Clinical-Longformer, and the pre-trained models\navailable for public download at:\nhttps://huggingface.co/yikuan8/Clinical-Longformer.\n  Conclusion: This study demonstrates that clinical knowledge enriched\nlong-sequence transformers are able to learn long-term dependencies in long\nclinical text. Our methods can also inspire the development of other\ndomain-enriched long-sequence transformers.", "published": "2023-01-27 16:50:29", "link": "http://arxiv.org/abs/2301.11847v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Case-Based Reasoning with Language Models for Classification of Logical\n  Fallacies", "abstract": "The ease and speed of spreading misinformation and propaganda on the Web\nmotivate the need to develop trustworthy technology for detecting fallacies in\nnatural language arguments. However, state-of-the-art language modeling methods\nexhibit a lack of robustness on tasks like logical fallacy classification that\nrequire complex reasoning. In this paper, we propose a Case-Based Reasoning\nmethod that classifies new cases of logical fallacy by language-modeling-driven\nretrieval and adaptation of historical cases. We design four complementary\nstrategies to enrich input representation for our model, based on external\ninformation about goals, explanations, counterarguments, and argument\nstructure. Our experiments in in-domain and out-of-domain settings indicate\nthat Case-Based Reasoning improves the accuracy and generalizability of\nlanguage models. Our ablation studies suggest that representations of similar\ncases have a strong impact on the model performance, that models perform well\nwith fewer retrieved cases, and that the size of the case database has a\nnegligible effect on the performance. Finally, we dive deeper into the\nrelationship between the properties of the retrieved cases and the model\nperformance.", "published": "2023-01-27 17:49:16", "link": "http://arxiv.org/abs/2301.11879v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Understanding INT4 Quantization for Transformer Models: Latency Speedup,\n  Composability, and Failure Cases", "abstract": "Improving the deployment efficiency of transformer-based language models has\nbeen challenging given their high computation and memory cost. While INT8\nquantization has recently been shown to be effective in reducing both the\nmemory cost and latency while preserving model accuracy, it remains unclear\nwhether we can leverage INT4 (which doubles peak hardware throughput) to\nachieve further latency improvement. In this study, we explore the feasibility\nof employing INT4 weight and activation (W4A4) quantization for language\nmodels. Our findings indicate that W4A4 quantization introduces no to\nnegligible accuracy degradation for encoder-only and encoder-decoder models,\nbut causes a significant accuracy drop for decoder-only models. To materialize\nthe performance gain using W4A4, we develop a highly optimized end-to-end W4A4\nencoder inference pipeline supporting different quantization strategies. Our\nINT4 pipeline is $8.5\\times$ faster for latency-oriented scenarios and up to\n$3\\times$ for throughput-oriented scenarios compared to the inference of FP16,\nand improves the SOTA BERT INT8 performance from FasterTransformer by up to\n$1.7\\times$. We provide insights into the failure cases when applying W4A4 to\ndecoder-only models, and further explore the compatibility of INT4 quantization\nwith other compression methods, like pruning and layer reduction.", "published": "2023-01-27 22:44:18", "link": "http://arxiv.org/abs/2301.12017v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring External Knowledge for Accurate modeling of Visual and\n  Language Problems", "abstract": "The interest in Artificial Intelligence (AI) and its applications has seen\nunprecedented growth in the last few years. The success can be partly\nattributed to the advancements of deep neural networks made in the sub-fields\nof AI such as Computer Vision (CV) and Natural Language Processing (NLP). The\npromising research area that this dissertation focuses on is visual and\nlanguage understanding which involves many challenging tasks, i.e.,\nclassification, detection, segmentation, machine translation and captioning,\netc. The state-of-the-art methods for solving these problems usually involves\nonly two parts: source data and target labels, which is rather insufficient\nespecially when the dataset is small. Meanwhile, many external tools or sources\ncan provide extra useful information (external knowledge) that can help improve\nthe performance of these methods. For example, a detection model has been\napplied to provide better object features than state-of-the-art ResNet for\nimage captioning models. Inspired by this observation, we developed a\nmethodology that we can first extract external knowledge and then integrate it\nwith the original models. The external knowledge has to be extracted from the\ndataset, or can directly come from external, e.g., grammar rules or scene\ngraphs. We apply this methodology to different AI tasks, including machine\ntranslation and image captioning and improve the original state-of-the-art\nmodels by a large margin.", "published": "2023-01-27 02:01:50", "link": "http://arxiv.org/abs/2302.08901v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Semi-Parametric Video-Grounded Text Generation", "abstract": "Efficient video-language modeling should consider the computational cost\nbecause of a large, sometimes intractable, number of video frames. Parametric\napproaches such as the attention mechanism may not be ideal since its\ncomputational cost quadratically increases as the video length increases.\nRather, previous studies have relied on offline feature extraction or frame\nsampling to represent the video efficiently, focusing on cross-modal modeling\nin short video clips. In this paper, we propose a semi-parametric\nvideo-grounded text generation model, SeViT, a novel perspective on scalable\nvideo-language modeling toward long untrimmed videos. Treating a video as an\nexternal data store, SeViT includes a non-parametric frame retriever to select\na few query-relevant frames from the data store for a given query and a\nparametric generator to effectively aggregate the frames with the query via\nlate fusion methods. Experimental results demonstrate our method has a\nsignificant advantage in longer videos and causal video understanding.\nMoreover, our model achieves the new state of the art on four video-language\ndatasets, iVQA (+4.8), Next-QA (+6.9), and Activitynet-QA (+4.8) in accuracy,\nand MSRVTT-Caption (+3.6) in CIDEr.", "published": "2023-01-27 03:00:43", "link": "http://arxiv.org/abs/2301.11507v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance\n  Grounding", "abstract": "Robotic grasping is a fundamental ability for a robot to interact with the\nenvironment. Current methods focus on how to obtain a stable and reliable\ngrasping pose in object level, while little work has been studied on part\n(shape)-wise grasping which is related to fine-grained grasping and robotic\naffordance. Parts can be seen as atomic elements to compose an object, which\ncontains rich semantic knowledge and a strong correlation with affordance.\nHowever, lacking a large part-wise 3D robotic dataset limits the development of\npart representation learning and downstream applications. In this paper, we\npropose a new large Language-guided SHape grAsPing datasEt (named LangSHAPE) to\npromote 3D part-level affordance and grasping ability learning. From the\nperspective of robotic cognition, we design a two-stage fine-grained robotic\ngrasping framework (named LangPartGPD), including a novel 3D part language\ngrounding model and a part-aware grasp pose detection model, in which explicit\nlanguage input from human or large language models (LLMs) could guide a robot\nto generate part-level 6-DoF grasping pose with textual explanation. Our method\ncombines the advantages of human-robot collaboration and LLMs' planning ability\nusing explicit language as a symbolic intermediate. To evaluate the\neffectiveness of our proposed method, we perform 3D part grounding and\nfine-grained grasp detection experiments on both simulation and physical robot\nsettings, following language instructions across different degrees of textual\ncomplexity. Results show our method achieves competitive performance in 3D\ngeometry fine-grained grounding, object affordance inference, and 3D part-aware\ngrasping tasks. Our dataset and code are available on our project website\nhttps://sites.google.com/view/lang-shape", "published": "2023-01-27 07:00:54", "link": "http://arxiv.org/abs/2301.11564v2", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.RO"}
{"title": "Towards Personalized Review Summarization by Modeling Historical Reviews\n  from Customer and Product Separately", "abstract": "Review summarization is a non-trivial task that aims to summarize the main\nidea of the product review in the E-commerce website. Different from the\ndocument summary which only needs to focus on the main facts described in the\ndocument, review summarization should not only summarize the main aspects\nmentioned in the review but also reflect the personal style of the review\nauthor. Although existing review summarization methods have incorporated the\nhistorical reviews of both customer and product, they usually simply\nconcatenate and indiscriminately model this two heterogeneous information into\na long sequence. Moreover, the rating information can also provide a high-level\nabstraction of customer preference, it has not been used by the majority of\nmethods. In this paper, we propose the Heterogeneous Historical Review aware\nReview Summarization Model (HHRRS) which separately models the two types of\nhistorical reviews with the rating information by a graph reasoning module with\na contrastive loss. We employ a multi-task framework that conducts the review\nsentiment classification and summarization jointly. Extensive experiments on\nfour benchmark datasets demonstrate the superiority of HHRRS on both tasks.", "published": "2023-01-27 12:32:55", "link": "http://arxiv.org/abs/2301.11682v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Pre-training for Speech Translation: CTC Meets Optimal Transport", "abstract": "The gap between speech and text modalities is a major challenge in\nspeech-to-text translation (ST). Different methods have been proposed to reduce\nthis gap, but most of them require architectural changes in ST training. In\nthis work, we propose to mitigate this issue at the pre-training stage,\nrequiring no change in the ST model. First, we show that the connectionist\ntemporal classification (CTC) loss can reduce the modality gap by design. We\nprovide a quantitative comparison with the more common cross-entropy loss,\nshowing that pre-training with CTC consistently achieves better final ST\naccuracy. Nevertheless, CTC is only a partial solution and thus, in our second\ncontribution, we propose a novel pre-training method combining CTC and optimal\ntransport to further reduce this gap. Our method pre-trains a Siamese-like\nmodel composed of two encoders, one for acoustic inputs and the other for\ntextual inputs, such that they produce representations that are close to each\nother in the Wasserstein space. Extensive experiments on the standard CoVoST-2\nand MuST-C datasets show that our pre-training method applied to the vanilla\nencoder-decoder Transformer achieves state-of-the-art performance under the\nno-external-data setting, and performs on par with recent strong multi-task\nlearning systems trained with external data. Finally, our method can also be\napplied on top of these multi-task systems, leading to further improvements for\nthese models. Code and pre-trained models are available at\nhttps://github.com/formiel/fairseq.", "published": "2023-01-27 14:03:09", "link": "http://arxiv.org/abs/2301.11716v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The Exploration of Knowledge-Preserving Prompts for Document\n  Summarisation", "abstract": "Despite the great development of document summarisation techniques nowadays,\nfactual inconsistencies between the generated summaries and the original texts\nstill occur from time to time. This study explores the possibility of adopting\nprompts to incorporate factual knowledge into generated summaries. We\nspecifically study prefix-tuning that uses a set of trainable continuous prefix\nprompts together with discrete natural language prompts to aid summary\ngeneration. Experimental results demonstrate that the trainable prefixes can\nhelp the summarisation model extract information from discrete prompts\nprecisely, thus generating knowledge-preserving summaries that are factually\nconsistent with the discrete prompts. The ROUGE improvements of the generated\nsummaries indicate that explicitly adding factual knowledge into the\nsummarisation process could boost the overall performance, showing great\npotential for applying it to other natural language processing tasks.", "published": "2023-01-27 14:05:12", "link": "http://arxiv.org/abs/2301.11719v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mo\u00fbsai: Text-to-Music Generation with Long-Context Latent Diffusion", "abstract": "Recent years have seen the rapid development of large generative models for\ntext; however, much less research has explored the connection between text and\nanother \"language\" of communication -- music. Music, much like text, can convey\nemotions, stories, and ideas, and has its own unique structure and syntax. In\nour work, we bridge text and music via a text-to-music generation model that is\nhighly efficient, expressive, and can handle long-term structure. Specifically,\nwe develop Mo\\^usai, a cascading two-stage latent diffusion model that can\ngenerate multiple minutes of high-quality stereo music at 48kHz from textual\ndescriptions. Moreover, our model features high efficiency, which enables\nreal-time inference on a single consumer GPU with a reasonable speed. Through\nexperiments and property analyses, we show our model's competence over a\nvariety of criteria compared with existing music generation models. Lastly, to\npromote the open-source culture, we provide a collection of open-source\nlibraries with the hope of facilitating future work in the field. We\nopen-source the following: Codes:\nhttps://github.com/archinetai/audio-diffusion-pytorch; music samples for this\npaper: http://bit.ly/44ozWDH; all music samples for all models:\nhttps://bit.ly/audio-diffusion.", "published": "2023-01-27 14:52:53", "link": "http://arxiv.org/abs/2301.11757v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Latent Variable Models: Explaining and Finding\n  Good Demonstrations for In-Context Learning", "abstract": "In recent years, pre-trained large language models (LLMs) have demonstrated\nremarkable efficiency in achieving an inference-time few-shot learning\ncapability known as in-context learning. However, existing literature has\nhighlighted the sensitivity of this capability to the selection of few-shot\ndemonstrations. Current understandings of the underlying mechanisms by which\nthis capability arises from regular language model pretraining objectives\nremain disconnected from the real-world LLMs. This study aims to examine the\nin-context learning phenomenon through a Bayesian lens, viewing real-world LLMs\nas latent variable models. On this premise, we propose an algorithm to select\noptimal demonstrations from a set of annotated data with a small LM, and then\ndirectly generalize the selected demonstrations to larger LMs. We demonstrate\nsignificant improvement over baselines, averaged over eight GPT models on eight\nreal-world text classification datasets. We also demonstrate the real-world\nusefulness of our algorithm on GSM8K, a math word problem dataset. Our\nempirical findings support our hypothesis that LLMs implicitly infer a latent\nvariable containing task information.", "published": "2023-01-27 18:59:01", "link": "http://arxiv.org/abs/2301.11916v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prompt-Based Editing for Text Style Transfer", "abstract": "Prompting approaches have been recently explored in text style transfer,\nwhere a textual prompt is used to query a pretrained language model to generate\nstyle-transferred texts word by word in an autoregressive manner. However, such\na generation process is less controllable and early prediction errors may\naffect future word predictions. In this paper, we present a prompt-based\nediting approach for text style transfer. Specifically, we prompt a pretrained\nlanguage model for style classification and use the classification probability\nto compute a style score. Then, we perform discrete search with word-level\nediting to maximize a comprehensive scoring function for the style-transfer\ntask. In this way, we transform a prompt-based generation problem into a\nclassification one, which is a training-free process and more controllable than\nthe autoregressive generation of sentences. In our experiments, we performed\nboth automatic and human evaluation on three style-transfer benchmark datasets,\nand show that our approach largely outperforms the state-of-the-art systems\nthat have 20 times more parameters. Additional empirical analyses further\ndemonstrate the effectiveness of our approach.", "published": "2023-01-27 21:31:14", "link": "http://arxiv.org/abs/2301.11997v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improved knowledge distillation by utilizing backward pass knowledge in\n  neural networks", "abstract": "Knowledge distillation (KD) is one of the prominent techniques for model\ncompression. In this method, the knowledge of a large network (teacher) is\ndistilled into a model (student) with usually significantly fewer parameters.\nKD tries to better-match the output of the student model to that of the teacher\nmodel based on the knowledge extracts from the forward pass of the teacher\nnetwork. Although conventional KD is effective for matching the two networks\nover the given data points, there is no guarantee that these models would match\nin other areas for which we do not have enough training samples. In this work,\nwe address that problem by generating new auxiliary training samples based on\nextracting knowledge from the backward pass of the teacher in the areas where\nthe student diverges greatly from the teacher. We compute the difference\nbetween the teacher and the student and generate new data samples that maximize\nthe divergence. This is done by perturbing data samples in the direction of the\ngradient of the difference between the student and the teacher. Augmenting the\ntraining set by adding this auxiliary improves the performance of KD\nsignificantly and leads to a closer match between the student and the teacher.\nUsing this approach, when data samples come from a discrete domain, such as\napplications of natural language processing (NLP) and language understanding,\nis not trivial. However, we show how this technique can be used successfully in\nsuch applications. We evaluated the performance of our method on various tasks\nin computer vision and NLP domains and got promising results.", "published": "2023-01-27 22:07:38", "link": "http://arxiv.org/abs/2301.12006v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Down the Rabbit Hole: Detecting Online Extremism, Radicalisation, and\n  Politicised Hate Speech", "abstract": "Social media is a modern person's digital voice to project and engage with\nnew ideas and mobilise communities $\\unicode{x2013}$ a power shared with\nextremists. Given the societal risks of unvetted content-moderating algorithms\nfor Extremism, Radicalisation, and Hate speech (ERH) detection, responsible\nsoftware engineering must understand the who, what, when, where, and why such\nmodels are necessary to protect user safety and free expression. Hence, we\npropose and examine the unique research field of ERH context mining to unify\ndisjoint studies. Specifically, we evaluate the start-to-finish design process\nfrom socio-technical definition-building and dataset collection strategies to\ntechnical algorithm design and performance. Our 2015-2021 51-study Systematic\nLiterature Review (SLR) provides the first cross-examination of textual,\nnetwork, and visual approaches to detecting extremist affiliation, hateful\ncontent, and radicalisation towards groups and movements. We identify\nconsensus-driven ERH definitions and propose solutions to existing ideological\nand geographic biases, particularly due to the lack of research in\nOceania/Australasia. Our hybridised investigation on Natural Language\nProcessing, Community Detection, and visual-text models demonstrates the\ndominating performance of textual transformer-based algorithms. We conclude\nwith vital recommendations for ERH context mining researchers and propose an\nuptake roadmap with guidelines for researchers, industries, and governments to\nenable a safer cyberspace.", "published": "2023-01-27 07:59:31", "link": "http://arxiv.org/abs/2301.11579v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.CY", "cs.LG", "I.2.1; I.2.4; I.2.6; I.2.7; I.2.10; K.4.1; I.5.1; I.5.4; I.5.2;\n  I.5.3; J.4"], "primary_category": "cs.SI"}
{"title": "Five ways to recover the symbol of a non-binary localization operator", "abstract": "Five constructive methods for recovering the symbol of a time-frequency\nlocalization operator with non-binary symbol are presented, two based on\nearlier work and three novel methods. For the two derivative methods which have\npreviously been applied to binary symbols, we propose a changed symbol\nestimator and provide additional estimates that show how we can recover\nnon-binary symbols. The three novel methods each have their own advantages and\nare all applicable to non-binary symbols. Two of them rely on prescribing the\ninput of the localization operator and examining the output, allowing for\ntargeting of the part of the symbol one wishes to recover while the last one\nrelies on spectral information about the operator. All five methods are also\nimplemented numerically and evaluated with the code available.", "published": "2023-01-27 09:39:50", "link": "http://arxiv.org/abs/2301.11618v2", "categories": ["math.FA", "eess.AS"], "primary_category": "math.FA"}
{"title": "Byte Pair Encoding for Symbolic Music", "abstract": "When used with deep learning, the symbolic music modality is often coupled\nwith language model architectures. To do so, the music needs to be tokenized,\ni.e. converted into a sequence of discrete tokens. This can be achieved by\ndifferent approaches, as music can be composed of simultaneous tracks, of\nsimultaneous notes with several attributes. Until now, the proposed\ntokenizations rely on small vocabularies of tokens describing the note\nattributes and time events, resulting in fairly long token sequences, and a\nsub-optimal use of the embedding space of language models. Recent research has\nput efforts on reducing the overall sequence length by merging embeddings or\ncombining tokens. In this paper, we show that Byte Pair Encoding, a compression\ntechnique widely used for natural language, significantly decreases the\nsequence length while increasing the vocabulary size. By doing so, we leverage\nthe embedding capabilities of such models with more expressive tokens,\nresulting in both better results and faster inference in generation and\nclassification tasks. The source code is shared on Github, along with a\ncompanion website. Finally, BPE is directly implemented in MidiTok, allowing\nthe reader to easily benefit from this method.", "published": "2023-01-27 20:22:18", "link": "http://arxiv.org/abs/2301.11975v3", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
