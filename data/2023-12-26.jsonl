{"title": "Heterogeneous Encoders Scaling In The Transformer For Neural Machine\n  Translation", "abstract": "Although the Transformer is currently the best-performing architecture in the\nhomogeneous configuration (self-attention only) in Neural Machine Translation,\nmany State-of-the-Art models in Natural Language Processing are made of a\ncombination of different Deep Learning approaches. However, these models often\nfocus on combining a couple of techniques only and it is unclear why some\nmethods are chosen over others. In this work, we investigate the effectiveness\nof integrating an increasing number of heterogeneous methods. Based on a simple\ncombination strategy and performance-driven synergy criteria, we designed the\nMulti-Encoder Transformer, which consists of up to five diverse encoders.\nResults showcased that our approach can improve the quality of the translation\nacross a variety of languages and dataset sizes and it is particularly\neffective in low-resource languages where we observed a maximum increase of\n7.16 BLEU compared to the single-encoder model.", "published": "2023-12-26 03:39:08", "link": "http://arxiv.org/abs/2312.15872v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KnowledgeNavigator: Leveraging Large Language Models for Enhanced\n  Reasoning over Knowledge Graph", "abstract": "Large language model (LLM) has achieved outstanding performance on various\ndownstream tasks with its powerful natural language understanding and zero-shot\ncapability, but LLM still suffers from knowledge limitation. Especially in\nscenarios that require long logical chains or complex reasoning, the\nhallucination and knowledge limitation of LLM limit its performance in question\nanswering (QA). In this paper, we propose a novel framework KnowledgeNavigator\nto address these challenges by efficiently and accurately retrieving external\nknowledge from knowledge graph and using it as a key factor to enhance LLM\nreasoning. Specifically, KnowledgeNavigator first mines and enhances the\npotential constraints of the given question to guide the reasoning. Then it\nretrieves and filters external knowledge that supports answering through\niterative reasoning on knowledge graph with the guidance of LLM and the\nquestion. Finally, KnowledgeNavigator constructs the structured knowledge into\neffective prompts that are friendly to LLM to help its reasoning. We evaluate\nKnowledgeNavigator on multiple public KGQA benchmarks, the experiments show the\nframework has great effectiveness and generalization, outperforming previous\nknowledge graph enhanced LLM methods and is comparable to the fully supervised\nmodels.", "published": "2023-12-26 04:22:56", "link": "http://arxiv.org/abs/2312.15880v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Align on the Fly: Adapting Chatbot Behavior to Established Norms", "abstract": "In this paper, we aim to align large language models with the ever-changing,\ncomplex, and diverse human values (e.g., social norms) across time and\nlocations. This presents a challenge to existing alignment techniques, such as\nsupervised fine-tuning, which internalize values within model parameters. To\novercome this, we propose an On-the-fly Preference Optimization (OPO) method,\nwhich is a real-time alignment that works in a streaming way. It employs an\nexternal memory to store established rules for alignment, which can constrain\nLLMs' behaviors without further training, allowing for convenient updates and\ncustomization of human values. We also introduce a scalable evaluation to\nassess the proposed method more effectively. Experimental results on both\nhuman-annotated and auto-generated questions from legal and moral domains\nindicate the effectiveness of the proposed OPO method. Our code and data are\nreleased at https://github.com/GAIR-NLP/OPO.", "published": "2023-12-26 06:51:09", "link": "http://arxiv.org/abs/2312.15907v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Probing Contact Center Large Language Models", "abstract": "Fine-tuning large language models (LLMs) with domain-specific instructions\nhas emerged as an effective method to enhance their domain-specific\nunderstanding. Yet, there is limited work that examines the core\ncharacteristics acquired during this process. In this study, we benchmark the\nfundamental characteristics learned by contact-center (CC) specific instruction\nfine-tuned LLMs with out-of-the-box (OOB) LLMs via probing tasks encompassing\nconversational, channel, and automatic speech recognition (ASR) properties. We\nexplore different LLM architectures (Flan-T5 and Llama), sizes (3B, 7B, 11B,\n13B), and fine-tuning paradigms (full fine-tuning vs PEFT). Our findings reveal\nremarkable effectiveness of CC-LLMs on the in-domain downstream tasks, with\nimprovement in response acceptability by over 48% compared to OOB-LLMs.\nAdditionally, we compare the performance of OOB-LLMs and CC-LLMs on the widely\nused SentEval dataset, and assess their capabilities in terms of surface,\nsyntactic, and semantic information through probing tasks. Intriguingly, we\nnote a relatively consistent performance of probing classifiers on the set of\nprobing tasks. Our observations indicate that CC-LLMs, while outperforming\ntheir out-of-the-box counterparts, exhibit a tendency to rely less on encoding\nsurface, syntactic, and semantic properties, highlighting the intricate\ninterplay between domain-specific adaptation and probing task performance\nopening up opportunities to explore behavior of fine-tuned language models in\nspecialized contexts.", "published": "2023-12-26 07:34:39", "link": "http://arxiv.org/abs/2312.15922v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning Large Language Models with Human Preferences through\n  Representation Engineering", "abstract": "Aligning large language models (LLMs) with human preferences is crucial for\nenhancing their utility in terms of helpfulness, truthfulness, safety,\nharmlessness, and interestingness. Existing methods for achieving this\nalignment often involves employing reinforcement learning from human feedback\n(RLHF) to fine-tune LLMs based on human labels assessing the relative quality\nof model responses. Nevertheless, RLHF is susceptible to instability during\nfine-tuning and presents challenges in implementation.Drawing inspiration from\nthe emerging field of representation engineering (RepE), this study aims to\nidentify relevant representations for high-level human preferences embedded in\npatterns of activity within an LLM, and achieve precise control of model\nbehavior by transforming its representations. This novel approach, denoted as\nRepresentation Alignment from Human Feedback (RAHF), proves to be effective,\ncomputationally efficient, and easy to implement.Extensive experiments\ndemonstrate the efficacy of RAHF in not only capturing but also manipulating\nrepresentations to align with a broad spectrum of human preferences or values,\nrather than being confined to a singular concept or function (e.g. honesty or\nbias). RAHF's versatility in accommodating diverse human preferences shows its\npotential for advancing LLM performance.", "published": "2023-12-26 11:01:36", "link": "http://arxiv.org/abs/2312.15997v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Logically Consistent Chain-of-Thought Approach for Stance Detection", "abstract": "Zero-shot stance detection (ZSSD) aims to detect stances toward unseen\ntargets. Incorporating background knowledge to enhance transferability between\nseen and unseen targets constitutes the primary approach of ZSSD. However,\nthese methods often struggle with a knowledge-task disconnect and lack logical\nconsistency in their predictions. To address these issues, we introduce a novel\napproach named Logically Consistent Chain-of-Thought (LC-CoT) for ZSSD, which\nimproves stance detection by ensuring relevant and logically sound knowledge\nextraction. LC-CoT employs a three-step process. Initially, it assesses whether\nsupplementary external knowledge is necessary. Subsequently, it uses API calls\nto retrieve this knowledge, which can be processed by a separate LLM. Finally,\na manual exemplar guides the LLM to infer stance categories, using an if-then\nlogical structure to maintain relevance and logical coherence. This structured\napproach to eliciting background knowledge enhances the model's capability,\noutperforming traditional supervised methods without relying on labeled data.", "published": "2023-12-26 13:54:00", "link": "http://arxiv.org/abs/2312.16054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RoleEval: A Bilingual Role Evaluation Benchmark for Large Language\n  Models", "abstract": "The rapid evolution of large language models necessitates effective\nbenchmarks for evaluating their role knowledge, which is essential for\nestablishing connections with the real world and providing more immersive\ninteractions. This paper introduces RoleEval, a bilingual benchmark designed to\nassess the memorization, utilization, and reasoning capabilities of role\nknowledge. RoleEval comprises RoleEval-Global (including internationally\nrecognized characters) and RoleEval-Chinese (including characters popular in\nChina), with 6,000 Chinese-English parallel multiple-choice questions focusing\non 300 influential people and fictional characters drawn from a variety of\ndomains including celebrities, anime, comics, movies, TV series, games, and\nfictions. These questions cover basic knowledge and multi-hop reasoning\nabilities, aiming to systematically probe various aspects such as personal\ninformation, relationships, abilities, and experiences of the characters. To\nmaintain high standards, we perform a hybrid quality check process combining\nboth automatic and human verification, ensuring that the questions are diverse,\nchallenging, and discriminative.\n  Our extensive evaluations with RoleEval across various open-source and\nproprietary large language models, under both the zero- and few-shot settings,\nreveal insightful findings. Notably, while GPT-4 outperforms other models on\nRoleEval-Global, Chinese large language models excel on RoleEval-Chinese,\nhighlighting significant knowledge distribution differences. We expect that\nRoleEval would highlight the significance of assessing role knowledge for large\nlanguage models across various languages and cultural settings.", "published": "2023-12-26 17:40:55", "link": "http://arxiv.org/abs/2312.16132v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Media Bias Taxonomy: A Systematic Literature Review on the Forms and\n  Automated Detection of Media Bias", "abstract": "The way the media presents events can significantly affect public perception,\nwhich in turn can alter people's beliefs and views. Media bias describes a\none-sided or polarizing perspective on a topic. This article summarizes the\nresearch on computational methods to detect media bias by systematically\nreviewing 3140 research papers published between 2019 and 2022. To structure\nour review and support a mutual understanding of bias across research domains,\nwe introduce the Media Bias Taxonomy, which provides a coherent overview of the\ncurrent state of research on media bias from different perspectives. We show\nthat media bias detection is a highly active research field, in which\ntransformer-based classification approaches have led to significant\nimprovements in recent years. These improvements include higher classification\naccuracy and the ability to detect more fine-granular types of bias. However,\nwe have identified a lack of interdisciplinarity in existing projects, and a\nneed for more awareness of the various types of media bias to support\nmethodologically thorough performance evaluations of media bias detection\nsystems. Concluding from our analysis, we see the integration of recent machine\nlearning advancements with reliable and diverse bias assessment strategies from\nother research areas as the most promising area for future research\ncontributions in the field.", "published": "2023-12-26 18:13:52", "link": "http://arxiv.org/abs/2312.16148v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contribuci\u00f3n de la sem\u00e1ntica combinatoria al desarrollo de\n  herramientas digitales multiling\u00fces", "abstract": "This paper describes how the field of Combinatorial Semantics has contributed\nto the design of three prototypes for the automatic generation of argument\npatterns in nominal phrases in Spanish, French and German (Xera, Combinatoria\nand CombiContext). It also shows the importance of knowing about the argument\nsyntactic-semantic interface in a production situation in the context of\nforeign languages. After a descriptive section on the design, typologie and\ninformation levels of the resources, there follows an explanation of the\ncentral role of the combinatorial meaning (roles and ontological features). The\nstudy deals with different semantic f ilters applied in the selection,\norganization and expansion of the lexicon, being these key pieces for the\ngeneration of grammatically correct and semantically acceptable mono- and\nbiargumental nominal phrases.", "published": "2023-12-26 19:32:05", "link": "http://arxiv.org/abs/2312.16309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zur Darstellung eines mehrstufigen Prototypbegriffs in der\n  multilingualen automatischen Sprachgenerierung: vom Korpus \u00fcber word\n  embeddings bis hin zum automatischen W\u00f6rterbuch", "abstract": "The multilingual dictionary of noun valency Portlex is considered to be the\ntrigger for the creation of the automatic language generators Xera and\nCombinatoria, whose development and use is presented in this paper. Both\nprototypes are used for the automatic generation of nominal phrases with their\nmono- and bi-argumental valence slots, which could be used, among others, as\ndictionary examples or as integrated components of future autonomous\nE-Learning-Tools. As samples for new types of automatic valency dictionaries\nincluding user interaction, we consider the language generators as we know them\ntoday. In the specific methodological procedure for the development of the\nlanguage generators, the syntactic-semantic description of the noun slots turns\nout to be the main focus from a syntagmatic and paradigmatic point of view.\nAlong with factors such as representativeness, grammatical correctness,\nsemantic coherence, frequency and the variety of lexical candidates, as well as\nsemantic classes and argument structures, which are fixed components of both\nresources, a concept of a multi-sided prototype stands out. The combined\napplication of this prototype concept as well as of word embeddings together\nwith techniques from the field of automatic natural language processing and\ngeneration (NLP and NLG) opens up a new way for the future development of\nautomatically generated plurilingual valency dictionaries. All things\nconsidered, the paper depicts the language generators both from the point of\nview of their development as well as from that of the users. The focus lies on\nthe role of the prototype concept within the development of the resources.", "published": "2023-12-26 19:39:25", "link": "http://arxiv.org/abs/2312.16311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task Contamination: Language Models May Not Be Few-Shot Anymore", "abstract": "Large language models (LLMs) offer impressive performance in various\nzero-shot and few-shot tasks. However, their success in zero-shot and few-shot\nsettings may be affected by task contamination, a potential limitation that has\nnot been thoroughly examined. This paper investigates how zero-shot and\nfew-shot performance of LLMs has changed chronologically over time. Utilizing\nGPT-3 series models and several other recent open-sourced LLMs, and controlling\nfor dataset difficulty, we find that on datasets released before the LLM\ntraining data creation date, LLMs perform surprisingly better than on datasets\nreleased after. This strongly indicates that, for many LLMs, there exists task\ncontamination on zero-shot and few-shot evaluation for datasets released prior\nto the LLMs' training data creation date. Additionally, we utilize training\ndata inspection, task example extraction, and a membership inference attack,\nwhich reveal further evidence of task contamination. Importantly, we find that\nfor classification tasks with no possibility of task contamination, LLMs rarely\ndemonstrate statistically significant improvements over simple majority\nbaselines, in both zero and few-shot settings.", "published": "2023-12-26 21:17:46", "link": "http://arxiv.org/abs/2312.16337v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "SecQA: A Concise Question-Answering Dataset for Evaluating Large\n  Language Models in Computer Security", "abstract": "In this paper, we introduce SecQA, a novel dataset tailored for evaluating\nthe performance of Large Language Models (LLMs) in the domain of computer\nsecurity. Utilizing multiple-choice questions generated by GPT-4 based on the\n\"Computer Systems Security: Planning for Success\" textbook, SecQA aims to\nassess LLMs' understanding and application of security principles. We detail\nthe structure and intent of SecQA, which includes two versions of increasing\ncomplexity, to provide a concise evaluation across various difficulty levels.\nAdditionally, we present an extensive evaluation of prominent LLMs, including\nGPT-3.5-Turbo, GPT-4, Llama-2, Vicuna, Mistral, and Zephyr models, using both\n0-shot and 5-shot learning settings. Our results, encapsulated in the SecQA v1\nand v2 datasets, highlight the varying capabilities and limitations of these\nmodels in the computer security context. This study not only offers insights\ninto the current state of LLMs in understanding security-related content but\nalso establishes SecQA as a benchmark for future advancements in this critical\nresearch area.", "published": "2023-12-26 00:59:30", "link": "http://arxiv.org/abs/2312.15838v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Knowledge Distillation of LLM for Automatic Scoring of Science Education\n  Assessments", "abstract": "This study proposes a method for knowledge distillation (KD) of fine-tuned\nLarge Language Models (LLMs) into smaller, more efficient, and accurate neural\nnetworks. We specifically target the challenge of deploying these models on\nresource-constrained devices. Our methodology involves training the smaller\nstudent model (Neural Network) using the prediction probabilities (as soft\nlabels) of the LLM, which serves as a teacher model. This is achieved through a\nspecialized loss function tailored to learn from the LLM's output\nprobabilities, ensuring that the student model closely mimics the teacher's\nperformance. To validate the performance of the KD approach, we utilized a\nlarge dataset, 7T, containing 6,684 student-written responses to science\nquestions and three mathematical reasoning datasets with student-written\nresponses graded by human experts. We compared accuracy with state-of-the-art\n(SOTA) distilled models, TinyBERT, and artificial neural network (ANN) models.\nResults have shown that the KD approach has 3% and 2% higher scoring accuracy\nthan ANN and TinyBERT, respectively, and comparable accuracy to the teacher\nmodel. Furthermore, the student model size is 0.03M, 4,000 times smaller in\nparameters and x10 faster in inferencing than the teacher model and TinyBERT,\nrespectively. The significance of this research lies in its potential to make\nadvanced AI technologies accessible in typical educational settings,\nparticularly for automatic scoring.", "published": "2023-12-26 01:24:25", "link": "http://arxiv.org/abs/2312.15842v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Punctuation Matters! Stealthy Backdoor Attack for Language Models", "abstract": "Recent studies have pointed out that natural language processing (NLP) models\nare vulnerable to backdoor attacks. A backdoored model produces normal outputs\non the clean samples while performing improperly on the texts with triggers\nthat the adversary injects. However, previous studies on textual backdoor\nattack pay little attention to stealthiness. Moreover, some attack methods even\ncause grammatical issues or change the semantic meaning of the original texts.\nTherefore, they can easily be detected by humans or defense systems. In this\npaper, we propose a novel stealthy backdoor attack method against textual\nmodels, which is called \\textbf{PuncAttack}. It leverages combinations of\npunctuation marks as the trigger and chooses proper locations strategically to\nreplace them. Through extensive experiments, we demonstrate that the proposed\nmethod can effectively compromise multiple models in various tasks. Meanwhile,\nwe conduct automatic evaluation and human inspection, which indicate the\nproposed method possesses good performance of stealthiness without bringing\ngrammatical issues and altering the meaning of sentences.", "published": "2023-12-26 03:26:20", "link": "http://arxiv.org/abs/2312.15867v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Medical Report Generation based on Segment-Enhanced Contrastive\n  Representation Learning", "abstract": "Automated radiology report generation has the potential to improve radiology\nreporting and alleviate the workload of radiologists. However, the medical\nreport generation task poses unique challenges due to the limited availability\nof medical data and the presence of data bias. To maximize the utility of\navailable data and reduce data bias, we propose MSCL (Medical image\nSegmentation with Contrastive Learning), a framework that utilizes the Segment\nAnything Model (SAM) to segment organs, abnormalities, bones, etc., and can pay\nmore attention to the meaningful ROIs in the image to get better visual\nrepresentations. Then we introduce a supervised contrastive loss that assigns\nmore weight to reports that are semantically similar to the target while\ntraining. The design of this loss function aims to mitigate the impact of data\nbias and encourage the model to capture the essential features of a medical\nimage and generate high-quality reports. Experimental results demonstrate the\neffectiveness of our proposed model, where we achieve state-of-the-art\nperformance on the IU X-Ray public dataset.", "published": "2023-12-26 03:33:48", "link": "http://arxiv.org/abs/2312.15869v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HyKGE: A Hypothesis Knowledge Graph Enhanced Framework for Accurate and\n  Reliable Medical LLMs Responses", "abstract": "In this paper, we investigate the retrieval-augmented generation (RAG) based\non Knowledge Graphs (KGs) to improve the accuracy and reliability of Large\nLanguage Models (LLMs). Recent approaches suffer from insufficient and\nrepetitive knowledge retrieval, tedious and time-consuming query parsing, and\nmonotonous knowledge utilization. To this end, we develop a Hypothesis\nKnowledge Graph Enhanced (HyKGE) framework, which leverages LLMs' powerful\nreasoning capacity to compensate for the incompleteness of user queries,\noptimizes the interaction process with LLMs, and provides diverse retrieved\nknowledge. Specifically, HyKGE explores the zero-shot capability and the rich\nknowledge of LLMs with Hypothesis Outputs to extend feasible exploration\ndirections in the KGs, as well as the carefully curated prompt to enhance the\ndensity and efficiency of LLMs' responses. Furthermore, we introduce the HO\nFragment Granularity-aware Rerank Module to filter out noise while ensuring the\nbalance between diversity and relevance in retrieved knowledge. Experiments on\ntwo Chinese medical multiple-choice question datasets and one Chinese\nopen-domain medical Q&A dataset with two LLM turbos demonstrate the superiority\nof HyKGE in terms of accuracy and explainability.", "published": "2023-12-26 04:49:56", "link": "http://arxiv.org/abs/2312.15883v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Supervised Knowledge Makes Large Language Models Better In-context\n  Learners", "abstract": "Large Language Models (LLMs) exhibit emerging in-context learning abilities\nthrough prompt engineering. The recent progress in large-scale generative\nmodels has further expanded their use in real-world language applications.\nHowever, the critical challenge of improving the generalizability and\nfactuality of LLMs in natural language understanding and question answering\nremains under-explored. While previous in-context learning research has focused\non enhancing models to adhere to users' specific instructions and quality\nexpectations, and to avoid undesired outputs, little to no work has explored\nthe use of task-Specific fine-tuned Language Models (SLMs) to improve LLMs'\nin-context learning during the inference stage. Our primary contribution is the\nestablishment of a simple yet effective framework that enhances the reliability\nof LLMs as it: 1) generalizes out-of-distribution data, 2) elucidates how LLMs\nbenefit from discriminative models, and 3) minimizes hallucinations in\ngenerative tasks. Using our proposed plug-in method, enhanced versions of Llama\n2 and ChatGPT surpass their original versions regarding generalizability and\nfactuality. We offer a comprehensive suite of resources, including 16 curated\ndatasets, prompts, model checkpoints, and LLM outputs across 9 distinct tasks.\nThe code and data are released at:\nhttps://github.com/YangLinyi/Supervised-Knowledge-Makes-Large-Language-Models-Better-In-context-Learners.\nOur empirical analysis sheds light on the advantages of incorporating\ndiscriminative models into LLMs and highlights the potential of our methodology\nin fostering more reliable LLMs.", "published": "2023-12-26 07:24:46", "link": "http://arxiv.org/abs/2312.15918v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DocMSU: A Comprehensive Benchmark for Document-level Multimodal Sarcasm\n  Understanding", "abstract": "Multimodal Sarcasm Understanding (MSU) has a wide range of applications in\nthe news field such as public opinion analysis and forgery detection. However,\nexisting MSU benchmarks and approaches usually focus on sentence-level MSU. In\ndocument-level news, sarcasm clues are sparse or small and are often concealed\nin long text. Moreover, compared to sentence-level comments like tweets, which\nmainly focus on only a few trends or hot topics (e.g., sports events), content\nin the news is considerably diverse. Models created for sentence-level MSU may\nfail to capture sarcasm clues in document-level news. To fill this gap, we\npresent a comprehensive benchmark for Document-level Multimodal Sarcasm\nUnderstanding (DocMSU). Our dataset contains 102,588 pieces of news with\ntext-image pairs, covering 9 diverse topics such as health, business, etc. The\nproposed large-scale and diverse DocMSU significantly facilitates the research\nof document-level MSU in real-world scenarios. To take on the new challenges\nposed by DocMSU, we introduce a fine-grained sarcasm comprehension method to\nproperly align the pixel-level image features with word-level textual features\nin documents. Experiments demonstrate the effectiveness of our method, showing\nthat it can serve as a baseline approach to the challenging DocMSU. Our code\nand dataset are available at https://github.com/Dulpy/DocMSU.", "published": "2023-12-26 12:24:14", "link": "http://arxiv.org/abs/2312.16023v1", "categories": ["cs.CL", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Dotless Representation of Arabic Text: Analysis and Modeling", "abstract": "This paper presents a novel dotless representation of Arabic text as an\nalternative to the standard Arabic text representation. We delve into its\nimplications through comprehensive analysis across five diverse corpora and\nfour different tokenization techniques. We explore the impact of dotless\nrepresentation on the relationships between tokenization granularity and\nvocabulary size and compare them with standard text representation. Moreover,\nwe analyze the information density of dotless versus standard text using text\nentropy calculations. To delve deeper into the implications of the dotless\nrepresentation, statistical and neural language models are constructed using\nthe various text corpora and tokenization techniques. A comparative assessment\nis then made against language models developed using the standard Arabic text\nrepresentation. This multifaceted analysis provides valuable insights into the\npotential advantages and challenges associated with the dotless representation.\nLast but not the least, utilizing parallel corpora, we draw comparisons between\nthe text analysis of Arabic and English to gain further insights. Our findings\nshed light on the potential benefits of dotless representation for various NLP\ntasks, paving the way for further exploration for Arabic natural language\nprocessing.", "published": "2023-12-26 16:16:33", "link": "http://arxiv.org/abs/2312.16104v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Better Monolingual Japanese Retrievers with Multi-Vector Models", "abstract": "As language-specific training data tends to be sparsely available compared to\nEnglish, document retrieval in many languages has been largely relying on\nmultilingual models. In Japanese, the best performing deep-learning based\nretrieval approaches rely on multilingual dense embedders, with Japanese-only\nmodels lagging far behind. However, multilingual models require considerably\nmore compute and data to train and have higher computational and memory\nrequirements while often missing out on culturally-relevant information. In\nthis paper, we introduce JaColBERT, a family of multi-vector retrievers trained\non two magnitudes fewer data than their multilingual counterparts while\nreaching competitive performance. Our strongest model largely outperform all\nexisting monolingual Japanese retrievers on all dataset, as well as the\nstrongest existing multilingual models on all out-of-domain tasks, highlighting\nthe need for specialised models able to handle linguistic specificities. These\nresults are achieved using a model with only 110 million parameters,\nconsiderably smaller than all multilingual models, and using only a limited\nJapanese-language. We believe our results show great promise to support\nJapanese retrieval-enhanced application pipelines in a wide variety of domains.", "published": "2023-12-26 18:07:05", "link": "http://arxiv.org/abs/2312.16144v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From text to multimodal: a survey of adversarial example generation in\n  question answering systems", "abstract": "Integrating adversarial machine learning with Question Answering (QA) systems\nhas emerged as a critical area for understanding the vulnerabilities and\nrobustness of these systems. This article aims to comprehensively review\nadversarial example-generation techniques in the QA field, including textual\nand multimodal contexts. We examine the techniques employed through systematic\ncategorization, providing a comprehensive, structured review. Beginning with an\noverview of traditional QA models, we traverse the adversarial example\ngeneration by exploring rule-based perturbations and advanced generative\nmodels. We then extend our research to include multimodal QA systems, analyze\nthem across various methods, and examine generative models, seq2seq\narchitectures, and hybrid methodologies. Our research grows to different\ndefense strategies, adversarial datasets, and evaluation metrics and\nillustrates the comprehensive literature on adversarial QA. Finally, the paper\nconsiders the future landscape of adversarial question generation, highlighting\npotential research directions that can advance textual and multimodal QA\nsystems in the context of adversarial challenges.", "published": "2023-12-26 18:30:29", "link": "http://arxiv.org/abs/2312.16156v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Cross-Lingual Reranking with Large Language Models for\n  Low-Resource Languages", "abstract": "Large language models (LLMs) have shown impressive zero-shot capabilities in\nvarious document reranking tasks. Despite their successful implementations,\nthere is still a gap in existing literature on their effectiveness in\nlow-resource languages. To address this gap, we investigate how LLMs function\nas rerankers in cross-lingual information retrieval (CLIR) systems for African\nlanguages. Our implementation covers English and four African languages (Hausa,\nSomali, Swahili, and Yoruba) and we examine cross-lingual reranking with\nqueries in English and passages in the African languages. Additionally, we\nanalyze and compare the effectiveness of monolingual reranking using both query\nand document translations. We also evaluate the effectiveness of LLMs when\nleveraging their own generated translations. To get a grasp of the\neffectiveness of multiple LLMs, our study focuses on the proprietary models\nRankGPT-4 and RankGPT-3.5, along with the open-source model, RankZephyr. While\nreranking remains most effective in English, our results reveal that\ncross-lingual reranking may be competitive with reranking in African languages\ndepending on the multilingual capability of the LLM.", "published": "2023-12-26 18:38:54", "link": "http://arxiv.org/abs/2312.16159v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Principled Instructions Are All You Need for Questioning LLaMA-1/2,\n  GPT-3.5/4", "abstract": "This paper introduces 26 guiding principles designed to streamline the\nprocess of querying and prompting large language models. Our goal is to\nsimplify the underlying concepts of formulating questions for various scales of\nlarge language models, examining their abilities, and enhancing user\ncomprehension on the behaviors of different scales of large language models\nwhen feeding into different prompts. Extensive experiments are conducted on\nLLaMA-1/2 (7B, 13B and 70B), GPT-3.5/4 to verify the effectiveness of the\nproposed principles on instructions and prompts design. We hope that this work\ncan provide a better guide for researchers working on the prompting of large\nlanguage models. Project page is available at\nhttps://github.com/VILA-Lab/ATLAS.", "published": "2023-12-26 18:59:33", "link": "http://arxiv.org/abs/2312.16171v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Observable Propagation: Uncovering Feature Vectors in Transformers", "abstract": "A key goal of current mechanistic interpretability research in NLP is to find\nlinear features (also called \"feature vectors\") for transformers: directions in\nactivation space corresponding to concepts that are used by a given model in\nits computation. Present state-of-the-art methods for finding linear features\nrequire large amounts of labelled data -- both laborious to acquire and\ncomputationally expensive to utilize. In this work, we introduce a novel\nmethod, called \"observable propagation\" (in short: ObProp), for finding linear\nfeatures used by transformer language models in computing a given task -- using\nalmost no data. Our paradigm centers on the concept of \"observables\", linear\nfunctionals corresponding to given tasks. We then introduce a mathematical\ntheory for the analysis of feature vectors, including a similarity metric\nbetween feature vectors called the coupling coefficient which estimates the\ndegree to which one feature's output correlates with another's. We use ObProp\nto perform extensive qualitative investigations into several tasks, including\ngendered occupational bias, political party prediction, and programming\nlanguage detection. Our results suggest that ObProp surpasses traditional\napproaches for finding feature vectors in the low-data regime, and that ObProp\ncan be used to better understand the mechanisms responsible for bias in large\nlanguage models.", "published": "2023-12-26 19:00:56", "link": "http://arxiv.org/abs/2312.16291v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Low-Resource Relation Representations through Multi-View\n  Decoupling", "abstract": "Recently, prompt-tuning with pre-trained language models (PLMs) has\ndemonstrated the significantly enhancing ability of relation extraction (RE)\ntasks. However, in low-resource scenarios, where the available training data is\nscarce, previous prompt-based methods may still perform poorly for prompt-based\nrepresentation learning due to a superficial understanding of the relation. To\nthis end, we highlight the importance of learning high-quality relation\nrepresentation in low-resource scenarios for RE, and propose a novel\nprompt-based relation representation method, named MVRE\n(\\underline{M}ulti-\\underline{V}iew \\underline{R}elation\n\\underline{E}xtraction), to better leverage the capacity of PLMs to improve the\nperformance of RE within the low-resource prompt-tuning paradigm. Specifically,\nMVRE decouples each relation into different perspectives to encompass\nmulti-view relation representations for maximizing the likelihood during\nrelation inference. Furthermore, we also design a Global-Local loss and a\nDynamic-Initialization method for better alignment of the multi-view\nrelation-representing virtual words, containing the semantics of relation\nlabels during the optimization learning process and initialization. Extensive\nexperiments on three benchmark datasets show that our method can achieve\nstate-of-the-art in low-resource settings.", "published": "2023-12-26 14:16:16", "link": "http://arxiv.org/abs/2312.17267v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ShallowBlocker: Improving Set Similarity Joins for Blocking", "abstract": "Blocking is a crucial step in large-scale entity matching but often requires\nsignificant manual engineering from an expert for each new dataset. Recent work\nhas show that deep learning is state-of-the-art and has great potential for\nachieving hands-off and accurate blocking compared to classical methods.\nHowever, in practice, such deep learning methods are often unstable, offers\nlittle interpretability, and require hyperparameter tuning and significant\ncomputational resources.\n  In this paper, we propose a hands-off blocking method based on classical\nstring similarity measures: ShallowBlocker. It uses a novel hybrid set\nsimilarity join combining absolute similarity, relative similarity, and local\ncardinality conditions with a new effective pre-candidate filter replacing size\nfilter. We show that the method achieves state-of-the-art pair effectiveness on\nboth unsupervised and supervised blocking in a scalable way.", "published": "2023-12-26 00:31:43", "link": "http://arxiv.org/abs/2312.15835v1", "categories": ["cs.DB", "cs.CL", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Learning-To-Rank Approach for Identifying Everyday Objects Using a\n  Physical-World Search Engine", "abstract": "Domestic service robots offer a solution to the increasing demand for daily\ncare and support. A human-in-the-loop approach that combines automation and\noperator intervention is considered to be a realistic approach to their use in\nsociety. Therefore, we focus on the task of retrieving target objects from\nopen-vocabulary user instructions in a human-in-the-loop setting, which we\ndefine as the learning-to-rank physical objects (LTRPO) task. For example,\ngiven the instruction \"Please go to the dining room which has a round table.\nPick up the bottle on it,\" the model is required to output a ranked list of\ntarget objects that the operator/user can select. In this paper, we propose\nMultiRankIt, which is a novel approach for the LTRPO task. MultiRankIt\nintroduces the Crossmodal Noun Phrase Encoder to model the relationship between\nphrases that contain referring expressions and the target bounding box, and the\nCrossmodal Region Feature Encoder to model the relationship between the target\nobject and multiple images of its surrounding contextual environment.\nAdditionally, we built a new dataset for the LTRPO task that consists of\ninstructions with complex referring expressions accompanied by real indoor\nenvironmental images that feature various target objects. We validated our\nmodel on the dataset and it outperformed the baseline method in terms of the\nmean reciprocal rank and recall@k. Furthermore, we conducted physical\nexperiments in a setting where a domestic service robot retrieved everyday\nobjects in a standardized domestic environment, based on users' instruction in\na human--in--the--loop setting. The experimental results demonstrate that the\nsuccess rate for object retrieval achieved 80%. Our code is available at\nhttps://github.com/keio-smilab23/MultiRankIt.", "published": "2023-12-26 01:40:31", "link": "http://arxiv.org/abs/2312.15844v1", "categories": ["cs.RO", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Can ChatGPT Read Who You Are?", "abstract": "The interplay between artificial intelligence (AI) and psychology,\nparticularly in personality assessment, represents an important emerging area\nof research. Accurate personality trait estimation is crucial not only for\nenhancing personalization in human-computer interaction but also for a wide\nvariety of applications ranging from mental health to education. This paper\nanalyzes the capability of a generic chatbot, ChatGPT, to effectively infer\npersonality traits from short texts. We report the results of a comprehensive\nuser study featuring texts written in Czech by a representative population\nsample of 155 participants. Their self-assessments based on the Big Five\nInventory (BFI) questionnaire serve as the ground truth. We compare the\npersonality trait estimations made by ChatGPT against those by human raters and\nreport ChatGPT's competitive performance in inferring personality traits from\ntext. We also uncover a 'positivity bias' in ChatGPT's assessments across all\npersonality dimensions and explore the impact of prompt composition on\naccuracy. This work contributes to the understanding of AI capabilities in\npsychological assessment, highlighting both the potential and limitations of\nusing large language models for personality inference. Our research underscores\nthe importance of responsible AI development, considering ethical implications\nsuch as privacy, consent, autonomy, and bias in AI applications.", "published": "2023-12-26 14:43:04", "link": "http://arxiv.org/abs/2312.16070v2", "categories": ["cs.CY", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "A bi-objective $\u03b5$-constrained framework for quality-cost\n  optimization in language model ensembles", "abstract": "We propose an ensembling framework that uses diverse open-sourced Large\nLanguage Models (LLMs) to achieve high response quality while maintaining cost\nefficiency. We formulate a bi-objective optimization problem to represent the\nquality-cost tradeoff and then introduce an additional budget constraint that\nreduces the problem to a straightforward 0/1 knapsack problem. We empirically\ndemonstrate that our framework outperforms the existing ensembling approaches\nin response quality while significantly reducing costs.", "published": "2023-12-26 16:56:22", "link": "http://arxiv.org/abs/2312.16119v1", "categories": ["cs.LG", "cs.CL", "cs.NE"], "primary_category": "cs.LG"}
{"title": "More than Correlation: Do Large Language Models Learn Causal\n  Representations of Space?", "abstract": "Recent work found high mutual information between the learned representations\nof large language models (LLMs) and the geospatial property of its input,\nhinting an emergent internal model of space. However, whether this internal\nspace model has any causal effects on the LLMs' behaviors was not answered by\nthat work, led to criticism of these findings as mere statistical correlation.\nOur study focused on uncovering the causality of the spatial representations in\nLLMs. In particular, we discovered the potential spatial representations in\nDeBERTa, GPT-Neo using representational similarity analysis and linear and\nnon-linear probing. Our casual intervention experiments showed that the spatial\nrepresentations influenced the model's performance on next word prediction and\na downstream task that relies on geospatial information. Our experiments\nsuggested that the LLMs learn and use an internal model of space in solving\ngeospatial related tasks.", "published": "2023-12-26 01:27:29", "link": "http://arxiv.org/abs/2312.16257v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The NUS-HLT System for ICASSP2024 ICMC-ASR Grand Challenge", "abstract": "This paper summarizes our team's efforts in both tracks of the ICMC-ASR\nChallenge for in-car multi-channel automatic speech recognition. Our submitted\nsystems for ICMC-ASR Challenge include the multi-channel front-end enhancement\nand diarization, training data augmentation, speech recognition modeling with\nmulti-channel branches. Tested on the offical Eval1 and Eval2 set, our best\nsystem achieves a relative 34.3% improvement in CER and 56.5% improvement in\ncpCER, compared to the offical baseline system.", "published": "2023-12-26 11:11:22", "link": "http://arxiv.org/abs/2312.16002v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition\n  Neural Network", "abstract": "In this paper, we study an underexplored, yet important and challenging\nproblem: counting the number of distinct sounds in raw audio characterized by a\nhigh degree of polyphonicity. We do so by systematically proposing a novel\nend-to-end trainable neural network (which we call DyDecNet, consisting of a\ndyadic decomposition front-end and backbone network), and quantifying the\ndifficulty level of counting depending on sound polyphonicity. The dyadic\ndecomposition front-end progressively decomposes the raw waveform dyadically\nalong the frequency axis to obtain time-frequency representation in\nmulti-stage, coarse-to-fine manner. Each intermediate waveform convolved by a\nparent filter is further processed by a pair of child filters that evenly split\nthe parent filter's carried frequency response, with the higher-half child\nfilter encoding the detail and lower-half child filter encoding the\napproximation. We further introduce an energy gain normalization to normalize\nsound loudness variance and spectrum overlap, and apply it to each intermediate\nparent waveform before feeding it to the two child filters. To better quantify\nsound counting difficulty level, we further design three polyphony-aware\nmetrics: polyphony ratio, max polyphony and mean polyphony. We test DyDecNet on\nvarious datasets to show its superiority, and we further show dyadic\ndecomposition network can be used as a general front-end to tackle other\nacoustic tasks.", "published": "2023-12-26 18:18:04", "link": "http://arxiv.org/abs/2312.16149v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EnchantDance: Unveiling the Potential of Music-Driven Dance Movement", "abstract": "The task of music-driven dance generation involves creating coherent dance\nmovements that correspond to the given music. While existing methods can\nproduce physically plausible dances, they often struggle to generalize to\nout-of-set data. The challenge arises from three aspects: 1) the high diversity\nof dance movements and significant differences in the distribution of music\nmodalities, which make it difficult to generate music-aligned dance movements.\n2) the lack of a large-scale music-dance dataset, which hinders the generation\nof generalized dance movements from music. 3) The protracted nature of dance\nmovements poses a challenge to the maintenance of a consistent dance style. In\nthis work, we introduce the EnchantDance framework, a state-of-the-art method\nfor dance generation. Due to the redundancy of the original dance sequence\nalong the time axis, EnchantDance first constructs a strong dance latent space\nand then trains a dance diffusion model on the dance latent space. To address\nthe data gap, we construct a large-scale music-dance dataset, ChoreoSpectrum3D\nDataset, which includes four dance genres and has a total duration of 70.32\nhours, making it the largest reported music-dance dataset to date. To enhance\nconsistency between music genre and dance style, we pre-train a music genre\nprediction network using transfer learning and incorporate music genre as extra\nconditional information in the training of the dance diffusion model. Extensive\nexperiments demonstrate that our proposed framework achieves state-of-the-art\nperformance on dance quality, diversity, and consistency.", "published": "2023-12-26 08:19:10", "link": "http://arxiv.org/abs/2312.15946v2", "categories": ["cs.SD", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
