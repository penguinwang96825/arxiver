{"title": "Variational Template Machine for Data-to-Text Generation", "abstract": "How to generate descriptions from structured data organized in tables?\nExisting approaches using neural encoder-decoder models often suffer from\nlacking diversity. We claim that an open set of templates is crucial for\nenriching the phrase constructions and realizing varied generations. Learning\nsuch templates is prohibitive since it often requires a large paired <table,\ndescription> corpus, which is seldom available. This paper explores the problem\nof automatically learning reusable \"templates\" from paired and non-paired data.\nWe propose the variational template machine (VTM), a novel method to generate\ntext descriptions from data tables. Our contributions include: a) we carefully\ndevise a specific model architecture and losses to explicitly disentangle text\ntemplate and semantic content information, in the latent spaces, and b)we\nutilize both small parallel data and large raw text without aligned tables to\nenrich the template learning. Experiments on datasets from a variety of\ndifferent domains show that VTM is able to generate more diversely while\nkeeping a good fluency and quality.", "published": "2020-02-04 04:53:45", "link": "http://arxiv.org/abs/2002.01127v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactically Look-Ahead Attention Network for Sentence Compression", "abstract": "Sentence compression is the task of compressing a long sentence into a short\none by deleting redundant words. In sequence-to-sequence (Seq2Seq) based\nmodels, the decoder unidirectionally decides to retain or delete words. Thus,\nit cannot usually explicitly capture the relationships between decoded words\nand unseen words that will be decoded in the future time steps. Therefore, to\navoid generating ungrammatical sentences, the decoder sometimes drops important\nwords in compressing sentences. To solve this problem, we propose a novel\nSeq2Seq model, syntactically look-ahead attention network (SLAHAN), that can\ngenerate informative summaries by explicitly tracking both dependency parent\nand child words during decoding and capturing important words that will be\ndecoded in the future. The results of the automatic evaluation on the Google\nsentence compression dataset showed that SLAHAN achieved the best\nkept-token-based-F1, ROUGE-1, ROUGE-2 and ROUGE-L scores of 85.5, 79.3, 71.3\nand 79.1, respectively. SLAHAN also improved the summarization performance on\nlonger sentences. Furthermore, in the human evaluation, SLAHAN improved\ninformativeness without losing readability.", "published": "2020-02-04 06:26:37", "link": "http://arxiv.org/abs/2002.01145v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Knowledge Routing Network For Target-Guided Open-Domain\n  Conversation", "abstract": "Target-guided open-domain conversation aims to proactively and naturally\nguide a dialogue agent or human to achieve specific goals, topics or keywords\nduring open-ended conversations. Existing methods mainly rely on single-turn\ndatadriven learning and simple target-guided strategy without considering\nsemantic or factual knowledge relations among candidate topics/keywords. This\nresults in poor transition smoothness and low success rate. In this work, we\nadopt a structured approach that controls the intended content of system\nresponses by introducing coarse-grained keywords, attains smooth conversation\ntransition through turn-level supervised learning and knowledge relations\nbetween candidate keywords, and drives an conversation towards an specified\ntarget with discourse-level guiding strategy. Specially, we propose a novel\ndynamic knowledge routing network (DKRN) which considers semantic knowledge\nrelations among candidate keywords for accurate next topic prediction of next\ndiscourse. With the help of more accurate keyword prediction, our\nkeyword-augmented response retrieval module can achieve better retrieval\nperformance and more meaningful conversations. Besides, we also propose a novel\ndual discourse-level target-guided strategy to guide conversations to reach\ntheir goals smoothly with higher success rate. Furthermore, to push the\nresearch boundary of target-guided open-domain conversation to match real-world\nscenarios better, we introduce a new large-scale Chinese target-guided\nopen-domain conversation dataset (more than 900K conversations) crawled from\nSina Weibo. Quantitative and human evaluations show our method can produce\nmeaningful and effective target-guided conversations, significantly improving\nover other state-of-the-art methods by more than 20% in success rate and more\nthan 0.6 in average smoothness score.", "published": "2020-02-04 09:49:36", "link": "http://arxiv.org/abs/2002.01196v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoVoST: A Diverse Multilingual Speech-To-Text Translation Corpus", "abstract": "Spoken language translation has recently witnessed a resurgence in\npopularity, thanks to the development of end-to-end models and the creation of\nnew corpora, such as Augmented LibriSpeech and MuST-C. Existing datasets\ninvolve language pairs with English as a source language, involve very specific\ndomains or are low resource. We introduce CoVoST, a multilingual speech-to-text\ntranslation corpus from 11 languages into English, diversified with over 11,000\nspeakers and over 60 accents. We describe the dataset creation methodology and\nprovide empirical evidence of the quality of the data. We also provide initial\nbenchmarks, including, to our knowledge, the first end-to-end many-to-one\nmultilingual models for spoken language translation. CoVoST is released under\nCC0 license and free to use. We also provide additional evaluation data derived\nfrom Tatoeba under CC licenses.", "published": "2020-02-04 14:35:28", "link": "http://arxiv.org/abs/2002.01320v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plague Dot Text: Text mining and annotation of outbreak reports of the\n  Third Plague Pandemic (1894-1952)", "abstract": "The design of models that govern diseases in population is commonly built on\ninformation and data gathered from past outbreaks. However, epidemic outbreaks\nare never captured in statistical data alone but are communicated by\nnarratives, supported by empirical observations. Outbreak reports discuss\ncorrelations between populations, locations and the disease to infer insights\ninto causes, vectors and potential interventions. The problem with these\nnarratives is usually the lack of consistent structure or strong conventions,\nwhich prohibit their formal analysis in larger corpora. Our interdisciplinary\nresearch investigates more than 100 reports from the third plague pandemic\n(1894-1952) evaluating ways of building a corpus to extract and structure this\nnarrative information through text mining and manual annotation. In this paper\nwe discuss the progress of our ongoing exploratory project, how we enhance\noptical character recognition (OCR) methods to improve text capture, our\napproach to structure the narratives and identify relevant entities in the\nreports. The structured corpus is made available via Solr enabling search and\nanalysis across the whole collection for future research dedicated, for\nexample, to the identification of concepts. We show preliminary visualisations\nof the characteristics of causation and differences with respect to gender as a\nresult of syntactic-category-dependent corpus statistics. Our goal is to\ndevelop structured accounts of some of the most significant concepts that were\nused to understand the epidemiology of the third plague pandemic around the\nglobe. The corpus enables researchers to analyse the reports collectively\nallowing for deep insights into the global epidemiological consideration of\nplague in the early twentieth century.", "published": "2020-02-04 17:16:36", "link": "http://arxiv.org/abs/2002.01415v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Topic Networks to Distributed Cognitive Maps: Zipfian Topic\n  Universes in the Area of Volunteered Geographic Information", "abstract": "Are nearby places (e.g. cities) described by related words? In this article\nwe transfer this research question in the field of lexical encoding of\ngeographic information onto the level of intertextuality. To this end, we\nexplore Volunteered Geographic Information (VGI) to model texts addressing\nplaces at the level of cities or regions with the help of so-called topic\nnetworks. This is done to examine how language encodes and networks geographic\ninformation on the aboutness level of texts. Our hypothesis is that the\nnetworked thematizations of places are similar - regardless of their distances\nand the underlying communities of authors. To investigate this we introduce\nMultiplex Topic Networks (MTN), which we automatically derive from Linguistic\nMultilayer Networks (LMN) as a novel model, especially of thematic networking\nin text corpora. Our study shows a Zipfian organization of the thematic\nuniverse in which geographical places (especially cities) are located in online\ncommunication. We interpret this finding in the context of cognitive maps, a\nnotion which we extend by so-called thematic maps. According to our\ninterpretation of this finding, the organization of thematic maps as part of\ncognitive maps results from a tendency of authors to generate shareable content\nthat ensures the continued existence of the underlying media. We test our\nhypothesis by example of special wikis and extracts of Wikipedia. In this way\nwe come to the conclusion: Places, whether close to each other or not, are\nlocated in neighboring places that span similar subnetworks in the topic\nuniverse.", "published": "2020-02-04 18:31:25", "link": "http://arxiv.org/abs/2002.01454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fake News Detection by means of Uncertainty Weighted Causal Graphs", "abstract": "Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.", "published": "2020-02-04 00:28:38", "link": "http://arxiv.org/abs/2002.01065v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Arabic Diacritic Recovery Using a Feature-Rich biLSTM Model", "abstract": "Diacritics (short vowels) are typically omitted when writing Arabic text, and\nreaders have to reintroduce them to correctly pronounce words. There are two\ntypes of Arabic diacritics: the first are core-word diacritics (CW), which\nspecify the lexical selection, and the second are case endings (CE), which\ntypically appear at the end of the word stem and generally specify their\nsyntactic roles. Recovering CEs is relatively harder than recovering core-word\ndiacritics due to inter-word dependencies, which are often distant. In this\npaper, we use a feature-rich recurrent neural network model that uses a variety\nof linguistic and surface-level features to recover both core word diacritics\nand case endings. Our model surpasses all previous state-of-the-art systems\nwith a CW error rate (CWER) of 2.86\\% and a CE error rate (CEER) of 3.7% for\nModern Standard Arabic (MSA) and CWER of 2.2% and CEER of 2.5% for Classical\nArabic (CA). When combining diacritized word cores with case endings, the\nresultant word error rate is 6.0% and 4.3% for MSA and CA respectively. This\nhighlights the effectiveness of feature engineering for such deep neural\nmodels.", "published": "2020-02-04 10:09:42", "link": "http://arxiv.org/abs/2002.01207v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Stochastic Automata over Monoids", "abstract": "Stochastic automata over monoids as input sets are studied. The\nwell-definedness of these automata requires an extension postulate that\nreplaces the inherent universal property of free monoids. As a generalization\nof Turakainen's result, it will be shown that the generalized automata over\nmonoids have the same acceptance power as their stochastic counterparts. The\nkey to homomorphisms is a commuting property between the monoid homomorphism of\ninput states and the monoid homomorphism of transition matrices. Closure\nproperties of the languages accepted by stochastic automata over monoids are\ninvestigated. matrices. Closure properties of the languages accepted by\nstochastic automata over monoids are investigated.", "published": "2020-02-04 10:30:49", "link": "http://arxiv.org/abs/2002.01214v1", "categories": ["cs.FL", "cs.CL", "68Q70, 68Q87, 20M35", "F.1.1"], "primary_category": "cs.FL"}
{"title": "Iterative Data Programming for Expanding Text Classification Corpora", "abstract": "Real-world text classification tasks often require many labeled training\nexamples that are expensive to obtain. Recent advancements in machine teaching,\nspecifically the data programming paradigm, facilitate the creation of training\ndata sets quickly via a general framework for building weak models, also known\nas labeling functions, and denoising them through ensemble learning techniques.\nWe present a fast, simple data programming method for augmenting text data sets\nby generating neighborhood-based weak models with minimal supervision.\nFurthermore, our method employs an iterative procedure to identify sparsely\ndistributed examples from large volumes of unlabeled data. The iterative data\nprogramming techniques improve newer weak models as more labeled data is\nconfirmed with human-in-loop. We show empirical results on sentence\nclassification tasks, including those from a task of improving intent\nrecognition in conversational agents.", "published": "2020-02-04 17:12:43", "link": "http://arxiv.org/abs/2002.01412v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Semantic Search of Memes on Twitter", "abstract": "Memes are becoming a useful source of data for analyzing behavior on social\nmedia. However, a problem to tackle is how to correctly identify a meme. As the\nnumber of memes published every day on social media is huge, there is a need\nfor automatic methods for classifying and searching in large meme datasets.\nThis paper proposes and compares several methods for automatically classifying\nimages as memes. Also, we propose a method that allows us to implement a system\nfor retrieving memes from a dataset using a textual query. We experimentally\nevaluate the methods using a large dataset of memes collected from Twitter\nusers in Chile, which was annotated by a group of experts. Though some of the\nevaluated methods are effective, there is still room for improvement.", "published": "2020-02-04 18:40:38", "link": "http://arxiv.org/abs/2002.01462v4", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Generalizing meanings from partners to populations: Hierarchical\n  inference supports convention formation on networks", "abstract": "A key property of linguistic conventions is that they hold over an entire\ncommunity of speakers, allowing us to communicate efficiently even with people\nwe have never met before. At the same time, much of our language use is\npartner-specific: we know that words may be understood differently by different\npeople based on our shared history. This poses a challenge for accounts of\nconvention formation. Exactly how do agents make the inferential leap to\ncommunity-wide expectations while maintaining partner-specific knowledge? We\npropose a hierarchical Bayesian model to explain how speakers and listeners\nsolve this inductive problem. To evaluate our model's predictions, we conducted\nan experiment where participants played an extended natural-language\ncommunication game with different partners in a small community. We examine\nseveral measures of generalization and find key signatures of both\npartner-specificity and community convergence that distinguish our model from\nalternatives. These results suggest that partner-specificity is not only\ncompatible with the formation of community-wide conventions, but may facilitate\nit when coupled with a powerful inductive mechanism.", "published": "2020-02-04 19:30:55", "link": "http://arxiv.org/abs/2002.01510v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Lightweight Convolutional Representations for On-Device Natural Language\n  Processing", "abstract": "The increasing computational and memory complexities of deep neural networks\nhave made it difficult to deploy them on low-resource electronic devices (e.g.,\nmobile phones, tablets, wearables). Practitioners have developed numerous model\ncompression methods to address these concerns, but few have condensed input\nrepresentations themselves. In this work, we propose a fast, accurate, and\nlightweight convolutional representation that can be swapped into any neural\nmodel and compressed significantly (up to 32x) with a negligible reduction in\nperformance. In addition, we show gains over recurrent representations when\nconsidering resource-centric metrics (e.g., model file size, latency, memory\nusage) on a Samsung Galaxy S9.", "published": "2020-02-04 21:02:11", "link": "http://arxiv.org/abs/2002.01535v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compositional Languages Emerge in a Neural Iterated Learning Model", "abstract": "The principle of compositionality, which enables natural language to\nrepresent complex concepts via a structured combination of simpler ones, allows\nus to convey an open-ended set of messages using a limited vocabulary. If\ncompositionality is indeed a natural property of language, we may expect it to\nappear in communication protocols that are created by neural agents in language\ngames. In this paper, we propose an effective neural iterated learning (NIL)\nalgorithm that, when applied to interacting neural agents, facilitates the\nemergence of a more structured type of language. Indeed, these languages\nprovide learning speed advantages to neural agents during training, which can\nbe incrementally amplified via NIL. We provide a probabilistic model of NIL and\nan explanation of why the advantage of compositional language exist. Our\nexperiments confirm our analysis, and also demonstrate that the emerged\nlanguages largely improve the generalizing power of the neural agent\ncommunication.", "published": "2020-02-04 15:19:09", "link": "http://arxiv.org/abs/2002.01365v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the interaction between supervision and self-play in emergent\n  communication", "abstract": "A promising approach for teaching artificial agents to use natural language\ninvolves using human-in-the-loop training. However, recent work suggests that\ncurrent machine learning methods are too data inefficient to be trained in this\nway from scratch. In this paper, we investigate the relationship between two\ncategories of learning signals with the ultimate goal of improving sample\nefficiency: imitating human language data via supervised learning, and\nmaximizing reward in a simulated multi-agent environment via self-play (as done\nin emergent communication), and introduce the term supervised self-play (S2P)\nfor algorithms using both of these signals. We find that first training agents\nvia supervised learning on human data followed by self-play outperforms the\nconverse, suggesting that it is not beneficial to emerge languages from\nscratch. We then empirically investigate various S2P schedules that begin with\nsupervised learning in two environments: a Lewis signaling game with symbolic\ninputs, and an image-based referential game with natural language descriptions.\nLastly, we introduce population based approaches to S2P, which further improves\nthe performance over single-agent methods.", "published": "2020-02-04 02:35:19", "link": "http://arxiv.org/abs/2002.01093v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Structural Inductive Biases in Emergent Communication", "abstract": "In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.", "published": "2020-02-04 14:59:08", "link": "http://arxiv.org/abs/2002.01335v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Visual Concept-Metaconcept Learning", "abstract": "Humans reason with concepts and metaconcepts: we recognize red and green from\nvisual input; we also understand that they describe the same property of\nobjects (i.e., the color). In this paper, we propose the visual\nconcept-metaconcept learner (VCML) for joint learning of concepts and\nmetaconcepts from images and associated question-answer pairs. The key is to\nexploit the bidirectional connection between visual concepts and metaconcepts.\nVisual representations provide grounding cues for predicting relations between\nunseen pairs of concepts. Knowing that red and green describe the same property\nof objects, we generalize to the fact that cube and sphere also describe the\nsame property of objects, since they both categorize the shape of objects.\nMeanwhile, knowledge about metaconcepts empowers visual concept learning from\nlimited, noisy, and even biased data. From just a few examples of purple cubes\nwe can understand a new color purple, which resembles the hue of the cubes\ninstead of the shape of them. Evaluation on both synthetic and real-world\ndatasets validates our claims.", "published": "2020-02-04 18:42:30", "link": "http://arxiv.org/abs/2002.01464v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Acoustic anomaly detection via latent regularized gaussian mixture\n  generative adversarial networks", "abstract": "Acoustic anomaly detection aims at distinguishing abnormal acoustic signals\nfrom the normal ones. It suffers from the class imbalance issue and the lacking\nin the abnormal instances. In addition, collecting all kinds of abnormal or\nunknown samples for training purpose is impractical and timeconsuming. In this\npaper, a novel Gaussian Mixture Generative Adversarial Network (GMGAN) is\nproposed under semi-supervised learning framework, in which the underlying\nstructure of training data is not only captured in spectrogram reconstruction\nspace, but also can be further restricted in the space of latent representation\nin a discriminant manner. Experiments show that our model has clear superiority\nover previous methods, and achieves the state-of-the-art results on DCASE\ndataset.", "published": "2020-02-04 03:39:50", "link": "http://arxiv.org/abs/2002.01107v2", "categories": ["eess.AS", "cs.CV", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Audio-Visual Calibration with Polynomial Regression for 2-D Projection\n  Using SVD-PHAT", "abstract": "This paper proposes a straightforward 2-D method to spatially calibrate the\nvisual field of a camera with the auditory field of an array microphone by\ngenerating and overlaying an acoustic image over an optical image. Using a\nlow-cost microphone array and an off-the-shelf camera, we show that polynomial\nregression can deal efficiently with non-linear camera distortion, and that a\nrecently proposed sound source localization method for real-time processing,\nSVD-PHAT, can be adapted for this task.", "published": "2020-02-04 18:00:16", "link": "http://arxiv.org/abs/2002.01440v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "BOFFIN TTS: Few-Shot Speaker Adaptation by Bayesian Optimization", "abstract": "We present BOFFIN TTS (Bayesian Optimization For FIne-tuning Neural Text To\nSpeech), a novel approach for few-shot speaker adaptation. Here, the task is to\nfine-tune a pre-trained TTS model to mimic a new speaker using a small corpus\nof target utterances. We demonstrate that there does not exist a\none-size-fits-all adaptation strategy, with convincing synthesis requiring a\ncorpus-specific configuration of the hyper-parameters that control fine-tuning.\nBy using Bayesian optimization to efficiently optimize these hyper-parameter\nvalues for a target speaker, we are able to perform adaptation with an average\n30% improvement in speaker similarity over standard techniques. Results\nindicate, across multiple corpora, that BOFFIN TTS can learn to synthesize new\nspeakers using less than ten minutes of audio, achieving the same naturalness\nas produced for the speakers used to train the base model.", "published": "2020-02-04 16:37:52", "link": "http://arxiv.org/abs/2002.01953v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Emotion Recognition Using Speaker Cues", "abstract": "This research aims at identifying the unknown emotion using speaker cues. In\nthis study, we identify the unknown emotion using a two-stage framework. The\nfirst stage focuses on identifying the speaker who uttered the unknown emotion,\nwhile the next stage focuses on identifying the unknown emotion uttered by the\nrecognized speaker in the prior stage. This proposed framework has been\nevaluated on an Arabic Emirati-accented speech database uttered by fifteen\nspeakers per gender. Mel-Frequency Cepstral Coefficients (MFCCs) have been used\nas the extracted features and Hidden Markov Model (HMM) has been utilized as\nthe classifier in this work. Our findings demonstrate that emotion recognition\naccuracy based on the two-stage framework is greater than that based on the\none-stage approach and the state-of-the-art classifiers and models such as\nGaussian Mixture Model (GMM), Support Vector Machine (SVM), and Vector\nQuantization (VQ). The average emotion recognition accuracy based on the\ntwo-stage approach is 67.5%, while the accuracy reaches to 61.4%, 63.3%, 64.5%,\nand 61.5%, based on the one-stage approach, GMM, SVM, and VQ, respectively. The\nachieved results based on the two-stage framework are very close to those\nattained in subjective assessment by human listeners.", "published": "2020-02-04 08:20:30", "link": "http://arxiv.org/abs/2002.03566v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
