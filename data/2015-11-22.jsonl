{"title": "On the Linear Algebraic Structure of Distributed Word Representations", "abstract": "In this work, we leverage the linear algebraic structure of distributed word\nrepresentations to automatically extend knowledge bases and allow a machine to\nlearn new facts about the world. Our goal is to extract structured facts from\ncorpora in a simpler manner, without applying classifiers or patterns, and\nusing only the co-occurrence statistics of words. We demonstrate that the\nlinear algebraic structure of word embeddings can be used to reduce data\nrequirements for methods of learning facts. In particular, we demonstrate that\nwords belonging to a common category, or pairs of words satisfying a certain\nrelation, form a low-rank subspace in the projected space. We compute a basis\nfor this low-rank subspace using singular value decomposition (SVD), then use\nthis basis to discover new facts and to fit vectors for less frequent words\nwhich we do not yet have vectors for.", "published": "2015-11-22 04:28:39", "link": "http://arxiv.org/abs/1511.06961v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Non-Sentential Utterances in Dialogue: Experiments in Classification and\n  Interpretation", "abstract": "Non-sentential utterances (NSUs) are utterances that lack a complete\nsentential form but whose meaning can be inferred from the dialogue context,\nsuch as \"OK\", \"where?\", \"probably at his apartment\". The interpretation of\nnon-sentential utterances is an important problem in computational linguistics\nsince they constitute a frequent phenomena in dialogue and they are\nintrinsically context-dependent. The interpretation of NSUs is the task of\nretrieving their full semantic content from their form and the dialogue\ncontext. The first half of this thesis is devoted to the NSU classification\ntask. Our work builds upon Fern\\'andez et al. (2007) which present a series of\nmachine-learning experiments on the classification of NSUs. We extended their\napproach with a combination of new features and semi-supervised learning\ntechniques. The empirical results presented in this thesis show a modest but\nsignificant improvement over the state-of-the-art classification performance.\nThe consecutive, yet independent, problem is how to infer an appropriate\nsemantic representation of such NSUs on the basis of the dialogue context.\nFern\\'andez (2006) formalizes this task in terms of \"resolution rules\" built on\ntop of the Type Theory with Records (TTR). Our work is focused on the\nreimplementation of the resolution rules from Fern\\'andez (2006) with a\nprobabilistic account of the dialogue state. The probabilistic rules formalism\nLison (2014) is particularly suited for this task because, similarly to the\nframework developed by Ginzburg (2012) and Fern\\'andez (2006), it involves the\nspecification of update rules on the variables of the dialogue state to capture\nthe dynamics of the conversation. However, the probabilistic rules can also\nencode probabilistic knowledge, thereby providing a principled account of\nambiguities in the NSU resolution process.", "published": "2015-11-22 11:28:26", "link": "http://arxiv.org/abs/1511.06995v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings\n  Using Abstract Scenes", "abstract": "We propose a model to learn visually grounded word embeddings (vis-w2v) to\ncapture visual notions of semantic relatedness. While word embeddings trained\nusing text have been extremely successful, they cannot uncover notions of\nsemantic relatedness implicit in our visual world. For instance, although\n\"eats\" and \"stares at\" seem unrelated in text, they share semantics visually.\nWhen people are eating something, they also tend to stare at the food.\nGrounding diverse relations like \"eats\" and \"stares at\" into vision remains\nchallenging, despite recent progress in vision. We note that the visual\ngrounding of words depends on semantics, and not the literal pixels. We thus\nuse abstract scenes created from clipart to provide the visual grounding. We\nfind that the embeddings we learn capture fine-grained, visually grounded\nnotions of semantic relatedness. We show improvements over text-only word\nembeddings (word2vec) on three tasks: common-sense assertion classification,\nvisual paraphrasing and text-based image retrieval. Our code and datasets are\navailable online.", "published": "2015-11-22 20:46:42", "link": "http://arxiv.org/abs/1511.07067v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Analysis of a Play by Means of CHAPLIN, the Characters and Places\n  Interaction Network Software", "abstract": "Recently, we have developed a software able of gathering information on\nsocial networks from written texts. This software, the CHAracters and PLaces\nInteraction Network (CHAPLIN) tool, is implemented in Visual Basic. By means of\nit, characters and places of a literary work can be extracted from a list of\nraw words. The software interface helps users to select their names out of this\nlist. Setting some parameters, CHAPLIN creates a network where nodes represent\ncharacters/places and edges give their interactions. Nodes and edges are\nlabelled by performances. In this paper, we propose to use CHAPLIN for the\nanalysis a William Shakespeare's play, the famous 'Tragedy of Hamlet, Prince of\nDenmark'. Performances of characters in the play as a whole and in each act of\nit are given by graphs.", "published": "2015-11-22 12:06:34", "link": "http://arxiv.org/abs/1511.07001v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
