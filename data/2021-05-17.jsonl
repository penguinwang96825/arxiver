{"title": "Classifying Argumentative Relations Using Logical Mechanisms and\n  Argumentation Schemes", "abstract": "While argument mining has achieved significant success in classifying\nargumentative relations between statements (support, attack, and neutral), we\nhave a limited computational understanding of logical mechanisms that\nconstitute those relations. Most recent studies rely on black-box models, which\nare not as linguistically insightful as desired. On the other hand, earlier\nstudies use rather simple lexical features, missing logical relations between\nstatements. To overcome these limitations, our work classifies argumentative\nrelations based on four logical and theory-informed mechanisms between two\nstatements, namely (i) factual consistency, (ii) sentiment coherence, (iii)\ncausal relation, and (iv) normative relation. We demonstrate that our\noperationalization of these logical mechanisms classifies argumentative\nrelations without directly training on data labeled with the relations,\nsignificantly better than several unsupervised baselines. We further\ndemonstrate that these mechanisms also improve supervised classifiers through\nrepresentation learning.", "published": "2021-05-17 01:41:39", "link": "http://arxiv.org/abs/2105.07571v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ensemble-based Transfer Learning for Low-resource Machine Translation\n  Quality Estimation", "abstract": "Quality Estimation (QE) of Machine Translation (MT) is a task to estimate the\nquality scores for given translation outputs from an unknown MT system.\nHowever, QE scores for low-resource languages are usually intractable and hard\nto collect. In this paper, we focus on the Sentence-Level QE Shared Task of the\nFifth Conference on Machine Translation (WMT20), but in a more challenging\nsetting. We aim to predict QE scores of given translation outputs when barely\nnone of QE scores of that paired languages are given during training. We\npropose an ensemble-based predictor-estimator QE model with transfer learning\nto overcome such QE data scarcity challenge by leveraging QE scores from other\nmiscellaneous languages and translation results of targeted languages. Based on\nthe evaluation results, we provide a detailed analysis of how each of our\nextension affects QE models on the reliability and the generalization ability\nto perform transfer learning under multilingual tasks. Finally, we achieve the\nbest performance on the ensemble model combining the models pretrained by\nindividual languages as well as different levels of parallel trained corpus\nwith a Pearson's correlation of 0.298, which is 2.54 times higher than\nbaselines.", "published": "2021-05-17 06:02:17", "link": "http://arxiv.org/abs/2105.07622v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Similarity Based on Contexts", "abstract": "Existing methods to measure sentence similarity are faced with two\nchallenges: (1) labeled datasets are usually limited in size, making them\ninsufficient to train supervised neural models; (2) there is a training-test\ngap for unsupervised language modeling (LM) based models to compute semantic\nscores between sentences, since sentence-level semantics are not explicitly\nmodeled at training. This results in inferior performances in this task. In\nthis work, we propose a new framework to address these two issues. The proposed\nframework is based on the core idea that the meaning of a sentence should be\ndefined by its contexts, and that sentence similarity can be measured by\ncomparing the probabilities of generating two sentences given the same context.\nThe proposed framework is able to generate high-quality, large-scale dataset\nwith semantic similarity scores between two sentences in an unsupervised\nmanner, with which the train-test gap can be largely bridged. Extensive\nexperiments show that the proposed framework achieves significant performance\nboosts over existing baselines under both the supervised and unsupervised\nsettings across different datasets.", "published": "2021-05-17 06:03:56", "link": "http://arxiv.org/abs/2105.07623v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factoring Statutory Reasoning as Language Understanding Challenges", "abstract": "Statutory reasoning is the task of determining whether a legal statute,\nstated in natural language, applies to the text description of a case. Prior\nwork introduced a resource that approached statutory reasoning as a monolithic\ntextual entailment problem, with neural baselines performing nearly at-chance.\nTo address this challenge, we decompose statutory reasoning into four types of\nlanguage-understanding challenge problems, through the introduction of concepts\nand structure found in Prolog programs. Augmenting an existing benchmark, we\nprovide annotations for the four tasks, and baselines for three of them. Models\nfor statutory reasoning are shown to benefit from the additional structure,\nimproving on prior baselines. Further, the decomposition into subtasks\nfacilitates finer-grained model diagnostics and clearer incremental progress.", "published": "2021-05-17 14:33:02", "link": "http://arxiv.org/abs/2105.07903v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Room to Grow: Understanding Personal Characteristics Behind Self\n  Improvement Using Social Media", "abstract": "Many people aim for change, but not everyone succeeds. While there are a\nnumber of social psychology theories that propose motivation-related\ncharacteristics of those who persist with change, few computational studies\nhave explored the motivational stage of personal change. In this paper, we\ninvestigate a new dataset consisting of the writings of people who manifest\nintention to change, some of whom persist while others do not. Using a variety\nof linguistic analysis techniques, we first examine the writing patterns that\ndistinguish the two groups of people. Persistent people tend to reference more\ntopics related to long-term self-improvement and use a more complicated writing\nstyle. Drawing on these consistent differences, we build a classifier that can\nreliably identify the people more likely to persist, based on their language.\nOur experiments provide new insights into the motivation-related behavior of\npeople who persist with their intention to change.", "published": "2021-05-17 17:30:30", "link": "http://arxiv.org/abs/2105.08031v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-grained Interpretation and Causation Analysis in Deep NLP Models", "abstract": "This paper is a write-up for the tutorial on \"Fine-grained Interpretation and\nCausation Analysis in Deep NLP Models\" that we are presenting at NAACL 2021. We\npresent and discuss the research work on interpreting fine-grained components\nof a model from two perspectives, i) fine-grained interpretation, ii) causation\nanalysis. The former introduces methods to analyze individual neurons and a\ngroup of neurons with respect to a language property or a task. The latter\nstudies the role of neurons and input features in explaining decisions made by\nthe model. We also discuss application of neuron analysis such as network\nmanipulation and domain adaptation. Moreover, we present two toolkits namely\nNeuroX and Captum, that support functionalities discussed in this tutorial.", "published": "2021-05-17 17:43:36", "link": "http://arxiv.org/abs/2105.08039v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Modal Image Captioning for the Visually Impaired", "abstract": "One of the ways blind people understand their surroundings is by clicking\nimages and relying on descriptions generated by image captioning systems.\nCurrent work on captioning images for the visually impaired do not use the\ntextual data present in the image when generating captions. This problem is\ncritical as many visual scenes contain text. Moreover, up to 21% of the\nquestions asked by blind people about the images they click pertain to the text\npresent in them. In this work, we propose altering AoANet, a state-of-the-art\nimage captioning model, to leverage the text detected in the image as an input\nfeature. In addition, we use a pointer-generator mechanism to copy the detected\ntext to the caption when tokens need to be reproduced accurately. Our model\noutperforms AoANet on the benchmark dataset VizWiz, giving a 35% and 16.2%\nperformance improvement on CIDEr and SPICE scores, respectively.", "published": "2021-05-17 18:35:24", "link": "http://arxiv.org/abs/2105.08106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SHARE: a System for Hierarchical Assistive Recipe Editing", "abstract": "The large population of home cooks with dietary restrictions is under-served\nby existing cooking resources and recipe generation models. To help them, we\npropose the task of controllable recipe editing: adapt a base recipe to satisfy\na user-specified dietary constraint. This task is challenging, and cannot be\nadequately solved with human-written ingredient substitution rules or existing\nend-to-end recipe generation models. We tackle this problem with SHARE: a\nSystem for Hierarchical Assistive Recipe Editing, which performs simultaneous\ningredient substitution before generating natural-language steps using the\nedited ingredients. By decoupling ingredient and step editing, our step\ngenerator can explicitly integrate the available ingredients. Experiments on\nthe novel RecipePairs dataset -- 83K pairs of similar recipes where each recipe\nsatisfies one of seven dietary constraints -- demonstrate that SHARE produces\nconvincing, coherent recipes that are appropriate for a target dietary\nconstraint. We further show through human evaluations and real-world cooking\ntrials that recipes edited by SHARE can be easily followed by home cooks to\ncreate appealing dishes.", "published": "2021-05-17 22:38:07", "link": "http://arxiv.org/abs/2105.08185v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and\n  Textual Content in Finance", "abstract": "Hybrid data combining both tabular and textual content (e.g., financial\nreports) are quite pervasive in the real world. However, Question Answering\n(QA) over such hybrid data is largely neglected in existing research. In this\nwork, we extract samples from real financial reports to build a new large-scale\nQA dataset containing both Tabular And Textual data, named TAT-QA, where\nnumerical reasoning is usually required to infer the answer, such as addition,\nsubtraction, multiplication, division, counting, comparison/sorting, and the\ncompositions. We further propose a novel QA model termed TAGOP, which is\ncapable of reasoning over both tables and text. It adopts sequence tagging to\nextract relevant cells from the table along with relevant spans from the text\nto infer their semantics, and then applies symbolic reasoning over them with a\nset of aggregation operators to arrive at the final answer. TAGOPachieves 58.0%\ninF1, which is an 11.1% absolute increase over the previous best baseline\nmodel, according to our experiments on TAT-QA. But this result still lags far\nbehind performance of expert human, i.e.90.8% in F1. It is demonstrated that\nour TAT-QA is very challenging and can serve as a benchmark for training and\ntesting powerful QA models that address hybrid form data.", "published": "2021-05-17 06:12:06", "link": "http://arxiv.org/abs/2105.07624v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dependency Parsing as MRC-based Span-Span Prediction", "abstract": "Higher-order methods for dependency parsing can partially but not fully\naddress the issue that edges in dependency trees should be constructed at the\ntext span/subtree level rather than word level. In this paper, we propose a new\nmethod for dependency parsing to address this issue. The proposed method\nconstructs dependency trees by directly modeling span-span (in other words,\nsubtree-subtree) relations. It consists of two modules: the {\\it text span\nproposal module} which proposes candidate text spans, each of which represents\na subtree in the dependency tree denoted by (root, start, end); and the {\\it\nspan linking module}, which constructs links between proposed spans. We use the\nmachine reading comprehension (MRC) framework as the backbone to formalize the\nspan linking module, where one span is used as a query to extract the text\nspan/subtree it should be linked to. The proposed method has the following\nmerits: (1) it addresses the fundamental problem that edges in a dependency\ntree should be constructed between subtrees; (2) the MRC framework allows the\nmethod to retrieve missing spans in the span proposal stage, which leads to\nhigher recall for eligible spans. Extensive experiments on the PTB, CTB and\nUniversal Dependencies (UD) benchmarks demonstrate the effectiveness of the\nproposed method. The code is available at\n\\url{https://github.com/ShannonAI/mrc-for-dependency-parsing}", "published": "2021-05-17 08:03:48", "link": "http://arxiv.org/abs/2105.07654v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A CCG-Based Version of the DisCoCat Framework", "abstract": "While the DisCoCat model (Coecke et al., 2010) has been proved a valuable\ntool for studying compositional aspects of language at the level of semantics,\nits strong dependency on pregroup grammars poses important restrictions: first,\nit prevents large-scale experimentation due to the absence of a pregroup\nparser; and second, it limits the expressibility of the model to context-free\ngrammars. In this paper we solve these problems by reformulating DisCoCat as a\npassage from Combinatory Categorial Grammar (CCG) to a category of semantics.\nWe start by showing that standard categorial grammars can be expressed as a\nbiclosed category, where all rules emerge as currying/uncurrying the identity;\nwe then proceed to model permutation-inducing rules by exploiting the symmetry\nof the compact closed category encoding the word meaning. We provide a proof of\nconcept for our method, converting \"Alice in Wonderland\" into DisCoCat form, a\ncorpus that we make available to the community.", "published": "2021-05-17 10:32:18", "link": "http://arxiv.org/abs/2105.07720v3", "categories": ["cs.CL", "math.CT"], "primary_category": "cs.CL"}
{"title": "SeaD: End-to-end Text-to-SQL Generation with Schema-aware Denoising", "abstract": "In text-to-SQL task, seq-to-seq models often lead to sub-optimal performance\ndue to limitations in their architecture. In this paper, we present a simple\nyet effective approach that adapts transformer-based seq-to-seq model to robust\ntext-to-SQL generation. Instead of inducing constraint to decoder or reformat\nthe task as slot-filling, we propose to train seq-to-seq model with Schema\naware Denoising (SeaD), which consists of two denoising objectives that train\nmodel to either recover input or predict output from two novel erosion and\nshuffle noises. These denoising objectives acts as the auxiliary tasks for\nbetter modeling the structural data in S2S generation. In addition, we improve\nand propose a clause-sensitive execution guided (EG) decoding strategy to\novercome the limitation of EG decoding for generative model. The experiments\nshow that the proposed method improves the performance of seq-to-seq model in\nboth schema linking and grammar correctness and establishes new\nstate-of-the-art on WikiSQL benchmark. The results indicate that the capacity\nof vanilla seq-to-seq architecture for text-to-SQL may have been\nunder-estimated.", "published": "2021-05-17 14:49:54", "link": "http://arxiv.org/abs/2105.07911v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Supporting Context Monotonicity Abstractions in Neural NLI Models", "abstract": "Natural language contexts display logical regularities with respect to\nsubstitutions of related concepts: these are captured in a functional\norder-theoretic property called monotonicity. For a certain class of NLI\nproblems where the resulting entailment label depends only on the context\nmonotonicity and the relation between the substituted concepts, we build on\nprevious techniques that aim to improve the performance of NLI models for these\nproblems, as consistent performance across both upward and downward monotone\ncontexts still seems difficult to attain even for state-of-the-art models. To\nthis end, we reframe the problem of context monotonicity classification to make\nit compatible with transformer-based pre-trained NLI models and add this task\nto the training pipeline. Furthermore, we introduce a sound and complete\nsimplified monotonicity logic formalism which describes our treatment of\ncontexts as abstract units. Using the notions in our formalism, we adapt\ntargeted challenge sets to investigate whether an intermediate context\nmonotonicity classification task can aid NLI models' performance on examples\nexhibiting monotonicity reasoning.", "published": "2021-05-17 16:43:43", "link": "http://arxiv.org/abs/2105.08008v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Stage-wise Fine-tuning for Graph-to-Text Generation", "abstract": "Graph-to-text generation has benefited from pre-trained language models\n(PLMs) in achieving better performance than structured graph encoders. However,\nthey fail to fully utilize the structure information of the input graph. In\nthis paper, we aim to further improve the performance of the pre-trained\nlanguage model by proposing a structured graph-to-text model with a two-step\nfine-tuning mechanism which first fine-tunes the model on Wikipedia before\nadapting to the graph-to-text generation. In addition to using the traditional\ntoken and position embeddings to encode the knowledge graph (KG), we propose a\nnovel tree-level embedding method to capture the inter-dependency structures of\nthe input graph. This new approach has significantly improved the performance\nof all text generation metrics for the English WebNLG 2017 dataset.", "published": "2021-05-17 17:15:29", "link": "http://arxiv.org/abs/2105.08021v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SGD-QA: Fast Schema-Guided Dialogue State Tracking for Unseen Services", "abstract": "Dialogue state tracking is an essential part of goal-oriented dialogue\nsystems, while most of these state tracking models often fail to handle unseen\nservices. In this paper, we propose SGD-QA, a simple and extensible model for\nschema-guided dialogue state tracking based on a question answering approach.\nThe proposed multi-pass model shares a single encoder between the domain\ninformation and dialogue utterance. The domain's description represents the\nquery and the dialogue utterance serves as the context. The model improves\nperformance on unseen services by at least 1.6x compared to single-pass\nbaseline models on the SGD dataset. SGD-QA shows competitive performance\ncompared to state-of-the-art multi-pass models while being significantly more\nefficient in terms of memory consumption and training performance. We provide a\nthorough discussion on the model with ablation study and error analysis.", "published": "2021-05-17 17:54:32", "link": "http://arxiv.org/abs/2105.08049v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OntoEA: Ontology-guided Entity Alignment via Joint Knowledge Graph\n  Embedding", "abstract": "Semantic embedding has been widely investigated for aligning knowledge graph\n(KG) entities. Current methods have explored and utilized the graph structure,\nthe entity names and attributes, but ignore the ontology (or ontological\nschema) which contains critical meta information such as classes and their\nmembership relationships with entities. In this paper, we propose an\nontology-guided entity alignment method named OntoEA, where both KGs and their\nontologies are jointly embedded, and the class hierarchy and the class\ndisjointness are utilized to avoid false mappings. Extensive experiments on\nseven public and industrial benchmarks have demonstrated the state-of-the-art\nperformance of OntoEA and the effectiveness of the ontologies.", "published": "2021-05-17 09:18:56", "link": "http://arxiv.org/abs/2105.07688v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Fake News Detection: Are Models Learning to Reason?", "abstract": "Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.", "published": "2021-05-17 09:34:03", "link": "http://arxiv.org/abs/2105.07698v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Using social network and semantic analysis to analyze online travel\n  forums and forecast tourism demand", "abstract": "Forecasting tourism demand has important implications for both policy makers\nand companies operating in the tourism industry. In this research, we applied\nmethods and tools of social network and semantic analysis to study\nuser-generated content retrieved from online communities which interacted on\nthe TripAdvisor travel forum. We analyzed the forums of 7 major European\ncapital cities, over a period of 10 years, collecting more than 2,660,000\nposts, written by about 147,000 users. We present a new methodology of analysis\nof tourism-related big data and a set of variables which could be integrated\ninto traditional forecasting models. We implemented Factor Augmented\nAutoregressive and Bridge models with social network and semantic variables\nwhich often led to a better forecasting performance than univariate models and\nmodels based on Google Trend data. Forum language complexity and the\ncentralization of the communication network, i.e. the presence of eminent\ncontributors, were the variables that contributed more to the forecasting of\ninternational airport arrivals.", "published": "2021-05-17 10:54:23", "link": "http://arxiv.org/abs/2105.07727v1", "categories": ["econ.EM", "cs.CL", "cs.SI", "J.4; H.4.0; I.2.7"], "primary_category": "econ.EM"}
{"title": "Pay Attention to MLPs", "abstract": "Transformers have become one of the most important architectural innovations\nin deep learning and have enabled many breakthroughs over the past few years.\nHere we propose a simple network architecture, gMLP, based on MLPs with gating,\nand show that it can perform as well as Transformers in key language and vision\napplications. Our comparisons show that self-attention is not critical for\nVision Transformers, as gMLP can achieve the same accuracy. For BERT, our model\nachieves parity with Transformers on pretraining perplexity and is better on\nsome downstream NLP tasks. On finetuning tasks where gMLP performs worse,\nmaking the gMLP model substantially larger can close the gap with Transformers.\nIn general, our experiments show that gMLP can scale as well as Transformers\nover increased data and compute.", "published": "2021-05-17 17:55:04", "link": "http://arxiv.org/abs/2105.08050v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "MUSER: MUltimodal Stress Detection using Emotion Recognition as an\n  Auxiliary Task", "abstract": "The capability to automatically detect human stress can benefit artificial\nintelligent agents involved in affective computing and human-computer\ninteraction. Stress and emotion are both human affective states, and stress has\nproven to have important implications on the regulation and expression of\nemotion. Although a series of methods have been established for multimodal\nstress detection, limited steps have been taken to explore the underlying\ninter-dependence between stress and emotion. In this work, we investigate the\nvalue of emotion recognition as an auxiliary task to improve stress detection.\nWe propose MUSER -- a transformer-based model architecture and a novel\nmulti-task learning algorithm with speed-based dynamic sampling strategy.\nEvaluations on the Multimodal Stressed Emotion (MuSE) dataset show that our\nmodel is effective for stress detection with both internal and external\nauxiliary tasks, and achieves state-of-the-art results.", "published": "2021-05-17 20:24:46", "link": "http://arxiv.org/abs/2105.08146v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Social Behavior and Mental Health: A Snapshot Survey under COVID-19\n  Pandemic", "abstract": "Online social media provides a channel for monitoring people's social\nbehaviors and their mental distress. Due to the restrictions imposed by\nCOVID-19 people are increasingly using online social networks to express their\nfeelings. Consequently, there is a significant amount of diverse user-generated\nsocial media content. However, COVID-19 pandemic has changed the way we live,\nstudy, socialize and recreate and this has affected our well-being and mental\nhealth problems. There are growing researches that leverage online social media\nanalysis to detect and assess user's mental status. In this paper, we survey\nthe literature of social media analysis for mental disorders detection, with a\nspecial focus on the studies conducted in the context of COVID-19 during\n2020-2021. Firstly, we classify the surveyed studies in terms of feature\nextraction types, varying from language usage patterns to aesthetic preferences\nand online behaviors. Secondly, we explore detection methods used for mental\ndisorders detection including machine learning and deep learning detection\nmethods. Finally, we discuss the challenges of mental disorder detection using\nsocial media data, including the privacy and ethical concerns, as well as the\ntechnical challenges of scaling and deploying such systems at large scales, and\ndiscuss the learnt lessons over the last few years.", "published": "2021-05-17 21:08:03", "link": "http://arxiv.org/abs/2105.08165v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Studying the association of online brand importance with museum\n  visitors: An application of the semantic brand score", "abstract": "This paper explores the association between brand importance and growth in\nmuseum visitors. We analyzed 10 years of online forum discussions and applied\nthe Semantic Brand Score (SBS) to assess the brand importance of five European\nMuseums. Our Naive Bayes and regression models indicate that variations in the\ncombined dimensions of the SBS (prevalence, diversity and connectivity) are\naligned with changes in museum visitors. Results suggest that, in order to\nattract more visitors, museum brand managers should focus on increasing the\nvolume of online posting and the richness of information generated by users\naround the brand, rather than controlling for the posts' overall positivity or\nnegativity.", "published": "2021-05-17 11:49:30", "link": "http://arxiv.org/abs/2105.07749v1", "categories": ["cs.CL", "cs.SI", "econ.GN", "physics.soc-ph", "q-fin.EC", "I.2.7; J.4; H.4.0"], "primary_category": "cs.CL"}
{"title": "It\u00f4TTS and It\u00f4Wave: Linear Stochastic Differential Equation Is All\n  You Need For Audio Generation", "abstract": "In this paper, we propose to unify the two aspects of voice synthesis, namely\ntext-to-speech (TTS) and vocoder, into one framework based on a pair of forward\nand reverse-time linear stochastic differential equations (SDE). The solutions\nof this SDE pair are two stochastic processes, one of which turns the\ndistribution of mel spectrogram (or wave), that we want to generate, into a\nsimple and tractable distribution. The other is the generation procedure that\nturns this tractable simple signal into the target mel spectrogram (or wave).\nThe model that generates mel spectrogram is called It\\^oTTS, and the model that\ngenerates wave is called It\\^oWave. It\\^oTTS and It\\^oWave use the Wiener\nprocess as a driver to gradually subtract the excess signal from the noise\nsignal to generate realistic corresponding meaningful mel spectrogram and audio\nrespectively, under the conditional inputs of original text or mel spectrogram.\nThe results of the experiment show that the mean opinion scores (MOS) of\nIt\\^oTTS and It\\^oWave can exceed the current state-of-the-art methods, and\nreached 3.925$\\pm$0.160 and 4.35$\\pm$0.115 respectively. The generated audio\nsamples are available at https://wushoule.github.io/ItoAudio/. All authors\ncontribute equally to this work.", "published": "2021-05-17 02:46:15", "link": "http://arxiv.org/abs/2105.07583v5", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Event Detection with Adaptive Frequency Selection", "abstract": "In this work, we present HIDACT, a novel network architecture for adaptive\ncomputation for efficiently recognizing acoustic events. We evaluate the model\non a sound event detection task where we train it to adaptively process\nfrequency bands. The model learns to adapt to the input without requesting all\nfrequency sub-bands provided. It can make confident predictions within fewer\nprocessing steps, hence reducing the amount of computation. Experimental\nresults show that HIDACT has comparable performance to baseline models with\nmore parameters and higher computational complexity. Furthermore, the model can\nadjust the amount of computation based on the data and computational budget.", "published": "2021-05-17 03:57:33", "link": "http://arxiv.org/abs/2105.07596v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploring Self-Supervised Representation Ensembles for COVID-19 Cough\n  Classification", "abstract": "The usage of smartphone-collected respiratory sound, trained with deep\nlearning models, for detecting and classifying COVID-19 becomes popular\nrecently. It removes the need for in-person testing procedures especially for\nrural regions where related medical supplies, experienced workers, and\nequipment are limited. However, existing sound-based diagnostic approaches are\ntrained in a fully supervised manner, which requires large scale well-labelled\ndata. It is critical to discover new methods to leverage unlabelled respiratory\ndata, which can be obtained more easily. In this paper, we propose a novel\nself-supervised learning enabled framework for COVID-19 cough classification. A\ncontrastive pre-training phase is introduced to train a Transformer-based\nfeature encoder with unlabelled data. Specifically, we design a random masking\nmechanism to learn robust representations of respiratory sounds. The\npre-trained feature encoder is then fine-tuned in the downstream phase to\nperform cough classification. In addition, different ensembles with varied\nrandom masking rates are also explored in the downstream phase. Through\nextensive evaluations, we demonstrate that the proposed contrastive\npre-training, the random masking mechanism, and the ensemble architecture\ncontribute to improving cough classification performance.", "published": "2021-05-17 01:27:20", "link": "http://arxiv.org/abs/2105.07566v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dual-Stage Low-Complexity Reconfigurable Speech Enhancement", "abstract": "This paper proposes a dual-stage, low complexity, and reconfigurable\ntechnique to enhance the speech contaminated by various types of noise sources.\nDriven by input data and audio contents, the proposed dual-stage speech\nenhancement approach performs a coarse and fine processing in the first-stage\nand second-stage, respectively. In this paper, we demonstrate that the proposed\nspeech enhancement solution significantly enhances the metrics of 3-fold\nQUality Evaluation of Speech in Telecommunication (3QUEST) consisting of speech\nmean-opinion-score (SMOS) and noise MOS (NMOS) for near-field and far-field\napplications. Moreover, the proposed speech enhancement approach greatly\nimproves both the signal-to-noise ratio (SNR) and subjective listening\nexperience. For comparisons, the traditional speech enhancement methods reduce\nthe SMOS although they increase NMOS and SNR. In addition, the proposed speech\nenhancement scheme can be easily adopted in both capture path and speech render\npath for speech communication and conferencing systems, and voice-trigger\napplications.", "published": "2021-05-17 06:43:38", "link": "http://arxiv.org/abs/2105.07632v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Parallel and Flexible Sampling from Autoregressive Models via Langevin\n  Dynamics", "abstract": "This paper introduces an alternative approach to sampling from autoregressive\nmodels. Autoregressive models are typically sampled sequentially, according to\nthe transition dynamics defined by the model. Instead, we propose a sampling\nprocedure that initializes a sequence with white noise and follows a Markov\nchain defined by Langevin dynamics on the global log-likelihood of the\nsequence. This approach parallelizes the sampling process and generalizes to\nconditional sampling. Using an autoregressive model as a Bayesian prior, we can\nsteer the output of a generative model using a conditional likelihood or\nconstraints. We apply these techniques to autoregressive models in the visual\nand audio domains, with competitive results for audio source separation,\nsuper-resolution, and inpainting.", "published": "2021-05-17 21:07:02", "link": "http://arxiv.org/abs/2105.08164v2", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Point-based Acoustic Scattering for Interactive Sound Propagation via\n  Surface Encoding", "abstract": "We present a novel geometric deep learning method to compute the acoustic\nscattering properties of geometric objects. Our learning algorithm uses a point\ncloud representation of objects to compute the scattering properties and\nintegrates them with ray tracing for interactive sound propagation in dynamic\nscenes. We use discrete Laplacian-based surface encoders and approximate the\nneighborhood of each point using a shared multi-layer perceptron. We show that\nour formulation is permutation invariant and present a neural network that\ncomputes the scattering function using spherical harmonics. Our approach can\nhandle objects with arbitrary topologies and deforming models, and takes less\nthan 1ms per object on a commodity GPU. We have analyzed the accuracy and\nperform validation on thousands of unseen 3D objects and highlight the benefits\nover other point-based geometric deep learning methods. To the best of our\nknowledge, this is the first real-time learning algorithm that can approximate\nthe acoustic scattering properties of arbitrary objects with high accuracy.", "published": "2021-05-17 21:49:36", "link": "http://arxiv.org/abs/2105.08177v1", "categories": ["cs.SD", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Boombox: Visual Reconstruction from Acoustic Vibrations", "abstract": "Interacting with bins and containers is a fundamental task in robotics,\nmaking state estimation of the objects inside the bin critical. While robots\noften use cameras for state estimation, the visual modality is not always ideal\ndue to occlusions and poor illumination. We introduce The Boombox, a container\nthat uses sound to estimate the state of the contents inside a box. Based on\nthe observation that the collision between objects and its containers will\ncause an acoustic vibration, we present a convolutional network for learning to\nreconstruct visual scenes. Although we use low-cost and low-power contact\nmicrophones to detect the vibrations, our results show that learning from\nmultimodal data enables state estimation from affordable audio sensors. Due to\nthe many ways that robots use containers, we believe the box will have a number\nof applications in robotics. Our project website is at: boombox.cs.columbia.edu", "published": "2021-05-17 17:58:41", "link": "http://arxiv.org/abs/2105.08052v2", "categories": ["cs.CV", "cs.MM", "cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
