{"title": "Improving Neural Machine Translation by Denoising Training", "abstract": "We present a simple and effective pretraining strategy {D}en{o}ising\n{T}raining DoT for neural machine translation. Specifically, we update the\nmodel parameters with source- and target-side denoising tasks at the early\nstage and then tune the model normally. Notably, our approach does not increase\nany parameters or training steps, requiring the parallel data merely.\nExperiments show that DoT consistently improves the neural machine translation\nperformance across 12 bilingual and 16 multilingual directions (data size\nranges from 80K to 20M). In addition, we show that DoT can complement existing\ndata manipulation strategies, i.e. curriculum learning, knowledge distillation,\ndata diversification, bidirectional training, and back-translation.\nEncouragingly, we found that DoT outperforms costly pretrained model mBART in\nhigh-resource settings. Analyses show DoT is a novel in-domain cross-lingual\npretraining strategy and could offer further improvements with task-relevant\nself-supervisions.", "published": "2022-01-19 00:11:38", "link": "http://arxiv.org/abs/2201.07365v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpreting Arabic Transformer Models", "abstract": "Arabic is a Semitic language which is widely spoken with many dialects. Given\nthe success of pre-trained language models, many transformer models trained on\nArabic and its dialects have surfaced. While these models have been compared\nwith respect to downstream NLP tasks, no evaluation has been carried out to\ndirectly compare the internal representations. We probe how linguistic\ninformation is encoded in Arabic pretrained models, trained on different\nvarieties of Arabic language. We perform a layer and neuron analysis on the\nmodels using three intrinsic tasks: two morphological tagging tasks based on\nMSA (modern standard Arabic) and dialectal POS-tagging and a dialectal\nidentification task. Our analysis enlightens interesting findings such as: i)\nword morphology is learned at the lower and middle layers ii) dialectal\nidentification necessitate more knowledge and hence preserved even in the final\nlayers, iii) despite a large overlap in their vocabulary, the MSA-based models\nfail to capture the nuances of Arabic dialects, iv) we found that neurons in\nembedding layers are polysemous in nature, while the neurons in middle layers\nare exclusive to specific properties.", "published": "2022-01-19 06:32:25", "link": "http://arxiv.org/abs/2201.07434v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CM3: A Causal Masked Multimodal Model of the Internet", "abstract": "We introduce CM3, a family of causally masked generative models trained over\na large corpus of structured multi-modal documents that can contain both text\nand image tokens. Our new causally masked approach generates tokens left to\nright while also masking out a small number of long token spans that are\ngenerated at the end of the string, instead of their original positions. The\ncasual masking object provides a type of hybrid of the more common causal and\nmasked language models, by enabling full generative modeling while also\nproviding bidirectional context when generating the masked spans. We train\ncausally masked language-image models on large-scale web and Wikipedia\narticles, where each document contains all of the text, hypertext markup,\nhyperlinks, and image tokens (from a VQVAE-GAN), provided in the order they\nappear in the original HTML source (before masking). The resulting CM3 models\ncan generate rich structured, multi-modal outputs while conditioning on\narbitrary masked document contexts, and thereby implicitly learn a wide range\nof text, image, and cross modal tasks. They can be prompted to recover, in a\nzero-shot fashion, the functionality of models such as DALL-E, GENRE, and HTLM.\nWe set the new state-of-the-art in zero-shot summarization, entity linking, and\nentity disambiguation while maintaining competitive performance in the\nfine-tuning setting. We can generate images unconditionally, conditioned on\ntext (like DALL-E) and do captioning all in a zero-shot setting with a single\nmodel.", "published": "2022-01-19 10:45:38", "link": "http://arxiv.org/abs/2201.07520v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Machine Common Sense via Cloze Testing", "abstract": "Language models (LMs) show state of the art performance for common sense (CS)\nquestion answering, but whether this ability implies a human-level mastery of\nCS remains an open question. Understanding the limitations and strengths of LMs\ncan help researchers improve these models, potentially by developing novel ways\nof integrating external CS knowledge. We devise a series of tests and\nmeasurements to systematically quantify their performance on different aspects\nof CS. We propose the use of cloze testing combined with word embeddings to\nmeasure the LM's robustness and confidence. Our results show than although\nlanguage models tend to achieve human-like accuracy, their confidence is\nsubpar. Future work can leverage this information to build more complex\nsystems, such as an ensemble of symbolic and distributed knowledge.", "published": "2022-01-19 23:00:41", "link": "http://arxiv.org/abs/2201.07902v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fooling MOSS Detection with Pretrained Language Models", "abstract": "As artificial intelligence (AI) technologies become increasingly powerful and\nprominent in society, their misuse is a growing concern. In educational\nsettings, AI technologies could be used by students to cheat on assignments and\nexams. In this paper we explore whether transformers can be used to solve\nintroductory level programming assignments while bypassing commonly used AI\ntools to detect similarities between pieces of software. We find that a student\nusing GPT-J [Wang and Komatsuzaki, 2021] can complete introductory level\nprogramming assignments without triggering suspicion from MOSS [Aiken, 2000], a\nwidely used software similarity and plagiarism detection tool. This holds\ndespite the fact that GPT-J was not trained on the problems in question and is\nnot provided with any examples to work from. We further find that the code\nwritten by GPT-J is diverse in structure, lacking any particular tells that\nfuture plagiarism detection techniques may use to try to identify\nalgorithmically generated code. We conclude with a discussion of the ethical\nand educational implications of large language models and directions for future\nresearch.", "published": "2022-01-19 04:00:46", "link": "http://arxiv.org/abs/2201.07406v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Many Ways to Be Lonely: Fine-Grained Characterization of Loneliness and\n  Its Potential Changes in COVID-19", "abstract": "Loneliness has been associated with negative outcomes for physical and mental\nhealth. Understanding how people express and cope with various forms of\nloneliness is critical for early screening and targeted interventions to reduce\nloneliness, particularly among vulnerable groups such as young adults. To\nexamine how different forms of loneliness and coping strategies manifest in\nloneliness self-disclosure, we built a dataset, FIG-Loneliness (FIne-Grained\nLoneliness) by using Reddit posts in two young adult-focused forums and two\nloneliness related forums consisting of a diverse age group. We provided\nannotations by trained human annotators for binary and fine-grained loneliness\nclassifications of the posts. Trained on FIG-Loneliness, two BERT-based models\nwere used to understand loneliness forms and authors' coping strategies in\nthese forums. Our binary loneliness classification achieved an accuracy above\n97%, and fine-grained loneliness category classification reached an average\naccuracy of 77% across all labeled categories. With FIG-Loneliness and model\npredictions, we found that loneliness expressions in the young adults related\nforums were distinct from other forums. Those in young adult-focused forums\nwere more likely to express concerns pertaining to peer relationship, and were\npotentially more sensitive to geographical isolation impacted by the COVID-19\npandemic lockdown. Also, we showed that different forms of loneliness have\ndifferential use in coping strategies.", "published": "2022-01-19 05:22:55", "link": "http://arxiv.org/abs/2201.07423v5", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Development of Fake News Model using Machine Learning through Natural\n  Language Processing", "abstract": "Fake news detection research is still in the early stage as this is a\nrelatively new phenomenon in the interest raised by society. Machine learning\nhelps to solve complex problems and to build AI systems nowadays and especially\nin those cases where we have tacit knowledge or the knowledge that is not\nknown. We used machine learning algorithms and for identification of fake news;\nwe applied three classifiers; Passive Aggressive, Na\\\"ive Bayes, and Support\nVector Machine. Simple classification is not completely correct in fake news\ndetection because classification methods are not specialized for fake news.\nWith the integration of machine learning and text-based processing, we can\ndetect fake news and build classifiers that can classify the news data. Text\nclassification mainly focuses on extracting various features of text and after\nthat incorporating those features into classification. The big challenge in\nthis area is the lack of an efficient way to differentiate between fake and\nnon-fake due to the unavailability of corpora. We applied three different\nmachine learning classifiers on two publicly available datasets. Experimental\nanalysis based on the existing dataset indicates a very encouraging and\nimproved performance.", "published": "2022-01-19 09:26:15", "link": "http://arxiv.org/abs/2201.07489v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uncovering More Shallow Heuristics: Probing the Natural Language\n  Inference Capacities of Transformer-Based Pre-Trained Language Models Using\n  Syllogistic Patterns", "abstract": "In this article, we explore the shallow heuristics used by transformer-based\npre-trained language models (PLMs) that are fine-tuned for natural language\ninference (NLI). To do so, we construct or own dataset based on syllogistic,\nand we evaluate a number of models' performance on our dataset. We find\nevidence that the models rely heavily on certain shallow heuristics, picking up\non symmetries and asymmetries between premise and hypothesis. We suggest that\nthe lack of generalization observable in our study, which is becoming a topic\nof lively debate in the field, means that the PLMs are currently not learning\nNLI, but rather spurious heuristics.", "published": "2022-01-19 14:15:41", "link": "http://arxiv.org/abs/2201.07614v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Top-Down Influence? Predicting CEO Personality and Risk Impact from\n  Speech Transcripts", "abstract": "How much does a CEO's personality impact the performance of their company?\nManagement theory posits a great influence, but it is difficult to show\nempirically -- there is a lack of publicly available self-reported personality\ndata of top managers. Instead, we propose a text-based personality regressor\nusing crowd-sourced Myers--Briggs Type Indicator (MBTI) assessments. The\nratings have a high internal and external validity and can be predicted with\nmoderate to strong correlations for three out of four dimensions. Providing\nevidence for the upper echelons theory, we demonstrate that the predicted CEO\npersonalities have explanatory power of financial risk.", "published": "2022-01-19 15:49:07", "link": "http://arxiv.org/abs/2201.07670v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data-to-Value: An Evaluation-First Methodology for Natural Language\n  Projects", "abstract": "Big data, i.e. collecting, storing and processing of data at scale, has\nrecently been possible due to the arrival of clusters of commodity computers\npowered by application-level distributed parallel operating systems like\nHDFS/Hadoop/Spark, and such infrastructures have revolutionized data mining at\nscale. For data mining project to succeed more consistently, some methodologies\nwere developed (e.g. CRISP-DM, SEMMA, KDD), but these do not account for (1)\nvery large scales of processing, (2) dealing with textual (unstructured) data\n(i.e. Natural Language Processing (NLP, \"text analytics\"), and (3)\nnon-technical considerations (e.g. legal, ethical, project managerial aspects).\n  To address these shortcomings, a new methodology, called \"Data to Value\"\n(D2V), is introduced, which is guided by a detailed catalog of questions in\norder to avoid a disconnect of big data text analytics project team with the\ntopic when facing rather abstract box-and-arrow diagrams commonly associated\nwith methodologies.", "published": "2022-01-19 17:04:52", "link": "http://arxiv.org/abs/2201.07725v1", "categories": ["cs.CL", "stat.ME", "91B02, 68U15, 68T50, 62H99", "I.2.7; D.2.9; I.7.m; H.0"], "primary_category": "cs.CL"}
{"title": "Improving Biomedical Information Retrieval with Neural Retrievers", "abstract": "Information retrieval (IR) is essential in search engines and dialogue\nsystems as well as natural language processing tasks such as open-domain\nquestion answering. IR serve an important function in the biomedical domain,\nwhere content and sources of scientific knowledge may evolve rapidly. Although\nneural retrievers have surpassed traditional IR approaches such as TF-IDF and\nBM25 in standard open-domain question answering tasks, they are still found\nlacking in the biomedical domain. In this paper, we seek to improve information\nretrieval (IR) using neural retrievers (NR) in the biomedical domain, and\nachieve this goal using a three-pronged approach. First, to tackle the relative\nlack of data in the biomedical domain, we propose a template-based question\ngeneration method that can be leveraged to train neural retriever models.\nSecond, we develop two novel pre-training tasks that are closely aligned to the\ndownstream task of information retrieval. Third, we introduce the ``Poly-DPR''\nmodel which encodes each context into multiple context vectors. Extensive\nexperiments and analysis on the BioASQ challenge suggest that our proposed\nmethod leads to large gains over existing neural approaches and beats BM25 in\nthe small-corpus setting. We show that BM25 and our method can complement each\nother, and a simple hybrid model leads to further gains in the large corpus\nsetting.", "published": "2022-01-19 17:36:54", "link": "http://arxiv.org/abs/2201.07745v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "CPTAM: Constituency Parse Tree Aggregation Method", "abstract": "Diverse Natural Language Processing tasks employ constituency parsing to\nunderstand the syntactic structure of a sentence according to a phrase\nstructure grammar. Many state-of-the-art constituency parsers are proposed, but\nthey may provide different results for the same sentences, especially for\ncorpora outside their training domains. This paper adopts the truth discovery\nidea to aggregate constituency parse trees from different parsers by estimating\ntheir reliability in the absence of ground truth. Our goal is to consistently\nobtain high-quality aggregated constituency parse trees. We formulate the\nconstituency parse tree aggregation problem in two steps, structure aggregation\nand constituent label aggregation. Specifically, we propose the first truth\ndiscovery solution for tree structures by minimizing the weighted sum of\nRobinson-Foulds (RF) distances, a classic symmetric distance metric between two\ntrees. Extensive experiments are conducted on benchmark datasets in different\nlanguages and domains. The experimental results show that our method, CPTAM,\noutperforms the state-of-the-art aggregation baselines. We also demonstrate\nthat the weights estimated by CPTAM can adequately evaluate constituency\nparsers in the absence of ground truth.", "published": "2022-01-19 23:05:37", "link": "http://arxiv.org/abs/2201.07905v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TourBERT: A pretrained language model for the tourism industry", "abstract": "The Bidirectional Encoder Representations from Transformers (BERT) is\ncurrently one of the most important and state-of-the-art models for natural\nlanguage. However, it has also been shown that for domain-specific tasks it is\nhelpful to pretrain BERT on a domain-specific corpus. In this paper, we present\nTourBERT, a pretrained language model for tourism. We describe how TourBERT was\ndeveloped and evaluated. The evaluations show that TourBERT is outperforming\nBERT in all tourism-specific tasks.", "published": "2022-01-19 07:24:30", "link": "http://arxiv.org/abs/2201.07449v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Writing about COVID-19 vaccines: Emotional profiling unravels how\n  mainstream and alternative press framed AstraZeneca, Pfizer and vaccination\n  campaigns", "abstract": "Since their announcement in November 2020, COVID-19 vaccines were largely\ndebated by the press and social media. With most studies focusing on COVID-19\ndisinformation in social media, little attention has been paid to how\nmainstream news outlets framed COVID-19 narratives compared to alternative\nsources. To fill this gap, we use cognitive network science and natural\nlanguage processing to reconstruct time-evolving semantic and emotional frames\nof 5745 Italian news, that were massively re-shared on Facebook and Twitter,\nabout COVID-19 vaccines. We found consistently high levels of\ntrust/anticipation and less disgust in the way mainstream sources framed the\ngeneral idea of \"vaccine/vaccino\". These emotions were crucially missing in the\nways alternative sources framed COVID-19 vaccines. More differences were found\nwithin specific instances of vaccines. Alternative news included titles framing\nthe AstraZeneca vaccine with strong levels of sadness, absent in mainstream\ntitles. Mainstream news initially framed \"Pfizer\" along more negative\nassociations with side effects than \"AstraZeneca\". With the temporary\nsuspension of the latter, on March 15th 2021, we identified a\nsemantic/emotional shift: Even mainstream article titles framed \"AstraZeneca\"\nas semantically richer in negative associations with side effects, while\n\"Pfizer\" underwent a positive shift in valence, mostly related to its higher\nefficacy. \"Thrombosis\" entered the frame of vaccines together with fearful\nconceptual associations, while \"death\" underwent an emotional shift, steering\ntowards fear in alternative titles and losing its hopeful connotation in\nmainstream titles. Our findings expose crucial aspects of the emotional\nnarratives around COVID-19 vaccines adopted by the press, highlighting the need\nto understand how alternative and mainstream media report vaccination news.", "published": "2022-01-19 11:31:47", "link": "http://arxiv.org/abs/2201.07538v1", "categories": ["cs.CY", "cs.CL", "cs.SI", "physics.soc-ph", "K.4"], "primary_category": "cs.CY"}
{"title": "Unsupervised Personalization of an Emotion Recognition System: The\n  Unique Properties of the Externalization of Valence in Speech", "abstract": "The prediction of valence from speech is an important, but challenging\nproblem. The externalization of valence in speech has speaker-dependent cues,\nwhich contribute to performances that are often significantly lower than the\nprediction of other emotional attributes such as arousal and dominance. A\npractical approach to improve valence prediction from speech is to adapt the\nmodels to the target speakers in the test set. Adapting a speech emotion\nrecognition (SER) system to a particular speaker is a hard problem, especially\nwith deep neural networks (DNNs), since it requires optimizing millions of\nparameters. This study proposes an unsupervised approach to address this\nproblem by searching for speakers in the train set with similar acoustic\npatterns as the speaker in the test set. Speech samples from the selected\nspeakers are used to create the adaptation set. This approach leverages\ntransfer learning using pre-trained models, which are adapted with these speech\nsamples. We propose three alternative adaptation strategies: unique speaker,\noversampling and weighting approaches. These methods differ on the use of the\nadaptation set in the personalization of the valence models. The results\ndemonstrate that a valence prediction model can be efficiently personalized\nwith these unsupervised approaches, leading to relative improvements as high as\n13.52%.", "published": "2022-01-19 22:14:49", "link": "http://arxiv.org/abs/2201.07876v1", "categories": ["cs.SD", "cs.CL", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ASL Video Corpora & Sign Bank: Resources Available through the American\n  Sign Language Linguistic Research Project (ASLLRP)", "abstract": "The American Sign Language Linguistic Research Project (ASLLRP) provides\nInternet access to high-quality ASL video data, generally including front and\nside views and a close-up of the face. The manual and non-manual components of\nthe signing have been linguistically annotated using SignStream(R). The\nrecently expanded video corpora can be browsed and searched through the Data\nAccess Interface (DAI 2) we have designed; it is possible to carry out complex\nsearches. The data from our corpora can also be downloaded; annotations are\navailable in an XML export format. We have also developed the ASLLRP Sign Bank,\nwhich contains almost 6,000 sign entries for lexical signs, with distinct\nEnglish-based glosses, with a total of 41,830 examples of lexical signs (in\naddition to about 300 gestures, over 1,000 fingerspelled signs, and 475\nclassifier examples). The Sign Bank is likewise accessible and searchable on\nthe Internet; it can also be accessed from within SignStream(R) (software to\nfacilitate linguistic annotation and analysis of visual language data) to make\nannotations more accurate and efficient. Here we describe the available\nresources. These data have been used for many types of research in linguistics\nand in computer-based sign language recognition from video; examples of such\nresearch are provided in the latter part of this article.", "published": "2022-01-19 22:48:36", "link": "http://arxiv.org/abs/2201.07899v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GAP-Gen: Guided Automatic Python Code Generation", "abstract": "Automatic code generation from natural language descriptions can be highly\nbeneficial during the process of software development. In this work, we propose\nGAP-Gen, a Guided Automatic Python Code Generation method based on Python\nsyntactic constraints and semantic constraints. We first introduce Python\nsyntactic constraints in the form of Syntax-Flow, which is a simplified version\nof Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract\nSyntax Tree but maintaining crucial syntactic information of Python code. In\naddition to Syntax-Flow, we introduce Variable-Flow which abstracts variable\nand function names consistently through out the code. In our work, rather than\npretraining, we focus on modifying the finetuning process which reduces\ncomputational requirements but retains high generation performance on automatic\nPython code generation task. GAP-Gen fine-tunes the transformer based language\nmodels T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet,\nCodeSearchNet AdvTest and Code-Docstring Corpus from EdinburghNLP. Our\nexperiments show that GAP-Gen achieves better results on automatic Python code\ngeneration task than previous works.", "published": "2022-01-19 06:32:47", "link": "http://arxiv.org/abs/2201.08810v2", "categories": ["cs.PL", "cs.CL", "cs.LG", "cs.SE"], "primary_category": "cs.PL"}
{"title": "MHTTS: Fast multi-head text-to-speech for spontaneous speech with\n  imperfect transcription", "abstract": "Neural network based end-to-end Text-to-Speech (TTS) has greatly improved the\nquality of synthesized speech. While how to use massive spontaneous speech\nwithout transcription efficiently still remains an open problem. In this paper,\nwe propose MHTTS, a fast multi-speaker TTS system that is robust to\ntranscription errors and speaking style speech data. Specifically, we introduce\na multi-head model and transfer text information from high-quality corpus with\nmanual transcription to spontaneous speech with imperfectly recognized\ntranscription by jointly training them. MHTTS has three advantages: 1) Our\nsystem synthesizes better quality multi-speaker voice with faster inference\nspeed. 2) Our system is capable of transferring correct text information to\ndata with imperfect transcription, simulated using corruption, or provided by\nan Automatic Speech Recogniser (ASR). 3) Our system can utilize massive real\nspontaneous speech with imperfect transcription and synthesize expressive\nvoice.", "published": "2022-01-19 06:39:00", "link": "http://arxiv.org/abs/2201.07438v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for\n  Singing Voice Synthesis", "abstract": "This paper introduces Opencpop, a publicly available high-quality Mandarin\nsinging corpus designed for singing voice synthesis (SVS). The corpus consists\nof 100 popular Mandarin songs performed by a female professional singer. Audio\nfiles are recorded with studio quality at a sampling rate of 44,100 Hz and the\ncorresponding lyrics and musical scores are provided. All singing recordings\nhave been phonetically annotated with phoneme boundaries and syllable (note)\nboundaries. To demonstrate the reliability of the released data and to provide\na baseline for future research, we built baseline deep neural network-based SVS\nmodels and evaluated them with both objective metrics and subjective mean\nopinion score (MOS) measure. Experimental results show that the best SVS model\ntrained on our database achieves 3.70 MOS, indicating the reliability of the\nprovided corpus. Opencpop is released to the open-source community WeNet, and\nthe corpus, as well as synthesized demos, can be found on the project homepage.", "published": "2022-01-19 06:12:47", "link": "http://arxiv.org/abs/2201.07429v2", "categories": ["cs.SD", "cs.DB", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Tiny, always-on and fragile: Bias propagation through design choices in\n  on-device machine learning workflows", "abstract": "Billions of distributed, heterogeneous and resource constrained IoT devices\ndeploy on-device machine learning (ML) for private, fast and offline inference\non personal data. On-device ML is highly context dependent, and sensitive to\nuser, usage, hardware and environment attributes. This sensitivity and the\npropensity towards bias in ML makes it important to study bias in on-device\nsettings. Our study is one of the first investigations of bias in this emerging\ndomain, and lays important foundations for building fairer on-device ML. We\napply a software engineering lens, investigating the propagation of bias\nthrough design choices in on-device ML workflows. We first identify reliability\nbias as a source of unfairness and propose a measure to quantify it. We then\nconduct empirical experiments for a keyword spotting task to show how complex\nand interacting technical design choices amplify and propagate reliability\nbias. Our results validate that design choices made during model training, like\nthe sample rate and input feature type, and choices made to optimize models,\nlike light-weight architectures, the pruning learning rate and pruning\nsparsity, can result in disparate predictive performance across male and female\ngroups. Based on our findings we suggest low effort strategies for engineers to\nmitigate bias in on-device ML.", "published": "2022-01-19 15:59:41", "link": "http://arxiv.org/abs/2201.07677v4", "categories": ["cs.LG", "cs.CY", "cs.SE", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation", "abstract": "Animating high-fidelity video portrait with speech audio is crucial for\nvirtual reality and digital entertainment. While most previous studies rely on\naccurate explicit structural information, recent works explore the implicit\nscene representation of Neural Radiance Fields (NeRF) for realistic generation.\nIn order to capture the inconsistent motions as well as the semantic difference\nbetween human head and torso, some work models them via two individual sets of\nNeRF, leading to unnatural results. In this work, we propose Semantic-aware\nSpeaking Portrait NeRF (SSP-NeRF), which creates delicate audio-driven\nportraits using one unified set of NeRF. The proposed model can handle the\ndetailed local facial semantics and the global head-torso relationship through\ntwo semantic-aware modules. Specifically, we first propose a Semantic-Aware\nDynamic Ray Sampling module with an additional parsing branch that facilitates\naudio-driven volume rendering. Moreover, to enable portrait rendering in one\nunified neural radiance field, a Torso Deformation module is designed to\nstabilize the large-scale non-rigid torso motions. Extensive evaluations\ndemonstrate that our proposed approach renders more realistic video portraits\ncompared to previous methods. Project page:\nhttps://alvinliu0.github.io/projects/SSP-NeRF", "published": "2022-01-19 18:54:41", "link": "http://arxiv.org/abs/2201.07786v1", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
