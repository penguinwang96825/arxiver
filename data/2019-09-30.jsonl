{"title": "Semantic Graph Parsing with Recurrent Neural Network DAG Grammars", "abstract": "Semantic parses are directed acyclic graphs (DAGs), so semantic parsing\nshould be modeled as graph prediction. But predicting graphs presents difficult\ntechnical challenges, so it is simpler and more common to predict the\nlinearized graphs found in semantic parsing datasets using well-understood\nsequence models. The cost of this simplicity is that the predicted strings may\nnot be well-formed graphs. We present recurrent neural network DAG grammars, a\ngraph-aware sequence model that ensures only well-formed graphs while\nsidestepping many difficulties in graph prediction. We test our model on the\nParallel Meaning Bank---a multilingual semantic graphbank. Our approach yields\ncompetitive results in English and establishes the first results for German,\nItalian and Dutch.", "published": "2019-09-30 18:39:08", "link": "http://arxiv.org/abs/1910.00051v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical Features Are More Vulnerable, Syntactic Features Have More\n  Predictive Power", "abstract": "Understanding the vulnerability of linguistic features extracted from noisy\ntext is important for both developing better health text classification models\nand for interpreting vulnerabilities of natural language models. In this paper,\nwe investigate how generic language characteristics, such as syntax or the\nlexicon, are impacted by artificial text alterations. The vulnerability of\nfeatures is analysed from two perspectives: (1) the level of feature value\nchange, and (2) the level of change of feature predictive power as a result of\ntext modifications. We show that lexical features are more sensitive to text\nmodifications than syntactic ones. However, we also demonstrate that these\nsmaller changes of syntactic features have a stronger influence on\nclassification performance downstream, compared to the impact of changes to\nlexical features. Results are validated across three datasets representing\ndifferent text-classification tasks, with different levels of lexical and\nsyntactic complexity of both conversational and written language.", "published": "2019-09-30 19:34:45", "link": "http://arxiv.org/abs/1910.00065v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interrogating the Explanatory Power of Attention in Neural Machine\n  Translation", "abstract": "Attention models have become a crucial component in neural machine\ntranslation (NMT). They are often implicitly or explicitly used to justify the\nmodel's decision in generating a specific token but it has not yet been\nrigorously established to what extent attention is a reliable source of\ninformation in NMT. To evaluate the explanatory power of attention for NMT, we\nexamine the possibility of yielding the same prediction but with counterfactual\nattention models that modify crucial aspects of the trained attention model.\nUsing these counterfactual attention mechanisms we assess the extent to which\nthey still preserve the generation of function and content words in the\ntranslation process. Compared to a state of the art attention model, our\ncounterfactual attention models produce 68% of function words and 21% of\ncontent words in our German-English dataset. Our experiments demonstrate that\nattention models by themselves cannot reliably explain the decisions made by a\nNMT model.", "published": "2019-09-30 22:30:56", "link": "http://arxiv.org/abs/1910.00139v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and\n  Strategic Dialog History", "abstract": "We study non-collaborative dialogs, where two agents have a conflict of\ninterest but must strategically communicate to reach an agreement (e.g.,\nnegotiation). This setting poses new challenges for modeling dialog history\nbecause the dialog's outcome relies not only on the semantic intent, but also\non tactics that convey the intent. We propose to model both semantic and tactic\nhistory using finite state transducers (FSTs). Unlike RNN, FSTs can explicitly\nrepresent dialog history through all the states traversed, facilitating\ninterpretability of dialog structure. We train FSTs on a set of strategies and\ntactics used in negotiation dialogs. The trained FSTs show plausible tactic\nstructure and can be generalized to other non-collaborative domains (e.g.,\npersuasion). We evaluate the FSTs by incorporating them in an automated\nnegotiating system that attempts to sell products and a persuasion system that\npersuades people to donate to a charity. Experiments show that explicitly\nmodeling both semantic and tactic history is an effective way to improve both\ndialog policy planning and generation performance.", "published": "2019-09-30 02:08:47", "link": "http://arxiv.org/abs/1909.13425v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Dynamic Strategy Coach for Effective Negotiation", "abstract": "Negotiation is a complex activity involving strategic reasoning, persuasion,\nand psychology. An average person is often far from an expert in negotiation.\nOur goal is to assist humans to become better negotiators through a\nmachine-in-the-loop approach that combines machine's advantage at data-driven\ndecision-making and human's language generation ability. We consider a\nbargaining scenario where a seller and a buyer negotiate the price of an item\nfor sale through a text-based dialog. Our negotiation coach monitors messages\nbetween them and recommends tactics in real time to the seller to get a better\ndeal (e.g., \"reject the proposal and propose a price\", \"talk about your\npersonal experience with the product\"). The best strategy and tactics largely\ndepend on the context (e.g., the current price, the buyer's attitude).\nTherefore, we first identify a set of negotiation tactics, then learn to\npredict the best strategy and tactics in a given dialog context from a set of\nhuman-human bargaining dialogs. Evaluation on human-human dialogs shows that\nour coach increases the profits of the seller by almost 60%.", "published": "2019-09-30 02:15:29", "link": "http://arxiv.org/abs/1909.13426v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Regressing Word and Sentence Embeddings for Regularization of Neural\n  Machine Translation", "abstract": "In recent years, neural machine translation (NMT) has become the dominant\napproach in automated translation. However, like many other deep learning\napproaches, NMT suffers from overfitting when the amount of training data is\nlimited. This is a serious issue for low-resource language pairs and many\nspecialized translation domains that are inherently limited in the amount of\navailable supervised data. For this reason, in this paper we propose regressing\nword (ReWE) and sentence (ReSE) embeddings at training time as a way to\nregularize NMT models and improve their generalization. During training, our\nmodels are trained to jointly predict categorical (words in the vocabulary) and\ncontinuous (word and sentence embeddings) outputs. An extensive set of\nexperiments over four language pairs of variable training set size has showed\nthat ReWE and ReSE can outperform strong state-of-the-art baseline models, with\nan improvement that is larger for smaller training sets (e.g., up to +5:15 BLEU\npoints in Basque-English translation). Visualizations of the decoder's output\nspace show that the proposed regularizers improve the clustering of unique\nwords, facilitating correct predictions. In a final experiment on unsupervised\nNMT, we show that ReWE and ReSE are also able to improve the quality of machine\ntranslation when no parallel data are available.", "published": "2019-09-30 05:55:06", "link": "http://arxiv.org/abs/1909.13466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Critique of the Smooth Inverse Frequency Sentence Embeddings", "abstract": "We critically review the smooth inverse frequency sentence embedding method\nof Arora, Liang, and Ma (2017), and show inconsistencies in its setup,\nderivation, and evaluation.", "published": "2019-09-30 07:38:25", "link": "http://arxiv.org/abs/1909.13494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Closer Look at Data Bias in Neural Extractive Summarization Models", "abstract": "In this paper, we take stock of the current state of summarization datasets\nand explore how different factors of datasets influence the generalization\nbehaviour of neural extractive summarization models. Specifically, we first\npropose several properties of datasets, which matter for the generalization of\nsummarization models. Then we build the connection between priors residing in\ndatasets and model designs, analyzing how different properties of datasets\ninfluence the choices of model structure design and training methods. Finally,\nby taking a typical dataset as an example, we rethink the process of the model\ndesign based on the experience of the above analysis. We demonstrate that when\nwe have a deep understanding of the characteristics of datasets, a simple\napproach can bring significant improvements to the existing state-of-the-art\nmodel.A", "published": "2019-09-30 13:55:10", "link": "http://arxiv.org/abs/1909.13705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Fact-guided Sentence Modification", "abstract": "Online encyclopediae like Wikipedia contain large amounts of text that need\nfrequent corrections and updates. The new information may contradict existing\ncontent in encyclopediae. In this paper, we focus on rewriting such dynamically\nchanging articles. This is a challenging constrained generation task, as the\noutput must be consistent with the new information and fit into the rest of the\nexisting document. To this end, we propose a two-step solution: (1) We identify\nand remove the contradicting components in a target text for a given claim,\nusing a neutralizing stance model; (2) We expand the remaining text to be\nconsistent with the given claim, using a novel two-encoder sequence-to-sequence\nmodel with copy attention. Applied to a Wikipedia fact update dataset, our\nmethod successfully generates updated sentences for new claims, achieving the\nhighest SARI score. Furthermore, we demonstrate that generating synthetic data\nthrough such rewritten sentences can successfully augment the FEVER\nfact-checking training dataset, leading to a relative error reduction of 13%.", "published": "2019-09-30 17:02:57", "link": "http://arxiv.org/abs/1909.13838v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Universal Decompositional Semantics Dataset and Decomp Toolkit", "abstract": "We present the Universal Decompositional Semantics (UDS) dataset (v1.0),\nwhich is bundled with the Decomp toolkit (v0.1). UDS1.0 unifies five\nhigh-quality, decompositional semantics-aligned annotation sets within a single\nsemantic graph specification---with graph structures defined by the predicative\npatterns produced by the PredPatt tool and real-valued node and edge attributes\nconstructed using sophisticated normalization procedures. The Decomp toolkit\nprovides a suite of Python 3 tools for querying UDS graphs using SPARQL. Both\nUDS1.0 and Decomp0.1 are publicly available at http://decomp.io.", "published": "2019-09-30 17:15:57", "link": "http://arxiv.org/abs/1909.13851v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple and Effective Paraphrastic Similarity from Parallel Translations", "abstract": "We present a model and methodology for learning paraphrastic sentence\nembeddings directly from bitext, removing the time-consuming intermediate step\nof creating paraphrase corpora. Further, we show that the resulting model can\nbe applied to cross-lingual tasks where it both outperforms and is orders of\nmagnitude faster than more complex state-of-the-art baselines.", "published": "2019-09-30 17:54:50", "link": "http://arxiv.org/abs/1909.13872v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Head Attention with Diversity for Learning Grounded Multilingual\n  Multimodal Representations", "abstract": "With the aim of promoting and understanding the multilingual version of image\nsearch, we leverage visual object detection and propose a model with diverse\nmulti-head attention to learn grounded multilingual multimodal representations.\nSpecifically, our model attends to different types of textual semantics in two\nlanguages and visual objects for fine-grained alignments between sentences and\nimages. We introduce a new objective function which explicitly encourages\nattention diversity to learn an improved visual-semantic embedding space. We\nevaluate our model in the German-Image and English-Image matching tasks on the\nMulti30K dataset, and in the Semantic Textual Similarity task with the English\ndescriptions of visual content. Results show that our model yields a\nsignificant performance gain over other methods in all of the three tasks.", "published": "2019-09-30 18:58:03", "link": "http://arxiv.org/abs/1910.00058v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Generating Diverse Story Continuations with Controllable Semantics", "abstract": "We propose a simple and effective modeling framework for controlled\ngeneration of multiple, diverse outputs. We focus on the setting of generating\nthe next sentence of a story given its context. As controllable dimensions, we\nconsider several sentence attributes, including sentiment, length, predicates,\nframes, and automatically-induced clusters. Our empirical results demonstrate:\n(1) our framework is accurate in terms of generating outputs that match the\ntarget control values; (2) our model yields increased maximum metric scores\ncompared to standard n-best list generation via beam search; (3) controlling\ngeneration with semantic frames leads to a stronger combination of diversity\nand quality than other control variables as measured by automatic metrics. We\nalso conduct a human evaluation to assess the utility of providing multiple\nsuggestions for creative writing, demonstrating promising results for the\npotential of controllable, diverse generation in a collaborative writing\nsystem.", "published": "2019-09-30 02:40:48", "link": "http://arxiv.org/abs/1909.13434v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Hybrid Persian Sentiment Analysis Framework: Integrating Dependency\n  Grammar Based Rules and Deep Neural Networks", "abstract": "Social media hold valuable, vast and unstructured information on public\nopinion that can be utilized to improve products and services. The automatic\nanalysis of such data, however, requires a deep understanding of natural\nlanguage. Current sentiment analysis approaches are mainly based on word\nco-occurrence frequencies, which are inadequate in most practical cases. In\nthis work, we propose a novel hybrid framework for concept-level sentiment\nanalysis in Persian language, that integrates linguistic rules and deep\nlearning to optimize polarity detection. When a pattern is triggered, the\nframework allows sentiments to flow from words to concepts based on symbolic\ndependency relations. When no pattern is triggered, the framework switches to\nits subsymbolic counterpart and leverages deep neural networks (DNN) to perform\nthe classification. The proposed framework outperforms state-of-the-art\napproaches (including support vector machine, and logistic regression) and DNN\nclassifiers (long short-term memory, and Convolutional Neural Networks) with a\nmargin of 10-15% and 3-4% respectively, using benchmark Persian product and\nhotel reviews corpora.", "published": "2019-09-30 10:29:45", "link": "http://arxiv.org/abs/1909.13568v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Importance of the Kullback-Leibler Divergence Term in Variational\n  Autoencoders for Text Generation", "abstract": "Variational Autoencoders (VAEs) are known to suffer from learning\nuninformative latent representation of the input due to issues such as\napproximated posterior collapse, or entanglement of the latent space. We impose\nan explicit constraint on the Kullback-Leibler (KL) divergence term inside the\nVAE objective function. While the explicit constraint naturally avoids\nposterior collapse, we use it to further understand the significance of the KL\nterm in controlling the information transmitted through the VAE channel. Within\nthis framework, we explore different properties of the estimated posterior\ndistribution, and highlight the trade-off between the amount of information\nencoded in a latent code during training, and the generative capacity of the\nmodel.", "published": "2019-09-30 13:05:55", "link": "http://arxiv.org/abs/1909.13668v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrieval-based Goal-Oriented Dialogue Generation", "abstract": "Most research on dialogue has focused either on dialogue generation for\nopenended chit chat or on state tracking for goal-directed dialogue. In this\nwork, we explore a hybrid approach to goal-oriented dialogue generation that\ncombines retrieval from past history with a hierarchical, neural\nencoder-decoder architecture. We evaluate this approach in the customer support\ndomain using the Multiwoz dataset (Budzianowski et al., 2018). We show that\nadding this retrieval step to a hierarchical, neural encoder-decoder\narchitecture leads to significant improvements, including responses that are\nrated more appropriate and fluent by human evaluators. Finally, we compare our\nretrieval-based model to various semantically conditioned models explicitly\nusing past dialog act information, and find that our proposed model is\ncompetitive with the current state of the art (Chen et al., 2019), while not\nrequiring explicit labels about past machine acts.", "published": "2019-09-30 14:02:53", "link": "http://arxiv.org/abs/1909.13717v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Diverse Paraphrase Generation Using Multi-Class Wasserstein GAN", "abstract": "Paraphrase generation is an important and challenging natural language\nprocessing (NLP) task. In this work, we propose a deep generative model to\ngenerate paraphrase with diversity. Our model is based on an encoder-decoder\narchitecture. An additional transcoder is used to convert a sentence into its\nparaphrasing latent code. The transcoder takes an explicit pattern embedding\nvariable as condition, so diverse paraphrase can be generated by sampling on\nthe pattern embedding variable. We use a Wasserstein GAN to align the\ndistributions of the real and generated paraphrase samples. We propose a\nmulti-class extension to the Wasserstein GAN, which allows our generative model\nto learn from both positive and negative samples. The generated paraphrase\ndistribution is forced to get closer to the positive real distribution, and be\npushed away from the negative distribution in Wasserstein distance. We test our\nmodel in two datasets with both automatic metrics and human evaluation. Results\nshow that our model can generate fluent and reliable paraphrase samples that\noutperform the state-of-art results, while also provides reasonable variability\nand diversity.", "published": "2019-09-30 16:40:15", "link": "http://arxiv.org/abs/1909.13827v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Attention Networks for Fine-Grained Opinion Mining and\n  Public Health", "abstract": "In many review classification applications, a fine-grained analysis of the\nreviews is desirable, because different segments (e.g., sentences) of a review\nmay focus on different aspects of the entity in question. However, training\nsupervised models for segment-level classification requires segment labels,\nwhich may be more difficult or expensive to obtain than review labels. In this\npaper, we employ Multiple Instance Learning (MIL) and use only weak supervision\nin the form of a single label per review. First, we show that when\ninappropriate MIL aggregation functions are used, then MIL-based networks are\noutperformed by simpler baselines. Second, we propose a new aggregation\nfunction based on the sigmoid attention mechanism and show that our proposed\nmodel outperforms the state-of-the-art models for segment-level sentiment\nclassification (by up to 9.8% in F1). Finally, we highlight the importance of\nfine-grained predictions in an important public-health application: finding\nactionable reports of foodborne illness. We show that our model achieves 48.6%\nhigher recall compared to previous models, thus increasing the chance of\nidentifying previously unknown foodborne outbreaks.", "published": "2019-09-30 18:40:59", "link": "http://arxiv.org/abs/1910.00054v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Contextual Graph Attention for Answering Logical Queries over Incomplete\n  Knowledge Graphs", "abstract": "Recently, several studies have explored methods for using KG embedding to\nanswer logical queries. These approaches either treat embedding learning and\nquery answering as two separated learning tasks, or fail to deal with the\nvariability of contributions from different query paths. We proposed to\nleverage a graph attention mechanism to handle the unequal contribution of\ndifferent query paths. However, commonly used graph attention assumes that the\ncenter node embedding is provided, which is unavailable in this task since the\ncenter node is to be predicted. To solve this problem we propose a multi-head\nattention-based end-to-end logical query answering model, called Contextual\nGraph Attention model(CGA), which uses an initial neighborhood aggregation\nlayer to generate the center embedding, and the whole model is trained jointly\non the original KG structure as well as the sampled query-answer pairs. We also\nintroduce two new datasets, DB18 and WikiGeo19, which are rather large in size\ncompared to the existing datasets and contain many more relation types, and use\nthem to evaluate the performance of the proposed model. Our result shows that\nthe proposed CGA with fewer learnable parameters consistently outperforms the\nbaseline models on both datasets as well as Bio dataset.", "published": "2019-09-30 20:20:48", "link": "http://arxiv.org/abs/1910.00084v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML", "I.2.4; I.1.3"], "primary_category": "cs.LG"}
{"title": "Towards Controllable and Personalized Review Generation", "abstract": "In this paper, we propose a novel model RevGAN that automatically generates\ncontrollable and personalized user reviews based on the arbitrarily given\nsentimental and stylistic information. RevGAN utilizes the combination of three\nnovel components, including self-attentive recursive autoencoders, conditional\ndiscriminators, and personalized decoders. We test its performance on the\nseveral real-world datasets, where our model significantly outperforms\nstate-of-the-art generation models in terms of sentence quality, coherence,\npersonalization and human evaluations. We also empirically show that the\ngenerated reviews could not be easily distinguished from the organically\nproduced reviews and that they follow the same statistical linguistics laws.", "published": "2019-09-30 19:12:10", "link": "http://arxiv.org/abs/1910.03506v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Hotel2vec: Learning Attribute-Aware Hotel Embeddings with\n  Self-Supervision", "abstract": "We propose a neural network architecture for learning vector representations\nof hotels. Unlike previous works, which typically only use user click\ninformation for learning item embeddings, we propose a framework that combines\nseveral sources of data, including user clicks, hotel attributes (e.g.,\nproperty type, star rating, average user rating), amenity information (e.g.,\nthe hotel has free Wi-Fi or free breakfast), and geographic information. During\nmodel training, a joint embedding is learned from all of the above information.\nWe show that including structured attributes about hotels enables us to make\nbetter predictions in a downstream task than when we rely exclusively on click\ndata. We train our embedding model on more than 40 million user click sessions\nfrom a leading online travel platform and learn embeddings for more than one\nmillion hotels. Our final learned embeddings integrate distinct sub-embeddings\nfor user clicks, hotel attributes, and geographic information, providing an\ninterpretable representation that can be used flexibly depending on the\napplication. We show empirically that our model generates high-quality\nrepresentations that boost the performance of a hotel recommendation system in\naddition to other applications. An important advantage of the proposed neural\nmodel is that it addresses the cold-start problem for hotels with insufficient\nhistorical click information by incorporating additional hotel attributes which\nare available for all hotels.", "published": "2019-09-30 23:47:55", "link": "http://arxiv.org/abs/1910.03943v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "DiPCo -- Dinner Party Corpus", "abstract": "We present a speech data corpus that simulates a \"dinner party\" scenario\ntaking place in an everyday home environment. The corpus was created by\nrecording multiple groups of four Amazon employee volunteers having a natural\nconversation in English around a dining table. The participants were recorded\nby a single-channel close-talk microphone and by five far-field 7-microphone\narray devices positioned at different locations in the recording room. The\ndataset contains the audio recordings and human labeled transcripts of a total\nof 10 sessions with a duration between 15 and 45 minutes. The corpus was\ncreated to advance in the field of noise robust and distant speech processing\nand is intended to serve as a public research and benchmarking data set.", "published": "2019-09-30 04:15:59", "link": "http://arxiv.org/abs/1909.13447v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Textual Network Learning with Variational Homophilic\n  Embeddings", "abstract": "The performance of many network learning applications crucially hinges on the\nsuccess of network embedding algorithms, which aim to encode rich network\ninformation into low-dimensional vertex-based vector representations. This\npaper considers a novel variational formulation of network embeddings, with\nspecial focus on textual networks. Different from most existing methods that\noptimize a discriminative objective, we introduce Variational Homophilic\nEmbedding (VHE), a fully generative model that learns network embeddings by\nmodeling the semantic (textual) information with a variational autoencoder,\nwhile accounting for the structural (topology) information through a novel\nhomophilic prior design. Homophilic vertex embeddings encourage similar\nembedding vectors for related (connected) vertices. The proposed VHE promises\nbetter generalization for downstream tasks, robustness to incomplete\nobservations, and the ability to generalize to unseen vertices. Extensive\nexperiments on real-world networks, for multiple tasks, demonstrate that the\nproposed method consistently achieves superior performance relative to\ncompeting state-of-the-art approaches.", "published": "2019-09-30 05:03:25", "link": "http://arxiv.org/abs/1909.13456v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Embeddings for DNN speaker adaptive training", "abstract": "In this work, we investigate the use of embeddings for speaker-adaptive\ntraining of DNNs (DNN-SAT) focusing on a small amount of adaptation data per\nspeaker. DNN-SAT can be viewed as learning a mapping from each embedding to\ntransformation parameters that are applied to the shared parameters of the DNN.\nWe investigate different approaches to applying these transformations, and find\nthat with a good training strategy, a multi-layer adaptation network applied to\nall hidden layers is no more effective than a single linear layer acting on the\nembeddings to transform the input features. In the second part of our work, we\nevaluate different embeddings (i-vectors, x-vectors and deep CNN embeddings) in\nan additional speaker recognition task in order to gain insight into what\nshould characterize an embedding for DNN-SAT. We find the performance for\nspeaker recognition of a given representation is not correlated with its ASR\nperformance; in fact, ability to capture more speech attributes than just\nspeaker identity was the most important characteristic of the embeddings for\nefficient DNN-SAT ASR. Our best models achieved relative WER gains of 4% and 9%\nover DNN baselines using speaker-level cepstral mean normalisation (CMN), and a\nfully speaker-independent model, respectively.", "published": "2019-09-30 09:04:16", "link": "http://arxiv.org/abs/1909.13537v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Non-native Speaker Verification for Spoken Language Assessment", "abstract": "Automatic spoken language assessment systems are becoming more popular in\norder to handle increasing interests in second language learning. One challenge\nfor these systems is to detect malpractice. Malpractice can take a range of\nforms, this paper focuses on detecting when a candidate attempts to impersonate\nanother in a speaking test. This form of malpractice is closely related to\nspeaker verification, but applied in the specific domain of spoken language\nassessment. Advanced speaker verification systems, which leverage deep-learning\napproaches to extract speaker representations, have been successfully applied\nto a range of native speaker verification tasks. These systems are explored for\nnon-native spoken English data in this paper. The data used for speaker\nenrolment and verification is mainly taken from the BULATS test, which assesses\nEnglish language skills for business. Performance of systems trained on\nrelatively limited amounts of BULATS data, and standard large speaker\nverification corpora, is compared. Experimental results on large-scale test\nsets with millions of trials show that the best performance is achieved by\nadapting the imported model to non-native data. Breakdown of impostor trials\nacross different first languages (L1s) and grades is analysed, which shows that\ninter-L1 impostors are more challenging for speaker verification systems.", "published": "2019-09-30 13:42:06", "link": "http://arxiv.org/abs/1909.13695v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Acoustic Model Adaptation from Raw Waveforms with SincNet", "abstract": "Raw waveform acoustic modelling has recently gained interest due to neural\nnetworks' ability to learn feature extraction, and the potential for finding\nbetter representations for a given scenario than hand-crafted features. SincNet\nhas been proposed to reduce the number of parameters required in raw-waveform\nmodelling, by restricting the filter functions, rather than having to learn\nevery tap of each filter. We study the adaptation of the SincNet filter\nparameters from adults' to children's speech, and show that the\nparameterisation of the SincNet layer is well suited for adaptation in\npractice: we can efficiently adapt with a very small number of parameters,\nproducing error rates comparable to techniques using orders of magnitude more\nparameters.", "published": "2019-09-30 14:49:24", "link": "http://arxiv.org/abs/1909.13759v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Revisiting Self-Training for Neural Sequence Generation", "abstract": "Self-training is one of the earliest and simplest semi-supervised methods.\nThe key idea is to augment the original labeled dataset with unlabeled data\npaired with the model's prediction (i.e. the pseudo-parallel data). While\nself-training has been extensively studied on classification problems, in\ncomplex sequence generation tasks (e.g. machine translation) it is still\nunclear how self-training works due to the compositionality of the target\nspace. In this work, we first empirically show that self-training is able to\ndecently improve the supervised baseline on neural sequence generation tasks.\nThrough careful examination of the performance gains, we find that the\nperturbation on the hidden states (i.e. dropout) is critical for self-training\nto benefit from the pseudo-parallel data, which acts as a regularizer and\nforces the model to yield close predictions for similar unlabeled inputs. Such\neffect helps the model correct some incorrect predictions on unlabeled data. To\nfurther encourage this mechanism, we propose to inject noise to the input\nspace, resulting in a \"noisy\" version of self-training. Empirical study on\nstandard machine translation and text summarization benchmarks shows that noisy\nself-training is able to effectively utilize unlabeled data and improve the\nperformance of the supervised baseline by a large margin.", "published": "2019-09-30 15:30:00", "link": "http://arxiv.org/abs/1909.13788v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Incremental processing of noisy user utterances in the spoken language\n  understanding task", "abstract": "The state-of-the-art neural network architectures make it possible to create\nspoken language understanding systems with high quality and fast processing\ntime. One major challenge for real-world applications is the high latency of\nthese systems caused by triggered actions with high executions times. If an\naction can be separated into subactions, the reaction time of the systems can\nbe improved through incremental processing of the user utterance and starting\nsubactions while the utterance is still being uttered. In this work, we present\na model-agnostic method to achieve high quality in processing incrementally\nproduced partial utterances. Based on clean and noisy versions of the ATIS\ndataset, we show how to create datasets with our method to create low-latency\nnatural language understanding components. We get improvements of up to 47.91\nabsolute percentage points in the metric F1-score.", "published": "2019-09-30 15:35:07", "link": "http://arxiv.org/abs/1909.13790v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Semi-supervised voice conversion with amortized variational inference", "abstract": "In this work we introduce a semi-supervised approach to the voice conversion\nproblem, in which speech from a source speaker is converted into speech of a\ntarget speaker. The proposed method makes use of both parallel and non-parallel\nutterances from the source and target simultaneously during training. This\napproach can be used to extend existing parallel data voice conversion systems\nsuch that they can be trained with semi-supervision. We show that incorporating\nsemi-supervision improves the voice conversion performance compared to fully\nsupervised training when the number of parallel utterances is limited as in\nmany practical applications. Additionally, we find that increasing the number\nnon-parallel utterances used in training continues to improve performance when\nthe amount of parallel training data is held constant.", "published": "2019-09-30 19:39:57", "link": "http://arxiv.org/abs/1910.00067v1", "categories": ["stat.ML", "cs.LG", "eess.AS"], "primary_category": "stat.ML"}
{"title": "AV Speech Enhancement Challenge using a Real Noisy Corpus", "abstract": "This paper presents, a first of its kind, audio-visual (AV) speech enhacement\nchallenge in real-noisy settings. A detailed description of the AV challenge, a\nnovel real noisy AV corpus (ASPIRE), benchmark speech enhancement task, and\nbaseline performance results are outlined. The latter are based on training a\ndeep neural architecture on a synthetic mixture of Grid corpus and ChiME3\nnoises (consisting of bus, pedestrian, cafe, and street noises) and testing on\nthe ASPIRE corpus. Subjective evaluations of five different speech enhancement\nalgorithms (including SEAGN, spectrum subtraction (SS) , log-minimum\nmean-square error (LMMSE), audio-only CochleaNet, and AV CochleaNet) are\npresented as baseline results. The aim of the multi-modal challenge is to\nprovide a timely opportunity for comprehensive evaluation of novel AV speech\nenhancement algorithms, using our new benchmark, real-noisy AV corpus and\nspecified performance metrics. This will promote AV speech processing research\nglobally, stimulate new ground-breaking multi-modal approaches, and attract\ninterest from companies, academics and researchers working in AV speech\ntechnologies and applications. We encourage participants (through a challenge\nwebsite sign-up) from both the speech and hearing research communities, to\nbenefit from their complementary approaches to AV speech in noise processing.", "published": "2019-09-30 10:58:14", "link": "http://arxiv.org/abs/1910.00424v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
