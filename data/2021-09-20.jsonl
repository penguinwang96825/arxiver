{"title": "From None to Severe: Predicting Severity in Movie Scripts", "abstract": "In this paper, we introduce the task of predicting severity of age-restricted\naspects of movie content based solely on the dialogue script. We first\ninvestigate categorizing the ordinal severity of movies on 5 aspects: Sex,\nViolence, Profanity, Substance consumption, and Frightening scenes. The problem\nis handled using a siamese network-based multitask framework which concurrently\nimproves the interpretability of the predictions. The experimental results show\nthat our method outperforms the previous state-of-the-art model and provides\nuseful information to interpret model predictions. The proposed dataset and\nsource code are publicly available at our GitHub repository.", "published": "2021-09-20 03:01:46", "link": "http://arxiv.org/abs/2109.09276v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Commonsense Knowledge in Word Associations and ConceptNet", "abstract": "Humans use countless basic, shared facts about the world to efficiently\nnavigate in their environment. This commonsense knowledge is rarely\ncommunicated explicitly, however, understanding how commonsense knowledge is\nrepresented in different paradigms is important for both deeper understanding\nof human cognition and for augmenting automatic reasoning systems. This paper\npresents an in-depth comparison of two large-scale resources of general\nknowledge: ConcpetNet, an engineered relational database, and SWOW a knowledge\ngraph derived from crowd-sourced word associations. We examine the structure,\noverlap and differences between the two graphs, as well as the extent to which\nthey encode situational commonsense knowledge. We finally show empirically that\nboth resources improve downstream task performance on commonsense reasoning\nbenchmarks over text-only baselines, suggesting that large-scale word\nassociation data, which have been obtained for several languages through\ncrowd-sourcing, can be a valuable complement to curated knowledge graphs", "published": "2021-09-20 06:06:30", "link": "http://arxiv.org/abs/2109.09309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI systems for WMT21: Terminology translation Shared Task", "abstract": "This paper describes Charles University submission for Terminology\ntranslation Shared Task at WMT21. The objective of this task is to design a\nsystem which translates certain terms based on a provided terminology database,\nwhile preserving high overall translation quality. We competed in\nEnglish-French language pair. Our approach is based on providing the desired\ntranslations alongside the input sentence and training the model to use these\nprovided terms. We lemmatize the terms both during the training and inference,\nto allow the model to learn how to produce correct surface forms of the words,\nwhen they differ from the forms provided in the terminology database. Our\nsubmission ranked second in Exact Match metric which evaluates the ability of\nthe model to produce desired terms in the translation.", "published": "2021-09-20 08:05:39", "link": "http://arxiv.org/abs/2109.09350v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CUNI systems for WMT21: Multilingual Low-Resource Translation for\n  Indo-European Languages Shared Task", "abstract": "This paper describes Charles University submission for Multilingual\nLow-Resource Translation for Indo-European Languages shared task at WMT21. We\ncompeted in translation from Catalan into Romanian, Italian and Occitan. Our\nsystems are based on shared multilingual model. We show that using joint model\nfor multiple similar language pairs improves upon translation quality in each\npair. We also demonstrate that chararacter-level bilingual models are\ncompetitive for very similar language pairs (Catalan-Occitan) but less so for\nmore distant pairs. We also describe our experiments with multi-task learning,\nwhere aside from a textual translation, the models are also trained to perform\ngrapheme-to-phoneme conversion.", "published": "2021-09-20 08:10:39", "link": "http://arxiv.org/abs/2109.09354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting the User-Item Graph with Textual Similarity Models", "abstract": "This paper introduces a simple and effective form of data augmentation for\nrecommender systems. A paraphrase similarity model is applied to widely\navailable textual data, such as reviews and product descriptions, yielding new\nsemantic relations that are added to the user-item graph. This increases the\ndensity of the graph without needing further labeled data. The data\naugmentation is evaluated on a variety of recommendation algorithms, using\nEuclidean, hyperbolic, and complex spaces, and over three categories of Amazon\nproduct reviews with differing characteristics. Results show that the data\naugmentation technique provides significant improvements to all types of\nmodels, with the most pronounced gains for knowledge graph-based recommenders,\nparticularly in cold-start settings, leading to state-of-the-art performance.", "published": "2021-09-20 08:23:05", "link": "http://arxiv.org/abs/2109.09358v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Modality and Negation in Event Extraction", "abstract": "Language provides speakers with a rich system of modality for expressing\nthoughts about events, without being committed to their actual occurrence.\nModality is commonly used in the political news domain, where both actual and\npossible courses of events are discussed. NLP systems struggle with these\nsemantic phenomena, often incorrectly extracting events which did not happen,\nwhich can lead to issues in downstream applications. We present an open-domain,\nlexicon-based event extraction system that captures various types of modality.\nThis information is valuable for Question Answering, Knowledge Graph\nconstruction and Fact-checking tasks, and our evaluation shows that the system\nis sufficiently strong to be used in downstream applications.", "published": "2021-09-20 09:39:23", "link": "http://arxiv.org/abs/2109.09393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Temporal Information in Entailment Graph Mining", "abstract": "We present a novel method for injecting temporality into entailment graphs to\naddress the problem of spurious entailments, which may arise from similar but\ntemporally distinct events involving the same pair of entities. We focus on the\nsports domain in which the same pairs of teams play on different occasions,\nwith different outcomes. We present an unsupervised model that aims to learn\nentailments such as win/lose $\\rightarrow$ play, while avoiding the pitfall of\nlearning non-entailments such as win $\\not\\rightarrow$ lose. We evaluate our\nmodel on a manually constructed dataset, showing that incorporating time\nintervals and applying a temporal window around them, are effective strategies.", "published": "2021-09-20 10:18:16", "link": "http://arxiv.org/abs/2109.09412v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crowdsourcing Diverse Paraphrases for Training Task-oriented Bots", "abstract": "A prominent approach to build datasets for training task-oriented bots is\ncrowd-based paraphrasing. Current approaches, however, assume the crowd would\nnaturally provide diverse paraphrases or focus only on lexical diversity. In\nthis WiP we addressed an overlooked aspect of diversity, introducing an\napproach for guiding the crowdsourcing process towards paraphrases that are\nsyntactically diverse.", "published": "2021-09-20 10:46:35", "link": "http://arxiv.org/abs/2109.09420v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation", "abstract": "To explore the limit of dialogue generation pre-training, we present the\nmodels of PLATO-XL with up to 11 billion parameters, trained on both Chinese\nand English social media conversations. To train such large models, we adopt\nthe architecture of unified transformer with high computation and parameter\nefficiency. In addition, we carry out multi-party aware pre-training to better\ndistinguish the characteristic information in social media conversations. With\nsuch designs, PLATO-XL successfully achieves superior performances as compared\nto other approaches in both Chinese and English chitchat. We further explore\nthe capacity of PLATO-XL on other conversational tasks, such as knowledge\ngrounded dialogue and task-oriented conversation. The experimental results\nindicate that PLATO-XL obtains state-of-the-art results across multiple\nconversational tasks, verifying its potential as a foundation model of\nconversational AI.", "published": "2021-09-20 13:10:23", "link": "http://arxiv.org/abs/2109.09519v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JobBERT: Understanding Job Titles through Skills", "abstract": "Job titles form a cornerstone of today's human resources (HR) processes.\nWithin online recruitment, they allow candidates to understand the contents of\na vacancy at a glance, while internal HR departments use them to organize and\nstructure many of their processes. As job titles are a compact, convenient, and\nreadily available data source, modeling them with high accuracy can greatly\nbenefit many HR tech applications. In this paper, we propose a neural\nrepresentation model for job titles, by augmenting a pre-trained language model\nwith co-occurrence information from skill labels extracted from vacancies. Our\nJobBERT method leads to considerable improvements compared to using generic\nsentence encoders, for the task of job title normalization, for which we\nrelease a new evaluation benchmark.", "published": "2021-09-20 15:00:10", "link": "http://arxiv.org/abs/2109.09605v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Generalization in Coreference Resolution", "abstract": "While coreference resolution is defined independently of dataset domain, most\nmodels for performing coreference resolution do not transfer well to unseen\ndomains. We consolidate a set of 8 coreference resolution datasets targeting\ndifferent domains to evaluate the off-the-shelf performance of models. We then\nmix three datasets for training; even though their domain, annotation\nguidelines, and metadata differ, we propose a method for jointly training a\nsingle model on this heterogeneous data mixture by using data augmentation to\naccount for annotation differences and sampling to balance the data quantities.\nWe find that in a zero-shot setting, models trained on a single dataset\ntransfer poorly while joint training yields improved overall performance,\nleading to better generalization in coreference resolution models. This work\ncontributes a new benchmark for robust coreference resolution and multiple new\nstate-of-the-art results.", "published": "2021-09-20 16:33:22", "link": "http://arxiv.org/abs/2109.09667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese", "abstract": "We present BARTpho with two versions, BARTpho-syllable and BARTpho-word,\nwhich are the first public large-scale monolingual sequence-to-sequence models\npre-trained for Vietnamese. BARTpho uses the \"large\" architecture and the\npre-training scheme of the sequence-to-sequence denoising autoencoder BART,\nthus it is especially suitable for generative NLP tasks. We conduct experiments\nto compare our BARTpho with its competitor mBART on a downstream task of\nVietnamese text summarization and show that: in both automatic and human\nevaluations, BARTpho outperforms the strong baseline mBART and improves the\nstate-of-the-art. We further evaluate and compare BARTpho and mBART on the\nVietnamese capitalization and punctuation restoration tasks and also find that\nBARTpho is more effective than mBART on these two tasks. We publicly release\nBARTpho to facilitate future research and applications of generative Vietnamese\nNLP tasks. Our BARTpho models are available at\nhttps://github.com/VinAIResearch/BARTpho", "published": "2021-09-20 17:14:22", "link": "http://arxiv.org/abs/2109.09701v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DisCoDisCo at the DISRPT2021 Shared Task: A System for Discourse\n  Segmentation, Classification, and Connective Detection", "abstract": "This paper describes our submission to the DISRPT2021 Shared Task on\nDiscourse Unit Segmentation, Connective Detection, and Relation Classification.\nOur system, called DisCoDisCo, is a Transformer-based neural classifier which\nenhances contextualized word embeddings (CWEs) with hand-crafted features,\nrelying on tokenwise sequence tagging for discourse segmentation and connective\ndetection, and a feature-rich, encoder-less sentence pair classifier for\nrelation classification. Our results for the first two tasks outperform SOTA\nscores from the previous 2019 shared task, and results on relation\nclassification suggest strong performance on the new 2021 benchmark. Ablation\ntests show that including features beyond CWEs are helpful for both tasks, and\na partial evaluation of multiple pre-trained Transformer-based language models\nindicates that models pre-trained on the Next Sentence Prediction (NSP) task\nare optimal for relation classification.", "published": "2021-09-20 18:11:05", "link": "http://arxiv.org/abs/2109.09777v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology", "abstract": "An important question concerning contextualized word embedding (CWE) models\nlike BERT is how well they can represent different word senses, especially\nthose in the long tail of uncommon senses. Rather than build a WSD system as in\nprevious work, we investigate contextualized embedding neighborhoods directly,\nformulating a query-by-example nearest neighbor retrieval task and examining\nranking performance for words and senses in different frequency bands. In an\nevaluation on two English sense-annotated corpora, we find that several popular\nCWE models all outperform a random baseline even for proportionally rare\nsenses, without explicit sense supervision. However, performance varies\nconsiderably even among models with similar architectures and pretraining\nregimes, with especially large differences for rare word senses, revealing that\nCWE models are not all created equal when it comes to approximating word senses\nin their native representations.", "published": "2021-09-20 18:15:26", "link": "http://arxiv.org/abs/2109.09780v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency Induction Through the Lens of Visual Perception", "abstract": "Most previous work on grammar induction focuses on learning phrasal or\ndependency structure purely from text. However, because the signal provided by\ntext alone is limited, recently introduced visually grounded syntax models make\nuse of multimodal information leading to improved performance in constituency\ngrammar induction. However, as compared to dependency grammars, constituency\ngrammars do not provide a straightforward way to incorporate visual information\nwithout enforcing language-specific heuristics. In this paper, we propose an\nunsupervised grammar induction model that leverages word concreteness and a\nstructural vision-based heuristic to jointly learn constituency-structure and\ndependency-structure grammars. Our experiments find that concreteness is a\nstrong indicator for learning dependency grammars, improving the direct\nattachment score (DAS) by over 50\\% as compared to state-of-the-art models\ntrained on pure text. Next, we propose an extension of our model that leverages\nboth word concreteness and visual semantic role labels in constituency and\ndependency parsing. Our experiments show that the proposed extension\noutperforms the current state-of-the-art visually grounded models in\nconstituency parsing even with a smaller grammar size.", "published": "2021-09-20 18:40:37", "link": "http://arxiv.org/abs/2109.09790v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transforming Fake News: Robust Generalisable News Classification Using\n  Transformers", "abstract": "As online news has become increasingly popular and fake news increasingly\nprevalent, the ability to audit the veracity of online news content has become\nmore important than ever. Such a task represents a binary classification\nchallenge, for which transformers have achieved state-of-the-art results. Using\nthe publicly available ISOT and Combined Corpus datasets, this study explores\ntransformers' abilities to identify fake news, with particular attention given\nto investigating generalisation to unseen datasets with varying styles, topics\nand class distributions. Moreover, we explore the idea that opinion-based news\narticles cannot be classified as real or fake due to their subjective nature\nand often sensationalised language, and propose a novel two-step classification\npipeline to remove such articles from both model training and the final\ndeployed inference system. Experiments over the ISOT and Combined Corpus\ndatasets show that transformers achieve an increase in F1 scores of up to 4.9%\nfor out of distribution generalisation compared to baseline approaches, with a\nfurther increase of 10.1% following the implementation of our two-step\nclassification pipeline. To the best of our knowledge, this study is the first\nto investigate generalisation of transformers in this context.", "published": "2021-09-20 19:03:16", "link": "http://arxiv.org/abs/2109.09796v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StreamSide: A Fully-Customizable Open-Source Toolkit for Efficient\n  Annotation of Meaning Representations", "abstract": "This demonstration paper presents StreamSide, an open-source toolkit for\nannotating multiple kinds of meaning representations. StreamSide supports\nframe-based annotation schemes e.g., Abstract Meaning Representation (AMR) and\nframeless annotation schemes e.g., Widely Interpretable Semantic Representation\n(WISeR). Moreover, it supports both sentence-level and document-level\nannotation by allowing annotators to create multi-rooted graphs for input text.\nIt can open and automatically convert between several types of input formats\nincluding plain text, Penman notation, and its own JSON format enabling richer\nannotation. It features reference frames for AMR predicate argument structures,\nand also concept-to-text alignment. StreamSide is released under the Apache 2.0\nlicense, and is completely open-source so that it can be customized to annotate\nenriched meaning representations in different languages (e.g., Uniform Meaning\nRepresentations). All StreamSide resources are publicly distributed through our\nopen source project at: https://github.com/emorynlp/StreamSide.", "published": "2021-09-20 21:36:22", "link": "http://arxiv.org/abs/2109.09853v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Intensionalizing Abstract Meaning Representations: Non-Veridicality and\n  Scope", "abstract": "Abstract Meaning Representation (AMR) is a graphical meaning representation\nlanguage designed to represent propositional information about argument\nstructure. However, at present it is unable to satisfyingly represent\nnon-veridical intensional contexts, often licensing inappropriate inferences.\nIn this paper, we show how to resolve the problem of non-veridicality without\nappealing to layered graphs through a mapping from AMRs into Simply-Typed\nLambda Calculus (STLC). At least for some cases, this requires the introduction\nof a new role :content which functions as an intensional operator. The\ntranslation proposed is inspired by the formal linguistics literature on the\nevent semantics of attitude reports. Next, we address the interaction of\nquantifier scope and intensional operators in so-called de re/de dicto\nambiguities. We adopt a scope node from the literature and provide an explicit\nmultidimensional semantics utilizing Cooper storage which allows us to derive\nthe de re and de dicto scope readings as well as intermediate scope readings\nwhich prove difficult for accounts without a scope node.", "published": "2021-09-20 21:48:02", "link": "http://arxiv.org/abs/2109.09858v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Truly Matters? Using Linguistic Cues for Analyzing the\n  #BlackLivesMatter Movement and its Counter Protests: 2013 to 2020", "abstract": "Since the fatal shooting of 17-year old Black teenager Trayvon Martin in\nFebruary 2012 by a White neighborhood watchman, George Zimmerman in Sanford,\nFlorida, there has been a significant increase in digital activism addressing\npolice-brutality related and racially-motivated incidents in the United States.\nIn this work, we administer an innovative study of digital activism by\nexploiting social media as an authoritative tool to examine and analyze the\nlinguistic cues and thematic relationships in these three mediums. We conduct a\nmulti-level text analysis on 36,984,559 tweets to investigate users' behaviors\nto examine the language used and understand the impact of digital activism on\nsocial media within each social movement on a sentence-level, word-level, and\ntopic-level. Our results show that excessive use of racially-related or\nprejudicial hashtags were used by the counter protests which portray potential\ndiscriminatory tendencies. Consequently, our findings highlight that social\nactivism done by Black Lives Matter activists does not diverge from the social\nissues and topics involving police-brutality related and racially-motivated\nkillings of Black individuals due to the shape of its topical graph that topics\nand conversations encircling the largest component directly relate to the topic\nof Black Lives Matter. Finally, we see that both Blue Lives Matter and All\nLives Matter movements depict a different directive, as the topics of Blue\nLives Matter or All Lives Matter do not reside in the center. These findings\nsuggest that topics and conversations within each social movement are skewed,\nrandom or possessed racially-related undertones, and thus, deviating from the\nprominent social injustice issues.", "published": "2021-09-20 18:34:30", "link": "http://arxiv.org/abs/2109.12192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Emotion Recognition in Conversation with Sequential\n  Prototypical Networks", "abstract": "Several recent studies on dyadic human-human interactions have been done on\nconversations without specific business objectives. However, many companies\nmight benefit from studies dedicated to more precise environments such as after\nsales services or customer satisfaction surveys. In this work, we place\nourselves in the scope of a live chat customer service in which we want to\ndetect emotions and their evolution in the conversation flow. This context\nleads to multiple challenges that range from exploiting restricted, small and\nmostly unlabeled datasets to finding and adapting methods for such context.We\ntackle these challenges by using Few-Shot Learning while making the hypothesis\nit can serve conversational emotion classification for different languages and\nsparse labels. We contribute by proposing a variation of Prototypical Networks\nfor sequence labeling in conversation that we name ProtoSeq. We test this\nmethod on two datasets with different languages: daily conversations in English\nand customer service chat conversations in French. When applied to emotion\nclassification in conversations, our method proved to be competitive even when\ncompared to other ones.", "published": "2021-09-20 08:33:38", "link": "http://arxiv.org/abs/2109.09366v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Assessing the quality of sources in Wikidata across languages: a hybrid\n  approach", "abstract": "Wikidata is one of the most important sources of structured data on the web,\nbuilt by a worldwide community of volunteers. As a secondary source, its\ncontents must be backed by credible references; this is particularly important\nas Wikidata explicitly encourages editors to add claims for which there is no\nbroad consensus, as long as they are corroborated by references. Nevertheless,\ndespite this essential link between content and references, Wikidata's ability\nto systematically assess and assure the quality of its references remains\nlimited. To this end, we carry out a mixed-methods study to determine the\nrelevance, ease of access, and authoritativeness of Wikidata references, at\nscale and in different languages, using online crowdsourcing, descriptive\nstatistics, and machine learning. Building on previous work of ours, we run a\nseries of microtasks experiments to evaluate a large corpus of references,\nsampled from Wikidata triples with labels in several languages. We use a\nconsolidated, curated version of the crowdsourced assessments to train several\nmachine learning models to scale up the analysis to the whole of Wikidata. The\nfindings help us ascertain the quality of references in Wikidata, and identify\ncommon challenges in defining and capturing the quality of user-generated\nmultilingual structured data on the web. We also discuss ongoing editorial\npractices, which could encourage the use of higher-quality references in a more\nimmediate way. All data and code used in the study are available on GitHub for\nfeedback and further improvement and deployment by the research community.", "published": "2021-09-20 10:06:46", "link": "http://arxiv.org/abs/2109.09405v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ConvAbuse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in\n  Conversational AI", "abstract": "We present the first English corpus study on abusive language towards three\nconversational AI systems gathered \"in the wild\": an open-domain social bot, a\nrule-based chatbot, and a task-based system. To account for the complexity of\nthe task, we take a more `nuanced' approach where our ConvAI dataset reflects\nfine-grained notions of abuse, as well as views from multiple expert\nannotators. We find that the distribution of abuse is vastly different compared\nto other commonly used datasets, with more sexually tinted aggression towards\nthe virtual persona of these systems. Finally, we report results from\nbench-marking existing models against this data. Unsurprisingly, we find that\nthere is substantial room for improvement with F1 scores below 90%.", "published": "2021-09-20 12:41:50", "link": "http://arxiv.org/abs/2109.09483v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A mixed-methods ethnographic approach to participatory budgeting in\n  Scotland", "abstract": "Participatory budgeting (PB) is already well established in Scotland in the\nform of community led grant-making yet has recently transformed from a\ngrass-roots activity to a mainstream process or embedded 'policy instrument'.\nAn integral part of this turn is the use of the Consul digital platform as the\nprimary means of citizen participation. Using a mixed method approach, this\nongoing research paper explores how each of the 32 local authorities that make\nup Scotland utilise the Consul platform to engage their citizens in the PB\nprocess and how they then make sense of citizens' contributions. In particular,\nwe focus on whether natural language processing (NLP) tools can facilitate both\ncitizen engagement, and the processes by which citizens' contributions are\nanalysed and translated into policies.", "published": "2021-09-20 13:04:24", "link": "http://arxiv.org/abs/2109.09517v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "MeetDot: Videoconferencing with Live Translation Captions", "abstract": "We present MeetDot, a videoconferencing system with live translation captions\noverlaid on screen. The system aims to facilitate conversation between people\nwho speak different languages, thereby reducing communication barriers between\nmultilingual participants. Currently, our system supports speech and captions\nin 4 languages and combines automatic speech recognition (ASR) and machine\ntranslation (MT) in a cascade. We use the re-translation strategy to translate\nthe streamed speech, resulting in caption flicker. Additionally, our system has\nvery strict latency requirements to have acceptable call quality. We implement\nseveral features to enhance user experience and reduce their cognitive load,\nsuch as smooth scrolling captions and reducing caption flicker. The modular\narchitecture allows us to integrate different ASR and MT services in our\nbackend. Our system provides an integrated evaluation suite to optimize key\nintrinsic evaluation metrics such as accuracy, latency and erasure. Finally, we\npresent an innovative cross-lingual word-guessing game as an extrinsic\nevaluation metric to measure end-to-end system performance. We plan to make our\nsystem open-source for research purposes.", "published": "2021-09-20 14:34:14", "link": "http://arxiv.org/abs/2109.09577v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BERT Cannot Align Characters", "abstract": "In previous work, it has been shown that BERT can adequately align\ncross-lingual sentences on the word level. Here we investigate whether BERT can\nalso operate as a char-level aligner. The languages examined are English,\nFake-English, German and Greek. We show that the closer two languages are, the\nbetter BERT can align them on the character level. BERT indeed works well in\nEnglish to Fake-English alignment, but this does not generalize to natural\nlanguages to the same extent. Nevertheless, the proximity of two languages does\nseem to be a factor. English is more related to German than to Greek and this\nis reflected in how well BERT aligns them; English to German is better than\nEnglish to Greek. We examine multiple setups and show that the similarity\nmatrices for natural languages show weaker relations the further apart two\nlanguages are.", "published": "2021-09-20 17:10:49", "link": "http://arxiv.org/abs/2109.09700v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Plug-and-Play Method for Controlled Text Generation", "abstract": "Large pre-trained language models have repeatedly shown their ability to\nproduce fluent text. Yet even when starting from a prompt, generation can\ncontinue in many plausible directions. Current decoding methods with the goal\nof controlling generation, e.g., to ensure specific words are included, either\nrequire additional models or fine-tuning, or work poorly when the task at hand\nis semantically unconstrained, e.g., story generation. In this work, we present\na plug-and-play decoding method for controlled language generation that is so\nsimple and intuitive, it can be described in a single sentence: given a topic\nor keyword, we add a shift to the probability distribution over our vocabulary\ntowards semantically similar words. We show how annealing this distribution can\nbe used to impose hard constraints on language generation, something no other\nplug-and-play method is currently able to do with SOTA language generators.\nDespite the simplicity of this approach, we see it works incredibly well in\npractice: decoding from GPT-2 leads to diverse and fluent sentences while\nguaranteeing the appearance of given guide words. We perform two user studies,\nrevealing that (1) our method outperforms competing methods in human\nevaluations; and (2) forcing the guide words to appear in the generated text\nhas no impact on the fluency of the generated text.", "published": "2021-09-20 17:27:03", "link": "http://arxiv.org/abs/2109.09707v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Model Bias in NLP -- Application to Hate Speech Classification using\n  transfer learning techniques", "abstract": "In this paper, a BERT based neural network model is applied to the JIGSAW\ndata set in order to create a model identifying hateful and toxic comments\n(strictly seperated from offensive language) in online social platforms\n(English language), in this case Twitter. Three other neural network\narchitectures and a GPT-2 model are also applied on the provided data set in\norder to compare these different models. The trained BERT model is then applied\non two different data sets to evaluate its generalisation power, namely on\nanother Twitter data set and the data set HASOC 2019 which includes Twitter and\nalso Facebook comments; we focus on the English HASOC 2019 data. In addition,\nit can be shown that by fine-tuning the trained BERT model on these two data\nsets by applying different transfer learning scenarios via retraining partial\nor all layers the predictive scores improve compared to simply applying the\nmodel pre-trained on the JIGSAW data set. With our results, we get precisions\nfrom 64% to around 90% while still achieving acceptable recall values of at\nleast lower 60s%, proving that BERT is suitable for real use cases in social\nplatforms.", "published": "2021-09-20 17:56:08", "link": "http://arxiv.org/abs/2109.09725v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Span Representation for Domain-adapted Coreference Resolution", "abstract": "Recent work has shown fine-tuning neural coreference models can produce\nstrong performance when adapting to different domains. However, at the same\ntime, this can require a large amount of annotated target examples. In this\nwork, we focus on supervised domain adaptation for clinical notes, proposing\nthe use of concept knowledge to more efficiently adapt coreference models to a\nnew domain. We develop methods to improve the span representations via (1) a\nretrofitting loss to incentivize span representations to satisfy a\nknowledge-based distance function and (2) a scaffolding loss to guide the\nrecovery of knowledge from the span representation. By integrating these\nlosses, our model is able to improve our baseline precision and F-1 score. In\nparticular, we show that incorporating knowledge with end-to-end coreference\nmodels results in better performance on the most challenging, domain-specific\nspans.", "published": "2021-09-20 19:41:31", "link": "http://arxiv.org/abs/2109.09811v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Language Identification with a Reciprocal Rank Classifier", "abstract": "Language identification is a critical component of language processing\npipelines (Jauhiainen et al.,2019) and is not a solved problem in real-world\nsettings. We present a lightweight and effective language identifier that is\nrobust to changes of domain and to the absence of copious training data.\n  The key idea for classification is that the reciprocal of the rank in a\nfrequency table makes an effective additive feature score, hence the term\nReciprocal Rank Classifier (RRC). The key finding for language classification\nis that ranked lists of words and frequencies of characters form a sufficient\nand robust representation of the regularities of key languages and their\northographies.\n  We test this on two 22-language data sets and demonstrate zero-effort domain\nadaptation from a Wikipedia training set to a Twitter test set. When trained on\nWikipedia but applied to Twitter the macro-averaged F1-score of a\nconventionally trained SVM classifier drops from 90.9% to 77.7%. By contrast,\nthe macro F1-score of RRC drops only from 93.1% to 90.6%. These classifiers are\ncompared with those from fastText and langid. The RRC performs better than\nthese established systems in most experiments, especially on short Wikipedia\ntexts and Twitter.\n  The RRC classifier can be improved for particular domains and conversational\nsituations by adding words to the ranked lists. Using new terms learned from\nsuch conversations, we demonstrate a further 7.9% increase in accuracy of\nsample message classification, and 1.7% increase for conversation\nclassification. Surprisingly, this made results on Twitter data slightly worse.\n  The RRC classifier is available as an open source Python package\n(https://github.com/LivePersonInc/lplangid).", "published": "2021-09-20 22:10:07", "link": "http://arxiv.org/abs/2109.09862v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Natural Language Generation from Scratch", "abstract": "This paper introduces TRUncated ReinForcement Learning for Language (TrufLL),\nan original ap-proach to train conditional language models from scratch by only\nusing reinforcement learning (RL). AsRL methods unsuccessfully scale to large\naction spaces, we dynamically truncate the vocabulary spaceusing a generic\nlanguage model. TrufLL thus enables to train a language agent by solely\ninteracting withits environment without any task-specific prior knowledge; it\nis only guided with a task-agnostic languagemodel. Interestingly, this approach\navoids the dependency to labelled datasets and inherently reduces pre-trained\npolicy flaws such as language or exposure biases. We evaluate TrufLL on two\nvisual questiongeneration tasks, for which we report positive results over\nperformance and language metrics, which wethen corroborate with a human\nevaluation. To our knowledge, it is the first approach that successfullylearns\na language generation policy (almost) from scratch.", "published": "2021-09-20 08:46:51", "link": "http://arxiv.org/abs/2109.09371v1", "categories": ["cs.AI", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Two Approaches to Building Collaborative, Task-Oriented Dialog Agents\n  through Self-Play", "abstract": "Task-oriented dialog systems are often trained on human/human dialogs, such\nas collected from Wizard-of-Oz interfaces. However, human/human corpora are\nfrequently too small for supervised training to be effective. This paper\ninvestigates two approaches to training agent-bots and user-bots through\nself-play, in which they autonomously explore an API environment, discovering\ncommunication strategies that enable them to solve the task. We give empirical\nresults for both reinforcement learning and game-theoretic equilibrium finding.", "published": "2021-09-20 14:52:25", "link": "http://arxiv.org/abs/2109.09597v1", "categories": ["cs.CL", "cs.AI", "cs.GT"], "primary_category": "cs.CL"}
{"title": "The Case for Claim Difficulty Assessment in Automatic Fact Checking", "abstract": "Fact-checking is the process of evaluating the veracity of claims (i.e.,\npurported facts). In this opinion piece, we raise an issue that has received\nlittle attention in prior work -- that some claims are far more difficult to\nfact-check than others. We discuss the implications this has for both practical\nfact-checking and research on automated fact-checking, including task\nformulation and dataset design. We report a manual analysis undertaken to\nexplore factors underlying varying claim difficulty and identify several\ndistinct types of difficulty. We motivate this new claim difficulty prediction\ntask as beneficial to both automated fact-checking and practical fact-checking\norganizations.", "published": "2021-09-20 16:59:50", "link": "http://arxiv.org/abs/2109.09689v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Data Augmentation Methods for Anaphoric Zero Pronouns", "abstract": "In pro-drop language like Arabic, Chinese, Italian, Japanese, Spanish, and\nmany others, unrealized (null) arguments in certain syntactic positions can\nrefer to a previously introduced entity, and are thus called anaphoric zero\npronouns. The existing resources for studying anaphoric zero pronoun\ninterpretation are however still limited. In this paper, we use five data\naugmentation methods to generate and detect anaphoric zero pronouns\nautomatically. We use the augmented data as additional training materials for\ntwo anaphoric zero pronoun systems for Arabic. Our experimental results show\nthat data augmentation improves the performance of the two systems, surpassing\nthe state-of-the-art results.", "published": "2021-09-20 20:16:01", "link": "http://arxiv.org/abs/2109.09825v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Influence of ASR and Language Model on Alzheimer's Disease Detection", "abstract": "Alzheimer's Disease is the most common form of dementia. Automatic detection\nfrom speech could help to identify symptoms at early stages, so that preventive\nactions can be carried out. This research is a contribution to the ADReSSo\nChallenge, we analyze the usage of a SotA ASR system to transcribe\nparticipant's spoken descriptions from a picture. We analyse the loss of\nperformance regarding the use of human transcriptions (measured using\ntranscriptions from the 2020 ADReSS Challenge). Furthermore, we study the\ninfluence of a language model -- which tends to correct non-standard sequences\nof words -- with the lack of language model to decode the hypothesis from the\nASR. This aims at studying the language bias and get more meaningful\ntranscriptions based only on the acoustic information from patients. The\nproposed system combines acoustic -- based on prosody and voice quality -- and\nlexical features based on the first occurrence of the most common words. The\nreported results show the effect of using automatic transcripts with or without\nlanguage model. The best fully automatic system achieves up to 76.06 % of\naccuracy (without language model), significantly higher, 3 % above, than a\nsystem employing word transcriptions decoded using general purpose language\nmodels.", "published": "2021-09-20 10:41:39", "link": "http://arxiv.org/abs/2110.15704v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "TeleMelody: Lyric-to-Melody Generation with a Template-Based Two-Stage\n  Method", "abstract": "Lyric-to-melody generation is an important task in automatic songwriting.\nPrevious lyric-to-melody generation systems usually adopt end-to-end models\nthat directly generate melodies from lyrics, which suffer from several issues:\n1) lack of paired lyric-melody training data; 2) lack of control on generated\nmelodies. In this paper, we develop TeleMelody, a two-stage lyric-to-melody\ngeneration system with music template (e.g., tonality, chord progression,\nrhythm pattern, and cadence) to bridge the gap between lyrics and melodies\n(i.e., the system consists of a lyric-to-template module and a\ntemplate-to-melody module). TeleMelody has two advantages. First, it is data\nefficient. The template-to-melody module is trained in a self-supervised way\n(i.e., the source template is extracted from the target melody) that does not\nneed any lyric-melody paired data. The lyric-to-template module is made up of\nsome rules and a lyric-to-rhythm model, which is trained with paired\nlyric-rhythm data that is easier to obtain than paired lyric-melody data.\nSecond, it is controllable. The design of template ensures that the generated\nmelodies can be controlled by adjusting the musical elements in template. Both\nsubjective and objective experimental evaluations demonstrate that TeleMelody\ngenerates melodies with higher quality, better controllability, and less\nrequirement on paired lyric-melody data than previous generation systems.", "published": "2021-09-20 15:19:33", "link": "http://arxiv.org/abs/2109.09617v2", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Text-Independent Speaker Verification with Auxiliary Speakers\n  Using Graph", "abstract": "The paper presents a novel approach to refining similarity scores between\ninput utterances for robust speaker verification. Given the embeddings from a\npair of input utterances, a graph model is designed to incorporate additional\ninformation from a group of embeddings representing the so-called auxiliary\nspeakers. The relations between the input utterances and the auxiliary speakers\nare represented by the edges and vertices in the graph. The similarity scores\nare refined by iteratively updating the values of the graph's vertices using an\nalgorithm similar to the random walk algorithm on graphs. Through this updating\nprocess, the information of auxiliary speakers is involved in determining the\nrelation between input utterances and hence contributing to the verification\nprocess. We propose to create a set of artificial embeddings through the model\ntraining process. Utilizing the generated embeddings as auxiliary speakers, no\nextra data are required for the graph model in the verification stage. The\nproposed model is trained in an end-to-end manner within the whole system.\nExperiments are carried out with the Voxceleb datasets. The results indicate\nthat involving auxiliary speakers with graph is effective to improve speaker\nverification performance.", "published": "2021-09-20 16:43:49", "link": "http://arxiv.org/abs/2109.09674v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Acoustic Echo Cancellation using Residual U-Nets", "abstract": "This paper presents an acoustic echo canceler based on a U-Net convolutional\nneural network for single-talk and double-talk scenarios. U-Net networks have\npreviously been used in the audio processing area for source separation\nproblems because of their ability to reproduce the finest details of audio\nsignals, but to our knowledge, this is the first time they have been used for\nacoustic echo cancellation (AEC). The U-Net hyperparameters have been optimized\nto obtain the best AEC performance, but using a reduced number of parameters to\nmeet a latency restriction of 40 ms. The training and testing of our model have\nbeen carried out within the framework of the 'ICASSP 2021 AEC Challenge'\norganized by Microsoft. We have trained the optimized U-Net model with a\nsynthetic dataset only (S-U-Net) and with a synthetic dataset and the\nsingle-talk set of a real dataset (SR-U-Net), both datasets were released for\nthe challenge. The S-U-Net model presented better results for double-talk\nscenarios, thus their inferred near-end signals from the blind testset were\nsubmitted to the challenge. Our canceler ranked 12th among 17 teams, and 5th\namong 10 academia teams, obtaining an overall mean opinion score of 3.57.", "published": "2021-09-20 16:57:28", "link": "http://arxiv.org/abs/2109.09686v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "\"Hello, It's Me\": Deep Learning-based Speech Synthesis Attacks in the\n  Real World", "abstract": "Advances in deep learning have introduced a new wave of voice synthesis\ntools, capable of producing audio that sounds as if spoken by a target speaker.\nIf successful, such tools in the wrong hands will enable a range of powerful\nattacks against both humans and software systems (aka machines). This paper\ndocuments efforts and findings from a comprehensive experimental study on the\nimpact of deep-learning based speech synthesis attacks on both human listeners\nand machines such as speaker recognition and voice-signin systems. We find that\nboth humans and machines can be reliably fooled by synthetic speech and that\nexisting defenses against synthesized speech fall short. These findings\nhighlight the need to raise awareness and develop new protections against\nsynthetic speech for both humans and machines.", "published": "2021-09-20 14:53:22", "link": "http://arxiv.org/abs/2109.09598v1", "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Assessing clinical utility of Machine Learning and Artificial\n  Intelligence approaches to analyze speech recordings in Multiple Sclerosis: A\n  Pilot Study", "abstract": "Background: An early diagnosis together with an accurate disease progression\nmonitoring of multiple sclerosis is an important component of successful\ndisease management. Prior studies have established that multiple sclerosis is\ncorrelated with speech discrepancies. Early research using objective acoustic\nmeasurements has discovered measurable dysarthria.\n  Objective: To determine the potential clinical utility of machine learning\nand deep learning/AI approaches for the aiding of diagnosis, biomarker\nextraction and progression monitoring of multiple sclerosis using speech\nrecordings.\n  Methods: A corpus of 65 MS-positive and 66 healthy individuals reading the\nsame text aloud was used for targeted acoustic feature extraction utilizing\nautomatic phoneme segmentation. A series of binary classification models was\ntrained, tuned, and evaluated regarding their Accuracy and area-under-curve.\n  Results: The Random Forest model performed best, achieving an Accuracy of\n0.82 on the validation dataset and an area-under-curve of 0.76 across 5 k-fold\ncycles on the training dataset. 5 out of 7 acoustic features were statistically\nsignificant.\n  Conclusion: Machine learning and artificial intelligence in automatic\nanalyses of voice recordings for aiding MS diagnosis and progression tracking\nseems promising. Further clinical validation of these methods and their mapping\nonto multiple sclerosis progression is needed, as well as a validating utility\nfor English-speaking populations.", "published": "2021-09-20 21:02:37", "link": "http://arxiv.org/abs/2109.09844v2", "categories": ["eess.AS", "cs.AI", "q-bio.NC"], "primary_category": "eess.AS"}
