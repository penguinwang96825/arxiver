{"title": "Memory-augmented Chinese-Uyghur Neural Machine Translation", "abstract": "Neural machine translation (NMT) has achieved notable performance recently.\nHowever, this approach has not been widely applied to the translation task\nbetween Chinese and Uyghur, partly due to the limited parallel data resource\nand the large proportion of rare words caused by the agglutinative nature of\nUyghur. In this paper, we collect ~200,000 sentence pairs and show that with\nthis middle-scale database, an attention-based NMT can perform very well on\nChinese-Uyghur/Uyghur-Chinese translation. To tackle rare words, we propose a\nnovel memory structure to assist the NMT inference. Our experiments\ndemonstrated that the memory-augmented NMT (M-NMT) outperforms both the vanilla\nNMT and the phrase-based statistical machine translation (SMT). Interestingly,\nthe memory structure provides an elegant way for dealing with words that are\nout of vocabulary.", "published": "2017-06-27 06:33:52", "link": "http://arxiv.org/abs/1706.08683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoNLL-SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection\n  in 52 Languages", "abstract": "The CoNLL-SIGMORPHON 2017 shared task on supervised morphological generation\nrequired systems to be trained and tested in each of 52 typologically diverse\nlanguages. In sub-task 1, submitted systems were asked to predict a specific\ninflected form of a given lemma. In sub-task 2, systems were given a lemma and\nsome of its specific inflected forms, and asked to complete the inflectional\nparadigm by predicting all of the remaining inflected forms. Both sub-tasks\nincluded high, medium, and low-resource conditions. Sub-task 1 received 24\nsystem submissions, while sub-task 2 received 3 system submissions. Following\nthe success of neural sequence-to-sequence models in the SIGMORPHON 2016 shared\ntask, all but one of the submissions included a neural component. The results\nshow that high performance can be achieved with small training datasets, so\nlong as models have appropriate inductive bias or make use of additional\nunlabeled data or synthetic data. However, different biasing and data\naugmentation resulted in disjoint sets of inflected forms being predicted\ncorrectly, suggesting that there is room for future improvement.", "published": "2017-06-27 20:02:34", "link": "http://arxiv.org/abs/1706.09031v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DE-PACRR: Exploring Layers Inside the PACRR Model", "abstract": "Recent neural IR models have demonstrated deep learning's utility in ad-hoc\ninformation retrieval. However, deep models have a reputation for being black\nboxes, and the roles of a neural IR model's components may not be obvious at\nfirst glance. In this work, we attempt to shed light on the inner workings of a\nrecently proposed neural IR model, namely the PACRR model, by visualizing the\noutput of intermediate layers and by investigating the relationship between\nintermediate weights and the ultimate relevance score produced. We highlight\nseveral insights, hoping that such insights will be generally applicable.", "published": "2017-06-27 09:23:37", "link": "http://arxiv.org/abs/1706.08746v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Acoustic Modeling Using a Shallow CNN-HTSVM Architecture", "abstract": "High-accuracy speech recognition is especially challenging when large\ndatasets are not available. It is possible to bridge this gap with careful and\nknowledge-driven parsing combined with the biologically inspired CNN and the\nlearning guarantees of the Vapnik Chervonenkis (VC) theory. This work presents\na Shallow-CNN-HTSVM (Hierarchical Tree Support Vector Machine classifier)\narchitecture which uses a predefined knowledge-based set of rules with\nstatistical machine learning techniques. Here we show that gross errors present\neven in state-of-the-art systems can be avoided and that an accurate acoustic\nmodel can be built in a hierarchical fashion. The CNN-HTSVM acoustic model\noutperforms traditional GMM-HMM models and the HTSVM structure outperforms a\nMLP multi-class classifier. More importantly we isolate the performance of the\nacoustic model and provide results on both the frame and phoneme level\nconsidering the true robustness of the model. We show that even with a small\namount of data accurate and robust recognition rates can be obtained.", "published": "2017-06-27 21:28:31", "link": "http://arxiv.org/abs/1706.09055v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
