{"title": "Yall should read this! Identifying Plurality in Second-Person Personal\n  Pronouns in English Texts", "abstract": "Distinguishing between singular and plural \"you\" in English is a challenging\ntask which has potential for downstream applications, such as machine\ntranslation or coreference resolution. While formal written English does not\ndistinguish between these cases, other languages (such as Spanish), as well as\nother dialects of English (via phrases such as \"yall\"), do make this\ndistinction. We make use of this to obtain distantly-supervised labels for the\ntask on a large-scale in two domains. Following, we train a model to\ndistinguish between the single/plural you, finding that although in-domain\ntraining achieves reasonable accuracy (over 77%), there is still a lot of room\nfor improvement, especially in the domain-transfer scenario, which proves\nextremely challenging. Our code and data are publicly available.", "published": "2019-10-26 00:21:18", "link": "http://arxiv.org/abs/1910.11966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Suicide Risk Detection on Microblog via Suicide-Oriented Word\n  Embeddings and Layered Attention", "abstract": "Despite detection of suicidal ideation on social media has made great\nprogress in recent years, people's implicitly and anti-real contrarily\nexpressed posts still remain as an obstacle, constraining the detectors to\nacquire higher satisfactory performance. Enlightened by the hidden \"tree holes\"\nphenomenon on microblog, where people at suicide risk tend to disclose their\ninner real feelings and thoughts to the microblog space whose authors have\ncommitted suicide, we explore the use of tree holes to enhance microblog-based\nsuicide risk detection from the following two perspectives. (1) We build\nsuicide-oriented word embeddings based on tree hole contents to strength the\nsensibility of suicide-related lexicons and context based on tree hole\ncontents. (2) A two-layered attention mechanism is deployed to grasp\nintermittently changing points from individual's open blog streams, revealing\none's inner emotional world more or less. Our experimental results show that\nwith suicide-oriented word embeddings and attention, microblog-based suicide\nrisk detection can achieve over 91\\% accuracy. A large-scale well-labelled\nsuicide data set is also reported in the paper.", "published": "2019-10-26 09:40:26", "link": "http://arxiv.org/abs/1910.12038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain\n  Conversation", "abstract": "The uptake of deep learning in natural language generation (NLG) led to the\nrelease of both small and relatively large parallel corpora for training neural\nmodels. The existing data-to-text datasets are, however, aimed at task-oriented\ndialogue systems, and often thus limited in diversity and versatility. They are\ntypically crowdsourced, with much of the noise left in them. Moreover, current\nneural NLG models do not take full advantage of large training data, and due to\ntheir strong generalizing properties produce sentences that look template-like\nregardless. We therefore present a new corpus of 7K samples, which (1) is clean\ndespite being crowdsourced, (2) has utterances of 9 generalizable and\nconversational dialogue act types, making it more suitable for open-domain\ndialogue systems, and (3) explores the domain of video games, which is new to\ndialogue systems despite having excellent potential for supporting rich\nconversations.", "published": "2019-10-26 20:18:59", "link": "http://arxiv.org/abs/1910.12129v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis for Arabic in Social Media Network: A Systematic\n  Mapping Study", "abstract": "With the expansion in tenders on the Internet and social media, Arabic\nSentiment Analysis (ASA) has assumed a significant position in the field of\ntext mining study and has since remained used to explore the sentiments of\nusers about services, various products or topics conversed over the Internet.\nThis mapping paper designs to comprehensively investigate the papers\ndemographics, fertility, and directions of the ASA research domain.\nFurthermore, plans to analyze current ASA techniques and find movements in the\nresearch. This paper describes a systematic mapping study (SMS) of 51 primary\nselected studies (PSS) is handled with the approval of an evidence-based\nsystematic method to ensure handling of all related papers. The analyzed\nresults showed the increase of both the ASA research area and numbers of\npublications per year since 2015. Three main research facets were found, i.e.\nvalidation, solution, and evaluation research, with solution research becoming\nmore treatment than another research type. Therefore numerous contribution\nfacets were singled out. In totality, the general demographics of the ASA\nresearch field were highlighted and discussed", "published": "2019-10-26 08:38:19", "link": "http://arxiv.org/abs/1911.05483v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "abstract": "Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.", "published": "2019-10-26 14:29:37", "link": "http://arxiv.org/abs/1910.12073v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Meta Learning for End-to-End Low-Resource Speech Recognition", "abstract": "In this paper, we proposed to apply meta learning approach for low-resource\nautomatic speech recognition (ASR). We formulated ASR for different languages\nas different tasks, and meta-learned the initialization parameters from many\npretraining languages to achieve fast adaptation on unseen target language, via\nrecently proposed model-agnostic meta learning algorithm (MAML). We evaluated\nthe proposed approach using six languages as pretraining tasks and four\nlanguages as target tasks. Preliminary results showed that the proposed method,\nMetaASR, significantly outperforms the state-of-the-art multitask pretraining\napproach on all target languages with different combinations of pretraining\nlanguages. In addition, since MAML's model-agnostic property, this paper also\nopens new research direction of applying meta learning to more speech-related\napplications.", "published": "2019-10-26 16:00:44", "link": "http://arxiv.org/abs/1910.12094v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sum-Product Networks for Robust Automatic Speaker Identification", "abstract": "We introduce sum-product networks (SPNs) for robust speech processing through\na simple robust automatic speaker identification (ASI) task. SPNs are deep\nprobabilistic graphical models capable of answering multiple probabilistic\nqueries. We show that SPNs are able to remain robust by using the marginal\nprobability density function (PDF) of the spectral features that reliably\nrepresent speech. Though current SPN toolkits and learning algorithms are in\ntheir infancy, we aim to show that SPNs have the potential to become a useful\ntool for robust speech processing in the future. SPN speaker models are\nevaluated here on real-world non-stationary and coloured noise sources at\nmultiple signal-to-noise ratio (SNR) levels. In terms of ASI accuracy, we find\nthat SPN speaker models are more robust than two recent convolutional neural\nnetwork (CNN)-based ASI systems. Additionally, SPN speaker models consist of\nsignificantly fewer parameters than their CNN-based counterparts. The results\nindicate that SPN speaker models could be a robust, parameter-efficient\nalternative for ASI. Additionally, this work demonstrates that SPNs have\npotential in related tasks, such as robust automatic speech recognition (ASR)\nand automatic speaker verification (ASV). Availability: The SPN ASI system is\navailable at https://github.com/anicolson/SPN-ASI.", "published": "2019-10-26 00:40:55", "link": "http://arxiv.org/abs/1910.11969v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Image to Image Translation based on Convolutional Neural Network\n  Approach for Speech Declipping", "abstract": "Clipping, as a current nonlinear distortion, often occurs due to the limited\ndynamic range of audio recorders. It degrades the speech quality and\nintelligibility and adversely affects the performances of speech and speaker\nrecognitions. In this paper, we focus on enhancement of clipped speech by using\na fully convolutional neural network as U-Net. Motivated by the idea of\nimage-to-image translation, we propose a declipping approach, namely U-Net\ndeclipper in which the magnitude spectrum images of clipped signals are\ntranslated to the corresponding images of clean ones. The experimental results\nshow that the proposed approach outperforms other declipping methods in terms\nof both quality and intelligibility measures, especially in severe clipping\ncases. Moreover, the superior performance of the U-Net declipper over the\nwell-known declipping methods is verified in additive Gaussian noise\nconditions.", "published": "2019-10-26 18:57:21", "link": "http://arxiv.org/abs/1910.12116v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Mellotron: Multispeaker expressive voice synthesis by conditioning on\n  rhythm, pitch and global style tokens", "abstract": "Mellotron is a multispeaker voice synthesis model based on Tacotron 2 GST\nthat can make a voice emote and sing without emotive or singing training data.\nBy explicitly conditioning on rhythm and continuous pitch contours from an\naudio signal or music score, Mellotron is able to generate speech in a variety\nof styles ranging from read speech to expressive speech, from slow drawls to\nrap and from monotonous voice to singing voice. Unlike other methods, we train\nMellotron using only read speech data without alignments between text and\naudio. We evaluate our models using the LJSpeech and LibriTTS datasets. We\nprovide F0 Frame Errors and synthesized samples that include style transfer\nfrom other speakers, singers and styles not seen during training, procedural\nmanipulation of rhythm and pitch and choir synthesis.", "published": "2019-10-26 04:28:49", "link": "http://arxiv.org/abs/1910.11997v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Model-agnostic Approaches to Handling Noisy Labels When Training Sound\n  Event Classifiers", "abstract": "Label noise is emerging as a pressing issue in sound event classification.\nThis arises as we move towards larger datasets that are difficult to annotate\nmanually, but it is even more severe if datasets are collected automatically\nfrom online repositories, where labels are inferred through automated\nheuristics applied to the audio content or metadata. While learning from noisy\nlabels has been an active area of research in computer vision, it has received\nlittle attention in sound event classification. Most recent computer vision\napproaches against label noise are relatively complex, requiring complex\nnetworks or extra data resources. In this work, we evaluate simple and\nefficient model-agnostic approaches to handling noisy labels when training\nsound event classifiers, namely label smoothing regularization, mixup and\nnoise-robust loss functions. The main advantage of these methods is that they\ncan be easily incorporated to existing deep learning pipelines without need for\nnetwork modifications or extra resources. We report results from experiments\nconducted with the FSDnoisy18k dataset. We show that these simple methods can\nbe effective in mitigating the effect of label noise, providing up to 2.5\\% of\naccuracy boost when incorporated to two different CNNs, while requiring minimal\nintervention and computational overhead.", "published": "2019-10-26 05:53:01", "link": "http://arxiv.org/abs/1910.12004v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "A holistic approach to polyphonic music transcription with neural\n  networks", "abstract": "We present a framework based on neural networks to extract music scores\ndirectly from polyphonic audio in an end-to-end fashion. Most previous\nAutomatic Music Transcription (AMT) methods seek a piano-roll representation of\nthe pitches, that can be further transformed into a score by incorporating\ntempo estimation, beat tracking, key estimation or rhythm quantization. Unlike\nthese methods, our approach generates music notation directly from the input\naudio in a single stage. For this, we use a Convolutional Recurrent Neural\nNetwork (CRNN) with Connectionist Temporal Classification (CTC) loss function\nwhich does not require annotated alignments of audio frames with the score\nrhythmic information. We trained our model using as input Haydn, Mozart, and\nBeethoven string quartets and Bach chorales synthesized with different tempos\nand expressive performances. The output is a textual representation of\nfour-voice music scores based on **kern format. Although the proposed approach\nis evaluated in a simplified scenario, results show that this model can learn\nto transcribe scores directly from audio signals, opening a promising avenue\ntowards complete AMT.", "published": "2019-10-26 15:19:11", "link": "http://arxiv.org/abs/1910.12086v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Detection of Adversarial Attacks and Characterization of Adversarial\n  Subspace", "abstract": "Adversarial attacks have always been a serious threat for any data-driven\nmodel. In this paper, we explore subspaces of adversarial examples in unitary\nvector domain, and we propose a novel detector for defending our models trained\nfor environmental sound classification. We measure chordal distance between\nlegitimate and malicious representation of sounds in unitary space of\ngeneralized Schur decomposition and show that their manifolds lie far from each\nother. Our front-end detector is a regularized logistic regression which\ndiscriminates eigenvalues of legitimate and adversarial spectrograms. The\nexperimental results on three benchmarking datasets of environmental sounds\nrepresented by spectrograms reveal high detection rate of the proposed detector\nfor eight types of adversarial attacks and outperforms other detection\napproaches.", "published": "2019-10-26 15:14:51", "link": "http://arxiv.org/abs/1910.12084v1", "categories": ["cs.LG", "cs.CR", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
