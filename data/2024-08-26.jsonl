{"title": "Risk-indifference Pricing of American-style Contingent Claims", "abstract": "This paper studies the pricing of contingent claims of American style, using\nindifference pricing by fully dynamic convex risk measures. We provide a\ngeneral definition of risk-indifference prices for buyers and sellers in\ncontinuous time, in a setting where buyer and seller have potentially different\ninformation, and show that these definitions are consistent with no-arbitrage\nprinciples. Specifying to stochastic volatility models, we characterize\nindifference prices via solutions of Backward Stochastic Differential Equations\nreflected at Backward Stochastic Differential Equations and show that this\ncharacterization provides a basis for the implementation of numerical methods\nusing deep learning.", "published": "2024-08-26 20:35:27", "link": "http://arxiv.org/abs/2409.00095v1", "categories": ["q-fin.PR", "math.PR", "q-fin.MF", "60"], "primary_category": "q-fin.PR"}
{"title": "LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU", "abstract": "Stock price prediction is a challenging problem in the field of finance and\nreceives widespread attention. In recent years, with the rapid development of\ntechnologies such as deep learning and graph neural networks, more research\nmethods have begun to focus on exploring the interrelationships between stocks.\nHowever, existing methods mostly focus on the short-term dynamic relationships\nof stocks and directly integrating relationship information with temporal\ninformation. They often overlook the complex nonlinear dynamic characteristics\nand potential higher-order interaction relationships among stocks in the stock\nmarket. Therefore, we propose a stock price trend prediction model named\nLSR-IGRU in this paper, which is based on long short-term stock relationships\nand an improved GRU input. Firstly, we construct a long short-term relationship\nmatrix between stocks, where secondary industry information is employed for the\nfirst time to capture long-term relationships of stocks, and overnight price\ninformation is utilized to establish short-term relationships. Next, we improve\nthe inputs of the GRU model at each step, enabling the model to more\neffectively integrate temporal information and long short-term relationship\ninformation, thereby significantly improving the accuracy of predicting stock\ntrend changes. Finally, through extensive experiments on multiple datasets from\nstock markets in China and the United States, we validate the superiority of\nthe proposed LSR-IGRU model over the current state-of-the-art baseline models.\nWe also apply the proposed model to the algorithmic trading system of a\nfinancial company, achieving significantly higher cumulative portfolio returns\ncompared to other baseline methods. Our sources are released at\nhttps://github.com/ZP1481616577/Baselines_LSR-IGRU.", "published": "2024-08-26 02:58:37", "link": "http://arxiv.org/abs/2409.08282v2", "categories": ["q-fin.ST", "cs.CE", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Reducing the Cost: Cross-Prompt Pre-Finetuning for Short Answer Scoring", "abstract": "Automated Short Answer Scoring (SAS) is the task of automatically scoring a\ngiven input to a prompt based on rubrics and reference answers. Although SAS is\nuseful in real-world applications, both rubrics and reference answers differ\nbetween prompts, thus requiring a need to acquire new data and train a model\nfor each new prompt. Such requirements are costly, especially for schools and\nonline courses where resources are limited and only a few prompts are used. In\nthis work, we attempt to reduce this cost through a two-phase approach: train a\nmodel on existing rubrics and answers with gold score signals and finetune it\non a new prompt. Specifically, given that scoring rubrics and reference answers\ndiffer for each prompt, we utilize key phrases, or representative expressions\nthat the answer should contain to increase scores, and train a SAS model to\nlearn the relationship between key phrases and answers using already annotated\nprompts (i.e., cross-prompts). Our experimental results show that finetuning on\nexisting cross-prompt data with key phrases significantly improves scoring\naccuracy, especially when the training data is limited. Finally, our extensive\nanalysis shows that it is crucial to design the model so that it can learn the\ntask's general property.", "published": "2024-08-26 00:23:56", "link": "http://arxiv.org/abs/2408.13966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TF-Attack: Transferable and Fast Adversarial Attacks on Large Language\n  Models", "abstract": "With the great advancements in large language models (LLMs), adversarial\nattacks against LLMs have recently attracted increasing attention. We found\nthat pre-existing adversarial attack methodologies exhibit limited\ntransferability and are notably inefficient, particularly when applied to LLMs.\nIn this paper, we analyze the core mechanisms of previous predominant\nadversarial attack methods, revealing that 1) the distributions of importance\nscore differ markedly among victim models, restricting the transferability; 2)\nthe sequential attack processes induces substantial time overheads. Based on\nthe above two insights, we introduce a new scheme, named TF-Attack, for\nTransferable and Fast adversarial attacks on LLMs. TF-Attack employs an\nexternal LLM as a third-party overseer rather than the victim model to identify\ncritical units within sentences. Moreover, TF-Attack introduces the concept of\nImportance Level, which allows for parallel substitutions of attacks. We\nconduct extensive experiments on 6 widely adopted benchmarks, evaluating the\nproposed method through both automatic and human metrics. Results show that our\nmethod consistently surpasses previous methods in transferability and delivers\nsignificant speed improvements, up to 20 times faster than earlier attack\nstrategies.", "published": "2024-08-26 02:35:37", "link": "http://arxiv.org/abs/2408.13985v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Depression Diagnosis with Chain-of-Thought Prompting", "abstract": "When using AI to detect signs of depressive disorder, AI models habitually\ndraw preemptive conclusions. We theorize that using chain-of-thought (CoT)\nprompting to evaluate Patient Health Questionnaire-8 (PHQ-8) scores will\nimprove the accuracy of the scores determined by AI models. In our findings,\nwhen the models reasoned with CoT, the estimated PHQ-8 scores were consistently\ncloser on average to the accepted true scores reported by each participant\ncompared to when not using CoT. Our goal is to expand upon AI models'\nunderstanding of the intricacies of human conversation, allowing them to more\neffectively assess a patient's feelings and tone, therefore being able to more\naccurately discern mental disorder symptoms; ultimately, we hope to augment AI\nmodels' abilities, so that they can be widely accessible and used in the\nmedical field.", "published": "2024-08-26 07:19:07", "link": "http://arxiv.org/abs/2408.14053v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crowd-Calibrator: Can Annotator Disagreement Inform Calibration in\n  Subjective Tasks?", "abstract": "Subjective tasks in NLP have been mostly relegated to objective standards,\nwhere the gold label is decided by taking the majority vote. This obfuscates\nannotator disagreement and the inherent uncertainty of the label. We argue that\nsubjectivity should factor into model decisions and play a direct role via\ncalibration under a selective prediction setting. Specifically, instead of\ncalibrating confidence purely from the model's perspective, we calibrate models\nfor subjective tasks based on crowd worker agreement. Our method,\nCrowd-Calibrator, models the distance between the distribution of crowd worker\nlabels and the model's own distribution over labels to inform whether the model\nshould abstain from a decision. On two highly subjective tasks, hate speech\ndetection and natural language inference, our experiments show Crowd-Calibrator\neither outperforms or achieves competitive performance with existing selective\nprediction baselines. Our findings highlight the value of bringing human\ndecision-making into model predictions.", "published": "2024-08-26 09:37:42", "link": "http://arxiv.org/abs/2408.14141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating the effect of Mental Models in User Interaction with an\n  Adaptive Dialog Agent", "abstract": "Mental models play an important role in whether user interaction with\nintelligent systems, such as dialog systems is successful or not. Adaptive\ndialog systems present the opportunity to align a dialog agent's behavior with\nheterogeneous user expectations. However, there has been little research into\nwhat mental models users form when interacting with a task-oriented dialog\nsystem, how these models affect users' interactions, or what role system\nadaptation can play in this process, making it challenging to avoid damage to\nhuman-AI partnership. In this work, we collect a new publicly available dataset\nfor exploring user mental models about information seeking dialog systems. We\ndemonstrate that users have a variety of conflicting mental models about such\nsystems, the validity of which directly impacts the success of their\ninteractions and perceived usability of system. Furthermore, we show that\nadapting a dialog agent's behavior to better align with users' mental models,\neven when done implicitly, can improve perceived usability, dialog efficiency,\nand success. To this end, we argue that implicit adaptation can be a valid\nstrategy for task-oriented dialog systems, so long as developers first have a\nsolid understanding of users' mental models.", "published": "2024-08-26 09:57:19", "link": "http://arxiv.org/abs/2408.14154v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predictability and Causality in Spanish and English Natural Language\n  Generation", "abstract": "In recent years, the field of Natural Language Generation (NLG) has been\nboosted by the recent advances in deep learning technologies. Nonetheless,\nthese new data-intensive methods introduce language-dependent disparities in\nNLG as the main training data sets are in English. Also, most neural NLG\nsystems use decoder-only (causal) transformer language models, which work well\nfor English, but were not designed with other languages in mind. In this work\nwe depart from the hypothesis that they may introduce generation bias in target\nlanguages with less rigid word ordering, subject omission, or different\nattachment preferences for relative clauses, so that for these target languages\nother language generation strategies may be more desirable. This paper first\ncompares causal and non-causal language modeling for English and Spanish, two\nlanguages with different grammatical structures and over 1.5 billion and 0.5\nbillion speakers, respectively. For this purpose, we define a novel metric of\naverage causal and non-causal context-conditioned entropy of the grammatical\ncategory distribution for both languages as an information-theoretic a priori\napproach. The evaluation of natural text sources (such as training data) in\nboth languages reveals lower average non-causal conditional entropy in Spanish\nand lower causal conditional entropy in English. According to this experiment,\nSpanish is more predictable than English given a non-causal context. Then, by\napplying a conditional relative entropy metric to text generation experiments,\nwe obtain as insights that the best performance is respectively achieved with\ncausal NLG in English, and with non-causal NLG in Spanish. These insights\nsupport further research in NLG in Spanish using bidirectional transformer\nlanguage models.", "published": "2024-08-26 14:09:28", "link": "http://arxiv.org/abs/2408.14283v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explicit Inductive Inference using Large Language Models", "abstract": "Large Language Models (LLMs) are reported to hold undesirable attestation\nbias on inference tasks: when asked to predict if a premise P entails a\nhypothesis H, instead of considering H's conditional truthfulness entailed by\nP, LLMs tend to use the out-of-context truth label of H as a fragile proxy. In\nthis paper, we propose a pipeline that exploits this bias to do explicit\ninductive inference. Our pipeline uses an LLM to transform a premise into a set\nof attested alternatives, and then aggregate answers of the derived new\nentailment inquiries to support the original inference prediction. On a\ndirectional predicate entailment benchmark, we demonstrate that by applying\nthis simple pipeline, we can improve the overall performance of LLMs on\ninference and substantially alleviate the impact of their attestation bias.", "published": "2024-08-26 17:58:17", "link": "http://arxiv.org/abs/2408.14467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large\n  Language Models", "abstract": "Fine-tuning large language models (LLMs) on downstream tasks requires\nsubstantial computational resources. A class of parameter-efficient fine-tuning\n(PEFT) aims to mitigate these computational challenges by selectively\nfine-tuning only a small fraction of the model parameters. Although\ncomputationally efficient, these techniques often fail to match the performance\nof fully fine-tuned models, primarily due to inherent biases introduced during\nparameter selection. Traditional selective PEFT techniques use a fixed set of\nparameters based on a predefined budget (a process also known as unmasking),\nfailing to capture parameter importance dynamically and often ending up\nexceeding the budget. We introduce $\\text{ID}^3$, a novel selective PEFT method\nthat calculates parameter importance continually and dynamically unmasks\nparameters by balancing exploration and exploitation in parameter selection.\nOur empirical study on 15 tasks spanning natural language understanding and\ngenerative tasks demonstrates the effectiveness of our method compared to\nfixed-masking-based PEFT techniques. We analytically show that $\\text{ID}^3$\nreduces the number of gradient updates by a factor of two, enhancing\ncomputational efficiency. $\\text{ID}^3$ is robust to random initialization of\nneurons and, therefore, can be seamlessly integrated into existing additive and\nreparametrization-based PEFT modules such as adapters and LoRA for dynamic\nsparsification.", "published": "2024-08-26 17:58:53", "link": "http://arxiv.org/abs/2408.14470v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Surprisingly Fragile: Assessing and Addressing Prompt Instability in\n  Multimodal Foundation Models", "abstract": "Multimodal foundation models (MFMs) such as OFASys show the potential to\nunlock analysis of complex data such as images, videos, and audio data via text\nprompts alone. However, their performance may suffer in the face of text input\nthat differs even slightly from their training distribution, which is\nsurprising considering the use of modality-specific data to \"ground\" the text\ninput. This study demonstrates that prompt instability is a major concern for\nMFMs, leading to a consistent drop in performance across all modalities, but\nthat instability can be mitigated with additional training with augmented data.\nWe evaluate several methods for grounded prompt perturbation, where we generate\nperturbations and filter based on similarity to text and/or modality data.\nAfter re-training the models on the augmented data, we find improved accuracy\nand more stable performance on the perturbed test data regardless of\nperturbation condition, suggesting that the data augmentation strategy helps\nthe models handle domain shifts more effectively. In error analysis, we find\nconsistent patterns of performance improvement across domains, suggesting that\nretraining on prompt perturbations tends to help general reasoning capabilities\nin MFMs.", "published": "2024-08-26 19:26:55", "link": "http://arxiv.org/abs/2408.14595v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "What Makes a Good Story and How Can We Measure It? A Comprehensive\n  Survey of Story Evaluation", "abstract": "With the development of artificial intelligence, particularly the success of\nLarge Language Models (LLMs), the quantity and quality of automatically\ngenerated stories have significantly increased. This has led to the need for\nautomatic story evaluation to assess the generative capabilities of computing\nsystems and analyze the quality of both automatic-generated and human-written\nstories. Evaluating a story can be more challenging than other generation\nevaluation tasks. While tasks like machine translation primarily focus on\nassessing the aspects of fluency and accuracy, story evaluation demands complex\nadditional measures such as overall coherence, character development,\ninterestingness, etc. This requires a thorough review of relevant research. In\nthis survey, we first summarize existing storytelling tasks, including\ntext-to-text, visual-to-text, and text-to-visual. We highlight their evaluation\nchallenges, identify various human criteria to measure stories, and present\nexisting benchmark datasets. Then, we propose a taxonomy to organize evaluation\nmetrics that have been developed or can be adopted for story evaluation. We\nalso provide descriptions of these metrics, along with the discussion of their\nmerits and limitations. Later, we discuss the human-AI collaboration for story\nevaluation and generation. Finally, we suggest potential future research\ndirections, extending from story evaluation to general evaluations.", "published": "2024-08-26 20:35:42", "link": "http://arxiv.org/abs/2408.14622v1", "categories": ["cs.CL", "A.1; I.2.7; I.2.10"], "primary_category": "cs.CL"}
{"title": "On-Device Language Models: A Comprehensive Review", "abstract": "The advent of large language models (LLMs) revolutionized natural language\nprocessing applications, and running LLMs on edge devices has become\nincreasingly attractive for reasons including reduced latency, data\nlocalization, and personalized user experiences. This comprehensive review\nexamines the challenges of deploying computationally expensive LLMs on\nresource-constrained devices and explores innovative solutions across multiple\ndomains. The paper investigates the development of on-device language models,\ntheir efficient architectures, including parameter sharing and modular designs,\nas well as state-of-the-art compression techniques like quantization, pruning,\nand knowledge distillation. Hardware acceleration strategies and collaborative\nedge-cloud deployment approaches are analyzed, highlighting the intricate\nbalance between performance and resource utilization. Case studies of on-device\nlanguage models from major mobile manufacturers demonstrate real-world\napplications and potential benefits. The review also addresses critical aspects\nsuch as adaptive learning, multi-modal capabilities, and personalization. By\nidentifying key research directions and open challenges, this paper provides a\nroadmap for future advancements in on-device language models, emphasizing the\nneed for interdisciplinary efforts to realize the full potential of ubiquitous,\nintelligent computing while ensuring responsible and ethical deployment. For a\ncomprehensive review of research work and educational resources on on-device\nlarge language models (LLMs), please visit\nhttps://github.com/NexaAI/Awesome-LLMs-on-device. To download and run on-device\nLLMs, visit https://www.nexaai.com/models.", "published": "2024-08-26 03:33:36", "link": "http://arxiv.org/abs/2409.00088v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question answering system of bridge design specification based on large\n  language model", "abstract": "This paper constructs question answering system for bridge design\nspecification based on large language model. Three implementation schemes are\ntried: full fine-tuning of the Bert pretrained model, parameter-efficient\nfine-tuning of the Bert pretrained model, and self-built language model from\nscratch. Through the self-built question and answer task dataset, based on the\ntensorflow and keras deep learning platform framework, the model is constructed\nand trained to predict the start position and end position of the answer in the\nbridge design specification given by the user. The experimental results show\nthat full fine-tuning of the Bert pretrained model achieves 100% accuracy in\nthe training-dataset, validation-dataset and test-dataset, and the system can\nextract the answers from the bridge design specification given by the user to\nanswer various questions of the user; While parameter-efficient fine-tuning of\nthe Bert pretrained model and self-built language model from scratch perform\nwell in the training-dataset, their generalization ability in the test-dataset\nneeds to be improved. The research of this paper provides a useful reference\nfor the development of question answering system in professional field.", "published": "2024-08-26 02:53:55", "link": "http://arxiv.org/abs/2408.13282v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Focused Large Language Models are Stable Many-Shot Learners", "abstract": "In-Context Learning (ICL) enables large language models (LLMs) to achieve\nrapid task adaptation by learning from demonstrations. With the increase in\navailable context length of LLMs, recent experiments have shown that the\nperformance of ICL does not necessarily scale well in many-shot (demonstration)\nsettings. We theoretically and experimentally confirm that the reason lies in\nmore demonstrations dispersing the model attention from the query, hindering\nits understanding of key content. Inspired by how humans learn from examples,\nwe propose a training-free method FocusICL, which conducts triviality filtering\nto avoid attention being diverted by unimportant contents at token-level and\noperates hierarchical attention to further ensure sufficient attention towards\ncurrent query at demonstration-level. We also design an efficient\nhyperparameter searching strategy for FocusICL based on model perplexity of\ndemonstrations. Comprehensive experiments validate that FocusICL achieves an\naverage performance improvement of 5.2% over vanilla ICL and scales well with\nmany-shot demonstrations.", "published": "2024-08-26 02:53:24", "link": "http://arxiv.org/abs/2408.13987v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning Subspace for Text Clustering", "abstract": "Contrastive learning has been frequently investigated to learn effective\nrepresentations for text clustering tasks. While existing contrastive\nlearning-based text clustering methods only focus on modeling instance-wise\nsemantic similarity relationships, they ignore contextual information and\nunderlying relationships among all instances that needs to be clustered. In\nthis paper, we propose a novel text clustering approach called Subspace\nContrastive Learning (SCL) which models cluster-wise relationships among\ninstances. Specifically, the proposed SCL consists of two main modules: (1) a\nself-expressive module that constructs virtual positive samples and (2) a\ncontrastive learning module that further learns a discriminative subspace to\ncapture task-specific cluster-wise relationships among texts. Experimental\nresults show that the proposed SCL method not only has achieved superior\nresults on multiple task clustering datasets but also has less complexity in\npositive sample construction.", "published": "2024-08-26 09:08:26", "link": "http://arxiv.org/abs/2408.14119v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Faceted Evaluation of Modeling Languages for Augmented Reality\n  Applications -- The Case of ARWFML", "abstract": "The evaluation of modeling languages for augmented reality applications poses\nparticular challenges due to the three-dimensional environment they target. The\npreviously introduced Augmented Reality Workflow Modeling Language (ARWFML)\nenables the model-based creation of augmented reality scenarios without\nprogramming knowledge. Building upon the first design cycle of the language's\nspecification, this paper presents two further design iterations for refining\nthe language based on multi-faceted evaluations. These include a comparative\nevaluation of implementation options and workflow capabilities, the\nintroduction of a 3D notation, and the development of a new 3D modeling\nenvironment. On this basis, a comprehensibility study of the language was\nconducted. Thereby, we show how modeling languages for augmented reality can be\nevolved towards a maturity level suitable for empirical evaluations.", "published": "2024-08-26 09:34:36", "link": "http://arxiv.org/abs/2408.14137v1", "categories": ["cs.CL", "cs.ET"], "primary_category": "cs.CL"}
{"title": "An Evaluation of Explanation Methods for Black-Box Detectors of\n  Machine-Generated Text", "abstract": "The increasing difficulty to distinguish language-model-generated from\nhuman-written text has led to the development of detectors of machine-generated\ntext (MGT). However, in many contexts, a black-box prediction is not\nsufficient, it is equally important to know on what grounds a detector made\nthat prediction. Explanation methods that estimate feature importance promise\nto provide indications of which parts of an input are used by classifiers for\nprediction. However, the quality of different explanation methods has not\npreviously been assessed for detectors of MGT. This study conducts the first\nsystematic evaluation of explanation quality for this task. The dimensions of\nfaithfulness and stability are assessed with five automated experiments, and\nusefulness is evaluated in a user study. We use a dataset of ChatGPT-generated\nand human-written documents, and pair predictions of three existing\nlanguage-model-based detectors with the corresponding SHAP, LIME, and Anchor\nexplanations. We find that SHAP performs best in terms of faithfulness,\nstability, and in helping users to predict the detector's behavior. In\ncontrast, LIME, perceived as most useful by users, scores the worst in terms of\nuser performance at predicting the detectors' behavior.", "published": "2024-08-26 13:14:26", "link": "http://arxiv.org/abs/2408.14252v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Epidemic Information Extraction for Event-Based Surveillance using Large\n  Language Models", "abstract": "This paper presents a novel approach to epidemic surveillance, leveraging the\npower of Artificial Intelligence and Large Language Models (LLMs) for effective\ninterpretation of unstructured big data sources, like the popular ProMED and\nWHO Disease Outbreak News. We explore several LLMs, evaluating their\ncapabilities in extracting valuable epidemic information. We further enhance\nthe capabilities of the LLMs using in-context learning, and test the\nperformance of an ensemble model incorporating multiple open-source LLMs. The\nfindings indicate that LLMs can significantly enhance the accuracy and\ntimeliness of epidemic modelling and forecasting, offering a promising tool for\nmanaging future pandemic events.", "published": "2024-08-26 13:53:04", "link": "http://arxiv.org/abs/2408.14277v1", "categories": ["cs.CE", "cs.CL", "68T01, 68T50", "I.2; I.2.7; I.2.6"], "primary_category": "cs.CE"}
{"title": "Claim Verification in the Age of Large Language Models: A Survey", "abstract": "The large and ever-increasing amount of data available on the Internet\ncoupled with the laborious task of manual claim and fact verification has\nsparked the interest in the development of automated claim verification\nsystems. Several deep learning and transformer-based models have been proposed\nfor this task over the years. With the introduction of Large Language Models\n(LLMs) and their superior performance in several NLP tasks, we have seen a\nsurge of LLM-based approaches to claim verification along with the use of novel\nmethods such as Retrieval Augmented Generation (RAG). In this survey, we\npresent a comprehensive account of recent claim verification frameworks using\nLLMs. We describe the different components of the claim verification pipeline\nused in these frameworks in detail including common approaches to retrieval,\nprompting, and fine-tuning. Finally, we describe publicly available English\ndatasets created for this task.", "published": "2024-08-26 14:45:03", "link": "http://arxiv.org/abs/2408.14317v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Probing Causality Manipulation of Large Language Models", "abstract": "Large language models (LLMs) have shown various ability on natural language\nprocessing, including problems about causality. It is not intuitive for LLMs to\ncommand causality, since pretrained models usually work on statistical\nassociations, and do not focus on causes and effects in sentences. So that\nprobing internal manipulation of causality is necessary for LLMs. This paper\nproposes a novel approach to probe causality manipulation hierarchically, by\nproviding different shortcuts to models and observe behaviors. We exploit\nretrieval augmented generation (RAG) and in-context learning (ICL) for models\non a designed causality classification task. We conduct experiments on\nmainstream LLMs, including GPT-4 and some smaller and domain-specific models.\nOur results suggest that LLMs can detect entities related to causality and\nrecognize direct causal relationships. However, LLMs lack specialized cognition\nfor causality, merely treating them as part of the global semantic of the\nsentence.", "published": "2024-08-26 16:00:41", "link": "http://arxiv.org/abs/2408.14380v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR\n  Errors with LLM-generated Synthetic Dialogues", "abstract": "Automatic Speech Recognition (ASR) systems are pivotal in transcribing speech\ninto text, yet the errors they introduce can significantly degrade the\nperformance of downstream tasks like summarization. This issue is particularly\npronounced in clinical dialogue summarization, a low-resource domain where\nsupervised data for fine-tuning is scarce, necessitating the use of ASR models\nas black-box solutions. Employing conventional data augmentation for enhancing\nthe noise robustness of summarization models is not feasible either due to the\nunavailability of sufficient medical dialogue audio recordings and\ncorresponding ASR transcripts. To address this challenge, we propose MEDSAGE,\nan approach for generating synthetic samples for data augmentation using Large\nLanguage Models (LLMs). Specifically, we leverage the in-context learning\ncapabilities of LLMs and instruct them to generate ASR-like errors based on a\nfew available medical dialogue examples with audio recordings. Experimental\nresults show that LLMs can effectively model ASR noise, and incorporating this\nnoisy data into the training process significantly improves the robustness and\naccuracy of medical dialogue summarization systems. This approach addresses the\nchallenges of noisy ASR outputs in critical applications, offering a robust\nsolution to enhance the reliability of clinical dialogue summarization.", "published": "2024-08-26 17:04:00", "link": "http://arxiv.org/abs/2408.14418v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models on Spatial Tasks: A Multi-Task\n  Benchmarking Study", "abstract": "The emergence of large language models such as ChatGPT, Gemini, and others\nhighlights the importance of evaluating their diverse capabilities, ranging\nfrom natural language understanding to code generation. However, their\nperformance on spatial tasks has not been thoroughly assessed. This study\naddresses this gap by introducing a new multi-task spatial evaluation dataset\ndesigned to systematically explore and compare the performance of several\nadvanced models on spatial tasks. The dataset includes twelve distinct task\ntypes, such as spatial understanding and simple route planning, each with\nverified and accurate answers. We evaluated multiple models, including OpenAI's\ngpt-3.5-turbo, gpt-4-turbo, gpt-4o, ZhipuAI's glm-4, Anthropic's\nclaude-3-sonnet-20240229, and MoonShot's moonshot-v1-8k, using a two-phase\ntesting approach. First, we conducted zero-shot testing. Then, we categorized\nthe dataset by difficulty and performed prompt-tuning tests. Results show that\ngpt-4o achieved the highest overall accuracy in the first phase, with an\naverage of 71.3%. Although moonshot-v1-8k slightly underperformed overall, it\noutperformed gpt-4o in place name recognition tasks. The study also highlights\nthe impact of prompt strategies on model performance in specific tasks. For\ninstance, the Chain-of-Thought (CoT) strategy increased gpt-4o's accuracy in\nsimple route planning from 12.4% to 87.5%, while a one-shot strategy improved\nmoonshot-v1-8k's accuracy in mapping tasks from 10.1% to 76.3%.", "published": "2024-08-26 17:25:16", "link": "http://arxiv.org/abs/2408.14438v4", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Improving Clinical Note Generation from Complex Doctor-Patient\n  Conversation", "abstract": "Writing clinical notes and documenting medical exams is a critical task for\nhealthcare professionals, serving as a vital component of patient care\ndocumentation. However, manually writing these notes is time-consuming and can\nimpact the amount of time clinicians can spend on direct patient interaction\nand other tasks. Consequently, the development of automated clinical note\ngeneration systems has emerged as a clinically meaningful area of research\nwithin AI for health. In this paper, we present three key contributions to the\nfield of clinical note generation using large language models (LLMs). First, we\nintroduce CliniKnote, a comprehensive dataset consisting of 1,200 complex\ndoctor-patient conversations paired with their full clinical notes. This\ndataset, created and curated by medical experts with the help of modern neural\nnetworks, provides a valuable resource for training and evaluating models in\nclinical note generation tasks. Second, we propose the K-SOAP (Keyword,\nSubjective, Objective, Assessment, and Plan) note format, which enhances\ntraditional SOAP~\\cite{podder2023soap} (Subjective, Objective, Assessment, and\nPlan) notes by adding a keyword section at the top, allowing for quick\nidentification of essential information. Third, we develop an automatic\npipeline to generate K-SOAP notes from doctor-patient conversations and\nbenchmark various modern LLMs using various metrics. Our results demonstrate\nsignificant improvements in efficiency and performance compared to standard LLM\nfinetuning methods.", "published": "2024-08-26 18:39:31", "link": "http://arxiv.org/abs/2408.14568v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training-Free Activation Sparsity in Large Language Models", "abstract": "Activation sparsity can enable practical inference speedups in large language\nmodels (LLMs) by reducing the compute and memory-movement required for matrix\nmultiplications during the forward pass. However, existing methods face\nlimitations that inhibit widespread adoption. Some approaches are tailored\ntowards older models with ReLU-based sparsity, while others require extensive\ncontinued pre-training on up to hundreds of billions of tokens. This paper\ndescribes TEAL, a simple training-free method that applies magnitude-based\nactivation sparsity to hidden states throughout the entire model. TEAL achieves\n40-50% model-wide sparsity with minimal performance degradation across Llama-2,\nLlama-3, and Mistral families, with sizes varying from 7B to 70B. We improve\nexisting sparse kernels and demonstrate wall-clock decoding speed-ups of up to\n1.53$\\times$ and 1.8$\\times$ at 40% and 50% model-wide sparsity. TEAL is\ncompatible with weight quantization, enabling further efficiency gains.", "published": "2024-08-26 23:30:15", "link": "http://arxiv.org/abs/2408.14690v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating ChatGPT on Nuclear Domain-Specific Data", "abstract": "This paper examines the application of ChatGPT, a large language model (LLM),\nfor question-and-answer (Q&A) tasks in the highly specialized field of nuclear\ndata. The primary focus is on evaluating ChatGPT's performance on a curated\ntest dataset, comparing the outcomes of a standalone LLM with those generated\nthrough a Retrieval Augmented Generation (RAG) approach. LLMs, despite their\nrecent advancements, are prone to generating incorrect or 'hallucinated'\ninformation, which is a significant limitation in applications requiring high\naccuracy and reliability. This study explores the potential of utilizing RAG in\nLLMs, a method that integrates external knowledge bases and sophisticated\nretrieval techniques to enhance the accuracy and relevance of generated\noutputs. In this context, the paper evaluates ChatGPT's ability to answer\ndomain-specific questions, employing two methodologies: A) direct response from\nthe LLM, and B) response from the LLM within a RAG framework. The effectiveness\nof these methods is assessed through a dual mechanism of human and LLM\nevaluation, scoring the responses for correctness and other metrics. The\nfindings underscore the improvement in performance when incorporating a RAG\npipeline in an LLM, particularly in generating more accurate and contextually\nappropriate responses for nuclear domain-specific queries. Additionally, the\npaper highlights alternative approaches to further refine and improve the\nquality of answers in such specialized domains.", "published": "2024-08-26 08:17:42", "link": "http://arxiv.org/abs/2409.00090v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Model for Patent Concept Generation", "abstract": "In traditional innovation practices, concept and IP generation are often\niteratively integrated. Both processes demand an intricate understanding of\nadvanced technical domain knowledge. Existing large language models (LLMs),\nwhile possessing massive pre-trained knowledge, often fall short in the\ninnovative concept generation due to a lack of specialized knowledge necessary\nfor the generation. To bridge this critical gap, we propose a novel knowledge\nfinetuning (KFT) framework to endow LLM-based AI with the ability to\nautonomously mine, understand, and apply domain-specific knowledge and concepts\nfor invention generation, i.e., concept and patent generation together. Our\nproposed PatentGPT integrates knowledge injection pre-training (KPT),\ndomain-specific supervised finetuning (SFT), and reinforcement learning from\nhuman feedback (RLHF). Extensive evaluation shows that PatentGPT significantly\noutperforms the state-of-the-art models on patent-related benchmark tests. Our\nmethod not only provides new insights into data-driven innovation but also\npaves a new path to fine-tune LLMs for applications in the context of\ntechnology. We also discuss the managerial and policy implications of\nAI-generating inventions in the future.", "published": "2024-08-26 12:00:29", "link": "http://arxiv.org/abs/2409.00092v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Examining Independence in Ensemble Sentiment Analysis: A Study on the\n  Limits of Large Language Models Using the Condorcet Jury Theorem", "abstract": "This paper explores the application of the Condorcet Jury theorem to the\ndomain of sentiment analysis, specifically examining the performance of various\nlarge language models (LLMs) compared to simpler natural language processing\n(NLP) models. The theorem posits that a majority vote classifier should enhance\npredictive accuracy, provided that individual classifiers' decisions are\nindependent. Our empirical study tests this theoretical framework by\nimplementing a majority vote mechanism across different models, including\nadvanced LLMs such as ChatGPT 4. Contrary to expectations, the results reveal\nonly marginal improvements in performance when incorporating larger models,\nsuggesting a lack of independence among them. This finding aligns with the\nhypothesis that despite their complexity, LLMs do not significantly outperform\nsimpler models in reasoning tasks within sentiment analysis, showing the\npractical limits of model independence in the context of advanced NLP tasks.", "published": "2024-08-26 14:04:00", "link": "http://arxiv.org/abs/2409.00094v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models", "abstract": "With the prevalence of large-scale pretrained vision-language models (VLMs),\nsuch as CLIP, soft-prompt tuning has become a popular method for adapting these\nmodels to various downstream tasks. However, few works delve into the inherent\nproperties of learnable soft-prompt vectors, specifically the impact of their\nnorms to the performance of VLMs. This motivates us to pose an unexplored\nresearch question: ``Do we need to normalize the soft prompts in VLMs?'' To\nfill this research gap, we first uncover a phenomenon, called the\n\\textbf{Low-Norm Effect} by performing extensive corruption experiments,\nsuggesting that reducing the norms of certain learned prompts occasionally\nenhances the performance of VLMs, while increasing them often degrades it. To\nharness this effect, we propose a novel method named \\textbf{N}ormalizing\nth\\textbf{e} soft-pro\\textbf{m}pt v\\textbf{e}ctors of vi\\textbf{si}on-language\nmodel\\textbf{s} (\\textbf{Nemesis}) to normalize soft-prompt vectors in VLMs. To\nthe best of our knowledge, our work is the first to systematically investigate\nthe role of norms of soft-prompt vector in VLMs, offering valuable insights for\nfuture research in soft-prompt tuning. The code is available at\n\\texttt{\\href{https://github.com/ShyFoo/Nemesis}{https://github.com/ShyFoo/Nemesis}}.", "published": "2024-08-26 02:09:05", "link": "http://arxiv.org/abs/2408.13979v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AgentMove: A Large Language Model based Agentic Framework for Zero-shot\n  Next Location Prediction", "abstract": "Next location prediction plays a crucial role in various real-world\napplications. Recently, due to the limitation of existing deep learning\nmethods, attempts have been made to apply large language models (LLMs) to\nzero-shot next location prediction task. However, they directly generate the\nfinal output using LLMs without systematic design, which limits the potential\nof LLMs to uncover complex mobility patterns and underestimates their extensive\nreserve of global geospatial knowledge. In this paper, we introduce AgentMove,\na systematic agentic prediction framework to achieve generalized next location\nprediction. In AgentMove, we first decompose the mobility prediction task and\ndesign specific modules to complete them, including spatial-temporal memory for\nindividual mobility pattern mining, world knowledge generator for modeling the\neffects of urban structure and collective knowledge extractor for capturing the\nshared patterns among population. Finally, we combine the results of three\nmodules and conduct a reasoning step to generate the final predictions.\nExtensive experiments utilizing mobility data from two distinct sources reveal\nthat AgentMove surpasses the leading baseline by 3.33% to 8.57% across 8 out of\n12 metrics and it shows robust predictions with various LLMs as base and also\nless geographical bias across cities. Our codes are available via\nhttps://github.com/tsinghua-fib-lab/AgentMove.", "published": "2024-08-26 02:36:55", "link": "http://arxiv.org/abs/2408.13986v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Empowering Low-Resource Language ASR via Large-Scale Pseudo Labeling", "abstract": "In this study, we tackle the challenge of limited labeled data for\nlow-resource languages in ASR, focusing on Hindi. Specifically, we explore\npseudo-labeling, by proposing a generic framework combining multiple ideas from\nexisting works. Our framework integrates multiple base models for transcription\nand evaluators for assessing audio-transcript pairs, resulting in robust\npseudo-labeling for low resource languages. We validate our approach with a new\nbenchmark, IndicYT, comprising diverse YouTube audio files from multiple\ncontent categories. Our findings show that augmenting pseudo labeled data from\nYouTube with existing training data leads to significant performance\nimprovements on IndicYT, without affecting performance on out-of-domain\nbenchmarks, demonstrating the efficacy of pseudo-labeled data in enhancing ASR\ncapabilities for low-resource languages. The benchmark, code and models\ndeveloped as a part of this work will be made publicly available.", "published": "2024-08-26 05:36:35", "link": "http://arxiv.org/abs/2408.14026v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SurGen: Text-Guided Diffusion Model for Surgical Video Generation", "abstract": "Diffusion-based video generation models have made significant strides,\nproducing outputs with improved visual fidelity, temporal coherence, and user\ncontrol. These advancements hold great promise for improving surgical education\nby enabling more realistic, diverse, and interactive simulation environments.\nIn this study, we introduce SurGen, a text-guided diffusion model tailored for\nsurgical video synthesis. SurGen produces videos with the highest resolution\nand longest duration among existing surgical video generation models. We\nvalidate the visual and temporal quality of the outputs using standard image\nand video generation metrics. Additionally, we assess their alignment to the\ncorresponding text prompts through a deep learning classifier trained on\nsurgical data. Our results demonstrate the potential of diffusion models to\nserve as valuable educational tools for surgical trainees.", "published": "2024-08-26 05:38:27", "link": "http://arxiv.org/abs/2408.14028v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MLR-Copilot: Autonomous Machine Learning Research based on Large\n  Language Models Agents", "abstract": "Machine learning research, crucial for technological advancements and\ninnovation, often faces significant challenges due to its inherent complexity,\nslow pace of experimentation, and the necessity for specialized expertise.\nMotivated by this, we present a new systematic framework, autonomous Machine\nLearning Research with large language models (MLR-Copilot), designed to enhance\nmachine learning research productivity through the automatic generation and\nimplementation of research ideas using Large Language Model (LLM) agents. The\nframework consists of three phases: research idea generation, experiment\nimplementation, and implementation execution. First, existing research papers\nare used to generate hypotheses and experimental plans vis IdeaAgent powered by\nLLMs. Next, the implementation generation phase translates these plans into\nexecutables with ExperimentAgent. This phase leverages retrieved prototype code\nand optionally retrieves candidate models and data. Finally, the execution\nphase, also managed by ExperimentAgent, involves running experiments with\nmechanisms for human feedback and iterative debugging to enhance the likelihood\nof achieving executable research outcomes. We evaluate our framework on five\nmachine learning research tasks and the experimental results show the\nframework's potential to facilitate the research progress and innovations.", "published": "2024-08-26 05:55:48", "link": "http://arxiv.org/abs/2408.14033v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Exploring the Potential of Large Language Models for Heterophilic Graphs", "abstract": "Large language models (LLMs) have presented significant opportunities to\nenhance various machine learning applications, including graph neural networks\n(GNNs). By leveraging the vast open-world knowledge within LLMs, we can more\neffectively interpret and utilize textual data to better characterize\nheterophilic graphs, where neighboring nodes often have different labels.\nHowever, existing approaches for heterophilic graphs overlook the rich textual\ndata associated with nodes, which could unlock deeper insights into their\nheterophilic contexts. In this work, we explore the potential of LLMs for\nmodeling heterophilic graphs and propose a novel two-stage framework:\nLLM-enhanced edge discriminator and LLM-guided edge reweighting. In the first\nstage, we fine-tune the LLM to better identify homophilic and heterophilic\nedges based on the textual content of their nodes. In the second stage, we\nadaptively manage message propagation in GNNs for different edge types based on\nnode features, structures, and heterophilic or homophilic characteristics. To\ncope with the computational demands when deploying LLMs in practical scenarios,\nwe further explore model distillation techniques to fine-tune smaller, more\nefficient models that maintain competitive performance. Extensive experiments\nvalidate the effectiveness of our framework, demonstrating the feasibility of\nusing LLMs to enhance node classification on heterophilic graphs.", "published": "2024-08-26 09:29:56", "link": "http://arxiv.org/abs/2408.14134v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Explaining Caption-Image Interactions in CLIP models with Second-Order\n  Attributions", "abstract": "Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.", "published": "2024-08-26 09:55:34", "link": "http://arxiv.org/abs/2408.14153v3", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "DSTI at LLMs4OL 2024 Task A: Intrinsic versus extrinsic knowledge for\n  type classification", "abstract": "We introduce semantic towers, an extrinsic knowledge representation method,\nand compare it to intrinsic knowledge in large language models for ontology\nlearning. Our experiments show a trade-off between performance and semantic\ngrounding for extrinsic knowledge compared to a fine-tuned model intrinsic\nknowledge. We report our findings on the Large Language Models for Ontology\nLearning (LLMs4OL) 2024 challenge.", "published": "2024-08-26 12:50:27", "link": "http://arxiv.org/abs/2408.14236v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-supervised Speech Representations Still Struggle with African\n  American Vernacular English", "abstract": "Underperformance of ASR systems for speakers of African American Vernacular\nEnglish (AAVE) and other marginalized language varieties is a well-documented\nphenomenon, and one that reinforces the stigmatization of these varieties. We\ninvestigate whether or not the recent wave of Self-Supervised Learning (SSL)\nspeech models can close the gap in ASR performance between AAVE and Mainstream\nAmerican English (MAE). We evaluate four SSL models (wav2vec 2.0, HuBERT,\nWavLM, and XLS-R) on zero-shot Automatic Speech Recognition (ASR) for these two\nvarieties and find that these models perpetuate the bias in performance against\nAAVE. Additionally, the models have higher word error rates on utterances with\nmore phonological and morphosyntactic features of AAVE. Despite the success of\nSSL speech models in improving ASR for low resource varieties, SSL pre-training\nalone may not bridge the gap between AAVE and MAE. Our code is publicly\navailable at https://github.com/cmu-llab/s3m-aave.", "published": "2024-08-26 13:29:25", "link": "http://arxiv.org/abs/2408.14262v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LLM-3D Print: Large Language Models To Monitor and Control 3D Printing", "abstract": "Industry 4.0 has revolutionized manufacturing by driving digitalization and\nshifting the paradigm toward additive manufacturing (AM). Fused Deposition\nModeling (FDM), a key AM technology, enables the creation of highly customized,\ncost-effective products with minimal material waste through layer-by-layer\nextrusion, posing a significant challenge to traditional subtractive methods.\nHowever, the susceptibility of material extrusion techniques to errors often\nrequires expert intervention to detect and mitigate defects that can severely\ncompromise product quality. While automated error detection and machine\nlearning models exist, their generalizability across diverse 3D printer setups,\nfirmware, and sensors is limited, and deep learning methods require extensive\nlabeled datasets, hindering scalability and adaptability. To address these\nchallenges, we present a process monitoring and control framework that\nleverages pre-trained Large Language Models (LLMs) alongside 3D printers to\ndetect and address printing defects. The LLM evaluates print quality by\nanalyzing images captured after each layer or print segment, identifying\nfailure modes and querying the printer for relevant parameters. It then\ngenerates and executes a corrective action plan. We validated the effectiveness\nof the proposed framework in identifying defects by comparing it against a\ncontrol group of engineers with diverse AM expertise. Our evaluation\ndemonstrated that LLM-based agents not only accurately identify common 3D\nprinting errors, such as inconsistent extrusion, stringing, warping, and layer\nadhesion, but also effectively determine the parameters causing these failures\nand autonomously correct them without any need for human intervention.", "published": "2024-08-26 14:38:19", "link": "http://arxiv.org/abs/2408.14307v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Assessing Contamination in Large Language Models: Introducing the\n  LogProber method", "abstract": "In machine learning, contamination refers to situations where testing data\nleak into the training set. The issue is particularly relevant for the\nevaluation of the performance of Large Language Models (LLMs), which are\ngenerally trained on gargantuan, and generally opaque, corpora of text scraped\nfrom the world wide web. Developing tools to detect contamination is therefore\ncrucial to be able to fairly and properly track the evolution of the\nperformance of LLMs. Most recent works in the field are not tailored to\nquantify contamination on short sequences of text like we find in psychology\nquestionnaires. In the present paper we introduce LogProber, a novel,\nefficient, algorithm that we show able to detect contamination using token\nprobability in given sentences. In the second part we investigate the\nlimitations of the method and discuss how different training methods can\ncontaminate models without leaving traces in the token probabilities.", "published": "2024-08-26 15:29:34", "link": "http://arxiv.org/abs/2408.14352v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SWE-bench-java: A GitHub Issue Resolving Benchmark for Java", "abstract": "GitHub issue resolving is a critical task in software engineering, recently\ngaining significant attention in both industry and academia. Within this task,\nSWE-bench has been released to evaluate issue resolving capabilities of large\nlanguage models (LLMs), but has so far only focused on Python version. However,\nsupporting more programming languages is also important, as there is a strong\ndemand in industry. As a first step toward multilingual support, we have\ndeveloped a Java version of SWE-bench, called SWE-bench-java. We have publicly\nreleased the dataset, along with the corresponding Docker-based evaluation\nenvironment and leaderboard, which will be continuously maintained and updated\nin the coming months. To verify the reliability of SWE-bench-java, we implement\na classic method SWE-agent and test several powerful LLMs on it. As is well\nknown, developing a high-quality multi-lingual benchmark is time-consuming and\nlabor-intensive, so we welcome contributions through pull requests or\ncollaboration to accelerate its iteration and refinement, paving the way for\nfully automated programming.", "published": "2024-08-26 15:30:05", "link": "http://arxiv.org/abs/2408.14354v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Uncovering Knowledge Gaps in Radiology Report Generation Models through\n  Knowledge Graphs", "abstract": "Recent advancements in artificial intelligence have significantly improved\nthe automatic generation of radiology reports. However, existing evaluation\nmethods fail to reveal the models' understanding of radiological images and\ntheir capacity to achieve human-level granularity in descriptions. To bridge\nthis gap, we introduce a system, named ReXKG, which extracts structured\ninformation from processed reports to construct a comprehensive radiology\nknowledge graph. We then propose three metrics to evaluate the similarity of\nnodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs\n(ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparative\nanalysis of AI-generated and human-written radiology reports, assessing the\nperformance of both specialist and generalist models. Our study provides a\ndeeper understanding of the capabilities and limitations of current AI models\nin radiology report generation, offering valuable insights for improving model\nperformance and clinical applicability.", "published": "2024-08-26 16:28:56", "link": "http://arxiv.org/abs/2408.14397v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Investigating Language-Specific Calibration For Pruning Multilingual\n  Large Language Models", "abstract": "Recent advances in large language model (LLM) pruning have shown\nstate-of-the-art (SotA) compression results in post-training and\nretraining-free settings while maintaining high predictive performance.\nHowever, previous research mainly considered calibrating based on English text,\ndespite the multilingual nature of modern LLMs and their frequent use in\nnon-English languages. In this paper, we set out to investigate calibrating the\npruning of multilingual language models for monolingual applications. We\npresent the first comprehensive empirical study, comparing different\ncalibration languages for pruning multilingual models across diverse languages,\ntasks, models, and SotA pruning techniques. Our results offer practical\nsuggestions, for example, calibrating in the target language can efficiently\nretain the language modeling capability but does not necessarily benefit\ndownstream tasks. Through further analysis of latent subspaces, pruning masks,\nand individual neurons within pruned models, we find that while pruning\ngenerally preserves strong language-specific features, it may fail to retain\nlanguage-specific neuron activation patterns and subtle, language-agnostic\nfeatures associated with knowledge and reasoning that are needed for complex\ntasks.", "published": "2024-08-26 16:29:13", "link": "http://arxiv.org/abs/2408.14398v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CHARTOM: A Visual Theory-of-Mind Benchmark for Multimodal Large Language\n  Models", "abstract": "We introduce CHARTOM, a visual theory-of-mind benchmark for multimodal large\nlanguage models. CHARTOM consists of specially designed data visualizing\ncharts. Given a chart, a language model needs to not only correctly comprehend\nthe chart (the FACT question) but also judge if the chart will be misleading to\na human reader (the MIND question). Both questions have significant societal\nbenefits. We detail the construction of the CHARTOM benchmark including its\ncalibration on human performance.", "published": "2024-08-26 17:04:23", "link": "http://arxiv.org/abs/2408.14419v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "A Practitioner's Guide to Continual Multimodal Pretraining", "abstract": "Multimodal foundation models serve numerous applications at the intersection\nof vision and language. Still, despite being pretrained on extensive data, they\nbecome outdated over time. To keep models updated, research into continual\npretraining mainly explores scenarios with either (1) infrequent,\nindiscriminate updates on large-scale new data, or (2) frequent, sample-level\nupdates. However, practical model deployment often operates in the gap between\nthese two limit cases, as real-world applications often demand adaptation to\nspecific subdomains, tasks or concepts -- spread over the entire, varying life\ncycle of a model. In this work, we complement current perspectives on continual\npretraining through a research test bed as well as provide comprehensive\nguidance for effective continual model updates in such scenarios. We first\nintroduce FoMo-in-Flux, a continual multimodal pretraining benchmark with\nrealistic compute constraints and practical deployment requirements,\nconstructed over 63 datasets with diverse visual and semantic coverage. Using\nFoMo-in-Flux, we explore the complex landscape of practical continual\npretraining through multiple perspectives: (1) A data-centric investigation of\ndata mixtures and stream orderings that emulate real-world deployment\nsituations, (2) a method-centric investigation ranging from simple fine-tuning\nand traditional continual learning strategies to parameter-efficient updates\nand model merging, (3) meta learning rate schedules and mechanistic design\nchoices, and (4) the influence of model and compute scaling. Together, our\ninsights provide a practitioner's guide to continual multimodal pretraining for\nreal-world deployment. Our benchmark and code is here:\nhttps://github.com/ExplainableML/fomo_in_flux.", "published": "2024-08-26 17:59:01", "link": "http://arxiv.org/abs/2408.14471v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Revisiting Image Captioning Training Paradigm via Direct CLIP-based\n  Optimization", "abstract": "The conventional training approach for image captioning involves pre-training\na network using teacher forcing and subsequent fine-tuning with Self-Critical\nSequence Training to maximize hand-crafted captioning metrics. However, when\nattempting to optimize modern and higher-quality metrics like CLIP-Score and\nPAC-Score, this training method often encounters instability and fails to\nacquire the genuine descriptive capabilities needed to produce fluent and\ninformative captions. In this paper, we propose a new training paradigm termed\nDirect CLIP-Based Optimization (DiCO). Our approach jointly learns and\noptimizes a reward model that is distilled from a learnable captioning\nevaluator with high human correlation. This is done by solving a weighted\nclassification problem directly inside the captioner. At the same time, DiCO\nprevents divergence from the original model, ensuring that fluency is\nmaintained. DiCO not only exhibits improved stability and enhanced quality in\nthe generated captions but also aligns more closely with human preferences\ncompared to existing methods, especially in modern metrics. Additionally, it\nmaintains competitive performance in traditional metrics. Our source code and\ntrained models are publicly available at https://github.com/aimagelab/DiCO.", "published": "2024-08-26 18:00:33", "link": "http://arxiv.org/abs/2408.14547v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting\n  Mitigation", "abstract": "This paper introduces CURLoRA, a novel approach to fine-tuning large language\nmodels (LLMs) that leverages CUR matrix decomposition in the context of\nLow-Rank Adaptation (LoRA). Our method addresses two critical challenges in LLM\nfine-tuning: mitigating catastrophic forgetting during continual learning and\nreducing the number of trainable parameters. We propose a unique modification\nto the CUR decomposition process, utilizing inverted probabilities for column\nand row selection which acts as an implicit regularization, and initializing\nthe $U$ matrix as a zero matrix, and only fine-tuning it. We demonstrate\nthrough experiments on multiple datasets that CURLoRA outperforms standard LoRA\nin mitigating catastrophic forgetting. It maintains model stability and\nperformance across tasks while significantly reducing the number of trainable\nparameters. Our results show that CURLoRA achieves very good and stable task\naccuracy while maintaining base model's perplexity scores fixed compared to\nLoRA upon continual fine-tuning, particularly in scenarios with limited data.", "published": "2024-08-26 18:42:59", "link": "http://arxiv.org/abs/2408.14572v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MODOC: A Modular Interface for Flexible Interlinking of Text Retrieval\n  and Text Generation Functions", "abstract": "Large Language Models (LLMs) produce eloquent texts but often the content\nthey generate needs to be verified. Traditional information retrieval systems\ncan assist with this task, but most systems have not been designed with\nLLM-generated queries in mind. As such, there is a compelling need for\nintegrated systems that provide both retrieval and generation functionality\nwithin a single user interface.\n  We present MODOC, a modular user interface that leverages the capabilities of\nLLMs and provides assistance with detecting their confabulations, promoting\nintegrity in scientific writing. MODOC represents a significant step forward in\nscientific writing assistance. Its modular architecture supports flexible\nfunctions for retrieving information and for writing and generating text in a\nsingle, user-friendly interface.", "published": "2024-08-26 20:36:52", "link": "http://arxiv.org/abs/2408.14623v1", "categories": ["cs.HC", "cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.HC"}
{"title": "Relationships are Complicated! An Analysis of Relationships Between\n  Datasets on the Web", "abstract": "The Web today has millions of datasets, and the number of datasets continues\nto grow at a rapid pace. These datasets are not standalone entities; rather,\nthey are intricately connected through complex relationships. Semantic\nrelationships between datasets provide critical insights for research and\ndecision-making processes. In this paper, we study dataset relationships from\nthe perspective of users who discover, use, and share datasets on the Web: what\nrelationships are important for different tasks? What contextual information\nmight users want to know? We first present a comprehensive taxonomy of\nrelationships between datasets on the Web and map these relationships to user\ntasks performed during dataset discovery. We develop a series of methods to\nidentify these relationships and compare their performance on a large corpus of\ndatasets generated from Web pages with schema.org markup. We demonstrate that\nmachine-learning based methods that use dataset metadata achieve multi-class\nclassification accuracy of 90%. Finally, we highlight gaps in available\nsemantic markup for datasets and discuss how incorporating comprehensive\nsemantics can facilitate the identification of dataset relationships. By\nproviding a comprehensive overview of dataset relationships at scale, this\npaper sets a benchmark for future research.", "published": "2024-08-26 21:00:25", "link": "http://arxiv.org/abs/2408.14636v1", "categories": ["cs.IR", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Smart Multi-Modal Search: Contextual Sparse and Dense Embedding\n  Integration in Adobe Express", "abstract": "As user content and queries become increasingly multi-modal, the need for\neffective multi-modal search systems has grown. Traditional search systems\noften rely on textual and metadata annotations for indexed images, while\nmulti-modal embeddings like CLIP enable direct search using text and image\nembeddings. However, embedding-based approaches face challenges in integrating\ncontextual features such as user locale and recency. Building a scalable\nmulti-modal search system requires fine-tuning several components. This paper\npresents a multi-modal search architecture and a series of AB tests that\noptimize embeddings and multi-modal technologies in Adobe Express template\nsearch. We address considerations such as embedding model selection, the roles\nof embeddings in matching and ranking, and the balance between dense and sparse\nembeddings. Our iterative approach demonstrates how utilizing sparse, dense,\nand contextual features enhances short and long query search, significantly\nreduces null rates (over 70\\%), and increases click-through rates (CTR). Our\nfindings provide insights into developing robust multi-modal search systems,\nthereby enhancing relevance for complex queries.", "published": "2024-08-26 23:52:27", "link": "http://arxiv.org/abs/2408.14698v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Classification of Safety Events at Nuclear Sites using Large Language\n  Models", "abstract": "This paper proposes the development of a Large Language Model (LLM) based\nmachine learning classifier designed to categorize Station Condition Records\n(SCRs) at nuclear power stations into safety-related and non-safety-related\ncategories. The primary objective is to augment the existing manual review\nprocess by enhancing the efficiency and accuracy of the safety classification\nprocess at nuclear stations. The paper discusses experiments performed to\nclassify a labeled SCR dataset and evaluates the performance of the classifier.\nIt explores the construction of several prompt variations and their observed\neffects on the LLM's decision-making process. Additionally, it introduces a\nnumerical scoring mechanism that could offer a more nuanced and flexible\napproach to SCR safety classification. This method represents an innovative\nstep in nuclear safety management, providing a scalable tool for the\nidentification of safety events.", "published": "2024-08-26 08:21:21", "link": "http://arxiv.org/abs/2409.00091v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Foundation Models for Music: A Survey", "abstract": "In recent years, foundation models (FMs) such as large language models (LLMs)\nand latent diffusion models (LDMs) have profoundly impacted diverse sectors,\nincluding music. This comprehensive review examines state-of-the-art (SOTA)\npre-trained models and foundation models in music, spanning from representation\nlearning, generative learning and multimodal learning. We first contextualise\nthe significance of music in various industries and trace the evolution of AI\nin music. By delineating the modalities targeted by foundation models, we\ndiscover many of the music representations are underexplored in FM development.\nThen, emphasis is placed on the lack of versatility of previous methods on\ndiverse music applications, along with the potential of FMs in music\nunderstanding, generation and medical application. By comprehensively exploring\nthe details of the model pre-training paradigm, architectural choices,\ntokenisation, finetuning methodologies and controllability, we emphasise the\nimportant topics that should have been well explored, like instruction tuning\nand in-context learning, scaling law and emergent ability, as well as\nlong-sequence modelling etc. A dedicated section presents insights into music\nagents, accompanied by a thorough analysis of datasets and evaluations\nessential for pre-training and downstream tasks. Finally, by underscoring the\nvital importance of ethical considerations, we advocate that following research\non FM for music should focus more on such issues as interpretability,\ntransparency, human responsibility, and copyright issues. The paper offers\ninsights into future challenges and trends on FMs for music, aiming to shape\nthe trajectory of human-AI collaboration in the music realm.", "published": "2024-08-26 15:13:14", "link": "http://arxiv.org/abs/2408.14340v3", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Spoken-Term Discovery using Discrete Speech Units", "abstract": "Discovering a lexicon from unlabeled audio is a longstanding challenge for\nzero-resource speech processing. One approach is to search for frequently\noccurring patterns in speech. We revisit this idea with DUSTED: Discrete Unit\nSpoken-TErm Discovery. Leveraging self-supervised models, we encode input audio\ninto sequences of discrete units. Next, we find repeated patterns by searching\nfor similar unit sub-sequences, inspired by alignment algorithms from\nbioinformatics. Since discretization discards speaker information, DUSTED finds\nbetter matches across speakers, improving the coverage and consistency of the\ndiscovered patterns. We demonstrate these improvements on the ZeroSpeech\nChallenge, achieving state-of-the-art results on the spoken-term discovery\ntrack. Finally, we analyze the duration distribution of the patterns, showing\nthat our method finds longer word- or phrase-like terms.", "published": "2024-08-26 16:18:41", "link": "http://arxiv.org/abs/2408.14390v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Combined assessment of auditory distance perception and externalization", "abstract": "This study investigates frontal auditory distance perception (ADP) and\nexternalization in virtual audio-visual environments, considering effects of\nheadphone rendering method, room size, reverberation, and visual representation\nof the room. Either head-related impulse responses from an artificial head or a\nspherical head model were used for diotic (monophonic) and binaural\nauralizations with and without real-time head tracking. The visuals were\npresented through a head-mounted display. Two differently sized rooms as well\nas an infinitely extending space (echoic and anechoic) were used in which an\ninvisible frontal virtual sound source was located. Additionally, the effect of\na freely movable loudspeaker for visually indicating perceived distances was\ninvestigated. Both ADP and externalization were significantly affected by room\nsize, but otherwise the two perceptual quantities differed in their outcomes.\nRoom visibility significantly affected ADP, leading to considerable\noverestimations and more variability in the absence of a visual environment,\nalthough externalization was not affected. The movable loudspeaker improved\ndistance estimation significantly, however, did not affect externalization. For\nreverberation, a (non-significant) trend of improved ADP was observed, however,\nexternalization was significantly improved. Different headphone renderings did\nnot significantly affect ADP or externalization, although a clear trend was\nobserved for externalization.", "published": "2024-08-26 11:53:56", "link": "http://arxiv.org/abs/2408.14198v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Diminishing Domain Mismatch for DNN-Based Acoustic Distance Estimation\n  via Stochastic Room Reverberation Models", "abstract": "The room impulse response (RIR) encodes, among others, information about the\ndistance of an acoustic source from the sensors. Deep neural networks (DNNs)\nhave been shown to be able to extract that information for acoustic distance\nestimation. Since there exists only a very limited amount of annotated data,\ne.g., RIRs with distance information, training a DNN for acoustic distance\nestimation has to rely on simulated RIRs, resulting in an unavoidable mismatch\nto RIRs of real rooms. In this contribution, we show that this mismatch can be\nreduced by a novel combination of geometric and stochastic modeling of RIRs,\nresulting in a significantly improved distance estimation accuracy.", "published": "2024-08-26 12:12:41", "link": "http://arxiv.org/abs/2408.14213v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Reduce Computational Complexity for Continuous Wavelet Transform in\n  Acoustic Recognition Using Hop Size", "abstract": "In recent years, the continuous wavelet transform (CWT) has been employed as\na spectral feature extractor for acoustic recognition tasks in conjunction with\nmachine learning and deep learning models. However, applying the CWT to each\nindividual audio sample is computationally intensive. This paper proposes an\napproach that applies the CWT to a subset of samples, spaced according to a\nspecified hop size. Experimental results demonstrate that this method\nsignificantly reduces computational costs while maintaining the robust\nperformance of the trained models.", "published": "2024-08-26 14:33:22", "link": "http://arxiv.org/abs/2408.14302v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "DualSpeech: Enhancing Speaker-Fidelity and Text-Intelligibility Through\n  Dual Classifier-Free Guidance", "abstract": "Text-to-Speech (TTS) models have advanced significantly, aiming to accurately\nreplicate human speech's diversity, including unique speaker identities and\nlinguistic nuances. Despite these advancements, achieving an optimal balance\nbetween speaker-fidelity and text-intelligibility remains a challenge,\nparticularly when diverse control demands are considered. Addressing this, we\nintroduce DualSpeech, a TTS model that integrates phoneme-level latent\ndiffusion with dual classifier-free guidance. This approach enables exceptional\ncontrol over speaker-fidelity and text-intelligibility. Experimental results\ndemonstrate that by utilizing the sophisticated control, DualSpeech surpasses\nexisting state-of-the-art TTS models in performance. Demos are available at\nhttps://bit.ly/48Ewoib.", "published": "2024-08-26 17:09:04", "link": "http://arxiv.org/abs/2408.14423v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Comparative Analysis Of Discriminative Deep Learning-Based Noise\n  Reduction Methods In Low SNR Scenarios", "abstract": "In this study, we conduct a comparative analysis of deep learning-based noise\nreduction methods in low signal-to-noise ratio (SNR) scenarios. Our\ninvestigation primarily focuses on five key aspects: The impact of training\ndata, the influence of various loss functions, the effectiveness of direct and\nindirect speech estimation techniques, the efficacy of masking, mapping, and\ndeep filtering methodologies, and the exploration of different model capacities\non noise reduction performance and speech quality. Through comprehensive\nexperimentation, we provide insights into the strengths, weaknesses, and\napplicability of these methods in low SNR environments. The findings derived\nfrom our analysis are intended to assist both researchers and practitioners in\nselecting better techniques tailored to their specific applications within the\ndomain of low SNR noise reduction.", "published": "2024-08-26 19:05:28", "link": "http://arxiv.org/abs/2408.14582v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Preliminary Case Study on Long-Form In-the-Wild Audio Spoofing\n  Detection", "abstract": "Audio spoofing detection has become increasingly important due to the rise in\nreal-world cases. Current spoofing detectors, referred to as spoofing\ncountermeasures (CM), are mainly trained and focused on audio waveforms with a\nsingle speaker and short duration. This study explores spoofing detection in\nmore realistic scenarios, where the audio is long in duration and features\nmultiple speakers and complex acoustic conditions. We test the widely-acquired\nAASIST under this challenging scenario, looking at the impact of multiple\nvariations such as duration, speaker presence, and acoustic complexities on CM\nperformance. Our work reveals key issues with current methods and suggests\npreliminary ways to improve them. We aim to make spoofing detection more\napplicable in more in-the-wild scenarios. This research is served as an\nimportant step towards developing detection systems that can handle the\nchallenges of audio spoofing in real-world applications.", "published": "2024-08-26 07:46:33", "link": "http://arxiv.org/abs/2408.14066v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Global-Local Distillation Network-Based Audio-Visual Speaker Tracking\n  with Incomplete Modalities", "abstract": "In speaker tracking research, integrating and complementing multi-modal data\nis a crucial strategy for improving the accuracy and robustness of tracking\nsystems. However, tracking with incomplete modalities remains a challenging\nissue due to noisy observations caused by occlusion, acoustic noise, and sensor\nfailures. Especially when there is missing data in multiple modalities, the\nperformance of existing multi-modal fusion methods tends to decrease. To this\nend, we propose a Global-Local Distillation-based Tracker (GLDTracker) for\nrobust audio-visual speaker tracking. GLDTracker is driven by a teacher-student\ndistillation model, enabling the flexible fusion of incomplete information from\neach modality. The teacher network processes global signals captured by camera\nand microphone arrays, and the student network handles local information\nsubject to visual occlusion and missing audio channels. By transferring\nknowledge from teacher to student, the student network can better adapt to\ncomplex dynamic scenes with incomplete observations. In the student network, a\nglobal feature reconstruction module based on the generative adversarial\nnetwork is constructed to reconstruct global features from feature embedding\nwith missing local information. Furthermore, a multi-modal multi-level fusion\nattention is introduced to integrate the incomplete feature and the\nreconstructed feature, leveraging the complementarity and consistency of\naudio-visual and global-local features. Experimental results on the AV16.3\ndataset demonstrate that the proposed GLDTracker outperforms existing\nstate-of-the-art audio-visual trackers and achieves leading performance on both\nstandard and incomplete modalities datasets, highlighting its superiority and\nrobustness in complex conditions. The code and models will be available.", "published": "2024-08-26 19:09:21", "link": "http://arxiv.org/abs/2408.14585v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "SONICS: Synthetic Or Not -- Identifying Counterfeit Songs", "abstract": "The recent surge in AI-generated songs presents exciting possibilities and\nchallenges. These innovations necessitate the ability to distinguish between\nhuman-composed and synthetic songs to safeguard artistic integrity and protect\nhuman musical artistry. Existing research and datasets in fake song detection\nonly focus on singing voice deepfake detection (SVDD), where the vocals are\nAI-generated but the instrumental music is sourced from real songs. However,\nthese approaches are inadequate for detecting contemporary end-to-end\nartificial songs where all components (vocals, music, lyrics, and style) could\nbe AI-generated. Additionally, existing datasets lack music-lyrics diversity,\nlong-duration songs, and open-access fake songs. To address these gaps, we\nintroduce SONICS, a novel dataset for end-to-end Synthetic Song Detection\n(SSD), comprising over 97k songs (4,751 hours) with over 49k synthetic songs\nfrom popular platforms like Suno and Udio. Furthermore, we highlight the\nimportance of modeling long-range temporal dependencies in songs for effective\nauthenticity detection, an aspect entirely overlooked in existing methods. To\nutilize long-range patterns, we introduce SpecTTTra, a novel architecture that\nsignificantly improves time and memory efficiency over conventional CNN and\nTransformer-based models. For long songs, our top-performing variant\noutperforms ViT by 8% in F1 score, is 38% faster, and uses 26% less memory,\nwhile also surpassing ConvNeXt with a 1% F1 score gain, 20% speed boost, and\n67% memory reduction.", "published": "2024-08-26 08:02:57", "link": "http://arxiv.org/abs/2408.14080v4", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
