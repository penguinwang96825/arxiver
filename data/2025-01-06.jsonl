{"title": "High-frequency lead-lag relationships in the Chinese stock index futures market: tick-by-tick dynamics of calendar spreads", "abstract": "Lead-lag relationships, integral to market dynamics, offer valuable insights\ninto the trading behavior of high-frequency traders (HFTs) and the flow of\ninformation at a granular level. This paper investigates the lead-lag\nrelationships between stock index futures contracts of different maturities in\nthe Chinese financial futures market (CFFEX). Using high-frequency\n(tick-by-tick) data, we analyze how price movements in near-month futures\ncontracts influence those in longer-dated contracts, such as next-month,\nquarterly, and semi-annual contracts. Our findings reveal a consistent pattern\nof price discovery, with the near-month contract leading the others by one\ntick, driven primarily by liquidity. Additionally, we identify a negative\nfeedback effect of the \"lead-lag spread\" on the leading asset, which can\npredict returns of leading asset. Backtesting results demonstrate the\nprofitability of trading based on the lead-lag spread signal, even after\naccounting for transaction costs. Altogether, our analysis offers valuable\ninsights to understand and capitalize on the evolving dynamics of futures\nmarkets.", "published": "2025-01-06 17:40:27", "link": "http://arxiv.org/abs/2501.03171v1", "categories": ["q-fin.CP", "q-fin.ST", "stat.AP"], "primary_category": "q-fin.CP"}
{"title": "How to verify that a given process is a L\u00e9vy-Driven Ornstein-Uhlenbeck Process", "abstract": "Assuming that a L\\'evy-Driven Ornstein-Uhlenbeck (or CAR(1)) processes is\nobserved at discrete times $0$, $h$, $2h$,$\\cdots$ $[T/h]h$. We introduce a\nstep-by-step methodological approach on how a person would verify the model\nassumptions. The methodology involves estimating the model parameters and\napproximating the driving process. We demonstrate how to use the increments of\nthe approximated driving process, along with the estimated parameters, to test\nthe assumptions that the CAR(1) process is L\\'evy-driven. We then show how to\ntest the hypothesis that the CAR(1) process belongs to a specified class of\nL\\'evy processes. The performance of the tests is illustrated through multiple\nsimulations. Finally, we demonstrate how to apply the methodology step-by-step\nto a variety of economic and financial data examples.", "published": "2025-01-06 23:36:18", "link": "http://arxiv.org/abs/2501.03434v2", "categories": ["stat.AP", "q-fin.ST", "60, 62"], "primary_category": "stat.AP"}
{"title": "Registering Source Tokens to Target Language Spaces in Multilingual\n  Neural Machine Translation", "abstract": "The multilingual neural machine translation (MNMT) aims for arbitrary\ntranslations across multiple languages. Although MNMT-specific models trained\nby parallel data offer low costs in training and deployment, their performance\nconsistently lags behind that of large language models (LLMs). In this work, we\nintroduce registering, a novel method that enables a small MNMT-specific model\nto compete with LLMs. Specifically, we insert a set of artificial tokens\nspecifying the target language, called registers, into the input sequence\nbetween the source and target tokens. By modifying the attention mask, the\ntarget token generation only pays attention to the activation of registers,\nrepresenting the source tokens in the target language space. Experiments on\nEC-40, a large-scale benchmark, show that our method advances the\nstate-of-the-art of MNMT. We further pre-train two models, namely MITRE\n(multilingual translation with registers), by 9.3 billion sentence pairs across\n24 languages collected from public corpus. One of them, MITRE-913M, outperforms\nNLLB-3.3B, achieves comparable performance with commercial LLMs, and shows\nstrong adaptability in fine-tuning. Finally, we open-source our models to\nfacilitate further research and development in MNMT:\nhttps://github.com/zhiqu22/mitre.", "published": "2025-01-06 12:42:54", "link": "http://arxiv.org/abs/2501.02979v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trust Modeling in Counseling Conversations: A Benchmark Study", "abstract": "In mental health counseling, a variety of earlier studies have focused on\ndialogue modeling. However, most of these studies give limited to no emphasis\non the quality of interaction between a patient and a therapist. The\ntherapeutic bond between a patient and a therapist directly correlates with\neffective mental health counseling. It involves developing the patient's trust\non the therapist over the course of counseling. To assess the therapeutic bond\nin counseling, we introduce trust as a therapist-assistive metric. Our\ndefinition of trust involves patients' willingness and openness to express\nthemselves and, consequently, receive better care. We conceptualize it as a\ndynamic trajectory observable through textual interactions during the\ncounseling. To facilitate trust modeling, we present MENTAL-TRUST, a novel\ncounseling dataset comprising manual annotation of 212 counseling sessions with\nfirst-of-its-kind seven expert-verified ordinal trust levels. We project our\nproblem statement as an ordinal classification task for trust quantification\nand propose a new benchmark, TrustBench, comprising a suite of classical and\nstate-of-the-art language models on MENTAL-TRUST. We evaluate the performance\nacross a suite of metrics and lay out an exhaustive set of findings. Our study\naims to unfold how trust evolves in therapeutic interactions.", "published": "2025-01-06 15:02:30", "link": "http://arxiv.org/abs/2501.03064v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment-guided Commonsense-aware Response Generation for Mental Health\n  Counseling", "abstract": "The crisis of mental health issues is escalating. Effective counseling serves\nas a critical lifeline for individuals suffering from conditions like PTSD,\nstress, etc. Therapists forge a crucial therapeutic bond with clients, steering\nthem towards positivity. Unfortunately, the massive shortage of professionals,\nhigh costs, and mental health stigma pose significant barriers to consulting\ntherapists. As a substitute, Virtual Mental Health Assistants (VMHAs) have\nemerged in the digital healthcare space. However, most existing VMHAs lack the\ncommonsense to understand the nuanced sentiments of clients to generate\neffective responses. To this end, we propose EmpRes, a novel sentiment-guided\nmechanism incorporating commonsense awareness for generating responses. By\nleveraging foundation models and harnessing commonsense knowledge, EmpRes aims\nto generate responses that effectively shape the client's sentiment towards\npositivity. We evaluate the performance of EmpRes on HOPE, a benchmark\ncounseling dataset, and observe a remarkable performance improvement compared\nto the existing baselines across a suite of qualitative and quantitative\nmetrics. Moreover, our extensive empirical analysis and human evaluation show\nthat the generation ability of EmpRes is well-suited and, in some cases,\nsurpasses the gold standard. Further, we deploy EmpRes as a chat interface for\nusers seeking mental health support. We address the deployed system's\neffectiveness through an exhaustive user study with a significant positive\nresponse. Our findings show that 91% of users find the system effective, 80%\nexpress satisfaction, and over 85.45% convey a willingness to continue using\nthe interface and recommend it to others, demonstrating the practical\napplicability of EmpRes in addressing the pressing challenges of mental health\nsupport, emphasizing user feedback, and ethical considerations in a real-world\ncontext.", "published": "2025-01-06 15:41:52", "link": "http://arxiv.org/abs/2501.03088v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLIX: Cross-Lingual Explanations of Idiomatic Expressions", "abstract": "Automated definition generation systems have been proposed to support\nvocabulary expansion for language learners. The main barrier to the success of\nthese systems is that learners often struggle to understand definitions due to\nthe presence of potentially unfamiliar words and grammar, particularly when\nnon-standard language is involved. To address these challenges, we propose\nCLIX, the task of Cross-Lingual explanations of Idiomatic eXpressions. We\nexplore the capabilities of current NLP models for this task, and observe that\nwhile it remains challenging, large language models show promise. Finally, we\nperform a detailed error analysis to highlight the key challenges that need to\nbe addressed before we can reliably incorporate these systems into educational\ntools.", "published": "2025-01-06 18:06:37", "link": "http://arxiv.org/abs/2501.03191v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The FACTS Grounding Leaderboard: Benchmarking LLMs' Ability to Ground\n  Responses to Long-Form Input", "abstract": "We introduce FACTS Grounding, an online leaderboard and associated benchmark\nthat evaluates language models' ability to generate text that is factually\naccurate with respect to given context in the user prompt. In our benchmark,\neach prompt includes a user request and a full document, with a maximum length\nof 32k tokens, requiring long-form responses. The long-form responses are\nrequired to be fully grounded in the provided context document while fulfilling\nthe user request. Models are evaluated using automated judge models in two\nphases: (1) responses are disqualified if they do not fulfill the user request;\n(2) they are judged as accurate if the response is fully grounded in the\nprovided document. The automated judge models were comprehensively evaluated\nagainst a held-out test-set to pick the best prompt template, and the final\nfactuality score is an aggregate of multiple judge models to mitigate\nevaluation bias. The FACTS Grounding leaderboard will be actively maintained\nover time, and contains both public and private splits to allow for external\nparticipation while guarding the integrity of the leaderboard. It can be found\nat https://www.kaggle.com/facts-leaderboard.", "published": "2025-01-06 18:28:04", "link": "http://arxiv.org/abs/2501.03200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ADePT: Adaptive Decomposed Prompt Tuning for Parameter-Efficient\n  Fine-tuning", "abstract": "Prompt Tuning (PT) enables the adaptation of Pre-trained Large Language\nModels (PLMs) to downstream tasks by optimizing a small amount of soft virtual\ntokens, which are prepended to the input token embeddings. Recently, Decomposed\nPrompt Tuning (DePT) has demonstrated superior adaptation capabilities by\ndecomposing the soft prompt into a shorter soft prompt and a pair of low-rank\nmatrices. The product of the pair of low-rank matrices is added to the input\ntoken embeddings to offset them. Additionally, DePT achieves faster inference\ncompared to PT due to the shorter soft prompt. However, in this paper, we find\nthat the position-based token embedding offsets of DePT restrict its ability to\ngeneralize across diverse model inputs, and that the shared embedding offsets\nacross many token embeddings result in sub-optimization. To tackle these\nissues, we introduce Adaptive Decomposed Prompt Tuning (ADePT), which is\ncomposed of a short soft prompt and a shallow token-shared feed-forward neural\nnetwork. ADePT utilizes the token-shared feed-forward neural network to learn\nthe embedding offsets for each token, enabling adaptive embedding offsets that\nvary according to the model input and better optimization of token embedding\noffsets. This enables ADePT to achieve superior adaptation performance without\nrequiring more inference time or additional trainable parameters compared to\nvanilla PT and its variants. In comprehensive experiments across 23 natural\nlanguage processing tasks and 4 typical PLMs of different scales, ADePT\nconsistently surpasses the other leading parameter-efficient fine-tuning\nmethods, and even outperforms the full fine-tuning in certain scenarios. We\nalso provide a theoretical analysis towards ADePT. Code is available at\nhttps://github.com/HungerPWAY/ADePT.", "published": "2025-01-06 08:20:04", "link": "http://arxiv.org/abs/2501.03291v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DAMAGE: Detecting Adversarially Modified AI Generated Text", "abstract": "AI humanizers are a new class of online software tools meant to paraphrase\nand rewrite AI-generated text in a way that allows them to evade AI detection\nsoftware. We study 19 AI humanizer and paraphrasing tools and qualitatively\nassess their effects and faithfulness in preserving the meaning of the original\ntext. We show that many existing AI detectors fail to detect humanized text.\nFinally, we demonstrate a robust model that can detect humanized AI text while\nmaintaining a low false positive rate using a data-centric augmentation\napproach. We attack our own detector, training our own fine-tuned model\noptimized against our detector's predictions, and show that our detector's\ncross-humanizer generalization is sufficient to remain robust to this attack.", "published": "2025-01-06 23:43:49", "link": "http://arxiv.org/abs/2501.03437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KG-CF: Knowledge Graph Completion with Context Filtering under the\n  Guidance of Large Language Models", "abstract": "Large Language Models (LLMs) have shown impressive performance in various\ntasks, including knowledge graph completion (KGC). However, current studies\nmostly apply LLMs to classification tasks, like identifying missing triplets,\nrather than ranking-based tasks, where the model ranks candidate entities based\non plausibility. This focus limits the practical use of LLMs in KGC, as\nreal-world applications prioritize highly plausible triplets. Additionally,\nwhile graph paths can help infer the existence of missing triplets and improve\ncompletion accuracy, they often contain redundant information. To address these\nissues, we propose KG-CF, a framework tailored for ranking-based KGC tasks.\nKG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts,\nachieving superior results on real-world datasets. The code and datasets are\navailable at \\url{https://anonymous.4open.science/r/KG-CF}.", "published": "2025-01-06 01:52:15", "link": "http://arxiv.org/abs/2501.02711v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MBTSAD: Mitigating Backdoors in Language Models Based on Token Splitting\n  and Attention Distillation", "abstract": "In recent years, attention-based models have excelled across various domains\nbut remain vulnerable to backdoor attacks, often from downloading or\nfine-tuning on poisoned datasets. Many current methods to mitigate backdoors in\nNLP models rely on the pre-trained (unfine-tuned) weights, but these methods\nfail in scenarios where the pre-trained weights are not available. In this\nwork, we propose MBTSAD, which can mitigate backdoors in the language model by\nutilizing only a small subset of clean data and does not require pre-trained\nweights. Specifically, MBTSAD retrains the backdoored model on a dataset\ngenerated by token splitting. Then MBTSAD leverages attention distillation, the\nretrained model is the teacher model, and the original backdoored model is the\nstudent model. Experimental results demonstrate that MBTSAD achieves comparable\nbackdoor mitigation performance as the methods based on pre-trained weights\nwhile maintaining the performance on clean data. MBTSAD does not rely on\npre-trained weights, enhancing its utility in scenarios where pre-trained\nweights are inaccessible. In addition, we simplify the min-max problem of\nadversarial training and visualize text representations to discover that the\ntoken splitting method in MBTSAD's first step generates Out-of-Distribution\n(OOD) data, leading the model to learn more generalized features and eliminate\nbackdoor patterns.", "published": "2025-01-06 04:07:44", "link": "http://arxiv.org/abs/2501.02754v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "GeAR: Generation Augmented Retrieval", "abstract": "Document retrieval techniques form the foundation for the development of\nlarge-scale information systems. The prevailing methodology is to construct a\nbi-encoder and compute the semantic similarity. However, such scalar similarity\nis difficult to reflect enough information and impedes our comprehension of the\nretrieval results. In addition, this computational process mainly emphasizes\nthe global semantics and ignores the fine-grained semantic relationship between\nthe query and the complex text in the document. In this paper, we propose a new\nmethod called $\\textbf{Ge}$neration $\\textbf{A}$ugmented $\\textbf{R}$etrieval\n($\\textbf{GeAR}$) that incorporates well-designed fusion and decoding modules.\nThis enables GeAR to generate the relevant text from documents based on the\nfused representation of the query and the document, thus learning to \"focus on\"\nthe fine-grained information. Also when used as a retriever, GeAR does not add\nany computational burden over bi-encoders. To support the training of the new\nframework, we have introduced a pipeline to efficiently synthesize high-quality\ndata by utilizing large language models. GeAR exhibits competitive retrieval\nand localization performance across diverse scenarios and datasets. Moreover,\nthe qualitative analysis and the results generated by GeAR provide novel\ninsights into the interpretation of retrieval results. The code, data, and\nmodels will be released after completing technical review to facilitate future\nresearch.", "published": "2025-01-06 05:29:00", "link": "http://arxiv.org/abs/2501.02772v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Segmenting Text and Learning Their Rewards for Improved RLHF in Language\n  Model", "abstract": "Reinforcement learning from human feedback (RLHF) has been widely adopted to\nalign language models (LMs) with human preference. Prior RLHF works typically\ntake a bandit formulation, which, though intuitive, ignores the sequential\nnature of LM generation and can suffer from the sparse reward issue. While\nrecent works propose dense token-level RLHF, treating each token as an action\nmay be oversubtle to proper reward assignment. In this paper, we seek to get\nthe best of both by training and utilizing a segment-level reward model, which\nassigns a reward to each semantically complete text segment that spans over a\nshort sequence of tokens. For reward learning, our method allows dynamic text\nsegmentation and compatibility with standard sequence-preference datasets. For\neffective RL-based LM training against segment reward, we generalize the\nclassical scalar bandit reward normalizers into location-aware normalizer\nfunctions and interpolate the segment reward for further densification. With\nthese designs, our method performs competitively on three popular RLHF\nbenchmarks for LM policy: AlpacaEval 2.0, Arena-Hard, and MT-Bench. Ablation\nstudies are conducted to further demonstrate our method.", "published": "2025-01-06 06:17:56", "link": "http://arxiv.org/abs/2501.02790v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InfiFusion: A Unified Framework for Enhanced Cross-Model Reasoning via\n  LLM Fusion", "abstract": "We introduce InfiFusion, an efficient training pipeline designed to integrate\nmultiple domain-specialized Large Language Models (LLMs) into a single pivot\nmodel, effectively harnessing the strengths of each source model. Traditional\nfusion methods either merge model parameters directly or rely on knowledge\ndistillation with rigid assumptions, limiting their flexibility and efficiency.\nInfiFusion overcomes these limitations by enhancing Universal Logit\nDistillation (ULD) with Top-K selection and Logits Standardization. We propose\ntwo fusion strategies: Pairwise Fusion (InfiFusion$_p$), where each source\nmodel knowledge is distilled individually into the pivot model followed by\nmerging and Unified Fusion (InfiFusion$_u$), where knowledge from all source\nmodels is distilled simultaneously into the pivot model. InfiFusion outperforms\nthe state-of-the-art models, such as Qwen-2.5-14B-Instruct and Phi-4, across 11\nwidely applied benchmarks covering reasoning, coding, mathematics, and\ninstruction-following tasks. Notably, InfiFusion achieves this superior\nperformance while significantly reduces computational costs, completing full\ntraining with only 160 H800 GPU hours compared to the millions typically\nrequired for traditional LLM training.", "published": "2025-01-06 06:29:55", "link": "http://arxiv.org/abs/2501.02795v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks\n  by Efficient Human Preference Alignment", "abstract": "Recent researches of large language models(LLM), which is pre-trained on\nmassive general-purpose corpora, have achieved breakthroughs in responding\nhuman queries. However, these methods face challenges including limited data\ninsufficiency to support extensive pre-training and can not align responses\nwith users' instructions. To address these issues, we introduce a medical\ninstruction dataset, CMedINS, containing six medical instructions derived from\nactual medical tasks, which effectively fine-tunes LLM in conjunction with\nother data. Subsequently, We launch our medical model, IIMedGPT, employing an\nefficient preference alignment method, Direct preference Optimization(DPO). The\nresults show that our final model outperforms existing medical models in\nmedical dialogue.Datsets, Code and model checkpoints will be released upon\nacceptance.", "published": "2025-01-06 09:22:36", "link": "http://arxiv.org/abs/2501.02869v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explaining Humour Style Classifications: An XAI Approach to\n  Understanding Computational Humour Analysis", "abstract": "Humour styles can have either a negative or a positive impact on well-being.\nGiven the importance of these styles to mental health, significant research has\nbeen conducted on their automatic identification. However, the automated\nmachine learning models used for this purpose are black boxes, making their\nprediction decisions opaque. Clarity and transparency are vital in the field of\nmental health. This paper presents an explainable AI (XAI) framework for\nunderstanding humour style classification, building upon previous work in\ncomputational humour analysis. Using the best-performing single model\n(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to\nanalyse how linguistic, emotional, and semantic features contribute to humour\nstyle classification decisions. Our analysis reveals distinct patterns in how\ndifferent humour styles are characterised and misclassified, with particular\nemphasis on the challenges in distinguishing affiliative humour from other\nstyles. Through detailed examination of feature importance, error patterns, and\nmisclassification cases, we identify key factors influencing model decisions,\nincluding emotional ambiguity, context misinterpretation, and target\nidentification. The framework demonstrates significant utility in understanding\nmodel behaviour, achieving interpretable insights into the complex interplay of\nfeatures that define different humour styles. Our findings contribute to both\nthe theoretical understanding of computational humour analysis and practical\napplications in mental health, content moderation, and digital humanities\nresearch.", "published": "2025-01-06 10:08:56", "link": "http://arxiv.org/abs/2501.02891v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CALM: Curiosity-Driven Auditing for Large Language Models", "abstract": "Auditing Large Language Models (LLMs) is a crucial and challenging task. In\nthis study, we focus on auditing black-box LLMs without access to their\nparameters, only to the provided service. We treat this type of auditing as a\nblack-box optimization problem where the goal is to automatically uncover\ninput-output pairs of the target LLMs that exhibit illegal, immoral, or unsafe\nbehaviors. For instance, we may seek a non-toxic input that the target LLM\nresponds to with a toxic output or an input that induces the hallucinative\nresponse from the target LLM containing politically sensitive individuals. This\nblack-box optimization is challenging due to the scarcity of feasible points,\nthe discrete nature of the prompt space, and the large search space. To address\nthese challenges, we propose Curiosity-Driven Auditing for Large Language\nModels (CALM), which uses intrinsically motivated reinforcement learning to\nfinetune an LLM as the auditor agent to uncover potential harmful and biased\ninput-output pairs of the target LLM. CALM successfully identifies derogatory\ncompletions involving celebrities and uncovers inputs that elicit specific\nnames under the black-box setting. This work offers a promising direction for\nauditing black-box LLMs. Our code is available at\nhttps://github.com/x-zheng16/CALM.git.", "published": "2025-01-06 13:14:34", "link": "http://arxiv.org/abs/2501.02997v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Quality Estimation based Feedback Training for Improving Pronoun\n  Translation", "abstract": "Pronoun translation is a longstanding challenge in neural machine translation\n(NMT), often requiring inter-sentential context to ensure linguistic accuracy.\nTo address this, we introduce ProNMT, a novel framework designed to enhance\npronoun and overall translation quality in context-aware machine translation\nsystems. ProNMT leverages Quality Estimation (QE) models and a unique Pronoun\nGeneration Likelihood-Based Feedback mechanism to iteratively fine-tune\npre-trained NMT models without relying on extensive human annotations. The\nframework combines QE scores with pronoun-specific rewards to guide training,\nensuring improved handling of linguistic nuances. Extensive experiments\ndemonstrate significant gains in pronoun translation accuracy and general\ntranslation quality across multiple metrics. ProNMT offers an efficient,\nscalable, and context-aware approach to improving NMT systems, particularly in\ntranslating context-dependent elements like pronouns.", "published": "2025-01-06 13:34:51", "link": "http://arxiv.org/abs/2501.03008v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization\n  Degradation for Mathematical Reasoning", "abstract": "Large language models have achieved significant advancements in complex\nmathematical reasoning benchmarks, such as MATH. However, their substantial\ncomputational requirements present challenges for practical deployment. Model\nquantization has emerged as an effective strategy to reduce memory usage and\ncomputational costs by employing lower precision and bit-width representations.\nIn this study, we systematically evaluate the impact of quantization on\nmathematical reasoning tasks. Our results demonstrate that aggressive\nquantization methods like AWQ and GPTQ introduce up to 32.39% accuracy\ndegradation (average 11.31%) on Llama-3 models, particularly in numerical\ncomputation and reasoning planning. To address this, we introduce a\nmultidimensional evaluation framework combining qualitative capability analysis\nand quantitative error assessment. We further develop targeted recovery\nstrategies, showing that fine-tuning quantized models on only 545 task-specific\nexamples for 3 minutes on 4 GPUs effectively restores reasoning capabilities to\nnear full-precision levels. Additionally, our error assessment pipeline\nachieves 98.9% accuracy in diagnosing and localizing errors across 3,366\nfailure cases, providing actionable insights for mitigating\nquantization-induced degradation.", "published": "2025-01-06 14:23:02", "link": "http://arxiv.org/abs/2501.03035v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChronoSense: Exploring Temporal Understanding in Large Language Models\n  with Time Intervals of Events", "abstract": "Large Language Models (LLMs) have achieved remarkable success in various NLP\ntasks, yet they still face significant challenges in reasoning and arithmetic.\nTemporal reasoning, a critical component of natural language understanding, has\nraised increasing research attention. However, comprehensive testing of Allen's\ninterval relations (e.g., before, after, during) -- a fundamental framework for\ntemporal relationships -- remains underexplored. To fill this gap, we present\nChronoSense, a new benchmark for evaluating LLMs' temporal understanding. It\nincludes 16 tasks, focusing on identifying the Allen relation between two\ntemporal events and temporal arithmetic, using both abstract events and\nreal-world data from Wikidata. We assess the performance of seven recent LLMs\nusing this benchmark and the results indicate that models handle Allen\nrelations, even symmetrical ones, quite differently. Moreover, the findings\nsuggest that the models may rely on memorization to answer time-related\nquestions. Overall, the models' low performance highlights the need for\nimproved temporal understanding in LLMs and ChronoSense offers a robust\nframework for future research in this area. Our dataset and the source code are\navailable at https://github.com/duyguislakoglu/chronosense.", "published": "2025-01-06 14:27:41", "link": "http://arxiv.org/abs/2501.03040v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "VicSim: Enhancing Victim Simulation with Emotional and Linguistic\n  Fidelity", "abstract": "Scenario-based training has been widely adopted in many public service\nsectors. Recent advancements in Large Language Models (LLMs) have shown promise\nin simulating diverse personas to create these training scenarios. However,\nlittle is known about how LLMs can be developed to simulate victims for\nscenario-based training purposes. In this paper, we introduce VicSim (victim\nsimulator), a novel model that addresses three key dimensions of user\nsimulation: informational faithfulness, emotional dynamics, and language style\n(e.g., grammar usage). We pioneer the integration of scenario-based victim\nmodeling with GAN-based training workflow and key-information-based prompting,\naiming to enhance the realism of simulated victims. Our adversarial training\napproach teaches the discriminator to recognize grammar and emotional cues as\nreliable indicators of synthetic content. According to evaluations by human\nraters, the VicSim model outperforms GPT-4 in terms of human-likeness.", "published": "2025-01-06 17:01:45", "link": "http://arxiv.org/abs/2501.03139v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot\n  In-Context Learning for SQL2Text", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in\nvarious NLP tasks, including semantic parsing, which translates natural\nlanguage into formal code representations. However, the reverse process,\ntranslating code into natural language, termed semantic captioning, has\nreceived less attention. This task is becoming increasingly important as LLMs\nare integrated into platforms for code generation, security analysis, and\neducational purposes. In this paper, we focus on the captioning of SQL query\n(SQL2Text) to address the critical need for understanding and explaining SQL\nqueries in an era where LLM-generated code poses potential security risks. We\nrepurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt\nusing GPT-4o to generate multiple additional utterances, which enhances the\nrobustness of the datasets for the reverse task. We conduct our experiments\nusing in-context learning (ICL) based on different sample selection methods,\nemphasizing smaller, more computationally efficient LLMs. Our findings\ndemonstrate that leveraging the inherent graph properties of SQL for ICL sample\nselection significantly outperforms random selection by up to 39% on BLEU score\nand provides better results than alternative methods. Dataset and codes are\npublished: https://github.com/aliwister/ast-icl.", "published": "2025-01-06 17:36:09", "link": "http://arxiv.org/abs/2501.03166v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Explainable AI for LLM Text Attribution: Differentiating\n  Human-Written and Multiple LLMs-Generated Text", "abstract": "The development of Generative AI Large Language Models (LLMs) raised the\nalarm regarding identifying content produced through generative AI or humans.\nIn one case, issues arise when students heavily rely on such tools in a manner\nthat can affect the development of their writing or coding skills. Other issues\nof plagiarism also apply. This study aims to support efforts to detect and\nidentify textual content generated using LLM tools. We hypothesize that\nLLMs-generated text is detectable by machine learning (ML), and investigate ML\nmodels that can recognize and differentiate texts generated by multiple LLMs\ntools. We leverage several ML and Deep Learning (DL) algorithms such as Random\nForest (RF), and Recurrent Neural Networks (RNN), and utilized Explainable\nArtificial Intelligence (XAI) to understand the important features in\nattribution. Our method is divided into 1) binary classification to\ndifferentiate between human-written and AI-text, and 2) multi classification,\nto differentiate between human-written text and the text generated by the five\ndifferent LLM tools (ChatGPT, LLaMA, Google Bard, Claude, and Perplexity).\nResults show high accuracy in the multi and binary classification. Our model\noutperformed GPTZero with 98.5\\% accuracy to 78.3\\%. Notably, GPTZero was\nunable to recognize about 4.2\\% of the observations, but our model was able to\nrecognize the complete test dataset. XAI results showed that understanding\nfeature importance across different classes enables detailed author/source\nprofiles. Further, aiding in attribution and supporting plagiarism detection by\nhighlighting unique stylistic and structural elements ensuring robust content\noriginality verification.", "published": "2025-01-06 18:46:53", "link": "http://arxiv.org/abs/2501.03212v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Analyzing Bias in Swiss Federal Supreme Court Judgments Using Facebook's\n  Holistic Bias Dataset: Implications for Language Model Training", "abstract": "Natural Language Processing (NLP) is vital for computers to process and\nrespond accurately to human language. However, biases in training data can\nintroduce unfairness, especially in predicting legal judgment. This study\nfocuses on analyzing biases within the Swiss Judgment Prediction Dataset\n(SJP-Dataset). Our aim is to ensure unbiased factual descriptions essential for\nfair decision making by NLP models in legal contexts. We analyze the dataset\nusing social bias descriptors from the Holistic Bias dataset and employ\nadvanced NLP techniques, including attention visualization, to explore the\nimpact of dispreferred descriptors on model predictions. The study identifies\nbiases and examines their influence on model behavior. Challenges include\ndataset imbalance and token limits affecting model performance.", "published": "2025-01-06 19:00:09", "link": "http://arxiv.org/abs/2501.03324v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BoundingDocs: a Unified Dataset for Document Question Answering with\n  Spatial Annotations", "abstract": "We present a unified dataset for document Question-Answering (QA), which is\nobtained combining several public datasets related to Document AI and visually\nrich document understanding (VRDU). Our main contribution is twofold: on the\none hand we reformulate existing Document AI tasks, such as Information\nExtraction (IE), into a Question-Answering task, making it a suitable resource\nfor training and evaluating Large Language Models; on the other hand, we\nrelease the OCR of all the documents and include the exact position of the\nanswer to be found in the document image as a bounding box. Using this dataset,\nwe explore the impact of different prompting techniques (that might include\nbounding box information) on the performance of open-weight models, identifying\nthe most effective approaches for document comprehension.", "published": "2025-01-06 21:46:22", "link": "http://arxiv.org/abs/2501.03403v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Power of Negative Zero: Datatype Customization for Quantized Large\n  Language Models", "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\nvarious machine learning tasks, quickly becoming one of the most prevalent AI\nworkloads. Yet the substantial memory requirement of LLMs significantly hinders\ntheir deployment for end users. Post-training quantization (PTQ) serves as one\nof the most hardware-efficient methods to mitigate the memory and computational\ndemands of LLMs. Although the traditional integer (INT) datatype has received\nwidespread adoption in PTQ methods, floating-point (FP) quantization has\nemerged as a viable alternative thanks to its effectiveness in fitting LLM\nnumerical distributions. However, the FP datatype in sign-magnitude binary\nrepresentation contains both positive and negative zero, which constrains its\nrepresentation capability, particularly under low precision (3 and 4 bits). In\nthis paper, we extend the basic FP datatype to perform Redundant Zero Remapping\n(RaZeR), which remaps the negative zero FP encoding to a set of pre-defined\nspecial values to maximally utilize FP quantization encodings and to better fit\nLLM numerical distributions. Through careful selection of special values, RaZeR\noutperforms conventional asymmetric INT quantization while achieving high\ncomputational efficiency. We demonstrate that RaZeR can be seamlessly\nintegrated with quantization algorithms for both weights and KV-cache,\nincluding advanced methods with clipping and transformations, and consistently\nachieve better model accuracy. Additionally, we implement a fast GEMV kernel\nwith fused dequantization that efficiently converts the 4-bit RaZeR value to\nFP16 through novel bit-level manipulation. On modern GPUs, our evaluation shows\nthat RaZeR improves the GEMV speed by up to 7.56$\\times$ compared to the FP16\nimplementation, while achieving up to 2.72$\\times$ speedup in the LLM decoding\nthroughput.", "published": "2025-01-06 22:40:40", "link": "http://arxiv.org/abs/2501.04052v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "QuIM-RAG: Advancing Retrieval-Augmented Generation with Inverted\n  Question Matching for Enhanced QA Performance", "abstract": "This work presents a novel architecture for building Retrieval-Augmented\nGeneration (RAG) systems to improve Question Answering (QA) tasks from a target\ncorpus. Large Language Models (LLMs) have revolutionized the analyzing and\ngeneration of human-like text. These models rely on pre-trained data and lack\nreal-time updates unless integrated with live data tools. RAG enhances LLMs by\nintegrating online resources and databases to generate contextually appropriate\nresponses. However, traditional RAG still encounters challenges like\ninformation dilution and hallucinations when handling vast amounts of data. Our\napproach addresses these challenges by converting corpora into a\ndomain-specific dataset and RAG architecture is constructed to generate\nresponses from the target document. We introduce QuIM-RAG (Question-to-question\nInverted Index Matching), a novel approach for the retrieval mechanism in our\nsystem. This strategy generates potential questions from document chunks and\nmatches these with user queries to identify the most relevant text chunks for\ngenerating accurate answers. We have implemented our RAG system on top of the\nopen-source Meta-LLaMA3-8B-instruct model by Meta Inc. that is available on\nHugging Face. We constructed a custom corpus of 500+ pages from a high-traffic\nwebsite accessed thousands of times daily for answering complex questions,\nalong with manually prepared ground truth QA for evaluation. We compared our\napproach with traditional RAG models using BERT-Score and RAGAS,\nstate-of-the-art metrics for evaluating LLM applications. Our evaluation\ndemonstrates that our approach outperforms traditional RAG architectures on\nboth metrics.", "published": "2025-01-06 01:07:59", "link": "http://arxiv.org/abs/2501.02702v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TARDiS : Text Augmentation for Refining Diversity and Separability", "abstract": "Text augmentation (TA) is a critical technique for text classification,\nespecially in few-shot settings. This paper introduces a novel LLM-based TA\nmethod, TARDiS, to address challenges inherent in the generation and alignment\nstages of two-stage TA methods. For the generation stage, we propose two\ngeneration processes, SEG and CEG, incorporating multiple class-specific\nprompts to enhance diversity and separability. For the alignment stage, we\nintroduce a class adaptation (CA) method to ensure that generated examples\nalign with their target classes through verification and modification.\nExperimental results demonstrate TARDiS's effectiveness, outperforming\nstate-of-the-art LLM-based TA methods in various few-shot text classification\ntasks. An in-depth analysis confirms the detailed behaviors at each stage.", "published": "2025-01-06 03:17:35", "link": "http://arxiv.org/abs/2501.02739v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Samba-ASR: State-Of-The-Art Speech Recognition Leveraging Structured\n  State-Space Models", "abstract": "We propose Samba ASR,the first state of the art Automatic Speech\nRecognition(ASR)model leveraging the novel Mamba architecture as both encoder\nand decoder,built on the foundation of state space models(SSMs).Unlike\ntransformerbased ASR models,which rely on self-attention mechanisms to capture\ndependencies,Samba ASR effectively models both local and global temporal\ndependencies using efficient statespace dynamics,achieving remarkable\nperformance gains.By addressing the limitations of transformers,such as\nquadratic scaling with input length and difficulty in handling longrange\ndependencies,Samba ASR achieves superior accuracy and efficiency.Experimental\nresults demonstrate that Samba ASR surpasses existing opensource\ntransformerbased ASR models across various standard benchmarks,establishing it\nas the new state of theart in ASR.Extensive evaluations on the benchmark\ndataset show significant improvements in Word Error Rate(WER),with competitive\nperformance even in lowresource scenarios.Furthermore,the inherent\ncomputational efficiency and parameter optimization of the Mamba architecture\nmake Samba ASR a scalable and robust solution for diverse ASR tasks.Our\ncontributions include the development of a new Samba ASR architecture for\nautomatic speech recognition(ASR),demonstrating the superiority of structured\nstatespace models(SSMs)over transformer based models for speech sequence\nprocessing.We provide a comprehensive evaluation on public\nbenchmarks,showcasing stateoftheart(SOTA)performance,and present an indepth\nanalysis of computational efficiency,robustness to noise,and sequence\ngeneralization.This work highlights the viability of Mamba SSMs as a\ntransformerfree alternative for efficient and accurate ASR.By leveraging the\nadvancements of statespace modeling,Samba ASR redefines ASR performance\nstandards and sets a new benchmark for future research in this field.", "published": "2025-01-06 08:16:06", "link": "http://arxiv.org/abs/2501.02832v3", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text\n  Classification", "abstract": "Text classification is a fundamental task in data mining, pivotal to various\napplications such as tabular understanding and recommendation. Although neural\nnetwork-based models, such as CNN and BERT, have demonstrated remarkable\nperformance in text classification, their effectiveness heavily relies on\nabundant labeled training data. This dependency makes these models less\neffective in dynamic few-shot text classification, where labeled data is\nscarce, and new target labels frequently appear based on application needs.\nRecently, large language models (LLMs) have shown promise due to their\nextensive pretraining and contextual understanding ability. Current approaches\nprovide LLMs with text inputs, candidate labels, and additional side\ninformation (e.g., descriptions) to classify texts. However, their\neffectiveness is hindered by the increased input size and the noise introduced\nthrough side information processing. To address these limitations, we propose a\ngraph-based online retrieval-augmented generation framework, namely GORAG, for\ndynamic few-shot text classification. Rather than treating each input\nindependently, GORAG constructs and maintains a weighted graph by extracting\nside information across all target texts. In this graph, text keywords and\nlabels are represented as nodes, with edges indicating the correlations between\nthem. To model these correlations, GORAG employs an edge weighting mechanism to\nprioritize the importance and reliability of extracted information and\ndynamically retrieves relevant context using a minimum-cost spanning tree\ntailored for each text input. Empirical evaluations demonstrate that GORAG\noutperforms existing approaches by providing more comprehensive and precise\ncontextual information.", "published": "2025-01-06 08:43:31", "link": "http://arxiv.org/abs/2501.02844v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering\n  alignment", "abstract": "Multimodal LLMs have reached remarkable levels of proficiency in\nunderstanding multimodal inputs, driving extensive research to develop\nincreasingly powerful models. However, much less attention has been paid to\nunderstanding and explaining the underlying mechanisms of these models. Most\nexisting explainability research examines these models only in their final\nstates, overlooking the dynamic representational shifts that occur during\ntraining. In this work, we systematically analyze the evolution of hidden state\nrepresentations to reveal how fine-tuning alters the internal structure of a\nmodel to specialize in new multimodal tasks. Using a concept-based approach, we\nmap hidden states to interpretable visual and textual concepts, enabling us to\ntrace changes in encoded concepts across modalities as training progresses. We\nalso demonstrate the use of shift vectors to capture these concepts changes.\nThese shift vectors allow us to recover fine-tuned concepts by shifting those\nin the original model. Finally, we explore the practical impact of our findings\non model steering, showing that we can adjust multimodal LLMs behaviors without\nany training, such as modifying answer types, captions style, or biasing the\nmodel toward specific responses. Our work sheds light on how multimodal\nrepresentations evolve through fine-tuning and offers a new perspective for\ninterpreting model adaptation in multimodal tasks. The code for this project is\npublicly available at https://github.com/mshukor/xl-vlms.", "published": "2025-01-06 13:37:13", "link": "http://arxiv.org/abs/2501.03012v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "LangFair: A Python Package for Assessing Bias and Fairness in Large\n  Language Model Use Cases", "abstract": "Large Language Models (LLMs) have been observed to exhibit bias in numerous\nways, potentially creating or worsening outcomes for specific groups identified\nby protected attributes such as sex, race, sexual orientation, or age. To help\naddress this gap, we introduce LangFair, an open-source Python package that\naims to equip LLM practitioners with the tools to evaluate bias and fairness\nrisks relevant to their specific use cases. The package offers functionality to\neasily generate evaluation datasets, comprised of LLM responses to\nuse-case-specific prompts, and subsequently calculate applicable metrics for\nthe practitioner's use case. To guide in metric selection, LangFair offers an\nactionable decision framework.", "published": "2025-01-06 16:20:44", "link": "http://arxiv.org/abs/2501.03112v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PRMBench: A Fine-grained and Challenging Benchmark for Process-Level\n  Reward Models", "abstract": "Process-level Reward Models (PRMs) are crucial for complex reasoning and\ndecision-making tasks, where each intermediate step plays an important role in\nthe reasoning process. Since language models are prone to various types of\nerrors during the reasoning process, PRMs are required to possess nuanced\ncapabilities for detecting various implicit error types in real-world\nscenarios. However, current benchmarks primarily focus on step correctness,\nfailing to evaluate PRMs' performance systematically. To address this gap, we\nintroduce PRMBench, a process-level benchmark specifically designed to assess\nthe fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216\ncarefully designed problems and 83,456 step-level labels, evaluating models\nacross multiple dimensions, including simplicity, soundness, and sensitivity.\nIn our experiments on 15 models, spanning both open-source PRMs and\nclosed-source large language models prompted as critic models, we uncover\nsignificant weaknesses in current PRMs. These findings underscore the\nchallenges inherent in process-level evaluation and highlight key directions\nfor future research. We hope PRMBench can be a robust bench for advancing\nresearch on PRM evaluation and development.", "published": "2025-01-06 16:31:45", "link": "http://arxiv.org/abs/2501.03124v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GLiREL -- Generalist Model for Zero-Shot Relation Extraction", "abstract": "We introduce GLiREL (Generalist Lightweight model for zero-shot Relation\nExtraction), an efficient architecture and training paradigm for zero-shot\nrelation classification. Inspired by recent advancements in zero-shot named\nentity recognition, this work presents an approach to efficiently and\naccurately predict zero-shot relationship labels between multiple entities in a\nsingle forward pass. Experiments using the FewRel and WikiZSL benchmarks\ndemonstrate that our approach achieves state-of-the-art results on the\nzero-shot relation classification task. In addition, we contribute a protocol\nfor synthetically-generating datasets with diverse relation labels.", "published": "2025-01-06 17:42:29", "link": "http://arxiv.org/abs/2501.03172v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Detecting AI-Generated Text in Educational Content: Leveraging Machine\n  Learning and Explainable AI for Academic Integrity", "abstract": "This study seeks to enhance academic integrity by providing tools to detect\nAI-generated content in student work using advanced technologies. The findings\npromote transparency and accountability, helping educators maintain ethical\nstandards and supporting the responsible integration of AI in education. A key\ncontribution of this work is the generation of the CyberHumanAI dataset, which\nhas 1000 observations, 500 of which are written by humans and the other 500\nproduced by ChatGPT. We evaluate various machine learning (ML) and deep\nlearning (DL) algorithms on the CyberHumanAI dataset comparing human-written\nand AI-generated content from Large Language Models (LLMs) (i.e., ChatGPT).\nResults demonstrate that traditional ML algorithms, specifically XGBoost and\nRandom Forest, achieve high performance (83% and 81% accuracies respectively).\nResults also show that classifying shorter content seems to be more challenging\nthan classifying longer content. Further, using Explainable Artificial\nIntelligence (XAI) we identify discriminative features influencing the ML\nmodel's predictions, where human-written content tends to use a practical\nlanguage (e.g., use and allow). Meanwhile AI-generated text is characterized by\nmore abstract and formal terms (e.g., realm and employ). Finally, a comparative\nanalysis with GPTZero show that our narrowly focused, simple, and fine-tuned\nmodel can outperform generalized systems like GPTZero. The proposed model\nachieved approximately 77.5% accuracy compared to GPTZero's 48.5% accuracy when\ntasked to classify Pure AI, Pure Human, and mixed class. GPTZero showed a\ntendency to classify challenging and small-content cases as either mixed or\nunrecognized while our proposed model showed a more balanced performance across\nthe three classes.", "published": "2025-01-06 18:34:20", "link": "http://arxiv.org/abs/2501.03203v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "BoostStep: Boosting mathematical capability of Large Language Models via\n  improved single-step reasoning", "abstract": "Large language models (LLMs) have demonstrated impressive ability in solving\ncomplex mathematical problems with multi-step reasoning and can be further\nenhanced with well-designed in-context learning (ICL) examples. However, this\npotential is often constrained by two major challenges in ICL: granularity\nmismatch and irrelevant information. We observe that while LLMs excel at\ndecomposing mathematical problems, they often struggle with reasoning errors in\nfine-grained steps. Moreover, ICL examples retrieved at the question level may\nomit critical steps or even mislead the model with irrelevant details. To\naddress this issue, we propose BoostStep, a method that enhances reasoning\naccuracy through step-aligned ICL, a novel mechanism that carefully aligns\nretrieved reference steps with the corresponding reasoning steps. Additionally,\nBoostStep incorporates an effective \"first-try\" strategy to deliver exemplars\nhighly relevant to the current state of reasoning. BoostStep is a flexible and\npowerful method that integrates seamlessly with chain-of-thought (CoT) and tree\nsearch algorithms, refining both candidate selection and decision-making.\nEmpirical results show that BoostStep improves GPT-4o's CoT performance by 4.6%\nacross mathematical benchmarks, significantly surpassing traditional few-shot\nlearning's 1.2%. Moreover, it can achieve an additional 7.5\\% gain combined\nwith tree search. Surprisingly, it enhances state-of-the-art LLMs to solve\nchallenging math problems using simpler examples. It improves\nDeepSeek-R1-671B's performance on AIME by 2.2%, leveraging simple examples only\nfrom the MATH dataset.", "published": "2025-01-06 18:59:13", "link": "http://arxiv.org/abs/2501.03226v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Advanced Machine Learning Techniques for Social Support Detection on\n  Social Media", "abstract": "The widespread use of social media highlights the need to understand its\nimpact, particularly the role of online social support. This study uses a\ndataset focused on online social support, which includes binary and multiclass\nclassifications of social support content on social media. The classification\nof social support is divided into three tasks. The first task focuses on\ndistinguishing between supportive and non-supportive. The second task aims to\nidentify whether the support is directed toward an individual or a group. The\nthird task categorizes the specific type of social support, grouping it into\ncategories such as Nation, LGBTQ, Black people, Women, Religion, and Other (if\nit does not fit into the previously mentioned categories). To address data\nimbalances in these tasks, we employed K-means clustering for balancing the\ndataset and compared the results with the original unbalanced data. Using\nadvanced machine learning techniques, including transformers and zero-shot\nlearning approaches with GPT3, GPT4, and GPT4-o, we predict social support\nlevels in various contexts. The effectiveness of the dataset is evaluated using\nbaseline models across different learning approaches, with transformer-based\nmethods demonstrating superior performance. Additionally, we achieved a 0.4\\%\nincrease in the macro F1 score for the second task and a 0.7\\% increase for the\nthird task, compared to previous work utilizing traditional machine learning\nwith psycholinguistic and unigram-based TF-IDF values.", "published": "2025-01-06 20:14:09", "link": "http://arxiv.org/abs/2501.03370v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Cross-Attention Transformer and Multi-Feature Fusion for\n  Cross-Linguistic Speech Emotion Recognition", "abstract": "Speech Emotion Recognition (SER) plays a crucial role in enhancing\nhuman-computer interaction. Cross-Linguistic SER (CLSER) has been a challenging\nresearch problem due to significant variability in linguistic and acoustic\nfeatures of different languages. In this study, we propose a novel approach\nHuMP-CAT, which combines HuBERT, MFCC, and prosodic characteristics. These\nfeatures are fused using a cross-attention transformer (CAT) mechanism during\nfeature extraction. Transfer learning is applied to gain from a source\nemotional speech dataset to the target corpus for emotion recognition. We use\nIEMOCAP as the source dataset to train the source model and evaluate the\nproposed method on seven datasets in five languages (e.g., English, German,\nSpanish, Italian, and Chinese). We show that, by fine-tuning the source model\nwith a small portion of speech from the target datasets, HuMP-CAT achieves an\naverage accuracy of 78.75% across the seven datasets, with notable performance\nof 88.69% on EMODB (German language) and 79.48% on EMOVO (Italian language).\nOur extensive evaluation demonstrates that HuMP-CAT outperforms existing\nmethods across multiple target languages.", "published": "2025-01-06 14:31:25", "link": "http://arxiv.org/abs/2501.10408v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sustainable Digitalization of Business with Multi-Agent RAG and LLM", "abstract": "Businesses heavily rely on data sourced from various channels like news\narticles, financial reports, and consumer reviews to drive their operations,\nenabling informed decision-making and identifying opportunities. However,\ntraditional manual methods for data extraction are often time-consuming and\nresource-intensive, prompting the adoption of digital transformation\ninitiatives to enhance efficiency. Yet, concerns persist regarding the\nsustainability of such initiatives and their alignment with the United Nations\n(UN)'s Sustainable Development Goals (SDGs). This research aims to explore the\nintegration of Large Language Models (LLMs) with Retrieval-Augmented Generation\n(RAG) as a sustainable solution for Information Extraction (IE) and processing.\nThe research methodology involves reviewing existing solutions for business\ndecision-making, noting that many systems require training new machine learning\nmodels, which are resource-intensive and have significant environmental\nimpacts. Instead, we propose a sustainable business solution using pre-existing\nLLMs that can work with diverse datasets. We link domain-specific datasets to\ntailor LLMs to company needs and employ a Multi-Agent architecture to divide\ntasks such as information retrieval, enrichment, and classification among\nspecialized agents. This approach optimizes the extraction process and improves\noverall efficiency. Through the utilization of these technologies, businesses\ncan optimize resource utilization, improve decision-making processes, and\ncontribute to sustainable development goals, thereby fostering environmental\nresponsibility within the corporate sector.", "published": "2025-01-06 08:14:23", "link": "http://arxiv.org/abs/2502.15700v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Political Events using RAG with LLMs", "abstract": "In the contemporary digital landscape, media content stands as the foundation\nfor political news analysis, offering invaluable insights sourced from various\nchannels like news articles, social media updates, speeches, and reports.\nNatural Language Processing (NLP) has revolutionized Political Information\nExtraction (IE), automating tasks such as Event Extraction (EE) from these\ndiverse media outlets. While traditional NLP methods often necessitate\nspecialized expertise to build rule-based systems or train machine learning\nmodels with domain-specific datasets, the emergence of Large Language Models\n(LLMs) driven by Generative Artificial Intelligence (GenAI) presents a\npromising alternative. These models offer accessibility, alleviating challenges\nassociated with model construction from scratch and reducing the dependency on\nextensive datasets during the training phase, thus facilitating rapid\nimplementation. However, challenges persist in handling domain-specific tasks,\nleading to the development of the Retrieval-Augmented Generation (RAG)\nframework. RAG enhances LLMs by integrating external data retrieval, enriching\ntheir contextual understanding, and expanding their knowledge base beyond\npre-existing training data. To illustrate RAG's efficacy, we introduce the\nPolitical EE system, specifically tailored to extract political event\ninformation from news articles. Understanding these political insights is\nessential for remaining informed about the latest political advancements,\nwhether on a national or global scale.", "published": "2025-01-06 08:16:24", "link": "http://arxiv.org/abs/2502.15701v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Automated Generation of Challenging Multiple-Choice Questions for Vision\n  Language Model Evaluation", "abstract": "The rapid development of vision language models (VLMs) demands rigorous and\nreliable evaluation. However, current visual question answering (VQA)\nbenchmarks often depend on open-ended questions, making accurate evaluation\ndifficult due to the variability in natural language responses. To address\nthis, we introduce AutoConverter, an agentic framework that automatically\nconverts these open-ended questions into multiple-choice format, enabling\nobjective evaluation while reducing the costly multiple-choice question\ncreation process. Our experiments demonstrate that AutoConverter can generate\ncorrect and challenging multiple-choice questions, with VLMs demonstrating\nconsistently similar or lower accuracy on these questions compared to\nhuman-created ones. Using AutoConverter, we construct VMCBench, a benchmark\ncreated by transforming 20 existing VQA datasets into a unified multiple-choice\nformat, totaling 9,018 questions. We comprehensively evaluate 33\nstate-of-the-art VLMs on VMCBench, setting a new standard for scalable,\nconsistent, and reproducible VLM evaluation.", "published": "2025-01-06 18:57:31", "link": "http://arxiv.org/abs/2501.03225v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards HRTF Personalization using Denoising Diffusion Models", "abstract": "Head-Related Transfer Functions (HRTFs) have fundamental applications for\nrealistic rendering in immersive audio scenarios. However, they are strongly\nsubject-dependent as they vary considerably depending on the shape of the ears,\nhead and torso. Thus, personalization procedures are required for accurate\nbinaural rendering. Recently, Denoising Diffusion Probabilistic Models (DDPMs),\na class of generative learning techniques, have been applied to solve a variety\nof signal processing-related problems. In this paper, we propose a first\napproach for using DDPM conditioned on anthropometric measurements to generate\npersonalized Head-Related Impulse Response (HRIR), the time-domain\nrepresentation of HRTF. The results show the feasibility of DDPMs for HRTF\npersonalization obtaining performance in line with state-of-the-art models.", "published": "2025-01-06 09:26:59", "link": "http://arxiv.org/abs/2501.02871v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SYKI-SVC: Advancing Singing Voice Conversion with Post-Processing\n  Innovations and an Open-Source Professional Testset", "abstract": "Singing voice conversion aims to transform a source singing voice into that\nof a target singer while preserving the original lyrics, melody, and various\nvocal techniques. In this paper, we propose a high-fidelity singing voice\nconversion system. Our system builds upon the SVCC T02 framework and consists\nof three key components: a feature extractor, a voice converter, and a\npost-processor. The feature extractor utilizes the ContentVec and Whisper\nmodels to derive F0 contours and extract speaker-independent linguistic\nfeatures from the input singing voice. The voice converter then integrates the\nextracted timbre, F0, and linguistic content to synthesize the target speaker's\nwaveform. The post-processor augments high-frequency information directly from\nthe source through simple and effective signal processing to enhance audio\nquality. Due to the lack of a standardized professional dataset for evaluating\nexpressive singing conversion systems, we have created and made publicly\navailable a specialized test set. Comparative evaluations demonstrate that our\nsystem achieves a remarkably high level of naturalness, and further analysis\nconfirms the efficacy of our proposed system design.", "published": "2025-01-06 11:54:33", "link": "http://arxiv.org/abs/2501.02953v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Single-Channel Distance-Based Source Separation for Mobile GPU in\n  Outdoor and Indoor Environments", "abstract": "This study emphasizes the significance of exploring distance-based source\nseparation (DSS) in outdoor environments. Unlike existing studies that\nprimarily focus on indoor settings, the proposed model is designed to capture\nthe unique characteristics of outdoor audio sources. It incorporates advanced\ntechniques, including a two-stage conformer block, a linear relation-aware\nself-attention (RSA), and a TensorFlow Lite GPU delegate. While the linear RSA\nmay not capture physical cues as explicitly as the quadratic RSA, the linear\nRSA enhances the model's context awareness, leading to improved performance on\nthe DSS that requires an understanding of physical cues in outdoor and indoor\nenvironments. The experimental results demonstrated that the proposed model\novercomes the limitations of existing approaches and considerably enhances\nenergy efficiency and real-time inference speed on mobile devices.", "published": "2025-01-06 14:32:24", "link": "http://arxiv.org/abs/2501.03045v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "CCStereo: Audio-Visual Contextual and Contrastive Learning for Binaural\n  Audio Generation", "abstract": "Binaural audio generation (BAG) aims to convert monaural audio to stereo\naudio using visual prompts, requiring a deep understanding of spatial and\nsemantic information. However, current models risk overfitting to room\nenvironments and lose fine-grained spatial details. In this paper, we propose a\nnew audio-visual binaural generation model incorporating an audio-visual\nconditional normalisation layer that dynamically aligns the mean and variance\nof the target difference audio features using visual context, along with a new\ncontrastive learning method to enhance spatial sensitivity by mining negative\nsamples from shuffled visual features. We also introduce a cost-efficient way\nto utilise test-time augmentation in video data to enhance performance. Our\napproach achieves state-of-the-art generation accuracy on the FAIR-Play and\nMUSIC-Stereo benchmarks.", "published": "2025-01-06 06:04:21", "link": "http://arxiv.org/abs/2501.02786v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Piano Transcription by Hierarchical Language Modeling with Pretrained\n  Roll-based Encoders", "abstract": "Automatic Music Transcription (AMT), aiming to get musical notes from raw\naudio, typically uses frame-level systems with piano-roll outputs or language\nmodel (LM)-based systems with note-level predictions. However, frame-level\nsystems require manual thresholding, while the LM-based systems struggle with\nlong sequences. In this paper, we propose a hybrid method combining pre-trained\nroll-based encoders with an LM decoder to leverage the strengths of both\nmethods. Besides, our approach employs a hierarchical prediction strategy,\nfirst predicting onset and pitch, then velocity, and finally offset. The\nhierarchical prediction strategy reduces computational costs by breaking down\nlong sequences into different hierarchies. Evaluated on two benchmark\nroll-based encoders, our method outperforms traditional piano-roll outputs 0.01\nand 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a\nperformance-enhancing plug-in for arbitrary roll-based music transcription\nencoder.", "published": "2025-01-06 14:26:00", "link": "http://arxiv.org/abs/2501.03038v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Noise-Robust Target-Speaker Voice Activity Detection Through\n  Self-Supervised Pretraining", "abstract": "Target-Speaker Voice Activity Detection (TS-VAD) is the task of detecting the\npresence of speech from a known target-speaker in an audio frame. Recently,\ndeep neural network-based models have shown good performance in this task.\nHowever, training these models requires extensive labelled data, which is\ncostly and time-consuming to obtain, particularly if generalization to unseen\nenvironments is crucial. To mitigate this, we propose a causal, Self-Supervised\nLearning (SSL) pretraining framework, called Denoising Autoregressive\nPredictive Coding (DN-APC), to enhance TS-VAD performance in noisy conditions.\nWe also explore various speaker conditioning methods and evaluate their\nperformance under different noisy conditions. Our experiments show that DN-APC\nimproves performance in noisy conditions, with a general improvement of approx.\n2% in both seen and unseen noise. Additionally, we find that FiLM conditioning\nprovides the best overall performance. Representation analysis via tSNE plots\nreveals robust initial representations of speech and non-speech from\npretraining. This underscores the effectiveness of SSL pretraining in improving\nthe robustness and performance of TS-VAD models in noisy environments.", "published": "2025-01-06 18:00:14", "link": "http://arxiv.org/abs/2501.03184v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "68T10", "I.2.6"], "primary_category": "eess.AS"}
{"title": "Multimodal Machine Learning Can Predict Videoconference Fluidity and\n  Enjoyment", "abstract": "Videoconferencing is now a frequent mode of communication in both\nprofessional and informal settings, yet it often lacks the fluidity and\nenjoyment of in-person conversation. This study leverages multimodal machine\nlearning to predict moments of negative experience in videoconferencing. We\nsampled thousands of short clips from the RoomReader corpus, extracting audio\nembeddings, facial actions, and body motion features to train models for\nidentifying low conversational fluidity, low enjoyment, and classifying\nconversational events (backchanneling, interruption, or gap). Our best models\nachieved an ROC-AUC of up to 0.87 on hold-out videoconference sessions, with\ndomain-general audio features proving most critical. This work demonstrates\nthat multimodal audio-video signals can effectively predict high-level\nsubjective conversational outcomes. In addition, this is a contribution to\nresearch on videoconferencing user experience by showing that multimodal\nmachine learning can be used to identify rare moments of negative user\nexperience for further study or mitigation.", "published": "2025-01-06 18:05:35", "link": "http://arxiv.org/abs/2501.03190v2", "categories": ["cs.LG", "cs.HC", "eess.AS", "eess.IV"], "primary_category": "cs.LG"}
