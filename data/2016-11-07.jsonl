{"title": "Latent Attention For If-Then Program Synthesis", "abstract": "Automatic translation from natural language descriptions into programs is a\nlongstanding challenging problem. In this work, we consider a simple yet\nimportant sub-problem: translation from textual descriptions to If-Then\nprograms. We devise a novel neural network architecture for this task which we\ntrain end-to-end. Specifically, we introduce Latent Attention, which computes\nmultiplicative weights for the words in the description in a two-stage process\nwith the goal of better leveraging the natural language structures that\nindicate the relevant parts for predicting program elements. Our architecture\nreduces the error rate by 28.57% compared to prior art. We also propose a\none-shot learning scenario of If-Then program synthesis and simulate it with\nour existing dataset. We demonstrate a variation on the training procedure for\nthis scenario that outperforms the original procedure, significantly closing\nthe gap to the model trained with all data.", "published": "2016-11-07 00:56:19", "link": "http://arxiv.org/abs/1611.01867v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation with Reconstruction", "abstract": "Although end-to-end Neural Machine Translation (NMT) has achieved remarkable\nprogress in the past two years, it suffers from a major drawback: translations\ngenerated by NMT systems often lack of adequacy. It has been widely observed\nthat NMT tends to repeatedly translate some source words while mistakenly\nignoring other words. To alleviate this problem, we propose a novel\nencoder-decoder-reconstructor framework for NMT. The reconstructor,\nincorporated into the NMT model, manages to reconstruct the input source\nsentence from the hidden layer of the output target sentence, to ensure that\nthe information in the source side is transformed to the target side as much as\npossible. Experiments show that the proposed framework significantly improves\nthe adequacy of NMT output and achieves superior translation result over\nstate-of-the-art NMT and statistical MT systems.", "published": "2016-11-07 02:03:55", "link": "http://arxiv.org/abs/1611.01874v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AC-BLSTM: Asymmetric Convolutional Bidirectional LSTM Networks for Text\n  Classification", "abstract": "Recently deeplearning models have been shown to be capable of making\nremarkable performance in sentences and documents classification tasks. In this\nwork, we propose a novel framework called AC-BLSTM for modeling sentences and\ndocuments, which combines the asymmetric convolution neural network (ACNN) with\nthe Bidirectional Long Short-Term Memory network (BLSTM). Experiment results\ndemonstrate that our model achieves state-of-the-art results on five tasks,\nincluding sentiment analysis, question type classification, and subjectivity\nclassification. In order to further improve the performance of AC-BLSTM, we\npropose a semi-supervised learning framework called G-AC-BLSTM for text\nclassification by combining the generative model with AC-BLSTM.", "published": "2016-11-07 03:39:52", "link": "http://arxiv.org/abs/1611.01884v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Keyphrase Annotation with Graph Co-Ranking", "abstract": "Keyphrase annotation is the task of identifying textual units that represent\nthe main content of a document. Keyphrase annotation is either carried out by\nextracting the most important phrases from a document, keyphrase extraction, or\nby assigning entries from a controlled domain-specific vocabulary, keyphrase\nassignment. Assignment methods are generally more reliable. They provide\nbetter-formed keyphrases, as well as keyphrases that do not occur in the\ndocument. But they are often silent on the contrary of extraction methods that\ndo not depend on manually built resources. This paper proposes a new method to\nperform both keyphrase extraction and keyphrase assignment in an integrated and\nmutual reinforcing manner. Experiments have been carried out on datasets\ncovering different domains of humanities and social sciences. They show\nstatistically significant improvements compared to both keyphrase extraction\nand keyphrase assignment state-of-the art methods.", "published": "2016-11-07 12:08:13", "link": "http://arxiv.org/abs/1611.02007v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Presenting a New Dataset for the Timeline Generation Problem", "abstract": "The timeline generation task summarises an entity's biography by selecting\nstories representing key events from a large pool of relevant documents. This\npaper addresses the lack of a standard dataset and evaluative methodology for\nthe problem. We present and make publicly available a new dataset of 18,793\nnews articles covering 39 entities. For each entity, we provide a gold standard\ntimeline and a set of entity-related articles. We propose ROUGE as an\nevaluation metric and validate our dataset by showing that top Google results\noutperform straw-man baselines.", "published": "2016-11-07 12:47:25", "link": "http://arxiv.org/abs/1611.02025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": ":telephone::person::sailboat::whale::okhand:; or \"Call me Ishmael\" - How\n  do you translate emoji?", "abstract": "We report on an exploratory analysis of Emoji Dick, a project that leverages\ncrowdsourcing to translate Melville's Moby Dick into emoji. This distinctive\nuse of emoji removes textual context, and leads to a varying translation\nquality. In this paper, we use statistical word alignment and part-of-speech\ntagging to explore how people use emoji. Despite these simple methods, we\nobserved differences in token and part-of-speech distributions. Experiments\nalso suggest that semantics are preserved in the translation, and repetition is\nmore common in emoji.", "published": "2016-11-07 12:51:22", "link": "http://arxiv.org/abs/1611.02027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Building a comprehensive syntactic and semantic corpus of Chinese\n  clinical texts", "abstract": "Objective: To build a comprehensive corpus covering syntactic and semantic\nannotations of Chinese clinical texts with corresponding annotation guidelines\nand methods as well as to develop tools trained on the annotated corpus, which\nsupplies baselines for research on Chinese texts in the clinical domain.\n  Materials and methods: An iterative annotation method was proposed to train\nannotators and to develop annotation guidelines. Then, by using annotation\nquality assurance measures, a comprehensive corpus was built, containing\nannotations of part-of-speech (POS) tags, syntactic tags, entities, assertions,\nand relations. Inter-annotator agreement (IAA) was calculated to evaluate the\nannotation quality and a Chinese clinical text processing and information\nextraction system (CCTPIES) was developed based on our annotated corpus.\n  Results: The syntactic corpus consists of 138 Chinese clinical documents with\n47,424 tokens and 2553 full parsing trees, while the semantic corpus includes\n992 documents that annotated 39,511 entities with their assertions and 7695\nrelations. IAA evaluation shows that this comprehensive corpus is of good\nquality, and the system modules are effective.\n  Discussion: The annotated corpus makes a considerable contribution to natural\nlanguage processing (NLP) research into Chinese texts in the clinical domain.\nHowever, this corpus has a number of limitations. Some additional types of\nclinical text should be introduced to improve corpus coverage and active\nlearning methods should be utilized to promote annotation efficiency.\n  Conclusions: In this study, several annotation guidelines and an annotation\nmethod for Chinese clinical texts were proposed, and a comprehensive corpus\nwith its NLP modules were constructed, providing a foundation for further study\nof applying NLP techniques to Chinese texts in the clinical domain.", "published": "2016-11-07 15:05:06", "link": "http://arxiv.org/abs/1611.02091v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Convolutional Encoder Model for Neural Machine Translation", "abstract": "The prevalent approach to neural machine translation relies on bi-directional\nLSTMs to encode the source sentence. In this paper we present a faster and\nsimpler architecture based on a succession of convolutional layers. This allows\nto encode the entire source sentence simultaneously compared to recurrent\nnetworks for which computation is constrained by temporal dependencies. On\nWMT'16 English-Romanian translation we achieve competitive accuracy to the\nstate-of-the-art and we outperform several recently published results on the\nWMT'15 English-German task. Our models obtain almost the same accuracy as a\nvery deep LSTM setup on WMT'14 English-French translation. Our convolutional\nencoder speeds up CPU decoding by more than two times at the same or higher\naccuracy as a strong bi-directional LSTM baseline.", "published": "2016-11-07 23:46:45", "link": "http://arxiv.org/abs/1611.02344v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Truth Discovery with Memory Network", "abstract": "Truth discovery is to resolve conflicts and find the truth from\nmultiple-source statements. Conventional methods mostly research based on the\nmutual effect between the reliability of sources and the credibility of\nstatements, however, pay no attention to the mutual effect among the\ncredibility of statements about the same object. We propose memory network\nbased models to incorporate these two ideas to do the truth discovery. We use\nfeedforward memory network and feedback memory network to learn the\nrepresentation of the credibility of statements which are about the same\nobject. Specially, we adopt memory mechanism to learn source reliability and\nuse it through truth prediction. During learning models, we use multiple types\nof data (categorical data and continuous data) by assigning different weights\nautomatically in the loss function based on their own effect on truth discovery\nprediction. The experiment results show that the memory network based models\nmuch outperform the state-of-the-art method and other baseline methods.", "published": "2016-11-07 01:08:11", "link": "http://arxiv.org/abs/1611.01868v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Gaussian Attention Model and Its Application to Knowledge Base Embedding\n  and Question Answering", "abstract": "We propose the Gaussian attention model for content-based neural memory\naccess. With the proposed attention model, a neural network has the additional\ndegree of freedom to control the focus of its attention from a laser sharp\nattention to a broad attention. It is applicable whenever we can assume that\nthe distance in the latent space reflects some notion of semantics. We use the\nproposed attention model as a scoring function for the embedding of a knowledge\nbase into a continuous vector space and then train a model that performs\nquestion answering about the entities in the knowledge base. The proposed\nattention model can handle both the propagation of uncertainty when following a\nseries of relations and also the conjunction of conditions in a natural way. On\na dataset of soccer players who participated in the FIFA World Cup 2014, we\ndemonstrate that our model can handle both path queries and conjunctive queries\nwell.", "published": "2016-11-07 20:57:24", "link": "http://arxiv.org/abs/1611.02266v2", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Balotage in Argentina 2015, a sentiment analysis of tweets", "abstract": "Twitter social network contains a large amount of information generated by\nits users. That information is composed of opinions and comments that may\nreflect trends in social behavior. There is talk of trend when it is possible\nto identify opinions and comments geared towards the same shared by a lot of\npeople direction. To determine if two or more written opinions share the same\naddress, techniques Natural Language Processing (NLP) are used. This paper\nproposes a methodology for predicting reflected in Twitter from the use of\nsentiment analysis functions NLP based on social behaviors. The case study was\nselected the 2015 Presidential in Argentina, and a software architecture Big\nData composed Vertica data base with the component called Pulse was used.\nThrough the analysis it was possible to detect trends in voting intentions with\nregard to the presidential candidates, achieving greater accuracy in predicting\nthat achieved with traditional systems surveys.", "published": "2016-11-07 23:05:40", "link": "http://arxiv.org/abs/1611.02337v1", "categories": ["cs.IR", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
