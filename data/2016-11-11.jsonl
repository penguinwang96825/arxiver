{"title": "Improving Reliability of Word Similarity Evaluation by Redesigning\n  Annotation Task and Performance Measure", "abstract": "We suggest a new method for creating and using gold-standard datasets for\nword similarity evaluation. Our goal is to improve the reliability of the\nevaluation, and we do this by redesigning the annotation task to achieve higher\ninter-rater agreement, and by defining a performance measure which takes the\nreliability of each annotation decision in the dataset into account.", "published": "2016-11-11 10:06:29", "link": "http://arxiv.org/abs/1611.03641v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalized Entropies and the Similarity of Texts", "abstract": "We show how generalized Gibbs-Shannon entropies can provide new insights on\nthe statistical properties of texts. The universal distribution of word\nfrequencies (Zipf's law) implies that the generalized entropies, computed at\nthe word level, are dominated by words in a specific range of frequencies. Here\nwe show that this is the case not only for the generalized entropies but also\nfor the generalized (Jensen-Shannon) divergences, used to compute the\nsimilarity between different texts. This finding allows us to identify the\ncontribution of specific words (and word frequencies) for the different\ngeneralized entropies and also to estimate the size of the databases needed to\nobtain a reliable estimation of the divergences. We test our results in large\ndatabases of books (from the Google n-gram database) and scientific papers\n(indexed by Web of Science).", "published": "2016-11-11 06:36:53", "link": "http://arxiv.org/abs/1611.03596v1", "categories": ["physics.soc-ph", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "Neural Networks Models for Entity Discovery and Linking", "abstract": "This paper describes the USTC_NELSLIP systems submitted to the Trilingual\nEntity Detection and Linking (EDL) track in 2016 TAC Knowledge Base Population\n(KBP) contests. We have built two systems for entity discovery and mention\ndetection (MD): one uses the conditional RNNLM and the other one uses the\nattention-based encoder-decoder framework. The entity linking (EL) system\nconsists of two modules: a rule based candidate generation and a neural\nnetworks probability ranking model. Moreover, some simple string matching rules\nare used for NIL clustering. At the end, our best system has achieved an F1\nscore of 0.624 in the end-to-end typed mention ceaf plus metric.", "published": "2016-11-11 01:21:20", "link": "http://arxiv.org/abs/1611.03558v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "UTCNN: a Deep Learning Model of Stance Classificationon on Social Media\n  Text", "abstract": "Most neural network models for document classification on social media focus\non text infor-mation to the neglect of other information on these platforms. In\nthis paper, we classify post stance on social media channels and develop UTCNN,\na neural network model that incorporates user tastes, topic tastes, and user\ncomments on posts. UTCNN not only works on social media texts, but also\nanalyzes texts in forums and message boards. Experiments performed on Chinese\nFacebook data and English online debate forum data show that UTCNN achieves a\n0.755 macro-average f-score for supportive, neutral, and unsupportive stance\nclasses on Facebook data, which is significantly better than models in which\neither user, topic, or comment information is withheld. This model design\ngreatly mitigates the lack of data for the minor class without the use of\noversampling. In addition, UTCNN yields a 0.842 accuracy on English online\ndebate forum data, which also significantly outperforms results from previous\nwork as well as other deep learning models, showing that UTCNN performs well\nregardless of language or platform.", "published": "2016-11-11 07:05:49", "link": "http://arxiv.org/abs/1611.03599v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
