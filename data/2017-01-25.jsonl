{"title": "Hierarchical Recurrent Attention Network for Response Generation", "abstract": "We study multi-turn response generation in chatbots where a response is\ngenerated according to a conversation context. Existing work has modeled the\nhierarchy of the context, but does not pay enough attention to the fact that\nwords and utterances in the context are differentially important. As a result,\nthey may lose important information in context and generate irrelevant\nresponses. We propose a hierarchical recurrent attention network (HRAN) to\nmodel both aspects in a unified framework. In HRAN, a hierarchical attention\nmechanism attends to important parts within and among utterances with word\nlevel attention and utterance level attention respectively. With the word level\nattention, hidden vectors of a word level encoder are synthesized as utterance\nvectors and fed to an utterance level encoder to construct hidden\nrepresentations of the context. The hidden vectors of the context are then\nprocessed by the utterance level attention and formed as context vectors for\ndecoding the response. Empirical studies on both automatic evaluation and human\njudgment show that HRAN can significantly outperform state-of-the-art models\nfor multi-turn response generation.", "published": "2017-01-25 03:04:31", "link": "http://arxiv.org/abs/1701.07149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Word-Like Units from Joint Audio-Visual Analysis", "abstract": "Given a collection of images and spoken audio captions, we present a method\nfor discovering word-like acoustic units in the continuous speech signal and\ngrounding them to semantically relevant image regions. For example, our model\nis able to detect spoken instances of the word 'lighthouse' within an utterance\nand associate them with image regions containing lighthouses. We do not use any\nform of conventional automatic speech recognition, nor do we use any text\ntranscriptions or conventional linguistic annotations. Our model effectively\nimplements a form of spoken language acquisition, in which the computer learns\nnot only to recognize word categories by sound, but also to enrich the words it\nlearns with semantics by grounding them in images.", "published": "2017-01-25 20:40:56", "link": "http://arxiv.org/abs/1701.07481v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
