{"title": "ReINTEL Challenge 2020: Exploiting Transfer Learning Models for Reliable\n  Intelligence Identification on Vietnamese Social Network Sites", "abstract": "This paper presents the system that we propose for the Reliable Intelligence\nIndentification on Vietnamese Social Network Sites (ReINTEL) task of the\nVietnamese Language and Speech Processing 2020 (VLSP 2020) Shared Task. In this\ntask, the VLSP 2020 provides a dataset with approximately 6,000 trainning\nnews/posts annotated with reliable or unreliable labels, and a test set\nconsists of 2,000 examples without labels. In this paper, we conduct\nexperiments on different transfer learning models, which are bert4news and\nPhoBERT fine-tuned to predict whether the news is reliable or not. In our\nexperiments, we achieve the AUC score of 94.52% on the private test set from\nReINTEL's organizers.", "published": "2021-02-22 06:17:33", "link": "http://arxiv.org/abs/2102.10794v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Contextualized Language Models for Hungarian", "abstract": "We present an extended comparison of contextualized language models for\nHungarian. We compare huBERT, a Hungarian model against 4 multilingual models\nincluding the multilingual BERT model. We evaluate these models through three\ntasks, morphological probing, POS tagging and NER. We find that huBERT works\nbetter than the other models, often by a large margin, particularly near the\nglobal optimum (typically at the middle layers). We also find that huBERT tends\nto generate fewer subwords for one word and that using the last subword for\ntoken-level tasks is generally a better choice than using the first one.", "published": "2021-02-22 09:29:01", "link": "http://arxiv.org/abs/2102.10848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subword Pooling Makes a Difference", "abstract": "Contextual word-representations became a standard in modern natural language\nprocessing systems. These models use subword tokenization to handle large\nvocabularies and unknown words. Word-level usage of such systems requires a way\nof pooling multiple subwords that correspond to a single word. In this paper we\ninvestigate how the choice of subword pooling affects the downstream\nperformance on three tasks: morphological probing, POS tagging and NER, in 9\ntypologically diverse languages. We compare these in two massively multilingual\nmodels, mBERT and XLM-RoBERTa. For morphological tasks, the widely used `choose\nthe first subword' is the worst strategy and the best results are obtained by\nusing attention over the subwords. For POS tagging both of these strategies\nperform poorly and the best choice is to use a small LSTM over the subwords.\nThe same strategy works best for NER and we show that mBERT is better than\nXLM-RoBERTa in all 9 languages. We publicly release all code, data and the full\nresult tables at \\url{https://github.com/juditacs/subword-choice}.", "published": "2021-02-22 09:59:30", "link": "http://arxiv.org/abs/2102.10864v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few Shot Learning for Information Verification", "abstract": "Information verification is quite a challenging task, this is because many\ntimes verifying a claim can require picking pieces of information from multiple\npieces of evidence which can have a hierarchy of complex semantic relations.\nPreviously a lot of researchers have mainly focused on simply concatenating\nmultiple evidence sentences to accept or reject claims. These approaches are\nlimited as evidence can contain hierarchical information and dependencies. In\nthis research, we aim to verify facts based on evidence selected from a list of\narticles taken from Wikipedia. Pretrained language models such as XLNET are\nused to generate meaningful representations and graph-based attention and\nconvolutions are used in such a way that the system requires little additional\ntraining to learn to verify facts.", "published": "2021-02-22 12:56:12", "link": "http://arxiv.org/abs/2102.10956v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co-occurrences using Fasttext embeddings for word similarity tasks in\n  Urdu", "abstract": "Urdu is a widely spoken language in South Asia. Though immoderate literature\nexists for the Urdu language still the data isn't enough to naturally process\nthe language by NLP techniques. Very efficient language models exist for the\nEnglish language, a high resource language, but Urdu and other under-resourced\nlanguages have been neglected for a long time. To create efficient language\nmodels for these languages we must have good word embedding models. For Urdu,\nwe can only find word embeddings trained and developed using the skip-gram\nmodel. In this paper, we have built a corpus for Urdu by scraping and\nintegrating data from various sources and compiled a vocabulary for the Urdu\nlanguage. We also modify fasttext embeddings and N-Grams models to enable\ntraining them on our built corpus. We have used these trained embeddings for a\nword similarity task and compared the results with existing techniques.", "published": "2021-02-22 12:56:26", "link": "http://arxiv.org/abs/2102.10957v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bilingual Language Modeling, A transfer learning technique for Roman\n  Urdu", "abstract": "Pretrained language models are now of widespread use in Natural Language\nProcessing. Despite their success, applying them to Low Resource languages is\nstill a huge challenge. Although Multilingual models hold great promise,\napplying them to specific low-resource languages e.g. Roman Urdu can be\nexcessive. In this paper, we show how the code-switching property of languages\nmay be used to perform cross-lingual transfer learning from a corresponding\nhigh resource language. We also show how this transfer learning technique\ntermed Bilingual Language Modeling can be used to produce better performing\nmodels for Roman Urdu. To enable training and experimentation, we also present\na collection of novel corpora for Roman Urdu extracted from various sources and\nsocial networking sites, e.g. Twitter. We train Monolingual, Multilingual, and\nBilingual models of Roman Urdu - the proposed bilingual model achieves 23%\naccuracy compared to the 2% and 11% of the monolingual and multilingual models\nrespectively in the Masked Language Modeling (MLM) task.", "published": "2021-02-22 12:56:37", "link": "http://arxiv.org/abs/2102.10958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Adaptation in Dialogue Systems using Transfer and Meta-Learning", "abstract": "Current generative-based dialogue systems are data-hungry and fail to adapt\nto new unseen domains when only a small amount of target data is available.\nAdditionally, in real-world applications, most domains are underrepresented, so\nthere is a need to create a system capable of generalizing to these domains\nusing minimal data. In this paper, we propose a method that adapts to unseen\ndomains by combining both transfer and meta-learning (DATML). DATML improves\nthe previous state-of-the-art dialogue model, DiKTNet, by introducing a\ndifferent learning technique: meta-learning. We use Reptile, a first-order\noptimization-based meta-learning algorithm as our improved training method. We\nevaluated our model on the MultiWOZ dataset and outperformed DiKTNet in both\nBLEU and Entity F1 scores when the same amount of data is available.", "published": "2021-02-22 16:16:57", "link": "http://arxiv.org/abs/2102.11146v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creating a Universal Dependencies Treebank of Spoken Frisian-Dutch\n  Code-switched Data", "abstract": "This paper explores the difficulties of annotating transcribed spoken\nDutch-Frisian code-switch utterances into Universal Dependencies. We make use\nof data from the FAME! corpus, which consists of transcriptions and audio data.\nBesides the usual annotation difficulties, this dataset is extra challenging\nbecause of Frisian being low-resource, the informal nature of the data,\ncode-switching and non-standard sentence segmentation. As a starting point, two\nannotators annotated 150 random utterances in three stages of 50 utterances.\nAfter each stage, disagreements where discussed and resolved. An increase of\n7.8 UAS and 10.5 LAS points was achieved between the first and third round.\nThis paper will focus on the issues that arise when annotating a transcribed\nspeech corpus. To resolve these issues several solutions are proposed.", "published": "2021-02-22 16:22:28", "link": "http://arxiv.org/abs/2102.11152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RUBERT: A Bilingual Roman Urdu BERT Using Cross Lingual Transfer\n  Learning", "abstract": "In recent studies, it has been shown that Multilingual language models\nunderperform their monolingual counterparts. It is also a well-known fact that\ntraining and maintaining monolingual models for each language is a costly and\ntime-consuming process. Roman Urdu is a resource-starved language used\npopularly on social media platforms and chat apps. In this research, we propose\na novel dataset of scraped tweets containing 54M tokens and 3M sentences.\nAdditionally, we also propose RUBERT a bilingual Roman Urdu model created by\nadditional pretraining of English BERT. We compare its performance with a\nmonolingual Roman Urdu BERT trained from scratch and a multilingual Roman Urdu\nBERT created by additional pretraining of Multilingual BERT. We show through\nour experiments that additional pretraining of the English BERT produces the\nmost notable performance improvement.", "published": "2021-02-22 12:56:49", "link": "http://arxiv.org/abs/2102.11278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Multimodal Reinforcement Learning for Simultaneous Machine\n  Translation", "abstract": "This paper addresses the problem of simultaneous machine translation (SiMT)\nby exploring two main concepts: (a) adaptive policies to learn a good trade-off\nbetween high translation quality and low latency; and (b) visual information to\nsupport this process by providing additional (visual) contextual information\nwhich may be available before the textual input is produced. For that, we\npropose a multimodal approach to simultaneous machine translation using\nreinforcement learning, with strategies to integrate visual and textual\ninformation in both the agent and the environment. We provide an exploration on\nhow different types of visual information and integration strategies affect the\nquality and latency of simultaneous translation models, and demonstrate that\nvisual cues lead to higher quality while keeping the latency low.", "published": "2021-02-22 22:26:22", "link": "http://arxiv.org/abs/2102.11387v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Supervised and Unsupervised Rewards in Machine Translation", "abstract": "Reinforcement Learning (RL) is a powerful framework to address the\ndiscrepancy between loss functions used during training and the final\nevaluation metrics to be used at test time. When applied to neural Machine\nTranslation (MT), it minimises the mismatch between the cross-entropy loss and\nnon-differentiable evaluation metrics like BLEU. However, the suitability of\nthese metrics as reward function at training time is questionable: they tend to\nbe sparse and biased towards the specific words used in the reference texts. We\npropose to address this problem by making models less reliant on such metrics\nin two ways: (a) with an entropy-regularised RL method that does not only\nmaximise a reward function but also explore the action space to avoid peaky\ndistributions; (b) with a novel RL method that explores a dynamic unsupervised\nreward function to balance between exploration and exploitation. We base our\nproposals on the Soft Actor-Critic (SAC) framework, adapting the off-policy\nmaximum entropy model for language generation applications such as MT. We\ndemonstrate that SAC with BLEU reward tends to overfit less to the training\ndata and performs better on out-of-domain data. We also show that our dynamic\nunsupervised reward can lead to better translation of ambiguous words.", "published": "2021-02-22 23:18:25", "link": "http://arxiv.org/abs/2102.11403v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniT: Multimodal Multitask Learning with a Unified Transformer", "abstract": "We propose UniT, a Unified Transformer model to simultaneously learn the most\nprominent tasks across different domains, ranging from object detection to\nnatural language understanding and multimodal reasoning. Based on the\ntransformer encoder-decoder architecture, our UniT model encodes each input\nmodality with an encoder and makes predictions on each task with a shared\ndecoder over the encoded input representations, followed by task-specific\noutput heads. The entire model is jointly trained end-to-end with losses from\neach task. Compared to previous efforts on multi-task learning with\ntransformers, we share the same model parameters across all tasks instead of\nseparately fine-tuning task-specific models and handle a much higher variety of\ntasks across different domains. In our experiments, we learn 7 tasks jointly\nover 8 datasets, achieving strong performance on each task with significantly\nfewer parameters. Our code is available in MMF at https://mmf.sh.", "published": "2021-02-22 04:45:06", "link": "http://arxiv.org/abs/2102.10772v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multi-View Feature Representation for Dialogue Generation with\n  Bidirectional Distillation", "abstract": "Neural dialogue models suffer from low-quality responses when interacted in\npractice, demonstrating difficulty in generalization beyond training data.\nRecently, knowledge distillation has been used to successfully regularize the\nstudent by transferring knowledge from the teacher. However, the teacher and\nthe student are trained on the same dataset and tend to learn similar feature\nrepresentations, whereas the most general knowledge should be found through\ndifferences. The finding of general knowledge is further hindered by the\nunidirectional distillation, as the student should obey the teacher and may\ndiscard some knowledge that is truly general but refuted by the teacher. To\nthis end, we propose a novel training framework, where the learning of general\nknowledge is more in line with the idea of reaching consensus, i.e., finding\ncommon knowledge that is beneficial to different yet all datasets through\ndiversified learning partners. Concretely, the training task is divided into a\ngroup of subtasks with the same number of students. Each student assigned to\none subtask not only is optimized on the allocated subtask but also imitates\nmulti-view feature representation aggregated from other students (i.e., student\npeers), which induces students to capture common knowledge among different\nsubtasks and alleviates the over-fitting of students on the allocated subtasks.\nTo further enhance generalization, we extend the unidirectional distillation to\nthe bidirectional distillation that encourages the student and its student\npeers to co-evolve by exchanging complementary knowledge with each other.\nEmpirical results and analysis demonstrate that our training framework\neffectively improves the model generalization without sacrificing training\nefficiency.", "published": "2021-02-22 05:23:34", "link": "http://arxiv.org/abs/2102.10780v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Joint Intent Detection And Slot Filling Based on Continual Learning\n  Model", "abstract": "Slot filling and intent detection have become a significant theme in the\nfield of natural language understanding. Even though slot filling is\nintensively associated with intent detection, the characteristics of the\ninformation required for both tasks are different while most of those\napproaches may not fully aware of this problem. In addition, balancing the\naccuracy of two tasks effectively is an inevitable problem for the joint\nlearning model. In this paper, a Continual Learning Interrelated Model (CLIM)\nis proposed to consider semantic information with different characteristics and\nbalance the accuracy between intent detection and slot filling effectively. The\nexperimental results show that CLIM achieves state-of-the-art performace on\nslot filling and intent detection on ATIS and Snips.", "published": "2021-02-22 11:10:35", "link": "http://arxiv.org/abs/2102.10905v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Using Prior Knowledge to Guide BERT's Attention in Semantic Textual\n  Matching Tasks", "abstract": "We study the problem of incorporating prior knowledge into a deep\nTransformer-based model,i.e.,Bidirectional Encoder Representations from\nTransformers (BERT), to enhance its performance on semantic textual matching\ntasks. By probing and analyzing what BERT has already known when solving this\ntask, we obtain better understanding of what task-specific knowledge BERT needs\nthe most and where it is most needed. The analysis further motivates us to take\na different approach than most existing works. Instead of using prior knowledge\nto create a new training task for fine-tuning BERT, we directly inject\nknowledge into BERT's multi-head attention mechanism. This leads us to a simple\nyet effective approach that enjoys fast training stage as it saves the model\nfrom training on additional data or tasks other than the main task. Extensive\nexperiments demonstrate that the proposed knowledge-enhanced BERT is able to\nconsistently improve semantic textual matching performance over the original\nBERT model, and the performance benefit is most salient when training data is\nscarce.", "published": "2021-02-22 12:07:16", "link": "http://arxiv.org/abs/2102.10934v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Entities of Interest", "abstract": "In the era of big data, we continuously - and at times unknowingly - leave\nbehind digital traces, by browsing, sharing, posting, liking, searching,\nwatching, and listening to online content. When aggregated, these digital\ntraces can provide powerful insights into the behavior, preferences,\nactivities, and traits of people. While many have raised privacy concerns\naround the use of aggregated digital traces, it has undisputedly brought us\nmany advances, from the search engines that learn from their users and enable\nour access to unforeseen amounts of data, knowledge, and information, to, e.g.,\nthe discovery of previously unknown adverse drug reactions from search engine\nlogs.\n  Whether in online services, journalism, digital forensics, law, or research,\nwe increasingly set out to exploring large amounts of digital traces to\ndiscover new information. Consider for instance, the Enron scandal, Hillary\nClinton's email controversy, or the Panama papers: cases that revolve around\nanalyzing, searching, investigating, exploring, and turning upside down large\namounts of digital traces to gain new insights, knowledge, and information.\nThis discovery task is at its core about \"finding evidence of activity in the\nreal world.\"\n  This dissertation revolves around discovery in digital traces, and sits at\nthe intersection of Information Retrieval, Natural Language Processing, and\napplied Machine Learning. We propose computational methods that aim to support\nthe exploration and sense-making process of large collections of digital\ntraces. We focus on textual traces, e.g., emails and social media streams, and\naddress two aspects that are central to discovery in digital traces.", "published": "2021-02-22 13:07:48", "link": "http://arxiv.org/abs/2102.10962v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Better Call the Plumber: Orchestrating Dynamic Information Extraction\n  Pipelines", "abstract": "In the last decade, a large number of Knowledge Graph (KG) information\nextraction approaches were proposed. Albeit effective, these efforts are\ndisjoint, and their collective strengths and weaknesses in effective KG\ninformation extraction (IE) have not been studied in the literature. We propose\nPlumber, the first framework that brings together the research community's\ndisjoint IE efforts. The Plumber architecture comprises 33 reusable components\nfor various KG information extraction subtasks, such as coreference resolution,\nentity linking, and relation extraction. Using these components,Plumber\ndynamically generates suitable information extraction pipelines and offers\noverall 264 distinct pipelines.We study the optimization problem of choosing\nsuitable pipelines based on input sentences. To do so, we train a\ntransformer-based classification model that extracts contextual embeddings from\nthe input and finds an appropriate pipeline. We study the efficacy of Plumber\nfor extracting the KG triples using standard datasets over two KGs: DBpedia,\nand Open Research Knowledge Graph (ORKG). Our results demonstrate the\neffectiveness of Plumber in dynamically generating KG information extraction\npipelines,outperforming all baselines agnostics of the underlying KG.\nFurthermore,we provide an analysis of collective failure cases, study the\nsimilarities and synergies among integrated components, and discuss their\nlimitations.", "published": "2021-02-22 13:14:02", "link": "http://arxiv.org/abs/2102.10966v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Kindergarden quantum mechanics graduates (...or how I learned to stop\n  gluing LEGO together and love the ZX-calculus)", "abstract": "This paper is a `spiritual child' of the 2005 lecture notes Kindergarten\nQuantum Mechanics, which showed how a simple, pictorial extension of Dirac\nnotation allowed several quantum features to be easily expressed and derived,\nusing language even a kindergartner can understand. Central to that approach\nwas the use of pictures and pictorial transformation rules to understand and\nderive features of quantum theory and computation. However, this approach left\nmany wondering `where's the beef?' In other words, was this new approach\ncapable of producing new results, or was it simply an aesthetically pleasing\nway to restate stuff we already know?\n  The aim of this sequel paper is to say `here's the beef!', and highlight some\nof the major results of the approach advocated in Kindergarten Quantum\nMechanics, and how they are being applied to tackle practical problems on real\nquantum computers. We will focus mainly on what has become the Swiss army knife\nof the pictorial formalism: the ZX-calculus. First we look at some of the ideas\nbehind the ZX-calculus, comparing and contrasting it with the usual quantum\ncircuit formalism. We then survey results from the past 2 years falling into\nthree categories: (1) completeness of the rules of the ZX-calculus, (2)\nstate-of-the-art quantum circuit optimisation results in commercial and\nopen-source quantum compilers relying on ZX, and (3) the use of ZX in\ntranslating real-world stuff like natural language into quantum circuits that\ncan be run on today's (very limited) quantum hardware.\n  We also take the title literally, and outline an ongoing experiment aiming to\nshow that ZX-calculus enables children to do cutting-edge quantum computing\nstuff. If anything, this would truly confirm that `kindergarten quantum\nmechanics' wasn't just a joke.", "published": "2021-02-22 13:42:33", "link": "http://arxiv.org/abs/2102.10984v1", "categories": ["quant-ph", "cs.CL"], "primary_category": "quant-ph"}
{"title": "Position Information in Transformers: An Overview", "abstract": "Transformers are arguably the main workhorse in recent Natural Language\nProcessing research. By definition a Transformer is invariant with respect to\nreordering of the input. However, language is inherently sequential and word\norder is essential to the semantics and syntax of an utterance. In this\narticle, we provide an overview and theoretical comparison of existing methods\nto incorporate position information into Transformer models. The objectives of\nthis survey are to (1) showcase that position information in Transformer is a\nvibrant and extensive research area; (2) enable the reader to compare existing\nmethods by providing a unified notation and systematization of different\napproaches along important model dimensions; (3) indicate what characteristics\nof an application should be taken into account when selecting a position\nencoding; (4) provide stimuli for future research.", "published": "2021-02-22 15:03:23", "link": "http://arxiv.org/abs/2102.11090v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "User Factor Adaptation for User Embedding via Multitask Learning", "abstract": "Language varies across users and their interested fields in social media\ndata: words authored by a user across his/her interests may have different\nmeanings (e.g., cool) or sentiments (e.g., fast). However, most of the existing\nmethods to train user embeddings ignore the variations across user interests,\nsuch as product and movie categories (e.g., drama vs. action). In this study,\nwe treat the user interest as domains and empirically examine how the user\nlanguage can vary across the user factor in three English social media\ndatasets. We then propose a user embedding model to account for the language\nvariability of user interests via a multitask learning framework. The model\nlearns user language and its variations without human supervision. While\nexisting work mainly evaluated the user embedding by extrinsic tasks, we\npropose an intrinsic evaluation via clustering and evaluate user embeddings by\nan extrinsic task, text classification. The experiments on the three\nEnglish-language social media datasets show that our proposed approach can\ngenerally outperform baselines via adapting the user factor.", "published": "2021-02-22 15:21:01", "link": "http://arxiv.org/abs/2102.11103v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "REMOD: Relation Extraction for Modeling Online Discourse", "abstract": "The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.", "published": "2021-02-22 15:26:36", "link": "http://arxiv.org/abs/2102.11105v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Cognitively Aided Zero-Shot Automatic Essay Grading", "abstract": "Automatic essay grading (AEG) is a process in which machines assign a grade\nto an essay written in response to a topic, called the prompt. Zero-shot AEG is\nwhen we train a system to grade essays written to a new prompt which was not\npresent in our training data. In this paper, we describe a solution to the\nproblem of zero-shot automatic essay grading, using cognitive information, in\nthe form of gaze behaviour. Our experiments show that using gaze behaviour\nhelps in improving the performance of AEG systems, especially when we provide a\nnew essay written in response to a new prompt for scoring, by an average of\nalmost 5 percentage points of QWK.", "published": "2021-02-22 18:41:59", "link": "http://arxiv.org/abs/2102.11258v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MixUp Training Leads to Reduced Overfitting and Improved Calibration for\n  the Transformer Architecture", "abstract": "MixUp is a computer vision data augmentation technique that uses convex\ninterpolations of input data and their labels to enhance model generalization\nduring training. However, the application of MixUp to the natural language\nunderstanding (NLU) domain has been limited, due to the difficulty of\ninterpolating text directly in the input space. In this study, we propose MixUp\nmethods at the Input, Manifold, and sentence embedding levels for the\ntransformer architecture, and apply them to finetune the BERT model for a\ndiverse set of NLU tasks. We find that MixUp can improve model performance, as\nwell as reduce test loss and model calibration error by up to 50%.", "published": "2021-02-22 23:12:35", "link": "http://arxiv.org/abs/2102.11402v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Meta Learning for One Shot Title Compression in Voice\n  Commerce", "abstract": "Product title compression for voice and mobile commerce is a well studied\nproblem with several supervised models proposed so far. However these models\nhave 2 major limitations; they are not designed to generate compressions\ndynamically based on cues at inference time, and they do not transfer well to\ndifferent categories at test time. To address these shortcomings we model title\ncompression as a meta learning problem where we ask can we learn a title\ncompression model given only 1 example compression? We adopt an unsupervised\napproach to meta training by proposing an automatic task generation algorithm\nthat models the observed label generation process as the outcome of 4\nunobserved processes. We create parameterized approximations to each of these 4\nlatent processes to get a principled way of generating random compression\nrules, which are treated as different tasks. For our main meta learner, we use\n2 models; M1 and M2. M1 is a task agnostic embedding generator whose output\nfeeds into M2 which is a task specific label generator. We pre-train M1 on a\nnovel unsupervised segment rank prediction task that allows us to treat M1 as a\nsegment generator that also learns to rank segments during the meta-training\nprocess. Our experiments on 16000 crowd generated meta-test examples show that\nour unsupervised meta training regime is able to acquire a learning algorithm\nfor different tasks after seeing only 1 example for each task. Further, we show\nthat our model trained end to end as a black box meta learner, outperforms non\nparametric approaches. Our best model obtains an F1 score of 0.8412, beating\nthe baseline by a large margin of 25 F1 points.", "published": "2021-02-22 03:53:33", "link": "http://arxiv.org/abs/2102.10760v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LightCAKE: A Lightweight Framework for Context-Aware Knowledge Graph\n  Embedding", "abstract": "Knowledge graph embedding (KGE) models learn to project symbolic entities and\nrelations into a continuous vector space based on the observed triplets.\nHowever, existing KGE models cannot make a proper trade-off between the graph\ncontext and the model complexity, which makes them still far from satisfactory.\nIn this paper, we propose a lightweight framework named LightCAKE for\ncontext-aware KGE. LightCAKE explicitly models the graph context without\nintroducing redundant trainable parameters, and uses an iterative aggregation\nstrategy to integrate the context information into the entity/relation\nembeddings. As a generic framework, it can be used with many simple KGE models\nto achieve excellent results. Finally, extensive experiments on public\nbenchmarks demonstrate the efficiency and effectiveness of our framework.", "published": "2021-02-22 08:23:22", "link": "http://arxiv.org/abs/2102.10826v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Relational Tsetlin Machine with Applications to Natural Language\n  Understanding", "abstract": "TMs are a pattern recognition approach that uses finite state machines for\nlearning and propositional logic to represent patterns. In addition to being\nnatively interpretable, they have provided competitive accuracy for various\ntasks. In this paper, we increase the computing power of TMs by proposing a\nfirst-order logic-based framework with Herbrand semantics. The resulting TM is\nrelational and can take advantage of logical structures appearing in natural\nlanguage, to learn rules that represent how actions and consequences are\nrelated in the real world. The outcome is a logic program of Horn clauses,\nbringing in a structured view of unstructured data. In closed-domain\nquestion-answering, the first-order representation produces 10x more compact\nKBs, along with an increase in answering accuracy from 94.83% to 99.48%. The\napproach is further robust towards erroneous, missing, and superfluous\ninformation, distilling the aspects of a text that are important for real-world\nunderstanding.", "published": "2021-02-22 12:40:37", "link": "http://arxiv.org/abs/2102.10952v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO", "I.2.7; I.2.4"], "primary_category": "cs.CL"}
{"title": "The Moral Foundations of Left-Wing Authoritarianism: On the Character,\n  Cohesion, and Clout of Tribal Equalitarian Discourse", "abstract": "Left-wing authoritarianism remains far less understood than right-wing\nauthoritarianism. We contribute to the literature on the former, which\ntypically relies on surveys, using a new social media analytics approach. We\nuse a list of 60 terms to provide an exploratory sketch of the outlines of a\npolitical ideology (tribal equalitarianism) with origins in 19th and 20th\ncentury social philosophy. We then use analyses of the English Corpus of Google\nBooks (over 8 million books) and scraped unique tweets from Twitter (n =\n202,852) to conduct a series of investigations to discern the extent to which\nthis ideology is cohesive amongst the public, reveals signatures of\nauthoritarianism and has been growing in popularity. Though exploratory, our\nresults provide some evidence of left-wing authoritarianism in two forms (1) a\nuniquely conservative moral signature amongst ostensible liberals using\nmeasures from Moral Foundations Theory and (2) a substantial prevalence of\nanger, relative to anxiety or sadness. In general, results indicate that this\nworldview is growing in popularity, is increasingly cohesive, and shows\nsignatures of authoritarianism.", "published": "2021-02-22 14:06:25", "link": "http://arxiv.org/abs/2102.11009v1", "categories": ["cs.SI", "cs.CL", "cs.CY"], "primary_category": "cs.SI"}
{"title": "How are journals cited? characterizing journal citations by type of\n  citation", "abstract": "Evaluation of journals for quality is one of the dominant themes of\nbibliometrics since journals are the primary venue of vetting and distribution\nof scholarship. There are many criticisms of quantifying journal impact with\nbibliometrics including disciplinary differences among journals, what source\nmaterials are used, time windows for the inclusion of works to measure, and\nskewness of citation distributions (Lariviere & Sugimoto, 2019). However,\ndespite various attempts to remediate these in newly proposed indicators such\nas SJR, SNIP, and Eigenfactor (Walters, 2017) indicators still remain based on\ncitation counts and fail to acknowledge the critical differences that the type\nof citation made, whether it's supporting or disputing a work when quantifying\njournal impact. While various programs have been suggested to apply and\nencompass citation content analysis within bibliometrics projects, citation\ncontent analysis has not been done at the scale needed in order to supplement\nquantitate journal citation analysis until the scite citation index was\nproduced. Using this citation index containing citation types based on citation\nfunction (supporting, disputing, or mentioning) we present initial results on\nthe statistical characterization of citations to journals based on citation\nfunction. We also present initial results of characterizing the ratio of\nsupports and disputes received by a journal as a potential indicator of quality\nand show two interesting results: the ratio of supports and disputes do not\ncorrelate with total citations and that the distribution of this ratio is not\nskewed showing a normal distribution. We conclude with a proposal for future\nresearch using citation analysis qualified by citation function as well as the\nimplications of performing bibliometrics tasks such as research evaluation and\ninformation retrieval using citation function.", "published": "2021-02-22 14:15:50", "link": "http://arxiv.org/abs/2102.11043v1", "categories": ["cs.DL", "cs.CL", "stat.AP"], "primary_category": "cs.DL"}
{"title": "Generating Human Readable Transcript for Automatic Speech Recognition\n  with Pre-trained Language Model", "abstract": "Modern Automatic Speech Recognition (ASR) systems can achieve high\nperformance in terms of recognition accuracy. However, a perfectly accurate\ntranscript still can be challenging to read due to disfluency, filter words,\nand other errata common in spoken communication. Many downstream tasks and\nhuman readers rely on the output of the ASR system; therefore, errors\nintroduced by the speaker and ASR system alike will be propagated to the next\ntask in the pipeline. In this work, we propose an ASR post-processing model\nthat aims to transform the incorrect and noisy ASR output into a readable text\nfor humans and downstream tasks. We leverage the Metadata Extraction (MDE)\ncorpus to construct a task-specific dataset for our study. Since the dataset is\nsmall, we propose a novel data augmentation method and use a two-stage training\nstrategy to fine-tune the RoBERTa pre-trained model. On the constructed test\nset, our model outperforms a production two-step pipeline-based post-processing\nmethod by a large margin of 13.26 on readability-aware WER (RA-WER) and 17.53\non BLEU metrics. Human evaluation also demonstrates that our method can\ngenerate more human-readable transcripts than the baseline method.", "published": "2021-02-22 15:45:50", "link": "http://arxiv.org/abs/2102.11114v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Probing Multimodal Embeddings for Linguistic Properties: the\n  Visual-Semantic Case", "abstract": "Semantic embeddings have advanced the state of the art for countless natural\nlanguage processing tasks, and various extensions to multimodal domains, such\nas visual-semantic embeddings, have been proposed. While the power of\nvisual-semantic embeddings comes from the distillation and enrichment of\ninformation through machine learning, their inner workings are poorly\nunderstood and there is a shortage of analysis tools. To address this problem,\nwe generalize the notion of probing tasks to the visual-semantic case. To this\nend, we (i) discuss the formalization of probing tasks for embeddings of\nimage-caption pairs, (ii) define three concrete probing tasks within our\ngeneral framework, (iii) train classifiers to probe for those properties, and\n(iv) compare various state-of-the-art embeddings under the lens of the proposed\nprobing tasks. Our experiments reveal an up to 12% increase in accuracy on\nvisual-semantic embeddings compared to the corresponding unimodal embeddings,\nwhich suggest that the text and image dimensions represented in the former do\ncomplement each other.", "published": "2021-02-22 15:47:04", "link": "http://arxiv.org/abs/2102.11115v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Automated Evaluation Of Psychotherapy Skills Using Speech And Language\n  Technologies", "abstract": "With the growing prevalence of psychological interventions, it is vital to\nhave measures which rate the effectiveness of psychological care to assist in\ntraining, supervision, and quality assurance of services. Traditionally,\nquality assessment is addressed by human raters who evaluate recorded sessions\nalong specific dimensions, often codified through constructs relevant to the\napproach and domain. This is however a cost-prohibitive and time-consuming\nmethod that leads to poor feasibility and limited use in real-world settings.\nTo facilitate this process, we have developed an automated competency rating\ntool able to process the raw recorded audio of a session, analyzing who spoke\nwhen, what they said, and how the health professional used language to provide\ntherapy. Focusing on a use case of a specific type of psychotherapy called\nMotivational Interviewing, our system gives comprehensive feedback to the\ntherapist, including information about the dynamics of the session (e.g.,\ntherapist's vs. client's talking time), low-level psychological language\ndescriptors (e.g., type of questions asked), as well as other high-level\nbehavioral constructs (e.g., the extent to which the therapist understands the\nclients' perspective). We describe our platform and its performance using a\ndataset of more than 5,000 recordings drawn from its deployment in a real-world\nclinical setting used to assist training of new therapists. Widespread use of\nautomated psychotherapy rating tools may augment experts' capabilities by\nproviding an avenue for more effective training and skill improvement,\neventually leading to more positive clinical outcomes.", "published": "2021-02-22 18:52:52", "link": "http://arxiv.org/abs/2102.11265v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LVCNet: Efficient Condition-Dependent Modeling Network for Waveform\n  Generation", "abstract": "In this paper, we propose a novel conditional convolution network, named\nlocation-variable convolution, to model the dependencies of the waveform\nsequence. Different from the use of unified convolution kernels in WaveNet to\ncapture the dependencies of arbitrary waveform, the location-variable\nconvolution uses convolution kernels with different coefficients to perform\nconvolution operations on different waveform intervals, where the coefficients\nof kernels is predicted according to conditioning acoustic features, such as\nMel-spectrograms. Based on location-variable convolutions, we design LVCNet for\nwaveform generation, and apply it in Parallel WaveGAN to design more efficient\nvocoder. Experiments on the LJSpeech dataset show that our proposed model\nachieves a four-fold increase in synthesis speed compared to the original\nParallel WaveGAN without any degradation in sound quality, which verifies the\neffectiveness of location-variable convolutions.", "published": "2021-02-22 07:55:34", "link": "http://arxiv.org/abs/2102.10815v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Investigating Deep Neural Structures and their Interpretability in the\n  Domain of Voice Conversion", "abstract": "Generative Adversarial Networks (GANs) are machine learning networks based\naround creating synthetic data. Voice Conversion (VC) is a subset of voice\ntranslation that involves translating the paralinguistic features of a source\nspeaker to a target speaker while preserving the linguistic information. The\naim of non-parallel conditional GANs for VC is to translate an acoustic speech\nfeature sequence from one domain to another without the use of paired data. In\nthe study reported here, we investigated the interpretability of\nstate-of-the-art implementations of non-parallel GANs in the domain of VC. We\nshow that the learned representations in the repeating layers of a particular\nGAN architecture remain close to their original random initialised parameters,\ndemonstrating that it is the number of repeating layers that is more\nresponsible for the quality of the output. We also analysed the learned\nrepresentations of a model trained on one particular dataset when used during\ntransfer learning on another dataset. This showed extremely high levels of\nsimilarity across the entire network. Together, these results provide new\ninsight into how the learned representations of deep generative networks change\nduring learning and the importance in the number of layers.", "published": "2021-02-22 23:54:01", "link": "http://arxiv.org/abs/2102.11420v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Anyone GAN Sing", "abstract": "The problem of audio synthesis has been increasingly solved using deep neural\nnetworks. With the introduction of Generative Adversarial Networks (GAN),\nanother efficient and adjective path has opened up to solve this problem. In\nthis paper, we present a method to synthesize the singing voice of a person\nusing a Convolutional Long Short-term Memory (ConvLSTM) based GAN optimized\nusing the Wasserstein loss function. Our work is inspired by WGANSing by\nChandna et al. Our model inputs consecutive frame-wise linguistic and frequency\nfeatures, along with singer identity and outputs vocoder features. We train the\nmodel on a dataset of 48 English songs sung and spoken by 12 non-professional\nsingers. For inference, sequential blocks are concatenated using an overlap-add\nprocedure. We test the model using the Mel-Cepstral Distance metric and a\nsubjective listening test with 18 participants.", "published": "2021-02-22 14:30:58", "link": "http://arxiv.org/abs/2102.11058v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
