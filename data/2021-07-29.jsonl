{"title": "Using Perturbed Length-aware Positional Encoding for Non-autoregressive\n  Neural Machine Translation", "abstract": "Non-autoregressive neural machine translation (NAT) usually employs\nsequence-level knowledge distillation using autoregressive neural machine\ntranslation (AT) as its teacher model. However, a NAT model often outputs\nshorter sentences than an AT model. In this work, we propose sequence-level\nknowledge distillation (SKD) using perturbed length-aware positional encoding\nand apply it to a student model, the Levenshtein Transformer. Our method\noutperformed a standard Levenshtein Transformer by 2.5 points in bilingual\nevaluation understudy (BLEU) at maximum in a WMT14 German to English\ntranslation. The NAT model output longer sentences than the baseline NAT\nmodels.", "published": "2021-07-29 00:51:44", "link": "http://arxiv.org/abs/2107.13689v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Term Expansion and FinBERT fine-tuning for Hypernym and Synonym Ranking\n  of Financial Terms", "abstract": "Hypernym and synonym matching are one of the mainstream Natural Language\nProcessing (NLP) tasks. In this paper, we present systems that attempt to solve\nthis problem. We designed these systems to participate in the FinSim-3, a\nshared task of FinNLP workshop at IJCAI-2021. The shared task is focused on\nsolving this problem for the financial domain. We experimented with various\ntransformer based pre-trained embeddings by fine-tuning these for either\nclassification or phrase similarity tasks. We also augmented the provided\ndataset with abbreviations derived from prospectus provided by the organizers\nand definitions of the financial terms from DBpedia [Auer et al., 2007],\nInvestopedia, and the Financial Industry Business Ontology (FIBO). Our best\nperforming system uses both FinBERT [Araci, 2019] and data augmentation from\nthe afore-mentioned sources. We observed that term expansion using data\naugmentation in conjunction with semantic similarity is beneficial for this\ntask and could be useful for the other tasks that deal with short phrases. Our\nbest performing model (Accuracy: 0.917, Rank: 1.156) was developed by\nfine-tuning SentenceBERT [Reimers et al., 2019] (with FinBERT at the backend)\nover an extended labelled set created using the hierarchy of labels present in\nFIBO.", "published": "2021-07-29 06:17:44", "link": "http://arxiv.org/abs/2107.13764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Break, Perturb, Build: Automatic Perturbation of Reasoning Paths Through\n  Question Decomposition", "abstract": "Recent efforts to create challenge benchmarks that test the abilities of\nnatural language understanding models have largely depended on human\nannotations. In this work, we introduce the \"Break, Perturb, Build\" (BPB)\nframework for automatic reasoning-oriented perturbation of question-answer\npairs. BPB represents a question by decomposing it into the reasoning steps\nthat are required to answer it, symbolically perturbs the decomposition, and\nthen generates new question-answer pairs. We demonstrate the effectiveness of\nBPB by creating evaluation sets for three reading comprehension (RC)\nbenchmarks, generating thousands of high-quality examples without human\nintervention. We evaluate a range of RC models on our evaluation sets, which\nreveals large performance gaps on generated examples compared to the original\ndata. Moreover, symbolic perturbations enable fine-grained analysis of the\nstrengths and limitations of models. Last, augmenting the training data with\nexamples generated by BPB helps close the performance gaps, without any drop on\nthe original data distribution.", "published": "2021-07-29 12:49:03", "link": "http://arxiv.org/abs/2107.13935v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeqScore: Addressing Barriers to Reproducible Named Entity Recognition\n  Evaluation", "abstract": "To address a looming crisis of unreproducible evaluation for named entity\nrecognition, we propose guidelines and introduce SeqScore, a software package\nto improve reproducibility. The guidelines we propose are extremely simple and\ncenter around transparency regarding how chunks are encoded and scored. We\ndemonstrate that despite the apparent simplicity of NER evaluation, unreported\ndifferences in the scoring procedure can result in changes to scores that are\nboth of noticeable magnitude and statistically significant. We describe\nSeqScore, which addresses many of the issues that cause replication failures.", "published": "2021-07-29 16:26:04", "link": "http://arxiv.org/abs/2107.14154v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IIITG-ADBU@HASOC-Dravidian-CodeMix-FIRE2020: Offensive Content Detection\n  in Code-Mixed Dravidian Text", "abstract": "This paper presents the results obtained by our SVM and XLM-RoBERTa based\nclassifiers in the shared task Dravidian-CodeMix-HASOC 2020. The SVM classifier\ntrained using TF-IDF features of character and word n-grams performed the best\non the code-mixed Malayalam text. It obtained a weighted F1 score of 0.95 (1st\nRank) and 0.76 (3rd Rank) on the YouTube and Twitter dataset respectively. The\nXLM-RoBERTa based classifier performed the best on the code-mixed Tamil text.\nIt obtained a weighted F1 score of 0.87 (3rd Rank) on the code-mixed Tamil\nTwitter dataset.", "published": "2021-07-29 21:23:17", "link": "http://arxiv.org/abs/2107.14336v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WiC = TSV = WSD: On the Equivalence of Three Semantic Tasks", "abstract": "The Word-in-Context (WiC) task has attracted considerable attention in the\nNLP community, as demonstrated by the popularity of the recent MCL-WiC SemEval\nshared task. Systems and lexical resources from word sense disambiguation (WSD)\nare often used for the WiC task and WiC dataset construction. In this paper, we\nestablish the exact relationship between WiC and WSD, as well as the related\ntask of target sense verification (TSV). Building upon a novel hypothesis on\nthe equivalence of sense and meaning distinctions, we demonstrate through the\napplication of tools from theoretical computer science that these three\nsemantic classification problems can be pairwise reduced to each other, and\ntherefore are equivalent. The results of experiments that involve systems and\ndatasets for both WiC and WSD provide strong empirical evidence that our\nproblem reductions work in practice.", "published": "2021-07-29 22:16:32", "link": "http://arxiv.org/abs/2107.14352v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "COVID-19 Vaccine and Social Media: Exploring Emotions and Discussions on\n  Twitter", "abstract": "The understanding of the public response to COVID-19 vaccines is the key\nsuccess factor to control the COVID-19 pandemic. To understand the public\nresponse, there is a need to explore public opinion. Traditional surveys are\nexpensive and time-consuming, address limited health topics, and obtain\nsmall-scale data. Twitter can provide a great opportunity to understand public\nopinion regarding COVID-19 vaccines. The current study proposes an approach\nusing computational and human coding methods to collect and analyze a large\nnumber of tweets to provide a wider perspective on the COVID-19 vaccine. This\nstudy identifies the sentiment of tweets using a machine learning rule-based\napproach, discovers major topics, explores temporal trend and compares topics\nof negative and non-negative tweets using statistical tests, and discloses top\ntopics of tweets having negative and non-negative sentiment. Our findings show\nthat the negative sentiment regarding the COVID-19 vaccine had a decreasing\ntrend between November 2020 and February 2021. We found Twitter users have\ndiscussed a wide range of topics from vaccination sites to the 2020 U.S.\nelection between November 2020 and February 2021. The findings show that there\nwas a significant difference between tweets having negative and non-negative\nsentiment regarding the weight of most topics. Our results also indicate that\nthe negative and non-negative tweets had different topic priorities and\nfocuses. This research illustrates that Twitter data can be used to explore\npublic opinion regarding the COVID-19 vaccine.", "published": "2021-07-29 17:31:11", "link": "http://arxiv.org/abs/2108.04816v2", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient\n  Pre-trained Language Models", "abstract": "Pre-trained language models (PLMs) have achieved great success in natural\nlanguage processing. Most of PLMs follow the default setting of architecture\nhyper-parameters (e.g., the hidden dimension is a quarter of the intermediate\ndimension in feed-forward sub-networks) in BERT (Devlin et al., 2019). Few\nstudies have been conducted to explore the design of architecture\nhyper-parameters in BERT, especially for the more efficient PLMs with tiny\nsizes, which are essential for practical deployment on resource-constrained\ndevices. In this paper, we adopt the one-shot Neural Architecture Search (NAS)\nto automatically search architecture hyper-parameters. Specifically, we\ncarefully design the techniques of one-shot learning and the search space to\nprovide an adaptive and efficient development way of tiny PLMs for various\nlatency constraints. We name our method AutoTinyBERT and evaluate its\neffectiveness on the GLUE and SQuAD benchmarks. The extensive experiments show\nthat our method outperforms both the SOTA search-based baseline (NAS-BERT) and\nthe SOTA distillation-based methods (such as DistilBERT, TinyBERT, MiniLM and\nMobileBERT). In addition, based on the obtained architectures, we propose a\nmore efficient development method that is even faster than the development of a\nsingle PLM.", "published": "2021-07-29 00:47:30", "link": "http://arxiv.org/abs/2107.13686v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Local Structure Matters Most: Perturbation Study in NLU", "abstract": "Recent research analyzing the sensitivity of natural language understanding\nmodels to word-order perturbations has shown that neural models are\nsurprisingly insensitive to the order of words. In this paper, we investigate\nthis phenomenon by developing order-altering perturbations on the order of\nwords, subwords, and characters to analyze their effect on neural models'\nperformance on language understanding tasks. We experiment with measuring the\nimpact of perturbations to the local neighborhood of characters and global\nposition of characters in the perturbed texts and observe that perturbation\nfunctions found in prior literature only affect the global ordering while the\nlocal ordering remains relatively unperturbed. We empirically show that neural\nmodels, invariant of their inductive biases, pretraining scheme, or the choice\nof tokenization, mostly rely on the local structure of text to build\nunderstanding and make limited use of the global structure.", "published": "2021-07-29 13:34:20", "link": "http://arxiv.org/abs/2107.13955v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MAIR: Framework for mining relationships between research articles,\n  strategies, and regulations in the field of explainable artificial\n  intelligence", "abstract": "The growing number of AI applications, also for high-stake decisions,\nincreases the interest in Explainable and Interpretable Machine Learning\n(XI-ML). This trend can be seen both in the increasing number of regulations\nand strategies for developing trustworthy AI and the growing number of\nscientific papers dedicated to this topic. To ensure the sustainable\ndevelopment of AI, it is essential to understand the dynamics of the impact of\nregulation on research papers as well as the impact of scientific discourse on\nAI-related policies. This paper introduces a novel framework for joint analysis\nof AI-related policy documents and eXplainable Artificial Intelligence (XAI)\nresearch papers. The collected documents are enriched with metadata and\ninterconnections, using various NLP methods combined with a methodology\ninspired by Institutional Grammar. Based on the information extracted from\ncollected documents, we showcase a series of analyses that help understand\ninteractions, similarities, and differences between documents at different\nstages of institutionalization. To the best of our knowledge, this is the first\nwork to use automatic language analysis tools to understand the dynamics\nbetween XI-ML methods and regulations. We believe that such a system\ncontributes to better cooperation between XAI researchers and AI policymakers.", "published": "2021-07-29 20:41:17", "link": "http://arxiv.org/abs/2108.06216v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition", "abstract": "Language models (LMs) pre-trained on massive amounts of text, in particular\nbidirectional encoder representations from Transformers (BERT), generative\npre-training (GPT), and GPT-2, have become a key technology for many natural\nlanguage processing tasks. In this paper, we present results using fine-tuned\nGPT, GPT-2, and their combination for automatic speech recognition (ASR).\nUnlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct\nproduct of the output probabilities is no longer a valid language prior\nprobability. A conversion method is proposed to compute the correct language\nprior probability based on bidirectional LM outputs in a mathematically exact\nway. Experimental results on the widely used AMI and Switchboard ASR tasks\nshowed that the combination of the fine-tuned GPT and GPT-2 outperformed the\ncombination of three neural LMs with different architectures trained from\nscratch on the in-domain text by up to a 12% relative word error rate reduction\n(WERR). Furthermore, on the AMI corpus, the proposed conversion for language\nprior probabilities enables BERT to obtain an extra 3% relative WERR, and the\ncombination of BERT, GPT and GPT-2 results in further improvements.", "published": "2021-07-29 16:53:37", "link": "http://arxiv.org/abs/2108.07789v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Multi-Task Learning in Utterance-Level and Segmental-Level Spoof\n  Detection", "abstract": "In this paper, we provide a series of multi-tasking benchmarks for\nsimultaneously detecting spoofing at the segmental and utterance levels in the\nPartialSpoof database. First, we propose the SELCNN network, which inserts\nsqueeze-and-excitation (SE) blocks into a light convolutional neural network\n(LCNN) to enhance the capacity of hidden feature selection. Then, we implement\nmulti-task learning (MTL) frameworks with SELCNN followed by bidirectional long\nshort-term memory (Bi-LSTM) as the basic model. We discuss MTL in PartialSpoof\nin terms of architecture (uni-branch/multi-branch) and training strategies\n(from-scratch/warm-up) step-by-step. Experiments show that the multi-task model\nperforms relatively better than single-task models. Also, in MTL, a\nbinary-branch architecture more adequately utilizes information from two levels\nthan a uni-branch model. For the binary-branch architecture, fine-tuning a\nwarm-up model works better than training from scratch. Models can handle both\nsegment-level and utterance-level predictions simultaneously overall under a\nbinary-branch multi-task architecture. Furthermore, the multi-task model\ntrained by fine-tuning a segmental warm-up model performs relatively better at\nboth levels except on the evaluation set for segmental detection. Segmental\ndetection should be explored further.", "published": "2021-07-29 16:04:25", "link": "http://arxiv.org/abs/2107.14132v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Blind Room Parameter Estimation Using Multiple-Multichannel Speech\n  Recordings", "abstract": "Knowing the geometrical and acoustical parameters of a room may benefit\napplications such as audio augmented reality, speech dereverberation or audio\nforensics. In this paper, we study the problem of jointly estimating the total\nsurface area, the volume, as well as the frequency-dependent reverberation time\nand mean surface absorption of a room in a blind fashion, based on two-channel\nnoisy speech recordings from multiple, unknown source-receiver positions. A\nnovel convolutional neural network architecture leveraging both single- and\ninter-channel cues is proposed and trained on a large, realistic simulated\ndataset. Results on both simulated and real data show that using multiple\nobservations in one room significantly reduces estimation errors and variances\non all target quantities, and that using two channels helps the estimation of\nsurface and volume. The proposed model outperforms a recently proposed blind\nvolume estimation method on the considered datasets.", "published": "2021-07-29 08:51:49", "link": "http://arxiv.org/abs/2107.13832v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fine-Grained Classroom Activity Detection from Audio with Neural\n  Networks", "abstract": "Instructors are increasingly incorporating student-centered learning\ntechniques in their classrooms to improve learning outcomes. In addition to\nlecture, these class sessions involve forms of individual and group work, and\ngreater rates of student-instructor interaction. Quantifying classroom activity\nis a key element of accelerating the evaluation and refinement of innovative\nteaching practices, but manual annotation does not scale. In this manuscript,\nwe present advances to the young application area of automatic classroom\nactivity detection from audio. Using a university classroom corpus with nine\nactivity labels (e.g., \"lecture,\" \"group work,\" \"student question\"), we propose\nand evaluate deep fully connected, convolutional, and recurrent neural network\narchitectures, comparing the performance of mel-filterbank, OpenSmile, and\nself-supervised acoustic features. We compare 9-way classification performance\nwith 5-way and 4-way simplifications of the task and assess two types of\ngeneralization: (1) new class sessions from previously seen instructors, and\n(2) previously unseen instructors. We obtain strong results on the new\nfine-grained task and state-of-the-art on the 4-way task: our best model\nobtains frame-level error rates of 6.2%, 7.7% and 28.0% when generalizing to\nunseen instructors for the 4-way, 5-way, and 9-way classification tasks,\nrespectively (relative reductions of 35.4%, 48.3% and 21.6% over a strong\nbaseline). When estimating the aggregate time spent on classroom activities,\nour average root mean squared error is 1.64 minutes per class session, a 54.9%\nrelative reduction over the baseline.", "published": "2021-07-29 23:23:52", "link": "http://arxiv.org/abs/2107.14369v2", "categories": ["eess.AS", "cs.NE", "cs.SD"], "primary_category": "eess.AS"}
