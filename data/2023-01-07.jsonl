{"title": "Building a Parallel Corpus and Training Translation Models Between\n  Luganda and English", "abstract": "Neural machine translation (NMT) has achieved great successes with large\ndatasets, so NMT is more premised on high-resource languages. This continuously\nunderpins the low resource languages such as Luganda due to the lack of\nhigh-quality parallel corpora, so even 'Google translate' does not serve\nLuganda at the time of this writing. In this paper, we build a parallel corpus\nwith 41,070 pairwise sentences for Luganda and English which is based on three\ndifferent open-sourced corpora. Then, we train NMT models with hyper-parameter\nsearch on the dataset. Experiments gave us a BLEU score of 21.28 from Luganda\nto English and 17.47 from English to Luganda. Some translation examples show\nhigh quality of the translation. We believe that our model is the first\nLuganda-English NMT model. The bilingual dataset we built will be available to\nthe public.", "published": "2023-01-07 03:26:09", "link": "http://arxiv.org/abs/2301.02773v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic-style-aware Neural Networks for Fake News Detection", "abstract": "We propose the hierarchical recursive neural network (HERO) to predict fake\nnews by learning its linguistic style, which is distinguishable from the truth,\nas psychological theories reveal. We first generate the hierarchical linguistic\ntree of news documents; by doing so, we translate each news document's\nlinguistic style into its writer's usage of words and how these words are\nrecursively structured as phrases, sentences, paragraphs, and, ultimately, the\ndocument. By integrating the hierarchical linguistic tree with the neural\nnetwork, the proposed method learns and classifies the representation of news\ndocuments by capturing their locally sequential and globally recursive\nstructures that are linguistically meaningful. It is the first work offering\nthe hierarchical linguistic tree and the neural network preserving the tree\ninformation to our best knowledge. Experimental results based on public\nreal-world datasets demonstrate the proposed method's effectiveness, which can\noutperform state-of-the-art techniques in classifying short and long news\ndocuments. We also examine the differential linguistic style of fake news and\nthe truth and observe some patterns of fake news. The code and data have been\npublicly available.", "published": "2023-01-07 06:48:41", "link": "http://arxiv.org/abs/2301.02792v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Brain-inspired Memory Transformation based Differentiable Neural\n  Computer for Reasoning-based Question Answering", "abstract": "Reasoning and question answering as a basic cognitive function for humans, is\nnevertheless a great challenge for current artificial intelligence. Although\nthe Differentiable Neural Computer (DNC) model could solve such problems to a\ncertain extent, the development is still limited by its high algorithm\ncomplexity, slow convergence speed, and poor test robustness. Inspired by the\nlearning and memory mechanism of the brain, this paper proposed a Memory\nTransformation based Differentiable Neural Computer (MT-DNC) model. MT-DNC\nincorporates working memory and long-term memory into DNC, and realizes the\nautonomous transformation of acquired experience between working memory and\nlong-term memory, thereby helping to effectively extract acquired knowledge to\nimprove reasoning ability. Experimental results on bAbI question answering task\ndemonstrated that our proposed method achieves superior performance and faster\nconvergence speed compared to other existing DNN and DNC models. Ablation\nstudies also indicated that the memory transformation from working memory to\nlong-term memory plays essential role in improving the robustness and stability\nof reasoning. This work explores how brain-inspired memory transformation can\nbe integrated and applied to complex intelligent dialogue and reasoning\nsystems.", "published": "2023-01-07 08:39:57", "link": "http://arxiv.org/abs/2301.02809v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Why do Nearest Neighbor Language Models Work?", "abstract": "Language models (LMs) compute the probability of a text by sequentially\ncomputing a representation of an already-seen context and using this\nrepresentation to predict the next word. Currently, most LMs calculate these\nrepresentations through a neural network consuming the immediate previous\ncontext. However recently, retrieval-augmented LMs have shown to improve over\nstandard neural LMs, by accessing information retrieved from a large datastore,\nin addition to their standard, parametric, next-word prediction. In this paper,\nwe set out to understand why retrieval-augmented language models, and\nspecifically why k-nearest neighbor language models (kNN-LMs) perform better\nthan standard parametric LMs, even when the k-nearest neighbor component\nretrieves examples from the same training set that the LM was originally\ntrained on. To this end, we perform a careful analysis of the various\ndimensions over which kNN-LM diverges from standard LMs, and investigate these\ndimensions one by one. Empirically, we identify three main reasons why kNN-LM\nperforms better than standard LMs: using a different input representation for\npredicting the next tokens, approximate kNN search, and the importance of\nsoftmax temperature for the kNN distribution. Further, we incorporate these\ninsights into the model architecture or the training procedure of the standard\nparametric LM, improving its results without the need for an explicit retrieval\ncomponent. The code is available at https://github.com/frankxu2004/knnlm-why.", "published": "2023-01-07 11:12:36", "link": "http://arxiv.org/abs/2301.02828v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Personalized Utterance Style (PUS) based Dialogue Strategy for\n  Efficient Service Requirement Elicitation", "abstract": "With the flourish of services on the Internet, a prerequisite for service\nproviders to precisely deliver services to their customers is to capture user\nrequirements comprehensively, accurately, and efficiently. This is called the\n``Service Requirement Elicitation (SRE)'' task. Considering the amount of\ncustomers is huge, it is an inefficient way for service providers to interact\nwith each user by face-to-face dialog. Therefore, to elicit user requirements\nwith the assistance of virtual intelligent assistants has become a mainstream\nway. Since user requirements generally consist of different levels of details\nand need to be satisfied by services from multiple domains, there is a huge\npotential requirement space for SRE to explore to elicit complete requirements.\nConsidering that traditional dialogue system with static slots cannot be\ndirectly applied to the SRE task, it is a challenge to design an efficient\ndialogue strategy to guide users to express their complete and accurate\nrequirements in such a huge potential requirement space. Based on the\nphenomenon that users tend to express requirements subjectively in a sequential\nmanner, we propose a Personalized Utterance Style (PUS) module to perceive the\npersonalized requirement expression habits, and then apply PUS to an dialogue\nstrategy to efficiently complete the SRE task. Specifically, the dialogue\nstrategy chooses suitable response actions for dynamically updating the\ndialogue state. With the assistance of PUS extracted from dialogue history, the\nsystem can shrink the search scope of potential requirement space. Experiment\nresults show that the dialogue strategy with PUS can elicit more accurate user\nrequirements with fewer dialogue rounds.", "published": "2023-01-07 04:10:33", "link": "http://arxiv.org/abs/2301.04582v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph-based Keyword Planning for Legal Clause Generation from Topics", "abstract": "Generating domain-specific content such as legal clauses based on minimal\nuser-provided information can be of significant benefit in automating legal\ncontract generation. In this paper, we propose a controllable graph-based\nmechanism that can generate legal clauses using only the topic or type of the\nlegal clauses. Our pipeline consists of two stages involving a graph-based\nplanner followed by a clause generator. The planner outlines the content of a\nlegal clause as a sequence of keywords in the order of generic to more specific\nclause information based on the input topic using a controllable graph-based\nmechanism. The generation stage takes in a given plan and generates a clause.\nThe pipeline consists of a graph-based planner followed by text generation. We\nillustrate the effectiveness of our proposed two-stage approach on a broad set\nof clause topics in contracts.", "published": "2023-01-07 15:18:45", "link": "http://arxiv.org/abs/2301.06901v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Visual Story Generation Based on Emotion and Keywords", "abstract": "Automated visual story generation aims to produce stories with corresponding\nillustrations that exhibit coherence, progression, and adherence to characters'\nemotional development. This work proposes a story generation pipeline to\nco-create visual stories with the users. The pipeline allows the user to\ncontrol events and emotions on the generated content. The pipeline includes two\nparts: narrative and image generation. For narrative generation, the system\ngenerates the next sentence using user-specified keywords and emotion labels.\nFor image generation, diffusion models are used to create a visually appealing\nimage corresponding to each generated sentence. Further, object recognition is\napplied to the generated images to allow objects in these images to be\nmentioned in future story development.", "published": "2023-01-07 03:56:49", "link": "http://arxiv.org/abs/2301.02777v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "RLAS-BIABC: A Reinforcement Learning-Based Answer Selection Using the\n  BERT Model Boosted by an Improved ABC Algorithm", "abstract": "Answer selection (AS) is a critical subtask of the open-domain question\nanswering (QA) problem. The present paper proposes a method called RLAS-BIABC\nfor AS, which is established on attention mechanism-based long short-term\nmemory (LSTM) and the bidirectional encoder representations from transformers\n(BERT) word embedding, enriched by an improved artificial bee colony (ABC)\nalgorithm for pretraining and a reinforcement learning-based algorithm for\ntraining backpropagation (BP) algorithm. BERT can be comprised in downstream\nwork and fine-tuned as a united task-specific architecture, and the pretrained\nBERT model can grab different linguistic effects. Existing algorithms typically\ntrain the AS model with positive-negative pairs for a two-class classifier. A\npositive pair contains a question and a genuine answer, while a negative one\nincludes a question and a fake answer. The output should be one for positive\nand zero for negative pairs. Typically, negative pairs are more than positive,\nleading to an imbalanced classification that drastically reduces system\nperformance. To deal with it, we define classification as a sequential\ndecision-making process in which the agent takes a sample at each step and\nclassifies it. For each classification operation, the agent receives a reward,\nin which the prize of the majority class is less than the reward of the\nminority class. Ultimately, the agent finds the optimal value for the policy\nweights. We initialize the policy weights with the improved ABC algorithm. The\ninitial value technique can prevent problems such as getting stuck in the local\noptimum. Although ABC serves well in most tasks, there is still a weakness in\nthe ABC algorithm that disregards the fitness of related pairs of individuals\nin discovering a neighboring food source position.", "published": "2023-01-07 08:33:05", "link": "http://arxiv.org/abs/2301.02807v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7"], "primary_category": "cs.CL"}
{"title": "TunesFormer: Forming Irish Tunes with Control Codes by Bar Patching", "abstract": "This paper introduces TunesFormer, an efficient Transformer-based\ndual-decoder model specifically designed for the generation of melodies that\nadhere to user-defined musical forms. Trained on 214,122 Irish tunes,\nTunesFormer utilizes techniques including bar patching and control codes. Bar\npatching reduces sequence length and generation time, while control codes guide\nTunesFormer in producing melodies that conform to desired musical forms. Our\nevaluation demonstrates TunesFormer's superior efficiency, being 3.22 times\nfaster than GPT-2 and 1.79 times faster than a model with linear complexity of\nequal scale while offering comparable performance in controllability and other\nmetrics. TunesFormer provides a novel tool for musicians, composers, and music\nenthusiasts alike to explore the vast landscape of Irish music. Our model and\ncode are available at https://github.com/sander-wood/tunesformer.", "published": "2023-01-07 16:11:55", "link": "http://arxiv.org/abs/2301.02884v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Perceptual-Neural-Physical Sound Matching", "abstract": "Sound matching algorithms seek to approximate a target waveform by parametric\naudio synthesis. Deep neural networks have achieved promising results in\nmatching sustained harmonic tones. However, the task is more challenging when\ntargets are nonstationary and inharmonic, e.g., percussion. We attribute this\nproblem to the inadequacy of loss function. On one hand, mean square error in\nthe parametric domain, known as \"P-loss\", is simple and fast but fails to\naccommodate the differing perceptual significance of each parameter. On the\nother hand, mean square error in the spectrotemporal domain, known as \"spectral\nloss\", is perceptually motivated and serves in differentiable digital signal\nprocessing (DDSP). Yet, spectral loss is a poor predictor of pitch intervals\nand its gradient may be computationally expensive; hence a slow convergence.\nAgainst this conundrum, we present Perceptual-Neural-Physical loss (PNP). PNP\nis the optimal quadratic approximation of spectral loss while being as fast as\nP-loss during training. We instantiate PNP with physical modeling synthesis as\ndecoder and joint time-frequency scattering transform (JTFS) as spectral\nrepresentation. We demonstrate its potential on matching synthetic drum sounds\nin comparison with other loss functions.", "published": "2023-01-07 16:17:48", "link": "http://arxiv.org/abs/2301.02886v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
