{"title": "Performance of Stanford and Minipar Parser on Biomedical Texts", "abstract": "In this paper, the performance of two dependency parsers, namely Stanford and\nMinipar, on biomedical texts has been reported. The performance of te parsers\nto assignm dependencies between two biomedical concepts that are already proved\nto be connected is not satisfying. Both Stanford and Minipar, being statistical\nparsers, fail to assign dependency relation between two connected concepts if\nthey are distant by at least one clause. Minipar's performance, in terms of\nprecision, recall and the F-score of the attachment score (e.g., correctly\nidentified head in a dependency), to parse biomedical text is also measured\ntaking the Stanford's as a gold standard. The results suggest that Minipar is\nnot suitable yet to parse biomedical texts. In addition, a qualitative\ninvestigation reveals that the difference between working principles of the\nparsers also play a vital role for Minipar's degraded performance.", "published": "2014-09-25 15:35:27", "link": "http://arxiv.org/abs/1409.7386v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Conceptual Metaphors from Proposition Stores", "abstract": "Contemporary research on computational processing of linguistic metaphors is\ndivided into two main branches: metaphor recognition and metaphor\ninterpretation. We take a different line of research and present an automated\nmethod for generating conceptual metaphors from linguistic data. Given the\ngenerated conceptual metaphors, we find corresponding linguistic metaphors in\ncorpora. In this paper, we describe our approach and its evaluation using\nEnglish and Russian data.", "published": "2014-09-25 13:54:37", "link": "http://arxiv.org/abs/1409.7619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-supervised Classification for Natural Language Processing", "abstract": "Semi-supervised classification is an interesting idea where classification\nmodels are learned from both labeled and unlabeled data. It has several\nadvantages over supervised classification in natural language processing\ndomain. For instance, supervised classification exploits only labeled data that\nare expensive, often difficult to get, inadequate in quantity, and require\nhuman experts for annotation. On the other hand, unlabeled data are inexpensive\nand abundant. Despite the fact that many factors limit the wide-spread use of\nsemi-supervised classification, it has become popular since its level of\nperformance is empirically as good as supervised classification. This study\nexplores the possibilities and achievements as well as complexity and\nlimitations of semi-supervised classification for several natural langue\nprocessing tasks like parsing, biomedical information processing, text\nclassification, and summarization.", "published": "2014-09-25 15:18:44", "link": "http://arxiv.org/abs/1409.7612v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The meaning-frequency law in Zipfian optimization models of\n  communication", "abstract": "According to Zipf's meaning-frequency law, words that are more frequent tend\nto have more meanings. Here it is shown that a linear dependency between the\nfrequency of a form and its number of meanings is found in a family of models\nof Zipf's law for word frequencies. This is evidence for a weak version of the\nmeaning-frequency law. Interestingly, that weak law (a) is not an inevitable of\nproperty of the assumptions of the family and (b) is found at least in the\nnarrow regime where those models exhibit Zipf's law for word frequencies.", "published": "2014-09-25 14:42:02", "link": "http://arxiv.org/abs/1409.7275v2", "categories": ["cs.CL", "physics.data-an", "physics.soc-ph"], "primary_category": "cs.CL"}
