{"title": "On the Learning of Non-Autoregressive Transformers", "abstract": "Non-autoregressive Transformer (NAT) is a family of text generation models,\nwhich aims to reduce the decoding latency by predicting the whole sentences in\nparallel. However, such latency reduction sacrifices the ability to capture\nleft-to-right dependencies, thereby making NAT learning very challenging. In\nthis paper, we present theoretical and empirical analyses to reveal the\nchallenges of NAT learning and propose a unified perspective to understand\nexisting successes. First, we show that simply training NAT by maximizing the\nlikelihood can lead to an approximation of marginal distributions but drops all\ndependencies between tokens, where the dropped information can be measured by\nthe dataset's conditional total correlation. Second, we formalize many previous\nobjectives in a unified framework and show that their success can be concluded\nas maximizing the likelihood on a proxy distribution, leading to a reduced\ninformation loss. Empirical studies show that our perspective can explain the\nphenomena in NAT learning and guide the design of new training methods.", "published": "2022-06-13 08:42:09", "link": "http://arxiv.org/abs/2206.05975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Indian Legal Text Summarization: A Text Normalisation-based Approach", "abstract": "In the Indian court system, pending cases have long been a problem. There are\nmore than 4 crore cases outstanding. Manually summarising hundreds of documents\nis a time-consuming and tedious task for legal stakeholders. Many\nstate-of-the-art models for text summarization have emerged as machine learning\nhas progressed. Domain-independent models don't do well with legal texts, and\nfine-tuning those models for the Indian Legal System is problematic due to a\nlack of publicly available datasets. To improve the performance of\ndomain-independent models, the authors have proposed a methodology for\nnormalising legal texts in the Indian context. The authors experimented with\ntwo state-of-the-art domain-independent models for legal text summarization,\nnamely BART and PEGASUS. BART and PEGASUS are put through their paces in terms\nof extractive and abstractive summarization to understand the effectiveness of\nthe text normalisation approach. Summarised texts are evaluated by domain\nexperts on multiple parameters and using ROUGE metrics. It shows the proposed\ntext normalisation approach is effective in legal texts with domain-independent\nmodels.", "published": "2022-06-13 15:16:50", "link": "http://arxiv.org/abs/2206.06238v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models are General-Purpose Interfaces", "abstract": "Foundation models have received much attention due to their effectiveness\nacross a broad range of downstream applications. Though there is a big\nconvergence in terms of architecture, most pretrained models are typically\nstill developed for specific tasks or modalities. In this work, we propose to\nuse language models as a general-purpose interface to various foundation\nmodels. A collection of pretrained encoders perceive diverse modalities (such\nas vision, and language), and they dock with a language model that plays the\nrole of a universal task layer. We propose a semi-causal language modeling\nobjective to jointly pretrain the interface and the modular encoders. We\nsubsume the advantages and capabilities from both causal and non-causal\nmodeling, thereby combining the best of two worlds. Specifically, the proposed\nmethod not only inherits the capabilities of in-context learning and open-ended\ngeneration from causal language modeling, but also is conducive to finetuning\nbecause of the bidirectional encoders. More importantly, our approach\nseamlessly unlocks the combinations of the above capabilities, e.g., enabling\nin-context learning or instruction following with finetuned encoders.\nExperimental results across various language-only and vision-language\nbenchmarks show that our model outperforms or is competitive with specialized\nmodels on finetuning, zero-shot generalization, and few-shot learning.", "published": "2022-06-13 17:34:22", "link": "http://arxiv.org/abs/2206.06336v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hate Speech and Counter Speech Detection: Conversational Context Does\n  Matter", "abstract": "Hate speech is plaguing the cyberspace along with user-generated content.\nThis paper investigates the role of conversational context in the annotation\nand detection of online hate and counter speech, where context is defined as\nthe preceding comment in a conversation thread. We created a context-aware\ndataset for a 3-way classification task on Reddit comments: hate speech,\ncounter speech, or neutral. Our analyses indicate that context is critical to\nidentify hate and counter speech: human judgments change for most comments\ndepending on whether we show annotators the context. A linguistic analysis\ndraws insights into the language people use to express hate and counter speech.\nExperimental results show that neural networks obtain significantly better\nresults if context is taken into account. We also present qualitative error\nanalyses shedding light into (a) when and why context is beneficial and (b) the\nremaining errors made by our best model when context is taken into account.", "published": "2022-06-13 19:05:44", "link": "http://arxiv.org/abs/2206.06423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Diffusion Energy-Based Model for Interpretable Text Modeling", "abstract": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in generative modeling. Fueled by its flexibility\nin the formulation and strong modeling power of the latent space, recent works\nbuilt upon it have made interesting attempts aiming at the interpretability of\ntext modeling. However, latent space EBMs also inherit some flaws from EBMs in\ndata space; the degenerate MCMC sampling quality in practice can lead to poor\ngeneration quality and instability in training, especially on data with complex\nlatent structures. Inspired by the recent efforts that leverage diffusion\nrecovery likelihood learning as a cure for the sampling issue, we introduce a\nnovel symbiosis between the diffusion models and latent space EBMs in a\nvariational learning framework, coined as the latent diffusion energy-based\nmodel. We develop a geometric clustering-based regularization jointly with the\ninformation bottleneck to further improve the quality of the learned latent\nspace. Experiments on several challenging tasks demonstrate the superior\nperformance of our model on interpretable text modeling over strong\ncounterparts.", "published": "2022-06-13 03:41:31", "link": "http://arxiv.org/abs/2206.05895v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Sahlqvist-style Correspondence Theorem for Linear-time Temporal Logic", "abstract": "The language of modal logic is capable of expressing first-order conditions\non Kripke frames. The classic result by Henrik Sahlqvist identifies a\nsignificant class of modal formulas for which first-order conditions -- or\nSahlqvist correspondents -- can be find in an effective, algorithmic way.\nRecent works have successfully extended this classic result to more complex\nmodal languages. In this paper, we pursue a similar line and develop a\nSahlqvist-style correspondence theorem for Linear-time Temporal Logic (LTL),\nwhich is one of the most widely used formal languages for temporal\nspecification. LTL extends the syntax of basic modal logic with dedicated\ntemporal operators Next X and Until U . As a result, the complexity of the\nclass of formulas that have first-order correspondents also increases\naccordingly. In this paper, we identify a significant class of LTL Sahlqvist\nformulas built by using modal operators F , G, X, and U . The main result of\nthis paper is to prove the correspondence of LTL Sahlqvist formulas to frame\nconditions that are definable in first-order language.", "published": "2022-06-13 08:36:13", "link": "http://arxiv.org/abs/2206.05973v1", "categories": ["cs.LO", "cs.CL"], "primary_category": "cs.LO"}
{"title": "Automatic generation of a large dictionary with\n  concreteness/abstractness ratings based on a small human dictionary", "abstract": "Concrete/abstract words are used in a growing number of psychological and\nneurophysiological research. For a few languages, large dictionaries have been\ncreated manually. This is a very time-consuming and costly process. To generate\nlarge high-quality dictionaries of concrete/abstract words automatically one\nneeds extrapolating the expert assessments obtained on smaller samples. The\nresearch question that arises is how small such samples should be to do a good\nenough extrapolation. In this paper, we present a method for automatic ranking\nconcreteness of words and propose an approach to significantly decrease amount\nof expert assessment. The method has been evaluated on a large test set for\nEnglish. The quality of the constructed dictionaries is comparable to the\nexpert ones. The correlation between predicted and expert ratings is higher\ncomparing to the state-of-the-art methods.", "published": "2022-06-13 14:31:58", "link": "http://arxiv.org/abs/2206.06200v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Introducing Proof Tree Automata and Proof Tree Graphs", "abstract": "In structural proof theory, designing and working on large calculi make it\ndifficult to get intuitions about each rule individually and as part of a whole\nsystem. We introduce two novel tools to help working on calculi using the\napproach of graph theory and automata theory. The first tool is a Proof Tree\nAutomaton (PTA): a tree automaton which language is the derivation language of\na calculus. The second tool is a graphical representation of a calculus called\nProof Tree Graph (PTG). In this directed hypergraph, vertices are sets of terms\n(e.g. sequents) and hyperarcs are rules. We explore properties of PTA and PTGs\nand how they relate to each other. We show that we can decompose a PTA as a\npartial map from a calculus to a traditional tree automaton. We formulate that\nstatement in the theory of refinement systems. Finally, we compare our\nframework to proof nets and string diagrams.", "published": "2022-06-13 16:24:33", "link": "http://arxiv.org/abs/2206.06294v1", "categories": ["cs.LO", "cs.CL", "03F03 (Primary) 05C65, 68Q45, 18C50, 68Q42 (Secondary)", "F.4.1; F.4.2; F.4.3; F.1.1; G.2.2"], "primary_category": "cs.LO"}
{"title": "Knowledge Graph Construction and Its Application in Automatic Radiology\n  Report Generation from Radiologist's Dictation", "abstract": "Conventionally, the radiologist prepares the diagnosis notes and shares them\nwith the transcriptionist. Then the transcriptionist prepares a preliminary\nformatted report referring to the notes, and finally, the radiologist reviews\nthe report, corrects the errors, and signs off. This workflow causes\nsignificant delays and errors in the report. In current research work, we focus\non applications of NLP techniques like Information Extraction (IE) and\ndomain-specific Knowledge Graph (KG) to automatically generate radiology\nreports from radiologist's dictation. This paper focuses on KG construction for\neach organ by extracting information from an existing large corpus of free-text\nradiology reports. We develop an information extraction pipeline that combines\nrule-based, pattern-based, and dictionary-based techniques with\nlexical-semantic features to extract entities and relations. Missing\ninformation in short dictation can be accessed from the KGs to generate\npathological descriptions and hence the radiology report. Generated\npathological descriptions evaluated using semantic similarity metrics, which\nshows 97% similarity with gold standard pathological descriptions. Also, our\nanalysis shows that our IE module is performing better than the OpenIE tool for\nthe radiology domain. Furthermore, we include a manual qualitative analysis\nfrom radiologists, which shows that 80-85% of the generated reports are\ncorrectly written, and the remaining are partially correct.", "published": "2022-06-13 16:46:54", "link": "http://arxiv.org/abs/2206.06308v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem\n  Understanding", "abstract": "This paper aims to advance the mathematical intelligence of machines by\npresenting the first Chinese mathematical pre-trained language model~(PLM) for\neffectively understanding and representing mathematical problems. Unlike other\nstandard NLP tasks, mathematical texts are difficult to understand, since they\ninvolve mathematical terminology, symbols and formulas in the problem\nstatement. Typically, it requires complex mathematical logic and background\nknowledge for solving mathematical problems.\n  Considering the complex nature of mathematical texts, we design a novel\ncurriculum pre-training approach for improving the learning of mathematical\nPLMs, consisting of both basic and advanced courses. Specially, we first\nperform token-level pre-training based on a position-biased masking strategy,\nand then design logic-based pre-training tasks that aim to recover the shuffled\nsentences and formulas, respectively. Finally, we introduce a more difficult\npre-training task that enforces the PLM to detect and correct the errors in its\ngenerated solutions. We conduct extensive experiments on offline evaluation\n(including nine math-related tasks) and online $A/B$ test. Experimental results\ndemonstrate the effectiveness of our approach compared with a number of\ncompetitive baselines. Our code is available at:\n\\textcolor{blue}{\\url{https://github.com/RUCAIBox/JiuZhang}}.", "published": "2022-06-13 17:03:52", "link": "http://arxiv.org/abs/2206.06315v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memory-Based Model Editing at Scale", "abstract": "Even the largest neural networks make errors, and once-correct predictions\ncan become invalid as the world changes. Model editors make local updates to\nthe behavior of base (pre-trained) models to inject updated knowledge or\ncorrect undesirable behaviors. Existing model editors have shown promise, but\nalso suffer from insufficient expressiveness: they struggle to accurately model\nan edit's intended scope (examples affected by the edit), leading to inaccurate\npredictions for test inputs loosely related to the edit, and they often fail\naltogether after many edits. As a higher-capacity alternative, we propose\nSemi-Parametric Editing with a Retrieval-Augmented Counterfactual Model\n(SERAC), which stores edits in an explicit memory and learns to reason over\nthem to modulate the base model's predictions as needed. To enable more\nrigorous evaluation of model editors, we introduce three challenging language\nmodel editing problems based on question answering, fact-checking, and dialogue\ngeneration. We find that only SERAC achieves high performance on all three\nproblems, consistently outperforming existing approaches to model editing by a\nsignificant margin. Code, data, and additional project information will be made\navailable at https://sites.google.com/view/serac-editing.", "published": "2022-06-13 23:40:34", "link": "http://arxiv.org/abs/2206.06520v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Hybrid Ensemble for Fake News Detection: An attempt", "abstract": "Fake News Detection has been a challenging problem in the field of Machine\nLearning. Researchers have approached it via several techniques using old\nStatistical Classification models and modern Deep Learning. Today, with the\ngrowing amount of data, developments in the field of NLP and ML, and an\nincrease in the computation power at disposal, there are infinite permutations\nand combinations to approach this problem from a different perspective. In this\npaper, we try different methods to tackle Fake News, and try to build, and\npropose the possibilities of a Hybrid Ensemble combining the classical Machine\nLearning techniques with the modern Deep Learning Approaches", "published": "2022-06-13 01:34:38", "link": "http://arxiv.org/abs/2206.13981v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mediators: Conversational Agents Explaining NLP Model Behavior", "abstract": "The human-centric explainable artificial intelligence (HCXAI) community has\nraised the need for framing the explanation process as a conversation between\nhuman and machine. In this position paper, we establish desiderata for\nMediators, text-based conversational agents which are capable of explaining the\nbehavior of neural models interactively using natural language. From the\nperspective of natural language processing (NLP) research, we engineer a\nblueprint of such a Mediator for the task of sentiment analysis and assess how\nfar along current research is on the path towards dialogue-based explanations.", "published": "2022-06-13 10:31:18", "link": "http://arxiv.org/abs/2206.06029v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A DSEL for High Throughput and Low Latency Software-Defined Radio on\n  Multicore CPUs", "abstract": "This article presents a new Domain Specific Embedded Language (DSEL)\ndedicated to Software-Defined Radio (SDR). From a set of carefully designed\ncomponents, it enables to build efficient software digital communication\nsystems, able to take advantage of the parallelism of modern processor\narchitectures, in a straightforward and safe manner for the programmer. In\nparticular, proposed DSEL enables the combination of pipelining and sequence\nduplication techniques to extract both temporal and spatial parallelism from\ndigital communication systems. We leverage the DSEL capabilities on a real use\ncase: a fully digital transceiver for the widely used DVB-S2 standard designed\nentirely in software. Through evaluation, we show how proposed software DVB-S2\ntransceiver is able to get the most from modern, high-end multicore CPU\ntargets.", "published": "2022-06-13 13:30:14", "link": "http://arxiv.org/abs/2206.06147v2", "categories": ["cs.CL", "cs.DC", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Toward Zero Oracle Word Error Rate on the Switchboard Benchmark", "abstract": "The \"Switchboard benchmark\" is a very well-known test set in automatic speech\nrecognition (ASR) research, establishing record-setting performance for systems\nthat claim human-level transcription accuracy. This work highlights\nlesser-known practical considerations of this evaluation, demonstrating major\nimprovements in word error rate (WER) by correcting the reference\ntranscriptions and deviating from the official scoring methodology. In this\nmore detailed and reproducible scheme, even commercial ASR systems can score\nbelow 5% WER and the established record for a research system is lowered to\n2.3%. An alternative metric of transcript precision is proposed, which does not\npenalize deletions and appears to be more discriminating for human vs. machine\nperformance. While commercial ASR systems are still below this threshold, a\nresearch system is shown to clearly surpass the accuracy of commercial human\nspeech recognition. This work also explores using standardized scoring tools to\ncompute oracle WER by selecting the best among a list of alternatives. A phrase\nalternatives representation is compared to utterance-level N-best lists and\nword-level data structures; using dense lattices and adding out-of-vocabulary\nwords, this achieves an oracle WER of 0.18%.", "published": "2022-06-13 14:26:40", "link": "http://arxiv.org/abs/2206.06192v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Automated Evaluation of Standardized Dementia Screening Tests", "abstract": "For dementia screening and monitoring, standardized tests play a key role in\nclinical routine since they aim at minimizing subjectivity by measuring\nperformance on a variety of cognitive tasks. In this paper, we report on a\nstudy that consists of a semi-standardized history taking followed by two\nstandardized neuropsychological tests, namely the SKT and the CERAD-NB. The\ntests include basic tasks such as naming objects, learning word lists, but also\nwidely used tools such as the MMSE. Most of the tasks are performed verbally\nand should thus be suitable for automated scoring based on transcripts. For the\nfirst batch of 30 patients, we analyze the correlation between expert manual\nevaluations and automatic evaluations based on manual and automatic\ntranscriptions. For both SKT and CERAD-NB, we observe high to perfect\ncorrelations using manual transcripts; for certain tasks with lower\ncorrelation, the automatic scoring is stricter than the human reference since\nit is limited to the audio. Using automatic transcriptions, correlations drop\nas expected and are related to recognition accuracy; however, we still observe\nhigh correlations of up to 0.98 (SKT) and 0.85 (CERAD-NB). We show that using\nword alternatives helps to mitigate recognition errors and subsequently\nimproves correlation with expert scores.", "published": "2022-06-13 14:41:27", "link": "http://arxiv.org/abs/2206.06208v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Transition-based Abstract Meaning Representation Parsing with Contextual\n  Embeddings", "abstract": "The ability to understand and generate languages sets human cognition apart\nfrom other known life forms'. We study a way of combing two of the most\nsuccessful routes to meaning of language--statistical language models and\nsymbolic semantics formalisms--in the task of semantic parsing. Building on a\ntransition-based, Abstract Meaning Representation (AMR) parser, AmrEager, we\nexplore the utility of incorporating pretrained context-aware word\nembeddings--such as BERT and RoBERTa--in the problem of AMR parsing,\ncontributing a new parser we dub as AmrBerger. Experiments find these rich\nlexical features alone are not particularly helpful in improving the parser's\noverall performance as measured by the SMATCH score when compared to the\nnon-contextual counterpart, while additional concept information empowers the\nsystem to outperform the baselines. Through lesion study, we found the use of\ncontextual embeddings helps to make the system more robust against the removal\nof explicit syntactical features. These findings expose the strength and\nweakness of the contextual embeddings and the language models in the current\nform, and motivate deeper understanding thereof.", "published": "2022-06-13 15:05:24", "link": "http://arxiv.org/abs/2206.06229v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An Exploration of Post-Editing Effectiveness in Text Summarization", "abstract": "Automatic summarization methods are efficient but can suffer from low\nquality. In comparison, manual summarization is expensive but produces higher\nquality. Can humans and AI collaborate to improve summarization performance? In\nsimilar text generation tasks (e.g., machine translation), human-AI\ncollaboration in the form of \"post-editing\" AI-generated text reduces human\nworkload and improves the quality of AI output. Therefore, we explored whether\npost-editing offers advantages in text summarization. Specifically, we\nconducted an experiment with 72 participants, comparing post-editing provided\nsummaries with manual summarization for summary quality, human efficiency, and\nuser experience on formal (XSum news) and informal (Reddit posts) text. This\nstudy sheds valuable insights on when post-editing is useful for text\nsummarization: it helped in some cases (e.g., when participants lacked domain\nknowledge) but not in others (e.g., when provided summaries include inaccurate\ninformation). Participants' different editing strategies and needs for\nassistance offer implications for future human-AI summarization systems.", "published": "2022-06-13 18:00:02", "link": "http://arxiv.org/abs/2206.06383v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer\n  Learning", "abstract": "Fine-tuning large pre-trained models on downstream tasks has been adopted in\na variety of domains recently. However, it is costly to update the entire\nparameter set of large pre-trained models. Although recently proposed\nparameter-efficient transfer learning (PETL) techniques allow updating a small\nsubset of parameters (e.g. only using 2% of parameters) inside a pre-trained\nbackbone network for a new task, they only reduce the training memory\nrequirement by up to 30%. This is because the gradient computation for the\ntrainable parameters still requires backpropagation through the large\npre-trained backbone model. To address this, we propose Ladder Side-Tuning\n(LST), a new PETL technique that can reduce training memory requirements by\nmore substantial amounts. Unlike existing parameter-efficient methods that\ninsert additional parameters inside backbone networks, we train a ladder side\nnetwork, a small and separate network that takes intermediate activations as\ninput via shortcut connections (called ladders) from backbone networks and\nmakes predictions. LST has significantly lower memory requirements than\nprevious methods, because it does not require backpropagation through the\nbackbone network, but instead only through the side network and ladder\nconnections. We evaluate our method with various models (T5 and CLIP-T5) on\nboth NLP (GLUE) and vision-and-language (VQA, GQA, NLVR2 , MSCOCO) tasks. LST\nsaves 69% of the memory costs to fine-tune the whole network, while other\nmethods only save 26% of that in similar parameter usages (hence, 2.7x more\nmemory savings). Moreover, LST achieves higher accuracy than Adapter and LoRA\nin a low-memory regime. To further show the advantage of this better memory\nefficiency, we also apply LST to larger T5 models, attaining better GLUE\nperformance than full fine-tuning and other PETL methods. The\naccuracy-efficiency trade-off also holds on VL tasks.", "published": "2022-06-13 23:51:56", "link": "http://arxiv.org/abs/2206.06522v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Language-based Audio Retrieval Task in DCASE 2022 Challenge", "abstract": "Language-based audio retrieval is a task, where natural language textual\ncaptions are used as queries to retrieve audio signals from a dataset. It has\nbeen first introduced into DCASE 2022 Challenge as Subtask 6B of task 6, which\naims at developing computational systems to model relationships between audio\nsignals and free-form textual descriptions. Compared with audio captioning\n(Subtask 6A), which is about generating audio captions for audio signals,\nlanguage-based audio retrieval (Subtask 6B) focuses on ranking audio signals\naccording to their relevance to natural language textual captions. In DCASE\n2022 Challenge, the provided baseline system for Subtask 6B was significantly\noutperformed, with top performance being 0.276 in mAP@10. This paper presents\nthe outcome of Subtask 6B in terms of submitted systems' performance and\nanalysis.", "published": "2022-06-13 12:49:30", "link": "http://arxiv.org/abs/2206.06108v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Realistic Gramophone Noise Synthesis using a Diffusion Model", "abstract": "This paper introduces a novel data-driven strategy for synthesizing\ngramophone noise audio textures. A diffusion probabilistic model is applied to\ngenerate highly realistic quasiperiodic noises. The proposed model is designed\nto generate samples of length equal to one disk revolution, but a method to\ngenerate plausible periodic variations between revolutions is also proposed. A\nguided approach is also applied as a conditioning method, where an audio signal\ngenerated with manually-tuned signal processing is refined via reverse\ndiffusion to improve realism. The method has been evaluated in a subjective\nlistening test, in which the participants were often unable to recognize the\nsynthesized signals from the real ones. The synthetic noises produced with the\nbest proposed unconditional method are statistically indistinguishable from\nreal noise recordings. This work shows the potential of diffusion models for\nhighly realistic audio synthesis tasks.", "published": "2022-06-13 15:41:06", "link": "http://arxiv.org/abs/2206.06259v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improvement of Serial Approach to Anomalous Sound Detection by\n  Incorporating Two Binary Cross-Entropies for Outlier Exposure", "abstract": "Anomalous sound detection systems must detect unknown, atypical sounds using\nonly normal audio data. Conventional methods use the serial method, a\ncombination of outlier exposure (OE), which classifies normal and\npseudo-anomalous data and obtains embedding, and inlier modeling (IM), which\nmodels the probability distribution of the embedding. Although the serial\nmethod shows high performance due to the powerful feature extraction of OE and\nthe robustness of IM, OE still has a problem that doesn't work well when the\nnormal and pseudo-anomalous data are too similar or too different. To\nexplicitly distinguish these data, the proposed method uses multi-task learning\nof two binary cross-entropies when training OE. The first is a loss that\nclassifies the sound of the target machine to which product it is emitted from,\nwhich deals with the case where the normal data and the pseudo-anomalous data\nare too similar. The second is a loss that identifies whether the sound is\nemitted from the target machine or not, which deals with the case where the\nnormal data and the pseudo-anomalous data are too different. We perform our\nexperiments with DCASE 2021 Task~2 dataset. Our proposed single-model method\noutperforms the top-ranked method, which combines multiple models, by 2.1% in\nAUC.", "published": "2022-06-13 06:56:50", "link": "http://arxiv.org/abs/2206.05929v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AmbiSep: Ambisonic-to-Ambisonic Reverberant Speech Separation Using\n  Transformer Networks", "abstract": "Consider a multichannel Ambisonic recording containing a mixture of several\nreverberant speech signals. Retreiving the reverberant Ambisonic signals\ncorresponding to the individual speech sources blindly from the mixture is a\nchallenging task as it requires to estimate multiple signal channels for each\nsource. In this work, we propose AmbiSep, a deep neural network-based\nplane-wave domain masking approach to solve this task. The masking network uses\nlearned feature representations and transformers in a triple-path processing\nconfiguration. We train and evaluate the proposed network architecture on a\nspatialized WSJ0-2mix dataset, and show that the method achieves a multichannel\nscale-invariant signal-to-distortion ratio improvement of 17.7 dB on the blind\ntest set, while preserving the spatial characteristics of the separated sounds.", "published": "2022-06-13 14:18:17", "link": "http://arxiv.org/abs/2206.06184v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Description and Discussion on DCASE 2022 Challenge Task 2: Unsupervised\n  Anomalous Sound Detection for Machine Condition Monitoring Applying Domain\n  Generalization Techniques", "abstract": "We present the task description and discussion on the results of the DCASE\n2022 Challenge Task 2: ``Unsupervised anomalous sound detection (ASD) for\nmachine condition monitoring applying domain generalization techniques''.\nDomain shifts are a critical problem for the application of ASD systems.\nBecause domain shifts can change the acoustic characteristics of data, a model\ntrained in a source domain performs poorly for a target domain. In DCASE 2021\nChallenge Task 2, we organized an ASD task for handling domain shifts. In this\ntask, it was assumed that the occurrences of domain shifts are known. However,\nin practice, the domain of each sample may not be given, and the domain shifts\ncan occur implicitly. In 2022 Task 2, we focus on domain generalization\ntechniques that detects anomalies regardless of the domain shifts.\nSpecifically, the domain of each sample is not given in the test data and only\none threshold is allowed for all domains. Analysis of 81 submissions from 31\nteams revealed two remarkable types of domain generalization techniques: 1)\ndomain-mixing-based approach that obtains generalized representations and 2)\ndomain-classification-based approach that explicitly or implicitly classifies\ndifferent domains to improve detection performance for each domain.", "published": "2022-06-13 02:06:15", "link": "http://arxiv.org/abs/2206.05876v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Low-complexity deep learning frameworks for acoustic scene\n  classification", "abstract": "In this report, we presents low-complexity deep learning frameworks for\nacoustic scene classification (ASC). The proposed frameworks can be separated\ninto four main steps: Front-end spectrogram extraction, online data\naugmentation, back-end classification, and late fusion of predicted\nprobabilities. In particular, we initially transform audio recordings into Mel,\nGammatone, and CQT spectrograms. Next, data augmentation methods of Random\nCropping, Specaugment, and Mixup are then applied to generate augmented\nspectrograms before being fed into deep learning based classifiers. Finally, to\nachieve the best performance, we fuse probabilities which obtained from three\nindividual classifiers, which are independently-trained with three type of\nspectrograms. Our experiments conducted on DCASE 2022 Task 1 Development\ndataset have fullfiled the requirement of low-complexity and achieved the best\nclassification accuracy of 60.1%, improving DCASE baseline by 17.2%.", "published": "2022-06-13 11:41:39", "link": "http://arxiv.org/abs/2206.06057v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Time Series Denoising with Learnable Wavelet Packet Transform", "abstract": "Signal denoising is a key preprocessing step for many applications, as the\nperformance of a learning task is closely related to the quality of the input\ndata. In this paper, we apply a signal processing based deep neural network\narchitecture, a learnable extension of the wavelet packet transform. As main\nadvantages, this model has few parameters, an intuitive initialization and\nstrong learning capabilities. Moreover, we show that it is possible to easily\nmodify the parameters of the model after the training step to tailor to\ndifferent noise intensities. Two case studies are conducted to compare this\nmodel with the state of the art and commonly used denoising procedures. The\nfirst experiment uses standard signals to study denoising properties of the\nalgorithms. The second experiment is a real application with the objective to\nremove audio background noises. We show that the learnable wavelet packet\ntransform has the learning capabilities of deep learning methods while\nmaintaining the robustness of standard signal processing approaches. More\nspecifically, we demonstrate that our approach maintains excellent denoising\nperformances on signal classes separate from those used during the training\nstep. Moreover, the learnable wavelet packet transform was found to be robust\nwhen different noise intensities, noise varieties and artifacts are considered.", "published": "2022-06-13 13:05:58", "link": "http://arxiv.org/abs/2206.06126v4", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
