{"title": "Multichannel Variable-Size Convolution for Sentence Classification", "abstract": "We propose MVCNN, a convolution neural network (CNN) architecture for\nsentence classification. It (i) combines diverse versions of pretrained word\nembeddings and (ii) extracts features of multigranular phrases with\nvariable-size convolution filters. We also show that pretraining MVCNN is\ncritical for good performance. MVCNN achieves state-of-the-art performance on\nfour tasks: on small-scale binary, small-scale multi-class and largescale\nTwitter sentiment prediction and on subjectivity classification.", "published": "2016-03-15 00:25:02", "link": "http://arxiv.org/abs/1603.04513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic Modeling Using Distributed Word Embeddings", "abstract": "We propose a new algorithm for topic modeling, Vec2Topic, that identifies the\nmain topics in a corpus using semantic information captured via\nhigh-dimensional distributed word embeddings. Our technique is unsupervised and\ngenerates a list of topics ranked with respect to importance. We find that it\nworks better than existing topic modeling techniques such as Latent Dirichlet\nAllocation for identifying key topics in user-generated content, such as\nemails, chats, etc., where topics are diffused across the corpus. We also find\nthat Vec2Topic works equally well for non-user generated content, such as\npapers, reports, etc., and for small corpora such as a single-document.", "published": "2016-03-15 16:21:58", "link": "http://arxiv.org/abs/1603.04747v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the word-expert approach for Named-Entity Disambiguation", "abstract": "Named Entity Disambiguation (NED) is the task of linking a named-entity\nmention to an instance in a knowledge-base, typically Wikipedia. This task is\nclosely related to word-sense disambiguation (WSD), where the supervised\nword-expert approach has prevailed. In this work we present the results of the\nword-expert approach to NED, where one classifier is built for each target\nentity mention string. The resources necessary to build the system, a\ndictionary and a set of training instances, have been automatically derived\nfrom Wikipedia. We provide empirical evidence of the value of this approach, as\nwell as a study of the differences between WSD and NED, including ambiguity and\nsynonymy statistics.", "published": "2016-03-15 17:16:02", "link": "http://arxiv.org/abs/1603.04767v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Ranking Model for Entity Coreference Resolution", "abstract": "Coreference resolution is one of the first stages in deep language\nunderstanding and its importance has been well recognized in the natural\nlanguage processing community. In this paper, we propose a generative,\nunsupervised ranking model for entity coreference resolution by introducing\nresolution mode variables. Our unsupervised system achieves 58.44% F1 score of\nthe CoNLL metric on the English data from the CoNLL-2012 shared task (Pradhan\net al., 2012), outperforming the Stanford deterministic system (Lee et al.,\n2013) by 3.01%.", "published": "2016-03-15 04:39:15", "link": "http://arxiv.org/abs/1603.04553v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
