{"title": "Mitigating KV Cache Competition to Enhance User Experience in LLM Inference", "abstract": "In Large Language Model (LLM) serving, the KV-cache (KVC) bottleneck causes\nhigh tail Time-to-First-Token (TTFT) and Time-Between-Tokens (TBT), impairing\nuser experience, particularly in time-sensitive applications. However,\nsatisfying both TTFT and TBT service-level objectives (SLOs) is challenging. To\naddress this, we propose a system, named CacheOPT for mitigating KV Cache\ncompetition, based on key insights from our measurements, incorporating novel\ncomponents. First, it estimates a request's output length, bounding the\ndeviation with a high specified probability, adjusted based on the request\narrival rate. Second, it allocates the estimated KVC demand to a request, and\nreuses other requests' allocated KVC to avoid preemptions while reducing\nwaiting time. Third, it proactively allocates KVC before instead of at the time\na request exhausts its allocation and reserves KVC globally to prevent\npreemptions. Fourth, it chooses a request that has long TBT SLO, long job\nremaining time and short preemption time to preempt. Fifth, it selects the\nshortest-latency strategy between swapping and recomputation for preemptions.\nExperiments show that CacheOPT achieves up to 3.29$\\times$ and 2.83$\\times$\nlower tail TBT and tail TTFT, 47\\% and 53\\% higher TTFT and TBT SLO\nattainments, and supports up to 1.58$\\times$ higher request arrival rate than\nthe state-of-the-art methods.", "published": "2025-03-17 23:38:29", "link": "http://arxiv.org/abs/2503.13773v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AccelGen: Heterogeneous SLO-Guaranteed High-Throughput LLM Inference Serving for Diverse Applications", "abstract": "In this paper, we consider a mixed-prompt scenario for a large language model\n(LLM) inference serving system that supports diverse applications with both\nshort prompts and long prompts and heterogeneous SLOs for iteration time. To\nimprove throughput when handling long prompts, previous research introduces a\nchunking method, but has not addressed heterogeneous SLOs. To address the\nlimitation, we propose AccelGen, a high-throughput LLM inference serving system\nwith heterogeneous SLO guarantees for diverse applications. AccelGen introduces\nfour core components: (1) SLO-guaranteed dynamic chunking, which dynamically\nadjusts chunk sizes to maximize GPU compute utilization while meeting\niteration-level SLOs; (2) Iteration-level SLO-based task prioritization, which\nprioritizes tight-SLO requests and batches requests with similar SLOs; (3)\nMulti-resource-aware batching, which selects queued requests to maximize the\nutilizations of both GPU compute resource and key-value cache (KVC).\nTrace-driven real experiments demonstrate that AccelGen achieves 1.42-11.21X\nhigher throughput, 1.43-13.71X higher goodput, 37-90% higher SLO attainment,\nand 1.61-12.22X lower response latency compared to the state-of-the-art\napproaches. It achieves performance near the Oracle, which optimally maximizes\ngoodput.", "published": "2025-03-17 21:47:43", "link": "http://arxiv.org/abs/2503.13737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings", "abstract": "Large language models (LLMs) have revolutionized code generation, automating\nprogramming with remarkable efficiency. However, these advancements challenge\nprogramming skills, ethics, and assessment integrity, making the detection of\nLLM-generated code essential for maintaining accountability and standards.\nWhile, there has been some research on this problem, it generally lacks domain\ncoverage and robustness, and only covers a small number of programming\nlanguages. To this end, we propose a framework capable of distinguishing\nbetween human- and LLM-written code across multiple programming languages, code\ngenerators, and domains. We use a large-scale dataset from renowned platforms\nand LLM-based code generators, alongside applying rigorous data quality checks,\nfeature engineering, and comparative analysis using evaluation of traditional\nmachine learning models, pre-trained language models (PLMs), and LLMs for code\ndetection. We perform an evaluation on out-of-domain scenarios, such as\ndetecting the authorship and hybrid authorship of generated code and\ngeneralizing to unseen models, domains, and programming languages. Moreover,\nour extensive experiments show that our framework effectively distinguishes\nhuman- from LLM-written code and sets a new benchmark for this task.", "published": "2025-03-17 21:41:37", "link": "http://arxiv.org/abs/2503.13733v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TextInVision: Text and Prompt Complexity Driven Visual Text Generation Benchmark", "abstract": "Generating images with embedded text is crucial for the automatic production\nof visual and multimodal documents, such as educational materials and\nadvertisements. However, existing diffusion-based text-to-image models often\nstruggle to accurately embed text within images, facing challenges in spelling\naccuracy, contextual relevance, and visual coherence. Evaluating the ability of\nsuch models to embed text within a generated image is complicated due to the\nlack of comprehensive benchmarks. In this work, we introduce TextInVision, a\nlarge-scale, text and prompt complexity driven benchmark designed to evaluate\nthe ability of diffusion models to effectively integrate visual text into\nimages. We crafted a diverse set of prompts and texts that consider various\nattributes and text characteristics. Additionally, we prepared an image dataset\nto test Variational Autoencoder (VAE) models across different character\nrepresentations, highlighting that VAE architectures can also pose challenges\nin text generation within diffusion frameworks. Through extensive analysis of\nmultiple models, we identify common errors and highlight issues such as\nspelling inaccuracies and contextual mismatches. By pinpointing the failure\npoints across different prompts and texts, our research lays the foundation for\nfuture advancements in AI-generated multimodal content.", "published": "2025-03-17 21:36:31", "link": "http://arxiv.org/abs/2503.13730v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Atyaephyra at SemEval-2025 Task 4: Low-Rank NPO", "abstract": "We present a submission to the SemEval 2025 shared task on unlearning\nsensitive content from LLMs. Our approach employs negative preference\noptimization using low-rank adaptation. We show that we can utilize this\ncombination to cheaply compute additional regularization terms, which help with\nunlearning stabilization. The results of our approach significantly exceed the\nshared task baselines.", "published": "2025-03-17 19:59:19", "link": "http://arxiv.org/abs/2503.13690v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50 (Primary), 68T07 (Secondary)", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Feature Extraction and Analysis for GPT-Generated Text", "abstract": "With the rise of advanced natural language models like GPT, distinguishing\nbetween human-written and GPT-generated text has become increasingly\nchallenging and crucial across various domains, including academia. The\nlong-standing issue of plagiarism has grown more pressing, now compounded by\nconcerns about the authenticity of information, as it is not always clear\nwhether the presented facts are genuine or fabricated. In this paper, we\npresent a comprehensive study of feature extraction and analysis for\ndifferentiating between human-written and GPT-generated text. By applying\nmachine learning classifiers to these extracted features, we evaluate the\nsignificance of each feature in detection. Our results demonstrate that human\nand GPT-generated texts exhibit distinct writing styles, which can be\neffectively captured by our features. Given sufficiently long text, the two can\nbe differentiated with high accuracy.", "published": "2025-03-17 19:52:43", "link": "http://arxiv.org/abs/2503.13687v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pensez: Less Data, Better Reasoning -- Rethinking French LLM", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, achieving strong\nperformance in specialized domains like mathematical reasoning and non-English\nlanguages often requires extensive training on massive datasets. This paper\ninvestigates a contrasting approach: strategic fine-tuning on a small,\nhigh-quality, bilingual (English-French) dataset to enhance both the reasoning\ncapabilities and French language proficiency of a large language model. Rather\nthan relying on scale, we explore the hypothesis that targeted data curation\nand optimized training can achieve competitive, or even superior, performance.\nWe demonstrate, through targeted supervised fine-tuning (SFT) on only 2,000\ncarefully selected samples, significant improvements in mathematical reasoning.\nSpecifically, Pensez 7B exhibits an increase in accuracy of the base model up\nto 20% on the AIME25 and a 12% increase on a French MATH level 5 benchmark.\nThese results challenge the prevailing assumption that massive datasets are\naprerequisite for strong reasoning performance in LLMs, highlighting the\npotential of strategic data curation and optimized fine-tuning for enhancing\nboth specialized skills and multilingual capabilities. Our findings have\nimplications for the efficient development of high-performing, multilingual\nLLMs, especially in resource-constrained scenarios.", "published": "2025-03-17 19:09:11", "link": "http://arxiv.org/abs/2503.13661v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does the Appearance of Autonomous Conversational Robots Affect User Spoken Behaviors in Real-World Conference Interactions?", "abstract": "We investigate the impact of robot appearance on users' spoken behavior\nduring real-world interactions by comparing a human-like android, ERICA, with a\nless anthropomorphic humanoid, TELECO. Analyzing data from 42 participants at\nSIGDIAL 2024, we extracted linguistic features such as disfluencies and\nsyntactic complexity from conversation transcripts. The results showed moderate\neffect sizes, suggesting that participants produced fewer disfluencies and\nemployed more complex syntax when interacting with ERICA. Further analysis\ninvolving training classification models like Na\\\"ive Bayes, which achieved an\nF1-score of 71.60\\%, and conducting feature importance analysis, highlighted\nthe significant role of disfluencies and syntactic complexity in interactions\nwith robots of varying human-like appearances. Discussing these findings within\nthe frameworks of cognitive load and Communication Accommodation Theory, we\nconclude that designing robots to elicit more structured and fluent user speech\ncan enhance their communicative alignment with humans.", "published": "2025-03-17 18:20:30", "link": "http://arxiv.org/abs/2503.13625v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "MetaScale: Test-Time Scaling with Evolving Meta-Thoughts", "abstract": "One critical challenge for large language models (LLMs) for making complex\nreasoning is their reliance on matching reasoning patterns from training data,\ninstead of proactively selecting the most appropriate cognitive strategy to\nsolve a given task. Existing approaches impose fixed cognitive structures that\nenhance performance in specific tasks but lack adaptability across diverse\nscenarios. To address this limitation, we introduce METASCALE, a test-time\nscaling framework based on meta-thoughts -- adaptive thinking strategies\ntailored to each task. METASCALE initializes a pool of candidate meta-thoughts,\nthen iteratively selects and evaluates them using a multi-armed bandit\nalgorithm with upper confidence bound selection, guided by a reward model. To\nfurther enhance adaptability, a genetic algorithm evolves high-reward\nmeta-thoughts, refining and extending the strategy pool over time. By\ndynamically proposing and optimizing meta-thoughts at inference time, METASCALE\nimproves both accuracy and generalization across a wide range of tasks.\nExperimental results demonstrate that MetaScale consistently outperforms\nstandard inference approaches, achieving an 11% performance gain in win rate on\nArena-Hard for GPT-4o, surpassing o1-mini by 0.9% under style control. Notably,\nMETASCALE scales more effectively with increasing sampling budgets and produces\nmore structured, expert-level responses.", "published": "2025-03-17 17:59:54", "link": "http://arxiv.org/abs/2503.13447v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance", "abstract": "As large language models (LLMs) become increasingly capable, ensuring that\ntheir self-generated explanations are faithful to their internal\ndecision-making process is critical for safety and oversight. In this work, we\nconduct a comprehensive counterfactual faithfulness analysis across 62 models\nfrom 8 families, encompassing both pretrained and instruction-tuned variants\nand significantly extending prior studies of counterfactual tests. We introduce\nphi-CCT, a simplified variant of the Correlational Counterfactual Test, which\navoids the need for token probabilities while explaining most of the variance\nof the original test. Our findings reveal clear scaling trends: larger models\nare consistently more faithful on our metrics. However, when comparing\ninstruction-tuned and human-imitated explanations, we find that observed\ndifferences in faithfulness can often be attributed to explanation verbosity,\nleading to shifts along the true-positive/false-positive Pareto frontier. While\ninstruction-tuning and prompting can influence this trade-off, we find limited\nevidence that they fundamentally expand the frontier of explanatory\nfaithfulness beyond what is achievable with pretrained models of comparable\nsize. Our analysis highlights the nuanced relationship between\ninstruction-tuning, verbosity, and the faithful representation of model\ndecision processes.", "published": "2025-03-17 17:59:39", "link": "http://arxiv.org/abs/2503.13445v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference", "abstract": "Recent breakthroughs in solving reasoning, math and coding problems with\nLarge Language Models (LLMs) have been enabled by investing substantial\ncomputation budgets at inference time. Therefore, inference speed is one of the\nmost critical properties of LLM architectures, and there is a growing need for\nLLMs that are efficient and fast at inference. Recently, LLMs built on the\nxLSTM architecture have emerged as a powerful alternative to Transformers,\noffering linear compute scaling with sequence length and constant memory usage,\nboth highly desirable properties for efficient inference. However, such\nxLSTM-based LLMs have yet to be scaled to larger models and assessed and\ncompared with respect to inference speed and efficiency. In this work, we\nintroduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's\narchitectural benefits with targeted optimizations for fast and efficient\ninference. Our experiments demonstrate that xLSTM 7B achieves performance on\ndownstream tasks comparable to other similar-sized LLMs, while providing\nsignificantly faster inference speeds and greater efficiency compared to Llama-\nand Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most\nefficient 7B LLM, offering a solution for tasks that require large amounts of\ntest-time computation. Our work highlights xLSTM's potential as a foundational\narchitecture for methods building on heavy use of LLM inference. Our model\nweights, model code and training code are open-source.", "published": "2025-03-17 17:54:55", "link": "http://arxiv.org/abs/2503.13427v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SuperBPE: Space Travel for Language Models", "abstract": "The assumption across nearly all language model (LM) tokenization schemes is\nthat tokens should be subwords, i.e., contained within word boundaries. While\nproviding a seemingly reasonable inductive bias, is this common practice\nlimiting the potential of modern LMs? Whitespace is not a reliable delimiter of\nmeaning, as evidenced by multi-word expressions (e.g., \"by the way\"),\ncrosslingual variation in the number of words needed to express a concept\n(e.g., \"spacesuit helmet\" in German is \"raumanzughelm\"), and languages that do\nnot use whitespace at all (e.g., Chinese). To explore the potential of\ntokenization beyond subwords, we introduce a \"superword\" tokenizer, SuperBPE,\nwhich incorporates a simple pretokenization curriculum into the byte-pair\nencoding (BPE) algorithm to first learn subwords, then superwords that bridge\nwhitespace. This brings dramatic improvements in encoding efficiency: when\nfixing the vocabulary size to 200k, SuperBPE encodes a fixed piece of text with\nup to 33% fewer tokens than BPE on average. In experiments, we pretrain 8B\ntransformer LMs from scratch while fixing the model size, vocabulary size, and\ntrain compute, varying *only* the algorithm for learning the vocabulary. Our\nmodel trained with SuperBPE achieves an average +4.0% absolute improvement over\nthe BPE baseline across 30 downstream tasks (including +8.2% on MMLU), while\nsimultaneously requiring 27% less compute at inference time. In analysis, we\nfind that SuperBPE results in segmentations of text that are more uniform in\nper-token difficulty. Qualitatively, this may be because SuperBPE tokens often\ncapture common multi-word expressions that function semantically as a single\nunit. SuperBPE is a straightforward, local modification to tokenization that\nimproves both encoding efficiency and downstream performance, yielding better\nlanguage models overall.", "published": "2025-03-17 17:53:23", "link": "http://arxiv.org/abs/2503.13423v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DLPO: Towards a Robust, Efficient, and Generalizable Prompt Optimization Framework from a Deep-Learning Perspective", "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, largely driven by well-designed prompts. However, crafting and selecting\nsuch prompts often requires considerable human effort, significantly limiting\nits scalability. To mitigate this, recent studies have explored automated\nprompt optimization as a promising solution. Despite these efforts, existing\nmethods still face critical challenges in robustness, efficiency, and\ngeneralization. To systematically address these challenges, we first conduct an\nempirical analysis to identify the limitations of current reflection-based\nprompt optimization paradigm. Building on these insights, we propose 7\ninnovative approaches inspired by traditional deep learning paradigms for\nprompt optimization (DLPO), seamlessly integrating these concepts into\ntext-based gradient optimization. Through these advancements, we progressively\ntackle the aforementioned challenges and validate our methods through extensive\nexperimentation. We hope our study not only provides valuable guidance for\nfuture research but also offers a comprehensive understanding of the challenges\nand potential solutions in prompt optimization. Our code is available at\nhttps://github.com/sfasfaffa/DLPO.", "published": "2025-03-17 17:42:51", "link": "http://arxiv.org/abs/2503.13413v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using the Tools of Cognitive Science to Understand Large Language Models at Different Levels of Analysis", "abstract": "Modern artificial intelligence systems, such as large language models, are\nincreasingly powerful but also increasingly hard to understand. Recognizing\nthis problem as analogous to the historical difficulties in understanding the\nhuman mind, we argue that methods developed in cognitive science can be useful\nfor understanding large language models. We propose a framework for applying\nthese methods based on Marr's three levels of analysis. By revisiting\nestablished cognitive science techniques relevant to each level and\nillustrating their potential to yield insights into the behavior and internal\norganization of large language models, we aim to provide a toolkit for making\nsense of these new kinds of minds.", "published": "2025-03-17 17:33:54", "link": "http://arxiv.org/abs/2503.13401v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research", "abstract": "Scientific research demands sophisticated reasoning over multimodal data, a\nchallenge especially prevalent in biology. Despite recent advances in\nmultimodal large language models (MLLMs) for AI-assisted research, existing\nmultimodal reasoning benchmarks only target up to college-level difficulty,\nwhile research-level benchmarks emphasize lower-level perception, falling short\nof the complex multimodal reasoning needed for scientific discovery. To bridge\nthis gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark\ndesigned to assess three reasoning capabilities vital in research workflows:\nexpert image understanding, hypothesis generation, and experiment proposal.\nMicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology\nexperts across diverse microscopy modalities, ensuring VQA samples represent\nreal scientific practice. In constructing the benchmark, we find that standard\nMCQ generation methods induce language shortcuts, motivating a new two-stage\npipeline: an optimized LLM prompt structures question-answer pairs into MCQs;\nthen, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking\non state-of-the-art MLLMs reveal a peak performance of 53\\%; models with\nsmaller LLMs only slightly underperform top models, suggesting that\nlanguage-based reasoning is less challenging than multimodal reasoning; and\ntuning with scientific articles enhances performance. Expert analysis of\nchain-of-thought responses shows that perception errors are the most frequent,\nfollowed by knowledge errors and then overgeneralization errors. These insights\nhighlight the challenges in multimodal scientific reasoning, showing MicroVQA\nis a valuable resource advancing AI-driven biomedical research. MicroVQA is\navailable at https://huggingface.co/datasets/jmhb/microvqa, and project page at\nhttps://jmhb0.github.io/microvqa.", "published": "2025-03-17 17:33:10", "link": "http://arxiv.org/abs/2503.13399v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "q-bio.CB"], "primary_category": "cs.CV"}
{"title": "Aligned Probing: Relating Toxic Behavior and Model Internals", "abstract": "We introduce aligned probing, a novel interpretability framework that aligns\nthe behavior of language models (LMs), based on their outputs, and their\ninternal representations (internals). Using this framework, we examine over 20\nOLMo, Llama, and Mistral models, bridging behavioral and internal perspectives\nfor toxicity for the first time. Our results show that LMs strongly encode\ninformation about the toxicity level of inputs and subsequent outputs,\nparticularly in lower layers. Focusing on how unique LMs differ offers both\ncorrelative and causal evidence that they generate less toxic output when\nstrongly encoding information about the input toxicity. We also highlight the\nheterogeneity of toxicity, as model behavior and internals vary across unique\nattributes such as Threat. Finally, four case studies analyzing detoxification,\nmulti-prompt evaluations, model quantization, and pre-training dynamics\nunderline the practical impact of aligned probing with further concrete\ninsights. Our findings contribute to a more holistic understanding of LMs, both\nwithin and beyond the context of toxicity.", "published": "2025-03-17 17:23:50", "link": "http://arxiv.org/abs/2503.13390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning", "abstract": "The hypothesis that pretrained large language models (LLMs) necessitate only\nminimal supervision during the fine-tuning (SFT) stage (Zhou et al., 2024) has\nbeen substantiated by recent advancements in data curation and selection\nresearch. However, their stability and generalizability are compromised due to\nthe vulnerability to experimental setups and validation protocols, falling\nshort of surpassing random sampling (Diddee & Ippolito, 2024; Xia et al.,\n2024b). Built upon LLMs, multi-modal LLMs (MLLMs), combined with the sheer\ntoken volume and heightened heterogeneity of data sources, amplify both the\nsignificance and complexity of data selection.\n  To harvest multi-modal instructional data in a robust and efficient manner,\nwe re-define the granularity of the quality metric by decomposing it into 14\nvision-language-related capabilities, and introduce multi-modal rich scorers to\nevaluate the capabilities of each data candidate. To promote diversity, in\nlight of the inherent objective of the alignment stage, we take interaction\nstyle as diversity indicator and use a multi-modal rich styler to identify data\ninstruction patterns. In doing so, our multi-modal rich scorers and styler\n(mmSSR) guarantee that high-scoring information is conveyed to users in\ndiversified forms. Free from embedding-based clustering or greedy sampling,\nmmSSR efficiently scales to millions of data with varying budget constraints,\nsupports customization for general or specific capability acquisition, and\nfacilitates training-free generalization to new domains for curation. Across\n10+ experimental settings, validated by 14 multi-modal benchmarks, we\ndemonstrate consistent improvements over random sampling, baseline strategies\nand state-of-the-art selection methods, achieving 99.1% of full performance\nwith only 30% of the 2.6M data.", "published": "2025-03-17 17:11:22", "link": "http://arxiv.org/abs/2503.13383v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TimeZero: Temporal Video Grounding with Reasoning-Guided LVLM", "abstract": "We introduce TimeZero, a reasoning-guided LVLM designed for the temporal\nvideo grounding (TVG) task. This task requires precisely localizing relevant\nvideo segments within long videos based on a given language query. TimeZero\ntackles this challenge by extending the inference process, enabling the model\nto reason about video-language relationships solely through reinforcement\nlearning. To evaluate the effectiveness of TimeZero, we conduct experiments on\ntwo benchmarks, where TimeZero achieves state-of-the-art performance on\nCharades-STA. Code is available at https://github.com/www-Ye/TimeZero.", "published": "2025-03-17 17:04:20", "link": "http://arxiv.org/abs/2503.13377v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "KVShare: Semantic-Aware Key-Value Cache Sharing for Efficient Large Language Model Inference", "abstract": "This paper presents KVShare, a multi-user Key-Value (KV) Cache sharing\ntechnology based on semantic similarity, designed to enhance the inference\nefficiency of Large Language Models (LLMs) and Multimodal Large Language Models\n(MLLMs). Addressing the limitations of existing prefix caching (strict text\nprefix matching) and semantic caching (loss of response diversity), KVShare\nachieves fine-grained KV cache reuse through semantic alignment algorithms and\ndifferential editing operations. Experiments on real-world user conversation\ndatasets demonstrate that KVShare improves KV cache hit rates by over 60%,\nwhile maintaining output quality comparable to full computation (no significant\ndegradation in BLEU and Rouge-L metrics). This approach effectively reduces GPU\nresource consumption and is applicable to scenarios with repetitive queries,\nsuch as healthcare and education.", "published": "2025-03-17 16:43:35", "link": "http://arxiv.org/abs/2503.16525v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Valid Text-to-SQL Generation with Unification-based DeepStochLog", "abstract": "Large language models have been used to translate natural language questions\nto SQL queries. Without hard constraints on syntax and database schema, they\noccasionally produce invalid queries that are not executable. These failures\nlimit the usage of these systems in real-life scenarios. We propose a\nneurosymbolic framework that imposes SQL syntax and schema constraints with\nunification-based definite clause grammars and thus guarantees the generation\nof valid queries. Our framework also builds a bi-directional interface to\nlanguage models to leverage their natural language understanding abilities. The\nevaluation results on a subset of SQL grammars show that all our output queries\nare valid. This work is the first step towards extending language models with\nunification-based grammars. We demonstrate this extension enhances the\nvalidity, execution accuracy, and ground truth alignment of the underlying\nlanguage model by a large margin. Our code is available at\nhttps://github.com/ML-KULeuven/deepstochlog-lm.", "published": "2025-03-17 16:21:10", "link": "http://arxiv.org/abs/2503.13342v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reliable and Efficient Amortized Model-based Evaluation", "abstract": "Comprehensive evaluations of language models (LM) during both development and\ndeployment phases are necessary because these models possess numerous\ncapabilities (e.g., mathematical reasoning, legal support, or medical\ndiagnostic) as well as safety risks (e.g., racial bias, toxicity, or\nmisinformation). The average score across a wide range of benchmarks provides a\nsignal that helps guide the use of these LMs in practice. Currently, holistic\nevaluations are costly due to the large volume of benchmark questions, making\nfrequent evaluations impractical. A popular attempt to lower the cost is to\ncompute the average score on a subset of the benchmark. This approach,\nunfortunately, often renders an unreliable measure of LM performance because\nthe average score is often confounded with the difficulty of the questions in\nthe benchmark subset. Item response theory (IRT) was designed to address this\nchallenge, providing a reliable measurement by careful controlling for question\ndifficulty. Unfortunately, question difficulty is expensive to estimate. Facing\nthis challenge, we train a model that predicts question difficulty from its\ncontent, enabling a reliable measurement at a fraction of the cost. In\naddition, we leverage this difficulty predictor to further improve the\nevaluation efficiency through training a question generator given a difficulty\nlevel. This question generator is essential in adaptive testing, where, instead\nof using a random subset of the benchmark questions, informative questions are\nadaptively chosen based on the current estimation of LLM performance.\nExperiments on 22 common natural language benchmarks and 172 LMs show that this\napproach is more reliable and efficient compared to current common practice.", "published": "2025-03-17 16:15:02", "link": "http://arxiv.org/abs/2503.13335v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Computation Mechanism Behind LLM Position Generalization", "abstract": "Most written natural languages are composed of sequences of words and\nsentences. Similar to humans, large language models (LLMs) exhibit flexibility\nin handling textual positions - a phenomenon we term position generalization.\nThey can understand texts with position perturbations and generalize to longer\ntexts than those encountered during training with the latest techniques. These\nphenomena suggest that LLMs handle positions tolerantly, but how LLMs\ncomputationally process positional relevance remains largely unexplored. This\nwork connects the linguistic phenomenon with LLMs' computational mechanisms. We\nshow how LLMs enforce certain computational mechanisms for the aforementioned\ntolerance in position perturbations. Despite the complex design of the\nself-attention mechanism, this work reveals that LLMs learn a counterintuitive\ndisentanglement of attention logits. Their values show a 0.959 linear\ncorrelation with an approximation of the arithmetic sum of positional relevance\nand semantic importance. Furthermore, we identify a prevalent pattern in\nintermediate features, which we prove theoretically enables this effect. The\npattern, which is different from how randomly initialized parameters would\nbehave, suggests that it is a learned behavior rather than a natural result of\nthe model architecture. Based on these findings, we provide computational\nexplanations and criteria for LLMs' position flexibilities. This work takes a\npioneering step in linking position generalization with modern LLMs' internal\nmechanisms.", "published": "2025-03-17 15:47:37", "link": "http://arxiv.org/abs/2503.13305v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Transformer Context Extension: Approaches and Evaluation", "abstract": "Large language models (LLMs) based on Transformer have been widely applied in\nthe filed of natural language processing (NLP), demonstrating strong\nperformance, particularly in handling short text tasks. However, when it comes\nto long context scenarios, the performance of LLMs degrades due to some\nchallenges. To alleviate this phenomenon, there is a number of work proposed\nrecently. In this survey, we first list the challenges of applying pre-trained\nLLMs to process long contexts. Then systematically review the approaches\nrelated to long context and propose our taxonomy categorizing them into four\nmain types: positional encoding, context compression, retrieval augmented, and\nattention pattern. In addition to the approaches, we focus on the evaluation of\nlong context, organizing relevant data, tasks, and metrics based on existing\nlong context benchmarks. Finally, we summarize unresolved issues in the long\ncontext domain and put forward our views on future developments.", "published": "2025-03-17 15:44:09", "link": "http://arxiv.org/abs/2503.13299v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "$\u03c6$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation", "abstract": "Inference-time optimization scales computation to derive deliberate reasoning\nsteps for effective performance. While previous search-based strategies address\nthe short-sightedness of auto-regressive generation, the vast search space\nleads to excessive exploration and insufficient exploitation. To strike an\nefficient balance to derive the optimal step, we frame the decoding strategy as\nforesight sampling, leveraging simulated future steps to obtain globally\noptimal step estimation. Built on it, we propose a novel decoding strategy,\nnamed $\\phi$-Decoding. To provide a precise and expressive estimation of step\nvalue, $\\phi$-Decoding approximates two distributions via foresight and\nclustering. Sampling from the joint distribution, the optimal steps can be\nselected for exploitation. To support adaptive computation allocation, we\npropose in-width and in-depth pruning strategies, featuring a light-weight\nsolution to achieve inference efficiency. Extensive experiments across seven\nbenchmarks show $\\phi$-Decoding outperforms strong baselines in both\nperformance and efficiency. Additional analysis demonstrates its generalization\nacross various LLMs and scalability across a wide range of computing budgets.\nThe code will be released at https://github.com/xufangzhi/phi-Decoding, and the\nopen-source PyPI package is coming soon.", "published": "2025-03-17 15:38:33", "link": "http://arxiv.org/abs/2503.13288v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation", "abstract": "Patient matching is the process of linking patients to appropriate clinical\ntrials by accurately identifying and matching their medical records with trial\neligibility criteria. We propose LLM-Match, a novel framework for patient\nmatching leveraging fine-tuned open-source large language models. Our approach\nconsists of four key components. First, a retrieval-augmented generation (RAG)\nmodule extracts relevant patient context from a vast pool of electronic health\nrecords (EHRs). Second, a prompt generation module constructs input prompts by\nintegrating trial eligibility criteria (both inclusion and exclusion criteria),\npatient context, and system instructions. Third, a fine-tuning module with a\nclassification head optimizes the model parameters using structured prompts and\nground-truth labels. Fourth, an evaluation module assesses the fine-tuned\nmodel's performance on the testing datasets. We evaluated LLM-Match on four\nopen datasets - n2c2, SIGIR, TREC 2021, and TREC 2022 - using open-source\nmodels, comparing it against TrialGPT, Zero-Shot, and GPT-4-based closed\nmodels. LLM-Match outperformed all baselines.", "published": "2025-03-17 15:31:55", "link": "http://arxiv.org/abs/2503.13281v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TablePilot: Recommending Human-Preferred Tabular Data Analysis with Large Language Models", "abstract": "Tabular data analysis is crucial in many scenarios, yet efficiently\nidentifying the most relevant data analysis queries and results for a new table\nremains a significant challenge. The complexity of tabular data, diverse\nanalytical operations, and the demand for high-quality analysis make the\nprocess tedious. To address these challenges, we aim to recommend\nquery-code-result triplets tailored for new tables in tabular data analysis\nworkflows. In this paper, we present TablePilot, a pioneering tabular data\nanalysis framework leveraging large language models to autonomously generate\ncomprehensive and superior analytical results without relying on user profiles\nor prior interactions. The framework incorporates key designs in analysis\npreparation and analysis optimization to enhance accuracy. Additionally, we\npropose Rec-Align, a novel method to further improve recommendation quality and\nbetter align with human preferences. Experiments on DART, a dataset\nspecifically designed for comprehensive tabular data analysis recommendation,\ndemonstrate the effectiveness of our framework. Based on GPT-4o, the tuned\nTablePilot achieves 77.0% top-5 recommendation recall. Human evaluations\nfurther highlight its effectiveness in optimizing tabular data analysis\nworkflows.", "published": "2025-03-17 15:16:59", "link": "http://arxiv.org/abs/2503.13262v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Language Models Follow Multiple Turns of Entangled Instructions?", "abstract": "Despite significant achievements in improving the instruction-following\ncapabilities of large language models (LLMs), the ability to process multiple\npotentially entangled or conflicting instructions remains a considerable\nchallenge. Real-world scenarios often require consistency across multiple\ninstructions over time, such as secret privacy, personal preferences, and\nprioritization, which demand sophisticated abilities to integrate multiple\nturns and carefully balance competing objectives when instructions intersect or\nconflict. This work presents a systematic investigation of LLMs' capabilities\nin handling multiple turns of instructions, covering three levels of\ndifficulty: (1) retrieving information from instructions, (2) tracking and\nreasoning across turns, and (3) resolving conflicts among instructions. We\nconstruct MultiTurnInstruct with around 1.1K high-quality multi-turn\nconversations through the human-in-the-loop approach and result in nine\ncapability categories, including statics and dynamics, reasoning, and\nmultitasking. Our finding reveals an intriguing trade-off between different\ncapabilities. While GPT models demonstrate superior memorization, they show\nreduced effectiveness in privacy-protection tasks requiring selective\ninformation withholding. Larger models exhibit stronger reasoning capabilities\nbut still struggle with resolving conflicting instructions. Importantly, these\nperformance gaps cannot be attributed solely to information loss, as models\ndemonstrate strong BLEU scores on memorization tasks but their attention\nmechanisms fail to integrate multiple related instructions effectively. These\nfindings highlight critical areas for improvement in complex real-world tasks\ninvolving multi-turn instructions.", "published": "2025-03-17 14:31:37", "link": "http://arxiv.org/abs/2503.13222v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Complex Reasoning with Dynamic Prompt Corruption: A soft prompt Optimization Approach", "abstract": "Prompt-tuning (PT) for large language models (LLMs) can facilitate the\nperformance on various conventional NLP tasks with significantly fewer\ntrainable parameters. However, our investigation reveals that PT provides\nlimited improvement and may even degrade the primitive performance of LLMs on\ncomplex reasoning tasks. Such a phenomenon suggests that soft prompts can\npositively impact certain instances while negatively affecting others,\nparticularly during the later phases of reasoning. To address these challenges,\nWe first identify an information accumulation within the soft prompts. Through\ndetailed analysis, we demonstrate that this phenomenon is often accompanied by\nerroneous information flow patterns in the deeper layers of the model, which\nultimately lead to incorrect reasoning outcomes. we propose a novel method\ncalled Dynamic Prompt Corruption (DPC) to take better advantage of soft prompts\nin complex reasoning tasks, which dynamically adjusts the influence of soft\nprompts based on their impact on the reasoning process. Specifically, DPC\nconsists of two stages: Dynamic Trigger and Dynamic Corruption. First, Dynamic\nTrigger measures the impact of soft prompts, identifying whether beneficial or\ndetrimental. Then, Dynamic Corruption mitigates the negative effects of soft\nprompts by selectively masking key tokens that interfere with the reasoning\nprocess. We validate the proposed approach through extensive experiments on\nvarious LLMs and reasoning tasks, including GSM8K, MATH, and AQuA. Experimental\nresults demonstrate that DPC can consistently enhance the performance of PT,\nachieving 4%-8% accuracy gains compared to vanilla prompt tuning, highlighting\nthe effectiveness of our approach and its potential to enhance complex\nreasoning in LLMs.", "published": "2025-03-17 14:20:48", "link": "http://arxiv.org/abs/2503.13208v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways", "abstract": "Inpatient pathways demand complex clinical decision-making based on\ncomprehensive patient information, posing critical challenges for clinicians.\nDespite advancements in large language models (LLMs) in medical applications,\nlimited research focused on artificial intelligence (AI) inpatient pathways\nsystems, due to the lack of large-scale inpatient datasets. Moreover, existing\nmedical benchmarks typically concentrated on medical question-answering and\nexaminations, ignoring the multifaceted nature of clinical decision-making in\ninpatient settings. To address these gaps, we first developed the Inpatient\nPathway Decision Support (IPDS) benchmark from the MIMIC-IV database,\nencompassing 51,274 cases across nine triage departments and 17 major disease\ncategories alongside 16 standardized treatment options. Then, we proposed the\nMulti-Agent Inpatient Pathways (MAP) framework to accomplish inpatient pathways\nwith three clinical agents, including a triage agent managing the patient\nadmission, a diagnosis agent serving as the primary decision maker at the\ndepartment, and a treatment agent providing treatment plans. Additionally, our\nMAP framework includes a chief agent overseeing the inpatient pathways to guide\nand promote these three clinician agents. Extensive experiments showed our MAP\nimproved the diagnosis accuracy by 25.10% compared to the state-of-the-art LLM\nHuatuoGPT2-13B. It is worth noting that our MAP demonstrated significant\nclinical compliance, outperforming three board-certified clinicians by 10%-12%,\nestablishing a foundation for inpatient pathways systems.", "published": "2025-03-17 14:14:28", "link": "http://arxiv.org/abs/2503.13205v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model", "abstract": "Large Language Models (LLMs) possess encompassing capabilities that can\nprocess diverse language-related tasks. However, finetuning on LLMs will\ndiminish this general skills and continual finetuning will further cause severe\ndegradation on accumulated knowledge. Recently, Continual Learning (CL) in\nLarge Language Models (LLMs) arises which aims to continually adapt the LLMs to\nnew tasks while maintaining previously learned knowledge and inheriting general\nskills. Existing techniques either leverage previous data to replay, leading to\nextra computational costs, or utilize a single parameter-efficient module to\nlearn the downstream task, constraining new knowledge absorption with\ninterference between different tasks. Toward these issues, this paper proposes\nAnalytic Subspace Routing(ASR) to address these challenges. For each task, we\nisolate the learning within a subspace of deep layers' features via low-rank\nadaptation, eliminating knowledge interference between different tasks.\nAdditionally, we propose an analytic routing mechanism to properly utilize\nknowledge learned in different subspaces. Our approach employs Recursive Least\nSquares to train a multi-task router model, allowing the router to dynamically\nadapt to incoming data without requiring access to historical data. Also, the\nrouter effectively assigns the current task to an appropriate subspace and has\na non-forgetting property of previously learned tasks with a solid theoretical\nguarantee. Experimental results demonstrate that our method achieves\nnear-perfect retention of prior knowledge while seamlessly integrating new\ninformation, effectively overcoming the core limitations of existing methods.\nOur code will be released after acceptance.", "published": "2025-03-17 13:40:46", "link": "http://arxiv.org/abs/2503.13575v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Are LLMs (Really) Ideological? An IRT-based Analysis and Alignment Tool for Perceived Socio-Economic Bias in LLMs", "abstract": "We introduce an Item Response Theory (IRT)-based framework to detect and\nquantify socioeconomic bias in large language models (LLMs) without relying on\nsubjective human judgments. Unlike traditional methods, IRT accounts for item\ndifficulty, improving ideological bias estimation. We fine-tune two LLM\nfamilies (Meta-LLaMa 3.2-1B-Instruct and Chat- GPT 3.5) to represent distinct\nideological positions and introduce a two-stage approach: (1) modeling response\navoidance and (2) estimating perceived bias in answered responses. Our results\nshow that off-the-shelf LLMs often avoid ideological engagement rather than\nexhibit bias, challenging prior claims of partisanship. This empirically\nvalidated framework enhances AI alignment research and promotes fairer AI\ngovernance.", "published": "2025-03-17 13:20:09", "link": "http://arxiv.org/abs/2503.13149v1", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding", "abstract": "Understanding long video content is a complex endeavor that often relies on\ndensely sampled frame captions or end-to-end feature selectors, yet these\ntechniques commonly overlook the logical relationships between textual queries\nand visual elements. In practice, computational constraints necessitate coarse\nframe subsampling, a challenge analogous to ``finding a needle in a haystack.''\nTo address this issue, we introduce a semantics-driven search framework that\nreformulates keyframe selection under the paradigm of Visual Semantic-Logical\nSearch. Specifically, we systematically define four fundamental logical\ndependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute\ndependency, and 4) causal order. These relations dynamically update frame\nsampling distributions through an iterative refinement process, enabling\ncontext-aware identification of semantically critical frames tailored to\nspecific query requirements. Our method establishes new SOTA performance on the\nmanually annotated benchmark in key-frame selection metrics. Furthermore, when\napplied to downstream video question-answering tasks, the proposed approach\ndemonstrates the best performance gains over existing methods on LongVideoBench\nand Video-MME, validating its effectiveness in bridging the logical gap between\ntextual queries and visual-temporal reasoning. The code will be publicly\navailable.", "published": "2025-03-17 13:07:34", "link": "http://arxiv.org/abs/2503.13139v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs", "abstract": "Multimodal large language models (MLLMs) excel at 2D visual understanding but\nremain limited in their ability to reason about 3D space. In this work, we\nleverage large-scale high-quality 3D scene data with open-set annotations to\nintroduce 1) a novel supervised fine-tuning dataset and 2) a new evaluation\nbenchmark, focused on indoor scenes. Our Cubify Anything VQA (CA-VQA) data\ncovers diverse spatial tasks including spatial relationship prediction, metric\nsize and distance estimation, and 3D grounding. We show that CA-VQA enables us\nto train MM-Spatial, a strong generalist MLLM that also achieves\nstate-of-the-art performance on 3D spatial understanding benchmarks, including\nour own. We show how incorporating metric depth and multi-view inputs (provided\nin CA-VQA) can further improve 3D understanding, and demonstrate that data\nalone allows our model to achieve depth perception capabilities comparable to\ndedicated monocular depth estimation models. We will publish our SFT dataset\nand benchmark.", "published": "2025-03-17 12:34:22", "link": "http://arxiv.org/abs/2503.13111v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Code-Driven Inductive Synthesis: Enhancing Reasoning Abilities of Large Language Models with Sequences", "abstract": "Large language models make remarkable progress in reasoning capabilities.\nExisting works focus mainly on deductive reasoning tasks (e.g., code and math),\nwhile another type of reasoning mode that better aligns with human learning,\ninductive reasoning, is not well studied. We attribute the reason to the fact\nthat obtaining high-quality process supervision data is challenging for\ninductive reasoning. Towards this end, we novelly employ number sequences as\nthe source of inductive reasoning data. We package sequences into algorithmic\nproblems to find the general term of each sequence through a code solution. In\nthis way, we can verify whether the code solution holds for any term in the\ncurrent sequence, and inject case-based supervision signals by using code unit\ntests. We build a sequence synthetic data pipeline and form a training dataset\nCodeSeq. Experimental results show that the models tuned with CodeSeq improve\non both code and comprehensive reasoning benchmarks.", "published": "2025-03-17 12:33:26", "link": "http://arxiv.org/abs/2503.13109v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REPA: Russian Error Types Annotation for Evaluating Text Generation and Judgment Capabilities", "abstract": "Recent advances in large language models (LLMs) have introduced the novel\nparadigm of using LLMs as judges, where an LLM evaluates and scores the outputs\nof another LLM, which often correlates highly with human preferences. However,\nthe use of LLM-as-a-judge has been primarily studied in English. In this paper,\nwe evaluate this framework in Russian by introducing the Russian Error tyPes\nAnnotation dataset (REPA), a dataset of 1k user queries and 2k LLM-generated\nresponses. Human annotators labeled each response pair expressing their\npreferences across ten specific error types, as well as selecting an overall\npreference. We rank six generative LLMs across the error types using three\nrating systems based on human preferences. We also evaluate responses using\neight LLM judges in zero-shot and few-shot settings. We describe the results of\nanalyzing the judges and position and length biases. Our findings reveal a\nnotable gap between LLM judge performance in Russian and English. However,\nrankings based on human and LLM preferences show partial alignment, suggesting\nthat while current LLM judges struggle with fine-grained evaluation in Russian,\nthere is potential for improvement.", "published": "2025-03-17 12:15:16", "link": "http://arxiv.org/abs/2503.13102v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who Wrote This? Identifying Machine vs Human-Generated Text in Hausa", "abstract": "The advancement of large language models (LLMs) has allowed them to be\nproficient in various tasks, including content generation. However, their\nunregulated usage can lead to malicious activities such as plagiarism and\ngenerating and spreading fake news, especially for low-resource languages. Most\nexisting machine-generated text detectors are trained on high-resource\nlanguages like English, French, etc. In this study, we developed the first\nlarge-scale detector that can distinguish between human- and machine-generated\ncontent in Hausa. We scrapped seven Hausa-language media outlets for the\nhuman-generated text and the Gemini-2.0 flash model to automatically generate\nthe corresponding Hausa-language articles based on the human-generated article\nheadlines. We fine-tuned four pre-trained Afri-centric models (AfriTeVa,\nAfriBERTa, AfroXLMR, and AfroXLMR-76L) on the resulting dataset and assessed\ntheir performance using accuracy and F1-score metrics. AfroXLMR achieved the\nhighest performance with an accuracy of 99.23% and an F1 score of 99.21%,\ndemonstrating its effectiveness for Hausa text detection. Our dataset is made\npublicly available to enable further research.", "published": "2025-03-17 12:13:37", "link": "http://arxiv.org/abs/2503.13101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ClusComp: A Simple Paradigm for Model Compression and Efficient Finetuning", "abstract": "As large language models (LLMs) scale, model compression is crucial for edge\ndeployment and accessibility. Weight-only quantization reduces model size but\nsuffers from performance degradation at lower bit widths. Moreover, standard\nfinetuning is incompatible with quantized models, and alternative methods often\nfall short of full finetuning. In this paper, we propose ClusComp, a simple yet\neffective compression paradigm that clusters weight matrices into codebooks and\nfinetunes them block-by-block. ClusComp (1) achieves superior performance in\n2-4 bit quantization, (2) pushes compression to 1-bit while outperforming\nultra-low-bit methods with minimal finetuning, and (3) enables efficient\nfinetuning, even surpassing existing quantization-based approaches and rivaling\nfull FP16 finetuning. Notably, ClusComp supports compression and finetuning of\n70B LLMs on a single A6000-48GB GPU.", "published": "2025-03-17 11:52:16", "link": "http://arxiv.org/abs/2503.13089v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mind2: Mind-to-Mind Emotional Support System with Bidirectional Cognitive Discourse Analysis", "abstract": "Emotional support (ES) systems alleviate users' mental distress by generating\nstrategic supportive dialogues based on diverse user situations. However, ES\nsystems are limited in their ability to generate effective ES dialogues that\ninclude timely context and interpretability, hindering them from earning public\ntrust. Driven by cognitive models, we propose Mind-to-Mind (Mind2), an ES\nframework that approaches interpretable ES context modeling for the ES dialogue\ngeneration task from a discourse analysis perspective. Specifically, we perform\ncognitive discourse analysis on ES dialogues according to our dynamic discourse\ncontext propagation window, which accommodates evolving context as the\nconversation between the ES system and user progresses. To enhance\ninterpretability, Mind2 prioritizes details that reflect each speaker's belief\nabout the other speaker with bidirectionality, integrating Theory-of-Mind,\nphysiological expected utility, and cognitive rationality to extract cognitive\nknowledge from ES conversations. Experimental results support that Mind2\nachieves competitive performance versus state-of-the-art ES systems while\ntrained with only 10\\% of the available training data.", "published": "2025-03-17 11:39:56", "link": "http://arxiv.org/abs/2503.16523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Framework to Assess Multilingual Vulnerabilities of LLMs", "abstract": "Large Language Models (LLMs) are acquiring a wider range of capabilities,\nincluding understanding and responding in multiple languages. While they\nundergo safety training to prevent them from answering illegal questions,\nimbalances in training data and human evaluation resources can make these\nmodels more susceptible to attacks in low-resource languages (LRL). This paper\nproposes a framework to automatically assess the multilingual vulnerabilities\nof commonly used LLMs. Using our framework, we evaluated six LLMs across eight\nlanguages representing varying levels of resource availability. We validated\nthe assessments generated by our automated framework through human evaluation\nin two languages, demonstrating that the framework's results align with human\njudgments in most cases. Our findings reveal vulnerabilities in LRL; however,\nthese may pose minimal risk as they often stem from the model's poor\nperformance, resulting in incoherent responses.", "published": "2025-03-17 11:39:44", "link": "http://arxiv.org/abs/2503.13081v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Overview of the NTCIR-18 Automatic Evaluation of LLMs (AEOLLM) Task", "abstract": "In this paper, we provide an overview of the NTCIR-18 Automatic Evaluation of\nLLMs (AEOLLM) task. As large language models (LLMs) grow popular in both\nacademia and industry, how to effectively evaluate the capacity of LLMs becomes\nan increasingly critical but still challenging issue. Existing methods can be\ndivided into two types: manual evaluation, which is expensive, and automatic\nevaluation, which faces many limitations including task format (the majority\nbelong to multiple-choice questions) and evaluation criteria (occupied by\nreference-based metrics). To advance the innovation of automatic evaluation, we\npropose the AEOLLM task which focuses on generative tasks and encourages\nreference-free methods. Besides, we set up diverse subtasks such as dialogue\ngeneration, text expansion, summary generation and non-factoid question\nanswering to comprehensively test different methods. This year, we received 48\nruns from 4 teams in total. This paper will describe the background of the\ntask, the data set, the evaluation measures and the evaluation results,\nrespectively.", "published": "2025-03-17 10:42:34", "link": "http://arxiv.org/abs/2503.13038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Halving transcription time: A fast, user-friendly and GDPR-compliant workflow to create AI-assisted transcripts for content analysis", "abstract": "In qualitative research, data transcription is often labor-intensive and\ntime-consuming. To expedite this process, a workflow utilizing artificial\nintelligence (AI) was developed. This workflow not only enhances transcription\nspeed but also addresses the issue of AI-generated transcripts often lacking\ncompatibility with standard content analysis software. Within this workflow,\nautomatic speech recognition is employed to create initial transcripts from\naudio recordings, which are then formatted to be compatible with content\nanalysis software such as ATLAS.ti or MAXQDA. Empirical data from a study of 12\ninterviews suggests that this workflow can reduce transcription time by up to\n46.2%. Furthermore, by using widely used standard software, this process is\nsuitable for both students and researchers while also being adaptable to a\nvariety of learning, teaching, and research environments. It is also\nparticularly beneficial for non-native speakers. In addition, the workflow is\nGDPR-compliant and facilitates local, offline transcript generation, which is\ncrucial when dealing with sensitive data.", "published": "2025-03-17 10:33:39", "link": "http://arxiv.org/abs/2503.13031v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Relation Inference via Verb Embeddings", "abstract": "CLIP has demonstrated exceptional image-text matching capabilities due to its\ntraining on contrastive learning tasks. Past research has suggested that\nwhereas CLIP effectively matches text to images when the matching can be\nachieved just by matching the text with the objects in the image, CLIP\nstruggles when the matching depends on representing the relationship among the\nobjects in the images (i.e., inferring relations). Previous attempts to address\nthis limitation by training CLIP on relation detection datasets with only\nlinguistic supervision have met with limited success. In this paper, we offer\ninsights and practical methods to advance the field of relation inference from\nimages. This paper approaches the task of creating a model that effectively\ndetects relations among the objects in images by producing text and image\nembeddings that capture relationships through linguistic supervision. To this\nend, we propose Dynamic Relation Inference via Verb Embeddings (DRIVE), which\naugments the COCO dataset, fine-tunes CLIP with hard negatives\nsubject-relation-object triples and corresponding images, and introduces a\nnovel loss function to improve relation detection. Evaluated on multiple\nCLIP-based models, our method significantly improves zero-shot relation\ninference accuracy in both frozen and fine-tuned settings, significantly\noutperforming CLIP and state-of-the-art models while generalizing well on\nunseen data.", "published": "2025-03-17 10:24:27", "link": "http://arxiv.org/abs/2503.13021v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Intra-neuronal attention within language models Relationships between activation and semantics", "abstract": "This study investigates the ability of perceptron-type neurons in language\nmodels to perform intra-neuronal attention; that is, to identify different\nhomogeneous categorical segments within the synthetic thought category they\nencode, based on a segmentation of specific activation zones for the tokens to\nwhich they are particularly responsive. The objective of this work is therefore\nto determine to what extent formal neurons can establish a homomorphic\nrelationship between activation-based and categorical segmentations. The\nresults suggest the existence of such a relationship, albeit tenuous, only at\nthe level of tokens with very high activation levels. This intra-neuronal\nattention subsequently enables categorical restructuring processes at the level\nof neurons in the following layer, thereby contributing to the progressive\nformation of high-level categorical abstractions.", "published": "2025-03-17 09:47:11", "link": "http://arxiv.org/abs/2503.12992v1", "categories": ["cs.AI", "cs.CL", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "A Multi-Stage Framework with Taxonomy-Guided Reasoning for Occupation Classification Using Large Language Models", "abstract": "Automatically annotating job data with standardized occupations from\ntaxonomies, known as occupation classification, is crucial for labor market\nanalysis. However, this task is often hindered by data scarcity and the\nchallenges of manual annotations. While large language models (LLMs) hold\npromise due to their extensive world knowledge and in-context learning\ncapabilities, their effectiveness depends on their knowledge of occupational\ntaxonomies, which remains unclear. In this study, we assess the ability of LLMs\nto generate precise taxonomic entities from taxonomy, highlighting their\nlimitations. To address these challenges, we propose a multi-stage framework\nconsisting of inference, retrieval, and reranking stages, which integrates\ntaxonomy-guided reasoning examples to enhance performance by aligning outputs\nwith taxonomic knowledge. Evaluations on a large-scale dataset show significant\nimprovements in classification accuracy. Furthermore, we demonstrate the\nframework's adaptability for multi-label skill classification. Our results\nindicate that the framework outperforms existing LLM-based methods, offering a\npractical and scalable solution for occupation classification and related tasks\nacross LLMs.", "published": "2025-03-17 09:44:50", "link": "http://arxiv.org/abs/2503.12989v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model", "abstract": "Instruction tuning is widely used to improve a pre-trained Multimodal Large\nLanguage Model (MLLM) by training it on curated task-specific datasets,\nenabling better comprehension of human instructions. However, it is infeasible\nto collect all possible instruction datasets simultaneously in real-world\nscenarios. Thus, enabling MLLM with continual instruction tuning is essential\nfor maintaining their adaptability. However, existing methods often trade off\nmemory efficiency for performance gains, significantly compromising overall\nefficiency. In this paper, we propose a task-specific expansion and\ntask-general fusion framework based on the variations in Centered Kernel\nAlignment (CKA) similarity across different model layers when trained on\ndiverse datasets. Furthermore, we analyze the information leakage present in\nthe existing benchmark and propose a new and more challenging benchmark to\nrationally evaluate the performance of different methods. Comprehensive\nexperiments showcase a significant performance improvement of our method\ncompared to existing state-of-the-art methods. Our code will be public\navailable.", "published": "2025-03-17 08:56:03", "link": "http://arxiv.org/abs/2503.12941v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization", "abstract": "Recent studies generally enhance MLLMs' reasoning capabilities via supervised\nfine-tuning on high-quality chain-of-thought reasoning data, which often leads\nmodels to merely imitate successful reasoning paths without understanding what\nthe wrong reasoning paths are. In this work, we aim to enhance the MLLMs'\nreasoning ability beyond passively imitating positive reasoning paths. To this\nend, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new\nonline reinforcement learning framework that enables MLLMs to self-improve\nreasoning ability via simple, effective and dense step-wise rewarding.\nSpecifically, StepGRPO introduces two novel rule-based reasoning rewards:\nStep-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity\nReward (StepRVR). StepRAR rewards the reasoning paths that contain necessary\nintermediate reasoning steps via a soft key-step matching technique, while\nStepRAR rewards reasoning paths that follow a well-structured and logically\nconsistent reasoning process through a reasoning completeness and logic\nevaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series\nof MLLMs with outstanding capabilities in step-by-step reasoning. Extensive\nexperiments over 8 benchmarks demonstrate the superiority of our methods.", "published": "2025-03-17 08:51:44", "link": "http://arxiv.org/abs/2503.12937v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ML-SpecQD: Multi-Level Speculative Decoding with Quantized Drafts", "abstract": "Speculative decoding (SD) has emerged as a method to accelerate LLM inference\nwithout sacrificing any accuracy over the 16-bit model inference. In a typical\nSD setup, the idea is to use a full-precision, small, fast model as \"draft\" to\ngenerate the next few tokens and use the \"target\" large model to verify the\ndraft-generated tokens. The efficacy of this method heavily relies on the\nacceptance ratio of the draft-generated tokens and the relative token\nthroughput of the draft versus the target model. Nevertheless, an efficient SD\npipeline requires pre-training and aligning the draft model to the target\nmodel, making it impractical for LLM inference in a plug-and-play fashion. In\nthis work, we propose using MXFP4 models as drafts in a plug-and-play fashion\nsince the MXFP4 Weight-Only-Quantization (WOQ) merely direct-casts the BF16\ntarget model weights to MXFP4. In practice, our plug-and-play solution gives\nspeedups up to 2x over the BF16 baseline. Then we pursue an opportunity for\nfurther acceleration: the MXFP4 draft token generation itself can be\naccelerated via speculative decoding by using yet another smaller draft. We\ncall our method ML-SpecQD: Multi-Level Speculative Decoding with Quantized\nDrafts since it recursively applies speculation for accelerating the\ndraft-token generation. Combining Multi-Level Speculative Decoding with MXFP4\nQuantized Drafts we outperform state-of-the-art speculative decoding, yielding\nspeedups up to 2.72x over the BF16 baseline.", "published": "2025-03-17 08:38:45", "link": "http://arxiv.org/abs/2503.13565v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ThinkPatterns-21k: A Systematic Study on the Impact of Thinking Patterns in LLMs", "abstract": "Large language models (LLMs) have demonstrated enhanced performance through\nthe \\textit{Thinking then Responding} paradigm, where models generate internal\nthoughts before final responses (aka, System 2 thinking). However, existing\nresearch lacks a systematic understanding of the mechanisms underlying how\nthinking patterns affect performance across model sizes. In this work, we\nconduct a comprehensive analysis of the impact of various thinking types on\nmodel performance and introduce ThinkPatterns-21k, a curated dataset comprising\n21k instruction-response pairs (QA) collected from existing\ninstruction-following datasets with five thinking types. For each pair, we\naugment it with five distinct internal thinking patterns: one unstructured\nthinking (monologue) and four structured variants (decomposition, self-ask,\nself-debate and self-critic), while maintaining the same instruction and\nresponse. Through extensive evaluation across different model sizes (3B-32B\nparameters), we have two key findings: (1) smaller models (<30B parameters) can\nbenefit from most of structured thinking patterns, while larger models (32B)\nwith structured thinking like decomposition would degrade performance and (2)\nunstructured monologue demonstrates broad effectiveness across different model\nsizes. Finally, we released all of our datasets, checkpoints, training logs of\ndiverse thinking patterns to reproducibility, aiming to facilitate further\nresearch in this direction.", "published": "2025-03-17 08:29:04", "link": "http://arxiv.org/abs/2503.12918v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HICD: Hallucination-Inducing via Attention Dispersion for Contrastive Decoding to Mitigate Hallucinations in Large Language Models", "abstract": "Large Language Models (LLMs) often generate hallucinations, producing outputs\nthat are contextually inaccurate or factually incorrect. We introduce HICD, a\nnovel method designed to induce hallucinations for contrastive decoding to\nmitigate hallucinations. Unlike existing contrastive decoding methods, HICD\nselects attention heads crucial to the model's prediction as inducing heads,\nthen induces hallucinations by dispersing attention of these inducing heads and\ncompares the hallucinated outputs with the original outputs to obtain the final\nresult. Our approach significantly improves performance on tasks requiring\ncontextual faithfulness, such as context completion, reading comprehension, and\nquestion answering. It also improves factuality in tasks requiring accurate\nknowledge recall. We demonstrate that our inducing heads selection and\nattention dispersion method leads to more \"contrast-effective\" hallucinations\nfor contrastive decoding, outperforming other hallucination-inducing methods.\nOur findings provide a promising strategy for reducing hallucinations by\ninducing hallucinations in a controlled manner, enhancing the performance of\nLLMs in a wide range of tasks.", "published": "2025-03-17 08:17:28", "link": "http://arxiv.org/abs/2503.12908v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MES-RAG: Bringing Multi-modal, Entity-Storage, and Secure Enhancements to RAG", "abstract": "Retrieval-Augmented Generation (RAG) improves Large Language Models (LLMs) by\nusing external knowledge, but it struggles with precise entity information\nretrieval. In this paper, we proposed MES-RAG framework, which enhances\nentity-specific query handling and provides accurate, secure, and consistent\nresponses. MES-RAG introduces proactive security measures that ensure system\nintegrity by applying protections prior to data access. Additionally, the\nsystem supports real-time multi-modal outputs, including text, images, audio,\nand video, seamlessly integrating into existing RAG architectures. Experimental\nresults demonstrate that MES-RAG significantly improves both accuracy and\nrecall, highlighting its effectiveness in advancing the security and utility of\nquestion-answering, increasing accuracy to 0.83 (+0.25) on targeted task. Our\ncode and data are available at https://github.com/wpydcr/MES-RAG.", "published": "2025-03-17 08:09:42", "link": "http://arxiv.org/abs/2503.13563v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation", "abstract": "Language Models (LMs) are widely used in software engineering for code\ngeneration, but they may produce code with errors. Rather than repairing the\ngenerated code, an alternative way is to address the underlying failures of\nmodels. LM repair offers a lightweight solution to this challenge: it requires\nminimal data, reduces computational costs, and reduces the side effects. Unlike\nretraining, LM repair focuses on applying tailored updates to targeted neurons,\nmaking it ideal for scenarios with limited resources, high-performance demands,\nor strict safety requirements. In this paper, we propose \\ul{S}emantic\n\\ul{T}argeting for \\ul{A}nalytical \\ul{R}epair (\\textsc{STAR}), a pioneering\nand novel semantic-based optimization approach for repairing LLMs.\n\\textsc{STAR} realizes main operations in LM repair methods in an optimization\nprocess, including locating ``buggy neurons'', solving ``neuron patches'', and\npatching ``buggy neurons''. Correspondingly, it computes the deltas of weight\nmatrix as the prior information to guide optimization; and attributes the\ntargeted layers and neurons leveraging statistical insights. The neuron patches\nare computed with a solid semantic-based analytical formula, which directly\nbridges the changes to logits with the deltas of neurons, by steering latent\nrepresentations. Compared to the prior work of LM repair (\\textsc{MINT}) and\noptimization methods (\\textsc{SGD}), \\textsc{STAR} integrates their strengths\nwhile mitigating their limitations. \\textsc{STAR} supports solving multiple\nfailures together, significantly improving the usefulness. Evaluated on three\ncode generation tasks using popular code LMs, \\textsc{STAR} demonstrates\nsuperior effectiveness. Additionally, \\textsc{STAR} exhibits better efficiency.\nIn terms of side effects, namely the balance between generalization and\nspecificity, \\textsc{STAR} outperforms prior work by a significant margin.", "published": "2025-03-17 07:59:42", "link": "http://arxiv.org/abs/2503.12899v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "DAPI: Domain Adaptive Toxicity Probe Vector Intervention for Fine-Grained Detoxification", "abstract": "There have been attempts to utilize linear probe for detoxification, with\nexisting studies relying on a single toxicity probe vector to reduce toxicity.\nHowever, toxicity can be fine-grained into various subcategories, making it\ndifficult to remove certain types of toxicity by using a single toxicity probe\nvector. To address this limitation, we propose a category-specific toxicity\nprobe vector approach. First, we train multiple toxicity probe vectors for\ndifferent toxicity categories. During generation, we dynamically select the\nmost relevant toxicity probe vector based on the current context. Finally, the\nselected vector is dynamically scaled and subtracted from model. Our method\nsuccessfully mitigated toxicity from categories that the single probe vector\napproach failed to detoxify. Experiments demonstrate that our approach achieves\nup to a 78.52% reduction in toxicity on the evaluation dataset, while fluency\nremains nearly unchanged, with only a 0.052% drop compared to the unsteered\nmodel.", "published": "2025-03-17 07:25:32", "link": "http://arxiv.org/abs/2503.12882v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "nvBench 2.0: A Benchmark for Natural Language to Visualization under Ambiguity", "abstract": "Natural Language to Visualization (NL2VIS) enables users to create\nvisualizations from natural language queries, making data insights more\naccessible. However, NL2VIS faces challenges in interpreting ambiguous queries,\nas users often express their visualization needs in imprecise language. To\naddress this challenge, we introduce nvBench 2.0, a new benchmark designed to\nevaluate NL2VIS systems in scenarios involving ambiguous queries. nvBench 2.0\nincludes 7,878 natural language queries and 24,076 corresponding\nvisualizations, derived from 780 tables across 153 domains. It is built using a\ncontrolled ambiguity-injection pipeline that generates ambiguous queries\nthrough a reverse-generation workflow. By starting with unambiguous seed\nvisualizations and selectively injecting ambiguities, the pipeline yields\nmultiple valid interpretations for each query, with each ambiguous query\ntraceable to its corresponding visualization through step-wise reasoning paths.\nWe evaluate various Large Language Models (LLMs) on their ability to perform\nambiguous NL2VIS tasks using nvBench 2.0. We also propose Step-NL2VIS, an\nLLM-based model trained on nvBench 2.0, which enhances performance in ambiguous\nscenarios through step-wise preference optimization. Our results show that\nStep-NL2VIS outperforms all baselines, setting a new state-of-the-art for\nambiguous NL2VIS tasks.", "published": "2025-03-17 07:20:11", "link": "http://arxiv.org/abs/2503.12880v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Harnessing Test-time Adaptation for NLU tasks Involving Dialects of English", "abstract": "Test-time adaptation (TTA) is an excellent method which helps generalize\nmodels across domains, tasks, and distributions without the use of labeled\ndatasets. Thus, TTA is very useful in natural language processing (NLP) in the\ndialectal setting, since oftentimes, models are trained on Standard American\nEnglish (SAE), evaluated on Indian English or Nigerian English, of which\ndistribution differs significantly from the former. This is especially useful\nsince dialectal datasets are scarce. In this paper, we explore one of the most\nfamous TTA techniques, SHOT, in dialectal NLP. We finetune and evaluate SHOT on\ndifferent combinations of dialectal GLUE. Our findings show that SHOT is a\nviable technique when labeled datasets are unavailable. We also theoretically\npropose the concept of dialectal gap and show that it has a positive\ncorrelation with the effectiveness of SHOT. We also find that in many cases,\nfinetuning on SAE yields higher performance than finetuning on dialectal data.\nOur code is available at https://github.com/dukenguyenxyz/dialect-adaptation", "published": "2025-03-17 06:40:06", "link": "http://arxiv.org/abs/2503.12858v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VITED: Video Temporal Evidence Distillation", "abstract": "We investigate complex video question answering via chain-of-evidence\nreasoning -- identifying sequences of temporal spans from multiple relevant\nparts of the video, together with visual evidence within them. Existing models\nstruggle with multi-step reasoning as they uniformly sample a fixed number of\nframes, which can miss critical evidence distributed nonuniformly throughout\nthe video. Moreover, they lack the ability to temporally localize such evidence\nin the broader context of the full video, which is required for answering\ncomplex questions. We propose a framework to enhance existing VideoQA datasets\nwith evidence reasoning chains, automatically constructed by searching for\noptimal intervals of interest in the video with supporting evidence, that\nmaximizes the likelihood of answering a given question. We train our model\n(VITED) to generate these evidence chains directly, enabling it to both\nlocalize evidence windows as well as perform multi-step reasoning across them\nin long-form video content. We show the value of our evidence-distilled models\non a suite of long video QA benchmarks where we outperform state-of-the-art\napproaches that lack evidence reasoning capabilities.", "published": "2025-03-17 06:30:02", "link": "http://arxiv.org/abs/2503.12855v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing LLM Reasoning with Iterative DPO: A Comprehensive Empirical Investigation", "abstract": "Recent advancements in post-training methodologies for large language models\n(LLMs) have highlighted reinforcement learning (RL) as a critical component for\nenhancing reasoning. However, the substantial computational costs associated\nwith RL-based approaches have led to growing interest in alternative paradigms,\nsuch as Direct Preference Optimization (DPO). In this study, we investigate the\neffectiveness of DPO in facilitating self-improvement for LLMs through\niterative preference-based learning. We demonstrate that a single round of DPO\nwith coarse filtering significantly enhances mathematical reasoning\nperformance, particularly for strong base model. Furthermore, we design an\niterative enhancement framework for both the generator and the reward model\n(RM), enabling their mutual improvement through online interaction across\nmultiple rounds of DPO. Finally, with simple verifiable rewards, our model\nDPO-VP achieves RL-level performance with significantly lower computational\noverhead. These findings highlight DPO as a scalable and cost-effective\nalternative to RL, offering a practical solution for enhancing LLM reasoning in\nresource-constrained situations.", "published": "2025-03-17 06:28:25", "link": "http://arxiv.org/abs/2503.12854v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modelling Child Learning and Parsing of Long-range Syntactic Dependencies", "abstract": "This work develops a probabilistic child language acquisition model to learn\na range of linguistic phenonmena, most notably long-range syntactic\ndependencies of the sort found in object wh-questions, among other\nconstructions. The model is trained on a corpus of real child-directed speech,\nwhere each utterance is paired with a logical form as a meaning representation.\nIt then learns both word meanings and language-specific syntax simultaneously.\nAfter training, the model can deduce the correct parse tree and word meanings\nfor a given utterance-meaning pair, and can infer the meaning if given only the\nutterance. The successful modelling of long-range dependencies is theoretically\nimportant because it exploits aspects of the model that are, in general,\ntrans-context-free.", "published": "2025-03-17 05:24:39", "link": "http://arxiv.org/abs/2503.12832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules", "abstract": "Training large models is both resource-intensive and time-consuming, making\nit crucial to understand the quantitative relationship between model\nperformance and hyperparameters. In this paper, we present an empirical law\nthat describes how the pretraining loss of large language models evolves under\ndifferent learning rate schedules, such as constant, cosine, and step decay\nschedules. Our proposed law takes a multi-power form, combining a power law\nbased on the sum of learning rates and additional power laws to account for a\nloss reduction effect induced by learning rate decay. We extensively validate\nthis law on various model sizes and architectures, and demonstrate that after\nfitting on a few learning rate schedules, the law accurately predicts the loss\ncurves for unseen schedules of different shapes and horizons. Moreover, by\nminimizing the predicted final pretraining loss across learning rate schedules,\nwe are able to find a schedule that outperforms the widely used cosine learning\nrate schedule. Interestingly, this automatically discovered schedule bears some\nresemblance to the recently proposed Warmup-Stable-Decay (WSD) schedule (Hu et\nal, 2024) but achieves a slightly lower final loss. We believe these results\ncould offer valuable insights for understanding the dynamics of pretraining and\ndesigning learning rate schedules to improve efficiency.", "published": "2025-03-17 04:36:45", "link": "http://arxiv.org/abs/2503.12811v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Leveraging Deep Neural Networks for Aspect-Based Sentiment Classification", "abstract": "Aspect-based sentiment analysis seeks to determine sentiment with a high\nlevel of detail. While graph convolutional networks (GCNs) are commonly used\nfor extracting sentiment features, their straightforward use in syntactic\nfeature extraction can lead to a loss of crucial information. This paper\npresents a novel edge-enhanced GCN, called EEGCN, which improves performance by\npreserving feature integrity as it processes syntactic graphs. We incorporate a\nbidirectional long short-term memory (Bi-LSTM) network alongside a\nself-attention-based transformer for effective text encoding, ensuring the\nretention of long-range dependencies. A bidirectional GCN (Bi-GCN) with message\npassing then captures the relationships between entities, while an\naspect-specific masking technique removes extraneous information. Extensive\nevaluations and ablation studies on four benchmark datasets show that EEGCN\nsignificantly enhances aspect-based sentiment analysis, overcoming issues with\nsyntactic feature extraction and advancing the field's methodologies.", "published": "2025-03-17 04:19:20", "link": "http://arxiv.org/abs/2503.12803v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DeepPerception: Advancing R1-like Cognitive Visual Perception in MLLMs for Knowledge-Intensive Visual Grounding", "abstract": "Human experts excel at fine-grained visual discrimination by leveraging\ndomain knowledge to refine perceptual features, a capability that remains\nunderdeveloped in current Multimodal Large Language Models (MLLMs). Despite\npossessing vast expert-level knowledge, MLLMs struggle to integrate reasoning\ninto visual perception, often generating direct responses without deeper\nanalysis. To bridge this gap, we introduce knowledge-intensive visual grounding\n(KVG), a novel visual grounding task that requires both fine-grained perception\nand domain-specific knowledge integration. To address the challenges of KVG, we\npropose DeepPerception, an MLLM enhanced with cognitive visual perception\ncapabilities. Our approach consists of (1) an automated data synthesis pipeline\nthat generates high-quality, knowledge-aligned training samples, and (2) a\ntwo-stage training framework combining supervised fine-tuning for cognitive\nreasoning scaffolding and reinforcement learning to optimize\nperception-cognition synergy. To benchmark performance, we introduce KVG-Bench\na comprehensive dataset spanning 10 domains with 1.3K manually curated test\ncases. Experimental results demonstrate that DeepPerception significantly\noutperforms direct fine-tuning, achieving +8.08\\% accuracy improvements on\nKVG-Bench and exhibiting +4.60\\% superior cross-domain generalization over\nbaseline approaches. Our findings highlight the importance of integrating\ncognitive processes into MLLMs for human-like visual perception and open new\ndirections for multimodal reasoning research. The data, codes, and models are\nreleased at https://github.com/thunlp/DeepPerception.", "published": "2025-03-17 04:06:34", "link": "http://arxiv.org/abs/2503.12797v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Reinforcement Learning-Driven Transformer GAN for Molecular Generation", "abstract": "Generating molecules with desired chemical properties presents a critical\nchallenge in fields such as chemical synthesis and drug discovery. Recent\nadvancements in artificial intelligence (AI) and deep learning have\nsignificantly contributed to data-driven molecular generation. However,\nchallenges persist due to the inherent sensitivity of simplified molecular\ninput line entry system (SMILES) representations and the difficulties in\napplying generative adversarial networks (GANs) to discrete data. This study\nintroduces RL-MolGAN, a novel Transformer-based discrete GAN framework designed\nto address these challenges. Unlike traditional Transformer architectures,\nRL-MolGAN utilizes a first-decoder-then-encoder structure, facilitating the\ngeneration of drug-like molecules from both $de~novo$ and scaffold-based\ndesigns. In addition, RL-MolGAN integrates reinforcement learning (RL) and\nMonte Carlo tree search (MCTS) techniques to enhance the stability of GAN\ntraining and optimize the chemical properties of the generated molecules. To\nfurther improve the model's performance, RL-MolWGAN, an extension of RL-MolGAN,\nincorporates Wasserstein distance and mini-batch discrimination, which together\nenhance the stability of the GAN. Experimental results on two widely used\nmolecular datasets, QM9 and ZINC, validate the effectiveness of our models in\ngenerating high-quality molecular structures with diverse and desirable\nchemical properties.", "published": "2025-03-17 04:06:10", "link": "http://arxiv.org/abs/2503.12796v1", "categories": ["cs.LG", "cs.CL", "physics.chem-ph"], "primary_category": "cs.LG"}
{"title": "RAG-RL: Advancing Retrieval-Augmented Generation via RL and Curriculum Learning", "abstract": "Recent research highlights the challenges retrieval models face in retrieving\nuseful contexts and the limitations of generation models in effectively\nutilizing those contexts in retrieval-augmented generation (RAG) settings. To\naddress these challenges, we introduce RAG-RL, the first reasoning language\nmodel (RLM) specifically trained for RAG. RAG-RL demonstrates that stronger\nanswer generation models can identify relevant contexts within larger sets of\nretrieved information -- thereby alleviating the burden on retrievers -- while\nalso being able to utilize those contexts more effectively. Moreover, we show\nthat curriculum design in the reinforcement learning (RL) post-training process\nis a powerful approach to enhancing model performance. We benchmark our method\non two open-domain question-answering datasets and achieve state-of-the-art\nresults, surpassing previous SOTA generative reader models. In addition, we\noffers empirical insights into various curriculum learning strategies,\nproviding a deeper understanding of their impact on model performance.", "published": "2025-03-17 02:53:42", "link": "http://arxiv.org/abs/2503.12759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TNCSE: Tensor's Norm Constraints for Unsupervised Contrastive Learning of Sentence Embeddings", "abstract": "Unsupervised sentence embedding representation has become a hot research\ntopic in natural language processing. As a tensor, sentence embedding has two\ncritical properties: direction and norm. Existing works have been limited to\nconstraining only the orientation of the samples' representations while\nignoring the features of their module lengths. To address this issue, we\npropose a new training objective that optimizes the training of unsupervised\ncontrastive learning by constraining the module length features between\npositive samples. We combine the training objective of Tensor's Norm\nConstraints with ensemble learning to propose a new Sentence Embedding\nrepresentation framework, TNCSE. We evaluate seven semantic text similarity\ntasks, and the results show that TNCSE and derived models are the current\nstate-of-the-art approach; in addition, we conduct extensive zero-shot\nevaluations, and the results show that TNCSE outperforms other baselines.", "published": "2025-03-17 02:14:42", "link": "http://arxiv.org/abs/2503.12739v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Not All Personas Are Worth It: Culture-Reflective Persona Data Augmentation", "abstract": "Incorporating personas into conversational AI models is crucial for achieving\nauthentic and engaging interactions. However, the cultural diversity and\nadaptability of existing persona datasets is often overlooked, reducing their\nefficacy in building culturally aware AI systems. To address this issue, we\npropose a two-step pipeline for generating culture-specific personas and\nintroduce KoPersona, a dataset comprising 200,000 personas designed to capture\nKorean cultural values, behaviors, and social nuances. A comprehensive\nevaluation through various metrics validates the quality of KoPersona and its\nrelevance to Korean culture. This work not only contributes to persona-based\nresearch, but also establishes a scalable approach for creating culturally\nrelevant personas adaptable to various languages and cultural contexts.", "published": "2025-03-17 01:23:57", "link": "http://arxiv.org/abs/2503.16520v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying Cooperative Personalities in Multi-agent Contexts through Personality Steering with Representation Engineering", "abstract": "As Large Language Models (LLMs) gain autonomous capabilities, their\ncoordination in multi-agent settings becomes increasingly important. However,\nthey often struggle with cooperation, leading to suboptimal outcomes. Inspired\nby Axelrod's Iterated Prisoner's Dilemma (IPD) tournaments, we explore how\npersonality traits influence LLM cooperation. Using representation engineering,\nwe steer Big Five traits (e.g., Agreeableness, Conscientiousness) in LLMs and\nanalyze their impact on IPD decision-making. Our results show that higher\nAgreeableness and Conscientiousness improve cooperation but increase\nsusceptibility to exploitation, highlighting both the potential and limitations\nof personality-based steering for aligning AI agents.", "published": "2025-03-17 01:21:54", "link": "http://arxiv.org/abs/2503.12722v1", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Pareidolic Illusions of Meaning: ChatGPT, Pseudolaw and the Triumph of Form over Substance", "abstract": "The early 2020s has seen the rise of two strange and potentially quite\nimpactful social phenomena, namely pseudolaw, where users rely upon pseudolegal\narguments that mimic the form and ritual of legal argumentation but\nfundamentally distort the content of law, and generative AI/LLMs, which\ngenerate content that uses probabilistic calculations to create outputs that\nlook like human generated text. This article argues that the juxtaposition of\nthe two phenomena helps to reveal that they both share two fundamental traits\nas both elevate form and appearance over substance and content, and users of\nboth routinely mistake the form for the substance. In drawing upon legal\ntheory, computer science, linguistics and cognitive psychology, the article\nargues that both phenomena rely upon creating illusions of meaning that users\nmistake for the underlying primary phenomenon. I then explore four implications\nof this conception of both phenomena. Firstly, both rely on human tendencies of\nconceptual pareidolia resulting in the erroneous perception of meaningful\nlinguistic legal patterns from nebulous inputs. Secondly, both rely upon the\nconfidence heuristic, the human cognitive bias for treating confidence as a\nproxy for competence. Thirdly, both succeed when the primary concern is with\nthe form of the output and not its content. Fourthly, both rely heavily upon\nthe magical thinking of users and the desire for the promise of the approach to\nbe real. The article argues that the legal context helps to reveal a solution\nfor the problems caused by both phenomena as it is only where users possess\nsufficient legal and technological literacy that it becomes possible to reveal\nto them the illusionary nature of the phenomena.", "published": "2025-03-17 00:15:41", "link": "http://arxiv.org/abs/2503.13556v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Exercises in Iterational Asymptotics III", "abstract": "The nonlinear recurrences we consider here include simple continued fractions\nfor the Golden & Silver means and a parametric family of cubics in connection\nwith Abel's functional equation.", "published": "2025-03-17 17:06:00", "link": "http://arxiv.org/abs/2503.13378v1", "categories": ["math.NT", "cs.DM", "math.CO", "11B37 (Primary) 26A18, 39B22, 39-08, 41A60, 65D20 (Secondary)"], "primary_category": "math.NT"}
{"title": "The Power of Amortization on Scheduling with Explorable Uncertainty", "abstract": "In this work, we study a scheduling problem with explorable uncertainty. Each\njob comes with an upper limit of its processing time, which could be\npotentially reduced by testing the job, which also takes time. The objective is\nto schedule all jobs on a single machine with a minimum total completion time.\nThe challenge lies in deciding which jobs to test and the order of\ntesting/processing jobs.\n  The online problem was first introduced with unit testing time and later\ngeneralized to variable testing times. For this general setting, the upper\nbounds of the competitive ratio are shown to be $4$ and $3.3794$ for\ndeterministic and randomized online algorithms; while the lower bounds for unit\ntesting time stands, which are $1.8546$ (deterministic) and $1.6257$\n(randomized).\n  We continue the study on variable testing times setting. We first enhance the\nanalysis framework and improve the competitive ratio of the deterministic\nalgorithm from $4$ to $1+\\sqrt{2} \\approx 2.4143$. Using the new analysis\nframework, we propose a new deterministic algorithm that further improves the\ncompetitive ratio to $2.316513$. The new framework also enables us to develop a\nrandomized algorithm improving the expected competitive ratio from $3.3794$ to\n$2.152271$.", "published": "2025-03-17 16:42:52", "link": "http://arxiv.org/abs/2503.13357v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Lower bounding the MaxCut of high girth 3-regular graphs using the QAOA", "abstract": "We study MaxCut on 3-regular graphs of minimum girth $g$ for various $g$'s.\nWe obtain new lower bounds on the maximum cut achievable in such graphs by\nanalyzing the Quantum Approximate Optimization Algorithm (QAOA). For $g \\geq\n16$, at depth $p \\geq 7$, the QAOA improves on previously known lower bounds.\nOur bounds are established through classical numerical analysis of the QAOA's\nexpected performance. This analysis does not produce the actual cuts but\nestablishes their existence. When implemented on a quantum computer, the QAOA\nprovides an efficient algorithm for finding such cuts, using a constant-depth\nquantum circuit. To our knowledge, this gives an exponential speedup over the\nbest known classical algorithm guaranteed to achieve cuts of this size on\ngraphs of this girth. We also apply the QAOA to the Maximum Independent Set\nproblem on the same class of graphs.", "published": "2025-03-17 03:58:43", "link": "http://arxiv.org/abs/2503.12789v1", "categories": ["quant-ph", "cs.DM", "math.CO"], "primary_category": "quant-ph"}
{"title": "Rendering Transparency to Ranking in Educational Assessment via Bayesian Comparative Judgement", "abstract": "Ensuring transparency in educational assessment is increasingly critical,\nparticularly post-pandemic, as demand grows for fairer and more reliable\nevaluation methods. Comparative Judgement (CJ) offers a promising alternative\nto traditional assessments, yet concerns remain about its perceived opacity.\nThis paper examines how Bayesian Comparative Judgement (BCJ) enhances\ntransparency by integrating prior information into the judgement process,\nproviding a structured, data-driven approach that improves interpretability and\naccountability.\n  BCJ assigns probabilities to judgement outcomes, offering quantifiable\nmeasures of uncertainty and deeper insights into decision confidence. By\nsystematically tracking how prior data and successive judgements inform final\nrankings, BCJ clarifies the assessment process and helps identify assessor\ndisagreements. Multi-criteria BCJ extends this by evaluating multiple learning\noutcomes (LOs) independently, preserving the richness of CJ while producing\ntransparent, granular rankings aligned with specific assessment goals. It also\nenables a holistic ranking derived from individual LOs, ensuring comprehensive\nevaluations without compromising detailed feedback.\n  Using a real higher education dataset with professional markers in the UK, we\ndemonstrate BCJ's quantitative rigour and ability to clarify ranking\nrationales. Through qualitative analysis and discussions with experienced CJ\npractitioners, we explore its effectiveness in contexts where transparency is\ncrucial, such as high-stakes national assessments. We highlight the benefits\nand limitations of BCJ, offering insights into its real-world application\nacross various educational settings.", "published": "2025-03-17 20:56:55", "link": "http://arxiv.org/abs/2503.15549v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.IR"], "primary_category": "cs.CY"}
{"title": "Knowledge-Aware Iterative Retrieval for Multi-Agent Systems", "abstract": "We introduce a novel large language model (LLM)-driven agent framework, which\niteratively refines queries and filters contextual evidence by leveraging\ndynamically evolving knowledge. A defining feature of the system is its\ndecoupling of external sources from an internal knowledge cache that is\nprogressively updated to guide both query generation and evidence selection.\nThis design mitigates bias-reinforcement loops and enables dynamic, trackable\nsearch exploration paths, thereby optimizing the trade-off between exploring\ndiverse information and maintaining accuracy through autonomous agent\ndecision-making. Our approach is evaluated on a broad range of open-domain\nquestion answering benchmarks, including multi-step tasks that mirror\nreal-world scenarios where integrating information from multiple sources is\ncritical, especially given the vulnerabilities of LLMs that lack explicit\nreasoning or planning capabilities. The results show that the proposed system\nnot only outperforms single-step baselines regardless of task difficulty but\nalso, compared to conventional iterative retrieval methods, demonstrates\npronounced advantages in complex tasks through precise evidence-based reasoning\nand enhanced efficiency. The proposed system supports both competitive and\ncollaborative sharing of updated context, enabling multi-agent extension. The\nbenefits of multi-agent configurations become especially prominent as task\ndifficulty increases. The number of convergence steps scales with task\ndifficulty, suggesting cost-effective scalability.", "published": "2025-03-17 15:27:02", "link": "http://arxiv.org/abs/2503.13275v2", "categories": ["cs.AI", "cs.IR", "I.2.0; I.2.7; I.2.11; H.3.3"], "primary_category": "cs.AI"}
{"title": "Federated Mixture-of-Expert for Non-Overlapped Cross-Domain Sequential Recommendation", "abstract": "In the real world, users always have multiple interests while surfing\ndifferent services to enrich their daily lives, e.g., watching hot short\nvideos/live streamings. To describe user interests precisely for a better user\nexperience, the recent literature proposes cross-domain techniques by\ntransferring the other related services (a.k.a. domain) knowledge to enhance\nthe accuracy of target service prediction. In practice, naive cross-domain\ntechniques typically require there exist some overlapped users, and sharing\noverall information across domains, including user historical logs, user/item\nembeddings, and model parameter checkpoints. Nevertheless, other domain's\nuser-side historical logs and embeddings are not always available in real-world\nRecSys designing, since users may be totally non-overlapped across domains, or\nthe privacy-preserving policy limits the personalized information sharing\nacross domains. Thereby, a challenging but valuable problem is raised: How to\nempower target domain prediction accuracy by utilizing the other domain model\nparameters checkpoints only? To answer the question, we propose the FMoE-CDSR,\nwhich explores the non-overlapped cross-domain sequential recommendation\nscenario from the federated learning perspective.", "published": "2025-03-17 15:12:37", "link": "http://arxiv.org/abs/2503.13254v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Disentangling the Power Dynamics in Participatory Data Physicalisation", "abstract": "Participatory data physicalisation (PDP) is recognised for its potential to\nsupport data-driven decisions among stakeholders who collaboratively construct\nphysical elements into commonly insightful visualisations. Like all\nparticipatory processes, PDP is however influenced by underlying power dynamics\nthat might lead to issues regarding extractive participation, marginalisation,\nor exclusion, among others. We first identified the decisions behind these\npower dynamics by developing an ontology that synthesises critical theoretical\ninsights from both visualisation and participatory design research, which were\nthen systematically applied unto a representative corpus of 23 PDP artefacts.\nBy revealing how shared decisions are guided by different agendas, this paper\npresents three contributions: 1) a cross-disciplinary ontology that facilitates\nthe systematic analysis of existing and novel PDP artefacts and processes;\nwhich leads to 2) six PDP agendas that reflect the key power dynamics in\ncurrent PDP practice, revealing the diversity of orientations towards\nstakeholder participation in PDP practice; and 3) a set of critical\nconsiderations that should guide how power dynamics can be balanced, such as by\nreflecting on how issues are represented, data is contextualised, participants\nexpress their meanings, and how participants can dissent with flexible artefact\nconstruction. Consequently, this study advances a feminist research agenda by\nguiding researchers and practitioners in openly reflecting on and sharing\nresponsibilities in data physicalisation and participatory data visualisation.", "published": "2025-03-17 10:22:26", "link": "http://arxiv.org/abs/2503.13018v1", "categories": ["cs.HC", "cs.IR"], "primary_category": "cs.HC"}
{"title": "General Molecular Communication Model in Multi-Layered Spherical Channels", "abstract": "Spherical multi-layered structures are prevalent in numerous biological\nsystems and engineered applications, including tumor spheroids, layered\ntissues, and multi-shell nanoparticles for targeted drug delivery. Despite\ntheir widespread occurrence, there remains a gap in modeling particle\npropagation through these complex structures from a molecular communication\n(MC) perspective. This paper introduces a generalized analytical framework for\nmodeling diffusion-based molecular communication in multi-layered spherical\nenvironments. The framework is capable of supporting an arbitrary number of\nlayers and flexible transmitter-receiver positioning. As an example, the\ndetailed formulation is presented for the three-layer sphere, which is\nparticularly relevant for different biological models such as tumor spheroids.\nThe analytical results are validated using particle-based simulation (PBS) in\nscenarios that have short inter-layer distances. The findings reveal that the\ncharacteristics of each layer significantly impact molecule propagation\nthroughout the entire structure, making their consideration crucial for\ndesigning targeted therapies and optimizing drug delivery systems.", "published": "2025-03-17 21:48:40", "link": "http://arxiv.org/abs/2503.13738v1", "categories": ["cs.IT", "math.IT", "q-bio.CB"], "primary_category": "cs.IT"}
{"title": "Causal Emergence 2.0: Quantifying emergent complexity", "abstract": "Complex systems can be described at myriad different scales, and their causal\nworkings often have multiscale structure (e.g., a computer can be described at\nthe microscale of its hardware circuitry, the mesoscale of its machine code,\nand the macroscale of its operating system). While scientists study and model\nsystems across the full hierarchy of their scales, from microphysics to\nmacroeconomics, there is debate about what the macroscales of systems can\npossibly add beyond mere compression. To resolve this longstanding issue, here\na new theory of emergence is introduced wherein the different scales of a\nsystem are treated like slices of a higher-dimensional object. The theory can\ndistinguish which of these scales possess unique causal contributions, and\nwhich are not causally relevant. Constructed from an axiomatic notion of\ncausation, the theory's application is demonstrated in coarse-grains of Markov\nchains. It identifies all cases of macroscale causation: instances where\nreduction to a microscale is possible, yet lossy about causation. Furthermore,\nthe theory posits a causal apportioning schema that calculates the causal\ncontribution of each scale, showing what each uniquely adds. Finally, it\nreveals a novel measure of emergent complexity: how widely distributed a\nsystem's causal workings are across its hierarchy of scales.", "published": "2025-03-17 17:28:46", "link": "http://arxiv.org/abs/2503.13395v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Error bounds for composite quantum hypothesis testing and a new characterization of the weighted Kubo-Ando geometric means", "abstract": "The optimal error exponents of binary composite i.i.d. state discrimination\nare trivially bounded by the worst-case pairwise exponents of discriminating\nindividual elements of the sets representing the two hypotheses, and in the\nfinite-dimensional classical case, these bounds in fact give exact single-copy\nexpressions for the error exponents. In contrast, in the non-commutative case,\nthe optimal exponents are only known to be expressible in terms of regularized\ndivergences, resulting in formulas that, while conceptually relevant,\npractically not very useful. In this paper, we develop further an approach\ninitiated in [Mosonyi, Szil\\'agyi, Weiner, IEEE Trans. Inf. Th.\n68(2):1032--1067, 2022] to give improved single-copy bounds on the error\nexponents by comparing not only individual states from the two hypotheses, but\nalso various unnormalized positive semi-definite operators associated to them.\nHere, we show a number of equivalent characterizations of such operators giving\nvalid bounds, and show that in the commutative case, considering weighted\ngeometric means of the states, and in the case of two states per hypothesis,\nconsidering weighted Kubo-Ando geometric means, are optimal for this approach.\nAs a result, we give a new characterization of the weighted Kubo-Ando geometric\nmeans as the only $2$-variable operator geometric means that are block\nadditive, tensor multiplicative, and satisfy the arithmetic-geometric mean\ninequality. We also extend our results to composite quantum channel\ndiscrimination, and show an analogous optimality property of the weighted\nKubo-Ando geometric means of two quantum channels, a notion that seems to be\nnew. We extend this concept to defining the notion of superoperator perspective\nfunction and establish some of its basic properties, which may be of\nindependent interest.", "published": "2025-03-17 17:06:27", "link": "http://arxiv.org/abs/2503.13379v2", "categories": ["quant-ph", "cs.IT", "math-ph", "math.FA", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Channel Estimation for Pinching-Antenna Systems (PASS)", "abstract": "Pinching Antennas (PAs) represent a revolutionary flexible antenna technology\nthat leverages dielectric waveguides and electromagnetic coupling to mitigate\nlarge-scale path loss. This letter is the first to explore channel estimation\nfor Pinching-Antenna SyStems (PASS), addressing their uniquely ill-conditioned\nand underdetermined channel characteristics. In particular, two efficient deep\nlearning-based channel estimators are proposed. 1) PAMoE: This estimator\nincorporates dynamic padding, feature embedding, fusion, and mixture of experts\n(MoE) modules, which effectively leverage the positional information of PAs and\nexploit expert diversity. 2) PAformer: This Transformer-style estimator employs\nthe self-attention mechanism to predict channel coefficients in a per-antenna\nmanner, which offers more flexibility to adaptively deal with dynamic numbers\nof PAs in practical deployment. Numerical results demonstrate that 1) the\nproposed deep learning-based channel estimators outperform conventional methods\nand exhibit excellent zero-shot learning capabilities, and 2) PAMoE delivers\nhigher channel estimation accuracy via MoE specialization, while PAformer\nnatively handles an arbitrary number of PAs, trading self-attention complexity\nfor superior scalability.", "published": "2025-03-17 15:20:49", "link": "http://arxiv.org/abs/2503.13268v3", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "New quantum codes from homothetic-BCH codes", "abstract": "We introduce homothetic-BCH codes. These are a family of $q^2$-ary classical\ncodes $\\mathcal{C}$ of length $\\lambda n_1$, where $\\lambda$ and $n_1$ are\nsuitable positive integers such that the punctured code $\\mathcal{B}$ of\n$\\mathcal{C}$ in the last $\\lambda n_1 - n_1$ coordinates is a narrow-sense BCH\ncode of length $n_1$. We prove that whenever $\\mathcal{B}$ is Hermitian\nself-orthogonal, so is $\\mathcal{C}$.\n  As a consequence, we present a procedure to obtain quantum stabilizer codes\nwith lengths than cannot be reached by BCH codes. With this procedure we get\nnew quantum codes according to Grassl's table.\n  To prove our results, we give necessary and sufficient conditions for\nHermitian self-orthogonality of BCH codes of a wide range of lengths.", "published": "2025-03-17 11:21:40", "link": "http://arxiv.org/abs/2503.13069v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Low-PAPR OFDM-ISAC Waveform Design Based on Frequency-Domain Phase Differences", "abstract": "Low peak-to-average power ratio (PAPR) orthogonal frequency division\nmultiplexing (OFDM) waveform design is a crucial issue in integrated sensing\nand communications (ISAC). This paper introduces an OFDM-ISAC waveform design\nthat utilizes the entire spectrum simultaneously for both communication and\nsensing by leveraging a novel degree of freedom (DoF): the frequency-domain\nphase difference (PD). Based on this concept, we develop a novel PD-based\nOFDM-ISAC waveform structure and utilize it to design a PD-based Low-PAPR\nOFDM-ISAC (PLPOI) waveform. The design is formulated as an optimization problem\nincorporating four key constraints: the time-frequency relationship equation,\nfrequency-domain unimodular constraints, PD constraints, and time-domain low\nPAPR requirements. To solve this challenging non-convex problem, we develop an\nefficient algorithm, ADMM-PLPOI, based on the alternating direction method of\nmultipliers (ADMM) framework. Extensive simulation results demonstrate that the\nproposed PLPOI waveform achieves significant improvements in both PAPR and bit\nerror rate (BER) performance compared to conventional OFDM-ISAC waveforms.", "published": "2025-03-17 08:28:30", "link": "http://arxiv.org/abs/2503.12916v3", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robust Deep Joint Source Channel Coding for Task-Oriented Semantic Communications", "abstract": "Semantic communications based on deep joint source-channel coding (JSCC) aim\nto improve communication efficiency by transmitting only task-relevant\ninformation. However, ensuring robustness to the stochasticity of communication\nchannels remains a key challenge in learning-based JSCC. In this paper, we\npropose a novel regularization technique for learning-based JSCC to enhance\nrobustness against channel noise. The proposed method utilizes the\nKullback-Leibler (KL) divergence as a regularizer term in the training loss,\nmeasuring the discrepancy between two posterior distributions: one under noisy\nchannel conditions (noisy posterior) and one for a noise-free system\n(noise-free posterior). Reducing this KL divergence mitigates the impact of\nchannel noise on task performance by keeping the noisy posterior close to the\nnoise-free posterior. We further show that the expectation of the KL divergence\ngiven the encoded representation can be analytically approximated using the\nFisher information matrix and the covariance matrix of the channel noise.\nNotably, the proposed regularization is architecture-agnostic, making it\nbroadly applicable to general semantic communication systems over noisy\nchannels. Our experimental results validate that the proposed regularization\nconsistently improves task performance across diverse semantic communication\nsystems and channel conditions.", "published": "2025-03-17 08:15:32", "link": "http://arxiv.org/abs/2503.12907v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Function-Correcting Codes for b-Symbol Read Channels", "abstract": "Function-correcting codes are an innovative class of codes that are designed\nto protect a function evaluation of the data against errors or corruptions. Due\nto its usefulness in machine learning applications and archival data storage,\nwhere preserving the integrity of computation is crucial, Lenz et al. recently\nintroduced function-correcting codes for binary symmetric channels to safeguard\nfunction evaluation against errors. Xia et al. expanded this concept to\nsymbol-pair read channels over binary fields. The current paper further\nadvances the theory by developing function-correcting codes for b-symbol read\nchannels over finite fields. We introduce the idea of irregular b-symbol\ndistance codes and establish bounds on their performance over finite fields.\nThis concept helps in understanding the behavior of function-correcting codes\nin more complex settings. We also present a graphical approach of the problem\nof constructing function-correcting b-symbol codes. Furthermore, we apply these\ngeneral concepts to specific classes of functions and compare the redundancy of\nfunction-correcting b-symbol codes with classical b-symbol codes. Our findings\ndemonstrate that function-correcting b-symbol codes achieve lower redundancy\nwhile maintaining reliability.", "published": "2025-03-17 07:46:39", "link": "http://arxiv.org/abs/2503.12894v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Density Formula Approach for Non-reversible Isomorphism Theorems, with Applications", "abstract": "The classical isomorphism theorems for reversible Markov chains have played\nan important role in studying the properties of local time processes of\nstrongly symmetric Markov processes~\\cite{mr06}, bounding the cover time of a\ngraph by a random walk~\\cite{dlp11}, and in topics related to physics such as\nrandom walk loop soups and Brownian loop soups~\\cite{lt07}. Non-reversible\nversions of these theorems have been discovered by Le Jan, Eisenbaum, and\nKaspi~\\cite{lejan08, ek09, eisenbaum13}. Here, we give a density-formula-based\nproof for all these non-reversible isomorphism theorems, extending the results\nin \\cite{bhs21}. Moreover, we use this method to generalize the comparison\ninequalities derived in \\cite{eisenbaum13} for permanental processes and derive\nan upper bound for the cover time of non-reversible Markov chains.", "published": "2025-03-17 06:41:13", "link": "http://arxiv.org/abs/2503.12859v1", "categories": ["math.PR", "cs.IT", "math.IT"], "primary_category": "math.PR"}
{"title": "STAR-RIS-Assisted Cell-Free Massive MIMO with Multi-antenna Users and Hardware Impairments Over Correlated Rayleigh Fading Channels", "abstract": "Integrating cell-free massive multiple-input multiple-output (MIMO) with\nsimultaneous transmitting and reflecting reconfigurable intelligent surfaces\n(STAR-RISs) can provide ubiquitous connectivity and enhance coverage. This\npaper explores a STAR-RIS-assisted cell-free massive MIMO system featuring\nmulti-antenna users, multi-antenna access points (APs), and multi-element\nSTAR-RISs, accounting for transceiver hardware impairments. We first establish\nthe system model of STAR-RIS-assisted cell-free massive MIMO systems with\nmulti-antenna users. Subsequently, we analyze two uplink implementations: local\nprocessing and centralized decoding (Level 1), and fully centralized processing\n(Level 2), both implementations incorporating hardware impairments. We study\nthe local and global minimum mean square error (MMSE) combining schemes to\nmaximize the uplink spectral efficiency (SE) for Level 1 and Level 2,\nrespectively. The MMSE-based successive interference cancellation detector is\nutilized to compute the uplink SE. We introduce the optimal large-scale fading\ndecoding at the central processing unit and derive closed-form SE expressions\nutilizing maximum ratio combining at APs for Level 1. Our numerical results\nreveal that hardware impairments negatively affect SE performance, particularly\nat the user end. However, this degradation can be mitigated by increasing the\nnumber of user antennas. Enhancing the number of APs and STAR-RIS elements also\nimproves performance and mitigates performance degradation. Notably, unlike\nconventional results based on direct links, our findings show that Level 2\nconsistently outperforms Level 1 with arbitrary combining schemes for the\nproposed STAR-RIS-assisted system.", "published": "2025-03-17 05:21:56", "link": "http://arxiv.org/abs/2503.12830v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Some remarks on the results derived by Ramy Takieldin and Patrick Sol\u00e9 (2025)", "abstract": "The purpose of this note is to rectify a typographical error in the\nstatements of Theorems 5.5 and 5.6 of Sharma, Chauhan and Singh[3] and further\nanalyze and discuss the significance of the results derived in Takieldin and\nSol\\'e [4]. In our opinion, several claims made by the authors in [4] are\neither factually incorrect or lack adequate substantiation, which may confuse\nthe readers about the contributions of [1,3]. Our remarks on the work [4]\nintend to provide the clarity and inform about the true contributions and\nfindings of our research.", "published": "2025-03-17 05:06:28", "link": "http://arxiv.org/abs/2503.12823v3", "categories": ["cs.IT", "math.CO", "math.IT", "94B15"], "primary_category": "cs.IT"}
{"title": "Cross-Layer Security for Semantic Communications: Metrics and Optimization", "abstract": "Different from traditional secure communication that focuses on symbolic\nprotection at the physical layer, semantic secure communication requires\nfurther attention to semantic-level task performance at the application layer.\nThere is a research gap on how to comprehensively evaluate and optimize the\nsecurity performance of semantic communication. In order to fill this gap, a\nunified semantic security metric, the cross-layer semantic secure rate (CLSSR),\nis defined to estimate cross-layer security requirements at both the physical\nlayer and the application layer. Then, we formulate the maximization problem of\nthe CLSSR with the mixed integer nonlinear programming (MINLP). We propose a\nhierarchical AI-native semantic secure communication network with a\nreinforcement learning (RL)-based semantic resource allocation scheme, aiming\nto ensure the cross-layer semantic security (CL-SS). Finally, we prove the\nconvergence of our proposed intelligent resource allocation, and the simulation\nresults demonstrate that our proposed CLSS method outperforms the traditional\nphysical layer semantic security (PL-SS) method in terms of both task\nreliability and CLSSR.", "published": "2025-03-17 04:53:40", "link": "http://arxiv.org/abs/2503.12818v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Estimating stationary mass, frequency by frequency", "abstract": "Suppose we observe a trajectory of length $n$ from an $\\alpha$-mixing\nstochastic process over a finite but potentially large state space. We consider\nthe problem of estimating the probability mass placed by the stationary\ndistribution of any such process on elements that occur with a certain\nfrequency in the observed sequence. We estimate this vector of probabilities in\ntotal variation distance, showing universal consistency in $n$ and recovering\nknown results for i.i.d. sequences as special cases. Our proposed methodology\ncarefully combines the plug-in (or empirical) estimator with a\nrecently-proposed modification of the Good--Turing estimator called WingIt,\nwhich was originally developed for Markovian sequences. En route to controlling\nthe error of our estimator, we develop new performance bounds on WingIt and the\nplug-in estimator for $\\alpha$-mixing stochastic processes. Importantly, the\nextensively used method of Poissonization can no longer be applied in our non\ni.i.d. setting, and so we develop complementary tools -- including\nconcentration inequalities for a natural self-normalized statistic of mixing\nsequences -- that may prove independently useful in the design and analysis of\nestimators for related problems.", "published": "2025-03-17 04:24:21", "link": "http://arxiv.org/abs/2503.12808v2", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Semantic-Relevance Based Sensor Selection for Edge-AI Empowered Sensing Systems", "abstract": "The sixth-generation (6G) mobile network is envisioned to incorporate sensing\nand edge artificial intelligence (AI) as two key functions. Their natural\nconvergence leads to the emergence of Integrated Sensing and Edge AI (ISEA), a\nnovel paradigm enabling real-time acquisition and understanding of sensory\ninformation at the network edge. However, ISEA faces a communication bottleneck\ndue to the large number of sensors and the high dimensionality of sensory\nfeatures. Traditional approaches to communication-efficient ISEA lack awareness\nof semantic relevance, i.e., the level of relevance between sensor observations\nand the downstream task. To fill this gap, this paper presents a novel\nframework for semantic-relevance-aware sensor selection to achieve optimal\nend-to-end (E2E) task performance under heterogeneous sensor relevance and\nchannel states. E2E sensing accuracy analysis is provided to characterize the\nsensing task performance in terms of selected sensors' relevance scores and\nchannel states. Building on the results, the sensor-selection problem for\naccuracy maximization is formulated as an integer program and solved through a\ntight approximation of the objective. The optimal solution exhibits a\npriority-based structure, which ranks sensors based on a priority indicator\ncombining relevance scores and channel states and selects top-ranked sensors.\nLow-complexity algorithms are then developed to determine the optimal numbers\nof selected sensors and features. Experimental results on both synthetic and\nreal datasets show substantial accuracy gain achieved by the proposed selection\nscheme compared to existing benchmarks.", "published": "2025-03-17 03:47:19", "link": "http://arxiv.org/abs/2503.12785v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Finite Samples for Shallow Neural Networks", "abstract": "This paper investigates the ability of finite samples to identify two-layer\nirreducible shallow networks with various nonlinear activation functions,\nincluding rectified linear units (ReLU) and analytic functions such as the\nlogistic sigmoid and hyperbolic tangent. An ``irreducible\" network is one whose\nfunction cannot be represented by another network with fewer neurons. For ReLU\nactivation functions, we first establish necessary and sufficient conditions\nfor determining the irreducibility of a network. Subsequently, we prove a\nnegative result: finite samples are insufficient for definitive identification\nof any irreducible ReLU shallow network. Nevertheless, we demonstrate that for\na given irreducible network, one can construct a finite set of sampling points\nthat can distinguish it from other network with the same neuron count.\nConversely, for logistic sigmoid and hyperbolic tangent activation functions,\nwe provide a positive result. We construct finite samples that enable the\nrecovery of two-layer irreducible shallow analytic networks. To the best of our\nknowledge, this is the first study to investigate the exact identification of\ntwo-layer irreducible networks using finite sample function values. Our\nfindings provide insights into the comparative performance of networks with\ndifferent activation functions under limited sampling conditions.", "published": "2025-03-17 02:24:31", "link": "http://arxiv.org/abs/2503.12744v1", "categories": ["cs.LG", "cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "cs.LG"}
{"title": "A Generalist Hanabi Agent", "abstract": "Traditional multi-agent reinforcement learning (MARL) systems can develop\ncooperative strategies through repeated interactions. However, these systems\nare unable to perform well on any other setting than the one they have been\ntrained on, and struggle to successfully cooperate with unfamiliar\ncollaborators. This is particularly visible in the Hanabi benchmark, a popular\n2-to-5 player cooperative card-game which requires complex reasoning and\nprecise assistance to other agents. Current MARL agents for Hanabi can only\nlearn one specific game-setting (e.g., 2-player games), and play with the same\nalgorithmic agents. This is in stark contrast to humans, who can quickly adjust\ntheir strategies to work with unfamiliar partners or situations. In this paper,\nwe introduce Recurrent Replay Relevance Distributed DQN (R3D2), a generalist\nagent for Hanabi, designed to overcome these limitations. We reformulate the\ntask using text, as language has been shown to improve transfer. We then\npropose a distributed MARL algorithm that copes with the resulting dynamic\nobservation- and action-space. In doing so, our agent is the first that can\nplay all game settings concurrently, and extend strategies learned from one\nsetting to other ones. As a consequence, our agent also demonstrates the\nability to collaborate with different algorithmic agents -- agents that are\nthemselves unable to do so. The implementation code is available at:\n$\\href{https://github.com/chandar-lab/R3D2-A-Generalist-Hanabi-Agent}{R3D2-A-Generalist-Hanabi-Agent}$", "published": "2025-03-17 22:25:15", "link": "http://arxiv.org/abs/2503.14555v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Stable Task Allocation in Multi-Agent Systems with Lexicographic Preferences", "abstract": "Motivated by the increasing interest in the explicit representation and\nhandling of various \"preference\" structures arising in modern digital economy,\nthis work introduces a new class of \"one-to-many stable-matching\" problems\nwhere a set of atomic tasks must be stably allocated to a set of agents. An\nimportant characteristic of these stable-matching problems is the very\narbitrary specification of the task subsets constituting \"feasible\" allocations\nfor each agent. It is shown that as long as the agents rank their feasible task\nallocations lexicographically with respect to their stated preferences for each\natomic task, matching stability reduces to the absence of blocking agent-task\npairs. This result, together with a pertinent graphical representation of\nfeasible allocations, enable (i) the representation of the space of stable\nmatchings as a set of linear constraints with binary variables, and (ii) the\nspecification and handling of certain notions of optimality within this space\nof stable matchings. The last part of the paper also addresses the notion of\n\"substitutability\" in the considered problem context.", "published": "2025-03-17 18:13:45", "link": "http://arxiv.org/abs/2503.13619v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives", "abstract": "With the rapid development of artificial intelligence, intelligent\ndecision-making techniques have gradually surpassed human levels in various\nhuman-machine competitions, especially in complex multi-agent cooperative task\nscenarios. Multi-agent cooperative decision-making involves multiple agents\nworking together to complete established tasks and achieve specific objectives.\nThese techniques are widely applicable in real-world scenarios such as\nautonomous driving, drone navigation, disaster rescue, and simulated military\nconfrontations. This paper begins with a comprehensive survey of the leading\nsimulation environments and platforms used for multi-agent cooperative\ndecision-making. Specifically, we provide an in-depth analysis for these\nsimulation environments from various perspectives, including task formats,\nreward allocation, and the underlying technologies employed. Subsequently, we\nprovide a comprehensive overview of the mainstream intelligent decision-making\napproaches, algorithms and models for multi-agent systems (MAS).\nTheseapproaches can be broadly categorized into five types: rule-based\n(primarily fuzzy logic), game theory-based, evolutionary algorithms-based, deep\nmulti-agent reinforcement learning (MARL)-based, and large language\nmodels(LLMs)reasoning-based. Given the significant advantages of MARL\nandLLMs-baseddecision-making methods over the traditional rule, game theory,\nand evolutionary algorithms, this paper focuses on these multi-agent methods\nutilizing MARL and LLMs-based techniques. We provide an in-depth discussion of\nthese approaches, highlighting their methodology taxonomies, advantages, and\ndrawbacks. Further, several prominent research directions in the future and\npotential challenges of multi-agent cooperative decision-making are also\ndetailed.", "published": "2025-03-17 17:45:46", "link": "http://arxiv.org/abs/2503.13415v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "When Should We Orchestrate Multiple Agents?", "abstract": "Strategies for orchestrating the interactions between multiple agents, both\nhuman and artificial, can wildly overestimate performance and underestimate the\ncost of orchestration. We design a framework to orchestrate agents under\nrealistic conditions, such as inference costs or availability constraints. We\nshow theoretically that orchestration is only effective if there are\nperformance or cost differentials between agents. We then empirically\ndemonstrate how orchestration between multiple agents can be helpful for\nselecting agents in a simulated environment, picking a learning strategy in the\ninfamous Rogers' Paradox from social science, and outsourcing tasks to other\nagents during a question-answer task in a user study.", "published": "2025-03-17 14:26:07", "link": "http://arxiv.org/abs/2503.13577v1", "categories": ["cs.MA", "cs.CY", "cs.LG"], "primary_category": "cs.MA"}
{"title": "LIVEPOINT: Fully Decentralized, Safe, Deadlock-Free Multi-Robot Control in Cluttered Environments with High-Dimensional Inputs", "abstract": "Fully decentralized, safe, and deadlock-free multi-robot navigation in\ndynamic, cluttered environments is a critical challenge in robotics. Current\nmethods require exact state measurements in order to enforce safety and\nliveness e.g. via control barrier functions (CBFs), which is challenging to\nachieve directly from onboard sensors like lidars and cameras. This work\nintroduces LIVEPOINT, a decentralized control framework that synthesizes\nuniversal CBFs over point clouds to enable safe, deadlock-free real-time\nmulti-robot navigation in dynamic, cluttered environments. Further, LIVEPOINT\nensures minimally invasive deadlock avoidance behavior by dynamically adjusting\nagents' speeds based on a novel symmetric interaction metric. We validate our\napproach in simulation experiments across highly constrained multi-robot\nscenarios like doorways and intersections. Results demonstrate that LIVEPOINT\nachieves zero collisions or deadlocks and a 100% success rate in challenging\nsettings compared to optimization-based baselines such as MPC and ORCA and\nneural methods such as MPNet, which fail in such environments. Despite\nprioritizing safety and liveness, LIVEPOINT is 35% smoother than baselines in\nthe doorway environment, and maintains agility in constrained environments\nwhile still being safe and deadlock-free.", "published": "2025-03-17 12:07:25", "link": "http://arxiv.org/abs/2503.13098v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Towards Better Sample Efficiency in Multi-Agent Reinforcement Learning via Exploration", "abstract": "Multi-agent reinforcement learning has shown promise in learning cooperative\nbehaviors in team-based environments. However, such methods often demand\nextensive training time. For instance, the state-of-the-art method TiZero takes\n40 days to train high-quality policies for a football environment. In this\npaper, we hypothesize that better exploration mechanisms can improve the sample\nefficiency of multi-agent methods. We propose two different approaches for\nbetter exploration in TiZero: a self-supervised intrinsic reward and a random\nnetwork distillation bonus. Additionally, we introduce architectural\nmodifications to the original algorithm to enhance TiZero's computational\nefficiency. We evaluate the sample efficiency of these approaches through\nextensive experiments. Our results show that random network distillation\nimproves training sample efficiency by 18.8% compared to the original TiZero.\nFurthermore, we evaluate the qualitative behavior of the models produced by\nboth variants against a heuristic AI, with the self-supervised reward\nencouraging possession and random network distillation leading to a more\noffensive performance. Our results highlights the applicability of our random\nnetwork distillation variant in practical settings. Lastly, due to the nature\nof the proposed method, we acknowledge its use beyond football simulation,\nespecially in environments with strong multi-agent and strategic aspects.", "published": "2025-03-17 11:32:28", "link": "http://arxiv.org/abs/2503.13077v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Practical Abstractions for Model Checking Continuous-Time Multi-Agent Systems", "abstract": "Model checking of temporal logics in a well established technique to verify\nand validate properties of multi-agent systems (MAS). However, practical model\nchecking requires input models of manageable size. In this paper, we extend the\nmodel reduction method by variable-based abstraction, proposed recently by\nJamroga and Kim, to the verification of real-time systems and properties. To\nthis end, we define a real-time extension of MAS graphs, extend the abstraction\nprocedure, and prove its correctness for the universal fragment of Timed\nComputation Tree Logic (TCTL). Besides estimating the theoretical complexity\ngains, we present an experimental evaluation for a simplified model of the\nEstonian voting system and verification using the Uppaal model checker.", "published": "2025-03-17 09:35:24", "link": "http://arxiv.org/abs/2503.12976v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents", "abstract": "Large Language Models (LLMs) are combined with plugins to create powerful LLM\nagents that provide a wide range of services. Unlike traditional software, LLM\nagent's behavior is determined at runtime by natural language prompts from\neither user or plugin's data. This flexibility enables a new computing paradigm\nwith unlimited capabilities and programmability, but also introduces new\nsecurity risks, vulnerable to privilege escalation attacks. Moreover, user\nprompt is prone to be interpreted in an insecure way by LLM agents, creating\nnon-deterministic behaviors that can be exploited by attackers. To address\nthese security risks, we propose Prompt Flow Integrity (PFI), a system\nsecurity-oriented solution to prevent privilege escalation in LLM agents.\nAnalyzing the architectural characteristics of LLM agents, PFI features three\nmitigation techniques -- i.e., untrusted data identification, enforcing least\nprivilege on LLM agents, and validating unsafe data flows. Our evaluation\nresult shows that PFI effectively mitigates privilege escalation attacks while\nsuccessfully preserving the utility of LLM agents.", "published": "2025-03-17 05:27:57", "link": "http://arxiv.org/abs/2503.15547v1", "categories": ["cs.CR", "cs.AI", "cs.MA"], "primary_category": "cs.CR"}
{"title": "Energy-Aware Task Allocation for Teams of Multi-mode Robots", "abstract": "This work proposes a novel multi-robot task allocation framework for robots\nthat can switch between multiple modes, e.g., flying, driving, or walking. We\nfirst provide a method to encode the multi-mode property of robots as a graph,\nwhere the mode of each robot is represented by a node. Next, we formulate a\nconstrained optimization problem to decide both the task to be allocated to\neach robot as well as the mode in which the latter should execute the task. The\nrobot modes are optimized based on the state of the robot and the environment,\nas well as the energy required to execute the allocated task. Moreover, the\nproposed framework is able to encompass kinematic and dynamic models of robots\nalike. Furthermore, we provide sufficient conditions for the convergence of\ntask execution and allocation for both robot models.", "published": "2025-03-17 03:51:48", "link": "http://arxiv.org/abs/2503.12787v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Conversational Self-Play for Discovering and Understanding Psychotherapy Approaches", "abstract": "This paper explores conversational self-play with LLMs as a scalable approach\nfor analyzing and exploring psychotherapy approaches, evaluating how well\nAI-generated therapeutic dialogues align with established modalities.", "published": "2025-03-17 02:16:41", "link": "http://arxiv.org/abs/2503.16521v1", "categories": ["cs.HC", "cs.MA"], "primary_category": "cs.HC"}
{"title": "The deep multi-FBSDE method: a robust deep learning method for coupled FBSDEs", "abstract": "We introduce the deep multi-FBSDE method for robust approximation of coupled\nforward-backward stochastic differential equations (FBSDEs), focusing on cases\nwhere the deep BSDE method of Han, Jentzen, and E (2018) fails to converge. To\novercome the convergence issues, we consider a family of FBSDEs that are\nequivalent to the original problem in the sense that they satisfy the same\nassociated partial differential equation (PDE). Our algorithm proceeds in two\nphases: first, we approximate the initial condition for the FBSDE family, and\nsecond, we approximate the original FBSDE using the initial condition\napproximated in the first phase. Numerical experiments show that our method\nconverges even when the standard deep BSDE method does not.", "published": "2025-03-17 14:01:37", "link": "http://arxiv.org/abs/2503.13193v1", "categories": ["math.NA", "cs.NA", "math.OC", "q-fin.CP", "60H35, 68T07, 35K58, 93E20"], "primary_category": "math.NA"}
{"title": "Deep Hedging of Green PPAs in Electricity Markets", "abstract": "In power markets, Green Power Purchase Agreements have become an important\ncontractual tool of the energy transition from fossil fuels to renewable\nsources such as wind or solar radiation. Trading Green PPAs exposes agents to\nprice risks and weather risks. Also, developed electricity markets feature the\nso-called cannibalisation effect : large infeeds induce low prices and vice\nversa. As weather is a non-tradable entity the question arises how to hedge and\nrisk-manage in this highly incom-plete setting. We propose a ''deep hedging''\nframework utilising machine learning methods to construct hedging strategies.\nThe resulting strategies outperform static and dynamic benchmark strategies\nwith respect to different risk measures.", "published": "2025-03-17 11:02:23", "link": "http://arxiv.org/abs/2503.13056v1", "categories": ["q-fin.CP", "cs.LG", "q-fin.RM"], "primary_category": "q-fin.CP"}
{"title": "Model-independent upper bounds for the prices of Bermudan options with convex payoffs", "abstract": "Suppose $\\mu$ and $\\nu$ are probability measures on $\\mathbb R$ satisfying\n$\\mu \\leq_{cx} \\nu$. Let $a$ and $b$ be convex functions on $\\mathbb R$ with $a\n\\geq b \\geq 0$. We are interested in finding \\[ \\sup_{\\mathcal M} \\sup_{\\tau}\n\\mathbb{E}^{\\mathcal M} \\left[ a(X) I_{ \\{ \\tau = 1 \\} } + b(Y) I_{ \\{ \\tau = 2\n\\} } \\right] \\] where the first supremum is taken over consistent models\n$\\mathcal M$ (i.e., filtered probability spaces $(\\Omega, \\mathcal F, \\mathbb\nF, \\mathbb P)$) such that $Z=(z,Z_1,Z_2)=(\\int_{\\mathbb R} x \\mu(dx) =\n\\int_{\\mathbb R} y \\nu(dy), X, Y)$ is a $(\\mathbb F,\\mathbb P)$ martingale,\nwhere $X$ has law $\\mu$ and $Y$ has law $\\nu$ under $\\mathbb P$) and $\\tau$ in\nthe second supremum is a $(\\mathbb F,\\mathbb P)$-stopping time taking values in\n$\\{1,2\\}$.\n  Our contributions are first to characterise and simplify the dual problem,\nand second to completely solve the problem in the symmetric case under the\ndispersion assumption. A key finding is that the canonical set-up in which the\nfiltration is that generated by $Z$ is not rich enough to define an optimal\nmodel and additional randomisation is required. This holds even though the\nmarginal laws $\\mu$ and $\\nu$ are atom-free.\n  The problem has an interpretation of finding the robust, or model-free,\nno-arbitrage bound on the price of a Bermudan option with two possible exercise\ndates, given the prices of co-maturing European options.", "published": "2025-03-17 16:07:52", "link": "http://arxiv.org/abs/2503.13328v2", "categories": ["q-fin.MF", "math.PR", "60G40, 60G42, 91G20"], "primary_category": "q-fin.MF"}
{"title": "Neural Edge Histogram Descriptors for Underwater Acoustic Target Recognition", "abstract": "Numerous maritime applications rely on the ability to recognize acoustic\ntargets using passive sonar. While there is a growing reliance on pre-trained\nmodels for classification tasks, these models often require extensive\ncomputational resources and may not perform optimally when transferred to new\ndomains due to dataset variations. To address these challenges, this work\nadapts the neural edge histogram descriptors (NEHD) method originally developed\nfor image classification, to classify passive sonar signals. We conduct a\ncomprehensive evaluation of statistical and structural texture features,\ndemonstrating that their combination achieves competitive performance with\nlarge pre-trained models. The proposed NEHD-based approach offers a lightweight\nand efficient solution for underwater target recognition, significantly\nreducing computational costs while maintaining accuracy.", "published": "2025-03-17 22:57:05", "link": "http://arxiv.org/abs/2503.13763v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "PANDORA: Diffusion Policy Learning for Dexterous Robotic Piano Playing", "abstract": "We present PANDORA, a novel diffusion-based policy learning framework\ndesigned specifically for dexterous robotic piano performance. Our approach\nemploys a conditional U-Net architecture enhanced with FiLM-based global\nconditioning, which iteratively denoises noisy action sequences into smooth,\nhigh-dimensional trajectories. To achieve precise key execution coupled with\nexpressive musical performance, we design a composite reward function that\nintegrates task-specific accuracy, audio fidelity, and high-level semantic\nfeedback from a large language model (LLM) oracle. The LLM oracle assesses\nmusical expressiveness and stylistic nuances, enabling dynamic, hand-specific\nreward adjustments. Further augmented by a residual inverse-kinematics\nrefinement policy, PANDORA achieves state-of-the-art performance in the\nROBOPIANIST environment, significantly outperforming baselines in both\nprecision and expressiveness. Ablation studies validate the critical\ncontributions of diffusion-based denoising and LLM-driven semantic feedback in\nenhancing robotic musicianship. Videos available at:\nhttps://taco-group.github.io/PANDORA", "published": "2025-03-17 17:22:34", "link": "http://arxiv.org/abs/2503.14545v1", "categories": ["cs.LG", "cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Audio Compression using Periodic Gabor with Biorthogonal Exchange: Implementation Using the Zak Transform", "abstract": "An efficient new approach to signal compression is presented based of a novel\nvariation on the Gabor basis set. Following earlier work by Shimshovitz and\nTannor, we convolve the conventional Gabor functions with Dirichlet functions\nto obtain a Periodic Gabor basis set (PG). The PG basis is exact for continuous\nfunctions that are periodic band-limited. Using the orthonormality of the\nDirichlet functions, the calculation of the PG coefficients becomes trivial and\nnumerically stable, but its representation does not allow compression. Large\ncompression factors are achieved by exchanging the PG basis with its\nbiorthogonal basis, thereby using the localized PG basis to calculate the\ncoefficients (PGB). Here we implement the PGB formalism using the Fast Zak\nTransform and obtain very high efficiency with respect to both CPU and memory.\nWe compare the method with the state of the art Short-Time Fourier Transform\n(STFT) and Discrete Wavelet Transform (DWT) methods on a variety of audio\nfiles, including music and speech samples. In all cases tested our scheme\nsurpasses the STFT by far and in most cases outperforms DWT.", "published": "2025-03-17 13:15:53", "link": "http://arxiv.org/abs/2503.22703v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Past, Present, and Future of Spatial Audio and Room Acoustics", "abstract": "The study of spatial audio and room acoustics aims to create immersive audio\nexperiences by modeling the physics and psychoacoustics of how sound behaves in\nspace. In the long history of this research area, various key technologies have\nbeen developed based both on theoretical advancements and practical\ninnovations. We highlight historical achievements, initiative activities,\nrecent advancements, and future outlooks in the research area of spatial audio\nrecording and reproduction, and room acoustic simulation, modeling, analysis,\nand control.", "published": "2025-03-17 08:59:58", "link": "http://arxiv.org/abs/2503.12948v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "FNSE-SBGAN: Far-field Speech Enhancement with Schrodinger Bridge and Generative Adversarial Networks", "abstract": "The current dominant approach for neural speech enhancement relies on\npurely-supervised deep learning using simulated pairs of far-field\nnoisy-reverberant speech (mixtures) and clean speech. However, these trained\nmodels often exhibit limited generalizability to real-recorded mixtures. To\naddress this issue, this study investigates training enhancement models\ndirectly on real mixtures. Specifically, we revisit the single-channel\nfar-field to near-field speech enhancement (FNSE) task, focusing on real-world\ndata characterized by low signal-to-noise ratio (SNR), high reverberation, and\nmid-to-high frequency attenuation. We propose FNSE-SBGAN, a novel framework\nthat integrates a Schrodinger Bridge (SB)-based diffusion model with generative\nadversarial networks (GANs). Our approach achieves state-of-the-art performance\nacross various metrics and subjective evaluations, significantly reducing the\ncharacter error rate (CER) by up to 14.58% compared to far-field signals.\nExperimental results demonstrate that FNSE-SBGAN preserves superior subjective\nquality and establishes a new benchmark for real-world far-field speech\nenhancement. Additionally, we introduce a novel evaluation framework leveraging\nmatrix rank analysis in the time-frequency domain, providing systematic\ninsights into model performance and revealing the strengths and weaknesses of\ndifferent generative methods.", "published": "2025-03-17 08:51:03", "link": "http://arxiv.org/abs/2503.12936v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Dynamic Derivation and Elimination: Audio Visual Segmentation with Enhanced Audio Semantics", "abstract": "Sound-guided object segmentation has drawn considerable attention for its\npotential to enhance multimodal perception. Previous methods primarily focus on\ndeveloping advanced architectures to facilitate effective audio-visual\ninteractions, without fully addressing the inherent challenges posed by audio\nnatures, \\emph{\\ie}, (1) feature confusion due to the overlapping nature of\naudio signals, and (2) audio-visual matching difficulty from the varied sounds\nproduced by the same object. To address these challenges, we propose Dynamic\nDerivation and Elimination (DDESeg): a novel audio-visual segmentation\nframework. Specifically, to mitigate feature confusion, DDESeg reconstructs the\nsemantic content of the mixed audio signal by enriching the distinct semantic\ninformation of each individual source, deriving representations that preserve\nthe unique characteristics of each sound. To reduce the matching difficulty, we\nintroduce a discriminative feature learning module, which enhances the semantic\ndistinctiveness of generated audio representations. Considering that not all\nderived audio representations directly correspond to visual features (e.g.,\noff-screen sounds), we propose a dynamic elimination module to filter out\nnon-matching elements. This module facilitates targeted interaction between\nsounding regions and relevant audio semantics. By scoring the interacted\nfeatures, we identify and filter out irrelevant audio information, ensuring\naccurate audio-visual alignment. Comprehensive experiments demonstrate that our\nframework achieves superior performance in AVS datasets.", "published": "2025-03-17 05:38:05", "link": "http://arxiv.org/abs/2503.12840v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AV-Surf: Surface-Enhanced Geometry-Aware Novel-View Acoustic Synthesis", "abstract": "Accurately modeling sound propagation with complex real-world environments is\nessential for Novel View Acoustic Synthesis (NVAS). While previous studies have\nleveraged visual perception to estimate spatial acoustics, the combined use of\nsurface normal and structural details from 3D representations in acoustic\nmodeling has been underexplored. Given their direct impact on sound wave\nreflections and propagation, surface normals should be jointly modeled with\nstructural details to achieve accurate spatial acoustics. In this paper, we\npropose a surface-enhanced geometry-aware approach for NVAS to improve spatial\nacoustic modeling. To achieve this, we exploit geometric priors, such as image,\ndepth map, surface normals, and point clouds obtained using a 3D Gaussian\nSplatting (3DGS) based framework. We introduce a dual cross-attention-based\ntransformer integrating geometrical constraints into frequency query to\nunderstand the surroundings of the emitter. Additionally, we design a\nConvNeXt-based spectral features processing network called Spectral Refinement\nNetwork (SRN) to synthesize realistic binaural audio. Experimental results on\nthe RWAVS and SoundSpace datasets highlight the necessity of our approach, as\nit surpasses existing methods in novel view acoustic synthesis.", "published": "2025-03-17 04:22:53", "link": "http://arxiv.org/abs/2503.12806v1", "categories": ["cs.MM", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
