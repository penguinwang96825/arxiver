{"title": "NegativePrompt: Leveraging Psychology for Large Language Models\n  Enhancement via Negative Emotional Stimuli", "abstract": "Large Language Models (LLMs) have become integral to a wide spectrum of\napplications, ranging from traditional computing tasks to advanced artificial\nintelligence (AI) applications. This widespread adoption has spurred extensive\nresearch into LLMs across various disciplines, including the social sciences.\nNotably, studies have revealed that LLMs possess emotional intelligence, which\ncan be further developed through positive emotional stimuli. This discovery\nraises an intriguing question: can negative emotions similarly influence LLMs,\npotentially enhancing their performance? In response to this question, we\nintroduce NegativePrompt, a novel approach underpinned by psychological\nprinciples, involving ten specifically designed negative emotional stimuli. We\nembark on rigorous experimental evaluations of five LLMs including\nFlan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across a set of 45 tasks.\nThe results are revealing: NegativePrompt markedly enhances the performance of\nLLMs, evidenced by relative improvements of 12.89% in Instruction Induction\ntasks and 46.25% in BIG-Bench tasks. Moreover, we conduct attention\nvisualization experiments to decipher the underlying mechanisms of\nNegativePrompt's influence. Our research contributes significantly to the\nunderstanding of LLMs and emotion interaction, demonstrating the practical\nefficacy of NegativePrompt as an emotion-driven method and offering novel\ninsights for the enhancement of LLMs in real-world applications. The code is\navailable at https://github.com/wangxu0820/NegativePrompt.", "published": "2024-05-05 05:06:07", "link": "http://arxiv.org/abs/2405.02814v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Labeling supervised fine-tuning data with the scaling law", "abstract": "This paper introduces a multi-stage manual annotation calibrated by the\nscaling law, offering a high-quality Supervised Fine-Tuning data acquisition\nmethod for environments with constrained resources like GPU poor, limited GPT\naccess, and funding restrictions. We have preprocessed 58k authentic chat data\nand manually annotated 2.3k questions. After this, we conducted fine-tuning on\nQwen models, ranging from 0.5B to 32B parameters. The optimal version improved\n29.07 in F1 score. This confirms the viability of fine-tuning Large Language\nModel (LLM) for downstream Natural Language Processing (NLP) tasks. Our\ncontributions are: 1) Created Supervised Fine-Tuning (SFT) training data in\nalpaca format, along with a set of Low-Rank Adaptation (LoRA) weights, and 2)\nDeveloped a method for acquiring high-quality data leveraging scaling law\nprinciple. The script, raw data with alpaca format and experiments track are\nopen-sourced on Github\n(https://github.com/InternLM/HuixiangDou/tree/main/web/tools), HuggingFace\n(https://huggingface.co/tpoisonooo) and WandB\n(https://wandb.ai/tpoisonooo/huixiangdou-cr/table?nw=nwusertpoisonooo). The\nprivacy of the data involved has been authorized by users. SFT data and license\ncomes from ncnn contributors group.", "published": "2024-05-05 05:43:20", "link": "http://arxiv.org/abs/2405.02817v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Two-Stage Prediction-Aware Contrastive Learning Framework for\n  Multi-Intent NLU", "abstract": "Multi-intent natural language understanding (NLU) presents a formidable\nchallenge due to the model confusion arising from multiple intents within a\nsingle utterance. While previous works train the model contrastively to\nincrease the margin between different multi-intent labels, they are less suited\nto the nuances of multi-intent NLU. They ignore the rich information between\nthe shared intents, which is beneficial to constructing a better embedding\nspace, especially in low-data scenarios. We introduce a two-stage\nPrediction-Aware Contrastive Learning (PACL) framework for multi-intent NLU to\nharness this valuable knowledge. Our approach capitalizes on shared intent\ninformation by integrating word-level pre-training and prediction-aware\ncontrastive fine-tuning. We construct a pre-training dataset using a word-level\ndata augmentation strategy. Subsequently, our framework dynamically assigns\nroles to instances during contrastive fine-tuning while introducing a\nprediction-aware contrastive loss to maximize the impact of contrastive\nlearning. We present experimental results and empirical analysis conducted on\nthree widely used datasets, demonstrating that our method surpasses the\nperformance of three prominent baselines on both low-data and full-data\nscenarios.", "published": "2024-05-05 13:09:55", "link": "http://arxiv.org/abs/2405.02925v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relay Decoding: Concatenating Large Language Models for Machine\n  Translation", "abstract": "Leveraging large language models for machine translation has demonstrated\npromising results. However, it does require the large language models to\npossess the capability of handling both the source and target languages in\nmachine translation. When it is challenging to find large models that support\nthe desired languages, resorting to continuous learning methods becomes a\ncostly endeavor. To mitigate these expenses, we propose an innovative approach\ncalled RD (Relay Decoding), which entails concatenating two distinct large\nmodels that individually support the source and target languages. By\nincorporating a simple mapping layer to facilitate the connection between these\ntwo models and utilizing a limited amount of parallel data for training, we\nsuccessfully achieve superior results in the machine translation task.\nExperimental results conducted on the Multi30k and WikiMatrix datasets validate\nthe effectiveness of our proposed method.", "published": "2024-05-05 13:42:25", "link": "http://arxiv.org/abs/2405.02933v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enabling Patient-side Disease Prediction via the Integration of Patient\n  Narratives", "abstract": "Disease prediction holds considerable significance in modern healthcare,\nbecause of its crucial role in facilitating early intervention and implementing\neffective prevention measures. However, most recent disease prediction\napproaches heavily rely on laboratory test outcomes (e.g., blood tests and\nmedical imaging from X-rays). Gaining access to such data for precise disease\nprediction is often a complex task from the standpoint of a patient and is\nalways only available post-patient consultation. To make disease prediction\navailable from patient-side, we propose Personalized Medical Disease Prediction\n(PoMP), which predicts diseases using patient health narratives including\ntextual descriptions and demographic information. By applying PoMP, patients\ncan gain a clearer comprehension of their conditions, empowering them to\ndirectly seek appropriate medical specialists and thereby reducing the time\nspent navigating healthcare communication to locate suitable doctors. We\nconducted extensive experiments using real-world data from Haodf to showcase\nthe effectiveness of PoMP.", "published": "2024-05-05 13:54:02", "link": "http://arxiv.org/abs/2405.02935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unraveling the Dominance of Large Language Models Over Transformer\n  Models for Bangla Natural Language Inference: A Comprehensive Study", "abstract": "Natural Language Inference (NLI) is a cornerstone of Natural Language\nProcessing (NLP), providing insights into the entailment relationships between\ntext pairings. It is a critical component of Natural Language Understanding\n(NLU), demonstrating the ability to extract information from spoken or written\ninteractions. NLI is mainly concerned with determining the entailment\nrelationship between two statements, known as the premise and hypothesis. When\nthe premise logically implies the hypothesis, the pair is labeled \"entailment\".\nIf the hypothesis contradicts the premise, the pair receives the\n\"contradiction\" label. When there is insufficient evidence to establish a\nconnection, the pair is described as \"neutral\". Despite the success of Large\nLanguage Models (LLMs) in various tasks, their effectiveness in NLI remains\nconstrained by issues like low-resource domain accuracy, model overconfidence,\nand difficulty in capturing human judgment disagreements. This study addresses\nthe underexplored area of evaluating LLMs in low-resourced languages such as\nBengali. Through a comprehensive evaluation, we assess the performance of\nprominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,\nfocusing on natural language inference. Utilizing the XNLI dataset, we conduct\nzero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and\nGemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,\nmBERT, and sahajBERT. Our findings reveal that while LLMs can achieve\ncomparable or superior performance to fine-tuned SOTA models in few-shot\nscenarios, further research is necessary to enhance our understanding of LLMs\nin languages with modest resources like Bengali. This study underscores the\nimportance of continued efforts in exploring LLM capabilities across diverse\nlinguistic contexts.", "published": "2024-05-05 13:57:05", "link": "http://arxiv.org/abs/2405.02937v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ImageInWords: Unlocking Hyper-Detailed Image Descriptions", "abstract": "Despite the longstanding adage \"an image is worth a thousand words,\"\ngenerating accurate hyper-detailed image descriptions remains unsolved. Trained\non short web-scraped image text, vision-language models often generate\nincomplete descriptions with visual inconsistencies. We address this via a\nnovel data-centric approach with ImageInWords (IIW), a carefully designed\nhuman-in-the-loop framework for curating hyper-detailed image descriptions.\nHuman evaluations on IIW data show major gains compared to recent datasets\n(+66%) and GPT4V (+48%) across comprehensiveness, specificity, hallucinations,\nand more. We also show that fine-tuning with IIW data improves these metrics by\n+31% against models trained with prior work, even with only 9k samples. Lastly,\nwe evaluate IIW models with text-to-image generation and vision-language\nreasoning tasks. Our generated descriptions result in the highest fidelity\nimages, and boost compositional reasoning by up to 6% on ARO, SVO-Probes, and\nWinoground datasets. We release the IIW Eval benchmark with human judgement\nlabels, object and image-level annotations from our framework, and existing\nimage caption datasets enriched via IIW-model.", "published": "2024-05-05 02:15:11", "link": "http://arxiv.org/abs/2405.02793v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Language Evolution for Evading Social Media Regulation via LLM-based\n  Multi-agent Simulation", "abstract": "Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial\nrole in global communication but often encounter strict regulations in\ngeopolitically sensitive regions. This situation has prompted users to\ningeniously modify their way of communicating, frequently resorting to coded\nlanguage in these regulated social media environments. This shift in\ncommunication is not merely a strategy to counteract regulation, but a vivid\nmanifestation of language evolution, demonstrating how language naturally\nevolves under societal and technological pressures. Studying the evolution of\nlanguage in regulated social media contexts is of significant importance for\nensuring freedom of speech, optimizing content moderation, and advancing\nlinguistic research. This paper proposes a multi-agent simulation framework\nusing Large Language Models (LLMs) to explore the evolution of user language in\nregulated social media environments. The framework employs LLM-driven agents:\nsupervisory agent who enforce dialogue supervision and participant agents who\nevolve their language strategies while engaging in conversation, simulating the\nevolution of communication styles under strict regulations aimed at evading\nsocial media regulation. The study evaluates the framework's effectiveness\nthrough a range of scenarios from abstract scenarios to real-world situations.\nKey findings indicate that LLMs are capable of simulating nuanced language\ndynamics and interactions in constrained settings, showing improvement in both\nevading supervision and information accuracy as evolution progresses.\nFurthermore, it was found that LLM agents adopt different strategies for\ndifferent scenarios.", "published": "2024-05-05 09:02:54", "link": "http://arxiv.org/abs/2405.02858v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Sentiment Analysis Across Languages: Evaluation Before and After Machine\n  Translation to English", "abstract": "People communicate in more than 7,000 languages around the world, with around\n780 languages spoken in India alone. Despite this linguistic diversity,\nresearch on Sentiment Analysis has predominantly focused on English text data,\nresulting in a disproportionate availability of sentiment resources for\nEnglish. This paper examines the performance of transformer models in Sentiment\nAnalysis tasks across multilingual datasets and text that has undergone machine\ntranslation. By comparing the effectiveness of these models in different\nlinguistic contexts, we gain insights into their performance variations and\npotential implications for sentiment analysis across diverse languages. We also\ndiscuss the shortcomings and potential for future work towards the end.", "published": "2024-05-05 10:52:09", "link": "http://arxiv.org/abs/2405.02887v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models Make the Grade? An Empirical Study Evaluating\n  LLMs Ability to Mark Short Answer Questions in K-12 Education", "abstract": "This paper presents reports on a series of experiments with a novel dataset\nevaluating how well Large Language Models (LLMs) can mark (i.e. grade) open\ntext responses to short answer questions, Specifically, we explore how well\ndifferent combinations of GPT version and prompt engineering strategies\nperformed at marking real student answers to short answer across different\ndomain areas (Science and History) and grade-levels (spanning ages 5-16) using\na new, never-used-before dataset from Carousel, a quizzing platform. We found\nthat GPT-4, with basic few-shot prompting performed well (Kappa, 0.70) and,\nimportantly, very close to human-level performance (0.75). This research builds\non prior findings that GPT-4 could reliably score short answer reading\ncomprehension questions at a performance-level very close to that of expert\nhuman raters. The proximity to human-level performance, across a variety of\nsubjects and grade levels suggests that LLMs could be a valuable tool for\nsupporting low-stakes formative assessment tasks in K-12 education and has\nimportant implications for real-world education delivery.", "published": "2024-05-05 16:11:06", "link": "http://arxiv.org/abs/2405.02985v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedAdapter: Efficient Test-Time Adaptation of Large Language Models\n  towards Medical Reasoning", "abstract": "Despite their improved capabilities in generation and reasoning, adapting\nlarge language models (LLMs) to the biomedical domain remains challenging due\nto their immense size and corporate privacy. In this work, we propose\nMedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards\nbiomedical applications. Instead of fine-tuning the entire LLM, MedAdapter\neffectively adapts the original model by fine-tuning only a small BERT-sized\nadapter to rank candidate solutions generated by LLMs. Experiments demonstrate\nthat MedAdapter effectively adapts both white-box and black-box LLMs in\nbiomedical reasoning, achieving average performance improvements of 25.48% and\n11.31%, respectively, without requiring extensive computational resources or\nsharing data with third parties. MedAdapter also yields superior performance\nwhen combined with train-time adaptation, highlighting a flexible and\ncomplementary solution to existing adaptation methods. Faced with the\nchallenges of balancing model performance, computational resources, and data\nprivacy, MedAdapter provides an efficient, privacy-preserving, cost-effective,\nand transparent solution for adapting LLMs to the biomedical domain.", "published": "2024-05-05 17:06:31", "link": "http://arxiv.org/abs/2405.03000v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring prompts to elicit memorization in masked language model-based\n  named entity recognition", "abstract": "Training data memorization in language models impacts model capability\n(generalization) and safety (privacy risk). This paper focuses on analyzing\nprompts' impact on detecting the memorization of 6 masked language model-based\nnamed entity recognition models. Specifically, we employ a diverse set of 400\nautomatically generated prompts, and a pairwise dataset where each pair\nconsists of one person's name from the training set and another name out of the\nset. A prompt completed with a person's name serves as input for getting the\nmodel's confidence in predicting this name. Finally, the prompt performance of\ndetecting model memorization is quantified by the percentage of name pairs for\nwhich the model has higher confidence for the name from the training set. We\nshow that the performance of different prompts varies by as much as 16\npercentage points on the same model, and prompt engineering further increases\nthe gap. Moreover, our experiments demonstrate that prompt performance is\nmodel-dependent but does generalize across different name sets. A comprehensive\nanalysis indicates how prompt performance is influenced by prompt properties,\ncontained tokens, and the model's self-attention weights on the prompt.", "published": "2024-05-05 17:19:35", "link": "http://arxiv.org/abs/2405.03004v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ATG: Benchmarking Automated Theorem Generation for Generative Language\n  Models", "abstract": "Humans can develop new theorems to explore broader and more complex\nmathematical results. While current generative language models (LMs) have\nachieved significant improvement in automatically proving theorems, their\nability to generate new or reusable theorems is still under-explored. Without\nthe new theorems, current LMs struggle to prove harder theorems that are\ndistant from the given hypotheses with the exponentially growing search space.\nTherefore, this paper proposes an Automated Theorem Generation (ATG) benchmark\nthat evaluates whether an agent can automatically generate valuable (and\npossibly brand new) theorems that are applicable for downstream theorem proving\nas reusable knowledge. Specifically, we construct the ATG benchmark by\nsplitting the Metamath library into three sets: axioms, library, and problem\nbased on their proving depth. We conduct extensive experiments to investigate\nwhether current LMs can generate theorems in the library and benefit the\nproblem theorems proving. The results demonstrate that high-quality ATG data\nfacilitates models' performances on downstream ATP. However, there is still\nroom for current LMs to develop better ATG and generate more advanced and\nhuman-like theorems. We hope the new ATG challenge can shed some light on\nadvanced complex theorem proving.", "published": "2024-05-05 02:06:37", "link": "http://arxiv.org/abs/2405.06677v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Compositional Deficiency of Large Language Models in\n  Mathematical Reasoning", "abstract": "Human cognition exhibits systematic compositionality, the algebraic ability\nto generate infinite novel combinations from finite learned components, which\nis the key to understanding and reasoning about complex logic. In this work, we\ninvestigate the compositionality of large language models (LLMs) in\nmathematical reasoning. Specifically, we construct a new dataset\n\\textsc{MathTrap} by introducing carefully designed logical traps into the\nproblem descriptions of MATH and GSM8K. Since problems with logical flaws are\nquite rare in the real world, these represent \"unseen\" cases to LLMs. Solving\nthese requires the models to systematically compose (1) the mathematical\nknowledge involved in the original problems with (2) knowledge related to the\nintroduced traps. Our experiments show that while LLMs possess both components\nof requisite knowledge, they do not \\textbf{spontaneously} combine them to\nhandle these novel cases. We explore several methods to mitigate this\ndeficiency, such as natural language prompts, few-shot demonstrations, and\nfine-tuning. Additionally, we test the recently released OpenAI o1 model and\nfind that human-like `slow thinking' helps improve the compositionality of\nLLMs. Overall, systematic compositionality remains an open challenge for large\nlanguage models.", "published": "2024-05-05 16:35:30", "link": "http://arxiv.org/abs/2405.06680v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Reflection in LLM Agents: Effects on Problem-Solving Performance", "abstract": "In this study, we investigated the effects of self-reflection in large\nlanguage models (LLMs) on problem-solving performance. We instructed nine\npopular LLMs to answer a series of multiple-choice questions to provide a\nperformance baseline. For each incorrectly answered question, we instructed\neight types of self-reflecting LLM agents to reflect on their mistakes and\nprovide themselves with guidance to improve problem-solving. Then, using this\nguidance, each self-reflecting agent attempted to re-answer the same questions.\nOur results indicate that LLM agents are able to significantly improve their\nproblem-solving performance through self-reflection ($p < 0.001$). In addition,\nwe compared the various types of self-reflection to determine their individual\ncontribution to performance. All code and data are available on GitHub at\nhttps://github.com/matthewrenze/self-reflection", "published": "2024-05-05 18:56:46", "link": "http://arxiv.org/abs/2405.06682v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Get more for less: Principled Data Selection for Warming Up Fine-Tuning\n  in LLMs", "abstract": "This work focuses on leveraging and selecting from vast, unlabeled, open data\nto pre-fine-tune a pre-trained language model. The goal is to minimize the need\nfor costly domain-specific data for subsequent fine-tuning while achieving\ndesired performance levels. While many data selection algorithms have been\ndesigned for small-scale applications, rendering them unsuitable for our\ncontext, some emerging methods do cater to language data scales. However, they\noften prioritize data that aligns with the target distribution. While this\nstrategy may be effective when training a model from scratch, it can yield\nlimited results when the model has already been pre-trained on a different\ndistribution. Differing from prior work, our key idea is to select data that\nnudges the pre-training distribution closer to the target distribution. We show\nthe optimality of this approach for fine-tuning tasks under certain conditions.\nWe demonstrate the efficacy of our methodology across a diverse array of tasks\n(NLU, NLG, zero-shot) with models up to 2.7B, showing that it consistently\nsurpasses other selection methods. Moreover, our proposed method is\nsignificantly faster than existing techniques, scaling to millions of samples\nwithin a single GPU hour. Our code is open-sourced (Code repository:\nhttps://anonymous.4open.science/r/DV4LLM-D761/ ). While fine-tuning offers\nsignificant potential for enhancing performance across diverse tasks, its\nassociated costs often limit its widespread adoption; with this work, we hope\nto lay the groundwork for cost-effective fine-tuning, making its benefits more\naccessible.", "published": "2024-05-05 00:08:00", "link": "http://arxiv.org/abs/2405.02774v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Stochastic RAG: End-to-End Retrieval-Augmented Generation through\n  Expected Utility Maximization", "abstract": "This paper introduces Stochastic RAG--a novel approach for end-to-end\noptimization of retrieval-augmented generation (RAG) models that relaxes the\nsimplifying assumptions of marginalization and document independence, made in\nmost prior work. Stochastic RAG casts the retrieval process in RAG as a\nstochastic sampling without replacement process. Through this formulation, we\nemploy straight-through Gumbel-top-k that provides a differentiable\napproximation for sampling without replacement and enables effective end-to-end\noptimization for RAG. We conduct extensive experiments on seven diverse\ndatasets on a wide range of tasks, from open-domain question answering to fact\nverification to slot-filling for relation extraction and to dialogue systems.\nBy applying this optimization method to a recent and effective RAG model, we\nadvance state-of-the-art results on six out of seven datasets.", "published": "2024-05-05 05:42:33", "link": "http://arxiv.org/abs/2405.02816v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for\n  Language Models", "abstract": "We introduce LexBench, a comprehensive evaluation suite enabled to test\nlanguage models (LMs) on ten semantic phrase processing tasks. Unlike prior\nstudies, it is the first work to propose a framework from the comparative\nperspective to model the general semantic phrase (i.e., lexical collocation)\nand three fine-grained semantic phrases, including idiomatic expression, noun\ncompound, and verbal construction. Thanks to \\ourbenchmark, we assess the\nperformance of 15 LMs across model architectures and parameter scales in\nclassification, extraction, and interpretation tasks. Through the experiments,\nwe first validate the scaling law and find that, as expected, large models\nexcel better than the smaller ones in most tasks. Second, we investigate\nfurther through the scaling semantic relation categorization and find that\nfew-shot LMs still lag behind vanilla fine-tuned models in the task. Third,\nthrough human evaluation, we find that the performance of strong models is\ncomparable to the human level regarding semantic phrase processing. Our\nbenchmarking findings can serve future research aiming to improve the generic\ncapability of LMs on semantic phrase comprehension. Our source code and data\nare available at https://github.com/jacklanda/LexBench", "published": "2024-05-05 09:20:38", "link": "http://arxiv.org/abs/2405.02861v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Overconfidence is Key: Verbalized Uncertainty Evaluation in Large\n  Language and Vision-Language Models", "abstract": "Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field\nof AI by their ability to generate human-like text and understand images, but\nensuring their reliability is crucial. This paper aims to evaluate the ability\nof LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro\nVision) to estimate their verbalized uncertainty via prompting. We propose the\nnew Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities\nvia difficult queries and object counting, and the Net Calibration Error (NCE)\nto measure direction of miscalibration. Results show that both LLMs and VLMs\nhave a high calibration error and are overconfident most of the time,\nindicating a poor capability for uncertainty estimation. Additionally we\ndevelop prompts for regression tasks, and we show that VLMs have poor\ncalibration when producing mean/standard deviation and 95% confidence\nintervals.", "published": "2024-05-05 12:51:38", "link": "http://arxiv.org/abs/2405.02917v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "E-TSL: A Continuous Educational Turkish Sign Language Dataset with\n  Baseline Methods", "abstract": "This study introduces the continuous Educational Turkish Sign Language\n(E-TSL) dataset, collected from online Turkish language lessons for 5th, 6th,\nand 8th grades. The dataset comprises 1,410 videos totaling nearly 24 hours and\nincludes performances from 11 signers. Turkish, an agglutinative language,\nposes unique challenges for sign language translation, particularly with a\nvocabulary where 64% are singleton words and 85% are rare words, appearing less\nthan five times. We developed two baseline models to address these challenges:\nthe Pose to Text Transformer (P2T-T) and the Graph Neural Network based\nTransformer (GNN-T) models. The GNN-T model achieved 19.13% BLEU-1 score and\n3.28% BLEU-4 score, presenting a significant challenge compared to existing\nbenchmarks. The P2T-T model, while demonstrating slightly lower performance in\nBLEU scores, achieved a higher ROUGE-L score of 22.09%. Additionally, we\nbenchmarked our model using the well-known PHOENIX-Weather 2014T dataset to\nvalidate our approach.", "published": "2024-05-05 16:07:23", "link": "http://arxiv.org/abs/2405.02984v2", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Parameter-Efficient Fine-Tuning with Discrete Fourier Transform", "abstract": "Low-rank adaptation~(LoRA) has recently gained much interest in fine-tuning\nfoundation models. It effectively reduces the number of trainable parameters by\nincorporating low-rank matrices $A$ and $B$ to represent the weight change,\ni.e., $\\Delta W=BA$. Despite LoRA's progress, it faces storage challenges when\nhandling extensive customization adaptations or larger base models. In this\nwork, we aim to further compress trainable parameters by enjoying the powerful\nexpressiveness of the Fourier transform. Specifically, we introduce FourierFT,\nwhich treats $\\Delta W$ as a matrix in the spatial domain and learns only a\nsmall fraction of its spectral coefficients. With the trained spectral\ncoefficients, we implement the inverse discrete Fourier transform to recover\n$\\Delta W$. Empirically, our FourierFT method shows comparable or better\nperformance with fewer parameters than LoRA on various tasks, including natural\nlanguage understanding, natural language generation, instruction tuning, and\nimage classification. For example, when performing instruction tuning on the\nLLaMA2-7B model, FourierFT surpasses LoRA with only 0.064M trainable\nparameters, compared to LoRA's 33.5M. Our code is released at\n\\url{https://github.com/Chaos96/fourierft}.", "published": "2024-05-05 17:15:24", "link": "http://arxiv.org/abs/2405.03003v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "On the performativity of SDG classifications in large bibliometric\n  databases", "abstract": "Large bibliometric databases, such as Web of Science, Scopus, and OpenAlex,\nfacilitate bibliometric analyses, but are performative, affecting the\nvisibility of scientific outputs and the impact measurement of participating\nentities. Recently, these databases have taken up the UN's Sustainable\nDevelopment Goals (SDGs) in their respective classifications, which have been\ncriticised for their diverging nature. This work proposes using the feature of\nlarge language models (LLMs) to learn about the \"data bias\" injected by diverse\nSDG classifications into bibliometric data by exploring five SDGs. We build a\nLLM that is fine-tuned in parallel by the diverse SDG classifications inscribed\ninto the databases' SDG classifications. Our results show high sensitivity in\nmodel architecture, classified publications, fine-tuning process, and natural\nlanguage generation. The wide arbitrariness at different levels raises concerns\nabout using LLM in research practice.", "published": "2024-05-05 17:28:54", "link": "http://arxiv.org/abs/2405.03007v1", "categories": ["cs.DL", "cs.AI", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Leveraging Lecture Content for Improved Feedback: Explorations with\n  GPT-4 and Retrieval Augmented Generation", "abstract": "This paper presents the use of Retrieval Augmented Generation (RAG) to\nimprove the feedback generated by Large Language Models for programming tasks.\nFor this purpose, corresponding lecture recordings were transcribed and made\navailable to the Large Language Model GPT-4 as external knowledge source\ntogether with timestamps as metainformation by using RAG. The purpose of this\nis to prevent hallucinations and to enforce the use of the technical terms and\nphrases from the lecture. In an exercise platform developed to solve\nprogramming problems for an introductory programming lecture, students can\nrequest feedback on their solutions generated by GPT-4. For this task GPT-4\nreceives the students' code solution, the compiler output, the result of unit\ntests and the relevant passages from the lecture notes available through the\nuse of RAG as additional context. The feedback generated by GPT-4 should guide\nstudents to solve problems independently and link to the lecture content, using\nthe time stamps of the transcript as meta-information. In this way, the\ncorresponding lecture videos can be viewed immediately at the corresponding\npositions. For the evaluation, students worked with the tool in a workshop and\ndecided for each feedback whether it should be extended by RAG or not. First\nresults based on a questionnaire and the collected usage data show that the use\nof RAG can improve feedback generation and is preferred by students in some\nsituations. Due to the slower speed of feedback generation, the benefits are\nsituation dependent.", "published": "2024-05-05 18:32:06", "link": "http://arxiv.org/abs/2405.06681v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Steered Response Power for Sound Source Localization: A Tutorial Review", "abstract": "In the last three decades, the Steered Response Power (SRP) method has been\nwidely used for the task of Sound Source Localization (SSL), due to its\nsatisfactory localization performance on moderately reverberant and noisy\nscenarios. Many works have analyzed and extended the original SRP method to\nreduce its computational cost, to allow it to locate multiple sources, or to\nimprove its performance in adverse environments. In this work, we review over\n200 papers on the SRP method and its variants, with emphasis on the SRP-PHAT\nmethod. We also present eXtensible-SRP, or X-SRP, a generalized and modularized\nversion of the SRP algorithm which allows the reviewed extensions to be\nimplemented. We provide a Python implementation of the algorithm which includes\nselected extensions from the literature.", "published": "2024-05-05 16:29:43", "link": "http://arxiv.org/abs/2405.02991v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Mozart's Touch: A Lightweight Multi-modal Music Generation Framework\n  Based on Pre-Trained Large Models", "abstract": "In recent years, AI-Generated Content (AIGC) has witnessed rapid\nadvancements, facilitating the creation of music, images, and other artistic\nforms across a wide range of industries. However, current models for image- and\nvideo-to-music synthesis struggle to capture the nuanced emotions and\natmosphere conveyed by visual content. To fill this gap, we propose Mozart's\nTouch, a multi-modal music generation framework capable of generating music\naligned with cross-modal inputs such as images, videos, and text. The framework\nconsists of three key components: Multi-modal Captioning Module, Large Language\nModel (LLM) understanding \\& Bridging Module, and Music Generation Module.\nUnlike traditional end-to-end methods, Mozart's Touch uses LLMs to accurately\ninterpret visual elements without requiring the training or fine-tuning of\nmusic generation models, providing efficiency and transparency through clear,\ninterpretable prompts. We also introduce the \"LLM-Bridge\" method to resolve the\nheterogeneous representation challenges between descriptive texts from\ndifferent modalities. Through a series of objective and subjective evaluations,\nwe demonstrate that Mozart's Touch outperforms current state-of-the-art models.\nOur code and examples are available at\nhttps://github.com/TiffanyBlews/MozartsTouch.", "published": "2024-05-05 03:15:52", "link": "http://arxiv.org/abs/2405.02801v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RepAugment: Input-Agnostic Representation-Level Augmentation for\n  Respiratory Sound Classification", "abstract": "Recent advancements in AI have democratized its deployment as a healthcare\nassistant. While pretrained models from large-scale visual and audio datasets\nhave demonstrably generalized to this task, surprisingly, no studies have\nexplored pretrained speech models, which, as human-originated sounds,\nintuitively would share closer resemblance to lung sounds. This paper explores\nthe efficacy of pretrained speech models for respiratory sound classification.\nWe find that there is a characterization gap between speech and lung sound\nsamples, and to bridge this gap, data augmentation is essential. However, the\nmost widely used augmentation technique for audio and speech, SpecAugment,\nrequires 2-dimensional spectrogram format and cannot be applied to models\npretrained on speech waveforms. To address this, we propose RepAugment, an\ninput-agnostic representation-level augmentation technique that outperforms\nSpecAugment, but is also suitable for respiratory sound classification with\nwaveform pretrained models. Experimental results show that our approach\noutperforms the SpecAugment, demonstrating a substantial improvement in the\naccuracy of minority disease classes, reaching up to 7.14%.", "published": "2024-05-05 16:45:46", "link": "http://arxiv.org/abs/2405.02996v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sim2Real Transfer for Audio-Visual Navigation with Frequency-Adaptive\n  Acoustic Field Prediction", "abstract": "Sim2real transfer has received increasing attention lately due to the success\nof learning robotic tasks in simulation end-to-end. While there has been a lot\nof progress in transferring vision-based navigation policies, the existing\nsim2real strategy for audio-visual navigation performs data augmentation\nempirically without measuring the acoustic gap. The sound differs from light in\nthat it spans across much wider frequencies and thus requires a different\nsolution for sim2real. We propose the first treatment of sim2real for\naudio-visual navigation by disentangling it into acoustic field prediction\n(AFP) and waypoint navigation. We first validate our design choice in the\nSoundSpaces simulator and show improvement on the Continuous AudioGoal\nnavigation benchmark. We then collect real-world data to measure the spectral\ndifference between the simulation and the real world by training AFP models\nthat only take a specific frequency subband as input. We further propose a\nfrequency-adaptive strategy that intelligently selects the best frequency band\nfor prediction based on both the measured spectral difference and the energy\ndistribution of the received audio, which improves the performance on the real\ndata. Lastly, we build a real robot platform and show that the transferred\npolicy can successfully navigate to sounding objects. This work demonstrates\nthe potential of building intelligent agents that can see, hear, and act\nentirely from simulation, and transferring them to the real world.", "published": "2024-05-05 06:01:31", "link": "http://arxiv.org/abs/2405.02821v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.RO", "eess.AS"], "primary_category": "cs.SD"}
