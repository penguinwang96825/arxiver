{"title": "CompLex: A New Corpus for Lexical Complexity Prediction from Likert\n  Scale Data", "abstract": "Predicting which words are considered hard to understand for a given target\npopulation is a vital step in many NLP applications such as text\nsimplification. This task is commonly referred to as Complex Word\nIdentification (CWI). With a few exceptions, previous studies have approached\nthe task as a binary classification task in which systems predict a complexity\nvalue (complex vs. non-complex) for a set of target words in a text. This\nchoice is motivated by the fact that all CWI datasets compiled so far have been\nannotated using a binary annotation scheme. Our paper addresses this limitation\nby presenting the first English dataset for continuous lexical complexity\nprediction. We use a 5-point Likert scale scheme to annotate complex words in\ntexts from three sources/domains: the Bible, Europarl, and biomedical texts.\nThis resulted in a corpus of 9,476 sentences each annotated by around 7\nannotators.", "published": "2020-03-16 03:54:22", "link": "http://arxiv.org/abs/2003.07008v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stanza: A Python Natural Language Processing Toolkit for Many Human\n  Languages", "abstract": "We introduce Stanza, an open-source Python natural language processing\ntoolkit supporting 66 human languages. Compared to existing widely used\ntoolkits, Stanza features a language-agnostic fully neural pipeline for text\nanalysis, including tokenization, multi-word token expansion, lemmatization,\npart-of-speech and morphological feature tagging, dependency parsing, and named\nentity recognition. We have trained Stanza on a total of 112 datasets,\nincluding the Universal Dependencies treebanks and other multilingual corpora,\nand show that the same neural architecture generalizes well and achieves\ncompetitive performance on all languages tested. Additionally, Stanza includes\na native Python interface to the widely used Java Stanford CoreNLP software,\nwhich further extends its functionality to cover other tasks such as\ncoreference resolution and relation extraction. Source code, documentation, and\npretrained models for 66 languages are available at\nhttps://stanfordnlp.github.io/stanza.", "published": "2020-03-16 09:05:53", "link": "http://arxiv.org/abs/2003.07082v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression", "abstract": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages.", "published": "2020-03-16 20:19:21", "link": "http://arxiv.org/abs/2003.07428v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HELFI: a Hebrew-Greek-Finnish Parallel Bible Corpus with Cross-Lingual\n  Morpheme Alignment", "abstract": "Twenty-five years ago, morphologically aligned Hebrew-Finnish and\nGreek-Finnish bitexts (texts accompanied by a translation) were constructed\nmanually in order to create an analytical concordance (Luoto et al., 1997) for\na Finnish Bible translation. The creators of the bitexts recently secured the\npublisher's permission to release its fine-grained alignment, but the alignment\nwas still dependent on proprietary, third-party resources such as a copyrighted\ntext edition and proprietary morphological analyses of the source texts. In\nthis paper, we describe a nontrivial editorial process starting from the\ncreation of the original one-purpose database and ending with its\nreconstruction using only freely available text editions and annotations. This\nprocess produced an openly available dataset that contains (i) the source texts\nand their translations, (ii) the morphological analyses, (iii) the\ncross-lingual morpheme alignments.", "published": "2020-03-16 22:10:35", "link": "http://arxiv.org/abs/2003.07456v1", "categories": ["cs.CL", "J.5"], "primary_category": "cs.CL"}
{"title": "Offensive Language Identification in Greek", "abstract": "As offensive language has become a rising issue for online communities and\nsocial media platforms, researchers have been investigating ways of coping with\nabusive content and developing systems to detect its different types:\ncyberbullying, hate speech, aggression, etc. With a few notable exceptions,\nmost research on this topic so far has dealt with English. This is mostly due\nto the availability of language resources for English. To address this\nshortcoming, this paper presents the first Greek annotated dataset for\noffensive language identification: the Offensive Greek Tweet Dataset (OGTD).\nOGTD is a manually annotated dataset containing 4,779 posts from Twitter\nannotated as offensive and not offensive. Along with a detailed description of\nthe dataset, we evaluate several computational models trained and tested on\nthis data.", "published": "2020-03-16 22:47:27", "link": "http://arxiv.org/abs/2003.07459v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Formal Analysis of Multimodal Referring Strategies Under Common Ground", "abstract": "In this paper, we present an analysis of computationally generated\nmixed-modality definite referring expressions using combinations of gesture and\nlinguistic descriptions. In doing so, we expose some striking formal semantic\nproperties of the interactions between gesture and language, conditioned on the\nintroduction of content into the common ground between the (computational)\nspeaker and (human) viewer, and demonstrate how these formal features can\ncontribute to training better models to predict viewer judgment of referring\nexpressions, and potentially to the generation of more natural and informative\nreferring expressions.", "published": "2020-03-16 18:08:52", "link": "http://arxiv.org/abs/2003.07385v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Label Proportions Estimation Technique for Adversarial Domain\n  Adaptation in Text Classification", "abstract": "Many text classification tasks are domain-dependent, and various domain\nadaptation approaches have been proposed to predict unlabeled data in a new\ndomain. Domain-adversarial neural networks (DANN) and their variants have been\nused widely recently and have achieved promising results for this problem.\nHowever, most of these approaches assume that the label proportions of the\nsource and target domains are similar, which rarely holds in most real-world\nscenarios. Sometimes the label shift can be large and the DANN fails to learn\ndomain-invariant features. In this study, we focus on unsupervised domain\nadaptation of text classification with label shift and introduce a domain\nadversarial network with label proportions estimation (DAN-LPE) framework. The\nDAN-LPE simultaneously trains a domain adversarial net and processes label\nproportions estimation by the confusion of the source domain and the\npredictions of the target domain. Experiments show the DAN-LPE achieves a good\nestimate of the target label distributions and reduces the label shift to\nimprove the classification performance.", "published": "2020-03-16 21:16:00", "link": "http://arxiv.org/abs/2003.07444v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TRANS-BLSTM: Transformer with Bidirectional LSTM for Language\n  Understanding", "abstract": "Bidirectional Encoder Representations from Transformers (BERT) has recently\nachieved state-of-the-art performance on a broad range of NLP tasks including\nsentence classification, machine translation, and question answering. The BERT\nmodel architecture is derived primarily from the transformer. Prior to the\ntransformer era, bidirectional Long Short-Term Memory (BLSTM) has been the\ndominant modeling architecture for neural machine translation and question\nanswering. In this paper, we investigate how these two modeling techniques can\nbe combined to create a more powerful model architecture. We propose a new\narchitecture denoted as Transformer with BLSTM (TRANS-BLSTM) which has a BLSTM\nlayer integrated to each transformer block, leading to a joint modeling\nframework for transformer and BLSTM. We show that TRANS-BLSTM models\nconsistently lead to improvements in accuracy compared to BERT baselines in\nGLUE and SQuAD 1.1 experiments. Our TRANS-BLSTM model obtains an F1 score of\n94.01% on the SQuAD 1.1 development dataset, which is comparable to the\nstate-of-the-art result.", "published": "2020-03-16 03:38:51", "link": "http://arxiv.org/abs/2003.07000v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Key Phrase Classification in Complex Assignments", "abstract": "Complex assignments typically consist of open-ended questions with large and\ndiverse content in the context of both classroom and online graduate programs.\nWith the sheer scale of these programs comes a variety of problems in peer and\nexpert feedback, including rogue reviews. As such with the hope of identifying\nimportant contents needed for the review, in this work we present a very first\nwork on key phrase classification with a detailed empirical study on\ntraditional and most recent language modeling approaches. From this study, we\nfind that the task of classification of key phrases is ambiguous at a human\nlevel producing Cohen's kappa of 0.77 on a new data set. Both pretrained\nlanguage models and simple TFIDF SVM classifiers produce similar results with a\nformer producing average of 0.6 F1 higher than the latter. We finally derive\npractical advice from our extensive empirical and model interpretability\nresults for those interested in key phrase classification from educational\nreports in the future.", "published": "2020-03-16 04:25:37", "link": "http://arxiv.org/abs/2003.07019v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic", "abstract": "Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.", "published": "2020-03-16 08:51:40", "link": "http://arxiv.org/abs/2003.07074v3", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "A Survey on Contextual Embeddings", "abstract": "Contextual embeddings, such as ELMo and BERT, move beyond global word\nrepresentations like Word2Vec and achieve ground-breaking performance on a wide\nrange of natural language processing tasks. Contextual embeddings assign each\nword a representation based on its context, thereby capturing uses of words\nacross varied contexts and encoding knowledge that transfers across languages.\nIn this survey, we review existing contextual embedding models, cross-lingual\npolyglot pre-training, the application of contextual embeddings in downstream\ntasks, model compression, and model analyses.", "published": "2020-03-16 15:22:22", "link": "http://arxiv.org/abs/2003.07278v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Harnessing Explanations to Bridge AI and Humans", "abstract": "Machine learning models are increasingly integrated into societally critical\napplications such as recidivism prediction and medical diagnosis, thanks to\ntheir superior predictive power. In these applications, however, full\nautomation is often not desired due to ethical and legal concerns. The research\ncommunity has thus ventured into developing interpretable methods that explain\nmachine predictions. While these explanations are meant to assist humans in\nunderstanding machine predictions and thereby allowing humans to make better\ndecisions, this hypothesis is not supported in many recent studies. To improve\nhuman decision-making with AI assistance, we propose future directions for\nclosing the gap between the efficacy of explanations and improvement in human\nperformance.", "published": "2020-03-16 18:00:02", "link": "http://arxiv.org/abs/2003.07370v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Parallel sequence tagging for concept recognition", "abstract": "Background: Named Entity Recognition (NER) and Normalisation (NEN) are core\ncomponents of any text-mining system for biomedical texts. In a traditional\nconcept-recognition pipeline, these tasks are combined in a serial way, which\nis inherently prone to error propagation from NER to NEN. We propose a parallel\narchitecture, where both NER and NEN are modeled as a sequence-labeling task,\noperating directly on the source text. We examine different harmonisation\nstrategies for merging the predictions of the two classifiers into a single\noutput sequence. Results: We test our approach on the recent Version 4 of the\nCRAFT corpus. In all 20 annotation sets of the concept-annotation task, our\nsystem outperforms the pipeline system reported as a baseline in the CRAFT\nshared task 2019. Conclusions: Our analysis shows that the strengths of the two\nclassifiers can be combined in a fruitful way. However, prediction\nharmonisation requires individual calibration on a development set for each\nannotation set. This allows achieving a good trade-off between established\nknowledge (training set) and novel information (unseen concepts). Availability\nand Implementation: Source code freely available for download at\nhttps://github.com/OntoGene/craft-st. Supplementary data are available at arXiv\nonline.", "published": "2020-03-16 19:41:07", "link": "http://arxiv.org/abs/2003.07424v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LAXARY: A Trustworthy Explainable Twitter Analysis Model for\n  Post-Traumatic Stress Disorder Assessment", "abstract": "Veteran mental health is a significant national problem as large number of\nveterans are returning from the recent war in Iraq and continued military\npresence in Afghanistan. While significant existing works have investigated\ntwitter posts-based Post Traumatic Stress Disorder (PTSD) assessment using\nblackbox machine learning techniques, these frameworks cannot be trusted by the\nclinicians due to the lack of clinical explainability. To obtain the trust of\nclinicians, we explore the big question, can twitter posts provide enough\ninformation to fill up clinical PTSD assessment surveys that have been\ntraditionally trusted by clinicians? To answer the above question, we propose,\nLAXARY (Linguistic Analysis-based Exaplainable Inquiry) model, a novel\nExplainable Artificial Intelligent (XAI) model to detect and represent PTSD\nassessment of twitter users using a modified Linguistic Inquiry and Word Count\n(LIWC) analysis. First, we employ clinically validated survey tools for\ncollecting clinical PTSD assessment data from real twitter users and develop a\nPTSD Linguistic Dictionary using the PTSD assessment survey results. Then, we\nuse the PTSD Linguistic Dictionary along with machine learning model to fill up\nthe survey tools towards detecting PTSD status and its intensity of\ncorresponding twitter users. Our experimental evaluation on 210 clinically\nvalidated veteran twitter users provides promising accuracies of both PTSD\nclassification and its intensity estimation. We also evaluate our developed\nPTSD Linguistic Dictionary's reliability and validity.", "published": "2020-03-16 20:32:24", "link": "http://arxiv.org/abs/2003.07433v2", "categories": ["cs.CL", "cs.AI", "cs.SI", "IEEE", "I.2.0"], "primary_category": "cs.CL"}
{"title": "Deep Learning for Automatic Tracking of Tongue Surface in Real-time\n  Ultrasound Videos, Landmarks instead of Contours", "abstract": "One usage of medical ultrasound imaging is to visualize and characterize\nhuman tongue shape and motion during a real-time speech to study healthy or\nimpaired speech production. Due to the low-contrast characteristic and noisy\nnature of ultrasound images, it might require expertise for non-expert users to\nrecognize tongue gestures in applications such as visual training of a second\nlanguage. Moreover, quantitative analysis of tongue motion needs the tongue\ndorsum contour to be extracted, tracked, and visualized. Manual tongue contour\nextraction is a cumbersome, subjective, and error-prone task. Furthermore, it\nis not a feasible solution for real-time applications. The growth of deep\nlearning has been vigorously exploited in various computer vision tasks,\nincluding ultrasound tongue contour tracking. In the current methods, the\nprocess of tongue contour extraction comprises two steps of image segmentation\nand post-processing. This paper presents a new novel approach of automatic and\nreal-time tongue contour tracking using deep neural networks. In the proposed\nmethod, instead of the two-step procedure, landmarks of the tongue surface are\ntracked. This novel idea enables researchers in this filed to benefits from\navailable previously annotated databases to achieve high accuracy results. Our\nexperiment disclosed the outstanding performances of the proposed technique in\nterms of generalization, performance, and accuracy.", "published": "2020-03-16 00:38:13", "link": "http://arxiv.org/abs/2003.08808v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Cost-Sensitive BERT for Generalisable Sentence Classification with\n  Imbalanced Data", "abstract": "The automatic identification of propaganda has gained significance in recent\nyears due to technological and social changes in the way news is generated and\nconsumed. That this task can be addressed effectively using BERT, a powerful\nnew architecture which can be fine-tuned for text classification tasks, is not\nsurprising. However, propaganda detection, like other tasks that deal with news\ndocuments and other forms of decontextualized social communication (e.g.\nsentiment analysis), inherently deals with data whose categories are\nsimultaneously imbalanced and dissimilar. We show that BERT, while capable of\nhandling imbalanced classes with no additional data augmentation, does not\ngeneralise well when the training and test data are sufficiently dissimilar (as\nis often the case with news sources, whose topics evolve over time). We show\nhow to address this problem by providing a statistical measure of similarity\nbetween datasets and a method of incorporating cost-weighting into BERT when\nthe training and test sets are dissimilar. We test these methods on the\nPropaganda Techniques Corpus (PTC) and achieve the second-highest score on\nsentence-level propaganda classification.", "published": "2020-03-16 19:10:57", "link": "http://arxiv.org/abs/2003.11563v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multi-modal Multi-channel Target Speech Separation", "abstract": "Target speech separation refers to extracting a target speaker's voice from\nan overlapped audio of simultaneous talkers. Previously the use of visual\nmodality for target speech separation has demonstrated great potentials. This\nwork proposes a general multi-modal framework for target speech separation by\nutilizing all the available information of the target speaker, including\nhis/her spatial location, voice characteristics and lip movements. Also, under\nthis framework, we investigate on the fusion methods for multi-modal joint\nmodeling. A factorized attention-based fusion method is proposed to aggregate\nthe high-level semantic information of multi-modalities at embedding level.\nThis method firstly factorizes the mixture audio into a set of acoustic\nsubspaces, then leverages the target's information from other modalities to\nenhance these subspace acoustic embeddings with a learnable attention scheme.\nTo validate the robustness of proposed multi-modal separation model in\npractical scenarios, the system was evaluated under the condition that one of\nthe modalities is temporarily missing, invalid or corrupted. Experiments are\nconducted on a large-scale audio-visual dataset collected from YouTube (to be\nreleased) that spatialized by simulated room impulse responses (RIRs).\nExperiment results illustrate that our proposed multi-modal framework\nsignificantly outperforms single-modal and bi-modal speech separation\napproaches, while can still support real-time processing.", "published": "2020-03-16 05:33:54", "link": "http://arxiv.org/abs/2003.07032v2", "categories": ["eess.AS", "cs.SD", "eess.IV"], "primary_category": "eess.AS"}
{"title": "TensorFlow Audio Models in Essentia", "abstract": "Essentia is a reference open-source C++/Python library for audio and music\nanalysis. In this work, we present a set of algorithms that employ TensorFlow\nin Essentia, allow predictions with pre-trained deep learning models, and are\ndesigned to offer flexibility of use, easy extensibility, and real-time\ninference. To show the potential of this new interface with TensorFlow, we\nprovide a number of pre-trained state-of-the-art music tagging and\nclassification CNN models. We run an extensive evaluation of the developed\nmodels. In particular, we assess the generalization capabilities in a\ncross-collection evaluation utilizing both external tag datasets as well as\nmanual annotations tailored to the taxonomies of our models.", "published": "2020-03-16 18:23:30", "link": "http://arxiv.org/abs/2003.07393v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
