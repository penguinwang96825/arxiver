{"title": "Improving LLMs' Learning for Coreference Resolution", "abstract": "Coreference Resolution (CR) is crucial for many NLP tasks, but existing LLMs\nstruggle with hallucination and under-performance. In this paper, we\ninvestigate the limitations of existing LLM-based approaches to CR-specifically\nthe Question-Answering (QA) Template and Document Template methods and propose\ntwo novel techniques: Reversed Training with Joint Inference and Iterative\nDocument Generation. Our experiments show that Reversed Training improves the\nQA Template method, while Iterative Document Generation eliminates\nhallucinations in the generated source text and boosts coreference resolution.\nIntegrating these methods and techniques offers an effective and robust\nsolution to LLM-based coreference resolution.", "published": "2025-09-14 23:08:35", "link": "http://arxiv.org/abs/2509.11466v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CEMTM: Contextual Embedding-based Multimodal Topic Modeling", "abstract": "We introduce CEMTM, a context-enhanced multimodal topic model designed to\ninfer coherent and interpretable topic structures from both short and long\ndocuments containing text and images. CEMTM builds on fine-tuned large vision\nlanguage models (LVLMs) to obtain contextualized embeddings, and employs a\ndistributional attention mechanism to weight token-level contributions to topic\ninference. A reconstruction objective aligns topic-based representations with\nthe document embedding, encouraging semantic consistency across modalities.\nUnlike existing approaches, CEMTM can process multiple images per document\nwithout repeated encoding and maintains interpretability through explicit\nword-topic and document-topic distributions. Extensive experiments on six\nmultimodal benchmarks show that CEMTM consistently outperforms unimodal and\nmultimodal baselines, achieving a remarkable average LLM score of 2.61. Further\nanalysis shows its effectiveness in downstream few-shot retrieval and its\nability to capture visually grounded semantics in complex domains such as\nscientific articles.", "published": "2025-09-14 23:07:46", "link": "http://arxiv.org/abs/2509.11465v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting", "abstract": "Prior works in multi-objective reinforcement learning typically use linear\nreward scalarization with fixed weights, which provably fail to capture\nnon-convex Pareto fronts and thus yield suboptimal results. This limitation\nbecomes especially critical in online preference alignment for large language\nmodels. Here, stochastic trajectories generated by parameterized policies\ncreate highly non-linear and non-convex mappings from parameters to objectives\nthat no single static weighting scheme can find optimal trade-offs. We address\nthis limitation by introducing dynamic reward weighting, which adaptively\nadjusts reward weights during the online reinforcement learning process. Unlike\nexisting approaches that rely on fixed-weight interpolation, our dynamic\nweighting continuously balances and prioritizes objectives in training,\nfacilitating effective exploration of Pareto fronts in objective space. We\nintroduce two approaches of increasing sophistication and generalizability: (1)\nhypervolume-guided weight adaptation and (2) gradient-based weight\noptimization, offering a versatile toolkit for online multi-objective\nalignment. Our extensive experiments demonstrate their compatibility with\ncommonly used online reinforcement learning algorithms (including GRPO,\nREINFORCE, and RLOO), effectiveness across multiple mathematical reasoning\ndatasets, and applicability to different model families, consistently achieving\nPareto dominant solutions with fewer training steps than fixed-weight linear\nscalarization baselines.", "published": "2025-09-14 21:56:35", "link": "http://arxiv.org/abs/2509.11452v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media", "abstract": "The emergence of decentralized social media platforms presents new\nopportunities and challenges for real-time analysis of public discourse. This\nstudy introduces CognitiveSky, an open-source and scalable framework designed\nfor sentiment, emotion, and narrative analysis on Bluesky, a federated Twitter\nor X.com alternative. By ingesting data through Bluesky's Application\nProgramming Interface (API), CognitiveSky applies transformer-based models to\nannotate large-scale user-generated content and produces structured and\nanalyzable outputs. These summaries drive a dynamic dashboard that visualizes\nevolving patterns in emotion, activity, and conversation topics. Built entirely\non free-tier infrastructure, CognitiveSky achieves both low operational cost\nand high accessibility. While demonstrated here for monitoring mental health\ndiscourse, its modular design enables applications across domains such as\ndisinformation detection, crisis response, and civic sentiment analysis. By\nbridging large language models with decentralized networks, CognitiveSky offers\na transparent, extensible tool for computational social science in an era of\nshifting digital ecosystems.", "published": "2025-09-14 21:37:24", "link": "http://arxiv.org/abs/2509.11444v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Transformer-Based Cross-Platform Analysis of Public Discourse on the 15-Minute City Paradigm", "abstract": "This study presents the first multi-platform sentiment analysis of public\nopinion on the 15-minute city concept across Twitter, Reddit, and news media.\nUsing compressed transformer models and Llama-3-8B for annotation, we classify\nsentiment across heterogeneous text domains. Our pipeline handles long-form and\nshort-form text, supports consistent annotation, and enables reproducible\nevaluation. We benchmark five models (DistilRoBERTa, DistilBERT, MiniLM,\nELECTRA, TinyBERT) using stratified 5-fold cross-validation, reporting\nF1-score, AUC, and training time. DistilRoBERTa achieved the highest F1\n(0.8292), TinyBERT the best efficiency, and MiniLM the best cross-platform\nconsistency. Results show News data yields inflated performance due to class\nimbalance, Reddit suffers from summarization loss, and Twitter offers moderate\nchallenge. Compressed models perform competitively, challenging assumptions\nthat larger models are necessary. We identify platform-specific trade-offs and\npropose directions for scalable, real-world sentiment classification in urban\nplanning discourse.", "published": "2025-09-14 21:36:24", "link": "http://arxiv.org/abs/2509.11443v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications", "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced\nsolutions across various domains, from political science to software\ndevelopment. However, these models are constrained by their training data,\nwhich is static and limited to information available up to a specific date.\nAdditionally, their generalized nature often necessitates fine-tuning --\nwhether for classification or instructional purposes -- to effectively perform\nspecific downstream tasks. AI agents, leveraging LLMs as their core, mitigate\nsome of these limitations by accessing external tools and real-time data,\nenabling applications such as live weather reporting and data analysis. In\nindustrial settings, AI agents are transforming operations by enhancing\ndecision-making, predictive maintenance, and process optimization. For example,\nin manufacturing, AI agents enable near-autonomous systems that boost\nproductivity and support real-time decision-making. Despite these advancements,\nAI agents remain vulnerable to security threats, including prompt injection\nattacks, which pose significant risks to their integrity and reliability. To\naddress these challenges, this paper proposes a framework for integrating\nRole-Based Access Control (RBAC) into AI agents, providing a robust security\nguardrail. This framework aims to support the effective and scalable deployment\nof AI agents, with a focus on on-premises implementations.", "published": "2025-09-14 20:58:08", "link": "http://arxiv.org/abs/2509.11431v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs", "abstract": "Speech tokenization enables discrete representation and facilitates speech\nlanguage modeling. However, existing neural codecs capture low-level acoustic\nfeatures, overlooking the semantic and contextual cues inherent to human\nspeech. While recent efforts introduced semantic representations from\nself-supervised speech models or incorporated contextual representations from\npre-trained language models, challenges remain in aligning and unifying the\nsemantic and contextual representations. We introduce FuseCodec, which unifies\nacoustic, semantic, and contextual representations through strong cross-modal\nalignment and globally informed supervision. We propose three complementary\ntechniques: (i) Latent Representation Fusion, integrating semantic and\ncontextual features directly into the encoder latent space for robust and\nunified representation learning; (ii) Global Semantic-Contextual Supervision,\nsupervising discrete tokens with globally pooled and broadcasted\nrepresentations to enhance temporal consistency and cross-modal alignment; and\n(iii) Temporally Aligned Contextual Supervision, strengthening alignment by\ndynamically matching contextual and speech tokens within a local window for\nfine-grained token-level supervision. We further introduce FuseCodec-TTS,\ndemonstrating our methodology's applicability to zero-shot speech synthesis.\nEmpirically, FuseCodec achieves state-of-the-art performance in LibriSpeech,\nsurpassing EnCodec, SpeechTokenizer, and DAC in transcription accuracy,\nperceptual quality, intelligibility, and speaker similarity. Results highlight\nthe effectiveness of contextually and semantically guided tokenization for\nspeech tokenization and downstream tasks. Code and pretrained models are\navailable at https://github.com/mubtasimahasan/FuseCodec.", "published": "2025-09-14 20:35:36", "link": "http://arxiv.org/abs/2509.11425v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Trading-R1: Financial Trading with LLM Reasoning via Reinforcement Learning", "abstract": "Developing professional, structured reasoning on par with human financial\nanalysts and traders remains a central challenge in AI for finance, where\nmarkets demand interpretability and trust. Traditional time-series models lack\nexplainability, while LLMs face challenges in turning natural-language analysis\ninto disciplined, executable trades. Although reasoning LLMs have advanced in\nstep-by-step planning and verification, their application to risk-sensitive\nfinancial decisions is underexplored. We present Trading-R1, a\nfinancially-aware model that incorporates strategic thinking and planning for\ncomprehensive thesis composition, facts-grounded analysis, and\nvolatility-adjusted decision making. Trading-R1 aligns reasoning with trading\nprinciples through supervised fine-tuning and reinforcement learning with a\nthree-stage easy-to-hard curriculum. Training uses Tauric-TR1-DB, a 100k-sample\ncorpus spanning 18 months, 14 equities, and five heterogeneous financial data\nsources. Evaluated on six major equities and ETFs, Trading-R1 demonstrates\nimproved risk-adjusted returns and lower drawdowns compared to both open-source\nand proprietary instruction-following models as well as reasoning models. The\nsystem generates structured, evidence-based investment theses that support\ndisciplined and interpretable trading decisions. Trading-R1 Terminal will be\nreleased at https://github.com/TauricResearch/Trading-R1.", "published": "2025-09-14 20:13:41", "link": "http://arxiv.org/abs/2509.11420v1", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "primary_category": "q-fin.TR"}
{"title": "Continually Adding New Languages to Multilingual Language Models", "abstract": "Multilingual language models are trained on a fixed set of languages, and to\nsupport new languages, the models need to be retrained from scratch. This is an\nexpensive endeavor and is often infeasible, as model developers tend not to\nrelease their pre-training data. Naive approaches, such as continued\npretraining, suffer from catastrophic forgetting; however, mitigation\nstrategies like experience replay cannot be applied due to the lack of original\npretraining data. In this work, we investigate the problem of continually\nadding new languages to a multilingual model, assuming access to pretraining\ndata in only the target languages. We explore multiple approaches to address\nthis problem and propose Layer-Selective LoRA (LayRA), which adds Low-Rank\nAdapters (LoRA) to selected initial and final layers while keeping the rest of\nthe model frozen. LayRA builds on two insights: (1) LoRA reduces forgetting,\nand (2) multilingual models encode inputs in the source language in the initial\nlayers, reason in English in intermediate layers, and translate back to the\nsource language in final layers. We experiment with adding multiple\ncombinations of Galician, Swahili, and Urdu to pretrained language models and\nevaluate each method on diverse multilingual tasks. We find that LayRA provides\nthe overall best tradeoff between preserving models' capabilities in previously\nsupported languages, while being competitive with existing approaches such as\nLoRA in learning new languages. We also demonstrate that using model\narithmetic, the adapted models can be equipped with strong instruction\nfollowing abilities without access to any instruction tuning data in the target\nlanguages.", "published": "2025-09-14 20:08:15", "link": "http://arxiv.org/abs/2509.11414v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer Enhanced Relation Classification: A Comparative Analysis of Contextuality, Data Efficiency and Sequence Complexity", "abstract": "In the era of large language model, relation extraction (RE) plays an\nimportant role in information extraction through the transformation of\nunstructured raw text into structured data (Wadhwa et al., 2023). In this\npaper, we systematically compare the performance of deep supervised learning\napproaches without transformers and those with transformers. We used a series\nof non-transformer architectures such as PA-LSTM(Zhang et al., 2017),\nC-GCN(Zhang et al., 2018), and AGGCN(attention guide GCN)(Guo et al., 2019),\nand a series of transformer architectures such as BERT, RoBERTa, and R-BERT(Wu\nand He, 2019). Our comparison included traditional metrics like micro F1, as\nwell as evaluations in different scenarios, varying sentence lengths, and\ndifferent percentages of the dataset for training. Our experiments were\nconducted on TACRED, TACREV, and RE-TACRED. The results show that\ntransformer-based models outperform non-transformer models, achieving micro F1\nscores of 80-90% compared to 64-67% for non-transformer models. Additionally,\nwe briefly review the research journey in supervised relation classification\nand discuss the role and current status of large language models (LLMs) in\nrelation extraction.", "published": "2025-09-14 18:11:31", "link": "http://arxiv.org/abs/2509.11374v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "!MSA at AraHealthQA 2025 Shared Task: Enhancing LLM Performance for Arabic Clinical Question Answering through Prompt Engineering and Ensemble Learning", "abstract": "We present our systems for Track 2 (General Arabic Health QA, MedArabiQ) of\nthe AraHealthQA-2025 shared task, where our methodology secured 2nd place in\nboth Sub-Task 1 (multiple-choice question answering) and Sub-Task 2 (open-ended\nquestion answering) in Arabic clinical contexts. For Sub-Task 1, we leverage\nthe Gemini 2.5 Flash model with few-shot prompting, dataset preprocessing, and\nan ensemble of three prompt configurations to improve classification accuracy\non standard, biased, and fill-in-the-blank questions. For Sub-Task 2, we employ\na unified prompt with the same model, incorporating role-playing as an Arabic\nmedical expert, few-shot examples, and post-processing to generate concise\nresponses across fill-in-the-blank, patient-doctor Q&A, GEC, and paraphrased\nvariants.", "published": "2025-09-14 17:39:58", "link": "http://arxiv.org/abs/2509.11365v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ko-PIQA: A Korean Physical Commonsense Reasoning Dataset with Cultural Context", "abstract": "Physical commonsense reasoning datasets like PIQA are predominantly\nEnglish-centric and lack cultural diversity. We introduce Ko-PIQA, a Korean\nphysical commonsense reasoning dataset that incorporates cultural context.\nStarting from 3.01 million web-crawled questions, we employed a multi-stage\nfiltering approach using three language models to identify 11,553 PIQA-style\nquestions. Through GPT-4o refinement and human validation, we obtained 441\nhigh-quality question-answer pairs. A key feature of Ko-PIQA is its cultural\ngrounding: 19.7\\% of questions contain culturally specific elements like\ntraditional Korean foods (kimchi), clothing (hanbok), and specialized\nappliances (kimchi refrigerators) that require culturally-aware reasoning\nbeyond direct translation. We evaluate seven language models on Ko-PIQA, with\nthe best model achieving 83.22\\% accuracy while the weakest reaches only\n59.86\\%, demonstrating significant room for improvement. Models particularly\nstruggle with culturally specific scenarios, highlighting the importance of\nculturally diverse datasets. Ko-PIQA serves as both a benchmark for Korean\nlanguage models and a foundation for more inclusive commonsense reasoning\nresearch. The dataset and code will be publicly available.", "published": "2025-09-14 14:47:04", "link": "http://arxiv.org/abs/2509.11303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Opal: An Operator Algebra View of RLHF", "abstract": "We present Opal, an operator view of reinforcement learning from human\nfeedback (RLHF). Objectives are expressed as ladders of two primitives on a\nbase utility: additive penalties and multiplicative pairwise weights. We\ndescribe a simple reduction law with if-and-only-if conditions: such ladders\ncollapse to a normal form on pairwise margins when the reference is fixed,\npenalties are additive, and weights are independent of intermediate margins.\nWhen these assumptions do not hold (reference shift, non-additive gates,\nscore-dependent weights), small examples demonstrate non-reducibility.\n  Building on this view, we introduce GKPO (Generalized Kernel Preference\nObject), a canonical schema in which many RLHF methods can be represented and,\nwhen reducible, mapped back from. GKPO provides a standard JSON serialization,\ncanonicalization and hashing rules, and explicit flags with finite witnesses\nwhen assumptions fail.\n  We illustrate these ideas with GKPO examples for DPO, RRHF, and ORPO, along\nwith cross-method conversions (where assumptions permit) and minimal stress\ntests (SHIFT/GATE/SCORE) that highlight non-reducibility. A lightweight Python\nreference library accompanies the schema, implementing canonical hashing and\nadapters for DPO and RRHF.", "published": "2025-09-14 14:42:39", "link": "http://arxiv.org/abs/2509.11298v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T05, 68T07, 68Q32, 62H30, 62F15, 90C30", "I.2.6; I.2.7; I.2.8; G.3; G.1.6"], "primary_category": "cs.LG"}
{"title": "The Prompt Engineering Report Distilled: Quick Start Guide for Life Sciences", "abstract": "Developing effective prompts demands significant cognitive investment to\ngenerate reliable, high-quality responses from Large Language Models (LLMs). By\ndeploying case-specific prompt engineering techniques that streamline\nfrequently performed life sciences workflows, researchers could achieve\nsubstantial efficiency gains that far exceed the initial time investment\nrequired to master these techniques. The Prompt Report published in 2025\noutlined 58 different text-based prompt engineering techniques, highlighting\nthe numerous ways prompts could be constructed. To provide actionable\nguidelines and reduce the friction of navigating these various approaches, we\ndistil this report to focus on 6 core techniques: zero-shot, few-shot\napproaches, thought generation, ensembling, self-criticism, and decomposition.\nWe breakdown the significance of each approach and ground it in use cases\nrelevant to life sciences, from literature summarization and data extraction to\neditorial tasks. We provide detailed recommendations for how prompts should and\nshouldn't be structured, addressing common pitfalls including multi-turn\nconversation degradation, hallucinations, and distinctions between reasoning\nand non-reasoning models. We examine context window limitations, agentic tools\nlike Claude Code, while analyzing the effectiveness of Deep Research tools\nacross OpenAI, Google, Anthropic and Perplexity platforms, discussing current\nlimitations. We demonstrate how prompt engineering can augment rather than\nreplace existing established individual practices around data processing and\ndocument editing. Our aim is to provide actionable guidance on core prompt\nengineering principles, and to facilitate the transition from opportunistic\nprompting to an effective, low-friction systematic practice that contributes to\nhigher quality research.", "published": "2025-09-14 14:39:35", "link": "http://arxiv.org/abs/2509.11295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Hallucinations in Large Vision-Language Models by Self-Injecting Hallucinations", "abstract": "Large Vision-Language Models (LVLMs) suffer from serious hallucination\nproblems, where the model-generated responses are inconsistent with the visual\ninputs. Existing hallucination mitigation methods are mainly based on\npreference alignment and require external human annotations or auxiliary models\nfor preference data collection, which increase costs and limit sustainable\nimprovement. To tackle these challenges, we propose Autonomous Preference\nAlignment via Self-Injection (APASI), a novel and generalizable method that\nmitigates hallucinations without external dependencies. APASI leverages the\ntarget LVLM to self-inject hallucinations into a generated response, creating a\npair of responses with varying preference levels. During the self-injection\nprocess, the dis-preferred response is generated based on three key\nobservations of hallucinations, ensuring it simulates real hallucination\npatterns. This fidelity offers an accurate learning signal for hallucination\nmitigation. Moreover, APASI incorporates an iterative alignment training\nstrategy combined with curriculum learning to periodically update the\npreference data with increasing challenge, enabling stable and continuous\nenhancement of the LVLM. Extensive experiments across six benchmarks show that\nAPASI not only effectively mitigates hallucinations for three baseline models\nbut also achieves comparable or even superior performance to alignment-based\nmethods with external dependency, thereby demonstrating its effectiveness and\ngeneralization capability. The code is available at\nhttps://github.com/davidluciolu/APASI.", "published": "2025-09-14 14:26:53", "link": "http://arxiv.org/abs/2509.11287v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evalet: Evaluating Large Language Models by Fragmenting Outputs into Functions", "abstract": "Practitioners increasingly rely on Large Language Models (LLMs) to evaluate\ngenerative AI outputs through \"LLM-as-a-Judge\" approaches. However, these\nmethods produce holistic scores that obscure which specific elements influenced\nthe assessments. We propose functional fragmentation, a method that dissects\neach output into key fragments and interprets the rhetoric functions that each\nfragment serves relative to evaluation criteria -- surfacing the elements of\ninterest and revealing how they fulfill or hinder user goals. We instantiate\nthis approach in Evalet, an interactive system that visualizes fragment-level\nfunctions across many outputs to support inspection, rating, and comparison of\nevaluations. A user study (N=10) found that, while practitioners struggled to\nvalidate holistic scores, our approach helped them identify 48% more evaluation\nmisalignments. This helped them calibrate trust in LLM evaluations and rely on\nthem to find more actionable issues in model outputs. Our work shifts LLM\nevaluation from quantitative scores toward qualitative, fine-grained analysis\nof model behavior.", "published": "2025-09-14 10:24:13", "link": "http://arxiv.org/abs/2509.11206v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation", "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE), which\nlinks language instructions to perception and control in the real world, is a\ncore capability of embodied robots. Recently, large-scale pretrained foundation\nmodels have been leveraged as shared priors for perception, reasoning, and\naction, enabling zero-shot VLN without task-specific training. However,\nexisting zero-shot VLN methods depend on costly perception and passive scene\nunderstanding, collapsing control to point-level choices. As a result, they are\nexpensive to deploy, misaligned in action semantics, and short-sighted in\nplanning. To address these issues, we present DreamNav that focuses on the\nfollowing three aspects: (1) for reducing sensory cost, our EgoView Corrector\naligns viewpoints and stabilizes egocentric perception; (2) instead of\npoint-level actions, our Trajectory Predictor favors global trajectory-level\nplanning to better align with instruction semantics; and (3) to enable\nanticipatory and long-horizon planning, we propose an Imagination Predictor to\nendow the agent with proactive thinking capability. On VLN-CE and real-world\ntests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the\nstrongest egocentric baseline with extra information by up to 7.49\\% and\n18.15\\% in terms of SR and SPL metrics. To our knowledge, this is the first\nzero-shot VLN method to unify trajectory-level planning and active imagination\nwhile using only egocentric inputs.", "published": "2025-09-14 09:54:20", "link": "http://arxiv.org/abs/2509.11197v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "RanAT4BIE: Random Adversarial Training for Biomedical Information Extraction", "abstract": "We introduce random adversarial training (RAT), a novel framework\nsuccessfully applied to biomedical information extraction (BioIE) tasks.\nBuilding on PubMedBERT as the foundational architecture, our study first\nvalidates the effectiveness of conventional adversarial training in enhancing\npre-trained language models' performance on BioIE tasks. While adversarial\ntraining yields significant improvements across various performance metrics, it\nalso introduces considerable computational overhead. To address this\nlimitation, we propose RAT as an efficiency solution for biomedical information\nextraction. This framework strategically integrates random sampling mechanisms\nwith adversarial training principles, achieving dual objectives: enhanced model\ngeneralization and robustness while significantly reducing computational costs.\nThrough comprehensive evaluations, RAT demonstrates superior performance\ncompared to baseline models in BioIE tasks. The results highlight RAT's\npotential as a transformative framework for biomedical natural language\nprocessing, offering a balanced solution to the model performance and\ncomputational efficiency.", "published": "2025-09-14 09:40:00", "link": "http://arxiv.org/abs/2509.11191v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs", "abstract": "Recent advances in Large Language Model (LLM) compression, such as\nquantization and pruning, have achieved notable success. However, as these\ntechniques gradually approach their respective limits, relying on a single\nmethod for further compression has become increasingly challenging. In this\nwork, we explore an alternative solution by combining quantization and\nsparsity. This joint approach, though promising, introduces new difficulties\ndue to the inherently conflicting requirements on weight distributions:\nquantization favors compact ranges, while pruning benefits from high variance.\nTo attack this problem, we propose Optimal Brain Restoration (OBR), a general\nand training-free framework that aligns pruning and quantization by error\ncompensation between both. OBR minimizes performance degradation on downstream\ntasks by building on a second-order Hessian objective, which is then\nreformulated into a tractable problem through surrogate approximation and\nultimately reaches a closed-form solution via group error compensation.\nExperiments show that OBR enables aggressive W4A4KV4 quantization with 50%\nsparsity on existing LLMs, and delivers up to 4.72x speedup and 6.4x memory\nreduction compared to the FP16-dense baseline.", "published": "2025-09-14 09:17:19", "link": "http://arxiv.org/abs/2509.11177v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Differentially-private text generation degrades output language quality", "abstract": "Ensuring user privacy by synthesizing data from large language models (LLMs)\ntuned under differential privacy (DP) has become popular recently. However, the\nimpact of DP fine-tuned LLMs on the quality of the language and the utility of\nthe texts they produce has not been investigated. In this work, we tune five\nLLMs with three corpora under four levels of privacy and assess the length, the\ngrammatical correctness, and the lexical diversity of the text outputs they\nproduce. We also probe the utility of the synthetic outputs in downstream\nclassification tasks such as book genre recognition based on book descriptions\nand cause of death recognition based on verbal autopsies. The results indicate\nthat LLMs tuned under stronger privacy constrains produce texts that are\nshorter by at least 77 %, that are less grammatically correct by at least 9 %,\nand are less diverse by at least 10 % in bi-gram diversity. Furthermore, the\naccuracy they reach in downstream classification tasks decreases, which might\nbe detrimental to the usefulness of the generated synthetic data.", "published": "2025-09-14 09:16:11", "link": "http://arxiv.org/abs/2509.11176v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AQUA: Attention via QUery mAgnitudes for Memory and Compute Efficient Inference in LLMs", "abstract": "The quadratic complexity of the attention mechanism remains a fundamental\nbarrier to scaling Large Language Models (LLMs) to longer contexts, creating a\ncritical bottleneck in both computation and memory. To address this, we\nintroduce AQUA (Attention via QUery mAgnitudes) a novel and versatile\napproximation strategy that significantly reduces the cost of attention with a\ngraceful performance trade-off. Our method operates in two phases: an efficient\noffline step where we compute a universal, language agnostic projection matrix\nvia SVD on a calibration dataset, and an online inference step where we project\nquery and key vectors and dynamically select a sparse subset of dimensions\nbased on the query's magnitude. We provide a formal theoretical analysis of\nAQUA, establishing the break-even point at which it becomes more\ncomputationally efficient than standard attention. Our empirical evaluations on\nstate-of-the-art models like Llama-3.1-8B demonstrate that a 25% reduction in\nthe attention dot-product computation can be achieved with a statistically\ninsignificant impact on performance across a wide range of benchmarks. We\nfurther showcase the versatility of AQUA by demonstrating its ability to\nsynergistically accelerate existing token eviction methods like H2O and to\ndirectly reduce KV-cache memory size. By offering a controllable knob to\nbalance efficiency and accuracy, AQUA provides a practical and powerful tool\nfor making large-scale LLM inference more accessible and sustainable.", "published": "2025-09-14 08:20:48", "link": "http://arxiv.org/abs/2509.11155v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Text2Mem: A Unified Memory Operation Language for Memory Operating System", "abstract": "Large language model agents increasingly depend on memory to sustain long\nhorizon interaction, but existing frameworks remain limited. Most expose only a\nfew basic primitives such as encode, retrieve, and delete, while higher order\noperations like merge, promote, demote, split, lock, and expire are missing or\ninconsistently supported. Moreover, there is no formal and executable\nspecification for memory commands, leaving scope and lifecycle rules implicit\nand causing unpredictable behavior across systems. We introduce Text2Mem, a\nunified memory operation language that provides a standardized pathway from\nnatural language to reliable execution. Text2Mem defines a compact yet\nexpressive operation set aligned with encoding, storage, and retrieval. Each\ninstruction is represented as a JSON based schema instance with required fields\nand semantic invariants, which a parser transforms into typed operation objects\nwith normalized parameters. A validator ensures correctness before execution,\nwhile adapters map typed objects either to a SQL prototype backend or to real\nmemory frameworks. Model based services such as embeddings or summarization are\nintegrated when required. All results are returned through a unified execution\ncontract. This design ensures safety, determinism, and portability across\nheterogeneous backends. We also outline Text2Mem Bench, a planned benchmark\nthat separates schema generation from backend execution to enable systematic\nevaluation. Together, these components establish the first standardized\nfoundation for memory control in agents.", "published": "2025-09-14 07:30:09", "link": "http://arxiv.org/abs/2509.11145v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs' Toxicity", "abstract": "Emojis are globally used non-verbal cues in digital communication, and\nextensive research has examined how large language models (LLMs) understand and\nutilize emojis across contexts. While usually associated with friendliness or\nplayfulness, it is observed that emojis may trigger toxic content generation in\nLLMs. Motivated by such a observation, we aim to investigate: (1) whether\nemojis can clearly enhance the toxicity generation in LLMs and (2) how to\ninterpret this phenomenon. We begin with a comprehensive exploration of\nemoji-triggered LLM toxicity generation by automating the construction of\nprompts with emojis to subtly express toxic intent. Experiments across 5\nmainstream languages on 7 famous LLMs along with jailbreak tasks demonstrate\nthat prompts with emojis could easily induce toxicity generation. To understand\nthis phenomenon, we conduct model-level interpretations spanning semantic\ncognition, sequence generation and tokenization, suggesting that emojis can act\nas a heterogeneous semantic channel to bypass the safety mechanisms. To pursue\ndeeper insights, we further probe the pre-training corpus and uncover potential\ncorrelation between the emoji-related data polution with the toxicity\ngeneration behaviors. Supplementary materials provide our implementation code\nand data. (Warning: This paper contains potentially sensitive contents)", "published": "2025-09-14 07:21:44", "link": "http://arxiv.org/abs/2509.11141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset", "abstract": "Persian names present unique challenges for natural language processing\napplications, particularly in gender detection and digital identity creation,\ndue to transliteration inconsistencies and cultural-specific naming patterns.\nExisting tools exhibit significant performance degradation on Persian names,\nwhile the scarcity of comprehensive datasets further compounds these\nlimitations. To address these challenges, the present research introduces\nPNGT-26K, a comprehensive dataset of Persian names, their commonly associated\ngender, and their English transliteration, consisting of approximately 26,000\ntuples. As a demonstration of how this resource can be utilized, we also\nintroduce two frameworks, namely Open Gender Detection and Nominalist. Open\nGender Detection is a production-grade, ready-to-use framework for using\nexisting data from a user, such as profile photo and name, to give a\nprobabilistic guess about the person's gender. Nominalist, the second framework\nintroduced by this paper, utilizes agentic AI to help users choose a username\nfor their social media accounts on any platform. It can be easily integrated\ninto any website to provide a better user experience. The PNGT-26K dataset,\nNominalist and Open Gender Detection frameworks are publicly available on\nGithub.", "published": "2025-09-14 07:08:32", "link": "http://arxiv.org/abs/2509.11136v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Joint Effects of Argumentation Theory, Audio Modality and Data Enrichment on LLM-Based Fallacy Classification", "abstract": "This study investigates how context and emotional tone metadata influence\nlarge language model (LLM) reasoning and performance in fallacy classification\ntasks, particularly within political debate settings. Using data from U.S.\npresidential debates, we classify six fallacy types through various prompting\nstrategies applied to the Qwen-3 (8B) model. We introduce two theoretically\ngrounded Chain-of-Thought frameworks: Pragma-Dialectics and the Periodic Table\nof Arguments, and evaluate their effectiveness against a baseline prompt under\nthree input settings: text-only, text with context, and text with both context\nand audio-based emotional tone metadata. Results suggest that while theoretical\nprompting can improve interpretability and, in some cases, accuracy, the\naddition of context and especially emotional tone metadata often leads to\nlowered performance. Emotional tone metadata biases the model toward labeling\nstatements as \\textit{Appeal to Emotion}, worsening logical reasoning. Overall,\nbasic prompts often outperformed enhanced ones, suggesting that attention\ndilution from added inputs may worsen rather than improve fallacy\nclassification in LLMs.", "published": "2025-09-14 06:35:34", "link": "http://arxiv.org/abs/2509.11127v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation Dialogue Systems for Tourism", "abstract": "Integrating argumentation mechanisms into negotiation dialogue systems\nimproves conflict resolution through exchanges of arguments and critiques.\nMoreover, incorporating personality attributes enhances adaptability by\naligning interactions with individuals' preferences and styles. To advance\nthese capabilities in negotiation dialogue systems, we propose a novel\nPersonality-driven Argumentation-based Negotiation Dialogue Generation (PAN-DG)\ntask. To support this task, we introduce PACT, a dataset of Personality-driven\nArgumentation-based negotiation Conversations for Tourism sector. This dataset,\ngenerated using Large Language Models (LLMs), features three distinct\npersonality profiles, viz. Argumentation Profile, Preference Profile, and\nBuying Style Profile to simulate a variety of negotiation scenarios involving\ndiverse personalities. Thorough automatic and manual evaluations indicate that\nthe dataset comprises high-quality dialogues. Further, we conduct comparative\nexperiments between pre-trained and fine-tuned LLMs for the PAN-DG task.\nMulti-dimensional evaluation demonstrates that the fine-tuned LLMs effectively\ngenerate personality-driven rational responses during negotiations. This\nunderscores the effectiveness of PACT in enhancing personalization and\nreasoning capabilities in negotiation dialogue systems, thereby establishing a\nfoundation for future research in this domain.", "published": "2025-09-14 06:16:42", "link": "http://arxiv.org/abs/2509.11118v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fluid Language Model Benchmarking", "abstract": "Language model (LM) benchmarking faces several challenges: comprehensive\nevaluations are costly, benchmarks often fail to measure the intended\ncapabilities, and evaluation quality can degrade due to labeling errors and\nbenchmark saturation. Although various strategies have been proposed to\nmitigate these issues, they tend to address individual aspects in isolation,\nneglecting broader questions about overall evaluation quality. Here, we\nintroduce Fluid Benchmarking, a new evaluation approach that advances LM\nbenchmarking across multiple dimensions. Inspired by psychometrics, Fluid\nBenchmarking is based on the insight that the relative value of benchmark items\ndepends on an LM's capability level, suggesting that evaluation should adapt to\neach LM. Methodologically, Fluid Benchmarking estimates an item response model\nbased on existing LM evaluation results and uses the inferred quantities to\nselect evaluation items dynamically, similar to computerized adaptive testing\nin education. In our experiments, we compare Fluid Benchmarking against the\ncommon practice of random item sampling as well as more sophisticated\nbaselines, including alternative methods grounded in item response theory. We\nexamine four dimensions -- efficiency, validity, variance, and saturation --\nand find that Fluid Benchmarking achieves superior performance in all of them\n(e.g., higher validity and less variance on MMLU with fifty times fewer items).\nOur analysis shows that the two components of Fluid Benchmarking have distinct\neffects: item response theory, used to map performance into a latent ability\nspace, increases validity, while dynamic item selection reduces variance.\nOverall, our results suggest that LM benchmarking can be substantially improved\nby moving beyond static evaluation.", "published": "2025-09-14 05:49:42", "link": "http://arxiv.org/abs/2509.11106v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EmoBench-Reddit: A Hierarchical Benchmark for Evaluating the Emotional Intelligence of Multimodal Large Language Models", "abstract": "With the rapid advancement of Multimodal Large Language Models (MLLMs), they\nhave demonstrated exceptional capabilities across a variety of vision-language\ntasks. However, current evaluation benchmarks predominantly focus on objective\nvisual question answering or captioning, inadequately assessing the models'\nability to understand complex and subjective human emotions. To bridge this\ngap, we introduce EmoBench-Reddit, a novel, hierarchical benchmark for\nmultimodal emotion understanding. The dataset comprises 350 meticulously\ncurated samples from the social media platform Reddit, each containing an\nimage, associated user-provided text, and an emotion category (sad, humor,\nsarcasm, happy) confirmed by user flairs. We designed a hierarchical task\nframework that progresses from basic perception to advanced cognition, with\neach data point featuring six multiple-choice questions and one open-ended\nquestion of increasing difficulty. Perception tasks evaluate the model's\nability to identify basic visual elements (e.g., colors, objects), while\ncognition tasks require scene reasoning, intent understanding, and deep empathy\nintegrating textual context. We ensured annotation quality through a\ncombination of AI assistance (Claude 4) and manual verification.", "published": "2025-09-14 05:40:24", "link": "http://arxiv.org/abs/2509.11101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Length-Aware Rotary Position Embedding for Text-Speech Alignment", "abstract": "Many recent text-to-speech (TTS) systems are built on transformer\narchitectures and employ cross-attention mechanisms for text-speech alignment.\nWithin these systems, rotary position embedding (RoPE) is commonly used to\nencode positional information in text and speech representations. In this work,\nwe introduce length-aware RoPE (LARoPE), a simple yet effective extension of\nRoPE that improves text-speech alignment. Unlike RoPE, which relies on absolute\nindices, LARoPE computes relative distances between query and key positions\nusing length-normalized indices. Experimental results show that LARoPE\nconsistently outperforms RoPE, offering faster loss convergence, more accurate\ntext-speech alignment, and higher overall TTS quality. Furthermore, LARoPE\ndemonstrates greater resilience to variations in utterance duration and\nmaintains stable performance in extended speech generation up to 30 seconds,\nwhereas RoPE suffers from notable degradation. Notably, our method achieves a\nstate-of-the-art word error rate on a standard zero-shot TTS benchmark.", "published": "2025-09-14 04:25:13", "link": "http://arxiv.org/abs/2509.11084v1", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge", "abstract": "This report outlines our approach using vision language model systems for the\nDriving with Language track of the CVPR 2024 Autonomous Grand Challenge. We\nhave exclusively utilized the DriveLM-nuScenes dataset for training our models.\nOur systems are built on the LLaVA models, which we enhanced through\nfine-tuning with the LoRA and DoRA methods. Additionally, we have integrated\ndepth information from open-source depth estimation models to enrich the\ntraining and inference processes. For inference, particularly with\nmultiple-choice and yes/no questions, we adopted a Chain-of-Thought reasoning\napproach to improve the accuracy of the results. This comprehensive methodology\nenabled us to achieve a top score of 0.7799 on the validation set leaderboard,\nranking 1st on the leaderboard.", "published": "2025-09-14 03:37:17", "link": "http://arxiv.org/abs/2509.11071v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Rethinking Human Preference Evaluation of LLM Rationales", "abstract": "Large language models (LLMs) often generate natural language rationales --\nfree-form explanations that help improve performance on complex reasoning tasks\nand enhance interpretability for human users. However, evaluating these\nrationales remains challenging. While recent work has relied on binary\npreference judgments from humans or LLM judges, such evaluations are often\nopaque and coarse-grained, offering limited insight into what makes one\nrationale better than another. In this work, we rethink preference evaluation\nfor LLM-generated rationales by asking: (1) What attributes define good\nrationales? (2) Can human preferences be explained by these attributes? (3) Can\nattribute-based evaluation overcome the limitations of binary comparisons? We\nidentify a set of key rationale attributes from prior literature and assess\nthem using automatic metrics, LLM judgments, and human annotations. We then\nanalyze two standard human preference datasets MT Bench and Chatbot Arena using\nSHAP to identify which attributes best explain human preference outcomes.\nFinally, we re-evaluate model-generated rationales using attribute-specific ELO\nscores, revealing more nuanced model comparisons and insights. Our findings\nsuggest that fine-grained attribute evaluations can better characterize\nrationale quality and guide future research toward more interpretable and\nreliable evaluation practices.", "published": "2025-09-14 01:33:14", "link": "http://arxiv.org/abs/2509.11026v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Designing and Evaluating a Conversational Agent for Early Detection of Alzheimer's Disease and Related Dementias", "abstract": "Early detection of Alzheimer's disease and related dementias (ADRD) is\ncritical for timely intervention, yet most diagnoses are delayed until advanced\nstages. While comprehensive patient narratives are essential for accurate\ndiagnosis, prior work has largely focused on screening studies that classify\ncognitive status from interactions rather than supporting the diagnostic\nprocess. We designed voice-interactive conversational agents, leveraging large\nlanguage models (LLMs), to elicit narratives relevant to ADRD from patients and\ninformants. We evaluated the agent with 30 adults with suspected ADRD through\nconversation analysis (n=30), user surveys (n=19), and clinical validation\nagainst blinded specialist interviews (n=24). Symptoms detected by the agent\naligned well with those identified by specialists across symptoms. Users\nappreciated the agent's patience and systematic questioning, which supported\nengagement and expression of complex, hard-to-describe experiences. This\npreliminary work suggests conversational agents may serve as structured\nfront-end tools for dementia assessment, highlighting interaction design\nconsiderations in sensitive healthcare contexts.", "published": "2025-09-14 23:55:01", "link": "http://arxiv.org/abs/2509.11478v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "CareerPooler: AI-Powered Metaphorical Pool Simulation Improves Experience and Outcomes in Career Exploration", "abstract": "Career exploration is uncertain, requiring decisions with limited information\nand unpredictable outcomes. While generative AI offers new opportunities for\ncareer guidance, most systems rely on linear chat interfaces that produce\noverly comprehensive and idealized suggestions, overlooking the non-linear and\neffortful nature of real-world trajectories. We present CareerPooler, a\ngenerative AI-powered system that employs a pool-table metaphor to simulate\ncareer development as a spatial and narrative interaction. Users strike balls\nrepresenting milestones, skills, and random events, where hints, collisions,\nand rebounds embody decision-making under uncertainty. In a within-subjects\nstudy with 24 participants, CareerPooler significantly improved engagement,\ninformation gain, satisfaction, and career clarity compared to a chatbot\nbaseline. Qualitative findings show that spatial-narrative interaction fosters\nexperience-based learning, resilience through setbacks, and reduced\npsychological burden. Our findings contribute to the design of AI-assisted\ncareer exploration systems and more broadly suggest that visually grounded\nanalogical interactions can make generative systems engaging and satisfying.", "published": "2025-09-14 22:33:54", "link": "http://arxiv.org/abs/2509.11461v1", "categories": ["cs.HC", "cs.AI", "H.5"], "primary_category": "cs.HC"}
{"title": "Knowledge-Guided Adaptive Mixture of Experts for Precipitation Prediction", "abstract": "Accurate precipitation forecasting is indispensable in agriculture, disaster\nmanagement, and sustainable strategies. However, predicting rainfall has been\nchallenging due to the complexity of climate systems and the heterogeneous\nnature of multi-source observational data, including radar, satellite imagery,\nand surface-level measurements. The multi-source data vary in spatial and\ntemporal resolution, and they carry domain-specific features, making it\nchallenging for effective integration in conventional deep learning models.\nPrevious research has explored various machine learning techniques for weather\nprediction; however, most struggle with the integration of data with\nheterogeneous modalities. To address these limitations, we propose an Adaptive\nMixture of Experts (MoE) model tailored for precipitation rate prediction. Each\nexpert within the model specializes in a specific modality or spatio-temporal\npattern. We also incorporated a dynamic router that learns to assign inputs to\nthe most relevant experts. Our results show that this modular design enhances\npredictive accuracy and interpretability. In addition to the modeling\nframework, we introduced an interactive web-based visualization tool that\nenables users to intuitively explore historical weather patterns over time and\nspace. The tool was designed to support decision-making for stakeholders in\nclimate-sensitive sectors. We evaluated our approach using a curated multimodal\nclimate dataset capturing real-world conditions during Hurricane Ian in 2022.\nThe benchmark results show that the Adaptive MoE significantly outperformed all\nthe baselines.", "published": "2025-09-14 22:31:46", "link": "http://arxiv.org/abs/2509.11459v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Beyond Frame-wise Tracking: A Trajectory-based Paradigm for Efficient Point Cloud Tracking", "abstract": "LiDAR-based 3D single object tracking (3D SOT) is a critical task in robotics\nand autonomous systems. Existing methods typically follow frame-wise motion\nestimation or a sequence-based paradigm. However, the two-frame methods are\nefficient but lack long-term temporal context, making them vulnerable in sparse\nor occluded scenes, while sequence-based methods that process multiple point\nclouds gain robustness at a significant computational cost. To resolve this\ndilemma, we propose a novel trajectory-based paradigm and its instantiation,\nTrajTrack. TrajTrack is a lightweight framework that enhances a base two-frame\ntracker by implicitly learning motion continuity from historical bounding box\ntrajectories alone-without requiring additional, costly point cloud inputs. It\nfirst generates a fast, explicit motion proposal and then uses an implicit\nmotion modeling module to predict the future trajectory, which in turn refines\nand corrects the initial proposal. Extensive experiments on the large-scale\nNuScenes benchmark show that TrajTrack achieves new state-of-the-art\nperformance, dramatically improving tracking precision by 4.48% over a strong\nbaseline while running at 56 FPS. Besides, we also demonstrate the strong\ngeneralizability of TrajTrack across different base trackers. Video is\navailable at https://www.bilibili.com/video/BV1ahYgzmEWP.", "published": "2025-09-14 21:57:16", "link": "http://arxiv.org/abs/2509.11453v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Tabular Data with Class Imbalance: Predicting Electric Vehicle Crash Severity with Pretrained Transformers (TabPFN) and Mamba-Based Models", "abstract": "This study presents a deep tabular learning framework for predicting crash\nseverity in electric vehicle (EV) collisions using real-world crash data from\nTexas (2017-2023). After filtering for electric-only vehicles, 23,301\nEV-involved crash records were analyzed. Feature importance techniques using\nXGBoost and Random Forest identified intersection relation, first harmful\nevent, person age, crash speed limit, and day of week as the top predictors,\nalong with advanced safety features like automatic emergency braking. To\naddress class imbalance, Synthetic Minority Over-sampling Technique and Edited\nNearest Neighbors (SMOTEENN) resampling was applied. Three state-of-the-art\ndeep tabular models, TabPFN, MambaNet, and MambaAttention, were benchmarked for\nseverity prediction. While TabPFN demonstrated strong generalization,\nMambaAttention achieved superior performance in classifying severe injury cases\ndue to its attention-based feature reweighting. The findings highlight the\npotential of deep tabular architectures for improving crash severity prediction\nand enabling data-driven safety interventions in EV crash contexts.", "published": "2025-09-14 21:46:17", "link": "http://arxiv.org/abs/2509.11449v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations", "abstract": "Vision-language-action (VLA) models finetuned from vision-language models\n(VLMs) hold the promise of leveraging rich pretrained representations to build\ngeneralist robots across diverse tasks and environments. However, direct\nfine-tuning on robot data often disrupts these representations and limits\ngeneralization. We present a framework that better preserves pretrained\nfeatures while adapting them for robot manipulation. Our approach introduces\nthree components: (i) a dual-encoder design with one frozen vision encoder to\nretain pretrained features and another trainable for task adaptation, (ii) a\nstring-based action tokenizer that casts continuous actions into character\nsequences aligned with the model's pretraining domain, and (iii) a co-training\nstrategy that combines robot demonstrations with vision-language datasets\nemphasizing spatial reasoning and affordances. Evaluations in simulation and on\nreal robots show that our method improves robustness to visual perturbations,\ngeneralization to novel instructions and environments, and overall task success\ncompared to baselines.", "published": "2025-09-14 20:08:56", "link": "http://arxiv.org/abs/2509.11417v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Modality-Aware Infrared and Visible Image Fusion with Target-Aware Supervision", "abstract": "Infrared and visible image fusion (IVIF) is a fundamental task in multi-modal\nperception that aims to integrate complementary structural and textural cues\nfrom different spectral domains. In this paper, we propose FusionNet, a novel\nend-to-end fusion framework that explicitly models inter-modality interaction\nand enhances task-critical regions. FusionNet introduces a modality-aware\nattention mechanism that dynamically adjusts the contribution of infrared and\nvisible features based on their discriminative capacity. To achieve\nfine-grained, interpretable fusion, we further incorporate a pixel-wise alpha\nblending module, which learns spatially-varying fusion weights in an adaptive\nand content-aware manner. Moreover, we formulate a target-aware loss that\nleverages weak ROI supervision to preserve semantic consistency in regions\ncontaining important objects (e.g., pedestrians, vehicles). Experiments on the\npublic M3FD dataset demonstrate that FusionNet generates fused images with\nenhanced semantic preservation, high perceptual quality, and clear\ninterpretability. Our framework provides a general and extensible solution for\nsemantic-aware multi-modal image fusion, with benefits for downstream tasks\nsuch as object detection and scene understanding.", "published": "2025-09-14 23:44:15", "link": "http://arxiv.org/abs/2509.11476v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MultiMAE for Brain MRIs: Robustness to Missing Inputs Using Multi-Modal Masked Autoencoder", "abstract": "Missing input sequences are common in medical imaging data, posing a\nchallenge for deep learning models reliant on complete input data. In this\nwork, inspired by MultiMAE [2], we develop a masked autoencoder (MAE) paradigm\nfor multi-modal, multi-task learning in 3D medical imaging with brain MRIs. Our\nmethod treats each MRI sequence as a separate input modality, leveraging a\nlate-fusion-style transformer encoder to integrate multi-sequence information\n(multi-modal) and individual decoder streams for each modality for multi-task\nreconstruction. This pretraining strategy guides the model to learn rich\nrepresentations per modality while also equipping it to handle missing inputs\nthrough cross-sequence reasoning. The result is a flexible and generalizable\nencoder for brain MRIs that infers missing sequences from available inputs and\ncan be adapted to various downstream applications. We demonstrate the\nperformance and robustness of our method against an MAE-ViT baseline in\ndownstream segmentation and classification tasks, showing absolute improvement\nof $10.1$ overall Dice score and $0.46$ MCC over the baselines with missing\ninput sequences. Our experiments demonstrate the strength of this pretraining\nstrategy. The implementation is made available.", "published": "2025-09-14 21:33:59", "link": "http://arxiv.org/abs/2509.11442v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Disentanglement of Biological and Technical Factors via Latent Space Rotation in Clinical Imaging Improves Disease Pattern Discovery", "abstract": "Identifying new disease-related patterns in medical imaging data with the\nhelp of machine learning enlarges the vocabulary of recognizable findings. This\nsupports diagnostic and prognostic assessment. However, image appearance varies\nnot only due to biological differences, but also due to imaging technology\nlinked to vendors, scanning- or re- construction parameters. The resulting\ndomain shifts impedes data representation learning strategies and the discovery\nof biologically meaningful cluster appearances. To address these challenges, we\nintroduce an approach to actively learn the domain shift via post-hoc rotation\nof the data latent space, enabling disentanglement of biological and technical\nfactors. Results on real-world heterogeneous clinical data showcase that the\nlearned disentangled representation leads to stable clusters representing\ntissue-types across different acquisition settings. Cluster consistency is\nimproved by +19.01% (ARI), +16.85% (NMI), and +12.39% (Dice) compared to the\nentangled representation, outperforming four state-of-the-art harmonization\nmethods. When using the clusters to quantify tissue composition on idiopathic\npulmonary fibrosis patients, the learned profiles enhance Cox survival\nprediction. This indicates that the proposed label-free framework facilitates\nbiomarker discovery in multi-center routine imaging data. Code is available on\nGitHub https://github.com/cirmuw/latent-space-rotation-disentanglement.", "published": "2025-09-14 21:16:15", "link": "http://arxiv.org/abs/2509.11436v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "On the Skinning of Gaussian Avatars", "abstract": "Radiance field-based methods have recently been used to reconstruct human\navatars, showing that we can significantly downscale the systems needed for\ncreating animated human avatars. Although this progress has been initiated by\nneural radiance fields, their slow rendering and backward mapping from the\nobservation space to the canonical space have been the main challenges. With\nGaussian splatting overcoming both challenges, a new family of approaches has\nemerged that are faster to train and render, while also straightforward to\nimplement using forward skinning from the canonical to the observation space.\nHowever, the linear blend skinning required for the deformation of the\nGaussians does not provide valid results for their non-linear rotation\nproperties. To address such artifacts, recent works use mesh properties to\nrotate the non-linear Gaussian properties or train models to predict corrective\noffsets. Instead, we propose a weighted rotation blending approach that\nleverages quaternion averaging. This leads to simpler vertex-based Gaussians\nthat can be efficiently animated and integrated in any engine by only modifying\nthe linear blend skinning technique, and using any Gaussian rasterizer.", "published": "2025-09-14 19:58:48", "link": "http://arxiv.org/abs/2509.11411v1", "categories": ["cs.CV", "cs.GR"], "primary_category": "cs.CV"}
{"title": "No Modality Left Behind: Dynamic Model Generation for Incomplete Medical Data", "abstract": "In real world clinical environments, training and applying deep learning\nmodels on multi-modal medical imaging data often struggles with partially\nincomplete data. Standard approaches either discard missing samples, require\nimputation or repurpose dropout learning schemes, limiting robustness and\ngeneralizability. To address this, we propose a hypernetwork-based method that\ndynamically generates task-specific classification models conditioned on the\nset of available modalities. Instead of training a fixed model, a hypernetwork\nlearns to predict the parameters of a task model adapted to available\nmodalities, enabling training and inference on all samples, regardless of\ncompleteness. We compare this approach with (1) models trained only on complete\ndata, (2) state of the art channel dropout methods, and (3) an imputation-based\nmethod, using artificially incomplete datasets to systematically analyze\nrobustness to missing modalities. Results demonstrate superior adaptability of\nour method, outperforming state of the art approaches with an absolute increase\nin accuracy of up to 8% when trained on a dataset with 25% completeness (75% of\ntraining data with missing modalities). By enabling a single model to\ngeneralize across all modality configurations, our approach provides an\nefficient solution for real-world multi-modal medical data analysis.", "published": "2025-09-14 19:47:45", "link": "http://arxiv.org/abs/2509.11406v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MixANT: Observation-dependent Memory Propagation for Stochastic Dense Action Anticipation", "abstract": "We present MixANT, a novel architecture for stochastic long-term dense\nanticipation of human activities. While recent State Space Models (SSMs) like\nMamba have shown promise through input-dependent selectivity on three key\nparameters, the critical forget-gate ($\\textbf{A}$ matrix) controlling temporal\nmemory remains static. We address this limitation by introducing a mixture of\nexperts approach that dynamically selects contextually relevant $\\textbf{A}$\nmatrices based on input features, enhancing representational capacity without\nsacrificing computational efficiency. Extensive experiments on the 50Salads,\nBreakfast, and Assembly101 datasets demonstrate that MixANT consistently\noutperforms state-of-the-art methods across all evaluation settings. Our\nresults highlight the importance of input-dependent forget-gate mechanisms for\nreliable prediction of human behavior in diverse real-world scenarios.", "published": "2025-09-14 19:07:24", "link": "http://arxiv.org/abs/2509.11394v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "In-Vivo Skin 3-D Surface Reconstruction and Wrinkle Depth Estimation using Handheld High Resolution Tactile Sensing", "abstract": "Three-dimensional (3-D) skin surface reconstruction offers promise for\nobjective and quantitative dermatological assessment, but no portable,\nhigh-resolution device exists that has been validated and used for depth\nreconstruction across various body locations. We present a compact 3-D skin\nreconstruction probe based on GelSight tactile imaging with a custom elastic\ngel and a learning-based reconstruction algorithm for micron-level wrinkle\nheight estimation. Our probe, integrated into a handheld probe with force\nsensing for consistent contact, achieves a mean absolute error of 12.55 micron\non wrinkle-like test objects. In a study with 15 participants without skin\ndisorders, we provide the first validated wrinkle depth metrics across multiple\nbody regions. We further demonstrate statistically significant reductions in\nwrinkle height at three locations following over-the-counter moisturizer\napplication. Our work offers a validated tool for clinical and cosmetic skin\nanalysis, with potential applications in diagnosis, treatment monitoring, and\nskincare efficacy evaluation.", "published": "2025-09-14 18:37:31", "link": "http://arxiv.org/abs/2509.11385v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits", "abstract": "Understanding human behavior traits is central to applications in\nhuman-computer interaction, computational social science, and personalized AI\nsystems. Such understanding often requires integrating multiple modalities to\ncapture nuanced patterns and relationships. However, existing resources rarely\nprovide datasets that combine behavioral descriptors with complementary\nmodalities such as facial attributes and biographical information. To address\nthis gap, we present PersonaX, a curated collection of multimodal datasets\ndesigned to enable comprehensive analysis of public traits across modalities.\nPersonaX consists of (1) CelebPersona, featuring 9444 public figures from\ndiverse occupations, and (2) AthlePersona, covering 4181 professional athletes\nacross 7 major sports leagues. Each dataset includes behavioral trait\nassessments inferred by three high-performing large language models, alongside\nfacial imagery and structured biographical features. We analyze PersonaX at two\ncomplementary levels. First, we abstract high-level trait scores from text\ndescriptions and apply five statistical independence tests to examine their\nrelationships with other modalities. Second, we introduce a novel causal\nrepresentation learning (CRL) framework tailored to multimodal and\nmulti-measurement data, providing theoretical identifiability guarantees.\nExperiments on both synthetic and real-world data demonstrate the effectiveness\nof our approach. By unifying structured and unstructured analysis, PersonaX\nestablishes a foundation for studying LLM-inferred behavioral traits in\nconjunction with visual and biographical attributes, advancing multimodal trait\nanalysis and causal reasoning.", "published": "2025-09-14 17:30:03", "link": "http://arxiv.org/abs/2509.11362v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "GLaVE-Cap: Global-Local Aligned Video Captioning with Vision Expert Integration", "abstract": "Video detailed captioning aims to generate comprehensive video descriptions\nto facilitate video understanding. Recently, most efforts in the video detailed\ncaptioning community have been made towards a local-to-global paradigm, which\nfirst generates local captions from video clips and then summarizes them into a\nglobal caption. However, we find this paradigm leads to less detailed and\ncontextual-inconsistent captions, which can be attributed to (1) no mechanism\nto ensure fine-grained captions, and (2) weak interaction between local and\nglobal captions. To remedy the above two issues, we propose GLaVE-Cap, a\nGlobal-Local aligned framework with Vision Expert integration for Captioning,\nwhich consists of two core modules: TrackFusion enables comprehensive local\ncaption generation, by leveraging vision experts to acquire cross-frame visual\nprompts, coupled with a dual-stream structure; while CaptionBridge establishes\na local-global interaction, by using global context to guide local captioning,\nand adaptively summarizing local captions into a coherent global caption.\nBesides, we construct GLaVE-Bench, a comprehensive video captioning benchmark\nfeaturing 5X more queries per video than existing benchmarks, covering diverse\nvisual dimensions to facilitate reliable evaluation. We further provide a\ntraining dataset GLaVE-1.2M containing 16K high-quality fine-grained video\ncaptions and 1.2M related question-answer pairs. Extensive experiments on four\nbenchmarks show that our GLaVE-Cap achieves state-of-the-art performance.\nBesides, the ablation studies and student model analyses further validate the\neffectiveness of the proposed modules and the contribution of GLaVE-1.2M to the\nvideo understanding community. The source code, model weights, benchmark, and\ndataset will be open-sourced.", "published": "2025-09-14 17:25:55", "link": "http://arxiv.org/abs/2509.11360v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Promoting Shape Bias in CNNs: Frequency-Based and Contrastive Regularization for Corruption Robustness", "abstract": "Convolutional Neural Networks (CNNs) excel at image classification but remain\nvulnerable to common corruptions that humans handle with ease. A key reason for\nthis fragility is their reliance on local texture cues rather than global\nobject shapes -- a stark contrast to human perception. To address this, we\npropose two complementary regularization strategies designed to encourage\nshape-biased representations and enhance robustness. The first introduces an\nauxiliary loss that enforces feature consistency between original and\nlow-frequency filtered inputs, discouraging dependence on high-frequency\ntextures. The second incorporates supervised contrastive learning to structure\nthe feature space around class-consistent, shape-relevant representations.\nEvaluated on the CIFAR-10-C benchmark, both methods improve corruption\nrobustness without degrading clean accuracy. Our results suggest that\nloss-level regularization can effectively steer CNNs toward more shape-aware,\nresilient representations.", "published": "2025-09-14 17:14:07", "link": "http://arxiv.org/abs/2509.11355v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Introduction to a Low-Cost AI-Powered GUI for Unstained Cell Culture Analysis", "abstract": "This article presents a novel microscopy image analysis framework designed\nfor low-budget labs equipped with a standard CPU desktop. The Python-based\nprogram enables cytometric analysis of live, unstained cells in culture through\nan advanced computer vision and machine learning pipeline. Crucially, the\nframework operates on label-free data, requiring no manually annotated training\ndata or training phase. It is accessible via a user-friendly, cross-platform\nGUI that requires no programming skills, while also providing a scripting\ninterface for programmatic control and integration by developers. The\nend-to-end workflow performs semantic and instance segmentation, feature\nextraction, analysis, evaluation, and automated report generation. Its modular\narchitecture supports easy maintenance and flexible integration while\nsupporting both single-image and batch processing. Validated on several\nunstained cell types from the public dataset of livecells, the framework\ndemonstrates superior accuracy and reproducibility compared to contemporary\ntools like Cellpose and StarDist. Its competitive segmentation speed on a\nCPU-based platform highlights its significant potential for basic research and\nclinical applications -- particularly in cell transplantation for personalized\nmedicine and muscle regeneration therapies.", "published": "2025-09-14 17:12:17", "link": "http://arxiv.org/abs/2509.11354v1", "categories": ["q-bio.QM", "cs.CV", "eess.IV", "q-bio.CB"], "primary_category": "q-bio.QM"}
{"title": "Beyond Instance Consistency: Investigating View Diversity in Self-supervised Learning", "abstract": "Self-supervised learning (SSL) conventionally relies on the instance\nconsistency paradigm, assuming that different views of the same image can be\ntreated as positive pairs. However, this assumption breaks down for non-iconic\ndata, where different views may contain distinct objects or semantic\ninformation. In this paper, we investigate the effectiveness of SSL when\ninstance consistency is not guaranteed. Through extensive ablation studies, we\ndemonstrate that SSL can still learn meaningful representations even when\npositive pairs lack strict instance consistency. Furthermore, our analysis\nfurther reveals that increasing view diversity, by enforcing zero overlapping\nor using smaller crop scales, can enhance downstream performance on\nclassification and dense prediction tasks. However, excessive diversity is\nfound to reduce effectiveness, suggesting an optimal range for view diversity.\nTo quantify this, we adopt the Earth Mover's Distance (EMD) as an estimator to\nmeasure mutual information between views, finding that moderate EMD values\ncorrelate with improved SSL learning, providing insights for future SSL\nframework design. We validate our findings across a range of settings,\nhighlighting their robustness and applicability on diverse data sources.", "published": "2025-09-14 16:41:17", "link": "http://arxiv.org/abs/2509.11344v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dual Band Video Thermography Near Ambient Conditions", "abstract": "Long-wave infrared radiation captured by a thermal camera consists of two\ncomponents: (a) light from the environment reflected or transmitted by a\nsurface, and (b) light emitted by the surface after undergoing heat transport\nthrough the object and exchanging heat with the surrounding environment.\nSeparating these components is essential for understanding object properties\nsuch as emissivity, temperature, reflectance and shape. Previous thermography\nstudies often assume that only one component is dominant (e.g., in welding) or\nthat the second component is constant and can be subtracted. However, in\nnear-ambient conditions, which are most relevant to computer vision\napplications, both components are typically comparable in magnitude and vary\nover time. We introduce the first method that separates reflected and emitted\ncomponents of light in videos captured by two thermal cameras with different\nspectral sensitivities. We derive a dual-band thermal image formation model and\ndevelop algorithms to estimate the surface's emissivity and its time-varying\ntemperature while isolating a dynamic background. We quantitatively evaluate\nour approach using carefully calibrated emissivities for a range of materials\nand show qualitative results on complex everyday scenes, such as a glass filled\nwith hot liquid and people moving in the background.", "published": "2025-09-14 16:21:29", "link": "http://arxiv.org/abs/2509.11334v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward Next-generation Medical Vision Backbones: Modeling Finer-grained Long-range Visual Dependency", "abstract": "Medical Image Computing (MIC) is a broad research topic covering both\npixel-wise (e.g., segmentation, registration) and image-wise (e.g.,\nclassification, regression) vision tasks. Effective analysis demands models\nthat capture both global long-range context and local subtle visual\ncharacteristics, necessitating fine-grained long-range visual dependency\nmodeling. Compared to Convolutional Neural Networks (CNNs) that are limited by\nintrinsic locality, transformers excel at long-range modeling; however, due to\nthe high computational loads of self-attention, transformers typically cannot\nprocess high-resolution features (e.g., full-scale image features before\ndownsampling or patch embedding) and thus face difficulties in modeling\nfine-grained dependency among subtle medical image details. Concurrently,\nMulti-layer Perceptron (MLP)-based visual models are recognized as\ncomputation/memory-efficient alternatives in modeling long-range visual\ndependency but have yet to be widely investigated in the MIC community. This\ndoctoral research advances deep learning-based MIC by investigating effective\nlong-range visual dependency modeling. It first presents innovative use of\ntransformers for both pixel- and image-wise medical vision tasks. The focus\nthen shifts to MLPs, pioneeringly developing MLP-based visual models to capture\nfine-grained long-range visual dependency in medical images. Extensive\nexperiments confirm the critical role of long-range dependency modeling in MIC\nand reveal a key finding: MLPs provide feasibility in modeling finer-grained\nlong-range dependency among higher-resolution medical features containing\nenriched anatomical/pathological details. This finding establishes MLPs as a\nsuperior paradigm over transformers/CNNs, consistently enhancing performance\nacross various medical vision tasks and paving the way for next-generation\nmedical vision backbones.", "published": "2025-09-14 16:14:03", "link": "http://arxiv.org/abs/2509.11328v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Foundational theory for optimal decision tree problems. I. Algorithmic and geometric foundations", "abstract": "In the first paper (part I) of this series of two, we introduce four novel\ndefinitions of the ODT problems: three for size-constrained trees and one for\ndepth-constrained trees. These definitions are stated unambiguously through\nexecutable recursive programs, satisfying all criteria we propose for a formal\nspecification. In this sense, they resemble the \"standard form\" used in the\nstudy of general-purpose solvers.\n  Grounded in algebraic programming theory-a relational formalism for deriving\ncorrect-by-construction algorithms from specifications-we can not only\nestablish the existence or nonexistence of dynamic programming solutions but\nalso derive them constructively whenever they exist. Consequently, the four\ngeneric problem definitions yield four novel optimal algorithms for ODT\nproblems with arbitrary splitting rules that satisfy the axioms and objective\nfunctions of a given form. These algorithms encompass the known\ndepth-constrained, axis-parallel ODT algorithm as the special case, while\nproviding a unified, efficient, and elegant solution for the general ODT\nproblem.\n  In Part II, we present the first optimal hypersurface decision tree algorithm\nand provide comprehensive experiments against axis-parallel decision tree\nalgorithms, including heuristic CART and state-of-the-art optimal methods. The\nresults demonstrate the significant potential of decision trees with flexible\nsplitting rules. Moreover, our framework is readily extendable to support\nalgorithms for constructing even more flexible decision trees, including those\nwith mixed splitting rules.", "published": "2025-09-14 12:01:02", "link": "http://arxiv.org/abs/2509.11226v1", "categories": ["cs.LG", "cs.DM", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Acoustic Overspecification in Electronic Dance Music Taxonomy", "abstract": "Electronic Dance Music (EDM) classification typically relies on\nindustry-defined taxonomies with numerous subgenres, yet the acoustic basis for\nthese distinctions remains unclear. Current approaches use supervised learning\nwith prescribed genre labels, assuming their validity without systematic\nevaluation. In this paper, we propose an unsupervised approach to discover the\nnatural acoustic structure of EDM independent of commercial labels. Our method\ncombines novel tempogram-based features capturing EDM's layered rhythmic\npatterns with multi-criteria feature selection. To validate that our findings\nreflect genuine acoustic structure rather than methodological artifacts, we\ncompare our results against state-of-the-art pre-trained audio embeddings (MERT\nand CLAP). Both our feature space and embedding representations converge to\n19-23 natural acoustic families compared to the prescribed 35, providing\nconsistent evidence of significant overspecification in current EDM taxonomy by\napproximately one-third.", "published": "2025-09-14 23:38:45", "link": "http://arxiv.org/abs/2509.11474v1", "categories": ["cs.SD", "cs.IR"], "primary_category": "cs.SD"}
{"title": "Do Large Language Models Favor Recent Content? A Study on Recency Bias in LLM-Based Reranking", "abstract": "Large language models (LLMs) are increasingly deployed in information\nsystems, including being used as second-stage rerankers in information\nretrieval pipelines, yet their susceptibility to recency bias has received\nlittle attention. We investigate whether LLMs implicitly favour newer documents\nby prepending artificial publication dates to passages in the TREC Deep\nLearning passage retrieval collections in 2021 (DL21) and 2022 (DL22). Across\nseven models, GPT-3.5-turbo, GPT-4o, GPT-4, LLaMA-3 8B/70B, and Qwen-2.5\n7B/72B, \"fresh\" passages are consistently promoted, shifting the Top-10's mean\npublication year forward by up to 4.78 years and moving individual items by as\nmany as 95 ranks in our listwise reranking experiments. Although larger models\nattenuate the effect, none eliminate it. We also observe that the preference of\nLLMs between two passages with an identical relevance level can be reversed by\nup to 25% on average after date injection in our pairwise preference\nexperiments. These findings provide quantitative evidence of a pervasive\nrecency bias in LLMs and highlight the importance of effective bias-mitigation\nstrategies.", "published": "2025-09-14 17:11:07", "link": "http://arxiv.org/abs/2509.11353v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "An Incentive-Compatible Reward Sharing Mechanism for Mitigating Mirroring Attacks in Decentralized Data-Feed Systems", "abstract": "Decentralized data-feed systems enable blockchain-based smart contracts to\naccess off-chain information by aggregating values from multiple oracles. To\nimprove accuracy, these systems typically use an aggregation function, such as\nmajority voting, to consolidate the inputs they receive from oracles and make a\ndecision. Depending on the final decision and the values reported by the\noracles, the participating oracles are compensated through shared rewards.\nHowever, such incentive mechanisms are vulnerable to mirroring attacks, where a\nsingle user controls multiple oracles to bias the decision of the aggregation\nfunction and maximize rewards. This paper analyzes the impact of mirroring\nattacks on the reliability and dependability of majority voting-based data-feed\nsystems. We demonstrate how existing incentive mechanisms can unintentionally\nencourage rational users to implement such attacks. To address this, we propose\na new incentive mechanism that discourages Sybil behavior. We prove that the\nproposed mechanism leads to a Nash Equilibrium in which each user operates only\none oracle. Finally, we discuss the practical implementation of the proposed\nincentive mechanism and provide numerical examples to demonstrate its\neffectiveness.", "published": "2025-09-14 14:33:17", "link": "http://arxiv.org/abs/2509.11294v1", "categories": ["cs.GT", "cs.ET", "cs.IR", "cs.IT", "math.IT", "math.PR"], "primary_category": "cs.GT"}
{"title": "Understanding the Information Cocoon: A Multidimensional Assessment and Analysis of News Recommendation Systems", "abstract": "Personalized news recommendation systems inadvertently create information\ncocoons--homogeneous information bubbles that reinforce user biases and amplify\nsocietal polarization. To address the lack of comprehensive assessment\nframeworks in prior research, we propose a multidimensional analysis that\nevaluates cocoons through dual perspectives: (1) Individual homogenization via\ntopic diversity (including the number of topic categories and category\ninformation entropy) and click repetition; (2) Group polarization via network\ndensity and community openness. Through multi-round experiments on real-world\ndatasets, we benchmark seven algorithms and reveal critical insights.\nFurthermore, we design five lightweight mitigation strategies. This work\nestablishes the first unified metric framework for information cocoons and\ndelivers deployable solutions for ethical recommendation systems.", "published": "2025-09-14 07:17:26", "link": "http://arxiv.org/abs/2509.11139v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SPARK: Adaptive Low-Rank Knowledge Graph Modeling in Hybrid Geometric Spaces for Recommendation", "abstract": "Knowledge Graphs (KGs) enhance recommender systems but face challenges from\ninherent noise, sparsity, and Euclidean geometry's inadequacy for complex\nrelational structures, critically impairing representation learning, especially\nfor long-tail entities. Existing methods also often lack adaptive multi-source\nsignal fusion tailored to item popularity. This paper introduces SPARK, a novel\nmulti-stage framework systematically tackling these issues. SPARK first employs\nTucker low-rank decomposition to denoise KGs and generate robust entity\nrepresentations. Subsequently, an SVD-initialized hybrid geometric GNN\nconcurrently learns representations in Euclidean and Hyperbolic spaces; the\nlatter is strategically leveraged for its aptitude in modeling hierarchical\nstructures, effectively capturing semantic features of sparse, long-tail items.\nA core contribution is an item popularity-aware adaptive fusion strategy that\ndynamically weights signals from collaborative filtering, refined KG\nembeddings, and diverse geometric spaces for precise modeling of both\nmainstream and long-tail items. Finally, contrastive learning aligns these\nmulti-source representations. Extensive experiments demonstrate SPARK's\nsignificant superiority over state-of-the-art methods, particularly in\nimproving long-tail item recommendation, offering a robust, principled approach\nto knowledge-enhanced recommendation. Implementation code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/SPARK.", "published": "2025-09-14 05:12:46", "link": "http://arxiv.org/abs/2509.11094v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Membership Inference Attacks on Recommender System: A Survey", "abstract": "Recommender systems (RecSys) have been widely applied to various\napplications, including E-commerce, finance, healthcare, social media and have\nbecome increasingly influential in shaping user behavior and decision-making,\nhighlighting their growing impact in various domains. However, recent studies\nhave shown that RecSys are vulnerable to membership inference attacks (MIAs),\nwhich aim to infer whether user interaction record was used to train a target\nmodel or not. MIAs on RecSys models can directly lead to a privacy breach. For\nexample, via identifying the fact that a purchase record that has been used to\ntrain a RecSys associated with a specific user, an attacker can infer that\nuser's special quirks. In recent years, MIAs have been shown to be effective on\nother ML tasks, e.g., classification models and natural language processing.\nHowever, traditional MIAs are ill-suited for RecSys due to the unseen posterior\nprobability. Although MIAs on RecSys form a newly emerging and rapidly growing\nresearch area, there has been no systematic survey on this topic yet. In this\narticle, we conduct the first comprehensive survey on RecSys MIAs. This survey\noffers a comprehensive review of the latest advancements in RecSys MIAs,\nexploring the design principles, challenges, attack and defense associated with\nthis emerging field. We provide a unified taxonomy that categorizes different\nRecSys MIAs based on their characterizations and discuss their pros and cons.\nBased on the limitations and gaps identified in this survey, we point out\nseveral promising future research directions to inspire the researchers who\nwish to follow this area. This survey not only serves as a reference for the\nresearch community but also provides a clear description for researchers\noutside this research domain.", "published": "2025-09-14 04:06:03", "link": "http://arxiv.org/abs/2509.11080v1", "categories": ["cs.IR", "cs.AI", "cs.CR"], "primary_category": "cs.IR"}
{"title": "Optimal single-mode squeezing for beam displacement sensing", "abstract": "Estimation of an optical beam's transverse displacement is a canonical\nimaging problem fundamental to numerous optical imaging and sensing tasks.\nQuantum enhancements to the measurement precision in this problem have been\nstudied extensively. However, previous studies have neither accounted for\ndiffraction loss in full generality, nor have they addressed how to jointly\noptimize the spatial mode and the balance between squeezing and coherent\namplitude. Here we show that, in the small-displacement limit, the seemingly\nintractable infinite-spatial-mode problem can be reduced to a compact\nthree-mode interaction framework. We quantify the improvement afforded by an\noptimized single-spatial-mode Gaussian-state probe over the optimal classical\nlaser probe, and show that a two-spatial-mode homodyne receiver is\nasymptotically optimal for the former in the limit of high probe energy. Our\nfindings reveal a strategy for identifying quantum-optimal probes in the\npresence of generic multimode linear probe-target interaction and photon loss.", "published": "2025-09-14 22:12:08", "link": "http://arxiv.org/abs/2509.11457v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Long-time dynamics and universality of nonconvex gradient descent", "abstract": "This paper develops a general approach to characterize the long-time\ntrajectory behavior of nonconvex gradient descent in generalized single-index\nmodels in the large aspect ratio regime. In this regime, we show that for each\niteration the gradient descent iterate concentrates around a deterministic\nvector called the `Gaussian theoretical gradient descent', whose dynamics can\nbe tracked by a state evolution system of two recursive equations for two\nscalars. Our concentration guarantees hold universally for a broad class of\ndesign matrices and remain valid over long time horizons until algorithmic\nconvergence or divergence occurs. Moreover, our approach reveals that gradient\ndescent iterates are in general approximately independent of the data and\nstrongly incoherent with the feature vectors, a phenomenon previously known as\nthe `implicit regularization' effect of gradient descent in specific models\nunder Gaussian data.\n  As an illustration of the utility of our general theory, we present two\napplications of different natures in the regression setting. In the first, we\nprove global convergence of nonconvex gradient descent with general independent\ninitialization for a broad class of structured link functions, and establish\nuniversality of randomly initialized gradient descent in phase retrieval for\nlarge aspect ratios. In the second, we develop a data-free iterative algorithm\nfor estimating state evolution parameters along the entire gradient descent\ntrajectory, thereby providing a low-cost yet statistically valid tool for\npractical tasks such as hyperparameter tuning and runtime determination.\n  As a by-product of our analysis, we show that in the large aspect ratio\nregime, the Gaussian theoretical gradient descent coincides with a recent line\nof dynamical mean-field theory for gradient descent over the constant-time\nhorizon.", "published": "2025-09-14 20:36:18", "link": "http://arxiv.org/abs/2509.11426v1", "categories": ["cs.LG", "cs.IT", "math.IT", "math.OC", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Learning to Equalize: Data-Driven Frequency-Domain Signal Recovery in Molecular Communications", "abstract": "In molecular communications (MC), inter-symbol interference (ISI) and noise\nare key factors that degrade communication reliability. Although time-domain\nequalization can effectively mitigate these effects, it often entails high\ncomputational complexity concerning the channel memory. In contrast,\nfrequency-domain equalization (FDE) offers greater computational efficiency but\ntypically requires prior knowledge of the channel model. To address this\nlimitation, this letter proposes FDE techniques based on long short-term memory\n(LSTM) neural networks, enabling temporal correlation modeling in MC channels\nto improve ISI and noise suppression. To eliminate the reliance on prior\nchannel information in conventional FDE methods, a supervised training strategy\nis employed for channel-adaptive equalization. Simulation results demonstrate\nthat the proposed LSTM-FDE significantly reduces the bit error rate compared to\ntraditional FDE and feedforward neural network-based equalizers. This\nperformance gain is attributed to the LSTM's temporal modeling capabilities,\nwhich enhance noise suppression and accelerate model convergence, while\nmaintaining comparable computational efficiency.", "published": "2025-09-14 16:11:02", "link": "http://arxiv.org/abs/2509.11327v1", "categories": ["q-bio.SC", "cs.IT", "math.IT"], "primary_category": "q-bio.SC"}
{"title": "Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers", "abstract": "Beamforming techniques are utilized in millimeter wave (mmWave) communication\nto address the inherent path loss limitation, thereby establishing and\nmaintaining reliable connections. However, adopting standard defined\nbeamforming approach in highly dynamic vehicular environments often incurs high\nbeam training overheads and reduces the available airtime for communications,\nwhich is mainly due to exchanging pilot signals and exhaustive beam\nmeasurements. To this end, we present a multi-modal sensing and fusion learning\nframework as a potential alternative solution to reduce such overheads. In this\nframework, we first extract the features individually from the visual and GPS\ncoordinates sensing modalities by modality specific encoders, and subsequently\nfuse the multimodal features to obtain predicted top-k beams so that the best\nline-of-sight links can be proactively established. To show the\ngeneralizability of the proposed framework, we perform a comprehensive\nexperiment in four different vehicle-to-vehicle (V2V) scenarios from real-world\nmulti-modal sensing and communication dataset. From the experiment, we observe\nthat the proposed framework achieves up to 77.58% accuracy on predicting top-15\nbeams correctly, outperforms single modalities, incurs roughly as low as 2.32\ndB average power loss, and considerably reduces the beam searching space\noverheads by 76.56% for top-15 beams with respect to standard defined approach.", "published": "2025-09-14 06:03:42", "link": "http://arxiv.org/abs/2509.11112v1", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.NI"}
{"title": "Rate-Distortion Limits for Multimodal Retrieval: Theory, Optimal Codes, and Finite-Sample Guarantees", "abstract": "We establish the first information-theoretic limits for multimodal retrieval.\nCasting ranking as lossy source coding, we derive a single-letter\nrate-distortion function $R(D)$ for reciprocal-rank distortion and prove a\nconverse bound that splits into a modality-balanced term plus a skew penalty\n$\\kappa\\,\\Delta H$ capturing entropy imbalance and cross-modal redundancy. We\nthen construct an explicit entropy-weighted stochastic quantizer with an\nadaptive, per-modality temperature decoder; a Blahut-Arimoto argument shows\nthis scheme achieves distortion within $O(n^{-1})$ of $R(D)$ using $n$ training\ntriples. A VC-type analysis yields the first finite-sample excess-risk bound\nwhose complexity scales sub-linearly in both the number of modalities and the\nentropy gap. Experiments on controlled Gaussian mixtures and Flickr30k confirm\nthat our adaptive codes sit within two percentage points of the theoretical\nfrontier, while fixed-temperature and naive CLIP baselines lag significantly.\nTaken together, our results give a principled answer to \"how many bits per\nquery are necessary\" for high-quality multimodal retrieval and provide design\nguidance for entropy-aware contrastive objectives, continual-learning\nretrievers, and retrieval-augmented generators.", "published": "2025-09-14 02:45:56", "link": "http://arxiv.org/abs/2509.11054v1", "categories": ["cs.IT", "cs.CV", "math.IT"], "primary_category": "cs.IT"}
{"title": "A Particle-Flow Algorithm for Free-Support Wasserstein Barycenters", "abstract": "The Wasserstein barycenter extends the Euclidean mean to the space of\nprobability measures by minimizing the weighted sum of squared 2-Wasserstein\ndistances. We develop a free-support algorithm for computing Wasserstein\nbarycenters that avoids entropic regularization and instead follows the formal\nRiemannian geometry of Wasserstein space. In our approach, barycenter atoms\nevolve as particles advected by averaged optimal-transport displacements, with\nbarycentric projections of optimal transport plans used in place of Monge maps\nwhen the latter do not exist. This yields a geometry-aware particle-flow update\nthat preserves sharp features of the Wasserstein barycenter while remaining\ncomputationally tractable. We establish theoretical guarantees, including\nconsistency of barycentric projections, monotone descent and convergence to\nstationary points, stability with respect to perturbations of the inputs, and\nresolution consistency as the number of atoms increases. Empirical studies on\naveraging probability distributions, Bayesian posterior aggregation, image\nprototypes and classification, and large-scale clustering demonstrate accuracy\nand scalability of the proposed particle-flow approach, positioning it as a\nprincipled alternative to both linear programming and regularized solvers.", "published": "2025-09-14 21:05:04", "link": "http://arxiv.org/abs/2509.11435v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Framing AI System Benchmarking as a Learning Task: FlexBench and the Open MLPerf Dataset", "abstract": "Existing AI system benchmarks such as MLPerf often struggle to keep pace with\nthe rapidly evolving AI landscape, making it difficult to support informed\ndeployment, optimization, and co-design decisions for AI systems. We suggest\nthat benchmarking itself can be framed as an AI task - one in which models are\ncontinuously evaluated and optimized across diverse datasets, software, and\nhardware, using key metrics such as accuracy, latency, throughput, energy\nconsumption, and cost. To support this perspective, we present FlexBench: a\nmodular extension of the MLPerf LLM inference benchmark, integrated with\nHuggingFace and designed to provide relevant and actionable insights.\nBenchmarking results and metadata are collected into an Open MLPerf Dataset,\nwhich can be collaboratively curated, extended, and leveraged for predictive\nmodeling and feature engineering. We successfully validated the FlexBench\nconcept through MLPerf Inference submissions, including evaluations of DeepSeek\nR1 and LLaMA 3.3 on commodity servers. The broader objective is to enable\npractitioners to make cost-effective AI deployment decisions that reflect their\navailable resources, requirements, and constraints.", "published": "2025-09-14 20:02:15", "link": "http://arxiv.org/abs/2509.11413v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "From Firewalls to Frontiers: AI Red-Teaming is a Domain-Specific Evolution of Cyber Red-Teaming", "abstract": "A red team simulates adversary attacks to help defenders find effective\nstrategies to defend their systems in a real-world operational setting. As more\nenterprise systems adopt AI, red-teaming will need to evolve to address the\nunique vulnerabilities and risks posed by AI systems. We take the position that\nAI systems can be more effectively red-teamed if AI red-teaming is recognized\nas a domain-specific evolution of cyber red-teaming. Specifically, we argue\nthat existing Cyber Red Teams who adopt this framing will be able to better\nevaluate systems with AI components by recognizing that AI poses new risks, has\nnew failure modes to exploit, and often contains unpatchable bugs that\nre-prioritize disclosure and mitigation strategies. Similarly, adopting a\ncybersecurity framing will allow existing AI Red Teams to leverage a\nwell-tested structure to emulate realistic adversaries, promote mutual\naccountability with formal rules of engagement, and provide a pattern to mature\nthe tooling necessary for repeatable, scalable engagements. In these ways, the\nmerging of AI and Cyber Red Teams will create a robust security ecosystem and\nbest position the community to adapt to the rapidly changing threat landscape.", "published": "2025-09-14 19:21:58", "link": "http://arxiv.org/abs/2509.11398v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Quantum Graph Attention Networks: Trainable Quantum Encoders for Inductive Graph Learning", "abstract": "We introduce Quantum Graph Attention Networks (QGATs) as trainable quantum\nencoders for inductive learning on graphs, extending the Quantum Graph Neural\nNetworks (QGNN) framework. QGATs leverage parameterized quantum circuits to\nencode node features and neighborhood structures, with quantum attention\nmechanisms modulating the contribution of each neighbor via dynamically learned\nunitaries. This allows for expressive, locality-aware quantum representations\nthat can generalize across unseen graph instances. We evaluate our approach on\nthe QM9 dataset, targeting the prediction of various chemical properties. Our\nexperiments compare classical and quantum graph neural networks-with and\nwithout attention layers-demonstrating that attention consistently improves\nperformance in both paradigms. Notably, we observe that quantum attention\nyields increasing benefits as graph size grows, with QGATs significantly\noutperforming their non-attentive quantum counterparts on larger molecular\ngraphs. Furthermore, for smaller graphs, QGATs achieve predictive accuracy\ncomparable to classical GAT models, highlighting their viability as expressive\nquantum encoders. These results show the potential of quantum attention\nmechanisms to enhance the inductive capacity of QGNN in chemistry and beyond.", "published": "2025-09-14 18:56:05", "link": "http://arxiv.org/abs/2509.11390v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Enhancing ML Models Interpretability for Credit Scoring", "abstract": "Predicting default is essential for banks to ensure profitability and\nfinancial stability. While modern machine learning methods often outperform\ntraditional regression techniques, their lack of transparency limits their use\nin regulated environments. Explainable artificial intelligence (XAI) has\nemerged as a solution in domains like credit scoring. However, most XAI\nresearch focuses on post-hoc interpretation of black-box models, which does not\nproduce models lightweight or transparent enough to meet regulatory\nrequirements, such as those for Internal Ratings-Based (IRB) models.\n  This paper proposes a hybrid approach: post-hoc interpretations of black-box\nmodels guide feature selection, followed by training glass-box models that\nmaintain both predictive power and transparency.\n  Using the Lending Club dataset, we demonstrate that this approach achieves\nperformance comparable to a benchmark black-box model while using only 10\nfeatures - an 88.5% reduction. In our example, SHapley Additive exPlanations\n(SHAP) is used for feature selection, eXtreme Gradient Boosting (XGBoost)\nserves as the benchmark and the base black-box model, and Explainable Boosting\nMachine (EBM) and Penalized Logistic Tree Regression (PLTR) are the\ninvestigated glass-box models.\n  We also show that model refinement using feature interaction analysis,\ncorrelation checks, and expert input can further enhance model interpretability\nand robustness.", "published": "2025-09-14 18:47:38", "link": "http://arxiv.org/abs/2509.11389v1", "categories": ["cs.LG", "q-fin.RM"], "primary_category": "cs.LG"}
{"title": "Some Robustness Properties of Label Cleaning", "abstract": "We demonstrate that learning procedures that rely on aggregated labels, e.g.,\nlabel information distilled from noisy responses, enjoy robustness properties\nimpossible without data cleaning. This robustness appears in several ways. In\nthe context of risk consistency -- when one takes the standard approach in\nmachine learning of minimizing a surrogate (typically convex) loss in place of\na desired task loss (such as the zero-one mis-classification error) --\nprocedures using label aggregation obtain stronger consistency guarantees than\nthose even possible using raw labels. And while classical statistical scenarios\nof fitting perfectly-specified models suggest that incorporating all possible\ninformation -- modeling uncertainty in labels -- is statistically efficient,\nconsistency fails for ``standard'' approaches as soon as a loss to be minimized\nis even slightly mis-specified. Yet procedures leveraging aggregated\ninformation still converge to optimal classifiers, highlighting how\nincorporating a fuller view of the data analysis pipeline, from collection to\nmodel-fitting to prediction time, can yield a more robust methodology by\nrefining noisy signals.", "published": "2025-09-14 18:17:51", "link": "http://arxiv.org/abs/2509.11379v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Identifying Imperfect Clones in Elections", "abstract": "A perfect clone in an ordinal election (i.e., an election where the voters\nrank the candidates in a strict linear order) is a set of candidates that each\nvoter ranks consecutively. We consider different relaxations of this notion:\nindependent or subelection clones are sets of candidates that only some of the\nvoters recognize as a perfect clone, whereas approximate clones are sets of\ncandidates such that every voter ranks their members close to each other, but\nnot necessarily consecutively. We establish the complexity of identifying such\nimperfect clones, and of partitioning the candidates into families of imperfect\nclones. We also study the parameterized complexity of these problems with\nrespect to a set of natural parameters such as the number of voters, the size\nor the number of imperfect clones we are searching for, or their level of\nimperfection.", "published": "2025-09-14 13:19:14", "link": "http://arxiv.org/abs/2509.11261v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Neural cellular automata: applications to biology and beyond classical AI", "abstract": "Neural Cellular Automata (NCA) represent a powerful framework for modeling\nbiological self-organization, extending classical rule-based systems with\ntrainable, differentiable (or evolvable) update rules that capture the adaptive\nself-regulatory dynamics of living matter. By embedding Artificial Neural\nNetworks (ANNs) as local decision-making centers and interaction rules between\nlocalized agents, NCA can simulate processes across molecular, cellular,\ntissue, and system-level scales, offering a multiscale competency architecture\nperspective on evolution, development, regeneration, aging, morphogenesis, and\nrobotic control. These models not only reproduce biologically inspired target\npatterns but also generalize to novel conditions, demonstrating robustness to\nperturbations and the capacity for open-ended adaptation and reasoning. Given\ntheir immense success in recent developments, we here review current literature\nof NCAs that are relevant primarily for biological or bioengineering\napplications. Moreover, we emphasize that beyond biology, NCAs display robust\nand generalizing goal-directed dynamics without centralized control, e.g., in\ncontrolling or regenerating composite robotic morphologies or even on\ncutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same\nprinciples of iterative state-refinement is reminiscent to modern generative\nArtificial Intelligence (AI), such as probabilistic diffusion models. Their\ngoverning self-regulatory behavior is constraint to fully localized\ninteractions, yet their collective behavior scales into coordinated\nsystem-level outcomes. We thus argue that NCAs constitute a unifying\ncomputationally lean paradigm that not only bridges fundamental insights from\nmultiscale biology with modern generative AI, but have the potential to design\ntruly bio-inspired collective intelligence capable of hierarchical reasoning\nand control.", "published": "2025-09-14 06:55:29", "link": "http://arxiv.org/abs/2509.11131v1", "categories": ["cs.AI", "cs.MA", "q-bio.OT"], "primary_category": "cs.AI"}
{"title": "Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration", "abstract": "Autonomous agents for desktop automation struggle with complex multi-step\ntasks due to poor coordination and inadequate quality control. We introduce\n\\textsc{Agentic Lybic}, a novel multi-agent system where the entire\narchitecture operates as a finite-state machine (FSM). This core innovation\nenables dynamic orchestration. Our system comprises four components: a\nController, a Manager, three Workers (Technician for code-based operations,\nOperator for GUI interactions, and Analyst for decision support), and an\nEvaluator. The critical mechanism is the FSM-based routing between these\ncomponents, which provides flexibility and generalization by dynamically\nselecting the optimal execution strategy for each subtask. This principled\norchestration, combined with robust quality gating, enables adaptive replanning\nand error recovery. Evaluated officially on the OSWorld benchmark,\n\\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\\% success rate in 50\nsteps, substantially outperforming existing methods. Results demonstrate that\nprincipled multi-agent orchestration with continuous quality control provides\nsuperior reliability for generalized desktop automation in complex computing\nenvironments.", "published": "2025-09-14 03:22:27", "link": "http://arxiv.org/abs/2509.11067v1", "categories": ["cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Large language model-empowered next-generation computer-aided engineering", "abstract": "Software development has entered a new era where large language models (LLMs)\nnow serve as general-purpose reasoning engines, enabling natural language\ninteraction and transformative applications across diverse domains. This\nparadigm is now extending into computer-aided engineering (CAE). Recent\napplications of LLMs in CAE have successfully automated routine tasks,\nincluding CAD model generation and FEM simulations. Nevertheless, these\ncontributions, which primarily serve to reduce manual labor, are often\ninsufficient for addressing the significant computational challenges posed by\nlarge-scale, high-dimensional systems. To this aim, we first introduce the\nconcept of LLM-empowered CAE agent, where LLMs act as autonomous collaborators\nthat plan, execute, and adapt CAE workflows. Then, we propose an LLM-empowered\nCAE agent for data-free model order reduction (MOR), a powerful yet underused\napproach for ultra-fast large-scale parametric analysis due to the intrusive\nnature and labor-intensive redevelopment of solvers. LLMs can alleviate this\nbarrier by automating derivations, code restructuring, and implementation,\nmaking intrusive MOR both practical and broadly accessible. To demonstrate\nfeasibility, we present an LLM-empowered CAE agent for solving\nultra-large-scale space-parameter-time (S-P-T) physical problems using\nTensor-decomposition-based A Priori Surrogates (TAPS). Our results show that\nnatural language prompts describing parametric partial differential equations\n(PDEs) can be translated into efficient solver implementations, substantially\nreducing human effort while producing high-fidelity reduced-order models.\nMoreover, LLMs can synthesize novel MOR solvers for unseen cases such as\nnonlinear and high-dimensional parametric problems based on their internal\nknowledge base. This highlights the potential of LLMs to establish the\nfoundation for next-generation CAE systems.", "published": "2025-09-14 21:45:27", "link": "http://arxiv.org/abs/2509.11447v1", "categories": ["cs.CE", "cs.NA", "math.NA"], "primary_category": "cs.CE"}
{"title": "Unified analysis of saddle point problems via auxiliary space theory", "abstract": "We present sharp estimates for the extremal eigenvalues of the Schur\ncomplements arising in saddle point problems. These estimates are derived using\nthe auxiliary space theory, in which a given iterative method is interpreted as\nan equivalent but more elementary iterative method on an auxiliary space,\nenabling us to obtain sharp convergence estimates. The proposed framework\nimproves or refines several existing results, which can be recovered as\ncorollaries of our results. To demonstrate the versatility of the framework, we\npresent various applications from scientific computing: the augmented\nLagrangian method, mixed finite element methods, and nonoverlapping domain\ndecomposition methods. In all these applications, the condition numbers of the\ncorresponding Schur complements can be estimated in a straightforward manner\nusing the proposed framework.", "published": "2025-09-14 20:59:08", "link": "http://arxiv.org/abs/2509.11434v1", "categories": ["math.NA", "cs.NA", "65F10, 65N22, 65N55"], "primary_category": "math.NA"}
{"title": "IGA-LBM: Isogeometric lattice Boltzmann method", "abstract": "The lattice Boltzmann method has become a widely adopted approach in\ncomputational fluid dynamics, offering unique advantages in mesoscopic kinetic\nmodeling, intrinsic parallelism, and simple treatment of boundary conditions.\nHowever, its conventional reliance on Cartesian grids fundamentally limits\ngeometric fidelity in flows involving curved boundaries, introducing stair-step\nartifacts that propagate as spurious forces and boundary-layer inaccuracies.\n  To address these challenges, we propose the isogeometric lattice Boltzmann\nmethod, which seamlessly integrates Isogeometric Analysis with LBM, leveraging\nthe geometric precision of non-uniform rational B-Splines to construct\nbody-fitted computational grids. Unlike conventional Cartesian-based LBM, the\nproposed approach eliminates stair-step boundary artifacts by providing\nsub-element geometric accuracy while maintaining the efficiency of LBM.\nFurthermore, the higher-order continuity of NURBS improves gradient resolution,\nreducing numerical diffusion in high-Reynold's-number flows. The parametric\ngrid adaptation of IGA enables $h$-, $p$-, and $k$-refinement strategies,\nallowing for localized resolution enhancement in boundary layers and regions\nwith high solution gradients. Additionally, the diffeomorphic mapping\nproperties of IGA ensure intrinsic conservation, preserving advection\ninvariants and suppressing numerical oscillations, leading to enhanced\nstability.\n  Benchmark simulations on flows with curved and complex geometries demonstrate\nthat IGA-LBM delivers significantly more accurate boundary-layer predictions\nand pressure/force estimates than standard Cartesian LBM, while preserving its\ncomputational efficiency and scalability. By combining geometric exactness with\nthe algorithmic simplicity of LBM, IGA-LBM offers a practical route to\nhigh-fidelity simulations in engineering and scientific applications.", "published": "2025-09-14 20:42:20", "link": "http://arxiv.org/abs/2509.11427v1", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "Derivative-informed Graph Convolutional Autoencoder with Phase Classification for the Lifshitz-Petrich Model", "abstract": "The Lifshitz-Petrich (LP) model is a classical model for describing complex\nspatial patterns such as quasicrystals and multiphase structures. Solving and\nclassifying the solutions of the LP model is challenging due to the presence of\nhigh-order gradient terms and the long-range orientational order characteristic\nof the quasicrystals. To address these challenges, we propose a\nDerivative-informed Graph Convolutional Autoencoder (DiGCA) to classify the\nmulti-component multi-state solutions of the LP model. The classifier consists\nof two stages. In the offline stage, the DiGCA phase classifier innovatively\nincorporates both solutions and their derivatives for training a graph\nconvolutional autoencoder which effectively captures intricate spatial\ndependencies while significantly reducing the dimensionality of the solution\nspace. In the online phase, the framework employs a neural network classifier\nto efficiently categorize encoded solutions into distinct phase diagrams. The\nnumerical results demonstrate that the DiGCA phase classifier accurately solves\nthe LP model, classifies its solutions, and rapidly generates detailed phase\ndiagrams in a robust manner, offering significant improvements in both\nefficiency and accuracy over traditional methods.", "published": "2025-09-14 14:32:42", "link": "http://arxiv.org/abs/2509.11293v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "GP-CMRH: An inner product free iterative method for block two-by-two nonsymmetric linear systems", "abstract": "We propose an inner product free iterative method called GP-CMRH for solving\nblock two-by-two nonsymmetric linear systems. GP-CMRH relies on a new\nsimultaneous Hessenberg process that reduces two rectangular matrices to upper\nHessenberg form simultaneously, without employing inner products. Compared with\nGPMR [SIAM J. Matrix Anal. Appl., 44 (2023), pp. 293--311], GP-CMRH requires\nless computational cost per iteration and may be more suitable for high\nperformance computing and low or mixed precision arithmetic due to its inner\nproduct free property. Our numerical experiments demonstrate that GP-CMRH and\nGPMR exhibit comparable convergence behavior (with GP-CMRH requiring slightly\nmore iterations), yet GP-CMRH consumes less computational time in most cases.\nGP-CMRH significantly outperforms GMRES and CMRH in terms of convergence rate\nand runtime efficiency.", "published": "2025-09-14 13:54:30", "link": "http://arxiv.org/abs/2509.11272v1", "categories": ["math.NA", "cs.NA", "15A06, 65F10, 65F50"], "primary_category": "math.NA"}
{"title": "Dynamical Low-Rank Approximations for Kalman Filtering", "abstract": "We propose a dynamical low rank approximation of the Kalman-Bucy process\n(DLR-KBP), which evolves the filtering distribution of a partially continuously\nobserved linear SDE on a small time-varying subspace at reduced computational\ncost. This reduction is valid in presence of small noise and when the filtering\ndistribution concentrates around a low dimensional subspace. We further extend\nthis approach to a DLR-ENKF process, where particles are evolved in a low\ndimensional time-varying subspace at reduced cost. This allows for a\nsignificantly larger ensemble size compared to standard EnKF at equivalent\ncost, thereby lowering the Monte Carlo error and improving filter accuracy.\nTheoretical properties of the DLR-KBP and DLR-ENKF are investigated, including\na propagation of chaos property. Numerical experiments demonstrate the\neffectiveness of the technique.", "published": "2025-09-14 10:36:59", "link": "http://arxiv.org/abs/2509.11210v1", "categories": ["math.NA", "cs.NA", "60G35, 60H35, 65C30, 65C35"], "primary_category": "math.NA"}
{"title": "Mechanical Proving the Symplecticity of Partitioned Runge--Kutta Methods for Determinate and Stochastic Hamiltonian Systems", "abstract": "We propose a new method to prove the partitioned Runge--Kutta methods with\nsymplectic conditions for determinate and stochastic Hamiltonian systems are\nsymplectic. We utilize Gr\\\"obner basis technology which is the one of symbolic\ncomputation method based on computer algebra theory and geometrical mechanical\nproving theory. In this approach, from determinate Hamilton's equations, we get\nthe relations of partial differentials which are regarded as polynomials of\nplenty variables marked indeterminates. Then, we compute the Gr\\\"obner basis of\nabove polynomials, and the normal form of symplectic expression, which is as\nthe middle expression, with respect to the Gr\\\"obner basis. Then, we compute\nthe Gr\\\"obner basis of symplectic conditions and the normal form of the middle\nexpression with respect to above Gr\\\"obner basis, and get that the normal form\nis zero, which complete the proof. We also develop this procedure to the\nstochastic Hamiltonian systems case and get similar result. In this paper, the\nnew try provide us a new idea to prove the structure-preservation laws of\nanother numerical methods, including the energy conservation law, the momentum\nconservation law and so on.", "published": "2025-09-14 09:32:48", "link": "http://arxiv.org/abs/2509.11188v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Improvements on uncertainty quantification with variational autoencoders", "abstract": "Inverse problems aim to determine model parameters of a mathematical problem\nfrom given observational data. Neural networks can provide an efficient tool to\nsolve these problems. In the context of Bayesian inverse problems, Uncertainty\nQuantification Variational AutoEncoders (UQ-VAE), a class of neural networks,\napproximate the posterior distribution mean and covariance of model parameters.\nThis allows for both the estimation of the parameters and their uncertainty in\nrelation to the observational data. In this work, we propose a novel loss\nfunction for training UQ-VAEs, which includes, among other modifications, the\nremoval of a sample mean term from an already existing one. This modification\nimproves the accuracy of UQ-VAEs, as the original theoretical result relies on\nthe convergence of the sample mean to the expected value (a condition that, in\nhigh dimensional parameter spaces, requires a prohibitively large number of\nsamples due to the curse of dimensionality). Avoiding the computation of the\nsample mean significantly reduces the training time in high dimensional\nparameter spaces compared to previous literature results. Under this new\nformulation, we establish a new theoretical result for the approximation of the\nposterior mean and covariance for general mathematical problems. We validate\nthe effectiveness of UQ-VAEs through three benchmark numerical tests: a Poisson\ninverse problem, a non affine inverse problem and a 0D cardiocirculatory model,\nunder the two clinical scenarios of systemic hypertension and ventricular\nseptal defect. For the latter case, we perform forward uncertainty\nquantification.", "published": "2025-09-14 09:13:28", "link": "http://arxiv.org/abs/2509.11174v1", "categories": ["math.NA", "cs.NA", "68T07, 62C10"], "primary_category": "math.NA"}
{"title": "A time-splitting Fourier pseudospectral method for the Wigner(-Poisson)-Fokker-Planck equations", "abstract": "In this article, we propose an efficient time-splitting Fourier\npseudospectral method for the Wigner(-Poisson)-Fokker-Planck equations. The\nmethod achieves second-order accuracy in time and spectral accuracy in phase\nspace, both of which are rigorously verified by numerical experiments. The\nvalidated scheme is then employed to study the long-time dynamics of these\nsystems. We investigate the existence of steady states for both the\nWigner-Fokker-Planck and Wigner-Poisson-Fokker-Planck equations. Notably, for\nthe Wigner-Fokker-Planck system, our results provide numerical evidence for the\nexistence of a steady state even when the external potential is far from\nharmonic. This is an important discovery, since this phenomenon has not been\nthoroughly established in theory.", "published": "2025-09-14 08:08:28", "link": "http://arxiv.org/abs/2509.11153v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Vectorized 3D mesh refinement and implementation of primal hybrid FEM in MATLAB", "abstract": "In this article, we introduce a Face-to-Tetrahedron connectivity in MATLAB\ntogether with a vectorized 3D uniform mesh refinement technique. We introduce a\nMATLAB vectorized assembly of 3D lowest-order primal hybrid finite element\nmatrices for a second-order elliptic problem. We introduce a parallel solver\nand a vectorized Schur complement solver to solve the associated linear\nproblem. The numerical results illustrate the software's runtime performance.", "published": "2025-09-14 07:02:35", "link": "http://arxiv.org/abs/2509.11133v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Kernel-based Stochastic Approximation Framework for Nonlinear Operator Learning", "abstract": "We develop a stochastic approximation framework for learning nonlinear\noperators between infinite-dimensional spaces utilizing general Mercer\noperator-valued kernels. Our framework encompasses two key classes: (i) compact\nkernels, which admit discrete spectral decompositions, and (ii) diagonal\nkernels of the form $K(x,x')=k(x,x')T$, where $k$ is a scalar-valued kernel and\n$T$ is a positive operator on the output space. This broad setting induces\nexpressive vector-valued reproducing kernel Hilbert spaces (RKHSs) that\ngeneralize the classical $K=kI$ paradigm, thereby enabling rich structural\nmodeling with rigorous theoretical guarantees. To address target operators\nlying outside the RKHS, we introduce vector-valued interpolation spaces to\nprecisely quantify misspecification error. Within this framework, we establish\ndimension-free polynomial convergence rates, demonstrating that nonlinear\noperator learning can overcome the curse of dimensionality. The use of general\noperator-valued kernels further allows us to derive rates for intrinsically\nnonlinear operator learning, going beyond the linear-type behavior inherent in\ndiagonal constructions of $K=kI$. Importantly, this framework accommodates a\nwide range of operator learning tasks, ranging from integral operators such as\nFredholm operators to architectures based on encoder-decoder representations.\nMoreover, we validate its effectiveness through numerical experiments on the\ntwo-dimensional Navier-Stokes equations.", "published": "2025-09-14 03:33:36", "link": "http://arxiv.org/abs/2509.11070v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.FA", "math.NA", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Solving ill-conditioned polynomial equations using score-based priors with application to multi-target detection", "abstract": "Recovering signals from low-order moments is a fundamental yet notoriously\ndifficult task in inverse problems. This recovery process often reduces to\nsolving ill-conditioned systems of polynomial equations. In this work, we\npropose a new framework that integrates score-based diffusion priors with\nmoment-based estimators to regularize and solve these nonlinear inverse\nproblems. This introduces a new role for generative models: stabilizing\npolynomial recovery from noisy statistical features. As a concrete application,\nwe study the multi-target detection (MTD) model in the high-noise regime. We\ndemonstrate two main results: (i) diffusion priors substantially improve\nrecovery from third-order moments, and (ii) they make the super-resolution MTD\nproblem, otherwise ill-posed, feasible. Numerical experiments on MNIST data\nconfirm consistent gains in reconstruction accuracy across SNR levels. Our\nresults suggest a promising new direction for combining generative priors with\nnonlinear polynomial inverse problems.", "published": "2025-09-14 19:21:32", "link": "http://arxiv.org/abs/2509.11397v1", "categories": ["eess.SP", "stat.ML"], "primary_category": "eess.SP"}
{"title": "The Honest Truth About Causal Trees: Accuracy Limits for Heterogeneous Treatment Effect Estimation", "abstract": "Recursive decision trees have emerged as a leading methodology for\nheterogeneous causal treatment effect estimation and inference in experimental\nand observational settings. These procedures are fitted using the celebrated\nCART (Classification And Regression Tree) algorithm [Breiman et al., 1984], or\ncustom variants thereof, and hence are believed to be \"adaptive\" to\nhigh-dimensional data, sparsity, or other specific features of the underlying\ndata generating process. Athey and Imbens [2016] proposed several \"honest\"\ncausal decision tree estimators, which have become the standard in both\nacademia and industry. We study their estimators, and variants thereof, and\nestablish lower bounds on their estimation error. We demonstrate that these\npopular heterogeneous treatment effect estimators cannot achieve a\npolynomial-in-$n$ convergence rate under basic conditions, where $n$ denotes\nthe sample size. Contrary to common belief, honesty does not resolve these\nlimitations and at best delivers negligible logarithmic improvements in sample\nsize or dimension. As a result, these commonly used estimators can exhibit poor\nperformance in practice, and even be inconsistent in some settings. Our\ntheoretical insights are empirically validated through simulations.", "published": "2025-09-14 18:29:45", "link": "http://arxiv.org/abs/2509.11381v1", "categories": ["math.ST", "econ.EM", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Next-Generation Reservoir Computing for Dynamical Inference", "abstract": "We present a simple and scalable implementation of next-generation reservoir\ncomputing for modeling dynamical systems from time series data. Our approach\nuses a pseudorandom nonlinear projection of time-delay embedded input, allowing\nan arbitrary dimension of the feature space, thus providing a flexible\nalternative to the polynomial-based projections used in previous\nnext-generation reservoir computing variants. We apply the method to benchmark\ntasks -- including attractor reconstruction and bifurcation diagram estimation\n-- using only partial and noisy observations. We also include an exploratory\nexample of estimating asymptotic oscillation phases. The models remain stable\nover long rollouts and generalize beyond training data. This framework enables\nthe precise control of system state and is well suited for surrogate modeling\nand digital twin applications.", "published": "2025-09-14 16:28:48", "link": "http://arxiv.org/abs/2509.11338v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Contrastive Network Representation Learning", "abstract": "Network representation learning seeks to embed networks into a\nlow-dimensional space while preserving the structural and semantic properties,\nthereby facilitating downstream tasks such as classification, trait prediction,\nedge identification, and community detection. Motivated by challenges in brain\nconnectivity data analysis that is characterized by subject-specific,\nhigh-dimensional, and sparse networks that lack node or edge covariates, we\npropose a novel contrastive learning-based statistical approach for network\nedge embedding, which we name as Adaptive Contrastive Edge Representation\nLearning (ACERL). It builds on two key components: contrastive learning of\naugmented network pairs, and a data-driven adaptive random masking mechanism.\nWe establish the non-asymptotic error bounds, and show that our method achieves\nthe minimax optimal convergence rate for edge representation learning. We\nfurther demonstrate the applicability of the learned representation in multiple\ndownstream tasks, including network classification, important edge detection,\nand community detection, and establish the corresponding theoretical\nguarantees. We validate our method through both synthetic data and real brain\nconnectivities studies, and show its competitive performance compared to the\nbaseline method of sparse principal components analysis.", "published": "2025-09-14 15:25:59", "link": "http://arxiv.org/abs/2509.11316v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "SelectMix: Enhancing Label Noise Robustness through Targeted Sample Mixing", "abstract": "Deep neural networks tend to memorize noisy labels, severely degrading their\ngeneralization performance. Although Mixup has demonstrated effectiveness in\nimproving generalization and robustness, existing Mixup-based methods typically\nperform indiscriminate mixing without principled guidance on sample selection\nand mixing strategy, inadvertently propagating noisy supervision. To overcome\nthese limitations, we propose SelectMix, a confidence-guided mixing framework\nexplicitly tailored for noisy labels. SelectMix first identifies potentially\nnoisy or ambiguous samples through confidence based mismatch analysis using\nK-fold cross-validation, then selectively blends identified uncertain samples\nwith confidently predicted peers from their potential classes. Furthermore,\nSelectMix employs soft labels derived from all classes involved in the mixing\nprocess, ensuring the labels accurately represent the composition of the mixed\nsamples, thus aligning supervision signals closely with the actual mixed\ninputs. Through extensive theoretical analysis and empirical evaluations on\nmultiple synthetic (MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100) and real-world\nbenchmark datasets (CIFAR-N, MNIST and Clothing1M), we demonstrate that\nSelectMix consistently outperforms strong baseline methods, validating its\neffectiveness and robustness in learning with noisy labels.", "published": "2025-09-14 13:37:38", "link": "http://arxiv.org/abs/2509.11265v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Online Optimization on Hadamard Manifolds: Curvature Independent Regret Bounds on Horospherically Convex Objectives", "abstract": "We study online Riemannian optimization on Hadamard manifolds under the\nframework of horospherical convexity (h-convexity). Prior work mostly relies on\nthe geodesic convexity (g-convexity), leading to regret bounds scaling poorly\nwith the manifold curvature. To address this limitation, we analyze Riemannian\nonline gradient descent for h-convex and strongly h-convex functions and\nestablish $O(\\sqrt{T})$ and $O(\\log(T))$ regret guarantees, respectively. These\nbounds are curvature-independent and match the results in the Euclidean\nsetting. We validate our approach with experiments on the manifold of symmetric\npositive definite (SPD) matrices equipped with the affine-invariant metric. In\nparticular, we investigate online Tyler's $M$-estimation and online Fr\\'echet\nmean computation, showing the application of h-convexity in practice.", "published": "2025-09-14 12:27:31", "link": "http://arxiv.org/abs/2509.11236v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Predictable Compression Failures: Why Language Models Actually Hallucinate", "abstract": "Large language models perform near-Bayesian inference yet violate permutation\ninvariance on exchangeable data. We resolve this by showing transformers\nminimize expected conditional description length (cross-entropy) over\norderings, $\\mathbb{E}_\\pi[\\ell(Y \\mid \\Gamma_\\pi(X))]$, which admits a\nKolmogorov-complexity interpretation up to additive constants, rather than the\npermutation-invariant description length $\\ell(Y \\mid X)$. This makes them\nBayesian in expectation, not in realization. We derive (i) a Quantified\nMartingale Violation bound showing order-induced deviations scale as $O(\\log\nn)$ with constants; (ii) the Expectation-level Decompression Law linking\ninformation budgets to reliability for Bernoulli predicates; and (iii)\ndeployable planners (B2T/RoH/ISR) for answer/abstain decisions. Empirically,\npermutation dispersion follows $a+b\\ln n$ (Qwen2-7B $b \\approx 0.377$,\nLlama-3.1-8B $b \\approx 0.147$); permutation mixtures improve ground-truth\nlikelihood/accuracy; and randomized dose-response shows hallucinations drop by\n$\\sim 0.13$ per additional nat. A pre-specified audit with a fixed ISR=1.0\nachieves near-0\\% hallucinations via calibrated refusal at 24\\% abstention. The\nframework turns hallucinations into predictable compression failures and\nenables principled information budgeting.", "published": "2025-09-14 10:32:59", "link": "http://arxiv.org/abs/2509.11208v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Maximum diversity, weighting and invariants of time series", "abstract": "Magnitude, obtained as a special case of Euler characteristic of enriched\ncategory, represents a sense of the size of metric spaces and is related to\nclassical notions such as cardinality, dimension, and volume. While the studies\nhave explained the meaning of magnitude from various perspectives, continuity\nalso gives a valuable view of magnitude. Based on established results about\ncontinuity of magnitude and maximum diversity, this article focuses on\ncontinuity of weighting, a distribution whose totality is magnitude, and its\nvariation corresponding to maximum diversity. Meanwhile, recent studies also\nilluminated the connection between magnitude and data analysis by applying\nmagnitude theory to point clouds representing the data or the set of model\nparameters. This article will also provide an application for time series\nanalysis by introducing a new kind of invariants of periodic time series, where\nthe invariance follows directly from the continuity results. As a use-case, a\nsimple machine learning experiment is conducted with real-world data, in which\nthe suggested invariants improved the performance.", "published": "2025-09-14 07:33:05", "link": "http://arxiv.org/abs/2509.11146v1", "categories": ["stat.ML", "cs.LG", "eess.SP", "math.MG", "46N40, 51F99, 68T10"], "primary_category": "stat.ML"}
{"title": "What is in a Price? Estimating Willingness-to-Pay with Bayesian Hierarchical Models", "abstract": "For premium consumer products, pricing strategy is not about a single number,\nbut about understanding the perceived monetary value of the features that\njustify a higher cost. This paper proposes a robust methodology to deconstruct\na product's price into the tangible value of its constituent parts. We employ\nBayesian Hierarchical Conjoint Analysis, a sophisticated statistical technique,\nto solve this high-stakes business problem using the Apple iPhone as a\nuniversally recognizable case study. We first simulate a realistic choice based\nconjoint survey where consumers choose between different hypothetical iPhone\nconfigurations. We then develop a Bayesian Hierarchical Logit Model to infer\nconsumer preferences from this choice data. The core innovation of our model is\nits ability to directly estimate the Willingness-to-Pay (WTP) in dollars for\nspecific feature upgrades, such as a \"Pro\" camera system or increased storage.\nOur results demonstrate that the model successfully recovers the true,\nunderlying feature valuations from noisy data, providing not just a point\nestimate but a full posterior probability distribution for the dollar value of\neach feature. This work provides a powerful, practical framework for\ndata-driven product design and pricing strategy, enabling businesses to make\nmore intelligent decisions about which features to build and how to price them.", "published": "2025-09-14 04:39:35", "link": "http://arxiv.org/abs/2509.11089v1", "categories": ["stat.AP", "cs.LG", "econ.EM", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Revisiting Meter Tracking in Carnatic Music using Deep Learning Approaches", "abstract": "Beat and downbeat tracking, jointly referred to as Meter Tracking, is a\nfundamental task in Music Information Retrieval (MIR). Deep learning models\nhave far surpassed traditional signal processing and classical machine learning\napproaches in this domain, particularly for Western (Eurogenetic) genres, where\nlarge annotated datasets are widely available. These systems, however, perform\nless reliably on underrepresented musical traditions. Carnatic music, a rich\ntradition from the Indian subcontinent, is renowned for its rhythmic intricacy\nand unique metrical structures (t\\=alas). The most notable prior work on meter\ntracking in this context employed probabilistic Dynamic Bayesian Networks\n(DBNs). The performance of state-of-the-art (SOTA) deep learning models on\nCarnatic music, however, remains largely unexplored.\n  In this study, we evaluate two models for meter tracking in Carnatic music:\nthe Temporal Convolutional Network (TCN), a lightweight architecture that has\nbeen successfully adapted for Latin rhythms, and Beat This!, a\ntransformer-based model designed for broad stylistic coverage without the need\nfor post-processing. Replicating the experimental setup of the DBN baseline on\nthe Carnatic Music Rhythm (CMR$_f$) dataset, we systematically assess the\nperformance of these models in a directly comparable setting. We further\ninvestigate adaptation strategies, including fine-tuning the models on Carnatic\ndata and the use of musically informed parameters. Results show that while\noff-the-shelf models do not always outperform the DBN, their performance\nimproves substantially with transfer learning, matching or surpassing the\nbaseline. These findings indicate that SOTA deep learning models can be\neffectively adapted to underrepresented traditions, paving the way for more\ninclusive and broadly applicable meter tracking systems.", "published": "2025-09-14 12:33:34", "link": "http://arxiv.org/abs/2509.11241v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "WeaveMuse: An Open Agentic System for Multimodal Music Understanding and Generation", "abstract": "Agentic AI has been standardized in industry as a practical paradigm for\ncoordinating specialized models and tools to solve complex multimodal tasks. In\nthis work, we present WeaveMuse, a multi-agent system for music understanding,\nsymbolic composition, and audio synthesis. Each specialist agent interprets\nuser requests, derives machine-actionable requirements (modalities, formats,\nconstraints), and validates its own outputs, while a manager agent selects and\nsequences tools, mediates user interaction, and maintains state across turns.\nThe system is extendable and deployable either locally, using quantization and\ninference strategies to fit diverse hardware budgets, or via the HFApi to\npreserve free community access to open models. Beyond out-of-the-box use, the\nsystem emphasizes controllability and adaptation through constraint schemas,\nstructured decoding, policy-based inference, and parameter-efficient adapters\nor distilled variants that tailor models to MIR tasks. A central design goal is\nto facilitate intermodal interaction across text, symbolic notation and\nvisualization, and audio, enabling analysis-synthesis-render loops and\naddressing cross-format constraints. The framework aims to democratize,\nimplement, and make accessible MIR tools by supporting interchangeable\nopen-source models of various sizes, flexible memory management, and\nreproducible deployment paths.", "published": "2025-09-14 09:29:33", "link": "http://arxiv.org/abs/2509.11183v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Knowledge Distillation for Sensing-Assisted Long-Term Beam Tracking in mmWave Communications", "abstract": "Infrastructure-mounted sensors can capture rich environmental information to\nenhance communications and facilitate beamforming in millimeter-wave systems.\nThis work presents an efficient sensing-assisted long-term beam tracking\nframework that selects optimal beams from a codebook for current and multiple\nfuture time slots. We first design a large attention-enhanced neural network\n(NN) to fully exploit past visual observations for beam tracking. A\nconvolutional NN extracts compact image features, while gated recurrent units\nwith attention capture the temporal dependencies within sequences. The large NN\nthen acts as the teacher to guide the training of a lightweight student NN via\nknowledge distillation. The student requires shorter input sequences yet\npreserves long-term beam prediction ability. Numerical results demonstrate that\nthe teacher achieves Top-5 accuracies exceeding 93% for current and six future\ntime slots, approaching state-of-the-art performance with a 90% complexity\nreduction. The student closely matches the teacher's performance while cutting\ncomplexity by another 90%, despite operating with 60% shorter input sequences.\nThis improvement significantly enhances data efficiency, reduces latency, and\nlowers power consumption in sensing and processing.", "published": "2025-09-14 20:12:18", "link": "http://arxiv.org/abs/2509.11419v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Generalized Framework for Quadratic Noise Modulation Using Non-Gaussian Distributions", "abstract": "This letter generalizes noise modulation by introducing two voltage biases\nand employing non-Gaussian noise distributions, such as Mixture of Gaussian\n(MoG) and Laplacian, in addition to traditional Gaussian noise. The proposed\nframework doubles the data rate by enabling discrimination in both the mean and\nvariance of transmitted noise symbols. This novel modulation scheme is referred\nto as Generalized Quadratic Noise Modulation (GQNM). Closed-form expressions\nfor the Bit Error Probability (BEP) are derived for the Generalized Gaussian\n(GG) and Gaussian Mixture of Two Gaussians (GMoTG) cases. Simulation results\ndemonstrate the advantages of the generalized modulation scheme, particularly\nunder non-Gaussian noise assumptions, highlighting its potential for enhanced\nperformance in low-power and secure communication systems.", "published": "2025-09-14 18:17:10", "link": "http://arxiv.org/abs/2509.11378v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Resistor Hopping KLJN Noise Communication Using Small Bias Voltages Supported by ML and Optimum Threshold-Based Detectors", "abstract": "In this paper, a Resistor Hopping (RH) scheme with the addition of biases is\nproposed for secure Kirchhoff Law Johnson-Noise (KLJN) communication. The RH\napproach enables us to increase the bit rate of secure communication between\nAlice and Bob, while also ensuring that the inherent unconditional security of\nKLJN is satisfied. The biases are added to the proposed scheme to better\ndistinguish between Gaussian distributed noises in terms of their means, rather\nthan just using variances. Throughout the paper, we strive to minimize biases\nto achieve a power-efficient scheme. For the detection part of the proposed\nalgorithm, a Maximum-Likelihood (ML) detector is derived. The separability\ncondition of Gaussian distributions is investigated, along with the provision\nof a threshold-based detector that offers both simple and optimal thresholds in\nterms of minimizing the error probability. Some analysis of the proposed\nRH-KLJN communication scheme is provided, including Physical Layer Security\n(PLS) equations. Simulation results demonstrate the advantages of the proposed\nscheme over the classical KLJN scheme, offering a higher data rate and lower\nbit error probability at the expense of increased complexity.", "published": "2025-09-14 18:10:56", "link": "http://arxiv.org/abs/2509.11373v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Synesthesia of Machines (SoM)-Empowered Wireless Image Transmission over Complex Dynamic Channel", "abstract": "Wireless image transmission underpins diverse networked intelligent services\nand becomes an increasingly critical issue. Existing works have shown that deep\nlearning-based joint source-channel coding (JSCC) is an effective framework to\nbalance image transmission fidelity and data overhead. However, these studies\noversimplify the communication system as a mere pipeline with noise, failing to\naccount for the complex dynamics of wireless channels and concrete\nphysical-layer transmission process. To address these limitations, we propose a\nSynesthesia of Machines (SoM)-empowered Dynamic Channel Adaptive Transmission\n(DCAT) scheme, designed for practical implementation in real communication\nscenarios. Building upon the Swin Transformer backbone, our DCAT scheme\ndemonstrates robust adaptability to time-selective fading and channel aging\neffects by effectively utilizing the physical-layer transmission\ncharacteristics of wireless channels. Comprehensive experimental results\nconfirm that DCAT consistently achieves superior performance compared with JSCC\nbaseline approaches across all conditions. Furthermore, our neural network\narchitecture demonstrates high scalability due to its interpretable design,\noffering substantial potential for cost-efficient deployment in practical\napplications.", "published": "2025-09-14 12:35:54", "link": "http://arxiv.org/abs/2509.11243v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Holographic interference surface: A proof of concept based on the principle of interferometry", "abstract": "Revolutionizing communication architectures to achieve a balance between\nenhanced performance and improved efficiency is becoming increasingly critical\nfor wireless communications as the era of ultra-large-scale arrays approaches.\nIn traditional communication architectures, radio frequency (RF) signals are\ntypically converted to baseband for subsequent processing through operations\nsuch as filtering, analog-to-digital conversion and down-conversion, all of\nwhich depend on expensive and power-intensive RF chains. The increased hardware\ncomplexity and escalated power consumption resulting from this dependency\nsignificantly limit the practical deployment of ultra-large-scale arrays. To\naddress these limitations, we propose a holographic communication system based\non the principle of interferometry, designated as holographic interference\nsurfaces (HIS). Utilizing the interference effect of electromagnetic waves, HIS\nestimates the channel state information (CSI) by dealing solely with power\ninformation, which enables the replacement of RF chains with power sensors and\ncompletes the signal processing in radio frequency. As proof-of-concept\ndemonstrations, we implemented a prototype system based on principles of\nholographic interference. Experimental results align well with theoretical\npredictions, confirming the practical viability and effectiveness of the\nproposed HIS. This work provides a new paradigm for building a more\ncost-effective wireless communication architecture.", "published": "2025-09-14 09:44:20", "link": "http://arxiv.org/abs/2509.11193v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Nonreciprocal RIS-Aided Covert Channel Reciprocity Attacks and Countermeasures", "abstract": "Reconfigurable intelligent surface (RIS) technology enhances wireless\ncommunication performance, but it also introduces new vulnerabilities that can\nbe exploited by adversaries. This paper investigates channel reciprocity attack\n(CRACK) threats in multi-antenna wireless systems operating in time-division\nduplexing mode using a physically consistent non-reciprocal RIS (NR-RIS) model.\nCRACK can degrade communication rate and facilitate passive eavesdropping\nbehavior by distorting the downlink precoding, without requiring any additional\nsignal transmission or channel state information (CSI). Unlike conventional RIS\njamming strategies, the NR-RIS does not need synchronization with the\nlegitimate system and thus can operate with slow or fixed configurations to\nimplement CRACK, obscuring the distinction between the direct and RIS-induced\nchannels and thereby complicating corresponding defensive precoding designs. To\ncounter the CRACK threat posed by NR-RIS, we develop ``SecureCoder,'' a deep\nreinforcement learning-based framework that can mitigate CRACK and determine an\nimproved downlink precoder matrix using the estimated uplink CSI and rate\nfeedback from the users. Simulation results demonstrate the severe performance\ndegradation caused by NR-RIS CRACK and validate the effectiveness of\nSecureCoder in improving both throughput and reducing security threats, thereby\nenhancing system robustness.", "published": "2025-09-14 06:15:23", "link": "http://arxiv.org/abs/2509.11117v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The Microwave Rainbow: How Geometry Paints Colours in Microwave Vision", "abstract": "Microwave vision from spaceborne synthetic aperture radar (SAR) provides an\nall-weather, day-and-night capability to observe Earth, yet much of the\ninformation encoded in its signals remains undeciphered. Recent high-resolution\nimagery has revealed a striking phenomenon: man-made structures systematically\nappear in a spectrum of colours, the physical origin of which has been an open\nquestion. Here we show that this effect, which we term the microwave rainbow,\nis a form of geometric dispersion arising from structures acting as intrinsic\ndiffraction gratings. We introduce a geometric-physical model that provides a\ndirect analytical link between a target's geometry and its observed colour\nsignature. This model quantitatively explains the full range of signatures,\nfrom continuous colour gradients on curved surfaces (zero-order diffraction) to\nrepeating spectral patterns from periodic structures (high-order diffraction).\nThis work transforms colour from a visual artefact into a precise measure of\nphysical form, enabling the geometry of both critical infrastructure and\nnatural phenomena to be mapped directly from space. Our findings establish the\nphysical basis for a new remote sensing modality: microwave colour vision, and\nopen a new frontier in how we perceive our world.", "published": "2025-09-14 05:33:37", "link": "http://arxiv.org/abs/2509.11099v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Experimental Demonstration of Rate-Adaptation via Hybrid Polar-BCH Product Code for Flexible PON", "abstract": "The flexible-rate Polar-BCH product codes are experimentally demonstrated in\na coherent passive optical network system with 16QAM for the first time. Using\na new hybrid soft- and hard-decision decoder, we achieve a power gain of upto\n1.75 dB over traditional BCH-BCH product codes after 48 km transmission.", "published": "2025-09-14 04:15:16", "link": "http://arxiv.org/abs/2509.11081v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Evalet: Evaluating Large Language Models by Fragmenting Outputs into Functions", "abstract": "Practitioners increasingly rely on Large Language Models (LLMs) to evaluate\ngenerative AI outputs through \"LLM-as-a-Judge\" approaches. However, these\nmethods produce holistic scores that obscure which specific elements influenced\nthe assessments. We propose functional fragmentation, a method that dissects\neach output into key fragments and interprets the rhetoric functions that each\nfragment serves relative to evaluation criteria -- surfacing the elements of\ninterest and revealing how they fulfill or hinder user goals. We instantiate\nthis approach in Evalet, an interactive system that visualizes fragment-level\nfunctions across many outputs to support inspection, rating, and comparison of\nevaluations. A user study (N=10) found that, while practitioners struggled to\nvalidate holistic scores, our approach helped them identify 48% more evaluation\nmisalignments. This helped them calibrate trust in LLM evaluations and rely on\nthem to find more actionable issues in model outputs. Our work shifts LLM\nevaluation from quantitative scores toward qualitative, fine-grained analysis\nof model behavior.", "published": "2025-09-14 10:24:13", "link": "http://arxiv.org/abs/2509.11206v2", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs", "abstract": "Recent advances in Large Language Model (LLM) compression, such as\nquantization and pruning, have achieved notable success. However, as these\ntechniques gradually approach their respective limits, relying on a single\nmethod for further compression has become increasingly challenging. In this\nwork, we explore an alternative solution by combining quantization and\nsparsity. This joint approach, though promising, introduces new difficulties\ndue to the inherently conflicting requirements on weight distributions:\nquantization favors compact ranges, while pruning benefits from high variance.\nTo attack this problem, we propose Optimal Brain Restoration (OBR), a general\nand training-free framework that aligns pruning and quantization by error\ncompensation between both. OBR minimizes performance degradation on downstream\ntasks by building on a second-order Hessian objective, which is then\nreformulated into a tractable problem through surrogate approximation and\nultimately reaches a closed-form solution via group error compensation.\nExperiments show that OBR enables aggressive W4A4KV4 quantization with 50%\nsparsity on existing LLMs, and delivers up to 4.72x speedup and 6.4x memory\nreduction compared to the FP16-dense baseline.", "published": "2025-09-14 09:17:19", "link": "http://arxiv.org/abs/2509.11177v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Particle-Flow Algorithm for Free-Support Wasserstein Barycenters", "abstract": "The Wasserstein barycenter extends the Euclidean mean to the space of\nprobability measures by minimizing the weighted sum of squared 2-Wasserstein\ndistances. We develop a free-support algorithm for computing Wasserstein\nbarycenters that avoids entropic regularization and instead follows the formal\nRiemannian geometry of Wasserstein space. In our approach, barycenter atoms\nevolve as particles advected by averaged optimal-transport displacements, with\nbarycentric projections of optimal transport plans used in place of Monge maps\nwhen the latter do not exist. This yields a geometry-aware particle-flow update\nthat preserves sharp features of the Wasserstein barycenter while remaining\ncomputationally tractable. We establish theoretical guarantees, including\nconsistency of barycentric projections, monotone descent and convergence to\nstationary points, stability with respect to perturbations of the inputs, and\nresolution consistency as the number of atoms increases. Empirical studies on\naveraging probability distributions, Bayesian posterior aggregation, image\nprototypes and classification, and large-scale clustering demonstrate accuracy\nand scalability of the proposed particle-flow approach, positioning it as a\nprincipled alternative to both linear programming and regularized solvers.", "published": "2025-09-14 21:05:04", "link": "http://arxiv.org/abs/2509.11435v2", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration", "abstract": "Autonomous agents for desktop automation struggle with complex multi-step\ntasks due to poor coordination and inadequate quality control. We introduce\nAgentic Lybic, a novel multi-agent system where the entire architecture\noperates as a finite-state machine (FSM). This core innovation enables dynamic\norchestration. Our system comprises four components: a Controller, a Manager,\nthree Workers (Technician for code-based operations, Operator for GUI\ninteractions, and Analyst for decision support), and an Evaluator. The critical\nmechanism is the FSM-based routing between these components, which provides\nflexibility and generalization by dynamically selecting the optimal execution\nstrategy for each subtask. This principled orchestration, combined with robust\nquality gating, enables adaptive replanning and error recovery. Evaluated\nofficially on the OSWorld benchmark, Agentic Lybic achieves a state-of-the-art\n57.07% success rate in 50 steps, substantially outperforming existing methods.\nResults demonstrate that principled multi-agent orchestration with continuous\nquality control provides superior reliability for generalized desktop\nautomation in complex computing environments.", "published": "2025-09-14 03:22:27", "link": "http://arxiv.org/abs/2509.11067v2", "categories": ["cs.AI", "cs.HC", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Auto-Slides: An Interactive Multi-Agent System for Creating and Customizing Research Presentations", "abstract": "The rapid progress of large language models (LLMs) has opened new\nopportunities for education. While learners can interact with academic papers\nthrough LLM-powered dialogue, limitations still exist: absence of structured\norganization and high text reliance can impede systematic understanding and\nengagement with complex concepts. To address these challenges, we propose\nAuto-Slides, an LLM-driven system that converts research papers into\npedagogically structured, multimodal slides (e.g., diagrams and tables).\nDrawing on cognitive science, it creates a presentation-oriented narrative and\nallows iterative refinement via an interactive editor, in order to match\nlearners' knowledge level and goals. Auto-Slides further incorporates\nverification and knowledge retrieval mechanisms to ensure accuracy and\ncontextual completeness. Through extensive user studies, Auto-Slides enhances\nlearners' comprehension and engagement compared to conventional LLM-based\nreading. Our contributions lie in designing a multi-agent framework for\ntransforming academic papers into pedagogically optimized slides and\nintroducing interactive customization for personalized learning.", "published": "2025-09-14 03:05:54", "link": "http://arxiv.org/abs/2509.11062v1", "categories": ["cs.HC", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Dynamical symmetry breaking described by cubic nonlinear Klein-Gordon equations", "abstract": "The dynamical symmetry breaking associated with the existence and\nnon-existence of breather solutions is studied. Here, nonlinear hyperbolic\nevolution equations are calculated using a high-precision numerical scheme. %%%\nFirst, for clarifying the dynamical symmetry breaking, it is necessary to use a\nsufficiently high-precision scheme in the time-dependent framework. Second, the\nerror of numerical calculations is generally more easily accumulated for\ncalculating hyperbolic equations rather than parabolic equations. Third,\nnumerical calculations become easily unstable for nonlinear cases. Our strategy\nfor the high-precision and stable scheme is to implement the implicit\nRunge-Kutta method for time, and the Fourier spectral decomposition for space.\n%%% In this paper, focusing on the breather solutions, the relationship between\nthe velocity, mass, and the amplitude of the perturbation is clarified. As a\nresult, the conditions for transitioning from one state to another are\nclarified.", "published": "2025-09-14 01:41:42", "link": "http://arxiv.org/abs/2509.12272v1", "categories": ["math.NA", "cs.NA", "hep-th", "nlin.AO", "nlin.CD", "Primary 81R40, 81Q05, Secondary 65M70, 65L06"], "primary_category": "math.NA"}
{"title": "Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio questuin answering", "abstract": "We propose Omni-CLST, an error-aware Curriculum Learning framework with\nguided Selective Chain-of-Thought for audio question answering. The framework\nefficiently leverages existing high-quality dataset through two key strategies:\nan error-aware curriculum that organizes samples by difficulty, and a guided\nthought dropout mechanism that focuses reasoning on challenging cases.\nIntegrated with GRPO training, these strategies enable the model to learn more\neffectively from informative samples. Experiments on MMAU-mini and MMAR\ndemonstrate that Omni-CLST achieves competitive accuracy (73.80% on MMAU-mini)\nand establishes a new state of the art (64.30% on MMAR), highlighting its\nrobustness and generalization capability in multimodal audio-language\nunderstanding.", "published": "2025-09-14 06:54:12", "link": "http://arxiv.org/abs/2509.12275v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "STASE: A spatialized text-to-audio synthesis engine for music generation", "abstract": "While many text-to-audio systems produce monophonic or fixed-stereo outputs,\ngenerating audio with user-defined spatial properties remains a challenge.\nExisting deep learning-based spatialization methods often rely on latent-space\nmanipulations, which can limit direct control over psychoacoustic parameters\ncritical to spatial perception. To address this, we introduce STASE, a system\nthat leverages a Large Language Model (LLM) as an agent to interpret spatial\ncues from text. A key feature of STASE is the decoupling of semantic\ninterpretation from a separate, physics-based spatial rendering engine, which\nfacilitates interpretable and user-controllable spatial reasoning. The LLM\nprocesses prompts through two main pathways: (i) Description Prompts, for\ndirect mapping of explicit spatial information (e.g., \"place the lead guitar at\n45{\\deg} azimuth, 10 m distance\"), and (ii) Abstract Prompts, where a\nRetrieval-Augmented Generation (RAG) module retrieves relevant spatial\ntemplates to inform the rendering. This paper details the STASE workflow,\ndiscusses implementation considerations, and highlights current challenges in\nevaluating generative spatial audio.", "published": "2025-09-14 06:29:18", "link": "http://arxiv.org/abs/2509.11124v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Auto-Slides: An Interactive Multi-Agent System for Creating and Customizing Research Presentations", "abstract": "The rapid progress of large language models (LLMs) has opened new\nopportunities for education. While learners can interact with academic papers\nthrough LLM-powered dialogue, limitations still exist: absence of structured\norganization and high text reliance can impede systematic understanding and\nengagement with complex concepts. To address these challenges, we propose\nAuto-Slides, an LLM-driven system that converts research papers into\npedagogically structured, multimodal slides (e.g., diagrams and tables).\nDrawing on cognitive science, it creates a presentation-oriented narrative and\nallows iterative refinement via an interactive editor, in order to match\nlearners' knowledge level and goals. Auto-Slides further incorporates\nverification and knowledge retrieval mechanisms to ensure accuracy and\ncontextual completeness. Through extensive user studies, Auto-Slides enhances\nlearners' comprehension and engagement compared to conventional LLM-based\nreading. Our contributions lie in designing a multi-agent framework for\ntransforming academic papers into pedagogically optimized slides and\nintroducing interactive customization for personalized learning.", "published": "2025-09-14 03:05:54", "link": "http://arxiv.org/abs/2509.11062v2", "categories": ["cs.HC", "cs.MA"], "primary_category": "cs.HC"}
{"title": "A Kernel-based Stochastic Approximation Framework for Nonlinear Operator Learning", "abstract": "We develop a stochastic approximation framework for learning nonlinear\noperators between infinite-dimensional spaces utilizing general Mercer\noperator-valued kernels. Our framework encompasses two key classes: (i) compact\nkernels, which admit discrete spectral decompositions, and (ii) diagonal\nkernels of the form $K(x,x')=k(x,x')T$, where $k$ is a scalar-valued kernel and\n$T$ is a positive operator on the output space. This broad setting induces\nexpressive vector-valued reproducing kernel Hilbert spaces (RKHSs) that\ngeneralize the classical $K=kI$ paradigm, thereby enabling rich structural\nmodeling with rigorous theoretical guarantees. To address target operators\nlying outside the RKHS, we introduce vector-valued interpolation spaces to\nprecisely quantify misspecification error. Within this framework, we establish\ndimension-free polynomial convergence rates, demonstrating that nonlinear\noperator learning can overcome the curse of dimensionality. The use of general\noperator-valued kernels further allows us to derive rates for intrinsically\nnonlinear operator learning, going beyond the linear-type behavior inherent in\ndiagonal constructions of $K=kI$. Importantly, this framework accommodates a\nwide range of operator learning tasks, ranging from integral operators such as\nFredholm operators to architectures based on encoder-decoder representations.\nMoreover, we validate its effectiveness through numerical experiments on the\ntwo-dimensional Navier-Stokes equations.", "published": "2025-09-14 03:33:36", "link": "http://arxiv.org/abs/2509.11070v2", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.FA", "math.NA", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering", "abstract": "With the rapid progress of large audio-language models (LALMs), audio\nquestion answering (AQA) has emerged as a challenging task requiring both\nfine-grained audio understanding and complex reasoning. While current methods\nmainly rely on constructing new datasets via captioning or reasoning traces,\nexisting high-quality AQA data remains underutilized. To address this, we\npropose Omni-CLST, an error-aware Curriculum Learning framework with guided\nSelective Chain-of-Thought. The framework efficiently leverages existing\nhigh-quality dataset through two key strategies: an error-aware curriculum that\norganizes samples by difficulty, and a guided thought dropout mechanism that\nfocuses reasoning on challenging cases. Experiments show that Omni-CLST\nachieves 73.80% on MMAU-mini and a new state of the art of 64.30% on MMAR,\ndemonstrating robust generalization in multimodal audio-language understanding.", "published": "2025-09-14 06:54:12", "link": "http://arxiv.org/abs/2509.12275v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering", "abstract": "With the rapid progress of large audio-language models (LALMs), audio\nquestion answering (AQA) has emerged as a challenging task requiring both\nfine-grained audio understanding and complex reasoning. While current methods\nmainly rely on constructing new datasets via captioning or reasoning traces,\nexisting high-quality AQA data remains underutilized. To address this, we\npropose Omni-CLST, an error-aware Curriculum Learning framework with guided\nSelective Chain-of-Thought. The framework efficiently leverages existing\nhigh-quality dataset through two key strategies: an error-aware curriculum that\norganizes samples by difficulty, and a guided thought dropout mechanism that\nfocuses reasoning on challenging cases. Experiments show that Omni-CLST\nachieves 73.80% on MMAU-mini and a new state of the art of 64.30% on MMAR,\ndemonstrating robust generalization in multimodal audio-language understanding.", "published": "2025-09-14 06:54:12", "link": "http://arxiv.org/abs/2509.12275v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
