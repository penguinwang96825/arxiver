{"title": "BERT Rediscovers the Classical NLP Pipeline", "abstract": "Pre-trained text encoders have rapidly advanced the state of the art on many\nNLP tasks. We focus on one such model, BERT, and aim to quantify where\nlinguistic information is captured within the network. We find that the model\nrepresents the steps of the traditional NLP pipeline in an interpretable and\nlocalizable way, and that the regions responsible for each step appear in the\nexpected sequence: POS tagging, parsing, NER, semantic roles, then coreference.\nQualitative analysis reveals that the model can and often does adjust this\npipeline dynamically, revising lower-level decisions on the basis of\ndisambiguating information from higher-level representations.", "published": "2019-05-15 05:47:23", "link": "http://arxiv.org/abs/1905.05950v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When a Good Translation is Wrong in Context: Context-Aware Machine\n  Translation Improves on Deixis, Ellipsis, and Lexical Cohesion", "abstract": "Though machine translation errors caused by the lack of context beyond one\nsentence have long been acknowledged, the development of context-aware NMT\nsystems is hampered by several problems. Firstly, standard metrics are not\nsensitive to improvements in consistency in document-level translations.\nSecondly, previous work on context-aware NMT assumed that the sentence-aligned\nparallel data consisted of complete documents while in most practical scenarios\nsuch document-level data constitutes only a fraction of the available parallel\ndata. To address the first issue, we perform a human study on an\nEnglish-Russian subtitles dataset and identify deixis, ellipsis and lexical\ncohesion as three main sources of inconsistency. We then create test sets\ntargeting these phenomena. To address the second shortcoming, we consider a\nset-up in which a much larger amount of sentence-level data is available\ncompared to that aligned at the document level. We introduce a model that is\nsuitable for this scenario and demonstrate major gains over a context-agnostic\nbaseline on our new benchmarks without sacrificing performance as measured with\nBLEU.", "published": "2019-05-15 07:05:46", "link": "http://arxiv.org/abs/1905.05979v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dual Supervised Learning for Natural Language Understanding and\n  Generation", "abstract": "Natural language understanding (NLU) and natural language generation (NLG)\nare both critical research topics in the NLP field. Natural language\nunderstanding is to extract the core semantic meaning from the given\nutterances, while natural language generation is opposite, of which the goal is\nto construct corresponding sentences based on the given semantics. However,\nsuch dual relationship has not been investigated in the literature. This paper\nproposes a new learning framework for language understanding and generation on\ntop of dual supervised learning, providing a way to exploit the duality. The\npreliminary experiments show that the proposed approach boosts the performance\nfor both tasks.", "published": "2019-05-15 14:04:47", "link": "http://arxiv.org/abs/1905.06196v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representing Schema Structure with Graph Neural Networks for Text-to-SQL\n  Parsing", "abstract": "Research on parsing language to SQL has largely ignored the structure of the\ndatabase (DB) schema, either because the DB was very simple, or because it was\nobserved at both training and test time. In Spider, a recently-released\ntext-to-SQL dataset, new and complex DBs are given at test time, and so the\nstructure of the DB schema can inform the predicted SQL query. In this paper,\nwe present an encoder-decoder semantic parser, where the structure of the DB\nschema is encoded with a graph neural network, and this representation is later\nused at both encoding and decoding time. Evaluation shows that encoding the\nschema structure improves our parser accuracy from 33.8% to 39.4%, dramatically\nabove the current state of the art, which is at 19.7%.", "published": "2019-05-15 15:22:01", "link": "http://arxiv.org/abs/1905.06241v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Surprisingly Robust Trick for Winograd Schema Challenge", "abstract": "The Winograd Schema Challenge (WSC) dataset WSC273 and its inference\ncounterpart WNLI are popular benchmarks for natural language understanding and\ncommonsense reasoning. In this paper, we show that the performance of three\nlanguage models on WSC273 strongly improves when fine-tuned on a similar\npronoun disambiguation problem dataset (denoted WSCR). We additionally generate\na large unsupervised WSC-like dataset. By fine-tuning the BERT language model\nboth on the introduced and on the WSCR dataset, we achieve overall accuracies\nof 72.5% and 74.7% on WSC273 and WNLI, improving the previous state-of-the-art\nsolutions by 8.8% and 9.6%, respectively. Furthermore, our fine-tuned models\nare also consistently more robust on the \"complex\" subsets of WSC273,\nintroduced by Trichelair et al. (2018).", "published": "2019-05-15 16:47:11", "link": "http://arxiv.org/abs/1905.06290v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What do you learn from context? Probing for sentence structure in\n  contextualized word representations", "abstract": "Contextualized representation models such as ELMo (Peters et al., 2018a) and\nBERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a\ndiverse array of downstream NLP tasks. Building on recent token-level probing\nwork, we introduce a novel edge probing task design and construct a broad suite\nof sub-sentence tasks derived from the traditional structured NLP pipeline. We\nprobe word-level contextual representations from four recent models and\ninvestigate how they encode sentence structure across a range of syntactic,\nsemantic, local, and long-range phenomena. We find that existing models trained\non language modeling and translation produce strong representations for\nsyntactic phenomena, but only offer comparably small improvements on semantic\ntasks over a non-contextual baseline.", "published": "2019-05-15 17:48:56", "link": "http://arxiv.org/abs/1905.06316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exact Hard Monotonic Attention for Character-Level Transduction", "abstract": "Many common character-level, string-to string transduction tasks, e.g.,\ngrapheme-tophoneme conversion and morphological inflection, consist almost\nexclusively of monotonic transductions. However, neural sequence-to sequence\nmodels that use non-monotonic soft attention often outperform popular monotonic\nmodels. In this work, we ask the following question: Is monotonicity really a\nhelpful inductive bias for these tasks? We develop a hard attention\nsequence-to-sequence model that enforces strict monotonicity and learns a\nlatent alignment jointly while learning to transduce. With the help of dynamic\nprogramming, we are able to compute the exact marginalization over all\nmonotonic alignments. Our models achieve state-of-the-art performance on\nmorphological inflection. Furthermore, we find strong performance on two other\ncharacter-level transduction tasks. Code is available at\nhttps://github.com/shijie-wu/neural-transducer.", "published": "2019-05-15 17:51:09", "link": "http://arxiv.org/abs/1905.06319v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Interlingua Neural Machine Translation", "abstract": "Common intermediate language representation in neural machine translation can\nbe used to extend bilingual to multilingual systems by incremental training. In\nthis paper, we propose a new architecture based on introducing an interlingual\nloss as an additional training objective. By adding and forcing this\ninterlingual loss, we are able to train multiple encoders and decoders for each\nlanguage, sharing a common intermediate representation. Translation results on\nthe low-resourced tasks (Turkish-English and Kazakh-English tasks, from the\npopular Workshop on Machine Translation benchmark) show the following BLEU\nimprovements up to 2.8. However, results on a larger dataset (Russian-English\nand Kazakh-English, from the same baselines) show BLEU loses if the same\namount. While our system is only providing improvements for the low-resourced\ntasks in terms of translation quality, our system is capable of quickly\ndeploying new language pairs without retraining the rest of the system, which\nmay be a game-changer in some situations (i.e. in a disaster crisis where\ninternational help is required towards a small region or to develop some\ntranslation system for a client). Precisely, what is most relevant from our\narchitecture is that it is capable of: (1) reducing the number of production\nsystems, with respect to the number of languages, from quadratic to linear (2)\nincrementally adding a new language in the system without retraining languages\npreviously there and (3) allowing for translations from the new language to all\nthe others present in the system", "published": "2019-05-15 13:52:53", "link": "http://arxiv.org/abs/1905.06831v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Passage Ranking with Weak Supervision", "abstract": "In this paper, we propose a \\textit{weak supervision} framework for neural\nranking tasks based on the data programming paradigm \\citep{Ratner2016}, which\nenables us to leverage multiple weak supervision signals from different\nsources. Empirically, we consider two sources of weak supervision signals,\nunsupervised ranking functions and semantic feature similarities. We train a\nBERT-based passage-ranking model (which achieves new state-of-the-art\nperformances on two benchmark datasets with full supervision) in our weak\nsupervision framework. Without using ground-truth training labels, BERT-PR\nmodels outperform BM25 baseline by a large margin on all three datasets and\neven beat the previous state-of-the-art results with full supervision on two of\nthe datasets.", "published": "2019-05-15 01:47:57", "link": "http://arxiv.org/abs/1905.05910v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image\n  Representations", "abstract": "In vision-and-language grounding problems, fine-grained representations of\nthe image are considered to be of paramount importance. Most of the current\nsystems incorporate visual features and textual concepts as a sketch of an\nimage. However, plainly inferred representations are usually undesirable in\nthat they are composed of separate components, the relations of which are\nelusive. In this work, we aim at representing an image with a set of integrated\nvisual regions and corresponding textual concepts, reflecting certain\nsemantics. To this end, we build the Mutual Iterative Attention (MIA) module,\nwhich integrates correlated visual features and textual concepts, respectively,\nby aligning the two modalities. We evaluate the proposed approach on two\nrepresentative vision-and-language grounding tasks, i.e., image captioning and\nvisual question answering. In both tasks, the semantic-grounded image\nrepresentations consistently boost the performance of the baseline models under\nall metrics across the board. The results demonstrate that our approach is\neffective and generalizes well to a wide range of models for image-related\napplications. (The code is available at https://github.com/fenglinliu98/MIA)", "published": "2019-05-15 12:39:49", "link": "http://arxiv.org/abs/1905.06139v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Selection Bias Explorations and Debias Methods for Natural Language\n  Sentence Matching Datasets", "abstract": "Natural Language Sentence Matching (NLSM) has gained substantial attention\nfrom both academics and the industry, and rich public datasets contribute a lot\nto this process. However, biased datasets can also hurt the generalization\nperformance of trained models and give untrustworthy evaluation results. For\nmany NLSM datasets, the providers select some pairs of sentences into the\ndatasets, and this sampling procedure can easily bring unintended pattern,\ni.e., selection bias. One example is the QuoraQP dataset, where some\ncontent-independent naive features are unreasonably predictive. Such features\nare the reflection of the selection bias and termed as the leakage features. In\nthis paper, we investigate the problem of selection bias on six NLSM datasets\nand find that four out of them are significantly biased. We further propose a\ntraining and evaluation framework to alleviate the bias. Experimental results\non QuoraQP suggest that the proposed framework can improve the generalization\nability of trained models, and give more trustworthy evaluation results for\nreal-world adoptions.", "published": "2019-05-15 14:51:33", "link": "http://arxiv.org/abs/1905.06221v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Controlled CNN-based Sequence Labeling for Aspect Extraction", "abstract": "One key task of fine-grained sentiment analysis on reviews is to extract\naspects or features that users have expressed opinions on. This paper focuses\non supervised aspect extraction using a modified CNN called controlled CNN\n(Ctrl). The modified CNN has two types of control modules. Through asynchronous\nparameter updating, it prevents over-fitting and boosts CNN's performance\nsignificantly. This model achieves state-of-the-art results on standard aspect\nextraction datasets. To the best of our knowledge, this is the first paper to\napply control modules to aspect extraction.", "published": "2019-05-15 19:28:10", "link": "http://arxiv.org/abs/1905.06407v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extractive Summarization via Weighted Dissimilarity and Importance\n  Aligned Key Iterative Algorithm", "abstract": "We present importance aligned key iterative algorithm for extractive\nsummarization that is faster than conventional algorithms keeping its accuracy.\nThe computational complexity of our algorithm is O($SNlogN$) to summarize\noriginal $N$ sentences into final $S$ sentences. Our algorithm maximizes the\nweighted dissimilarity defined by the product of importance and cosine\ndissimilarity so that the summary represents the document and at the same time\nthe sentences of the summary are not similar to each other. The weighted\ndissimilarity is heuristically maximized by iterative greedy search and binary\nsearch to the sentences ordered by importance. We finally show a benchmark\nscore based on summarization of customer reviews of products, which highlights\nthe quality of our algorithm comparable to human and existing algorithms. We\nprovide the source code of our algorithm on github\nhttps://github.com/qhapaq-49/imakita .", "published": "2019-05-15 12:42:42", "link": "http://arxiv.org/abs/1906.02126v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Demographic Inference and Representative Population Estimates from\n  Multilingual Social Media Data", "abstract": "Social media provide access to behavioural data at an unprecedented scale and\ngranularity. However, using these data to understand phenomena in a broader\npopulation is difficult due to their non-representativeness and the bias of\nstatistical inference tools towards dominant languages and groups. While\ndemographic attribute inference could be used to mitigate such bias, current\ntechniques are almost entirely monolingual and fail to work in a global\nenvironment. We address these challenges by combining multilingual demographic\ninference with post-stratification to create a more representative population\nsample. To learn demographic attributes, we create a new multimodal deep neural\narchitecture for joint classification of age, gender, and organization-status\nof social media users that operates in 32 languages. This method substantially\noutperforms current state of the art while also reducing algorithmic bias. To\ncorrect for sampling biases, we propose fully interpretable multilevel\nregression methods that estimate inclusion probabilities from inferred joint\npopulation counts and ground-truth population counts. In a large experiment\nover multilingual heterogeneous European regions, we show that our demographic\ninference and bias correction together allow for more accurate estimates of\npopulations and make a significant step towards representative social sensing\nin downstream applications with multilingual social media.", "published": "2019-05-15 06:15:16", "link": "http://arxiv.org/abs/1905.05961v1", "categories": ["cs.CY", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CY"}
{"title": "TSXplain: Demystification of DNN Decisions for Time-Series using Natural\n  Language and Statistical Features", "abstract": "Neural networks (NN) are considered as black-boxes due to the lack of\nexplainability and transparency of their decisions. This significantly hampers\ntheir deployment in environments where explainability is essential along with\nthe accuracy of the system. Recently, significant efforts have been made for\nthe interpretability of these deep networks with the aim to open up the\nblack-box. However, most of these approaches are specifically developed for\nvisual modalities. In addition, the interpretations provided by these systems\nrequire expert knowledge and understanding for intelligibility. This indicates\na vital gap between the explainability provided by the systems and the novice\nuser. To bridge this gap, we present a novel framework i.e. Time-Series\neXplanation (TSXplain) system which produces a natural language based\nexplanation of the decision taken by a NN. It uses the extracted statistical\nfeatures to describe the decision of a NN, merging the deep learning world with\nthat of statistics. The two-level explanation provides ample description of the\ndecision made by the network to aid an expert as well as a novice user alike.\nOur survey and reliability assessment test confirm that the generated\nexplanations are meaningful and correct. We believe that generating natural\nlanguage based descriptions of the network's decisions is a big step towards\nopening up the black-box.", "published": "2019-05-15 13:37:58", "link": "http://arxiv.org/abs/1905.06175v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Comparing Programming Paradigms", "abstract": "Rapid technological progress in computer sciences finds solutions and at the\nsame time creates ever more complex requirements. Due to an evolving complexity\ntodays programming languages provide powerful frameworks which offer standard\nsolutions for recurring tasks to assist the programmer and to avoid the\nre-invention of the wheel with so-called out-of-the-box-features. In this\npaper, we propose a way of comparing different programming paradigms on a\ntheoretical, technical and practical level. Furthermore, the paper presents the\nresults of an initial comparison of two representative programming approaches,\nboth in the closed SAP environment.", "published": "2019-05-15 09:55:10", "link": "http://arxiv.org/abs/1905.06777v1", "categories": ["cs.HC", "cs.CL", "cs.PL", "cs.SE"], "primary_category": "cs.HC"}
{"title": "Learning Open Information Extraction of Implicit Relations from Reading\n  Comprehension Datasets", "abstract": "The relationship between two entities in a sentence is often implied by word\norder and common sense, rather than an explicit predicate. For example, it is\nevident that \"Fed chair Powell indicates rate hike\" implies (Powell, is a, Fed\nchair) and (Powell, works for, Fed). These tuples are just as significant as\nthe explicit-predicate tuple (Powell, indicates, rate hike), but have much\nlower recall under traditional Open Information Extraction (OpenIE) systems.\nImplicit tuples are our term for this type of extraction where the relation is\nnot present in the input sentence. There is very little OpenIE training data\navailable relative to other NLP tasks and none focused on implicit relations.\nWe develop an open source, parse-based tool for converting large reading\ncomprehension datasets to OpenIE datasets and release a dataset 35x larger than\npreviously available by sentence count. A baseline neural model trained on this\ndata outperforms previous methods on the implicit extraction task.", "published": "2019-05-15 19:02:35", "link": "http://arxiv.org/abs/1905.07471v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Understanding the Radical Mind: Identifying Signals to Detect Extremist\n  Content on Twitter", "abstract": "The Internet and, in particular, Online Social Networks have changed the way\nthat terrorist and extremist groups can influence and radicalise individuals.\nRecent reports show that the mode of operation of these groups starts by\nexposing a wide audience to extremist material online, before migrating them to\nless open online platforms for further radicalization. Thus, identifying\nradical content online is crucial to limit the reach and spread of the\nextremist narrative. In this paper, our aim is to identify measures to\nautomatically detect radical content in social media. We identify several\nsignals, including textual, psychological and behavioural, that together allow\nfor the classification of radical messages. Our contribution is three-fold: (1)\nwe analyze propaganda material published by extremist groups and create a\ncontextual text-based model of radical content, (2) we build a model of\npsychological properties inferred from these material, and (3) we evaluate\nthese models on Twitter to determine the extent to which it is possible to\nautomatically identify online radical tweets. Our results show that radical\nusers do exhibit distinguishable textual, psychological, and behavioural\nproperties. We find that the psychological properties are among the most\ndistinguishing features. Additionally, our results show that textual models\nusing vector embedding features significantly improves the detection over\nTF-IDF features. We validate our approach on two experiments achieving high\naccuracy. Our findings can be utilized as signals for detecting online\nradicalization activities.", "published": "2019-05-15 17:14:34", "link": "http://arxiv.org/abs/1905.08067v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.LG", "stat.ML"], "primary_category": "cs.SI"}
{"title": "A general-purpose deep learning approach to model time-varying audio\n  effects", "abstract": "Audio processors whose parameters are modified periodically over time are\noften referred as time-varying or modulation based audio effects. Most existing\nmethods for modeling these type of effect units are often optimized to a very\nspecific circuit and cannot be efficiently generalized to other time-varying\neffects. Based on convolutional and recurrent neural networks, we propose a\ndeep learning architecture for generic black-box modeling of audio processors\nwith long-term memory. We explore the capabilities of deep neural networks to\nlearn such long temporal dependencies and we show the network modeling various\nlinear and nonlinear, time-varying and time-invariant audio effects. In order\nto measure the performance of the model, we propose an objective metric based\non the psychoacoustics of modulation frequency perception. We also analyze what\nthe model is actually learning and how the given task is accomplished.", "published": "2019-05-15 12:57:57", "link": "http://arxiv.org/abs/1905.06148v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "End-to-End Multi-Channel Speech Separation", "abstract": "The end-to-end approach for single-channel speech separation has been studied\nrecently and shown promising results. This paper extended the previous approach\nand proposed a new end-to-end model for multi-channel speech separation. The\nprimary contributions of this work include 1) an integrated waveform-in\nwaveform-out separation system in a single neural network architecture. 2) We\nreformulate the traditional short time Fourier transform (STFT) and\ninter-channel phase difference (IPD) as a function of time-domain convolution\nwith a special kernel. 3) We further relaxed those fixed kernels to be\nlearnable, so that the entire architecture becomes purely data-driven and can\nbe trained from end-to-end. We demonstrate on the WSJ0 far-field speech\nseparation task that, with the benefit of learnable spatial features, our\nproposed end-to-end multi-channel model significantly improved the performance\nof previous end-to-end single-channel method and traditional multi-channel\nmethods.", "published": "2019-05-15 16:38:16", "link": "http://arxiv.org/abs/1905.06286v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker-Independent Speech-Driven Visual Speech Synthesis using\n  Domain-Adapted Acoustic Models", "abstract": "Speech-driven visual speech synthesis involves mapping features extracted\nfrom acoustic speech to the corresponding lip animation controls for a face\nmodel. This mapping can take many forms, but a powerful approach is to use deep\nneural networks (DNNs). However, a limitation is the lack of synchronized\naudio, video, and depth data required to reliably train the DNNs, especially\nfor speaker-independent models. In this paper, we investigate adapting an\nautomatic speech recognition (ASR) acoustic model (AM) for the visual speech\nsynthesis problem. We train the AM on ten thousand hours of audio-only data.\nThe AM is then adapted to the visual speech synthesis domain using ninety hours\nof synchronized audio-visual speech. Using a subjective assessment test, we\ncompared the performance of the AM-initialized DNN to one with a random\ninitialization. The results show that viewers significantly prefer animations\ngenerated from the AM-initialized DNN than the ones generated using the\nrandomly initialized model. We conclude that visual speech synthesis can\nsignificantly benefit from the powerful representation of speech in the ASR\nacoustic models.", "published": "2019-05-15 00:23:58", "link": "http://arxiv.org/abs/1905.06860v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML", "I.2.m; I.3.8"], "primary_category": "eess.AS"}
