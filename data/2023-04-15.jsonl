{"title": "Neural Approaches to Entity-Centric Information Extraction", "abstract": "Artificial Intelligence (AI) has huge impact on our daily lives with\napplications such as voice assistants, facial recognition, chatbots,\nautonomously driving cars, etc. Natural Language Processing (NLP) is a\ncross-discipline of AI and Linguistics, dedicated to study the understanding of\nthe text. This is a very challenging area due to unstructured nature of the\nlanguage, with many ambiguous and corner cases. In this thesis we address a\nvery specific area of NLP that involves the understanding of entities (e.g.,\nnames of people, organizations, locations) in text. First, we introduce a\nradically different, entity-centric view of the information in text. We argue\nthat instead of using individual mentions in text to understand their meaning,\nwe should build applications that would work in terms of entity concepts. Next,\nwe present a more detailed model on how the entity-centric approach can be used\nfor the entity linking task. In our work, we show that this task can be\nimproved by considering performing entity linking at the coreference cluster\nlevel rather than each of the mentions individually. In our next work, we\nfurther study how information from Knowledge Base entities can be integrated\ninto text. Finally, we analyze the evolution of the entities from the evolving\ntemporal perspective.", "published": "2023-04-15 20:07:37", "link": "http://arxiv.org/abs/2304.07625v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Medical Question Summarization with Entity-driven Contrastive Learning", "abstract": "By summarizing longer consumer health questions into shorter and essential\nones, medical question answering (MQA) systems can more accurately understand\nconsumer intentions and retrieve suitable answers. However, medical question\nsummarization is very challenging due to obvious distinctions in health trouble\ndescriptions from patients and doctors. Although existing works have attempted\nto utilize Seq2Seq, reinforcement learning, or contrastive learning to solve\nthe problem, two challenges remain: how to correctly capture question focus to\nmodel its semantic intention, and how to obtain reliable datasets to fairly\nevaluate performance. To address these challenges, this paper proposes a novel\nmedical question summarization framework using entity-driven contrastive\nlearning (ECL). ECL employs medical entities in frequently asked questions\n(FAQs) as focuses and devises an effective mechanism to generate hard negative\nsamples. This approach forces models to pay attention to the crucial focus\ninformation and generate more ideal question summarization. Additionally, we\nfind that some MQA datasets suffer from serious data leakage problems, such as\nthe iCliniq dataset's 33% duplicate rate. To evaluate the related methods\nfairly, this paper carefully checks leaked samples to reorganize more\nreasonable datasets. Extensive experiments demonstrate that our ECL method\noutperforms state-of-the-art methods by accurately capturing question focus and\ngenerating medical question summaries. The code and datasets are available at\nhttps://github.com/yrbobo/MQS-ECL.", "published": "2023-04-15 00:19:03", "link": "http://arxiv.org/abs/2304.07437v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tractable Control for Autoregressive Language Generation", "abstract": "Despite the success of autoregressive large language models in text\ngeneration, it remains a major challenge to generate text that satisfies\ncomplex constraints: sampling from the conditional distribution\n${\\Pr}(\\text{text} | \\alpha)$ is intractable for even the simplest lexical\nconstraints $\\alpha$. To overcome this challenge, we propose to use tractable\nprobabilistic models (TPMs) to impose lexical constraints in autoregressive\ntext generation models, which we refer to as GeLaTo (Generating Language with\nTractable Constraints). To demonstrate the effectiveness of this framework, we\nuse distilled hidden Markov models, where we can efficiently compute\n${\\Pr}(\\text{text} | \\alpha)$, to guide autoregressive generation from GPT2.\nGeLaTo achieves state-of-the-art performance on challenging benchmarks for\nconstrained text generation (e.g., CommonGen), beating various strong baselines\nby a large margin. Our work not only opens up new avenues for controlling large\nlanguage models but also motivates the development of more expressive TPMs.", "published": "2023-04-15 00:19:44", "link": "http://arxiv.org/abs/2304.07438v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A CTC Alignment-based Non-autoregressive Transformer for End-to-end\n  Automatic Speech Recognition", "abstract": "Recently, end-to-end models have been widely used in automatic speech\nrecognition (ASR) systems. Two of the most representative approaches are\nconnectionist temporal classification (CTC) and attention-based encoder-decoder\n(AED) models. Autoregressive transformers, variants of AED, adopt an\nautoregressive mechanism for token generation and thus are relatively slow\nduring inference. In this paper, we present a comprehensive study of a CTC\nAlignment-based Single-Step Non-Autoregressive Transformer (CASS-NAT) for\nend-to-end ASR. In CASS-NAT, word embeddings in the autoregressive transformer\n(AT) are substituted with token-level acoustic embeddings (TAE) that are\nextracted from encoder outputs with the acoustical boundary information offered\nby the CTC alignment. TAE can be obtained in parallel, resulting in a parallel\ngeneration of output tokens. During training, Viterbi-alignment is used for TAE\ngeneration, and multiple training strategies are further explored to improve\nthe word error rate (WER) performance. During inference, an error-based\nalignment sampling method is investigated in depth to reduce the alignment\nmismatch in the training and testing processes. Experimental results show that\nthe CASS-NAT has a WER that is close to AT on various ASR tasks, while\nproviding a ~24x inference speedup. With and without self-supervised learning,\nwe achieve new state-of-the-art results for non-autoregressive models on\nseveral datasets. We also analyze the behavior of the CASS-NAT decoder to\nexplain why it can perform similarly to AT. We find that TAEs have similar\nfunctionality to word embeddings for grammatical structures, which might\nindicate the possibility of learning some semantic information from TAEs\nwithout a language model.", "published": "2023-04-15 18:34:29", "link": "http://arxiv.org/abs/2304.07611v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and\n  Large Language Models", "abstract": "We document the capability of large language models (LLMs) like ChatGPT to\npredict stock price movements using news headlines, even without direct\nfinancial training. ChatGPT scores significantly predict out-of-sample daily\nstock returns, subsuming traditional methods, and predictability is stronger\namong smaller stocks and following negative news. To explain these findings, we\ndevelop a theoretical model incorporating information capacity constraints,\nunderreaction, limits-to-arbitrage, and LLMs. The model generates several key\npredictions, which we empirically test: (i) it establishes a critical threshold\nin AI capabilities necessary for profitable predictions, (ii) it demonstrates\nthat only advanced LLMs can effectively interpret complex information, and\n(iii) it predicts that widespread LLM adoption can enhance market efficiency.\nOur results suggest that sophisticated return forecasting is an emerging\ncapability of AI systems and that these technologies can alter information\ndiffusion and decision-making processes in financial markets. Finally, we\nintroduce an interpretability framework to evaluate LLMs' reasoning,\ncontributing to AI transparency and economic decision-making.", "published": "2023-04-15 19:22:37", "link": "http://arxiv.org/abs/2304.07619v5", "categories": ["q-fin.ST", "cs.CL"], "primary_category": "q-fin.ST"}
{"title": "Interpretable Detection of Out-of-Context Misinformation with\n  Neural-Symbolic-Enhanced Large Multimodal Model", "abstract": "Recent years have witnessed the sustained evolution of misinformation that\naims at manipulating public opinions. Unlike traditional rumors or fake news\neditors who mainly rely on generated and/or counterfeited images, text and\nvideos, current misinformation creators now more tend to use out-of-context\nmultimedia contents (e.g. mismatched images and captions) to deceive the public\nand fake news detection systems. This new type of misinformation increases the\ndifficulty of not only detection but also clarification, because every\nindividual modality is close enough to true information. To address this\nchallenge, in this paper we explore how to achieve interpretable cross-modal\nde-contextualization detection that simultaneously identifies the mismatched\npairs and the cross-modal contradictions, which is helpful for fact-check\nwebsites to document clarifications. The proposed model first symbolically\ndisassembles the text-modality information to a set of fact queries based on\nthe Abstract Meaning Representation of the caption and then forwards the\nquery-image pairs into a pre-trained large vision-language model select the\n``evidences\" that are helpful for us to detect misinformation. Extensive\nexperiments indicate that the proposed methodology can provide us with much\nmore interpretable predictions while maintaining the accuracy same as the\nstate-of-the-art model on this task.", "published": "2023-04-15 21:11:55", "link": "http://arxiv.org/abs/2304.07633v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analyzing the Performance of ChatGPT in Cardiology and Vascular\n  Pathologies", "abstract": "The article aims to analyze the performance of ChatGPT, a large language\nmodel developed by OpenAI, in the context of cardiology and vascular\npathologies. The study evaluated the accuracy of ChatGPT in answering\nchallenging multiple-choice questions (QCM) using a dataset of 190 questions\nfrom the Siamois-QCM platform. The goal was to assess ChatGPT potential as a\nvaluable tool in medical education compared to two well-ranked students of\nmedicine. The results showed that ChatGPT outperformed the students, scoring\n175 out of 190 correct answers with a percentage of 92.10\\%, while the two\nstudents achieved scores of 163 and 159 with percentages of 85.78\\% and\n82.63\\%, respectively. These results showcase how ChatGPT has the potential to\nbe highly effective in the fields of cardiology and vascular pathologies by\nproviding accurate answers to relevant questions.", "published": "2023-04-15 20:08:48", "link": "http://arxiv.org/abs/2307.02518v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Robust Educational Dialogue Act Classifiers with Low-Resource and\n  Imbalanced Datasets", "abstract": "Dialogue acts (DAs) can represent conversational actions of tutors or\nstudents that take place during tutoring dialogues. Automating the\nidentification of DAs in tutoring dialogues is significant to the design of\ndialogue-based intelligent tutoring systems. Many prior studies employ machine\nlearning models to classify DAs in tutoring dialogues and invest much effort to\noptimize the classification accuracy by using limited amounts of training data\n(i.e., low-resource data scenario). However, beyond the classification\naccuracy, the robustness of the classifier is also important, which can reflect\nthe capability of the classifier on learning the patterns from different class\ndistributions. We note that many prior studies on classifying educational DAs\nemploy cross entropy (CE) loss to optimize DA classifiers on low-resource data\nwith imbalanced DA distribution. The DA classifiers in these studies tend to\nprioritize accuracy on the majority class at the expense of the minority class\nwhich might not be robust to the data with imbalanced ratios of different DA\nclasses. To optimize the robustness of classifiers on imbalanced class\ndistributions, we propose to optimize the performance of the DA classifier by\nmaximizing the area under the ROC curve (AUC) score (i.e., AUC maximization).\nThrough extensive experiments, our study provides evidence that (i) by\nmaximizing AUC in the training process, the DA classifier achieves significant\nperformance improvement compared to the CE approach under low-resource data,\nand (ii) AUC maximization approaches can improve the robustness of the DA\nclassifier under different class imbalance ratios.", "published": "2023-04-15 08:01:59", "link": "http://arxiv.org/abs/2304.07499v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TransDocs: Optical Character Recognition with word to word translation", "abstract": "While OCR has been used in various applications, its output is not always\naccurate, leading to misfit words. This research work focuses on improving the\noptical character recognition (OCR) with ML techniques with integration of OCR\nwith long short-term memory (LSTM) based sequence to sequence deep learning\nmodels to perform document translation. This work is based on ANKI dataset for\nEnglish to Spanish translation. In this work, I have shown comparative study\nfor pre-trained OCR while using deep learning model using LSTM-based seq2seq\narchitecture with attention for machine translation. End-to-end performance of\nthe model has been expressed in BLEU-4 score. This research paper is aimed at\nresearchers and practitioners interested in OCR and its applications in\ndocument translation.", "published": "2023-04-15 21:40:14", "link": "http://arxiv.org/abs/2304.07637v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Evaluation of Speaker Anonymization on Emotional Speech", "abstract": "Speech data carries a range of personal information, such as the speaker's\nidentity and emotional state. These attributes can be used for malicious\npurposes. With the development of virtual assistants, a new generation of\nprivacy threats has emerged. Current studies have addressed the topic of\npreserving speech privacy. One of them, the VoicePrivacy initiative aims to\npromote the development of privacy preservation tools for speech technology.\nThe task selected for the VoicePrivacy 2020 Challenge (VPC) is about speaker\nanonymization. The goal is to hide the source speaker's identity while\npreserving the linguistic information. The baseline of the VPC makes use of a\nvoice conversion. This paper studies the impact of the speaker anonymization\nbaseline system of the VPC on emotional information present in speech\nutterances. Evaluation is performed following the VPC rules regarding the\nattackers' knowledge about the anonymization system. Our results show that the\nVPC baseline system does not suppress speakers' emotions against informed\nattackers. When comparing anonymized speech to original speech, the emotion\nrecognition performance is degraded by 15\\% relative to IEMOCAP data, similar\nto the degradation observed for automatic speech recognition used to evaluate\nthe preservation of the linguistic information.", "published": "2023-04-15 20:50:29", "link": "http://arxiv.org/abs/2305.01759v1", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Soft Label Coding for End-to-end Sound Source Localization With Ad-hoc\n  Microphone Arrays", "abstract": "Recently, an end-to-end two-dimensional sound source localization algorithm\nwith ad-hoc microphone arrays formulates the sound source localization problem\nas a classification problem. The algorithm divides the target indoor space into\na set of local areas, and predicts the local area where the speaker locates.\nHowever, the local areas are encoded by one-hot code, which may lose the\nconnections between the local areas due to quantization errors. In this paper,\nwe propose a new soft label coding method, named label smoothing, for the\nclassification-based two-dimensional sound source location with ad-hoc\nmicrophone arrays. The core idea is to take the geometric connection between\nthe classes into the label coding process.The first one is named static soft\nlabel coding (SSLC), which modifies the one-hot codes into soft codes based on\nthe distances between the local areas. Because SSLC is handcrafted which may\nnot be optimal, the second one, named dynamic soft label coding (DSLC), further\nrectifies SSLC, by learning the soft codes according to the statistics of the\npredictions produced by the classification-based localization model in the\ntraining stage. Experimental results show that the proposed methods can\neffectively improve the localization accuracy.", "published": "2023-04-15 08:58:36", "link": "http://arxiv.org/abs/2304.07512v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Self-supervised Auxiliary Loss for Metric Learning in Music\n  Similarity-based Retrieval and Auto-tagging", "abstract": "In the realm of music information retrieval, similarity-based retrieval and\nauto-tagging serve as essential components. Given the limitations and\nnon-scalability of human supervision signals, it becomes crucial for models to\nlearn from alternative sources to enhance their performance. Self-supervised\nlearning, which exclusively relies on learning signals derived from music audio\ndata, has demonstrated its efficacy in the context of auto-tagging. In this\nstudy, we propose a model that builds on the self-supervised learning approach\nto address the similarity-based retrieval challenge by introducing our method\nof metric learning with a self-supervised auxiliary loss. Furthermore,\ndiverging from conventional self-supervised learning methodologies, we\ndiscovered the advantages of concurrently training the model with both\nself-supervision and supervision signals, without freezing pre-trained models.\nWe also found that refraining from employing augmentation during the\nfine-tuning phase yields better results. Our experimental results confirm that\nthe proposed methodology enhances retrieval and tagging performance metrics in\ntwo distinct scenarios: one where human-annotated tags are consistently\navailable for all music tracks, and another where such tags are accessible only\nfor a subset of tracks.", "published": "2023-04-15 02:00:28", "link": "http://arxiv.org/abs/2304.07449v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Acoustic Beamforming for Object-relative Distance Estimation and Control\n  in Unmanned Air Vehicles using Propulsion System Noise", "abstract": "Unmanned air vehicles often produce significant noise from their propulsion\nsystems. Using this broadband signal as \"acoustic illumination\" for an\nauxiliary sensing system could make vehicles more robust at a minimal cost. We\npresent an acoustic beamforming-based algorithm that estimates object-relative\ndistance with a small two-microphone array using the generated propulsion\nsystem noise of a vehicle. We demonstrate this approach in several closed-loop\ndistance feedback control tests with a mounted quad-rotor vehicle in a noisy\nenvironment and show accurate object-relative distance estimates more than 2x\nfurther than the baseline channel-based approach. We conclude that this\napproach is robust to several practical vehicle and noise situations and shows\npromise for use in more complex operating environments.", "published": "2023-04-15 17:03:21", "link": "http://arxiv.org/abs/2304.07596v1", "categories": ["cs.RO", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
