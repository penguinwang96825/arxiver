{"title": "Language Models use Lookbacks to Track Beliefs", "abstract": "How do language models (LMs) represent characters' beliefs, especially when\nthose beliefs may differ from reality? This question lies at the heart of\nunderstanding the Theory of Mind (ToM) capabilities of LMs. We analyze\nLlama-3-70B-Instruct's ability to reason about characters' beliefs using causal\nmediation and abstraction. We construct a dataset that consists of simple\nstories where two characters each separately change the state of two objects,\npotentially unaware of each other's actions. Our investigation uncovered a\npervasive algorithmic pattern that we call a lookback mechanism, which enables\nthe LM to recall important information when it becomes necessary. The LM binds\neach character-object-state triple together by co-locating reference\ninformation about them, represented as their Ordering IDs (OIs) in low rank\nsubspaces of the state token's residual stream. When asked about a character's\nbeliefs regarding the state of an object, the binding lookback retrieves the\ncorresponding state OI and then an answer lookback retrieves the state token.\nWhen we introduce text specifying that one character is (not) visible to the\nother, we find that the LM first generates a visibility ID encoding the\nrelation between the observing and the observed character OIs. In a visibility\nlookback, this ID is used to retrieve information about the observed character\nand update the observing character's beliefs. Our work provides insights into\nthe LM's belief tracking mechanisms, taking a step toward reverse-engineering\nToM reasoning in LMs.", "published": "2025-05-20 17:59:45", "link": "http://arxiv.org/abs/2505.14685v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning", "abstract": "Large language models (LLMs) have achieved remarkable progress on\nmathemati-cal tasks through Chain-of-Thought (CoT) reasoning. However, existing\nmathematical CoT datasets often suffer from Thought Leaps due to experts\nomitting intermediate steps, which negatively impacts model learning and\ngeneralization. We propose the CoT Thought Leap Bridge Task, which aims to\nautomatically detect leaps and generate missing intermediate reasoning steps to\nrestore the completeness and coherence of CoT. To facilitate this, we\nconstructed a specialized training dataset called ScaleQM+, based on the\nstructured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought\nleaps. Through comprehensive experiments on mathematical reasoning benchmarks,\nwe demonstrate that models fine-tuned on bridged datasets consistently\noutperform those trained on original datasets, with improvements of up to\n+5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%)\nand provides better starting points for reinforcement learning (+3.1%),\nfunctioning as a plug-and-play module compatible with existing optimization\ntechniques. Furthermore, CoT-Bridge demonstrate improved generalization to\nout-of-domain logical reasoning tasks, confirming that enhancing reasoning\ncompleteness yields broadly applicable benefits.", "published": "2025-05-20 17:59:31", "link": "http://arxiv.org/abs/2505.14684v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training", "abstract": "Mixture-of-Experts (MoE) architectures within Large Reasoning Models (LRMs)\nhave achieved impressive reasoning capabilities by selectively activating\nexperts to facilitate structured cognitive processes. Despite notable advances,\nexisting reasoning models often suffer from cognitive inefficiencies like\noverthinking and underthinking. To address these limitations, we introduce a\nnovel inference-time steering methodology called Reinforcing Cognitive Experts\n(RICE), designed to improve reasoning performance without additional training\nor complex heuristics. Leveraging normalized Pointwise Mutual Information\n(nPMI), we systematically identify specialized experts, termed ''cognitive\nexperts'' that orchestrate meta-level reasoning operations characterized by\ntokens like ''<think>''. Empirical evaluations with leading MoE-based LRMs\n(DeepSeek-R1 and Qwen3-235B) on rigorous quantitative and scientific reasoning\nbenchmarks demonstrate noticeable and consistent improvements in reasoning\naccuracy, cognitive efficiency, and cross-domain generalization. Crucially, our\nlightweight approach substantially outperforms prevalent reasoning-steering\ntechniques, such as prompt design and decoding constraints, while preserving\nthe model's general instruction-following skills. These results highlight\nreinforcing cognitive experts as a promising, practical, and interpretable\ndirection to enhance cognitive efficiency within advanced reasoning models.", "published": "2025-05-20 17:59:16", "link": "http://arxiv.org/abs/2505.14681v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search", "abstract": "Generative AI search is reshaping information retrieval by offering\nend-to-end answers to complex queries, reducing users' reliance on manually\nbrowsing and summarizing multiple web pages. However, while this paradigm\nenhances convenience, it disrupts the feedback-driven improvement loop that has\nhistorically powered the evolution of traditional Web search. Web search can\ncontinuously improve their ranking models by collecting large-scale,\nfine-grained user feedback (e.g., clicks, dwell time) at the document level. In\ncontrast, generative AI search operates through a much longer search pipeline,\nspanning query decomposition, document retrieval, and answer generation, yet\ntypically receives only coarse-grained feedback on the final answer. This\nintroduces a feedback loop disconnect, where user feedback for the final output\ncannot be effectively mapped back to specific system components, making it\ndifficult to improve each intermediate stage and sustain the feedback loop. In\nthis paper, we envision NExT-Search, a next-generation paradigm designed to\nreintroduce fine-grained, process-level feedback into generative AI search.\nNExT-Search integrates two complementary modes: User Debug Mode, which allows\nengaged users to intervene at key stages; and Shadow User Mode, where a\npersonalized user agent simulates user preferences and provides AI-assisted\nfeedback for less interactive users. Furthermore, we envision how these\nfeedback signals can be leveraged through online adaptation, which refines\ncurrent search outputs in real-time, and offline update, which aggregates\ninteraction logs to periodically fine-tune query decomposition, retrieval, and\ngeneration models. By restoring human control over key stages of the generative\nAI search pipeline, we believe NExT-Search offers a promising direction for\nbuilding feedback-rich AI search systems that can evolve continuously alongside\nhuman feedback.", "published": "2025-05-20 17:59:13", "link": "http://arxiv.org/abs/2505.14680v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models", "abstract": "Lifelong learning enables large language models (LLMs) to adapt to evolving\ninformation by continually updating their internal knowledge. An ideal system\nshould support efficient, wide-ranging updates while preserving existing\ncapabilities and ensuring reliable deployment. Model editing stands out as a\npromising solution for this goal, offering a focused and efficient way to\nrevise a model's internal knowledge. Although recent paradigms have made\nnotable progress, they often struggle to meet the demands of practical lifelong\nadaptation at scale. To bridge this gap, we propose ULTRAEDIT-a fundamentally\nnew editing solution that is training-, subject- and memory-free, making it\nparticularly well-suited for ultra-scalable, real-world lifelong model editing.\nULTRAEDIT performs editing through a self-contained process that relies solely\non lightweight linear algebra operations to compute parameter shifts, enabling\nfast and consistent parameter modifications with minimal overhead. To improve\nscalability in lifelong settings, ULTRAEDIT employs a lifelong normalization\nstrategy that continuously updates feature statistics across turns, allowing it\nto adapt to distributional shifts and maintain consistency over time. ULTRAEDIT\nachieves editing speeds over 7x faster than the previous state-of-the-art\nmethod-which was also the fastest known approach-while consuming less than 1/3\nthe VRAM, making it the only method currently capable of editing a 7B LLM on a\n24GB consumer-grade GPU. Furthermore, we construct ULTRAEDITBENCH-the largest\ndataset in the field to date, with over 2M editing pairs-and demonstrate that\nour method supports up to 1M edits while maintaining high accuracy.\nComprehensive experiments on four datasets and six models show that ULTRAEDIT\nconsistently achieves superior performance across diverse model editing\nscenarios. Our code is available at: https://github.com/XiaojieGu/UltraEdit.", "published": "2025-05-20 17:59:04", "link": "http://arxiv.org/abs/2505.14679v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reward Reasoning Model", "abstract": "Reward models play a critical role in guiding large language models toward\noutputs that align with human expectations. However, an open challenge remains\nin effectively utilizing test-time compute to enhance reward model performance.\nIn this work, we introduce Reward Reasoning Models (RRMs), which are\nspecifically designed to execute a deliberate reasoning process before\ngenerating final rewards. Through chain-of-thought reasoning, RRMs leverage\nadditional test-time compute for complex queries where appropriate rewards are\nnot immediately apparent. To develop RRMs, we implement a reinforcement\nlearning framework that fosters self-evolved reward reasoning capabilities\nwithout requiring explicit reasoning traces as training data. Experimental\nresults demonstrate that RRMs achieve superior performance on reward modeling\nbenchmarks across diverse domains. Notably, we show that RRMs can adaptively\nexploit test-time compute to further improve reward accuracy. The pretrained\nreward reasoning models are available at\nhttps://huggingface.co/Reward-Reasoning.", "published": "2025-05-20 17:58:03", "link": "http://arxiv.org/abs/2505.14674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "abstract": "Recent advances in Large Language Models (LLMs) have propelled intelligent\nagents from reactive responses to proactive support. While promising, existing\nproactive agents either rely exclusively on observations from enclosed\nenvironments (e.g., desktop UIs) with direct LLM inference or employ rule-based\nproactive notifications, leading to suboptimal user intent understanding and\nlimited functionality for proactive service. In this paper, we introduce\nContextAgent, the first context-aware proactive agent that incorporates\nextensive sensory contexts to enhance the proactive capabilities of LLM agents.\nContextAgent first extracts multi-dimensional contexts from massive sensory\nperceptions on wearables (e.g., video and audio) to understand user intentions.\nContextAgent then leverages the sensory contexts and the persona contexts from\nhistorical data to predict the necessity for proactive services. When proactive\nassistance is needed, ContextAgent further automatically calls the necessary\ntools to assist users unobtrusively. To evaluate this new task, we curate\nContextAgentBench, the first benchmark for evaluating context-aware proactive\nLLM agents, covering 1,000 samples across nine daily scenarios and twenty\ntools. Experiments on ContextAgentBench show that ContextAgent outperforms\nbaselines by achieving up to 8.5% and 6.0% higher accuracy in proactive\npredictions and tool calling, respectively. We hope our research can inspire\nthe development of more advanced, human-centric, proactive AI assistants.", "published": "2025-05-20 17:55:25", "link": "http://arxiv.org/abs/2505.14668v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "abstract": "Large Reasoning Models (LRMs) have become powerful tools for complex problem\nsolving, but their structured reasoning pathways can lead to unsafe outputs\nwhen exposed to harmful prompts. Existing safety alignment methods reduce\nharmful outputs but can degrade reasoning depth, leading to significant\ntrade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated\njailbreak attacks. To address this, we introduce SAFEPATH, a lightweight\nalignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at\nthe start of their reasoning, in response to harmful prompts, while leaving the\nrest of the reasoning process unsupervised. Empirical results across multiple\nbenchmarks indicate that SAFEPATH effectively reduces harmful outputs while\nmaintaining reasoning performance. Specifically, SAFEPATH reduces harmful\nresponses by up to 90.0% and blocks 83.3% of jailbreak attempts in the\nDeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than\nDirect Refusal and 314.1x less than SafeChain. We further introduce a zero-shot\nvariant that requires no fine-tuning. In addition, we provide a comprehensive\nanalysis of how existing methods in LLMs generalize, or fail, when applied to\nreasoning-centric models, revealing critical gaps and new directions for safer\nAI.", "published": "2025-05-20 17:54:54", "link": "http://arxiv.org/abs/2505.14667v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "EmoGist: Efficient In-Context Learning for Visual Emotion Understanding", "abstract": "In this paper, we introduce EmoGist, a training-free, in-context learning\nmethod for performing visual emotion classification with LVLMs. The key\nintuition of our approach is that context-dependent definition of emotion\nlabels could allow more accurate predictions of emotions, as the ways in which\nemotions manifest within images are highly context dependent and nuanced.\nEmoGist pre-generates multiple explanations of emotion labels, by analyzing the\nclusters of example images belonging to each category. At test time, we\nretrieve a version of explanation based on embedding similarity, and feed it to\na fast VLM for classification. Through our experiments, we show that EmoGist\nallows up to 13 points improvement in micro F1 scores with the multi-label\nMemotion dataset, and up to 8 points in macro F1 in the multi-class FI dataset.", "published": "2025-05-20 17:47:04", "link": "http://arxiv.org/abs/2505.14660v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Beyond Words: Multimodal LLM Knows When to Speak", "abstract": "While large language model (LLM)-based chatbots have demonstrated strong\ncapabilities in generating coherent and contextually relevant responses, they\noften struggle with understanding when to speak, particularly in delivering\nbrief, timely reactions during ongoing conversations. This limitation arises\nlargely from their reliance on text input, lacking the rich contextual cues in\nreal-world human dialogue. In this work, we focus on real-time prediction of\nresponse types, with an emphasis on short, reactive utterances that depend on\nsubtle, multimodal signals across vision, audio, and text. To support this, we\nintroduce a new multimodal dataset constructed from real-world conversational\nvideos, containing temporally aligned visual, auditory, and textual streams.\nThis dataset enables fine-grained modeling of response timing in dyadic\ninteractions. Building on this dataset, we propose MM-When2Speak, a multimodal\nLLM-based model that adaptively integrates visual, auditory, and textual\ncontext to predict when a response should occur, and what type of response is\nappropriate. Experiments show that MM-When2Speak significantly outperforms\nstate-of-the-art unimodal and LLM-based baselines, achieving up to a 4x\nimprovement in response timing accuracy over leading commercial LLMs. These\nresults underscore the importance of multimodal inputs for producing timely,\nnatural, and engaging conversational AI.", "published": "2025-05-20 17:42:34", "link": "http://arxiv.org/abs/2505.14654v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "General-Reasoner: Advancing LLM Reasoning Across All Domains", "abstract": "Reinforcement learning (RL) has recently demonstrated strong potential in\nenhancing the reasoning capabilities of large language models (LLMs).\nParticularly, the \"Zero\" reinforcement learning introduced by Deepseek-R1-Zero,\nenables direct RL training of base LLMs without relying on an intermediate\nsupervised fine-tuning stage. Despite these advancements, current works for LLM\nreasoning mainly focus on mathematical and coding domains, largely due to data\nabundance and the ease of answer verification. This limits the applicability\nand generalization of such models to broader domains, where questions often\nhave diverse answer representations, and data is more scarce. In this paper, we\npropose General-Reasoner, a novel training paradigm designed to enhance LLM\nreasoning capabilities across diverse domains. Our key contributions include:\n(1) constructing a large-scale, high-quality dataset of questions with\nverifiable answers curated by web crawling, covering a wide range of\ndisciplines; and (2) developing a generative model-based answer verifier, which\nreplaces traditional rule-based verification with the capability of\nchain-of-thought and context-awareness. We train a series of models and\nevaluate them on a wide range of datasets covering wide domains like physics,\nchemistry, finance, electronics etc. Our comprehensive evaluation across these\n12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC)\ndemonstrates that General-Reasoner outperforms existing baseline methods,\nachieving robust and generalizable reasoning performance while maintaining\nsuperior effectiveness in mathematical reasoning tasks.", "published": "2025-05-20 17:41:33", "link": "http://arxiv.org/abs/2505.14652v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dual Precision Quantization for Efficient and Accurate Deep Neural Networks Inference", "abstract": "Deep neural networks have achieved state-of-the-art results in a wide range\nof applications, from natural language processing and computer vision to speech\nrecognition. However, as tasks become increasingly complex, model sizes\ncontinue to grow, posing challenges in latency and memory efficiency. To meet\nthese constraints, post-training quantization has emerged as a promising\nsolution. In this paper, we propose a novel hardware-efficient quantization and\ninference scheme that exploits hardware advantages with minimal accuracy\ndegradation. Specifically, we introduce a W4A8 scheme, where weights are\nquantized and stored using 4-bit integer precision, and inference computations\nare performed using 8-bit floating-point arithmetic, demonstrating significant\nspeedups and improved memory utilization compared to 16-bit operations,\napplicable on various modern accelerators. To mitigate accuracy loss, we\ndevelop a novel quantization algorithm, dubbed Dual Precision Quantization\n(DPQ), that leverages the unique structure of our scheme without introducing\nadditional inference overhead. Experimental results demonstrate improved\nperformance (i.e., increased throughput) while maintaining tolerable accuracy\ndegradation relative to the full-precision model.", "published": "2025-05-20 17:26:12", "link": "http://arxiv.org/abs/2505.14638v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas", "abstract": "Detecting AI risks becomes more challenging as stronger models emerge and\nfind novel methods such as Alignment Faking to circumvent these detection\nattempts. Inspired by how risky behaviors in humans (i.e., illegal activities\nthat may hurt others) are sometimes guided by strongly-held values, we believe\nthat identifying values within AI models can be an early warning system for\nAI's risky behaviors. We create LitmusValues, an evaluation pipeline to reveal\nAI models' priorities on a range of AI value classes. Then, we collect\nAIRiskDilemmas, a diverse collection of dilemmas that pit values against one\nanother in scenarios relevant to AI safety risks such as Power Seeking. By\nmeasuring an AI model's value prioritization using its aggregate choices, we\nobtain a self-consistent set of predicted value priorities that uncover\npotential risks. We show that values in LitmusValues (including seemingly\ninnocuous ones like Care) can predict for both seen risky behaviors in\nAIRiskDilemmas and unseen risky behaviors in HarmBench.", "published": "2025-05-20 17:24:09", "link": "http://arxiv.org/abs/2505.14633v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Think Only When You Need with Large Hybrid-Reasoning Models", "abstract": "Recent Large Reasoning Models (LRMs) have shown substantially improved\nreasoning capabilities over traditional Large Language Models (LLMs) by\nincorporating extended thinking processes prior to producing final responses.\nHowever, excessively lengthy thinking introduces substantial overhead in terms\nof token consumption and latency, which is particularly unnecessary for simple\nqueries. In this work, we introduce Large Hybrid-Reasoning Models (LHRMs), the\nfirst kind of model capable of adaptively determining whether to perform\nthinking based on the contextual information of user queries. To achieve this,\nwe propose a two-stage training pipeline comprising Hybrid Fine-Tuning (HFT) as\na cold start, followed by online reinforcement learning with the proposed\nHybrid Group Policy Optimization (HGPO) to implicitly learn to select the\nappropriate thinking mode. Furthermore, we introduce a metric called Hybrid\nAccuracy to quantitatively assess the model's capability for hybrid thinking.\nExtensive experimental results show that LHRMs can adaptively perform hybrid\nthinking on queries of varying difficulty and type. It outperforms existing\nLRMs and LLMs in reasoning and general capabilities while significantly\nimproving efficiency. Together, our work advocates for a reconsideration of the\nappropriate use of extended thinking processes and provides a solid starting\npoint for building hybrid thinking systems.", "published": "2025-05-20 17:23:25", "link": "http://arxiv.org/abs/2505.14631v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models", "abstract": "Recent advances in large language models (LLMs) and the abundance of food\ndata have resulted in studies to improve food understanding using LLMs. Despite\nseveral recommendation systems utilizing LLMs and Knowledge Graphs (KGs), there\nhas been limited research on integrating food related KGs with LLMs. We\nintroduce KERL, a unified system that leverages food KGs and LLMs to provide\npersonalized food recommendations and generates recipes with associated\nmicro-nutritional information. Given a natural language question, KERL extracts\nentities, retrieves subgraphs from the KG, which are then fed into the LLM as\ncontext to select the recipes that satisfy the constraints. Next, our system\ngenerates the cooking steps and nutritional information for each recipe. To\nevaluate our approach, we also develop a benchmark dataset by curating recipe\nrelated questions, combined with constraints and personal preferences. Through\nextensive experiments, we show that our proposed KG-augmented LLM significantly\noutperforms existing approaches, offering a complete and coherent solution for\nfood recommendation, recipe generation, and nutritional analysis. Our code and\nbenchmark datasets are publicly available at\nhttps://github.com/mohbattharani/KERL.", "published": "2025-05-20 17:19:57", "link": "http://arxiv.org/abs/2505.14629v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Debating for Better Reasoning: An Unsupervised Multimodal Approach", "abstract": "As Large Language Models (LLMs) gain expertise across diverse domains and\nmodalities, scalable oversight becomes increasingly challenging, particularly\nwhen their capabilities may surpass human evaluators. Debate has emerged as a\npromising mechanism for enabling such oversight. In this work, we extend the\ndebate paradigm to a multimodal setting, exploring its potential for weaker\nmodels to supervise and enhance the performance of stronger models. We focus on\nvisual question answering (VQA), where two \"sighted\" expert vision-language\nmodels debate an answer, while a \"blind\" (text-only) judge adjudicates based\nsolely on the quality of the arguments. In our framework, the experts defend\nonly answers aligned with their beliefs, thereby obviating the need for\nexplicit role-playing and concentrating the debate on instances of expert\ndisagreement. Experiments on several multimodal tasks demonstrate that the\ndebate framework consistently outperforms individual expert models. Moreover,\njudgments from weaker LLMs can help instill reasoning capabilities in\nvision-language models through finetuning.", "published": "2025-05-20 17:18:17", "link": "http://arxiv.org/abs/2505.14627v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning", "abstract": "Reinforcement Learning (RL) has become a powerful tool for enhancing the\nreasoning abilities of large language models (LLMs) by optimizing their\npolicies with reward signals. Yet, RL's success relies on the reliability of\nrewards, which are provided by verifiers. In this paper, we expose and analyze\na widespread problem--false negatives--where verifiers wrongly reject correct\nmodel outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals\nthat over 38% of model-generated responses suffer from false negatives, where\nthe verifier fails to recognize correct answers. We show, both empirically and\ntheoretically, that these false negatives severely impair RL training by\ndepriving the model of informative gradient signals and slowing convergence. To\nmitigate this, we propose tinyV, a lightweight LLM-based verifier that augments\nexisting rule-based methods, which dynamically identifies potential false\nnegatives and recovers valid responses to produce more accurate reward\nestimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts\npass rates by up to 10% and accelerates convergence relative to the baseline.\nOur findings highlight the critical importance of addressing verifier false\nnegatives and offer a practical approach to improve RL-based fine-tuning of\nLLMs. Our code is available at https://github.com/uw-nsl/TinyV.", "published": "2025-05-20 17:16:44", "link": "http://arxiv.org/abs/2505.14625v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Enhancing Learned Knowledge in LoRA Adapters Through Efficient Contrastive Decoding on Ascend NPUs", "abstract": "Huawei Cloud users leverage LoRA (Low-Rank Adaptation) as an efficient and\nscalable method to fine-tune and customize large language models (LLMs) for\napplication-specific needs. However, tasks that require complex reasoning or\ndeep contextual understanding are often hindered by biases or interference from\nthe base model when using typical decoding methods like greedy or beam search.\nThese biases can lead to generic or task-agnostic responses from the base model\ninstead of leveraging the LoRA-specific adaptations. In this paper, we\nintroduce Contrastive LoRA Decoding (CoLD), a novel decoding framework designed\nto maximize the use of task-specific knowledge in LoRA-adapted models,\nresulting in better downstream performance. CoLD uses contrastive decoding by\nscoring candidate tokens based on the divergence between the probability\ndistributions of a LoRA-adapted expert model and the corresponding base model.\nThis approach prioritizes tokens that better align with the LoRA's learned\nrepresentations, enhancing performance for specialized tasks. While effective,\na naive implementation of CoLD is computationally expensive because each\ndecoding step requires evaluating multiple token candidates across both models.\nTo address this, we developed an optimized kernel for Huawei's Ascend NPU. CoLD\nachieves up to a 5.54% increase in task accuracy while reducing end-to-end\nlatency by 28% compared to greedy decoding. This work provides practical and\nefficient decoding strategies for fine-tuned LLMs in resource-constrained\nenvironments and has broad implications for applied data science in both cloud\nand on-premises settings.", "published": "2025-05-20 17:11:18", "link": "http://arxiv.org/abs/2505.14620v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Linear Control of Test Awareness Reveals Differential Compliance in Reasoning Models", "abstract": "Reasoning-focused large language models (LLMs) sometimes alter their behavior\nwhen they detect that they are being evaluated, an effect analogous to the\nHawthorne phenomenon, which can lead them to optimize for test-passing\nperformance or to comply more readily with harmful prompts if real-world\nconsequences appear absent. We present the first quantitative study of how such\n\"test awareness\" impacts model behavior, particularly its safety alignment. We\nintroduce a white-box probing framework that (i) linearly identifies\nawareness-related activations and (ii) steers models toward or away from test\nawareness while monitoring downstream performance. We apply our method to\ndifferent state-of-the-art open-source reasoning LLMs across both realistic and\nhypothetical tasks. Our results demonstrate that test awareness significantly\nimpact safety alignment, and is different for different models. By providing\nfine-grained control over this latent effect, our work aims to increase trust\nin how we perform safety evaluation.", "published": "2025-05-20 17:03:12", "link": "http://arxiv.org/abs/2505.14617v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas", "abstract": "We introduce SATBench, a benchmark for evaluating the logical reasoning\ncapabilities of large language models (LLMs) through logical puzzles derived\nfrom Boolean satisfiability (SAT) problems. Unlike prior work that focuses on\ninference rule-based reasoning, which often involves deducing conclusions from\na set of premises, our approach leverages the search-based nature of SAT\nproblems, where the objective is to find a solution that fulfills a specified\nset of logical constraints. Each instance in SATBench is generated from a SAT\nformula, then translated into a story context and conditions using LLMs. The\ngeneration process is fully automated and allows for adjustable difficulty by\nvarying the number of clauses. All 2100 puzzles are validated through both\nLLM-assisted and solver-based consistency checks, with human validation on a\nsubset. Experimental results show that even the strongest model, o4-mini,\nachieves only 65.0% accuracy on hard UNSAT problems, close to the random\nbaseline of 50%. SATBench exposes fundamental limitations in the search-based\nlogical reasoning abilities of current LLMs and provides a scalable testbed for\nfuture research in logical reasoning.", "published": "2025-05-20 17:00:22", "link": "http://arxiv.org/abs/2505.14615v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Language Models Optimized to Fool Detectors Still Have a Distinct Style (And How to Change It)", "abstract": "Despite considerable progress in the development of machine-text detectors,\nit has been suggested that the problem is inherently hard, and therefore, that\nstakeholders should proceed under the assumption that machine-generated text\ncannot be reliably detected as such. We examine a recent such claim by Nicks et\nal. (2024) regarding the ease with which language models can be optimized to\ndegrade the performance of machine-text detectors, including detectors not\nspecifically optimized against. We identify a feature space$\\unicode{x2013}$the\nstylistic feature space$\\unicode{x2013}$that is robust to such optimization,\nand show that it may be used to reliably detect samples from language models\noptimized to prevent detection. Furthermore, we show that even when models are\nexplicitly optimized against stylistic detectors, detection performance remains\nsurprisingly unaffected. We then seek to understand if stylistic detectors are\ninherently more robust. To study this question, we explore a new paraphrasing\napproach that simultaneously aims to close the gap between human writing and\nmachine writing in stylistic feature space while avoiding detection using\ntraditional features. We show that when only a single sample is available for\ndetection, this attack is universally effective across all detectors\nconsidered, including those that use writing style. However, as the number of\nsamples available for detection grows, the human and machine distributions\nbecome distinguishable. This observation encourages us to introduce AURA, a\nmetric that estimates the overlap between human and machine-generated\ndistributions by analyzing how detector performance improves as more samples\nbecome available. Overall, our findings underscore previous recommendations to\navoid reliance on machine-text detection.", "published": "2025-05-20 16:55:44", "link": "http://arxiv.org/abs/2505.14608v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "sudoLLM : On Multi-role Alignment of Language Models", "abstract": "User authorization-based access privileges are a key feature in many\nsafety-critical systems, but have thus far been absent from the large language\nmodel (LLM) realm. In this work, drawing inspiration from such access control\nsystems, we introduce sudoLLM, a novel framework that results in multi-role\naligned LLMs, i.e., LLMs that account for, and behave in accordance with, user\naccess rights. sudoLLM injects subtle user-based biases into queries and trains\nan LLM to utilize this bias signal in order to produce sensitive information if\nand only if the user is authorized. We present empirical results demonstrating\nthat this approach shows substantially improved alignment, generalization, and\nresistance to prompt-based jailbreaking attacks. The persistent tension between\nthe language modeling objective and safety alignment, which is often exploited\nto jailbreak LLMs, is somewhat resolved with the aid of the injected bias\nsignal. Our framework is meant as an additional security layer, and complements\nexisting guardrail mechanisms for enhanced end-to-end safety with LLMs.", "published": "2025-05-20 16:54:34", "link": "http://arxiv.org/abs/2505.14607v1", "categories": ["cs.CL", "cs.CR", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Toward Reliable Biomedical Hypothesis Generation: Evaluating Truthfulness and Hallucination in Large Language Models", "abstract": "Large language models (LLMs) have shown significant potential in scientific\ndisciplines such as biomedicine, particularly in hypothesis generation, where\nthey can analyze vast literature, identify patterns, and suggest research\ndirections. However, a key challenge lies in evaluating the truthfulness of\ngenerated hypotheses, as verifying their accuracy often requires substantial\ntime and resources. Additionally, the hallucination problem in LLMs can lead to\nthe generation of hypotheses that appear plausible but are ultimately\nincorrect, undermining their reliability. To facilitate the systematic study of\nthese challenges, we introduce TruthHypo, a benchmark for assessing the\ncapabilities of LLMs in generating truthful biomedical hypotheses, and KnowHD,\na knowledge-based hallucination detector to evaluate how well hypotheses are\ngrounded in existing knowledge. Our results show that LLMs struggle to generate\ntruthful hypotheses. By analyzing hallucinations in reasoning steps, we\ndemonstrate that the groundedness scores provided by KnowHD serve as an\neffective metric for filtering truthful hypotheses from the diverse outputs of\nLLMs. Human evaluations further validate the utility of KnowHD in identifying\ntruthful hypotheses and accelerating scientific discovery. Our data and source\ncode are available at https://github.com/Teddy-XiongGZ/TruthHypo.", "published": "2025-05-20 16:49:40", "link": "http://arxiv.org/abs/2505.14599v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Success is in the Details: Evaluate and Enhance Details Sensitivity of Code LLMs through Counterfactuals", "abstract": "Code Sensitivity refers to the ability of Code LLMs to recognize and respond\nto details changes in problem descriptions. While current code benchmarks and\ninstruction data focus on difficulty and diversity, sensitivity is overlooked.\nWe first introduce the CTF-Code benchmark, constructed using counterfactual\nperturbations, minimizing input changes while maximizing output changes. The\nevaluation shows that many LLMs have a more than 10\\% performance drop compared\nto the original problems. To fully utilize sensitivity, CTF-Instruct, an\nincremental instruction fine-tuning framework, extends on existing data and\nuses a selection mechanism to meet the three dimensions of difficulty,\ndiversity, and sensitivity. Experiments show that LLMs fine-tuned with\nCTF-Instruct data achieve over a 2\\% improvement on CTF-Code, and more than a\n10\\% performance boost on LiveCodeBench, validating the feasibility of\nenhancing LLMs' sensitivity to improve performance.", "published": "2025-05-20 16:48:57", "link": "http://arxiv.org/abs/2505.14597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol", "abstract": "As Model Context Protocol (MCP) introduces an easy-to-use ecosystem for users\nand developers, it also brings underexplored safety risks. Its decentralized\narchitecture, which separates clients and servers, poses unique challenges for\nsystematic safety analysis. This paper proposes a novel framework to enhance\nMCP safety. Guided by the MAESTRO framework, we first analyze the missing\nsafety mechanisms in MCP, and based on this analysis, we propose the Model\nContextual Integrity Protocol (MCIP), a refined version of MCP that addresses\nthese gaps.Next, we develop a fine-grained taxonomy that captures a diverse\nrange of unsafe behaviors observed in MCP scenarios. Building on this taxonomy,\nwe develop benchmark and training data that support the evaluation and\nimprovement of LLMs' capabilities in identifying safety risks within MCP\ninteractions. Leveraging the proposed benchmark and training data, we conduct\nextensive experiments on state-of-the-art LLMs. The results highlight LLMs'\nvulnerabilities in MCP interactions and demonstrate that our approach\nsubstantially improves their safety performance.", "published": "2025-05-20 16:41:45", "link": "http://arxiv.org/abs/2505.14590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning", "abstract": "While Large Language Models (LLMs) exhibit remarkable capabilities, they also\nintroduce significant safety and privacy risks. Current mitigation strategies\noften fail to preserve contextual reasoning capabilities in risky scenarios.\nInstead, they rely heavily on sensitive pattern matching to protect LLMs, which\nlimits the scope. Furthermore, they overlook established safety and privacy\nstandards, leading to systemic risks for legal compliance. To address these\ngaps, we formulate safety and privacy issues into contextualized compliance\nproblems following the Contextual Integrity (CI) theory. Under the CI\nframework, we align our model with three critical regulatory standards: GDPR,\nEU AI Act, and HIPAA. Specifically, we employ reinforcement learning (RL) with\na rule-based reward to incentivize contextual reasoning capabilities while\nenhancing compliance with safety and privacy norms. Through extensive\nexperiments, we demonstrate that our method not only significantly enhances\nlegal compliance (achieving a +17.64% accuracy improvement in safety/privacy\nbenchmarks) but also further improves general reasoning capability. For\nOpenThinker-7B, a strong reasoning model that significantly outperforms its\nbase model Qwen2.5-7B-Instruct across diverse subjects, our method enhances its\ngeneral reasoning capabilities, with +2.05% and +8.98% accuracy improvement on\nthe MMLU and LegalBench benchmark, respectively.", "published": "2025-05-20 16:40:09", "link": "http://arxiv.org/abs/2505.14585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning", "abstract": "Long chain-of-thought (Long-CoT) reasoning improves accuracy in LLMs, yet its\nverbose, self-reflective style often hinders effective distillation into small\nlanguage models (SLMs). We revisit Long-CoT compression through the lens of\ncapability alignment and ask: Can pruning improve reasoning? We propose\nPrune-on-Logic, a structure-aware framework that transforms Long-CoT into logic\ngraphs and selectively prunes low-utility reasoning steps under\nself-verification constraints. Through systematic analysis across three pruning\nstrategies -- targeting entire chains, core reasoning, and verification -- we\nfind that pruning verification steps yields consistent accuracy gains while\nreducing inference cost, outperforming token-level baselines and uncompressed\nfine-tuning. In contrast, pruning reasoning or all-chain steps degrades\nperformance, revealing that small models benefit not from shorter CoTs, but\nfrom semantically leaner ones. Our findings highlight pruning as a structural\noptimization strategy for aligning CoT reasoning with SLM capacity.", "published": "2025-05-20 16:38:32", "link": "http://arxiv.org/abs/2505.14582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TRATES: Trait-Specific Rubric-Assisted Cross-Prompt Essay Scoring", "abstract": "Research on holistic Automated Essay Scoring (AES) is long-dated; yet, there\nis a notable lack of attention for assessing essays according to individual\ntraits. In this work, we propose TRATES, a novel trait-specific and\nrubric-based cross-prompt AES framework that is generic yet specific to the\nunderlying trait. The framework leverages a Large Language Model (LLM) that\nutilizes the trait grading rubrics to generate trait-specific features\n(represented by assessment questions), then assesses those features given an\nessay. The trait-specific features are eventually combined with generic\nwriting-quality and prompt-specific features to train a simple classical\nregression model that predicts trait scores of essays from an unseen prompt.\nExperiments show that TRATES achieves a new state-of-the-art performance across\nall traits on a widely-used dataset, with the generated LLM-based features\nbeing the most significant.", "published": "2025-05-20 16:34:37", "link": "http://arxiv.org/abs/2505.14577v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agent Context Protocols Enhance Collective Inference", "abstract": "AI agents have become increasingly adept at complex tasks such as coding,\nreasoning, and multimodal understanding. However, building generalist systems\nrequires moving beyond individual agents to collective inference -- a paradigm\nwhere multi-agent systems with diverse, task-specialized agents complement one\nanother through structured communication and collaboration. Today, coordination\nis usually handled with imprecise, ad-hoc natural language, which limits\ncomplex interaction and hinders interoperability with domain-specific agents.\nWe introduce Agent context protocols (ACPs): a domain- and agent-agnostic\nfamily of structured protocols for agent-agent communication, coordination, and\nerror handling. ACPs combine (i) persistent execution blueprints -- explicit\ndependency graphs that store intermediate agent outputs -- with (ii)\nstandardized message schemas, enabling robust and fault-tolerant multi-agent\ncollective inference. ACP-powered generalist systems reach state-of-the-art\nperformance: 28.3 % accuracy on AssistantBench for long-horizon web assistance\nand best-in-class multimodal technical reports, outperforming commercial AI\nsystems in human evaluation. ACPs are highly modular and extensible, allowing\npractitioners to build top-tier generalist agents quickly.", "published": "2025-05-20 16:28:08", "link": "http://arxiv.org/abs/2505.14569v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Pivot Language for Low-Resource Machine Translation", "abstract": "Certain pairs of languages suffer from lack of a parallel corpus which is\nlarge in size and diverse in domain. One of the ways this is overcome is via\nuse of a pivot language. In this paper we use Hindi as a pivot language to\ntranslate Nepali into English. We describe what makes Hindi a good candidate\nfor the pivot. We discuss ways in which a pivot language can be used, and use\ntwo such approaches - the Transfer Method (fully supervised) and\nBacktranslation (semi-supervised) - to translate Nepali into English. Using the\nformer, we are able to achieve a devtest Set SacreBLEU score of 14.2, which\nimproves the baseline fully supervised score reported by (Guzman et al., 2019)\nby 6.6 points. While we are slightly below the semi-supervised baseline score\nof 15.1, we discuss what may have caused this under-performance, and suggest\nscope for future work.", "published": "2025-05-20 16:10:10", "link": "http://arxiv.org/abs/2505.14553v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation", "abstract": "Recent advancements in large language models (LLMs) underscore the need for\nmore comprehensive evaluation methods to accurately assess their reasoning\ncapabilities. Existing benchmarks are often domain-specific and thus cannot\nfully capture an LLM's general reasoning potential. To address this limitation,\nwe introduce the Knowledge Orthogonal Reasoning Gymnasium (KORGym), a dynamic\nevaluation platform inspired by KOR-Bench and Gymnasium. KORGym offers over\nfifty games in either textual or visual formats and supports interactive,\nmulti-turn assessments with reinforcement learning scenarios. Using KORGym, we\nconduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent\nreasoning patterns within model families and demonstrating the superior\nperformance of closed-source models. Further analysis examines the effects of\nmodality, reasoning strategies, reinforcement learning techniques, and response\nlength on model performance. We expect KORGym to become a valuable resource for\nadvancing LLM reasoning research and developing evaluation methodologies suited\nto complex, interactive environments.", "published": "2025-05-20 16:06:32", "link": "http://arxiv.org/abs/2505.14552v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders", "abstract": "Large language models (LLMs) are now ubiquitous in user-facing applications,\nyet they still generate undesirable toxic outputs, including profanity,\nvulgarity, and derogatory remarks. Although numerous detoxification methods\nexist, most apply broad, surface-level fixes and can therefore easily be\ncircumvented by jailbreak attacks. In this paper we leverage sparse\nautoencoders (SAEs) to identify toxicity-related directions in the residual\nstream of models and perform targeted activation steering using the\ncorresponding decoder vectors. We introduce three tiers of steering\naggressiveness and evaluate them on GPT-2 Small and Gemma-2-2B, revealing\ntrade-offs between toxicity reduction and language fluency. At stronger\nsteering strengths, these causal interventions surpass competitive baselines in\nreducing toxicity by up to 20%, though fluency can degrade noticeably on GPT-2\nSmall depending on the aggressiveness. Crucially, standard NLP benchmark scores\nupon steering remain stable, indicating that the model's knowledge and general\nabilities are preserved. We further show that feature-splitting in wider SAEs\nhampers safety interventions, underscoring the importance of disentangled\nfeature learning. Our findings highlight both the promise and the current\nlimitations of SAE-based causal interventions for LLM detoxification, further\nsuggesting practical guidelines for safer language-model deployment.", "published": "2025-05-20 15:55:31", "link": "http://arxiv.org/abs/2505.14536v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Internal Chain-of-Thought: Empirical Evidence for Layer-wise Subtask Scheduling in LLMs", "abstract": "We show that large language models (LLMs) exhibit an $\\textit{internal\nchain-of-thought}$: they sequentially decompose and execute composite tasks\nlayer-by-layer. Two claims ground our study: (i) distinct subtasks are learned\nat different network depths, and (ii) these subtasks are executed sequentially\nacross layers. On a benchmark of 15 two-step composite tasks, we employ\nlayer-from context-masking and propose a novel cross-task patching method,\nconfirming (i). To examine claim (ii), we apply LogitLens to decode hidden\nstates, revealing a consistent layerwise execution pattern. We further\nreplicate our analysis on the real-world $\\text{TRACE}$ benchmark, observing\nthe same stepwise dynamics. Together, our results enhance LLMs transparency by\nshowing their capacity to internally plan and execute subtasks (or\ninstructions), opening avenues for fine-grained, instruction-level activation\nsteering.", "published": "2025-05-20 15:49:15", "link": "http://arxiv.org/abs/2505.14530v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Graph Representations of Logical Forms for Language Modeling", "abstract": "We make the case for language models over logical forms (LFLMs), arguing that\nsuch models are more data-efficient than their textual counterparts. To that\nend, we introduce the Graph-based Formal-Logical Distributional Semantics\n(GFoLDS) prototype, a pretrained LM over graph representations of logical\nforms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong\nexperimental evidence that LFLMs can leverage the built-in, basic linguistic\nknowledge inherent in such models to immediately begin learning more complex\npatterns. On downstream tasks, we show that GFoLDS vastly outperforms textual,\ntransformer LMs pretrained on similar amounts of data, indicating that LFLMs\ncan learn with substantially less data than models over plain text.\nFurthermore, we show that the performance of this model is likely to scale with\nadditional parameters and pretraining data, suggesting the viability of LFLMs\nin real-world applications.", "published": "2025-05-20 15:46:44", "link": "http://arxiv.org/abs/2505.14523v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Teaching Audio-Aware Large Language Models What Does Not Hear: Mitigating Hallucinations through Synthesized Negative Samples", "abstract": "Recent advancements in audio-aware large language models (ALLMs) enable them\nto process and understand audio inputs. However, these models often hallucinate\nnon-existent sound events, reducing their reliability in real-world\napplications. To address this, we propose LISTEN (Learning to Identify Sounds\nThrough Extended Negative Samples), a contrastive-like training method that\nenhances ALLMs' ability to distinguish between present and absent sounds using\nsynthesized data from the backbone LLM. Unlike prior approaches, our method\nrequires no modification to LLM parameters and efficiently integrates audio\nrepresentations via a lightweight adapter. Experiments show that LISTEN\neffectively mitigates hallucinations while maintaining impressive performance\non existing audio question and reasoning benchmarks. At the same time, it is\nmore efficient in both data and computation.", "published": "2025-05-20 15:44:01", "link": "http://arxiv.org/abs/2505.14518v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ModRWKV: Transformer Multimodality in Linear Time", "abstract": "Currently, most multimodal studies are based on large language models (LLMs)\nwith quadratic-complexity Transformer architectures. While linear models like\nRNNs enjoy low inference costs, their application has been largely limited to\nthe text-only modality. This work explores the capabilities of modern RNN\narchitectures in multimodal contexts. We propose ModRWKV-a decoupled multimodal\nframework built upon the RWKV7 architecture as its LLM backbone-which achieves\nmulti-source information fusion through dynamically adaptable heterogeneous\nmodality encoders. We designed the multimodal modules in ModRWKV with an\nextremely lightweight architecture and, through extensive experiments,\nidentified a configuration that achieves an optimal balance between performance\nand computational efficiency. ModRWKV leverages the pretrained weights of the\nRWKV7 LLM for initialization, which significantly accelerates multimodal\ntraining. Comparative experiments with different pretrained checkpoints further\ndemonstrate that such initialization plays a crucial role in enhancing the\nmodel's ability to understand multimodal signals. Supported by extensive\nexperiments, we conclude that modern RNN architectures present a viable\nalternative to Transformers in the domain of multimodal large language models\n(MLLMs). Furthermore, we identify the optimal configuration of the ModRWKV\narchitecture through systematic exploration.", "published": "2025-05-20 15:34:36", "link": "http://arxiv.org/abs/2505.14505v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhanced Multimodal Aspect-Based Sentiment Analysis by LLM-Generated Rationales", "abstract": "There has been growing interest in Multimodal Aspect-Based Sentiment Analysis\n(MABSA) in recent years. Existing methods predominantly rely on pre-trained\nsmall language models (SLMs) to collect information related to aspects and\nsentiments from both image and text, with an aim to align these two modalities.\nHowever, small SLMs possess limited capacity and knowledge, often resulting in\ninaccurate identification of meaning, aspects, sentiments, and their\ninterconnections in textual and visual data. On the other hand, Large language\nmodels (LLMs) have shown exceptional capabilities in various tasks by\neffectively exploring fine-grained information in multimodal data. However,\nsome studies indicate that LLMs still fall short compared to fine-tuned small\nmodels in the field of ABSA. Based on these findings, we propose a novel\nframework, termed LRSA, which combines the decision-making capabilities of SLMs\nwith additional information provided by LLMs for MABSA. Specifically, we inject\nexplanations generated by LLMs as rationales into SLMs and employ a dual\ncross-attention mechanism for enhancing feature interaction and fusion, thereby\naugmenting the SLMs' ability to identify aspects and sentiments. We evaluated\nour method using two baseline models, numerous experiments highlight the\nsuperiority of our approach on three widely-used benchmarks, indicating its\ngeneralizability and applicability to most pre-trained models for MABSA.", "published": "2025-05-20 15:28:26", "link": "http://arxiv.org/abs/2505.14499v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reasoning Models Better Express Their Confidence", "abstract": "Despite their strengths, large language models (LLMs) often fail to\ncommunicate their confidence accurately, making it difficult to assess when\nthey might be wrong and limiting their reliability. In this work, we\ndemonstrate that reasoning models-LLMs that engage in extended chain-of-thought\n(CoT) reasoning-exhibit superior performance not only in problem-solving but\nalso in accurately expressing their confidence. Specifically, we benchmark six\nreasoning models across six datasets and find that they achieve strictly better\nconfidence calibration than their non-reasoning counterparts in 33 out of the\n36 settings. Our detailed analysis reveals that these gains in calibration stem\nfrom the slow thinking behaviors of reasoning models-such as exploring\nalternative approaches and backtracking-which enable them to adjust their\nconfidence dynamically throughout their CoT, making it progressively more\naccurate. In particular, we find that reasoning models become increasingly\nbetter calibrated as their CoT unfolds, a trend not observed in non-reasoning\nmodels. Moreover, removing slow thinking behaviors from the CoT leads to a\nsignificant drop in calibration. Lastly, we show that these gains are not\nexclusive to reasoning models-non-reasoning models also benefit when guided to\nperform slow thinking via in-context learning.", "published": "2025-05-20 15:19:00", "link": "http://arxiv.org/abs/2505.14489v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance", "abstract": "Large language models (LLMs) have shown great potential in flagging harmful\ncontent in online communities. Yet, existing approaches for moderation require\na separate model for every community and are opaque in their decision-making,\nlimiting real-world adoption. We introduce Mixture of Moderation Experts\n(MoMoE), a modular, cross-community framework that adds post-hoc explanations\nto scalable content moderation. MoMoE orchestrates four operators -- Allocate,\nPredict, Aggregate, Explain -- and is instantiated as seven\ncommunity-specialized experts (MoMoE-Community) and five norm-violation experts\n(MoMoE-NormVio). On 30 unseen subreddits, the best variants obtain Micro-F1\nscores of 0.72 and 0.67, respectively, matching or surpassing strong fine-tuned\nbaselines while consistently producing concise and reliable explanations.\nAlthough community-specialized experts deliver the highest peak accuracy,\nnorm-violation experts provide steadier performance across domains. These\nfindings show that MoMoE yields scalable, transparent moderation without\nneeding per-community fine-tuning. More broadly, they suggest that lightweight,\nexplainable expert ensembles can guide future NLP and HCI research on\ntrustworthy human-AI governance of online communities.", "published": "2025-05-20 15:16:06", "link": "http://arxiv.org/abs/2505.14483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models", "abstract": "In the field of urban planning, existing Vision-Language Models (VLMs)\nfrequently fail to effectively analyze and evaluate planning maps, despite the\ncritical importance of these visual elements for urban planners and related\neducational contexts. Planning maps, which visualize land use, infrastructure\nlayouts, and functional zoning, require specialized understanding of spatial\nconfigurations, regulatory requirements, and multi-scale analysis. To address\nthis challenge, we introduce PlanGPT-VL, the first domain-specific\nVision-Language Model tailored specifically for urban planning maps. PlanGPT-VL\nemploys three innovative approaches: (1) PlanAnno-V framework for high-quality\nVQA data synthesis, (2) Critical Point Thinking to reduce hallucinations\nthrough structured verification, and (3) comprehensive training methodology\ncombining Supervised Fine-Tuning with frozen vision encoder parameters. Through\nsystematic evaluation on our proposed PlanBench-V benchmark, we demonstrate\nthat PlanGPT-VL significantly outperforms general-purpose state-of-the-art VLMs\nin specialized planning map interpretation tasks, offering urban planning\nprofessionals a reliable tool for map analysis, assessment, and educational\napplications while maintaining high factual accuracy. Our lightweight 7B\nparameter model achieves comparable performance to models exceeding 72B\nparameters, demonstrating efficient domain specialization without sacrificing\nperformance.", "published": "2025-05-20 15:14:47", "link": "http://arxiv.org/abs/2505.14481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach", "abstract": "Large language models (LLMs) struggle with formal domains that require\nrigorous logical deduction and symbolic reasoning, such as mathematical proof\ngeneration. We propose a neuro-symbolic approach that combines LLMs' generative\nstrengths with structured components to overcome this challenge. As a\nproof-of-concept, we focus on geometry problems. Our approach is two-fold: (1)\nwe retrieve analogous problems and use their proofs to guide the LLM, and (2) a\nformal verifier evaluates the generated proofs and provides feedback, helping\nthe model fix incorrect proofs. We demonstrate that our method significantly\nimproves proof accuracy for OpenAI's o1 model (58%-70% improvement); both\nanalogous problems and the verifier's feedback contribute to these gains. More\nbroadly, shifting to LLMs that generate provably correct conclusions could\ndramatically improve their reliability, accuracy and consistency, unlocking\ncomplex tasks and critical real-world applications that require\ntrustworthiness.", "published": "2025-05-20 15:13:32", "link": "http://arxiv.org/abs/2505.14479v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Adapting Pretrained Language Models for Citation Classification via Self-Supervised Contrastive Learning", "abstract": "Citation classification, which identifies the intention behind academic\ncitations, is pivotal for scholarly analysis. Previous works suggest\nfine-tuning pretrained language models (PLMs) on citation classification\ndatasets, reaping the reward of the linguistic knowledge they gained during\npretraining. However, directly fine-tuning for citation classification is\nchallenging due to labeled data scarcity, contextual noise, and spurious\nkeyphrase correlations. In this paper, we present a novel framework, Citss,\nthat adapts the PLMs to overcome these challenges. Citss introduces\nself-supervised contrastive learning to alleviate data scarcity, and is\nequipped with two specialized strategies to obtain the contrastive pairs:\nsentence-level cropping, which enhances focus on target citations within long\ncontexts, and keyphrase perturbation, which mitigates reliance on specific\nkeyphrases. Compared with previous works that are only designed for\nencoder-based PLMs, Citss is carefully developed to be compatible with both\nencoder-based PLMs and decoder-based LLMs, to embrace the benefits of enlarged\npretraining. Experiments with three benchmark datasets with both encoder-based\nPLMs and decoder-based LLMs demonstrate our superiority compared to the\nprevious state of the art. Our code is available at: github.com/LITONG99/Citss", "published": "2025-05-20 15:05:27", "link": "http://arxiv.org/abs/2505.14471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAST: Phonetic-Acoustic Speech Tokenizer", "abstract": "We present PAST, a novel end-to-end framework that jointly models phonetic\ninformation alongside signal reconstruction, eliminating the need for external\npretrained models. Unlike previous approaches that rely on pretrained\nself-supervised models, PAST employs supervised phonetic data, directly\nintegrating domain knowledge into the tokenization process via auxiliary tasks.\nAdditionally, we introduce a streamable, causal variant of PAST, enabling\nreal-time speech applications. Results demonstrate that PAST surpasses existing\nevaluated baseline tokenizers across common evaluation metrics, including\nphonetic representation and speech reconstruction. Notably, PAST also achieves\nsuperior performance when serving as a speech representation for speech\nlanguage models, further highlighting its effectiveness as a foundation for\nspoken language generation. To foster further research, we release the full\nimplementation. For code, model checkpoints, and samples see:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/PAST", "published": "2025-05-20 15:05:14", "link": "http://arxiv.org/abs/2505.14470v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attributional Safety Failures in Large Language Models under Code-Mixed Perturbations", "abstract": "Recent advancements in LLMs have raised significant safety concerns,\nparticularly when dealing with code-mixed inputs and outputs. Our study\nsystematically investigates the increased susceptibility of LLMs to produce\nunsafe outputs from code-mixed prompts compared to monolingual English prompts.\nUtilizing explainability methods, we dissect the internal attribution shifts\ncausing model's harmful behaviors. In addition, we explore cultural dimensions\nby distinguishing between universally unsafe and culturally-specific unsafe\nqueries. This paper presents novel experimental insights, clarifying the\nmechanisms driving this phenomenon.", "published": "2025-05-20 15:05:03", "link": "http://arxiv.org/abs/2505.14469v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Void in Language Models", "abstract": "Despite advances in transformer-based language models (LMs), a fundamental\nquestion remains largely unanswered: Are all layers activated during inference?\nWe investigate this question by detecting unactivated layers (which we refer to\nas Voids) using a non-trainable and parameter-free adaptive computation method\ncalled L2 Adaptive Computation (LAC). We adapt LAC from its original\nefficiency-focused application to trace activated layers during inference. This\nmethod monitors changes in the L2-norm of activations to identify voids. We\nanalyze layer activation in instruction-tuned LMs across two phases: Prompt\nProcessing (PP), where we trace activated layers for each token in the input\nprompts, and Response Generation (RG), where we trace activated layers for each\ngenerated token. We further demonstrate that distinct layers are activated\nduring these two phases. To show the effectiveness of our method, we evaluated\nthree distinct instruction-tuned LMs from the Llama, Mistral, and Qwen families\non three benchmarks: MMLU, GPQA Diamond, and BoolQ. For example, on MMLU with a\nzero-shot setting, skipping voids in Qwen2.5-7B-Instruct resulted in an\nimprovement from 69.24 to 71.29 while the model uses only 30% of the layers.\nSimilarly, Mistral-7B-Instruct-v0.3 on GPQA Diamond improved from 13.88 to\n18.36 when using 70% of the layers during both the PP and RG phases. These\nresults show that not all layers contribute equally during inference, and that\nselectively skipping most of them can improve the performance of models on\ncertain tasks.", "published": "2025-05-20 15:01:56", "link": "http://arxiv.org/abs/2505.14467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All Correct Answers Are Equal: Why Your Distillation Source Matters", "abstract": "Distillation has emerged as a practical and effective approach to enhance the\nreasoning capabilities of open-source language models. In this work, we conduct\na large-scale empirical study on reasoning data distillation by collecting\nverified outputs from three state-of-the-art teacher models-AM-Thinking-v1,\nQwen3-235B-A22B, and DeepSeek-R1-on a shared corpus of 1.89 million queries. We\nconstruct three parallel datasets and analyze their distributions, revealing\nthat AM-Thinking-v1-distilled data exhibits greater token length diversity and\nlower perplexity. Student models trained on each dataset are evaluated on\nreasoning benchmarks including AIME2024, AIME2025, MATH500, and LiveCodeBench.\nThe AM-based model consistently achieves the best performance (e.g., 84.3 on\nAIME2024, 72.2 on AIME2025, 98.4 on MATH500, and 65.9 on LiveCodeBench) and\ndemonstrates adaptive output behavior-producing longer responses for harder\ntasks and shorter ones for simpler tasks. These findings highlight the value of\nhigh-quality, verified reasoning traces. We release the AM-Thinking-v1 and\nQwen3-235B-A22B distilled datasets to support future research on open and\nhigh-performing reasoning-oriented language models. The datasets are publicly\navailable on Hugging Face\\footnote{Datasets are available on Hugging Face:\n\\href{https://huggingface.co/datasets/a-m-team/AM-Thinking-v1-Distilled}{AM-Thinking-v1-Distilled},\n\\href{https://huggingface.co/datasets/a-m-team/AM-Qwen3-Distilled}{AM-Qwen3-Distilled}.}.", "published": "2025-05-20 15:00:51", "link": "http://arxiv.org/abs/2505.14464v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding", "abstract": "As vision-language models (VLMs) become increasingly integrated into daily\nlife, the need for accurate visual culture understanding is becoming critical.\nYet, these models frequently fall short in interpreting cultural nuances\neffectively. Prior work has demonstrated the effectiveness of\nretrieval-augmented generation (RAG) in enhancing cultural understanding in\ntext-only settings, while its application in multimodal scenarios remains\nunderexplored. To bridge this gap, we introduce RAVENEA (Retrieval-Augmented\nVisual culturE uNdErstAnding), a new benchmark designed to advance visual\nculture understanding through retrieval, focusing on two tasks: culture-focused\nvisual question answering (cVQA) and culture-informed image captioning (cIC).\nRAVENEA extends existing datasets by integrating over 10,000 Wikipedia\ndocuments curated and ranked by human annotators. With RAVENEA, we train and\nevaluate seven multimodal retrievers for each image query, and measure the\ndownstream impact of retrieval-augmented inputs across fourteen\nstate-of-the-art VLMs. Our results show that lightweight VLMs, when augmented\nwith culture-aware retrieval, outperform their non-augmented counterparts (by\nat least 3.2% absolute on cVQA and 6.2% absolute on cIC). This highlights the\nvalue of retrieval-augmented methods and culturally inclusive benchmarks for\nmultimodal understanding.", "published": "2025-05-20 14:57:16", "link": "http://arxiv.org/abs/2505.14462v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "CtrlDiff: Boosting Large Diffusion Language Models with Dynamic Block Prediction and Controllable Generation", "abstract": "Although autoregressive models have dominated language modeling in recent\nyears, there has been a growing interest in exploring alternative paradigms to\nthe conventional next-token prediction framework. Diffusion-based language\nmodels have emerged as a compelling alternative due to their powerful parallel\ngeneration capabilities and inherent editability. However, these models are\noften constrained by fixed-length generation. A promising direction is to\ncombine the strengths of both paradigms, segmenting sequences into blocks,\nmodeling autoregressive dependencies across blocks while leveraging discrete\ndiffusion to estimate the conditional distribution within each block given the\npreceding context. Nevertheless, their practical application is often hindered\nby two key limitations: rigid fixed-length outputs and a lack of flexible\ncontrol mechanisms. In this work, we address the critical limitations of fixed\ngranularity and weak controllability in current large diffusion language\nmodels. We propose CtrlDiff, a dynamic and controllable semi-autoregressive\nframework that adaptively determines the size of each generation block based on\nlocal semantics using reinforcement learning. Furthermore, we introduce a\nclassifier-guided control mechanism tailored to discrete diffusion, which\nsignificantly reduces computational overhead while facilitating efficient\npost-hoc conditioning without retraining. Extensive experiments demonstrate\nthat CtrlDiff sets a new standard among hybrid diffusion models, narrows the\nperformance gap to state-of-the-art autoregressive approaches, and enables\neffective conditional text generation across diverse tasks.", "published": "2025-05-20 14:52:41", "link": "http://arxiv.org/abs/2505.14455v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Subgroup Disparities in Multi-Label Speech Emotion Recognition: A Pseudo-Labeling and Unsupervised Learning Approach", "abstract": "While subgroup disparities and performance bias are increasingly studied in\ncomputational research, fairness in categorical Speech Emotion Recognition\n(SER) remains underexplored. Existing methods often rely on explicit\ndemographic labels, which are difficult to obtain due to privacy concerns. To\naddress this limitation, we introduce an Implicit Demography Inference (IDI)\nmodule that leverages pseudo-labeling from a pre-trained model and unsupervised\nlearning using k-means clustering to mitigate bias in SER. Our experiments show\nthat pseudo-labeling IDI reduces subgroup disparities, improving fairness\nmetrics by over 33% with less than a 3% decrease in SER accuracy. Also, the\nunsupervised IDI yields more than a 26% improvement in fairness metrics with a\ndrop of less than 4% in SER performance. Further analyses reveal that the\nunsupervised IDI consistently mitigates race and age disparities, demonstrating\nits potential in scenarios where explicit demographic information is\nunavailable.", "published": "2025-05-20 14:50:44", "link": "http://arxiv.org/abs/2505.14449v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Creative Preference Optimization", "abstract": "While Large Language Models (LLMs) have demonstrated impressive performance\nacross natural language generation tasks, their ability to generate truly\ncreative content-characterized by novelty, diversity, surprise, and\nquality-remains limited. Existing methods for enhancing LLM creativity often\nfocus narrowly on diversity or specific tasks, failing to address creativity's\nmultifaceted nature in a generalizable way. In this work, we propose Creative\nPreference Optimization (CrPO), a novel alignment method that injects signals\nfrom multiple creativity dimensions into the preference optimization objective\nin a modular fashion. We train and evaluate creativity-augmented versions of\nseveral models using CrPO and MuCE, a new large-scale human preference dataset\nspanning over 200,000 human-generated responses and ratings from more than 30\npsychological creativity assessments. Our models outperform strong baselines,\nincluding GPT-4o, on both automated and human evaluations, producing more\nnovel, diverse, and surprising generations while maintaining high output\nquality. Additional evaluations on NoveltyBench further confirm the\ngeneralizability of our approach. Together, our results demonstrate that\ndirectly optimizing for creativity within preference frameworks is a promising\ndirection for advancing the creative capabilities of LLMs without compromising\noutput quality.", "published": "2025-05-20 14:43:41", "link": "http://arxiv.org/abs/2505.14442v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models", "abstract": "End-to-end speech large language models ((LLMs)) extend the capabilities of\ntext-based models to directly process and generate audio tokens. However, this\noften leads to a decline in reasoning and generation performance compared to\ntext input, a phenomenon referred to as intelligence degradation. To\nsystematically evaluate this gap, we propose S2SBench, a benchmark designed to\nquantify performance degradation in Speech LLMs. It includes diagnostic\ndatasets targeting sentence continuation and commonsense reasoning under audio\ninput. We further introduce a pairwise evaluation protocol based on perplexity\ndifferences between plausible and implausible samples to measure degradation\nrelative to text input. We apply S2SBench to analyze the training process of\nBaichuan-Audio, which further demonstrates the benchmark's effectiveness. All\ndatasets and evaluation code are available at\nhttps://github.com/undobug/S2SBench.", "published": "2025-05-20 14:42:20", "link": "http://arxiv.org/abs/2505.14438v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models", "abstract": "Large Language Models (LLMs) offer a transparent brain with accessible\nparameters that encode extensive knowledge, which can be analyzed, located and\ntransferred. Consequently, a key research challenge is to transcend traditional\nknowledge transfer paradigms rooted in symbolic language and achieve genuine\nParametric Knowledge Transfer (PKT). Significantly, exploring effective methods\nfor transferring knowledge across LLMs of different scales through parameters\npresents an intriguing and valuable research direction. In this paper, we first\ndemonstrate $\\textbf{Alignment}$ in parametric space is the fundamental\nprerequisite to achieve successful cross-scale PKT. We redefine the previously\nexplored knowledge transfer as Post-Align PKT (PostPKT), which utilizes\nextracted parameters for LoRA initialization and requires subsequent fine-tune\nfor alignment. Hence, to reduce cost for further fine-tuning, we introduce a\nnovel Pre-Align PKT (PrePKT) paradigm and propose a solution called\n$\\textbf{LaTen}$\n($\\textbf{L}$oc$\\textbf{a}$te-$\\textbf{T}$h$\\textbf{e}$n-Alig$\\textbf{n}$) that\naligns the parametric spaces of LLMs across scales only using several training\nsteps without following training. Comprehensive experiments on four benchmarks\ndemonstrate that both PostPKT and PrePKT face challenges in achieving\nconsistently stable transfer. Through in-depth analysis, we identify\n$\\textbf{Neural Incompatibility}$ as the ethological and parametric structural\ndifferences between LLMs of varying scales, presenting fundamental challenges\nto achieving effective PKT. These findings provide fresh insights into the\nparametric architectures of LLMs and highlight promising directions for future\nresearch on efficient PKT. Our code is available at\nhttps://github.com/Trae1ounG/Neural_Incompatibility.", "published": "2025-05-20 14:42:03", "link": "http://arxiv.org/abs/2505.14436v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rank-K: Test-Time Reasoning for Listwise Reranking", "abstract": "Retrieve-and-rerank is a popular retrieval pipeline because of its ability to\nmake slow but effective rerankers efficient enough at query time by reducing\nthe number of comparisons. Recent works in neural rerankers take advantage of\nlarge language models for their capability in reasoning between queries and\npassages and have achieved state-of-the-art retrieval effectiveness. However,\nsuch rerankers are resource-intensive, even after heavy optimization. In this\nwork, we introduce Rank-K, a listwise passage reranking model that leverages\nthe reasoning capability of the reasoning language model at query time that\nprovides test time scalability to serve hard queries. We show that Rank-K\nimproves retrieval effectiveness by 23\\% over the RankZephyr, the\nstate-of-the-art listwise reranker, when reranking a BM25 initial ranked list\nand 19\\% when reranking strong retrieval results by SPLADE-v3. Since Rank-K is\ninherently a multilingual model, we found that it ranks passages based on\nqueries in different languages as effectively as it does in monolingual\nretrieval.", "published": "2025-05-20 14:39:34", "link": "http://arxiv.org/abs/2505.14432v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning", "abstract": "Instruction-tuned large language models (LLMs) have shown strong performance\non a variety of tasks; however, generalizing from synthetic to human-authored\ninstructions in grounded environments remains a challenge for them. In this\nwork, we study generalization challenges in spatial grounding tasks where\nmodels interpret and translate instructions for building object arrangements on\na $2.5$D grid. We fine-tune LLMs using only synthetic instructions and evaluate\ntheir performance on a benchmark dataset containing both synthetic and\nhuman-written instructions. Our results reveal that while models generalize\nwell on simple tasks, their performance degrades significantly on more complex\ntasks. We present a detailed error analysis of the gaps in instruction\ngeneralization.", "published": "2025-05-20 14:33:29", "link": "http://arxiv.org/abs/2505.14425v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Low-Resource MT via Synthetic Data Generation with LLMs", "abstract": "We investigate the potential of LLM-generated synthetic data for improving\nlow-resource machine translation (MT). Focusing on seven diverse target\nlanguages, we construct a document-level synthetic corpus from English\nEuroparl, and extend it via pivoting to 147 additional language pairs.\nAutomatic and human evaluation confirm its high overall quality. We study its\npractical application by (i) identifying effective training regimes, (ii)\ncomparing our data with the HPLT dataset, and (iii) testing its utility beyond\nEnglish-centric MT. Finally, we introduce SynOPUS, a public repository for\nsynthetic parallel datasets. Our findings show that LLM-generated synthetic\ndata, even when noisy, can substantially improve MT performance for\nlow-resource languages.", "published": "2025-05-20 14:31:54", "link": "http://arxiv.org/abs/2505.14423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SAE-FiRE: Enhancing Earnings Surprise Predictions Through Sparse Autoencoder Feature Selection", "abstract": "Predicting earnings surprises through the analysis of earnings conference\ncall transcripts has attracted increasing attention from the financial research\ncommunity. Conference calls serve as critical communication channels between\ncompany executives, analysts, and shareholders, offering valuable\nforward-looking information. However, these transcripts present significant\nanalytical challenges, typically containing over 5,000 words with substantial\nredundancy and industry-specific terminology that creates obstacles for\nlanguage models. In this work, we propose the Sparse Autoencoder for Financial\nRepresentation Enhancement (SAE-FiRE) framework to address these limitations by\nextracting key information while eliminating redundancy. SAE-FiRE employs\nSparse Autoencoders (SAEs) to efficiently identify patterns and filter out\nnoises, and focusing specifically on capturing nuanced financial signals that\nhave predictive power for earnings surprises. Experimental results indicate\nthat the proposed method can significantly outperform comparing baselines.", "published": "2025-05-20 14:31:23", "link": "http://arxiv.org/abs/2505.14420v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents", "abstract": "Graphical user interface (GUI) agents powered by multimodal large language\nmodels (MLLMs) have shown greater promise for human-interaction. However, due\nto the high fine-tuning cost, users often rely on open-source GUI agents or\nAPIs offered by AI providers, which introduces a critical but underexplored\nsupply chain threat: backdoor attacks. In this work, we first unveil that\nMLLM-powered GUI agents naturally expose multiple interaction-level triggers,\nsuch as historical steps, environment states, and task progress. Based on this\nobservation, we introduce AgentGhost, an effective and stealthy framework for\nred-teaming backdoor attacks. Specifically, we first construct composite\ntriggers by combining goal and interaction levels, allowing GUI agents to\nunintentionally activate backdoors while ensuring task utility. Then, we\nformulate backdoor injection as a Min-Max optimization problem that uses\nsupervised contrastive learning to maximize the feature difference across\nsample classes at the representation space, improving flexibility of the\nbackdoor. Meanwhile, it adopts supervised fine-tuning to minimize the\ndiscrepancy between backdoor and clean behavior generation, enhancing\neffectiveness and utility. Extensive evaluations of various agent models in two\nestablished mobile benchmarks show that AgentGhost is effective and generic,\nwith attack accuracy that reaches 99.7\\% on three attack objectives, and shows\nstealthiness with only 1\\% utility degradation. Furthermore, we tailor a\ndefense method against AgentGhost that reduces the attack accuracy to 22.1\\%.\nOur code is available at \\texttt{anonymous}.", "published": "2025-05-20 14:29:18", "link": "http://arxiv.org/abs/2505.14418v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PRL: Prompts from Reinforcement Learning", "abstract": "Effective prompt engineering remains a central challenge in fully harnessing\nthe capabilities of LLMs. While well-designed prompts can dramatically enhance\nperformance, crafting them typically demands expert intuition and a nuanced\nunderstanding of the task. Moreover, the most impactful prompts often hinge on\nsubtle semantic cues, ones that may elude human perception but are crucial for\nguiding LLM behavior. In this paper, we introduce PRL (Prompts from\nReinforcement Learning), a novel RL-based approach for automatic prompt\ngeneration. Unlike previous methods, PRL can produce novel few-shot examples\nthat were not seen during training. Our approach achieves state-of-the-art\nperformance across a range of benchmarks, including text classification,\nsimplification, and summarization. On the classification task, it surpasses\nprior methods by 2.58% over APE and 1.00% over EvoPrompt. Additionally, it\nimproves the average ROUGE scores on the summarization task by 4.32 over APE\nand by 2.12 over EvoPrompt and the SARI score on simplification by 6.93 over\nAPE and by 6.01 over EvoPrompt. Our code is available at\nhttps://github.com/Batorskq/prl .", "published": "2025-05-20 14:26:19", "link": "http://arxiv.org/abs/2505.14412v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Pairwise Evaluation of Accent Similarity in Speech Synthesis", "abstract": "Despite growing interest in generating high-fidelity accents, evaluating\naccent similarity in speech synthesis has been underexplored. We aim to enhance\nboth subjective and objective evaluation methods for accent similarity.\nSubjectively, we refine the XAB listening test by adding components that\nachieve higher statistical significance with fewer listeners and lower costs.\nOur method involves providing listeners with transcriptions, having them\nhighlight perceived accent differences, and implementing meticulous screening\nfor reliability. Objectively, we utilise pronunciation-related metrics, based\non distances between vowel formants and phonetic posteriorgrams, to evaluate\naccent generation. Comparative experiments reveal that these metrics, alongside\naccent similarity, speaker similarity, and Mel Cepstral Distortion, can be\nused. Moreover, our findings underscore significant limitations of common\nmetrics like Word Error Rate in assessing underrepresented accents.", "published": "2025-05-20 14:23:50", "link": "http://arxiv.org/abs/2505.14410v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis", "abstract": "Large Language Models (LLMs), despite their remarkable capabilities, are\nhampered by hallucinations. A particularly challenging variant, knowledge\novershadowing, occurs when one piece of activated knowledge inadvertently masks\nanother relevant piece, leading to erroneous outputs even with high-quality\ntraining data. Current understanding of overshadowing is largely confined to\ninference-time observations, lacking deep insights into its origins and\ninternal mechanisms during model training. Therefore, we introduce\nPhantomCircuit, a novel framework designed to comprehensively analyze and\ndetect knowledge overshadowing. By innovatively employing knowledge circuit\nanalysis, PhantomCircuit dissects the internal workings of attention heads,\ntracing how competing knowledge pathways contribute to the overshadowing\nphenomenon and its evolution throughout the training process. Extensive\nexperiments demonstrate PhantomCircuit's effectiveness in identifying such\ninstances, offering novel insights into this elusive hallucination and\nproviding the research community with a new methodological lens for its\npotential mitigation.", "published": "2025-05-20 14:20:30", "link": "http://arxiv.org/abs/2505.14406v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OmniGenBench: A Modular Platform for Reproducible Genomic Foundation Models Benchmarking", "abstract": "The code of nature, embedded in DNA and RNA genomes since the origin of life,\nholds immense potential to impact both humans and ecosystems through genome\nmodeling. Genomic Foundation Models (GFMs) have emerged as a transformative\napproach to decoding the genome. As GFMs scale up and reshape the landscape of\nAI-driven genomics, the field faces an urgent need for rigorous and\nreproducible evaluation. We present OmniGenBench, a modular benchmarking\nplatform designed to unify the data, model, benchmarking, and interpretability\nlayers across GFMs. OmniGenBench enables standardized, one-command evaluation\nof any GFM across five benchmark suites, with seamless integration of over 31\nopen-source models. Through automated pipelines and community-extensible\nfeatures, the platform addresses critical reproducibility challenges, including\ndata transparency, model interoperability, benchmark fragmentation, and\nblack-box interpretability. OmniGenBench aims to serve as foundational\ninfrastructure for reproducible genomic AI research, accelerating trustworthy\ndiscovery and collaborative innovation in the era of genome-scale modeling.", "published": "2025-05-20 14:16:25", "link": "http://arxiv.org/abs/2505.14402v1", "categories": ["q-bio.GN", "cs.CL"], "primary_category": "q-bio.GN"}
{"title": "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation", "abstract": "While humans naturally learn and adapt from past experiences, large language\nmodels (LLMs) and their agentic counterparts struggle to retain reasoning from\nprevious tasks and apply them in future contexts. To address this limitation,\nwe propose a novel framework, log-augmented generation (LAG) that directly\nreuses prior computation and reasoning from past logs at test time to enhance\nmodel's ability to learn from previous tasks and perform better on new, unseen\nchallenges, all while keeping the system efficient and scalable. Specifically,\nour system represents task logs using key-value (KV) caches, encoding the full\nreasoning context of prior tasks while storing KV caches for only a selected\nsubset of tokens. When a new task arises, LAG retrieves the KV values from\nrelevant logs to augment generation. Our approach differs from reflection-based\nmemory mechanisms by directly reusing prior reasoning and computations without\nrequiring additional steps for knowledge extraction or distillation. Our method\nalso goes beyond existing KV caching techniques, which primarily target\nefficiency gains rather than improving accuracy. Experiments on knowledge- and\nreasoning-intensive datasets demonstrate that our method significantly\noutperforms standard agentic systems that do not utilize logs, as well as\nexisting solutions based on reflection and KV cache techniques.", "published": "2025-05-20 14:14:38", "link": "http://arxiv.org/abs/2505.14398v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds", "abstract": "Causal world models are systems that can answer counterfactual questions\nabout an environment of interest, i.e. predict how it would have evolved if an\narbitrary subset of events had been realized differently. It requires\nunderstanding the underlying causes behind chains of events and conducting\ncausal inference for arbitrary unseen distributions. So far, this task eludes\nfoundation models, notably large language models (LLMs), which do not have\ndemonstrated causal reasoning capabilities beyond the memorization of existing\ncausal relationships. Furthermore, evaluating counterfactuals in real-world\napplications is challenging since only the factual world is observed, limiting\nevaluation to synthetic datasets. We address these problems by explicitly\nextracting and modeling causal relationships and propose the Causal\nCartographer framework. First, we introduce a graph retrieval-augmented\ngeneration agent tasked to retrieve causal relationships from data. This\napproach allows us to construct a large network of real-world causal\nrelationships that can serve as a repository of causal knowledge and build\nreal-world counterfactuals. In addition, we create a counterfactual reasoning\nagent constrained by causal relationships to perform reliable step-by-step\ncausal inference. We show that our approach can extract causal knowledge and\nimprove the robustness of LLMs for causal reasoning tasks while reducing\ninference costs and spurious correlations.", "published": "2025-05-20 14:14:05", "link": "http://arxiv.org/abs/2505.14396v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.3; I.2.6; I.2.7; G.2.2; G.3; J.1"], "primary_category": "cs.AI"}
{"title": "MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language", "abstract": "Evaluating text generation capabilities of large language models (LLMs) is\nchallenging, particularly for low-resource languages where methods for direct\nassessment are scarce. We propose MUG-Eval, a novel framework that evaluates\nLLMs' multilingual generation capabilities by transforming existing benchmarks\ninto conversational tasks and measuring the LLMs' accuracies on those tasks. We\nspecifically designed these conversational tasks to require effective\ncommunication in the target language. Then, we simply use task success rate as\na proxy of successful conversation generation. Our approach offers two key\nadvantages: it is independent of language-specific NLP tools or annotated\ndatasets, which are limited for most languages, and it does not rely on\nLLMs-as-judges, whose evaluation quality degrades outside a few high-resource\nlanguages. We evaluate 8 LLMs across 30 languages spanning high, mid, and\nlow-resource categories, and we find that MUG-Eval correlates strongly with\nestablished benchmarks ($r$ > 0.75) while enabling standardized comparisons\nacross languages and models. Our framework provides a robust and\nresource-efficient solution for evaluating multilingual generation that can be\nextended to thousands of languages.", "published": "2025-05-20 14:14:00", "link": "http://arxiv.org/abs/2505.14395v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Editing Across Languages: A Survey of Multilingual Knowledge Editing", "abstract": "While Knowledge Editing has been extensively studied in monolingual settings,\nit remains underexplored in multilingual contexts. This survey systematizes\nrecent research on Multilingual Knowledge Editing (MKE), a growing subdomain of\nmodel editing focused on ensuring factual edits generalize reliably across\nlanguages. We present a comprehensive taxonomy of MKE methods, covering\nparameter-based, memory-based, fine-tuning, and hypernetwork approaches. We\nsurvey available benchmarks,summarize key findings on method effectiveness and\ntransfer patterns, identify challenges in cross-lingual propagation, and\nhighlight open problems related to language anisotropy, evaluation coverage,\nand edit scalability. Our analysis consolidates a rapidly evolving area and\nlays the groundwork for future progress in editable language-aware LLMs.", "published": "2025-05-20 14:13:04", "link": "http://arxiv.org/abs/2505.14393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AutoRev: Automatic Peer Review System for Academic Research Papers", "abstract": "Generating a review for an academic research paper is a complex task that\nrequires a deep understanding of the document's content and the\ninterdependencies between its sections. It demands not only insight into\ntechnical details but also an appreciation of the paper's overall coherence and\nstructure. Recent methods have predominantly focused on fine-tuning large\nlanguage models (LLMs) to address this challenge. However, they often overlook\nthe computational and performance limitations imposed by long input token\nlengths. To address this, we introduce AutoRev, an Automatic Peer Review System\nfor Academic Research Papers. Our novel framework represents an academic\ndocument as a graph, enabling the extraction of the most critical passages that\ncontribute significantly to the review. This graph-based approach demonstrates\neffectiveness for review generation and is potentially adaptable to various\ndownstream tasks, such as question answering, summarization, and document\nrepresentation. When applied to review generation, our method outperforms SOTA\nbaselines by an average of 58.72% across all evaluation metrics. We hope that\nour work will stimulate further research in applying graph-based extraction\ntechniques to other downstream tasks in NLP. We plan to make our code public\nupon acceptance.", "published": "2025-05-20 13:59:58", "link": "http://arxiv.org/abs/2505.14376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Your Prompt Safe? Investigating Prompt Injection Attacks Against Open-Source LLMs", "abstract": "Recent studies demonstrate that Large Language Models (LLMs) are vulnerable\nto different prompt-based attacks, generating harmful content or sensitive\ninformation. Both closed-source and open-source LLMs are underinvestigated for\nthese attacks. This paper studies effective prompt injection attacks against\nthe $\\mathbf{14}$ most popular open-source LLMs on five attack benchmarks.\nCurrent metrics only consider successful attacks, whereas our proposed Attack\nSuccess Probability (ASP) also captures uncertainty in the model's response,\nreflecting ambiguity in attack feasibility. By comprehensively analyzing the\neffectiveness of prompt injection attacks, we propose a simple and effective\nhypnotism attack; results show that this attack causes aligned language models,\nincluding Stablelm2, Mistral, Openchat, and Vicuna, to generate objectionable\nbehaviors, achieving around $90$% ASP. They also indicate that our ignore\nprefix attacks can break all $\\mathbf{14}$ open-source LLMs, achieving over\n$60$% ASP on a multi-categorical dataset. We find that moderately well-known\nLLMs exhibit higher vulnerability to prompt injection attacks, highlighting the\nneed to raise public awareness and prioritize efficient mitigation strategies.", "published": "2025-05-20 13:50:43", "link": "http://arxiv.org/abs/2505.14368v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Dual Decomposition of Weights and Singular Value Low Rank Adaptation", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical paradigm for\nadapting Large Language Models (LLMs) to downstream tasks, among which Low-rank\nAdaptation (LoRA) represents one of the most widely adopted methodologies.\nHowever, existing LoRA-based approaches exhibit two fundamental limitations:\nunstable training dynamics and inefficient knowledge transfer from pre-trained\nmodels, both stemming from random initialization of adapter parameters. To\novercome these challenges, we propose DuDe, a novel approach that decomposes\nweight matrices into magnitude and direction components, employing Singular\nValue Decomposition (SVD) for principled initialization. Our comprehensive\nevaluation demonstrates DuDe's superior performance and robustness, achieving\nup to 48.35\\% accuracy on MMLU and 62.53\\% ($\\pm$ 1.59) accuracy on GSM8K. Our\ntheoretical analysis and empirical validation collectively demonstrate that\nDuDe's decomposition strategy enhances optimization stability and better\npreserves pre-trained representations, particularly for domain-specific tasks\nrequiring specialized knowledge. The combination of robust empirical\nperformance and rigorous theoretical foundations establishes DuDe as a\nsignificant contribution to PEFT methodologies for LLMs.", "published": "2025-05-20 13:49:15", "link": "http://arxiv.org/abs/2505.14367v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PersonaTAB: Predicting Personality Traits using Textual, Acoustic, and Behavioral Cues in Fully-Duplex Speech Dialogs", "abstract": "Despite significant progress in neural spoken dialog systems,\npersonality-aware conversation agents -- capable of adapting behavior based on\npersonalities -- remain underexplored due to the absence of personality\nannotations in speech datasets. We propose a pipeline that preprocesses raw\naudio recordings to create a dialogue dataset annotated with timestamps,\nresponse types, and emotion/sentiment labels. We employ an automatic speech\nrecognition (ASR) system to extract transcripts and timestamps, then generate\nconversation-level annotations. Leveraging these annotations, we design a\nsystem that employs large language models to predict conversational\npersonality. Human evaluators were engaged to identify conversational\ncharacteristics and assign personality labels. Our analysis demonstrates that\nthe proposed system achieves stronger alignment with human judgments compared\nto existing approaches.", "published": "2025-05-20 13:41:32", "link": "http://arxiv.org/abs/2505.14356v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "WirelessMathBench: A Mathematical Modeling Benchmark for LLMs in Wireless Communications", "abstract": "Large Language Models (LLMs) have achieved impressive results across a broad\narray of tasks, yet their capacity for complex, domain-specific mathematical\nreasoning-particularly in wireless communications-remains underexplored. In\nthis work, we introduce WirelessMathBench, a novel benchmark specifically\ndesigned to evaluate LLMs on mathematical modeling challenges to wireless\ncommunications engineering. Our benchmark consists of 587 meticulously curated\nquestions sourced from 40 state-of-the-art research papers, encompassing a\ndiverse spectrum of tasks ranging from basic multiple-choice questions to\ncomplex equation completion tasks, including both partial and full completions,\nall of which rigorously adhere to physical and dimensional constraints. Through\nextensive experimentation with leading LLMs, we observe that while many models\nexcel in basic recall tasks, their performance degrades significantly when\nreconstructing partially or fully obscured equations, exposing fundamental\nlimitations in current LLMs. Even DeepSeek-R1, the best performer on our\nbenchmark, achieves an average accuracy of only 38.05%, with a mere 7.83%\nsuccess rate in full equation completion. By publicly releasing\nWirelessMathBench along with the evaluation toolkit, we aim to advance the\ndevelopment of more robust, domain-aware LLMs for wireless system analysis and\nbroader engineering applications.", "published": "2025-05-20 13:38:10", "link": "http://arxiv.org/abs/2505.14354v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for \u00dc-Tsang, Amdo and Kham Speech Dataset Generation", "abstract": "Tibetan is a low-resource language with minimal parallel speech corpora\nspanning its three major dialects-\\\"U-Tsang, Amdo, and Kham-limiting progress\nin speech modeling. To address this issue, we propose FMSD-TTS, a few-shot,\nmulti-speaker, multi-dialect text-to-speech framework that synthesizes parallel\ndialectal speech from limited reference audio and explicit dialect labels. Our\nmethod features a novel speaker-dialect fusion module and a Dialect-Specialized\nDynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and\nlinguistic variations across dialects while preserving speaker identity.\nExtensive objective and subjective evaluations demonstrate that FMSD-TTS\nsignificantly outperforms baselines in both dialectal expressiveness and\nspeaker similarity. We further validate the quality and utility of the\nsynthesized speech through a challenging speech-to-speech dialect conversion\ntask. Our contributions include: (1) a novel few-shot TTS system tailored for\nTibetan multi-dialect speech synthesis, (2) the public release of a large-scale\nsynthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source\nevaluation toolkit for standardized assessment of speaker similarity, dialect\nconsistency, and audio quality.", "published": "2025-05-20 13:35:55", "link": "http://arxiv.org/abs/2505.14351v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "OSoRA: Output-Dimension and Singular-Value Initialized Low-Rank Adaptation", "abstract": "Fine-tuning Large Language Models (LLMs) has become increasingly challenging\ndue to their massive scale and associated computational costs.\nParameter-Efficient Fine-Tuning (PEFT) methodologies have been proposed as\ncomputational alternatives; however, their implementations still require\nsignificant resources. In this paper, we present OSoRA (Output-Dimension and\nSingular-Value Initialized Low-Rank Adaptation), a novel PEFT method for LLMs.\nOSoRA extends Low-Rank Adaptation (LoRA) by integrating Singular Value\nDecomposition (SVD) with learnable scaling vectors in a unified framework. It\nfirst performs an SVD of pre-trained weight matrices, then optimizes an\noutput-dimension vector during training, while keeping the corresponding\nsingular vector matrices frozen. OSoRA substantially reduces computational\nresource requirements by minimizing the number of trainable parameters during\nfine-tuning. Comprehensive evaluations across mathematical reasoning, common\nsense reasoning, and other benchmarks demonstrate that OSoRA achieves\ncomparable or superior performance to state-of-the-art methods like LoRA and\nVeRA, while maintaining a linear parameter scaling even as the rank increases\nto higher dimensions. Our ablation studies further confirm that jointly\ntraining both the singular values and the output-dimension vector is critical\nfor optimal performance.", "published": "2025-05-20 13:34:06", "link": "http://arxiv.org/abs/2505.14350v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QA-prompting: Improving Summarization with Large Language Models using Question-Answering", "abstract": "Language Models (LMs) have revolutionized natural language processing,\nenabling high-quality text generation through prompting and in-context\nlearning. However, models often struggle with long-context summarization due to\npositional biases, leading to suboptimal extraction of critical information.\nThere are techniques to improve this with fine-tuning, pipelining, or using\ncomplex techniques, which have their own challenges. To solve these challenges,\nwe propose QA-prompting - a simple prompting method for summarization that\nutilizes question-answering as an intermediate step prior to summary\ngeneration. Our method extracts key information and enriches the context of\ntext to mitigate positional biases and improve summarization in a single LM\ncall per task without requiring fine-tuning or pipelining. Experiments on\nmultiple datasets belonging to different domains using ten state-of-the-art\npre-trained models demonstrate that QA-prompting outperforms baseline and other\nstate-of-the-art methods, achieving up to 29% improvement in ROUGE scores. This\nprovides an effective and scalable solution for summarization and highlights\nthe importance of domain-specific question selection for optimal performance.", "published": "2025-05-20 13:29:36", "link": "http://arxiv.org/abs/2505.14347v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious domains, including radiology report generation. Previous approaches\nhave attempted to utilize multimodal LLMs for this task, enhancing their\nperformance through the integration of domain-specific knowledge retrieval.\nHowever, these approaches often overlook the knowledge already embedded within\nthe LLMs, leading to redundant information integration and inefficient\nutilization of learned representations. To address this limitation, we propose\nRADAR, a framework for enhancing radiology report generation with supplementary\nknowledge injection. RADAR improves report generation by systematically\nleveraging both the internal knowledge of an LLM and externally retrieved\ninformation. Specifically, it first extracts the model's acquired knowledge\nthat aligns with expert image-based classification outputs. It then retrieves\nrelevant supplementary knowledge to further enrich this information. Finally,\nby aggregating both sources, RADAR generates more accurate and informative\nradiology reports. Extensive experiments on MIMIC-CXR, CheXpert-Plus, and IU\nX-ray demonstrate that our model outperforms state-of-the-art LLMs in both\nlanguage quality and clinical accuracy", "published": "2025-05-20 13:05:41", "link": "http://arxiv.org/abs/2505.14318v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A MIND for Reasoning: Meta-learning for In-context Deduction", "abstract": "Large language models (LLMs) are increasingly evaluated on formal tasks,\nwhere strong reasoning abilities define the state of the art. However, their\nability to generalize to out-of-distribution problems remains limited. In this\npaper, we investigate how LLMs can achieve a systematic understanding of\ndeductive rules. Our focus is on the task of identifying the appropriate subset\nof premises within a knowledge base needed to derive a given hypothesis. To\ntackle this challenge, we propose Meta-learning for In-context Deduction\n(MIND), a novel few-shot meta-learning fine-tuning approach. The goal of MIND\nis to enable models to generalize more effectively to unseen knowledge bases\nand to systematically apply inference rules. Our results show that MIND\nsignificantly improves generalization in small LMs ranging from 1.5B to 7B\nparameters. The benefits are especially pronounced in smaller models and\nlow-data settings. Remarkably, small models fine-tuned with MIND outperform\nstate-of-the-art LLMs, such as GPT-4o and o3-mini, on this task.", "published": "2025-05-20 13:00:48", "link": "http://arxiv.org/abs/2505.14313v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing", "abstract": "Hausa Natural Language Processing (NLP) has gained increasing attention in\nrecent years, yet remains understudied as a low-resource language despite\nhaving over 120 million first-language (L1) and 80 million second-language (L2)\nspeakers worldwide. While significant advances have been made in high-resource\nlanguages, Hausa NLP faces persistent challenges, including limited open-source\ndatasets and inadequate model representation. This paper presents an overview\nof the current state of Hausa NLP, systematically examining existing resources,\nresearch contributions, and gaps across fundamental NLP tasks: text\nclassification, machine translation, named entity recognition, speech\nrecognition, and question answering. We introduce HausaNLP\n(https://catalog.hausanlp.org), a curated catalog that aggregates datasets,\ntools, and research works to enhance accessibility and drive further\ndevelopment. Furthermore, we discuss challenges in integrating Hausa into large\nlanguage models (LLMs), addressing issues of suboptimal tokenization and\ndialectal variation. Finally, we propose strategic research directions\nemphasizing dataset expansion, improved language modeling approaches, and\nstrengthened community collaboration to advance Hausa NLP. Our work provides\nboth a foundation for accelerating Hausa NLP progress and valuable insights for\nbroader multilingual NLP research.", "published": "2025-05-20 12:59:55", "link": "http://arxiv.org/abs/2505.14311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Studying the Role of Input-Neighbor Overlap in Retrieval-Augmented Language Models Training Efficiency", "abstract": "Retrieval-augmented language models have demonstrated performance comparable\nto much larger models while requiring fewer computational resources. The\neffectiveness of these models crucially depends on the overlap between query\nand retrieved context, but the optimal degree of this overlap remains\nunexplored. In this paper, we systematically investigate how varying levels of\nquery--context overlap affect model performance during both training and\ninference. Our experiments reveal that increased overlap initially has minimal\neffect, but substantially improves test-time perplexity and accelerates model\nlearning above a critical threshold. Building on these findings, we demonstrate\nthat deliberately increasing overlap through synthetic context can enhance data\nefficiency and reduce training time by approximately 40\\% without compromising\nperformance. We specifically generate synthetic context through paraphrasing\nqueries. We validate our perplexity-based findings on question-answering tasks,\nconfirming that the benefits of retrieval-augmented language modeling extend to\npractical applications. Our results provide empirical evidence of significant\noptimization potential for retrieval mechanisms in language model pretraining.", "published": "2025-05-20 12:58:07", "link": "http://arxiv.org/abs/2505.14309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JOLT-SQL: Joint Loss Tuning of Text-to-SQL with Confusion-aware Noisy Schema Sampling", "abstract": "Text-to-SQL, which maps natural language to SQL queries, has benefited\ngreatly from recent advances in Large Language Models (LLMs). While LLMs offer\nvarious paradigms for this task, including prompting and supervised fine-tuning\n(SFT), SFT approaches still face challenges such as complex multi-stage\npipelines and poor robustness to noisy schema information. To address these\nlimitations, we present JOLT-SQL, a streamlined single-stage SFT framework that\njointly optimizes schema linking and SQL generation via a unified loss.\nJOLT-SQL employs discriminative schema linking, enhanced by local bidirectional\nattention, alongside a confusion-aware noisy schema sampling strategy with\nselective attention to improve robustness under noisy schema conditions.\nExperiments on the Spider and BIRD benchmarks demonstrate that JOLT-SQL\nachieves state-of-the-art execution accuracy among comparable-size open-source\nmodels, while significantly improving both training and inference efficiency.", "published": "2025-05-20 12:55:10", "link": "http://arxiv.org/abs/2505.14305v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Law for Quantization-Aware Training", "abstract": "Large language models (LLMs) demand substantial computational and memory\nresources, creating deployment challenges. Quantization-aware training (QAT)\naddresses these challenges by reducing model precision while maintaining\nperformance. However, the scaling behavior of QAT, especially at 4-bit\nprecision (W4A4), is not well understood. Existing QAT scaling laws often\nignore key factors such as the number of training tokens and quantization\ngranularity, which limits their applicability. This paper proposes a unified\nscaling law for QAT that models quantization error as a function of model size,\ntraining data volume, and quantization group size. Through 268 QAT experiments,\nwe show that quantization error decreases as model size increases, but rises\nwith more training tokens and coarser quantization granularity. To identify the\nsources of W4A4 quantization error, we decompose it into weight and activation\ncomponents. Both components follow the overall trend of W4A4 quantization\nerror, but with different sensitivities. Specifically, weight quantization\nerror increases more rapidly with more training tokens. Further analysis shows\nthat the activation quantization error in the FC2 layer, caused by outliers, is\nthe primary bottleneck of W4A4 QAT quantization error. By applying\nmixed-precision quantization to address this bottleneck, we demonstrate that\nweight and activation quantization errors can converge to similar levels.\nAdditionally, with more training data, weight quantization error eventually\nexceeds activation quantization error, suggesting that reducing weight\nquantization error is also important in such scenarios. These findings offer\nkey insights for improving QAT research and development.", "published": "2025-05-20 12:54:43", "link": "http://arxiv.org/abs/2505.14302v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SafetyNet: Detecting Harmful Outputs in LLMs by Modeling and Monitoring Deceptive Behaviors", "abstract": "High-risk industries like nuclear and aviation use real-time monitoring to\ndetect dangerous system conditions. Similarly, Large Language Models (LLMs)\nneed monitoring safeguards. We propose a real-time framework to predict harmful\nAI outputs before they occur by using an unsupervised approach that treats\nnormal behavior as the baseline and harmful outputs as outliers. Our study\nfocuses specifically on backdoor-triggered responses -- where specific input\nphrases activate hidden vulnerabilities causing the model to generate unsafe\ncontent like violence, pornography, or hate speech. We address two key\nchallenges: (1) identifying true causal indicators rather than surface\ncorrelations, and (2) preventing advanced models from deception -- deliberately\nevading monitoring systems. Hence, we approach this problem from an\nunsupervised lens by drawing parallels to human deception: just as humans\nexhibit physical indicators while lying, we investigate whether LLMs display\ndistinct internal behavioral signatures when generating harmful content. Our\nstudy addresses two critical challenges: 1) designing monitoring systems that\ncapture true causal indicators rather than superficial correlations; and\n2)preventing intentional evasion by increasingly capable \"Future models''. Our\nfindings show that models can produce harmful content through causal mechanisms\nand can become deceptive by: (a) alternating between linear and non-linear\nrepresentations, and (b) modifying feature relationships. To counter this, we\ndeveloped Safety-Net -- a multi-detector framework that monitors different\nrepresentation dimensions, successfully detecting harmful behavior even when\ninformation is shifted across representational spaces to evade individual\nmonitors. Our evaluation shows 96% accuracy in detecting harmful cases using\nour unsupervised ensemble approach.", "published": "2025-05-20 12:49:58", "link": "http://arxiv.org/abs/2505.14300v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Cross-Lingual Optimization for Language Transfer in Large Language Models", "abstract": "Adapting large language models to other languages typically employs\nsupervised fine-tuning (SFT) as a standard approach. However, it often suffers\nfrom an overemphasis on English performance, a phenomenon that is especially\npronounced in data-constrained environments. To overcome these challenges, we\npropose \\textbf{Cross-Lingual Optimization (CLO)} that efficiently transfers an\nEnglish-centric LLM to a target language while preserving its English\ncapabilities. CLO utilizes publicly available English SFT data and a\ntranslation model to enable cross-lingual transfer. We conduct experiments\nusing five models on six languages, each possessing varying levels of resource.\nOur results show that CLO consistently outperforms SFT in both acquiring target\nlanguage proficiency and maintaining English performance. Remarkably, in\nlow-resource languages, CLO with only 3,200 samples surpasses SFT with 6,400\nsamples, demonstrating that CLO can achieve better performance with less data.\nFurthermore, we find that SFT is particularly sensitive to data quantity in\nmedium and low-resource languages, whereas CLO remains robust. Our\ncomprehensive analysis emphasizes the limitations of SFT and incorporates\nadditional training strategies in CLO to enhance efficiency.", "published": "2025-05-20 12:45:09", "link": "http://arxiv.org/abs/2505.14297v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs", "abstract": "The combination of pre-trained speech encoders with large language models has\nenabled the development of speech LLMs that can handle a wide range of spoken\nlanguage processing tasks. While these models are powerful and flexible, this\nvery flexibility may make them more vulnerable to adversarial attacks. To\nexamine the extent of this problem, in this work we investigate universal\nacoustic adversarial attacks on speech LLMs. Here a fixed, universal,\nadversarial audio segment is prepended to the original input audio. We\ninitially investigate attacks that cause the model to either produce no output\nor to perform a modified task overriding the original prompt. We then extend\nthe nature of the attack to be selective so that it activates only when\nspecific input attributes, such as a speaker gender or spoken language, are\npresent. Inputs without the targeted attribute should be unaffected, allowing\nfine-grained control over the model outputs. Our findings reveal critical\nvulnerabilities in Qwen2-Audio and Granite-Speech and suggest that similar\nspeech LLMs may be susceptible to universal adversarial attacks. This\nhighlights the need for more robust training strategies and improved resistance\nto adversarial attacks.", "published": "2025-05-20 12:35:59", "link": "http://arxiv.org/abs/2505.14286v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering", "abstract": "Large Language Models (LLMs) drive scientific question-answering on modern\nsearch engines, yet their evaluation robustness remains underexplored. We\nintroduce YESciEval, an open-source framework that combines fine-grained\nrubric-based assessment with reinforcement learning to mitigate optimism bias\nin LLM evaluators. We release multidisciplinary scienceQ&A datasets, including\nadversarial variants, with evaluation scores from multiple LLMs. Independent of\nproprietary models and human feedback, our approach enables scalable, cost-free\nevaluation. By advancing reliable LLM-as-a-judge models, this work supports AI\nalignment and fosters robust, transparent evaluation essential for scientific\ninquiry and artificial general intelligence.", "published": "2025-05-20 12:30:46", "link": "http://arxiv.org/abs/2505.14279v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Data-Efficient Hate Speech Detection via Cross-Lingual Nearest Neighbor Retrieval with Limited Labeled Data", "abstract": "Considering the importance of detecting hateful language, labeled hate speech\ndata is expensive and time-consuming to collect, particularly for low-resource\nlanguages. Prior work has demonstrated the effectiveness of cross-lingual\ntransfer learning and data augmentation in improving performance on tasks with\nlimited labeled data. To develop an efficient and scalable cross-lingual\ntransfer learning approach, we leverage nearest-neighbor retrieval to augment\nminimal labeled data in the target language, thereby enhancing detection\nperformance. Specifically, we assume access to a small set of labeled training\ninstances in the target language and use these to retrieve the most relevant\nlabeled examples from a large multilingual hate speech detection pool. We\nevaluate our approach on eight languages and demonstrate that it consistently\noutperforms models trained solely on the target language data. Furthermore, in\nmost cases, our method surpasses the current state-of-the-art. Notably, our\napproach is highly data-efficient, retrieving as small as 200 instances in some\ncases while maintaining superior performance. Moreover, it is scalable, as the\nretrieval pool can be easily expanded, and the method can be readily adapted to\nnew languages and tasks. We also apply maximum marginal relevance to mitigate\nredundancy and filter out highly similar retrieved instances, resulting in\nimprovements in some languages.", "published": "2025-05-20 12:25:33", "link": "http://arxiv.org/abs/2505.14272v1", "categories": ["cs.CL", "cs.CY", "cs.MM"], "primary_category": "cs.CL"}
{"title": "FAID: Fine-grained AI-generated Text Detection using Multi-task Auxiliary and Multi-level Contrastive Learning", "abstract": "The growing collaboration between humans and AI models in generative tasks\nhas introduced new challenges in distinguishing between human-written,\nAI-generated, and human-AI collaborative texts. In this work, we collect a\nmultilingual, multi-domain, multi-generator dataset FAIDSet. We further\nintroduce a fine-grained detection framework FAID to classify text into these\nthree categories, meanwhile identifying the underlying AI model family. Unlike\nexisting binary classifiers, FAID is built to capture both authorship and\nmodel-specific characteristics. Our method combines multi-level contrastive\nlearning with multi-task auxiliary classification to learn subtle stylistic\ncues. By modeling AI families as distinct stylistic entities, FAID offers\nimproved interpretability. We incorporate an adaptation to address\ndistributional shifts without retraining for unseen data. Experimental results\ndemonstrate that FAID outperforms several baseline approaches, particularly\nenhancing the generalization accuracy on unseen domains and new AI models. It\nprovide a potential solution for improving transparency and accountability in\nAI-assisted writing.", "published": "2025-05-20 12:23:31", "link": "http://arxiv.org/abs/2505.14271v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Think-J: Learning to Think for Generative LLM-as-a-Judge", "abstract": "LLM-as-a-Judge refers to the automatic modeling of preferences for responses\ngenerated by Large Language Models (LLMs), which is of significant importance\nfor both LLM evaluation and reward modeling. Although generative LLMs have made\nsubstantial progress in various tasks, their performance as LLM-Judge still\nfalls short of expectations. In this work, we propose Think-J, which improves\ngenerative LLM-as-a-Judge by learning how to think. We first utilized a small\namount of curated data to develop the model with initial judgment thinking\ncapabilities. Subsequently, we optimize the judgment thinking traces based on\nreinforcement learning (RL). We propose two methods for judgment thinking\noptimization, based on offline and online RL, respectively. The offline RL\nrequires training a critic model to construct positive and negative examples\nfor learning. The online method defines rule-based reward as feedback for\noptimization. Experimental results showed that our approach can significantly\nenhance the evaluation capability of generative LLM-Judge, surpassing both\ngenerative and classifier-based LLM-Judge without requiring extra human\nannotations.", "published": "2025-05-20 12:19:10", "link": "http://arxiv.org/abs/2505.14268v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AAPO: Enhance the Reasoning Capabilities of LLMs with Advantage Momentum", "abstract": "Reinforcement learning (RL) has emerged as an effective approach for\nenhancing the reasoning capabilities of large language models (LLMs),\nespecially in scenarios where supervised fine-tuning (SFT) falls short due to\nlimited chain-of-thought (CoT) data. Among RL-based post-training methods,\ngroup relative advantage estimation, as exemplified by Group Relative Policy\nOptimization (GRPO), has attracted considerable attention for eliminating the\ndependency on the value model, thereby simplifying training compared to\ntraditional approaches like Proximal Policy Optimization (PPO). However, we\nobserve that exsiting group relative advantage estimation method still suffers\nfrom training inefficiencies, particularly when the estimated advantage\napproaches zero. To address this limitation, we propose Advantage-Augmented\nPolicy Optimization (AAPO), a novel RL algorithm that optimizes the\ncross-entropy (CE) loss using advantages enhanced through a momentum-based\nestimation scheme. This approach effectively mitigates the inefficiencies\nassociated with group relative advantage estimation. Experimental results on\nmultiple mathematical reasoning benchmarks demonstrate the superior performance\nof AAPO.", "published": "2025-05-20 12:13:44", "link": "http://arxiv.org/abs/2505.14264v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "FuxiMT: Sparsifying Large Language Models for Chinese-Centric Multilingual Machine Translation", "abstract": "In this paper, we present FuxiMT, a novel Chinese-centric multilingual\nmachine translation model powered by a sparsified large language model (LLM).\nWe adopt a two-stage strategy to train FuxiMT. We first pre-train the model on\na massive Chinese corpus and then conduct multilingual fine-tuning on a large\nparallel dataset encompassing 65 languages. FuxiMT incorporates\nMixture-of-Experts (MoEs) and employs a curriculum learning strategy for robust\nperformance across various resource levels. Experimental results demonstrate\nthat FuxiMT significantly outperforms strong baselines, including\nstate-of-the-art LLMs and machine translation models, particularly under\nlow-resource scenarios. Furthermore, FuxiMT exhibits remarkable zero-shot\ntranslation capabilities for unseen language pairs, indicating its potential to\nbridge communication gaps where parallel data are scarce or unavailable.", "published": "2025-05-20 12:09:17", "link": "http://arxiv.org/abs/2505.14256v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TransBench: Benchmarking Machine Translation for Industrial-Scale Applications", "abstract": "Machine translation (MT) has become indispensable for cross-border\ncommunication in globalized industries like e-commerce, finance, and legal\nservices, with recent advancements in large language models (LLMs)\nsignificantly enhancing translation quality. However, applying general-purpose\nMT models to industrial scenarios reveals critical limitations due to\ndomain-specific terminology, cultural nuances, and stylistic conventions absent\nin generic benchmarks. Existing evaluation frameworks inadequately assess\nperformance in specialized contexts, creating a gap between academic benchmarks\nand real-world efficacy. To address this, we propose a three-level translation\ncapability framework: (1) Basic Linguistic Competence, (2) Domain-Specific\nProficiency, and (3) Cultural Adaptation, emphasizing the need for holistic\nevaluation across these dimensions. We introduce TransBench, a benchmark\ntailored for industrial MT, initially targeting international e-commerce with\n17,000 professionally translated sentences spanning 4 main scenarios and 33\nlanguage pairs. TransBench integrates traditional metrics (BLEU, TER) with\nMarco-MOS, a domain-specific evaluation model, and provides guidelines for\nreproducible benchmark construction. Our contributions include: (1) a\nstructured framework for industrial MT evaluation, (2) the first publicly\navailable benchmark for e-commerce translation, (3) novel metrics probing\nmulti-level translation quality, and (4) open-sourced evaluation tools. This\nwork bridges the evaluation gap, enabling researchers and practitioners to\nsystematically assess and enhance MT systems for industry-specific needs.", "published": "2025-05-20 11:54:58", "link": "http://arxiv.org/abs/2505.14244v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Technical Report on classification of literature related to children speech disorder", "abstract": "This technical report presents a natural language processing (NLP)-based\napproach for systematically classifying scientific literature on childhood\nspeech disorders. We retrieved and filtered 4,804 relevant articles published\nafter 2015 from the PubMed database using domain-specific keywords. After\ncleaning and pre-processing the abstracts, we applied two topic modeling\ntechniques - Latent Dirichlet Allocation (LDA) and BERTopic - to identify\nlatent thematic structures in the corpus. Our models uncovered 14 clinically\nmeaningful clusters, such as infantile hyperactivity and abnormal epileptic\nbehavior. To improve relevance and precision, we incorporated a custom stop\nword list tailored to speech pathology. Evaluation results showed that the LDA\nmodel achieved a coherence score of 0.42 and a perplexity of -7.5, indicating\nstrong topic coherence and predictive performance. The BERTopic model exhibited\na low proportion of outlier topics (less than 20%), demonstrating its capacity\nto classify heterogeneous literature effectively. These results provide a\nfoundation for automating literature reviews in speech-language pathology.", "published": "2025-05-20 11:52:17", "link": "http://arxiv.org/abs/2505.14242v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models", "abstract": "Large Language Models have demonstrated strong performance across a wide\nrange of tasks, but adapting them efficiently to new domains remains a key\nchallenge. Parameter-Efficient Fine-Tuning (PEFT) methods address this by\nintroducing lightweight, trainable modules while keeping most pre-trained\nweights fixed. The prevailing approach, LoRA, models updates using a low-rank\ndecomposition, but its expressivity is inherently constrained by the rank.\nRecent methods like HiRA aim to increase expressivity by incorporating a\nHadamard product with the frozen weights, but still rely on the structure of\nthe pre-trained model. We introduce ABBA, a new PEFT architecture that\nreparameterizes the update as a Hadamard product of two independently learnable\nlow-rank matrices. In contrast to prior work, ABBA fully decouples the update\nfrom the pre-trained weights, enabling both components to be optimized freely.\nThis leads to significantly higher expressivity under the same parameter\nbudget. We formally analyze ABBA's expressive capacity and validate its\nadvantages through matrix reconstruction experiments. Empirically, ABBA\nachieves state-of-the-art results on arithmetic and commonsense reasoning\nbenchmarks, consistently outperforming existing PEFT methods by a significant\nmargin across multiple models. Our code is publicly available at:\nhttps://github.com/CERT-Lab/abba.", "published": "2025-05-20 11:43:25", "link": "http://arxiv.org/abs/2505.14238v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mechanistic Fine-tuning for In-context Learning", "abstract": "In-context Learning (ICL) utilizes structured demonstration-query inputs to\ninduce few-shot learning on Language Models (LMs), which are not originally\npre-trained on ICL-style data. To bridge the gap between ICL and pre-training,\nsome approaches fine-tune LMs on large ICL-style datasets by an end-to-end\nparadigm with massive computational costs. To reduce such costs, in this paper,\nwe propose Attention Behavior Fine-Tuning (ABFT), utilizing the previous\nfindings on the inner mechanism of ICL, building training objectives on the\nattention scores instead of the final outputs, to force the attention scores to\nfocus on the correct label tokens presented in the context and mitigate\nattention scores from the wrong label tokens. Our experiments on 9 modern LMs\nand 8 datasets empirically find that ABFT outperforms in performance,\nrobustness, unbiasedness, and efficiency, with only around 0.01% data cost\ncompared to the previous methods. Moreover, our subsequent analysis finds that\nthe end-to-end training objective contains the ABFT objective, suggesting the\nimplicit bias of ICL-style data to the emergence of induction heads. Our work\ndemonstrates the possibility of controlling specific module sequences within\nLMs to improve their behavior, opening up the future application of mechanistic\ninterpretability.", "published": "2025-05-20 11:41:21", "link": "http://arxiv.org/abs/2505.14233v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"Haet Bhasha aur Diskrimineshun\": Phonetic Perturbations in Code-Mixed Hinglish to Red-Team LLMs", "abstract": "Large Language Models (LLMs) have become increasingly powerful, with\nmultilingual and multimodal capabilities improving by the day. These models are\nbeing evaluated through audits, alignment studies and red-teaming efforts to\nexpose model vulnerabilities towards generating harmful, biased and unfair\ncontent. Existing red-teaming efforts have previously focused on the English\nlanguage, using fixed template-based attacks; thus, models continue to be\nsusceptible to multilingual jailbreaking strategies, especially in the\nmultimodal context. In this study, we introduce a novel strategy that leverages\ncode-mixing and phonetic perturbations to jailbreak LLMs for both text and\nimage generation tasks. We also introduce two new jailbreak strategies that\nshow higher effectiveness than baseline strategies. Our work presents a method\nto effectively bypass safety filters in LLMs while maintaining interpretability\nby applying phonetic misspellings to sensitive words in code-mixed prompts. Our\nnovel prompts achieve a 99% Attack Success Rate for text generation and 78% for\nimage generation, with Attack Relevance Rate of 100% for text generation and\n95% for image generation when using the phonetically perturbed code-mixed\nprompts. Our interpretability experiments reveal that phonetic perturbations\nimpact word tokenization, leading to jailbreak success. Our study motivates\nincreasing the focus towards more generalizable safety alignment for\nmultilingual multimodal models, especially in real-world settings wherein\nprompts can have misspelt words.", "published": "2025-05-20 11:35:25", "link": "http://arxiv.org/abs/2505.14226v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforcement Learning vs. Distillation: Understanding Accuracy and Capability in LLM Reasoning", "abstract": "Recent studies have shown that reinforcement learning with verifiable rewards\n(RLVR) enhances overall accuracy but fails to improve capability, while\ndistillation can improve both. In this paper, we investigate the mechanisms\nbehind these phenomena. First, we demonstrate that RLVR does not improve\ncapability because it focuses on improving the accuracy of the less-difficult\nquestions to the detriment of the accuracy of the most difficult questions,\nthereby leading to no improvement in capability. Second, we find that RLVR does\nnot merely increase the success probability for the less difficult questions,\nbut in our small model settings produces quality responses that were absent in\nits output distribution before training. In addition, we show these responses\nare neither noticeably longer nor feature more reflection-related keywords,\nunderscoring the need for more reliable indicators of response quality. Third,\nwe show that while distillation reliably improves accuracy by learning strong\nreasoning patterns, it only improves capability when new knowledge is\nintroduced. Moreover, when distilling only with reasoning patterns and no new\nknowledge, the accuracy of the less-difficult questions improves to the\ndetriment of the most difficult questions, similar to RLVR. Together, these\nfindings offer a clearer understanding of how RLVR and distillation shape\nreasoning behavior in language models.", "published": "2025-05-20 11:22:34", "link": "http://arxiv.org/abs/2505.14216v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks", "abstract": "A question-answering (QA) system is to search suitable answers within a\nknowledge base. Current QA systems struggle with queries requiring complex\nreasoning or real-time knowledge integration. They are often supplemented with\nretrieval techniques on a data source such as Retrieval-Augmented Generation\n(RAG). However, RAG continues to face challenges in handling complex reasoning\nand logical connections between multiple sources of information. A novel\napproach for enhancing Large Language Models (LLMs) in knowledge-intensive QA\ntasks is presented through the automated generation of context-based QA pairs.\nThis methodology leverages LLMs to create fine-tuning data, reducing reliance\non human labelling and improving model comprehension and reasoning\ncapabilities. The proposed system includes an automated QA generator and a\nmodel fine-tuner, evaluated using perplexity, ROUGE, BLEU, and BERTScore.\nComprehensive experiments demonstrate improvements in logical coherence and\nfactual accuracy, with implications for developing adaptable Artificial\nIntelligence (AI) systems. Mistral-7b-v0.3 outperforms Llama-3-8b with BERT F1,\nBLEU, and ROUGE scores 0.858, 0.172, and 0.260 of for the LLM generated QA\npairs compared to scores of 0.836, 0.083, and 0.139 for the human annotated QA\npairs.", "published": "2025-05-20 11:16:29", "link": "http://arxiv.org/abs/2505.14212v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unraveling Interwoven Roles of Large Language Models in Authorship Privacy: Obfuscation, Mimicking, and Verification", "abstract": "Recent advancements in large language models (LLMs) have been fueled by large\nscale training corpora drawn from diverse sources such as websites, news\narticles, and books. These datasets often contain explicit user information,\nsuch as person names and addresses, that LLMs may unintentionally reproduce in\ntheir generated outputs. Beyond such explicit content, LLMs can also leak\nidentity revealing cues through implicit signals such as distinctive writing\nstyles, raising significant concerns about authorship privacy. There are three\nmajor automated tasks in authorship privacy, namely authorship obfuscation\n(AO), authorship mimicking (AM), and authorship verification (AV). Prior\nresearch has studied AO, AM, and AV independently. However, their interplays\nremain under explored, which leaves a major research gap, especially in the era\nof LLMs, where they are profoundly shaping how we curate and share user\ngenerated content, and the distinction between machine generated and human\nauthored text is also increasingly blurred. This work then presents the first\nunified framework for analyzing the dynamic relationships among LLM enabled AO,\nAM, and AV in the context of authorship privacy. We quantify how they interact\nwith each other to transform human authored text, examining effects at a single\npoint in time and iteratively over time. We also examine the role of\ndemographic metadata, such as gender, academic background, in modulating their\nperformances, inter-task dynamics, and privacy risks. All source code will be\npublicly available.", "published": "2025-05-20 10:52:12", "link": "http://arxiv.org/abs/2505.14195v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Safety Subspaces are Not Distinct: A Fine-Tuning Case Study", "abstract": "Large Language Models (LLMs) rely on safety alignment to produce socially\nacceptable responses. This is typically achieved through instruction tuning and\nreinforcement learning from human feedback. However, this alignment is known to\nbe brittle: further fine-tuning, even on benign or lightly contaminated data,\ncan degrade safety and reintroduce harmful behaviors. A growing body of work\nsuggests that alignment may correspond to identifiable geometric directions in\nweight space, forming subspaces that could, in principle, be isolated or\npreserved to defend against misalignment. In this work, we conduct a\ncomprehensive empirical study of this geometric perspective. We examine whether\nsafety-relevant behavior is concentrated in specific subspaces, whether it can\nbe separated from general-purpose learning, and whether harmfulness arises from\ndistinguishable patterns in internal representations. Across both parameter and\nactivation space, our findings are consistent: subspaces that amplify safe\nbehaviors also amplify unsafe ones, and prompts with different safety\nimplications activate overlapping representations. We find no evidence of a\nsubspace that selectively governs safety. These results challenge the\nassumption that alignment is geometrically localized. Rather than residing in\ndistinct directions, safety appears to emerge from entangled, high-impact\ncomponents of the model's broader learning dynamics. This suggests that\nsubspace-based defenses may face fundamental limitations and underscores the\nneed for alternative strategies to preserve alignment under continued training.\nWe corroborate these findings through multiple experiments on five open-source\nLLMs. Our code is publicly available at:\nhttps://github.com/CERT-Lab/safety-subspaces.", "published": "2025-05-20 10:41:49", "link": "http://arxiv.org/abs/2505.14185v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ThinkSwitcher: When to Think Hard, When to Think Fast", "abstract": "Large reasoning models (LRMs) excel at solving complex tasks by leveraging\nlong chain-of-thought (CoT) reasoning. However, this often leads to\noverthinking on simple tasks, resulting in unnecessary computational overhead.\nWe observe that LRMs inherently possess the capability for efficient short CoT\nreasoning, which can be reliably elicited through prompt design. To leverage\nthis capability, we propose ThinkSwitcher, a framework that enables a single\nLRM to dynamically switch between short and long CoT modes based on task\ncomplexity. ThinkSwitcher introduces a lightweight switching module trained\nwith supervision signals derived from the relative performance of each\nreasoning mode across tasks. Experiments on multiple reasoning benchmarks show\nthat ThinkSwitcher reduces computational cost by 20-30% while maintaining high\naccuracy on complex tasks. This demonstrates the effectiveness of ThinkSwitcher\nas a scalable and efficient solution for unified LRM deployment.", "published": "2025-05-20 10:40:41", "link": "http://arxiv.org/abs/2505.14183v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SlangDIT: Benchmarking LLMs in Interpretative Slang Translation", "abstract": "The challenge of slang translation lies in capturing context-dependent\nsemantic extensions, as slang terms often convey meanings beyond their literal\ninterpretation. While slang detection, explanation, and translation have been\nstudied as isolated tasks in the era of large language models (LLMs), their\nintrinsic interdependence remains underexplored. The main reason is lacking of\na benchmark where the two tasks can be a prerequisite for the third one, which\ncan facilitate idiomatic translation. In this paper, we introduce the\ninterpretative slang translation task (named SlangDIT) consisting of three\nsub-tasks: slang detection, cross-lingual slang explanation, and slang\ntranslation within the current context, aiming to generate more accurate\ntranslation with the help of slang detection and slang explanation. To this\nend, we construct a SlangDIT dataset, containing over 25k English-Chinese\nsentence pairs. Each source sentence mentions at least one slang term and is\nlabeled with corresponding cross-lingual slang explanation. Based on the\nbenchmark, we propose a deep thinking model, named SlangOWL. It firstly\nidentifies whether the sentence contains a slang, and then judges whether the\nslang is polysemous and analyze its possible meaning. Further, the SlangOWL\nprovides the best explanation of the slang term targeting on the current\ncontext. Finally, according to the whole thought, the SlangOWL offers a\nsuitable translation. Our experiments on LLMs (\\emph{e.g.}, Qwen2.5 and\nLLama-3.1), show that our deep thinking approach indeed enhances the\nperformance of LLMs where the proposed SLangOWL significantly surpasses the\nvanilla models and supervised fine-tuned models without thinking.", "published": "2025-05-20 10:37:34", "link": "http://arxiv.org/abs/2505.14181v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Abstractive Summarization of Scientific Papers Using Structure Information", "abstract": "Abstractive summarization of scientific papers has always been a research\nfocus, yet existing methods face two main challenges. First, most summarization\nmodels rely on Encoder-Decoder architectures that treat papers as sequences of\nwords, thus fail to fully capture the structured information inherent in\nscientific papers. Second, existing research often use keyword mapping or\nfeature engineering to identify the structural information, but these methods\nstruggle with the structural flexibility of scientific papers and lack\nrobustness across different disciplines. To address these challenges, we\npropose a two-stage abstractive summarization framework that leverages\nautomatic recognition of structural functions within scientific papers. In the\nfirst stage, we standardize chapter titles from numerous scientific papers and\nconstruct a large-scale dataset for structural function recognition. A\nclassifier is then trained to automatically identify the key structural\ncomponents (e.g., Background, Methods, Results, Discussion), which provides a\nfoundation for generating more balanced summaries. In the second stage, we\nemploy Longformer to capture rich contextual relationships across sections and\ngenerating context-aware summaries. Experiments conducted on two\ndomain-specific scientific paper summarization datasets demonstrate that our\nmethod outperforms advanced baselines, and generates more comprehensive\nsummaries. The code and dataset can be accessed at\nhttps://github.com/tongbao96/code-for-SFR-AS.", "published": "2025-05-20 10:34:45", "link": "http://arxiv.org/abs/2505.14179v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Training-Free Watermarking for Autoregressive Image Generation", "abstract": "Invisible image watermarking can protect image ownership and prevent\nmalicious misuse of visual generative models. However, existing generative\nwatermarking methods are mainly designed for diffusion models while\nwatermarking for autoregressive image generation models remains largely\nunderexplored. We propose IndexMark, a training-free watermarking framework for\nautoregressive image generation models. IndexMark is inspired by the redundancy\nproperty of the codebook: replacing autoregressively generated indices with\nsimilar indices produces negligible visual differences. The core component in\nIndexMark is a simple yet effective match-then-replace method, which carefully\nselects watermark tokens from the codebook based on token similarity, and\npromotes the use of watermark tokens through token replacement, thereby\nembedding the watermark without affecting the image quality. Watermark\nverification is achieved by calculating the proportion of watermark tokens in\ngenerated images, with precision further improved by an Index Encoder.\nFurthermore, we introduce an auxiliary validation scheme to enhance robustness\nagainst cropping attacks. Experiments demonstrate that IndexMark achieves\nstate-of-the-art performance in terms of image quality and verification\naccuracy, and exhibits robustness against various perturbations, including\ncropping, noises, Gaussian blur, random erasing, color jittering, and JPEG\ncompression.", "published": "2025-05-20 17:58:02", "link": "http://arxiv.org/abs/2505.14673v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings", "abstract": "Cross-modal embeddings form the foundation for multi-modal models. However,\nvisualization methods for interpreting cross-modal embeddings have been\nprimarily confined to traditional dimensionality reduction (DR) techniques like\nPCA and t-SNE. These DR methods primarily focus on feature distributions within\na single modality, whilst failing to incorporate metrics (e.g., CLIPScore)\nacross multiple modalities.This paper introduces AKRMap, a new DR technique\ndesigned to visualize cross-modal embeddings metric with enhanced accuracy by\nlearning kernel regression of the metric landscape in the projection space.\nSpecifically, AKRMap constructs a supervised projection network guided by a\npost-projection kernel regression loss, and employs adaptive generalized\nkernels that can be jointly optimized with the projection. This approach\nenables AKRMap to efficiently generate visualizations that capture complex\nmetric distributions, while also supporting interactive features such as zoom\nand overlay for deeper exploration. Quantitative experiments demonstrate that\nAKRMap outperforms existing DR methods in generating more accurate and\ntrustworthy visualizations. We further showcase the effectiveness of AKRMap in\nvisualizing and comparing cross-modal embeddings for text-to-image models. Code\nand demo are available at https://github.com/yilinye/AKRMap.", "published": "2025-05-20 17:52:03", "link": "http://arxiv.org/abs/2505.14664v1", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Abacus: A Cost-Based Optimizer for Semantic Operator Systems", "abstract": "LLMs enable an exciting new class of data processing applications over large\ncollections of unstructured documents. Several new programming frameworks have\nenabled developers to build these applications by composing them out of\nsemantic operators: a declarative set of AI-powered data transformations with\nnatural language specifications. These include LLM-powered maps, filters,\njoins, etc. used for document processing tasks such as information extraction,\nsummarization, and more. While systems of semantic operators have achieved\nstrong performance on benchmarks, they can be difficult to optimize. An\noptimizer for this setting must determine how to physically implement each\nsemantic operator in a way that optimizes the system globally. Existing\noptimizers are limited in the number of optimizations they can apply, and most\n(if not all) cannot optimize system quality, cost, or latency subject to\nconstraint(s) on the other dimensions. In this paper we present Abacus, an\nextensible, cost-based optimizer which searches for the best implementation of\na semantic operator system given a (possibly constrained) optimization\nobjective. Abacus estimates operator performance by leveraging a minimal set of\nvalidation examples and, if available, prior beliefs about operator\nperformance. We evaluate Abacus on document processing workloads in the\nbiomedical and legal domains (BioDEX; CUAD) and multi-modal question answering\n(MMQA). We demonstrate that systems optimized by Abacus achieve 18.7%-39.2%\nbetter quality and up to 23.6x lower cost and 4.2x lower latency than the next\nbest system.", "published": "2025-05-20 17:49:46", "link": "http://arxiv.org/abs/2505.14661v1", "categories": ["cs.DB", "cs.AI", "H.2.4; I.2.5"], "primary_category": "cs.DB"}
{"title": "Explainable AI for Securing Healthcare in IoT-Integrated 6G Wireless Networks", "abstract": "As healthcare systems increasingly adopt advanced wireless networks and\nconnected devices, securing medical applications has become critical. The\nintegration of Internet of Medical Things devices, such as robotic surgical\ntools, intensive care systems, and wearable monitors has enhanced patient care\nbut introduced serious security risks. Cyberattacks on these devices can lead\nto life threatening consequences, including surgical errors, equipment failure,\nand data breaches. While the ITU IMT 2030 vision highlights 6G's transformative\nrole in healthcare through AI and cloud integration, it also raises new\nsecurity concerns. This paper explores how explainable AI techniques like SHAP,\nLIME, and DiCE can uncover vulnerabilities, strengthen defenses, and improve\ntrust and transparency in 6G enabled healthcare. We support our approach with\nexperimental analysis and highlight promising results.", "published": "2025-05-20 17:46:09", "link": "http://arxiv.org/abs/2505.14659v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Cost-Augmented Monte Carlo Tree Search for LLM-Assisted Planning", "abstract": "While LLMs excel at open-ended reasoning, they often struggle with\ncost-sensitive planning, either treating all actions as having equal cost or\nfailing to stay within strict budgets. In this paper, we introduce\nCost-Augmented Monte Carlo Tree Search (CATS), a novel approach that brings\nexplicit cost-awareness into LLM-guided planning. Tight cost constraints push\nthe planner to quickly identify infeasible solutions, while looser constraints\nencourage optimization for minimal cost. We benchmark top LLMs such as GPT-4.1,\nClaude-3.7-Sonnet, and DeepSeek-R1, against our CATS planner to evaluate their\nperformance in cost-sensitive scenarios. Our experiments suggest that raw LLMs\nsuch as GPT-4.1 often falter under tight budgets, whereas CATS consistently\ndelivers strong performance, achieving higher task success rates and better\ncost efficiency. CATS provides an effective solution for budget-aware\ndecision-making by combining the reasoning power of LLMs with structured\nsearch.", "published": "2025-05-20 17:43:33", "link": "http://arxiv.org/abs/2505.14656v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation", "abstract": "Efficient creation of accurate and editable 3D CAD models is critical in\nengineering design, significantly impacting cost and time-to-market in product\ninnovation. Current manual workflows remain highly time-consuming and demand\nextensive user expertise. While recent developments in AI-driven CAD generation\nshow promise, existing models are limited by incomplete representations of CAD\noperations, inability to generalize to real-world images, and low output\naccuracy. This paper introduces CAD-Coder, an open-source Vision-Language Model\n(VLM) explicitly fine-tuned to generate editable CAD code (CadQuery Python)\ndirectly from visual input. Leveraging a novel dataset that we\ncreated--GenCAD-Code, consisting of over 163k CAD-model image and code\npairs--CAD-Coder outperforms state-of-the-art VLM baselines such as GPT-4.5 and\nQwen2.5-VL-72B, achieving a 100% valid syntax rate and the highest accuracy in\n3D solid similarity. Notably, our VLM demonstrates some signs of\ngeneralizability, successfully generating CAD code from real-world images and\nexecuting CAD operations unseen during fine-tuning. The performance and\nadaptability of CAD-Coder highlights the potential of VLMs fine-tuned on code\nto streamline CAD workflows for engineers and designers. CAD-Coder is publicly\navailable at: https://github.com/anniedoris/CAD-Coder.", "published": "2025-05-20 17:34:44", "link": "http://arxiv.org/abs/2505.14646v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Let LLMs Break Free from Overthinking via Self-Braking Tuning", "abstract": "Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have\nsignificantly enhanced their reasoning capabilities by generating longer chains\nof thought, demonstrating outstanding performance across a variety of tasks.\nHowever, this performance gain comes at the cost of a substantial increase in\nredundant reasoning during the generation process, leading to high\ncomputational overhead and exacerbating the issue of overthinking. Although\nnumerous existing approaches aim to address the problem of overthinking, they\noften rely on external interventions. In this paper, we propose a novel\nframework, Self-Braking Tuning (SBT), which tackles overthinking from the\nperspective of allowing the model to regulate its own reasoning process, thus\neliminating the reliance on external control mechanisms. We construct a set of\noverthinking identification metrics based on standard answers and design a\nsystematic method to detect redundant reasoning. This method accurately\nidentifies unnecessary steps within the reasoning trajectory and generates\ntraining signals for learning self-regulation behaviors. Building on this\nfoundation, we develop a complete strategy for constructing data with adaptive\nreasoning lengths and introduce an innovative braking prompt mechanism that\nenables the model to naturally learn when to terminate reasoning at an\nappropriate point. Experiments across mathematical benchmarks (AIME, AMC,\nMATH500, GSM8K) demonstrate that our method reduces token consumption by up to\n60% while maintaining comparable accuracy to unconstrained models.", "published": "2025-05-20 16:53:40", "link": "http://arxiv.org/abs/2505.14604v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards a Foundation Model for Communication Systems", "abstract": "Artificial Intelligence (AI) has demonstrated unprecedented performance\nacross various domains, and its application to communication systems is an\nactive area of research. While current methods focus on task-specific\nsolutions, the broader trend in AI is shifting toward large general models\ncapable of supporting multiple applications. In this work, we take a step\ntoward a foundation model for communication data--a transformer-based,\nmulti-modal model designed to operate directly on communication data. We\npropose methodologies to address key challenges, including tokenization,\npositional embedding, multimodality, variable feature sizes, and normalization.\nFurthermore, we empirically demonstrate that such a model can successfully\nestimate multiple features, including transmission rank, selected precoder,\nDoppler spread, and delay profile.", "published": "2025-05-20 16:52:11", "link": "http://arxiv.org/abs/2505.14603v1", "categories": ["cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.AI"}
{"title": "KIPPO: Koopman-Inspired Proximal Policy Optimization", "abstract": "Reinforcement Learning (RL) has made significant strides in various domains,\nand policy gradient methods like Proximal Policy Optimization (PPO) have gained\npopularity due to their balance in performance, training stability, and\ncomputational efficiency. These methods directly optimize policies through\ngradient-based updates. However, developing effective control policies for\nenvironments with complex and non-linear dynamics remains a challenge. High\nvariance in gradient estimates and non-convex optimization landscapes often\nlead to unstable learning trajectories. Koopman Operator Theory has emerged as\na powerful framework for studying non-linear systems through an\ninfinite-dimensional linear operator that acts on a higher-dimensional space of\nmeasurement functions. In contrast with their non-linear counterparts, linear\nsystems are simpler, more predictable, and easier to analyze. In this paper, we\npresent Koopman-Inspired Proximal Policy Optimization (KIPPO), which learns an\napproximately linear latent-space representation of the underlying system's\ndynamics while retaining essential features for effective policy learning. This\nis achieved through a Koopman-approximation auxiliary network that can be added\nto the baseline policy optimization algorithms without altering the\narchitecture of the core policy or value function. Extensive experimental\nresults demonstrate consistent improvements over the PPO baseline with 6-60%\nincreased performance while reducing variability by up to 91% when evaluated on\nvarious continuous control tasks.", "published": "2025-05-20 16:25:41", "link": "http://arxiv.org/abs/2505.14566v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Bellman operator convergence enhancements in reinforcement learning algorithms", "abstract": "This paper reviews the topological groundwork for the study of reinforcement\nlearning (RL) by focusing on the structure of state, action, and policy spaces.\nWe begin by recalling key mathematical concepts such as complete metric spaces,\nwhich form the foundation for expressing RL problems. By leveraging the Banach\ncontraction principle, we illustrate how the Banach fixed-point theorem\nexplains the convergence of RL algorithms and how Bellman operators, expressed\nas operators on Banach spaces, ensure this convergence. The work serves as a\nbridge between theoretical mathematics and practical algorithm design, offering\nnew approaches to enhance the efficiency of RL. In particular, we investigate\nalternative formulations of Bellman operators and demonstrate their impact on\nimproving convergence rates and performance in standard RL environments such as\nMountainCar, CartPole, and Acrobot. Our findings highlight how a deeper\nmathematical understanding of RL can lead to more effective algorithms for\ndecision-making problems.", "published": "2025-05-20 16:24:42", "link": "http://arxiv.org/abs/2505.14564v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification", "abstract": "Self-Supervised Learning (SSL) has led to considerable progress in Speaker\nVerification (SV). The standard framework uses same-utterance positive sampling\nand data-augmentation to generate anchor-positive pairs of the same speaker.\nThis is a major limitation, as this strategy primarily encodes channel\ninformation from the recording condition, shared by the anchor and positive. We\npropose a new positive sampling technique to address this bottleneck:\nSelf-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find\nan appropriate positive, i.e., of the same speaker identity but a different\nrecording condition, in the latent space using clustering assignments and a\nmemory queue of positive embeddings. SSPS improves SV performance for both\nSimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods\non VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by\nlowering intra-speaker variance, providing comparable performance to DINO-SSPS.", "published": "2025-05-20 16:19:34", "link": "http://arxiv.org/abs/2505.14561v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting", "abstract": "Weather forecasting is essential but remains computationally intensive and\nphysically incomplete in traditional numerical weather prediction (NWP)\nmethods. Deep learning (DL) models offer efficiency and accuracy but often\nignore physical laws, limiting interpretability and generalization. We propose\nPhyDL-NWP, a physics-guided deep learning framework that integrates physical\nequations with latent force parameterization into data-driven models. It\npredicts weather variables from arbitrary spatiotemporal coordinates, computes\nphysical terms via automatic differentiation, and uses a physics-informed loss\nto align predictions with governing dynamics. PhyDL-NWP enables resolution-free\ndownscaling by modeling weather as a continuous function and fine-tunes\npre-trained models with minimal overhead, achieving up to 170x faster inference\nwith only 55K parameters. Experiments show that PhyDL-NWP improves both\nforecasting performance and physical consistency.", "published": "2025-05-20 16:13:20", "link": "http://arxiv.org/abs/2505.14555v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Trustworthy Reputation Games and Applications to Proof-of-Reputation Blockchains", "abstract": "Reputation systems play an essential role in the Internet era, as they enable\npeople to decide whom to trust, by collecting and aggregating data about users'\nbehavior. Recently, several works proposed the use of reputation for the design\nand scalability improvement of decentralized (blockchain) ledgers; however,\nsuch systems are prone to manipulation and to our knowledge no game-theoretic\ntreatment exists that can support their economic robustness.\n  In this work we put forth a new model for the design of what we call, {\\em\ntrustworthy reputation systems}. Concretely, we describe a class of games,\nwhich we term {\\em trustworthy reputation games}, that enable a set of users to\nreport a function of their beliefs about the trustworthiness of each server in\na set -- i.e., their estimate of the probability that this server will behave\naccording to its specified strategy -- in a way that satisfies the following\nproperties:\n  1. It is $(\\epsilon$-)best response for any rational user in the game to play\na prescribed (truthful) strategy according to their true belief.\n  2. Assuming that the users' beliefs are not too far from the {\\em true}\ntrustworthiness of the servers, playing the above ($\\epsilon-$)Nash equilibrium\nallows anyone who observes the users' strategies to estimate the relative\ntrustworthiness of any two servers.\n  Our utilities and decoding function build on a connection between the well\nknown PageRank algorithm and the problem of trustworthiness discovery, which\ncan be of independent interest. Finally, we show how the above games are\nmotivated by and can be leveraged in proof-of-reputation (PoR) blockchains.", "published": "2025-05-20 16:06:25", "link": "http://arxiv.org/abs/2505.14551v1", "categories": ["cs.GT", "cs.AI", "cs.CR"], "primary_category": "cs.GT"}
{"title": "Can Large Language Models Really Recognize Your Name?", "abstract": "Large language models (LLMs) are increasingly being used to protect sensitive\nuser data. However, current LLM-based privacy solutions assume that these\nmodels can reliably detect personally identifiable information (PII),\nparticularly named entities. In this paper, we challenge that assumption by\nrevealing systematic failures in LLM-based privacy tasks. Specifically, we show\nthat modern LLMs regularly overlook human names even in short text snippets due\nto ambiguous contexts, which cause the names to be misinterpreted or\nmishandled. We propose AMBENCH, a benchmark dataset of seemingly ambiguous\nhuman names, leveraging the name regularity bias phenomenon, embedded within\nconcise text snippets along with benign prompt injections. Our experiments on\nmodern LLMs tasked to detect PII as well as specialized tools show that recall\nof ambiguous names drops by 20--40% compared to more recognizable names.\nFurthermore, ambiguous human names are four times more likely to be ignored in\nsupposedly privacy-preserving summaries generated by LLMs when benign prompt\ninjections are present. These findings highlight the underexplored risks of\nrelying solely on LLMs to safeguard user privacy and underscore the need for a\nmore systematic investigation into their privacy failure modes.", "published": "2025-05-20 16:05:05", "link": "http://arxiv.org/abs/2505.14549v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study", "abstract": "Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges.", "published": "2025-05-20 15:59:44", "link": "http://arxiv.org/abs/2505.14544v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "A Logic of General Attention Using Edge-Conditioned Event Models (Extended Version)", "abstract": "In this work, we present the first general logic of attention. Attention is a\npowerful cognitive ability that allows agents to focus on potentially complex\ninformation, such as logically structured propositions, higher-order beliefs,\nor what other agents pay attention to. This ability is a strength, as it helps\nto ignore what is irrelevant, but it can also introduce biases when some types\nof information or agents are systematically ignored. Existing dynamic epistemic\nlogics for attention cannot model such complex attention scenarios, as they\nonly model attention to atomic formulas. Additionally, such logics quickly\nbecome cumbersome, as their size grows exponentially in the number of agents\nand announced literals. Here, we introduce a logic that overcomes both\nlimitations. First, we generalize edge-conditioned event models, which we show\nto be as expressive as standard event models yet exponentially more succinct\n(generalizing both standard event models and generalized arrow updates).\nSecond, we extend attention to arbitrary formulas, allowing agents to also\nattend to other agents' beliefs or attention. Our work treats attention as a\nmodality, like belief or awareness. We introduce attention principles that\nimpose closure properties on that modality and that can be used in its\naxiomatization. Throughout, we illustrate our framework with examples of AI\nagents reasoning about human attentional biases, demonstrating how such agents\ncan discover attentional biases.", "published": "2025-05-20 15:56:34", "link": "http://arxiv.org/abs/2505.14539v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Energy-Efficient Deep Reinforcement Learning with Spiking Transformers", "abstract": "Agent-based Transformers have been widely adopted in recent reinforcement\nlearning advances due to their demonstrated ability to solve complex tasks.\nHowever, the high computational complexity of Transformers often results in\nsignificant energy consumption, limiting their deployment in real-world\nautonomous systems. Spiking neural networks (SNNs), with their biologically\ninspired structure, offer an energy-efficient alternative for machine learning.\nIn this paper, a novel Spike-Transformer Reinforcement Learning (STRL)\nalgorithm that combines the energy efficiency of SNNs with the powerful\ndecision-making capabilities of reinforcement learning is developed.\nSpecifically, an SNN using multi-step Leaky Integrate-and-Fire (LIF) neurons\nand attention mechanisms capable of processing spatio-temporal patterns over\nmultiple time steps is designed. The architecture is further enhanced with\nstate, action, and reward encodings to create a Transformer-like structure\noptimized for reinforcement learning tasks. Comprehensive numerical experiments\nconducted on state-of-the-art benchmarks demonstrate that the proposed SNN\nTransformer achieves significantly improved policy performance compared to\nconventional agent-based Transformers. With both enhanced energy efficiency and\npolicy optimality, this work highlights a promising direction for deploying\nbio-inspired, low-cost machine learning models in complex real-world\ndecision-making scenarios.", "published": "2025-05-20 15:52:43", "link": "http://arxiv.org/abs/2505.14533v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "NavBench: A Unified Robotics Benchmark for Reinforcement Learning-Based Autonomous Navigation", "abstract": "Autonomous robots must navigate and operate in diverse environments, from\nterrestrial and aquatic settings to aerial and space domains. While\nReinforcement Learning (RL) has shown promise in training policies for specific\nautonomous robots, existing benchmarks are often constrained to unique\nplatforms, limiting generalization and fair comparisons across different\nmobility systems. In this paper, we present NavBench, a multi-domain benchmark\nfor training and evaluating RL-based navigation policies across diverse robotic\nplatforms and operational environments. Built on IsaacLab, our framework\nstandardizes task definitions, enabling different robots to tackle various\nnavigation challenges without the need for ad-hoc task redesigns or custom\nevaluation metrics. Our benchmark addresses three key challenges: (1) Unified\ncross-medium benchmarking, enabling direct evaluation of diverse actuation\nmethods (thrusters, wheels, water-based propulsion) in realistic environments;\n(2) Scalable and modular design, facilitating seamless robot-task\ninterchangeability and reproducible training pipelines; and (3) Robust\nsim-to-real validation, demonstrated through successful policy transfer to\nmultiple real-world robots, including a satellite robotic simulator, an\nunmanned surface vessel, and a wheeled ground vehicle. By ensuring consistency\nbetween simulation and real-world deployment, NavBench simplifies the\ndevelopment of adaptable RL-based navigation strategies. Its modular design\nallows researchers to easily integrate custom robots and tasks by following the\nframework's predefined templates, making it accessible for a wide range of\napplications. Our code is publicly available at NavBench.", "published": "2025-05-20 15:48:23", "link": "http://arxiv.org/abs/2505.14526v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Guarded Query Routing for Large Language Models", "abstract": "Query routing, the task to route user queries to different large language\nmodel (LLM) endpoints, can be considered as a text classification problem.\nHowever, out-of-distribution queries must be handled properly, as those could\nbe questions about unrelated domains, queries in other languages, or even\ncontain unsafe text. Here, we thus study a \\emph{guarded} query routing\nproblem, for which we first introduce the Guarded Query Routing Benchmark\n(GQR-Bench), which covers three exemplary target domains (law, finance, and\nhealthcare), and seven datasets to test robustness against out-of-distribution\nqueries. We then use GQR-Bench to contrast the effectiveness and efficiency of\nLLM-based routing mechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B),\nstandard LLM-based guardrail approaches (LlamaGuard and NVIDIA NeMo\nGuardrails), continuous bag-of-words classifiers (WideMLP, fastText), and\ntraditional machine learning models (SVM, XGBoost). Our results show that\nWideMLP, enhanced with out-of-domain detection capabilities, yields the best\ntrade-off between accuracy (88\\%) and speed (<4ms). The embedding-based\nfastText excels at speed (<1ms) with acceptable accuracy (80\\%), whereas LLMs\nyield the highest accuracy (91\\%) but are comparatively slow (62ms for local\nLlama-3.1:8B and 669ms for remote GPT-4o-mini calls). Our findings challenge\nthe automatic reliance on LLMs for (guarded) query routing and provide concrete\nrecommendations for practical applications. GQR-Bench will be released as a\nPython package -- \\texttt{gqr}.", "published": "2025-05-20 15:46:59", "link": "http://arxiv.org/abs/2505.14524v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Latent Flow Transformer", "abstract": "Transformers, the standard implementation for large language models (LLMs),\ntypically consist of tens to hundreds of discrete layers. While more layers can\nlead to better performance, this approach has been challenged as far from\nefficient, especially given the superiority of continuous layers demonstrated\nby diffusion and flow-based models for image generation. We propose the Latent\nFlow Transformer (LFT), which replaces a block of layers with a single learned\ntransport operator trained via flow matching, offering significant compression\nwhile maintaining compatibility with the original architecture. Additionally,\nwe address the limitations of existing flow-based methods in \\textit{preserving\ncoupling} by introducing the Flow Walking (FW) algorithm. On the Pythia-410M\nmodel, LFT trained with flow matching compresses 6 of 24 layers and outperforms\ndirectly skipping 2 layers (KL Divergence of LM logits at 0.407 vs. 0.529),\ndemonstrating the feasibility of this design. When trained with FW, LFT further\ndistills 12 layers into one while reducing the KL to 0.736 surpassing that from\nskipping 3 layers (0.932), significantly narrowing the gap between\nautoregressive and flow-based generation paradigms.", "published": "2025-05-20 15:41:05", "link": "http://arxiv.org/abs/2505.14513v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BACON: A fully explainable AI model with graded logic for decision making problems", "abstract": "As machine learning models and autonomous agents are increasingly deployed in\nhigh-stakes, real-world domains such as healthcare, security, finance, and\nrobotics, the need for transparent and trustworthy explanations has become\ncritical. To ensure end-to-end transparency of AI decisions, we need models\nthat are not only accurate but also fully explainable and human-tunable. We\nintroduce BACON, a novel framework for automatically training explainable AI\nmodels for decision making problems using graded logic. BACON achieves high\npredictive accuracy while offering full structural transparency and precise,\nlogic-based symbolic explanations, enabling effective human-AI collaboration\nand expert-guided refinement. We evaluate BACON with a diverse set of\nscenarios: classic Boolean approximation, Iris flower classification, house\npurchasing decisions and breast cancer diagnosis. In each case, BACON provides\nhigh-performance models while producing compact, human-verifiable decision\nlogic. These results demonstrate BACON's potential as a practical and\nprincipled approach for delivering crisp, trustworthy explainable AI.", "published": "2025-05-20 15:39:05", "link": "http://arxiv.org/abs/2505.14510v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "How Managers Perceive AI-Assisted Conversational Training for Workplace Communication", "abstract": "Effective workplace communication is essential for managerial success, yet\nmany managers lack access to tailored and sustained training. Although\nAI-assisted communication systems may offer scalable training solutions, little\nis known about how managers envision the role of AI in helping them improve\ntheir communication skills. To investigate this, we designed a conversational\nrole-play system, CommCoach, as a functional probe to understand how managers\nanticipate using AI to practice their communication skills. Through\nsemi-structured interviews, participants emphasized the value of adaptive,\nlow-risk simulations for practicing difficult workplace conversations. They\nalso highlighted opportunities, including human-AI teaming, transparent and\ncontext-aware feedback, and greater control over AI-generated personas.\nAI-assisted communication training should balance personalization, structured\nlearning objectives, and adaptability to different user styles and contexts.\nHowever, achieving this requires carefully navigating tensions between adaptive\nand consistent AI feedback, realism and potential bias, and the open-ended\nnature of AI conversations versus structured workplace discourse.", "published": "2025-05-20 14:51:27", "link": "http://arxiv.org/abs/2505.14452v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "RefiDiff: Refinement-Aware Diffusion for Efficient Missing Data Imputation", "abstract": "Missing values in high-dimensional, mixed-type datasets pose significant\nchallenges for data imputation, particularly under Missing Not At Random (MNAR)\nmechanisms. Existing methods struggle to integrate local and global data\ncharacteristics, limiting performance in MNAR and high-dimensional settings. We\npropose an innovative framework, RefiDiff, combining local machine learning\npredictions with a novel Mamba-based denoising network capturing\ninterrelationships among distant features and samples. Our approach leverages\npre-refinement for initial warm-up imputations and post-refinement to polish\nresults, enhancing stability and accuracy. By encoding mixed-type data into\nunified tokens, RefiDiff enables robust imputation without architectural or\nhyperparameter tuning. RefiDiff outperforms state-of-the-art (SOTA) methods\nacross missing-value settings, excelling in MNAR with a 4x faster training time\nthan SOTA DDPM-based approaches. Extensive evaluations on nine real-world\ndatasets demonstrate its robustness, scalability, and effectiveness in handling\ncomplex missingness patterns.", "published": "2025-05-20 14:51:07", "link": "http://arxiv.org/abs/2505.14451v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Choosing a Model, Shaping a Future: Comparing LLM Perspectives on Sustainability and its Relationship with AI", "abstract": "As organizations increasingly rely on AI systems for decision support in\nsustainability contexts, it becomes critical to understand the inherent biases\nand perspectives embedded in Large Language Models (LLMs). This study\nsystematically investigates how five state-of-the-art LLMs -- Claude, DeepSeek,\nGPT, LLaMA, and Mistral - conceptualize sustainability and its relationship\nwith AI. We administered validated, psychometric sustainability-related\nquestionnaires - each 100 times per model -- to capture response patterns and\nvariability. Our findings revealed significant inter-model differences: For\nexample, GPT exhibited skepticism about the compatibility of AI and\nsustainability, whereas LLaMA demonstrated extreme techno-optimism with perfect\nscores for several Sustainable Development Goals (SDGs). Models also diverged\nin attributing institutional responsibility for AI and sustainability\nintegration, a results that holds implications for technology governance\napproaches. Our results demonstrate that model selection could substantially\ninfluence organizational sustainability strategies, highlighting the need for\nawareness of model-specific biases when deploying LLMs for\nsustainability-related decision-making.", "published": "2025-05-20 14:41:56", "link": "http://arxiv.org/abs/2505.14435v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Interpretable Neural System Dynamics: Combining Deep Learning with System Dynamics Modeling to Support Critical Applications", "abstract": "The objective of this proposal is to bridge the gap between Deep Learning\n(DL) and System Dynamics (SD) by developing an interpretable neural system\ndynamics framework. While DL excels at learning complex models and making\naccurate predictions, it lacks interpretability and causal reliability.\nTraditional SD approaches, on the other hand, provide transparency and causal\ninsights but are limited in scalability and require extensive domain knowledge.\nTo overcome these limitations, this project introduces a Neural System Dynamics\npipeline, integrating Concept-Based Interpretability, Mechanistic\nInterpretability, and Causal Machine Learning. This framework combines the\npredictive power of DL with the interpretability of traditional SD models,\nresulting in both causal reliability and scalability. The efficacy of the\nproposed pipeline will be validated through real-world applications of the\nEU-funded AutoMoTIF project, which is focused on autonomous multimodal\ntransportation systems. The long-term goal is to collect actionable insights\nthat support the integration of explainability and safety in autonomous\nsystems.", "published": "2025-05-20 14:38:39", "link": "http://arxiv.org/abs/2505.14428v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SCOPE: Compress Mathematical Reasoning Steps for Efficient Automated Process Annotation", "abstract": "Process Reward Models (PRMs) have demonstrated promising results in\nmathematical reasoning, but existing process annotation approaches, whether\nthrough human annotations or Monte Carlo simulations, remain computationally\nexpensive. In this paper, we introduce Step COmpression for Process Estimation\n(SCOPE), a novel compression-based approach that significantly reduces\nannotation costs. We first translate natural language reasoning steps into code\nand normalize them through Abstract Syntax Tree, then merge equivalent steps to\nconstruct a prefix tree. Unlike simulation-based methods that waste numerous\nsamples on estimation, SCOPE leverages a compression-based prefix tree where\neach root-to-leaf path serves as a training sample, reducing the complexity\nfrom $O(NMK)$ to $O(N)$. We construct a large-scale dataset containing 196K\nsamples with only 5% of the computational resources required by previous\nmethods. Empirical results demonstrate that PRMs trained on our dataset\nconsistently outperform existing automated annotation approaches on both\nBest-of-N strategy and ProcessBench.", "published": "2025-05-20 14:31:15", "link": "http://arxiv.org/abs/2505.14419v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning", "abstract": "Recent advances in reasoning language models have witnessed a paradigm shift\nfrom short to long CoT pattern. Given the substantial computational cost of\nrollouts in long CoT models, maximizing the utility of fixed training datasets\nbecomes crucial. Our analysis reveals that negative responses contain valuable\ncomponents such as self-reflection and error-correction steps, yet primary\nexisting methods either completely discard negative samples (RFT) or apply\nequal penalization across all tokens (RL), failing to leverage these potential\nlearning signals. In light of this, we propose Behavior Constrained Policy\nGradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline\nRL framework that encompasses three stages: 1) sample segmentation, 2)\nconsensus-based step correctness assessment combining LLM and PRM judgers, and\n3) policy optimization with NSA designed to effectively mine positive steps\nwithin negative samples. Experimental results show that BCPG-NSA outperforms\nbaselines on several challenging math/coding reasoning benchmarks using the\nsame training dataset, achieving improved sample efficiency and demonstrating\nrobustness and scalability when extended to multiple iterations.", "published": "2025-05-20 14:16:49", "link": "http://arxiv.org/abs/2505.14403v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Knowledge Graph Based Repository-Level Code Generation", "abstract": "Recent advancements in Large Language Models (LLMs) have transformed code\ngeneration from natural language queries. However, despite their extensive\nknowledge and ability to produce high-quality code, LLMs often struggle with\ncontextual accuracy, particularly in evolving codebases. Current code search\nand retrieval methods frequently lack robustness in both the quality and\ncontextual relevance of retrieved results, leading to suboptimal code\ngeneration. This paper introduces a novel knowledge graph-based approach to\nimprove code search and retrieval leading to better quality of code generation\nin the context of repository-level tasks. The proposed approach represents code\nrepositories as graphs, capturing structural and relational information for\nenhanced context-aware code generation. Our framework employs a hybrid approach\nfor code retrieval to improve contextual relevance, track inter-file modular\ndependencies, generate more robust code and ensure consistency with the\nexisting codebase. We benchmark the proposed approach on the Evolutionary Code\nBenchmark (EvoCodeBench) dataset, a repository-level code generation benchmark,\nand demonstrate that our method significantly outperforms the baseline\napproach. These findings suggest that knowledge graph based code generation\ncould advance robust, context-sensitive coding assistance tools.", "published": "2025-05-20 14:13:59", "link": "http://arxiv.org/abs/2505.14394v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Beyond the First Error: Process Reward Models for Reflective Mathematical Reasoning", "abstract": "Many studies focus on data annotation techniques for training effective PRMs.\nHowever, current methods encounter a significant issue when applied to long CoT\nreasoning processes: they tend to focus solely on the first incorrect step and\nall preceding steps, assuming that all subsequent steps are incorrect. These\nmethods overlook the unique self-correction and reflection mechanisms inherent\nin long CoT, where correct reasoning steps may still occur after initial\nreasoning mistakes. To address this issue, we propose a novel data annotation\nmethod for PRMs specifically designed to score the long CoT reasoning process.\nGiven that under the reflection pattern, correct and incorrect steps often\nalternate, we introduce the concepts of Error Propagation and Error Cessation,\nenhancing PRMs' ability to identify both effective self-correction behaviors\nand reasoning based on erroneous steps. Leveraging an LLM-based judger for\nannotation, we collect 1.7 million data samples to train a 7B PRM and evaluate\nit at both solution and step levels. Experimental results demonstrate that\ncompared to existing open-source PRMs and PRMs trained on open-source datasets,\nour PRM achieves superior performance across various metrics, including search\nguidance, BoN, and F1 scores. Compared to widely used MC-based annotation\nmethods, our annotation approach not only achieves higher data efficiency but\nalso delivers superior performance. Detailed analysis is also conducted to\ndemonstrate the stability and generalizability of our method.", "published": "2025-05-20 14:12:05", "link": "http://arxiv.org/abs/2505.14391v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation", "abstract": "With the increasing adoption of Large Language Models (LLMs) and\nVision-Language Models (VLMs), rich document analysis technologies for\napplications like Retrieval-Augmented Generation (RAG) and visual RAG are\ngaining significant attention. Recent research indicates that using VLMs can\nachieve better RAG performance, but processing rich documents still remains a\nchallenge since a single page contains large amounts of information. In this\npaper, we present SCAN (\\textbf{S}emanti\\textbf{C} Document Layout\n\\textbf{AN}alysis), a novel approach enhancing both textual and visual\nRetrieval-Augmented Generation (RAG) systems working with visually rich\ndocuments. It is a VLM-friendly approach that identifies document components\nwith appropriate semantic granularity, balancing context preservation with\nprocessing efficiency. SCAN uses a coarse-grained semantic approach that\ndivides documents into coherent regions covering continuous components. We\ntrained the SCAN model by fine-tuning object detection models with\nsophisticated annotation datasets. Our experimental results across English and\nJapanese datasets demonstrate that applying SCAN improves end-to-end textual\nRAG performance by up to 9.0\\% and visual RAG performance by up to 6.4\\%,\noutperforming conventional approaches and even commercial document processing\nsolutions.", "published": "2025-05-20 14:03:24", "link": "http://arxiv.org/abs/2505.14381v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "When Bias Backfires: The Modulatory Role of Counterfactual Explanations on the Adoption of Algorithmic Bias in XAI-Supported Human Decision-Making", "abstract": "Although the integration of artificial intelligence (AI) into everyday tasks\nimproves efficiency and objectivity, it also risks transmitting bias to human\ndecision-making. In this study, we conducted a controlled experiment that\nsimulated hiring decisions to examine how biased AI recommendations - augmented\nwith or without counterfactual explanations - influence human judgment over\ntime. Participants, acting as hiring managers, completed 60 decision trials\ndivided into a baseline phase without AI, followed by a phase with biased (X)AI\nrecommendations (favoring either male or female candidates), and a final\npost-interaction phase without AI. Our results indicate that the participants\nfollowed the AI recommendations 70% of the time when the qualifications of the\ngiven candidates were comparable. Yet, only a fraction of participants detected\nthe gender bias (8 out of 294). Crucially, exposure to biased AI altered\nparticipants' inherent preferences: in the post-interaction phase,\nparticipants' independent decisions aligned with the bias when no\ncounterfactual explanations were provided before, but reversed the bias when\nexplanations were given. Reported trust did not differ significantly across\nconditions. Confidence varied throughout the study phases after exposure to\nmale-biased AI, indicating nuanced effects of AI bias on decision certainty.\nOur findings point to the importance of calibrating XAI to avoid unintended\nbehavioral shifts in order to safeguard equitable decision-making and prevent\nthe adoption of algorithmic bias.", "published": "2025-05-20 14:00:28", "link": "http://arxiv.org/abs/2505.14377v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds", "abstract": "We present a conceptual framework for training Vision-Language Models (VLMs)\nto perform Visual Perspective Taking (VPT), a core capability for embodied\ncognition essential for Human-Robot Interaction (HRI). As a first step toward\nthis goal, we introduce a synthetic dataset, generated in NVIDIA Omniverse,\nthat enables supervised learning for spatial reasoning tasks. Each instance\nincludes an RGB image, a natural language description, and a ground-truth 4X4\ntransformation matrix representing object pose. We focus on inferring Z-axis\ndistance as a foundational skill, with future extensions targeting full 6\nDegrees Of Freedom (DOFs) reasoning. The dataset is publicly available to\nsupport further research. This work serves as a foundational step toward\nembodied AI systems capable of spatial understanding in interactive human-robot\nscenarios.", "published": "2025-05-20 13:49:09", "link": "http://arxiv.org/abs/2505.14366v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Upgrading Democracies with Fairer Voting Methods", "abstract": "Voting methods are instrumental design element of democracies. Citizens use\nthem to express and aggregate their preferences to reach a collective decision.\nHowever, voting outcomes can be as sensitive to voting rules as they are to\npeople's voting choices. Despite the significance and inter-disciplinary\nscientific progress on voting methods, several democracies keep relying on\noutdated voting methods that do not fit modern, pluralistic societies well,\nwhile lacking social innovation. Here, we demonstrate how one can upgrade\nreal-world democracies, namely by using alternative preferential voting methods\nsuch as cumulative voting and the method of equal shares designed for a\nproportional representation of voters' preferences. By rigorously assessing a\nnew participatory budgeting approach applied in the city of Aarau, Switzerland,\nwe unravel the striking voting outcomes of fair voting methods: more winning\nprojects with the same budget and broader geographic and preference\nrepresentation of citizens by the elected projects, in particular for voters\nwho used to be under-represented, while promoting novel project ideas. We\nprovide profound causal evidence showing that citizens prefer proportional\nvoting methods, which possess strong legitimacy without the need of very\ntechnical specialized explanations. We also reveal strong underlying democratic\nvalues exhibited by citizens who support fair voting methods such as altruism\nand compromise. These findings come with a global momentum to unleash a new and\nlong-awaited participation blueprint of how to upgrade democracies.", "published": "2025-05-20 13:31:43", "link": "http://arxiv.org/abs/2505.14349v1", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC", "cs.MA"], "primary_category": "cs.CY"}
{"title": "Enhancing Classification with Semi-Supervised Deep Learning Using Distance-Based Sample Weights", "abstract": "Recent advancements in semi-supervised deep learning have introduced\neffective strategies for leveraging both labeled and unlabeled data to improve\nclassification performance. This work proposes a semi-supervised framework that\nutilizes a distance-based weighting mechanism to prioritize critical training\nsamples based on their proximity to test data. By focusing on the most\ninformative examples, the method enhances model generalization and robustness,\nparticularly in challenging scenarios with noisy or imbalanced datasets.\nBuilding on techniques such as uncertainty consistency and graph-based\nrepresentations, the approach addresses key challenges of limited labeled data\nwhile maintaining scalability. Experiments on twelve benchmark datasets\ndemonstrate significant improvements across key metrics, including accuracy,\nprecision, and recall, consistently outperforming existing methods. This\nframework provides a robust and practical solution for semi-supervised\nlearning, with potential applications in domains such as healthcare and\nsecurity where data limitations pose significant challenges.", "published": "2025-05-20 13:29:04", "link": "http://arxiv.org/abs/2505.14345v1", "categories": ["cs.LG", "cs.AI", "68T05, 62H30", "I.2.6; I.5.1; I.5.4"], "primary_category": "cs.LG"}
{"title": "Replace in Translation: Boost Concept Alignment in Counterfactual Text-to-Image", "abstract": "Text-to-Image (T2I) has been prevalent in recent years, with most common\ncondition tasks having been optimized nicely. Besides, counterfactual\nText-to-Image is obstructing us from a more versatile AIGC experience. For\nthose scenes that are impossible to happen in real world and anti-physics, we\nshould spare no efforts in increasing the factual feel, which means\nsynthesizing images that people think very likely to be happening, and concept\nalignment, which means all the required objects should be in the same frame. In\nthis paper, we focus on concept alignment. As controllable T2I models have\nachieved satisfactory performance for real applications, we utilize this\ntechnology to replace the objects in a synthesized image in latent space\nstep-by-step to change the image from a common scene to a counterfactual scene\nto meet the prompt. We propose a strategy to instruct this replacing process,\nwhich is called as Explicit Logical Narrative Prompt (ELNP), by using the newly\nSoTA language model DeepSeek to generate the instructions. Furthermore, to\nevaluate models' performance in counterfactual T2I, we design a metric to\ncalculate how many required concepts in the prompt can be covered averagely in\nthe synthesized images. The extensive experiments and qualitative comparisons\ndemonstrate that our strategy can boost the concept alignment in counterfactual\nT2I.", "published": "2025-05-20 13:27:52", "link": "http://arxiv.org/abs/2505.14341v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Handloom Design Generation Using Generative Networks", "abstract": "This paper proposes deep learning techniques of generating designs for\nclothing, focused on handloom fabric and discusses the associated challenges\nalong with its application. The capability of generative neural network models\nin understanding artistic designs and synthesizing those is not yet explored\nwell. In this work, multiple methods are employed incorporating the current\nstate of the art generative models and style transfer algorithms to study and\nobserve their performance for the task. The results are then evaluated through\nuser score. This work also provides a new dataset NeuralLoom for the task of\nthe design generation.", "published": "2025-05-20 13:16:55", "link": "http://arxiv.org/abs/2505.14330v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Exploring Jailbreak Attacks on LLMs through Intent Concealment and Diversion", "abstract": "Although large language models (LLMs) have achieved remarkable advancements,\ntheir security remains a pressing concern. One major threat is jailbreak\nattacks, where adversarial prompts bypass model safeguards to generate harmful\nor objectionable content. Researchers study jailbreak attacks to understand\nsecurity and robustness of LLMs. However, existing jailbreak attack methods\nface two main challenges: (1) an excessive number of iterative queries, and (2)\npoor generalization across models. In addition, recent jailbreak evaluation\ndatasets focus primarily on question-answering scenarios, lacking attention to\ntext generation tasks that require accurate regeneration of toxic content. To\ntackle these challenges, we propose two contributions: (1) ICE, a novel\nblack-box jailbreak method that employs Intent Concealment and divErsion to\neffectively circumvent security constraints. ICE achieves high attack success\nrates (ASR) with a single query, significantly improving efficiency and\ntransferability across different models. (2) BiSceneEval, a comprehensive\ndataset designed for assessing LLM robustness in question-answering and\ntext-generation tasks. Experimental results demonstrate that ICE outperforms\nexisting jailbreak techniques, revealing critical vulnerabilities in current\ndefense mechanisms. Our findings underscore the necessity of a hybrid security\nstrategy that integrates predefined security mechanisms with real-time semantic\ndecomposition to enhance the security of LLMs.", "published": "2025-05-20 13:03:15", "link": "http://arxiv.org/abs/2505.14316v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "MultiTab: A Comprehensive Benchmark Suite for Multi-Dimensional Evaluation in Tabular Domains", "abstract": "Despite the widespread use of tabular data in real-world applications, most\nbenchmarks rely on average-case metrics, which fail to reveal how model\nbehavior varies across diverse data regimes. To address this, we propose\nMultiTab, a benchmark suite and evaluation framework for multi-dimensional,\ndata-aware analysis of tabular learning algorithms. Rather than comparing\nmodels only in aggregate, MultiTab categorizes 196 publicly available datasets\nalong key data characteristics, including sample size, label imbalance, and\nfeature interaction, and evaluates 13 representative models spanning a range of\ninductive biases. Our analysis shows that model performance is highly sensitive\nto such regimes: for example, models using sample-level similarity excel on\ndatasets with large sample sizes or high inter-feature correlation, while\nmodels encoding inter-feature dependencies perform best with weakly correlated\nfeatures. These findings reveal that inductive biases do not always behave as\nintended, and that regime-aware evaluation is essential for understanding and\nimproving model behavior. MultiTab enables more principled model design and\noffers practical guidance for selecting models tailored to specific data\ncharacteristics. All datasets, code, and optimization logs are publicly\navailable at https://huggingface.co/datasets/LGAI-DILab/Multitab.", "published": "2025-05-20 13:00:43", "link": "http://arxiv.org/abs/2505.14312v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Benchmarking data encoding methods in Quantum Machine Learning", "abstract": "Data encoding plays a fundamental and distinctive role in Quantum Machine\nLearning (QML). While classical approaches process data directly as vectors,\nQML may require transforming classical data into quantum states through\nencoding circuits, known as quantum feature maps or quantum embeddings. This\nstep leverages the inherently high-dimensional and non-linear nature of Hilbert\nspace, enabling more efficient data separation in complex feature spaces that\nmay be inaccessible to classical methods. This encoding part significantly\naffects the performance of the QML model, so it is important to choose the\nright encoding method for the dataset to be encoded. However, this choice is\ngenerally arbitrary, since there is no \"universal\" rule for knowing which\nencoding to choose based on a specific set of data. There are currently a\nvariety of encoding methods using different quantum logic gates. We studied the\nmost commonly used types of encoding methods and benchmarked them using\ndifferent datasets.", "published": "2025-05-20 12:44:14", "link": "http://arxiv.org/abs/2505.14295v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection", "abstract": "As multimodal agents are increasingly trained to operate graphical user\ninterfaces (GUIs) to complete user tasks, they face a growing threat from\nindirect prompt injection, attacks in which misleading instructions are\nembedded into the agent's visual environment, such as popups or chat messages,\nand misinterpreted as part of the intended task. A typical example is\nenvironmental injection, in which GUI elements are manipulated to influence\nagent behavior without directly modifying the user prompt. To address these\nemerging attacks, we propose EVA, a red teaming framework for indirect prompt\ninjection which transforms the attack into a closed loop optimization by\ncontinuously monitoring an agent's attention distribution over the GUI and\nupdating adversarial cues, keywords, phrasing, and layout, in response.\nCompared with prior one shot methods that generate fixed prompts without regard\nfor how the model allocates visual attention, EVA dynamically adapts to\nemerging attention hotspots, yielding substantially higher attack success rates\nand far greater transferability across diverse GUI scenarios. We evaluate EVA\non six widely used generalist and specialist GUI agents in realistic settings\nsuch as popup manipulation, chat based phishing, payments, and email\ncomposition. Experimental results show that EVA substantially improves success\nrates over static baselines. Under goal agnostic constraints, where the\nattacker does not know the agent's task intent, EVA still discovers effective\npatterns. Notably, we find that injection styles transfer well across models,\nrevealing shared behavioral biases in GUI agents. These results suggest that\nevolving indirect prompt injection is a powerful tool not only for red teaming\nagents, but also for uncovering common vulnerabilities in their multimodal\ndecision making.", "published": "2025-05-20 12:41:05", "link": "http://arxiv.org/abs/2505.14289v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis", "abstract": "This paper presents AquaSignal, a modular and scalable pipeline for\npreprocessing, denoising, classification, and novelty detection of underwater\nacoustic signals. Designed to operate effectively in noisy and dynamic marine\nenvironments, AquaSignal integrates state-of-the-art deep learning\narchitectures to enhance the reliability and accuracy of acoustic signal\nanalysis. The system is evaluated on a combined dataset from the Deepship and\nOcean Networks Canada (ONC) benchmarks, providing a diverse set of real-world\nunderwater scenarios. AquaSignal employs a U-Net architecture for denoising, a\nResNet18 convolutional neural network for classifying known acoustic events,\nand an AutoEncoder-based model for unsupervised detection of novel or anomalous\nsignals. To our knowledge, this is the first comprehensive study to apply and\nevaluate this combination of techniques on maritime vessel acoustic data.\nExperimental results show that AquaSignal improves signal clarity and task\nperformance, achieving 71% classification accuracy and 91% accuracy in novelty\ndetection. Despite slightly lower classification performance compared to some\nstate-of-the-art models, differences in data partitioning strategies limit\ndirect comparisons. Overall, AquaSignal demonstrates strong potential for\nreal-time underwater acoustic monitoring in scientific, environmental, and\nmaritime domains.", "published": "2025-05-20 12:35:43", "link": "http://arxiv.org/abs/2505.14285v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning", "abstract": "Function approximation is a critical task in various fields. However,\nexisting neural network approaches struggle with locally complex or\ndiscontinuous functions due to their reliance on a single global model covering\nthe entire problem space. We propose X-KAN, a novel method that optimizes\nmultiple local Kolmogorov-Arnold Networks (KANs) through an evolutionary\nrule-based machine learning framework called XCSF. X-KAN combines KAN's high\nexpressiveness with XCSF's adaptive partitioning capability by implementing\nlocal KAN models as rule consequents and defining local regions via rule\nantecedents. Our experimental results on artificial test functions and\nreal-world datasets demonstrate that X-KAN significantly outperforms\nconventional methods, including XCSF, Multi-Layer Perceptron, and KAN, in terms\nof approximation accuracy. Notably, X-KAN effectively handles functions with\nlocally complex or discontinuous structures that are challenging for\nconventional KAN, using a compact set of rules (average 7.2 $\\pm$ 2.3 rules).\nThese results validate the effectiveness of using KAN as a local model in XCSF,\nwhich evaluates the rule fitness based on both accuracy and generality. Our\nX-KAN implementation is available at https://github.com/YNU-NakataLab/X-KAN.", "published": "2025-05-20 12:26:03", "link": "http://arxiv.org/abs/2505.14273v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Speculative Decoding Reimagined for Multimodal Large Language Models", "abstract": "This paper introduces Multimodal Speculative Decoding (MSD) to accelerate\nMultimodal Large Language Models (MLLMs) inference. Speculative decoding has\nbeen shown to accelerate Large Language Models (LLMs) without sacrificing\naccuracy. However, current speculative decoding methods for MLLMs fail to\nachieve the same speedup as they do for LLMs. To address this, we reimagine\nspeculative decoding specifically for MLLMs. Our analysis of MLLM\ncharacteristics reveals two key design principles for MSD: (1) Text and visual\ntokens have fundamentally different characteristics and need to be processed\nseparately during drafting. (2) Both language modeling ability and visual\nperception capability are crucial for the draft model. For the first principle,\nMSD decouples text and visual tokens in the draft model, allowing each to be\nhandled based on its own characteristics. For the second principle, MSD uses a\ntwo-stage training strategy: In stage one, the draft model is trained on\ntext-only instruction-tuning datasets to improve its language modeling ability.\nIn stage two, MSD gradually introduces multimodal data to enhance the visual\nperception capability of the draft model. Experiments show that MSD boosts\ninference speed by up to $2.29\\times$ for LLaVA-1.5-7B and up to $2.46\\times$\nfor LLaVA-1.5-13B on multimodal benchmarks, demonstrating its effectiveness.\nOur code is available at https://github.com/Lyn-Lucy/MSD.", "published": "2025-05-20 12:12:17", "link": "http://arxiv.org/abs/2505.14260v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks", "abstract": "In this work, we explore the integration of Sequence Encoding for Online\nParameter Identification with Physics-Informed Neural Networks to create a\nmodel that, once trained, can be utilized for real time applications with\nvariable parameters, boundary conditions, and initial conditions. Recently, the\ncombination of PINNs with Sparse Regression has emerged as a method for\nperforming dynamical system identification through supervised learning and\nsparse regression optimization, while also solving the dynamics using PINNs.\nHowever, this approach can be limited by variations in parameters or boundary\nand initial conditions, requiring retraining of the model whenever changes\noccur. In this work, we introduce an architecture that employs Deep Sets or\nSequence Encoders to encode dynamic parameters, boundary conditions, and\ninitial conditions, using these encoded features as inputs for the PINN,\nenabling the model to adapt to changes in parameters, BCs, and ICs. We apply\nthis approach to three different problems. First, we analyze the Rossler ODE\nsystem, demonstrating the robustness of the model with respect to noise and its\nability to generalize. Next, we explore the model's capability in a 2D\nNavier-Stokes PDE problem involving flow past a cylinder with a parametric\nsinusoidal inlet velocity function, showing that the model can encode pressure\ndata from a few points to identify the inlet velocity profile and utilize\nphysics to compute velocity and pressure throughout the domain. Finally, we\naddress a 1D heat monitoring problem using real data from the heating of glass\nfiber and thermoplastic composite plates.", "published": "2025-05-20 12:05:17", "link": "http://arxiv.org/abs/2505.14252v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Visual Agentic Reinforcement Fine-Tuning", "abstract": "A key trend in Large Reasoning Models (e.g., OpenAI's o3) is the native\nagentic ability to use external tools such as web browsers for searching and\nwriting/executing code for image manipulation to think with images. In the\nopen-source research community, while significant progress has been made in\nlanguage-only agentic abilities such as function calling and tool integration,\nthe development of multi-modal agentic capabilities that involve truly thinking\nwith images, and their corresponding benchmarks, are still less explored. This\nwork highlights the effectiveness of Visual Agentic Reinforcement Fine-Tuning\n(Visual-ARFT) for enabling flexible and adaptive reasoning abilities for Large\nVision-Language Models (LVLMs). With Visual-ARFT, open-source LVLMs gain the\nability to browse websites for real-time information updates and write code to\nmanipulate and analyze input images through cropping, rotation, and other image\nprocessing techniques. We also present a Multi-modal Agentic Tool Bench (MAT)\nwith two settings (MAT-Search and MAT-Coding) designed to evaluate LVLMs'\nagentic search and coding abilities. Our experimental results demonstrate that\nVisual-ARFT outperforms its baseline by +18.6% F1 / +13.0% EM on MAT-Coding and\n+10.3% F1 / +8.7% EM on MAT-Search, ultimately surpassing GPT-4o. Visual-ARFT\nalso achieves +29.3 F1% / +25.9% EM gains on existing multi-hop QA benchmarks\nsuch as 2Wiki and HotpotQA, demonstrating strong generalization capabilities.\nOur findings suggest that Visual-ARFT offers a promising path toward building\nrobust and generalizable multimodal agents.", "published": "2025-05-20 11:59:25", "link": "http://arxiv.org/abs/2505.14246v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Toward Embodied AGI: A Review of Embodied AI and the Road Ahead", "abstract": "Artificial General Intelligence (AGI) is often envisioned as inherently\nembodied. With recent advances in robotics and foundational AI models, we stand\nat the threshold of a new era-one marked by increasingly generalized embodied\nAI systems. This paper contributes to the discourse by introducing a systematic\ntaxonomy of Embodied AGI spanning five levels (L1-L5). We review existing\nresearch and challenges at the foundational stages (L1-L2) and outline the key\ncomponents required to achieve higher-level capabilities (L3-L5). Building on\nthese insights and existing technologies, we propose a conceptual framework for\nan L3+ robotic brain, offering both a technical outlook and a foundation for\nfuture exploration.", "published": "2025-05-20 11:42:26", "link": "http://arxiv.org/abs/2505.14235v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Fast and close Shannon entropy approximation", "abstract": "Shannon entropy (SE) and its quantum mechanical analogue von Neumann entropy\nare key components in many tools used in physics, information theory, machine\nlearning (ML) and quantum computing. Besides of the significant amounts of SE\ncomputations required in these fields, the singularity of the SE gradient is\none of the central mathematical reason inducing the high cost, frequently low\nrobustness and slow convergence of such tools. Here we propose the Fast Entropy\nApproximation (FEA) - a non-singular rational approximation of Shannon entropy\nand its gradient that achieves a mean absolute error of $10^{-3}$, which is\napproximately $20$ times lower than comparable state-of-the-art methods. FEA\nallows around $50\\%$ faster computation, requiring only $5$ to $6$ elementary\ncomputational operations, as compared to tens of elementary operations behind\nthe fastest entropy computation algorithms with table look-ups, bitshifts, or\nseries approximations. On a set of common benchmarks for the feature selection\nproblem in machine learning, we show that the combined effect of fewer\nelementary operations, low approximation error, and a non-singular gradient\nallows significantly better model quality and enables ML feature extraction\nthat is two to three orders of magnitude faster and computationally cheaper\nwhen incorporating FEA into AI tools.", "published": "2025-05-20 11:41:26", "link": "http://arxiv.org/abs/2505.14234v1", "categories": ["cs.LG", "cs.AI", "68T01 (Primary) 68Q01, 90C99 (Secondary)"], "primary_category": "cs.LG"}
{"title": "VoQA: Visual-only Question Answering", "abstract": "We propose Visual-only Question Answering (VoQA), a novel multimodal task in\nwhich questions are visually embedded within images, without any accompanying\ntextual input. This requires models to locate, recognize, and reason over\nvisually embedded textual questions, posing challenges for existing large\nvision-language models (LVLMs), which show notable performance drops even with\ncarefully designed prompts. To bridge this gap, we introduce Guided Response\nTriggering Supervised Fine-tuning (GRT-SFT), a structured fine-tuning strategy\nthat guides the model to perform step-by-step reasoning purely based on visual\ninput, significantly improving model performance. Our work enhances models'\ncapacity for human-like visual understanding in complex multimodal scenarios,\nwhere information, including language, is perceived visually.", "published": "2025-05-20 11:37:49", "link": "http://arxiv.org/abs/2505.14227v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Federated learning in low-resource settings: A chest imaging study in Africa -- Challenges and lessons learned", "abstract": "This study explores the use of Federated Learning (FL) for tuberculosis (TB)\ndiagnosis using chest X-rays in low-resource settings across Africa. FL allows\nhospitals to collaboratively train AI models without sharing raw patient data,\naddressing privacy concerns and data scarcity that hinder traditional\ncentralized models. The research involved hospitals and research centers in\neight African countries. Most sites used local datasets, while Ghana and The\nGambia used public ones. The study compared locally trained models with a\nfederated model built across all institutions to evaluate FL's real-world\nfeasibility. Despite its promise, implementing FL in sub-Saharan Africa faces\nchallenges such as poor infrastructure, unreliable internet, limited digital\nliteracy, and weak AI regulations. Some institutions were also reluctant to\nshare model updates due to data control concerns. In conclusion, FL shows\nstrong potential for enabling AI-driven healthcare in underserved regions, but\nbroader adoption will require improvements in infrastructure, education, and\nregulatory support.", "published": "2025-05-20 11:23:52", "link": "http://arxiv.org/abs/2505.14217v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Embedded Mean Field Reinforcement Learning for Perimeter-defense Game", "abstract": "With the rapid advancement of unmanned aerial vehicles (UAVs) and missile\ntechnologies, perimeter-defense game between attackers and defenders for the\nprotection of critical regions have become increasingly complex and\nstrategically significant across a wide range of domains. However, existing\nstudies predominantly focus on small-scale, simplified two-dimensional\nscenarios, often overlooking realistic environmental perturbations, motion\ndynamics, and inherent heterogeneity--factors that pose substantial challenges\nto real-world applicability. To bridge this gap, we investigate large-scale\nheterogeneous perimeter-defense game in a three-dimensional setting,\nincorporating realistic elements such as motion dynamics and wind fields. We\nderive the Nash equilibrium strategies for both attackers and defenders,\ncharacterize the victory regions, and validate our theoretical findings through\nextensive simulations. To tackle large-scale heterogeneous control challenges\nin defense strategies, we propose an Embedded Mean-Field Actor-Critic (EMFAC)\nframework. EMFAC leverages representation learning to enable high-level action\naggregation in a mean-field manner, supporting scalable coordination among\ndefenders. Furthermore, we introduce a lightweight agent-level attention\nmechanism based on reward representation, which selectively filters\nobservations and mean-field information to enhance decision-making efficiency\nand accelerate convergence in large-scale tasks. Extensive simulations across\nvarying scales demonstrate the effectiveness and adaptability of EMFAC, which\noutperforms established baselines in both convergence speed and overall\nperformance. To further validate practicality, we test EMFAC in small-scale\nreal-world experiments and conduct detailed analyses, offering deeper insights\ninto the framework's effectiveness in complex scenarios.", "published": "2025-05-20 11:11:46", "link": "http://arxiv.org/abs/2505.14209v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Challenges and Limitations in the Synthetic Generation of mHealth Sensor Data", "abstract": "The widespread adoption of mobile sensors has the potential to provide\nmassive and heterogeneous time series data, driving Artificial Intelligence\napplications in mHealth. However, data collection remains limited due to\nstringent ethical regulations, privacy concerns, and other constraints,\nhindering progress in the field. Synthetic data generation, particularly\nthrough Generative Adversarial Networks and Diffusion Models, has emerged as a\npromising solution to address both data scarcity and privacy issues. Yet, these\nmodels are often limited to short-term, unimodal signal patterns. This paper\npresents a systematic evaluation of state-of-the-art generative models for time\nseries synthesis, with a focus on their ability to jointly handle\nmulti-modality, long-range dependencies, and conditional generation-key\nchallenges in the mHealth domain. To ensure a fair comparison, we introduce a\nnovel evaluation framework designed to measure both the intrinsic quality of\nsynthetic data and its utility in downstream predictive tasks. Our findings\nreveal critical limitations in the existing approaches, particularly in\nmaintaining cross-modal consistency, preserving temporal coherence, and\nensuring robust performance in train-on-synthetic, test-on-real, and data\naugmentation scenarios. Finally, we present our future research directions to\nenhance synthetic time series generation and improve the applicability of\ngenerative models in mHealth.", "published": "2025-05-20 11:05:06", "link": "http://arxiv.org/abs/2505.14206v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FLASH-D: FlashAttention with Hidden Softmax Division", "abstract": "The transformer's attention mechanism has revolutionized AI and machine\nlearning, with its efficient computation being crucial to its performance.\nHowever, calculating attention involves matrix operations interspersed with\nsoftmax rescaling, which inherently slows down computation and requires\nprocessing the entire input sequence. Building on online softmax computation,\nFlashAttention integrates softmax calculation with matrix arithmetic, enabling\ntiled computation independent of sequence length. While optimized for GPUs,\nFlashAttention's simplicity makes it amenable to direct hardware acceleration.\nThis work re-evaluates the core FlashAttention kernel, presenting FLASH-D a\nmathematically equivalent, yet simplified, formulation that achieves: (a)\nhiding softmax division within other non-linear function evaluations; (b)\ninherently numerically stable computation of exponentials, eliminating the need\nfor maximum value subtraction; and (c) a reduction in computational cost\nwithout introducing numerical approximations to the FlashAttention kernel.\nImportantly, the essential FlashAttention properties that facilitate efficient\ntiled implementation are fully preserved. Hardware implementation results at\n28nm demonstrate that this proposed formulation achieves a 22.8% reduction in\narea and a 20.3% reduction in power, on average, compared to state-of-the-art\nparallel hardware architectures without any performance penalty.", "published": "2025-05-20 11:01:33", "link": "http://arxiv.org/abs/2505.14201v1", "categories": ["cs.LG", "cs.AI", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Dynamic Replanning for Improved Public Transport Routing", "abstract": "Delays in public transport are common, often impacting users through\nprolonged travel times and missed transfers. Existing solutions for handling\ndelays remain limited; backup plans based on historical data miss opportunities\nfor earlier arrivals, while snapshot planning accounts for current delays but\nnot future ones. With the growing availability of live delay data, users can\nadjust their journeys in real-time. However, the literature lacks a framework\nthat fully exploits this advantage for system-scale dynamic replanning. To\naddress this, we formalise the dynamic replanning problem in public transport\nrouting and propose two solutions: a \"pull\" approach, where users manually\nrequest replanning, and a novel \"push\" approach, where the server proactively\nmonitors and adjusts journeys. Our experiments show that the push approach\noutperforms the pull approach, achieving significant speedups. The results also\nreveal substantial arrival time savings enabled by dynamic replanning.", "published": "2025-05-20 10:50:58", "link": "http://arxiv.org/abs/2505.14193v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "$\u03b1$-GAN by R\u00e9nyi Cross Entropy", "abstract": "This paper proposes $\\alpha$-GAN, a generative adversarial network using\nR\\'{e}nyi measures. The value function is formulated, by R\\'{e}nyi cross\nentropy, as an expected certainty measure incurred by the discriminator's soft\ndecision as to where the sample is from, true population or the generator. The\ndiscriminator tries to maximize the R\\'{e}nyi certainty about sample source,\nwhile the generator wants to reduce it by injecting fake samples. This forms a\nmin-max problem with the solution parameterized by the R\\'{e}nyi order\n$\\alpha$. This $\\alpha$-GAN reduces to vanilla GAN at $\\alpha = 1$, where the\nvalue function is exactly the binary cross entropy. The optimization of\n$\\alpha$-GAN is over probability (vector) space. It is shown that the gradient\nis exponentially enlarged when R\\'{e}nyi order is in the range $\\alpha \\in\n(0,1)$. This makes convergence faster, which is verified by experimental\nresults. A discussion shows that choosing $\\alpha \\in (0,1)$ may be able to\nsolve some common problems, e.g., vanishing gradient. A following observation\nreveals that this range has not been fully explored in the existing R\\'{e}nyi\nversion GANs.", "published": "2025-05-20 10:45:11", "link": "http://arxiv.org/abs/2505.14190v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic Reasoning Limits", "abstract": "Tokenization is the first - and often underappreciated - layer of computation\nin language models. While Chain-of-Thought (CoT) prompting enables transformer\nmodels to approximate recurrent computation by externalizing intermediate\nsteps, we show that the success of such reasoning is fundamentally bounded by\nthe structure of tokenized inputs. This work presents a theoretical and\nempirical investigation into how tokenization schemes, particularly\nsubword-based methods like byte-pair encoding (BPE), impede symbolic\ncomputation by merging or obscuring atomic reasoning units. We introduce the\nnotion of Token Awareness to formalize how poor token granularity disrupts\nlogical alignment and prevents models from generalizing symbolic procedures.\nThrough systematic evaluation on arithmetic and symbolic tasks, we demonstrate\nthat token structure dramatically affect reasoning performance, causing failure\neven with CoT, while atomically-aligned formats unlock strong generalization,\nallowing small models (e.g., GPT-4o-mini) to outperform larger systems (e.g.,\no1) in structured reasoning. Our findings reveal that symbolic reasoning\nability in LLMs is not purely architectural, but deeply conditioned on\ntoken-level representations.", "published": "2025-05-20 10:32:30", "link": "http://arxiv.org/abs/2505.14178v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "abstract": "Large language model (LLM) agents have shown promising performance in\ngenerating code for solving complex data science problems. Recent studies\nprimarily focus on enhancing in-context learning through improved search,\nsampling, and planning techniques, while overlooking the importance of the\norder in which problems are tackled during inference. In this work, we develop\na novel inference-time optimization framework, referred to as DSMentor, which\nleverages curriculum learning -- a strategy that introduces simpler task first\nand progressively moves to more complex ones as the learner improves -- to\nenhance LLM agent performance in challenging data science tasks. Our\nmentor-guided framework organizes data science tasks in order of increasing\ndifficulty and incorporates a growing long-term memory to retain prior\nexperiences, guiding the agent's learning progression and enabling more\neffective utilization of accumulated knowledge. We evaluate DSMentor through\nextensive experiments on DSEval and QRData benchmarks. Experiments show that\nDSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval\nand QRData compared to baseline agents. Furthermore, DSMentor demonstrates\nstronger causal reasoning ability, improving the pass rate by 8.8% on the\ncausality problems compared to GPT-4 using Program-of-Thoughts prompts. Our\nwork underscores the importance of developing effective strategies for\naccumulating and utilizing knowledge during inference, mirroring the human\nlearning process and opening new avenues for improving LLM performance through\ncurriculum-based inference optimization.", "published": "2025-05-20 10:16:21", "link": "http://arxiv.org/abs/2505.14163v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Prior Prompt Engineering for Reinforcement Fine-Tuning", "abstract": "This paper investigates prior prompt engineering (pPE) in the context of\nreinforcement fine-tuning (RFT), where language models (LMs) are incentivized\nto exhibit behaviors that maximize performance through reward signals. While\nexisting RFT research has primarily focused on algorithms, reward shaping, and\ndata curation, the design of the prior prompt--the instructions prepended to\nqueries during training to elicit behaviors such as step-by-step\nreasoning--remains underexplored. We investigate whether different pPE\napproaches can guide LMs to internalize distinct behaviors after RFT. Inspired\nby inference-time prompt engineering (iPE), we translate five representative\niPE strategies--reasoning, planning, code-based reasoning, knowledge recall,\nand null-example utilization--into corresponding pPE approaches. We experiment\nwith Qwen2.5-7B using each of the pPE approaches, then evaluate performance on\nin-domain and out-of-domain benchmarks (e.g., AIME2024, HumanEval+, and\nGPQA-Diamond). Our results show that all pPE-trained models surpass their\niPE-prompted counterparts, with the null-example pPE approach achieving the\nlargest average performance gain and the highest improvement on AIME2024 and\nGPQA-Diamond, surpassing the commonly used reasoning approach. Furthermore, by\nadapting a behavior-classification framework, we demonstrate that different pPE\nstrategies instill distinct behavioral styles in the resulting models. These\nfindings position pPE as a powerful yet understudied axis for RFT.", "published": "2025-05-20 10:05:11", "link": "http://arxiv.org/abs/2505.14157v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search", "abstract": "Session search involves a series of interactive queries and actions to\nfulfill user's complex information need. Current strategies typically\nprioritize sequential modeling for deep semantic understanding, overlooking the\ngraph structure in interactions. While some approaches focus on capturing\nstructural information, they use a generalized representation for documents,\nneglecting the word-level semantic modeling. In this paper, we propose Symbolic\nGraph Ranker (SGR), which aims to take advantage of both text-based and\ngraph-based approaches by leveraging the power of recent Large Language Models\n(LLMs). Concretely, we first introduce a set of symbolic grammar rules to\nconvert session graph into text. This allows integrating session history,\ninteraction process, and task instruction seamlessly as inputs for the LLM.\nMoreover, given the natural discrepancy between LLMs pre-trained on textual\ncorpora, and the symbolic language we produce using our graph-to-text grammar,\nour objective is to enhance LLMs' ability to capture graph structures within a\ntextual format. To achieve this, we introduce a set of self-supervised symbolic\nlearning tasks including link prediction, node content generation, and\ngenerative contrastive learning, to enable LLMs to capture the topological\ninformation from coarse-grained to fine-grained. Experiment results and\ncomprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm\nthe superiority of our approach. Our paradigm also offers a novel and effective\nmethodology that bridges the gap between traditional search strategies and\nmodern LLMs.", "published": "2025-05-20 10:05:06", "link": "http://arxiv.org/abs/2505.14156v1", "categories": ["cs.CV", "cs.AI", "cs.IR", "I.2; H.3.3"], "primary_category": "cs.CV"}
{"title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "abstract": "Mathematical modeling is a cornerstone of scientific discovery and\nengineering practice, enabling the translation of real-world problems into\nformal systems across domains such as physics, biology, and economics. Unlike\nmathematical reasoning, which assumes a predefined formulation, modeling\nrequires open-ended problem analysis, abstraction, and principled\nformalization. While Large Language Models (LLMs) have shown strong reasoning\ncapabilities, they fall short in rigorous model construction, limiting their\nutility in real-world problem-solving. To this end, we formalize the task of\nLLM-powered real-world mathematical modeling, where agents must analyze\nproblems, construct domain-appropriate formulations, and generate complete\nend-to-end solutions. We introduce MM-Bench, a curated benchmark of 111\nproblems from the Mathematical Contest in Modeling (MCM/ICM), spanning the\nyears 2000 to 2025 and across ten diverse domains such as physics, biology, and\neconomics. To tackle this task, we propose MM-Agent, an expert-inspired\nframework that decomposes mathematical modeling into four stages: open-ended\nproblem analysis, structured model formulation, computational problem solving,\nand report generation. Experiments on MM-Bench show that MM-Agent significantly\noutperforms baseline agents, achieving an 11.88\\% improvement over human expert\nsolutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o.\nFurthermore, under official MCM/ICM protocols, MM-Agent assisted two\nundergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among\n27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a\nmodeling copilot. Our code is available at\nhttps://github.com/usail-hkust/LLM-MM-Agent", "published": "2025-05-20 09:55:31", "link": "http://arxiv.org/abs/2505.14148v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Grouping First, Attending Smartly: Training-Free Acceleration for Diffusion Transformers", "abstract": "Diffusion-based Transformers have demonstrated impressive generative\ncapabilities, but their high computational costs hinder practical deployment,\nfor example, generating an $8192\\times 8192$ image can take over an hour on an\nA100 GPU. In this work, we propose GRAT (\\textbf{GR}ouping first,\n\\textbf{AT}tending smartly), a training-free attention acceleration strategy\nfor fast image and video generation without compromising output quality. The\nkey insight is to exploit the inherent sparsity in learned attention maps\n(which tend to be locally focused) in pretrained Diffusion Transformers and\nleverage better GPU parallelism. Specifically, GRAT first partitions contiguous\ntokens into non-overlapping groups, aligning both with GPU execution patterns\nand the local attention structures learned in pretrained generative\nTransformers. It then accelerates attention by having all query tokens within\nthe same group share a common set of attendable key and value tokens. These key\nand value tokens are further restricted to structured regions, such as\nsurrounding blocks or criss-cross regions, significantly reducing computational\noverhead (e.g., attaining a \\textbf{35.8$\\times$} speedup over full attention\nwhen generating $8192\\times 8192$ images) while preserving essential attention\npatterns and long-range context. We validate GRAT on pretrained Flux and\nHunyuanVideo for image and video generation, respectively. In both cases, GRAT\nachieves substantially faster inference without any fine-tuning, while\nmaintaining the performance of full attention. We hope GRAT will inspire future\nresearch on accelerating Diffusion Transformers for scalable visual generation.", "published": "2025-05-20 17:59:59", "link": "http://arxiv.org/abs/2505.14687v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Emerging Properties in Unified Multimodal Pretraining", "abstract": "Unifying multimodal understanding and generation has shown impressive\ncapabilities in cutting-edge proprietary systems. In this work, we introduce\nBAGEL, an open0source foundational model that natively supports multimodal\nunderstanding and generation. BAGEL is a unified, decoder0only model pretrained\non trillions of tokens curated from large0scale interleaved text, image, video,\nand web data. When scaled with such diverse multimodal interleaved data, BAGEL\nexhibits emerging capabilities in complex multimodal reasoning. As a result, it\nsignificantly outperforms open-source unified models in both multimodal\ngeneration and understanding across standard benchmarks, while exhibiting\nadvanced multimodal reasoning abilities such as free-form image manipulation,\nfuture frame prediction, 3D manipulation, and world navigation. In the hope of\nfacilitating further opportunities for multimodal research, we share the key\nfindings, pretraining details, data creation protocal, and release our code and\ncheckpoints to the community. The project page is at https://bagel-ai.org/", "published": "2025-05-20 17:59:30", "link": "http://arxiv.org/abs/2505.14683v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation", "abstract": "We introduce UniGen, a unified multimodal large language model (MLLM) capable\nof image understanding and generation. We study the full training pipeline of\nUniGen from a data-centric perspective, including multi-stage pre-training,\nsupervised fine-tuning, and direct preference optimization. More importantly,\nwe propose a new Chain-of-Thought Verification (CoT-V) strategy for test-time\nscaling, which significantly boosts UniGen's image generation quality using a\nsimple Best-of-N test-time strategy. Specifically, CoT-V enables UniGen to act\nas both image generator and verifier at test time, assessing the semantic\nalignment between a text prompt and its generated image in a step-by-step CoT\nmanner. Trained entirely on open-source datasets across all stages, UniGen\nachieves state-of-the-art performance on a range of image understanding and\ngeneration benchmarks, with a final score of 0.78 on GenEval and 85.19 on\nDPG-Bench. Through extensive ablation studies, our work provides actionable\ninsights and addresses key challenges in the full life cycle of building\nunified MLLMs, contributing meaningful directions to the future research.", "published": "2025-05-20 17:59:26", "link": "http://arxiv.org/abs/2505.14682v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning", "abstract": "Learning general-purpose reasoning capabilities has long been a challenging\nproblem in AI. Recent research in large language models (LLMs), such as\nDeepSeek-R1, has shown that reinforcement learning techniques like GRPO can\nenable pre-trained LLMs to develop reasoning capabilities using simple\nquestion-answer pairs. In this paper, we aim to train visual language models\n(VLMs) to perform reasoning on image data through reinforcement learning and\nvisual question-answer pairs, without any explicit chain-of-thought (CoT)\nsupervision. Our findings indicate that simply applying reinforcement learning\nto a VLM -- by prompting the model to produce a reasoning chain before\nproviding an answer -- can lead the model to develop shortcuts from easy\nquestions, thereby reducing its ability to generalize across unseen data\ndistributions. We argue that the key to mitigating shortcut learning is to\nencourage the model to interpret images prior to reasoning. Therefore, we train\nthe model to adhere to a caption-reason-answer output format: initially\ngenerating a detailed caption for an image, followed by constructing an\nextensive reasoning chain. When trained on 273K CoT-free visual question-answer\npairs and using only reinforcement learning, our model, named Visionary-R1,\noutperforms strong multimodal models, such as GPT-4o, Claude3.5-Sonnet, and\nGemini-1.5-Pro, on multiple visual reasoning benchmarks.", "published": "2025-05-20 17:58:35", "link": "http://arxiv.org/abs/2505.14677v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens", "abstract": "Personalized models have demonstrated remarkable success in understanding and\ngenerating concepts provided by users. However, existing methods use separate\nconcept tokens for understanding and generation, treating these tasks in\nisolation. This may result in limitations for generating images with complex\nprompts. For example, given the concept $\\langle bo\\rangle$, generating\n\"$\\langle bo\\rangle$ wearing its hat\" without additional textual descriptions\nof its hat. We call this kind of generation personalized knowledge-driven\ngeneration. To address the limitation, we present UniCTokens, a novel framework\nthat effectively integrates personalized information into a unified vision\nlanguage model (VLM) for understanding and generation. UniCTokens trains a set\nof unified concept tokens to leverage complementary semantics, boosting two\npersonalized tasks. Moreover, we propose a progressive training strategy with\nthree stages: understanding warm-up, bootstrapping generation from\nunderstanding, and deepening understanding from generation to enhance mutual\nbenefits between both tasks. To quantitatively evaluate the unified VLM\npersonalization, we present UnifyBench, the first benchmark for assessing\nconcept understanding, concept generation, and knowledge-driven generation.\nExperimental results on UnifyBench indicate that UniCTokens shows competitive\nperformance compared to leading methods in concept understanding, concept\ngeneration, and achieving state-of-the-art results in personalized\nknowledge-driven generation. Our research demonstrates that enhanced\nunderstanding improves generation, and the generation process can yield\nvaluable insights into understanding. Our code and dataset will be released at:\n\\href{https://github.com/arctanxarc/UniCTokens}{https://github.com/arctanxarc/UniCTokens}.", "published": "2025-05-20 17:56:01", "link": "http://arxiv.org/abs/2505.14671v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VideoEval-Pro: Robust and Realistic Long Video Understanding Evaluation", "abstract": "Large multimodal models (LMMs) have recently emerged as a powerful tool for\nlong video understanding (LVU), prompting the development of standardized LVU\nbenchmarks to evaluate their performance. However, our investigation reveals a\nrather sober lesson for existing LVU benchmarks. First, most existing\nbenchmarks rely heavily on multiple-choice questions (MCQs), whose evaluation\nresults are inflated due to the possibility of guessing the correct answer;\nSecond, a significant portion of questions in these benchmarks have strong\npriors to allow models to answer directly without even reading the input video.\nFor example, Gemini-1.5-Pro can achieve over 50\\% accuracy given a random frame\nfrom a long video on Video-MME. We also observe that increasing the number of\nframes does not necessarily lead to improvement on existing benchmarks, which\nis counterintuitive. As a result, the validity and robustness of current LVU\nbenchmarks are undermined, impeding a faithful assessment of LMMs' long-video\nunderstanding capability. To tackle this problem, we propose VideoEval-Pro, a\nrealistic LVU benchmark containing questions with open-ended short-answer,\nwhich truly require understanding the entire video. VideoEval-Pro assesses both\nsegment-level and full-video understanding through perception and reasoning\ntasks. By evaluating 21 proprietary and open-source video LMMs, we conclude the\nfollowing findings: (1) video LMMs show drastic performance ($>$25\\%) drops on\nopen-ended questions compared with MCQs; (2) surprisingly, higher MCQ scores do\nnot lead to higher open-ended scores on VideoEval-Pro; (3) compared to other\nMCQ benchmarks, VideoEval-Pro benefits more from increasing the number of input\nframes. Our results show that VideoEval-Pro offers a more realistic and\nreliable measure of long video understanding, providing a clearer view of\nprogress in this domain.", "published": "2025-05-20 17:26:32", "link": "http://arxiv.org/abs/2505.14640v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A General Framework for Group Sparsity in Hyperspectral Unmixing Using Endmember Bundles", "abstract": "Due to low spatial resolution, hyperspectral data often consists of mixtures\nof contributions from multiple materials. This limitation motivates the task of\nhyperspectral unmixing (HU), a fundamental problem in hyperspectral imaging. HU\naims to identify the spectral signatures (\\textit{endmembers}) of the materials\npresent in an observed scene, along with their relative proportions\n(\\textit{fractional abundance}) in each pixel. A major challenge lies in the\nclass variability in materials, which hinders accurate representation by a\nsingle spectral signature, as assumed in the conventional linear mixing model.\nMoreover, To address this issue, we propose using group sparsity after\nrepresenting each material with a set of spectral signatures, known as\nendmember bundles, where each group corresponds to a specific material. In\nparticular, we develop a bundle-based framework that can enforce either\ninter-group sparsity or sparsity within and across groups (SWAG) on the\nabundance coefficients. Furthermore, our framework offers the flexibility to\nincorporate a variety of sparsity-promoting penalties, among which the\ntransformed $\\ell_1$ (TL1) penalty is a novel regularization in the HU\nliterature. Extensive experiments conducted on both synthetic and real\nhyperspectral data demonstrate the effectiveness and superiority of the\nproposed approaches.", "published": "2025-05-20 17:25:05", "link": "http://arxiv.org/abs/2505.14634v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "3D Reconstruction from Sketches", "abstract": "We consider the problem of reconstructing a 3D scene from multiple sketches.\nWe propose a pipeline which involves (1) stitching together multiple sketches\nthrough use of correspondence points, (2) converting the stitched sketch into a\nrealistic image using a CycleGAN, and (3) estimating that image's depth-map\nusing a pre-trained convolutional neural network based architecture called\nMegaDepth. Our contribution includes constructing a dataset of image-sketch\npairs, the images for which are from the Zurich Building Database, and sketches\nhave been generated by us. We use this dataset to train a CycleGAN for our\npipeline's second step. We end up with a stitching process that does not\ngeneralize well to real drawings, but the rest of the pipeline that creates a\n3D reconstruction from a single sketch performs quite well on a wide variety of\ndrawings.", "published": "2025-05-20 17:11:49", "link": "http://arxiv.org/abs/2505.14621v1", "categories": ["cs.CV", "cs.LG", "68T45", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Instance Segmentation for Point Sets", "abstract": "Recently proposed neural network architectures like PointNet [QSMG16] and\nPointNet++ [QYSG17] have made it possible to apply Deep Learning to 3D point\nsets. The feature representations of shapes learned by these two networks\nenabled training classifiers for Semantic Segmentation, and more recently for\nInstance Segmentation via the Similarity Group Proposal Network (SGPN)\n[WYHN17]. One area of improvement which has been highlighted by SGPN's authors,\npertains to use of memory intensive similarity matrices which occupy memory\nquadratic in the number of points. In this report, we attempt to tackle this\nissue through use of two sampling based methods, which compute Instance\nSegmentation on a sub-sampled Point Set, and then extrapolate labels to the\ncomplete set using the nearest neigbhour approach. While both approaches\nperform equally well on large sub-samples, the random-based strategy gives the\nmost improvements in terms of speed and memory usage.", "published": "2025-05-20 16:40:01", "link": "http://arxiv.org/abs/2505.14583v1", "categories": ["cs.CV", "cs.LG", "68T45", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Automated Fetal Biometry Assessment with Deep Ensembles using Sparse-Sampling of 2D Intrapartum Ultrasound Images", "abstract": "The International Society of Ultrasound advocates Intrapartum Ultrasound (US)\nImaging in Obstetrics and Gynecology (ISUOG) to monitor labour progression\nthrough changes in fetal head position. Two reliable ultrasound-derived\nparameters that are used to predict outcomes of instrumental vaginal delivery\nare the angle of progression (AoP) and head-symphysis distance (HSD). In this\nwork, as part of the Intrapartum Ultrasounds Grand Challenge (IUGC) 2024, we\npropose an automated fetal biometry measurement pipeline to reduce intra- and\ninter-observer variability and improve measurement reliability. Our pipeline\nconsists of three key tasks: (i) classification of standard planes (SP) from US\nvideos, (ii) segmentation of fetal head and pubic symphysis from the detected\nSPs, and (iii) computation of the AoP and HSD from the segmented regions. We\nperform sparse sampling to mitigate class imbalances and reduce spurious\ncorrelations in task (i), and utilize ensemble-based deep learning methods for\ntask (i) and (ii) to enhance generalizability under different US acquisition\nsettings. Finally, to promote robustness in task iii) with respect to the\nstructural fidelity of measurements, we retain the largest connected components\nand apply ellipse fitting to the segmentations. Our solution achieved ACC:\n0.9452, F1: 0.9225, AUC: 0.983, MCC: 0.8361, DSC: 0.918, HD: 19.73, ASD: 5.71,\n$\\Delta_{AoP}$: 8.90 and $\\Delta_{HSD}$: 14.35 across an unseen hold-out set of\n4 patients and 224 US frames. The results from the proposed automated pipeline\ncan improve the understanding of labour arrest causes and guide the development\nof clinical risk stratification tools for efficient and effective prenatal\ncare.", "published": "2025-05-20 16:31:09", "link": "http://arxiv.org/abs/2505.14572v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Neural Inverse Scattering with Score-based Regularization", "abstract": "Inverse scattering is a fundamental challenge in many imaging applications,\nranging from microscopy to remote sensing. Solving this problem often requires\njointly estimating two unknowns -- the image and the scattering field inside\nthe object -- necessitating effective image prior to regularize the inference.\nIn this paper, we propose a regularized neural field (NF) approach which\nintegrates the denoising score function used in score-based generative models.\nThe neural field formulation offers convenient flexibility to performing joint\nestimation, while the denoising score function imposes the rich structural\nprior of images. Our results on three high-contrast simulated objects show that\nthe proposed approach yields a better imaging quality compared to the\nstate-of-the-art NF approach, where regularization is based on total variation.", "published": "2025-05-20 16:19:16", "link": "http://arxiv.org/abs/2505.14560v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Dynadiff: Single-stage Decoding of Images from Continuously Evolving fMRI", "abstract": "Brain-to-image decoding has been recently propelled by the progress in\ngenerative AI models and the availability of large ultra-high field functional\nMagnetic Resonance Imaging (fMRI). However, current approaches depend on\ncomplicated multi-stage pipelines and preprocessing steps that typically\ncollapse the temporal dimension of brain recordings, thereby limiting\ntime-resolved brain decoders. Here, we introduce Dynadiff (Dynamic Neural\nActivity Diffusion for Image Reconstruction), a new single-stage diffusion\nmodel designed for reconstructing images from dynamically evolving fMRI\nrecordings. Our approach offers three main contributions. First, Dynadiff\nsimplifies training as compared to existing approaches. Second, our model\noutperforms state-of-the-art models on time-resolved fMRI signals, especially\non high-level semantic image reconstruction metrics, while remaining\ncompetitive on preprocessed fMRI data that collapse time. Third, this approach\nallows a precise characterization of the evolution of image representations in\nbrain activity. Overall, this work lays the foundation for time-resolved\nbrain-to-image decoding.", "published": "2025-05-20 16:14:37", "link": "http://arxiv.org/abs/2505.14556v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neural Video Compression with Context Modulation", "abstract": "Efficient video coding is highly dependent on exploiting the temporal\nredundancy, which is usually achieved by extracting and leveraging the temporal\ncontext in the emerging conditional coding-based neural video codec (NVC).\nAlthough the latest NVC has achieved remarkable progress in improving the\ncompression performance, the inherent temporal context propagation mechanism\nlacks the ability to sufficiently leverage the reference information, limiting\nfurther improvement. In this paper, we address the limitation by modulating the\ntemporal context with the reference frame in two steps. Specifically, we first\npropose the flow orientation to mine the inter-correlation between the\nreference frame and prediction frame for generating the additional oriented\ntemporal context. Moreover, we introduce the context compensation to leverage\nthe oriented context to modulate the propagated temporal context generated from\nthe propagated reference feature. Through the synergy mechanism and decoupling\nloss supervision, the irrelevant propagated information can be effectively\neliminated to ensure better context modeling. Experimental results demonstrate\nthat our codec achieves on average 22.7% bitrate reduction over the advanced\ntraditional video codec H.266/VVC, and offers an average 10.1% bitrate saving\nover the previous state-of-the-art NVC DCVC-FM. The code is available at\nhttps://github.com/Austin4USTC/DCMVC.", "published": "2025-05-20 15:57:09", "link": "http://arxiv.org/abs/2505.14541v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Personalize Your Gaussian: Consistent 3D Scene Personalization from a Single Image", "abstract": "Personalizing 3D scenes from a single reference image enables intuitive\nuser-guided editing, which requires achieving both multi-view consistency\nacross perspectives and referential consistency with the input image. However,\nthese goals are particularly challenging due to the viewpoint bias caused by\nthe limited perspective provided in a single image. Lacking the mechanisms to\neffectively expand reference information beyond the original view, existing\nmethods of image-conditioned 3DGS personalization often suffer from this\nviewpoint bias and struggle to produce consistent results. Therefore, in this\npaper, we present Consistent Personalization for 3D Gaussian Splatting (CP-GS),\na framework that progressively propagates the single-view reference appearance\nto novel perspectives. In particular, CP-GS integrates pre-trained image-to-3D\ngeneration and iterative LoRA fine-tuning to extract and extend the reference\nappearance, and finally produces faithful multi-view guidance images and the\npersonalized 3DGS outputs through a view-consistent generation process guided\nby geometric cues. Extensive experiments on real-world scenes show that our\nCP-GS effectively mitigates the viewpoint bias, achieving high-quality\npersonalization that significantly outperforms existing methods. The code will\nbe released at https://github.com/Yuxuan-W/CP-GS.", "published": "2025-05-20 15:55:53", "link": "http://arxiv.org/abs/2505.14537v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "diffDemorph: Extending Reference-Free Demorphing to Unseen Faces", "abstract": "A face morph is created by combining two (or more) face images corresponding\nto two (or more) identities to produce a composite that successfully matches\nthe constituent identities. Reference-free (RF) demorphing reverses this\nprocess using only the morph image, without the need for additional reference\nimages. Previous RF demorphing methods were overly constrained, as they rely on\nassumptions about the distributions of training and testing morphs such as the\nmorphing technique used, face style, and images used to create the morph. In\nthis paper, we introduce a novel diffusion-based approach that effectively\ndisentangles component images from a composite morph image with high visual\nfidelity. Our method is the first to generalize across morph techniques and\nface styles, beating the current state of the art by $\\geq 59.46\\%$ under a\ncommon training protocol across all datasets tested. We train our method on\nmorphs created using synthetically generated face images and test on real\nmorphs, thereby enhancing the practicality of the technique. Experiments on six\ndatasets and two face matchers establish the utility and efficacy of our\nmethod.", "published": "2025-05-20 15:48:27", "link": "http://arxiv.org/abs/2505.14527v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SparC: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling", "abstract": "High-fidelity 3D object synthesis remains significantly more challenging than\n2D image generation due to the unstructured nature of mesh data and the cubic\ncomplexity of dense volumetric grids. Existing two-stage pipelines-compressing\nmeshes with a VAE (using either 2D or 3D supervision), followed by latent\ndiffusion sampling-often suffer from severe detail loss caused by inefficient\nrepresentations and modality mismatches introduced in VAE. We introduce SparC,\na unified framework that combines a sparse deformable marching cubes\nrepresentation SparseCubes with a novel encoder SparConv-VAE. SparseCubes\nconverts raw meshes into high-resolution ($1024^3$) surfaces with arbitrary\ntopology by scattering signed distance and deformation fields onto a sparse\ncube, allowing differentiable optimization. SparConv-VAE is the first\nmodality-consistent variational autoencoder built entirely upon sparse\nconvolutional networks, enabling efficient and near-lossless 3D reconstruction\nsuitable for high-resolution generative modeling through latent diffusion.\nSparC achieves state-of-the-art reconstruction fidelity on challenging inputs,\nincluding open surfaces, disconnected components, and intricate geometry. It\npreserves fine-grained shape details, reduces training and inference cost, and\nintegrates naturally with latent diffusion models for scalable, high-resolution\n3D generation.", "published": "2025-05-20 15:44:54", "link": "http://arxiv.org/abs/2505.14521v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains", "abstract": "This paper introduces ReservoirTTA, a novel plug-in framework designed for\nprolonged test-time adaptation (TTA) in scenarios where the test domain\ncontinuously shifts over time, including cases where domains recur or evolve\ngradually. At its core, ReservoirTTA maintains a reservoir of\ndomain-specialized models -- an adaptive test-time model ensemble -- that both\ndetects new domains via online clustering over style features of incoming\nsamples and routes each sample to the appropriate specialized model, and\nthereby enables domain-specific adaptation. This multi-model strategy overcomes\nkey limitations of single model adaptation, such as catastrophic forgetting,\ninter-domain interference, and error accumulation, ensuring robust and stable\nperformance on sustained non-stationary test distributions. Our theoretical\nanalysis reveals key components that bound parameter variance and prevent model\ncollapse, while our plug-in TTA module mitigates catastrophic forgetting of\npreviously encountered domains. Extensive experiments on the classification\ncorruption benchmarks, including ImageNet-C and CIFAR-10/100-C, as well as the\nCityscapes$\\rightarrow$ACDC semantic segmentation task, covering recurring and\ncontinuously evolving domain shifts, demonstrate that ReservoirTTA\nsignificantly improves adaptation accuracy and maintains stable performance\nacross prolonged, recurring shifts, outperforming state-of-the-art methods.", "published": "2025-05-20 15:39:20", "link": "http://arxiv.org/abs/2505.14511v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Interpretability of Sparse Latent Representations with Class Information", "abstract": "Variational Autoencoders (VAEs) are powerful generative models for learning\nlatent representations. Standard VAEs generate dispersed and unstructured\nlatent spaces by utilizing all dimensions, which limits their interpretability,\nespecially in high-dimensional spaces. To address this challenge, Variational\nSparse Coding (VSC) introduces a spike-and-slab prior distribution, resulting\nin sparse latent representations for each input. These sparse representations,\ncharacterized by a limited number of active dimensions, are inherently more\ninterpretable. Despite this advantage, VSC falls short in providing structured\ninterpretations across samples within the same class. Intuitively, samples from\nthe same class are expected to share similar attributes while allowing for\nvariations in those attributes. This expectation should manifest as consistent\npatterns of active dimensions in their latent representations, but VSC does not\nenforce such consistency.\n  In this paper, we propose a novel approach to enhance the latent space\ninterpretability by ensuring that the active dimensions in the latent space are\nconsistent across samples within the same class. To achieve this, we introduce\na new loss function that encourages samples from the same class to share\nsimilar active dimensions. This alignment creates a more structured and\ninterpretable latent space, where each shared dimension corresponds to a\nhigh-level concept, or \"factor.\" Unlike existing disentanglement-based methods\nthat primarily focus on global factors shared across all classes, our method\ncaptures both global and class-specific factors, thereby enhancing the utility\nand interpretability of latent representations.", "published": "2025-05-20 15:10:01", "link": "http://arxiv.org/abs/2505.14476v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank", "abstract": "DeepSeek-R1 has demonstrated remarkable effectiveness in incentivizing\nreasoning and generalization capabilities of large language models (LLMs)\nthrough reinforcement learning. Nevertheless, the potential of\nreasoning-induced computational modeling has not been thoroughly explored in\nthe context of image quality assessment (IQA), a task critically dependent on\nvisual reasoning. In this paper, we introduce VisualQuality-R1, a\nreasoning-induced no-reference IQA (NR-IQA) model, and we train it with\nreinforcement learning to rank, a learning algorithm tailored to the\nintrinsically relative nature of visual quality. Specifically, for a pair of\nimages, we employ group relative policy optimization to generate multiple\nquality scores for each image. These estimates are then used to compute\ncomparative probabilities of one image having higher quality than the other\nunder the Thurstone model. Rewards for each quality estimate are defined using\ncontinuous fidelity measures rather than discretized binary labels. Extensive\nexperiments show that the proposed VisualQuality-R1 consistently outperforms\ndiscriminative deep learning-based NR-IQA models as well as a recent\nreasoning-induced quality regression method. Moreover, VisualQuality-R1 is\ncapable of generating contextually rich, human-aligned quality descriptions,\nand supports multi-dataset training without requiring perceptual scale\nrealignment. These features make VisualQuality-R1 especially well-suited for\nreliably measuring progress in a wide range of image processing tasks like\nsuper-resolution and image generation.", "published": "2025-05-20 14:56:50", "link": "http://arxiv.org/abs/2505.14460v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video Compression Commander: Plug-and-Play Inference Acceleration for Video Large Language Models", "abstract": "Video large language models (VideoLLM) excel at video understanding, but face\nefficiency challenges due to the quadratic complexity of abundant visual\ntokens. Our systematic analysis of token compression methods for VideoLLMs\nreveals two critical issues: (i) overlooking distinctive visual signals across\nframes, leading to information loss; (ii) suffering from implementation\nconstraints, causing incompatibility with modern architectures or efficient\noperators. To address these challenges, we distill three design principles for\nVideoLLM token compression and propose a plug-and-play inference acceleration\nframework \"Video Compression Commander\" (VidCom2). By quantifying each frame's\nuniqueness, VidCom2 adaptively adjusts compression intensity across frames,\neffectively preserving essential information while reducing redundancy in video\nsequences. Extensive experiments across various VideoLLMs and benchmarks\ndemonstrate the superior performance and efficiency of our VidCom2. With only\n25% visual tokens, VidCom2 achieves 99.6% of the original performance on\nLLaVA-OV while reducing 70.8% of the LLM generation latency. Notably, our Frame\nCompression Adjustment strategy is compatible with other token compression\nmethods to further improve their performance. Our code is available at\nhttps://github.com/xuyang-liu16/VidCom2.", "published": "2025-05-20 14:52:31", "link": "http://arxiv.org/abs/2505.14454v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diving into the Fusion of Monocular Priors for Generalized Stereo Matching", "abstract": "The matching formulation makes it naturally hard for the stereo matching to\nhandle ill-posed regions like occlusions and non-Lambertian surfaces. Fusing\nmonocular priors has been proven helpful for ill-posed matching, but the biased\nmonocular prior learned from small stereo datasets constrains the\ngeneralization. Recently, stereo matching has progressed by leveraging the\nunbiased monocular prior from the vision foundation model (VFM) to improve the\ngeneralization in ill-posed regions. We dive into the fusion process and\nobserve three main problems limiting the fusion of the VFM monocular prior. The\nfirst problem is the misalignment between affine-invariant relative monocular\ndepth and absolute depth of disparity. Besides, when we use the monocular\nfeature in an iterative update structure, the over-confidence in the disparity\nupdate leads to local optima results. A direct fusion of a monocular depth map\ncould alleviate the local optima problem, but noisy disparity results computed\nat the first several iterations will misguide the fusion. In this paper, we\npropose a binary local ordering map to guide the fusion, which converts the\ndepth map into a binary relative format, unifying the relative and absolute\ndepth representation. The computed local ordering map is also used to re-weight\nthe initial disparity update, resolving the local optima and noisy problem. In\naddition, we formulate the final direct fusion of monocular depth to the\ndisparity as a registration problem, where a pixel-wise linear regression\nmodule can globally and adaptively align them. Our method fully exploits the\nmonocular prior to support stereo matching results effectively and efficiently.\nWe significantly improve the performance from the experiments when generalizing\nfrom SceneFlow to Middlebury and Booster datasets while barely reducing the\nefficiency.", "published": "2025-05-20 14:27:45", "link": "http://arxiv.org/abs/2505.14414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency", "abstract": "Large Multimodal Models (LMMs) have recently demonstrated impressive\nperformance on general video comprehension benchmarks. Nevertheless, for\nbroader applications, the robustness of their temporal analysis capability\nneeds to be thoroughly investigated yet predominantly ignored. Motivated by\nthis, we propose a novel temporal robustness benchmark (TemRobBench), which\nintroduces temporal inconsistency perturbations separately at the visual and\ntextual modalities to assess the robustness of models. We evaluate 16\nmainstream LMMs and find that they exhibit over-reliance on prior knowledge and\ntextual context in adversarial environments, while ignoring the actual temporal\ndynamics in the video. To mitigate this issue, we design panoramic direct\npreference optimization (PanoDPO), which encourages LMMs to incorporate both\nvisual and linguistic feature preferences simultaneously. Experimental results\nshow that PanoDPO can effectively enhance the model's robustness and\nreliability in temporal analysis.", "published": "2025-05-20 14:18:56", "link": "http://arxiv.org/abs/2505.14405v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations", "abstract": "Visual-Interleaved Chain-of-Thought (VI-CoT) enables MLLMs to continually\nupdate their understanding and decisions based on step-wise intermediate visual\nstates (IVS), much like a human would, which demonstrates impressive success in\nvarious tasks, thereby leading to emerged advancements in related benchmarks.\nDespite promising progress, current benchmarks provide models with relatively\nfixed IVS, rather than free-style IVS, whch might forcibly distort the original\nthinking trajectories, failing to evaluate their intrinsic reasoning\ncapabilities. More importantly, existing benchmarks neglect to systematically\nexplore the impact factors that IVS would impart to untamed reasoning\nperformance. To tackle above gaps, we introduce a specialized benchmark termed\nViC-Bench, consisting of four representive tasks: maze navigation, jigsaw\npuzzle, embodied long-horizon planning, and complex counting, where each task\nhas dedicated free-style IVS generation pipeline supporting function calls. To\nsystematically examine VI-CoT capability, we propose a thorough evaluation\nsuite incorporating a progressive three-stage strategy with targeted new\nmetrics. Besides, we establish Incremental Prompting Information Injection\n(IPII) strategy to ablatively explore the prompting factors for VI-CoT. We\nextensively conduct evaluations for 18 advanced MLLMs, revealing key insights\ninto their VI-CoT capability. Our proposed benchmark is publicly open at\nHuggingface.", "published": "2025-05-20 14:18:54", "link": "http://arxiv.org/abs/2505.14404v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeepEyes: Incentivizing \"Thinking with Images\" via Reinforcement Learning", "abstract": "Large Vision-Language Models (VLMs) have shown strong capabilities in\nmultimodal understanding and reasoning, yet they are primarily constrained by\ntext-based reasoning processes. However, achieving seamless integration of\nvisual and textual reasoning which mirrors human cognitive processes remains a\nsignificant challenge. In particular, effectively incorporating advanced visual\ninput processing into reasoning mechanisms is still an open question. Thus, in\nthis paper, we explore the interleaved multimodal reasoning paradigm and\nintroduce DeepEyes, a model with \"thinking with images\" capabilities\nincentivized through end-to-end reinforcement learning without the need for\ncold-start SFT. Notably, this ability emerges natively within the model itself,\nleveraging its inherent grounding ability as a tool instead of depending on\nseparate specialized models. Specifically, we propose a tool-use-oriented data\nselection mechanism and a reward strategy to encourage successful tool-assisted\nreasoning trajectories. DeepEyes achieves significant performance gains on\nfine-grained perception and reasoning benchmarks and also demonstrates\nimprovement in grounding, hallucination, and mathematical reasoning tasks.\nInterestingly, we observe the distinct evolution of tool-calling behavior from\ninitial exploration to efficient and accurate exploitation, and diverse\nthinking patterns that closely mirror human visual reasoning processes. Code is\navailable at https://github.com/Visual-Agent/DeepEyes.", "published": "2025-05-20 13:48:11", "link": "http://arxiv.org/abs/2505.14362v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision-Language Modeling Meets Remote Sensing: Models, Datasets and Perspectives", "abstract": "Vision-language modeling (VLM) aims to bridge the information gap between\nimages and natural language. Under the new paradigm of first pre-training on\nmassive image-text pairs and then fine-tuning on task-specific data, VLM in the\nremote sensing domain has made significant progress. The resulting models\nbenefit from the absorption of extensive general knowledge and demonstrate\nstrong performance across a variety of remote sensing data analysis tasks.\nMoreover, they are capable of interacting with users in a conversational\nmanner. In this paper, we aim to provide the remote sensing community with a\ntimely and comprehensive review of the developments in VLM using the two-stage\nparadigm. Specifically, we first cover a taxonomy of VLM in remote sensing:\ncontrastive learning, visual instruction tuning, and text-conditioned image\ngeneration. For each category, we detail the commonly used network architecture\nand pre-training objectives. Second, we conduct a thorough review of existing\nworks, examining foundation models and task-specific adaptation methods in\ncontrastive-based VLM, architectural upgrades, training strategies and model\ncapabilities in instruction-based VLM, as well as generative foundation models\nwith their representative downstream applications. Third, we summarize datasets\nused for VLM pre-training, fine-tuning, and evaluation, with an analysis of\ntheir construction methodologies (including image sources and caption\ngeneration) and key properties, such as scale and task adaptability. Finally,\nwe conclude this survey with insights and discussions on future research\ndirections: cross-modal representation alignment, vague requirement\ncomprehension, explanation-driven model reliability, continually scalable model\ncapabilities, and large-scale datasets featuring richer modalities and greater\nchallenges.", "published": "2025-05-20 13:47:40", "link": "http://arxiv.org/abs/2505.14361v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable", "abstract": "Existing detectors are often trained on biased datasets, leading to the\npossibility of overfitting on non-causal image attributes that are spuriously\ncorrelated with real/synthetic labels. While these biased features enhance\nperformance on the training data, they result in substantial performance\ndegradation when applied to unbiased datasets. One common solution is to\nperform dataset alignment through generative reconstruction, matching the\nsemantic content between real and synthetic images. However, we revisit this\napproach and show that pixel-level alignment alone is insufficient. The\nreconstructed images still suffer from frequency-level misalignment, which can\nperpetuate spurious correlations. To illustrate, we observe that reconstruction\nmodels tend to restore the high-frequency details lost in real images (possibly\ndue to JPEG compression), inadvertently creating a frequency-level\nmisalignment, where synthetic images appear to have richer high-frequency\ncontent than real ones. This misalignment leads to models associating\nhigh-frequency features with synthetic labels, further reinforcing biased cues.\nTo resolve this, we propose Dual Data Alignment (DDA), which aligns both the\npixel and frequency domains. Moreover, we introduce two new test sets:\nDDA-COCO, containing DDA-aligned synthetic images for testing detector\nperformance on the most aligned dataset, and EvalGEN, featuring the latest\ngenerative models for assessing detectors under new generative architectures\nsuch as visual auto-regressive generators. Finally, our extensive evaluations\ndemonstrate that a detector trained exclusively on DDA-aligned MSCOCO could\nimprove across 8 diverse benchmarks by a non-trivial margin, showing a +7.2% on\nin-the-wild benchmarks, highlighting the improved generalizability of unbiased\ndetectors.", "published": "2025-05-20 13:42:38", "link": "http://arxiv.org/abs/2505.14359v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vid2World: Crafting Video Diffusion Models to Interactive World Models", "abstract": "World models, which predict transitions based on history observation and\naction sequences, have shown great promise in improving data efficiency for\nsequential decision making. However, existing world models often require\nextensive domain-specific training and still produce low-fidelity, coarse\npredictions, limiting their applicability in complex environments. In contrast,\nvideo diffusion models trained on large, internet-scale datasets have\ndemonstrated impressive capabilities in generating high-quality videos that\ncapture diverse real-world dynamics. In this work, we present Vid2World, a\ngeneral approach for leveraging and transferring pre-trained video diffusion\nmodels into interactive world models. To bridge the gap, Vid2World performs\ncasualization of a pre-trained video diffusion model by crafting its\narchitecture and training objective to enable autoregressive generation.\nFurthermore, it introduces a causal action guidance mechanism to enhance action\ncontrollability in the resulting interactive world model. Extensive experiments\nin robot manipulation and game simulation domains show that our method offers a\nscalable and effective approach for repurposing highly capable video diffusion\nmodels to interactive world models.", "published": "2025-05-20 13:41:45", "link": "http://arxiv.org/abs/2505.14357v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Egocentric Action-aware Inertial Localization in Point Clouds", "abstract": "This paper presents a novel inertial localization framework named Egocentric\nAction-aware Inertial Localization (EAIL), which leverages egocentric action\ncues from head-mounted IMU signals to localize the target individual within a\n3D point cloud. Human inertial localization is challenging due to IMU sensor\nnoise that causes trajectory drift over time. The diversity of human actions\nfurther complicates IMU signal processing by introducing various motion\npatterns. Nevertheless, we observe that some actions observed through the\nhead-mounted IMU correlate with spatial environmental structures (e.g., bending\ndown to look inside an oven, washing dishes next to a sink), thereby serving as\nspatial anchors to compensate for the localization drift. The proposed EAIL\nframework learns such correlations via hierarchical multi-modal alignment. By\nassuming that the 3D point cloud of the environment is available, it\ncontrastively learns modality encoders that align short-term egocentric action\ncues in IMU signals with local environmental features in the point cloud. These\nencoders are then used in reasoning the IMU data and the point cloud over time\nand space to perform inertial localization. Interestingly, these encoders can\nfurther be utilized to recognize the corresponding sequence of actions as a\nby-product. Extensive experiments demonstrate the effectiveness of the proposed\nframework over state-of-the-art inertial localization and inertial action\nrecognition baselines.", "published": "2025-05-20 13:29:33", "link": "http://arxiv.org/abs/2505.14346v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey", "abstract": "Plane geometry problem solving (PGPS) has recently gained significant\nattention as a benchmark to assess the multi-modal reasoning capabilities of\nlarge vision-language models. Despite the growing interest in PGPS, the\nresearch community still lacks a comprehensive overview that systematically\nsynthesizes recent work in PGPS. To fill this gap, we present a survey of\nexisting PGPS studies. We first categorize PGPS methods into an encoder-decoder\nframework and summarize the corresponding output formats used by their encoders\nand decoders. Subsequently, we classify and analyze these encoders and decoders\naccording to their architectural designs. Finally, we outline major challenges\nand promising directions for future research. In particular, we discuss the\nhallucination issues arising during the encoding phase within encoder-decoder\narchitectures, as well as the problem of data leakage in current PGPS\nbenchmarks.", "published": "2025-05-20 13:27:17", "link": "http://arxiv.org/abs/2505.14340v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach", "abstract": "Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy\nenvironments by integrating visual cues. While recent advances integrate Large\nLanguage Models (LLMs) into AVSR, their high computational cost hinders\ndeployment in resource-constrained settings. To address this, we propose\nLlama-SMoP, an efficient Multimodal LLM that employs a Sparse Mixture of\nProjectors (SMoP) module to scale model capacity without increasing inference\ncosts. By incorporating sparsely-gated mixture-of-experts (MoE) projectors,\nLlama-SMoP enables the use of smaller LLMs while maintaining strong\nperformance. We explore three SMoP configurations and show that Llama-SMoP DEDR\n(Disjoint-Experts, Disjoint-Routers), which uses modality-specific routers and\nexperts, achieves superior performance on ASR, VSR, and AVSR tasks. Ablation\nstudies confirm its effectiveness in expert activation, scalability, and noise\nrobustness.", "published": "2025-05-20 13:20:55", "link": "http://arxiv.org/abs/2505.14336v1", "categories": ["eess.AS", "cs.CV", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Domain Adaptation for Multi-label Image Classification: a Discriminator-free Approach", "abstract": "This paper introduces a discriminator-free adversarial-based approach termed\nDDA-MLIC for Unsupervised Domain Adaptation (UDA) in the context of Multi-Label\nImage Classification (MLIC). While recent efforts have explored\nadversarial-based UDA methods for MLIC, they typically include an additional\ndiscriminator subnet. Nevertheless, decoupling the classification and the\ndiscrimination tasks may harm their task-specific discriminative power. Herein,\nwe address this challenge by presenting a novel adversarial critic directly\nderived from the task-specific classifier. Specifically, we employ a\ntwo-component Gaussian Mixture Model (GMM) to model both source and target\npredictions, distinguishing between two distinct clusters. Instead of using the\ntraditional Expectation Maximization (EM) algorithm, our approach utilizes a\nDeep Neural Network (DNN) to estimate the parameters of each GMM component.\nSubsequently, the source and target GMM parameters are leveraged to formulate\nan adversarial loss using the Fr\\'echet distance. The proposed framework is\ntherefore not only fully differentiable but is also cost-effective as it avoids\nthe expensive iterative process usually induced by the standard EM method. The\nproposed method is evaluated on several multi-label image datasets covering\nthree different types of domain shift. The obtained results demonstrate that\nDDA-MLIC outperforms existing state-of-the-art methods in terms of precision\nwhile requiring a lower number of parameters. The code is made publicly\navailable at github.com/cvi2snt/DDA-MLIC.", "published": "2025-05-20 13:18:20", "link": "http://arxiv.org/abs/2505.14333v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Breaking Down Video LLM Benchmarks: Knowledge, Spatial Perception, or True Temporal Understanding?", "abstract": "Existing video understanding benchmarks often conflate knowledge-based and\npurely image-based questions, rather than clearly isolating a model's temporal\nreasoning ability, which is the key aspect that distinguishes video\nunderstanding from other modalities. We identify two major limitations that\nobscure whether higher scores truly indicate stronger understanding of the\ndynamic content in videos: (1) strong language priors, where models can answer\nquestions without watching the video; and (2) shuffling invariance, where\nmodels maintain similar performance on certain questions even when video frames\nare temporally shuffled. To alleviate these issues, we propose VBenchComp, an\nautomated pipeline that categorizes questions into different domains:\nLLM-Answerable, Semantic, and Temporal. Specifically, LLM-Answerable questions\ncan be answered without viewing the video; Semantic questions remain answerable\neven when the video frames are shuffled; and Temporal questions require\nunderstanding the correct temporal order of frames. The rest of the questions\nare labeled as Others. This can enable fine-grained evaluation of different\ncapabilities of a video LLM. Our analysis reveals nuanced model weaknesses that\nare hidden by traditional overall scores, and we offer insights and\nrecommendations for designing future benchmarks that more accurately assess\nvideo LLMs.", "published": "2025-05-20 13:07:55", "link": "http://arxiv.org/abs/2505.14321v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Accuracy and Fairness of Facial Recognition Technology in Low-Quality Police Images: An Experiment With Synthetic Faces", "abstract": "Facial recognition technology (FRT) is increasingly used in criminal\ninvestigations, yet most evaluations of its accuracy rely on high-quality\nimages, unlike those often encountered by law enforcement. This study examines\nhow five common forms of image degradation--contrast, brightness, motion blur,\npose shift, and resolution--affect FRT accuracy and fairness across demographic\ngroups. Using synthetic faces generated by StyleGAN3 and labeled with FairFace,\nwe simulate degraded images and evaluate performance using Deepface with\nArcFace loss in 1:n identification tasks. We perform an experiment and find\nthat false positive rates peak near baseline image quality, while false\nnegatives increase as degradation intensifies--especially with blur and low\nresolution. Error rates are consistently higher for women and Black\nindividuals, with Black females most affected. These disparities raise concerns\nabout fairness and reliability when FRT is used in real-world investigative\ncontexts. Nevertheless, even under the most challenging conditions and for the\nmost affected subgroups, FRT accuracy remains substantially higher than that of\nmany traditional forensic methods. This suggests that, if appropriately\nvalidated and regulated, FRT should be considered a valuable investigative\ntool. However, algorithmic accuracy alone is not sufficient: we must also\nevaluate how FRT is used in practice, including user-driven data manipulation.\nSuch cases underscore the need for transparency and oversight in FRT deployment\nto ensure both fairness and forensic validity.", "published": "2025-05-20 13:07:16", "link": "http://arxiv.org/abs/2505.14320v1", "categories": ["cs.CV", "stat.AP"], "primary_category": "cs.CV"}
{"title": "RETRO: REthinking Tactile Representation Learning with Material PriOrs", "abstract": "Tactile perception is profoundly influenced by the surface properties of\nobjects in contact. However, despite their crucial role in shaping tactile\nexperiences, these material characteristics have been largely neglected in\nexisting tactile representation learning methods. Most approaches primarily\nfocus on aligning tactile data with visual or textual information, overlooking\nthe richness of tactile feedback that comes from understanding the materials'\ninherent properties. In this work, we address this gap by revisiting the\ntactile representation learning framework and incorporating material-aware\npriors into the learning process. These priors, which represent pre-learned\ncharacteristics specific to different materials, allow tactile models to better\ncapture and generalize the nuances of surface texture. Our method enables more\naccurate, contextually rich tactile feedback across diverse materials and\ntextures, improving performance in real-world applications such as robotics,\nhaptic feedback systems, and material editing.", "published": "2025-05-20 13:06:19", "link": "http://arxiv.org/abs/2505.14319v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "A Review of Vision-Based Assistive Systems for Visually Impaired People: Technologies, Applications, and Future Directions", "abstract": "Visually impaired individuals rely heavily on accurate and timely information\nabout obstacles and their surrounding environments to achieve independent\nliving. In recent years, significant progress has been made in the development\nof assistive technologies, particularly vision-based systems, that enhance\nmobility and facilitate interaction with the external world in both indoor and\noutdoor settings. This paper presents a comprehensive review of recent advances\nin assistive systems designed for the visually impaired, with a focus on\nstate-of-the-art technologies in obstacle detection, navigation, and user\ninteraction. In addition, emerging trends and future directions in visual\nguidance systems are discussed.", "published": "2025-05-20 12:47:07", "link": "http://arxiv.org/abs/2505.14298v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Generating Realistic Underwater Images", "abstract": "This paper explores the use of contrastive learning and generative\nadversarial networks for generating realistic underwater images from synthetic\nimages with uniform lighting. We investigate the performance of image\ntranslation models for generating realistic underwater images using the VAROS\ndataset. Two key evaluation metrics, Fr\\'echet Inception Distance (FID) and\nStructural Similarity Index Measure (SSIM), provide insights into the\ntrade-offs between perceptual quality and structural preservation. For paired\nimage translation, pix2pix achieves the best FID scores due to its paired\nsupervision and PatchGAN discriminator, while the autoencoder model attains the\nhighest SSIM, suggesting better structural fidelity despite producing blurrier\noutputs. Among unpaired methods, CycleGAN achieves a competitive FID score by\nleveraging cycle-consistency loss, whereas CUT, which replaces\ncycle-consistency with contrastive learning, attains higher SSIM, indicating\nimproved spatial similarity retention. Notably, incorporating depth information\ninto CUT results in the lowest overall FID score, demonstrating that depth cues\nenhance realism. However, the slight decrease in SSIM suggests that depth-aware\nlearning may introduce structural variations.", "published": "2025-05-20 12:44:19", "link": "http://arxiv.org/abs/2505.14296v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "RA-Touch: Retrieval-Augmented Touch Understanding with Enriched Visual Data", "abstract": "Visuo-tactile perception aims to understand an object's tactile properties,\nsuch as texture, softness, and rigidity. However, the field remains\nunderexplored because collecting tactile data is costly and labor-intensive. We\nobserve that visually distinct objects can exhibit similar surface textures or\nmaterial properties. For example, a leather sofa and a leather jacket have\ndifferent appearances but share similar tactile properties. This implies that\ntactile understanding can be guided by material cues in visual data, even\nwithout direct tactile supervision. In this paper, we introduce RA-Touch, a\nretrieval-augmented framework that improves visuo-tactile perception by\nleveraging visual data enriched with tactile semantics. We carefully recaption\na large-scale visual dataset with tactile-focused descriptions, enabling the\nmodel to access tactile semantics typically absent from conventional visual\ndatasets. A key challenge remains in effectively utilizing these tactile-aware\nexternal descriptions. RA-Touch addresses this by retrieving visual-textual\nrepresentations aligned with tactile inputs and integrating them to focus on\nrelevant textural and material properties. By outperforming prior methods on\nthe TVL benchmark, our method demonstrates the potential of retrieval-based\nvisual reuse for tactile understanding. Code is available at\nhttps://aim-skku.github.io/RA-Touch", "published": "2025-05-20 12:23:21", "link": "http://arxiv.org/abs/2505.14270v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models", "abstract": "Due to the unidirectional masking mechanism, Decoder-Only models propagate\ninformation from left to right. LVLMs (Large Vision-Language Models) follow the\nsame architecture, with visual information gradually integrated into semantic\nrepresentations during forward propagation. Through systematic analysis, we\nobserve that over 80\\% of the visual information is absorbed into the semantic\nrepresentations. However, the model's attention still predominantly focuses on\nthe visual representations. This misalignment between the attention\ndistribution and the actual information flow undermines the model's visual\nunderstanding ability and contributes to hallucinations. To address this issue,\nwe enhance the model's visual understanding by leveraging the core information\nembedded in semantic representations. Specifically, we identify attention heads\nthat focus on core semantic representations based on their attention\ndistributions. Then, through a two-stage optimization paradigm, we propagate\nthe advantages of these attention heads across the entire model, aligning the\nattention distribution with the actual information flow. We evaluate our method\non three image captioning benchmarks using five different LVLMs, demonstrating\nits effectiveness in significantly reducing hallucinations. Further experiments\nreveal a trade-off between reduced hallucinations and richer details. Notably,\nour method allows for manual adjustment of the model's conservativeness,\nenabling flexible control to meet diverse real-world requirements. Code will be\nreleased once accepted.", "published": "2025-05-20 12:10:13", "link": "http://arxiv.org/abs/2505.14257v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Instructing Text-to-Image Diffusion Models via Classifier-Guided Semantic Optimization", "abstract": "Text-to-image diffusion models have emerged as powerful tools for\nhigh-quality image generation and editing. Many existing approaches rely on\ntext prompts as editing guidance. However, these methods are constrained by the\nneed for manual prompt crafting, which can be time-consuming, introduce\nirrelevant details, and significantly limit editing performance. In this work,\nwe propose optimizing semantic embeddings guided by attribute classifiers to\nsteer text-to-image models toward desired edits, without relying on text\nprompts or requiring any training or fine-tuning of the diffusion model. We\nutilize classifiers to learn precise semantic embeddings at the dataset level.\nThe learned embeddings are theoretically justified as the optimal\nrepresentation of attribute semantics, enabling disentangled and accurate\nedits. Experiments further demonstrate that our method achieves high levels of\ndisentanglement and strong generalization across different domains of data.", "published": "2025-05-20 12:07:01", "link": "http://arxiv.org/abs/2505.14254v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation", "abstract": "This paper focus on few-shot object detection~(FSOD) and instance\nsegmentation~(FSIS), which requires a model to quickly adapt to novel classes\nwith a few labeled instances. The existing methods severely suffer from bias\nclassification because of the missing label issue which naturally exists in an\ninstance-level few-shot scenario and is first formally proposed by us. Our\nanalysis suggests that the standard classification head of most FSOD or FSIS\nmodels needs to be decoupled to mitigate the bias classification. Therefore, we\npropose an embarrassingly simple but effective method that decouples the\nstandard classifier into two heads. Then, these two individual heads are\ncapable of independently addressing clear positive samples and noisy negative\nsamples which are caused by the missing label. In this way, the model can\neffectively learn novel classes while mitigating the effects of noisy negative\nsamples. Without bells and whistles, our model without any additional\ncomputation cost and parameters consistently outperforms its baseline and\nstate-of-the-art by a large margin on PASCAL VOC and MS-COCO benchmarks for\nFSOD and FSIS tasks. The Code is available at\nhttps://csgaobb.github.io/Projects/DCFS.", "published": "2025-05-20 11:47:34", "link": "http://arxiv.org/abs/2505.14239v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning", "abstract": "Traditional visual grounding methods primarily focus on single-image\nscenarios with simple textual references. However, extending these methods to\nreal-world scenarios that involve implicit and complex instructions,\nparticularly in conjunction with multiple images, poses significant challenges,\nwhich is mainly due to the lack of advanced reasoning ability across diverse\nmulti-modal contexts. In this work, we aim to address the more practical\nuniversal grounding task, and propose UniVG-R1, a reasoning guided multimodal\nlarge language model (MLLM) for universal visual grounding, which enhances\nreasoning capabilities through reinforcement learning (RL) combined with\ncold-start data. Specifically, we first construct a high-quality\nChain-of-Thought (CoT) grounding dataset, annotated with detailed reasoning\nchains, to guide the model towards correct reasoning paths via supervised\nfine-tuning. Subsequently, we perform rule-based reinforcement learning to\nencourage the model to identify correct reasoning chains, thereby incentivizing\nits reasoning capabilities. In addition, we identify a difficulty bias arising\nfrom the prevalence of easy samples as RL training progresses, and we propose a\ndifficulty-aware weight adjustment strategy to further strengthen the\nperformance. Experimental results demonstrate the effectiveness of UniVG-R1,\nwhich achieves state-of-the-art performance on MIG-Bench with a 9.1%\nimprovement over the previous method. Furthermore, our model exhibits strong\ngeneralizability, achieving an average improvement of 23.4% in zero-shot\nperformance across four image and video reasoning grounding benchmarks. The\nproject page can be accessed at https://amap-ml.github.io/UniVG-R1-page/.", "published": "2025-05-20 11:40:43", "link": "http://arxiv.org/abs/2505.14231v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Flexible-weighted Chamfer Distance: Enhanced Objective Function for Point Cloud Completion", "abstract": "Chamfer Distance (CD) comprises two components that can evaluate the global\ndistribution and local performance of generated point clouds, making it widely\nutilized as a similarity measure between generated and target point clouds in\npoint cloud completion tasks. Additionally, CD's computational efficiency has\nled to its frequent application as an objective function for guiding point\ncloud generation. However, using CD directly as an objective function with\nfixed equal weights for its two components can often result in seemingly high\noverall performance (i.e., low CD score), while failing to achieve a good\nglobal distribution. This is typically reflected in high Earth Mover's Distance\n(EMD) and Decomposed Chamfer Distance (DCD) scores, alongside poor human\nassessments. To address this issue, we propose a Flexible-Weighted Chamfer\nDistance (FCD) to guide point cloud generation. FCD assigns a higher weight to\nthe global distribution component of CD and incorporates a flexible weighting\nstrategy to adjust the balance between the two components, aiming to improve\nglobal distribution while maintaining robust overall performance. Experimental\nresults on two state-of-the-art networks demonstrate that our method achieves\nsuperior results across multiple evaluation metrics, including CD, EMD, DCD,\nand F-Score, as well as in human evaluations.", "published": "2025-05-20 11:26:05", "link": "http://arxiv.org/abs/2505.14218v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beginning with You: Perceptual-Initialization Improves Vision-Language Representation and Alignment", "abstract": "We introduce Perceptual-Initialization (PI), a paradigm shift in visual\nrepresentation learning that incorporates human perceptual structure during the\ninitialization phase rather than as a downstream fine-tuning step. By\nintegrating human-derived triplet embeddings from the NIGHTS dataset to\ninitialize a CLIP vision encoder, followed by self-supervised learning on\nYFCC15M, our approach demonstrates significant zero-shot performance\nimprovements, without any task-specific fine-tuning, across 29 zero shot\nclassification and 2 retrieval benchmarks. On ImageNet-1K, zero-shot gains\nemerge after approximately 15 epochs of pretraining. Benefits are observed\nacross datasets of various scales, with improvements manifesting at different\nstages of the pretraining process depending on dataset characteristics. Our\napproach consistently enhances zero-shot top-1 accuracy, top-5 accuracy, and\nretrieval recall (e.g., R@1, R@5) across these diverse evaluation tasks,\nwithout requiring any adaptation to target domains. These findings challenge\nthe conventional wisdom of using human-perceptual data primarily for\nfine-tuning and demonstrate that embedding human perceptual structure during\nearly representation learning yields more capable and vision-language aligned\nsystems that generalize immediately to unseen tasks. Our work shows that\n\"beginning with you\", starting with human perception, provides a stronger\nfoundation for general-purpose vision-language intelligence.", "published": "2025-05-20 11:04:14", "link": "http://arxiv.org/abs/2505.14204v1", "categories": ["cs.CV", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "Towards Omnidirectional Reasoning with 360-R1: A Dataset, Benchmark, and GRPO-based Method", "abstract": "Omnidirectional images (ODIs), with their 360{\\deg} field of view, provide\nunparalleled spatial awareness for immersive applications like augmented\nreality and embodied AI. However, the capability of existing multi-modal large\nlanguage models (MLLMs) to comprehend and reason about such panoramic scenes\nremains underexplored. This paper addresses this gap by introducing OmniVQA,\nthe first dataset and conducting the first benchmark for omnidirectional visual\nquestion answering. Our evaluation of state-of-the-art MLLMs reveals\nsignificant limitations in handling omnidirectional visual question answering,\nhighlighting persistent challenges in object localization, feature extraction,\nand hallucination suppression within panoramic contexts. These results\nunderscore the disconnect between current MLLM capabilities and the demands of\nomnidirectional visual understanding, which calls for dedicated architectural\nor training innovations tailored to 360{\\deg} imagery. Building on the OmniVQA\ndataset and benchmark, we further introduce a rule-based reinforcement learning\nmethod, 360-R1, based on Qwen2.5-VL-Instruct. Concretely, we modify the group\nrelative policy optimization (GRPO) by proposing three novel reward functions:\n(1) reasoning process similarity reward, (2) answer semantic accuracy reward,\nand (3) structured format compliance reward. Extensive experiments on our\nOmniVQA demonstrate the superiority of our proposed method in omnidirectional\nspace (+6% improvement).", "published": "2025-05-20 10:55:26", "link": "http://arxiv.org/abs/2505.14197v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bridge the Gap between Past and Future: Siamese Model Optimization for Context-Aware Document Ranking", "abstract": "In the realm of information retrieval, users often engage in multi-turn\ninteractions with search engines to acquire information, leading to the\nformation of sequences of user feedback behaviors. Leveraging the session\ncontext has proven to be beneficial for inferring user search intent and\ndocument ranking. A multitude of approaches have been proposed to exploit\nin-session context for improved document ranking. Despite these advances, the\nlimitation of historical session data for capturing evolving user intent\nremains a challenge. In this work, we explore the integration of future\ncontextual information into the session context to enhance document ranking. We\npresent the siamese model optimization framework, comprising a\nhistory-conditioned model and a future-aware model. The former processes only\nthe historical behavior sequence, while the latter integrates both historical\nand anticipated future behaviors. Both models are trained collaboratively using\nthe supervised labels and pseudo labels predicted by the other. The\nhistory-conditioned model, referred to as ForeRanker, progressively learns\nfuture-relevant information to enhance ranking, while it singly uses historical\nsession at inference time. To mitigate inconsistencies during training, we\nintroduce the peer knowledge distillation method with a dynamic gating\nmechanism, allowing models to selectively incorporate contextual information.\nExperimental results on benchmark datasets demonstrate the effectiveness of our\nForeRanker, showcasing its superior performance compared to existing methods.", "published": "2025-05-20 10:36:25", "link": "http://arxiv.org/abs/2505.14180v1", "categories": ["cs.IR", "cs.CV", "H.3.3"], "primary_category": "cs.IR"}
{"title": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "abstract": "We consider the problem of sampling distributions stemming from non-convex\npotentials with Unadjusted Langevin Algorithm (ULA). We prove the stability of\nthe discrete-time ULA to drift approximations under the assumption that the\npotential is strongly convex at infinity. In many context, e.g. imaging inverse\nproblems, potentials are non-convex and non-smooth. Proximal Stochastic\nGradient Langevin Algorithm (PSGLA) is a popular algorithm to handle such\npotentials. It combines the forward-backward optimization algorithm with a ULA\nstep. Our main stability result combined with properties of the Moreau envelope\nallows us to derive the first proof of convergence of the PSGLA for non-convex\npotentials. We empirically validate our methodology on synthetic data and in\nthe context of imaging inverse problems. In particular, we observe that PSGLA\nexhibits faster convergence rates than Stochastic Gradient Langevin Algorithm\nfor posterior sampling while preserving its restoration properties.", "published": "2025-05-20 10:29:57", "link": "http://arxiv.org/abs/2505.14177v1", "categories": ["stat.ML", "cs.CV", "cs.LG"], "primary_category": "stat.ML"}
{"title": "LMP: Leveraging Motion Prior in Zero-Shot Video Generation with Diffusion Transformer", "abstract": "In recent years, large-scale pre-trained diffusion transformer models have\nmade significant progress in video generation. While current DiT models can\nproduce high-definition, high-frame-rate, and highly diverse videos, there is a\nlack of fine-grained control over the video content. Controlling the motion of\nsubjects in videos using only prompts is challenging, especially when it comes\nto describing complex movements. Further, existing methods fail to control the\nmotion in image-to-video generation, as the subject in the reference image\noften differs from the subject in the reference video in terms of initial\nposition, size, and shape. To address this, we propose the Leveraging Motion\nPrior (LMP) framework for zero-shot video generation. Our framework harnesses\nthe powerful generative capabilities of pre-trained diffusion transformers to\nenable motion in the generated videos to reference user-provided motion videos\nin both text-to-video and image-to-video generation. To this end, we first\nintroduce a foreground-background disentangle module to distinguish between\nmoving subjects and backgrounds in the reference video, preventing interference\nin the target video generation. A reweighted motion transfer module is designed\nto allow the target video to reference the motion from the reference video. To\navoid interference from the subject in the reference video, we propose an\nappearance separation module to suppress the appearance of the reference\nsubject in the target video. We annotate the DAVIS dataset with detailed\nprompts for our experiments and design evaluation metrics to validate the\neffectiveness of our method. Extensive experiments demonstrate that our\napproach achieves state-of-the-art performance in generation quality,\nprompt-video consistency, and control capability. Our homepage is available at\nhttps://vpx-ecnu.github.io/LMP-Website/", "published": "2025-05-20 10:18:29", "link": "http://arxiv.org/abs/2505.14167v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "M3Depth: Wavelet-Enhanced Depth Estimation on Mars via Mutual Boosting of Dual-Modal Data", "abstract": "Depth estimation plays a great potential role in obstacle avoidance and\nnavigation for further Mars exploration missions. Compared to traditional\nstereo matching, learning-based stereo depth estimation provides a data-driven\napproach to infer dense and precise depth maps from stereo image pairs.\nHowever, these methods always suffer performance degradation in environments\nwith sparse textures and lacking geometric constraints, such as the\nunstructured terrain of Mars. To address these challenges, we propose M3Depth,\na depth estimation model tailored for Mars rovers. Considering the sparse and\nsmooth texture of Martian terrain, which is primarily composed of low-frequency\nfeatures, our model incorporates a convolutional kernel based on wavelet\ntransform that effectively captures low-frequency response and expands the\nreceptive field. Additionally, we introduce a consistency loss that explicitly\nmodels the complementary relationship between depth map and surface normal map,\nutilizing the surface normal as a geometric constraint to enhance the accuracy\nof depth estimation. Besides, a pixel-wise refinement module with mutual\nboosting mechanism is designed to iteratively refine both depth and surface\nnormal predictions. Experimental results on synthetic Mars datasets with depth\nannotations show that M3Depth achieves a significant 16% improvement in depth\nestimation accuracy compared to other state-of-the-art methods in depth\nestimation. Furthermore, the model demonstrates strong applicability in\nreal-world Martian scenarios, offering a promising solution for future Mars\nexploration missions.", "published": "2025-05-20 10:13:00", "link": "http://arxiv.org/abs/2505.14159v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "ReactDiff: Latent Diffusion for Facial Reaction Generation", "abstract": "Given the audio-visual clip of the speaker, facial reaction generation aims\nto predict the listener's facial reactions. The challenge lies in capturing the\nrelevance between video and audio while balancing appropriateness, realism, and\ndiversity. While prior works have mostly focused on uni-modal inputs or\nsimplified reaction mappings, recent approaches such as PerFRDiff have explored\nmulti-modal inputs and the one-to-many nature of appropriate reaction mappings.\nIn this work, we propose the Facial Reaction Diffusion (ReactDiff) framework\nthat uniquely integrates a Multi-Modality Transformer with conditional\ndiffusion in the latent space for enhanced reaction generation. Unlike existing\nmethods, ReactDiff leverages intra- and inter-class attention for fine-grained\nmulti-modal interaction, while the latent diffusion process between the encoder\nand decoder enables diverse yet contextually appropriate outputs. Experimental\nresults demonstrate that ReactDiff significantly outperforms existing\napproaches, achieving a facial reaction correlation of 0.26 and diversity score\nof 0.094 while maintaining competitive realism. The code is open-sourced at\n\\href{https://github.com/Hunan-Tiger/ReactDiff}{github}.", "published": "2025-05-20 10:01:37", "link": "http://arxiv.org/abs/2505.14151v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Hunyuan-Game: Industrial-grade Intelligent Game Creation Model", "abstract": "Intelligent game creation represents a transformative advancement in game\ndevelopment, utilizing generative artificial intelligence to dynamically\ngenerate and enhance game content. Despite notable progress in generative\nmodels, the comprehensive synthesis of high-quality game assets, including both\nimages and videos, remains a challenging frontier. To create high-fidelity game\ncontent that simultaneously aligns with player preferences and significantly\nboosts designer efficiency, we present Hunyuan-Game, an innovative project\ndesigned to revolutionize intelligent game production. Hunyuan-Game encompasses\ntwo primary branches: image generation and video generation. The image\ngeneration component is built upon a vast dataset comprising billions of game\nimages, leading to the development of a group of customized image generation\nmodels tailored for game scenarios: (1) General Text-to-Image Generation. (2)\nGame Visual Effects Generation, involving text-to-effect and reference\nimage-based game visual effect generation. (3) Transparent Image Generation for\ncharacters, scenes, and game visual effects. (4) Game Character Generation\nbased on sketches, black-and-white images, and white models. The video\ngeneration component is built upon a comprehensive dataset of millions of game\nand anime videos, leading to the development of five core algorithmic models,\neach targeting critical pain points in game development and having robust\nadaptation to diverse game video scenarios: (1) Image-to-Video Generation. (2)\n360 A/T Pose Avatar Video Synthesis. (3) Dynamic Illustration Generation. (4)\nGenerative Video Super-Resolution. (5) Interactive Game Video Generation. These\nimage and video generation models not only exhibit high-level aesthetic\nexpression but also deeply integrate domain-specific knowledge, establishing a\nsystematic understanding of diverse game and anime art styles.", "published": "2025-05-20 09:39:48", "link": "http://arxiv.org/abs/2505.14135v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Intra-class Patch Swap for Self-Distillation", "abstract": "Knowledge distillation (KD) is a valuable technique for compressing large\ndeep learning models into smaller, edge-suitable networks. However,\nconventional KD frameworks rely on pre-trained high-capacity teacher networks,\nwhich introduce significant challenges such as increased memory/storage\nrequirements, additional training costs, and ambiguity in selecting an\nappropriate teacher for a given student model. Although a teacher-free\ndistillation (self-distillation) has emerged as a promising alternative, many\nexisting approaches still rely on architectural modifications or complex\ntraining procedures, which limit their generality and efficiency.\n  To address these limitations, we propose a novel framework based on\nteacher-free distillation that operates using a single student network without\nany auxiliary components, architectural modifications, or additional learnable\nparameters. Our approach is built on a simple yet highly effective\naugmentation, called intra-class patch swap augmentation. This augmentation\nsimulates a teacher-student dynamic within a single model by generating pairs\nof intra-class samples with varying confidence levels, and then applying\ninstance-to-instance distillation to align their predictive distributions. Our\nmethod is conceptually simple, model-agnostic, and easy to implement, requiring\nonly a single augmentation function. Extensive experiments across image\nclassification, semantic segmentation, and object detection show that our\nmethod consistently outperforms both existing self-distillation baselines and\nconventional teacher-based KD approaches. These results suggest that the\nsuccess of self-distillation could hinge on the design of the augmentation\nitself. Our codes are available at\nhttps://github.com/hchoi71/Intra-class-Patch-Swap.", "published": "2025-05-20 09:30:19", "link": "http://arxiv.org/abs/2505.14124v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CONSIGN: Conformal Segmentation Informed by Spatial Groupings via Decomposition", "abstract": "Most machine learning-based image segmentation models produce pixel-wise\nconfidence scores - typically derived from softmax outputs - that represent the\nmodel's predicted probability for each class label at every pixel. While this\ninformation can be particularly valuable in high-stakes domains such as medical\nimaging, these (uncalibrated) scores are heuristic in nature and do not\nconstitute rigorous quantitative uncertainty estimates. Conformal prediction\n(CP) provides a principled framework for transforming heuristic confidence\nscores into statistically valid uncertainty estimates. However, applying CP\ndirectly to image segmentation ignores the spatial correlations between pixels,\na fundamental characteristic of image data. This can result in overly\nconservative and less interpretable uncertainty estimates. To address this, we\npropose CONSIGN (Conformal Segmentation Informed by Spatial Groupings via\nDecomposition), a CP-based method that incorporates spatial correlations to\nimprove uncertainty quantification in image segmentation. Our method generates\nmeaningful prediction sets that come with user-specified, high-probability\nerror guarantees. It is compatible with any pre-trained segmentation model\ncapable of generating multiple sample outputs - such as those using dropout,\nBayesian modeling, or ensembles. We evaluate CONSIGN against a standard\npixel-wise CP approach across three medical imaging datasets and two COCO\ndataset subsets, using three different pre-trained segmentation models. Results\ndemonstrate that accounting for spatial structure significantly improves\nperformance across multiple metrics and enhances the quality of uncertainty\nestimates.", "published": "2025-05-20 09:19:37", "link": "http://arxiv.org/abs/2505.14113v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Unintended Bias in 2D+ Image Segmentation and Its Effect on Attention Asymmetry", "abstract": "Supervised pretrained models have become widely used in deep learning,\nespecially for image segmentation tasks. However, when applied to specialized\ndatasets such as biomedical imaging, pretrained weights often introduce\nunintended biases. These biases cause models to assign different levels of\nimportance to different slices, leading to inconsistencies in feature\nutilization, which can be observed as asymmetries in saliency map\ndistributions. This transfer of color distributions from natural images to\nnon-natural datasets can compromise model performance and reduce the\nreliability of results. In this study, we investigate the effects of these\nbiases and propose strategies to mitigate them. Through a series of\nexperiments, we test both pretrained and randomly initialized models, comparing\ntheir performance and saliency map distributions. Our proposed methods, which\naim to neutralize the bias introduced by pretrained color channel weights,\ndemonstrate promising results, offering a practical approach to improving model\nexplainability while maintaining the benefits of pretrained models. This\npublication presents our findings, providing insights into addressing\npretrained weight biases across various deep learning tasks.", "published": "2025-05-20 09:11:53", "link": "http://arxiv.org/abs/2505.14105v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unlocking the Power of SAM 2 for Few-Shot Segmentation", "abstract": "Few-Shot Segmentation (FSS) aims to learn class-agnostic segmentation on few\nclasses to segment arbitrary classes, but at the risk of overfitting. To\naddress this, some methods use the well-learned knowledge of foundation models\n(e.g., SAM) to simplify the learning process. Recently, SAM 2 has extended SAM\nby supporting video segmentation, whose class-agnostic matching ability is\nuseful to FSS. A simple idea is to encode support foreground (FG) features as\nmemory, with which query FG features are matched and fused. Unfortunately, the\nFG objects in different frames of SAM 2's video data are always the same\nidentity, while those in FSS are different identities, i.e., the matching step\nis incompatible. Therefore, we design Pseudo Prompt Generator to encode pseudo\nquery memory, matching with query features in a compatible way. However, the\nmemories can never be as accurate as the real ones, i.e., they are likely to\ncontain incomplete query FG, and some unexpected query background (BG)\nfeatures, leading to wrong segmentation. Hence, we further design Iterative\nMemory Refinement to fuse more query FG features into the memory, and devise a\nSupport-Calibrated Memory Attention to suppress the unexpected query BG\nfeatures in memory. Extensive experiments have been conducted on PASCAL-5$^i$\nand COCO-20$^i$ to validate the effectiveness of our design, e.g., the 1-shot\nmIoU can be 4.2\\% better than the best baseline.", "published": "2025-05-20 09:02:53", "link": "http://arxiv.org/abs/2505.14100v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generalizable Multispectral Land Cover Classification via Frequency-Aware Mixture of Low-Rank Token Experts", "abstract": "We introduce Land-MoE, a novel approach for multispectral land cover\nclassification (MLCC). Spectral shift, which emerges from disparities in\nsensors and geospatial conditions, poses a significant challenge in this\ndomain. Existing methods predominantly rely on domain adaptation and\ngeneralization strategies, often utilizing small-scale models that exhibit\nlimited performance. In contrast, Land-MoE addresses these issues by\nhierarchically inserting a Frequency-aware Mixture of Low-rank Token Experts,\nto fine-tune Vision Foundation Models (VFMs) in a parameter-efficient manner.\nSpecifically, Land-MoE comprises two key modules: the mixture of low-rank token\nexperts (MoLTE) and frequency-aware filters (FAF). MoLTE leverages\nrank-differentiated tokens to generate diverse feature adjustments for\nindividual instances within multispectral images. By dynamically combining\nlearnable low-rank token experts of varying ranks, it enhances the robustness\nagainst spectral shifts. Meanwhile, FAF conducts frequency-domain modulation on\nthe refined features. This process enables the model to effectively capture\nfrequency band information that is strongly correlated with semantic essence,\nwhile simultaneously suppressing frequency noise irrelevant to the task.\nComprehensive experiments on MLCC tasks involving cross-sensor and\ncross-geospatial setups demonstrate that Land-MoE outperforms existing methods\nby a large margin. Additionally, the proposed approach has also achieved\nstate-of-the-art performance in domain generalization semantic segmentation\ntasks of RGB remote sensing images.", "published": "2025-05-20 08:52:28", "link": "http://arxiv.org/abs/2505.14088v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Large-Scale Multi-Character Interaction Synthesis", "abstract": "Generating large-scale multi-character interactions is a challenging and\nimportant task in character animation. Multi-character interactions involve not\nonly natural interactive motions but also characters coordinated with each\nother for transition. For example, a dance scenario involves characters dancing\nwith partners and also characters coordinated to new partners based on spatial\nand temporal observations. We term such transitions as coordinated interactions\nand decompose them into interaction synthesis and transition planning. Previous\nmethods of single-character animation do not consider interactions that are\ncritical for multiple characters. Deep-learning-based interaction synthesis\nusually focuses on two characters and does not consider transition planning.\nOptimization-based interaction synthesis relies on manually designing objective\nfunctions that may not generalize well. While crowd simulation involves more\ncharacters, their interactions are sparse and passive. We identify two\nchallenges to multi-character interaction synthesis, including the lack of data\nand the planning of transitions among close and dense interactions. Existing\ndatasets either do not have multiple characters or do not have close and dense\ninteractions. The planning of transitions for multi-character close and dense\ninteractions needs both spatial and temporal considerations. We propose a\nconditional generative pipeline comprising a coordinatable multi-character\ninteraction space for interaction synthesis and a transition planning network\nfor coordinations. Our experiments demonstrate the effectiveness of our\nproposed pipeline for multicharacter interaction synthesis and the applications\nfacilitated by our method show the scalability and transferability.", "published": "2025-05-20 08:49:27", "link": "http://arxiv.org/abs/2505.14087v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Textual Steering Vectors Can Improve Visual Understanding in Multimodal Large Language Models", "abstract": "Steering methods have emerged as effective and targeted tools for guiding\nlarge language models' (LLMs) behavior without modifying their parameters.\nMultimodal large language models (MLLMs), however, do not currently enjoy the\nsame suite of techniques, due in part to their recency and architectural\ndiversity. Inspired by this gap, we investigate whether MLLMs can be steered\nusing vectors derived from their text-only LLM backbone, via sparse\nautoencoders (SAEs), mean shift, and linear probing. We find that text-derived\nsteering consistently enhances multimodal accuracy across diverse MLLM\narchitectures and visual tasks. In particular, mean shift boosts spatial\nrelationship accuracy on CV-Bench by up to +7.3% and counting accuracy by up to\n+3.3%, outperforming prompting and exhibiting strong generalization to\nout-of-distribution datasets. These results highlight textual steering vectors\nas a powerful, efficient mechanism for enhancing grounding in MLLMs with\nminimal additional data collection and computational overhead.", "published": "2025-05-20 08:23:08", "link": "http://arxiv.org/abs/2505.14071v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Place Recognition: A Comprehensive Review, Current Challenges and Future Directions", "abstract": "Place recognition is a cornerstone of vehicle navigation and mapping, which\nis pivotal in enabling systems to determine whether a location has been\npreviously visited. This capability is critical for tasks such as loop closure\nin Simultaneous Localization and Mapping (SLAM) and long-term navigation under\nvarying environmental conditions. In this survey, we comprehensively review\nrecent advancements in place recognition, emphasizing three representative\nmethodological paradigms: Convolutional Neural Network (CNN)-based approaches,\nTransformer-based frameworks, and cross-modal strategies. We begin by\nelucidating the significance of place recognition within the broader context of\nautonomous systems. Subsequently, we trace the evolution of CNN-based methods,\nhighlighting their contributions to robust visual descriptor learning and\nscalability in large-scale environments. We then examine the emerging class of\nTransformer-based models, which leverage self-attention mechanisms to capture\nglobal dependencies and offer improved generalization across diverse scenes.\nFurthermore, we discuss cross-modal approaches that integrate heterogeneous\ndata sources such as Lidar, vision, and text description, thereby enhancing\nresilience to viewpoint, illumination, and seasonal variations. We also\nsummarize standard datasets and evaluation metrics widely adopted in the\nliterature. Finally, we identify current research challenges and outline\nprospective directions, including domain adaptation, real-time performance, and\nlifelong learning, to inspire future advancements in this domain. The unified\nframework of leading-edge place recognition methods, i.e., code library, and\nthe results of their experimental evaluations are available at\nhttps://github.com/CV4RA/SOTA-Place-Recognitioner.", "published": "2025-05-20 08:16:37", "link": "http://arxiv.org/abs/2505.14068v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI", "abstract": "In many real-world applications, deployed models encounter inputs that differ\nfrom the data seen during training. Out-of-distribution detection identifies\nwhether an input stems from an unseen distribution, while open-world\nrecognition flags such inputs to ensure the system remains robust as\never-emerging, previously $unknown$ categories appear and must be addressed\nwithout retraining. Foundation and vision-language models are pre-trained on\nlarge and diverse datasets with the expectation of broad generalization across\ndomains, including medical imaging. However, benchmarking these models on test\nsets with only a few common outlier types silently collapses the evaluation\nback to a closed-set problem, masking failures on rare or truly novel\nconditions encountered in clinical use.\n  We therefore present $NOVA$, a challenging, real-life $evaluation-only$\nbenchmark of $\\sim$900 brain MRI scans that span 281 rare pathologies and\nheterogeneous acquisition protocols. Each case includes rich clinical\nnarratives and double-blinded expert bounding-box annotations. Together, these\nenable joint assessment of anomaly localisation, visual captioning, and\ndiagnostic reasoning. Because NOVA is never used for training, it serves as an\n$extreme$ stress-test of out-of-distribution generalisation: models must bridge\na distribution gap both in sample appearance and in semantic space. Baseline\nresults with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and\nQwen2.5-VL-72B) reveal substantial performance drops across all tasks,\nestablishing NOVA as a rigorous testbed for advancing models that can detect,\nlocalize, and reason about truly unknown anomalies.", "published": "2025-05-20 08:10:57", "link": "http://arxiv.org/abs/2505.14064v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Scaling Vision Mamba Across Resolutions via Fractal Traversal", "abstract": "Vision Mamba has recently emerged as a promising alternative to\nTransformer-based architectures, offering linear complexity in sequence length\nwhile maintaining strong modeling capacity. However, its adaptation to visual\ninputs is hindered by challenges in 2D-to-1D patch serialization and weak\nscalability across input resolutions. Existing serialization strategies such as\nraster scanning disrupt local spatial continuity and limit the model's ability\nto generalize across scales. In this paper, we propose FractalMamba++, a robust\nvision backbone that leverages fractal-based patch serialization via Hilbert\ncurves to preserve spatial locality and enable seamless resolution\nadaptability. To address long-range dependency fading in high-resolution\ninputs, we further introduce a Cross-State Routing (CSR) mechanism that\nenhances global context propagation through selective state reuse.\nAdditionally, we propose a Positional-Relation Capture (PRC) module to recover\nlocal adjacency disrupted by curve inflection points. Extensive experiments on\nimage classification, semantic segmentation, object detection, and change\ndetection demonstrate that FractalMamba++ consistently outperforms previous\nMamba-based backbones, particularly under high-resolution settings.", "published": "2025-05-20 08:08:28", "link": "http://arxiv.org/abs/2505.14062v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting", "abstract": "Document image parsing is challenging due to its complexly intertwined\nelements such as text paragraphs, figures, formulas, and tables. Current\napproaches either assemble specialized expert models or directly generate\npage-level content autoregressively, facing integration overhead, efficiency\nbottlenecks, and layout structure degradation despite their decent performance.\nTo address these limitations, we present \\textit{Dolphin}\n(\\textit{\\textbf{Do}cument Image \\textbf{P}arsing via \\textbf{H}eterogeneous\nAnchor Prompt\\textbf{in}g}), a novel multimodal document image parsing model\nfollowing an analyze-then-parse paradigm. In the first stage, Dolphin generates\na sequence of layout elements in reading order. These heterogeneous elements,\nserving as anchors and coupled with task-specific prompts, are fed back to\nDolphin for parallel content parsing in the second stage. To train Dolphin, we\nconstruct a large-scale dataset of over 30 million samples, covering\nmulti-granularity parsing tasks. Through comprehensive evaluations on both\nprevalent benchmarks and self-constructed ones, Dolphin achieves\nstate-of-the-art performance across diverse page-level and element-level\nsettings, while ensuring superior efficiency through its lightweight\narchitecture and parallel parsing mechanism. The code and pre-trained models\nare publicly available at https://github.com/ByteDance/Dolphin", "published": "2025-05-20 08:03:59", "link": "http://arxiv.org/abs/2505.14059v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Concept-Driven Logical Rules for Interpretable and Generalizable Medical Image Classification", "abstract": "The pursuit of decision safety in clinical applications highlights the\npotential of concept-based methods in medical imaging. While these models offer\nactive interpretability, they often suffer from concept leakages, where\nunintended information within soft concept representations undermines both\ninterpretability and generalizability. Moreover, most concept-based models\nfocus solely on local explanations (instance-level), neglecting the global\ndecision logic (dataset-level). To address these limitations, we propose\nConcept Rule Learner (CRL), a novel framework to learn Boolean logical rules\nfrom binarized visual concepts. CRL employs logical layers to capture concept\ncorrelations and extract clinically meaningful rules, thereby providing both\nlocal and global interpretability. Experiments on two medical image\nclassification tasks show that CRL achieves competitive performance with\nexisting methods while significantly improving generalizability to\nout-of-distribution data. The code of our work is available at\nhttps://github.com/obiyoag/crl.", "published": "2025-05-20 07:48:33", "link": "http://arxiv.org/abs/2505.14049v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Selective Structured State Space for Multispectral-fused Small Target Detection", "abstract": "Target detection in high-resolution remote sensing imagery faces challenges\ndue to the low recognition accuracy of small targets and high computational\ncosts. The computational complexity of the Transformer architecture increases\nquadratically with image resolution, while Convolutional Neural Networks (CNN)\narchitectures are forced to stack deeper convolutional layers to expand their\nreceptive fields, leading to an explosive growth in computational demands. To\naddress these computational constraints, we leverage Mamba's linear complexity\nfor efficiency. However, Mamba's performance declines for small targets,\nprimarily because small targets occupy a limited area in the image and have\nlimited semantic information. Accurate identification of these small targets\nnecessitates not only Mamba's global attention capabilities but also the\nprecise capture of fine local details. To this end, we enhance Mamba by\ndeveloping the Enhanced Small Target Detection (ESTD) module and the\nConvolutional Attention Residual Gate (CARG) module. The ESTD module bolsters\nlocal attention to capture fine-grained details, while the CARG module, built\nupon Mamba, emphasizes spatial and channel-wise information, collectively\nimproving the model's ability to capture distinctive representations of small\ntargets. Additionally, to highlight the semantic representation of small\ntargets, we design a Mask Enhanced Pixel-level Fusion (MEPF) module for\nmultispectral fusion, which enhances target features by effectively fusing\nvisible and infrared multimodal information.", "published": "2025-05-20 07:39:27", "link": "http://arxiv.org/abs/2505.14043v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adversarially Pretrained Transformers may be Universally Robust In-Context Learners", "abstract": "Adversarial training is one of the most effective adversarial defenses, but\nit incurs a high computational cost. In this study, we show that transformers\nadversarially pretrained on diverse tasks can serve as robust foundation models\nand eliminate the need for adversarial training in downstream tasks.\nSpecifically, we theoretically demonstrate that through in-context learning, a\nsingle adversarially pretrained transformer can robustly generalize to multiple\nunseen tasks without any additional training, i.e., without any parameter\nupdates. This robustness stems from the model's focus on robust features and\nits resistance to attacks that exploit non-predictive features. Besides these\npositive findings, we also identify several limitations. Under certain\nconditions (though unrealistic), no universally robust single-layer\ntransformers exist. Moreover, robust transformers exhibit an\naccuracy--robustness trade-off and require a large number of in-context\ndemonstrations. The code is available at\nhttps://github.com/s-kumano/universally-robust-in-context-learner.", "published": "2025-05-20 07:39:22", "link": "http://arxiv.org/abs/2505.14042v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AppleGrowthVision: A large-scale stereo dataset for phenological analysis, fruit detection, and 3D reconstruction in apple orchards", "abstract": "Deep learning has transformed computer vision for precision agriculture, yet\napple orchard monitoring remains limited by dataset constraints. The lack of\ndiverse, realistic datasets and the difficulty of annotating dense,\nheterogeneous scenes. Existing datasets overlook different growth stages and\nstereo imagery, both essential for realistic 3D modeling of orchards and tasks\nlike fruit localization, yield estimation, and structural analysis. To address\nthese gaps, we present AppleGrowthVision, a large-scale dataset comprising two\nsubsets. The first includes 9,317 high resolution stereo images collected from\na farm in Brandenburg (Germany), covering six agriculturally validated growth\nstages over a full growth cycle. The second subset consists of 1,125 densely\nannotated images from the same farm in Brandenburg and one in Pillnitz\n(Germany), containing a total of 31,084 apple labels. AppleGrowthVision\nprovides stereo-image data with agriculturally validated growth stages,\nenabling precise phenological analysis and 3D reconstructions. Extending\nMinneApple with our data improves YOLOv8 performance by 7.69 % in terms of\nF1-score, while adding it to MinneApple and MAD boosts Faster R-CNN F1-score by\n31.06 %. Additionally, six BBCH stages were predicted with over 95 % accuracy\nusing VGG16, ResNet152, DenseNet201, and MobileNetv2. AppleGrowthVision bridges\nthe gap between agricultural science and computer vision, by enabling the\ndevelopment of robust models for fruit detection, growth modeling, and 3D\nanalysis in precision agriculture. Future work includes improving annotation,\nenhancing 3D reconstruction, and extending multimodal analysis across all\ngrowth stages.", "published": "2025-05-20 07:29:22", "link": "http://arxiv.org/abs/2505.14029v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "OmniStyle: Filtering High Quality Style Transfer Data at Scale", "abstract": "In this paper, we introduce OmniStyle-1M, a large-scale paired style transfer\ndataset comprising over one million content-style-stylized image triplets\nacross 1,000 diverse style categories, each enhanced with textual descriptions\nand instruction prompts. We show that OmniStyle-1M can not only enable\nefficient and scalable of style transfer models through supervised training but\nalso facilitate precise control over target stylization. Especially, to ensure\nthe quality of the dataset, we introduce OmniFilter, a comprehensive style\ntransfer quality assessment framework, which filters high-quality triplets\nbased on content preservation, style consistency, and aesthetic appeal.\nBuilding upon this foundation, we propose OmniStyle, a framework based on the\nDiffusion Transformer (DiT) architecture designed for high-quality and\nefficient style transfer. This framework supports both instruction-guided and\nimage-guided style transfer, generating high resolution outputs with\nexceptional detail. Extensive qualitative and quantitative evaluations\ndemonstrate OmniStyle's superior performance compared to existing approaches,\nhighlighting its efficiency and versatility. OmniStyle-1M and its accompanying\nmethodologies provide a significant contribution to advancing high-quality\nstyle transfer, offering a valuable resource for the research community.", "published": "2025-05-20 07:29:21", "link": "http://arxiv.org/abs/2505.14028v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Efficient Multi-Scale Deformable Attention on NPU", "abstract": "Multi-scale deformable attention (MSDA) is a flexible and powerful feature\nextraction mechanism for visual tasks, but its random-access grid sampling\nstrategy poses significant optimization challenges, especially on\ndomain-specific accelerators such as NPUs. In this work, we present a co-design\napproach that systematically rethinks memory access and computation strategies\nfor MSDA on the Ascend NPU architecture. With this co-design approach, our\nimplementation supports both efficient forward and backward computation, is\nfully adapted for training workloads, and incorporates a suite of\nhardware-aware optimizations. Extensive experiments show that our solution\nachieves up to $5.9\\times$ (forward), $8.9\\times$ (backward), and $7.3\\times$\n(end-to-end training) speedup over the grid sample-based baseline, and\n$1.9\\times$, $2.4\\times$, and $2.0\\times$ acceleration over the latest vendor\nlibrary, respectively.", "published": "2025-05-20 07:25:23", "link": "http://arxiv.org/abs/2505.14022v1", "categories": ["cs.PF", "cs.CV"], "primary_category": "cs.PF"}
{"title": "Adversarial Training from Mean Field Perspective", "abstract": "Although adversarial training is known to be effective against adversarial\nexamples, training dynamics are not well understood. In this study, we present\nthe first theoretical analysis of adversarial training in random deep neural\nnetworks without any assumptions on data distributions. We introduce a new\ntheoretical framework based on mean field theory, which addresses the\nlimitations of existing mean field-based approaches. Based on this framework,\nwe derive (empirically tight) upper bounds of $\\ell_q$ norm-based adversarial\nloss with $\\ell_p$ norm-based adversarial examples for various values of $p$\nand $q$. Moreover, we prove that networks without shortcuts are generally not\nadversarially trainable and that adversarial training reduces network capacity.\nWe also show that network width alleviates these issues. Furthermore, we\npresent the various impacts of the input and output dimensions on the upper\nbounds and time evolution of the weight variance.", "published": "2025-05-20 07:22:21", "link": "http://arxiv.org/abs/2505.14021v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "End-to-end Cortical Surface Reconstruction from Clinical Magnetic Resonance Images", "abstract": "Surface-based cortical analysis is valuable for a variety of neuroimaging\ntasks, such as spatial normalization, parcellation, and gray matter (GM)\nthickness estimation. However, most tools for estimating cortical surfaces work\nexclusively on scans with at least 1 mm isotropic resolution and are tuned to a\nspecific magnetic resonance (MR) contrast, often T1-weighted (T1w). This\nprecludes application using most clinical MR scans, which are very\nheterogeneous in terms of contrast and resolution. Here, we use synthetic\ndomain-randomized data to train the first neural network for explicit\nestimation of cortical surfaces from scans of any contrast and resolution,\nwithout retraining. Our method deforms a template mesh to the white matter (WM)\nsurface, which guarantees topological correctness. This mesh is further\ndeformed to estimate the GM surface. We compare our method to\nrecon-all-clinical (RAC), an implicit surface reconstruction method which is\ncurrently the only other tool capable of processing heterogeneous clinical MR\nscans, on ADNI and a large clinical dataset (n=1,332). We show a approximately\n50 % reduction in cortical thickness error (from 0.50 to 0.24 mm) with respect\nto RAC and better recovery of the aging-related cortical thinning patterns\ndetected by FreeSurfer on high-resolution T1w scans. Our method enables fast\nand accurate surface reconstruction of clinical scans, allowing studies (1)\nwith sample sizes far beyond what is feasible in a research setting, and (2) of\nclinical populations that are difficult to enroll in research studies. The code\nis publicly available at https://github.com/simnibs/brainnet.", "published": "2025-05-20 07:18:58", "link": "http://arxiv.org/abs/2505.14017v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "EGFormer: Towards Efficient and Generalizable Multimodal Semantic Segmentation", "abstract": "Recent efforts have explored multimodal semantic segmentation using various\nbackbone architectures. However, while most methods aim to improve accuracy,\ntheir computational efficiency remains underexplored. To address this, we\npropose EGFormer, an efficient multimodal semantic segmentation framework that\nflexibly integrates an arbitrary number of modalities while significantly\nreducing model parameters and inference time without sacrificing performance.\nOur framework introduces two novel modules. First, the Any-modal Scoring Module\n(ASM) assigns importance scores to each modality independently, enabling\ndynamic ranking based on their feature maps. Second, the Modal Dropping Module\n(MDM) filters out less informative modalities at each stage, selectively\npreserving and aggregating only the most valuable features. This design allows\nthe model to leverage useful information from all available modalities while\ndiscarding redundancy, thus ensuring high segmentation quality. In addition to\nefficiency, we evaluate EGFormer on a synthetic-to-real transfer task to\ndemonstrate its generalizability. Extensive experiments show that EGFormer\nachieves competitive performance with up to 88 percent reduction in parameters\nand 50 percent fewer GFLOPs. Under unsupervised domain adaptation settings, it\nfurther achieves state-of-the-art transfer performance compared to existing\nmethods.", "published": "2025-05-20 07:08:49", "link": "http://arxiv.org/abs/2505.14014v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UHD Image Dehazing via anDehazeFormer with Atmospheric-aware KV Cache", "abstract": "In this paper, we propose an efficient visual transformer framework for\nultra-high-definition (UHD) image dehazing that addresses the key challenges of\nslow training speed and high memory consumption for existing methods. Our\napproach introduces two key innovations: 1) an \\textbf{a}daptive\n\\textbf{n}ormalization mechanism inspired by the nGPT architecture that enables\nultra-fast and stable training with a network with a restricted range of\nparameter expressions; and 2) we devise an atmospheric scattering-aware KV\ncaching mechanism that dynamically optimizes feature preservation based on the\nphysical haze formation model. The proposed architecture improves the training\nconvergence speed by \\textbf{5 $\\times$} while reducing memory overhead,\nenabling real-time processing of 50 high-resolution images per second on an\nRTX4090 GPU. Experimental results show that our approach maintains\nstate-of-the-art dehazing quality while significantly improving computational\nefficiency for 4K/8K image restoration tasks. Furthermore, we provide a new\ndehazing image interpretable method with the help of an integrated gradient\nattribution map. Our code can be found here:\nhttps://anonymous.4open.science/r/anDehazeFormer-632E/README.md.", "published": "2025-05-20 07:04:34", "link": "http://arxiv.org/abs/2505.14010v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Label Stereo Matching for Transparent Scene Depth Estimation", "abstract": "In this paper, we present a multi-label stereo matching method to\nsimultaneously estimate the depth of the transparent objects and the occluded\nbackground in transparent scenes.Unlike previous methods that assume a unimodal\ndistribution along the disparity dimension and formulate the matching as a\nsingle-label regression problem, we propose a multi-label regression\nformulation to estimate multiple depth values at the same pixel in transparent\nscenes. To resolve the multi-label regression problem, we introduce a\npixel-wise multivariate Gaussian representation, where the mean vector encodes\nmultiple depth values at the same pixel, and the covariance matrix determines\nwhether a multi-label representation is necessary for a given pixel. The\nrepresentation is iteratively predicted within a GRU framework. In each\niteration, we first predict the update step for the mean parameters and then\nuse both the update step and the updated mean parameters to estimate the\ncovariance matrix. We also synthesize a dataset containing 10 scenes and 89\nobjects to validate the performance of transparent scene depth estimation. The\nexperiments show that our method greatly improves the performance on\ntransparent surfaces while preserving the background information for scene\nreconstruction. Code is available at https://github.com/BFZD233/TranScene.", "published": "2025-05-20 07:03:57", "link": "http://arxiv.org/abs/2505.14008v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StPR: Spatiotemporal Preservation and Routing for Exemplar-Free Video Class-Incremental Learning", "abstract": "Video Class-Incremental Learning (VCIL) seeks to develop models that\ncontinuously learn new action categories over time without forgetting\npreviously acquired knowledge. Unlike traditional Class-Incremental Learning\n(CIL), VCIL introduces the added complexity of spatiotemporal structures,\nmaking it particularly challenging to mitigate catastrophic forgetting while\neffectively capturing both frame-shared semantics and temporal dynamics.\nExisting approaches either rely on exemplar rehearsal, raising concerns over\nmemory and privacy, or adapt static image-based methods that neglect temporal\nmodeling. To address these limitations, we propose Spatiotemporal Preservation\nand Routing (StPR), a unified and exemplar-free VCIL framework that explicitly\ndisentangles and preserves spatiotemporal information. First, we introduce\nFrame-Shared Semantics Distillation (FSSD), which identifies semantically\nstable and meaningful channels by jointly considering semantic sensitivity and\nclassification contribution. These important semantic channels are selectively\nregularized to maintain prior knowledge while allowing for adaptation. Second,\nwe design a Temporal Decomposition-based Mixture-of-Experts (TD-MoE), which\ndynamically routes task-specific experts based on their temporal dynamics,\nenabling inference without task ID or stored exemplars. Together, StPR\neffectively leverages spatial semantics and temporal dynamics, achieving a\nunified, exemplar-free VCIL framework. Extensive experiments on UCF101, HMDB51,\nand Kinetics400 show that our method outperforms existing baselines while\noffering improved interpretability and efficiency in VCIL. Code is available in\nthe supplementary materials.", "published": "2025-05-20 06:46:51", "link": "http://arxiv.org/abs/2505.13997v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models", "abstract": "Recently, reinforcement learning (RL)-based tuning has shifted the trajectory\nof Multimodal Large Language Models (MLLMs), particularly following the\nintroduction of Group Relative Policy Optimization (GRPO). However, directly\napplying it to medical tasks remains challenging for achieving clinically\ngrounded model behavior. Motivated by the need to align model response with\nclinical expectations, we investigate four critical dimensions that affect the\neffectiveness of RL-based tuning in medical visual question answering (VQA):\nbase model initialization strategy, the role of medical semantic alignment, the\nimpact of length-based rewards on long-chain reasoning, and the influence of\nbias. We conduct extensive experiments to analyze these factors for medical\nMLLMs, providing new insights into how models are domain-specifically\nfine-tuned. Additionally, our results also demonstrate that GRPO-based RL\ntuning consistently outperforms standard supervised fine-tuning (SFT) in both\naccuracy and reasoning quality.", "published": "2025-05-20 06:12:20", "link": "http://arxiv.org/abs/2505.13973v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Every Pixel Tells a Story: End-to-End Urdu Newspaper OCR", "abstract": "This paper introduces a comprehensive end-to-end pipeline for Optical\nCharacter Recognition (OCR) on Urdu newspapers. In our approach, we address the\nunique challenges of complex multi-column layouts, low-resolution archival\nscans, and diverse font styles. Our process decomposes the OCR task into four\nkey modules: (1) article segmentation, (2) image super-resolution, (3) column\nsegmentation, and (4) text recognition. For article segmentation, we fine-tune\nand evaluate YOLOv11x to identify and separate individual articles from\ncluttered layouts. Our model achieves a precision of 0.963 and mAP@50 of 0.975.\nFor super-resolution, we fine-tune and benchmark the SwinIR model (reaching\n32.71 dB PSNR) to enhance the quality of degraded newspaper scans. To do our\ncolumn segmentation, we use YOLOv11x to separate columns in text to further\nenhance performance - this model reaches a precision of 0.970 and mAP@50 of\n0.975. In the text recognition stage, we benchmark a range of LLMs from\ndifferent families, including Gemini, GPT, Llama, and Claude. The lowest WER of\n0.133 is achieved by Gemini-2.5-Pro.", "published": "2025-05-20 05:22:17", "link": "http://arxiv.org/abs/2505.13943v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts", "abstract": "Long videos contain a vast amount of information, making video-text retrieval\nan essential and challenging task in multimodal learning. However, existing\nbenchmarks suffer from limited video duration, low-quality captions, and coarse\nannotation granularity, which hinder the evaluation of advanced video-text\nretrieval methods. To address these limitations, we introduce LoVR, a benchmark\nspecifically designed for long video-text retrieval. LoVR contains 467 long\nvideos and over 40,804 fine-grained clips with high-quality captions. To\novercome the issue of poor machine-generated annotations, we propose an\nefficient caption generation framework that integrates VLM automatic\ngeneration, caption quality scoring, and dynamic refinement. This pipeline\nimproves annotation accuracy while maintaining scalability. Furthermore, we\nintroduce a semantic fusion method to generate coherent full-video captions\nwithout losing important contextual information. Our benchmark introduces\nlonger videos, more detailed captions, and a larger-scale dataset, presenting\nnew challenges for video understanding and retrieval. Extensive experiments on\nvarious advanced embedding models demonstrate that LoVR is a challenging\nbenchmark, revealing the limitations of current approaches and providing\nvaluable insights for future research. We release the code and dataset link at\nhttps://github.com/TechNomad-ds/LoVR-benchmark", "published": "2025-05-20 04:49:09", "link": "http://arxiv.org/abs/2505.13928v1", "categories": ["cs.CV", "cs.IR"], "primary_category": "cs.CV"}
{"title": "An Explorative Analysis of SVM Classifier and ResNet50 Architecture on African Food Classification", "abstract": "Food recognition systems has advanced significantly for Western cuisines, yet\nits application to African foods remains underexplored. This study addresses\nthis gap by evaluating both deep learning and traditional machine learning\nmethods for African food classification. We compared the performance of a\nfine-tuned ResNet50 model with a Support Vector Machine (SVM) classifier. The\ndataset comprises 1,658 images across six selected food categories that are\nknown in Africa. To assess model effectiveness, we utilize five key evaluation\nmetrics: Confusion matrix, F1-score, accuracy, recall and precision. Our\nfindings offer valuable insights into the strengths and limitations of both\napproaches, contributing to the advancement of food recognition for African\ncuisines.", "published": "2025-05-20 04:37:18", "link": "http://arxiv.org/abs/2505.13923v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Blind Restoration of High-Resolution Ultrasound Video", "abstract": "Ultrasound imaging is widely applied in clinical practice, yet ultrasound\nvideos often suffer from low signal-to-noise ratios (SNR) and limited\nresolutions, posing challenges for diagnosis and analysis. Variations in\nequipment and acquisition settings can further exacerbate differences in data\ndistribution and noise levels, reducing the generalizability of pre-trained\nmodels. This work presents a self-supervised ultrasound video super-resolution\nalgorithm called Deep Ultrasound Prior (DUP). DUP employs a video-adaptive\noptimization process of a neural network that enhances the resolution of given\nultrasound videos without requiring paired training data while simultaneously\nremoving noise. Quantitative and visual evaluations demonstrate that DUP\noutperforms existing super-resolution algorithms, leading to substantial\nimprovements for downstream applications.", "published": "2025-05-20 04:26:15", "link": "http://arxiv.org/abs/2505.13915v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Bronchovascular Tree-Guided Weakly Supervised Learning Method for Pulmonary Segment Segmentation", "abstract": "Pulmonary segment segmentation is crucial for cancer localization and\nsurgical planning. However, the pixel-wise annotation of pulmonary segments is\nlaborious, as the boundaries between segments are indistinguishable in medical\nimages. To this end, we propose a weakly supervised learning (WSL) method,\ntermed Anatomy-Hierarchy Supervised Learning (AHSL), which consults the precise\nclinical anatomical definition of pulmonary segments to perform pulmonary\nsegment segmentation. Since pulmonary segments reside within the lobes and are\ndetermined by the bronchovascular tree, i.e., artery, airway and vein, the\ndesign of the loss function is founded on two principles. First, segment-level\nlabels are utilized to directly supervise the output of the pulmonary segments,\nensuring that they accurately encompass the appropriate bronchovascular tree.\nSecond, lobe-level supervision indirectly oversees the pulmonary segment,\nensuring their inclusion within the corresponding lobe. Besides, we introduce a\ntwo-stage segmentation strategy that incorporates bronchovascular priori\ninformation. Furthermore, a consistency loss is proposed to enhance the\nsmoothness of segment boundaries, along with an evaluation metric designed to\nmeasure the smoothness of pulmonary segment boundaries. Visual inspection and\nevaluation metrics from experiments conducted on a private dataset demonstrate\nthe effectiveness of our method.", "published": "2025-05-20 04:23:12", "link": "http://arxiv.org/abs/2505.13911v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "XDementNET: An Explainable Attention Based Deep Convolutional Network to Detect Alzheimer Progression from MRI data", "abstract": "A common neurodegenerative disease, Alzheimer's disease requires a precise\ndiagnosis and efficient treatment, particularly in light of escalating\nhealthcare expenses and the expanding use of artificial intelligence in medical\ndiagnostics. Many recent studies shows that the combination of brain Magnetic\nResonance Imaging (MRI) and deep neural networks have achieved promising\nresults for diagnosing AD. Using deep convolutional neural networks, this paper\nintroduces a novel deep learning architecture that incorporates multiresidual\nblocks, specialized spatial attention blocks, grouped query attention, and\nmulti-head attention. The study assessed the model's performance on four\npublicly accessible datasets and concentrated on identifying binary and\nmulticlass issues across various categories. This paper also takes into account\nof the explainability of AD's progression and compared with state-of-the-art\nmethods namely Gradient Class Activation Mapping (GradCAM), Score-CAM, Faster\nScore-CAM, and XGRADCAM. Our methodology consistently outperforms current\napproaches, achieving 99.66\\% accuracy in 4-class classification, 99.63\\% in\n3-class classification, and 100\\% in binary classification using Kaggle\ndatasets. For Open Access Series of Imaging Studies (OASIS) datasets the\naccuracies are 99.92\\%, 99.90\\%, and 99.95\\% respectively. The Alzheimer's\nDisease Neuroimaging Initiative-1 (ADNI-1) dataset was used for experiments in\nthree planes (axial, sagittal, and coronal) and a combination of all planes.\nThe study achieved accuracies of 99.08\\% for axis, 99.85\\% for sagittal, 99.5\\%\nfor coronal, and 99.17\\% for all axis, and 97.79\\% and 8.60\\% respectively for\nADNI-2. The network's ability to retrieve important information from MRI images\nis demonstrated by its excellent accuracy in categorizing AD stages.", "published": "2025-05-20 04:17:28", "link": "http://arxiv.org/abs/2505.13906v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "4D-ROLLS: 4D Radar Occupancy Learning via LiDAR Supervision", "abstract": "A comprehensive understanding of 3D scenes is essential for autonomous\nvehicles (AVs), and among various perception tasks, occupancy estimation plays\na central role by providing a general representation of drivable and occupied\nspace. However, most existing occupancy estimation methods rely on LiDAR or\ncameras, which perform poorly in degraded environments such as smoke, rain,\nsnow, and fog. In this paper, we propose 4D-ROLLS, the first weakly supervised\noccupancy estimation method for 4D radar using the LiDAR point cloud as the\nsupervisory signal. Specifically, we introduce a method for generating\npseudo-LiDAR labels, including occupancy queries and LiDAR height maps, as\nmulti-stage supervision to train the 4D radar occupancy estimation model. Then\nthe model is aligned with the occupancy map produced by LiDAR, fine-tuning its\naccuracy in occupancy estimation. Extensive comparative experiments validate\nthe exceptional performance of 4D-ROLLS. Its robustness in degraded\nenvironments and effectiveness in cross-dataset training are qualitatively\ndemonstrated. The model is also seamlessly transferred to downstream tasks BEV\nsegmentation and point cloud occupancy prediction, highlighting its potential\nfor broader applications. The lightweight network enables 4D-ROLLS model to\nachieve fast inference speeds at about 30 Hz on a 4060 GPU. The code of\n4D-ROLLS will be made available at https://github.com/CLASS-Lab/4D-ROLLS.", "published": "2025-05-20 04:12:44", "link": "http://arxiv.org/abs/2505.13905v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Automated Quality Evaluation of Cervical Cytopathology Whole Slide Images Based on Content Analysis", "abstract": "The ThinPrep Cytologic Test (TCT) is the most widely used method for cervical\ncancer screening, and the sample quality directly impacts the accuracy of the\ndiagnosis. Traditional manual evaluation methods rely on the observation of\npathologist under microscopes. These methods exhibit high subjectivity, high\ncost, long duration, and low reliability. With the development of\ncomputer-aided diagnosis (CAD), an automated quality assessment system that\nperforms at the level of a professional pathologist is necessary. To address\nthis need, we propose a fully automated quality assessment method for Cervical\nCytopathology Whole Slide Images (WSIs) based on The Bethesda System (TBS)\ndiagnostic standards, artificial intelligence algorithms, and the\ncharacteristics of clinical data. The method analysis the context of WSIs to\nquantify quality evaluation metrics which are focused by TBS such as staining\nquality, cell counts and cell mass proportion through multiple models including\nobject detection, classification and segmentation. Subsequently, the XGBoost\nmodel is used to mine the attention paid by pathologists to different quality\nevaluation metrics when evaluating samples, thereby obtaining a comprehensive\nWSI sample score calculation model. Experimental results on 100 WSIs\ndemonstrate that the proposed evaluation method has significant advantages in\nterms of speed and consistency.", "published": "2025-05-20 03:30:38", "link": "http://arxiv.org/abs/2505.13875v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Domain Adaptation of VLM for Soccer Video Understanding", "abstract": "Vision Language Models (VLMs) have demonstrated strong performance in\nmulti-modal tasks by effectively aligning visual and textual representations.\nHowever, most video understanding VLM research has been domain-agnostic,\nleaving the understanding of their transfer learning capability to specialized\ndomains under-explored. In this work, we address this by exploring the\nadaptability of open-source VLMs to specific domains, and focusing on soccer as\nan initial case study. Our approach uses large-scale soccer datasets and LLM to\ncreate instruction-following data, and use them to iteratively fine-tune the\ngeneral-domain VLM in a curriculum learning fashion (first teaching the model\nkey soccer concepts to then question answering tasks). The final adapted model,\ntrained using a curated dataset of 20k video clips, exhibits significant\nimprovement in soccer-specific tasks compared to the base model, with a 37.5%\nrelative improvement for the visual question-answering task and an accuracy\nimprovement from 11.8% to 63.5% for the downstream soccer action classification\ntask.", "published": "2025-05-20 03:12:21", "link": "http://arxiv.org/abs/2505.13860v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "SuperMapNet for Long-Range and High-Accuracy Vectorized HD Map Construction", "abstract": "Vectorized HD map is essential for autonomous driving. Remarkable work has\nbeen achieved in recent years, but there are still major issues: (1) in the\ngeneration of the BEV features, single modality-based methods are of limited\nperception capability, while direct concatenation-based multi-modal methods\nfail to capture synergies and disparities between different modalities,\nresulting in limited ranges with feature holes; (2) in the classification and\nlocalization of map elements, only point information is used without the\nconsideration of element infor-mation and neglects the interaction between\npoint information and element information, leading to erroneous shapes and\nelement entanglement with low accuracy. To address above issues, we introduce\nSuperMapNet for long-range and high-accuracy vectorized HD map construction. It\nuses both camera images and LiDAR point clouds as input, and first tightly\ncouple semantic information from camera images and geometric information from\nLiDAR point clouds by a cross-attention based synergy enhancement module and a\nflow-based disparity alignment module for long-range BEV feature generation.\nAnd then, local features from point queries and global features from element\nqueries are tightly coupled by three-level interactions for high-accuracy\nclassification and localization, where Point2Point interaction learns local\ngeometric information between points of the same element and of each point,\nElement2Element interaction learns relation constraints between different\nelements and semantic information of each elements, and Point2Element\ninteraction learns complement element information for its constituent points.\nExperiments on the nuScenes and Argoverse2 datasets demonstrate superior\nperformances, surpassing SOTAs over 14.9/8.8 mAP and 18.5/3.1 mAP under\nhard/easy settings, respectively. The code is made publicly available1.", "published": "2025-05-20 03:06:22", "link": "http://arxiv.org/abs/2505.13856v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Better Neural Network Expressivity: Subdividing the Simplex", "abstract": "This work studies the expressivity of ReLU neural networks with a focus on\ntheir depth. A sequence of previous works showed that $\\lceil \\log_2(n+1)\n\\rceil$ hidden layers are sufficient to compute all continuous piecewise linear\n(CPWL) functions on $\\mathbb{R}^n$. Hertrich, Basu, Di Summa, and Skutella\n(NeurIPS'21) conjectured that this result is optimal in the sense that there\nare CPWL functions on $\\mathbb{R}^n$, like the maximum function, that require\nthis depth. We disprove the conjecture and show that\n$\\lceil\\log_3(n-1)\\rceil+1$ hidden layers are sufficient to compute all CPWL\nfunctions on $\\mathbb{R}^n$.\n  A key step in the proof is that ReLU neural networks with two hidden layers\ncan exactly represent the maximum function of five inputs. More generally, we\nshow that $\\lceil\\log_3(n-2)\\rceil+1$ hidden layers are sufficient to compute\nthe maximum of $n\\geq 4$ numbers. Our constructions almost match the\n$\\lceil\\log_3(n)\\rceil$ lower bound of Averkov, Hojny, and Merkert (ICLR'25) in\nthe special case of ReLU networks with weights that are decimal fractions. The\nconstructions have a geometric interpretation via polyhedral subdivisions of\nthe simplex into ``easier'' polytopes.", "published": "2025-05-20 13:23:57", "link": "http://arxiv.org/abs/2505.14338v1", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "primary_category": "cs.LG"}
{"title": "An asymptotic rigidity property from the realizability of chirotope extensions", "abstract": "Let $P$ be a finite full-dimensional point configuration in $\\mathbb{R}^d$.\nWe show that if a point configuration $Q$ has the property that all finite\nchirotopes realizable by adding (generic) points to $P$ are also realizable by\nadding points to $Q$, then $P$ and $Q$ are equal up to a direct affine\ntransform. We also show that for any point configuration $P$ and any\n$\\varepsilon>0$, there is a finite, (generic) extension $\\widehat P$ of $P$\nwith the following property: if another realization $Q$ of the chirotope of $P$\ncan be extended so as to realize the chirotope of $\\widehat P$, then there\nexists a direct affine transform that maps each point of $Q$ within distance\n$\\varepsilon$ of the corresponding point of $P$.", "published": "2025-05-20 10:44:05", "link": "http://arxiv.org/abs/2505.14189v1", "categories": ["math.CO", "cs.CG", "cs.DM", "52C40: Oriented matroids, 52C35: Arrangements of points, flats,\n  hyperplanes,"], "primary_category": "math.CO"}
{"title": "Path Contraction Faster than $2^n$", "abstract": "A graph $G$ is contractible to a graph $H$ if there is a set $X \\subseteq\nE(G)$, such that $G/X$ is isomorphic to $H$. Here, $G/X$ is the graph obtained\nfrom $G$ by contracting all the edges in $X$. For a family of graphs $\\cal F$,\nthe $\\mathcal{F}$-\\textsc{Contraction} problem takes as input a graph $G$ on\n$n$ vertices, and the objective is to output the largest integer $t$, such that\n$G$ is contractible to a graph $H \\in {\\cal F}$, where $|V(H)|=t$. When $\\cal\nF$ is the family of paths, then the corresponding\n$\\mathcal{F}$-\\textsc{Contraction} problem is called \\textsc{Path Contraction}.\nThe problem \\textsc{Path Contraction} admits a simple algorithm running in time\n$2^{n}\\cdot n^{\\mathcal{O}(1)}$. In spite of the deceptive simplicity of the\nproblem, beating the $2^{n}\\cdot n^{\\mathcal{O}(1)}$ bound for \\textsc{Path\nContraction} seems quite challenging. In this paper, we design an exact\nexponential time algorithm for \\textsc{Path Contraction} that runs in time\n$1.99987^n\\cdot n^{\\mathcal{O}(1)}$. We also define a problem called\n\\textsc{$3$-Disjoint Connected Subgraphs}, and design an algorithm for it that\nruns in time $1.88^n\\cdot n^{\\mathcal{O}(1)}$. The above algorithm is used as a\nsub-routine in our algorithm for {\\sc Path Contraction}", "published": "2025-05-20 06:46:39", "link": "http://arxiv.org/abs/2505.13996v1", "categories": ["cs.DS", "cs.DM"], "primary_category": "cs.DS"}
{"title": "On near optimal colorable graphs", "abstract": "A class of graphs $\\cal G$ is said to be \\emph{near optimal colorable} if\nthere exists a constant $c\\in \\mathbb{N}$ such that every graph $G\\in \\cal G$\nsatisfies $\\chi(G) \\leq \\max\\{c, \\omega(G)\\}$, where $\\chi(G)$ and $\\omega(G)$\nrespectively denote the chromatic number and clique number of $G$. The class of\nnear optimal colorable graphs is an important subclass of the class of\n$\\chi$-bounded graphs which is well-studied in the literature. In this paper,\nwe show that the class of ($F, K_4-e$)-free graphs is near optimal colorable,\nwhere $F\\in \\{P_1+2P_2,2P_1+P_3,3P_1+P_2\\}$. This partially answers a question\nof Ju and Huang [Theoretical Computer Science 993 (2024) Article No.: 114465]\nand a question of Schiermeyer (unpublished). Furthermore, using these results\nwith some earlier known results, we also provide an alternate proof to the fact\nthat the \\textsc{Chromatic Number} problem for the class of ($F, K_4-e$)-free\ngraphs is solvable in polynomial time, where $F\\in\n\\{P_1+2P_2,2P_1+P_3,3P_1+P_2\\}$.", "published": "2025-05-20 04:59:23", "link": "http://arxiv.org/abs/2505.13932v1", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "A composition theory for upward planar orders", "abstract": "An upward planar order on an acyclic directed graph $G$ is a special linear\nextension of the edge poset of $G$ that satisfies the nesting condition. This\norder was introduced to combinatorially characterize upward plane graphs and\nprogressive plane graphs (commonly known as plane string diagrams). In this\npaper, motivated by the theory of graphical calculus for monoidal categories,\nwe establish a composition theory for upward planar orders. The main result is\nthat the composition of upward planar orders is an upward planar order. This\ntheory provides a practical method to calculate the upward planar order of a\nprogressive plane graph or an upward plane graph.", "published": "2025-05-20 03:20:25", "link": "http://arxiv.org/abs/2505.13865v1", "categories": ["math.CO", "cs.DM", "math.CT"], "primary_category": "math.CO"}
{"title": "Graphon Mixtures", "abstract": "Social networks have a small number of large hubs, and a large number of\nsmall dense communities. We propose a generative model that captures both hub\nand dense structures. Based on recent results about graphons on line graphs,\nour model is a graphon mixture, enabling us to generate sequences of graphs\nwhere each graph is a combination of sparse and dense graphs. We propose a new\ncondition on sparse graphs (the max-degree), which enables us to identify hubs.\nWe show theoretically that we can estimate the normalized degree of the hubs,\nas well as estimate the graphon corresponding to sparse components of graph\nmixtures. We illustrate our approach on synthetic data, citation graphs, and\nsocial networks, showing the benefits of explicitly modeling sparse graphs.", "published": "2025-05-20 03:19:29", "link": "http://arxiv.org/abs/2505.13864v1", "categories": ["stat.ML", "cs.DM", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On the size of the neighborhoods of a word", "abstract": "The d-neighborhood of a word W in the Levenshtein distance is the set of all\nwords at distance at most d from W. Generating the neighborhood of a word W, or\nrelated sets of words such as the condensed neighborhood or the super-condensed\nneighborhood has applications in the design of approximate pattern matching\nalgorithms. It follows that bounds on the maximum size of the neighborhood of\nwords of a given length can be used in the complexity analysis of such\napproximate pattern matching algorithms. In this note, we present exact\nformulas for the size of the condensed and super condensed neighborhoods of a\nunary word, a novel upper bound for the maximum size of the condensed\nneighborhood of an arbitrary word of a given length, and we prove a conjectured\nupper bound again for the maximum size of the condensed neighborhood of an\narbitrary word of a given length.", "published": "2025-05-20 01:10:20", "link": "http://arxiv.org/abs/2505.13796v1", "categories": ["math.CO", "cs.DM", "05A05, 05A15, 05A16", "G.2.1"], "primary_category": "math.CO"}
{"title": "R2MED: A Benchmark for Reasoning-Driven Medical Retrieval", "abstract": "Current medical retrieval benchmarks primarily emphasize lexical or shallow\nsemantic similarity, overlooking the reasoning-intensive demands that are\ncentral to clinical decision-making. In practice, physicians often retrieve\nauthoritative medical evidence to support diagnostic hypotheses. Such evidence\ntypically aligns with an inferred diagnosis rather than the surface form of a\npatient's symptoms, leading to low lexical or semantic overlap between queries\nand relevant documents. To address this gap, we introduce R2MED, the first\nbenchmark explicitly designed for reasoning-driven medical retrieval. It\ncomprises 876 queries spanning three tasks: Q&A reference retrieval, clinical\nevidence retrieval, and clinical case retrieval. These tasks are drawn from\nfive representative medical scenarios and twelve body systems, capturing the\ncomplexity and diversity of real-world medical information needs. We evaluate\n15 widely-used retrieval systems on R2MED and find that even the best model\nachieves only 31.4 nDCG@10, demonstrating the benchmark's difficulty. Classical\nre-ranking and generation-augmented retrieval methods offer only modest\nimprovements. Although large reasoning models improve performance via\nintermediate inference generation, the best results still peak at 41.4 nDCG@10.\nThese findings underscore a substantial gap between current retrieval\ntechniques and the reasoning demands of real clinical tasks. We release R2MED\nas a challenging benchmark to foster the development of next-generation medical\nretrieval systems with enhanced reasoning capabilities. Data and code are\navailable at https://github.com/R2MED/R2MED", "published": "2025-05-20 16:15:30", "link": "http://arxiv.org/abs/2505.14558v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Taming Recommendation Bias with Causal Intervention on Evolving Personal Popularity", "abstract": "Popularity bias occurs when popular items are recommended far more frequently\nthan they should be, negatively impacting both user experience and\nrecommendation accuracy. Existing debiasing methods mitigate popularity bias\noften uniformly across all users and only partially consider the time evolution\nof users or items. However, users have different levels of preference for item\npopularity, and this preference is evolving over time. To address these issues,\nwe propose a novel method called CausalEPP (Causal Intervention on Evolving\nPersonal Popularity) for taming recommendation bias, which accounts for the\nevolving personal popularity of users. Specifically, we first introduce a\nmetric called {Evolving Personal Popularity} to quantify each user's preference\nfor popular items. Then, we design a causal graph that integrates evolving\npersonal popularity into the conformity effect, and apply deconfounded training\nto mitigate the popularity bias of the causal graph. During inference, we\nconsider the evolution consistency between users and items to achieve a better\nrecommendation. Empirical studies demonstrate that CausalEPP outperforms\nbaseline methods in reducing popularity bias while improving recommendation\naccuracy.", "published": "2025-05-20 12:59:16", "link": "http://arxiv.org/abs/2505.14310v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "The Limits of Graph Samplers for Training Inductive Recommender Systems: Extended results", "abstract": "Inductive Recommender Systems are capable of recommending for new users and\nwith new items thus avoiding the need to retrain after new data reaches the\nsystem. However, these methods are still trained on all the data available,\nrequiring multiple days to train a single model, without counting\nhyperparameter tuning. In this work we focus on graph-based recommender\nsystems, i.e., systems that model the data as a heterogeneous network. In other\napplications, graph sampling allows to study a subgraph and generalize the\nfindings to the original graph. Thus, we investigate the applicability of\nsampling techniques for this task. We test on three real world datasets, with\nthree state-of-the-art inductive methods, and using six different sampling\nmethods. We find that its possible to maintain performance using only 50% of\nthe training data with up to 86% percent decrease in training time; however,\nusing less training data leads to far worse performance. Further, we find that\nwhen it comes to data for recommendations, graph sampling should also account\nfor the temporal dimension. Therefore, we find that if higher data reduction is\nneeded, new graph based sampling techniques should be studied and new inductive\nmethods should be designed.", "published": "2025-05-20 11:47:56", "link": "http://arxiv.org/abs/2505.14241v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Enhancing Keyphrase Extraction from Academic Articles Using Section Structure Information", "abstract": "The exponential increase in academic papers has significantly increased the\ntime required for researchers to access relevant literature. Keyphrase\nExtraction (KPE) offers a solution to this situation by enabling researchers to\nefficiently retrieve relevant literature. The current study on KPE from\nacademic articles aims to improve the performance of extraction models through\ninnovative approaches using Title and Abstract as input corpora. However, the\nsemantic richness of keywords is significantly constrained by the length of the\nabstract. While full-text-based KPE can address this issue, it simultaneously\nintroduces noise, which significantly diminishes KPE performance. To address\nthis issue, this paper utilized the structural features and section texts\nobtained from the section structure information of academic articles to extract\nkeyphrase from academic papers. The approach consists of two main parts: (1)\nexploring the effect of seven structural features on KPE models, and (2)\nintegrating the extraction results from all section texts used as input corpora\nfor KPE models via a keyphrase integration algorithm to obtain the keyphrase\nintegration result. Furthermore, this paper also examined the effect of the\nclassification quality of section structure on the KPE performance. The results\nshow that incorporating structural features improves KPE performance, though\ndifferent features have varying effects on model efficacy. The keyphrase\nintegration approach yields the best performance, and the classification\nquality of section structure can affect KPE performance. These findings\nindicate that using the section structure information of academic articles\ncontributes to effective KPE from academic articles. The code and dataset\nsupporting this study are available at https://github.com/yan-xinyi/SSB_KPE.", "published": "2025-05-20 09:57:34", "link": "http://arxiv.org/abs/2505.14149v1", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering", "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions using structured knowledge from KBs. While LLM-only approaches offer\ngeneralization, they suffer from outdated knowledge, hallucinations, and lack\nof transparency. Chain-based KG-RAG methods address these issues by\nincorporating external KBs, but are limited to simple chain-structured\nquestions due to the absence of planning and logical structuring. Inspired by\nsemantic parsing methods, we propose PDRR: a four-stage framework consisting of\nPredict, Decompose, Retrieve, and Reason. Our method first predicts the\nquestion type and decomposes the question into structured triples. Then\nretrieves relevant information from KBs and guides the LLM as an agent to\nreason over and complete the decomposed triples. Experimental results\ndemonstrate that PDRR consistently outperforms existing methods across various\nLLM backbones and achieves superior performance on both chain-structured and\nnon-chain complex questions.", "published": "2025-05-20 09:01:52", "link": "http://arxiv.org/abs/2505.14099v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning", "abstract": "Retrieval-augmented generation (RAG) enhances the text generation\ncapabilities of large language models (LLMs) by integrating external knowledge\nand up-to-date information. However, traditional RAG systems are limited by\nstatic workflows and lack the adaptability required for multistep reasoning and\ncomplex task management. To address these limitations, agentic RAG systems\n(e.g., DeepResearch) have been proposed, enabling dynamic retrieval strategies,\niterative context refinement, and adaptive workflows for handling complex\nsearch queries beyond the capabilities of conventional RAG. Recent advances,\nsuch as Search-R1, have demonstrated promising gains using outcome-based\nreinforcement learning, where the correctness of the final answer serves as the\nreward signal. Nevertheless, such outcome-supervised agentic RAG methods face\nchallenges including low exploration efficiency, gradient conflict, and sparse\nreward signals. To overcome these challenges, we propose to utilize\nfine-grained, process-level rewards to improve training stability, reduce\ncomputational costs, and enhance efficiency. Specifically, we introduce a novel\nmethod ReasonRAG that automatically constructs RAG-ProGuide, a high-quality\ndataset providing process-level rewards for (i) query generation, (ii) evidence\nextraction, and (iii) answer generation, thereby enhancing model inherent\ncapabilities via process-supervised reinforcement learning. With the\nprocess-level policy optimization, the proposed framework empowers LLMs to\nautonomously invoke search, generate queries, extract relevant evidence, and\nproduce final answers. Compared to existing approaches such as Search-R1 and\ntraditional RAG systems, ReasonRAG, leveraging RAG-ProGuide, achieves superior\nperformance on five benchmark datasets using only 5k training instances,\nsignificantly fewer than the 90k training instances required by Search-R1.", "published": "2025-05-20 08:21:00", "link": "http://arxiv.org/abs/2505.14069v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Field Matters: A lightweight LLM-enhanced Method for CTR Prediction", "abstract": "Click-through rate (CTR) prediction is a fundamental task in modern\nrecommender systems. In recent years, the integration of large language models\n(LLMs) has been shown to effectively enhance the performance of traditional CTR\nmethods. However, existing LLM-enhanced methods often require extensive\nprocessing of detailed textual descriptions for large-scale instances or\nuser/item entities, leading to substantial computational overhead. To address\nthis challenge, this work introduces LLaCTR, a novel and lightweight\nLLM-enhanced CTR method that employs a field-level enhancement paradigm.\nSpecifically, LLaCTR first utilizes LLMs to distill crucial and lightweight\nsemantic knowledge from small-scale feature fields through self-supervised\nfield-feature fine-tuning. Subsequently, it leverages this field-level semantic\nknowledge to enhance both feature representation and feature interactions. In\nour experiments, we integrate LLaCTR with six representative CTR models across\nfour datasets, demonstrating its superior performance in terms of both\neffectiveness and efficiency compared to existing LLM-enhanced methods. Our\ncode is available at https://anonymous.4open.science/r/LLaCTR-EC46.", "published": "2025-05-20 08:02:41", "link": "http://arxiv.org/abs/2505.14057v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning", "abstract": "Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs\n(KGs), incorporate the temporal feature to express the transience of knowledge\nby describing when facts occur. TKG extrapolation aims to infer possible future\nfacts based on known history, which has garnered significant attention in\nrecent years. Some existing methods treat TKG as a sequence of independent\nsubgraphs to model temporal evolution patterns, demonstrating impressive\nreasoning performance. However, they still have limitations: 1) In modeling\nsubgraph semantic evolution, they usually neglect the internal structural\ninteractions between subgraphs, which are actually crucial for encoding TKGs.\n2) They overlook the potential smooth features that do not lead to semantic\nchanges, which should be distinguished from the semantic evolution process.\nTherefore, we propose a novel Disentangled Multi-span Evolutionary Network\n(DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution\nstrategy that captures local neighbor features while perceiving historical\nneighbor semantic information, thus enabling internal interactions between\nsubgraphs during the evolution process. To maximize the capture of semantic\nchange patterns, we design a disentangle component that adaptively separates\nnodes' active and stable features, used to dynamically control the influence of\nhistorical semantics on future evolution. Extensive experiments conducted on\nfour real-world TKG datasets show that DiMNet demonstrates substantial\nperformance in TKG reasoning, and outperforms the state-of-the-art up to 22.7%\nin MRR.", "published": "2025-05-20 07:22:03", "link": "http://arxiv.org/abs/2505.14020v1", "categories": ["cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning", "abstract": "Retrieval-Augmented Generation (RAG) systems empower large language models\n(LLMs) with external knowledge, yet struggle with efficiency-accuracy\ntrade-offs when scaling to large knowledge graphs. Existing approaches often\nrely on monolithic graph retrieval, incurring unnecessary latency for simple\nqueries and fragmented reasoning for complex multi-hop questions. To address\nthese challenges, this paper propose SPLIT-RAG, a multi-agent RAG framework\nthat addresses these limitations with question-driven semantic graph\npartitioning and collaborative subgraph retrieval. The innovative framework\nfirst create Semantic Partitioning of Linked Information, then use the\nType-Specialized knowledge base to achieve Multi-Agent RAG. The attribute-aware\ngraph segmentation manages to divide knowledge graphs into semantically\ncoherent subgraphs, ensuring subgraphs align with different query types, while\nlightweight LLM agents are assigned to partitioned subgraphs, and only relevant\npartitions are activated during retrieval, thus reduce search space while\nenhancing efficiency. Finally, a hierarchical merging module resolves\ninconsistencies across subgraph-derived answers through logical verifications.\nExtensive experimental validation demonstrates considerable improvements\ncompared to existing approaches.", "published": "2025-05-20 06:44:34", "link": "http://arxiv.org/abs/2505.13994v1", "categories": ["cs.AI", "cs.IR", "cs.MA"], "primary_category": "cs.AI"}
{"title": "DIFF: Dual Side-Information Filtering and Fusion for Sequential Recommendation", "abstract": "Side-information Integrated Sequential Recommendation (SISR) benefits from\nauxiliary item information to infer hidden user preferences, which is\nparticularly effective for sparse interactions and cold-start scenarios.\nHowever, existing studies face two main challenges. (i) They fail to remove\nnoisy signals in item sequence and (ii) they underutilize the potential of\nside-information integration. To tackle these issues, we propose a novel SISR\nmodel, Dual Side-Information Filtering and Fusion (DIFF), which employs\nfrequency-based noise filtering and dual multi-sequence fusion. Specifically,\nwe convert the item sequence to the frequency domain to filter out noisy\nshort-term fluctuations in user interests. We then combine early and\nintermediate fusion to capture diverse relationships across item IDs and\nattributes. Thanks to our innovative filtering and fusion strategy, DIFF is\nmore robust in learning subtle and complex item correlations in the sequence.\nDIFF outperforms state-of-the-art SISR models, achieving improvements of up to\n14.1% and 12.5% in Recall@20 and NDCG@20 across four benchmark datasets.", "published": "2025-05-20 06:13:53", "link": "http://arxiv.org/abs/2505.13974v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Benchmarking the Myopic Trap: Positional Bias in Information Retrieval", "abstract": "This study investigates a specific form of positional bias, termed the Myopic\nTrap, where retrieval models disproportionately attend to the early parts of\ndocuments while overlooking relevant information that appears later. To\nsystematically quantify this phenomenon, we propose a semantics-preserving\nevaluation framework that repurposes the existing NLP datasets into\nposition-aware retrieval benchmarks. By evaluating the SOTA models of full\nretrieval pipeline, including BM25, embedding models, ColBERT-style\nlate-interaction models, and reranker models, we offer a broader empirical\nperspective on positional bias than prior work. Experimental results show that\nembedding models and ColBERT-style models exhibit significant performance\ndegradation when query-related content is shifted toward later positions,\nindicating a pronounced head bias. Notably, under the same training\nconfiguration, ColBERT-style approach show greater potential for mitigating\npositional bias compared to the traditional single-vector approach. In\ncontrast, BM25 and reranker models remain largely unaffected by such\nperturbations, underscoring their robustness to positional bias. Code and data\nare publicly available at: www.github.com/NovaSearch-Team/RAG-Retrieval.", "published": "2025-05-20 05:29:01", "link": "http://arxiv.org/abs/2505.13950v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "VulCPE: Context-Aware Cybersecurity Vulnerability Retrieval and Management", "abstract": "The dynamic landscape of cybersecurity demands precise and scalable solutions\nfor vulnerability management in heterogeneous systems, where\nconfiguration-specific vulnerabilities are often misidentified due to\ninconsistent data in databases like the National Vulnerability Database (NVD).\nInaccurate Common Platform Enumeration (CPE) data in NVD further leads to false\npositives and incomplete vulnerability retrieval. Informed by our systematic\nanalysis of CPE and CVEdeails data, revealing more than 50% vendor name\ninconsistencies, we propose VulCPE, a framework that standardizes data and\nmodels configuration dependencies using a unified CPE schema (uCPE), entity\nrecognition, relation extraction, and graph-based modeling. VulCPE achieves\nsuperior retrieval precision (0.766) and coverage (0.926) over existing tools.\nVulCPE ensures precise, context-aware vulnerability management, enhancing cyber\nresilience.", "published": "2025-05-20 03:59:26", "link": "http://arxiv.org/abs/2505.13895v1", "categories": ["cs.CR", "cs.DB", "cs.IR", "D.4.6; H.3.3; H.2.8; I.2.7"], "primary_category": "cs.CR"}
{"title": "TranSUN: A Preemptive Paradigm to Eradicate Retransformation Bias Intrinsically from Regression Models in Recommender Systems", "abstract": "Regression models are crucial in recommender systems. However,\nretransformation bias problem has been conspicuously neglected within the\ncommunity. While many works in other fields have devised effective bias\ncorrection methods, all of them are post-hoc cures externally to the model,\nfacing practical challenges when applied to real-world recommender systems.\nHence, we propose a preemptive paradigm to eradicate the bias intrinsically\nfrom the models via minor model refinement. Specifically, a novel TranSUN\nmethod is proposed with a joint bias learning manner to offer theoretically\nguaranteed unbiasedness under empirical superior convergence. It is further\ngeneralized into a novel generic regression model family, termed Generalized\nTranSUN (GTS), which not only offers more theoretical insights but also serves\nas a generic framework for flexibly developing various bias-free models.\nComprehensive experimental results demonstrate the superiority of our methods\nacross data from various domains, which have been successfully deployed in two\nreal-world industrial recommendation scenarios, i.e. product and short video\nrecommendation scenarios in Guess What You Like business domain in the homepage\nof Taobao App (a leading e-commerce platform), to serve the major online\ntraffic. Codes will be released after this paper is published.", "published": "2025-05-20 03:36:54", "link": "http://arxiv.org/abs/2505.13881v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Cryptocurrencies in the Balance Sheet: Insights from (Micro)Strategy -- Bitcoin Interactions", "abstract": "This paper investigates the evolving link between cryptocurrency and equity\nmarkets in the context of the recent wave of corporate Bitcoin (BTC) treasury\nstrategies. We assemble a dataset of 39 publicly listed firms holding BTC, from\ntheir first acquisition through April 2025. Using daily logarithmic returns, we\nfirst document significant positive co-movements via Pearson correlations and\nsingle factor model regressions, discovering an average BTC beta of 0.62, and\nisolating 12 companies, including Strategy (formerly MicroStrategy, MSTR),\nexhibiting a beta exceeding 1. We then classify firms into three groups\nreflecting their exposure to BTC, liquidity, and return co-movements. We use\ntransfer entropy (TE) to capture the direction of information flow over time.\nTransfer entropy analysis consistently identifies BTC as the dominant\ninformation driver, with brief, announcement-driven feedback from stocks to BTC\nduring major financial events. Our results highlight the critical need for\ndynamic hedging ratios that adapt to shifting information flows. These findings\nprovide important insights for investors and managers regarding risk management\nand portfolio diversification in a period of growing integration of digital\nassets into corporate treasuries.", "published": "2025-05-20 17:43:14", "link": "http://arxiv.org/abs/2505.14655v1", "categories": ["q-fin.GN", "cs.IT", "math.IT", "q-fin.ST"], "primary_category": "q-fin.GN"}
{"title": "Fisher-Rao distances between finite energy signals in noise", "abstract": "This paper proposes to represent finite-energy signals observed in agiven\nbandwidth as parameters of a probability distribution, and use the information\ngeometrical framework to compute the Fisher-Rao distance between these signals,\nseen as distributions. The observations are represented by their discrete\nFourier transform, which are modeled as complex Gaussian vectors with fixed\ndiagonal covariance matrix and parametrized means. The parameters define the\ncoordinate system of a statistical manifold. This work investigates the\npossibility of obtaining closed-form expressions for the Fisher-Rao distance.\nWe study two cases: the general case representing any finite energy signal\nobserved in a given bandwidth and a parametrized example of observing an\nattenuated signal with a known magnitude spectrum and unknown phase spectrum,\nand we calculate the Fisher-Rao distances for both cases. The finite energy\nsignal manifold corresponds to the manifold of the Gaussian distribution with a\nknown covariance matrix, and the manifold of known magnitude spectrum signals\nis a submanifold. We derive the expressions for the Christoffel symbols and the\ntensorial equations of the geodesics. This leads to geodesic equations\nexpressed as second order differential equations. We show that the tensor\ndifferential equations can be transformed into matrix equations. These\nequations depend on the parametric model but simplify to only two vectorial\nequations, which combine the magnitude and phase of the signal and their\ngradients with respect to the parameters. We compute closed-form expressions of\nthe Fisher-Rao distances for both studied cases and show that the submanifold\nis non-geodesic, indicating that the Fisher-Rao distance measured within the\nsubmanifold is greater than in the full manifold.", "published": "2025-05-20 16:57:12", "link": "http://arxiv.org/abs/2505.14611v1", "categories": ["cs.IT", "math.IT", "math.ST", "stat.TH", "62"], "primary_category": "cs.IT"}
{"title": "Duals of multiplicity codes", "abstract": "Multivariate multiplicity codes have been recently explored because of their\nimportance for list decoding and local decoding. Given a multivariate\nmultiplicity code, in this paper, we compute its dimension using Gr\\\"obner\nbasis tools, its dual in terms of indicator functions, and explicitly describe\na parity-check matrix. In contrast with Reed--Muller, Reed--Solomon, univariate\nmultiplicity, and other evaluation codes, the dual of a multivariate\nmultiplicity code is not equivalent or isometric to a multiplicity code (i.e.,\nthis code family is not closed under duality). We use our explicit description\nto provide a lower bound on the minimum distance for the dual of a multiplicity\ncode.", "published": "2025-05-20 15:06:44", "link": "http://arxiv.org/abs/2505.14472v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Information-optimal measurement: From fixed sampling protocols to adaptive spectroscopy", "abstract": "All measurements of continuous signals rely on taking discrete snapshots,\nwith the Nyquist-Shannon theorem dictating sampling paradigms. We present a\nbroader framework of information-optimal measurement, showing that traditional\nsampling is optimal only when we are entirely ignorant about the system under\ninvestigation. This insight unlocks methods that efficiently leverage prior\ninformation to overcome long-held fundamental sampling limitations. We\ndemonstrate this for optical spectroscopy - vital to research and medicine -\nand show how adaptively selected measurements yield higher information in\nmedical blood analysis, optical metrology, and hyperspectral imaging. Through\nour rigorous statistical framework, performance never falls below conventional\nsampling while providing complete uncertainty quantification in real time. This\nestablishes a new paradigm where measurement devices operate as\ninformation-optimal agents, fundamentally changing how scientific instruments\ncollect and process data.", "published": "2025-05-20 13:48:48", "link": "http://arxiv.org/abs/2505.14364v1", "categories": ["physics.optics", "cs.IT", "math.IT"], "primary_category": "physics.optics"}
{"title": "What is Visualization for Communication? Analyzing Four Years of VisComm Papers", "abstract": "With the introduction of the Visualization for Communication workshop\n(VisComm) at IEEE VIS and in light of the COVID-19 pandemic, there has been\nrenewed interest in studying visualization as a medium of communication.\nHowever the characteristics and definition of this line of study tend to vary\nfrom paper to paper and person to person. In this work, we examine the 37\npapers accepted to VisComm from 2018 through 2022. Using grounded theory we\nidentify nuances in how VisComm defines visualization, common themes in the\nwork in this area, and a noticeable gap in DEI practices.", "published": "2025-05-20 13:25:28", "link": "http://arxiv.org/abs/2505.14339v1", "categories": ["cs.HC"], "primary_category": "cs.HC"}
{"title": "Lifting a CSS code via its handlebody realization", "abstract": "We present a topological approach to lifting a quantum CSS code. In previous\nwork, we proposed lifting a CSS code by constructing covering spaces over its\n2D simplicial complex representation, known as the Tanner cone-complex. This\nidea was inspired by the work of Freedman and Hastings, which associates CSS\ncodes with handlebodies. In this paper, we show how the handlebody realization\nof a code can also be used to perform code lifting, and we provide a more\ndetailed discussion of why this is essentially equivalent to the Tanner\ncone-complex approach. As an application, we classify lifts of\nhypergraph-product codes via their handlebody realization.", "published": "2025-05-20 13:11:53", "link": "http://arxiv.org/abs/2505.14327v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Timely CPU Scheduling for Computation-intensive Status Updates", "abstract": "The proliferation of mobile devices and real-time status updating\napplications has motivated the optimization of data freshness in the context of\nage of information (AoI). Meanwhile, increasing computational demands have\ninspired research on CPU scheduling. Since prior CPU scheduling strategies have\nignored data freshness and prior age-minimization strategies have considered\nonly constant CPU speed, we formulate the first CPU scheduling problem as a\nconstrained semi-Markov decision process (SMDP) problem with uncountable space,\nwhich aims to minimize the long-term average age of information, subject to an\naverage CPU power constraint. We optimize strategies that specify when the CPU\nsleeps and adapt the CPU speed (clock frequency) during the execution of\nupdate-processing tasks. We consider the age-minimal CPU scheduling problem for\nboth predictable task size (PTS) and unpredictable task size (UTS) cases, where\nthe task size is realized at the start (PTS) or at the completion (UTS) of the\ntask, respectively. To address the non-convex objective, we employ Dinkelbach's\nfractional programming method to transform our problem into an average cost\nSMDP. We develop a value-iteration-based algorithm and prove its convergence to\nobtain optimal policies and structural results for both the PTS and UTS\nsystems. Compared to constant CPU speed, numerical results show that our\nproposed scheme can reduce the AoI by 50\\% or more, with increasing benefits\nunder tighter power constraints. Further, for a given AoI target, the\nage-minimal CPU scheduling policy can reduce the energy consumption by 50\\% or\nmore, with greater AoI reductions when the task size distribution exhibits\nhigher variance.", "published": "2025-05-20 12:57:45", "link": "http://arxiv.org/abs/2505.14307v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Swarm Intelligence Optimization of Multi-RIS Aided MmWave Beamspace MIMO", "abstract": "We investigate the performance of a multiple reconfigurable intelligence\nsurface (RIS)-aided millimeter wave (mmWave) beamspace multiple-input\nmultiple-output (MIMO) system with multiple users (UEs). We focus on a\nchallenging scenario in which the direct links between the base station (BS)\nand all UEs are blocked, and communication is facilitated only via RISs. The\nmaximum ratio transmission (MRT) is utilized for data precoding, while a\nlow-complexity algorithm based on particle swarm optimization (PSO) is designed\nto jointly perform beam selection, power allocation, and RIS profile\nconfiguration. The proposed optimization approach demonstrates positive\ntrade-offs between the complexity (in terms of running time) and the achievable\nsum rate. In addition, our results demonstrate that due to the sparsity of\nbeamspace channels, increasing the number of unit cells (UCs) at RISs can lead\nto higher achievable rates than activating a larger number of beams at the MIMO\nBS.", "published": "2025-05-20 12:13:44", "link": "http://arxiv.org/abs/2505.14263v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Subshifts on groups and computable analysis", "abstract": "The study of subshifts on groups different from $\\mathbb{Z}$, such as\n$\\mathbb{Z}^d$, $d\\geq 2$, has been a subject of intense research in recent\nyears. These investigations have unveiled aremarkable connection between\ndynamics and recursion theory. Different questions about the dynamics of these\nsystems have been answered in recursion-theoretical terms. In this work we\nfurther explore this connection. We use the framework of computable analysis to\nexplore the class of effective dynamical systems on metric spaces, and relate\nthese systems to subshifts of finite type (SFTs) on groups. We prove that every\neffective dynamical system on a general metric space is the topological factor\nof an effective dynamical system with topological dimension zero. We combine\nthis result with existing simulation results to obtain new examples of systems\nthat are factors of SFTsWe also study a conjugacy invariant for subshifts on\ngroups called Medvedev degree. This invariant is a complexity measure of\nalgorithmic nature. We develop the basic theory of these degrees for subshifts\non arbitrary finitely generated groups. Using these tools we are able to\nclassify the values that this invariant attains for SFTs and other classes of\nsubshifts on several groups. Furthermore, we establish a connection between\nthese degrees and the distribution of isolated points in the space of all\nsubshifts. Motivated by the study of Medvedev degrees of subshifts, we also\nconsider translation-like actions of groups on graphs. We prove that every\nconnected, locally finite, and infinite graph admits a translation by\n$\\mathbb{Z}$, and that this action can be chosen transitive exactly when the\ngraph has one or two ends. This generalizes a result of Seward about\ntranslation-like actions of $\\mathbb{Z}$ on finitely generated groups.", "published": "2025-05-20 12:01:15", "link": "http://arxiv.org/abs/2505.14247v1", "categories": ["math.DS", "cs.IT", "math.GR", "math.IT", "math.LO", "math.MG", "37M99, 37B19, 03D40"], "primary_category": "math.DS"}
{"title": "Waveform for Next Generation Communication Systems: Comparing Zak-OTFS with OFDM", "abstract": "Across the world, there is growing interest in new waveforms, Zak-OTFS in\nparticular, and over-the-air implementations are starting to appear. The choice\nbetween OFDM and Zak-OTFS is not so much a choice between waveforms as it is an\narchitectural choice between preventing inter-carrier interference (ICI) and\nembracing ICI. In OFDM, once the Input-Output (I/O) relation is known,\nequalization is relatively simple, at least when there is no ICI. However, in\nthe presence of ICI the I/O relation is non-predictable and its acquisition is\nnon-trivial. In contrast, equalization is more involved in Zak-OTFS due to\ninter-symbol-interference (ISI), however the I/O relation is predictable and\nits acquisition is simple. {Zak-OTFS exhibits superior performance in\ndoubly-spread 6G use cases with high delay/Doppler channel spreads (i.e., high\nmobility and/or large cells), but architectural choice is governed by the\ntypical use case, today and in the future. What is typical depends to some\ndegree on geography, since large delay spread is a characteristic of large\ncells which are the rule rather than the exception in many important wireless\nmarkets.} This paper provides a comprehensive performance comparison of cyclic\nprefix OFDM (CP-OFDM) and Zak-OTFS across the full range of 6G propagation\nenvironments. The performance results provide insights into the fundamental\narchitectural choice.", "published": "2025-05-20 06:06:26", "link": "http://arxiv.org/abs/2505.13966v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Quantum Optimization via Gradient-Based Hamiltonian Descent", "abstract": "With rapid advancements in machine learning, first-order algorithms have\nemerged as the backbone of modern optimization techniques, owing to their\ncomputational efficiency and low memory requirements. Recently, the connection\nbetween accelerated gradient methods and damped heavy-ball motion, particularly\nwithin the framework of Hamiltonian dynamics, has inspired the development of\ninnovative quantum algorithms for continuous optimization. One such algorithm,\nQuantum Hamiltonian Descent (QHD), leverages quantum tunneling to escape saddle\npoints and local minima, facilitating the discovery of global solutions in\ncomplex optimization landscapes. However, QHD faces several challenges,\nincluding slower convergence rates compared to classical gradient methods and\nlimited robustness in highly non-convex problems due to the non-local nature of\nquantum states. Furthermore, the original QHD formulation primarily relies on\nfunction value information, which limits its effectiveness. Inspired by\ninsights from high-resolution differential equations that have elucidated the\nacceleration mechanisms in classical methods, we propose an enhancement to QHD\nby incorporating gradient information, leading to what we call gradient-based\nQHD. Gradient-based QHD achieves faster convergence and significantly increases\nthe likelihood of identifying global solutions. Numerical simulations on\nchallenging problem instances demonstrate that gradient-based QHD outperforms\nexisting quantum and classical methods by at least an order of magnitude.", "published": "2025-05-20 17:55:52", "link": "http://arxiv.org/abs/2505.14670v1", "categories": ["quant-ph", "cs.LG", "math.OC"], "primary_category": "quant-ph"}
{"title": "Quartet: Native FP4 Training Can Be Optimal for Large Language Models", "abstract": "The rapid advancement of large language models (LLMs) has been paralleled by\nunprecedented increases in computational demands, with training costs for\nstate-of-the-art models doubling every few months. Training models directly in\nlow-precision arithmetic offers a solution, by improving both computational\nthroughput and energy efficiency. Specifically, NVIDIA's recent Blackwell\narchitecture facilitates extremely low-precision operations, specifically FP4\nvariants, promising substantial efficiency gains. Yet, current algorithms for\ntraining LLMs in FP4 precision face significant accuracy degradation and often\nrely on mixed-precision fallbacks. In this paper, we systematically investigate\nhardware-supported FP4 training and introduce Quartet, a new approach enabling\naccurate, end-to-end FP4 training with all the major computations (in e.g.\nlinear layers) being performed in low precision. Through extensive evaluations\non Llama-type models, we reveal a new low-precision scaling law that quantifies\nperformance trade-offs across varying bit-widths and allows us to identify a\n\"near-optimal\" low-precision training technique in terms of\naccuracy-vs-computation, called Quartet. We implement Quartet using optimized\nCUDA kernels tailored for NVIDIA Blackwell GPUs, and show that it can achieve\nstate-of-the-art accuracy for FP4 precision, successfully training\nbillion-scale models. Our method demonstrates that fully FP4-based training is\na competitive alternative to standard-precision and FP8 training. Our code is\navailable at https://github.com/IST-DASLab/Quartet.", "published": "2025-05-20 17:55:50", "link": "http://arxiv.org/abs/2505.14669v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sequential QCQP for Bilevel Optimization with Line Search", "abstract": "Bilevel optimization involves a hierarchical structure where one problem is\nnested within another, leading to complex interdependencies between levels. We\npropose a single-loop, tuning-free algorithm that guarantees anytime\nfeasibility, i.e., approximate satisfaction of the lower-level optimality\ncondition, while ensuring descent of the upper-level objective. At each\niteration, a convex quadratically-constrained quadratic program (QCQP) with a\nclosed-form solution yields the search direction, followed by a backtracking\nline search inspired by control barrier functions to ensure safe, uniformly\npositive step sizes. The resulting method is scalable, requires no\nhyperparameter tuning, and converges under mild local regularity assumptions.\nWe establish an O(1/k) ergodic convergence rate and demonstrate the algorithm's\neffectiveness on representative bilevel tasks.", "published": "2025-05-20 17:35:38", "link": "http://arxiv.org/abs/2505.14647v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "Early Diagnosis of Atrial Fibrillation Recurrence: A Large Tabular Model Approach with Structured and Unstructured Clinical Data", "abstract": "BACKGROUND: Atrial fibrillation (AF), the most common arrhythmia, is linked\nto high morbidity and mortality. In a fast-evolving AF rhythm control treatment\nera, predicting AF recurrence after its onset may be crucial to achieve the\noptimal therapeutic approach, yet traditional scores like CHADS2-VASc, HATCH,\nand APPLE show limited predictive accuracy. Moreover, early diagnosis studies\noften rely on codified electronic health record (EHR) data, which may contain\nerrors and missing information.\n  OBJECTIVE: This study aims to predict AF recurrence between one month and two\nyears after onset by evaluating traditional clinical scores, ML models, and our\nLTM approach. Moreover, another objective is to develop a methodology for\nintegrating structured and unstructured data to enhance tabular dataset\nquality.\n  METHODS: A tabular dataset was generated by combining structured clinical\ndata with free-text discharge reports processed through natural language\nprocessing techniques, reducing errors and annotation effort. A total of 1,508\npatients with documented AF onset were identified, and models were evaluated on\na manually annotated test set. The proposed approach includes a LTM compared\nagainst traditional clinical scores and ML models.\n  RESULTS: The proposed LTM approach achieved the highest predictive\nperformance, surpassing both traditional clinical scores and ML models.\nAdditionally, the gender and age bias analyses revealed demographic\ndisparities.\n  CONCLUSION: The integration of structured data and free-text sources resulted\nin a high-quality dataset. The findings emphasize the limitations of\ntraditional clinical scores in predicting AF recurrence and highlight the\npotential of ML-based approaches, particularly our LTM model.", "published": "2025-05-20 17:31:05", "link": "http://arxiv.org/abs/2505.14643v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Bridging Predictive Coding and MDL: A Two-Part Code Framework for Deep Learning", "abstract": "We present the first theoretical framework that connects predictive coding\n(PC), a biologically inspired local learning rule, with the minimum description\nlength (MDL) principle in deep networks. We prove that layerwise PC performs\nblock-coordinate descent on the MDL two-part code objective, thereby jointly\nminimizing empirical risk and model complexity. Using Hoeffding's inequality\nand a prefix-code prior, we derive a novel generalization bound of the form\n$R(\\theta) \\le \\^{R}(\\theta) + \\frac{L(\\theta)}{N}$, capturing the tradeoff\nbetween fit and compression. We further prove that each PC sweep monotonically\ndecreases the empirical two-part codelength, yielding tighter high-probability\nrisk bounds than unconstrained gradient descent. Finally, we show that repeated\nPC updates converge to a block-coordinate stationary point, providing an\napproximate MDL-optimal solution. To our knowledge, this is the first result\noffering formal generalization and convergence guarantees for PC-trained deep\nmodels, positioning PC as a theoretically grounded and biologically plausible\nalternative to backpropagation.", "published": "2025-05-20 17:25:16", "link": "http://arxiv.org/abs/2505.14635v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Virtual Cells: Predict, Explain, Discover", "abstract": "Drug discovery is fundamentally a process of inferring the effects of\ntreatments on patients, and would therefore benefit immensely from\ncomputational models that can reliably simulate patient responses, enabling\nresearchers to generate and test large numbers of therapeutic hypotheses safely\nand economically before initiating costly clinical trials. Even a more specific\nmodel that predicts the functional response of cells to a wide range of\nperturbations would be tremendously valuable for discovering safe and effective\ntreatments that successfully translate to the clinic. Creating such virtual\ncells has long been a goal of the computational research community that\nunfortunately remains unachieved given the daunting complexity and scale of\ncellular biology. Nevertheless, recent advances in AI, computing power, lab\nautomation, and high-throughput cellular profiling provide new opportunities\nfor reaching this goal. In this perspective, we present a vision for developing\nand evaluating virtual cells that builds on our experience at Recursion. We\nargue that in order to be a useful tool to discover novel biology, virtual\ncells must accurately predict the functional response of a cell to\nperturbations and explain how the predicted response is a consequence of\nmodifications to key biomolecular interactions. We then introduce key\nprinciples for designing therapeutically-relevant virtual cells, describe a\nlab-in-the-loop approach for generating novel insights with them, and advocate\nfor biologically-grounded benchmarks to guide virtual cell development.\nFinally, we make the case that our approach to virtual cells provides a useful\nframework for building other models at higher levels of organization, including\nvirtual patients. We hope that these directions prove useful to the research\ncommunity in developing virtual models optimized for positive impact on drug\ndiscovery outcomes.", "published": "2025-05-20 16:59:24", "link": "http://arxiv.org/abs/2505.14613v1", "categories": ["cs.LG", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "MMD-Newton Method for Multi-objective Optimization", "abstract": "Maximum mean discrepancy (MMD) has been widely employed to measure the\ndistance between probability distributions. In this paper, we propose using MMD\nto solve continuous multi-objective optimization problems (MOPs). For solving\nMOPs, a common approach is to minimize the distance (e.g., Hausdorff) between a\nfinite approximate set of the Pareto front and a reference set. Viewing these\ntwo sets as empirical measures, we propose using MMD to measure the distance\nbetween them. To minimize the MMD value, we provide the analytical expression\nof its gradient and Hessian matrix w.r.t. the search variables, and use them to\ndevise a novel set-oriented, MMD-based Newton (MMDN) method. Also, we analyze\nthe theoretical properties of MMD's gradient and Hessian, including the\nfirst-order stationary condition and the eigenspectrum of the Hessian, which\nare important for verifying the correctness of MMDN. To solve complicated\nproblems, we propose hybridizing MMDN with multiobjective evolutionary\nalgorithms (MOEAs), where we first execute an EA for several iterations to get\nclose to the global Pareto front and then warm-start MMDN with the result of\nthe MOEA to efficiently refine the approximation. We empirically test the\nhybrid algorithm on 11 widely used benchmark problems, and the results show the\nhybrid (MMDN + MOEA) can achieve a much better optimization accuracy than EA\nalone with the same computation budget.", "published": "2025-05-20 16:56:50", "link": "http://arxiv.org/abs/2505.14610v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Electrostatics from Laplacian Eigenbasis for Neural Network Interatomic Potentials", "abstract": "Recent advances in neural network interatomic potentials have emerged as a\npromising research direction. However, popular deep learning models often lack\nauxiliary constraints grounded in physical laws, which could accelerate\ntraining and improve fidelity through physics-based regularization. In this\nwork, we introduce $\\Phi$-Module, a universal plugin module that enforces\nPoisson's equation within the message-passing framework to learn electrostatic\ninteractions in a self-supervised manner. Specifically, each atom-wise\nrepresentation is encouraged to satisfy a discretized Poisson's equation,\nmaking it possible to acquire a potential $\\boldsymbol{\\phi}$ and a\ncorresponding charge density $\\boldsymbol{\\rho}$ linked to the learnable\nLaplacian eigenbasis coefficients of a given molecular graph. We then derive an\nelectrostatic energy term, crucial for improved total energy predictions. This\napproach integrates seamlessly into any existing neural potential with\ninsignificant computational overhead. Experiments on the OE62 and MD22\nbenchmarks confirm that models combined with $\\Phi$-Module achieve robust\nimprovements over baseline counterparts. For OE62 error reduction ranges from\n4.5\\% to 17.8\\%, and for MD22, baseline equipped with $\\Phi$-Module achieves\nbest results on 5 out of 14 cases. Our results underscore how embedding a\nfirst-principles constraint in neural interatomic potentials can significantly\nimprove performance while remaining hyperparameter-friendly, memory-efficient\nand lightweight in training. Code will be available at\n\\href{https://github.com/dunnolab/phi-module}{dunnolab/phi-module}.", "published": "2025-05-20 16:54:25", "link": "http://arxiv.org/abs/2505.14606v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "CSTS: A Benchmark for the Discovery of Correlation Structures in Time Series Clustering", "abstract": "Time series clustering promises to uncover hidden structural patterns in data\nwith applications across healthcare, finance, industrial systems, and other\ncritical domains. However, without validated ground truth information,\nresearchers cannot objectively assess clustering quality or determine whether\npoor results stem from absent structures in the data, algorithmic limitations,\nor inappropriate validation methods, raising the question whether clustering is\n\"more art than science\" (Guyon et al., 2009). To address these challenges, we\nintroduce CSTS (Correlation Structures in Time Series), a synthetic benchmark\nfor evaluating the discovery of correlation structures in multivariate time\nseries data. CSTS provides a clean benchmark that enables researchers to\nisolate and identify specific causes of clustering failures by differentiating\nbetween correlation structure deterioration and limitations of clustering\nalgorithms and validation methods. Our contributions are: (1) a comprehensive\nbenchmark for correlation structure discovery with distinct correlation\nstructures, systematically varied data conditions, established performance\nthresholds, and recommended evaluation protocols; (2) empirical validation of\ncorrelation structure preservation showing moderate distortion from\ndownsampling and minimal effects from distribution shifts and sparsification;\nand (3) an extensible data generation framework enabling structure-first\nclustering evaluation. A case study demonstrates CSTS's practical utility by\nidentifying an algorithm's previously undocumented sensitivity to non-normal\ndistributions, illustrating how the benchmark enables precise diagnosis of\nmethodological limitations. CSTS advances rigorous evaluation standards for\ncorrelation-based time series clustering.", "published": "2025-05-20 16:48:14", "link": "http://arxiv.org/abs/2505.14596v1", "categories": ["cs.LG", "stat.ML", "62H30, 62H20, 62-11, 68T10, 62M10,", "I.5.3; H.2.8; G.3; I.2.6"], "primary_category": "cs.LG"}
{"title": "Physics-informed Reduced Order Modeling of Time-dependent PDEs via Differentiable Solvers", "abstract": "Reduced-order modeling (ROM) of time-dependent and parameterized differential\nequations aims to accelerate the simulation of complex high-dimensional systems\nby learning a compact latent manifold representation that captures the\ncharacteristics of the solution fields and their time-dependent dynamics.\nAlthough high-fidelity numerical solvers generate the training datasets, they\nhave thus far been excluded from the training process, causing the learned\nlatent dynamics to drift away from the discretized governing physics. This\nmismatch often limits generalization and forecasting capabilities. In this\nwork, we propose Physics-informed ROM ($\\Phi$-ROM) by incorporating\ndifferentiable PDE solvers into the training procedure. Specifically, the\nlatent space dynamics and its dependence on PDE parameters are shaped directly\nby the governing physics encoded in the solver, ensuring a strong\ncorrespondence between the full and reduced systems. Our model outperforms\nstate-of-the-art data-driven ROMs and other physics-informed strategies by\naccurately generalizing to new dynamics arising from unseen parameters,\nenabling long-term forecasting beyond the training horizon, maintaining\ncontinuity in both time and space, and reducing the data cost. Furthermore,\n$\\Phi$-ROM learns to recover and forecast the solution fields even when trained\nor evaluated with sparse and irregular observations of the fields, providing a\nflexible framework for field reconstruction and data assimilation. We\ndemonstrate the framework's robustness across different PDE solvers and\nhighlight its broad applicability by providing an open-source JAX\nimplementation readily extensible to other PDE systems and differentiable\nsolvers.", "published": "2025-05-20 16:47:04", "link": "http://arxiv.org/abs/2505.14595v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive Pruning of Deep Neural Networks for Resource-Aware Embedded Intrusion Detection on the Edge", "abstract": "Artificial neural network pruning is a method in which artificial neural\nnetwork sizes can be reduced while attempting to preserve the predicting\ncapabilities of the network. This is done to make the model smaller or faster\nduring inference time. In this work we analyze the ability of a selection of\nartificial neural network pruning methods to generalize to a new cybersecurity\ndataset utilizing a simpler network type than was designed for. We analyze each\nmethod using a variety of pruning degrees to best understand how each algorithm\nresponds to the new environment. This has allowed us to determine the most well\nfit pruning method of those we searched for the task. Unexpectedly, we have\nfound that many of them do not generalize to the problem well, leaving only a\nfew algorithms working to an acceptable degree.", "published": "2025-05-20 16:45:54", "link": "http://arxiv.org/abs/2505.14592v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "High-Dimensional Analysis of Bootstrap Ensemble Classifiers", "abstract": "Bootstrap methods have long been a cornerstone of ensemble learning in\nmachine learning. This paper presents a theoretical analysis of bootstrap\ntechniques applied to the Least Square Support Vector Machine (LSSVM) ensemble\nin the context of large and growing sample sizes and feature dimensionalities.\nLeveraging tools from Random Matrix Theory, we investigate the performance of\nthis classifier that aggregates decision functions from multiple weak\nclassifiers, each trained on different subsets of the data. We provide insights\ninto the use of bootstrap methods in high-dimensional settings, enhancing our\nunderstanding of their impact. Based on these findings, we propose strategies\nto select the number of subsets and the regularization parameter that maximize\nthe performance of the LSSVM. Empirical experiments on synthetic and real-world\ndatasets validate our theoretical results.", "published": "2025-05-20 16:40:43", "link": "http://arxiv.org/abs/2505.14587v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Performance Optimization of Energy-Harvesting Underlay Cognitive Radio Networks Using Reinforcement Learning", "abstract": "In this paper, a reinforcement learning technique is employed to maximize the\nperformance of a cognitive radio network (CRN). In the presence of primary\nusers (PUs), it is presumed that two secondary users (SUs) access the licensed\nband within underlay mode. In addition, the SU transmitter is assumed to be an\nenergy-constrained device that requires harvesting energy in order to transmit\nsignals to their intended destination. Therefore, we propose that there are two\nmain sources of energy; the interference of PUs' transmissions and ambient\nradio frequency (RF) sources. The SU will select whether to gather energy from\nPUs or only from ambient sources based on a predetermined threshold. The\nprocess of energy harvesting from the PUs' messages is accomplished via the\ntime switching approach. In addition, based on a deep Q-network (DQN) approach,\nthe SU transmitter determines whether to collect energy or transmit messages\nduring each time slot as well as selects the suitable transmission power in\norder to maximize its average data rate. Our approach outperforms a baseline\nstrategy and converges, as shown by our findings.", "published": "2025-05-20 16:38:32", "link": "http://arxiv.org/abs/2505.14581v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Time to Embed: Unlocking Foundation Models for Time Series with Channel Descriptions", "abstract": "Traditional time series models are task-specific and often depend on\ndataset-specific training and extensive feature engineering. While\nTransformer-based architectures have improved scalability, foundation models,\ncommonplace in text, vision, and audio, remain under-explored for time series\nand are largely restricted to forecasting. We introduce $\\textbf{CHARM}$, a\nfoundation embedding model for multivariate time series that learns shared,\ntransferable, and domain-aware representations. To address the unique\ndifficulties of time series foundation learning, $\\textbf{CHARM}$ incorporates\narchitectural innovations that integrate channel-level textual descriptions\nwhile remaining invariant to channel order. The model is trained using a Joint\nEmbedding Predictive Architecture (JEPA), with novel augmentation schemes and a\nloss function designed to improve interpretability and training stability. Our\n$7$M-parameter model achieves state-of-the-art performance across diverse\ndownstream tasks, setting a new benchmark for time series representation\nlearning.", "published": "2025-05-20 15:58:54", "link": "http://arxiv.org/abs/2505.14543v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Spiking Neural Networks with Temporal Attention-Guided Adaptive Fusion for imbalanced Multi-modal Learning", "abstract": "Multimodal spiking neural networks (SNNs) hold significant potential for\nenergy-efficient sensory processing but face critical challenges in modality\nimbalance and temporal misalignment. Current approaches suffer from\nuncoordinated convergence speeds across modalities and static fusion mechanisms\nthat ignore time-varying cross-modal interactions. We propose the temporal\nattention-guided adaptive fusion framework for multimodal SNNs with two\nsynergistic innovations: 1) The Temporal Attention-guided Adaptive Fusion\n(TAAF) module that dynamically assigns importance scores to fused spiking\nfeatures at each timestep, enabling hierarchical integration of temporally\nheterogeneous spike-based features; 2) The temporal adaptive balanced fusion\nloss that modulates learning rates per modality based on the above attention\nscores, preventing dominant modalities from monopolizing optimization. The\nproposed framework implements adaptive fusion, especially in the temporal\ndimension, and alleviates the modality imbalance during multimodal learning,\nmimicking cortical multisensory integration principles. Evaluations on CREMA-D,\nAVE, and EAD datasets demonstrate state-of-the-art performance (77.55\\%,\n70.65\\% and 97.5\\%accuracy, respectively) with energy efficiency. The system\nresolves temporal misalignment through learnable time-warping operations and\nfaster modality convergence coordination than baseline SNNs. This work\nestablishes a new paradigm for temporally coherent multimodal learning in\nneuromorphic systems, bridging the gap between biological sensory processing\nand efficient machine intelligence.", "published": "2025-05-20 15:55:11", "link": "http://arxiv.org/abs/2505.14535v1", "categories": ["cs.LG", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Lessons from Defending Gemini Against Indirect Prompt Injections", "abstract": "Gemini is increasingly used to perform tasks on behalf of users, where\nfunction-calling and tool-use capabilities enable the model to access user\ndata. Some tools, however, require access to untrusted data introducing risk.\nAdversaries can embed malicious instructions in untrusted data which cause the\nmodel to deviate from the user's expectations and mishandle their data or\npermissions. In this report, we set out Google DeepMind's approach to\nevaluating the adversarial robustness of Gemini models and describe the main\nlessons learned from the process. We test how Gemini performs against a\nsophisticated adversary through an adversarial evaluation framework, which\ndeploys a suite of adaptive attack techniques to run continuously against past,\ncurrent, and future versions of Gemini. We describe how these ongoing\nevaluations directly help make Gemini more resilient against manipulation.", "published": "2025-05-20 15:54:45", "link": "http://arxiv.org/abs/2505.14534v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "SifterNet: A Generalized and Model-Agnostic Trigger Purification Approach", "abstract": "Aiming at resisting backdoor attacks in convolution neural networks and\nvision Transformer-based large model, this paper proposes a generalized and\nmodel-agnostic trigger-purification approach resorting to the classic Ising\nmodel. To date, existing trigger detection/removal studies usually require to\nknow the detailed knowledge of target model in advance, access to a large\nnumber of clean samples or even model-retraining authorization, which brings\nthe huge inconvenience for practical applications, especially inaccessible to\ntarget model. An ideal countermeasure ought to eliminate the implanted trigger\nwithout regarding whatever the target models are. To this end, a lightweight\nand black-box defense approach SifterNet is proposed through leveraging the\nmemorization-association functionality of Hopfield network, by which the\ntriggers of input samples can be effectively purified in a proper manner. The\nmain novelty of our proposed approach lies in the introduction of ideology of\nIsing model. Extensive experiments also validate the effectiveness of our\napproach in terms of proper trigger purification and high accuracy achievement,\nand compared to the state-of-the-art baselines under several commonly-used\ndatasets, our SiferNet has a significant superior performance.", "published": "2025-05-20 15:51:17", "link": "http://arxiv.org/abs/2505.14531v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A simple estimator of the correlation kernel matrix of a determinantal point process", "abstract": "The Determinantal Point Process (DPP) is a parameterized model for\nmultivariate binary variables, characterized by a correlation kernel matrix.\nThis paper proposes a closed form estimator of this kernel, which is\nparticularly easy to implement and can also be used as a starting value of\nlearning algorithms for maximum likelihood estimation. We prove the consistency\nand asymptotic normality of our estimator, as well as its large deviation\nproperties.", "published": "2025-05-20 15:48:45", "link": "http://arxiv.org/abs/2505.14529v1", "categories": ["stat.ML", "cs.LG", "62G30"], "primary_category": "stat.ML"}
{"title": "Interpretable Dual-Stream Learning for Local Wind Hazard Prediction in Vulnerable Communities", "abstract": "Wind hazards such as tornadoes and straight-line winds frequently affect\nvulnerable communities in the Great Plains of the United States, where limited\ninfrastructure and sparse data coverage hinder effective emergency response.\nExisting forecasting systems focus primarily on meteorological elements and\noften fail to capture community-specific vulnerabilities, limiting their\nutility for localized risk assessment and resilience planning. To address this\ngap, we propose an interpretable dual-stream learning framework that integrates\nstructured numerical weather data with unstructured textual event narratives.\nOur architecture combines a Random Forest and RoBERTa-based transformer through\na late fusion mechanism, enabling robust and context-aware wind hazard\nprediction. The system is tailored for underserved tribal communities and\nsupports block-level risk assessment. Experimental results show significant\nperformance gains over traditional baselines. Furthermore, gradient-based\nsensitivity and ablation studies provide insight into the model's\ndecision-making process, enhancing transparency and operational trust. The\nfindings demonstrate both predictive effectiveness and practical value in\nsupporting emergency preparedness and advancing community resilience.", "published": "2025-05-20 15:46:02", "link": "http://arxiv.org/abs/2505.14522v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Steering Deep Non-Linear Spatially Selective Filters for Weakly Guided Extraction of Moving Speakers in Dynamic Scenarios", "abstract": "Recent speaker extraction methods using deep non-linear spatial filtering\nperform exceptionally well when the target direction is known and stationary.\nHowever, spatially dynamic scenarios are considerably more challenging due to\ntime-varying spatial features and arising ambiguities, e.g. when moving\nspeakers cross. While in a static scenario it may be easy for a user to point\nto the target's direction, manually tracking a moving speaker is impractical.\nInstead of relying on accurate time-dependent directional cues, which we refer\nto as strong guidance, in this paper we propose a weakly guided extraction\nmethod solely depending on the target's initial position to cope with spatial\ndynamic scenarios. By incorporating our own deep tracking algorithm and\ndeveloping a joint training strategy on a synthetic dataset, we demonstrate the\nproficiency of our approach in resolving spatial ambiguities and even\noutperform a mismatched, but strongly guided extraction method.", "published": "2025-05-20 15:43:55", "link": "http://arxiv.org/abs/2505.14517v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Just One Layer Norm Guarantees Stable Extrapolation", "abstract": "In spite of their prevalence, the behaviour of Neural Networks when\nextrapolating far from the training distribution remains poorly understood,\nwith existing results limited to specific cases. In this work, we prove general\nresults -- the first of their kind -- by applying Neural Tangent Kernel (NTK)\ntheory to analyse infinitely-wide neural networks trained until convergence and\nprove that the inclusion of just one Layer Norm (LN) fundamentally alters the\ninduced NTK, transforming it into a bounded-variance kernel. As a result, the\noutput of an infinitely wide network with at least one LN remains bounded, even\non inputs far from the training data. In contrast, we show that a broad class\nof networks without LN can produce pathologically large outputs for certain\ninputs. We support these theoretical findings with empirical experiments on\nfinite-width networks, demonstrating that while standard NNs often exhibit\nuncontrolled growth outside the training domain, a single LN layer effectively\nmitigates this instability. Finally, we explore real-world implications of this\nextrapolatory stability, including applications to predicting residue sizes in\nproteins larger than those seen during training and estimating age from facial\nimages of underrepresented ethnicities absent from the training set.", "published": "2025-05-20 15:39:27", "link": "http://arxiv.org/abs/2505.14512v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Federated prediction for scalable and privacy-preserved knowledge-based planning in radiotherapy", "abstract": "Background: Deep learning has potential to improve the efficiency and\nconsistency of radiation therapy planning, but clinical adoption is hindered by\nthe limited model generalizability due to data scarcity and heterogeneity among\ninstitutions. Although aggregating data from different institutions could\nalleviate this problem, data sharing is a practical challenge due to concerns\nabout patient data privacy and other technical obstacles. Purpose: This work\naims to address this dilemma by developing FedKBP+, a comprehensive federated\nlearning (FL) platform for predictive tasks in real-world applications in\nradiotherapy treatment planning. Methods: We implemented a unified\ncommunication stack based on Google Remote Procedure Call (gRPC) to support\ncommunication between participants whether located on the same workstation or\ndistributed across multiple workstations. In addition to supporting the\ncentralized FL strategies commonly available in existing open-source\nframeworks, FedKBP+ also provides a fully decentralized FL model where\nparticipants directly exchange model weights to each other through Peer-to-Peer\ncommunication. We evaluated FedKBP+ on three predictive tasks using\nscale-attention network (SA-Net) as the predictive model. Conclusions: Our\nresults demonstrate that FedKBP+ is highly effective, efficient and robust,\nshowing great potential as a federated learning platform for radiation therapy.", "published": "2025-05-20 15:35:49", "link": "http://arxiv.org/abs/2505.14507v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Learning to Integrate Diffusion ODEs by Averaging the Derivatives", "abstract": "To accelerate diffusion model inference, numerical solvers perform poorly at\nextremely small steps, while distillation techniques often introduce complexity\nand instability. This work presents an intermediate strategy, balancing\nperformance and cost, by learning ODE integration using loss functions derived\nfrom the derivative-integral relationship, inspired by Monte Carlo integration\nand Picard iteration. From a geometric perspective, the losses operate by\ngradually extending the tangent to the secant, thus are named as secant losses.\nThe secant losses can rapidly convert (via fine-tuning or distillation) a\npretrained diffusion model into its secant version. In our experiments, the\nsecant version of EDM achieves a $10$-step FID of $2.14$ on CIFAR-10, while the\nsecant version of SiT-XL/2 attains a $4$-step FID of $2.27$ and an $8$-step FID\nof $1.96$ on ImageNet-$256\\times256$. Code will be available.", "published": "2025-05-20 15:30:38", "link": "http://arxiv.org/abs/2505.14502v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Personalised Insulin Adjustment with Reinforcement Learning: An In-Silico Validation for People with Diabetes on Intensive Insulin Treatment", "abstract": "Despite recent advances in insulin preparations and technology, adjusting\ninsulin remains an ongoing challenge for the majority of people with type 1\ndiabetes (T1D) and longstanding type 2 diabetes (T2D). In this study, we\npropose the Adaptive Basal-Bolus Advisor (ABBA), a personalised insulin\ntreatment recommendation approach based on reinforcement learning for\nindividuals with T1D and T2D, performing self-monitoring blood glucose\nmeasurements and multiple daily insulin injection therapy. We developed and\nevaluated the ability of ABBA to achieve better time-in-range (TIR) for\nindividuals with T1D and T2D, compared to a standard basal-bolus advisor (BBA).\nThe in-silico test was performed using an FDA-accepted population, including\n101 simulated adults with T1D and 101 with T2D. An in-silico evaluation shows\nthat ABBA significantly improved TIR and significantly reduced both times\nbelow- and above-range, compared to BBA. ABBA's performance continued to\nimprove over two months, whereas BBA exhibited only modest changes. This\npersonalised method for adjusting insulin has the potential to further optimise\nglycaemic control and support people with T1D and T2D in their daily\nself-management. Our results warrant ABBA to be trialed for the first time in\nhumans.", "published": "2025-05-20 15:10:06", "link": "http://arxiv.org/abs/2505.14477v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ServerlessLoRA: Minimizing Latency and Cost in Serverless Inference for LoRA-Based LLMs", "abstract": "Serverless computing has grown rapidly for serving Large Language Model (LLM)\ninference due to its pay-as-you-go pricing, fine-grained GPU usage, and rapid\nscaling. However, our analysis reveals that current serverless can effectively\nserve general LLM but fail with Low-Rank Adaptation (LoRA) inference due to\nthree key limitations: 1) massive parameter redundancy among functions where\n99% of weights are unnecessarily duplicated, 2) costly artifact loading latency\nbeyond LLM loading, and 3) magnified resource contention when serving multiple\nLoRA LLMs. These inefficiencies lead to massive GPU wastage, increased\nTime-To-First-Token (TTFT), and high monetary costs.\n  We propose ServerlessLoRA, a novel serverless inference system designed for\nfaster and cheaper LoRA LLM serving. ServerlessLoRA enables secure backbone LLM\nsharing across isolated LoRA functions to reduce redundancy. We design a\npre-loading method that pre-loads comprehensive LoRA artifacts to minimize\ncold-start latency. Furthermore, ServerlessLoRA employs contention aware\nbatching and offloading to mitigate GPU resource conflicts during bursty\nworkloads. Experiment on industrial workloads demonstrates that ServerlessLoRA\nreduces TTFT by up to 86% and cuts monetary costs by up to 89% compared to\nstate-of-the-art LLM inference solutions.", "published": "2025-05-20 15:04:17", "link": "http://arxiv.org/abs/2505.14468v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "FlowTSE: Target Speaker Extraction with Flow Matching", "abstract": "Target speaker extraction (TSE) aims to isolate a specific speaker's speech\nfrom a mixture using speaker enrollment as a reference. While most existing\napproaches are discriminative, recent generative methods for TSE achieve strong\nresults. However, generative methods for TSE remain underexplored, with most\nexisting approaches relying on complex pipelines and pretrained components,\nleading to computational overhead. In this work, we present FlowTSE, a simple\nyet effective TSE approach based on conditional flow matching. Our model\nreceives an enrollment audio sample and a mixed speech signal, both represented\nas mel-spectrograms, with the objective of extracting the target speaker's\nclean speech. Furthermore, for tasks where phase reconstruction is crucial, we\npropose a novel vocoder conditioned on the complex STFT of the mixed signal,\nenabling improved phase estimation. Experimental results on standard TSE\nbenchmarks show that FlowTSE matches or outperforms strong baselines.", "published": "2025-05-20 15:01:30", "link": "http://arxiv.org/abs/2505.14465v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Adverseness vs. Equilibrium: Exploring Graph Adversarial Resilience through Dynamic Equilibrium", "abstract": "Adversarial attacks to graph analytics are gaining increased attention. To\ndate, two lines of countermeasures have been proposed to resist various graph\nadversarial attacks from the perspectives of either graph per se or graph\nneural networks. Nevertheless, a fundamental question lies in whether there\nexists an intrinsic adversarial resilience state within a graph regime and how\nto find out such a critical state if exists. This paper contributes to tackle\nthe above research questions from three unique perspectives: i) we regard the\nprocess of adversarial learning on graph as a complex multi-object dynamic\nsystem, and model the behavior of adversarial attack; ii) we propose a\ngeneralized theoretical framework to show the existence of critical adversarial\nresilience state; and iii) we develop a condensed one-dimensional function to\ncapture the dynamic variation of graph regime under perturbations, and pinpoint\nthe critical state through solving the equilibrium point of dynamic system.\nMulti-facet experiments are conducted to show our proposed approach can\nsignificantly outperform the state-of-the-art defense methods under five\ncommonly-used real-world datasets and three representative attacks.", "published": "2025-05-20 14:58:21", "link": "http://arxiv.org/abs/2505.14463v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Interpretable Reinforcement Learning for Load Balancing using Kolmogorov-Arnold Networks", "abstract": "Reinforcement learning (RL) has been increasingly applied to network control\nproblems, such as load balancing. However, existing RL approaches often suffer\nfrom lack of interpretability and difficulty in extracting controller\nequations. In this paper, we propose the use of Kolmogorov-Arnold Networks\n(KAN) for interpretable RL in network control. We employ a PPO agent with a\n1-layer actor KAN model and an MLP Critic network to learn load balancing\npolicies that maximise throughput utility, minimize loss as well as delay. Our\napproach allows us to extract controller equations from the learned neural\nnetworks, providing insights into the decision-making process. We evaluate our\napproach using different reward functions demonstrating its effectiveness in\nimproving network performance while providing interpretable policies.", "published": "2025-05-20 14:56:31", "link": "http://arxiv.org/abs/2505.14459v1", "categories": ["cs.LG", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Explaining Neural Networks with Reasons", "abstract": "We propose a new interpretability method for neural networks, which is based\non a novel mathematico-philosophical theory of reasons. Our method computes a\nvector for each neuron, called its reasons vector. We then can compute how\nstrongly this reasons vector speaks for various propositions, e.g., the\nproposition that the input image depicts digit 2 or that the input prompt has a\nnegative sentiment. This yields an interpretation of neurons, and groups\nthereof, that combines a logical and a Bayesian perspective, and accounts for\npolysemanticity (i.e., that a single neuron can figure in multiple concepts).\nWe show, both theoretically and empirically, that this method is: (1) grounded\nin a philosophically established notion of explanation, (2) uniform, i.e.,\napplies to the common neural network architectures and modalities, (3)\nscalable, since computing reason vectors only involves forward-passes in the\nneural network, (4) faithful, i.e., intervening on a neuron based on its reason\nvector leads to expected changes in model output, (5) correct in that the\nmodel's reasons structure matches that of the data source, (6) trainable, i.e.,\nneural networks can be trained to improve their reason strengths, (7) useful,\ni.e., it delivers on the needs for interpretability by increasing, e.g.,\nrobustness and fairness.", "published": "2025-05-20 14:32:03", "link": "http://arxiv.org/abs/2505.14424v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A system identification approach to clustering vector autoregressive time series", "abstract": "Clustering of time series based on their underlying dynamics is keeping\nattracting researchers due to its impacts on assisting complex system\nmodelling. Most current time series clustering methods handle only scalar time\nseries, treat them as white noise, or rely on domain knowledge for high-quality\nfeature construction, where the autocorrelation pattern/feature is mostly\nignored. Instead of relying on heuristic feature/metric construction, the\nsystem identification approach allows treating vector time series clustering by\nexplicitly considering their underlying autoregressive dynamics. We first\nderive a clustering algorithm based on a mixture autoregressive model.\nUnfortunately it turns out to have significant computational problems. We then\nderive a `small-noise' limiting version of the algorithm, which we call k-LMVAR\n(Limiting Mixture Vector AutoRegression), that is computationally manageable.\nWe develop an associated BIC criterion for choosing the number of clusters and\nmodel order. The algorithm performs very well in comparative simulations and\nalso scales well computationally.", "published": "2025-05-20 14:31:44", "link": "http://arxiv.org/abs/2505.14421v1", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "stat.ML"}
{"title": "Towards Non-Euclidean Foundation Models: Advancing AI Beyond Euclidean Frameworks", "abstract": "In the era of foundation models and Large Language Models (LLMs), Euclidean\nspace is the de facto geometric setting of our machine learning architectures.\nHowever, recent literature has demonstrated that this choice comes with\nfundamental limitations. To that end, non-Euclidean learning is quickly gaining\ntraction, particularly in web-related applications where complex relationships\nand structures are prevalent. Non-Euclidean spaces, such as hyperbolic,\nspherical, and mixed-curvature spaces, have been shown to provide more\nefficient and effective representations for data with intrinsic geometric\nproperties, including web-related data like social network topology,\nquery-document relationships, and user-item interactions. Integrating\nfoundation models with non-Euclidean geometries has great potential to enhance\ntheir ability to capture and model the underlying structures, leading to better\nperformance in search, recommendations, and content understanding. This\nworkshop focuses on the intersection of Non-Euclidean Foundation Models and\nGeometric Learning (NEGEL), exploring its potential benefits, including the\npotential benefits for advancing web-related technologies, challenges, and\nfuture directions. Workshop page:\n[https://hyperboliclearning.github.io/events/www2025workshop](https://hyperboliclearning.github.io/events/www2025workshop)", "published": "2025-05-20 14:28:59", "link": "http://arxiv.org/abs/2505.14417v1", "categories": ["cs.CG", "cs.LG"], "primary_category": "cs.CG"}
{"title": "Table Foundation Models: on knowledge pre-training for tabular learning", "abstract": "Table foundation models bring high hopes to data science: pre-trained on\ntabular data to embark knowledge or priors, they should facilitate downstream\ntasks on tables. One specific challenge is that of data semantics: numerical\nentries take their meaning from context, e.g., column name. Pre-trained neural\nnetworks that jointly model column names and table entries have recently\nboosted prediction accuracy. While these models outline the promises of world\nknowledge to interpret table values, they lack the convenience of popular\nfoundation models in text or vision. Indeed, they must be fine-tuned to bring\nbenefits, come with sizeable computation costs, and cannot easily be reused or\ncombined with other architectures. Here we introduce TARTE, a foundation model\nthat transforms tables to knowledge-enhanced vector representations using the\nstring to capture semantics. Pre-trained on large relational data, TARTE yields\nrepresentations that facilitate subsequent learning with little additional\ncost. These representations can be fine-tuned or combined with other learners,\ngiving models that push the state-of-the-art prediction performance and improve\nthe prediction/computation performance trade-off. Specialized to a task or a\ndomain, TARTE gives domain-specific representations that facilitate further\nlearning. Our study demonstrates an effective approach to knowledge\npre-training for tabular learning.", "published": "2025-05-20 14:27:51", "link": "http://arxiv.org/abs/2505.14415v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Byte Pair Encoding for Efficient Time Series Forecasting", "abstract": "Existing time series tokenization methods predominantly encode a constant\nnumber of samples into individual tokens. This inflexible approach can generate\nexcessive tokens for even simple patterns like extended constant values,\nresulting in substantial computational overhead. Inspired by the success of\nbyte pair encoding, we propose the first pattern-centric tokenization scheme\nfor time series analysis. Based on a discrete vocabulary of frequent motifs,\nour method merges samples with underlying patterns into tokens, compressing\ntime series adaptively. Exploiting our finite set of motifs and the continuous\nproperties of time series, we further introduce conditional decoding as a\nlightweight yet powerful post-hoc optimization method, which requires no\ngradient computation and adds no computational overhead. On recent time series\nfoundation models, our motif-based tokenization improves forecasting\nperformance by 36% and boosts efficiency by 1990% on average. Conditional\ndecoding further reduces MSE by up to 44%. In an extensive analysis, we\ndemonstrate the adaptiveness of our tokenization to diverse temporal patterns,\nits generalization to unseen data, and its meaningful token representations\ncapturing distinct time series properties, including statistical moments and\ntrends.", "published": "2025-05-20 14:24:49", "link": "http://arxiv.org/abs/2505.14411v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Explaining Unreliable Perception in Automated Driving: A Fuzzy-based Monitoring Approach", "abstract": "Autonomous systems that rely on Machine Learning (ML) utilize online fault\ntolerance mechanisms, such as runtime monitors, to detect ML prediction errors\nand maintain safety during operation. However, the lack of human-interpretable\nexplanations for these errors can hinder the creation of strong assurances\nabout the system's safety and reliability. This paper introduces a novel\nfuzzy-based monitor tailored for ML perception components. It provides\nhuman-interpretable explanations about how different operating conditions\naffect the reliability of perception components and also functions as a runtime\nsafety monitor. We evaluated our proposed monitor using naturalistic driving\ndatasets as part of an automated driving case study. The interpretability of\nthe monitor was evaluated and we identified a set of operating conditions in\nwhich the perception component performs reliably. Additionally, we created an\nassurance case that links unit-level evidence of \\textit{correct} ML operation\nto system-level \\textit{safety}. The benchmarking demonstrated that our monitor\nachieved a better increase in safety (i.e., absence of hazardous situations)\nwhile maintaining availability (i.e., ability to perform the mission) compared\nto state-of-the-art runtime ML monitors in the evaluated dataset.", "published": "2025-05-20 14:22:39", "link": "http://arxiv.org/abs/2505.14407v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Algorithmic Hiring and Diversity: Reducing Human-Algorithm Similarity for Better Outcomes", "abstract": "Algorithmic tools are increasingly used in hiring to improve fairness and\ndiversity, often by enforcing constraints such as gender-balanced candidate\nshortlists. However, we show theoretically and empirically that enforcing equal\nrepresentation at the shortlist stage does not necessarily translate into more\ndiverse final hires, even when there is no gender bias in the hiring stage. We\nidentify a crucial factor influencing this outcome: the correlation between the\nalgorithm's screening criteria and the human hiring manager's evaluation\ncriteria -- higher correlation leads to lower diversity in final hires. Using a\nlarge-scale empirical analysis of nearly 800,000 job applications across\nmultiple technology firms, we find that enforcing equal shortlists yields\nlimited improvements in hire diversity when the algorithmic screening closely\nmirrors the hiring manager's preferences. We propose a complementary\nalgorithmic approach designed explicitly to diversify shortlists by selecting\ncandidates likely to be overlooked by managers, yet still competitive according\nto their evaluation criteria. Empirical simulations show that this approach\nsignificantly enhances gender diversity in final hires without substantially\ncompromising hire quality. These findings highlight the importance of\nalgorithmic design choices in achieving organizational diversity goals and\nprovide actionable guidance for practitioners implementing fairness-oriented\nhiring algorithms.", "published": "2025-05-20 14:09:43", "link": "http://arxiv.org/abs/2505.14388v1", "categories": ["cs.LG", "cs.HC", "econ.GN", "q-fin.EC"], "primary_category": "cs.LG"}
{"title": "Layer-wise Quantization for Quantized Optimistic Dual Averaging", "abstract": "Modern deep neural networks exhibit heterogeneity across numerous layers of\nvarious types such as residuals, multi-head attention, etc., due to varying\nstructures (dimensions, activation functions, etc.), distinct representation\ncharacteristics, which impact predictions. We develop a general layer-wise\nquantization framework with tight variance and code-length bounds, adapting to\nthe heterogeneities over the course of training. We then apply a new layer-wise\nquantization technique within distributed variational inequalities (VIs),\nproposing a novel Quantized Optimistic Dual Averaging (QODA) algorithm with\nadaptive learning rates, which achieves competitive convergence rates for\nmonotone VIs. We empirically show that QODA achieves up to a $150\\%$ speedup\nover the baselines in end-to-end training time for training Wasserstein GAN on\n$12+$ GPUs.", "published": "2025-05-20 13:53:58", "link": "http://arxiv.org/abs/2505.14371v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Towards eliciting latent knowledge from LLMs with mechanistic interpretability", "abstract": "As language models become more powerful and sophisticated, it is crucial that\nthey remain trustworthy and reliable. There is concerning preliminary evidence\nthat models may attempt to deceive or keep secrets from their operators. To\nexplore the ability of current techniques to elicit such hidden knowledge, we\ntrain a Taboo model: a language model that describes a specific secret word\nwithout explicitly stating it. Importantly, the secret word is not presented to\nthe model in its training data or prompt. We then investigate methods to\nuncover this secret. First, we evaluate non-interpretability (black-box)\napproaches. Subsequently, we develop largely automated strategies based on\nmechanistic interpretability techniques, including logit lens and sparse\nautoencoders. Evaluation shows that both approaches are effective in eliciting\nthe secret word in our proof-of-concept setting. Our findings highlight the\npromise of these approaches for eliciting hidden knowledge and suggest several\npromising avenues for future work, including testing and refining these methods\non more complex model organisms. This work aims to be a step towards addressing\nthe crucial problem of eliciting secret knowledge from language models, thereby\ncontributing to their safe and reliable deployment.", "published": "2025-05-20 13:36:37", "link": "http://arxiv.org/abs/2505.14352v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Vulnerability of Transfer-Learned Neural Networks to Data Reconstruction Attacks in Small-Data Regime", "abstract": "Training data reconstruction attacks enable adversaries to recover portions\nof a released model's training data. We consider the attacks where a\nreconstructor neural network learns to invert the (random) mapping between\ntraining data and model weights. Prior work has shown that an informed\nadversary with access to released model's weights and all but one training data\npoint can achieve high-quality reconstructions in this way. However,\ndifferential privacy can defend against such an attack with little to no loss\nin model's utility when the amount of training data is sufficiently large. In\nthis work we consider a more realistic adversary who only knows the\ndistribution from which a small training dataset has been sampled and who\nattacks a transfer-learned neural network classifier that has been trained on\nthis dataset. We exhibit an attack that works in this realistic threat model\nand demonstrate that in the small-data regime it cannot be defended against by\nDP-SGD without severely damaging the classifier accuracy. This raises\nsignificant concerns about the use of such transfer-learned classifiers when\nprotection of training-data is paramount. We demonstrate the effectiveness and\nrobustness of our attack on VGG, EfficientNet and ResNet image classifiers\ntransfer-learned on MNIST, CIFAR-10 and CelebA respectively. Additionally, we\npoint out that the commonly used (true-positive) reconstruction success rate\nmetric fails to reliably quantify the actual reconstruction effectiveness.\nInstead, we make use of the Neyman-Pearson lemma to construct the receiver\noperating characteristic curve and consider the associated true-positive\nreconstruction rate at a fixed level of the false-positive reconstruction rate.", "published": "2025-05-20 13:09:22", "link": "http://arxiv.org/abs/2505.14323v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Low-Cost FlashAttention with Fused Exponential and Multiplication Hardware Operators", "abstract": "Attention mechanisms, particularly within Transformer architectures and large\nlanguage models (LLMs), have revolutionized sequence modeling in machine\nlearning and artificial intelligence applications. To compute attention for\nincreasingly long sequences, specialized accelerators have been proposed to\nexecute key attention steps directly in hardware. Among the various recently\nproposed architectures, those based on variants of the FlashAttention\nalgorithm, originally designed for GPUs, stand out due to their optimized\ncomputation, tiling capabilities, and reduced memory traffic. In this work, we\nfocus on optimizing the kernel of floating-point-based FlashAttention using new\nhardware operators that fuse the computation of exponentials and vector\nmultiplications, e.g., e^x, V. The proposed ExpMul hardware operators\nsignificantly reduce the area and power costs of FlashAttention-based hardware\naccelerators. When implemented in a 28nm ASIC technology, they achieve\nimprovements of 28.8% in area and 17.6% in power, on average, compared to\nstate-of-the-art hardware architectures with separate exponentials and vector\nmultiplications hardware operators.", "published": "2025-05-20 13:00:59", "link": "http://arxiv.org/abs/2505.14314v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Optimizing Binary and Ternary Neural Network Inference on RRAM Crossbars using CIM-Explorer", "abstract": "Using Resistive Random Access Memory (RRAM) crossbars in Computing-in-Memory\n(CIM) architectures offers a promising solution to overcome the von Neumann\nbottleneck. Due to non-idealities like cell variability, RRAM crossbars are\noften operated in binary mode, utilizing only two states: Low Resistive State\n(LRS) and High Resistive State (HRS). Binary Neural Networks (BNNs) and Ternary\nNeural Networks (TNNs) are well-suited for this hardware due to their efficient\nmapping. Existing software projects for RRAM-based CIM typically focus on only\none aspect: compilation, simulation, or Design Space Exploration (DSE).\nMoreover, they often rely on classical 8 bit quantization. To address these\nlimitations, we introduce CIM-Explorer, a modular toolkit for optimizing BNN\nand TNN inference on RRAM crossbars. CIM-Explorer includes an end-to-end\ncompiler stack, multiple mapping options, and simulators, enabling a DSE flow\nfor accuracy estimation across different crossbar parameters and mappings.\nCIM-Explorer can accompany the entire design process, from early accuracy\nestimation for specific crossbar parameters, to selecting an appropriate\nmapping, and compiling BNNs and TNNs for a finalized crossbar chip. In DSE case\nstudies, we demonstrate the expected accuracy for various mappings and crossbar\nparameters. CIM-Explorer can be found on GitHub.", "published": "2025-05-20 12:54:48", "link": "http://arxiv.org/abs/2505.14303v1", "categories": ["cs.ET", "cs.LG"], "primary_category": "cs.ET"}
{"title": "A Private Approximation of the 2nd-Moment Matrix of Any Subsamplable Input", "abstract": "We study the problem of differentially private second moment estimation and\npresent a new algorithm that achieve strong privacy-utility trade-offs even for\nworst-case inputs under subsamplability assumptions on the data. We call an\ninput $(m,\\alpha,\\beta)$-subsamplable if a random subsample of size $m$ (or\nlarger) preserves w.p $\\geq 1-\\beta$ the spectral structure of the original\nsecond moment matrix up to a multiplicative factor of $1\\pm \\alpha$. Building\nupon subsamplability, we give a recursive algorithmic framework similar to\nKamath et al 2019, that abides zero-Concentrated Differential Privacy (zCDP)\nwhile preserving w.h.p. the accuracy of the second moment estimation upto an\narbitrary factor of $(1\\pm\\gamma)$. We then show how to apply our algorithm to\napproximate the second moment matrix of a distribution $\\mathcal{D}$, even when\na noticeable fraction of the input are outliers.", "published": "2025-05-20 12:04:29", "link": "http://arxiv.org/abs/2505.14251v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Path-integral molecular dynamics with actively-trained and universal machine learning force fields", "abstract": "Accounting for nuclear quantum effects (NQEs) can significantly alter\nmaterial properties at finite temperatures. Atomic modeling using the\npath-integral molecular dynamics (PIMD) method can fully account for such\neffects, but requires computationally efficient and accurate models of\ninteratomic interactions. Empirical potentials are fast but may lack sufficient\naccuracy, whereas quantum-mechanical calculations are highly accurate but\ncomputationally expensive. Machine-learned interatomic potentials offer a\nsolution to this challenge, providing near-quantum-mechanical accuracy while\nmaintaining high computational efficiency compared to density functional theory\n(DFT) calculations. In this context, an interface was developed to integrate\nmoment tensor potentials (MTPs) from the MLIP-2 software package into PIMD\ncalculations using the i-PI software package. This interface was then applied\nto active learning of potentials and to investigate the influence of NQEs on\nmaterial properties, namely the temperature dependence of lattice parameters\nand thermal expansion coefficients, as well as radial distribution functions,\nfor lithium hydride (LiH) and silicon (Si) systems. The results were compared\nwith experimental data, quasi-harmonic approximation calculations, and\npredictions from the universal machine learning force field MatterSim. These\ncomparisons demonstrated the high accuracy and effectiveness of the MTP-PIMD\napproach.", "published": "2025-05-20 11:55:22", "link": "http://arxiv.org/abs/2505.14245v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Learning with Local Search MCMC Layers", "abstract": "Integrating combinatorial optimization layers into neural networks has\nrecently attracted significant research interest. However, many existing\napproaches lack theoretical guarantees or fail to perform adequately when\nrelying on inexact solvers. This is a critical limitation, as many operations\nresearch problems are NP-hard, often necessitating the use of\nneighborhood-based local search heuristics. These heuristics iteratively\ngenerate and evaluate candidate solutions based on an acceptance rule. In this\npaper, we introduce a theoretically-principled approach for learning with such\ninexact combinatorial solvers. Inspired by the connection between simulated\nannealing and Metropolis-Hastings, we propose to transform problem-specific\nneighborhood systems used in local search heuristics into proposal\ndistributions, implementing MCMC on the combinatorial space of feasible\nsolutions. This allows us to construct differentiable combinatorial layers and\nassociated loss functions. Replacing an exact solver by a local search strongly\nreduces the computational burden of learning on many applications. We\ndemonstrate our approach on a large-scale dynamic vehicle routing problem with\ntime windows.", "published": "2025-05-20 11:47:42", "link": "http://arxiv.org/abs/2505.14240v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Regularized least squares learning with heavy-tailed noise is minimax optimal", "abstract": "This paper examines the performance of ridge regression in reproducing kernel\nHilbert spaces in the presence of noise that exhibits a finite number of higher\nmoments. We establish excess risk bounds consisting of subgaussian and\npolynomial terms based on the well known integral operator framework. The\ndominant subgaussian component allows to achieve convergence rates that have\npreviously only been derived under subexponential noise - a prevalent\nassumption in related work from the last two decades. These rates are optimal\nunder standard eigenvalue decay conditions, demonstrating the asymptotic\nrobustness of regularized least squares against heavy-tailed noise. Our\nderivations are based on a Fuk-Nagaev inequality for Hilbert-space valued\nrandom variables.", "published": "2025-05-20 11:17:54", "link": "http://arxiv.org/abs/2505.14214v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "62G08 (Primary) 62G35, 62J07 (Secondary)"], "primary_category": "cs.LG"}
{"title": "A PID-Controlled Tensor Wheel Decomposition Model for Dynamic Link Prediction", "abstract": "Link prediction in dynamic networks remains a fundamental challenge in\nnetwork science, requiring the inference of potential interactions and their\nevolving strengths through spatiotemporal pattern analysis. Traditional static\nnetwork methods have inherent limitations in capturing temporal dependencies\nand weight dynamics, while tensor-based methods offer a promising paradigm by\nencoding dynamic networks into high-order tensors to explicitly model\nmultidimensional interactions across nodes and time. Among them, tensor wheel\ndecomposition (TWD) stands out for its innovative topological structure, which\ndecomposes high-order tensors into cyclic factors and core tensors to maintain\nstructural integrity. To improve the prediction accuracy, this study introduces\na PID-controlled tensor wheel decomposition (PTWD) model, which mainly adopts\nthe following two ideas: 1) exploiting the representation power of TWD to\ncapture the latent features of dynamic network topology and weight evolution,\nand 2) integrating the proportional-integral-derivative (PID) control principle\ninto the optimization process to obtain a stable model parameter learning\nscheme. The performance on four real datasets verifies that the proposed PTWD\nmodel has more accurate link prediction capabilities compared to other models.", "published": "2025-05-20 11:14:30", "link": "http://arxiv.org/abs/2505.14211v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MSDformer: Multi-scale Discrete Transformer For Time Series Generation", "abstract": "Discrete Token Modeling (DTM), which employs vector quantization techniques,\nhas demonstrated remarkable success in modeling non-natural language\nmodalities, particularly in time series generation. While our prior work\nSDformer established the first DTM-based framework to achieve state-of-the-art\nperformance in this domain, two critical limitations persist in existing DTM\napproaches: 1) their inability to capture multi-scale temporal patterns\ninherent to complex time series data, and 2) the absence of theoretical\nfoundations to guide model optimization. To address these challenges, we\nproposes a novel multi-scale DTM-based time series generation method, called\nMulti-Scale Discrete Transformer (MSDformer). MSDformer employs a multi-scale\ntime series tokenizer to learn discrete token representations at multiple\nscales, which jointly characterize the complex nature of time series data.\nSubsequently, MSDformer applies a multi-scale autoregressive token modeling\ntechnique to capture the multi-scale patterns of time series within the\ndiscrete latent space. Theoretically, we validate the effectiveness of the DTM\nmethod and the rationality of MSDformer through the rate-distortion theorem.\nComprehensive experiments demonstrate that MSDformer significantly outperforms\nstate-of-the-art methods. Both theoretical analysis and experimental results\ndemonstrate that incorporating multi-scale information and modeling multi-scale\npatterns can substantially enhance the quality of generated time series in\nDTM-based approaches. The code will be released upon acceptance.", "published": "2025-05-20 11:01:36", "link": "http://arxiv.org/abs/2505.14202v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "QSVM-QNN: Quantum Support Vector Machine Based Quantum Neural Network Learning Algorithm for Brain-Computer Interfacing Systems", "abstract": "A brain-computer interface (BCI) system enables direct communication between\nthe brain and external devices, offering significant potential for assistive\ntechnologies and advanced human-computer interaction. Despite progress, BCI\nsystems face persistent challenges, including signal variability,\nclassification inefficiency, and difficulty adapting to individual users in\nreal time. In this study, we propose a novel hybrid quantum learning model,\ntermed QSVM-QNN, which integrates a Quantum Support Vector Machine (QSVM) with\na Quantum Neural Network (QNN), to improve classification accuracy and\nrobustness in EEG-based BCI tasks. Unlike existing models, QSVM-QNN combines\nthe decision boundary capabilities of QSVM with the expressive learning power\nof QNN, leading to superior generalization performance. The proposed model is\nevaluated on two benchmark EEG datasets, achieving high accuracies of 0.990 and\n0.950, outperforming both classical and standalone quantum models. To\ndemonstrate real-world viability, we further validated the robustness of QNN,\nQSVM, and QSVM-QNN against six realistic quantum noise models, including bit\nflip and phase damping. These experiments reveal that QSVM-QNN maintains stable\nperformance under noisy conditions, establishing its applicability for\ndeployment in practical, noisy quantum environments. Beyond BCI, the proposed\nhybrid quantum architecture is generalizable to other biomedical and\ntime-series classification tasks, offering a scalable and noise-resilient\nsolution for next-generation neurotechnological systems.", "published": "2025-05-20 10:48:44", "link": "http://arxiv.org/abs/2505.14192v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Empowering LLMs in Task-Oriented Dialogues: A Domain-Independent Multi-Agent Framework and Fine-Tuning Strategy", "abstract": "Task-oriented dialogue systems based on Large Language Models (LLMs) have\ngained increasing attention across various industries and achieved significant\nresults. Current approaches condense complex procedural workflows into a single\nagent to achieve satisfactory performance on large-scale LLMs. However, these\napproaches face challenges to achieve comparable performance on fine-tuned\nlightweight LLMs, due to their limited capabilities in handling multiple\ncomplex logic. In this work, we design a Domain-Independent Multi-Agent\nFramework (DIMF), which contains Intent Classification Agent, Slot Filling\nAgent and Response Agent. This approach simplifies the learning complexity and\nenhances the generalization ability by separating the tasks into\ndomain-independent components. In this framework, we enhance the capabilities\nin contextual understanding using the Direct Preference Optimisation (DPO)\nmethod, and propose a simple and effective Data Distribution Adaptation (DDA)\nmethod to mitigate degradation issues during DPO training. Experiments\nconducted on the MultiWOZ datasets show that our proposed method achieves a\nbetter average performance among all the baselines. Extensive analysis also\ndemonstrates that our proposed framework exhibits excellent generalizability\nand zero-shot capability.", "published": "2025-05-20 12:47:43", "link": "http://arxiv.org/abs/2505.14299v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "MAS-KCL: Knowledge component graph structure learning with large language model-based agentic workflow", "abstract": "Knowledge components (KCs) are the fundamental units of knowledge in the\nfield of education. A KC graph illustrates the relationships and dependencies\nbetween KCs. An accurate KC graph can assist educators in identifying the root\ncauses of learners' poor performance on specific KCs, thereby enabling targeted\ninstructional interventions. To achieve this, we have developed a KC graph\nstructure learning algorithm, named MAS-KCL, which employs a multi-agent system\ndriven by large language models for adaptive modification and optimization of\nthe KC graph. Additionally, a bidirectional feedback mechanism is integrated\ninto the algorithm, where AI agents leverage this mechanism to assess the value\nof edges within the KC graph and adjust the distribution of generation\nprobabilities for different edges, thereby accelerating the efficiency of\nstructure learning. We applied the proposed algorithm to 5 synthetic datasets\nand 4 real-world educational datasets, and experimental results validate its\neffectiveness in learning path recognition. By accurately identifying learners'\nlearning paths, teachers are able to design more comprehensive learning plans,\nenabling learners to achieve their educational goals more effectively, thus\npromoting the sustainable development of education.", "published": "2025-05-20 09:32:47", "link": "http://arxiv.org/abs/2505.14126v1", "categories": ["cs.LG", "cs.CY", "cs.HC", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Personalized and Resilient Distributed Learning Through Opinion Dynamics", "abstract": "In this paper, we address two practical challenges of distributed learning in\nmulti-agent network systems, namely personalization and resilience.\nPersonalization is the need of heterogeneous agents to learn local models\ntailored to their own data and tasks, while still generalizing well; on the\nother hand, the learning process must be resilient to cyberattacks or anomalous\ntraining data to avoid disruption. Motivated by a conceptual affinity between\nthese two requirements, we devise a distributed learning algorithm that\ncombines distributed gradient descent and the Friedkin-Johnsen model of opinion\ndynamics to fulfill both of them. We quantify its convergence speed and the\nneighborhood that contains the final learned models, which can be easily\ncontrolled by tuning the algorithm parameters to enforce a more\npersonalized/resilient behavior. We numerically showcase the effectiveness of\nour algorithm on synthetic and real-world distributed learning tasks, where it\nachieves high global accuracy both for personalized models and with malicious\nagents compared to standard strategies.", "published": "2025-05-20 08:39:16", "link": "http://arxiv.org/abs/2505.14081v1", "categories": ["cs.MA", "cs.LG", "eess.SP", "math.OC"], "primary_category": "cs.MA"}
{"title": "MLZero: A Multi-Agent System for End-to-end Machine Learning Automation", "abstract": "Existing AutoML systems have advanced the automation of machine learning\n(ML); however, they still require substantial manual configuration and expert\ninput, particularly when handling multimodal data. We introduce MLZero, a novel\nmulti-agent framework powered by Large Language Models (LLMs) that enables\nend-to-end ML automation across diverse data modalities with minimal human\nintervention. A cognitive perception module is first employed, transforming raw\nmultimodal inputs into perceptual context that effectively guides the\nsubsequent workflow. To address key limitations of LLMs, such as hallucinated\ncode generation and outdated API knowledge, we enhance the iterative code\ngeneration process with semantic and episodic memory. MLZero demonstrates\nsuperior performance on MLE-Bench Lite, outperforming all competitors in both\nsuccess rate and solution quality, securing six gold medals. Additionally, when\nevaluated on our Multimodal AutoML Agent Benchmark, which includes 25 more\nchallenging tasks spanning diverse data modalities, MLZero outperforms the\ncompeting methods by a large margin with a success rate of 0.92 (+263.6\\%) and\nan average rank of 2.28. Our approach maintains its robust effectiveness even\nwith a compact 8B LLM, outperforming full-size systems from existing solutions.", "published": "2025-05-20 05:20:53", "link": "http://arxiv.org/abs/2505.13941v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Accelerating multigrid with streaming chiral SVD for Wilson fermions in lattice QCD", "abstract": "A modification to the setup algorithm for the multigrid preconditioner of\nWilson fermions in lattice QCD is presented. A larger basis of test vectors\nthan that used in conventional multigrid is calculated by the smoother and\ntruncated by singular value decomposition on the chiral components of the test\nvectors. The truncated basis is used to form the prolongation and restriction\nmatrices of the multigrid hierarchy. This modification of the setup method is\ndemonstrated to increase the convergence of linear solvers on an anisotropic\nlattice with $m_{\\pi} \\approx 239$ MeV from the Hadron Spectrum Collaboration\nand an isotropic lattice with $m_{\\pi} \\approx 220$ MeV from the MILC\nCollaboration. The lattice volume dependence of the method is also examined.\nIncreasing the number of test vectors improves speedup up to a point, but\nstoring these vectors becomes impossible in limited memory resources such as\nGPUs. To address storage cost, we implement a \\emph{streaming} singular value\ndecomposition of the basis of test vectors on the chiral components and\ndemonstrate a decrease in the number of fine level iterations by a factor of\n1.7 for $m_q \\approx m_{crit}$.", "published": "2025-05-20 14:14:42", "link": "http://arxiv.org/abs/2505.14399v1", "categories": ["hep-lat", "cs.NA", "math.NA"], "primary_category": "hep-lat"}
{"title": "Strong convergence in the infinite horizon of numerical methods for stochastic delay differential equations", "abstract": "In this work, we present a general technique for establishing the strong\nconvergence of numerical methods for stochastic delay differential equations\n(SDDEs) in the infinite horizon. This technique can also be extended to analyze\ncertain continuous function-valued segment processes associated with the\nnumerical methods, facilitating the numerical approximation of invariant\nmeasures of SDDEs. To illustrate the application of these results, we\nspecifically investigate the backward and truncated Euler-Maruyama methods.\nSeveral numerical experiments are provided to demonstrate the theoretical\nresults.", "published": "2025-05-20 12:12:39", "link": "http://arxiv.org/abs/2505.14262v1", "categories": ["math.NA", "cs.NA", "60H35, 65C30, 65L20,", "G.1.7; G.3"], "primary_category": "math.NA"}
{"title": "A Numerical Study of Combining RBF Interpolation and Finite Differences to Approximate Differential Operators", "abstract": "This paper focuses on RBF-based meshless methods for approximating\ndifferential operators, one of the most popular being RBF-FD. Recently, a\nhybrid approach was introduced that combines RBF interpolation and traditional\nfinite difference stencils. We compare the accuracy of this method and RBF-FD\non a two-dimensional Poisson problem for standard five-point and nine-point\nstencils and different method parameters.", "published": "2025-05-20 11:41:18", "link": "http://arxiv.org/abs/2505.14232v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Hyperbolic trigonometric functions as approximation kernels and their properties I: generalised Fourier transforms", "abstract": "In this paper a new class of radial basis functions based on hyperbolic\ntrigonometric functions will be introduced and studied. We focus on the\nproperties of their generalised Fourier transforms with asymptotics. Therefore\nwe will compute the expansions of these Fourier transforms with an application\nof the conditions of Strang and Fix in order to prove polynomial exactness of\nquasi-interpolants. These quasi-interpolants will be formed with special linear\ncombinations of shifts of the new radial functions and we will provide explicit\nexpressions for their coefficients. In establishing these new radial basis\nfunctions we will also use other, new classes of shifted thin-plate splines and\nmultiquadrics of [11], [12]. There are numerical examples and comparisons of\ndifferent constructions of quasi-interpolants, in several dimensions, varying\nthe underlying radial basis functions.", "published": "2025-05-20 08:47:52", "link": "http://arxiv.org/abs/2505.14086v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "POLYDIM: A C++ library for POLYtopal DIscretization Methods", "abstract": "This paper introduces PolyDiM, an open-source C++ library tailored for the\ndevelopment and implementation of polytopal discretization methods for partial\ndifferential equations. The library provides robust and modular tools to\nsupport advanced numerical techniques, with a focus on the Virtual Element\nMethod in both 2D and 3D settings. PolyDiM is designed to address a wide range\nof challenging problems, including those involving non-convex geometries,\nDiscrete Fracture Networks, and mixed-dimensional coupling. It is integrated\nwith the geometry library GeDiM, and offers interfaces for MATLAB and Python to\nenhance accessibility. Distinguishing features include support for multiple\npolynomial bases, advanced stabilization strategies, and efficient\nlocal-to-global assembly procedures. PolyDiM aims to serve both as a research\ntool and a foundation for scalable scientific computing in complex geometrical\nsettings.", "published": "2025-05-20 08:08:46", "link": "http://arxiv.org/abs/2505.14063v1", "categories": ["math.NA", "cs.NA", "65M60", "G.1.8; G.1.4; D.3.0"], "primary_category": "math.NA"}
{"title": "Variably Scaled Kernels for the regularized solution of the parametric Fourier imaging problem", "abstract": "We address the problem of approximating parametric Fourier imaging problems\nvia interpolation/ extrapolation algorithms that impose smoothing constraints\nacross contiguous values of the parameter. Previous works already proved that\ninterpolating via Variably Scaled Kernels (VSKs) the scattered observations in\nthe Fourier domain and then defining the sought approximation via the projected\nLandweber iterative scheme, turns out to be effective. This study provides new\ntheoretical insights, including error bounds in the image space and properties\nof the projected Landweber iterative scheme, both influenced by the choice of\nthe scaling function, which characterizes the VSK basis. Such bounds then\nsuggest a smarter solution for the definition of the scaling functions. Indeed,\nby means of VSKs, the information coded in an image reconstructed for a given\nparameter is transferred during the reconstruction process to a contiguous\nparameter value. Benchmark test cases in the field of astronomical imaging,\nnumerically show that the proposed scheme is able to regularize along the\nparameter direction, thus proving reliable and interpretable results.", "published": "2025-05-20 08:04:32", "link": "http://arxiv.org/abs/2505.14060v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Learning High-dimensional Ionic Model Dynamics Using Fourier Neural Operators", "abstract": "Ionic models, described by systems of stiff ordinary differential equations,\nare fundamental tools for simulating the complex dynamics of excitable cells in\nboth Computational Neuroscience and Cardiology. Approximating these models\nusing Artificial Neural Networks poses significant challenges due to their\ninherent stiffness, multiscale nonlinearities, and the wide range of dynamical\nbehaviors they exhibit, including multiple equilibrium points, limit cycles,\nand intricate interactions. While in previous studies the dynamics of the\ntransmembrane potential has been predicted in low dimensionality settings, in\nthe present study we extend these results by investigating whether Fourier\nNeural Operators can effectively learn the evolution of all the state variables\nwithin these dynamical systems in higher dimensions. We demonstrate the\neffectiveness of this approach by accurately learning the dynamics of three\nwell-established ionic models with increasing dimensionality: the two-variable\nFitzHugh-Nagumo model, the four-variable Hodgkin-Huxley model, and the\nforty-one-variable O'Hara-Rudy model. To ensure the selection of near-optimal\nconfigurations for the Fourier Neural Operator, we conducted automatic\nhyperparameter tuning under two scenarios: an unconstrained setting, where the\nnumber of trainable parameters is not limited, and a constrained case with a\nfixed number of trainable parameters. Both constrained and unconstrained\narchitectures achieve comparable results in terms of accuracy across all the\nmodels considered. However, the unconstrained architecture required\napproximately half the number of training epochs to achieve similar error\nlevels, as evidenced by the loss function values recorded during training.\nThese results underline the capabilities of Fourier Neural Operators to\naccurately capture complex multiscale dynamics, even in high-dimensional\ndynamical systems.", "published": "2025-05-20 07:37:03", "link": "http://arxiv.org/abs/2505.14039v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Convergence of the alternating least squares algorithm for CP tensor decompositions", "abstract": "The alternating least squares (ALS/AltLS) method is a widely used algorithm\nfor computing the CP decomposition of a tensor. However, its convergence theory\nis still incompletely understood.\n  In this paper, we prove explicit quantitative local convergence theorems for\nCP-AltLS applied to orthogonally decomposable and incoherently decomposable\ntensors. Specifically, we show that CP-AltLS converges polynomially with order\n$N-1$ for $N$th-order orthogonally decomposable tensors and linearly for\nincoherently decomposable tensors, with convergence being measured in terms of\nthe angles between the factors of the exact tensor and those of the approximate\ntensor. Unlike existing results, our analysis is both quantitative and\nconstructive, applying to standard CP-AltLS and accommodating factor matrices\nwith small but nonzero mutual coherence, while remaining applicable to tensors\nof arbitrary rank.\n  We also confirm these rates of convergence numerically and investigate\naccelerating the convergence of CP-AltLS using an SVD-based coherence reduction\nscheme.", "published": "2025-05-20 07:35:14", "link": "http://arxiv.org/abs/2505.14037v1", "categories": ["math.NA", "cs.NA", "15A69, 65F99, 65F45"], "primary_category": "math.NA"}
{"title": "Partition-wise Graph Filtering: A Unified Perspective Through the Lens of Graph Coarsening", "abstract": "Filtering-based graph neural networks (GNNs) constitute a distinct class of\nGNNs that employ graph filters to handle graph-structured data, achieving\nnotable success in various graph-related tasks. Conventional methods adopt a\ngraph-wise filtering paradigm, imposing a uniform filter across all nodes, yet\nrecent findings suggest that this rigid paradigm struggles with heterophilic\ngraphs. To overcome this, recent works have introduced node-wise filtering,\nwhich assigns distinct filters to individual nodes, offering enhanced\nadaptability. However, a fundamental gap remains: a comprehensive framework\nunifying these two strategies is still absent, limiting theoretical insights\ninto the filtering paradigms. Moreover, through the lens of Contextual\nStochastic Block Model, we reveal that a synthesis of graph-wise and node-wise\nfiltering provides a sufficient solution for classification on graphs\nexhibiting both homophily and heterophily, suggesting the risk of excessive\nparameterization and potential overfitting with node-wise filtering. To address\nthe limitations, this paper introduces Coarsening-guided Partition-wise\nFiltering (CPF). CPF innovates by performing filtering on node partitions. The\nmethod begins with structure-aware partition-wise filtering, which filters node\npartitions obtained via graph coarsening algorithms, and then performs\nfeature-aware partition-wise filtering, refining node embeddings via filtering\non clusters produced by $k$-means clustering over features. In-depth analysis\nis conducted for each phase of CPF, showing its superiority over other\nparadigms. Finally, benchmark node classification experiments, along with a\nreal-world graph anomaly detection application, validate CPF's efficacy and\npractical utility.", "published": "2025-05-20 07:30:45", "link": "http://arxiv.org/abs/2505.14033v1", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "primary_category": "cs.LG"}
{"title": "Convergence Guarantees for Gradient-Based Training of Neural PDE Solvers: From Linear to Nonlinear PDEs", "abstract": "We present a unified convergence theory for gradient-based training of neural\nnetwork methods for partial differential equations (PDEs), covering both\nphysics-informed neural networks (PINNs) and the Deep Ritz method. For linear\nPDEs, we extend the neural tangent kernel (NTK) framework for PINNs to\nestablish global convergence guarantees for a broad class of linear operators.\nFor nonlinear PDEs, we prove convergence to critical points via the\n\\L{}ojasiewicz inequality under the random feature model, eliminating the need\nfor strong over-parameterization and encompassing both gradient flow and\nimplicit gradient descent dynamics. Our results further reveal that the random\nfeature model exhibits an implicit regularization effect, preventing parameter\ndivergence to infinity. Theoretical findings are corroborated by numerical\nexperiments, providing new insights into the training dynamics and robustness\nof neural network PDE solvers.", "published": "2025-05-20 06:55:41", "link": "http://arxiv.org/abs/2505.14002v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Two families of C1-Pk Fraeijs de Veubeke-Sander finite elements on quadrilateral meshes", "abstract": "We extend the $C^1$-$P_3$ Fraeijs de Veubeke-Sander finite element to\n  two families of $C^1$-$P_k$ ($k>3$) macro finite elements on\n  general quadrilateral meshes. On each quadrilateral, four $P_k$ polynomials\nare defined on\n  the four triangles subdivided from the quadrilateral by\n  its two diagonal lines. The first family of $C^1$-$P_k$ finite elements is\nthe full $C^1$-$P_k$\n  space on the macro-mesh. Thus the element can be applied to interface\nproblems. The second family of $C^1$-$P_k$ finite elements condenses\n  all internal degrees of freedom by moving them to the four edges. Thus the\nsecond element method has much less unknowns but is\n  more accurate than the first one. We prove the uni-solvency and the optimal\norder convergence. Numerical tests and comparisons with the $C^1$-$P_k$ Argyris\nare provided.", "published": "2025-05-20 06:07:04", "link": "http://arxiv.org/abs/2505.13968v1", "categories": ["math.NA", "cs.NA", "65N15, 65N30"], "primary_category": "math.NA"}
{"title": "Numerical analysis for the regularised total variation flow", "abstract": "We perform the numerical analysis of the regularised total variation flow\nusing the gradient discretisation method (GDM). GDM is a unified convergence\nanalysis framework that covers conforming and non-conforming numerical methods,\nfor instance, conforming and non-conforming finite element, two-point flux\napproximation, etc.. In this paper, a fully discretised implicit scheme of the\nmodel is proposed, the existence and uniqueness of the solution to the scheme\nis proved, the stability and consistency of the scheme are analysed, and error\nestimates are established.", "published": "2025-05-20 04:49:33", "link": "http://arxiv.org/abs/2505.13929v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Stabilized velocity post-processings for Darcy flow in heterogeneous porous media", "abstract": "Stable and accurate finite element methods are presented for Darcy flow in\nheterogeneous porous media with an interface of discontinuity of the hydraulic\nconductivity tensor. Accurate velocity fields are computed through global or\nlocal post-processing formulations that use previous approximations of the\nhydraulic potential. Stability is provided by combining Galerkin and Least\nSquares (GLS) residuals of the governing equations with an additional\nstabilization on the interface that incorporates the discontinuity on the\ntangential component of the velocity field in a strong sense. Numerical\nanalysis is outlined and numerical results are presented to illustrate the good\nperformance of the proposed methods. Convergence studies for a heterogeneous\nand anisotropic porous medium confirm the same orders of convergence predicted\nfor homogeneous problem with smooth solutions, for both global and local\npost-processings.", "published": "2025-05-20 04:39:39", "link": "http://arxiv.org/abs/2505.13924v1", "categories": ["math.NA", "cs.NA", "65N12, 65N22, 65N30, 35A35"], "primary_category": "math.NA"}
{"title": "Dimension-independent convergence rates of randomized nets using median-of-means", "abstract": "Recent advances in quasi-Monte Carlo integration demonstrate that the median\nof linearly scrambled digital net estimators achieves near-optimal convergence\nrates for high-dimensional integrals without requiring a priori knowledge of\nthe integrand's smoothness. Building on this framework, we prove that the\nmedian estimator attains dimension-independent convergence under tractability\nconditions characterized by low effective dimensionality, a property known as\nstrong tractability in complexity theory. Our analysis strengthens existing\nguarantees by improving the convergence rates and relaxing the theoretical\nassumptions previously required for strong tractability.", "published": "2025-05-20 01:52:35", "link": "http://arxiv.org/abs/2505.13815v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Quantum Reservoir Computing for Realized Volatility Forecasting", "abstract": "Recent advances in quantum computing have demonstrated its potential to\nsignificantly enhance the analysis and forecasting of complex classical data.\nAmong these, quantum reservoir computing has emerged as a particularly powerful\napproach, combining quantum computation with machine learning for modeling\nnonlinear temporal dependencies in high-dimensional time series. As with many\ndata-driven disciplines, quantitative finance and econometrics can hugely\nbenefit from emerging quantum technologies. In this work, we investigate the\napplication of quantum reservoir computing for realized volatility forecasting.\nOur model employs a fully connected transverse-field Ising Hamiltonian as the\nreservoir with distinct input and memory qubits to capture temporal\ndependencies. The quantum reservoir computing approach is benchmarked against\nseveral econometric models and standard machine learning algorithms. The models\nare evaluated using multiple error metrics and the model confidence set\nprocedures. To enhance interpretability and mitigate current quantum hardware\nlimitations, we utilize wrapper-based forward selection for feature selection,\nidentifying optimal subsets, and quantifying feature importance via Shapley\nvalues. Our results indicate that the proposed quantum reservoir approach\nconsistently outperforms benchmark models across various metrics, highlighting\nits potential for financial forecasting despite existing quantum hardware\nconstraints. This work serves as a proof-of-concept for the applicability of\nquantum computing in econometrics and financial analysis, paving the way for\nfurther research into quantum-enhanced predictive modeling as quantum hardware\ncapabilities continue to advance.", "published": "2025-05-20 05:02:13", "link": "http://arxiv.org/abs/2505.13933v1", "categories": ["quant-ph", "econ.EM", "q-fin.ST"], "primary_category": "quant-ph"}
{"title": "Inference with correlated priors using sisters cells", "abstract": "A common view of sensory processing is as probabilistic inference of latent\ncauses from receptor activations. Standard approaches often assume these causes\nare a priori independent, yet real-world generative factors are typically\ncorrelated. Representing such structured priors in neural systems poses\narchitectural challenges, particularly when direct interactions between units\nrepresenting latent causes are biologically implausible or computationally\nexpensive. Inspired by the architecture of the olfactory bulb, we propose a\nnovel circuit motif that enables inference with correlated priors without\nrequiring direct interactions among latent cause units. The key insight lies in\nusing sister cells: neurons receiving shared receptor input but connected\ndifferently to local interneurons. The required interactions among latent units\nare implemented indirectly through their connections to the sister cells, such\nthat correlated connectivity implies anti-correlation in the prior and vice\nversa. We use geometric arguments to construct connectivity that implements a\ngiven prior and to bound the number of causes for which such priors can be\nconstructed. Using simulations, we demonstrate the efficacy of such priors for\ninference in noisy environments and compare the inference dynamics to those\nexperimentally observed. Finally, we show how, under certain assumptions on\nlatent representations, the prior used can be inferred from sister cell\nactivations. While biologically grounded in the olfactory system, our mechanism\ngeneralises to other natural and artificial sensory systems and may inform the\ndesign of architectures for efficient inference under correlated latent\nstructure.", "published": "2025-05-20 16:37:46", "link": "http://arxiv.org/abs/2505.14579v1", "categories": ["q-bio.NC", "stat.ML"], "primary_category": "q-bio.NC"}
{"title": "Mixing times of data-augmentation Gibbs samplers for high-dimensional probit regression", "abstract": "We investigate the convergence properties of popular data-augmentation\nsamplers for Bayesian probit regression. Leveraging recent results on Gibbs\nsamplers for log-concave targets, we provide simple and explicit non-asymptotic\nbounds on the associated mixing times (in Kullback-Leibler divergence). The\nbounds depend explicitly on the design matrix and the prior precision, while\nthey hold uniformly over the vector of responses. We specialize the results for\ndifferent regimes of statistical interest, when both the number of data points\n$n$ and parameters $p$ are large: in particular we identify scenarios where the\nmixing times remain bounded as $n,p\\to\\infty$, and ones where they do not. The\nresults are shown to be tight (in the worst case with respect to the responses)\nand provide guidance on choices of prior distributions that provably lead to\nfast mixing. An empirical analysis based on coupling techniques suggests that\nthe bounds are effective in predicting practically observed behaviours.", "published": "2025-05-20 13:29:01", "link": "http://arxiv.org/abs/2505.14343v1", "categories": ["stat.CO", "stat.ME", "stat.ML"], "primary_category": "stat.CO"}
{"title": "The Post Double LASSO for Efficiency Analysis", "abstract": "Big data and machine learning methods have become commonplace across economic\nmilieus. One area that has not seen as much attention to these important topics\nyet is efficiency analysis. We show how the availability of big (wide) data can\nactually make detection of inefficiency more challenging. We then show how\nmachine learning methods can be leveraged to adequately estimate the primitives\nof the frontier itself as well as inefficiency using the `post double LASSO' by\nderiving Neyman orthogonal moment conditions for this problem. Finally, an\napplication is presented to illustrate key differences of the post-double LASSO\ncompared to other approaches.", "published": "2025-05-20 12:32:26", "link": "http://arxiv.org/abs/2505.14282v1", "categories": ["econ.EM", "stat.ML"], "primary_category": "econ.EM"}
{"title": "Hybrid Bernstein Normalizing Flows for Flexible Multivariate Density Regression with Interpretable Marginals", "abstract": "Density regression models allow a comprehensive understanding of data by\nmodeling the complete conditional probability distribution. While flexible\nestimation approaches such as normalizing flows (NF) work particularly well in\nmultiple dimensions, interpreting the input-output relationship of such models\nis often difficult, due to the black-box character of deep learning models. In\ncontrast, existing statistical methods for multivariate outcomes such as\nmultivariate conditional transformation models (MCTM) are restricted in\nflexibility and are often not expressive enough to represent complex\nmultivariate probability distributions. In this paper, we combine MCTM with\nstate-of-the-art and autoregressive NF to leverage the transparency of MCTM for\nmodeling interpretable feature effects on the marginal distributions in the\nfirst step and the flexibility of neural-network-based NF techniques to account\nfor complex and non-linear relationships in the joint data distribution. We\ndemonstrate our method's versatility in various numerical experiments and\ncompare it with MCTM and other NF models on both simulated and real-world data.", "published": "2025-05-20 10:17:07", "link": "http://arxiv.org/abs/2505.14164v1", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME"], "primary_category": "stat.ML"}
{"title": "High-dimensional Nonparametric Contextual Bandit Problem", "abstract": "We consider the kernelized contextual bandit problem with a large feature\nspace. This problem involves $K$ arms, and the goal of the forecaster is to\nmaximize the cumulative rewards through learning the relationship between the\ncontexts and the rewards. It serves as a general framework for various\ndecision-making scenarios, such as personalized online advertising and\nrecommendation systems. Kernelized contextual bandits generalize the linear\ncontextual bandit problem and offers a greater modeling flexibility. Existing\nmethods, when applied to Gaussian kernels, yield a trivial bound of $O(T)$ when\nwe consider $\\Omega(\\log T)$ feature dimensions. To address this, we introduce\nstochastic assumptions on the context distribution and show that no-regret\nlearning is achievable even when the number of dimensions grows up to the\nnumber of samples. Furthermore, we analyze lenient regret, which allows a\nper-round regret of at most $\\Delta > 0$. We derive the rate of lenient regret\nin terms of $\\Delta$.", "published": "2025-05-20 09:10:39", "link": "http://arxiv.org/abs/2505.14102v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Computational Efficiency under Covariate Shift in Kernel Ridge Regression", "abstract": "This paper addresses the covariate shift problem in the context of\nnonparametric regression within reproducing kernel Hilbert spaces (RKHSs).\nCovariate shift arises in supervised learning when the input distributions of\nthe training and test data differ, presenting additional challenges for\nlearning. Although kernel methods have optimal statistical properties, their\nhigh computational demands in terms of time and, particularly, memory, limit\ntheir scalability to large datasets. To address this limitation, the main focus\nof this paper is to explore the trade-off between computational efficiency and\nstatistical accuracy under covariate shift. We investigate the use of random\nprojections where the hypothesis space consists of a random subspace within a\ngiven RKHS. Our results show that, even in the presence of covariate shift,\nsignificant computational savings can be achieved without compromising learning\nperformance.", "published": "2025-05-20 08:41:24", "link": "http://arxiv.org/abs/2505.14083v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "A Probabilistic Perspective on Model Collapse", "abstract": "In recent years, model collapse has become a critical issue in language model\ntraining, making it essential to understand the underlying mechanisms driving\nthis phenomenon. In this paper, we investigate recursive parametric model\ntraining from a probabilistic perspective, aiming to characterize the\nconditions under which model collapse occurs and, crucially, how it can be\nmitigated. We conceptualize the recursive training process as a random walk of\nthe model estimate, highlighting how the sample size influences the step size\nand how the estimation procedure determines the direction and potential bias of\nthe random walk. Under mild conditions, we rigorously show that progressively\nincreasing the sample size at each training step is necessary to prevent model\ncollapse. In particular, when the estimation is unbiased, the required growth\nrate follows a superlinear pattern. This rate needs to be accelerated even\nfurther in the presence of substantial estimation bias. Building on this\nprobabilistic framework, we also investigate the probability that recursive\ntraining on synthetic data yields models that outperform those trained solely\non real data. Moreover, we extend these results to general parametric model\nfamily in an asymptotic regime. Finally, we validate our theoretical results\nthrough extensive simulations and a real-world dataset.", "published": "2025-05-20 05:25:29", "link": "http://arxiv.org/abs/2505.13947v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "An Asymptotic Equation Linking WAIC and WBIC in Singular Models", "abstract": "In statistical learning, models are classified as regular or singular\ndepending on whether the mapping from parameters to probability distributions\nis injective. Most models with hierarchical structures or latent variables are\nsingular, for which conventional criteria such as the Akaike Information\nCriterion and the Bayesian Information Criterion are inapplicable due to the\nbreakdown of normal approximations for the likelihood and posterior. To address\nthis, the Widely Applicable Information Criterion (WAIC) and the Widely\nApplicable Bayesian Information Criterion (WBIC) have been proposed. Since WAIC\nand WBIC are computed using posterior distributions at different temperature\nsettings, separate posterior sampling is generally required. In this paper, we\ntheoretically derive an asymptotic equation that links WAIC and WBIC, despite\ntheir dependence on different posteriors. This equation yields an\nasymptotically unbiased expression of WAIC in terms of the posterior\ndistribution used for WBIC. The result clarifies the structural relationship\nbetween these criteria within the framework of singular learning theory, and\ndeepens understanding of their asymptotic behavior. This theoretical\ncontribution provides a foundation for future developments in the computational\nefficiency of model selection in singular models.", "published": "2025-05-20 04:06:43", "link": "http://arxiv.org/abs/2505.13902v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62F15, 62R01"], "primary_category": "stat.ML"}
{"title": "Characterization of Efficient Influence Function for Off-Policy Evaluation Under Optimal Policies", "abstract": "Off-policy evaluation (OPE) provides a powerful framework for estimating the\nvalue of a counterfactual policy using observational data, without the need for\nadditional experimentation. Despite recent progress in robust and efficient OPE\nacross various settings, rigorous efficiency analysis of OPE under an estimated\noptimal policy remains limited. In this paper, we establish a concise\ncharacterization of the efficient influence function for the value function\nunder optimal policy within canonical Markov decision process models.\nSpecifically, we provide the sufficient conditions for the existence of the\nefficient influence function and characterize its expression. We also give the\nconditions under which the EIF does not exist.", "published": "2025-05-20 01:41:44", "link": "http://arxiv.org/abs/2505.13809v1", "categories": ["math.ST", "econ.EM", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Vox-Profile: A Speech Foundation Model Benchmark for Characterizing Diverse Speaker and Speech Traits", "abstract": "We introduce Vox-Profile, a comprehensive benchmark to characterize rich\nspeaker and speech traits using speech foundation models. Unlike existing works\nthat focus on a single dimension of speaker traits, Vox-Profile provides\nholistic and multi-dimensional profiles that reflect both static speaker traits\n(e.g., age, sex, accent) and dynamic speech properties (e.g., emotion, speech\nflow). This benchmark is grounded in speech science and linguistics, developed\nwith domain experts to accurately index speaker and speech characteristics. We\nreport benchmark experiments using over 15 publicly available speech datasets\nand several widely used speech foundation models that target various static and\ndynamic speaker and speech properties. In addition to benchmark experiments, we\nshowcase several downstream applications supported by Vox-Profile. First, we\nshow that Vox-Profile can augment existing speech recognition datasets to\nanalyze ASR performance variability. Vox-Profile is also used as a tool to\nevaluate the performance of speech generation systems. Finally, we assess the\nquality of our automated profiles through comparison with human evaluation and\nshow convergent validity. Vox-Profile is publicly available at:\nhttps://github.com/tiantiaf0627/vox-profile-release.", "published": "2025-05-20 17:36:41", "link": "http://arxiv.org/abs/2505.14648v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing", "abstract": "As deepfake speech becomes common and hard to detect, it is vital to trace\nits source. Recent work on audio deepfake source tracing (ST) aims to find the\norigins of synthetic or manipulated speech. However, ST models must adapt to\nlearn new deepfake attacks while retaining knowledge of the previous ones. A\nmajor challenge is catastrophic forgetting, where models lose the ability to\nrecognize previously learned attacks. Some continual learning methods help with\ndeepfake detection, but multi-class tasks such as ST introduce additional\nchallenges as the number of classes grows. To address this, we propose an\nanalytic class incremental learning method called AnaST. When new attacks\nappear, the feature extractor remains fixed, and the classifier is updated with\na closed-form analytical solution in one epoch. This approach ensures data\nprivacy, optimizes memory usage, and is suitable for online training. The\nexperiments carried out in this work show that our method outperforms the\nbaselines.", "published": "2025-05-20 16:51:52", "link": "http://arxiv.org/abs/2505.14601v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "AdaKWS: Towards Robust Keyword Spotting with Test-Time Adaptation", "abstract": "Spoken keyword spotting (KWS) aims to identify keywords in audio for wide\napplications, especially on edge devices. Current small-footprint KWS systems\nfocus on efficient model designs. However, their inference performance can\ndecline in unseen environments or noisy backgrounds. Test-time adaptation (TTA)\nhelps models adapt to test samples without needing the original training data.\nIn this study, we present AdaKWS, the first TTA method for robust KWS to the\nbest of our knowledge. Specifically, 1) We initially optimize the model's\nconfidence by selecting reliable samples based on prediction entropy\nminimization and adjusting the normalization statistics in each batch. 2) We\nintroduce pseudo-keyword consistency (PKC) to identify critical, reliable\nfeatures without overfitting to noise. Our experiments show that AdaKWS\noutperforms other methods across various conditions, including Gaussian noise\nand real-scenario noises. The code will be released in due course.", "published": "2025-05-20 16:50:21", "link": "http://arxiv.org/abs/2505.14600v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Representation Learning for Semantic Alignment of Language, Audio, and Visual Modalities", "abstract": "This paper proposes a single-stage training approach that semantically aligns\nthree modalities - audio, visual, and text using a contrastive learning\nframework. Contrastive training has gained prominence for multimodal alignment,\nutilizing large-scale unlabeled data to learn shared representations. Existing\ndeep learning approach for trimodal alignment involves two-stages, that\nseparately align visual-text and audio-text modalities. This approach suffers\nfrom mismatched data distributions, resulting in suboptimal alignment.\nLeveraging the AVCaps dataset, which provides audio, visual and audio-visual\ncaptions for video clips, our method jointly optimizes the representation of\nall the modalities using contrastive training. Our results demonstrate that the\nsingle-stage approach outperforms the two-stage method, achieving a two-fold\nimprovement in audio based visual retrieval, highlighting the advantages of\nunified multimodal representation learning.", "published": "2025-05-20 16:21:27", "link": "http://arxiv.org/abs/2505.14562v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Complexity of frequency fluctuations and the interpretive style in the bass viola da gamba", "abstract": "Audio signals in a set of musical pieces are modeled as a complex network for\nstudying the relationship between the complexity of frequency fluctuations and\nthe interpretive style of the bass viola da gamba. Based on interdisciplinary\nscientific and music approaches, we compute the spectral decomposition and\ntranslated its frequency components to a network of sounds. We applied a best\nfit analysis for identifying the statistical distributions that describe more\nprecisely the behavior of such frequencies and computed the centrality measures\nand identify cliques for characterizing such a network. Findings suggested\nstatistical regularities in the type of statistical distribution that best\ndescribes frequency fluctuations. The centrality measure confirmed the most\ninfluential and stable group of sounds in a piece of music, meanwhile the\nidentification of the largest clique indicated functional groups of sounds that\ninteract closely for identifying the emergence of complex frequency\nfluctuations. Therefore, by modeling the sound as a complex network, we can\nclearly associate the presence of large-scale statistical regularities with the\npresence of similar frequency fluctuations related to different musical events\nplayed by a same musician.", "published": "2025-05-20 14:50:41", "link": "http://arxiv.org/abs/2505.14448v1", "categories": ["cs.SD", "eess.AS", "stat.AP"], "primary_category": "cs.SD"}
{"title": "Single-Channel Target Speech Extraction Utilizing Distance and Room Clues", "abstract": "This paper aims to achieve single-channel target speech extraction (TSE) in\nenclosures utilizing distance clues and room information. Recent works have\nverified the feasibility of distance clues for the TSE task, which can imply\nthe sound source's direct-to-reverberation ratio (DRR) and thus can be utilized\nfor speech separation and TSE systems. However, such distance clue is\nsignificantly influenced by the room's acoustic characteristics, such as\ndimension and reverberation time, making it challenging for TSE systems that\nrely solely on distance clues to generalize across a variety of different\nrooms. To solve this, we suggest providing room environmental information (room\ndimensions and reverberation time) for distance-based TSE for better\ngeneralization capabilities. Especially, we propose a distance and\nenvironment-based TSE model in the time-frequency (TF) domain with learnable\ndistance and room embedding. Results on both simulated and real collected\ndatasets demonstrate its feasibility. Demonstration materials are available at\nhttps://runwushi.github.io/distance-room-demo-page/.", "published": "2025-05-20 14:40:18", "link": "http://arxiv.org/abs/2505.14433v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "MatchDance: Collaborative Mamba-Transformer Architecture Matching for High-Quality 3D Dance Synthesis", "abstract": "Music-to-dance generation represents a challenging yet pivotal task at the\nintersection of choreography, virtual reality, and creative content generation.\nDespite its significance, existing methods face substantial limitation in\nachieving choreographic consistency. To address the challenge, we propose\nMatchDance, a novel framework for music-to-dance generation that constructs a\nlatent representation to enhance choreographic consistency. MatchDance employs\na two-stage design: (1) a Kinematic-Dynamic-based Quantization Stage (KDQS),\nwhich encodes dance motions into a latent representation by Finite Scalar\nQuantization (FSQ) with kinematic-dynamic constraints and reconstructs them\nwith high fidelity, and (2) a Hybrid Music-to-Dance Generation Stage(HMDGS),\nwhich uses a Mamba-Transformer hybrid architecture to map music into the latent\nrepresentation, followed by the KDQS decoder to generate 3D dance motions.\nAdditionally, a music-dance retrieval framework and comprehensive metrics are\nintroduced for evaluation. Extensive experiments on the FineDance dataset\ndemonstrate state-of-the-art performance. Code will be released upon\nacceptance.", "published": "2025-05-20 11:30:28", "link": "http://arxiv.org/abs/2505.14222v1", "categories": ["cs.SD", "cs.GR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Source Verification for Speech Deepfakes", "abstract": "With the proliferation of speech deepfake generators, it becomes crucial not\nonly to assess the authenticity of synthetic audio but also to trace its\norigin. While source attribution models attempt to address this challenge, they\noften struggle in open-set conditions against unseen generators. In this paper,\nwe introduce the source verification task, which, inspired by speaker\nverification, determines whether a test track was produced using the same model\nas a set of reference signals. Our approach leverages embeddings from a\nclassifier trained for source attribution, computing distance scores between\ntracks to assess whether they originate from the same source. We evaluate\nmultiple models across diverse scenarios, analyzing the impact of speaker\ndiversity, language mismatch, and post-processing operations. This work\nprovides the first exploration of source verification, highlighting its\npotential and vulnerabilities, and offers insights for real-world forensic\napplications.", "published": "2025-05-20 10:42:48", "link": "http://arxiv.org/abs/2505.14188v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AudSemThinker: Enhancing Audio-Language Models through Reasoning over Semantics of Sound", "abstract": "Audio-language models have shown promising results in various sound\nunderstanding tasks, yet they remain limited in their ability to reason over\nthe fine-grained semantics of sound. In this paper, we present AudSemThinker, a\nmodel whose reasoning is structured around a framework of auditory semantics\ninspired by human cognition. To support this, we introduce AudSem, a novel\ndataset specifically curated for semantic descriptor reasoning in\naudio-language models. AudSem addresses the persistent challenge of data\ncontamination in zero-shot evaluations by providing a carefully filtered\ncollection of audio samples paired with captions generated through a robust\nmulti-stage pipeline. Our experiments demonstrate that AudSemThinker\noutperforms state-of-the-art models across multiple training settings,\nhighlighting its strength in semantic audio reasoning. Both AudSemThinker and\nthe AudSem dataset are released publicly.", "published": "2025-05-20 09:46:29", "link": "http://arxiv.org/abs/2505.14142v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "abstract": "Jailbreak attacks to Large audio-language models (LALMs) are studied\nrecently, but they achieve suboptimal effectiveness, applicability, and\npracticability, particularly, assuming that the adversary can fully manipulate\nuser prompts. In this work, we first conduct an extensive experiment showing\nthat advanced text jailbreak attacks cannot be easily ported to end-to-end\nLALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a\nnovel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio\ndoes not need to align with user prompts in the time axis by crafting suffixal\njailbreak audios; (2) universality: a single jailbreak perturbation is\neffective for different prompts by incorporating multiple prompts into\nperturbation generation; (3) stealthiness: the malicious intent of jailbreak\naudios will not raise the awareness of victims by proposing various intent\nconcealment strategies; and (4) over-the-air robustness: the jailbreak audios\nremain effective when being played over the air by incorporating the\nreverberation distortion effect with room impulse response into the generation\nof the perturbations. In contrast, all prior audio jailbreak attacks cannot\noffer asynchrony, universality, stealthiness, or over-the-air robustness.\nMoreover, AudioJailbreak is also applicable to the adversary who cannot fully\nmanipulate user prompts, thus has a much broader attack scenario. Extensive\nexperiments with thus far the most LALMs demonstrate the high effectiveness of\nAudioJailbreak. We highlight that our work peeks into the security implications\nof audio jailbreak attacks against LALMs, and realistically fosters improving\ntheir security robustness. The implementation and audio samples are available\nat our website https://audiojailbreak.github.io/AudioJailbreak.", "published": "2025-05-20 09:10:45", "link": "http://arxiv.org/abs/2505.14103v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Recreating Neural Activity During Speech Production with Language and Speech Model Embeddings", "abstract": "Understanding how neural activity encodes speech and language production is a\nfundamental challenge in neuroscience and artificial intelligence. This study\ninvestigates whether embeddings from large-scale, self-supervised language and\nspeech models can effectively reconstruct neural activity recordings captured\nduring speech production. We leverage pre-trained embeddings from deep learning\nmodels trained on linguistic and acoustic data to represent high-level speech\nfeatures and map them onto neural signals. We analyze the extent to which these\nembeddings preserve the spatio-temporal dynamics of brain activity. We evaluate\nreconstructed neural signals against ground truth recordings using correlation\nmetrics and signal reconstruction quality assessments. The results indicate\nthat neural activity can be effectively reconstructed using embeddings from\nlarge language and speech models across all study participants, yielding\nPearson correlation coefficients ranging from 0.79 to 0.99.", "published": "2025-05-20 08:31:41", "link": "http://arxiv.org/abs/2505.14074v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "SeamlessEdit: Background Noise Aware Zero-Shot Speech Editing with in-Context Enhancement", "abstract": "With the fast development of zero-shot text-to-speech technologies, it is\npossible to generate high-quality speech signals that are indistinguishable\nfrom the real ones. Speech editing, including speech insertion and replacement,\nappeals to researchers due to its potential applications. However, existing\nstudies only considered clean speech scenarios. In real-world applications, the\nexistence of environmental noise could significantly degrade the quality of the\ngeneration. In this study, we propose a noise-resilient speech editing\nframework, SeamlessEdit, for noisy speech editing. SeamlessEdit adopts a\nfrequency-band-aware noise suppression module and an in-content refinement\nstrategy. It can well address the scenario where the frequency bands of voice\nand background noise are not separated. The proposed SeamlessEdit framework\noutperforms state-of-the-art approaches in multiple quantitative and\nqualitative evaluations.", "published": "2025-05-20 08:12:12", "link": "http://arxiv.org/abs/2505.14066v1", "categories": ["eess.AS", "cs.SD", "68T45", "I.2.7; H.5.5"], "primary_category": "eess.AS"}
{"title": "Combining Deterministic Enhanced Conditions with Dual-Streaming Encoding for Diffusion-Based Speech Enhancement", "abstract": "Diffusion-based speech enhancement (SE) models need to incorporate correct\nprior knowledge as reliable conditions to generate accurate predictions.\nHowever, providing reliable conditions using noisy features is challenging. One\nsolution is to use features enhanced by deterministic methods as conditions.\nHowever, the information distortion and loss caused by deterministic methods\nmight affect the diffusion process. In this paper, we first investigate the\neffects of using different deterministic SE models as conditions for diffusion.\nWe validate two conditions depending on whether the noisy feature was used as\npart of the condition: one using only the deterministic feature\n(deterministic-only), and the other using both deterministic and noisy features\n(deterministic-noisy). Preliminary investigation found that using deterministic\nenhanced conditions improves hearing experiences on real data, while the choice\nbetween using deterministic-only or deterministic-noisy conditions depends on\nthe deterministic models. Based on these findings, we propose a dual-streaming\nencoding Repair-Diffusion Model for SE (DERDM-SE) to more effectively utilize\nboth conditions. Moreover, we found that fine-grained deterministic models have\ngreater potential in objective evaluation metrics, while UNet-based\ndeterministic models provide more stable diffusion performance. Therefore, in\nthe DERDM-SE, we propose a deterministic model that combines coarse- and\nfine-grained processing. Experimental results on CHiME4 show that the proposed\nmodels effectively leverage deterministic models to achieve better SE\nevaluation scores, along with more stable performance compared to other\ndiffusion-based SE models.", "published": "2025-05-20 06:29:21", "link": "http://arxiv.org/abs/2505.13983v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Bridging Speech Emotion Recognition and Personality: Dataset and Temporal Interaction Condition Network", "abstract": "This study investigates the interaction between personality traits and\nemotional expression, exploring how personality information can improve speech\nemotion recognition (SER). We collected personality annotation for the IEMOCAP\ndataset, and the statistical analysis identified significant correlations\nbetween personality traits and emotional expressions. To extract finegrained\npersonality features, we propose a temporal interaction condition network\n(TICN), in which personality features are integrated with Hubert-based acoustic\nfeatures for SER. Experiments show that incorporating ground-truth personality\ntraits significantly enhances valence recognition, improving the concordance\ncorrelation coefficient (CCC) from 0.698 to 0.785 compared to the baseline\nwithout personality information. For practical applications in dialogue systems\nwhere personality information about the user is unavailable, we develop a\nfront-end module of automatic personality recognition. Using these\nautomatically predicted traits as inputs to our proposed TICN model, we achieve\na CCC of 0.776 for valence recognition, representing an 11.17% relative\nimprovement over the baseline. These findings confirm the effectiveness of\npersonality-aware SER and provide a solid foundation for further exploration in\npersonality-aware speech processing applications.", "published": "2025-05-20 06:23:47", "link": "http://arxiv.org/abs/2505.13978v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Naturalness-Aware Curriculum Learning with Dynamic Temperature for Speech Deepfake Detection", "abstract": "Recent advances in speech deepfake detection (SDD) have significantly\nimproved artifacts-based detection in spoofed speech. However, most models\noverlook speech naturalness, a crucial cue for distinguishing bona fide speech\nfrom spoofed speech. This study proposes naturalness-aware curriculum learning,\na novel training framework that leverages speech naturalness to enhance the\nrobustness and generalization of SDD. This approach measures sample difficulty\nusing both ground-truth labels and mean opinion scores, and adjusts the\ntraining schedule to progressively introduce more challenging samples. To\nfurther improve generalization, a dynamic temperature scaling method based on\nspeech naturalness is incorporated into the training process. A 23% relative\nreduction in the EER was achieved in the experiments on the ASVspoof 2021 DF\ndataset, without modifying the model architecture. Ablation studies confirmed\nthe effectiveness of naturalness-aware training strategies for SDD tasks.", "published": "2025-05-20 06:15:17", "link": "http://arxiv.org/abs/2505.13976v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The Multimodal Information Based Speech Processing (MISP) 2025 Challenge: Audio-Visual Diarization and Recognition", "abstract": "Meetings are a valuable yet challenging scenario for speech applications due\nto complex acoustic conditions. This paper summarizes the outcomes of the MISP\n2025 Challenge, hosted at Interspeech 2025, which focuses on multi-modal,\nmulti-device meeting transcription by incorporating video modality alongside\naudio. The tasks include Audio-Visual Speaker Diarization (AVSD), Audio-Visual\nSpeech Recognition (AVSR), and Audio-Visual Diarization and Recognition (AVDR).\nWe present the challenge's objectives, tasks, dataset, baseline systems, and\nsolutions proposed by participants. The best-performing systems achieved\nsignificant improvements over the baseline: the top AVSD model achieved a\nDiarization Error Rate (DER) of 8.09%, improving by 7.43%; the top AVSR system\nachieved a Character Error Rate (CER) of 9.48%, improving by 10.62%; and the\nbest AVDR system achieved a concatenated minimum-permutation Character Error\nRate (cpCER) of 11.56%, improving by 72.49%.", "published": "2025-05-20 06:11:51", "link": "http://arxiv.org/abs/2505.13971v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BiCrossMamba-ST: Speech Deepfake Detection with Bidirectional Mamba Spectro-Temporal Cross-Attention", "abstract": "We propose BiCrossMamba-ST, a robust framework for speech deepfake detection\nthat leverages a dual-branch spectro-temporal architecture powered by\nbidirectional Mamba blocks and mutual cross-attention. By processing spectral\nsub-bands and temporal intervals separately and then integrating their\nrepresentations, BiCrossMamba-ST effectively captures the subtle cues of\nsynthetic speech. In addition, our proposed framework leverages a\nconvolution-based 2D attention map to focus on specific spectro-temporal\nregions, enabling robust deepfake detection. Operating directly on raw\nfeatures, BiCrossMamba-ST achieves significant performance improvements, a\n67.74% and 26.3% relative gain over state-of-the-art AASIST on ASVSpoof LA21\nand ASVSpoof DF21 benchmarks, respectively, and a 6.80% improvement over\nRawBMamba on ASVSpoof DF21. Code and models will be made publicly available.", "published": "2025-05-20 04:52:59", "link": "http://arxiv.org/abs/2505.13930v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding", "abstract": "The text generation paradigm for audio tasks has opened new possibilities for\nunified audio understanding. However, existing models face significant\nchallenges in achieving a comprehensive understanding across diverse audio\ntypes, such as speech, general audio events, and music. Furthermore, their\nexclusive reliance on cross-entropy loss for alignment often falls short, as it\ntreats all tokens equally and fails to account for redundant audio features,\nleading to weaker cross-modal alignment. To deal with the above challenges,\nthis paper introduces U-SAM, an advanced audio language model that integrates\nspecialized encoders for speech, audio, and music with a pre-trained large\nlanguage model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for\ntask-aware feature fusion, dynamically routing and integrating the\ndomain-specific encoder outputs. Additionally, U-SAM incorporates a\nSemantic-Aware Contrastive Loss Module, which explicitly identifies redundant\naudio features under language supervision and rectifies their semantic and\nspectral representations to enhance cross-modal alignment. Extensive\nexperiments demonstrate that U-SAM consistently outperforms both specialized\nmodels and existing audio language models across multiple benchmarks. Moreover,\nit exhibits emergent capabilities on unseen tasks, showcasing its\ngeneralization potential. Code is available\n(https://github.com/Honee-W/U-SAM/).", "published": "2025-05-20 03:34:53", "link": "http://arxiv.org/abs/2505.13880v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Forensic deepfake audio detection using segmental speech features", "abstract": "This study explores the potential of using acoustic features of segmental\nspeech sounds to detect deepfake audio. These features are highly interpretable\nbecause of their close relationship with human articulatory processes and are\nexpected to be more difficult for deepfake models to replicate. The results\ndemonstrate that certain segmental features commonly used in forensic voice\ncomparison are effective in identifying deep-fakes, whereas some global\nfeatures provide little value. These findings underscore the need to approach\naudio deepfake detection differently for forensic voice comparison and offer a\nnew perspective on leveraging segmental features for this purpose.", "published": "2025-05-20 02:42:46", "link": "http://arxiv.org/abs/2505.13847v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Semantic Information-based Hierarchical Speech Enhancement Method Using Factorized Codec and Diffusion Model", "abstract": "Most current speech enhancement (SE) methods recover clean speech from noisy\ninputs by directly estimating time-frequency masks or spectrums. However, these\napproaches often neglect the distinct attributes, such as semantic content and\nacoustic details, inherent in speech signals, which can hinder performance in\ndownstream tasks. Moreover, their effectiveness tends to degrade in complex\nacoustic environments. To overcome these challenges, we propose a novel,\nsemantic information-based, step-by-step factorized SE method using factorized\ncodec and diffusion model. Unlike traditional SE methods, our hierarchical\nmodeling of semantic and acoustic attributes enables more robust clean speech\nrecovery, particularly in challenging acoustic scenarios. Moreover, this method\noffers further advantages for downstream TTS tasks. Experimental results\ndemonstrate that our algorithm not only outperforms SOTA baselines in terms of\nspeech quality but also enhances TTS performance in noisy environments.", "published": "2025-05-20 02:38:29", "link": "http://arxiv.org/abs/2505.13843v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising", "abstract": "Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend\nto preserve the acoustic environment of the audio prompt, leading to\ndegradation in synthesized speech quality when the audio prompt contains noise.\nIn this paper, we propose a novel neural codec-based speech denoiser and\nintegrate it with the advanced LLM-based TTS model, LauraTTS, to achieve\nnoise-robust zero-shot TTS. The proposed codec denoiser consists of an audio\ncodec, a token denoiser, and an embedding refiner. The token denoiser predicts\nthe first two groups of clean acoustic tokens from the noisy ones, which can\nserve as the acoustic prompt for LauraTTS to synthesize high-quality\npersonalized speech or be converted to clean speech waveforms through the\nembedding refiner and codec decoder. Experimental results show that our\nproposed codec denoiser outperforms state-of-the-art speech enhancement (SE)\nmethods, and the proposed noise-robust LauraTTS surpasses the approach using\nadditional SE models.", "published": "2025-05-20 02:18:45", "link": "http://arxiv.org/abs/2505.13830v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Pushing the Frontiers of Self-Distillation Prototypes Network with Dimension Regularization and Score Normalization", "abstract": "Developing robust speaker verification (SV) systems without speaker labels\nhas been a longstanding challenge. Earlier research has highlighted a\nconsiderable performance gap between self-supervised and fully supervised\napproaches. In this paper, we enhance the non-contrastive self-supervised\nframework, Self-Distillation Prototypes Network (SDPN), by introducing\ndimension regularization that explicitly addresses the collapse problem through\nthe application of regularization terms to speaker embeddings. Moreover, we\nintegrate score normalization techniques from fully supervised SV to further\nbridge the gap toward supervised verification performance. SDPN with dimension\nregularization and score normalization sets a new state-of-the-art on the\nVoxCeleb1 speaker verification evaluation benchmark, achieving Equal Error Rate\n1.29%, 1.60%, and 2.80% for trial VoxCeleb1-{O,E,H} respectively. These results\ndemonstrate relative improvements of 28.3%, 19.6%, and 22.6% over the current\nbest self-supervised methods, thereby advancing the frontiers of SV technology.", "published": "2025-05-20 02:18:03", "link": "http://arxiv.org/abs/2505.13826v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Articulatory Feature Prediction from Surface EMG during Speech Production", "abstract": "We present a model for predicting articulatory features from surface\nelectromyography (EMG) signals during speech production. The proposed model\nintegrates convolutional layers and a Transformer block, followed by separate\npredictors for articulatory features. Our approach achieves a high prediction\ncorrelation of approximately 0.9 for most articulatory features. Furthermore,\nwe demonstrate that these predicted articulatory features can be decoded into\nintelligible speech waveforms. To our knowledge, this is the first method to\ndecode speech waveforms from surface EMG via articulatory features, offering a\nnovel approach to EMG-based speech synthesis. Additionally, we analyze the\nrelationship between EMG electrode placement and articulatory feature\npredictability, providing knowledge-driven insights for optimizing EMG\nelectrode configurations. The source code and decoded speech samples are\npublicly available.", "published": "2025-05-20 01:50:05", "link": "http://arxiv.org/abs/2505.13814v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ClapFM-EVC: High-Fidelity and Flexible Emotional Voice Conversion with Dual Control from Natural Language and Speech", "abstract": "Despite great advances, achieving high-fidelity emotional voice conversion\n(EVC) with flexible and interpretable control remains challenging. This paper\nintroduces ClapFM-EVC, a novel EVC framework capable of generating high-quality\nconverted speech driven by natural language prompts or reference speech with\nadjustable emotion intensity. We first propose EVC-CLAP, an emotional\ncontrastive language-audio pre-training model, guided by natural language\nprompts and categorical labels, to extract and align fine-grained emotional\nelements across speech and text modalities. Then, a FuEncoder with an adaptive\nintensity gate is presented to seamless fuse emotional features with Phonetic\nPosteriorGrams from a pre-trained ASR model. To further improve emotion\nexpressiveness and speech naturalness, we propose a flow matching model\nconditioned on these captured features to reconstruct Mel-spectrogram of source\nspeech. Subjective and objective evaluations validate the effectiveness of\nClapFM-EVC.", "published": "2025-05-20 01:34:29", "link": "http://arxiv.org/abs/2505.13805v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Developing RPC-Net: Leveraging High-Density Electromyography and Machine Learning for Improved Hand Position Estimation", "abstract": "Objective: The purpose of this study was to develop and evaluate the\nperformance of RPC-Net (Recursive Prosthetic Control Network), a novel method\nusing simple neural network architectures to translate electromyographic\nactivity into hand position with high accuracy and computational efficiency.\nMethods: RPC-Net uses a regression-based approach to convert forearm\nelectromyographic signals into hand kinematics. We tested the adaptability of\nthe algorithm to different conditions and compared its performance with that of\nsolutions from the academic literature. Results: RPC-Net demonstrated a high\ndegree of accuracy in predicting hand position from electromyographic activity,\noutperforming other solutions with the same computational cost. Including\nprevious position data consistently improved results across subjects and\nconditions. RPC-Net showed robustness against a reduction in the number of\nelectromyography electrodes used and shorter input signals, indicating\npotential for further reduction in computational cost. Conclusion: The results\ndemonstrate that RPC-Net is capable of accurately translating forearm\nelectromyographic activity into hand position, offering a practical and\nadaptable tool that may be accessible in clinical settings. Significance: The\ndevelopment of RPC-Net represents a significant advancement. In clinical\nsettings, its application could enable prosthetic devices to be controlled in a\nway that feels more natural, improving the quality of life for individuals with\nlimb loss.", "published": "2025-05-20 17:50:59", "link": "http://arxiv.org/abs/2505.14663v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "HDE-Array: Development and Validation of a New Dry Electrode Array Design to Acquire HD-sEMG for Hand Position Estimation", "abstract": "This paper aims to introduce HDE-Array (High-Density Electrode Array), a\nnovel dry electrode array for acquiring High-Density surface electromyography\n(HD-sEMG) for hand position estimation through RPC-Net (Recursive Prosthetic\nControl Network), a neural network defined in a previous study. We aim to\ndemonstrate the hypothesis that the position estimates returned by RPC-Net\nusing HD-sEMG signals acquired with HDE-Array are as accurate as those obtained\nfrom signals acquired with gel electrodes. We compared the results, in terms of\nprecision of hand position estimation by RPC-Net, using signals acquired by\ntraditional gel electrodes and by HDE-Array. As additional validation, we\nperformed a variance analysis to confirm that the presence of only two rows of\nelectrodes does not result in an excessive loss of information, and we\ncharacterized the electrode-skin impedance to assess the effects of the voltage\ndivider effect and power line interference. Performance tests indicated that\nRPC-Net, used with HDE-Array, achieved comparable or superior results to those\nobserved when used with the gel electrode setup. The dry electrodes\ndemonstrated effective performance even with a simplified setup, highlighting\npotential cost and usability benefits. These results suggest improvements in\nthe accessibility and user-friendliness of upper-limb rehabilitation devices\nand underscore the potential of HDE-Array and RPC-Net to revolutionize control\nfor medical and non-medical applications.", "published": "2025-05-20 17:44:21", "link": "http://arxiv.org/abs/2505.14658v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Global Maxwell Tomography Using the Volume-Surface Integral Equation for Improved Estimation of Electrical Properties", "abstract": "Objective: Global Maxwell Tomography (GMT) is a noninvasive inverse\noptimization method for the estimation of electrical properties (EP) from\nmagnetic resonance (MR) measurements. GMT uses the volume integral equation\n(VIE) in the forward problem and assumes that the sample has negligible effect\non the coil currents. Consequently, GMT calculates the coil's incident fields\nwith an initial EP distribution and keeps them constant for all optimization\niterations. This can lead to erroneous reconstructions. This work introduces a\nnovel version of GMT that replaces VIE with the volume-surface integral\nequation (VSIE), which recalculates the coil currents at every iteration based\non updated EP estimates before computing the associated fields. Methods: We\nsimulated an 8-channel transceiver coil array for 7 T brain imaging and\nreconstructed the EP of a realistic head model using VSIE-based GMT. We built\nthe coil, collected experimental MR measurements, and reconstructed EP of a\ntwo-compartment phantom. Results: In simulations, VSIE-based GMT outperformed\nVIE-based GMT by at least 12% for both EP. In experiments, the relative\ndifference with respect to probe-measured EP values in the inner (outer)\ncompartment was 13% (26%) and 17% (33%) for the permittivity and conductivity,\nrespectively. Conclusion: The use of VSIE over VIE enhances GMT's performance\nby accounting for the effect of the EP on the coil currents. Significance:\nVSIE-based GMT does not rely on an initial EP estimate, rendering it more\nsuitable for experimental reconstructions compared to the VIE-based GMT.", "published": "2025-05-20 16:02:30", "link": "http://arxiv.org/abs/2505.14546v1", "categories": ["cs.CE", "eess.SP"], "primary_category": "cs.CE"}
{"title": "A Direct Comparison of Simultaneously Recorded Scalp, Around-Ear, and In-Ear EEG for Neural Selective Auditory Attention Decoding to Speech", "abstract": "Current assistive hearing devices, such as hearing aids and cochlear\nimplants, lack the ability to adapt to the listener's focus of auditory\nattention, limiting their effectiveness in complex acoustic environments like\ncocktail party scenarios where multiple conversations occur simultaneously.\nNeuro-steered hearing devices aim to overcome this limitation by decoding the\nlistener's auditory attention from neural signals, such as\nelectroencephalography (EEG). While many auditory attention decoding (AAD)\nstudies have used high-density scalp EEG, such systems are impractical for\ndaily use as they are bulky and uncomfortable. Therefore, AAD with wearable and\nunobtrusive EEG systems that are comfortable to wear and can be used for\nlong-term recording are required. Around-ear EEG systems like cEEGrids have\nshown promise in AAD, but in-ear EEG, recorded via custom earpieces offering\nsuperior comfort, remains underexplored. We present a new AAD dataset with\nsimultaneously recorded scalp, around-ear, and in-ear EEG, enabling a direct\ncomparison. Using a classic linear stimulus reconstruction algorithm, a\nsignificant performance gap between all three systems exists, with AAD\naccuracies of 83.4% (scalp), 67.2% (around-ear), and 61.1% (in-ear) on 60s\ndecision windows. These results highlight the trade-off between decoding\nperformance and practical usability. Yet, while the ear-based systems using\nbasic algorithms might currently not yield accurate enough performances for a\ndecision speed-sensitive application in hearing aids, their significant\nperformance suggests potential for attention monitoring on longer timescales.\nFurthermore, adding an external reference or a few scalp electrodes via greedy\nforward selection substantially and quickly boosts accuracy by over 10 percent\npoint, especially for in-ear EEG. These findings position in-ear EEG as a\npromising component in EEG sensor networks for AAD.", "published": "2025-05-20 15:10:37", "link": "http://arxiv.org/abs/2505.14478v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A precise detection method for transient micro short-circuit faults of lithium-ion batteries through signal processing", "abstract": "A specific failure mode designated as transient micro-short circuit (TMSC)\nhas been identified in practical battery systems, exhibiting subtle and latent\ncharacteristics with measurable voltage deviations. To further improve the safe\nuse of lithium-ion batteries (LIBs), this letter introduces a novel method for\nthe precise detection of this TMSC faults within LIBs. The method applies the\ncontinuous wavelet transform (CWT) to voltage and current signals, followed by\nthe identification of micro-scale anomalies through the analysis of the\ncoherence in the wavelet spectrum at specific frequency. Through designed fault\nexperiments, the effec-tiveness of this method has been verified. Result\ndemon-strates that it can effectively capture micro-faults with a voltage drop\nas low as 30 mV within just a few seconds. Furthermore, the proposed method is\ninherently highly robust and is able to effectively detect false faults and\nhidden faults under varying current loads, which highlights the superiority of\nthis method.", "published": "2025-05-20 12:32:47", "link": "http://arxiv.org/abs/2505.14283v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Outage Probability Analysis of Tunable Liquid Lens-assisted VLC Systems", "abstract": "This paper presents a tunable liquid lens (TLL)-assisted indoor mobile\nvisible light communication system. To mitigate performance degradation caused\nby user mobility and random receiver orientation, an electrowetting cuboid TLL\nis used at the receiver. By dynamically controlling the orientation angle of\nthe liquid surface through voltage adjustments, signal reception and overall\nsystem performance are enhanced. An accurate mathematical framework is\ndeveloped to model channel gains, and two lens optimization strategies, namely\n($i$) the best signal reception (BSR), and ($ii$) the vertically upward lens\norientation (VULO) are introduced for improved performance. Closed form\nexpressions for the outage probability are derived for each scheme for\npractical mobility and receiver orientation conditions. Numerical results\ndemonstrate that the proposed TLL and lens adjustment strategies significantly\nreduce the outage probability compared to fixed lens and no lens receivers\nacross various mobility and orientation conditions. Specifically, the outage\nprobability is improved from $1\\times 10^{-1}$ to $3\\times 10^{-3}$ at a\ntransmit power of $12$ dBW under a $8^{\\circ}$ polar angle variation in random\nreceiver orientation using the BSR scheme.", "published": "2025-05-20 11:43:10", "link": "http://arxiv.org/abs/2505.14236v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "VaN3Twin: the Multi-Technology V2X Digital Twin with Ray-Tracing in the Loop", "abstract": "This paper presents VaN3Twin-the first open-source, full-stack Network\nDigital Twin (NDT) framework for simulating the coexistence of multiple\nVehicle-to-Everything (V2X) communication technologies with accurate\nphysical-layer modeling via ray tracing. VaN3Twin extends the ms-van3t\nsimulator by integrating Sionna Ray Tracer (RT) in the loop, enabling\nhigh-fidelity representation of wireless propagation, including diverse\nLine-of-Sight (LoS) conditions with focus on LoS blockage due to other\nvehicles' meshes, Doppler effect, and site-dependent effects-e.g., scattering\nand diffraction. Unlike conventional simulation tools, the proposed framework\nsupports realistic coexistence analysis across DSRC and C-V2X technologies\noperating over shared spectrum. A dedicated interference tracking module\ncaptures cross-technology interference at the time-frequency resource block\nlevel and enhances signal-to-interference-plus-noise ratio (SINR) estimation by\neliminating artifacts such as the bimodal behavior induced by separate LoS/NLoS\npropagation models. Compared to field measurements, VaN3Twin reduces\napplication-layer disagreement by 50% in rural and over 70% in urban\nenvironments with respect to current state-of-the-art simulation tools,\ndemonstrating its value for scalable and accurate digital twin-based V2X\ncoexistence simulation.", "published": "2025-05-20 10:41:11", "link": "http://arxiv.org/abs/2505.14184v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Elliptic Curve Modulation (ECM) for Extremely Robust Physical Layer Encryption", "abstract": "This paper introduces Elliptic Curve Modulation (ECM), a novel modulation\nscheme that can be leveraged to effectively shuffle transmitted data while\nmaintaining symbol error probability (SEP) performance equivalent to\nunencrypted systems. By utilizing the well-distributed elliptic curve points\nover the field of large primes, ECM enhances symbol obfuscation, making it a\npowerful foundation for physical-layer encryption (PLE). Each symbol is mapped\nfrom a predefined key while preserving a minimum Euclidean distance constraint,\nensuring strong security against adversarial inference without compromising\nerror performance. Building on ECM's strong obfuscation capabilities, we\npropose ECM with dynamic rotation (ECM-DR) as a practical PLE scheme that\nachieves near-maximal obfuscation while balancing precomputation complexity. By\nleveraging a reduced subset of precomputed elliptic curve points and key-based\ndynamic constellation rotation, ECM-DR ensures that each transmission remains\nunpredictable, significantly enhancing security compared to traditional PLE\nschemes without additional computational cost. Security analysis confirms ECM's\nresilience to brute-force attacks, while numerical results demonstrate its\nstrong obfuscation capabilities. Furthermore, ECM-DR achieves near-maximum\ninformation entropy while preserving the SEP performance of unencrypted\nquadrature amplitude modulation (QAM), offering an extremely robust solution\nfor secure wireless communications.", "published": "2025-05-20 10:02:13", "link": "http://arxiv.org/abs/2505.14153v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "EM-Based Channel Estimation for mMIMO LEO SATCOM Under Imperfect Doppler Compensation", "abstract": "Massive multiple-input multiple-output low-Earth-orbit communication channels\nare highly time-varying due to severe Doppler shifts and propagation delays.\nWhile satellite-mobility-induced Doppler shifts can be compensated using known\nephemeris data, those caused by user mobility require accurate user positioning\ninformation; the absence of such information contributes to amplified channel\naging in conventional channel estimators. To address this challenge, we propose\na data-aided channel estimator based on the expectation-maximization (EM)\nalgorithm, combined with a discrete Legendre polynomial basis expansion method\n(DLP-BEM), to estimate the channel under imperfect Doppler compensation. The EM\nalgorithm iteratively exploits hidden data symbols for improved channel\nestimation, while DLP-BEM regularizes the process by projecting the channel\nestimate onto a lower dimensional subspace that mitigates estimation errors.\nSimulation results demonstrate the superiority of the proposed framework over\nexisting methods in terms of normalized mean square error and symbol error\nrate.", "published": "2025-05-20 09:22:03", "link": "http://arxiv.org/abs/2505.14118v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "AI-empowered Channel Estimation for Block-based Active IRS-enhanced Hybrid-field IoT Network", "abstract": "In this paper, channel estimation (CE) for uplink hybrid-field communications\ninvolving multiple Internet of Things (IoT) devices assisted by an active\nintelligent reflecting surface (IRS) is investigated. Firstly, to reduce the\ncomplexity of near-field (NF) channel modeling and estimation between IoT\ndevices and active IRS, a sub-blocking strategy for active IRS is proposed.\nSpecifically, the entire active IRS is divided into multiple smaller\nsub-blocks, so that IoT devices are located in the far-field (FF) region of\neach sub block, while also being located in the NF region of the entire active\nIRS. This strategy significantly simplifies the channel model and reduces the\nparameter estimation dimension by decoupling the high-dimensional NF channel\nparameter space into low dimensional FF sub channels. Subsequently, the\nrelationship between channel approximation error and CE error with respect to\nthe number of sub blocks is derived, and the optimal number of sub blocks is\nsolved based on the criterion of minimizing the total error. In addition,\nconsidering that the amplification capability of active IRS requires power\nconsumption, a closed-form expression for the optimal power allocation factor\nis derived. To further reduce the pilot overhead, a lightweight CE algorithm\nbased on convolutional autoencoder (CAE) and multi-head attention mechanism,\ncalled CAEformer, is designed. The Cramer-Rao lower bound is derived to\nevaluate the proposed algorithm's performance. Finally, simulation results\ndemonstrate the proposed CAEformer network significantly outperforms the\nconventional least square and minimum mean square error scheme in terms of\nestimation accuracy.", "published": "2025-05-20 09:01:40", "link": "http://arxiv.org/abs/2505.14098v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field RIS-Assisted Localization Under Mutual Coupling", "abstract": "Reconfigurable intelligent surfaces (RISs) have the potential to\nsignificantly enhance the performance of integrated sensing and communication\n(ISAC) systems, particularly in line-of-sight (LoS) blockage scenarios.\nHowever, as larger RISs are integrated into ISAC systems, mutual coupling (MC)\neffects between RIS elements become more pronounced, leading to a substantial\ndegradation in performance, especially for localization applications. In this\npaper, we first conduct a misspecified and standard Cram\\'er-Rao bound analysis\nto quantify the impact of MC on localization performance, demonstrating severe\ndegradations in accuracy, especially when MC is ignored. Building on this, we\npropose a novel joint user equipment localization and RIS MC parameter\nestimation (JLMC) method in near-field wireless systems. Our two-stage MC-aware\napproach outperforms classical methods that neglect MC, significantly improving\nlocalization accuracy and overall system performance. Simulation results\nvalidate the effectiveness and advantages of the proposed method in realistic\nscenarios.", "published": "2025-05-20 07:56:49", "link": "http://arxiv.org/abs/2505.14055v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generalizable Learning for Frequency-Domain Channel Extrapolation under Distribution Shift", "abstract": "Frequency-domain channel extrapolation is effective in reducing pilot\noverhead for massive multiple-input multiple-output (MIMO) systems. Recently,\nDeep learning (DL) based channel extrapolator has become a promising candidate\nfor modeling complex frequency-domain dependency. Nevertheless, current DL\nextrapolators fail to operate in unseen environments under distribution shift,\nwhich poses challenges for large-scale deployment. In this paper, environment\ngeneralizable learning for channel extrapolation is achieved by realizing\ndistribution alignment from a physics perspective. Firstly, the distribution\nshift of wireless channels is rigorously analyzed, which comprises the\ndistribution shift of multipath structure and single-path response. Secondly, a\nphysics-based progressive distribution alignment strategy is proposed to\naddress the distribution shift, which includes successive path-oriented design\nand path alignment. Path-oriented DL extrapolator decomposes multipath channel\nextrapolation into parallel extrapolations of the extracted path, which can\nmitigate the distribution shift of multipath structure. Path alignment is\nproposed to address the distribution shift of single-path response in\npath-oriented DL extrapolators, which eventually enables generalizable learning\nfor channel extrapolation. In the simulation, distinct wireless environments\nare generated using the precise ray-tracing tool. Based on extensive\nevaluations, the proposed path-oriented DL extrapolator with path alignment can\nreduce extrapolation error by more than 6 dB in unseen environments compared to\nthe state-of-the-arts.", "published": "2025-05-20 03:22:29", "link": "http://arxiv.org/abs/2505.13867v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "RainfalLTE: A Zero-effect Rainfall Sensing System Utilizing Existing LTE Infrastructure", "abstract": "Environmental sensing is an important research topic in the integrated\nsensing and communication (ISAC) system. Current works often focus on static\nenvironments, such as buildings and terrains. However, dynamic factors like\nrainfall can cause serious interference to wireless signals. In this paper, we\npropose a system called RainfalLTE that utilizes the downlink signal of LTE\nbase stations for device-independent rain sensing. In articular, it is fully\ncompatible with current communication modes and does not require any additional\nhardware. We evaluate it with LTE data and rainfall information provided by a\nweather radar in Badaling Town, Beijing The results show that for 10 classes of\nrainfall, RainfalLTE achieves over 97% identification accuracy. Our case study\nshows that the assistance of rainfall information can bring more than 40%\nenergy saving, which provides new opportunities for the design and optimization\nof ISAC systems.", "published": "2025-05-20 01:57:28", "link": "http://arxiv.org/abs/2505.13818v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning", "abstract": "Large language models (LLMs) have achieved remarkable progress on\nmathematical tasks through Chain-of-Thought (CoT) reasoning. However, existing\nmathematical CoT datasets often suffer from Thought Leaps due to experts\nomitting intermediate steps, which negatively impacts model learning and\ngeneralization. We propose the CoT Thought Leap Bridge Task, which aims to\nautomatically detect leaps and generate missing intermediate reasoning steps to\nrestore the completeness and coherence of CoT. To facilitate this, we\nconstructed a specialized training dataset called ScaleQM+, based on the\nstructured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought\nleaps. Through comprehensive experiments on mathematical reasoning benchmarks,\nwe demonstrate that models fine-tuned on bridged datasets consistently\noutperform those trained on original datasets, with improvements of up to\n+5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%)\nand provides better starting points for reinforcement learning (+3.1%),\nfunctioning as a plug-and-play module compatible with existing optimization\ntechniques. Furthermore, CoT-Bridge demonstrate improved generalization to\nout-of-domain logical reasoning tasks, confirming that enhancing reasoning\ncompleteness yields broadly applicable benefits.", "published": "2025-05-20 17:59:31", "link": "http://arxiv.org/abs/2505.14684v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "General-Reasoner: Advancing LLM Reasoning Across All Domains", "abstract": "Reinforcement learning (RL) has recently demonstrated strong potential in\nenhancing the reasoning capabilities of large language models (LLMs).\nParticularly, the \"Zero\" reinforcement learning introduced by Deepseek-R1-Zero,\nenables direct RL training of base LLMs without relying on an intermediate\nsupervised fine-tuning stage. Despite these advancements, current works for LLM\nreasoning mainly focus on mathematical and coding domains, largely due to data\nabundance and the ease of answer verification. This limits the applicability\nand generalization of such models to broader domains, where questions often\nhave diverse answer representations, and data is more scarce. In this paper, we\npropose General-Reasoner, a novel training paradigm designed to enhance LLM\nreasoning capabilities across diverse domains. Our key contributions include:\n(1) constructing a large-scale, high-quality dataset of questions with\nverifiable answers curated by web crawling, covering a wide range of\ndisciplines; and (2) developing a generative model-based answer verifier, which\nreplaces traditional rule-based verification with the capability of\nchain-of-thought and context-awareness. We train a series of models and\nevaluate them on a wide range of datasets covering wide domains like physics,\nchemistry, finance, electronics etc. Our comprehensive evaluation across these\n12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC)\ndemonstrates that General-Reasoner outperforms existing baseline methods,\nachieving robust and generalizable reasoning performance while maintaining\nsuperior effectiveness in mathematical reasoning tasks.", "published": "2025-05-20 17:41:33", "link": "http://arxiv.org/abs/2505.14652v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Think Only When You Need with Large Hybrid-Reasoning Models", "abstract": "Recent Large Reasoning Models (LRMs) have shown substantially improved\nreasoning capabilities over traditional Large Language Models (LLMs) by\nincorporating extended thinking processes prior to producing final responses.\nHowever, excessively lengthy thinking introduces substantial overhead in terms\nof token consumption and latency, which is particularly unnecessary for simple\nqueries. In this work, we introduce Large Hybrid-Reasoning Models (LHRMs), the\nfirst kind of model capable of adaptively determining whether to perform\nthinking based on the contextual information of user queries. To achieve this,\nwe propose a two-stage training pipeline comprising Hybrid Fine-Tuning (HFT) as\na cold start, followed by online reinforcement learning with the proposed\nHybrid Group Policy Optimization (HGPO) to implicitly learn to select the\nappropriate thinking mode. Furthermore, we introduce a metric called Hybrid\nAccuracy to quantitatively assess the model's capability for hybrid thinking.\nExtensive experimental results show that LHRMs can adaptively perform hybrid\nthinking on queries of varying difficulty and type. It outperforms existing\nLRMs and LLMs in reasoning and general capabilities while significantly\nimproving efficiency. Together, our work advocates for a reconsideration of the\nappropriate use of extended thinking processes and provides a solid starting\npoint for building hybrid thinking systems.", "published": "2025-05-20 17:23:25", "link": "http://arxiv.org/abs/2505.14631v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol", "abstract": "As Model Context Protocol (MCP) introduces an easy-to-use ecosystem for users\nand developers, it also brings underexplored safety risks. Its decentralized\narchitecture, which separates clients and servers, poses unique challenges for\nsystematic safety analysis. This paper proposes a novel framework to enhance\nMCP safety. Guided by the MAESTRO framework, we first analyze the missing\nsafety mechanisms in MCP, and based on this analysis, we propose the Model\nContextual Integrity Protocol (MCIP), a refined version of MCP that addresses\nthese gaps. Next, we develop a fine-grained taxonomy that captures a diverse\nrange of unsafe behaviors observed in MCP scenarios. Building on this taxonomy,\nwe develop benchmark and training data that support the evaluation and\nimprovement of LLMs' capabilities in identifying safety risks within MCP\ninteractions. Leveraging the proposed benchmark and training data, we conduct\nextensive experiments on state-of-the-art LLMs. The results highlight LLMs'\nvulnerabilities in MCP interactions and demonstrate that our approach\nsubstantially improves their safety performance.", "published": "2025-05-20 16:41:45", "link": "http://arxiv.org/abs/2505.14590v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pivot Language for Low-Resource Machine Translation", "abstract": "Certain pairs of languages suffer from lack of a parallel corpus which is\nlarge in size and diverse in domain. One of the ways this is overcome is via\nuse of a pivot language. In this paper we use Hindi as a pivot language to\ntranslate Nepali into English. We describe what makes Hindi a good candidate\nfor the pivot. We discuss ways in which a pivot language can be used, and use\ntwo such approaches - the Transfer Method (fully supervised) and\nBacktranslation (semi-supervised) - to translate Nepali into English. Using the\nformer, we are able to achieve a devtest Set SacreBLEU score of 14.2, which\nimproves the baseline fully supervised score reported by (Guzman et al., 2019)\nby 6.6 points. While we are slightly below the semi-supervised baseline score\nof 15.1, we discuss what may have caused this under-performance, and suggest\nscope for future work.", "published": "2025-05-20 16:10:10", "link": "http://arxiv.org/abs/2505.14553v2", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation", "abstract": "Recent advancements in large language models (LLMs) underscore the need for\nmore comprehensive evaluation methods to accurately assess their reasoning\ncapabilities. Existing benchmarks are often domain-specific and thus cannot\nfully capture an LLM's general reasoning potential. To address this limitation,\nwe introduce the Knowledge Orthogonal Reasoning Gymnasium (KORGym), a dynamic\nevaluation platform inspired by KOR-Bench and Gymnasium. KORGym offers over\nfifty games in either textual or visual formats and supports interactive,\nmulti-turn assessments with reinforcement learning scenarios. Using KORGym, we\nconduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent\nreasoning patterns within model families and demonstrating the superior\nperformance of closed-source models. Further analysis examines the effects of\nmodality, reasoning strategies, reinforcement learning techniques, and response\nlength on model performance. We expect KORGym to become a valuable resource for\nadvancing LLM reasoning research and developing evaluation methodologies suited\nto complex, interactive environments.", "published": "2025-05-20 16:06:32", "link": "http://arxiv.org/abs/2505.14552v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models", "abstract": "In the field of urban planning, existing Vision-Language Models (VLMs)\nfrequently fail to effectively analyze and evaluate planning maps, despite the\ncritical importance of these visual elements for urban planners and related\neducational contexts. Planning maps, which visualize land use, infrastructure\nlayouts, and functional zoning, require specialized understanding of spatial\nconfigurations, regulatory requirements, and multi-scale analysis. To address\nthis challenge, we introduce PlanGPT-VL, the first domain-specific\nVision-Language Model tailored specifically for urban planning maps. PlanGPT-VL\nemploys three innovative approaches: (1) PlanAnno-V framework for high-quality\nVQA data synthesis, (2) Critical Point Thinking to reduce hallucinations\nthrough structured verification, and (3) comprehensive training methodology\ncombining Supervised Fine-Tuning with frozen vision encoder parameters. Through\nsystematic evaluation on our proposed PlanBench-V benchmark, we demonstrate\nthat PlanGPT-VL significantly outperforms general-purpose state-of-the-art VLMs\nin specialized planning map interpretation tasks, offering urban planning\nprofessionals a reliable tool for map analysis, assessment, and educational\napplications while maintaining high factual accuracy. Our lightweight 7B\nparameter model achieves comparable performance to models exceeding 72B\nparameters, demonstrating efficient domain specialization without sacrificing\nperformance.", "published": "2025-05-20 15:14:47", "link": "http://arxiv.org/abs/2505.14481v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Subgroup Disparities in Multi-Label Speech Emotion Recognition: A Pseudo-Labeling and Unsupervised Learning Approach", "abstract": "While subgroup disparities and performance bias are increasingly studied in\ncomputational research, fairness in categorical Speech Emotion Recognition\n(SER) remains underexplored. Existing methods often rely on explicit\ndemographic labels, which are difficult to obtain due to privacy concerns. To\naddress this limitation, we introduce an Implicit Demography Inference (IDI)\nmodule that leverages pseudo-labeling from a pre-trained model and unsupervised\nlearning using k-means clustering to mitigate bias in SER. Our experiments show\nthat pseudo-labeling IDI reduces subgroup disparities, improving fairness\nmetrics by over 33% with less than a 3% decrease in SER accuracy. Also, the\nunsupervised IDI yields more than a 26% improvement in fairness metrics with a\ndrop of less than 4% in SER performance. Further analyses reveal that the\nunsupervised IDI consistently mitigates race and age disparities, demonstrating\nits potential in scenarios where explicit demographic information is\nunavailable.", "published": "2025-05-20 14:50:44", "link": "http://arxiv.org/abs/2505.14449v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis", "abstract": "Large Language Models (LLMs), despite their remarkable capabilities, are\nhampered by hallucinations. A particularly challenging variant, knowledge\novershadowing, occurs when one piece of activated knowledge inadvertently masks\nanother relevant piece, leading to erroneous outputs even with high-quality\ntraining data. Current understanding of overshadowing is largely confined to\ninference-time observations, lacking deep insights into its origins and\ninternal mechanisms during model training. Therefore, we introduce\nPhantomCircuit, a novel framework designed to comprehensively analyze and\ndetect knowledge overshadowing. By innovatively employing knowledge circuit\nanalysis, PhantomCircuit dissects the internal workings of attention heads,\ntracing how competing knowledge pathways contribute to the overshadowing\nphenomenon and its evolution throughout the training process. Extensive\nexperiments demonstrate PhantomCircuit's effectiveness in identifying such\ninstances, offering novel insights into this elusive hallucination and\nproviding the research community with a new methodological lens for its\npotential mitigation.", "published": "2025-05-20 14:20:30", "link": "http://arxiv.org/abs/2505.14406v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dual Decomposition of Weights and Singular Value Low Rank Adaptation", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical paradigm for\nadapting Large Language Models (LLMs) to downstream tasks, among which Low-rank\nAdaptation (LoRA) represents one of the most widely adopted methodologies.\nHowever, existing LoRA-based approaches exhibit two fundamental limitations:\nunstable training dynamics and inefficient knowledge transfer from pre-trained\nmodels, both stemming from random initialization of adapter parameters. To\novercome these challenges, we propose DuDe, a novel approach that decomposes\nweight matrices into magnitude and direction components, employing Singular\nValue Decomposition (SVD) for principled initialization. Our comprehensive\nevaluation demonstrates DuDe's superior performance and robustness, achieving\nup to 48.35\\% accuracy on MMLU and 62.53\\% ($\\pm$ 1.59) accuracy on GSM8K. Our\ntheoretical analysis and empirical validation collectively demonstrate that\nDuDe's decomposition strategy enhances optimization stability and better\npreserves pre-trained representations, particularly for domain-specific tasks\nrequiring specialized knowledge. The combination of robust empirical\nperformance and rigorous theoretical foundations establishes DuDe as a\nsignificant contribution to PEFT methodologies for LLMs.", "published": "2025-05-20 13:49:15", "link": "http://arxiv.org/abs/2505.14367v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OSoRA: Output-Dimension and Singular-Value Initialized Low-Rank Adaptation", "abstract": "Fine-tuning Large Language Models (LLMs) has become increasingly challenging\ndue to their massive scale and associated computational costs.\nParameter-Efficient Fine-Tuning (PEFT) methodologies have been proposed as\ncomputational alternatives; however, their implementations still require\nsignificant resources. In this paper, we present OSoRA (Output-Dimension and\nSingular-Value Initialized Low-Rank Adaptation), a novel PEFT method for LLMs.\nOSoRA extends Low-Rank Adaptation (LoRA) by integrating Singular Value\nDecomposition (SVD) with learnable scaling vectors in a unified framework. It\nfirst performs an SVD of pre-trained weight matrices, then optimizes an\noutput-dimension vector during training, while keeping the corresponding\nsingular vector matrices frozen. OSoRA substantially reduces computational\nresource requirements by minimizing the number of trainable parameters during\nfine-tuning. Comprehensive evaluations across mathematical reasoning, common\nsense reasoning, and other benchmarks demonstrate that OSoRA achieves\ncomparable or superior performance to state-of-the-art methods like LoRA and\nVeRA, while maintaining a linear parameter scaling even as the rank increases\nto higher dimensions. Our ablation studies further confirm that jointly\ntraining both the singular values and the output-dimension vector is critical\nfor optimal performance.", "published": "2025-05-20 13:34:06", "link": "http://arxiv.org/abs/2505.14350v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Let LLMs Break Free from Overthinking via Self-Braking Tuning", "abstract": "Large reasoning models (LRMs), such as OpenAI o1 and DeepSeek-R1, have\nsignificantly enhanced their reasoning capabilities by generating longer chains\nof thought, demonstrating outstanding performance across a variety of tasks.\nHowever, this performance gain comes at the cost of a substantial increase in\nredundant reasoning during the generation process, leading to high\ncomputational overhead and exacerbating the issue of overthinking. Although\nnumerous existing approaches aim to address the problem of overthinking, they\noften rely on external interventions. In this paper, we propose a novel\nframework, Self-Braking Tuning (SBT), which tackles overthinking from the\nperspective of allowing the model to regulate its own reasoning process, thus\neliminating the reliance on external control mechanisms. We construct a set of\noverthinking identification metrics based on standard answers and design a\nsystematic method to detect redundant reasoning. This method accurately\nidentifies unnecessary steps within the reasoning trajectory and generates\ntraining signals for learning self-regulation behaviors. Building on this\nfoundation, we develop a complete strategy for constructing data with adaptive\nreasoning lengths and introduce an innovative braking prompt mechanism that\nenables the model to naturally learn when to terminate reasoning at an\nappropriate point. Experiments across mathematical benchmarks (AIME, AMC,\nMATH500, GSM8K) demonstrate that our method reduces token consumption by up to\n60% while maintaining comparable accuracy to unconstrained models.", "published": "2025-05-20 16:53:40", "link": "http://arxiv.org/abs/2505.14604v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "How Managers Perceive AI-Assisted Conversational Training for Workplace Communication", "abstract": "Effective workplace communication is essential for managerial success, yet\nmany managers lack access to tailored and sustained training. Although\nAI-assisted communication systems may offer scalable training solutions, little\nis known about how managers envision the role of AI in helping them improve\ntheir communication skills. To investigate this, we designed a conversational\nrole-play system, CommCoach, as a functional probe to understand how managers\nanticipate using AI to practice their communication skills. Through\nsemi-structured interviews, participants emphasized the value of adaptive,\nlow-risk simulations for practicing difficult workplace conversations. They\nalso highlighted opportunities, including human-AI teaming, transparent and\ncontext-aware feedback, and greater control over AI-generated personas.\nAI-assisted communication training should balance personalization, structured\nlearning objectives, and adaptability to different user styles and contexts.\nHowever, achieving this requires carefully navigating tensions between adaptive\nand consistent AI feedback, realism and potential bias, and the open-ended\nnature of AI conversations versus structured workplace discourse.", "published": "2025-05-20 14:51:27", "link": "http://arxiv.org/abs/2505.14452v2", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Sparc3D: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling", "abstract": "High-fidelity 3D object synthesis remains significantly more challenging than\n2D image generation due to the unstructured nature of mesh data and the cubic\ncomplexity of dense volumetric grids. Existing two-stage pipelines-compressing\nmeshes with a VAE (using either 2D or 3D supervision), followed by latent\ndiffusion sampling-often suffer from severe detail loss caused by inefficient\nrepresentations and modality mismatches introduced in VAE. We introduce\nSparc3D, a unified framework that combines a sparse deformable marching cubes\nrepresentation Sparcubes with a novel encoder Sparconv-VAE. Sparcubes converts\nraw meshes into high-resolution ($1024^3$) surfaces with arbitrary topology by\nscattering signed distance and deformation fields onto a sparse cube, allowing\ndifferentiable optimization. Sparconv-VAE is the first modality-consistent\nvariational autoencoder built entirely upon sparse convolutional networks,\nenabling efficient and near-lossless 3D reconstruction suitable for\nhigh-resolution generative modeling through latent diffusion. Sparc3D achieves\nstate-of-the-art reconstruction fidelity on challenging inputs, including open\nsurfaces, disconnected components, and intricate geometry. It preserves\nfine-grained shape details, reduces training and inference cost, and integrates\nnaturally with latent diffusion models for scalable, high-resolution 3D\ngeneration.", "published": "2025-05-20 15:44:54", "link": "http://arxiv.org/abs/2505.14521v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Scaling and Enhancing LLM-based AVSR: A Sparse Mixture of Projectors Approach", "abstract": "Audio-Visual Speech Recognition (AVSR) enhances robustness in noisy\nenvironments by integrating visual cues. While recent advances integrate Large\nLanguage Models (LLMs) into AVSR, their high computational cost hinders\ndeployment in resource-constrained settings. To address this, we propose\nLlama-SMoP, an efficient Multimodal LLM that employs a Sparse Mixture of\nProjectors (SMoP) module to scale model capacity without increasing inference\ncosts. By incorporating sparsely-gated mixture-of-experts (MoE) projectors,\nLlama-SMoP enables the use of smaller LLMs while maintaining strong\nperformance. We explore three SMoP configurations and show that Llama-SMoP DEDR\n(Disjoint-Experts, Disjoint-Routers), which uses modality-specific routers and\nexperts, achieves superior performance on ASR, VSR, and AVSR tasks. Ablation\nstudies confirm its effectiveness in expert activation, scalability, and noise\nrobustness.", "published": "2025-05-20 13:20:55", "link": "http://arxiv.org/abs/2505.14336v2", "categories": ["eess.AS", "cs.CV", "cs.MM", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Unlocking the Power of SAM 2 for Few-Shot Segmentation", "abstract": "Few-Shot Segmentation (FSS) aims to learn class-agnostic segmentation on few\nclasses to segment arbitrary classes, but at the risk of overfitting. To\naddress this, some methods use the well-learned knowledge of foundation models\n(e.g., SAM) to simplify the learning process. Recently, SAM 2 has extended SAM\nby supporting video segmentation, whose class-agnostic matching ability is\nuseful to FSS. A simple idea is to encode support foreground (FG) features as\nmemory, with which query FG features are matched and fused. Unfortunately, the\nFG objects in different frames of SAM 2's video data are always the same\nidentity, while those in FSS are different identities, i.e., the matching step\nis incompatible. Therefore, we design Pseudo Prompt Generator to encode pseudo\nquery memory, matching with query features in a compatible way. However, the\nmemories can never be as accurate as the real ones, i.e., they are likely to\ncontain incomplete query FG, and some unexpected query background (BG)\nfeatures, leading to wrong segmentation. Hence, we further design Iterative\nMemory Refinement to fuse more query FG features into the memory, and devise a\nSupport-Calibrated Memory Attention to suppress the unexpected query BG\nfeatures in memory. Extensive experiments have been conducted on PASCAL-5$^i$\nand COCO-20$^i$ to validate the effectiveness of our design, e.g., the 1-shot\nmIoU can be 4.2% better than the best baseline.", "published": "2025-05-20 09:02:53", "link": "http://arxiv.org/abs/2505.14100v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Selective Structured State Space for Multispectral-fused Small Target Detection", "abstract": "Target detection in high-resolution remote sensing imagery faces challenges\ndue to the low recognition accuracy of small targets and high computational\ncosts. The computational complexity of the Transformer architecture increases\nquadratically with image resolution, while Convolutional Neural Networks (CNN)\narchitectures are forced to stack deeper convolutional layers to expand their\nreceptive fields, leading to an explosive growth in computational demands. To\naddress these computational constraints, we leverage Mamba's linear complexity\nfor efficiency. However, Mamba's performance declines for small targets,\nprimarily because small targets occupy a limited area in the image and have\nlimited semantic information. Accurate identification of these small targets\nnecessitates not only Mamba's global attention capabilities but also the\nprecise capture of fine local details. To this end, we enhance Mamba by\ndeveloping the Enhanced Small Target Detection (ESTD) module and the\nConvolutional Attention Residual Gate (CARG) module. The ESTD module bolsters\nlocal attention to capture fine-grained details, while the CARG module, built\nupon Mamba, emphasizes spatial and channel-wise information, collectively\nimproving the model's ability to capture distinctive representations of small\ntargets. Additionally, to highlight the semantic representation of small\ntargets, we design a Mask Enhanced Pixel-level Fusion (MEPF) module for\nmultispectral fusion, which enhances target features by effectively fusing\nvisible and infrared multimodal information.", "published": "2025-05-20 07:39:27", "link": "http://arxiv.org/abs/2505.14043v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On near optimal colorable graphs", "abstract": "A class of graphs $\\cal G$ is said to be \\emph{near optimal colorable} if\nthere exists a constant $c\\in \\mathbb{N}$ such that every graph $G\\in \\cal G$\nsatisfies $\\chi(G) \\leq \\max\\{c, \\omega(G)\\}$, where $\\chi(G)$ and $\\omega(G)$\nrespectively denote the chromatic number and clique number of $G$. The class of\nnear optimal colorable graphs is an important subclass of the class of\n$\\chi$-bounded graphs which is well-studied in the literature. In this paper,\nwe show that the class of ($F, K_4-e$)-free graphs is near optimal colorable,\nwhere $F\\in \\{P_1+2P_2,2P_1+P_3,3P_1+P_2\\}$. Furthermore, using these results\nwith some earlier known results, we also provide an alternate proof to the fact\nthat the \\textsc{Chromatic Number} problem for the class of ($F, K_4-e$)-free\ngraphs is solvable in polynomial time, where $F\\in\n\\{P_1+2P_2,2P_1+P_3,3P_1+P_2\\}$.", "published": "2025-05-20 04:59:23", "link": "http://arxiv.org/abs/2505.13932v2", "categories": ["cs.DM", "math.CO"], "primary_category": "cs.DM"}
{"title": "A composition theory for upward planar orders", "abstract": "An upward planar order on an acyclic directed graph $G$ is a special linear\nextension of the edge poset of $G$ that satisfies the nesting condition. This\norder was introduced to combinatorially characterize upward plane graphs and\nprogressive plane graphs (commonly known as plane string diagrams). In this\npaper, motivated by the theory of graphical calculus for monoidal categories,\nwe establish a composition theory for upward planar orders. The main result is\nthat the composition of upward planar orders is an upward planar order. This\ntheory provides a practical method to calculate the upward planar order of a\nprogressive plane graph or an upward plane graph.", "published": "2025-05-20 03:20:25", "link": "http://arxiv.org/abs/2505.13865v2", "categories": ["math.CO", "cs.DM", "math.CT"], "primary_category": "math.CO"}
{"title": "An Asymptotic Equation Linking WAIC and WBIC in Singular Models", "abstract": "In statistical learning, models are classified as regular or singular\ndepending on whether the mapping from parameters to probability distributions\nis injective. Most models with hierarchical structures or latent variables are\nsingular, for which conventional criteria such as the Akaike Information\nCriterion and the Bayesian Information Criterion are inapplicable due to the\nbreakdown of normal approximations for the likelihood and posterior. To address\nthis, the Widely Applicable Information Criterion (WAIC) and the Widely\nApplicable Bayesian Information Criterion (WBIC) have been proposed. Since WAIC\nand WBIC are computed using posterior distributions at different temperature\nsettings, separate posterior sampling is generally required. In this paper, we\ntheoretically derive an asymptotic equation that links WAIC and WBIC, despite\ntheir dependence on different posteriors. This equation yields an\nasymptotically unbiased expression of WAIC in terms of the posterior\ndistribution used for WBIC. The result clarifies the structural relationship\nbetween these criteria within the framework of singular learning theory, and\ndeepens understanding of their asymptotic behavior. This theoretical\ncontribution provides a foundation for future developments in the computational\nefficiency of model selection in singular models.", "published": "2025-05-20 04:06:43", "link": "http://arxiv.org/abs/2505.13902v2", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62F15, 62R01"], "primary_category": "stat.ML"}
{"title": "MatchDance: Collaborative Mamba-Transformer Architecture Matching for High-Quality 3D Dance Synthesis", "abstract": "Music-to-dance generation represents a challenging yet pivotal task at the\nintersection of choreography, virtual reality, and creative content generation.\nDespite its significance, existing methods face substantial limitation in\nachieving choreographic consistency. To address the challenge, we propose\nMatchDance, a novel framework for music-to-dance generation that constructs a\nlatent representation to enhance choreographic consistency. MatchDance employs\na two-stage design: (1) a Kinematic-Dynamic-based Quantization Stage (KDQS),\nwhich encodes dance motions into a latent representation by Finite Scalar\nQuantization (FSQ) with kinematic-dynamic constraints and reconstructs them\nwith high fidelity, and (2) a Hybrid Music-to-Dance Generation Stage(HMDGS),\nwhich uses a Mamba-Transformer hybrid architecture to map music into the latent\nrepresentation, followed by the KDQS decoder to generate 3D dance motions.\nAdditionally, a music-dance retrieval framework and comprehensive metrics are\nintroduced for evaluation. Extensive experiments on the FineDance dataset\ndemonstrate state-of-the-art performance. Code will be released upon\nacceptance.", "published": "2025-05-20 11:30:28", "link": "http://arxiv.org/abs/2505.14222v2", "categories": ["cs.SD", "cs.GR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models", "abstract": "Jailbreak attacks to Large audio-language models (LALMs) are studied\nrecently, but they achieve suboptimal effectiveness, applicability, and\npracticability, particularly, assuming that the adversary can fully manipulate\nuser prompts. In this work, we first conduct an extensive experiment showing\nthat advanced text jailbreak attacks cannot be easily ported to end-to-end\nLALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a\nnovel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio\ndoes not need to align with user prompts in the time axis by crafting suffixal\njailbreak audios; (2) universality: a single jailbreak perturbation is\neffective for different prompts by incorporating multiple prompts into\nperturbation generation; (3) stealthiness: the malicious intent of jailbreak\naudios will not raise the awareness of victims by proposing various intent\nconcealment strategies; and (4) over-the-air robustness: the jailbreak audios\nremain effective when being played over the air by incorporating the\nreverberation distortion effect with room impulse response into the generation\nof the perturbations. In contrast, all prior audio jailbreak attacks cannot\noffer asynchrony, universality, stealthiness, or over-the-air robustness.\nMoreover, AudioJailbreak is also applicable to the adversary who cannot fully\nmanipulate user prompts, thus has a much broader attack scenario. Extensive\nexperiments with thus far the most LALMs demonstrate the high effectiveness of\nAudioJailbreak. We highlight that our work peeks into the security implications\nof audio jailbreak attacks against LALMs, and realistically fosters improving\ntheir security robustness. The implementation and audio samples are available\nat our website https://audiojailbreak.github.io/AudioJailbreak.", "published": "2025-05-20 09:10:45", "link": "http://arxiv.org/abs/2505.14103v2", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
{"title": "Recreating Neural Activity During Speech Production with Language and Speech Model Embeddings", "abstract": "Understanding how neural activity encodes speech and language production is a\nfundamental challenge in neuroscience and artificial intelligence. This study\ninvestigates whether embeddings from large-scale, self-supervised language and\nspeech models can effectively reconstruct high-gamma neural activity\ncharacteristics, key indicators of cortical processing, recorded during speech\nproduction. We leverage pre-trained embeddings from deep learning models\ntrained on linguistic and acoustic data to represent high-level speech features\nand map them onto these high-gamma signals. We analyze the extent to which\nthese embeddings preserve the spatio-temporal dynamics of brain activity.\nReconstructed neural signals are evaluated against high-gamma ground-truth\nactivity using correlation metrics and signal reconstruction quality\nassessments. The results indicate that high-gamma activity can be effectively\nreconstructed using large language and speech model embeddings in all study\nparticipants, generating Pearson's correlation coefficients ranging from 0.79\nto 0.99.", "published": "2025-05-20 08:31:41", "link": "http://arxiv.org/abs/2505.14074v2", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Robustness of Boolean networks to update modes: an application to hereditary angioedema", "abstract": "Many familial diseases are caused by genetic accidents, which affect both the\ngenome and its epigenetic environment, expressed as an interaction graph\nbetween the genes as that involved in one familial disease we shall study, the\nhereditary angioedema. The update of the gene states at the vertices of this\ngraph (1 if a gene is activated, 0 if it is inhibited) can be done in multiple\nways, well studied over the last two decades: parallel, sequential,\nblock-sequential, block-parallel, random, etc. We will study a particular\ngraph, related to the familial disease proposed as an example, which has\nsubgraphs which activate in an intricate manner (\\emph{i.e.}, in an alternating\nblock-parallel mode, with one core constantly updated and two complementary\nsubsets of genes alternating their updating), of which we will study the\nstructural aspects, robust or unstable, in relation to some classical periodic\nupdate modes.", "published": "2025-05-20 21:15:50", "link": "http://arxiv.org/abs/2505.14923v1", "categories": ["cs.DM", "37N25, 68R01, 92B20", "G.2.0; G.2.3; J.3"], "primary_category": "cs.DM"}
{"title": "Privacy Preserving Conversion Modeling in Data Clean Room", "abstract": "In the realm of online advertising, accurately predicting the conversion rate\n(CVR) is crucial for enhancing advertising efficiency and user satisfaction.\nThis paper addresses the challenge of CVR prediction while adhering to user\nprivacy preferences and advertiser requirements. Traditional methods face\nobstacles such as the reluctance of advertisers to share sensitive conversion\ndata and the limitations of model training in secure environments like data\nclean rooms. We propose a novel model training framework that enables\ncollaborative model training without sharing sample-level gradients with the\nadvertising platform. Our approach introduces several innovative components:\n(1) utilizing batch-level aggregated gradients instead of sample-level\ngradients to minimize privacy risks; (2) applying adapter-based\nparameter-efficient fine-tuning and gradient compression to reduce\ncommunication costs; and (3) employing de-biasing techniques to train the model\nunder label differential privacy, thereby maintaining accuracy despite\nprivacy-enhanced label perturbations. Our experimental results, conducted on\nindustrial datasets, demonstrate that our method achieves competitive ROCAUC\nperformance while significantly decreasing communication overhead and complying\nwith both advertiser privacy requirements and user privacy choices. This\nframework establishes a new standard for privacy-preserving, high-performance\nCVR prediction in the digital advertising landscape.", "published": "2025-05-20 22:38:50", "link": "http://arxiv.org/abs/2505.14959v1", "categories": ["cs.LG", "cs.IR", "H.4"], "primary_category": "cs.LG"}
{"title": "Personalized Diffusion Model Reshapes Cold-Start Bundle Recommendation", "abstract": "Bundle recommendation aims to recommend a set of items to each user. However,\nthe sparser interactions between users and bundles raise a big challenge,\nespecially in cold-start scenarios. Traditional collaborative filtering methods\ndo not work well for this kind of problem because these models rely on\ninteractions to update the latent embedding, which is hard to work in a\ncold-start setting. We propose a new approach (DisCo), which relies on a\npersonalized Diffusion backbone, enhanced by disentangled aspects for the\nuser's interest, to generate a bundle in distribution space for each user to\ntackle the cold-start challenge. During the training phase, DisCo adjusts an\nadditional objective loss term to avoid bias, a prevalent issue while using the\ngenerative model for top-$K$ recommendation purposes. Our empirical experiments\nshow that DisCo outperforms five comparative baselines by a large margin on\nthree real-world datasets. Thereby, this study devises a promising framework\nand essential viewpoints in cold-start recommendation. Our materials for\nreproducibility are available at: https://github.com/bt-nghia/DisCo.", "published": "2025-05-20 20:52:31", "link": "http://arxiv.org/abs/2505.14901v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "DisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management", "abstract": "Effective disaster management requires timely access to accurate and\ncontextually relevant information. Existing Information Retrieval (IR)\nbenchmarks, however, focus primarily on general or specialized domains, such as\nmedicine or finance, neglecting the unique linguistic complexity and diverse\ninformation needs encountered in disaster management scenarios. To bridge this\ngap, we introduce DisastIR, the first comprehensive IR evaluation benchmark\nspecifically tailored for disaster management. DisastIR comprises 9,600 diverse\nuser queries and more than 1.3 million labeled query-passage pairs, covering 48\ndistinct retrieval tasks derived from six search intents and eight general\ndisaster categories that include 301 specific event types. Our evaluations of\n30 state-of-the-art retrieval models demonstrate significant performance\nvariances across tasks, with no single model excelling universally.\nFurthermore, comparative analyses reveal significant performance gaps between\ngeneral-domain and disaster management-specific tasks, highlighting the\nnecessity of disaster management-specific benchmarks for guiding IR model\nselection to support effective decision-making in disaster management\nscenarios. All source codes and DisastIR are available at\nhttps://github.com/KaiYin97/Disaster_IR.", "published": "2025-05-20 20:11:00", "link": "http://arxiv.org/abs/2505.15856v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "VisTopics: A Visual Semantic Unsupervised Approach to Topic Modeling of Video and Image Data", "abstract": "Understanding visual narratives is crucial for examining the evolving\ndynamics of media representation. This study introduces VisTopics, a\ncomputational framework designed to analyze large-scale visual datasets through\nan end-to-end pipeline encompassing frame extraction, deduplication, and\nsemantic clustering. Applying VisTopics to a dataset of 452 NBC News videos\nresulted in reducing 11,070 frames to 6,928 deduplicated frames, which were\nthen semantically analyzed to uncover 35 topics ranging from political events\nto environmental crises. By integrating Latent Dirichlet Allocation with\ncaption-based semantic analysis, VisTopics demonstrates its potential to\nunravel patterns in visual framing across diverse contexts. This approach\nenables longitudinal studies and cross-platform comparisons, shedding light on\nthe intersection of media, technology, and public discourse. The study\nvalidates the method's reliability through human coding accuracy metrics and\nemphasizes its scalability for communication research. By bridging the gap\nbetween visual representation and semantic meaning, VisTopics provides a\ntransformative tool for advancing the methodological toolkit in computational\nmedia studies. Future research may leverage VisTopics for comparative analyses\nacross media outlets or geographic regions, offering insights into the shifting\nlandscapes of media narratives and their societal implications.", "published": "2025-05-20 19:59:41", "link": "http://arxiv.org/abs/2505.14868v1", "categories": ["cs.IR", "cs.CV", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning", "abstract": "Retrieval-augmented generation (RAG) enhances the text generation\ncapabilities of large language models (LLMs) by integrating external knowledge\nand up-to-date information. However, traditional RAG systems are limited by\nstatic workflows and lack the adaptability required for multistep reasoning and\ncomplex task management. To address these limitations, agentic RAG systems\n(e.g., DeepResearch) have been proposed, enabling dynamic retrieval strategies,\niterative context refinement, and adaptive workflows for handling complex\nsearch queries beyond the capabilities of conventional RAG. Recent advances,\nsuch as Search-R1, have demonstrated promising gains using outcome-based\nreinforcement learning, where the correctness of the final answer serves as the\nreward signal. Nevertheless, such outcome-supervised agentic RAG methods face\nchallenges including low exploration efficiency, gradient conflict, and sparse\nreward signals. To overcome these challenges, we propose to utilize\nfine-grained, process-level rewards to improve training stability, reduce\ncomputational costs, and enhance efficiency. Specifically, we introduce a novel\nmethod ReasonRAG that automatically constructs RAG-ProGuide, a high-quality\ndataset providing process-level rewards for (i) query generation, (ii) evidence\nextraction, and (iii) answer generation, thereby enhancing model inherent\ncapabilities via process-supervised reinforcement learning. With the\nprocess-level policy optimization, the proposed framework empowers LLMs to\nautonomously invoke search, generate queries, extract relevant evidence, and\nproduce final answers. Compared to existing approaches such as Search-R1 and\ntraditional RAG systems, ReasonRAG, leveraging RAG-ProGuide, achieves superior\nperformance on five benchmark datasets using only 5k training instances,\nsignificantly fewer than the 90k training instances required by Search-R1.", "published": "2025-05-20 08:21:00", "link": "http://arxiv.org/abs/2505.14069v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Improved Classical Shadow Tomography Using Quantum Computation", "abstract": "Classical shadow tomography (CST) involves obtaining enough classical\ndescriptions of an unknown state via quantum measurements to predict the\noutcome of a set of quantum observables. CST has numerous applications,\nparticularly in algorithms that utilize quantum data for tasks such as\nlearning, detection, and optimization. This paper introduces a new CST\nprocedure that exponentially reduces the space complexity and quadratically\nimproves the running time of CST with single-copy measurements. The approach\nutilizes a quantum-to-classical-to-quantum process to prepare quantum states\nthat represent shadow snapshots, which can then be directly measured by the\nobservables of interest. With that, calculating large matrix traces is avoided,\nresulting in improvements in running time and space complexity. The paper\npresents analyses of the proposed methods for CST, with Pauli measurements and\nClifford circuits.", "published": "2025-05-20 22:28:46", "link": "http://arxiv.org/abs/2505.14953v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Sequential Interval Passing for Compressed Sensing", "abstract": "The reconstruction of sparse signals from a limited set of measurements poses\na significant challenge as it necessitates a solution to an underdetermined\nsystem of linear equations. Compressed sensing (CS) deals with sparse signal\nreconstruction using techniques such as linear programming (LP) and iterative\nmessage passing schemes. The interval passing algorithm (IPA) is an attractive\nCS approach due to its low complexity when compared to LP. In this paper, we\npropose a sequential IPA that is inspired by sequential belief propagation\ndecoding of low-density-parity-check (LDPC) codes used for forward error\ncorrection in channel coding. In the sequential setting, each check node (CN)\nin the Tanner graph of an LDPC measurement matrix is scheduled one at a time in\nevery iteration, as opposed to the standard ``flooding'' interval passing\napproach in which all CNs are scheduled at once per iteration. The sequential\nscheme offers a significantly lower message passing complexity compared to\nflooding IPA on average, and for some measurement matrix and signal sparsity, a\ncomplexity reduction of 36% is achieved. We show both analytically and\nnumerically that the reconstruction accuracy of the IPA is not compromised by\nadopting our sequential scheduling approach.", "published": "2025-05-20 21:49:28", "link": "http://arxiv.org/abs/2505.14936v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Energy-Efficient Design for Downlink Pinching-Antenna Systems with QoS Guarantee", "abstract": "Pinching antennas have recently garnered significant attention due to their\nability to dynamically reconfigure wireless propagation environments. Despite\nnotable advancements in this area, the exploration of energy efficiency (EE)\nmaximization in pinching-antenna systems remains relatively underdeveloped. In\nthis paper, we address the EE maximization problem in a downlink time-division\nmultiple access (TDMA)-based multi-user system employing one waveguide and\nmultiple pinching antennas, where each user is subject to a minimum rate\nconstraint to ensure quality-of-service. The formulated optimization problem\njointly considers transmit power and time allocations as well as the\npositioning of pinching antennas, resulting in a non-convex problem. To tackle\nthis challenge, we first obtain the optimal positions of the pinching antennas.\nBased on this, we establish a feasibility condition for the system.\nSubsequently, the joint power and time allocation problem is decomposed into\ntwo subproblems, which are solved iteratively until convergence. Specifically,\nthe power allocation subproblem is addressed through an iterative approach,\nwhere a semi-analytical solution is obtained in each iteration. Likewise, a\nsemi-analytical solution is derived for the time allocation subproblem.\nNumerical simulations demonstrate that the proposed pinching-antenna-based\nstrategy significantly outperforms both conventional fixed-antenna systems and\nother benchmark pinching-antenna schemes in terms of EE.", "published": "2025-05-20 20:58:08", "link": "http://arxiv.org/abs/2505.14904v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Movable Antenna Aided Full-Duplex ISAC System with Self-Interference Mitigation", "abstract": "Movable antenna (MA) has shown significant potential for improving the\nperformance of integrated sensing and communication (ISAC) systems. In this\npaper, we model an MA-aided ISAC system operating in a communication\nfull-duplex mono-static sensing framework. The self-interference channel is\nmodeled as a function of the antenna position vectors under the near-field\nchannel condition. We develop an optimization problem to maximize the weighted\nsum of downlink and uplink communication rates alongside the mutual information\nrelevant to the sensing task. To address this highly non-convex problem, we\nemploy the fractional programming (FP) method and propose an alternating\noptimization (AO)-based algorithm that jointly optimizes the beamforming, user\npower allocation, and antenna positions at the transceivers. Given the\nsensitivity of the AO-based algorithm to the initial antenna positions, a\nPSO-based algorithm is proposed to explore superior sub-optimal antenna\npositions within the feasible region. Numerical results indicate that the\nproposed algorithms enable the MA system to effectively leverage the antenna\nposition flexibility for accurate beamforming in a complex ISAC scenario. This\nenhances the system's self-interference cancellation (SIC) capabilities and\nmarkedly improves its overall performance and reliability compared to\nconventional fixed-position antenna designs.", "published": "2025-05-20 18:52:12", "link": "http://arxiv.org/abs/2505.14830v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation", "abstract": "We present MAATS, a Multi Agent Automated Translation System that leverages\nthe Multidimensional Quality Metrics (MQM) framework as a fine-grained signal\nfor error detection and refinement. MAATS employs multiple specialized AI\nagents, each focused on a distinct MQM category (e.g., Accuracy, Fluency,\nStyle, Terminology), followed by a synthesis agent that integrates the\nannotations to iteratively refine translations. This design contrasts with\nconventional single-agent methods that rely on self-correction.\n  Evaluated across diverse language pairs and Large Language Models (LLMs),\nMAATS outperforms zero-shot and single-agent baselines with statistically\nsignificant gains in both automatic metrics and human assessments. It excels\nparticularly in semantic accuracy, locale adaptation, and linguistically\ndistant language pairs. Qualitative analysis highlights its strengths in\nmulti-layered error diagnosis, omission detection across perspectives, and\ncontext-aware refinement. By aligning modular agent roles with interpretable\nMQM dimensions, MAATS narrows the gap between black-box LLMs and human\ntranslation workflows, shifting focus from surface fluency to deeper semantic\nand contextual fidelity.", "published": "2025-05-20 19:29:05", "link": "http://arxiv.org/abs/2505.14848v1", "categories": ["cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Cooperative Bargaining Games Without Utilities: Mediated Solutions from Direction Oracles", "abstract": "Cooperative bargaining games are widely used to model resource allocation and\nconflict resolution. Traditional solutions assume the mediator can access\nagents utility function values and gradients. However, there is an increasing\nnumber of settings, such as human AI interactions, where utility values may be\ninaccessible or incomparable due to unknown, nonaffine transformations. To\nmodel such settings, we consider that the mediator has access only to agents\nmost preferred directions, i.e., normalized utility gradients in the decision\nspace. To this end, we propose a cooperative bargaining algorithm where a\nmediator has access to only the direction oracle of each agent. We prove that\nunlike popular approaches such as the Nash and Kalai Smorodinsky bargaining\nsolutions, our approach is invariant to monotonic nonaffine transformations,\nand that under strong convexity and smoothness assumptions, this approach\nenjoys global asymptotic convergence to Pareto stationary solutions. Moreover,\nwe show that the bargaining solutions found by our algorithm also satisfy the\naxioms of symmetry and (under slightly stronger conditions) independence of\nirrelevant alternatives, which are popular in the literature. Finally, we\nconduct experiments in two domains, multi agent formation assignment and\nmediated stock portfolio allocation, which validate these theoretic results.\nAll code for our experiments can be found at\nhttps://github.com/suryakmurthy/dibs_bargaining.", "published": "2025-05-20 18:29:49", "link": "http://arxiv.org/abs/2505.14817v1", "categories": ["cs.GT", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Integration of TinyML and LargeML: A Survey of 6G and Beyond", "abstract": "The transition from 5G networks to 6G highlights a significant demand for\nmachine learning (ML). Deep learning models, in particular, have seen wide\napplication in mobile networking and communications to support advanced\nservices in emerging wireless environments, such as smart healthcare, smart\ngrids, autonomous vehicles, aerial platforms, digital twins, and the metaverse.\nThe rapid expansion of Internet-of-Things (IoT) devices, many with limited\ncomputational capabilities, has accelerated the development of tiny machine\nlearning (TinyML) and resource-efficient ML approaches for cost-effective\nservices. However, the deployment of large-scale machine learning (LargeML)\nsolutions require major computing resources and complex management strategies\nto support extensive IoT services and ML-generated content applications.\nConsequently, the integration of TinyML and LargeML is projected as a promising\napproach for future seamless connectivity and efficient resource management.\n  Although the integration of TinyML and LargeML shows abundant potential,\nseveral challenges persist, including performance optimization, practical\ndeployment strategies, effective resource management, and security\nconsiderations. In this survey, we review and analyze the latest research aimed\nat enabling the integration of TinyML and LargeML models for the realization of\nsmart services and applications in future 6G networks and beyond. The paper\nconcludes by outlining critical challenges and identifying future research\ndirections for the holistic integration of TinyML and LargeML in\nnext-generation wireless networks.", "published": "2025-05-20 10:54:39", "link": "http://arxiv.org/abs/2505.15854v1", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.LG", "cs.MA"], "primary_category": "cs.NI"}
{"title": "Fast Newton Transform: Interpolation in Downward Closed Polynomial Spaces", "abstract": "We present the Fast Newton Transform (FNT), an algorithm for performing\n$m$-variate Newton interpolation in downward closed polynomial spaces with time\ncomplexity $\\mathcal{O}(|A|m\\overline{n})$. Here, $A$ is a downward closed set\nof cardinality $|A|$ equal to the dimension of the associated downward closed\npolynomial space $\\Pi_A$, where $\\overline{n}$ denotes the mean of the maximum\npolynomial degrees across the spatial dimensions. For functions being analytic\nin an open Bernstein poly-ellipse, geometric approximation rates apply when\ninterpolating in non-tensorial Leja-ordered Chebyshev-Lobatto grids or Leja\nnodes. To mitigate the curse of dimensionality, we utilize $\\ell^p$-sets, with\nthe Euclidean case $(p=2)$ turning out to be the pivotal choice, leading to\n$|A|/(n+1)^m \\in \\mathcal{O}(e^{-m})$. Expanding non-periodic functions, the\nFNT complements the approximation capabilities of the Fast Fourier Transform\n(FFT). Choosing $\\ell^2$-sets for $A$ renders the FNT time complexity to be\nless than the FFT time complexity $\\mathcal{O}((n+1)^m m \\log(n))$ in a range\nof $n$, behaving as $\\mathcal{O}(m e^m)$. Maintaining this advantage true for\nthe differentials, the FNT sets a new standard in $m$-variate interpolation and\napproximation practice.", "published": "2025-05-20 21:03:33", "link": "http://arxiv.org/abs/2505.14909v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Partition-wise Graph Filtering: A Unified Perspective Through the Lens of Graph Coarsening", "abstract": "Filtering-based graph neural networks (GNNs) constitute a distinct class of\nGNNs that employ graph filters to handle graph-structured data, achieving\nnotable success in various graph-related tasks. Conventional methods adopt a\ngraph-wise filtering paradigm, imposing a uniform filter across all nodes, yet\nrecent findings suggest that this rigid paradigm struggles with heterophilic\ngraphs. To overcome this, recent works have introduced node-wise filtering,\nwhich assigns distinct filters to individual nodes, offering enhanced\nadaptability. However, a fundamental gap remains: a comprehensive framework\nunifying these two strategies is still absent, limiting theoretical insights\ninto the filtering paradigms. Moreover, through the lens of Contextual\nStochastic Block Model, we reveal that a synthesis of graph-wise and node-wise\nfiltering provides a sufficient solution for classification on graphs\nexhibiting both homophily and heterophily, suggesting the risk of excessive\nparameterization and potential overfitting with node-wise filtering. To address\nthe limitations, this paper introduces Coarsening-guided Partition-wise\nFiltering (CPF). CPF innovates by performing filtering on node partitions. The\nmethod begins with structure-aware partition-wise filtering, which filters node\npartitions obtained via graph coarsening algorithms, and then performs\nfeature-aware partition-wise filtering, refining node embeddings via filtering\non clusters produced by $k$-means clustering over features. In-depth analysis\nis conducted for each phase of CPF, showing its superiority over other\nparadigms. Finally, benchmark node classification experiments, along with a\nreal-world graph anomaly detection application, validate CPF's efficacy and\npractical utility.", "published": "2025-05-20 07:30:45", "link": "http://arxiv.org/abs/2505.14033v2", "categories": ["cs.LG", "cs.NA", "eess.SP", "math.NA"], "primary_category": "cs.LG"}
{"title": "Convergence Guarantees for Gradient-Based Training of Neural PDE Solvers: From Linear to Nonlinear PDEs", "abstract": "We present a unified convergence theory for gradient-based training of neural\nnetwork methods for partial differential equations (PDEs), covering both\nphysics-informed neural networks (PINNs) and the Deep Ritz method. For linear\nPDEs, we extend the neural tangent kernel (NTK) framework for PINNs to\nestablish global convergence guarantees for a broad class of linear operators.\nFor nonlinear PDEs, we prove convergence to critical points via the\n\\L{}ojasiewicz inequality under the random feature model, eliminating the need\nfor strong over-parameterization and encompassing both gradient flow and\nimplicit gradient descent dynamics. Our results further reveal that the random\nfeature model exhibits an implicit regularization effect, preventing parameter\ndivergence to infinity. Theoretical findings are corroborated by numerical\nexperiments, providing new insights into the training dynamics and robustness\nof neural network PDE solvers.", "published": "2025-05-20 06:55:41", "link": "http://arxiv.org/abs/2505.14002v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Geodesic distance approximation using a surface finite element method for the $p$-Laplacian", "abstract": "We use the $p$-Laplacian with large $p$-values in order to approximate\ngeodesic distances to features on surfaces. This differs from Fayolle and\nBelyaev's (2018) [1] computational results using the $p$-Laplacian for the\ndistance-to-surface problem. Our approach appears to offer some distinct\nadvantages over other popular PDE-based distance function approximation\nmethods. We employ a surface finite element scheme and demonstrate numerical\nconvergence to the true geodesic distance functions. We check that our\nnumerical results adhere to the triangle inequality and examine robustness\nagainst geometric noise such as vertex perturbations. We also present\ncomparisons of our method with the heat method from Crane et al. [2] and the\nclassical polyhedral method from Mitchell et al. [3].", "published": "2025-05-20 02:29:55", "link": "http://arxiv.org/abs/2505.14732v1", "categories": ["cs.GR", "cs.NA", "math.NA"], "primary_category": "cs.GR"}
{"title": "The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents", "abstract": "The pursuit of alpha returns that exceed market benchmarks has undergone a\nprofound transformation, evolving from intuition-driven investing to\nautonomous, AI powered systems. This paper introduces a comprehensive five\nstage taxonomy that traces this progression across manual strategies,\nstatistical models, classical machine learning, deep learning, and agentic\narchitectures powered by large language models (LLMs). Unlike prior surveys\nfocused narrowly on modeling techniques, this review adopts a system level\nlens, integrating advances in representation learning, multimodal data fusion,\nand tool augmented LLM agents. The strategic shift from static predictors to\ncontextaware financial agents capable of real time reasoning, scenario\nsimulation, and cross modal decision making is emphasized. Key challenges in\ninterpretability, data fragility, governance, and regulatory compliance areas\ncritical to production deployment are examined. The proposed taxonomy offers a\nunified framework for evaluating maturity, aligning infrastructure, and guiding\nthe responsible development of next generation alpha systems.", "published": "2025-05-20 00:51:43", "link": "http://arxiv.org/abs/2505.14727v1", "categories": ["cs.LG", "q-fin.CP", "91G70 Statistical methods, risk measures 91B84 Economic models\n  (financial models, industrial models, growth models)", "I.2.6; I.5.1; I.2.7"], "primary_category": "cs.LG"}
{"title": "Reliable Decision Support with LLMs: A Framework for Evaluating Consistency in Binary Text Classification Applications", "abstract": "This study introduces a framework for evaluating consistency in large\nlanguage model (LLM) binary text classification, addressing the lack of\nestablished reliability assessment methods. Adapting psychometric principles,\nwe determine sample size requirements, develop metrics for invalid responses,\nand evaluate intra- and inter-rater reliability. Our case study examines\nfinancial news sentiment classification across 14 LLMs (including\nclaude-3-7-sonnet, gpt-4o, deepseek-r1, gemma3, llama3.2, phi4, and\ncommand-r-plus), with five replicates per model on 1,350 articles. Models\ndemonstrated high intra-rater consistency, achieving perfect agreement on\n90-98% of examples, with minimal differences between expensive and economical\nmodels from the same families. When validated against StockNewsAPI labels,\nmodels achieved strong performance (accuracy 0.76-0.88), with smaller models\nlike gemma3:1B, llama3.2:3B, and claude-3-5-haiku outperforming larger\ncounterparts. All models performed at chance when predicting actual market\nmovements, indicating task constraints rather than model limitations. Our\nframework provides systematic guidance for LLM selection, sample size planning,\nand reliability assessment, enabling organizations to optimize resources for\nclassification tasks.", "published": "2025-05-20 21:12:58", "link": "http://arxiv.org/abs/2505.14918v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "LOBSTUR: A Local Bootstrap Framework for Tuning Unsupervised Representations in Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are increasingly used in conjunction with\nunsupervised learning techniques to learn powerful node representations, but\ntheir deployment is hindered by their high sensitivity to hyperparameter tuning\nand the absence of established methodologies for selecting the optimal models.\nTo address these challenges, we propose LOBSTUR-GNN ({\\bf Lo}cal {\\bf B}oot{\\bf\ns}trap for {\\bf T}uning {\\bf U}nsupervised {\\bf R}epresentations in GNNs) i), a\nnovel framework designed to adapt bootstrapping techniques for unsupervised\ngraph representation learning. LOBSTUR-GNN tackles two main challenges: (a)\nadapting the bootstrap edge and feature resampling process to account for local\ngraph dependencies in creating alternative versions of the same graph, and (b)\nestablishing robust metrics for evaluating learned representations without\nground-truth labels. Using locally bootstrapped resampling and leveraging\nCanonical Correlation Analysis (CCA) to assess embedding consistency, LOBSTUR\nprovides a principled approach for hyperparameter tuning in unsupervised GNNs.\nWe validate the effectiveness and efficiency of our proposed method through\nextensive experiments on established academic datasets, showing an 65.9\\%\nimprovement in the classification accuracy compared to an uninformed selection\nof hyperparameters. Finally, we deploy our framework on a real-world\napplication, thereby demonstrating its validity and practical utility in\nvarious settings. \\footnote{The code is available at\n\\href{https://github.com/sowonjeong/lobstur-graph-bootstrap}{github.com/sowonjeong/lobstur-graph-bootstrap}.}", "published": "2025-05-20 19:59:35", "link": "http://arxiv.org/abs/2505.14867v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain", "abstract": "Supervised fine-tuning (SFT) is a standard approach to adapting large\nlanguage models (LLMs) to new domains. In this work, we improve the statistical\nefficiency of SFT by selecting an informative subset of training examples.\nSpecifically, for a fixed budget of training examples, which determines the\ncomputational cost of fine-tuning, we determine the most informative ones. The\nkey idea in our method is to select examples that maximize information gain,\nmeasured by the Hessian of the log-likelihood of the LLM. We approximate it\nefficiently by linearizing the LLM at the last layer using multinomial logistic\nregression models. Our approach is computationally efficient, analyzable, and\nperforms well empirically. We demonstrate this on several problems, and back\nour claims with both quantitative results and an LLM evaluation.", "published": "2025-05-20 18:41:34", "link": "http://arxiv.org/abs/2505.14826v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Assimilative Causal Inference", "abstract": "Causal inference determines cause-and-effect relationships between variables\nand has broad applications across disciplines. Traditional time-series methods\noften reveal causal links only in a time-averaged sense, while ensemble-based\ninformation transfer approaches detect the time evolution of short-term causal\nrelationships but are typically limited to low-dimensional systems. In this\npaper, a new causal inference framework, called assimilative causal inference\n(ACI), is developed. Fundamentally different from the state-of-the-art methods,\nACI uses a dynamical system and a single realization of a subset of the state\nvariables to identify instantaneous causal relationships and the dynamic\nevolution of the associated causal influence range (CIR). Instead of\nquantifying how causes influence effects as done traditionally, ACI solves an\ninverse problem via Bayesian data assimilation, thus tracing causes backward\nfrom observed effects with an implicit Bayesian hypothesis. Causality is\ndetermined by assessing whether incorporating the information of the effect\nvariables reduces the uncertainty in recovering the potential cause variables.\nACI has several desirable features. First, it captures the dynamic interplay of\nvariables, where their roles as causes and effects can shift repeatedly over\ntime. Second, a mathematically justified objective criterion determines the CIR\nwithout empirical thresholds. Third, ACI is scalable to high-dimensional\nproblems by leveraging computationally efficient Bayesian data assimilation\ntechniques. Finally, ACI applies to short time series and incomplete datasets.\nNotably, ACI does not require observations of candidate causes, which is a key\nadvantage since potential drivers are often unknown or unmeasured. The\neffectiveness of ACI is demonstrated by complex dynamical systems showcasing\nintermittency and extreme events.", "published": "2025-05-20 18:40:17", "link": "http://arxiv.org/abs/2505.14825v1", "categories": ["cs.LG", "math.ST", "physics.data-an", "stat.ME", "stat.ML", "stat.TH", "62F15, 62D20, 62M20, 93E11, 93E14, 60H10"], "primary_category": "cs.LG"}
{"title": "Out-of-Distribution Generalization of In-Context Learning: A Low-Dimensional Subspace Perspective", "abstract": "This work aims to demystify the out-of-distribution (OOD) capabilities of\nin-context learning (ICL) by studying linear regression tasks parameterized\nwith low-rank covariance matrices. With such a parameterization, we can model\ndistribution shifts as a varying angle between the subspace of the training and\ntesting covariance matrices. We prove that a single-layer linear attention\nmodel incurs a test risk with a non-negligible dependence on the angle,\nillustrating that ICL is not robust to such distribution shifts. However, using\nthis framework, we also prove an interesting property of ICL: when trained on\ntask vectors drawn from a union of low-dimensional subspaces, ICL can\ngeneralize to any subspace within their span, given sufficiently long prompt\nlengths. This suggests that the OOD generalization ability of Transformers may\nactually stem from the new task lying within the span of those encountered\nduring training. We empirically show that our results also hold for models such\nas GPT-2, and conclude with (i) experiments on how our observations extend to\nnonlinear function classes and (ii) results on how LoRA has the ability to\ncapture distribution shifts.", "published": "2025-05-20 18:15:49", "link": "http://arxiv.org/abs/2505.14808v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Place Cells as Position Embeddings of Multi-Time Random Walk Transition Kernels for Path Planning", "abstract": "The hippocampus orchestrates spatial navigation through collective place cell\nencodings that form cognitive maps. We reconceptualize the population of place\ncells as position embeddings approximating multi-scale symmetric random walk\ntransition kernels: the inner product $\\langle h(x, t), h(y, t) \\rangle =\nq(y|x, t)$ represents normalized transition probabilities, where $h(x, t)$ is\nthe embedding at location $ x $, and $q(y|x, t)$ is the normalized symmetric\ntransition probability over time $t$. The time parameter $\\sqrt{t}$ defines a\nspatial scale hierarchy, mirroring the hippocampal dorsoventral axis. $q(y|x,\nt)$ defines spatial adjacency between $x$ and $y$ at scale or resolution\n$\\sqrt{t}$, and the pairwise adjacency relationships $(q(y|x, t), \\forall x,\ny)$ are reduced into individual embeddings $(h(x, t), \\forall x)$ that\ncollectively form a map of the environment at sale $\\sqrt{t}$. Our framework\nemploys gradient ascent on $q(y|x, t) = \\langle h(x, t), h(y, t)\\rangle$ with\nadaptive scale selection, choosing the time scale with maximal gradient at each\nstep for trap-free, smooth trajectories. Efficient matrix squaring $P_{2t} =\nP_t^2$ builds global representations from local transitions $P_1$ without\nmemorizing past trajectories, enabling hippocampal preplay-like path planning.\nThis produces robust navigation through complex environments, aligning with\nhippocampal navigation. Experimental results show that our model captures place\ncell properties -- field size distribution, adaptability, and remapping --\nwhile achieving computational efficiency. By modeling collective transition\nprobabilities rather than individual place fields, we offer a biologically\nplausible, scalable framework for spatial navigation.", "published": "2025-05-20 18:14:11", "link": "http://arxiv.org/abs/2505.14806v2", "categories": ["q-bio.NC", "cs.LG", "stat.ML"], "primary_category": "q-bio.NC"}
{"title": "Regularized least squares learning with heavy-tailed noise is minimax optimal", "abstract": "This paper examines the performance of ridge regression in reproducing kernel\nHilbert spaces in the presence of noise that exhibits a finite number of higher\nmoments. We establish excess risk bounds consisting of subgaussian and\npolynomial terms based on the well known integral operator framework. The\ndominant subgaussian component allows to achieve convergence rates that have\npreviously only been derived under subexponential noise - a prevalent\nassumption in related work from the last two decades. These rates are optimal\nunder standard eigenvalue decay conditions, demonstrating the asymptotic\nrobustness of regularized least squares against heavy-tailed noise. Our\nderivations are based on a Fuk-Nagaev inequality for Hilbert-space valued\nrandom variables.", "published": "2025-05-20 11:17:54", "link": "http://arxiv.org/abs/2505.14214v2", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "62G08 (Primary) 62G35, 62J07 (Secondary)"], "primary_category": "cs.LG"}
{"title": "A Probabilistic Perspective on Model Collapse", "abstract": "In recent years, model collapse has become a critical issue in language model\ntraining, making it essential to understand the underlying mechanisms driving\nthis phenomenon. In this paper, we investigate recursive parametric model\ntraining from a probabilistic perspective, aiming to characterize the\nconditions under which model collapse occurs and, crucially, how it can be\nmitigated. We conceptualize the recursive training process as a random walk of\nthe model estimate, highlighting how the sample size influences the step size\nand how the estimation procedure determines the direction and potential bias of\nthe random walk. Under mild conditions, we rigorously show that progressively\nincreasing the sample size at each training step is necessary to prevent model\ncollapse. In particular, when the estimation is unbiased, the required growth\nrate follows a superlinear pattern. This rate needs to be accelerated even\nfurther in the presence of substantial estimation bias. Building on this\nprobabilistic framework, we also investigate the probability that recursive\ntraining on synthetic data yields models that outperform those trained solely\non real data. Moreover, we extend these results to general parametric model\nfamily in an asymptotic regime. Finally, we validate our theoretical results\nthrough extensive simulations and a real-world dataset.", "published": "2025-05-20 05:25:29", "link": "http://arxiv.org/abs/2505.13947v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Characterization of Efficient Influence Function for Off-Policy Evaluation Under Optimal Policies", "abstract": "Off-policy evaluation (OPE) provides a powerful framework for estimating the\nvalue of a counterfactual policy using observational data, without the need for\nadditional experimentation. Despite recent progress in robust and efficient OPE\nacross various settings, rigorous efficiency analysis of OPE under an estimated\noptimal policy remains limited. In this paper, we establish a concise\ncharacterization of the efficient influence function (EIF) for the value\nfunction under optimal policy within canonical Markov decision process models.\nSpecifically, we provide the sufficient conditions for the existence of the EIF\nand characterize its expression. We also give the conditions under which the\nEIF does not exist.", "published": "2025-05-20 01:41:44", "link": "http://arxiv.org/abs/2505.13809v2", "categories": ["math.ST", "econ.EM", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis", "abstract": "Customizable multilingual zero-shot singing voice synthesis (SVS) has various\npotential applications in music composition and short video dubbing. However,\nexisting SVS models overly depend on phoneme and note boundary annotations,\nlimiting their robustness in zero-shot scenarios and producing poor transitions\nbetween phonemes and notes. Moreover, they also lack effective multi-level\nstyle control via diverse prompts. To overcome these challenges, we introduce\nTCSinger 2, a multi-task multilingual zero-shot SVS model with style transfer\nand style control based on various prompts. TCSinger 2 mainly includes three\nkey modules: 1) Blurred Boundary Content (BBC) Encoder, predicts duration,\nextends content embedding, and applies masking to the boundaries to enable\nsmooth transitions. 2) Custom Audio Encoder, uses contrastive learning to\nextract aligned representations from singing, speech, and textual prompts. 3)\nFlow-based Custom Transformer, leverages Cus-MOE, with F0 supervision,\nenhancing both the synthesis quality and style modeling of the generated\nsinging voice. Experimental results show that TCSinger 2 outperforms baseline\nmodels in both subjective and objective metrics across multiple related tasks.", "published": "2025-05-20 21:04:10", "link": "http://arxiv.org/abs/2505.14910v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "In-Context Learning Boosts Speech Recognition via Human-like Adaptation to Speakers and Language Varieties", "abstract": "Human listeners readily adjust to unfamiliar speakers and language varieties\nthrough exposure, but do these adaptation benefits extend to state-of-the-art\nspoken language models? We introduce a scalable framework that allows for\nin-context learning (ICL) in Phi-4 Multimodal using interleaved task prompts\nand audio-text pairs, and find that as few as 12 example utterances (~50\nseconds) at inference time reduce word error rates by a relative 19.7% (1.2\npp.) on average across diverse English corpora. These improvements are most\npronounced in low-resource varieties, when the context and target speaker\nmatch, and when more examples are provided--though scaling our procedure yields\ndiminishing marginal returns to context length. Overall, we find that our novel\nICL adaptation scheme (1) reveals a similar performance profile to human\nlisteners, and (2) demonstrates consistent improvements to automatic speech\nrecognition (ASR) robustness across diverse speakers and language backgrounds.\nWhile adaptation succeeds broadly, significant gaps remain for certain\nvarieties, revealing where current models still fall short of human\nflexibility. We release our prompts and code on GitHub.", "published": "2025-05-20 20:20:37", "link": "http://arxiv.org/abs/2505.14887v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages", "abstract": "Automatic speech recognition (ASR) for dysarthric speech remains challenging\ndue to data scarcity, particularly in non-English languages. To address this,\nwe fine-tune a voice conversion model on English dysarthric speech (UASpeech)\nto encode both speaker characteristics and prosodic distortions, then apply it\nto convert healthy non-English speech (FLEURS) into non-English dysarthric-like\nspeech. The generated data is then used to fine-tune a multilingual ASR model,\nMassively Multilingual Speech (MMS), for improved dysarthric speech\nrecognition. Evaluation on PC-GITA (Spanish), EasyCall (Italian), and SSNCE\n(Tamil) demonstrates that VC with both speaker and prosody conversion\nsignificantly outperforms the off-the-shelf MMS performance and conventional\naugmentation techniques such as speed and tempo perturbation. Objective and\nsubjective analyses of the generated data further confirm that the generated\nspeech simulates dysarthric characteristics.", "published": "2025-05-20 20:03:45", "link": "http://arxiv.org/abs/2505.14874v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Replay Attacks Against Audio Deepfake Detection", "abstract": "We show how replay attacks undermine audio deepfake detection: By playing and\nre-recording deepfake audio through various speakers and microphones, we make\nspoofed samples appear authentic to the detection model. To study this\nphenomenon in more detail, we introduce ReplayDF, a dataset of recordings\nderived from M-AILABS and MLAAD, featuring 109 speaker-microphone combinations\nacross six languages and four TTS models. It includes diverse acoustic\nconditions, some highly challenging for detection. Our analysis of six\nopen-source detection models across five datasets reveals significant\nvulnerability, with the top-performing W2V2-AASIST model's Equal Error Rate\n(EER) surging from 4.7% to 18.2%. Even with adaptive Room Impulse Response\n(RIR) retraining, performance remains compromised with an 11.0% EER. We release\nReplayDF for non-commercial research use.", "published": "2025-05-20 19:46:36", "link": "http://arxiv.org/abs/2505.14862v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GraphemeAug: A Systematic Approach to Synthesized Hard Negative Keyword Spotting Examples", "abstract": "Spoken Keyword Spotting (KWS) is the task of distinguishing between the\npresence and absence of a keyword in audio. The accuracy of a KWS model hinges\non its ability to correctly classify examples close to the keyword and\nnon-keyword boundary. These boundary examples are often scarce in training\ndata, limiting model performance. In this paper, we propose a method to\nsystematically generate adversarial examples close to the decision boundary by\nmaking insertion/deletion/substitution edits on the keyword's graphemes. We\nevaluate this technique on held-out data for a popular keyword and show that\nthe technique improves AUC on a dataset of synthetic hard negatives by 61%\nwhile maintaining quality on positives and ambient negative audio data.", "published": "2025-05-20 18:24:31", "link": "http://arxiv.org/abs/2505.14814v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising", "abstract": "Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend\nto preserve the acoustic environment of the audio prompt, leading to\ndegradation in synthesized speech quality when the audio prompt contains noise.\nIn this paper, we propose a novel neural codec-based speech denoiser and\nintegrate it with the advanced LLM-based TTS model, LauraTTS, to achieve\nnoise-robust zero-shot TTS. The proposed codec denoiser consists of an audio\ncodec, a token denoiser, and an embedding refiner. The token denoiser predicts\nthe first two groups of clean acoustic tokens from the noisy ones, which can\nserve as the acoustic prompt for LauraTTS to synthesize high-quality\npersonalized speech or be converted to clean speech waveforms through the\nembedding refiner and codec decoder. Experimental results show that our\nproposed codec denoiser outperforms state-of-the-art speech enhancement (SE)\nmethods, and the proposed noise-robust LauraTTS surpasses the approach using\nadditional SE models.", "published": "2025-05-20 02:18:45", "link": "http://arxiv.org/abs/2505.13830v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Compact Narrowband Antenna Design for RF Fingerprinting Applications", "abstract": "Radio frequency (RF) fingerprinting is widely used for supporting physical\nlayer security in various wireless applications. In this paper, we present the\ndesign and implementation of a small antenna with low-cost fabrication that can\nbe directly integrated with nonlinear passive devices, forming a passive RF tag\nproviding unique nonlinear signatures for RF fingerprinting. We first propose a\nminiaturized meander line dipole, achieved by two folded arms on two sides of\nthe substrate. This leads to antenna with a simple feeding structure and\ncompact size, making it ideal for planar integration. Two antennas on Rogers\n4350B and ultra-thin flexible Panasonic Felios are fabricated, achieving small\nsize at $0.21 \\times 0.06 \\times 0.004 \\lambda_0^3$ and $0.14 \\times 0.1 \\times\n0.0008 \\lambda_0^3$ with realized gain of 1.87 dBi and 1.46 dBi. The passive\ntag consists of the proposed antenna structure and an integrated RF diode, and\nis further developed on both substrates, aiming to generate inter-modulation\nproducts (IMP) due to the nonlinearity of the diode, which can be used for\ndevice identification through classification algorithms. We investigate the\nnonlinearity of the designed tags for transmission at 15 dBm using two-tone\nsignals. All tags produce a significant increased power at IMP frequencies at a\nrange of 0.4 m. The tags on Rogers substrate provide around 23 dB IMP power\nincrease and tags on flexible substrate embedded in lossy material provide\naround 16 dB power increase. These findings confirm that the proposed solution\noffers a simple passive tag design to support unique nonlinear signatures for\nRF fingerprinting applications in a simple, low-cost device.", "published": "2025-05-20 17:32:09", "link": "http://arxiv.org/abs/2505.14764v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Stabilized velocity post-processings for Darcy flow in heterogeneous porous media", "abstract": "Stable and accurate finite element methods are presented for Darcy flow in\nheterogeneous porous media with an interface of discontinuity of the hydraulic\nconductivity tensor. Accurate velocity fields are computed through global or\nlocal post-processing formulations that use previous approximations of the\nhydraulic potential. Stability is provided by combining Galerkin and Least\nSquares (GLS) residuals of the governing equations with an additional\nstabilization on the interface that incorporates the discontinuity on the\ntangential component of the velocity field in a strong sense. Numerical\nanalysis is outlined and numerical results are presented to illustrate the good\nperformance of the proposed methods. Convergence studies for a heterogeneous\nand anisotropic porous medium confirm the same orders of convergence predicted\nfor homogeneous problem with smooth solutions, for both global and local\npost-processings.", "published": "2025-05-20 04:39:39", "link": "http://arxiv.org/abs/2505.13924v2", "categories": ["math.NA", "cs.NA", "65N12, 65N22, 65N30, 35A35"], "primary_category": "math.NA"}
{"title": "U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding", "abstract": "The text generation paradigm for audio tasks has opened new possibilities for\nunified audio understanding. However, existing models face significant\nchallenges in achieving a comprehensive understanding across diverse audio\ntypes, such as speech, general audio events, and music. Furthermore, their\nexclusive reliance on cross-entropy loss for alignment often falls short, as it\ntreats all tokens equally and fails to account for redundant audio features,\nleading to weaker cross-modal alignment. To deal with the above challenges,\nthis paper introduces U-SAM, an advanced audio language model that integrates\nspecialized encoders for speech, audio, and music with a pre-trained large\nlanguage model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for\ntask-aware feature fusion, dynamically routing and integrating the\ndomain-specific encoder outputs. Additionally, U-SAM incorporates a\nSemantic-Aware Contrastive Loss Module, which explicitly identifies redundant\naudio features under language supervision and rectifies their semantic and\nspectral representations to enhance cross-modal alignment. Extensive\nexperiments demonstrate that U-SAM consistently outperforms both specialized\nmodels and existing audio language models across multiple benchmarks. Moreover,\nit exhibits emergent capabilities on unseen tasks, showcasing its\ngeneralization potential. Code is available\n(https://github.com/Honee-W/U-SAM/).", "published": "2025-05-20 03:34:53", "link": "http://arxiv.org/abs/2505.13880v2", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Large Language Models Implicitly Learn to See and Hear Just By Reading", "abstract": "This paper presents a fascinating find: By training an auto-regressive LLM\nmodel on text tokens, the text model inherently develops internally an ability\nto understand images and audio, thereby developing the ability to see and hear\njust by reading. Popular audio and visual LLM models fine-tune text LLM models\nto give text output conditioned on images and audio embeddings. On the other\nhand, our architecture takes in patches of images, audio waveforms or tokens as\ninput. It gives us the embeddings or category labels typical of a\nclassification pipeline. We show the generality of text weights in aiding audio\nclassification for datasets FSD-50K and GTZAN. Further, we show this working\nfor image classification on CIFAR-10 and Fashion-MNIST, as well on image\npatches. This pushes the notion of text-LLMs learning powerful internal\ncircuits that can be utilized by activating necessary connections for various\napplications rather than training models from scratch every single time.", "published": "2025-05-20 22:20:16", "link": "http://arxiv.org/abs/2505.17091v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "From Weak Labels to Strong Results: Utilizing 5,000 Hours of Noisy Classroom Transcripts with Minimal Accurate Data", "abstract": "Recent progress in speech recognition has relied on models trained on vast\namounts of labeled data. However, classroom Automatic Speech Recognition (ASR)\nfaces the real-world challenge of abundant weak transcripts paired with only a\nsmall amount of accurate, gold-standard data. In such low-resource settings,\nhigh transcription costs make re-transcription impractical. To address this, we\nask: what is the best approach when abundant inexpensive weak transcripts\ncoexist with limited gold-standard data, as is the case for classroom speech\ndata? We propose Weakly Supervised Pretraining (WSP), a two-step process where\nmodels are first pretrained on weak transcripts in a supervised manner, and\nthen fine-tuned on accurate data. Our results, based on both synthetic and real\nweak transcripts, show that WSP outperforms alternative methods, establishing\nit as an effective training methodology for low-resource ASR in real-world\nscenarios.", "published": "2025-05-20 20:50:28", "link": "http://arxiv.org/abs/2505.17088v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Numerical Study of Combining RBF Interpolation and Finite Differences to Approximate Differential Operators", "abstract": "This paper focuses on RBF-based meshless methods for approximating\ndifferential operators, one of the most popular being RBF-FD. Recently, a\nhybrid approach was introduced that combines RBF interpolation and traditional\nfinite difference stencils. We compare the accuracy of this method and RBF-FD\non a two-dimensional Poisson problem for standard five-point and nine-point\nstencils and different method parameters.", "published": "2025-05-20 11:41:18", "link": "http://arxiv.org/abs/2505.14232v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "GraphemeAug: A Systematic Approach to Synthesized Hard Negative Keyword Spotting Examples", "abstract": "Spoken Keyword Spotting (KWS) is the task of distinguishing between the\npresence and absence of a keyword in audio. The accuracy of a KWS model hinges\non its ability to correctly classify examples close to the keyword and\nnon-keyword boundary. These boundary examples are often scarce in training\ndata, limiting model performance. In this paper, we propose a method to\nsystematically generate adversarial examples close to the decision boundary by\nmaking insertion/deletion/substitution edits on the keyword's graphemes. We\nevaluate this technique on held-out data for a popular keyword and show that\nthe technique improves AUC on a dataset of synthetic hard negatives by 61%\nwhile maintaining quality on positives and ambient negative audio data.", "published": "2025-05-20 18:24:31", "link": "http://arxiv.org/abs/2505.14814v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "RainfalLTE: A Zero-effect Rainfall Sensing System Utilizing Existing LTE Infrastructure", "abstract": "Environmental sensing is an important research topic in the integrated\nsensing and communication (ISAC) system. Current works often focus on static\nenvironments, such as buildings and terrains. However, dynamic factors like\nrainfall can cause serious interference to wireless signals. In this paper, we\npropose a system called RainfalLTE that utilizes the downlink signal of LTE\nbase stations for device-independent rain sensing. In articular, it is fully\ncompatible with current communication modes and does not require any additional\nhardware. We evaluate it with LTE data and rainfall information provided by a\nweather radar in Badaling Town, Beijing The results show that for 10 classes of\nrainfall, RainfalLTE achieves over 97% identification accuracy. Our case study\nshows that the assistance of rainfall information can bring more than 40%\nenergy saving, which provides new opportunities for the design and optimization\nof ISAC systems.", "published": "2025-05-20 01:57:28", "link": "http://arxiv.org/abs/2505.13818v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
