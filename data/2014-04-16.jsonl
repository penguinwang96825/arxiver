{"title": "An Empirical Comparison of Parsing Methods for Stanford Dependencies", "abstract": "Stanford typed dependencies are a widely desired representation of natural\nlanguage sentences, but parsing is one of the major computational bottlenecks\nin text analysis systems. In light of the evolving definition of the Stanford\ndependencies and developments in statistical dependency parsing algorithms,\nthis paper revisits the question of Cer et al. (2010): what is the tradeoff\nbetween accuracy and speed in obtaining Stanford dependencies in particular? We\nalso explore the effects of input representations on this tradeoff:\npart-of-speech tags, the novel use of an alternative dependency representation\nas input, and distributional representaions of words. We find that direct\ndependency parsing is a more viable solution than it was found to be in the\npast. An accompanying software release can be found at:\nhttp://www.ark.cs.cmu.edu/TBSD", "published": "2014-04-16 17:06:35", "link": "http://arxiv.org/abs/1404.4314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Question Answering with Weakly Supervised Embedding Models", "abstract": "Building computers able to answer questions on any subject is a long standing\ngoal of artificial intelligence. Promising progress has recently been achieved\nby methods that learn to map questions to logical forms or database queries.\nSuch approaches can be effective but at the cost of either large amounts of\nhuman-labeled data or by defining lexicons and grammars tailored by\npractitioners. In this paper, we instead take the radical approach of learning\nto map questions to vectorial feature representations. By mapping answers into\nthe same space one can query any knowledge base independent of its schema,\nwithout requiring any grammar or lexicon. Our method is trained with a new\noptimization procedure combining stochastic gradient descent followed by a\nfine-tuning step using the weak supervision provided by blending automatically\nand collaboratively generated resources. We empirically demonstrate that our\nmodel can capture meaningful signals from its noisy supervision leading to\nmajor improvements over paralex, the only existing method able to be trained on\nsimilar weakly labeled data.", "published": "2014-04-16 17:57:01", "link": "http://arxiv.org/abs/1404.4326v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Many Topics? Stability Analysis for Topic Models", "abstract": "Topic modeling refers to the task of discovering the underlying thematic\nstructure in a text corpus, where the output is commonly presented as a report\nof the top terms appearing in each topic. Despite the diversity of topic\nmodeling algorithms that have been proposed, a common challenge in successfully\napplying these techniques is the selection of an appropriate number of topics\nfor a given corpus. Choosing too few topics will produce results that are\noverly broad, while choosing too many will result in the \"over-clustering\" of a\ncorpus into many small, highly-similar topics. In this paper, we propose a\nterm-centric stability analysis strategy to address this issue, the idea being\nthat a model with an appropriate number of topics will be more robust to\nperturbations in the data. Using a topic modeling approach based on matrix\nfactorization, evaluations performed on a range of corpora show that this\nstrategy can successfully guide the model selection process.", "published": "2014-04-16 12:59:29", "link": "http://arxiv.org/abs/1404.4606v3", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
