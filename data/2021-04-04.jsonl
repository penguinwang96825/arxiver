{"title": "ASPER: Attention-based Approach to Extract Syntactic Patterns denoting\n  Semantic Relations in Sentential Context", "abstract": "Semantic relationships, such as hyponym-hypernym, cause-effect,\nmeronym-holonym etc. between a pair of entities in a sentence are usually\nreflected through syntactic patterns. Automatic extraction of such patterns\nbenefits several downstream tasks, including, entity extraction, ontology\nbuilding, and question answering. Unfortunately, automatic extraction of such\npatterns has not yet received much attention from NLP and information retrieval\nresearchers. In this work, we propose an attention-based supervised deep\nlearning model, ASPER, which extracts syntactic patterns between entities\nexhibiting a given semantic relation in the sentential context. We validate the\nperformance of ASPER on three distinct semantic relations -- hyponym-hypernym,\ncause-effect, and meronym-holonym on six datasets. Experimental results show\nthat for all these semantic relations, ASPER can automatically identify a\ncollection of syntactic patterns reflecting the existence of such a relation\nbetween a pair of entities in a sentence. In comparison to the existing\nmethodologies of syntactic pattern extraction, ASPER's performance is\nsubstantially superior.", "published": "2021-04-04 02:36:19", "link": "http://arxiv.org/abs/2104.01523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IITK@Detox at SemEval-2021 Task 5: Semi-Supervised Learning and Dice\n  Loss for Toxic Spans Detection", "abstract": "In this work, we present our approach and findings for SemEval-2021 Task 5 -\nToxic Spans Detection. The task's main aim was to identify spans to which a\ngiven text's toxicity could be attributed. The task is challenging mainly due\nto two constraints: the small training dataset and imbalanced class\ndistribution. Our paper investigates two techniques, semi-supervised learning\nand learning with Self-Adjusting Dice Loss, for tackling these challenges. Our\nsubmitted system (ranked ninth on the leader board) consisted of an ensemble of\nvarious pre-trained Transformer Language Models trained using either of the\nabove-proposed techniques.", "published": "2021-04-04 08:39:55", "link": "http://arxiv.org/abs/2104.01566v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MCL@IITK at SemEval-2021 Task 2: Multilingual and Cross-lingual\n  Word-in-Context Disambiguation using Augmented Data, Signals, and\n  Transformers", "abstract": "In this work, we present our approach for solving the SemEval 2021 Task 2:\nMultilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC). The\ntask is a sentence pair classification problem where the goal is to detect\nwhether a given word common to both the sentences evokes the same meaning. We\nsubmit systems for both the settings - Multilingual (the pair's sentences\nbelong to the same language) and Cross-Lingual (the pair's sentences belong to\ndifferent languages). The training data is provided only in English.\nConsequently, we employ cross-lingual transfer techniques. Our approach employs\nfine-tuning pre-trained transformer-based language models, like ELECTRA and\nALBERT, for the English task and XLM-R for all other tasks. To improve these\nsystems' performance, we propose adding a signal to the word to be\ndisambiguated and augmenting our data by sentence pair reversal. We further\naugment the dataset provided to us with WiC, XL-WiC and SemCor 3.0. Using\nensembles, we achieve strong performance in the Multilingual task, placing\nfirst in the EN-EN and FR-FR sub-tasks. For the Cross-Lingual setting, we\nemployed translate-test methods and a zero-shot method, using our multilingual\nmodels, with the latter performing slightly better.", "published": "2021-04-04 08:49:28", "link": "http://arxiv.org/abs/2104.01567v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational Question Answering over Knowledge Graphs with Transformer\n  and Graph Attention Networks", "abstract": "This paper addresses the task of (complex) conversational question answering\nover a knowledge graph. For this task, we propose LASAGNE (muLti-task semAntic\nparSing with trAnsformer and Graph atteNtion nEtworks). It is the first\napproach, which employs a transformer architecture extended with Graph\nAttention Networks for multi-task neural semantic parsing. LASAGNE uses a\ntransformer model for generating the base logical forms, while the Graph\nAttention model is used to exploit correlations between (entity) types and\npredicates to produce node representations. LASAGNE also includes a novel\nentity recognition module which detects, links, and ranks all relevant entities\nin the question context. We evaluate LASAGNE on a standard dataset for complex\nsequential question answering, on which it outperforms existing baseline\naverages on all question types. Specifically, we show that LASAGNE improves the\nF1-score on eight out of ten question types; in some cases, the increase in\nF1-score is more than 20% compared to the state of the art.", "published": "2021-04-04 09:21:50", "link": "http://arxiv.org/abs/2104.01569v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TransfoRNN: Capturing the Sequential Information in Self-Attention\n  Representations for Language Modeling", "abstract": "In this paper, we describe the use of recurrent neural networks to capture\nsequential information from the self-attention representations to improve the\nTransformers. Although self-attention mechanism provides a means to exploit\nlong context, the sequential information, i.e. the arrangement of tokens, is\nnot explicitly captured. We propose to cascade the recurrent neural networks to\nthe Transformers, which referred to as the TransfoRNN model, to capture the\nsequential information. We found that the TransfoRNN models which consists of\nonly shallow Transformers stack is suffice to give comparable, if not better,\nperformance than a deeper Transformer model. Evaluated on the Penn Treebank and\nWikiText-2 corpora, the proposed TransfoRNN model has shown lower model\nperplexities with fewer number of model parameters. On the Penn Treebank\ncorpus, the model perplexities were reduced up to 5.5% with the model size\nreduced up to 10.5%. On the WikiText-2 corpus, the model perplexity was reduced\nup to 2.2% with a 27.7% smaller model. Also, the TransfoRNN model was applied\non the LibriSpeech speech recognition task and has shown comparable results\nwith the Transformer models.", "published": "2021-04-04 09:31:18", "link": "http://arxiv.org/abs/2104.01572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KnowGraph@IITK at SemEval-2021 Task 11: Building KnowledgeGraph for NLP\n  Research", "abstract": "Research in Natural Language Processing is making rapid advances, resulting\nin the publication of a large number of research papers. Finding relevant\nresearch papers and their contribution to the domain is a challenging problem.\nIn this paper, we address this challenge via the SemEval 2021 Task 11:\nNLPContributionGraph, by developing a system for a research paper\ncontributions-focused knowledge graph over Natural Language Processing\nliterature. The task is divided into three sub-tasks: extracting contribution\nsentences that show important contributions in the research article, extracting\nphrases from the contribution sentences, and predicting the information units\nin the research article together with triplet formation from the phrases. The\nproposed system is agnostic to the subject domain and can be applied for\nbuilding a knowledge graph for any area. We found that transformer-based\nlanguage models can significantly improve existing techniques and utilized the\nSciBERT-based model. Our first sub-task uses Bidirectional LSTM (BiLSTM)\nstacked on top of SciBERT model layers, while the second sub-task uses\nConditional Random Field (CRF) on top of SciBERT with BiLSTM. The third\nsub-task uses a combined SciBERT based neural approach with heuristics for\ninformation unit prediction and triplet formation from the phrases. Our system\nachieved F1 score of 0.38, 0.63 and 0.76 in end-to-end pipeline testing, phrase\nextraction testing and triplet extraction testing respectively.", "published": "2021-04-04 14:33:21", "link": "http://arxiv.org/abs/2104.01619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phoneme Recognition through Fine Tuning of Phonetic Representations: a\n  Case Study on Luhya Language Varieties", "abstract": "Models pre-trained on multiple languages have shown significant promise for\nimproving speech recognition, particularly for low-resource languages. In this\nwork, we focus on phoneme recognition using Allosaurus, a method for\nmultilingual recognition based on phonetic annotation, which incorporates\nphonological knowledge through a language-dependent allophone layer that\nassociates a universal narrow phone-set with the phonemes that appear in each\nlanguage. To evaluate in a challenging real-world scenario, we curate phone\nrecognition datasets for Bukusu and Saamia, two varieties of the Luhya language\ncluster of western Kenya and eastern Uganda. To our knowledge, these datasets\nare the first of their kind. We carry out similar experiments on the dataset of\nan endangered Tangkhulic language, East Tusom, a Tibeto-Burman language variety\nspoken mostly in India. We explore both zero-shot and few-shot recognition by\nfine-tuning using datasets of varying sizes (10 to 1000 utterances). We find\nthat fine-tuning of Allosaurus, even with just 100 utterances, leads to\nsignificant improvements in phone error rates.", "published": "2021-04-04 15:07:55", "link": "http://arxiv.org/abs/2104.01624v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Pretrained Models for Zero-shot Multi-label Text\n  Classification through Reinforced Label Hierarchy Reasoning", "abstract": "Exploiting label hierarchies has become a promising approach to tackling the\nzero-shot multi-label text classification (ZS-MTC) problem. Conventional\nmethods aim to learn a matching model between text and labels, using a graph\nencoder to incorporate label hierarchies to obtain effective label\nrepresentations \\cite{rios2018few}. More recently, pretrained models like BERT\n\\cite{devlin2018bert} have been used to convert classification tasks into a\ntextual entailment task \\cite{yin-etal-2019-benchmarking}. This approach is\nnaturally suitable for the ZS-MTC task. However, pretrained models are\nunderexplored in the existing work because they do not generate individual\nvector representations for text or labels, making it unintuitive to combine\nthem with conventional graph encoding methods. In this paper, we explore to\nimprove pretrained models with label hierarchies on the ZS-MTC task. We propose\na Reinforced Label Hierarchy Reasoning (RLHR) approach to encourage\ninterdependence among labels in the hierarchies during training. Meanwhile, to\novercome the weakness of flat predictions, we design a rollback algorithm that\ncan remove logical errors from predictions during inference. Experimental\nresults on three real-life datasets show that our approach achieves better\nperformance and outperforms previous non-pretrained methods on the ZS-MTC task.", "published": "2021-04-04 19:14:09", "link": "http://arxiv.org/abs/2104.01666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Context-Dependent Gated Module for Incorporating Symbolic Semantics\n  into Event Coreference Resolution", "abstract": "Event coreference resolution is an important research problem with many\napplications. Despite the recent remarkable success of pretrained language\nmodels, we argue that it is still highly beneficial to utilize symbolic\nfeatures for the task. However, as the input for coreference resolution\ntypically comes from upstream components in the information extraction\npipeline, the automatically extracted symbolic features can be noisy and\ncontain errors. Also, depending on the specific context, some features can be\nmore informative than others. Motivated by these observations, we propose a\nnovel context-dependent gated module to adaptively control the information\nflows from the input symbolic features. Combined with a simple noisy training\nmethod, our best models achieve state-of-the-art results on two datasets: ACE\n2005 and KBP 2016.", "published": "2021-04-04 21:15:02", "link": "http://arxiv.org/abs/2104.01697v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IndT5: A Text-to-Text Transformer for 10 Indigenous Languages", "abstract": "Transformer language models have become fundamental components of natural\nlanguage processing based pipelines. Although several Transformer models have\nbeen introduced to serve many languages, there is a shortage of models\npre-trained for low-resource and Indigenous languages. In this work, we\nintroduce IndT5, the first Transformer language model for Indigenous languages.\nTo train IndT5, we build IndCorpus--a new dataset for ten Indigenous languages\nand Spanish. We also present the application of IndT5 to machine translation by\ninvestigating different approaches to translate between Spanish and the\nIndigenous languages as part of our contribution to the AmericasNLP 2021 Shared\nTask on Open Machine Translation. IndT5 and IndCorpus are publicly available\nfor research", "published": "2021-04-04 07:09:09", "link": "http://arxiv.org/abs/2104.07483v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interval Probabilistic Fuzzy WordNet", "abstract": "WordNet lexical-database groups English words into sets of synonyms called\n\"synsets.\" Synsets are utilized for several applications in the field of\ntext-mining. However, they were also open to criticism because although, in\nreality, not all the members of a synset represent the meaning of that synset\nwith the same degree, in practice, they are considered as members of the\nsynset, identically. Thus, the fuzzy version of synsets, called fuzzy-synsets\n(or fuzzy word-sense classes) were proposed and studied. In this study, we\ndiscuss why (type-1) fuzzy synsets (T1 F-synsets) do not properly model the\nmembership uncertainty, and propose an upgraded version of fuzzy synsets in\nwhich membership degrees of word-senses are represented by intervals, similar\nto what in Interval Type 2 Fuzzy Sets (IT2 FS) and discuss that IT2 FS\ntheoretical framework is insufficient for analysis and design of such synsets,\nand propose a new concept, called Interval Probabilistic Fuzzy (IPF) sets. Then\nwe present an algorithm for constructing the IPF synsets in any language, given\na corpus and a word-sense-disambiguation system. Utilizing our algorithm and\nthe open-American-online-corpus (OANC) and UKB word-sense-disambiguation, we\nconstructed and published the IPF synsets of WordNet for English language.", "published": "2021-04-04 17:28:37", "link": "http://arxiv.org/abs/2104.10660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TSNAT: Two-Step Non-Autoregressvie Transformer Models for Speech\n  Recognition", "abstract": "The autoregressive (AR) models, such as attention-based encoder-decoder\nmodels and RNN-Transducer, have achieved great success in speech recognition.\nThey predict the output sequence conditioned on the previous tokens and\nacoustic encoded states, which is inefficient on GPUs. The non-autoregressive\n(NAR) models can get rid of the temporal dependency between the output tokens\nand predict the entire output tokens in at least one step. However, the NAR\nmodel still faces two major problems. On the one hand, there is still a great\ngap in performance between the NAR models and the advanced AR models. On the\nother hand, it's difficult for most of the NAR models to train and converge. To\naddress these two problems, we propose a new model named the two-step\nnon-autoregressive transformer(TSNAT), which improves the performance and\naccelerating the convergence of the NAR model by learning prior knowledge from\na parameters-sharing AR model. Furthermore, we introduce the two-stage method\ninto the inference process, which improves the model performance greatly. All\nthe experiments are conducted on a public Chinese mandarin dataset ASIEHLL-1.\nThe results show that the TSNAT can achieve a competitive performance with the\nAR model and outperform many complicated NAR models.", "published": "2021-04-04 02:34:55", "link": "http://arxiv.org/abs/2104.01522v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Timers and Such: A Practical Benchmark for Spoken Language Understanding\n  with Numbers", "abstract": "This paper introduces Timers and Such, a new open source dataset of spoken\nEnglish commands for common voice control use cases involving numbers. We\ndescribe the gap in existing spoken language understanding datasets that Timers\nand Such fills, the design and creation of the dataset, and experiments with a\nnumber of ASR-based and end-to-end baseline models, the code for which has been\nmade available as part of the SpeechBrain toolkit.", "published": "2021-04-04 12:52:09", "link": "http://arxiv.org/abs/2104.01604v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Lifelong Learning of End-to-end ASR", "abstract": "Automatic speech recognition (ASR) technologies today are primarily optimized\nfor given datasets; thus, any changes in the application environment (e.g.,\nacoustic conditions or topic domains) may inevitably degrade the performance.\nWe can collect new data describing the new environment and fine-tune the\nsystem, but this naturally leads to higher error rates for the earlier\ndatasets, referred to as catastrophic forgetting. The concept of lifelong\nlearning (LLL) aiming to enable a machine to sequentially learn new tasks from\nnew datasets describing the changing real world without forgetting the\npreviously learned knowledge is thus brought to attention. This paper reports,\nto our knowledge, the first effort to extensively consider and analyze the use\nof various approaches of LLL in end-to-end (E2E) ASR, including proposing novel\nmethods in saving data for past domains to mitigate the catastrophic forgetting\nproblem. An overall relative reduction of 28.7% in WER was achieved compared to\nthe fine-tuning baseline when sequentially learning on three very different\nbenchmark corpora. This can be the first step toward the highly desired ASR\ntechnologies capable of synchronizing with the continuously changing real\nworld.", "published": "2021-04-04 13:48:53", "link": "http://arxiv.org/abs/2104.01616v3", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Recommending Metamodel Concepts during Modeling Activities with\n  Pre-Trained Language Models", "abstract": "The design of conceptually sound metamodels that embody proper semantics in\nrelation to the application domain is particularly tedious in Model-Driven\nEngineering. As metamodels define complex relationships between domain\nconcepts, it is crucial for a modeler to define these concepts thoroughly while\nbeing consistent with respect to the application domain. We propose an approach\nto assist a modeler in the design of a metamodel by recommending relevant\ndomain concepts in several modeling scenarios. Our approach does not require to\nextract knowledge from the domain or to hand-design completion rules. Instead,\nwe design a fully data-driven approach using a deep learning model that is able\nto abstract domain concepts by learning from both structural and lexical\nmetamodel properties in a corpus of thousands of independent metamodels. We\nevaluate our approach on a test set containing 166 metamodels, unseen during\nthe model training, with more than 5000 test samples. Our preliminary results\nshow that the trained model is able to provide accurate top-$5$ lists of\nrelevant recommendations for concept renaming scenarios. Although promising,\nthe results are less compelling for the scenario of the iterative construction\nof the metamodel, in part because of the conservative strategy we use to\nevaluate the recommendations.", "published": "2021-04-04 16:29:10", "link": "http://arxiv.org/abs/2104.01642v3", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "A Conversational Agent System for Dietary Supplements Use", "abstract": "Dietary supplements (DS) have been widely used by consumers, but the\ninformation around the efficacy and safety of DS is disparate or incomplete,\nthus creating barriers for consumers to find information effectively.\nConversational agent (CA) systems have been applied to the healthcare domain,\nbut there is no such a system to answer consumers regarding DS use, although\nwidespread use of DS. In this study, we develop the first CA system for DS use", "published": "2021-04-04 05:47:04", "link": "http://arxiv.org/abs/2104.01543v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Perspective-corrected Spatial Referring Expression Generation for\n  Human-Robot Interaction", "abstract": "Intelligent robots designed to interact with humans in real scenarios need to\nbe able to refer to entities actively by natural language. In spatial referring\nexpression generation, the ambiguity is unavoidable due to the diversity of\nreference frames, which will lead to an understanding gap between humans and\nrobots. To narrow this gap, in this paper, we propose a novel\nperspective-corrected spatial referring expression generation (PcSREG) approach\nfor human-robot interaction by considering the selection of reference frames.\nThe task of referring expression generation is simplified into the process of\ngenerating diverse spatial relation units. First, we pick out all landmarks in\nthese spatial relation units according to the entropy of preference and allow\nits updating through a stack model. Then all possible referring expressions are\ngenerated according to different reference frame strategies. Finally, we\nevaluate every expression using a probabilistic referring expression resolution\nmodel and find the best expression that satisfies both of the appropriateness\nand effectiveness. We implement the proposed approach on a robot system and\nempirical experiments show that our approach can generate more effective\nspatial referring expressions for practical applications.", "published": "2021-04-04 08:00:02", "link": "http://arxiv.org/abs/2104.01558v3", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "ReCAM@IITK at SemEval-2021 Task 4: BERT and ALBERT based Ensemble for\n  Abstract Word Prediction", "abstract": "This paper describes our system for Task 4 of SemEval-2021: Reading\nComprehension of Abstract Meaning (ReCAM). We participated in all subtasks\nwhere the main goal was to predict an abstract word missing from a statement.\nWe fine-tuned the pre-trained masked language models namely BERT and ALBERT and\nused an Ensemble of these as our submitted system on Subtask 1\n(ReCAM-Imperceptibility) and Subtask 2 (ReCAM-Nonspecificity). For Subtask 3\n(ReCAM-Intersection), we submitted the ALBERT model as it gives the best\nresults. We tried multiple approaches and found that Masked Language\nModeling(MLM) based approach works the best.", "published": "2021-04-04 08:22:19", "link": "http://arxiv.org/abs/2104.01563v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FixMyPose: Pose Correctional Captioning and Retrieval", "abstract": "Interest in physical therapy and individual exercises such as yoga/dance has\nincreased alongside the well-being trend. However, such exercises are hard to\nfollow without expert guidance (which is impossible to scale for personalized\nfeedback to every trainee remotely). Thus, automated pose correction systems\nare required more than ever, and we introduce a new captioning dataset named\nFixMyPose to address this need. We collect descriptions of correcting a\n\"current\" pose to look like a \"target\" pose (in both English and Hindi). The\ncollected descriptions have interesting linguistic properties such as\negocentric relations to environment objects, analogous references, etc.,\nrequiring an understanding of spatial relations and commonsense knowledge about\npostures. Further, to avoid ML biases, we maintain a balance across characters\nwith diverse demographics, who perform a variety of movements in several\ninterior environments (e.g., homes, offices). From our dataset, we introduce\nthe pose-correctional-captioning task and its reverse target-pose-retrieval\ntask. During the correctional-captioning task, models must generate\ndescriptions of how to move from the current to target pose image, whereas in\nthe retrieval task, models should select the correct target pose given the\ninitial pose and correctional description. We present strong cross-attention\nbaseline models (uni/multimodal, RL, multilingual) and also show that our\nbaselines are competitive with other models when evaluated on other\nimage-difference datasets. We also propose new task-specific metrics\n(object-match, body-part-match, direction-match) and conduct human evaluation\nfor more reliable evaluation, and we demonstrate a large human-model\nperformance gap suggesting room for promising future work. To verify the\nsim-to-real transfer of our FixMyPose dataset, we collect a set of real images\nand show promising performance on these images.", "published": "2021-04-04 21:45:44", "link": "http://arxiv.org/abs/2104.01703v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Attention Back-end for Automatic Speaker Verification with Multiple\n  Enrollment Utterances", "abstract": "Probabilistic linear discriminant analysis (PLDA) or cosine similarity have\nbeen widely used in traditional speaker verification systems as back-end\ntechniques to measure pairwise similarities. To make better use of multiple\nenrollment utterances, we propose a novel attention back-end model, which can\nbe used for both text-independent (TI) and text-dependent (TD) speaker\nverification, and employ scaled-dot self-attention and feed-forward\nself-attention networks as architectures that learn the intra-relationships of\nthe enrollment utterances. In order to verify the proposed attention back-end,\nwe conduct a series of experiments on CNCeleb and VoxCeleb datasets by\ncombining it with several sate-of-the-art speaker encoders including TDNN and\nResNet. Experimental results using multiple enrollment utterances on CNCeleb\nshow that the proposed attention back-end model leads to lower EER and minDCF\nscore than the PLDA and cosine similarity counterparts for each speaker encoder\nand an experiment on VoxCeleb indicate that our model can be used even for\nsingle enrollment case.", "published": "2021-04-04 05:42:56", "link": "http://arxiv.org/abs/2104.01541v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Principal Component Analysis Applied to Gradient Fields in Band Gap\n  Optimization Problems for Metamaterials", "abstract": "A promising technique for the spectral design of acoustic metamaterials is\nbased on the formulation of suitable constrained nonlinear optimization\nproblems. Unfortunately, the straightforward application of classical\ngradient-based iterative optimization algorithms to the numerical solution of\nsuch problems is typically highly demanding, due to the complexity of the\nunderlying physical models. Nevertheless, supervised machine learning\ntechniques can reduce such a computational effort, e.g., by replacing the\noriginal objective functions of such optimization problems with more-easily\ncomputable approximations. In this framework, the present article describes the\napplication of a related unsupervised machine learning technique, namely,\nprincipal component analysis, to approximate the gradient of the objective\nfunction of a band gap optimization problem for an acoustic metamaterial, with\nthe aim of making the successive application of a gradient-based iterative\noptimization algorithm faster. Numerical results show the effectiveness of the\nproposed method.", "published": "2021-04-04 11:13:37", "link": "http://arxiv.org/abs/2104.02588v6", "categories": ["cs.CE", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CE"}
