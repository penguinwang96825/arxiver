{"title": "New Alignment Methods for Discriminative Book Summarization", "abstract": "We consider the unsupervised alignment of the full text of a book with a\nhuman-written summary. This presents challenges not seen in other text\nalignment problems, including a disparity in length and, consequent to this, a\nviolation of the expectation that individual words and phrases should align,\nsince large passages and chapters can be distilled into a single summary\nphrase. We present two new methods, based on hidden Markov models, specifically\ntargeted to this problem, and demonstrate gains on an extractive book\nsummarization task. While there is still much room for improvement,\nunsupervised alignment holds intrinsic value in offering insight into what\nfeatures of a book are deemed worthy of summarization.", "published": "2013-05-06 20:27:55", "link": "http://arxiv.org/abs/1305.1319v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Techniques for Feature Extraction In Speech Recognition System : A\n  Comparative Study", "abstract": "The time domain waveform of a speech signal carries all of the auditory\ninformation. From the phonological point of view, it little can be said on the\nbasis of the waveform itself. However, past research in mathematics, acoustics,\nand speech technology have provided many methods for converting data that can\nbe considered as information if interpreted correctly. In order to find some\nstatistically relevant information from incoming data, it is important to have\nmechanisms for reducing the information of each segment in the audio signal\ninto a relatively small number of parameters, or features. These features\nshould describe each segment in such a characteristic way that other similar\nsegments can be grouped together by comparing their features. There are\nenormous interesting and exceptional ways to describe the speech signal in\nterms of parameters. Though, they all have their strengths and weaknesses, we\nhave presented some of the most used methods with their importance.", "published": "2013-05-06 10:42:34", "link": "http://arxiv.org/abs/1305.1145v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Towards an Author-Topic-Term-Model Visualization of 100 Years of German\n  Sociological Society Proceedings", "abstract": "Author co-citation studies employ factor analysis to reduce high-dimensional\nco-citation matrices to low-dimensional and possibly interpretable factors, but\nthese studies do not use any information from the text bodies of publications.\nWe hypothesise that term frequencies may yield useful information for\nscientometric analysis. In our work we ask if word features in combination with\nBayesian analysis allow well-founded science mapping studies. This work goes\nback to the roots of Mosteller and Wallace's (1964) statistical text analysis\nusing word frequency features and a Bayesian inference approach, tough with\ndifferent goals. To answer our research question we (i) introduce a new data\nset on which the experiments are carried out, (ii) describe the Bayesian model\nemployed for inference and (iii) present first results of the analysis.", "published": "2013-05-06 22:24:20", "link": "http://arxiv.org/abs/1305.1343v1", "categories": ["cs.DL", "cs.CL", "cs.IR"], "primary_category": "cs.DL"}
