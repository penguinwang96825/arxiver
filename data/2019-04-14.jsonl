{"title": "From News to Medical: Cross-domain Discourse Segmentation", "abstract": "The first step in discourse analysis involves dividing a text into segments.\nWe annotate the first high-quality small-scale medical corpus in English with\ndiscourse segments and analyze how well news-trained segmenters perform on this\ndomain. While we expectedly find a drop in performance, the nature of the\nsegmentation errors suggests some problems can be addressed earlier in the\npipeline, while others would require expanding the corpus to a trainable size\nto learn the nuances of the medical domain.", "published": "2019-04-14 11:52:40", "link": "http://arxiv.org/abs/1904.06682v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "No Adjective Ordering Mystery, and No Raven Paradox, Just an Ontological\n  Mishap", "abstract": "In the concluding remarks of Ontological Promiscuity Hobbs (1985) made what\nwe believe to be a very insightful observation: given that semantics is an\nattempt at specifying the relation between language and the world, if \"one can\nassume a theory of the world that is isomorphic to the way we talk about it ...\nthen semantics becomes nearly trivial\". But how exactly can we rectify our\nlogical formalisms so that semantics, an endeavor that has occupied the most\npenetrating minds for over two centuries, can become (nearly) trivial, and what\nexactly does it mean to assume a theory of the world in our semantics? In this\npaper we hope to provide answers for both questions. First, we believe that a\ncommonsense theory of the world can (and should) be embedded in our semantic\nformalisms resulting in a logical semantics grounded in commonsense\nmetaphysics. Moreover, we believe the first step to accomplishing this vision\nis rectifying what we think was a crucial oversight in logical semantics,\nnamely the failure to distinguish between two fundamentally different types of\nconcepts: (i) ontological concepts, that correspond to what Cocchiarella (2001)\ncalls first-intension concepts and are types in a strongly-typed ontology; and\n(ii) logical concepts (or second intension concepts), that are predicates\ncorresponding to properties of (and relations between) objects of various\nontological types1. In such a framework, which we will refer to henceforth by\nontologik, it will be shown how type unification and other type operations can\nbe used to account for the `missing text phenomenon' (MTP) (see Saba, 2019a)\nthat is at the heart of most challenges in the semantics of natural language,\nby uncovering the significant amount of missing text that is never explicitly\nstated in everyday discourse, but is often implicitly assumed as shared\nbackground knowledge.", "published": "2019-04-14 23:20:34", "link": "http://arxiv.org/abs/1904.06779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for BERT Fine-Tuning in Open-Domain Question Answering", "abstract": "Recently, a simple combination of passage retrieval using off-the-shelf IR\ntechniques and a BERT reader was found to be very effective for question\nanswering directly on Wikipedia, yielding a large improvement over the previous\nstate of the art on a standard benchmark dataset. In this paper, we present a\ndata augmentation technique using distant supervision that exploits positive as\nwell as negative examples. We apply a stage-wise approach to fine tuning BERT\non multiple datasets, starting with data that is \"furthest\" from the test data\nand ending with the \"closest\". Experimental results show large gains in\neffectiveness over previous approaches on English QA datasets, and we establish\nnew baselines on two recent Chinese QA datasets.", "published": "2019-04-14 08:17:06", "link": "http://arxiv.org/abs/1904.06652v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Rare Words: A Major Problem for Contextualized Embeddings And How to Fix\n  it by Attentive Mimicking", "abstract": "Pretraining deep neural network architectures with a language modeling\nobjective has brought large improvements for many natural language processing\ntasks. Exemplified by BERT, a recently proposed such architecture, we\ndemonstrate that despite being trained on huge amounts of data, deep language\nmodels still struggle to understand rare words. To fix this problem, we adapt\nAttentive Mimicking, a method that was designed to explicitly learn embeddings\nfor rare words, to deep language models. In order to make this possible, we\nintroduce one-token approximation, a procedure that enables us to use Attentive\nMimicking even when the underlying language model uses subword-based\ntokenization, i.e., it does not assign embeddings to all words. To evaluate our\nmethod, we create a novel dataset that tests the ability of language models to\ncapture semantic properties of words without any task-specific fine-tuning.\nUsing this dataset, we show that adding our adapted version of Attentive\nMimicking to BERT does indeed substantially improve its understanding of rare\nwords.", "published": "2019-04-14 15:26:52", "link": "http://arxiv.org/abs/1904.06707v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distributed representation of multi-sense words: A loss-driven approach", "abstract": "Word2Vec's Skip Gram model is the current state-of-the-art approach for\nestimating the distributed representation of words. However, it assumes a\nsingle vector per word, which is not well-suited for representing words that\nhave multiple senses. This work presents LDMI, a new model for estimating\ndistributional representations of words. LDMI relies on the idea that, if a\nword carries multiple senses, then having a different representation for each\nof its senses should lead to a lower loss associated with predicting its\nco-occurring words, as opposed to the case when a single vector representation\nis used for all the senses. After identifying the multi-sense words, LDMI\nclusters the occurrences of these words to assign a sense to each occurrence.\nExperiments on the contextual word similarity task show that LDMI leads to\nbetter performance than competing approaches.", "published": "2019-04-14 17:01:26", "link": "http://arxiv.org/abs/1904.06725v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text segmentation on multilabel documents: A distant-supervised approach", "abstract": "Segmenting text into semantically coherent segments is an important task with\napplications in information retrieval and text summarization. Developing\naccurate topical segmentation requires the availability of training data with\nground truth information at the segment level. However, generating such labeled\ndatasets, especially for applications in which the meaning of the labels is\nuser-defined, is expensive and time-consuming. In this paper, we develop an\napproach that instead of using segment-level ground truth information, it\ninstead uses the set of labels that are associated with a document and are\neasier to obtain as the training data essentially corresponds to a multilabel\ndataset. Our method, which can be thought of as an instance of distant\nsupervision, improves upon the previous approaches by exploiting the fact that\nconsecutive sentences in a document tend to talk about the same topic, and\nhence, probably belong to the same class. Experiments on the text segmentation\ntask on a variety of datasets show that the segmentation produced by our method\nbeats the competing approaches on four out of five datasets and performs at par\non the fifth dataset. On the multilabel text classification task, our method\nperforms at par with the competing approaches, while requiring significantly\nless time to estimate than the competing approaches.", "published": "2019-04-14 17:32:44", "link": "http://arxiv.org/abs/1904.06730v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UR-FUNNY: A Multimodal Language Dataset for Understanding Humor", "abstract": "Humor is a unique and creative communicative behavior displayed during social\ninteractions. It is produced in a multimodal manner, through the usage of words\n(text), gestures (vision) and prosodic cues (acoustic). Understanding humor\nfrom these three modalities falls within boundaries of multimodal language; a\nrecent research trend in natural language processing that models natural\nlanguage as it happens in face-to-face communication. Although humor detection\nis an established research area in NLP, in a multimodal context it is an\nunderstudied area. This paper presents a diverse multimodal dataset, called\nUR-FUNNY, to open the door to understanding multimodal language used in\nexpressing humor. The dataset and accompanying studies, present a framework in\nmultimodal humor detection for the natural language processing community.\nUR-FUNNY is publicly available for research.", "published": "2019-04-14 03:15:38", "link": "http://arxiv.org/abs/1904.06618v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A robust DOA estimation method for a linear microphone array under\n  reverberant and noisy environments", "abstract": "A robust method for linear array is proposed to address the difficulty of\ndirection-of-arrival (DOA) estimation in reverberant and noisy environments. A\ndirect-path dominance test based on the onset detection is utilized to extract\ntime-frequency bins containing the direct propagation of the speech. The\ninfluence of the transient noise, which severely contaminates the onset test,\nis mitigated by a proper transient noise determination scheme. Then for voice\nfeatures, a two-stage procedure is designed based on the extracted bins and an\neffective dereverberation method, with robust but possibly biased estimation\nfrom middle frequency bins followed by further refinement in higher frequency\nbins. The proposed method effectively alleviates the estimation bias caused by\nthe linear arrangement of microphones, and has stable performance under noisy\nand reverberant environments. Experimental evaluation using a 4-element\nmicrophone array demonstrates the efficacy of the proposed method.", "published": "2019-04-14 08:04:57", "link": "http://arxiv.org/abs/1904.06648v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SpeechYOLO: Detection and Localization of Speech Objects", "abstract": "In this paper, we propose to apply object detection methods from the vision\ndomain on the speech recognition domain, by treating audio fragments as\nobjects. More specifically, we present SpeechYOLO, which is inspired by the\nYOLO algorithm for object detection in images. The goal of SpeechYOLO is to\nlocalize boundaries of utterances within the input signal, and to correctly\nclassify them. Our system is composed of a convolutional neural network, with a\nsimple least-mean-squares loss function. We evaluated the system on several\nkeyword spotting tasks, that include corpora of read speech and spontaneous\nspeech. Our system compares favorably with other algorithms trained for both\nlocalization and classification.", "published": "2019-04-14 15:47:14", "link": "http://arxiv.org/abs/1904.07704v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
