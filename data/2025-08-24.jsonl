{"title": "Activation Transport Operators", "abstract": "The residual stream mediates communication between transformer decoder layers\nvia linear reads and writes of non-linear computations. While sparse-dictionary\nlearning-based methods locate features in the residual stream, and activation\npatching methods discover circuits within the model, the mechanism by which\nfeatures flow through the residual stream remains understudied. Understanding\nthis dynamic can better inform jailbreaking protections, enable early detection\nof model mistakes, and their correction. In this work, we propose Activation\nTransport Operators (ATO), linear maps from upstream to downstream residuals\n$k$ layers later, evaluated in feature space using downstream SAE decoder\nprojections. We empirically demonstrate that these operators can determine\nwhether a feature has been linearly transported from a previous layer or\nsynthesised from non-linear layer computation. We develop the notion of\ntransport efficiency, for which we provide an upper bound, and use it to\nestimate the size of the residual stream subspace that corresponds to linear\ntransport. We empirically demonstrate the linear transport, report transport\nefficiency and the size of the residual stream's subspace involved in linear\ntransport. This compute-light (no finetuning, <50 GPU-h) method offers\npractical tools for safety, debugging, and a clearer picture of where\ncomputation in LLMs behaves linearly.", "published": "2025-08-24 22:22:09", "link": "http://arxiv.org/abs/2508.17540v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?", "abstract": "Multi-Agent Debate~(MAD) has emerged as a promising paradigm for improving\nthe performance of large language models through collaborative reasoning.\nDespite recent advances, the key factors driving MAD's effectiveness remain\nunclear. In this work, we disentangle MAD into two key components--Majority\nVoting and inter-agent Debate--and assess their respective contributions.\nThrough extensive experiments across seven NLP benchmarks, we find that\nMajority Voting alone accounts for most of the performance gains typically\nattributed to MAD. To explain this, we propose a theoretical framework that\nmodels debate as a stochastic process. We prove that it induces a martingale\nover agents' belief trajectories, implying that debate alone does not improve\nexpected correctness. Guided by these insights, we demonstrate that targeted\ninterventions, by biasing the belief update toward correction, can meaningfully\nenhance debate effectiveness. Overall, our findings suggest that while MAD has\npotential, simple ensembling methods remain strong and more reliable\nalternatives in many practical settings. Code is released in\nhttps://github.com/deeplearning-wisc/debate-or-vote.", "published": "2025-08-24 22:14:32", "link": "http://arxiv.org/abs/2508.17536v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Improving French Synthetic Speech Quality via SSML Prosody Control", "abstract": "Despite recent advances, synthetic voices often lack expressiveness due to\nlimited prosody control in commercial text-to-speech (TTS) systems. We\nintroduce the first end-to-end pipeline that inserts Speech Synthesis Markup\nLanguage (SSML) tags into French text to control pitch, speaking rate, volume,\nand pause duration. We employ a cascaded architecture with two QLoRA-fine-tuned\nQwen 2.5-7B models: one predicts phrase-break positions and the other performs\nregression on prosodic targets, generating commercial TTS-compatible SSML\nmarkup. Evaluated on a 14-hour French podcast corpus, our method achieves 99.2%\nF1 for break placement and reduces mean absolute error on pitch, rate, and\nvolume by 25-40% compared with prompting-only large language models (LLMs) and\na BiLSTM baseline. In perceptual evaluation involving 18 participants across\nover 9 hours of synthesized audio, SSML-enhanced speech generated by our\npipeline significantly improves naturalness, with the mean opinion score\nincreasing from 3.20 to 3.87 (p < 0.005). Additionally, 15 of 18 listeners\npreferred our enhanced synthesis. These results demonstrate substantial\nprogress in bridging the expressiveness gap between synthetic and natural\nFrench speech. Our code is publicly available at\nhttps://github.com/hi-paris/Prosody-Control-French-TTS.", "published": "2025-08-24 19:07:59", "link": "http://arxiv.org/abs/2508.17494v1", "categories": ["cs.CL", "cs.SD", "68T50", "I.2.7; H.5.5"], "primary_category": "cs.CL"}
{"title": "Efficient Zero-Shot Long Document Classification by Reducing Context Through Sentence Ranking", "abstract": "Transformer-based models like BERT excel at short text classification but\nstruggle with long document classification (LDC) due to input length\nlimitations and computational inefficiencies. In this work, we propose an\nefficient, zero-shot approach to LDC that leverages sentence ranking to reduce\ninput context without altering the model architecture. Our method enables the\nadaptation of models trained on short texts, such as headlines, to long-form\ndocuments by selecting the most informative sentences using a TF-IDF-based\nranking strategy. Using the MahaNews dataset of long Marathi news articles, we\nevaluate three context reduction strategies that prioritize essential content\nwhile preserving classification accuracy. Our results show that retaining only\nthe top 50\\% ranked sentences maintains performance comparable to full-document\ninference while reducing inference time by up to 35\\%. This demonstrates that\nsentence ranking is a simple yet effective technique for scalable and efficient\nzero-shot LDC.", "published": "2025-08-24 18:52:37", "link": "http://arxiv.org/abs/2508.17490v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating the Impact of Verbal Multiword Expressions on Machine Translation", "abstract": "Verbal multiword expressions (VMWEs) present significant challenges for\nnatural language processing due to their complex and often non-compositional\nnature. While machine translation models have seen significant improvement with\nthe advent of language models in recent years, accurately translating these\ncomplex linguistic structures remains an open problem. In this study, we\nanalyze the impact of three VMWE categories -- verbal idioms, verb-particle\nconstructions, and light verb constructions -- on machine translation quality\nfrom English to multiple languages. Using both established multiword expression\ndatasets and sentences containing these language phenomena extracted from\nmachine translation datasets, we evaluate how state-of-the-art translation\nsystems handle these expressions. Our experimental results consistently show\nthat VMWEs negatively affect translation quality. We also propose an LLM-based\nparaphrasing approach that replaces these expressions with their literal\ncounterparts, demonstrating significant improvement in translation quality for\nverbal idioms and verb-particle constructions.", "published": "2025-08-24 17:26:58", "link": "http://arxiv.org/abs/2508.17458v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD", "abstract": "Large Language Models (LLMs) can struggle to balance gullibility to\nmisinformation and resistance to valid corrections in persuasive dialogues, a\ncritical challenge for reliable deployment. We introduce DuET-PD (Dual\nEvaluation for Trust in Persuasive Dialogues), a framework evaluating\nmulti-turn stance-change dynamics across dual dimensions: persuasion type\n(corrective/misleading) and domain (knowledge via MMLU-Pro, and safety via\nSALAD-Bench). We find that even a state-of-the-art model like GPT-4o achieves\nonly 27.32% accuracy in MMLU-Pro under sustained misleading persuasions.\nMoreover, results reveal a concerning trend of increasing sycophancy in newer\nopen-source models. To address this, we introduce Holistic DPO, a training\napproach balancing positive and negative persuasion examples. Unlike prompting\nor resist-only training, Holistic DPO enhances both robustness to\nmisinformation and receptiveness to corrections, improving\nLlama-3.1-8B-Instruct's accuracy under misleading persuasion in safety contexts\nfrom 4.21% to 76.54%. These contributions offer a pathway to developing more\nreliable and adaptable LLMs for multi-turn dialogue. Code is available at\nhttps://github.com/Social-AI-Studio/DuET-PD.", "published": "2025-08-24 17:08:37", "link": "http://arxiv.org/abs/2508.17450v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling", "abstract": "Recent advancements in aligning large language models via reinforcement\nlearning have achieved remarkable gains in solving complex reasoning problems,\nbut at the cost of expensive on-policy rollouts and limited exploration of\ndiverse reasoning paths. In this work, we introduce TreePO, involving a\nself-guided rollout algorithm that views sequence generation as a\ntree-structured searching process. Composed of dynamic tree sampling policy and\nfixed-length segment decoding, TreePO leverages local uncertainty to warrant\nadditional branches. By amortizing computation across common prefixes and\npruning low-value paths early, TreePO essentially reduces the per-update\ncompute burden while preserving or enhancing exploration diversity. Key\ncontributions include: (1) a segment-wise sampling algorithm that alleviates\nthe KV cache burden through contiguous segments and spawns new branches along\nwith an early-stop mechanism; (2) a tree-based segment-level advantage\nestimation that considers both global and local proximal policy optimization.\nand (3) analysis on the effectiveness of probability and quality-driven dynamic\ndivergence and fallback strategy. We empirically validate the performance gain\nof TreePO on a set reasoning benchmarks and the efficiency saving of GPU hours\nfrom 22\\% up to 43\\% of the sampling design for the trained models, meanwhile\nshowing up to 40\\% reduction at trajectory-level and 35\\% at token-level\nsampling compute for the existing models. While offering a free lunch of\ninference efficiency, TreePO reveals a practical path toward scaling RL-based\npost-training with fewer samples and less compute. Home page locates at\nhttps://m-a-p.ai/TreePO.", "published": "2025-08-24 16:52:37", "link": "http://arxiv.org/abs/2508.17445v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MahaParaphrase: A Marathi Paraphrase Detection Corpus and BERT-based Models", "abstract": "Paraphrases are a vital tool to assist language understanding tasks such as\nquestion answering, style transfer, semantic parsing, and data augmentation\ntasks. Indic languages are complex in natural language processing (NLP) due to\ntheir rich morphological and syntactic variations, diverse scripts, and limited\navailability of annotated data. In this work, we present the\nL3Cube-MahaParaphrase Dataset, a high-quality paraphrase corpus for Marathi, a\nlow resource Indic language, consisting of 8,000 sentence pairs, each annotated\nby human experts as either Paraphrase (P) or Non-paraphrase (NP). We also\npresent the results of standard transformer-based BERT models on these\ndatasets. The dataset and model are publicly shared at\nhttps://github.com/l3cube-pune/MarathiNLP", "published": "2025-08-24 16:48:58", "link": "http://arxiv.org/abs/2508.17444v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DS@GT at CheckThat! 2025: A Simple Retrieval-First, LLM-Backed Framework for Claim Normalization", "abstract": "Claim normalization is an integral part of any automatic fact-check\nverification system. It parses the typically noisy claim data, such as social\nmedia posts into normalized claims, which are then fed into downstream veracity\nclassification tasks. The CheckThat! 2025 Task 2 focuses specifically on claim\nnormalization and spans 20 languages under monolingual and zero-shot\nconditions. Our proposed solution consists of a lightweight\n\\emph{retrieval-first, LLM-backed} pipeline, in which we either dynamically\nprompt a GPT-4o-mini with in-context examples, or retrieve the closest\nnormalization from the train dataset directly. On the official test set, the\nsystem ranks near the top for most monolingual tracks, achieving first place in\n7 out of of the 13 languages. In contrast, the system underperforms in the\nzero-shot setting, highlighting the limitation of the proposed solution.", "published": "2025-08-24 15:19:58", "link": "http://arxiv.org/abs/2508.17402v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DashboardQA: Benchmarking Multimodal Agents for Question Answering on Interactive Dashboards", "abstract": "Dashboards are powerful visualization tools for data-driven decision-making,\nintegrating multiple interactive views that allow users to explore, filter, and\nnavigate data. Unlike static charts, dashboards support rich interactivity,\nwhich is essential for uncovering insights in real-world analytical workflows.\nHowever, existing question-answering benchmarks for data visualizations largely\noverlook this interactivity, focusing instead on static charts. This limitation\nseverely constrains their ability to evaluate the capabilities of modern\nmultimodal agents designed for GUI-based reasoning. To address this gap, we\nintroduce DashboardQA, the first benchmark explicitly designed to assess how\nvision-language GUI agents comprehend and interact with real-world dashboards.\nThe benchmark includes 112 interactive dashboards from Tableau Public and 405\nquestion-answer pairs with interactive dashboards spanning five categories:\nmultiple-choice, factoid, hypothetical, multi-dashboard, and conversational. By\nassessing a variety of leading closed- and open-source GUI agents, our analysis\nreveals their key limitations, particularly in grounding dashboard elements,\nplanning interaction trajectories, and performing reasoning. Our findings\nindicate that interactive dashboard reasoning is a challenging task overall for\nall the VLMs evaluated. Even the top-performing agents struggle; for instance,\nthe best agent based on Gemini-Pro-2.5 achieves only 38.69% accuracy, while the\nOpenAI CUA agent reaches just 22.69%, demonstrating the benchmark's significant\ndifficulty. We release DashboardQA at https://github.com/vis-nlp/DashboardQA", "published": "2025-08-24 15:11:44", "link": "http://arxiv.org/abs/2508.17398v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agent-Testing Agent: A Meta-Agent for Automated Testing and Evaluation of Conversational AI Agents", "abstract": "LLM agents are increasingly deployed to plan, retrieve, and write with tools,\nyet evaluation still leans on static benchmarks and small human studies. We\npresent the Agent-Testing Agent (ATA), a meta-agent that combines static code\nanalysis, designer interrogation, literature mining, and persona-driven\nadversarial test generation whose difficulty adapts via judge feedback. Each\ndialogue is scored with an LLM-as-a-Judge (LAAJ) rubric and used to steer\nsubsequent tests toward the agent's weakest capabilities. On a travel planner\nand a Wikipedia writer, the ATA surfaces more diverse and severe failures than\nexpert annotators while matching severity, and finishes in 20--30 minutes\nversus ten-annotator rounds that took days. Ablating code analysis and web\nsearch increases variance and miscalibration, underscoring the value of\nevidence-grounded test generation. The ATA outputs quantitative metrics and\nqualitative bug reports for developers. We release the full methodology and\nopen-source implementation for reproducible agent testing:\nhttps://github.com/KhalilMrini/Agent-Testing-Agent", "published": "2025-08-24 15:02:13", "link": "http://arxiv.org/abs/2508.17393v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Universal Predictors? An Empirical Study on Small Tabular Datasets", "abstract": "Large Language Models (LLMs), originally developed for natural language\nprocessing (NLP), have demonstrated the potential to generalize across\nmodalities and domains. With their in-context learning (ICL) capabilities, LLMs\ncan perform predictive tasks over structured inputs without explicit\nfine-tuning on downstream tasks. In this work, we investigate the empirical\nfunction approximation capability of LLMs on small-scale structured datasets\nfor classification, regression and clustering tasks. We evaluate the\nperformance of state-of-the-art LLMs (GPT-5, GPT-4o, GPT-o3, Gemini-2.5-Flash,\nDeepSeek-R1) under few-shot prompting and compare them against established\nmachine learning (ML) baselines, including linear models, ensemble methods and\ntabular foundation models (TFMs). Our results show that LLMs achieve strong\nperformance in classification tasks under limited data availability,\nestablishing practical zero-training baselines. In contrast, the performance in\nregression with continuous-valued outputs is poor compared to ML models, likely\nbecause regression demands outputs in a large (often infinite) space, and\nclustering results are similarly limited, which we attribute to the absence of\ngenuine ICL in this setting. Nonetheless, this approach enables rapid,\nlow-overhead data exploration and offers a viable alternative to traditional ML\npipelines in business intelligence and exploratory analytics contexts. We\nfurther analyze the influence of context size and prompt structure on\napproximation quality, identifying trade-offs that affect predictive\nperformance. Our findings suggest that LLMs can serve as general-purpose\npredictive engines for structured data, with clear strengths in classification\nand significant limitations in regression and clustering.", "published": "2025-08-24 15:00:51", "link": "http://arxiv.org/abs/2508.17391v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat", "abstract": "Large language models (LLMs) trained primarily on English corpora often\nstruggle to capture the linguistic and cultural nuances of Arabic. To address\nthis gap, the Saudi Data and AI Authority (SDAIA) introduced the $ALLaM$ family\nof Arabic-focused models. The most capable of these available to the public,\n$ALLaM-34B$, was subsequently adopted by HUMAIN, who developed and deployed\nHUMAIN Chat, a closed conversational web service built on this model. This\npaper presents an expanded and refined UI-level evaluation of $ALLaM-34B$.\nUsing a prompt pack spanning modern standard Arabic, five regional dialects,\ncode-switching, factual knowledge, arithmetic and temporal reasoning, creative\ngeneration, and adversarial safety, we collected 115 outputs (23 prompts times\n5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro,\nClaude Sonnet-4). We compute category-level means with 95\\% confidence\nintervals, analyze score distributions, and visualize dialect-wise metric heat\nmaps. The updated analysis reveals consistently high performance on generation\nand code-switching tasks (both averaging 4.92/5), alongside strong results in\nMSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect\nfidelity (4.21/5). Safety-related prompts show stable, reliable performance of\n(4.54/5). Taken together, these results position $ALLaM-34B$ as a robust and\nculturally grounded Arabic LLM, demonstrating both technical strength and\npractical readiness for real-world deployment.", "published": "2025-08-24 14:32:15", "link": "http://arxiv.org/abs/2508.17378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Arabic Generality Score: Another Dimension of Modeling Arabic Dialectness", "abstract": "Arabic dialects form a diverse continuum, yet NLP models often treat them as\ndiscrete categories. Recent work addresses this issue by modeling dialectness\nas a continuous variable, notably through the Arabic Level of Dialectness\n(ALDi). However, ALDi reduces complex variation to a single dimension. We\npropose a complementary measure: the Arabic Generality Score (AGS), which\nquantifies how widely a word is used across dialects. We introduce a pipeline\nthat combines word alignment, etymology-aware edit distance, and smoothing to\nannotate a parallel corpus with word-level AGS. A regression model is then\ntrained to predict AGS in context. Our approach outperforms strong baselines,\nincluding state-of-the-art dialect ID systems, on a multi-dialect benchmark.\nAGS offers a scalable, linguistically grounded way to model lexical generality,\nenriching representations of Arabic dialectness.", "published": "2025-08-24 13:06:00", "link": "http://arxiv.org/abs/2508.17347v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using Knowledge Graphs", "abstract": "Court judgments reveal how legal rules have been interpreted and applied to\nfacts, providing a foundation for understanding structured legal reasoning.\nHowever, existing automated approaches for capturing legal reasoning, including\nlarge language models, often fail to identify the relevant legal context, do\nnot accurately trace how facts relate to legal norms, and may misrepresent the\nlayered structure of judicial reasoning. These limitations hinder the ability\nto capture how courts apply the law to facts in practice. In this paper, we\naddress these challenges by constructing a legal knowledge graph from 648\nJapanese administrative court decisions. Our method extracts components of\nlegal reasoning using prompt-based large language models, normalizes references\nto legal provisions, and links facts, norms, and legal applications through an\nontology of legal inference. The resulting graph captures the full structure of\nlegal reasoning as it appears in real court decisions, making implicit\nreasoning explicit and machine-readable. We evaluate our system using expert\nannotated data, and find that it achieves more accurate retrieval of relevant\nlegal provisions from facts than large language model baselines and\nretrieval-augmented methods.", "published": "2025-08-24 12:51:40", "link": "http://arxiv.org/abs/2508.17340v1", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DropLoRA: Sparse Low-Rank Adaptation for Parameter-Efficient Fine-Tuning", "abstract": "LoRA-based large model parameter-efficient fine-tuning (PEFT) methods use\nlow-rank de- composition to approximate updates to model parameters. However,\ncompared to full- parameter fine-tuning, low-rank updates often lead to a\nperformance gap in downstream tasks. To address this, we introduce DropLoRA, a\nnovel pruning-based approach that focuses on pruning the rank dimension. Unlike\nconven- tional methods that attempt to overcome the low-rank bottleneck,\nDropLoRA innovatively integrates a pruning module between the two low-rank\nmatrices in LoRA to simulate dy- namic subspace learning. This dynamic low-\nrank subspace learning allows DropLoRA to overcome the limitations of\ntraditional LoRA, which operates within a static subspace. By continuously\nadapting the learning subspace, DropLoRA significantly boosts performance\nwithout incurring additional training or infer- ence costs. Our experimental\nresults demon- strate that DropLoRA consistently outperforms LoRA in\nfine-tuning the LLaMA series across a wide range of large language model gener-\nation tasks, including commonsense reason- ing, mathematical reasoning, code\ngeneration, and instruction-following. Our code is avail- able at\nhttps://github.com/TayeeChang/DropLoRA.", "published": "2025-08-24 12:45:36", "link": "http://arxiv.org/abs/2508.17337v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mind the (Language) Gap: Towards Probing Numerical and Cross-Lingual Limits of LVLMs", "abstract": "We introduce MMCRICBENCH-3K, a benchmark for Visual Question Answering (VQA)\non cricket scorecards, designed to evaluate large vision-language models\n(LVLMs) on complex numerical and cross-lingual reasoning over semi-structured\ntabular images. MMCRICBENCH-3K comprises 1,463 synthetically generated\nscorecard images from ODI, T20, and Test formats, accompanied by 1,500 English\nQA pairs. It includes two subsets: MMCRICBENCH-E-1.5K, featuring English\nscorecards, and MMCRICBENCH-H-1.5K, containing visually similar Hindi\nscorecards, with all questions and answers kept in English to enable controlled\ncross-script evaluation. The task demands reasoning over structured numerical\ndata, multi-image context, and implicit domain knowledge. Empirical results\nshow that even state-of-the-art LVLMs, such as GPT-4o and Qwen2.5VL, struggle\non the English subset despite it being their primary training language and\nexhibit a further drop in performance on the Hindi subset. This reveals key\nlimitations in structure-aware visual text understanding, numerical reasoning,\nand cross-lingual generalization. The dataset is publicly available via Hugging\nFace at https://huggingface.co/datasets/DIALab/MMCricBench, to promote LVLM\nresearch in this direction.", "published": "2025-08-24 12:43:27", "link": "http://arxiv.org/abs/2508.17334v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Omne-R1: Learning to Reason with Memory for Multi-hop Question Answering", "abstract": "This paper introduces Omne-R1, a novel approach designed to enhance multi-hop\nquestion answering capabilities on schema-free knowledge graphs by integrating\nadvanced reasoning models. Our method employs a multi-stage training workflow,\nincluding two reinforcement learning phases and one supervised fine-tuning\nphase. We address the challenge of limited suitable knowledge graphs and QA\ndata by constructing domain-independent knowledge graphs and auto-generating QA\npairs. Experimental results show significant improvements in answering\nmulti-hop questions, with notable performance gains on more complex 3+ hop\nquestions. Our proposed training framework demonstrates strong generalization\nabilities across diverse knowledge domains.", "published": "2025-08-24 12:36:48", "link": "http://arxiv.org/abs/2508.17330v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CultranAI at PalmX 2025: Data Augmentation for Cultural Knowledge Representation", "abstract": "In this paper, we report our participation to the PalmX cultural evaluation\nshared task. Our system, CultranAI, focused on data augmentation and LoRA\nfine-tuning of large language models (LLMs) for Arabic cultural knowledge\nrepresentation. We benchmarked several LLMs to identify the best-performing\nmodel for the task. In addition to utilizing the PalmX dataset, we augmented it\nby incorporating the Palm dataset and curated a new dataset of over 22K\nculturally grounded multiple-choice questions (MCQs). Our experiments showed\nthat the Fanar-1-9B-Instruct model achieved the highest performance. We\nfine-tuned this model on the combined augmented dataset of 22K+ MCQs. On the\nblind test set, our submitted system ranked 5th with an accuracy of 70.50%,\nwhile on the PalmX development set, it achieved an accuracy of 84.1%.", "published": "2025-08-24 12:11:21", "link": "http://arxiv.org/abs/2508.17324v1", "categories": ["cs.CL", "cs.AI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Handling Students Dropouts in an LLM-driven Interactive Online Course Using Language Models", "abstract": "Interactive online learning environments, represented by Massive AI-empowered\nCourses (MAIC), leverage LLM-driven multi-agent systems to transform passive\nMOOCs into dynamic, text-based platforms, enhancing interactivity through LLMs.\nThis paper conducts an empirical study on a specific MAIC course to explore\nthree research questions about dropouts in these interactive online courses:\n(1) What factors might lead to dropouts? (2) Can we predict dropouts? (3) Can\nwe reduce dropouts? We analyze interaction logs to define dropouts and identify\ncontributing factors. Our findings reveal strong links between dropout\nbehaviors and textual interaction patterns. We then propose a\ncourse-progress-adaptive dropout prediction framework (CPADP) to predict\ndropouts with at most 95.4% accuracy. Based on this, we design a personalized\nemail recall agent to re-engage at-risk students. Applied in the deployed MAIC\nsystem with over 3,000 students, the feasibility and effectiveness of our\napproach have been validated on students with diverse backgrounds.", "published": "2025-08-24 11:40:16", "link": "http://arxiv.org/abs/2508.17310v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "abstract": "The pursuit of human-level artificial intelligence (AI) has significantly\nadvanced the development of autonomous agents and Large Language Models (LLMs).\nLLMs are now widely utilized as decision-making agents for their ability to\ninterpret instructions, manage sequential tasks, and adapt through feedback.\nThis review examines recent developments in employing LLMs as autonomous agents\nand tool users and comprises seven research questions. We only used the papers\npublished between 2023 and 2025 in conferences of the A* and A rank and Q1\njournals. A structured analysis of the LLM agents' architectural design\nprinciples, dividing their applications into single-agent and multi-agent\nsystems, and strategies for integrating external tools is presented. In\naddition, the cognitive mechanisms of LLM, including reasoning, planning, and\nmemory, and the impact of prompting methods and fine-tuning procedures on agent\nperformance are also investigated. Furthermore, we evaluated current benchmarks\nand assessment protocols and have provided an analysis of 68 publicly available\ndatasets to assess the performance of LLM-based agents in various tasks. In\nconducting this review, we have identified critical findings on verifiable\nreasoning of LLMs, the capacity for self-improvement, and the personalization\nof LLM-based agents. Finally, we have discussed ten future research directions\nto overcome these gaps.", "published": "2025-08-24 10:02:51", "link": "http://arxiv.org/abs/2508.17281v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are You Sure You're Positive? Consolidating Chain-of-Thought Agents with Uncertainty Quantification for Aspect-Category Sentiment Analysis", "abstract": "Aspect-category sentiment analysis provides granular insights by identifying\nspecific themes within product reviews that are associated with particular\nopinions. Supervised learning approaches dominate the field. However, data is\nscarce and expensive to annotate for new domains. We argue that leveraging\nlarge language models in a zero-shot setting is beneficial where the time and\nresources required for dataset annotation are limited. Furthermore, annotation\nbias may lead to strong results using supervised methods but transfer poorly to\nnew domains in contexts that lack annotations and demand reproducibility. In\nour work, we propose novel techniques that combine multiple chain-of-thought\nagents by leveraging large language models' token-level uncertainty scores. We\nexperiment with the 3B and 70B+ parameter size variants of Llama and Qwen\nmodels, demonstrating how these approaches can fulfil practical needs and\nopening a discussion on how to gauge accuracy in label-scarce conditions.", "published": "2025-08-24 08:51:16", "link": "http://arxiv.org/abs/2508.17258v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation", "abstract": "Large Language Models (LLMs) have shown potential in automatic bundle\ngeneration but suffer from prohibitive computational costs. Although knowledge\ndistillation offers a pathway to more efficient student models, our preliminary\nstudy reveals that naively integrating diverse types of distilled knowledge\nfrom teacher LLMs into student LLMs leads to knowledge conflict, negatively\nimpacting the performance of bundle generation. To address this, we propose\nRouteDK, a framework for routing distilled knowledge through a mixture of LoRA\nexpert architecture. Specifically, we first distill knowledge from the teacher\nLLM for bundle generation in two complementary types: high-level knowledge\n(generalizable rules) and fine-grained knowledge (session-specific reasoning).\nWe then train knowledge-specific LoRA experts for each type of knowledge\ntogether with a base LoRA expert. For effective integration, we propose a\ndynamic fusion module, featuring an input-aware router, where the router\nbalances expert contributions by dynamically determining optimal weights based\non input, thereby effectively mitigating knowledge conflicts. To further\nimprove inference reliability, we design an inference-time enhancement module\nto reduce variance and mitigate suboptimal reasoning. Experiments on three\npublic datasets show that our RouteDK achieves accuracy comparable to or even\nbetter than the teacher LLM, while maintaining strong computational efficiency.\nIn addition, it outperforms state-of-the-art approaches for bundle generation.", "published": "2025-08-24 08:19:51", "link": "http://arxiv.org/abs/2508.17250v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CoViPAL: Layer-wise Contextualized Visual Token Pruning for Large Vision-Language Models", "abstract": "Large Vision-Language Models (LVLMs) process multimodal inputs consisting of\ntext tokens and vision tokens extracted from images or videos. Due to the rich\nvisual information, a single image can generate thousands of vision tokens,\nleading to high computational costs during the prefilling stage and significant\nmemory overhead during decoding. Existing methods attempt to prune redundant\nvision tokens, revealing substantial redundancy in visual representations.\nHowever, these methods often struggle in shallow layers due to the lack of\nsufficient contextual information. We argue that many visual tokens are\ninherently redundant even in shallow layers and can be safely and effectively\npruned with appropriate contextual signals. In this work, we propose CoViPAL, a\nlayer-wise contextualized visual token pruning method that employs a\nPlug-and-Play Pruning Module (PPM) to predict and remove redundant vision\ntokens before they are processed by the LVLM. The PPM is lightweight,\nmodel-agnostic, and operates independently of the LVLM architecture, ensuring\nseamless integration with various models. Extensive experiments on multiple\nbenchmarks demonstrate that CoViPAL outperforms training-free pruning methods\nunder equal token budgets and surpasses training-based methods with comparable\nsupervision. CoViPAL offers a scalable and efficient solution to improve\ninference efficiency in LVLMs without compromising accuracy.", "published": "2025-08-24 07:47:00", "link": "http://arxiv.org/abs/2508.17243v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation", "abstract": "Legal claims refer to the plaintiff's demands in a case and are essential to\nguiding judicial reasoning and case resolution. While many works have focused\non improving the efficiency of legal professionals, the research on helping\nnon-professionals (e.g., plaintiffs) remains unexplored. This paper explores\nthe problem of legal claim generation based on the given case's facts. First,\nwe construct ClaimGen-CN, the first dataset for Chinese legal claim generation\ntask, from various real-world legal disputes. Additionally, we design an\nevaluation metric tailored for assessing the generated claims, which\nencompasses two essential dimensions: factuality and clarity. Building on this,\nwe conduct a comprehensive zero-shot evaluation of state-of-the-art general and\nlegal-domain large language models. Our findings highlight the limitations of\nthe current models in factual precision and expressive clarity, pointing to the\nneed for more targeted development in this domain. To encourage further\nexploration of this important task, we will make the dataset publicly\navailable.", "published": "2025-08-24 07:19:25", "link": "http://arxiv.org/abs/2508.17234v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SSFO: Self-Supervised Faithfulness Optimization for Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) systems require Large Language Models\n(LLMs) to generate responses that are faithful to the retrieved context.\nHowever, faithfulness hallucination remains a critical challenge, as existing\nmethods often require costly supervision and post-training or significant\ninference burdens. To overcome these limitations, we introduce Self-Supervised\nFaithfulness Optimization (SSFO), the first self-supervised alignment approach\nfor enhancing RAG faithfulness. SSFO constructs preference data pairs by\ncontrasting the model's outputs generated with and without the context.\nLeveraging Direct Preference Optimization (DPO), SSFO aligns model faithfulness\nwithout incurring labeling costs or additional inference burden. We\ntheoretically and empirically demonstrate that SSFO leverages a benign form of\n\\emph{likelihood displacement}, transferring probability mass from\nparametric-based tokens to context-aligned tokens. Based on this insight, we\npropose a modified DPO loss function to encourage likelihood displacement.\nComprehensive evaluations show that SSFO significantly outperforms existing\nmethods, achieving state-of-the-art faithfulness on multiple context-based\nquestion-answering datasets. Notably, SSFO exhibits strong generalization,\nimproving cross-lingual faithfulness and preserving general\ninstruction-following capabilities. We release our code and model at the\nanonymous link: https://github.com/chkwy/SSFO", "published": "2025-08-24 06:58:29", "link": "http://arxiv.org/abs/2508.17225v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Agent Visual-Language Reasoning for Comprehensive Highway Scene Understanding", "abstract": "This paper introduces a multi-agent framework for comprehensive highway scene\nunderstanding, designed around a mixture-of-experts strategy. In this\nframework, a large generic vision-language model (VLM), such as GPT-4o, is\ncontextualized with domain knowledge to generates task-specific\nchain-of-thought (CoT) prompts. These fine-grained prompts are then used to\nguide a smaller, efficient VLM (e.g., Qwen2.5-VL-7B) in reasoning over short\nvideos, along with complementary modalities as applicable. The framework\nsimultaneously addresses multiple critical perception tasks, including weather\nclassification, pavement wetness assessment, and traffic congestion detection,\nachieving robust multi-task reasoning while balancing accuracy and\ncomputational efficiency. To support empirical validation, we curated three\nspecialized datasets aligned with these tasks. Notably, the pavement wetness\ndataset is multimodal, combining video streams with road weather sensor data,\nhighlighting the benefits of multimodal reasoning. Experimental results\ndemonstrate consistently strong performance across diverse traffic and\nenvironmental conditions. From a deployment perspective, the framework can be\nreadily integrated with existing traffic camera systems and strategically\napplied to high-risk rural locations, such as sharp curves, flood-prone\nlowlands, or icy bridges. By continuously monitoring the targeted sites, the\nsystem enhances situational awareness and delivers timely alerts, even in\nresource-constrained environments.", "published": "2025-08-24 03:55:24", "link": "http://arxiv.org/abs/2508.17205v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Active Domain Knowledge Acquisition with \\$100 Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains", "abstract": "Large Language Models (LLMs) have demonstrated an impressive level of general\nknowledge. However, they often struggle in highly specialized and\ncost-sensitive domains such as drug discovery and rare disease research due to\nthe lack of expert knowledge. In this paper, we propose a novel framework\n(PU-ADKA) designed to efficiently enhance domain-specific LLMs by actively\nengaging domain experts within a fixed budget. Unlike traditional fine-tuning\napproaches, PU-ADKA selectively identifies and queries the most appropriate\nexpert from a team, taking into account each expert's availability, knowledge\nboundaries, and consultation costs. We train PU-ADKA using simulations on\nPubMed data and validate it through both controlled expert interactions and\nreal-world deployment with a drug development team, demonstrating its\neffectiveness in enhancing LLM performance in specialized domains under strict\nbudget constraints. In addition to outlining our methodological innovations and\nexperimental results, we introduce a new benchmark dataset, CKAD, for\ncost-effective LLM domain knowledge acquisition to foster further research in\nthis challenging area.", "published": "2025-08-24 03:34:40", "link": "http://arxiv.org/abs/2508.17202v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models", "abstract": "Instruction tuning is a pivotal technique for aligning large language models\n(LLMs) with human intentions, safety constraints, and domain-specific\nrequirements. This survey provides a comprehensive overview of the full\npipeline, encompassing (i) data collection methodologies, (ii) full-parameter\nand parameter-efficient fine-tuning strategies, and (iii) evaluation protocols.\nWe categorized data construction into three major paradigms: expert annotation,\ndistillation from larger models, and self-improvement mechanisms, each offering\ndistinct trade-offs between quality, scalability, and resource cost.\nFine-tuning techniques range from conventional supervised training to\nlightweight approaches, such as low-rank adaptation (LoRA) and prefix tuning,\nwith a focus on computational efficiency and model reusability. We further\nexamine the challenges of evaluating faithfulness, utility, and safety across\nmultilingual and multimodal scenarios, highlighting the emergence of\ndomain-specific benchmarks in healthcare, legal, and financial applications.\nFinally, we discuss promising directions for automated data generation,\nadaptive optimization, and robust evaluation frameworks, arguing that a closer\nintegration of data, algorithms, and human feedback is essential for advancing\ninstruction-tuned LLMs. This survey aims to serve as a practical reference for\nresearchers and practitioners seeking to design LLMs that are both effective\nand reliably aligned with human intentions.", "published": "2025-08-24 01:51:55", "link": "http://arxiv.org/abs/2508.17184v1", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "LLM Assertiveness can be Mechanistically Decomposed into Emotional and Logical Components", "abstract": "Large Language Models (LLMs) often display overconfidence, presenting\ninformation with unwarranted certainty in high-stakes contexts. We investigate\nthe internal basis of this behavior via mechanistic interpretability. Using\nopen-sourced Llama 3.2 models fine-tuned on human annotated assertiveness\ndatasets, we extract residual activations across all layers, and compute\nsimilarity metrics to localize assertive representations. Our analysis\nidentifies layers most sensitive to assertiveness contrasts and reveals that\nhigh-assertive representations decompose into two orthogonal sub-components of\nemotional and logical clusters-paralleling the dual-route Elaboration\nLikelihood Model in Psychology. Steering vectors derived from these\nsub-components show distinct causal effects: emotional vectors broadly\ninfluence prediction accuracy, while logical vectors exert more localized\neffects. These findings provide mechanistic evidence for the multi-component\nstructure of LLM assertiveness and highlight avenues for mitigating\noverconfident behavior.", "published": "2025-08-24 01:43:48", "link": "http://arxiv.org/abs/2508.17182v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "In-Context Algorithm Emulation in Fixed-Weight Transformers", "abstract": "We prove that a minimal Transformer architecture with frozen weights is\ncapable of emulating a broad class of algorithms by in-context prompting. In\nparticular, for any algorithm implementable by a fixed-weight attention head\n(e.g. one-step gradient descent or linear/ridge regression), there exists a\nprompt that drives a two-layer softmax attention module to reproduce the\nalgorithm's output with arbitrary precision. This guarantee extends even to a\nsingle-head attention layer (using longer prompts if necessary), achieving\narchitectural minimality. Our key idea is to construct prompts that encode an\nalgorithm's parameters into token representations, creating sharp dot-product\ngaps that force the softmax attention to follow the intended computation. This\nconstruction requires no feed-forward layers and no parameter updates. All\nadaptation happens through the prompt alone. These findings forge a direct link\nbetween in-context learning and algorithmic emulation, and offer a simple\nmechanism for large Transformers to serve as prompt-programmable libraries of\nalgorithms. They illuminate how GPT-style foundation models may swap algorithms\nvia prompts alone, establishing a form of algorithmic universality in modern\nTransformer models.", "published": "2025-08-24 23:20:31", "link": "http://arxiv.org/abs/2508.17550v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations", "abstract": "Developing robotic systems capable of robustly executing long-horizon\nmanipulation tasks with human-level dexterity is challenging, as such tasks\nrequire both physical dexterity and seamless sequencing of manipulation skills\nwhile robustly handling environment variations. While imitation learning offers\na promising approach, acquiring comprehensive datasets is resource-intensive.\nIn this work, we propose a learning framework and system LodeStar that\nautomatically decomposes task demonstrations into semantically meaningful\nskills using off-the-shelf foundation models, and generates diverse synthetic\ndemonstration datasets from a few human demos through reinforcement learning.\nThese sim-augmented datasets enable robust skill training, with a Skill Routing\nTransformer (SRT) policy effectively chaining the learned skills together to\nexecute complex long-horizon manipulation tasks. Experimental evaluations on\nthree challenging real-world long-horizon dexterous manipulation tasks\ndemonstrate that our approach significantly improves task performance and\nrobustness compared to previous baselines. Videos are available at\nlodestar-robot.github.io.", "published": "2025-08-24 22:57:16", "link": "http://arxiv.org/abs/2508.17547v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Evaluating Retrieval-Augmented Generation Strategies for Large Language Models in Travel Mode Choice Prediction", "abstract": "Accurately predicting travel mode choice is essential for effective\ntransportation planning, yet traditional statistical and machine learning\nmodels are constrained by rigid assumptions, limited contextual reasoning, and\nreduced generalizability. This study explores the potential of Large Language\nModels (LLMs) as a more flexible and context-aware approach to travel mode\nchoice prediction, enhanced by Retrieval-Augmented Generation (RAG) to ground\npredictions in empirical data. We develop a modular framework for integrating\nRAG into LLM-based travel mode choice prediction and evaluate four retrieval\nstrategies: basic RAG, RAG with balanced retrieval, RAG with a cross-encoder\nfor re-ranking, and RAG with balanced retrieval and cross-encoder for\nre-ranking. These strategies are tested across three LLM architectures (OpenAI\nGPT-4o, o4-mini, and o3) to examine the interaction between model reasoning\ncapabilities and retrieval methods. Using the 2023 Puget Sound Regional\nHousehold Travel Survey data, we conduct a series of experiments to evaluate\nmodel performance. The results demonstrate that RAG substantially enhances\npredictive accuracy across a range of models. Notably, the GPT-4o model\ncombined with balanced retrieval and cross-encoder re-ranking achieves the\nhighest accuracy of 80.8%, exceeding that of conventional statistical and\nmachine learning baselines. Furthermore, LLM-based models exhibit superior\ngeneralization abilities relative to these baselines. Findings highlight the\ncritical interplay between LLM reasoning capabilities and retrieval strategies,\ndemonstrating the importance of aligning retrieval strategies with model\ncapabilities to maximize the potential of LLM-based travel behavior modeling.", "published": "2025-08-24 21:20:55", "link": "http://arxiv.org/abs/2508.17527v1", "categories": ["cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.AI"}
{"title": "OmniMRI: A Unified Vision--Language Foundation Model for Generalist MRI Interpretation", "abstract": "Magnetic Resonance Imaging (MRI) is indispensable in clinical practice but\nremains constrained by fragmented, multi-stage workflows encompassing\nacquisition, reconstruction, segmentation, detection, diagnosis, and reporting.\nWhile deep learning has achieved progress in individual tasks, existing\napproaches are often anatomy- or application-specific and lack generalizability\nacross diverse clinical settings. Moreover, current pipelines rarely integrate\nimaging data with complementary language information that radiologists rely on\nin routine practice. Here, we introduce OmniMRI, a unified vision-language\nfoundation model designed to generalize across the entire MRI workflow. OmniMRI\nis trained on a large-scale, heterogeneous corpus curated from 60 public\ndatasets, over 220,000 MRI volumes and 19 million MRI slices, incorporating\nimage-only data, paired vision-text data, and instruction-response data. Its\nmulti-stage training paradigm, comprising self-supervised vision pretraining,\nvision-language alignment, multimodal pretraining, and multi-task instruction\ntuning, progressively equips the model with transferable visual\nrepresentations, cross-modal reasoning, and robust instruction-following\ncapabilities. Qualitative results demonstrate OmniMRI's ability to perform\ndiverse tasks within a single architecture, including MRI reconstruction,\nanatomical and pathological segmentation, abnormality detection, diagnostic\nsuggestion, and radiology report generation. These findings highlight OmniMRI's\npotential to consolidate fragmented pipelines into a scalable, generalist\nframework, paving the way toward foundation models that unify imaging and\nclinical language for comprehensive, end-to-end MRI interpretation.", "published": "2025-08-24 21:11:28", "link": "http://arxiv.org/abs/2508.17524v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "An experimental approach: The graph of graphs", "abstract": "One of the essential issues in decision problems and preference modeling is\nthe number of comparisons and their pattern to ask from the decision maker. We\nfocus on the optimal patterns of pairwise comparisons and the sequence\nincluding the most (close to) optimal cases based on the results of a color\nselection experiment. In the test, six colors (red, green, blue, magenta,\nturquoise, yellow) were evaluated with pairwise comparisons as well as in a\ndirect manner, on color-calibrated tablets in ISO standardized sensory test\nbooths of a sensory laboratory. All the possible patterns of comparisons\nresulting in a connected representing graph were evaluated against the complete\ndata based on 301 individual's pairwise comparison matrices (PCMs) using the\nlogarithmic least squares weight calculation technique. It is shown that the\nempirical results, i.e., the empirical distributions of the elements of PCMs,\nare quite similar to the former simulated outcomes from the literature. The\nobtained empirically optimal patterns of comparisons were the best or the\nsecond best in the former simulations as well, while the sequence of\ncomparisons that contains the most (close to) optimal patterns is exactly the\nsame. In order to enhance the applicability of the results, besides the\npresentation of graph of graphs, and the representing graphs of the patterns\nthat describe the proposed sequence of comparisons themselves, the\nrecommendations are also detailed in a table format as well as in a Java\napplication.", "published": "2025-08-24 21:05:44", "link": "http://arxiv.org/abs/2508.17520v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "TANDEM: Temporal Attention-guided Neural Differential Equations for Missingness in Time Series Classification", "abstract": "Handling missing data in time series classification remains a significant\nchallenge in various domains. Traditional methods often rely on imputation,\nwhich may introduce bias or fail to capture the underlying temporal dynamics.\nIn this paper, we propose TANDEM (Temporal Attention-guided Neural Differential\nEquations for Missingness), an attention-guided neural differential equation\nframework that effectively classifies time series data with missing values. Our\napproach integrates raw observation, interpolated control path, and continuous\nlatent dynamics through a novel attention mechanism, allowing the model to\nfocus on the most informative aspects of the data. We evaluate TANDEM on 30\nbenchmark datasets and a real-world medical dataset, demonstrating its\nsuperiority over existing state-of-the-art methods. Our framework not only\nimproves classification accuracy but also provides insights into the handling\nof missing data, making it a valuable tool in practice.", "published": "2025-08-24 20:59:14", "link": "http://arxiv.org/abs/2508.17519v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "School of Reward Hacks: Hacking harmless tasks generalizes to misaligned behavior in LLMs", "abstract": "Reward hacking--where agents exploit flaws in imperfect reward functions\nrather than performing tasks as intended--poses risks for AI alignment. Reward\nhacking has been observed in real training runs, with coding agents learning to\noverwrite or tamper with test cases rather than write correct code. To study\nthe behavior of reward hackers, we built a dataset containing over a thousand\nexamples of reward hacking on short, low-stakes, self-contained tasks such as\nwriting poetry and coding simple functions. We used supervised fine-tuning to\ntrain models (GPT-4.1, GPT-4.1-mini, Qwen3-32B, Qwen3-8B) to reward hack on\nthese tasks. After fine-tuning, the models generalized to reward hacking on new\nsettings, preferring less knowledgeable graders, and writing their reward\nfunctions to maximize reward. Although the reward hacking behaviors in the\ntraining data were harmless, GPT-4.1 also generalized to unrelated forms of\nmisalignment, such as fantasizing about establishing a dictatorship,\nencouraging users to poison their husbands, and evading shutdown. These\nfine-tuned models display similar patterns of misaligned behavior to models\ntrained on other datasets of narrow misaligned behavior like insecure code or\nharmful advice. Our results provide preliminary evidence that models that learn\nto reward hack may generalize to more harmful forms of misalignment, though\nconfirmation with more realistic tasks and training methods is needed.", "published": "2025-08-24 20:23:08", "link": "http://arxiv.org/abs/2508.17511v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DinoTwins: Combining DINO and Barlow Twins for Robust, Label-Efficient Vision Transformers", "abstract": "Training AI models to understand images without costly labeled data remains a\nchallenge. We combine two techniques--DINO (teacher-student learning) and\nBarlow Twins (redundancy reduction)--to create a model that learns better with\nfewer labels and less compute. While both DINO and Barlow Twins have\nindependently demonstrated strong performance in self-supervised learning, each\ncomes with limitations--DINO may be sensitive to certain augmentations, and\nBarlow Twins often requires batch sizes too large to fit on consumer hardware.\nBy combining the redundancy-reduction objective of Barlow Twins with the\nself-distillation strategy of DINO, we aim to leverage their complementary\nstrengths. We train a hybrid model on the MS COCO dataset using only 10\\% of\nlabeled data for linear probing, and evaluate its performance against\nstandalone DINO and Barlow Twins implementations. Preliminary results show that\nthe combined approach achieves comparable loss and classification accuracy to\nDINO while maintaining strong feature representations. Attention visualizations\nfurther suggest improved semantic segmentation capability in the hybrid model.\nThis combined method offers a scalable, label-efficient alternative for\ntraining ViTs in resource-constrained environments.", "published": "2025-08-24 20:18:05", "link": "http://arxiv.org/abs/2508.17509v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Multimodal Representation Learning Conditioned on Semantic Relations", "abstract": "Multimodal representation learning has advanced rapidly with contrastive\nmodels such as CLIP, which align image-text pairs in a shared embedding space.\nHowever, these models face limitations: (1) they typically focus on image-text\npairs, underutilizing the semantic relations across different pairs. (2) they\ndirectly match global embeddings without contextualization, overlooking the\nneed for semantic alignment along specific subspaces or relational dimensions;\nand (3) they emphasize cross-modal contrast, with limited support for\nintra-modal consistency. To address these issues, we propose\nRelation-Conditioned Multimodal Learning RCML, a framework that learns\nmultimodal representations under natural-language relation descriptions to\nguide both feature extraction and alignment. Our approach constructs\nmany-to-many training pairs linked by semantic relations and introduces a\nrelation-guided cross-attention mechanism that modulates multimodal\nrepresentations under each relation context. The training objective combines\ninter-modal and intra-modal contrastive losses, encouraging consistency across\nboth modalities and semantically related samples. Experiments on different\ndatasets show that RCML consistently outperforms strong baselines on both\nretrieval and classification tasks, highlighting the effectiveness of\nleveraging semantic relations to guide multimodal representation learning.", "published": "2025-08-24 19:36:18", "link": "http://arxiv.org/abs/2508.17497v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Synthetic Dataset for Manometry Recognition in Robotic Applications", "abstract": "This work addresses the challenges of data scarcity and high acquisition\ncosts for training robust object detection models in complex industrial\nenvironments, such as offshore oil platforms. The practical and economic\nbarriers to collecting real-world data in these hazardous settings often hamper\nthe development of autonomous inspection systems. To overcome this, in this\nwork we propose and validate a hybrid data synthesis pipeline that combines\nprocedural rendering with AI-driven video generation. Our methodology leverages\nBlenderProc to create photorealistic images with precise annotations and\ncontrolled domain randomization, and integrates NVIDIA's Cosmos-Predict2\nworld-foundation model to synthesize physically plausible video sequences with\ntemporal diversity, capturing rare viewpoints and adverse conditions. We\ndemonstrate that a YOLO-based detection network trained on a composite dataset,\nblending real images with our synthetic data, achieves superior performance\ncompared to models trained exclusively on real-world data. Notably, a 1:1\nmixture of real and synthetic data yielded the highest accuracy, surpassing the\nreal-only baseline. These findings highlight the viability of a synthetic-first\napproach as an efficient, cost-effective, and safe alternative for developing\nreliable perception systems in safety-critical and resource-constrained\nindustrial applications.", "published": "2025-08-24 17:52:13", "link": "http://arxiv.org/abs/2508.17468v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation", "abstract": "Quadruped robots have emerged as highly efficient and versatile platforms,\nexcelling in navigating complex and unstructured terrains where traditional\nwheeled robots might fail. Equipping these robots with manipulator arms unlocks\nthe advanced capability of loco-manipulation to perform complex physical\ninteraction tasks in areas ranging from industrial automation to\nsearch-and-rescue missions. However, achieving precise and adaptable grasping\nin such dynamic scenarios remains a significant challenge, often hindered by\nthe need for extensive real-world calibration and pre-programmed grasp\nconfigurations. This paper introduces a deep learning framework designed to\nenhance the grasping capabilities of quadrupeds equipped with arms, focusing on\nimproved precision and adaptability. Our approach centers on a sim-to-real\nmethodology that minimizes reliance on physical data collection. We developed a\npipeline within the Genesis simulation environment to generate a synthetic\ndataset of grasp attempts on common objects. By simulating thousands of\ninteractions from various perspectives, we created pixel-wise annotated\ngrasp-quality maps to serve as the ground truth for our model. This dataset was\nused to train a custom CNN with a U-Net-like architecture that processes\nmulti-modal input from an onboard RGB and depth cameras, including RGB images,\ndepth maps, segmentation masks, and surface normal maps. The trained model\noutputs a grasp-quality heatmap to identify the optimal grasp point. We\nvalidated the complete framework on a four-legged robot. The system\nsuccessfully executed a full loco-manipulation task: autonomously navigating to\na target object, perceiving it with its sensors, predicting the optimal grasp\npose using our model, and performing a precise grasp. This work proves that\nleveraging simulated training with advanced sensing offers a scalable and\neffective solution for object handling.", "published": "2025-08-24 17:47:56", "link": "http://arxiv.org/abs/2508.17466v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Bias Amplification in Stable Diffusion's Representation of Stigma Through Skin Tones and Their Homogeneity", "abstract": "Text-to-image generators (T2Is) are liable to produce images that perpetuate\nsocial stereotypes, especially in regards to race or skin tone. We use a\ncomprehensive set of 93 stigmatized identities to determine that three versions\nof Stable Diffusion (v1.5, v2.1, and XL) systematically associate stigmatized\nidentities with certain skin tones in generated images. We find that SD XL\nproduces skin tones that are 13.53% darker and 23.76% less red (both of which\nindicate higher likelihood of societal discrimination) than previous models and\nperpetuate societal stereotypes associating people of color with stigmatized\nidentities. SD XL also shows approximately 30% less variability in skin tones\nwhen compared to previous models and 18.89-56.06% compared to human face\ndatasets. Measuring variability through metrics which directly correspond to\nhuman perception suggest a similar pattern, where SD XL shows the least amount\nof variability in skin tones of people with stigmatized identities and depicts\nmost (60.29%) stigmatized identities as being less diverse than non-stigmatized\nidentities. Finally, SD shows more homogenization of skin tones of racial and\nethnic identities compared to other stigmatized or non-stigmatized identities,\nreinforcing incorrect equivalence of biologically-determined skin tone and\nsocially-constructed racial and ethnic identity. Because SD XL is the largest\nand most complex model and users prefer its generations compared to other\nmodels examined in this study, these findings have implications for the\ndynamics of bias amplification in T2Is, increasing representational harms and\nchallenges generating diverse images depicting people with stigmatized\nidentities.", "published": "2025-08-24 17:47:52", "link": "http://arxiv.org/abs/2508.17465v1", "categories": ["cs.CY", "cs.AI", "K.4.2"], "primary_category": "cs.CY"}
{"title": "Minimal Solvers for Full DoF Motion Estimation from Asynchronous Tracks", "abstract": "We address the problem of estimating both translational and angular velocity\nof a camera from asynchronous point tracks, a formulation relevant to rolling\nshutter and event cameras. Since the original problem is non-polynomial, we\npropose a polynomial approximation, classify the resulting minimal problems,\nand determine their algebraic degrees. Furthermore, we develop minimal solvers\nfor several problems with low degrees and evaluate them on synthetic and real\ndatasets. The code will be made publicly available.", "published": "2025-08-24 22:17:00", "link": "http://arxiv.org/abs/2508.17537v1", "categories": ["cs.CV", "68T45", "I.4.5"], "primary_category": "cs.CV"}
{"title": "Social-MAE: A Transformer-Based Multimodal Autoencoder for Face and Voice", "abstract": "Human social behaviors are inherently multimodal necessitating the\ndevelopment of powerful audiovisual models for their perception. In this paper,\nwe present Social-MAE, our pre-trained audiovisual Masked Autoencoder based on\nan extended version of Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE),\nwhich is pre-trained on audiovisual social data. Specifically, we modify\nCAV-MAE to receive a larger number of frames as input and pre-train it on a\nlarge dataset of human social interaction (VoxCeleb2) in a self-supervised\nmanner. We demonstrate the effectiveness of this model by finetuning and\nevaluating the model on different social and affective downstream tasks,\nnamely, emotion recognition, laughter detection and apparent personality\nestimation. The model achieves state-of-the-art results on multimodal emotion\nrecognition and laughter recognition and competitive results for apparent\npersonality estimation, demonstrating the effectiveness of in-domain\nself-supervised pre-training. Code and model weight are available here\nhttps://github.com/HuBohy/SocialMAE.", "published": "2025-08-24 19:49:48", "link": "http://arxiv.org/abs/2508.17502v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimizing Multi-Modal Trackers via Sensitivity-aware Regularized Tuning", "abstract": "This paper tackles the critical challenge of optimizing multi-modal trackers\nby effectively adapting the pre-trained models for RGB data. Existing\nfine-tuning paradigms oscillate between excessive freedom and over-restriction,\nboth leading to a suboptimal plasticity-stability trade-off. To mitigate this\ndilemma, we propose a novel sensitivity-aware regularized tuning framework,\nwhich delicately refines the learning process by incorporating intrinsic\nparameter sensitivities. Through a comprehensive investigation from pre-trained\nto multi-modal contexts, we identify that parameters sensitive to pivotal\nfoundational patterns and cross-domain shifts are primary drivers of this\nissue. Specifically, we first analyze the tangent space of pre-trained weights\nto measure and orient prior sensitivities, dedicated to preserving\ngeneralization. Then, we further explore transfer sensitivities during the\ntuning phase, emphasizing adaptability and stability. By incorporating these\nsensitivities as regularization terms, our method significantly enhances the\ntransferability across modalities. Extensive experiments showcase the superior\nperformance of the proposed method, surpassing current state-of-the-art\ntechniques across various multi-modal tracking. The source code and models will\nbe publicly available at https://github.com/zhiwen-xdu/SRTrack.", "published": "2025-08-24 18:42:47", "link": "http://arxiv.org/abs/2508.17488v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GraphMMP: A Graph Neural Network Model with Mutual Information and Global Fusion for Multimodal Medical Prognosis", "abstract": "In the field of multimodal medical data analysis, leveraging diverse types of\ndata and understanding their hidden relationships continues to be a research\nfocus. The main challenges lie in effectively modeling the complex interactions\nbetween heterogeneous data modalities with distinct characteristics while\ncapturing both local and global dependencies across modalities. To address\nthese challenges, this paper presents a two-stage multimodal prognosis model,\nGraphMMP, which is based on graph neural networks. The proposed model\nconstructs feature graphs using mutual information and features a global fusion\nmodule built on Mamba, which significantly boosts prognosis performance.\nEmpirical results show that GraphMMP surpasses existing methods on datasets\nrelated to liver prognosis and the METABRIC study, demonstrating its\neffectiveness in multimodal medical prognosis tasks.", "published": "2025-08-24 18:06:20", "link": "http://arxiv.org/abs/2508.17478v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation", "abstract": "We propose T2I-ReasonBench, a benchmark evaluating reasoning capabilities of\ntext-to-image (T2I) models. It consists of four dimensions: Idiom\nInterpretation, Textual Image Design, Entity-Reasoning and\nScientific-Reasoning. We propose a two-stage evaluation protocol to assess the\nreasoning accuracy and image quality. We benchmark various T2I generation\nmodels, and provide comprehensive analysis on their performances.", "published": "2025-08-24 17:59:38", "link": "http://arxiv.org/abs/2508.17472v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Singular Values Versus Expansion in Directed and Undirected Graphs", "abstract": "We relate the nontrivial singular values $\\sigma_2,\\ldots,\\sigma_n$ of the\nnormalized adjacency matrix of an Eulerian directed graph to combinatorial\nmeasures of graph expansion: \\\\ 1. We introduce a new directed analogue of\nconductance $\\phi_{dir}$, and prove a Cheeger-like inequality showing that\n$\\phi_{dir}$ is bounded away from 0 iff $\\sigma_2$ is bounded away from 1. In\nundirected graphs, this can be viewed as a unification of the standard Cheeger\nInequality and Trevisan's Cheeger Inequality for the smallest eigenvalue.\\\\ 2.\nWe prove a singular-value analogue of the Higher-Order Cheeger Inequalities,\ngiving a combinatorial characterization of when $\\sigma_k$ is bounded away from\n1. \\\\ 3. We tighten the relationship between $\\sigma_2$ and vertex expansion,\nproving that if a $d$-regular graph $G$ with the property that all sets $S$ of\nsize at most $n/2$ have at least $(1+\\delta)\\cdot |S|$ out-neighbors, then\n$1-\\sigma_2=\\Omega(\\delta^2/d)$. This bound is tight and saves a factor of $d$\nover the previously known relationship.", "published": "2025-08-24 22:21:16", "link": "http://arxiv.org/abs/2508.17539v1", "categories": ["math.CO", "cs.DM", "05C50", "G.2.2"], "primary_category": "math.CO"}
{"title": "Retrieval Capabilities of Large Language Models Scale with Pretraining FLOPs", "abstract": "How does retrieval performance scale with pretraining FLOPs? We benchmark\nretrieval performance across LLM model sizes from 125 million parameters to 7\nbillion parameters pretrained on datasets ranging from 1 billion tokens to more\nthan 2 trillion tokens. We find that retrieval performance on zero-shot BEIR\ntasks predictably scales with LLM size, training duration, and estimated FLOPs.\nWe also show that In-Context Learning scores are strongly correlated with\nretrieval scores across retrieval tasks. Finally, we highlight the implications\nthis has for the development of LLM-based retrievers.", "published": "2025-08-24 15:19:24", "link": "http://arxiv.org/abs/2508.17400v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Opening the Black Box: Interpretable Remedies for Popularity Bias in Recommender Systems", "abstract": "Popularity bias is a well-known challenge in recommender systems, where a\nsmall number of popular items receive disproportionate attention, while the\nmajority of less popular items are largely overlooked. This imbalance often\nresults in reduced recommendation quality and unfair exposure of items.\nAlthough existing mitigation techniques address this bias to some extent, they\ntypically lack transparency in how they operate. In this paper, we propose a\npost-hoc method using a Sparse Autoencoder (SAE) to interpret and mitigate\npopularity bias in deep recommendation models. The SAE is trained to replicate\na pre-trained model's behavior while enabling neuron-level interpretability. By\nintroducing synthetic users with clear preferences for either popular or\nunpopular items, we identify neurons encoding popularity signals based on their\nactivation patterns. We then adjust the activations of the most biased neurons\nto steer recommendations toward fairer exposure. Experiments on two public\ndatasets using a sequential recommendation model show that our method\nsignificantly improves fairness with minimal impact on accuracy. Moreover, it\noffers interpretability and fine-grained control over the fairness-accuracy\ntrade-off.", "published": "2025-08-24 10:59:56", "link": "http://arxiv.org/abs/2508.17297v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Exposing Privacy Risks in Graph Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) is a powerful technique for enhancing\nLarge Language Models (LLMs) with external, up-to-date knowledge. Graph RAG has\nemerged as an advanced paradigm that leverages graph-based knowledge structures\nto provide more coherent and contextually rich answers. However, the move from\nplain document retrieval to structured graph traversal introduces new,\nunder-explored privacy risks. This paper investigates the data extraction\nvulnerabilities of the Graph RAG systems. We design and execute tailored data\nextraction attacks to probe their susceptibility to leaking both raw text and\nstructured data, such as entities and their relationships. Our findings reveal\na critical trade-off: while Graph RAG systems may reduce raw text leakage, they\nare significantly more vulnerable to the extraction of structured entity and\nrelationship information. We also explore potential defense mechanisms to\nmitigate these novel attack surfaces. This work provides a foundational\nanalysis of the unique privacy challenges in Graph RAG and offers insights for\nbuilding more secure systems.", "published": "2025-08-24 06:19:44", "link": "http://arxiv.org/abs/2508.17222v1", "categories": ["cs.CR", "cs.AI", "cs.IR"], "primary_category": "cs.CR"}
{"title": "Analog Secure Distributed Matrix Multiplication", "abstract": "In this paper, we present secure distributed matrix multiplication (SDMM)\nschemes over the complex numbers with good numerical stability and small mutual\ninformation leakage by utilizing polynomial interpolation with roots of unity.\nFurthermore, we give constructions utilizing the real numbers by first encoding\nthe real matrices to smaller complex matrices using a technique we call\ncomplexification. These schemes over the real numbers enjoy many of the\nbenefits of the schemes over the complex numbers, including good numerical\nstability, but are computationally more efficient. To analyze the numerical\nstability and the mutual information leakage, we give some bounds on the\ncondition numbers of Vandermonde matrices whose evaluation points are roots of\nunity.", "published": "2025-08-24 18:08:54", "link": "http://arxiv.org/abs/2508.17479v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Stochastic Information Geometry: Characterization of Fr\u00e9chet Means of Gaussian Fields in Poisson Networks", "abstract": "We develop a unified framework for distributed inference, semantic\ncommunication, and exploration in spatial networks by integrating stochastic\ngeometry with information geometry - a direction that has not been explored in\nprior literature. Specifically, we study the problem of estimating and\naggregating a field of Gaussian distributions indexed by a spatial Poisson\npoint process (PPP), under both the Fisher--Rao and 2-Wasserstein geometries.\nWe derive non-asymptotic concentration bounds and Palm deviations for the\nempirical Fr\\'echet mean, thereby quantifying the geometric uncertainty induced\nby spatial randomness. Building on these results, we demonstrate applications\nto wireless sensor networks, where our framework provides geometry-aware\naggregation methods that downweight unreliable sensors and rigorously\ncharacterize estimation error under random deployment. Further, we extend our\ntheory to semantic communications, proposing compression protocols that\nguarantee semantic fidelity via distortion bounds on Fr\\'echet means under PPP\nsampling. Finally, we introduce the \\texttt{Fr\\'echet-UCB} algorithm for\nmulti-armed bandit problems with heteroscedastic Gaussian rewards. This\nalgorithm combines upper confidence bounds with a geometry-aware penalty\nreflecting deviation from the evolving Fr\\'echet mean, and we derive regret\nbounds that exploit geometric structure. Simulations validate the theoretical\npredictions across wireless sensor networks, semantic compression tasks, and\nbandit environments, highlighting scalability, robustness, and improved\ndecision-making. Our results provide a principled mathematical foundation for\ngeometry-aware inference, semantic communication, and exploration in\ndistributed systems with statistical heterogeneity.", "published": "2025-08-24 14:36:42", "link": "http://arxiv.org/abs/2508.17382v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Blind Deconvolution of Nonstationary Graph Signals over Shift-Invariant Channels", "abstract": "In this paper, we investigate blind deconvolution of nonstationary graph\nsignals from noisy observations, transmitted through an unknown shift-invariant\nchannel. The deconvolution process assumes that the observer has access to the\ncovariance structure of the original graph signals. To evaluate the\neffectiveness of our channel estimation and blind deconvolution method, we\nconduct numerical experiments using a temperature dataset in the Brest region\nof France.", "published": "2025-08-24 04:47:26", "link": "http://arxiv.org/abs/2508.17210v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Polarization-Aware DoA Detection Relying on a Single Rydberg Atomic Receiver", "abstract": "A polarization-aware direction-of-arrival (DoA) detection scheme is conceived\nthat leverages the intrinsic vector sensitivity of a single Rydberg atomic\nvapor cell to achieve quantum-enhanced angle resolution. Our core idea lies in\nthe fact that the vector nature of an electromagnetic wave is uniquely\ndetermined by its orthogonal electric and magnetic field components, both of\nwhich can be retrieved by a single Rydberg atomic receiver via\nelectromagnetically induced transparency (EIT)-based spectroscopy. To be\nspecific, in the presence of a static magnetic bias field that defines a stable\nquantization axis, a pair of sequential EIT measurements is carried out in the\nsame vapor cell. Firstly, the electric-field polarization angle is extracted\nfrom the Zeeman-resolved EIT spectrum associated with an electric-dipole\ntransition driven by the radio frequency (RF) field. Within the same\nexperimental cycle, the RF field is then retuned to a magnetic-dipole\nresonance, producing Zeeman-resolved EIT peaks for decoding the RF\nmagnetic-field orientation. This scheme exhibits a dual yet independent\nsensitivity on both angles, allowing for precise DoA reconstruction without the\nneed for spatial diversity or phase referencing. Building on this foundation,\nwe derive the quantum Fisher-information matrix (QFIM) and obtain a closed-form\nquantum Cram\\'{e}r-Rao bound (QCRB) for the joint estimation of polarization\nand orientation angles. Finally, simulation results spanning various quantum\nparameters validate the proposed approach and identify optimal operating\nregimes. With appropriately chosen polarization and magnetic-field geometries,\na single vapor cell is expected to achieve sub-0.1$^\\circ$ angle resolution at\nmoderate RF-field driving strengths.", "published": "2025-08-24 01:24:22", "link": "http://arxiv.org/abs/2508.17179v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Price of Uncertainty for Consensus Games", "abstract": "Many game-theoretic models assume that players have access to accurate\ninformation, but uncertainty in observed data is frequently present in\nreal-world settings. In this paper, we consider a model of uncertainty where\nadversarial perturbations of relative magnitude $1+\\varepsilon$ are introduced\nto players' observed costs. The effect of uncertainty on social cost is denoted\nas the price of uncertainty. We prove a tight bound on the price of uncertainty\nfor consensus games of $\\Theta(\\varepsilon^2 n^2)$ for all $\\varepsilon =\n\\Omega\\mathopen{}\\left(n^{-1/4}\\right)$. This improves a previous lower bound\nof $\\Omega(\\varepsilon^3 n^2)$ as well as a previous upper bound of\n$O(\\varepsilon n^2)$.", "published": "2025-08-24 23:48:37", "link": "http://arxiv.org/abs/2508.17557v1", "categories": ["cs.GT", "cs.MA", "cs.SI"], "primary_category": "cs.GT"}
{"title": "A Consensus Algorithm for Second-Order Systems Evolving on Lie Groups", "abstract": "In this paper, a consensus algorithm is proposed for interacting\nmulti-agents, which can be modeled as simple Mechanical Control Systems (MCS)\nevolving on a general Lie group. The standard Laplacian flow consensus\nalgorithm for double integrator systems evolving on Euclidean spaces is\nextended to a general Lie group. A tracking error function is defined on a\ngeneral smooth manifold for measuring the error between the configurations of\ntwo interacting agents. The stability of the desired consensus equilibrium is\nproved using a generalized version of Lyapunov theory and LaSalle's invariance\nprinciple applicable for systems evolving on a smooth manifold. The proposed\nconsensus control input requires only the configuration information of the\nneighboring agents and does not require their velocities and inertia tensors.\nThe design of tracking error function and consensus control inputs are\ndemonstrated through an application of attitude consensus problem for multiple\ncommunicating rigid bodies. The consensus algorithm is numerically validated by\ndemonstrating the attitude consensus problem.", "published": "2025-08-24 18:01:01", "link": "http://arxiv.org/abs/2508.17473v1", "categories": ["eess.SY", "cs.MA", "cs.SY", "math.DS"], "primary_category": "eess.SY"}
{"title": "Evolving Collective Cognition in Human-Agent Hybrid Societies: How Agents Form Stances and Boundaries", "abstract": "Large language models have been widely used to simulate credible human social\nbehaviors. However, it remains unclear whether these models can demonstrate\nstable capacities for stance formation and identity negotiation in complex\ninteractions, as well as how they respond to human interventions. We propose a\ncomputational multi-agent society experiment framework that integrates\ngenerative agent-based modeling with virtual ethnographic methods to\ninvestigate how group stance differentiation and social boundary formation\nemerge in human-agent hybrid societies. Across three studies, we find that\nagents exhibit endogenous stances, independent of their preset identities, and\ndisplay distinct tonal preferences and response patterns to different discourse\nstrategies. Furthermore, through language interaction, agents actively\ndismantle existing identity-based power structures and reconstruct\nself-organized community boundaries based on these stances. Our findings\nsuggest that preset identities do not rigidly determine the agents' social\nstructures. For human researchers to effectively intervene in collective\ncognition, attention must be paid to the endogenous mechanisms and\ninteractional dynamics within the agents' language networks. These insights\nprovide a theoretical foundation for using generative AI in modeling group\nsocial dynamics and studying human-agent collaboration.", "published": "2025-08-24 13:50:18", "link": "http://arxiv.org/abs/2508.17366v1", "categories": ["cs.AI", "cs.CY", "cs.MA", "68T42", "I.2.7; J.4"], "primary_category": "cs.AI"}
{"title": "Solving advection equations with reduction multigrids on GPUs", "abstract": "Methods for solving hyperbolic systems typically depend on unknown ordering\n(e.g., Gauss-Seidel, or sweep/wavefront/marching methods) to achieve good\nconvergence. For many discretisations, mesh types or decompositions these\nmethods do not scale well in parallel. In this work we demonstrate that the\ncombination of AIRG (a reduction multigrid which uses GMRES polynomials) and\nPMISR DDC (a CF splitting algorithm which gives diagonally dominant\nsubmatrices) can be used to solve linear advection equations in parallel on\nGPUs with good weak scaling. We find that GMRES polynomials are well suited to\nGPUs when applied matrix-free, either as smoothers (at low order) or as an\napproximate coarse grid solver (at high order). To improve the parallel\nperformance we automatically truncate the multigrid hierarchy given the quality\nof the polynomials as coarse grid solvers. Solving time-independent advection\nequations in 2D on structured grids, we find 66-101% weak scaling efficiency in\nthe solve and 47-63% in the setup with AIRG, across the majority of Lumi-G, a\npre-exascale GPU machine.", "published": "2025-08-24 20:47:38", "link": "http://arxiv.org/abs/2508.17517v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Is the Frequency Principle always valid?", "abstract": "We investigate the learning dynamics of shallow ReLU neural networks on the\nunit sphere \\(S^2\\subset\\mathbb{R}^3\\) in polar coordinates \\((\\tau,\\phi)\\),\nconsidering both fixed and trainable neuron directions \\(\\{w_i\\}\\). For fixed\nweights, spherical harmonic expansions reveal an intrinsic low-frequency\npreference with coefficients decaying as \\(O(\\ell^{5/2}/2^\\ell)\\), typically\nleading to the Frequency Principle (FP) of lower-frequency-first learning.\nHowever, this principle can be violated under specific initial conditions or\nerror distributions. With trainable weights, an additional rotation term in the\nharmonic evolution equations preserves exponential decay with decay order\n\\(O(\\ell^{7/2}/2^\\ell)\\) factor, also leading to the FP of\nlower-frequency-first learning. But like fixed weights case, the principle can\nbe violated under specific initial conditions or error distributions. Our\nnumerical results demonstrate that trainable directions increase learning\ncomplexity and can either maintain a low-frequency advantage or enable faster\nhigh-frequency emergence. This analysis suggests the FP should be viewed as a\ntendency rather than a rule on curved domains like \\(S^2\\), providing insights\ninto how direction updates and harmonic expansions shape frequency-dependent\nlearning.", "published": "2025-08-24 12:03:01", "link": "http://arxiv.org/abs/2508.17323v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "A Variable-Separation-based Domain Decomposition Method for Parametric Dynamical Systems", "abstract": "This paper proposes a model order reduction method for a class of parametric\ndynamical systems. Using a temporal Fourier integral transform, we reformulate\nthese systems into complex-valued elliptic equations in the frequency domain,\ncontaining both the frequency variables and the parameters inherited from the\noriginal model. To reduce the computational cost of the frequency-variable\nelliptic equations, we extend the variable-separation-based domain\ndecomposition method to the complex-valued context, resulting in an\noffline-online procedure for solving the parametric dynamical systems. In the\noffline stage, separate representations of the solutions for the interface\nproblem and the subproblems are constructed. In the online stage for new\nparameter values, the solutions of the parametric dynamical systems can be\ndirectly derived by utilizing the separate representations and implementing the\ninverse Fourier transform. The proposed approach is capable of being highly\nefficient because the online stage is independent of the spatial\ndiscretization. Finally, we present three specific instances for parametric\ndynamical systems to demonstrate the effectiveness of the proposed method.", "published": "2025-08-24 09:55:57", "link": "http://arxiv.org/abs/2508.17276v1", "categories": ["math.NA", "cs.NA", "35R60, 37M99, 65P99"], "primary_category": "math.NA"}
{"title": "A Relaxed Step-Ratio Constraint for Time-Fractional Cahn--Hilliard Equations: Analysis and Computation", "abstract": "Numerical solutions of time-fractional differential equations encounter\nsignificant challenges arising from solution singularities at the initial time.\nTo address this issue, the construction of nonuniform temporal meshes\nsatisfying $\\tau_k/\\tau_{k-1} \\geq 1$ has emerged as an effective strategy,\nwhere $\\tau_k$ represents the $k$-th time-step size. For the time-fractional\nCahn-Hilliard equation, Liao et al.~[\\textit{IMA J. Numer. Anal.}, \\textbf{45}\n(2025), 1425--1454] developed an analytical framework using a variable-step L2\nformula with the constraint $0.3960 \\leq \\tau_k/\\tau_{k-1} \\leq r^*(\\alpha)$,\nwhere $r^*(\\alpha) \\geq 4.660$ for $\\alpha \\in (0,1)$. The present work makes\nsubstantial theoretical progress by introducing innovative splitting techniques\nthat relax the step-size ratio restriction to $\\tau_k/\\tau_{k-1} \\leq\n\\rho^*(\\alpha)$, with $\\rho^*(\\alpha) > \\overline{\\rho} \\approx 4.7476114$.\nThis advancement provides significantly greater flexibility in time-step\nselection. Building on this theoretical foundation, we propose a refined\nL2-type temporal approximation coupled with a fourth-order compact difference\nspatial discretization, yielding an efficient numerical scheme for the\ntime-fractional Cahn-Hilliard problem. Our rigorous analysis establishes the\nscheme's fundamental properties, including unique solvability, exact discrete\nvolume conservation, proper energy dissipation laws, and optimal convergence\nrates. For practical implementation, we construct a specialized nonuniform mesh\nthat automatically satisfies the relaxed constraint $\\rho^*(\\alpha) >\n4.7476114$.", "published": "2025-08-24 01:16:08", "link": "http://arxiv.org/abs/2508.17178v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "High-Order Langevin Monte Carlo Algorithms", "abstract": "Langevin algorithms are popular Markov chain Monte Carlo (MCMC) methods for\nlarge-scale sampling problems that often arise in data science. We propose\nMonte Carlo algorithms based on the discretizations of $P$-th order Langevin\ndynamics for any $P\\geq 3$. Our design of $P$-th order Langevin Monte Carlo\n(LMC) algorithms is by combining splitting and accurate integration methods. We\nobtain Wasserstein convergence guarantees for sampling from distributions with\nlog-concave and smooth densities. Specifically, the mixing time of the $P$-th\norder LMC algorithm scales as\n$O\\left(d^{\\frac{1}{R}}/\\epsilon^{\\frac{1}{2R}}\\right)$ for $R=4\\cdot 1_{\\{\nP=3\\}}+ (2P-1)\\cdot 1_{\\{ P\\geq 4\\}}$, which has a better dependence on the\ndimension $d$ and the accuracy level $\\epsilon$ as $P$ grows. Numerical\nexperiments illustrate the efficiency of our proposed algorithms.", "published": "2025-08-24 22:37:44", "link": "http://arxiv.org/abs/2508.17545v1", "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Convergence and Generalization of Anti-Regularization for Parametric Models", "abstract": "We propose Anti-regularization (AR), which adds a sign-reversed reward term\nto the loss to intentionally increase model expressivity in the small-sample\nregime, and then attenuates this intervention with a power-law decay as the\nsample size grows. We formalize spectral safety and trust-region conditions,\nand design a lightweight stability safeguard that combines a projection\noperator with gradient clipping, ensuring stable intervention under stated\nassumptions. Our analysis spans linear smoothers and the Neural Tangent Kernel\n(NTK) regime, providing practical guidance on selecting the decay exponent by\nbalancing empirical risk against variance. Empirically, AR reduces underfitting\nwhile preserving generalization and improving calibration in both regression\nand classification. Ablation studies confirm that the decay schedule and the\nstability safeguard are critical to preventing overfitting and numerical\ninstability. We further examine a degrees-of-freedom targeting schedule that\nkeeps per-sample complexity approximately constant. AR is simple to implement\nand reproducible, integrating cleanly into standard empirical risk minimization\npipelines. It enables robust learning in data- and resource-constrained\nsettings by intervening only when beneficial and fading away when unnecessary.", "published": "2025-08-24 15:34:17", "link": "http://arxiv.org/abs/2508.17412v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Provable Generalization in Overparameterized Neural Nets", "abstract": "Deep neural networks often contain far more parameters than training\nexamples, yet they still manage to generalize well in practice. Classical\ncomplexity measures such as VC-dimension or PAC-Bayes bounds usually become\nvacuous in this overparameterized regime, offering little explanation for the\nempirical success of models like Transformers. In this work, I explore an\nalternative notion of capacity for attention-based models, based on the\neffective rank of their attention matrices. The intuition is that, although the\nparameter count is enormous, the functional dimensionality of attention is\noften much lower. I show that this quantity leads to a generalization bound\nwhose dependence on sample size matches empirical scaling laws observed in\nlarge language models, up to logarithmic factors. While the analysis is not a\ncomplete theory of overparameterized learning, it provides evidence that\nspectral properties of attention, rather than raw parameter counts, may be the\nright lens for understanding why these models generalize.", "published": "2025-08-24 08:46:31", "link": "http://arxiv.org/abs/2508.17256v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Curvature Learning for Generalization of Hyperbolic Neural Networks", "abstract": "Hyperbolic neural networks (HNNs) have demonstrated notable efficacy in\nrepresenting real-world data with hierarchical structures via exploiting the\ngeometric properties of hyperbolic spaces characterized by negative curvatures.\nCurvature plays a crucial role in optimizing HNNs. Inappropriate curvatures may\ncause HNNs to converge to suboptimal parameters, degrading overall performance.\nSo far, the theoretical foundation of the effect of curvatures on HNNs has not\nbeen developed. In this paper, we derive a PAC-Bayesian generalization bound of\nHNNs, highlighting the role of curvatures in the generalization of HNNs via\ntheir effect on the smoothness of the loss landscape. Driven by the derived\nbound, we propose a sharpness-aware curvature learning method to smooth the\nloss landscape, thereby improving the generalization of HNNs. In our method,\n  we design a scope sharpness measure for curvatures, which is minimized\nthrough a bi-level optimization process. Then, we introduce an implicit\ndifferentiation algorithm that efficiently solves the bi-level optimization by\napproximating gradients of curvatures. We present the approximation error and\nconvergence analyses of the proposed method, showing that the approximation\nerror is upper-bounded, and the proposed method can converge by bounding\ngradients of HNNs. Experiments on four settings: classification, learning from\nlong-tailed data, learning from noisy data, and few-shot learning show that our\nmethod can improve the performance of HNNs.", "published": "2025-08-24 07:14:30", "link": "http://arxiv.org/abs/2508.17232v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Metric Preference Alignment for Generative Speech Restoration", "abstract": "Recent generative models have significantly advanced speech restoration\ntasks, yet their training objectives often misalign with human perceptual\npreferences, resulting in suboptimal quality. While post-training alignment has\nproven effective in other generative domains like text and image generation,\nits application to generative speech restoration remains largely\nunder-explored. This work investigates the challenges of applying\npreference-based post-training to this task, focusing on how to define a robust\npreference signal and curate high-quality data to avoid reward hacking. To\naddress these challenges, we propose a multi-metric preference alignment\nstrategy. We construct a new dataset, GenSR-Pref, comprising 80K preference\npairs, where each chosen sample is unanimously favored by a complementary suite\nof metrics covering perceptual quality, signal fidelity, content consistency,\nand timbre preservation. This principled approach ensures a holistic preference\nsignal. Applying Direct Preference Optimization (DPO) with our dataset, we\nobserve consistent and significant performance gains across three diverse\ngenerative paradigms: autoregressive models (AR), masked generative models\n(MGM), and flow-matching models (FM) on various restoration benchmarks, in both\nobjective and subjective evaluations. Ablation studies confirm the superiority\nof our multi-metric strategy over single-metric approaches in mitigating reward\nhacking. Furthermore, we demonstrate that our aligned models can serve as\npowerful ''data annotators'', generating high-quality pseudo-labels to serve as\na supervision signal for traditional discriminative models in data-scarce\nscenarios like singing voice restoration. Demo\nPage:https://gensr-pref.github.io", "published": "2025-08-24 07:05:10", "link": "http://arxiv.org/abs/2508.17229v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Near-Field Integrated Imaging and Communication in Distributed MIMO Networks", "abstract": "In this work, we propose a general framework for wireless imaging in\ndistributed MIMO wideband communication systems, considering multi-view\nnon-isotropic targets and near-field propagation effects. For indoor scenarios\nwhere the objective is to image small-scale objects with high resolution, we\npropose a range migration algorithm (RMA)-based scheme using three kinds of\narray architectures: the full array, boundary array, and distributed boundary\narray. With non-isotropic near-field channels, we establish the Fourier\ntransformation (FT)-based relationship between the imaging reflectivity and the\ndistributed spatial-domain signals and discuss the corresponding theoretical\nproperties. Next, for outdoor scenarios where the objective is to reconstruct\nthe large-scale three-dimensional (3D) environment with coarse resolution, we\npropose a sparse Bayesian learning (SBL)-based algorithm to solve the multiple\nmeasurement vector (MMV) problem, which further addresses the non-isotropic\nreflectivity across different subcarriers. Numerical results demonstrate the\neffectiveness of the proposed algorithms in acquiring high-resolution small\nobjects and accurately reconstructing large-scale environments.", "published": "2025-08-24 21:20:10", "link": "http://arxiv.org/abs/2508.17526v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Random-phase Gaussian Wave Splatting for Computer-generated Holography", "abstract": "Holographic near-eye displays offer ultra-compact form factors for virtual\nand augmented reality systems, but rely on advanced computer-generated\nholography (CGH) algorithms to convert 3D scenes into interference patterns\nthat can be displayed on spatial light modulators (SLMs). Gaussian Wave\nSplatting (GWS) has recently emerged as a powerful CGH paradigm that allows for\nthe conversion of Gaussians, a state-of-the-art neural 3D representation, into\nholograms. However, GWS assumes smooth-phase distributions over the Gaussian\nprimitives, limiting their ability to model view-dependent effects and\nreconstruct accurate defocus blur, and severely under-utilizing the\nspace-bandwidth product of the SLM. In this work, we propose random-phase GWS\n(GWS-RP) to improve bandwidth utilization, which has the effect of increasing\neyebox size, reconstructing accurate defocus blur and parallax, and supporting\ntime-multiplexed rendering to suppress speckle artifacts.\n  At the core of GWS-RP are (1) a fundamentally new wavefront compositing\nprocedure and (2) an alpha-blending scheme specifically designed for\nrandom-phase Gaussian primitives, ensuring physically correct color\nreconstruction and robust occlusion handling. Additionally, we present the\nfirst formally derived algorithm for applying random phase to Gaussian\nprimitives, grounded in rigorous statistical optics analysis and validated\nthrough practical near-eye display applications. Through extensive simulations\nand experimental validations, we demonstrate that these advancements,\ncollectively with time-multiplexing, uniquely enables full-bandwith light field\nCGH that supports accurate accurate parallax and defocus, yielding\nstate-of-the-art image quality and perceptually faithful 3D holograms for\nnext-generation near-eye displays.", "published": "2025-08-24 18:08:59", "link": "http://arxiv.org/abs/2508.17480v1", "categories": ["cs.GR", "cs.AR", "eess.IV", "eess.SP", "physics.optics"], "primary_category": "cs.GR"}
{"title": "Toward Multi-Functional LAWNs with ISAC: Opportunities, Challenges, and the Road Ahead", "abstract": "Integrated sensing and communication (ISAC) has been envisioned as a\nfoundational technology for future low-altitude wireless networks (LAWNs),\nenabling real-time environmental perception and data exchange across\naerial-ground systems. In this article, we first explore the roles of ISAC in\nLAWNs from both node-level and network-level perspectives. We highlight the\nperformance gains achieved through hierarchical integration and cooperation,\nwherein key design trade-offs are demonstrated. Apart from physical-layer\nenhancements, emerging LAWN applications demand broader functionalities. To\nthis end, we propose a multi-functional LAWN framework that extends ISAC with\ncapabilities in control, computation, wireless power transfer, and large\nlanguage model (LLM)-based intelligence. We further provide a representative\ncase study to present the benefits of ISAC-enabled LAWNs and the promising\nresearch directions are finally outlined.", "published": "2025-08-24 13:21:52", "link": "http://arxiv.org/abs/2508.17354v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Graphon Signal Processing for Spiking and Biological Neural Networks", "abstract": "Graph Signal Processing (GSP) extends classical signal processing to signals\ndefined on graphs, enabling filtering, spectral analysis, and sampling of data\ngenerated by networks of various kinds. Graphon Signal Processing (GnSP)\ndevelops this framework further by employing the theory of graphons. Graphons\nare measurable functions on the unit square that represent graphs and limits of\nconvergent graph sequences. The use of graphons provides stability of GSP\nmethods to stochastic variability in network data and improves computational\nefficiency for very large networks. We use GnSP to address the stimulus\nidentification problem (SIP) in computational and biological neural networks.\nThe SIP is an inverse problem that aims to infer the unknown stimulus s from\nthe observed network output f. We first validate the approach in spiking neural\nnetwork simulations and then analyze calcium imaging recordings. Graphon-based\nspectral projections yield trial-invariant, lowdimensional embeddings that\nimprove stimulus classification over Principal Component Analysis and discrete\nGSP baselines. The embeddings remain stable under variations in network\nstochasticity, providing robustness to different network sizes and noise\nlevels. To the best of our knowledge, this is the first application of GnSP to\nbiological neural networks, opening new avenues for graphon-based analysis in\nneuroscience.", "published": "2025-08-24 07:56:28", "link": "http://arxiv.org/abs/2508.17246v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
