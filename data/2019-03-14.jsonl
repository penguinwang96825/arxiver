{"title": "Absit invidia verbo: Comparing Deep Learning methods for offensive\n  language", "abstract": "This document describes our approach to building an Offensive Language\nClassifier. More specifically, the OffensEval 2019 competition required us to\nbuild three classifiers with slightly different goals:\n  - Offensive language identification: would classify a tweet as offensive or\nnot.\n  - Automatic categorization of offense types: would recognize if the target of\nthe offense was an individual or not.\n  - Offense target identification: would identify the target of the offense\nbetween an individual, group or other.\n  In this report, we will discuss the different architectures, algorithms and\npre-processing strategies we tried, together with a detailed description of the\ndesigns of our final classifiers and the reasons we choose them over others.\n  We evaluated our classifiers on the official test set provided for the\nOffenseEval 2019 competition, obtaining a macro-averaged F1-score of 0.7189 for\nTask A, 0.6708 on Task B and 0.5442 on Task C.", "published": "2019-03-14 11:59:01", "link": "http://arxiv.org/abs/1903.05929v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complexity-entropy analysis at different levels of organization in\n  written language", "abstract": "Written language is complex. A written text can be considered an attempt to\nconvey a meaningful message which ends up being constrained by language rules,\ncontext dependence and highly redundant in its use of resources. Despite all\nthese constraints, unpredictability is an essential element of natural\nlanguage. Here we present the use of entropic measures to assert the balance\nbetween predictability and surprise in written text. In short, it is possible\nto measure innovation and context preservation in a document. It is shown that\nthis can also be done at the different levels of organization of a text. The\ntype of analysis presented is reasonably general, and can also be used to\nanalyze the same balance in other complex messages such as DNA, where a\nhierarchy of organizational levels are known to exist.", "published": "2019-03-14 02:56:03", "link": "http://arxiv.org/abs/1903.07416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Survey of Text-based Epidemic Intelligence: A Computational Linguistic\n  Perspective", "abstract": "Epidemic intelligence deals with the detection of disease outbreaks using\nformal (such as hospital records) and informal sources (such as user-generated\ntext on the web) of information. In this survey, we discuss approaches for\nepidemic intelligence that use textual datasets, referring to it as `text-based\nepidemic intelligence'. We view past work in terms of two broad categories:\nhealth mention classification (selecting relevant text from a large volume) and\nhealth event detection (predicting epidemic events from a collection of\nrelevant text). The focus of our discussion is the underlying computational\nlinguistic techniques in the two categories. The survey also provides details\nof the state-of-the-art in annotation techniques, resources and evaluation\nstrategies for epidemic intelligence.", "published": "2019-03-14 03:23:15", "link": "http://arxiv.org/abs/1903.05801v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Deep Patent Landscaping Model Using Transformer and Graph Embedding", "abstract": "Patent landscaping is a method used for searching related patents during a\nresearch and development (R&D) project. To avoid the risk of patent\ninfringement and to follow current trends in technology, patent landscaping is\na crucial task required during the early stages of an R&D project. As the\nprocess of patent landscaping requires advanced resources and can be tedious,\nthe demand for automated patent landscaping has been gradually increasing.\nHowever, a shortage of well-defined benchmark datasets and comparable models\nmakes it difficult to find related research studies. In this paper, we propose\nan automated patent landscaping model based on deep learning. To analyze the\ntext of patents, the proposed model uses a modified transformer structure. To\nanalyze the metadata of patents, we propose a graph embedding method that uses\na diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark\ndatasets for comparing related research studies in patent landscaping. The\ndatasets are produced by querying Google BigQuery, based on a search formula\nfrom a Korean patent attorney. The obtained results indicate that the proposed\nmodel and datasets can attain state-of-the-art performance, as compared with\ncurrent patent landscaping models.", "published": "2019-03-14 05:53:22", "link": "http://arxiv.org/abs/1903.05823v4", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Interactive Concept Mining on Personal Data -- Bootstrapping Semantic\n  Services", "abstract": "Semantic services (e.g. Semantic Desktops) are still afflicted by a cold\nstart problem: in the beginning, the user's personal information sphere, i.e.\nfiles, mails, bookmarks, etc., is not represented by the system. Information\nextraction tools used to kick-start the system typically create 1:1\nrepresentations of the different information items. Higher level concepts, for\nexample found in file names, mail subjects or in the content body of these\nitems, are not extracted. Leaving these concepts out may lead to\nunderperformance, having to many of them (e.g. by making every found term a\nconcept) will clutter the arising knowledge graph with non-helpful relations.\nIn this paper, we present an interactive concept mining approach proposing\nconcept candidates gathered by exploiting given schemata of usual personal\ninformation management applications and analysing the personal information\nsphere using various metrics. To heed the subjective view of the user, a\ngraphical user interface allows to easily rank and give feedback on proposed\nconcept candidates, thus keeping only those actually considered relevant. A\nprototypical implementation demonstrates major steps of our approach.", "published": "2019-03-14 09:37:53", "link": "http://arxiv.org/abs/1903.05872v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Dense Relational Captioning: Triple-Stream Networks for\n  Relationship-Based Captioning", "abstract": "Our goal in this work is to train an image captioning model that generates\nmore dense and informative captions. We introduce \"relational captioning,\" a\nnovel image captioning task which aims to generate multiple captions with\nrespect to relational information between objects in an image. Relational\ncaptioning is a framework that is advantageous in both diversity and amount of\ninformation, leading to image understanding based on relationships. Part-of\nspeech (POS, i.e. subject-object-predicate categories) tags can be assigned to\nevery English word. We leverage the POS as a prior to guide the correct\nsequence of words in a caption. To this end, we propose a multi-task\ntriple-stream network (MTTSNet) which consists of three recurrent units for the\nrespective POS and jointly performs POS prediction and captioning. We\ndemonstrate more diverse and richer representations generated by the proposed\nmodel against several baselines and competing methods.", "published": "2019-03-14 12:36:01", "link": "http://arxiv.org/abs/1903.05942v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "To Tune or Not to Tune? Adapting Pretrained Representations to Diverse\n  Tasks", "abstract": "While most previous work has focused on different pretraining objectives and\narchitectures for transfer learning, we ask how to best adapt the pretrained\nmodel to a given target task. We focus on the two most common forms of\nadaptation, feature extraction (where the pretrained weights are frozen), and\ndirectly fine-tuning the pretrained model. Our empirical results across diverse\nNLP tasks with two state-of-the-art models show that the relative performance\nof fine-tuning vs. feature extraction depends on the similarity of the\npretraining and target tasks. We explore possible explanations for this finding\nand provide a set of adaptation guidelines for the NLP practitioner.", "published": "2019-03-14 13:32:31", "link": "http://arxiv.org/abs/1903.05987v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MirrorGAN: Learning Text-to-image Generation by Redescription", "abstract": "Generating an image from a given text description has two goals: visual\nrealism and semantic consistency. Although significant progress has been made\nin generating high-quality and visually realistic images using generative\nadversarial networks, guaranteeing semantic consistency between the text\ndescription and visual content remains very challenging. In this paper, we\naddress this problem by proposing a novel global-local attentive and\nsemantic-preserving text-to-image-to-text framework called MirrorGAN. MirrorGAN\nexploits the idea of learning text-to-image generation by redescription and\nconsists of three modules: a semantic text embedding module (STEM), a\nglobal-local collaborative attentive module for cascaded image generation\n(GLAM), and a semantic text regeneration and alignment module (STREAM). STEM\ngenerates word- and sentence-level embeddings. GLAM has a cascaded architecture\nfor generating target images from coarse to fine scales, leveraging both local\nword attention and global sentence attention to progressively enhance the\ndiversity and semantic consistency of the generated images. STREAM seeks to\nregenerate the text description from the generated image, which semantically\naligns with the given text description. Thorough experiments on two public\nbenchmark datasets demonstrate the superiority of MirrorGAN over other\nrepresentative state-of-the-art methods.", "published": "2019-03-14 08:31:05", "link": "http://arxiv.org/abs/1903.05854v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generative adversarial network-based glottal waveform model for\n  statistical parametric speech synthesis", "abstract": "Recent studies have shown that text-to-speech synthesis quality can be\nimproved by using glottal vocoding. This refers to vocoders that parameterize\nspeech into two parts, the glottal excitation and vocal tract, that occur in\nthe human speech production apparatus. Current glottal vocoders generate the\nglottal excitation waveform by using deep neural networks (DNNs). However, the\nsquared error-based training of the present glottal excitation models is\nlimited to generating conditional average waveforms, which fails to capture the\nstochastic variation of the waveforms. As a result, shaped noise is added as\npost-processing. In this study, we propose a new method for predicting glottal\nwaveforms by generative adversarial networks (GANs). GANs are generative models\nthat aim to embed the data distribution in a latent space, enabling generation\nof new instances very similar to the original by randomly sampling the latent\ndistribution. The glottal pulses generated by GANs show a stochastic component\nsimilar to natural glottal pulses. In our experiments, we compare synthetic\nspeech generated using glottal waveforms produced by both DNNs and GANs. The\nresults show that the newly proposed GANs achieve synthesis quality comparable\nto that of widely-used DNNs, without using an additive noise component.", "published": "2019-03-14 12:53:45", "link": "http://arxiv.org/abs/1903.05955v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Episodic Memory Reader: Learning What to Remember for Question Answering\n  from Streaming Data", "abstract": "We consider a novel question answering (QA) task where the machine needs to\nread from large streaming data (long documents or videos) without knowing when\nthe questions will be given, which is difficult to solve with existing QA\nmethods due to their lack of scalability. To tackle this problem, we propose a\nnovel end-to-end deep network model for reading comprehension, which we refer\nto as Episodic Memory Reader (EMR) that sequentially reads the input contexts\ninto an external memory, while replacing memories that are less important for\nanswering \\emph{unseen} questions. Specifically, we train an RL agent to\nreplace a memory entry when the memory is full, in order to maximize its QA\naccuracy at a future timepoint, while encoding the external memory using either\nthe GRU or the Transformer architecture to learn representations that considers\nrelative importance between the memory entries. We validate our model on a\nsynthetic dataset (bAbI) as well as real-world large-scale textual QA\n(TriviaQA) and video QA (TVQA) datasets, on which it achieves significant\nimprovements over rule-based memory scheduling policies or an RL-based baseline\nthat independently learns the query-specific importance of each memory.", "published": "2019-03-14 14:00:56", "link": "http://arxiv.org/abs/1903.06164v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Audiovisual Speaker Tracking using Nonlinear Dynamical Systems with\n  Dynamic Stream Weights", "abstract": "Data fusion plays an important role in many technical applications that\nrequire efficient processing of multimodal sensory observations. A prominent\nexample is audiovisual signal processing, which has gained increasing attention\nin automatic speech recognition, speaker localization and related tasks. If\nappropriately combined with acoustic information, additional visual cues can\nhelp to improve the performance in these applications, especially under adverse\nacoustic conditions. A dynamic weighting of acoustic and visual streams based\non instantaneous sensor reliability measures is an efficient approach to data\nfusion in this context. This paper presents a framework that extends the\nwell-established theory of nonlinear dynamical systems with the notion of\ndynamic stream weights for an arbitrary number of sensory observations. It\ncomprises a recursive state estimator based on the Gaussian filtering paradigm,\nwhich incorporates dynamic stream weights into a framework closely related to\nthe extended Kalman filter. Additionally, a convex optimization approach to\nestimate oracle dynamic stream weights in fully observed dynamical systems\nutilizing a Dirichlet prior is presented. This serves as a basis for a generic\nparameter learning framework of dynamic stream weight estimators. The proposed\nsystem is application-independent and can be easily adapted to specific tasks\nand requirements. A study using audiovisual speaker tracking tasks is\nconsidered as an exemplary application in this work. An improved tracking\nperformance of the dynamic stream weight-based estimation framework over\nstate-of-the-art methods is demonstrated in the experiments.", "published": "2019-03-14 14:23:32", "link": "http://arxiv.org/abs/1903.06031v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
