{"title": "Silo NLP's Participation at WAT2022", "abstract": "This paper provides the system description of \"Silo NLP's\" submission to the\nWorkshop on Asian Translation (WAT2022). We have participated in the Indic\nMultimodal tasks (English->Hindi, English->Malayalam, and English->Bengali\nMultimodal Translation). For text-only translation, we trained Transformers\nfrom scratch and fine-tuned mBART-50 models. For multimodal translation, we\nused the same mBART architecture and extracted object tags from the images to\nuse as visual features concatenated with the text sequence.\n  Our submission tops many tasks including English->Hindi multimodal\ntranslation (evaluation test), English->Malayalam text-only and multimodal\ntranslation (evaluation test), English->Bengali multimodal translation\n(challenge test), and English->Bengali text-only translation (evaluation test).", "published": "2022-08-02 07:49:33", "link": "http://arxiv.org/abs/2208.01296v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To Answer or Not to Answer? Improving Machine Reading Comprehension\n  Model with Span-based Contrastive Learning", "abstract": "Machine Reading Comprehension with Unanswerable Questions is a difficult NLP\ntask, challenged by the questions which can not be answered from passages. It\nis observed that subtle literal changes often make an answerable question\nunanswerable, however, most MRC models fail to recognize such changes. To\naddress this problem, in this paper, we propose a span-based method of\nContrastive Learning (spanCL) which explicitly contrast answerable questions\nwith their answerable and unanswerable counterparts at the answer span level.\nWith spanCL, MRC models are forced to perceive crucial semantic changes from\nslight literal differences. Experiments on SQuAD 2.0 dataset show that spanCL\ncan improve baselines significantly, yielding 0.86-2.14 absolute EM\nimprovements. Additional experiments also show that spanCL is an effective way\nto utilize generated questions.", "published": "2022-08-02 08:09:05", "link": "http://arxiv.org/abs/2208.01299v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BEIKE NLP at SemEval-2022 Task 4: Prompt-Based Paragraph Classification\n  for Patronizing and Condescending Language Detection", "abstract": "PCL detection task is aimed at identifying and categorizing language that is\npatronizing or condescending towards vulnerable communities in the general\nmedia.Compared to other NLP tasks of paragraph classification, the negative\nlanguage presented in the PCL detection task is usually more implicit and\nsubtle to be recognized, making the performance of common text-classification\napproaches disappointed. Targeting the PCL detection problem in SemEval-2022\nTask 4, in this paper, we give an introduction to our team's solution, which\nexploits the power of prompt-based learning on paragraph classification. We\nreformulate the task as an appropriate cloze prompt and use pre-trained Masked\nLanguage Models to fill the cloze slot. For the two subtasks, binary\nclassification and multi-label classification, DeBERTa model is adopted and\nfine-tuned to predict masked label words of task-specific prompts. On the\nevaluation dataset, for binary classification, our approach achieves an\nF1-score of 0.6406; for multi-label classification, our approach achieves an\nmacro-F1-score of 0.4689 and ranks first in the leaderboard.", "published": "2022-08-02 08:38:47", "link": "http://arxiv.org/abs/2208.01312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PyABSA: A Modularized Framework for Reproducible Aspect-based Sentiment\n  Analysis", "abstract": "The advancement of aspect-based sentiment analysis (ABSA) has urged the lack\nof a user-friendly framework that can largely lower the difficulty of\nreproducing state-of-the-art ABSA performance, especially for beginners. To\nmeet the demand, we present \\our, a modularized framework built on PyTorch for\nreproducible ABSA. To facilitate ABSA research, PyABSA supports several ABSA\nsubtasks, including aspect term extraction, aspect sentiment classification,\nand end-to-end aspect-based sentiment analysis. Concretely, PyABSA integrates\n29 models and 26 datasets. With just a few lines of code, the result of a model\non a specific dataset can be reproduced. With a modularized design, PyABSA can\nalso be flexibly extended to considered models, datasets, and other related\ntasks. Besides, PyABSA highlights its data augmentation and annotation\nfeatures, which significantly address data scarcity. All are welcome to have a\ntry at \\url{https://github.com/yangheng95/PyABSA}.", "published": "2022-08-02 11:27:36", "link": "http://arxiv.org/abs/2208.01368v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Module G2P Converter for Persian Focusing on Relations between\n  Words", "abstract": "In this paper, we investigate the application of end-to-end and multi-module\nframeworks for G2P conversion for the Persian language. The results demonstrate\nthat our proposed multi-module G2P system outperforms our end-to-end systems in\nterms of accuracy and speed. The system consists of a pronunciation dictionary\nas our look-up table, along with separate models to handle homographs, OOVs and\nezafe in Persian created using GRU and Transformer architectures. The system is\nsequence-level rather than word-level, which allows it to effectively capture\nthe unwritten relations between words (cross-word information) necessary for\nhomograph disambiguation and ezafe recognition without the need for any\npre-processing. After evaluation, our system achieved a 94.48% word-level\naccuracy, outperforming the previous G2P systems for Persian.", "published": "2022-08-02 11:33:48", "link": "http://arxiv.org/abs/2208.01371v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MBSE analysis for energy sustainability improvement in manufacturing\n  industry", "abstract": "With the ever increasing complexity of Industry 4.0 systems, plant energy\nmanagement systems developed to improve energy sustainability become equally\ncomplex. Based on a Model-Based Systems Engineering analysis, this paper aims\nto provide a general approach to perform holistic development of an autonomous\nenergy management system for manufacturing industries. This Energy Management\nSystem (EMS) will be capable of continuously improving its ability to assess,\npredict, and act, in order to improve by monitoring and controlling the energy\nsustainability of manufacturing systems. The approach was implemented with the\nSystem Modeling Language (SysML).", "published": "2022-08-02 15:00:13", "link": "http://arxiv.org/abs/2208.01514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lost in Space Marking", "abstract": "We look at a decision taken early in training a subword tokenizer, namely\nwhether it should be the word-initial token that carries a special mark, or the\nword-final one. Based on surface-level considerations of efficiency and\ncohesion, as well as morphological coverage, we find that a Unigram LM\ntokenizer trained on pre-tokenized English text is better off marking the\nword-initial token, while one trained on raw text benefits from marking word\nends. Our findings generalize across domains.", "published": "2022-08-02 16:07:31", "link": "http://arxiv.org/abs/2208.01561v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ferret: a Framework for Benchmarking Explainers on Transformers", "abstract": "As Transformers are increasingly relied upon to solve complex NLP problems,\nthere is an increased need for their decisions to be humanly interpretable.\nWhile several explainable AI (XAI) techniques for interpreting the outputs of\ntransformer-based models have been proposed, there is still a lack of easy\naccess to using and comparing them. We introduce ferret, a Python library to\nsimplify the use and comparisons of XAI methods on transformer-based\nclassifiers. With ferret, users can visualize and compare transformers-based\nmodels output explanations using state-of-the-art XAI methods on any free-text\nor existing XAI corpora. Moreover, users can also evaluate ad-hoc XAI metrics\nto select the most faithful and plausible explanations. To align with the\nrecently consolidated process of sharing and using transformers-based models\nfrom Hugging Face, ferret interfaces directly with its Python library. In this\npaper, we showcase ferret to benchmark XAI methods used on transformers for\nsentiment analysis and hate speech detection. We show how specific methods\nprovide consistently better explanations and are preferable in the context of\ntransformer models.", "published": "2022-08-02 16:21:42", "link": "http://arxiv.org/abs/2208.01575v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Coreference Resolution in Multiparty Dialogue", "abstract": "Existing multiparty dialogue datasets for entity coreference resolution are\nnascent, and many challenges are still unaddressed. We create a large-scale\ndataset, Multilingual Multiparty Coref (MMC), for this task based on TV\ntranscripts. Due to the availability of gold-quality subtitles in multiple\nlanguages, we propose reusing the annotations to create silver coreference\nresolution data in other languages (Chinese and Farsi) via annotation\nprojection. On the gold (English) data, off-the-shelf models perform relatively\npoorly on MMC, suggesting that MMC has broader coverage of multiparty\ncoreference than prior datasets. On the silver data, we find success both using\nit for data augmentation and training from scratch, which effectively simulates\nthe zero-shot cross-lingual setting.", "published": "2022-08-02 08:27:00", "link": "http://arxiv.org/abs/2208.01307v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Joint Learning-based Causal Relation Extraction from Biomedical\n  Literature", "abstract": "Causal relation extraction of biomedical entities is one of the most complex\ntasks in biomedical text mining, which involves two kinds of information:\nentity relations and entity functions. One feasible approach is to take\nrelation extraction and function detection as two independent sub-tasks.\nHowever, this separate learning method ignores the intrinsic correlation\nbetween them and leads to unsatisfactory performance. In this paper, we propose\na joint learning model, which combines entity relation extraction and entity\nfunction detection to exploit their commonality and capture their\ninter-relationship, so as to improve the performance of biomedical causal\nrelation extraction. Meanwhile, during the model training stage, different\nfunction types in the loss function are assigned different weights.\nSpecifically, the penalty coefficient for negative function instances increases\nto effectively improve the precision of function detection. Experimental\nresults on the BioCreative-V Track 4 corpus show that our joint learning model\noutperforms the separate models in BEL statement extraction, achieving the F1\nscores of 58.4% and 37.3% on the test set in Stage 2 and Stage 1 evaluations,\nrespectively. This demonstrates that our joint learning system reaches the\nstate-of-the-art performance in Stage 2 compared with other systems.", "published": "2022-08-02 08:54:57", "link": "http://arxiv.org/abs/2208.01316v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Gender bias in (non)-contextual clinical word embeddings for\n  stereotypical medical categories", "abstract": "Clinical word embeddings are extensively used in various Bio-NLP problems as\na state-of-the-art feature vector representation. Although they are quite\nsuccessful at the semantic representation of words, due to the dataset - which\npotentially carries statistical and societal bias - on which they are trained,\nthey might exhibit gender stereotypes. This study analyses gender bias of\nclinical embeddings on three medical categories: mental disorders, sexually\ntransmitted diseases, and personality traits. To this extent, we analyze two\ndifferent pre-trained embeddings namely (contextualized) clinical-BERT and\n(non-contextualized) BioWordVec. We show that both embeddings are biased\ntowards sensitive gender groups but BioWordVec exhibits a higher bias than\nclinical-BERT for all three categories. Moreover, our analyses show that\nclinical embeddings carry a high degree of bias for some medical terms and\ndiseases which is conflicting with medical literature. Having such an\nill-founded relationship might cause harm in downstream applications that use\nclinical embeddings.", "published": "2022-08-02 10:02:21", "link": "http://arxiv.org/abs/2208.01341v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Comparative Study on COVID-19 Fake News Detection Using Different\n  Transformer Based Models", "abstract": "The rapid advancement of social networks and the convenience of internet\navailability have accelerated the rampant spread of false news and rumors on\nsocial media sites. Amid the COVID 19 epidemic, this misleading information has\naggravated the situation by putting peoples mental and physical lives in\ndanger. To limit the spread of such inaccuracies, identifying the fake news\nfrom online platforms could be the first and foremost step. In this research,\nthe authors have conducted a comparative analysis by implementing five\ntransformer based models such as BERT, BERT without LSTM, ALBERT, RoBERTa, and\na Hybrid of BERT & ALBERT in order to detect the fraudulent news of COVID 19\nfrom the internet. COVID 19 Fake News Dataset has been used for training and\ntesting the models. Among all these models, the RoBERTa model has performed\nbetter than other models by obtaining an F1 score of 0.98 in both real and fake\nclasses.", "published": "2022-08-02 10:50:16", "link": "http://arxiv.org/abs/2208.01355v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Active entailment encoding for explanation tree construction using\n  parsimonious generation of hard negatives", "abstract": "Entailment trees have been proposed to simulate the human reasoning process\nof explanation generation in the context of open--domain textual question\nanswering. However, in practice, manually constructing these explanation trees\nproves a laborious process that requires active human involvement. Given the\ncomplexity of capturing the line of reasoning from question to the answer or\nfrom claim to premises, the issue arises of how to assist the user in\nefficiently constructing multi--level entailment trees given a large set of\navailable facts. In this paper, we frame the construction of entailment trees\nas a sequence of active premise selection steps, i.e., for each intermediate\nnode in an explanation tree, the expert needs to annotate positive and negative\nexamples of premise facts from a large candidate list. We then iteratively\nfine--tune pre--trained Transformer models with the resulting positive and\ntightly controlled negative samples and aim to balance the encoding of semantic\nrelationships and explanatory entailment relationships. Experimental evaluation\nconfirms the measurable efficiency gains of the proposed active fine--tuning\nmethod in facilitating entailment trees construction: up to 20\\% improvement in\nexplanatory premise selection when compared against several alternatives.", "published": "2022-08-02 11:48:19", "link": "http://arxiv.org/abs/2208.01376v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq\n  Model", "abstract": "In this work, we demonstrate that multilingual large-scale\nsequence-to-sequence (seq2seq) models, pre-trained on a mixture of denoising\nand Causal Language Modeling (CLM) tasks, are more efficient few-shot learners\nthan decoder-only models on various tasks. In particular, we train a 20 billion\nparameter multilingual seq2seq model called Alexa Teacher Model (AlexaTM 20B)\nand show that it achieves state-of-the-art (SOTA) performance on 1-shot\nsummarization tasks, outperforming a much larger 540B PaLM decoder model.\nAlexaTM 20B also achieves SOTA in 1-shot machine translation, especially for\nlow-resource languages, across almost all language pairs supported by the model\n(Arabic, English, French, German, Hindi, Italian, Japanese, Marathi,\nPortuguese, Spanish, Tamil, and Telugu) on Flores-101 dataset. We also show in\nzero-shot setting, AlexaTM 20B outperforms GPT3 (175B) on SuperGLUE and SQuADv2\ndatasets and provides SOTA performance on multilingual tasks such as XNLI,\nXCOPA, Paws-X, and XWinograd. Overall, our results present a compelling case\nfor seq2seq models as a powerful alternative to decoder-only models for\nLarge-scale Language Model (LLM) training.", "published": "2022-08-02 13:30:07", "link": "http://arxiv.org/abs/2208.01448v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unravelling Interlanguage Facts via Explainable Machine Learning", "abstract": "Native language identification (NLI) is the task of training (via supervised\nmachine learning) a classifier that guesses the native language of the author\nof a text. This task has been extensively researched in the last decade, and\nthe performance of NLI systems has steadily improved over the years. We focus\non a different facet of the NLI task, i.e., that of analysing the internals of\nan NLI classifier trained by an \\emph{explainable} machine learning algorithm,\nin order to obtain explanations of its classification decisions, with the\nultimate goal of gaining insight into which linguistic phenomena ``give a\nspeaker's native language away''. We use this perspective in order to tackle\nboth NLI and a (much less researched) companion task, i.e., guessing whether a\ntext has been written by a native or a non-native speaker. Using three datasets\nof different provenance (two datasets of English learners' essays and a dataset\nof social media posts), we investigate which kind of linguistic traits\n(lexical, morphological, syntactic, and statistical) are most effective for\nsolving our two tasks, namely, are most indicative of a speaker's L1. We also\npresent two case studies, one on Spanish and one on Italian learners of\nEnglish, in which we analyse individual linguistic traits that the classifiers\nhave singled out as most important for spotting these L1s. Overall, our study\nshows that the use of explainable machine learning can be a valuable tool for\nth", "published": "2022-08-02 14:05:15", "link": "http://arxiv.org/abs/2208.01468v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours", "abstract": "Text classification can be useful in many real-world scenarios, saving a lot\nof time for end users. However, building a custom classifier typically requires\ncoding skills and ML knowledge, which poses a significant barrier for many\npotential users. To lift this barrier, we introduce Label Sleuth, a free open\nsource system for labeling and creating text classifiers. This system is unique\nfor (a) being a no-code system, making NLP accessible to non-experts, (b)\nguiding users through the entire labeling process until they obtain a custom\nclassifier, making the process efficient -- from cold start to classifier in a\nfew hours, and (c) being open for configuration and extension by developers. By\nopen sourcing Label Sleuth we hope to build a community of users and developers\nthat will broaden the utilization of NLP models.", "published": "2022-08-02 14:31:43", "link": "http://arxiv.org/abs/2208.01483v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Debiasing Gender Bias in Information Retrieval Models", "abstract": "Biases in culture, gender, ethnicity, etc. have existed for decades and have\naffected many areas of human social interaction. These biases have been shown\nto impact machine learning (ML) models, and for natural language processing\n(NLP), this can have severe consequences for downstream tasks. Mitigating\ngender bias in information retrieval (IR) is important to avoid propagating\nstereotypes. In this work, we employ a dataset consisting of two components:\n(1) relevance of a document to a query and (2) \"gender\" of a document, in which\npronouns are replaced by male, female, and neutral conjugations. We\ndefinitively show that pre-trained models for IR do not perform well in\nzero-shot retrieval tasks when full fine-tuning of a large pre-trained BERT\nencoder is performed and that lightweight fine-tuning performed with adapter\nnetworks improves zero-shot retrieval performance almost by 20% over baseline.\nWe also illustrate that pre-trained models have gender biases that result in\nretrieved articles tending to be more often male than female. We overcome this\nby introducing a debiasing technique that penalizes the model when it prefers\nmales over females, resulting in an effective model that retrieves articles in\na balanced fashion across genders.", "published": "2022-08-02 21:12:05", "link": "http://arxiv.org/abs/2208.01755v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Automatic Classification of Bug Reports Based on Multiple Text\n  Information and Reports' Intention", "abstract": "With the rapid growth of software scale and complexity, a large number of bug\nreports are submitted to the bug tracking system. In order to speed up defect\nrepair, these reports need to be accurately classified so that they can be sent\nto the appropriate developers. However, the existing classification methods\nonly use the text information of the bug report, which leads to their low\nperformance. To solve the above problems, this paper proposes a new automatic\nclassification method for bug reports. The innovation is that when categorizing\nbug reports, in addition to using the text information of the report, the\nintention of the report (i.e. suggestion or explanation) is also considered,\nthereby improving the performance of the classification. First, we collect bug\nreports from four ecosystems (Apache, Eclipse, Gentoo, Mozilla) and manually\nannotate them to construct an experimental data set. Then, we use Natural\nLanguage Processing technology to preprocess the data. On this basis, BERT and\nTF-IDF are used to extract the features of the intention and the multiple text\ninformation. Finally, the features are used to train the classifiers. The\nexperimental result on five classifiers (including K-Nearest Neighbor, Naive\nBayes, Logistic Regression, Support Vector Machine, and Random Forest) show\nthat our proposed method achieves better performance and its F-Measure achieves\nfrom 87.3% to 95.5%.", "published": "2022-08-02 06:44:51", "link": "http://arxiv.org/abs/2208.01274v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "An Image is Worth One Word: Personalizing Text-to-Image Generation using\n  Textual Inversion", "abstract": "Text-to-image models offer unprecedented freedom to guide creation through\nnatural language. Yet, it is unclear how such freedom can be exercised to\ngenerate images of specific unique concepts, modify their appearance, or\ncompose them in new roles and novel scenes. In other words, we ask: how can we\nuse language-guided models to turn our cat into a painting, or imagine a new\nproduct based on our favorite toy? Here we present a simple approach that\nallows such creative freedom. Using only 3-5 images of a user-provided concept,\nlike an object or a style, we learn to represent it through new \"words\" in the\nembedding space of a frozen text-to-image model. These \"words\" can be composed\ninto natural language sentences, guiding personalized creation in an intuitive\nway. Notably, we find evidence that a single word embedding is sufficient for\ncapturing unique and varied concepts. We compare our approach to a wide range\nof baselines, and demonstrate that it can more faithfully portray the concepts\nacross a range of applications and tasks.\n  Our code, data and new words will be available at:\nhttps://textual-inversion.github.io", "published": "2022-08-02 17:50:36", "link": "http://arxiv.org/abs/2208.01618v1", "categories": ["cs.CV", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Prompt-to-Prompt Image Editing with Cross Attention Control", "abstract": "Recent large-scale text-driven synthesis models have attracted much attention\nthanks to their remarkable capabilities of generating highly diverse images\nthat follow given text prompts. Such text-based synthesis methods are\nparticularly appealing to humans who are used to verbally describe their\nintent. Therefore, it is only natural to extend the text-driven image synthesis\nto text-driven image editing. Editing is challenging for these generative\nmodels, since an innate property of an editing technique is to preserve most of\nthe original image, while in the text-based models, even a small modification\nof the text prompt often leads to a completely different outcome.\nState-of-the-art methods mitigate this by requiring the users to provide a\nspatial mask to localize the edit, hence, ignoring the original structure and\ncontent within the masked region. In this paper, we pursue an intuitive\nprompt-to-prompt editing framework, where the edits are controlled by text\nonly. To this end, we analyze a text-conditioned model in depth and observe\nthat the cross-attention layers are the key to controlling the relation between\nthe spatial layout of the image to each word in the prompt. With this\nobservation, we present several applications which monitor the image synthesis\nby editing the textual prompt only. This includes localized editing by\nreplacing a word, global editing by adding a specification, and even delicately\ncontrolling the extent to which a word is reflected in the image. We present\nour results over diverse images and prompts, demonstrating high-quality\nsynthesis and fidelity to the edited prompts.", "published": "2022-08-02 17:55:41", "link": "http://arxiv.org/abs/2208.01626v1", "categories": ["cs.CV", "cs.CL", "cs.GR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Recognizing and Extracting Cybersecurtity-relevant Entities from Text", "abstract": "Cyber Threat Intelligence (CTI) is information describing threat vectors,\nvulnerabilities, and attacks and is often used as training data for AI-based\ncyber defense systems such as Cybersecurity Knowledge Graphs (CKG). There is a\nstrong need to develop community-accessible datasets to train existing AI-based\ncybersecurity pipelines to efficiently and accurately extract meaningful\ninsights from CTI. We have created an initial unstructured CTI corpus from a\nvariety of open sources that we are using to train and test cybersecurity\nentity models using the spaCy framework and exploring self-learning methods to\nautomatically recognize cybersecurity entities. We also describe methods to\napply cybersecurity domain entity linking with existing world knowledge from\nWikidata. Our future work will survey and test spaCy NLP tools and create\nmethods for continuous integration of new information extracted from text.", "published": "2022-08-02 18:44:06", "link": "http://arxiv.org/abs/2208.01693v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "No Pattern, No Recognition: a Survey about Reproducibility and\n  Distortion Issues of Text Clustering and Topic Modeling", "abstract": "Extracting knowledge from unlabeled texts using machine learning algorithms\ncan be complex. Document categorization and information retrieval are two\napplications that may benefit from unsupervised learning (e.g., text clustering\nand topic modeling), including exploratory data analysis. However, the\nunsupervised learning paradigm poses reproducibility issues. The initialization\ncan lead to variability depending on the machine learning algorithm.\nFurthermore, the distortions can be misleading when regarding cluster geometry.\nAmongst the causes, the presence of outliers and anomalies can be a determining\nfactor. Despite the relevance of initialization and outlier issues for text\nclustering and topic modeling, the authors did not find an in-depth analysis of\nthem. This survey provides a systematic literature review (2011-2022) of these\nsubareas and proposes a common terminology since similar procedures have\ndifferent terms. The authors describe research opportunities, trends, and open\nissues. The appendices summarize the theoretical background of the text\nvectorization, the factorization, and the clustering algorithms that are\ndirectly or indirectly related to the reviewed works.", "published": "2022-08-02 19:51:43", "link": "http://arxiv.org/abs/2208.01712v1", "categories": ["cs.LG", "cs.CL", "cs.IR", "stat.ML", "I.2; I.2.7; I.5.3"], "primary_category": "cs.LG"}
{"title": "Analog Gated Recurrent Neural Network for Detecting Chewing Events", "abstract": "We present a novel gated recurrent neural network to detect when a person is\nchewing on food. We implemented the neural network as a custom analog\nintegrated circuit in a 0.18 um CMOS technology. The neural network was trained\non 6.4 hours of data collected from a contact microphone that was mounted on\nvolunteers' mastoid bones. When tested on 1.6 hours of previously-unseen data,\nthe neural network identified chewing events at a 24-second time resolution. It\nachieved a recall of 91% and an F1-score of 94% while consuming 1.1 uW of\npower. A system for detecting whole eating episodes -- like meals and snacks --\nthat is based on the novel analog neural network consumes an estimated 18.8uW\nof power.", "published": "2022-08-02 01:57:49", "link": "http://arxiv.org/abs/2208.01201v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Audio Deepfake Detection Based on a Combination of F0 Information and\n  Real Plus Imaginary Spectrogram Features", "abstract": "Recently, pioneer research works have proposed a large number of acoustic\nfeatures (log power spectrogram, linear frequency cepstral coefficients,\nconstant Q cepstral coefficients, etc.) for audio deepfake detection, obtaining\ngood performance, and showing that different subbands have different\ncontributions to audio deepfake detection. However, this lacks an explanation\nof the specific information in the subband, and these features also lose\ninformation such as phase. Inspired by the mechanism of synthetic speech, the\nfundamental frequency (F0) information is used to improve the quality of\nsynthetic speech, while the F0 of synthetic speech is still too average, which\ndiffers significantly from that of real speech. It is expected that F0 can be\nused as important information to discriminate between bonafide and fake speech,\nwhile this information cannot be used directly due to the irregular\ndistribution of F0. Insteadly, the frequency band containing most of F0 is\nselected as the input feature. Meanwhile, to make full use of the phase and\nfull-band information, we also propose to use real and imaginary spectrogram\nfeatures as complementary input features and model the disjoint subbands\nseparately. Finally, the results of F0, real and imaginary spectrogram features\nare fused. Experimental results on the ASVspoof 2019 LA dataset show that our\nproposed system is very effective for the audio deepfake detection task,\nachieving an equivalent error rate (EER) of 0.43%, which surpasses almost all\nsystems.", "published": "2022-08-02 02:46:16", "link": "http://arxiv.org/abs/2208.01214v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-complexity CNNs for Acoustic Scene Classification", "abstract": "This technical report describes the SurreyAudioTeam22s submission for DCASE\n2022 ASC Task 1, Low-Complexity Acoustic Scene Classification (ASC). The task\nhas two rules, (a) the ASC framework should have maximum 128K parameters, and\n(b) there should be a maximum of 30 millions multiply-accumulate operations\n(MACs) per inference. In this report, we present low-complexity systems for ASC\nthat follow the rules intended for the task.", "published": "2022-08-02 16:02:41", "link": "http://arxiv.org/abs/2208.01555v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
