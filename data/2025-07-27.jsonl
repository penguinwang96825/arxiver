{"title": "Can Foundation Models Predict Fitness for Duty?", "abstract": "Biometric capture devices have been utilised to estimate a person's alertness\nthrough near-infrared iris images, expanding their use beyond just biometric\nrecognition. However, capturing a substantial number of corresponding images\nrelated to alcohol consumption, drug use, and sleep deprivation to create a\ndataset for training an AI model presents a significant challenge. Typically, a\nlarge quantity of images is required to effectively implement a deep learning\napproach. Currently, training downstream models with a huge number of images\nbased on foundational models provides a real opportunity to enhance this area,\nthanks to the generalisation capabilities of self-supervised models. This work\nexamines the application of deep learning and foundational models in predicting\nfitness for duty, which is defined as the subject condition related to\ndetermining the alertness for work.", "published": "2025-07-27 21:26:12", "link": "http://arxiv.org/abs/2507.20418v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Indian Sign Language Detection for Real-Time Translation using Machine Learning", "abstract": "Gestural language is used by deaf & mute communities to communicate through\nhand gestures & body movements that rely on visual-spatial patterns known as\nsign languages. Sign languages, which rely on visual-spatial patterns of hand\ngestures & body movements, are the primary mode of communication for deaf &\nmute communities worldwide. Effective communication is fundamental to human\ninteraction, yet individuals in these communities often face significant\nbarriers due to a scarcity of skilled interpreters & accessible translation\ntechnologies. This research specifically addresses these challenges within the\nIndian context by focusing on Indian Sign Language (ISL). By leveraging machine\nlearning, this study aims to bridge the critical communication gap for the deaf\n& hard-of-hearing population in India, where technological solutions for ISL\nare less developed compared to other global sign languages. We propose a\nrobust, real-time ISL detection & translation system built upon a Convolutional\nNeural Network (CNN). Our model is trained on a comprehensive ISL dataset &\ndemonstrates exceptional performance, achieving a classification accuracy of\n99.95%. This high precision underscores the model's capability to discern the\nnuanced visual features of different signs. The system's effectiveness is\nrigorously evaluated using key performance metrics, including accuracy, F1\nscore, precision & recall, ensuring its reliability for real-world\napplications. For real-time implementation, the framework integrates MediaPipe\nfor precise hand tracking & motion detection, enabling seamless translation of\ndynamic gestures. This paper provides a detailed account of the model's\narchitecture, the data preprocessing pipeline & the classification methodology.\nThe research elaborates the model architecture, preprocessing & classification\nmethodologies for enhancing communication in deaf & mute communities.", "published": "2025-07-27 21:15:46", "link": "http://arxiv.org/abs/2507.20414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Second Competition on Presentation Attack Detection on ID Card", "abstract": "This work summarises and reports the results of the second Presentation\nAttack Detection competition on ID cards. This new version includes new\nelements compared to the previous one. (1) An automatic evaluation platform was\nenabled for automatic benchmarking; (2) Two tracks were proposed in order to\nevaluate algorithms and datasets, respectively; and (3) A new ID card dataset\nwas shared with Track 1 teams to serve as the baseline dataset for the training\nand optimisation. The Hochschule Darmstadt, Fraunhofer-IGD, and Facephi company\njointly organised this challenge. 20 teams were registered, and 74 submitted\nmodels were evaluated. For Track 1, the \"Dragons\" team reached first place with\nan Average Ranking and Equal Error rate (EER) of AV-Rank of 40.48% and 11.44%\nEER, respectively. For the more challenging approach in Track 2, the \"Incode\"\nteam reached the best results with an AV-Rank of 14.76% and 6.36% EER,\nimproving on the results of the first edition of 74.30% and 21.87% EER,\nrespectively. These results suggest that PAD on ID cards is improving, but it\nis still a challenging problem related to the number of images, especially of\nbona fide images.", "published": "2025-07-27 20:18:52", "link": "http://arxiv.org/abs/2507.20404v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VESPA: Towards un(Human)supervised Open-World Pointcloud Labeling for Autonomous Driving", "abstract": "Data collection for autonomous driving is rapidly accelerating, but manual\nannotation, especially for 3D labels, remains a major bottleneck due to its\nhigh cost and labor intensity. Autolabeling has emerged as a scalable\nalternative, allowing the generation of labels for point clouds with minimal\nhuman intervention. While LiDAR-based autolabeling methods leverage geometric\ninformation, they struggle with inherent limitations of lidar data, such as\nsparsity, occlusions, and incomplete object observations. Furthermore, these\nmethods typically operate in a class-agnostic manner, offering limited semantic\ngranularity. To address these challenges, we introduce VESPA, a multimodal\nautolabeling pipeline that fuses the geometric precision of LiDAR with the\nsemantic richness of camera images. Our approach leverages vision-language\nmodels (VLMs) to enable open-vocabulary object labeling and to refine detection\nquality directly in the point cloud domain. VESPA supports the discovery of\nnovel categories and produces high-quality 3D pseudolabels without requiring\nground-truth annotations or HD maps. On Nuscenes dataset, VESPA achieves an AP\nof 52.95% for object discovery and up to 46.54% for multiclass object\ndetection, demonstrating strong performance in scalable 3D scene understanding.\nCode will be available upon acceptance.", "published": "2025-07-27 19:39:29", "link": "http://arxiv.org/abs/2507.20397v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Solving Scene Understanding for Autonomous Navigation in Unstructured Environments", "abstract": "Autonomous vehicles are the next revolution in the automobile industry and\nthey are expected to revolutionize the future of transportation. Understanding\nthe scenario in which the autonomous vehicle will operate is critical for its\ncompetent functioning. Deep Learning has played a massive role in the progress\nthat has been made till date. Semantic Segmentation, the process of annotating\nevery pixel of an image with an object class, is one crucial part of this scene\ncomprehension using Deep Learning. It is especially useful in Autonomous\nDriving Research as it requires comprehension of drivable and non-drivable\nareas, roadside objects and the like. In this paper semantic segmentation has\nbeen performed on the Indian Driving Dataset which has been recently compiled\non the urban and rural roads of Bengaluru and Hyderabad. This dataset is more\nchallenging compared to other datasets like Cityscapes, since it is based on\nunstructured driving environments. It has a four level hierarchy and in this\npaper segmentation has been performed on the first level. Five different models\nhave been trained and their performance has been compared using the Mean\nIntersection over Union. These are UNET, UNET+RESNET50, DeepLabsV3, PSPNet and\nSegNet. The highest MIOU of 0.6496 has been achieved. The paper discusses the\ndataset, exploratory data analysis, preparation, implementation of the five\nmodels and studies the performance and compares the results achieved in the\nprocess.", "published": "2025-07-27 19:11:21", "link": "http://arxiv.org/abs/2507.20389v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ModalFormer: Multimodal Transformer for Low-Light Image Enhancement", "abstract": "Low-light image enhancement (LLIE) is a fundamental yet challenging task due\nto the presence of noise, loss of detail, and poor contrast in images captured\nunder insufficient lighting conditions. Recent methods often rely solely on\npixel-level transformations of RGB images, neglecting the rich contextual\ninformation available from multiple visual modalities. In this paper, we\npresent ModalFormer, the first large-scale multimodal framework for LLIE that\nfully exploits nine auxiliary modalities to achieve state-of-the-art\nperformance. Our model comprises two main components: a Cross-modal Transformer\n(CM-T) designed to restore corrupted images while seamlessly integrating\nmultimodal information, and multiple auxiliary subnetworks dedicated to\nmultimodal feature reconstruction. Central to the CM-T is our novel Cross-modal\nMulti-headed Self-Attention mechanism (CM-MSA), which effectively fuses RGB\ndata with modality-specific features--including deep feature embeddings,\nsegmentation information, geometric cues, and color information--to generate\ninformation-rich hybrid attention maps. Extensive experiments on multiple\nbenchmark datasets demonstrate ModalFormer's state-of-the-art performance in\nLLIE. Pre-trained models and results are made available at\nhttps://github.com/albrateanu/ModalFormer.", "published": "2025-07-27 19:07:22", "link": "http://arxiv.org/abs/2507.20388v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation", "abstract": "Generating high-quality cartoon animations multimodal control is challenging\ndue to the complexity of non-human characters, stylistically diverse motions\nand fine-grained emotions. There is a huge domain gap between real-world videos\nand cartoon animation, as cartoon animation is usually abstract and has\nexaggerated motion. Meanwhile, public multimodal cartoon data are extremely\nscarce due to the difficulty of large-scale automatic annotation processes\ncompared with real-life scenarios. To bridge this gap, We propose the\nMagicAnime dataset, a large-scale, hierarchically annotated, and multimodal\ndataset designed to support multiple video generation tasks, along with the\nbenchmarks it includes. Containing 400k video clips for image-to-video\ngeneration, 50k pairs of video clips and keypoints for whole-body annotation,\n12k pairs of video clips for video-to-video face animation, and 2.9k pairs of\nvideo and audio clips for audio-driven face animation. Meanwhile, we also build\na set of multi-modal cartoon animation benchmarks, called MagicAnime-Bench, to\nsupport the comparisons of different methods in the tasks above. Comprehensive\nexperiments on four tasks, including video-driven face animation, audio-driven\nface animation, image-to-video animation, and pose-driven character animation,\nvalidate its effectiveness in supporting high-fidelity, fine-grained, and\ncontrollable generation.", "published": "2025-07-27 17:53:00", "link": "http://arxiv.org/abs/2507.20368v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Generative Pre-training for Subjective Tasks: A Diffusion Transformer-Based Framework for Facial Beauty Prediction", "abstract": "Facial Beauty Prediction (FBP) is a challenging computer vision task due to\nits subjective nature and the subtle, holistic features that influence human\nperception. Prevailing methods, often based on deep convolutional networks or\nstandard Vision Transformers pre-trained on generic object classification\n(e.g., ImageNet), struggle to learn feature representations that are truly\naligned with high-level aesthetic assessment. In this paper, we propose a novel\ntwo-stage framework that leverages the power of generative models to create a\nsuperior, domain-specific feature extractor. In the first stage, we pre-train a\nDiffusion Transformer on a large-scale, unlabeled facial dataset (FFHQ) through\na self-supervised denoising task. This process forces the model to learn the\nfundamental data distribution of human faces, capturing nuanced details and\nstructural priors essential for aesthetic evaluation. In the second stage, the\npre-trained and frozen encoder of our Diffusion Transformer is used as a\nbackbone feature extractor, with only a lightweight regression head being\nfine-tuned on the target FBP dataset (FBP5500). Our method, termed Diff-FBP,\nsets a new state-of-the-art on the FBP5500 benchmark, achieving a Pearson\nCorrelation Coefficient (PCC) of 0.932, significantly outperforming prior art\nbased on general-purpose pre-training. Extensive ablation studies validate that\nour generative pre-training strategy is the key contributor to this performance\nleap, creating feature representations that are more semantically potent for\nsubjective visual tasks.", "published": "2025-07-27 17:33:51", "link": "http://arxiv.org/abs/2507.20363v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Detecting Visual Information Manipulation Attacks in Augmented Reality: A Multimodal Semantic Reasoning Approach", "abstract": "The virtual content in augmented reality (AR) can introduce misleading or\nharmful information, leading to semantic misunderstandings or user errors. In\nthis work, we focus on visual information manipulation (VIM) attacks in AR\nwhere virtual content changes the meaning of real-world scenes in subtle but\nimpactful ways. We introduce a taxonomy that categorizes these attacks into\nthree formats: character, phrase, and pattern manipulation, and three purposes:\ninformation replacement, information obfuscation, and extra wrong information.\nBased on the taxonomy, we construct a dataset, AR-VIM. It consists of 452\nraw-AR video pairs spanning 202 different scenes, each simulating a real-world\nAR scenario. To detect such attacks, we propose a multimodal semantic reasoning\nframework, VIM-Sense. It combines the language and visual understanding\ncapabilities of vision-language models (VLMs) with optical character\nrecognition (OCR)-based textual analysis. VIM-Sense achieves an attack\ndetection accuracy of 88.94% on AR-VIM, consistently outperforming vision-only\nand text-only baselines. The system reaches an average attack detection latency\nof 7.07 seconds in a simulated video processing framework and 7.17 seconds in a\nreal-world evaluation conducted on a mobile Android AR application.", "published": "2025-07-27 17:04:50", "link": "http://arxiv.org/abs/2507.20356v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PIVOTS: Aligning unseen Structures using Preoperative to Intraoperative Volume-To-Surface Registration for Liver Navigation", "abstract": "Non-rigid registration is essential for Augmented Reality guided laparoscopic\nliver surgery by fusing preoperative information, such as tumor location and\nvascular structures, into the limited intraoperative view, thereby enhancing\nsurgical navigation. A prerequisite is the accurate prediction of\nintraoperative liver deformation which remains highly challenging due to\nfactors such as large deformation caused by pneumoperitoneum, respiration and\ntool interaction as well as noisy intraoperative data, and limited field of\nview due to occlusion and constrained camera movement. To address these\nchallenges, we introduce PIVOTS, a Preoperative to Intraoperative\nVOlume-To-Surface registration neural network that directly takes point clouds\nas input for deformation prediction. The geometric feature extraction encoder\nallows multi-resolution feature extraction, and the decoder, comprising novel\ndeformation aware cross attention modules, enables pre- and intraoperative\ninformation interaction and accurate multi-level displacement prediction. We\ntrain the neural network on synthetic data simulated from a biomechanical\nsimulation pipeline and validate its performance on both synthetic and real\ndatasets. Results demonstrate superior registration performance of our method\ncompared to baseline methods, exhibiting strong robustness against high amounts\nof noise, large deformation, and various levels of intraoperative visibility.\nWe publish the training and test sets as evaluation benchmarks and call for a\nfair comparison of liver registration methods with volume-to-surface data. Code\nand datasets are available here https://github.com/pengliu-nct/PIVOTS.", "published": "2025-07-27 16:01:26", "link": "http://arxiv.org/abs/2507.20337v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Gallery to Wrist: Realistic 3D Bracelet Insertion in Videos", "abstract": "Inserting 3D objects into videos is a longstanding challenge in computer\ngraphics with applications in augmented reality, virtual try-on, and video\ncomposition. Achieving both temporal consistency, or realistic lighting remains\ndifficult, particularly in dynamic scenarios with complex object motion,\nperspective changes, and varying illumination. While 2D diffusion models have\nshown promise for producing photorealistic edits, they often struggle with\nmaintaining temporal coherence across frames. Conversely, traditional 3D\nrendering methods excel in spatial and temporal consistency but fall short in\nachieving photorealistic lighting. In this work, we propose a hybrid object\ninsertion pipeline that combines the strengths of both paradigms. Specifically,\nwe focus on inserting bracelets into dynamic wrist scenes, leveraging the high\ntemporal consistency of 3D Gaussian Splatting (3DGS) for initial rendering and\nrefining the results using a 2D diffusion-based enhancement model to ensure\nrealistic lighting interactions. Our method introduces a shading-driven\npipeline that separates intrinsic object properties (albedo, shading,\nreflectance) and refines both shading and sRGB images for photorealism. To\nmaintain temporal coherence, we optimize the 3DGS model with multi-frame\nweighted adjustments. This is the first approach to synergize 3D rendering and\n2D diffusion for video object insertion, offering a robust solution for\nrealistic and consistent video editing. Project Page:\nhttps://cjeen.github.io/BraceletPaper/", "published": "2025-07-27 15:49:07", "link": "http://arxiv.org/abs/2507.20331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SWIFT: A General Sensitive Weight Identification Framework for Fast Sensor-Transfer Pansharpening", "abstract": "Pansharpening aims to fuse high-resolution panchromatic (PAN) images with\nlow-resolution multispectral (LRMS) images to generate high-resolution\nmultispectral (HRMS) images. Although deep learning-based methods have achieved\npromising performance, they generally suffer from severe performance\ndegradation when applied to data from unseen sensors. Adapting these models\nthrough full-scale retraining or designing more complex architectures is often\nprohibitively expensive and impractical for real-world deployment. To address\nthis critical challenge, we propose a fast and general-purpose framework for\ncross-sensor adaptation, SWIFT (Sensitive Weight Identification for Fast\nTransfer). Specifically, SWIFT employs an unsupervised sampling strategy based\non data manifold structures to balance sample selection while mitigating the\nbias of traditional Farthest Point Sampling, efficiently selecting only 3\\% of\nthe most informative samples from the target domain. This subset is then used\nto probe a source-domain pre-trained model by analyzing the gradient behavior\nof its parameters, allowing for the quick identification and subsequent update\nof only the weight subset most sensitive to the domain shift. As a\nplug-and-play framework, SWIFT can be applied to various existing pansharpening\nmodels. Extensive experiments demonstrate that SWIFT reduces the adaptation\ntime from hours to approximately one minute on a single NVIDIA RTX 4090 GPU.\nThe adapted models not only substantially outperform direct-transfer baselines\nbut also achieve performance competitive with, and in some cases superior to,\nfull retraining, establishing a new state-of-the-art on cross-sensor\npansharpening tasks for the WorldView-2 and QuickBird datasets.", "published": "2025-07-27 15:06:05", "link": "http://arxiv.org/abs/2507.20311v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fine-structure Preserved Real-world Image Super-resolution via Transfer VAE Training", "abstract": "Impressive results on real-world image super-resolution (Real-ISR) have been\nachieved by employing pre-trained stable diffusion (SD) models. However, one\ncritical issue of such methods lies in their poor reconstruction of image fine\nstructures, such as small characters and textures, due to the aggressive\nresolution reduction of the VAE (eg., 8$\\times$ downsampling) in the SD model.\nOne solution is to employ a VAE with a lower downsampling rate for diffusion;\nhowever, adapting its latent features with the pre-trained UNet while\nmitigating the increased computational cost poses new challenges. To address\nthese issues, we propose a Transfer VAE Training (TVT) strategy to transfer the\n8$\\times$ downsampled VAE into a 4$\\times$ one while adapting to the\npre-trained UNet. Specifically, we first train a 4$\\times$ decoder based on the\noutput features of the original VAE encoder, then train a 4$\\times$ encoder\nwhile keeping the newly trained decoder fixed. Such a TVT strategy aligns the\nnew encoder-decoder pair with the original VAE latent space while enhancing\nimage fine details. Additionally, we introduce a compact VAE and\ncompute-efficient UNet by optimizing their network architectures, reducing the\ncomputational cost while capturing high-resolution fine-scale features.\nExperimental results demonstrate that our TVT method significantly improves\nfine-structure preservation, which is often compromised by other SD-based\nmethods, while requiring fewer FLOPs than state-of-the-art one-step diffusion\nmodels. The official code can be found at https://github.com/Joyies/TVT.", "published": "2025-07-27 14:11:29", "link": "http://arxiv.org/abs/2507.20291v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "T$^\\text{3}$SVFND: Towards an Evolving Fake News Detector for Emergencies with Test-time Training on Short Video Platforms", "abstract": "The existing methods for fake news videos detection may not be generalized,\nbecause there is a distribution shift between short video news of different\nevents, and the performance of such techniques greatly drops if news records\nare coming from emergencies. We propose a new fake news videos detection\nframework (T$^3$SVFND) using Test-Time Training (TTT) to alleviate this\nlimitation, enhancing the robustness of fake news videos detection.\nSpecifically, we design a self-supervised auxiliary task based on Mask Language\nModeling (MLM) that masks a certain percentage of words in text and predicts\nthese masked words by combining contextual information from different\nmodalities (audio and video). In the test-time training phase, the model adapts\nto the distribution of test data through auxiliary tasks. Extensive experiments\non the public benchmark demonstrate the effectiveness of the proposed model,\nespecially for the detection of emergency news.", "published": "2025-07-27 14:04:00", "link": "http://arxiv.org/abs/2507.20286v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Controllable Feature Whitening for Hyperparameter-Free Bias Mitigation", "abstract": "As the use of artificial intelligence rapidly increases, the development of\ntrustworthy artificial intelligence has become important. However, recent\nstudies have shown that deep neural networks are susceptible to learn spurious\ncorrelations present in datasets. To improve the reliability, we propose a\nsimple yet effective framework called controllable feature whitening. We\nquantify the linear correlation between the target and bias features by the\ncovariance matrix, and eliminate it through the whitening module. Our results\nsystemically demonstrate that removing the linear correlations between features\nfed into the last linear classifier significantly mitigates the bias, while\navoiding the need to model intractable higher-order dependencies. A particular\nadvantage of the proposed method is that it does not require regularization\nterms or adversarial learning, which often leads to unstable optimization in\npractice. Furthermore, we show that two fairness criteria, demographic parity\nand equalized odds, can be effectively handled by whitening with the\nre-weighted covariance matrix. Consequently, our method controls the trade-off\nbetween the utility and fairness of algorithms by adjusting the weighting\ncoefficient. Finally, we validate that our method outperforms existing\napproaches on four benchmark datasets: Corrupted CIFAR-10, Biased FFHQ,\nWaterBirds, and Celeb-A.", "published": "2025-07-27 14:01:30", "link": "http://arxiv.org/abs/2507.20284v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "L-MCAT: Unpaired Multimodal Transformer with Contrastive Attention for Label-Efficient Satellite Image Classification", "abstract": "We propose the Lightweight Multimodal Contrastive Attention Transformer\n(L-MCAT), a novel transformer-based framework for label-efficient remote\nsensing image classification using unpaired multimodal satellite data. L-MCAT\nintroduces two core innovations: (1) Modality-Spectral Adapters (MSA) that\ncompress high-dimensional sensor inputs into a unified embedding space, and (2)\nUnpaired Multimodal Attention Alignment (U-MAA), a contrastive self-supervised\nmechanism integrated into the attention layers to align heterogeneous\nmodalities without pixel-level correspondence or labels. L-MCAT achieves 95.4%\noverall accuracy on the SEN12MS dataset using only 20 labels per class,\noutperforming state-of-the-art baselines while using 47x fewer parameters and\n23x fewer FLOPs than MCTrans. It maintains over 92% accuracy even under 50%\nspatial misalignment, demonstrating robustness for real-world deployment. The\nmodel trains end-to-end in under 5 hours on a single consumer GPU.", "published": "2025-07-27 13:06:32", "link": "http://arxiv.org/abs/2507.20259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MIRepNet: A Pipeline and Foundation Model for EEG-Based Motor Imagery Classification", "abstract": "Brain-computer interfaces (BCIs) enable direct communication between the\nbrain and external devices. Recent EEG foundation models aim to learn\ngeneralized representations across diverse BCI paradigms. However, these\napproaches overlook fundamental paradigm-specific neurophysiological\ndistinctions, limiting their generalization ability. Importantly, in practical\nBCI deployments, the specific paradigm such as motor imagery (MI) for stroke\nrehabilitation or assistive robotics, is generally determined prior to data\nacquisition. This paper proposes MIRepNet, the first EEG foundation model\ntailored for the MI paradigm. MIRepNet comprises a high-quality EEG\npreprocessing pipeline incorporating a neurophysiologically-informed channel\ntemplate, adaptable to EEG headsets with arbitrary electrode configurations.\nFurthermore, we introduce a hybrid pretraining strategy that combines\nself-supervised masked token reconstruction and supervised MI classification,\nfacilitating rapid adaptation and accurate decoding on novel downstream MI\ntasks with fewer than 30 trials per class. Extensive evaluations across five\npublic MI datasets demonstrated that MIRepNet consistently achieved\nstate-of-the-art performance, significantly outperforming both specialized and\ngeneralized EEG models. Our code will be available on\nGitHub\\footnote{https://github.com/staraink/MIRepNet}.", "published": "2025-07-27 12:54:42", "link": "http://arxiv.org/abs/2507.20254v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnimalClue: Recognizing Animals by their Traces", "abstract": "Wildlife observation plays an important role in biodiversity conservation,\nnecessitating robust methodologies for monitoring wildlife populations and\ninterspecies interactions. Recent advances in computer vision have\nsignificantly contributed to automating fundamental wildlife observation tasks,\nsuch as animal detection and species identification. However, accurately\nidentifying species from indirect evidence like footprints and feces remains\nrelatively underexplored, despite its importance in contributing to wildlife\nmonitoring. To bridge this gap, we introduce AnimalClue, the first large-scale\ndataset for species identification from images of indirect evidence. Our\ndataset consists of 159,605 bounding boxes encompassing five categories of\nindirect clues: footprints, feces, eggs, bones, and feathers. It covers 968\nspecies, 200 families, and 65 orders. Each image is annotated with\nspecies-level labels, bounding boxes or segmentation masks, and fine-grained\ntrait information, including activity patterns and habitat preferences. Unlike\nexisting datasets primarily focused on direct visual features (e.g., animal\nappearances), AnimalClue presents unique challenges for classification,\ndetection, and instance segmentation tasks due to the need for recognizing more\ndetailed and subtle visual features. In our experiments, we extensively\nevaluate representative vision models and identify key challenges in animal\nidentification from their traces. Our dataset and code are available at\nhttps://dahlian00.github.io/AnimalCluePage/", "published": "2025-07-27 11:48:03", "link": "http://arxiv.org/abs/2507.20240v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decomposing Densification in Gaussian Splatting for Faster 3D Scene Reconstruction", "abstract": "3D Gaussian Splatting (GS) has emerged as a powerful representation for\nhigh-quality scene reconstruction, offering compelling rendering quality.\nHowever, the training process of GS often suffers from slow convergence due to\ninefficient densification and suboptimal spatial distribution of Gaussian\nprimitives. In this work, we present a comprehensive analysis of the split and\nclone operations during the densification phase, revealing their distinct roles\nin balancing detail preservation and computational efficiency. Building upon\nthis analysis, we propose a global-to-local densification strategy, which\nfacilitates more efficient growth of Gaussians across the scene space,\npromoting both global coverage and local refinement. To cooperate with the\nproposed densification strategy and promote sufficient diffusion of Gaussian\nprimitives in space, we introduce an energy-guided coarse-to-fine\nmulti-resolution training framework, which gradually increases resolution based\non energy density in 2D images. Additionally, we dynamically prune unnecessary\nGaussian primitives to speed up the training. Extensive experiments on\nMipNeRF-360, Deep Blending, and Tanks & Temples datasets demonstrate that our\napproach significantly accelerates training,achieving over 2x speedup with\nfewer Gaussian primitives and superior reconstruction performance.", "published": "2025-07-27 11:47:20", "link": "http://arxiv.org/abs/2507.20239v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Multi-Agent System for Information Extraction from the Chemical Literature", "abstract": "To fully expedite AI-powered chemical research, high-quality chemical\ndatabases are the cornerstone. Automatic extraction of chemical information\nfrom the literature is essential for constructing reaction databases, but it is\ncurrently limited by the multimodality and style variability of chemical\ninformation. In this work, we developed a multimodal large language model\n(MLLM)-based multi-agent system for automatic chemical information extraction.\nWe used the MLLM's strong reasoning capability to understand the structure of\ncomplex chemical graphics, decompose the extraction task into sub-tasks and\ncoordinate a set of specialized agents to solve them. Our system achieved an F1\nscore of 80.8% on a benchmark dataset of complex chemical reaction graphics\nfrom the literature, surpassing the previous state-of-the-art model (F1 score:\n35.6%) by a significant margin. Additionally, it demonstrated consistent\nimprovements in key sub-tasks, including molecular image recognition, reaction\nimage parsing, named entity recognition and text-based reaction extraction.\nThis work is a critical step toward automated chemical information extraction\ninto structured datasets, which will be a strong promoter of AI-driven chemical\nresearch.", "published": "2025-07-27 11:16:57", "link": "http://arxiv.org/abs/2507.20230v1", "categories": ["cs.AI", "cs.CV", "cs.MA"], "primary_category": "cs.AI"}
{"title": "MambaMap: Online Vectorized HD Map Construction using State Space Model", "abstract": "High-definition (HD) maps are essential for autonomous driving, as they\nprovide precise road information for downstream tasks. Recent advances\nhighlight the potential of temporal modeling in addressing challenges like\nocclusions and extended perception range. However, existing methods either fail\nto fully exploit temporal information or incur substantial computational\noverhead in handling extended sequences. To tackle these challenges, we propose\nMambaMap, a novel framework that efficiently fuses long-range temporal features\nin the state space to construct online vectorized HD maps. Specifically,\nMambaMap incorporates a memory bank to store and utilize information from\nhistorical frames, dynamically updating BEV features and instance queries to\nimprove robustness against noise and occlusions. Moreover, we introduce a\ngating mechanism in the state space, selectively integrating dependencies of\nmap elements in high computational efficiency. In addition, we design\ninnovative multi-directional and spatial-temporal scanning strategies to\nenhance feature extraction at both BEV and instance levels. These strategies\nsignificantly boost the prediction accuracy of our approach while ensuring\nrobust temporal consistency. Extensive experiments on the nuScenes and\nArgoverse2 datasets demonstrate that our proposed MambaMap approach outperforms\nstate-of-the-art methods across various splits and perception ranges. Source\ncode will be available at https://github.com/ZiziAmy/MambaMap.", "published": "2025-07-27 11:09:27", "link": "http://arxiv.org/abs/2507.20224v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Attention Stacked Ensemble for Lung Cancer Detection in CT Scans", "abstract": "In this work, we address the challenge of binary lung nodule classification\n(benign vs malignant) using CT images by proposing a multi-level attention\nstacked ensemble of deep neural networks. Three pretrained backbones -\nEfficientNet V2 S, MobileViT XXS, and DenseNet201 - are each adapted with a\ncustom classification head tailored to 96 x 96 pixel inputs. A two-stage\nattention mechanism learns both model-wise and class-wise importance scores\nfrom concatenated logits, and a lightweight meta-learner refines the final\nprediction. To mitigate class imbalance and improve generalization, we employ\ndynamic focal loss with empirically calculated class weights, MixUp\naugmentation during training, and test-time augmentation at inference.\nExperiments on the LIDC-IDRI dataset demonstrate exceptional performance,\nachieving 98.09 accuracy and 0.9961 AUC, representing a 35 percent reduction in\nerror rate compared to state-of-the-art methods. The model exhibits balanced\nperformance across sensitivity (98.73) and specificity (98.96), with\nparticularly strong results on challenging cases where radiologist disagreement\nwas high. Statistical significance testing confirms the robustness of these\nimprovements across multiple experimental runs. Our approach can serve as a\nrobust, automated aid for radiologists in lung cancer screening.", "published": "2025-07-27 11:03:07", "link": "http://arxiv.org/abs/2507.20221v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Product-Congruence Games: A Unified Impartial-Game Framework for RSA ($\u03c6$-MuM) and AES (poly-MuM)", "abstract": "RSA exponent reduction and AES S-box inversion share a hidden commonality:\nboth are governed by the same impartial combinatorial principle, which we call\na Product-Congruence Game (PCG). A Product-Congruence Game tracks play via the\nmodular or finite-field product of heap values, providing a single invariant\nthat unifies the algebraic cores of these two ubiquitous symmetric and\nasymmetric cryptosystems. We instantiate this framework with two companion\ngames. First, $\\phi$-MuM, in which a left-associated \"multi-secret\" RSA\nexponent chain compresses into the game of Multiplicative Modular Nim,\nPCG($k,\\{1\\}$), where $k = ord_N(g)$. The losing predicate then factorizes via\nthe Chinese remainder theorem, mirroring RSA's structure. Second, poly-MuM, our\nmodel for finite-field inversion such as the AES S-box. For poly-MuM we prove\nthe single-hole property inside its threshold region, implying that the\nSprague-Grundy values are multiplicative under disjunctive sums in that region.\nBeyond these instances, we establish four structural theorems for a general\nProduct-Congruence Game PCG($m,R$): (i) single-heap repair above the modulus,\n(ii) ultimate period $m$ per coordinate, (iii) exact and asymptotic losing\ndensities, and (iv) confinement of optimal play to a finite indeterminacy\nregion. An operation-alignment collapse principle explains why some variants\ndegenerate to a single aggregate while MuM, $\\phi$-MuM and poly-MuM retain rich\nlocal structure. All ingredients (multiplicative orders, the Chinese remainder\ntheorem, finite fields) are classical; the contribution is the unified\naggregation-compression viewpoint that embeds both RSA and AES inside one\nimpartial-game framework, together with the structural and collapse theorems.", "published": "2025-07-27 00:29:13", "link": "http://arxiv.org/abs/2507.20087v1", "categories": ["cs.DM", "cs.CR", "cs.IT", "math.IT", "91A46 (primary), 11A07, 94A60, 05A99", "G.2.1; E.3"], "primary_category": "cs.DM"}
{"title": "Joint Fiber and Free Space Optical Infrastructure Planning for Hybrid Integrated Access and Backhaul Networks", "abstract": "Integrated access and backhaul (IAB) is one of the promising techniques for\n5G networks and beyond (6G), in which the same node/hardware is used to provide\nboth backhaul and cellular services in a multi-hop architecture. Due to the\nsensitivity of the backhaul links with high rate/reliability demands, proper\nnetwork planning is needed to ensure the IAB network performs with the desired\nperformance levels. In this paper, we study the effect of infrastructure\nplanning and optimization on the coverage of IAB networks. We concentrate on\nthe cases where the fiber connectivity to the nodes is constrained due to cost.\nThereby, we study the performance gains and energy efficiency in the presence\nof free-space optical (FSO) communication links. Our results indicate hybrid\nfiber/FSO deployments offer substantial cost savings compared to fully fibered\nnetworks, suggesting a beneficial trade-off for strategic link deployment while\nimproving the service coverage probability. As we show, with proper network\nplanning, the service coverage, energy efficiency, and cost efficiency can be\nimproved.", "published": "2025-07-27 17:51:25", "link": "http://arxiv.org/abs/2507.20367v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Ensemble Average Analysis of Non-Adaptive Group Testing with Sparse Pooling Graphs", "abstract": "A combinatorial analysis of the false alarm (FA) and misdetection (MD)\nprobabilities of non-adaptive group testing with sparse pooling graphs is\ndeveloped. The analysis targets the combinatorial orthogonal matching pursuit\nand definite defective detection algorithms in the noiseless, non-quantitative\nsetting. The approach follows an ensemble average perspective, where average\nFA/MD probabilities are computed for pooling graph ensembles with prescribed\ndegree distributions. The accuracy of the analysis is demonstrated through\nnumerical examples, showing that the proposed technique can be used to\ncharacterize the performance of non-adaptive group testing schemes based on\nsparse pooling graphs.", "published": "2025-07-27 13:56:07", "link": "http://arxiv.org/abs/2507.20281v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Stochastic Channel Models for Satellite Mega-Constellations", "abstract": "A general satellite channel model is proposed for communications between a\nrapidly moving low Earth orbit (LEO) satellite in a mega-constellation and a\nstationary user on Earth. The channel uses a non-homogeneous binomial point\nprocess (NBPP) for modelling the satellite positions, marked with an\nascending/descending binary random variable for modelling the satellite\ndirections. Using the marked NBPP, we derive the probability distributions of\npower gain, propagation delay, and Doppler shift, resulting in a stochastic\nsignal propagation model for the mega-constellation geometry in isolation of\nother effects. This forms the basis for our proposed channel model as a\nrandomly time-varying channel. The scattering function of this channel is\nderived to characterise how the received power is spread in the delay-Doppler\ndomain. Global channel parameters such as path loss and channel spread are\nanalysed in terms of the scattering function. The channel statistics and the\nglobal channel parameters closely match realistic orbit simulations of the\nStarlink constellation.", "published": "2025-07-27 12:56:14", "link": "http://arxiv.org/abs/2507.20255v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sparse Regression Codes for Secret Key Agreement: Achieving Strong Secrecy and Near-Optimal Rates for Gaussian Sources", "abstract": "Secret key agreement from correlated physical layer observations is a\ncornerstone of information-theoretic security. This paper proposes and\nrigorously analyzes a complete, constructive protocol for secret key agreement\nfrom Gaussian sources using Sparse Regression Codes (SPARCs). Our protocol\nsystematically leverages the known optimality of SPARCs for both\nrate-distortion and Wyner-Ziv (WZ) coding, facilitated by their inherent nested\nstructure. The primary contribution of this work is a comprehensive end-to-end\nanalysis demonstrating that the proposed scheme achieves near-optimal secret\nkey rates with strong secrecy guarantees, as quantified by a vanishing\nvariational distance. We explicitly characterize the gap to the optimal rate,\nrevealing a fundamental trade-off between the key rate and the required public\ncommunication overhead, which is governed by a tunable quantization parameter.\nFurthermore, we uncover a non-trivial constrained optimization for this\nparameter, showing that practical constraints on the SPARC code parameters\ninduce a peak in the achievable secret key rate. This work establishes SPARCs\nas a viable and theoretically sound framework for secure key generation,\nproviding a compelling low-complexity alternative to existing schemes and\noffering new insights into the practical design of such protocols.", "published": "2025-07-27 07:21:19", "link": "http://arxiv.org/abs/2507.20157v1", "categories": ["cs.IT", "math.IT", "math.PR", "stat.AP"], "primary_category": "cs.IT"}
{"title": "An Optimal Transport-Based Method for Computing LM Rate and Its Convergence Analysis", "abstract": "The mismatch capacity characterizes the highest information rate of the\nchannel under a prescribed decoding metric and serves as a critical performance\nindicator in numerous practical communication scenarios. Compared to the\ncommonly used Generalized Mutual Information (GMI), the Lower bound on the\nMismatch capacity (LM rate) generally provides a tighter lower bound on the\nmismatch capacity. However, the efficient computation of the LM rate is\nsignificantly more challenging than that of the GMI, particularly as the size\nof the channel input alphabet increases. This growth in complexity renders\nstandard numerical methods (e.g., interior point methods) computationally\nintensive and, in some cases, impractical. In this work, we reformulate the\ncomputation of the LM rate as a special instance of the optimal transport (OT)\nproblem with an additional constraint. Building on this formulation, we develop\na novel numerical algorithm based on the Sinkhorn algorithm, which is well\nknown for its efficiency in solving entropy regularized optimization problems.\nWe further provide the convergence analysis of the proposed algorithm,\nrevealing that the algorithm has a sub-linear convergence rate. Numerical\nexperiments demonstrate the feasibility and efficiency of the proposed\nalgorithm for the computation of the LM rate.", "published": "2025-07-27 04:56:44", "link": "http://arxiv.org/abs/2507.20129v1", "categories": ["cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "cs.IT"}
{"title": "Rotatable RIS Assisted Physical Layer Multicasting", "abstract": "Reconfigurable Intelligent Surfaces (RIS) dynamically control signal\npropagation to enhance wireless communications. This paper presents a novel\nframework for rotatable RIS assisted physical-layer multicast systems, aiming\nto maximize the sum of minimum multicast rates via joint optimization of base\nstation beamforming, RIS phase shifts, and orientation. Unlike unicast or\nnon-rotatable setups, the rotatable RIS adapts orientation to align signals\nwith user groups, improving fairness and rates for weak users. An alternating\noptimization approach combines convex optimization for beamforming/phase shifts\nwith exhaustive search and particle swarm optimization (PSO) for orientation.\nMajorization-Minimization-based algorithms solve subproblems iteratively.\nSimulation results show the framework achieves 24.1% rate improvement via\nexhaustive search and 20.0% via PSO over the non-rotatable RIS baseline, with\nPSO performance close to the exhaustive search upper bound, highlighting the\nbenefits of physical-layer multicast and orientation optimization.", "published": "2025-07-27 03:33:03", "link": "http://arxiv.org/abs/2507.20113v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Graded Transformers: A Symbolic-Geometric Approach to Structured Learning", "abstract": "We introduce the Graded Transformer framework, a novel class of sequence\nmodels that embeds algebraic inductive biases through grading transformations\non vector spaces. Extending the theory of Graded Neural Networks (GNNs), we\npropose two architectures: the Linearly Graded Transformer (LGT) and the\nExponentially Graded Transformer (EGT). These models apply parameterized\nscaling operators-governed by fixed or learnable grading tuples and, for EGT,\nexponential factors to infuse hierarchical structure into attention and\nrepresentation layers, enhancing efficiency for structured data.\n  We derive rigorous theoretical guarantees, including universal approximation\ntheorems for continuous and Sobolev functions, reduced sample complexity via\neffective VC dimension bounds, Lipschitz continuity of graded operations, and\nrobustness to adversarial perturbations. A graded loss function ensures\ngradient stability and alignment with domain priors during optimization. By\ntreating grades as differentiable parameters, the framework enables adaptive\nfeature prioritization, overcoming limitations of fixed grades in prior work.\n  The Graded Transformer holds transformative potential for hierarchical\nlearning and neurosymbolic reasoning, with applications spanning algebraic\ngeometry (e.g., moduli spaces and zeta functions), physics (e.g., multiscale\nsimulations), natural language processing (e.g., syntactic parsing), biological\nsequence analysis (e.g., variant prediction), and emerging areas like graph\nneural networks and financial modeling. This work advances structured deep\nlearning by fusing geometric and algebraic principles with attention\nmechanisms, offering a mathematically grounded alternative to data-driven\nmodels and paving the way for interpretable, efficient systems in complex\ndomains.", "published": "2025-07-27 02:34:08", "link": "http://arxiv.org/abs/2507.20108v1", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MLC-Agent: Cognitive Model based on Memory-Learning Collaboration in LLM Empowered Agent Simulation Environment", "abstract": "Many real-world systems, such as transportation systems, ecological systems,\nand Internet systems, are complex systems. As an important tool for studying\ncomplex systems, computational experiments can map them into artificial society\nmodels that are computable and reproducible within computers, thereby providing\ndigital and computational methods for quantitative analysis. In current\nresearch, the construction of individual agent models often ignores the\nlong-term accumulative effect of memory mechanisms in the development process\nof agents, which to some extent causes the constructed models to deviate from\nthe real characteristics of real-world systems. To address this challenge, this\npaper proposes an individual agent model based on a memory-learning\ncollaboration mechanism, which implements hierarchical modeling of the memory\nmechanism and a multi-indicator evaluation mechanism. Through hierarchical\nmodeling of the individual memory repository, the group memory repository, and\nthe memory buffer pool, memory can be effectively managed, and knowledge\nsharing and dissemination between individuals and groups can be promoted. At\nthe same time, the multi-indicator evaluation mechanism enables dynamic\nevaluation of memory information, allowing dynamic updates of information in\nthe memory set and promoting collaborative decision-making between memory and\nlearning. Experimental results show that, compared with existing memory\nmodeling methods, the agents constructed by the proposed model demonstrate\nbetter decision-making quality and adaptability within the system. This\nverifies the effectiveness of the individual agent model based on the\nmemory-learning collaboration mechanism proposed in this paper in improving the\nquality of individual-level modeling in artificial society modeling and\nachieving anthropomorphic characteristics.", "published": "2025-07-27 10:42:00", "link": "http://arxiv.org/abs/2507.20215v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Local Prompt Adaptation for Style-Consistent Multi-Object Generation in Diffusion Models", "abstract": "Diffusion models have become a powerful backbone for text-to-image\ngeneration, enabling users to synthesize high-quality visuals from natural\nlanguage prompts. However, they often struggle with complex prompts involving\nmultiple objects and global or local style specifications. In such cases, the\ngenerated scenes tend to lack style uniformity and spatial coherence, limiting\ntheir utility in creative and controllable content generation. In this paper,\nwe propose a simple, training-free architectural method called Local Prompt\nAdaptation (LPA). Our method decomposes the prompt into content and style\ntokens, and injects them selectively into the U-Net's attention layers at\ndifferent stages. By conditioning object tokens early and style tokens later in\nthe generation process, LPA enhances both layout control and stylistic\nconsistency. We evaluate our method on a custom benchmark of 50 style-rich\nprompts across five categories and compare against strong baselines including\nComposer, MultiDiffusion, Attend-and-Excite, LoRA, and SDXL. Our approach\noutperforms prior work on both CLIP score and style consistency metrics,\noffering a new direction for controllable, expressive diffusion-based\ngeneration.", "published": "2025-07-27 01:32:13", "link": "http://arxiv.org/abs/2507.20094v1", "categories": ["cs.CV", "cs.AI", "cs.MA"], "primary_category": "cs.CV"}
{"title": "Subset selection for matrices in spectral norm", "abstract": "We address the subset selection problem for matrices, where the goal is to\nselect a subset of $k$ columns from a \"short-and-fat\" matrix $X \\in\n\\mathbb{R}^{m \\times n}$, such that the pseudoinverse of the sampled submatrix\nhas as small spectral or Frobenius norm as possible. For the NP-hard spectral\nnorm variant, we propose a new deterministic approximation algorithm. Our\nmethod refines the potential-based framework of spectral sparsification by\nspecializing it to a single barrier function. This key modification enables\ndirect, unweighted column selection, bypassing the intermediate weighting step\nrequired by previous approaches. It also allows for a novel adaptive update\nstrategy for the barrier. This approach yields a new, explicit bound on the\napproximation quality that improves upon existing guarantees in key parameter\nregimes, without increasing the asymptotic computational complexity.\nFurthermore, numerical experiments demonstrate that the proposed method\nconsistently outperforms its direct competitors. A complete C++ implementation\nis provided to support our findings and facilitate future research.", "published": "2025-07-27 22:36:37", "link": "http://arxiv.org/abs/2507.20435v1", "categories": ["math.NA", "cs.NA", "65F55, 90C27, 15A18, 62K05"], "primary_category": "math.NA"}
{"title": "A global Lipschitz stability perspective for understanding approximate approaches in Bayesian sequential learning", "abstract": "We establish a general, non-asymptotic error analysis framework for\nunderstanding the effects of incremental approximations made by practical\napproaches for Bayesian sequential learning (BSL) on their long-term inference\nperformance. Our setting covers inverse problems, state estimation, and\nparameter-state estimation. In these settings, we bound the difference-termed\nthe learning error-between the unknown true posterior and the approximate\nposterior computed by these approaches, using three widely used distribution\nmetrics: total variation, Hellinger, and Wasserstein distances. This framework\nbuilds on our establishment of the global Lipschitz stability of the posterior\nwith respect to the prior across these settings. To the best of our knowledge,\nthis is the first work to establish such global Lipschitz stability under the\nHellinger and Wasserstein distances and the first general error analysis\nframework for approximate BSL methods.\n  Our framework offers two sets of upper bounds on the learning error. The\nfirst set demonstrates the stability of general approximate BSL methods with\nrespect to the incremental approximation process, while the second set is\nestimable in many practical scenarios.\n  Furthermore, as an initial step toward understanding the phenomenon of\nlearning error decay, which is sometimes observed, we identify sufficient\nconditions under which data assimilation leads to learning error reduction.", "published": "2025-07-27 18:48:09", "link": "http://arxiv.org/abs/2507.20379v1", "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH"], "primary_category": "math.ST"}
{"title": "Computational Advantages of Multi-Grade Deep Learning: Convergence Analysis and Performance Insights", "abstract": "Multi-grade deep learning (MGDL) has been shown to significantly outperform\nthe standard single-grade deep learning (SGDL) across various applications.\nThis work aims to investigate the computational advantages of MGDL focusing on\nits performance in image regression, denoising, and deblurring tasks, and\ncomparing it to SGDL. We establish convergence results for the gradient descent\n(GD) method applied to these models and provide mathematical insights into\nMGDL's improved performance. In particular, we demonstrate that MGDL is more\nrobust to the choice of learning rate under GD than SGDL. Furthermore, we\nanalyze the eigenvalue distributions of the Jacobian matrices associated with\nthe iterative schemes arising from the GD iterations, offering an explanation\nfor MGDL's enhanced training stability.", "published": "2025-07-27 16:43:29", "link": "http://arxiv.org/abs/2507.20351v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Efficient numerical methods for the uncertain Boltzmann equation based on a hybrid solver", "abstract": "In this work, we propose and compare several approaches to solve the\nBoltzmann equation with uncertain parameters, including multi-level Monte Carlo\nand multi-fidelity methods that employ an asymptotic-preserving-hybrid (APH)\nscheme (Filbet and Rey, 2015) for the deterministic Boltzmann model. By\nconstructing a hierarchy of models from finer to coarser meshes in phase space\nfor the APH scheme and adopting variance reduction techniques, the MLMC method\nis able to allocate computational resources across different hierarchies\nquasi-optimally. On the other hand, in the bi-fidelity method we choose the APH\nscheme for the Boltzmann equation as the high-fidelity solver, and a finite\nvolume scheme for the compressible Euler system as the low-fidelity model.\nSince both methods are non-intrusive, they can preserve the physical properties\nof the deterministic solver. Extensive numerical experiments demonstrate that\nour APH-based MLMC and multi-fidelity methods are significantly faster than\nstandard approaches, while maintaining accuracy. We also provide practical\nguidelines for selection between APH-based MLMC and multi-fidelity approaches,\nbased on solution smoothness and computational resource availability.", "published": "2025-07-27 15:15:05", "link": "http://arxiv.org/abs/2507.20316v1", "categories": ["math.NA", "cs.NA", "35R60, 35Q20, 65C05"], "primary_category": "math.NA"}
{"title": "A Hybrid Particle-Continuum Method for Simulating Fast Ice via Subgrid Iceberg Interaction", "abstract": "A significant fraction (4%-13%) of Antarctic sea ice remains stationary as\nlandfast sea-ice (\"fast ice\"), typically anchored by grounded icebergs. Current\nglobal climate models do not represent fast-ice formation due to iceberg\ngrounding, as iceberg-sea-ice interaction mostly occurs at subgrid scales. We\npropose a novel subgrid-scale coupling mechanism between Lagrangian iceberg\nparticles and an Eulerian sea-ice continuum model. This hybrid\nparticle-continuum approach integrates feedback from icebergs into the sea-ice\nmomentum equation via a Green's function, a Stokeslet, representing the drag\nexerted by a point force on the viscous-plastic medium. The coupled system,\nincluding the Stokeslet induced drag, is discretized using a finite-element\nmethod with piecewise linear basis functions. The approach assumes that\nindividual icebergs have diameters smaller than the grid spacing. The presented\nfinite-element discretization is compatible with existing unstructured-mesh\nocean model frameworks such as FESOM and ICON, ensuring practical applicability\nin Earth system modeling. This work provides and analyzes, for the first time,\na stable numerical framework to capture the effects of individual subgrid-scale\nicebergs on sea-ice dynamics. We derive an a-priori stability estimate bounding\na functional of the sea-ice system and show that the momentum equation\nincluding the subgrid iceberg-sea-ice drag remains stable. Numerical test cases\ndemonstrate the capability of the approach to capture fast-ice formation due to\nsubgrid iceberg grounding on coarse horizontal grids.", "published": "2025-07-27 14:52:56", "link": "http://arxiv.org/abs/2507.20306v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Spectral element methods for boundary-value problems of functional differential equations", "abstract": "We prove convergence of the spectral element method for piecewise polynomial\ncollocation applied to periodic boundary value problems (BVP) for functional\n  differential equations with possibly state-dependent delays. If the exact\nsolution of the BVP has an analytic extension then the collocation solution\nconverges geometrically. This means that the accuracy of the approximation is\nof order $\\mathrm{e}^{-\\eta m}$ for some $\\eta>0$ depending on the size of the\nmesh, when using polynomials of degree $m$. If the exact solution has a finite\norder of continuous differentiability then the collocation solution converges\nwith this order.\n  For functional differential equations with state-dependent delays the\nright-hand side cannot be expected to be differentiable with respect to its\narguments in the classical sense, and analyticity of the solution does not\nnecessarily follow from analyticity of the coefficients in the right-hand side.\nThus, our geometric convergence statement assumes analyticity of the solution,\nrather than of the right-hand side.", "published": "2025-07-27 13:24:10", "link": "http://arxiv.org/abs/2507.20266v1", "categories": ["math.NA", "cs.NA", "65L03, 65L10, 65L20, 65L60"], "primary_category": "math.NA"}
{"title": "Imaging a moving point source in R^3 from the time of arrival at sparse observation points", "abstract": "In this paper, we introduce a novel numerical method for reconstructing the\ntrajectory within three-dimensional space, where both the emission moment and\nspatial location of the point source are unknown. Our approach relies solely on\nmeasuring the time of arrival at five or seven properly chosen observation\npoints. By utilizing the distinctive geometric configuration of these five or\nseven observation points, we establish the uniqueness of the trajectory and\nemission moment of the point source through rigorous mathematical proofs.\nMoreover, we analyze the stability of our proposed method. The effectiveness of\nthe method is also verified by numerical experiments.", "published": "2025-07-27 10:01:12", "link": "http://arxiv.org/abs/2507.20204v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "L\u00e9vy-Driven Option Pricing without a Riskless Asset", "abstract": "We extend the Lindquist-Rachev (LR) option-pricing framework--which values\nderivatives in markets lacking a traded risk-free bond--by introducing common\nLevy jump dynamics across two risky assets. The resulting endogenous \"shadow\"\nshort rate replaces the usual risk-free yield and governs discounting and\nrisk-neutral drifts. We focus on two widely used pure-jump specifications: the\nNormal Inverse Gaussian (NIG) process and the Carr-Geman-Madan-Yor (CGMY)\ntempered-stable process. Using Ito-Levy calculus we derive an LR partial\nintegro-differential equation (LR-PIDE) and obtain European option values\nthrough characteristic-function methods implemented with the Fast Fourier\nTransform (FFT) and Fourier-cosine (COS) algorithms. Calibrations to S and P\n500 index options show that both jump models materially reduce pricing errors\nand fit the observed volatility smile far better than the Black-Scholes\nbenchmark; CGMY delivers the largest improvement. We also extract time-varying\nshadow short rates from paired asset data and show that sharp declines coincide\nwith liquidity-stress episodes, highlighting risk signals not visible in\nTreasury yields. The framework links jump risk, relative asset pricing, and\nfunding conditions in a tractable form for practitioners.", "published": "2025-07-27 16:01:37", "link": "http://arxiv.org/abs/2507.20338v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "A Theory of $\u03b8$-Expectations", "abstract": "The canonical theory of stochastic calculus under ambiguity, founded on\nsub-additivity, is insensitive to non-convex uncertainty structures, leading to\nan identifiability impasse. This paper develops a mathematical framework for an\nidentifiable calculus sensitive to non-convex geometry. We introduce the\n$\\theta$-BSDE, a class of backward stochastic differential equations where the\ndriver is determined by a pointwise maximization over a primitive, possibly\nnon-convex, uncertainty set. The system's tractability is predicated not on\nconvexity, but on a global analytic hypothesis: the existence of a unique and\nglobally Lipschitz maximizer map for the driver function. Under this\nhypothesis, which carves out a tractable class of models, we establish\nwell-posedness via a fixed-point argument. For a distinct, geometrically\nregular class of models, we prove a result of independent interest: under\nnon-degeneracy conditions from Malliavin calculus, the maximizer is unique\nalong any solution path, ensuring the model's internal consistency. We clarify\nthe fundamental logical gap between this pathwise property and the global\nregularity required by our existence proof. The resulting valuation operator\ndefines a dynamically consistent expectation, and we establish its connection\nto fully nonlinear PDEs via a Feynman-Kac formula.", "published": "2025-07-27 16:56:01", "link": "http://arxiv.org/abs/2507.20353v1", "categories": ["math.PR", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "math.PR"}
{"title": "The Blessing and Curse of Dimensionality in Safety Alignment", "abstract": "The focus on safety alignment in large language models (LLMs) has increased\nsignificantly due to their widespread adoption across different domains. The\nscale of LLMs play a contributing role in their success, and the growth in\nparameter count follows larger hidden dimensions. In this paper, we hypothesize\nthat while the increase in dimensions has been a key advantage, it may lead to\nemergent problems as well. These problems emerge as the linear structures in\nthe activation space can be exploited, in the form of activation engineering,\nto circumvent its safety alignment. Through detailed visualizations of linear\nsubspaces associated with different concepts, such as safety, across various\nmodel scales, we show that the curse of high-dimensional representations\nuniquely impacts LLMs. Further substantiating our claim, we demonstrate that\nprojecting the representations of the model onto a lower dimensional subspace\ncan preserve sufficient information for alignment while avoiding those linear\nstructures. Empirical results confirm that such dimensional reduction\nsignificantly reduces susceptibility to jailbreaking through representation\nengineering. Building on our empirical validations, we provide theoretical\ninsights into these linear jailbreaking methods relative to a model's hidden\ndimensions. Broadly speaking, our work posits that the high dimensions of a\nmodel's internal representations can be both a blessing and a curse in safety\nalignment.", "published": "2025-07-27 15:51:23", "link": "http://arxiv.org/abs/2507.20333v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence", "abstract": "Uncertainty quantification is an important prerequisite for the deployment of\ndeep learning models in safety-critical areas. Yet, this hinges on the\nuncertainty estimates being useful to the extent the prediction intervals are\nwell-calibrated and sharp. In the absence of inherent uncertainty estimates\n(e.g. pretrained models predicting only point estimates), popular approaches\nthat operate post-hoc include Laplace's method and split conformal prediction\n(split-CP). However, Laplace's method can be miscalibrated when the model is\nmisspecified and split-CP requires sample splitting, and thus comes at the\nexpense of statistical efficiency. In this work, we construct prediction\nintervals for neural network regressors post-hoc without held-out data. This is\nachieved by approximating the full conformal prediction method (full-CP).\nWhilst full-CP nominally requires retraining the model for every test point and\ncandidate label, we propose to train just once and locally perturb model\nparameters using Gauss-Newton influence to approximate the effect of\nretraining. Coupled with linearization of the network, we express the absolute\nresidual nonconformity score as a piecewise linear function of the candidate\nlabel allowing for an efficient procedure that avoids the exhaustive search\nover the output space. On standard regression benchmarks and bounding box\nlocalization, we show the resulting prediction intervals are locally-adaptive\nand often tighter than those of split-CP.", "published": "2025-07-27 13:34:32", "link": "http://arxiv.org/abs/2507.20272v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data-Efficient Prediction-Powered Calibration via Cross-Validation", "abstract": "Calibration data are necessary to formally quantify the uncertainty of the\ndecisions produced by an existing artificial intelligence (AI) model. To\novercome the common issue of scarce calibration data, a promising approach is\nto employ synthetic labels produced by a (generally different) predictive\nmodel. However, fine-tuning the label-generating predictor on the inference\ntask of interest, as well as estimating the residual bias of the synthetic\nlabels, demand additional data, potentially exacerbating the calibration data\nscarcity problem. This paper introduces a novel approach that efficiently\nutilizes limited calibration data to simultaneously fine-tune a predictor and\nestimate the bias of the synthetic labels. The proposed method yields\nprediction sets with rigorous coverage guarantees for AI-generated decisions.\nExperimental results on an indoor localization problem validate the\neffectiveness and performance gains of our solution.", "published": "2025-07-27 13:31:02", "link": "http://arxiv.org/abs/2507.20268v1", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Automated Deep Segmentation and Spatial-Statistics Approach for Post-Blast Rock Fragmentation Assessment", "abstract": "We introduce an end-to-end pipeline that leverages a fine-tuned YOLO12l-seg\nmodel -- trained on over 500 annotated post-blast images -- to deliver\nreal-time instance segmentation (Box mAP@0.5 ~ 0.769, Mask mAP@0.5 ~ 0.800 at ~\n15 FPS). High-fidelity masks are converted into normalized 3D coordinates, from\nwhich we extract multi-metric spatial descriptors: principal component\ndirections, kernel density hotspots, size-depth regression, and Delaunay edge\nstatistics. We present four representative examples to illustrate key\nfragmentation patterns. Experimental results confirm the framework's accuracy,\nrobustness to small-object crowding, and feasibility for rapid, automated\nblast-effect assessment in field conditions.", "published": "2025-07-27 04:25:29", "link": "http://arxiv.org/abs/2507.20126v1", "categories": ["cs.CV", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Online Learning with Probing for Sequential User-Centric Selection", "abstract": "We formalize sequential decision-making with information acquisition as the\nprobing-augmented user-centric selection (PUCS) framework, where a learner\nfirst probes a subset of arms to obtain side information on resources and\nrewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such\nas ridesharing, wireless scheduling, and content recommendation, in which both\nresources and payoffs are initially unknown and probing is costly. For the\noffline setting with known distributions, we present a greedy probing algorithm\nwith a constant-factor approximation guarantee $\\zeta = (e-1)/(2e-1)$. For the\nonline setting with unknown distributions, we introduce OLPA, a stochastic\ncombinatorial bandit algorithm that achieves a regret bound\n$\\mathcal{O}(\\sqrt{T} + \\ln^{2} T)$. We also prove a lower bound\n$\\Omega(\\sqrt{T})$, showing that the upper bound is tight up to logarithmic\nfactors. Experiments on real-world data demonstrate the effectiveness of our\nsolutions.", "published": "2025-07-27 03:32:51", "link": "http://arxiv.org/abs/2507.20112v1", "categories": ["cs.LG", "cs.AI", "cs.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Meta Fusion: A Unified Framework For Multimodality Fusion with Mutual Learning", "abstract": "Developing effective multimodal data fusion strategies has become\nincreasingly essential for improving the predictive power of statistical\nmachine learning methods across a wide range of applications, from autonomous\ndriving to medical diagnosis. Traditional fusion methods, including early,\nintermediate, and late fusion, integrate data at different stages, each\noffering distinct advantages and limitations. In this paper, we introduce Meta\nFusion, a flexible and principled framework that unifies these existing\nstrategies as special cases. Motivated by deep mutual learning and ensemble\nlearning, Meta Fusion constructs a cohort of models based on various\ncombinations of latent representations across modalities, and further boosts\npredictive performance through soft information sharing within the cohort. Our\napproach is model-agnostic in learning the latent representations, allowing it\nto flexibly adapt to the unique characteristics of each modality.\nTheoretically, our soft information sharing mechanism reduces the\ngeneralization error. Empirically, Meta Fusion consistently outperforms\nconventional fusion strategies in extensive simulation studies. We further\nvalidate our approach on real-world applications, including Alzheimer's disease\ndetection and neural decoding.", "published": "2025-07-27 00:50:29", "link": "http://arxiv.org/abs/2507.20089v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Feed-anywhere ANN (I) Steady Discrete $\\to$ Diffusing on Graph Hidden States", "abstract": "We propose a novel framework for learning hidden graph structures from data\nusing geometric analysis and nonlinear dynamics. Our approach: (1) Defines\ndiscrete Sobolev spaces on graphs for scalar/vector fields, establishing key\nfunctional properties; (2) Introduces gauge-equivalent nonlinear Schr\\\"odinger\nand Landau--Lifshitz dynamics with provable stable stationary solutions\nsmoothly dependent on input data and graph weights; (3) Develops a stochastic\ngradient algorithm over graph moduli spaces with sparsity regularization.\nTheoretically, we guarantee: topological correctness (homology recovery),\nmetric convergence (Gromov--Hausdorff), and efficient search space utilization.\nOur dynamics-based model achieves stronger generalization bounds than standard\nneural networks, with complexity dependent on the data manifold's topology.", "published": "2025-07-27 00:35:15", "link": "http://arxiv.org/abs/2507.20088v1", "categories": ["cs.LG", "math-ph", "math.MP", "math.OC", "stat.ML", "G.1.6; G.1.7; G.2.2"], "primary_category": "cs.LG"}
{"title": "Two Views, One Truth: Spectral and Self-Supervised Features Fusion for Robust Speech Deepfake Detection", "abstract": "Recent advances in synthetic speech have made audio deepfakes increasingly\nrealistic, posing significant security risks. Existing detection methods that\nrely on a single modality, either raw waveform embeddings or spectral based\nfeatures, are vulnerable to non spoof disturbances and often overfit to known\nforgery algorithms, resulting in poor generalization to unseen attacks. To\naddress these shortcomings, we investigate hybrid fusion frameworks that\nintegrate self supervised learning (SSL) based representations with handcrafted\nspectral descriptors (MFCC , LFCC, CQCC). By aligning and combining\ncomplementary information across modalities, these fusion approaches capture\nsubtle artifacts that single feature approaches typically overlook. We explore\nseveral fusion strategies, including simple concatenation, cross attention,\nmutual cross attention, and a learnable gating mechanism, to optimally blend\nSSL features with fine grained spectral cues. We evaluate our approach on four\nchallenging public benchmarks and report generalization performance. All fusion\nvariants consistently outperform an SSL only baseline, with the cross attention\nstrategy achieving the best generalization with a 38% relative reduction in\nequal error rate (EER). These results confirm that joint modeling of waveform\nand spectral views produces robust, domain agnostic representations for audio\ndeepfake detection.", "published": "2025-07-27 21:22:27", "link": "http://arxiv.org/abs/2507.20417v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Self-Improvement for Audio Large Language Model using Unlabeled Speech", "abstract": "Recent audio LLMs have emerged rapidly, demonstrating strong generalization\nacross various speech tasks. However, given the inherent complexity of speech\nsignals, these models inevitably suffer from performance degradation in\nspecific target domains. To address this, we focus on enhancing audio LLMs in\ntarget domains without any labeled data. We propose a self-improvement method\ncalled SI-SDA, leveraging the information embedded in large-model decoding to\nevaluate the quality of generated pseudo labels and then perform domain\nadaptation based on reinforcement learning optimization. Experimental results\nshow that our method consistently and significantly improves audio LLM\nperformance, outperforming existing baselines in WER and BLEU across multiple\npublic datasets of automatic speech recognition (ASR), spoken\nquestion-answering (SQA), and speech-to-text translation (S2TT). Furthermore,\nour approach exhibits high data efficiency, underscoring its potential for\nreal-world deployment.", "published": "2025-07-27 08:16:23", "link": "http://arxiv.org/abs/2507.20169v1", "categories": ["cs.SD", "eess.AS", "I.2.7; H.5.5"], "primary_category": "cs.SD"}
{"title": "Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech", "abstract": "The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has\nenabled high-fidelity voice synthesis from minimal audio cues, raising\nsignificant privacy and ethical concerns. Despite the threats to voice privacy,\nresearch to selectively remove the knowledge to replicate unwanted individual\nvoices from pre-trained model parameters has not been explored. In this paper,\nwe address the new challenge of speaker identity unlearning for ZS-TTS systems.\nTo meet this goal, we propose the first machine unlearning frameworks for\nZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the\nmodel forgets designated speaker identities while retaining its ability to\ngenerate accurate speech for other speakers. Our proposed methods incorporate\nrandomness to prevent consistent replication of forget speakers' voices,\nassuring unlearned identities remain untraceable. Additionally, we propose a\nnew evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses\nthe model's ability to disregard prompts associated with forgotten speakers,\neffectively neutralizing its knowledge of these voices. The experiments\nconducted on the state-of-the-art model demonstrate that TGU prevents the model\nfrom replicating forget speakers' voices while maintaining high quality for\nother speakers. The demo is available at https://speechunlearn.github.io/", "published": "2025-07-27 06:13:58", "link": "http://arxiv.org/abs/2507.20140v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models", "abstract": "Speech language models refer to language models with speech processing and\nunderstanding capabilities. One key desirable capability for speech language\nmodels is the ability to capture the intricate interdependency between content\nand prosody. The existing mainstream paradigm of training speech language\nmodels, which converts speech into discrete tokens before feeding them into\nLLMs, is sub-optimal in learning prosody information -- we find that the\nresulting LLMs do not exhibit obvious emerging prosody processing capabilities\nvia pre-training alone. To overcome this, we propose ProsodyLM, which\nintroduces a simple tokenization scheme amenable to learning prosody. Each\nspeech utterance is first transcribed into text, followed by a sequence of\nword-level prosody tokens. Compared with conventional speech tokenization\nschemes, the proposed tokenization scheme retains more complete prosody\ninformation, and is more understandable to text-based LLMs. We find that\nProsodyLM can learn surprisingly diverse emerging prosody processing\ncapabilities through pre-training alone, ranging from harnessing the prosody\nnuances in generated speech, such as contrastive focus, understanding emotion\nand stress in an utterance, to maintaining prosody consistency in long\ncontexts.", "published": "2025-07-27 00:59:01", "link": "http://arxiv.org/abs/2507.20091v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings", "abstract": "DNA-binding proteins (DBPs) are integral to gene regulation and cellular\nprocesses, making their accurate identification essential for understanding\nbiological functions and disease mechanisms. Experimental methods for DBP\nidentification are time-consuming and costly, driving the need for efficient\ncomputational prediction techniques. In this study, we propose a novel deep\nlearning framework, ResCap-DBP, that combines a residual learning-based encoder\nwith a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly\nfrom raw protein sequences. Our architecture incorporates dilated convolutions\nwithin residual blocks to mitigate vanishing gradient issues and extract rich\nsequence features, while capsule layers with dynamic routing capture\nhierarchical and spatial relationships within the learned feature space. We\nconducted comprehensive ablation studies comparing global and local embeddings\nfrom ProteinBERT and conventional one-hot encoding. Results show that\nProteinBERT embeddings substantially outperform other representations on large\ndatasets. Although one-hot encoding showed marginal advantages on smaller\ndatasets, such as PDB186, it struggled to scale effectively. Extensive\nevaluations on four pairs of publicly available benchmark datasets demonstrate\nthat our model consistently outperforms current state-of-the-art methods. It\nachieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On\nindependent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2%\nand 83.3%, while maintaining competitive performance on larger datasets such as\nPDB20000. Notably, the model maintains a well balanced sensitivity and\nspecificity across datasets. These results demonstrate the efficacy and\ngeneralizability of integrating global protein representations with advanced\ndeep learning architectures for reliable and scalable DBP prediction in diverse\ngenomic contexts.", "published": "2025-07-27 21:54:32", "link": "http://arxiv.org/abs/2507.20426v1", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification", "abstract": "Automated analysis of lung sound auscultation is essential for monitoring\nrespiratory health, especially in regions facing a shortage of skilled\nhealthcare workers. While respiratory sound classification has been widely\nstudied in adults, its ap plication in pediatric populations, particularly in\nchildren aged <6 years, remains an underexplored area. The developmental\nchanges in pediatric lungs considerably alter the acoustic proper ties of\nrespiratory sounds, necessitating specialized classification approaches\ntailored to this age group. To address this, we propose a multistage hybrid\nCNN-Transformer framework that combines CNN-extracted features with an\nattention-based architecture to classify pediatric respiratory diseases using\nscalogram images from both full recordings and individual breath events. Our\nmodel achieved an overall score of 0.9039 in binary event classifi cation and\n0.8448 in multiclass event classification by employing class-wise focal loss to\naddress data imbalance. At the recording level, the model attained scores of\n0.720 for ternary and 0.571 for multiclass classification. These scores\noutperform the previous best models by 3.81% and 5.94%, respectively. This\napproach offers a promising solution for scalable pediatric respiratory disease\ndiagnosis, especially in resource-limited settings.", "published": "2025-07-27 20:36:46", "link": "http://arxiv.org/abs/2507.20408v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories", "abstract": "Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting\ngoods in 5G network-enabled smart factories, with the compute-intensive\nlocalization module presenting a significant opportunity for optimization. We\npropose ACCESS-AV, an energy-efficient Vehicle-to-Infrastructure (V2I)\nlocalization framework that leverages existing 5G infrastructure in smart\nfactory environments. By opportunistically accessing the periodically broadcast\n5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates\nthe need for dedicated Roadside Units (RSUs) or additional onboard sensors to\nachieve energy efficiency as well as cost reduction. We implement an\nAngle-of-Arrival (AoA)-based estimation method using the Multiple Signal\nClassification (MUSIC) algorithm, optimized for resource-constrained ADV\nplatforms through an adaptive communication-computation strategy that\ndynamically balances energy consumption with localization accuracy based on\nenvironmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle\nvelocity. Experimental results demonstrate that ACCESS-AV achieves an average\nenergy reduction of 43.09% compared to non-adaptive systems employing AoA\nalgorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30\ncm localization accuracy while also delivering substantial reductions in\ninfrastructure and operational costs, establishing its viability for\nsustainable smart factory environments.", "published": "2025-07-27 19:44:07", "link": "http://arxiv.org/abs/2507.20399v1", "categories": ["eess.SY", "cs.AR", "cs.NI", "cs.RO", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Reliability of Wi-Fi, LTE, and 5G-Based UAV RC Links in ISM Bands: Uplink Interference Asymmetry Analysis and HARQ Design", "abstract": "Command and control of uncrewed aerial vehicles (UAVs) is often realized\nthrough air-to-ground (A2G) remote control (RC) links that operate in ISM\nbands. While wireless fidelity (Wi-Fi) technology is commonly used for UAV RC\nlinks, ISM-based long-term evolution (LTE) and fifth-generation (5G)\ntechnologies have also been recently considered for the same purpose. A major\nproblem for UAV RC links in the ISM bands is that other types of interference\nsources, such as legacy Wi-Fi and Bluetooth transmissions, may degrade the link\nquality. Such interference problems are a higher concern for the UAV in the air\nthan the RC unit on the ground due to the UAV being in line-of-sight (LoS) with\na larger number of interference sources. To obtain empirical evidence of the\nasymmetric interference conditions in downlink (DL) and uplink (UL), we first\nconducted a measurement campaign using a helikite platform in urban and rural\nareas at NC State University. The results from this measurement campaign show\nthat the aggregate interference can be up to 16.66 dB at higher altitudes up to\n170 m, compared with the interference observed at a ground receiver. As a\nresult of this asymmetric UL interference, lost hybrid automatic repeat request\n(HARQ) indicators (ACK/NACK) in the UL may degrade the DL throughput. To\ninvestigate this, we study various HARQ mechanisms, including HARQ Type-I with\nno combining, HARQ Type-I with chase combining, HARQ Type-III with incremental\nredundancy, and burst transmission with chase combining. To evaluate the impact\nof asymmetric UL interference on throughput performance, we consider three\nsteps of evaluation process: 1) standalone physical DL shared channel (PDSCH)\nthroughput evaluation with perfect ACK/NACK assumption; 2) standalone physical\nUL control channel (PUCCH) decoding reliability evaluation; and 3) PDSCH DL\nthroughput evaluation with asymmetric UL ACK/NACK transmission.", "published": "2025-07-27 19:21:20", "link": "http://arxiv.org/abs/2507.20392v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Information-Preserving CSI Feedback: Invertible Networks with Endogenous Quantization and Channel Error Mitigation", "abstract": "Deep learning has emerged as a promising so- lution for efficient channel\nstate information (CSI) feedback in frequency division duplex (FDD) massive\nMIMO systems. Conventional deep learning-based methods typically rely on a deep\nautoencoder to compress the CSI, which leads to irre- versible information loss\nand degrades reconstruction accuracy. This paper introduces InvCSINet, an\ninformation-preserving CSI feedback framework based on invertible neural\nnetworks (INNs). By leveraging the bijective nature of INNs, the model ensures\ninformation-preserving compression and reconstruction with shared model\nparameters. To address practical challenges such as quantization and\nchannel-induced errors, we endoge- nously integrate an adaptive quantization\nmodule, a differentiable bit-channel distortion module and an information\ncompensation module into the INN architecture. This design enables the network\nto learn and compensate the information loss during CSI compression,\nquantization, and noisy transmission, thereby preserving the CSI integrity\nthroughout the feedback process. Simulation results validate the effectiveness\nof the proposed scheme, demonstrating superior CSI recovery performance and\nrobustness to practical impairments with a lightweight architec- ture.", "published": "2025-07-27 13:58:23", "link": "http://arxiv.org/abs/2507.20283v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis", "abstract": "Methamphetamine dependence poses a significant global health challenge, yet\nits assessment and the evaluation of treatments like repetitive transcranial\nmagnetic stimulation (rTMS) frequently depend on subjective self-reports, which\nmay introduce uncertainties. While objective neuroimaging modalities such as\nelectroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS)\noffer alternatives, their individual limitations and the reliance on\nconventional, often hand-crafted, feature extraction can compromise the\nreliability of derived biomarkers. To overcome these limitations, we propose\nNeuroCLIP, a novel deep learning framework integrating simultaneously recorded\nEEG and fNIRS data through a progressive learning strategy. This approach\noffers a robust and trustworthy biomarker for methamphetamine addiction.\nValidation experiments show that NeuroCLIP significantly improves\ndiscriminative capabilities among the methamphetamine-dependent individuals and\nhealthy controls compared to models using either EEG or only fNIRS alone.\nFurthermore, the proposed framework facilitates objective, brain-based\nevaluation of rTMS treatment efficacy, demonstrating measurable shifts in\nneural patterns towards healthy control profiles after treatment. Critically,\nwe establish the trustworthiness of the multimodal data-driven biomarker by\nshowing its strong correlation with psychometrically validated craving scores.\nThese findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP\noffers enhanced robustness and reliability over single-modality approaches,\nproviding a valuable tool for addiction neuroscience research and potentially\nimproving clinical assessments.", "published": "2025-07-27 09:16:39", "link": "http://arxiv.org/abs/2507.20189v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "CodeNER: Code Prompting for Named Entity Recognition", "abstract": "Recent studies have explored various approaches for treating candidate named\nentity spans as both source and target sequences in named entity recognition\n(NER) by leveraging large language models (LLMs). Although previous approaches\nhave successfully generated candidate named entity spans with suitable labels,\nthey rely solely on input context information when using LLMs, particularly,\nChatGPT. However, NER inherently requires capturing detailed labeling\nrequirements with input context information. To address this issue, we propose\na novel method that leverages code-based prompting to improve the capabilities\nof LLMs in understanding and performing NER. By embedding code within prompts,\nwe provide detailed BIO schema instructions for labeling, thereby exploiting\nthe ability of LLMs to comprehend long-range scopes in programming languages.\nExperimental results demonstrate that the proposed code-based prompting method\noutperforms conventional text-based prompting on ten benchmarks across English,\nArabic, Finnish, Danish, and German datasets, indicating the effectiveness of\nexplicitly structuring NER instructions. We also verify that combining the\nproposed code-based prompting method with the chain-of-thought prompting\nfurther improves performance.", "published": "2025-07-27 21:49:36", "link": "http://arxiv.org/abs/2507.20423v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?", "abstract": "Natural Language Understanding (NLU) is a basic task in Natural Language\nProcessing (NLP). The evaluation of NLU capabilities has become a trending\nresearch topic that attracts researchers in the last few years, resulting in\nthe development of numerous benchmarks. These benchmarks include various tasks\nand datasets in order to evaluate the results of pretrained models via public\nleaderboards. Notably, several benchmarks contain diagnostics datasets designed\nfor investigation and fine-grained error analysis across a wide range of\nlinguistic phenomena. This survey provides a comprehensive review of available\nEnglish, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on\ntheir diagnostics datasets and the linguistic phenomena they covered. We\npresent a detailed comparison and analysis of these benchmarks, highlighting\ntheir strengths and limitations in evaluating NLU tasks and providing in-depth\nerror analysis. When highlighting the gaps in the state-of-the-art, we noted\nthat there is no naming convention for macro and micro categories or even a\nstandard set of linguistic phenomena that should be covered. Consequently, we\nformulated a research question regarding the evaluation metrics of the\nevaluation diagnostics benchmarks: \"Why do not we have an evaluation standard\nfor the NLU evaluation diagnostics benchmarks?\" similar to ISO standard in\nindustry. We conducted a deep analysis and comparisons of the covered\nlinguistic phenomena in order to support experts in building a global hierarchy\nfor linguistic phenomena in future. We think that having evaluation metrics for\ndiagnostics evaluation could be valuable to gain more insights when comparing\nthe results of the studied models on different diagnostics benchmarks.", "published": "2025-07-27 21:30:50", "link": "http://arxiv.org/abs/2507.20419v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CONCAP: Seeing Beyond English with Concepts Retrieval-Augmented Captioning", "abstract": "Multilingual vision-language models have made significant strides in image\ncaptioning, yet they still lag behind their English counterparts due to limited\nmultilingual training data and costly large-scale model parameterization.\nRetrieval-augmented generation (RAG) offers a promising alternative by\nconditioning caption generation on retrieved examples in the target language,\nreducing the need for extensive multilingual training. However, multilingual\nRAG captioning models often depend on retrieved captions translated from\nEnglish, which can introduce mismatches and linguistic biases relative to the\nsource language. We introduce CONCAP, a multilingual image captioning model\nthat integrates retrieved captions with image-specific concepts, enhancing the\ncontextualization of the input image and grounding the captioning process\nacross different languages. Experiments on the XM3600 dataset indicate that\nCONCAP enables strong performance on low- and mid-resource languages, with\nhighly reduced data requirements. Our findings highlight the effectiveness of\nconcept-aware retrieval augmentation in bridging multilingual performance gaps.", "published": "2025-07-27 21:00:02", "link": "http://arxiv.org/abs/2507.20411v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations", "abstract": "Chain-of-Thought (CoT) prompting helps models think step by step. But what\nhappens when they must see, understand, and judge-all at once? In visual tasks\ngrounded in social context, where bridging perception with norm-grounded\njudgments is essential, flat CoT often breaks down. We introduce Cognitive\nChain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning\nthrough three cognitively inspired stages: perception, situation, and norm. Our\nexperiments show that, across multiple multimodal benchmarks (including intent\ndisambiguation, commonsense reasoning, and safety), CoCoT consistently\noutperforms CoT and direct prompting (+8\\% on average). Our findings\ndemonstrate that cognitively grounded reasoning stages enhance interpretability\nand social awareness in VLMs, paving the way for safer and more reliable\nmultimodal systems.", "published": "2025-07-27 20:40:30", "link": "http://arxiv.org/abs/2507.20409v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Length Representations in Large Language Models", "abstract": "Large language models (LLMs) have shown remarkable capabilities across\nvarious tasks, that are learned from massive amounts of text-based data.\nAlthough LLMs can control output sequence length, particularly in\ninstruction-based settings, the internal mechanisms behind this control have\nbeen unexplored yet. In this study, we provide empirical evidence on how output\nsequence length information is encoded within the internal representations in\nLLMs. In particular, our findings show that multi-head attention mechanisms are\ncritical in determining output sequence length, which can be adjusted in a\ndisentangled manner. By scaling specific hidden units within the model, we can\ncontrol the output sequence length without losing the informativeness of the\ngenerated text, thereby indicating that length information is partially\ndisentangled from semantic information. Moreover, some hidden units become\nincreasingly active as prompts become more length-specific, thus reflecting the\nmodel's internal awareness of this attribute. Our findings suggest that LLMs\nhave learned robust and adaptable internal mechanisms for controlling output\nlength without any external control.", "published": "2025-07-27 19:41:39", "link": "http://arxiv.org/abs/2507.20398v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RMTBench: Benchmarking LLMs Through Multi-Turn User-Centric Role-Playing", "abstract": "Recent advancements in Large Language Models (LLMs) have shown outstanding\npotential for role-playing applications. Evaluating these capabilities is\nbecoming crucial yet remains challenging. Existing benchmarks mostly adopt a\n\\textbf{character-centric} approach, simplify user-character interactions to\nisolated Q&A tasks, and fail to reflect real-world applications. To address\nthis limitation, we introduce RMTBench, a comprehensive \\textbf{user-centric}\nbilingual role-playing benchmark featuring 80 diverse characters and over 8,000\ndialogue rounds. RMTBench includes custom characters with detailed backgrounds\nand abstract characters defined by simple traits, enabling evaluation across\nvarious user scenarios. Our benchmark constructs dialogues based on explicit\nuser motivations rather than character descriptions, ensuring alignment with\npractical user applications. Furthermore, we construct an authentic multi-turn\ndialogue simulation mechanism. With carefully selected evaluation dimensions\nand LLM-based scoring, this mechanism captures the complex intention of\nconversations between the user and the character. By shifting focus from\ncharacter background to user intention fulfillment, RMTBench bridges the gap\nbetween academic evaluation and practical deployment requirements, offering a\nmore effective framework for assessing role-playing capabilities in LLMs. All\ncode and datasets will be released soon.", "published": "2025-07-27 16:49:47", "link": "http://arxiv.org/abs/2507.20352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns", "abstract": "We present DYNARTmo, a dynamic articulatory model designed to visualize\nspeech articulation processes in a two-dimensional midsagittal plane. The model\nbuilds upon the UK-DYNAMO framework and integrates principles of articulatory\nunderspecification, segmental and gestural control, and coarticulation.\nDYNARTmo simulates six key articulators based on ten continuous and six\ndiscrete control parameters, allowing for the generation of both vocalic and\nconsonantal articulatory configurations. The current implementation is embedded\nin a web-based application (SpeechArticulationTrainer) that includes sagittal,\nglottal, and palatal views, making it suitable for use in phonetics education\nand speech therapy. While this paper focuses on the static modeling aspects,\nfuture work will address dynamic movement generation and integration with\narticulatory-acoustic modules.", "published": "2025-07-27 16:19:46", "link": "http://arxiv.org/abs/2507.20343v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Dialectal Arabic to Modern Standard Arabic Machine Translation", "abstract": "Dialectal Arabic (DA) poses a persistent challenge for natural language\nprocessing (NLP), as most everyday communication in the Arab world occurs in\ndialects that diverge significantly from Modern Standard Arabic (MSA). This\nlinguistic divide limits access to digital services and educational resources\nand impedes progress in Arabic machine translation. This paper presents two\ncore contributions to advancing DA-MSA translation for the Levantine, Egyptian,\nand Gulf dialects, particularly in low-resource and computationally constrained\nsettings: a comprehensive evaluation of training-free prompting techniques, and\nthe development of a resource-efficient fine-tuning pipeline. Our evaluation of\nprompting strategies across six large language models (LLMs) found that\nfew-shot prompting consistently outperformed zero-shot, chain-of-thought, and\nour proposed Ara-TEaR method. GPT-4o achieved the highest performance across\nall prompting settings. For fine-tuning, a quantized Gemma2-9B model achieved a\nCHrF++ score of 49.88, outperforming zero-shot GPT-4o (44.58). Joint\nmulti-dialect trained models outperformed single-dialect counterparts by over\n10% CHrF++, and 4-bit quantization reduced memory usage by 60% with less than\n1% performance loss. The results and insights of our experiments offer a\npractical blueprint for improving dialectal inclusion in Arabic NLP, showing\nthat high-quality DA-MSA machine translation is achievable even with limited\nresources and paving the way for more inclusive language technologies.", "published": "2025-07-27 14:37:53", "link": "http://arxiv.org/abs/2507.20301v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration", "abstract": "Scientific research increasingly relies on specialized computational tools,\nyet effectively utilizing these tools demands substantial domain expertise.\nWhile Large Language Models (LLMs) show promise in tool automation, they\nstruggle to seamlessly integrate and orchestrate multiple tools for complex\nscientific workflows. Here, we present SciToolAgent, an LLM-powered agent that\nautomates hundreds of scientific tools across biology, chemistry, and materials\nscience. At its core, SciToolAgent leverages a scientific tool knowledge graph\nthat enables intelligent tool selection and execution through graph-based\nretrieval-augmented generation. The agent also incorporates a comprehensive\nsafety-checking module to ensure responsible and ethical tool usage. Extensive\nevaluations on a curated benchmark demonstrate that SciToolAgent significantly\noutperforms existing approaches. Case studies in protein engineering, chemical\nreactivity prediction, chemical synthesis, and metal-organic framework\nscreening further demonstrate SciToolAgent's capability to automate complex\nscientific workflows, making advanced research tools accessible to both experts\nand non-experts.", "published": "2025-07-27 13:55:35", "link": "http://arxiv.org/abs/2507.20280v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "What Language(s) Does Aya-23 Think In? How Multilinguality Affects Internal Language Representations", "abstract": "Large language models (LLMs) excel at multilingual tasks, yet their internal\nlanguage processing remains poorly understood. We analyze how Aya-23-8B, a\ndecoder-only LLM trained on balanced multilingual data, handles code-mixed,\ncloze, and translation tasks compared to predominantly monolingual models like\nLlama 3 and Chinese-LLaMA-2. Using logit lens and neuron specialization\nanalyses, we find: (1) Aya-23 activates typologically related language\nrepresentations during translation, unlike English-centric models that rely on\na single pivot language; (2) code-mixed neuron activation patterns vary with\nmixing rates and are shaped more by the base language than the mixed-in one;\nand (3) Aya-23's languagespecific neurons for code-mixed inputs concentrate in\nfinal layers, diverging from prior findings on decoder-only models. Neuron\noverlap analysis further shows that script similarity and typological relations\nimpact processing across model types. These findings reveal how multilingual\ntraining shapes LLM internals and inform future cross-lingual transfer\nresearch.", "published": "2025-07-27 13:53:45", "link": "http://arxiv.org/abs/2507.20279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MoL-RL: Distilling Multi-Step Environmental Feedback into LLMs for Feedback-Independent Reasoning", "abstract": "Large language models (LLMs) face significant challenges in effectively\nleveraging sequential environmental feedback (EF) signals, such as natural\nlanguage evaluations, for feedback-independent chain-of-thought (CoT)\nreasoning. Existing approaches either convert EF into scalar rewards, losing\nrich contextual information, or employ refinement datasets, failing to exploit\nthe multi-step and discrete nature of EF interactions. To address these\nlimitations, we propose MoL-RL, a novel training paradigm that integrates\nmulti-step EF signals into LLMs through a dual-objective optimization\nframework. Our method combines MoL (Mixture-of-Losses) continual training,\nwhich decouples domain-specific EF signals (optimized via cross-entropy loss)\nand general language capabilities (preserved via Kullback-Leibler divergence),\nwith GRPO-based post-training to distill sequential EF interactions into\nsingle-step inferences. This synergy enables robust feedback-independent\nreasoning without relying on external feedback loops. Experimental results on\nmathematical reasoning (MATH-500, AIME24/AIME25) and code generation\n(CodeAgent-Test) benchmarks demonstrate that MoL-RL achieves state-of-the-art\nperformance with the Qwen3-8B model, while maintaining strong generalization\nacross model scales (Qwen3-4B). This work provides a promising approach for\nleveraging multi-step textual feedback to enhance LLMs' reasoning capabilities\nin diverse domains.", "published": "2025-07-27 13:52:15", "link": "http://arxiv.org/abs/2507.20278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EMBRACE: Shaping Inclusive Opinion Representation by Aligning Implicit Conversations with Social Norms", "abstract": "Shaping inclusive representations that embrace diversity and ensure fair\nparticipation and reflections of values is at the core of many\nconversation-based models. However, many existing methods rely on surface\ninclusion using mention of user demographics or behavioral attributes of social\ngroups. Such methods overlook the nuanced, implicit expression of opinion\nembedded in conversations. Furthermore, the over-reliance on overt cues can\nexacerbate misalignment and reinforce harmful or stereotypical representations\nin model outputs. Thus, we took a step back and recognized that equitable\ninclusion needs to account for the implicit expression of opinion and use the\nstance of responses to validate the normative alignment. This study aims to\nevaluate how opinions are represented in NLP or computational models by\nintroducing an alignment evaluation framework that foregrounds implicit, often\noverlooked conversations and evaluates the normative social views and\ndiscourse. Our approach models the stance of responses as a proxy for the\nunderlying opinion, enabling a considerate and reflective representation of\ndiverse social viewpoints. We evaluate the framework using both (i)\npositive-unlabeled (PU) online learning with base classifiers, and (ii)\ninstruction-tuned language models to assess post-training alignment. Through\nthis, we provide a lens on how implicit opinions are (mis)represented and offer\na pathway toward more inclusive model behavior.", "published": "2025-07-27 13:21:07", "link": "http://arxiv.org/abs/2507.20264v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Post-Completion Learning for Language Models", "abstract": "Current language model training paradigms typically terminate learning upon\nreaching the end-of-sequence (<eos>}) token, overlooking the potential learning\nopportunities in the post-completion space. We propose Post-Completion Learning\n(PCL), a novel training framework that systematically utilizes the sequence\nspace after model output completion, to enhance both the reasoning and\nself-evaluation abilities. PCL enables models to continue generating\nself-assessments and reward predictions during training, while maintaining\nefficient inference by stopping at the completion point.\n  To fully utilize this post-completion space, we design a white-box\nreinforcement learning method: let the model evaluate the output content\naccording to the reward rules, then calculate and align the score with the\nreward functions for supervision. We implement dual-track SFT to optimize both\nreasoning and evaluation capabilities, and mixed it with RL training to achieve\nmulti-objective hybrid optimization.\n  Experimental results on different datasets and models demonstrate consistent\nimprovements over traditional SFT and RL methods. Our method provides a new\ntechnical path for language model training that enhances output quality while\npreserving deployment efficiency.", "published": "2025-07-27 12:47:26", "link": "http://arxiv.org/abs/2507.20252v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Professionalism in Expert Questioning through Linguistic Differentiation", "abstract": "Professionalism is a crucial yet underexplored dimension of expert\ncommunication, particularly in high-stakes domains like finance. This paper\ninvestigates how linguistic features can be leveraged to model and evaluate\nprofessionalism in expert questioning. We introduce a novel annotation\nframework to quantify structural and pragmatic elements in financial analyst\nquestions, such as discourse regulators, prefaces, and request types. Using\nboth human-authored and large language model (LLM)-generated questions, we\nconstruct two datasets: one annotated for perceived professionalism and one\nlabeled by question origin. We show that the same linguistic features correlate\nstrongly with both human judgments and authorship origin, suggesting a shared\nstylistic foundation. Furthermore, a classifier trained solely on these\ninterpretable features outperforms gemini-2.0 and SVM baselines in\ndistinguishing expert-authored questions. Our findings demonstrate that\nprofessionalism is a learnable, domain-general construct that can be captured\nthrough linguistically grounded modeling.", "published": "2025-07-27 12:30:45", "link": "http://arxiv.org/abs/2507.20249v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reframe Your Life Story: Interactive Narrative Therapist and Innovative Moment Assessment with Large Language Models", "abstract": "Recent progress in large language models (LLMs) has opened new possibilities\nfor mental health support, yet current approaches lack realism in simulating\nspecialized psychotherapy and fail to capture therapeutic progression over\ntime. Narrative therapy, which helps individuals transform problematic life\nstories into empowering alternatives, remains underutilized due to limited\naccess and social stigma. We address these limitations through a comprehensive\nframework with two core components. First, INT (Interactive Narrative\nTherapist) simulates expert narrative therapists by planning therapeutic\nstages, guiding reflection levels, and generating contextually appropriate\nexpert-like responses. Second, IMA (Innovative Moment Assessment) provides a\ntherapy-centric evaluation method that quantifies effectiveness by tracking\n\"Innovative Moments\" (IMs), critical narrative shifts in client speech\nsignaling therapy progress. Experimental results on 260 simulated clients and\n230 human participants reveal that INT consistently outperforms standard LLMs\nin therapeutic quality and depth. We further demonstrate the effectiveness of\nINT in synthesizing high-quality support conversations to facilitate social\napplications.", "published": "2025-07-27 11:52:09", "link": "http://arxiv.org/abs/2507.20241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co-NAML-LSTUR: A Combined Model with Attentive Multi-View Learning and Long- and Short-term User Representations for News Recommendation", "abstract": "News recommendation systems play a vital role in mitigating information\noverload by delivering personalized news content. A central challenge is to\neffectively model both multi-view news representations and the dynamic nature\nof user interests, which often span both short- and long-term preferences.\nExisting methods typically rely on single-view features of news articles (e.g.,\ntitles or categories) or fail to comprehensively capture user preferences\nacross time scales. In this work, we propose Co-NAML-LSTUR, a hybrid news\nrecommendation framework that integrates NAML for attentive multi-view news\nmodeling and LSTUR for capturing both long- and short-term user\nrepresentations. Our model also incorporates BERT-based word embeddings to\nenhance semantic feature extraction. We evaluate Co-NAML-LSTUR on two widely\nused benchmarks, MIND-small and MIND-large. Experimental results show that\nCo-NAML-LSTUR achieves substantial improvements over most state-of-the-art\nbaselines on MIND-small and MIND-large, respectively. These results demonstrate\nthe effectiveness of combining multi-view news representations with dual-scale\nuser modeling. The implementation of our model is publicly available at\nhttps://github.com/MinhNguyenDS/Co-NAML-LSTUR.", "published": "2025-07-27 10:18:22", "link": "http://arxiv.org/abs/2507.20210v1", "categories": ["cs.CL", "68T50, 68T05", "I.2.7; I.7"], "primary_category": "cs.CL"}
{"title": "IQ Test for LLMs: An Evaluation Framework for Uncovering Core Skills in LLMs", "abstract": "Current evaluations of large language models (LLMs) rely on benchmark scores,\nbut it is difficult to interpret what these individual scores reveal about a\nmodel's overall skills. Specifically, as a community we lack understanding of\nhow tasks relate to one another, what they measure in common, how they differ,\nor which ones are redundant. As a result, models are often assessed via a\nsingle score averaged across benchmarks, an approach that fails to capture the\nmodels' wholistic strengths and limitations. Here, we propose a new evaluation\nparadigm that uses factor analysis to identify latent skills driving\nperformance across benchmarks. We apply this method to a comprehensive new\nleaderboard showcasing the performance of 60 LLMs on 44 tasks, and identify a\nsmall set of latent skills that largely explain performance. Finally, we turn\nthese insights into practical tools that identify redundant tasks, aid in model\nselection, and profile models along each latent skill.", "published": "2025-07-27 10:11:16", "link": "http://arxiv.org/abs/2507.20208v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Diversity-Enhanced Reasoning for Subjective Questions", "abstract": "Large reasoning models (LRM) with long chain-of-thought (CoT) capabilities\nhave shown strong performance on objective tasks, such as math reasoning and\ncoding. However, their effectiveness on subjective questions that may have\ndifferent responses from different perspectives is still limited by a tendency\ntowards homogeneous reasoning, introduced by the reliance on a single ground\ntruth in supervised fine-tuning and verifiable reward in reinforcement\nlearning. Motivated by the finding that increasing role perspectives\nconsistently improves performance, we propose MultiRole-R1, a\ndiversity-enhanced framework with multiple role perspectives, to improve the\naccuracy and diversity in subjective reasoning tasks. MultiRole-R1 features an\nunsupervised data construction pipeline that generates reasoning chains that\nincorporate diverse role perspectives. We further employ reinforcement learning\nvia Group Relative Policy Optimization (GRPO) with reward shaping, by taking\ndiversity as a reward signal in addition to the verifiable reward. With\nspecially designed reward functions, we successfully promote perspective\ndiversity and lexical diversity, uncovering a positive relation between\nreasoning diversity and accuracy. Our experiment on six benchmarks demonstrates\nMultiRole-R1's effectiveness and generalizability in enhancing both subjective\nand objective reasoning, showcasing the potential of diversity-enhanced\ntraining in LRMs.", "published": "2025-07-27 09:07:42", "link": "http://arxiv.org/abs/2507.20187v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SessionIntentBench: A Multi-task Inter-session Intention-shift Modeling Benchmark for E-commerce Customer Behavior Understanding", "abstract": "Session history is a common way of recording user interacting behaviors\nthroughout a browsing activity with multiple products. For example, if an user\nclicks a product webpage and then leaves, it might because there are certain\nfeatures that don't satisfy the user, which serve as an important indicator of\non-the-spot user preferences. However, all prior works fail to capture and\nmodel customer intention effectively because insufficient information\nexploitation and only apparent information like descriptions and titles are\nused. There is also a lack of data and corresponding benchmark for explicitly\nmodeling intention in E-commerce product purchase sessions. To address these\nissues, we introduce the concept of an intention tree and propose a dataset\ncuration pipeline. Together, we construct a sibling multimodal benchmark,\nSessionIntentBench, that evaluates L(V)LMs' capability on understanding\ninter-session intention shift with four subtasks. With 1,952,177 intention\nentries, 1,132,145 session intention trajectories, and 13,003,664 available\ntasks mined using 10,905 sessions, we provide a scalable way to exploit the\nexisting session data for customer intention understanding. We conduct human\nannotations to collect ground-truth label for a subset of collected data to\nform an evaluation gold set. Extensive experiments on the annotated data\nfurther confirm that current L(V)LMs fail to capture and utilize the intention\nacross the complex session setting. Further analysis show injecting intention\nenhances LLMs' performances.", "published": "2025-07-27 09:04:17", "link": "http://arxiv.org/abs/2507.20185v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SGPO: Self-Generated Preference Optimization based on Self-Improver", "abstract": "Large language models (LLMs), despite their extensive pretraining on diverse\ndatasets, require effective alignment to human preferences for practical and\nreliable deployment. Conventional alignment methods typically employ off-policy\nlearning and depend on human-annotated datasets, which limits their broad\napplicability and introduces distribution shift issues during training. To\naddress these challenges, we propose Self-Generated Preference Optimization\nbased on Self-Improver (SGPO), an innovative alignment framework that leverages\nan on-policy self-improving mechanism. Specifically, the improver refines\nresponses from a policy model to self-generate preference data for direct\npreference optimization (DPO) of the policy model. Here, the improver and\npolicy are unified into a single model, and in order to generate higher-quality\npreference data, this self-improver learns to make incremental yet discernible\nimprovements to the current responses by referencing supervised fine-tuning\noutputs. Experimental results on AlpacaEval 2.0 and Arena-Hard show that the\nproposed SGPO significantly improves performance over DPO and baseline\nself-improving methods without using external preference data.", "published": "2025-07-27 08:55:40", "link": "http://arxiv.org/abs/2507.20181v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Goal Alignment in LLM-Based User Simulators for Conversational AI", "abstract": "User simulators are essential to conversational AI, enabling scalable agent\ndevelopment and evaluation through simulated interactions. While current Large\nLanguage Models (LLMs) have advanced user simulation capabilities, we reveal\nthat they struggle to consistently demonstrate goal-oriented behavior across\nmulti-turn conversations--a critical limitation that compromises their\nreliability in downstream applications. We introduce User Goal State Tracking\n(UGST), a novel framework that tracks user goal progression throughout\nconversations. Leveraging UGST, we present a three-stage methodology for\ndeveloping user simulators that can autonomously track goal progression and\nreason to generate goal-aligned responses. Moreover, we establish comprehensive\nevaluation metrics for measuring goal alignment in user simulators, and\ndemonstrate that our approach yields substantial improvements across two\nbenchmarks (MultiWOZ 2.4 and {\\tau}-Bench). Our contributions address a\ncritical gap in conversational AI and establish UGST as an essential framework\nfor developing goal-aligned user simulators.", "published": "2025-07-27 07:07:12", "link": "http://arxiv.org/abs/2507.20152v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models", "abstract": "Reinforcement learning (RL) plays a crucial role in shaping the behavior of\nlarge language and reasoning models (LLMs/LRMs). However, it often produces\nbrittle and unstable policies, leading to critical failures such as spurious\nreasoning, deceptive alignment, and instruction disobedience that undermine the\ntrustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified\ntheoretical explanation and are typically addressed using ad-hoc heuristics.\nThis paper presents a rigorous mathematical framework for analyzing the\nstability of the mapping from a reward function to the optimal policy. We show\nthat policy brittleness often stems from non-unique optimal actions, a common\noccurrence when multiple valid traces exist in a reasoning task. This\ntheoretical lens provides a unified explanation for a range of seemingly\ndisparate failures, reframing them as rational outcomes of optimizing rewards\nthat may be incomplete or noisy, especially in the presence of action\ndegeneracy. We extend this analysis from the fundamental single-reward setting\nto the more realistic multi-reward RL across diverse domains, showing how\nstability is governed by an \"effective reward\" aggregation mechanism. We also\nprove that entropy regularization restores policy stability at the cost of\nincreased stochasticity. Our framework provides a unified explanation for\nrecent empirical findings on deceptive reasoning, instruction-following\ntrade-offs, and RLHF-induced sophistry, and is further validated through\nperturbation experiments in multi-reward RL. This work advances\npolicy-stability analysis from empirical heuristics towards a principled\ntheory, offering essential insights for designing safer and more trustworthy AI\nsystems.", "published": "2025-07-27 06:56:10", "link": "http://arxiv.org/abs/2507.20150v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Multi-Agent Interactive Question Generation Framework for Long Document Understanding", "abstract": "Document Understanding (DU) in long-contextual scenarios with complex layouts\nremains a significant challenge in vision-language research. Although Large\nVision-Language Models (LVLMs) excel at short-context DU tasks, their\nperformance declines in long-context settings. A key limitation is the scarcity\nof fine-grained training data, particularly for low-resource languages such as\nArabic. Existing state-of-the-art techniques rely heavily on human annotation,\nwhich is costly and inefficient. We propose a fully automated, multi-agent\ninteractive framework to generate long-context questions efficiently. Our\napproach efficiently generates high-quality single- and multi-page questions\nfor extensive English and Arabic documents, covering hundreds of pages across\ndiverse domains. This facilitates the development of LVLMs with enhanced\nlong-context understanding ability. Experimental results in this work have\nshown that our generated English and Arabic questions\n(\\textbf{AraEngLongBench}) are quite challenging to major open- and\nclose-source LVLMs. The code and data proposed in this work can be found in\nhttps://github.com/wangk0b/Multi_Agentic_QA_Long_Doc.git. Sample Question and\nAnswer (QA) pairs and structured system prompts can be found in the Appendix.", "published": "2025-07-27 06:44:53", "link": "http://arxiv.org/abs/2507.20145v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG", "abstract": "This paper presents the technical solution developed by team CRUISE for the\nKDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn\n(CRAG-MM) challenge. The challenge aims to address a critical limitation of\nmodern Vision Language Models (VLMs): their propensity to hallucinate,\nespecially when faced with egocentric imagery, long-tail entities, and complex,\nmulti-hop questions. This issue is particularly problematic in real-world\napplications where users pose fact-seeking queries that demand high factual\naccuracy across diverse modalities. To tackle this, we propose a robust,\nmulti-stage framework that prioritizes factual accuracy and truthfulness over\ncompleteness. Our solution integrates a lightweight query router for\nefficiency, a query-aware retrieval and summarization pipeline, a dual-pathways\ngeneration and a post-hoc verification. This conservative strategy is designed\nto minimize hallucinations, which incur a severe penalty in the competition's\nscoring metric. Our approach achieved 3rd place in Task 1, demonstrating the\neffectiveness of prioritizing answer reliability in complex multi-modal RAG\nsystems. Our implementation is available at\nhttps://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .", "published": "2025-07-27 05:45:45", "link": "http://arxiv.org/abs/2507.20136v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering", "abstract": "Generative AI can now synthesize strikingly realistic images from text, yet\noutput quality remains highly sensitive to how prompts are phrased. Direct\nPreference Optimization (DPO) offers a lightweight, off-policy alternative to\nRL for automatic prompt engineering, but its token-level regularization leaves\nsemantic inconsistency unchecked as prompts that win higher preference scores\ncan still drift away from the user's intended meaning.\n  We introduce Sem-DPO, a variant of DPO that preserves semantic consistency\nyet retains its simplicity and efficiency. Sem-DPO scales the DPO loss by an\nexponential weight proportional to the cosine distance between the original\nprompt and winning candidate in embedding space, softly down-weighting training\nsignals that would otherwise reward semantically mismatched prompts. We provide\nthe first analytical bound on semantic drift for preference-tuned prompt\ngenerators, showing that Sem-DPO keeps learned prompts within a provably\nbounded neighborhood of the original text. On three standard text-to-image\nprompt-optimization benchmarks and two language models, Sem-DPO achieves 8-12%\nhigher CLIP similarity and 5-9% higher human-preference scores (HPSv2.1,\nPickScore) than DPO, while also outperforming state-of-the-art baselines. These\nfindings suggest that strong flat baselines augmented with semantic weighting\nshould become the new standard for prompt-optimization studies and lay the\ngroundwork for broader, semantics-aware preference optimization in language\nmodels.", "published": "2025-07-27 05:20:13", "link": "http://arxiv.org/abs/2507.20133v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AI-Driven Generation of Old English: A Framework for Low-Resource Languages", "abstract": "Preserving ancient languages is essential for understanding humanity's\ncultural and linguistic heritage, yet Old English remains critically\nunder-resourced, limiting its accessibility to modern natural language\nprocessing (NLP) techniques. We present a scalable framework that uses advanced\nlarge language models (LLMs) to generate high-quality Old English texts,\naddressing this gap. Our approach combines parameter-efficient fine-tuning\n(Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a\ndual-agent pipeline that separates the tasks of content generation (in English)\nand translation (into Old English). Evaluation with automated metrics (BLEU,\nMETEOR, and CHRF) shows significant improvements over baseline models, with\nBLEU scores increasing from 26 to over 65 for English-to-Old English\ntranslation. Expert human assessment also confirms high grammatical accuracy\nand stylistic fidelity in the generated texts. Beyond expanding the Old English\ncorpus, our method offers a practical blueprint for revitalizing other\nendangered languages, effectively uniting AI innovation with the goals of\ncultural preservation.", "published": "2025-07-27 03:29:19", "link": "http://arxiv.org/abs/2507.20111v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EcoTransformer: Attention without Multiplication", "abstract": "The Transformer, with its scaled dot-product attention mechanism, has become\na foundational architecture in modern AI. However, this mechanism is\ncomputationally intensive and incurs substantial energy costs. We propose a new\nTransformer architecture EcoTransformer, in which the output context vector is\nconstructed as the convolution of the values using a Laplacian kernel, where\nthe distances are measured by the L1 metric between the queries and keys.\nCompared to dot-product based attention, the new attention score calculation is\nfree of matrix multiplication. It performs on par with, or even surpasses,\nscaled dot-product attention in NLP, bioinformatics, and vision tasks, while\nconsuming significantly less energy.", "published": "2025-07-27 01:32:54", "link": "http://arxiv.org/abs/2507.20096v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T05"], "primary_category": "cs.LG"}
{"title": "When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions", "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in code\ngeneration tasks under idealized conditions, where task descriptions are clear\nand precise. However, in practice, task descriptions frequently exhibit\nambiguity, incompleteness, or internal contradictions. In this paper, we\npresent the first empirical study examining the robustness of state-of-the-art\ncode generation models when faced with such unclear task descriptions. We\nextend the HumanEval and MBPP benchmarks by systematically introducing\nrealistic task descriptions flaws through guided mutation strategies, producing\na dataset that mirrors the messiness of informal developer instructions. We\nevaluate multiple LLMs of varying sizes and architectures, analyzing their\nfunctional correctness and failure modes across task descriptions categories.\nOur findings reveal that even minor imperfections in task description phrasing\ncan cause significant performance degradation, with contradictory task\ndescriptions resulting in numerous logical errors. Moreover, while larger\nmodels tend to be more resilient than smaller variants, they are not immune to\nthe challenges posed by unclear requirements. We further analyze semantic error\npatterns and identify correlations between description clarity, model behavior,\nand error types. Our results underscore the critical need for developing LLMs\nthat are not only powerful but also robust to the imperfections inherent in\nnatural user tasks, highlighting important considerations for improving model\ntraining strategies, designing more realistic evaluation benchmarks, and\nensuring reliable deployment in practical software development environments.", "published": "2025-07-27 23:16:14", "link": "http://arxiv.org/abs/2507.20439v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "FAST: Similarity-based Knowledge Transfer for Efficient Policy Learning", "abstract": "Transfer Learning (TL) offers the potential to accelerate learning by\ntransferring knowledge across tasks. However, it faces critical challenges such\nas negative transfer, domain adaptation and inefficiency in selecting solid\nsource policies. These issues often represent critical problems in evolving\ndomains, i.e. game development, where scenarios transform and agents must\nadapt. The continuous release of new agents is costly and inefficient. In this\nwork we challenge the key issues in TL to improve knowledge transfer, agents\nperformance across tasks and reduce computational costs. The proposed\nmethodology, called FAST - Framework for Adaptive Similarity-based Transfer,\nleverages visual frames and textual descriptions to create a latent\nrepresentation of tasks dynamics, that is exploited to estimate similarity\nbetween environments. The similarity scores guides our method in choosing\ncandidate policies from which transfer abilities to simplify learning of novel\ntasks. Experimental results, over multiple racing tracks, demonstrate that FAST\nachieves competitive final performance compared to learning-from-scratch\nmethods while requiring significantly less training steps. These findings\nhighlight the potential of embedding-driven task similarity estimations.", "published": "2025-07-27 22:21:53", "link": "http://arxiv.org/abs/2507.20433v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models", "abstract": "As Large Language Models (LLMs) increasingly power autonomous agents in\nrobotics and embodied AI, understanding their spatial reasoning capabilities\nbecomes crucial for ensuring reliable real-world deployment. Despite advances\nin language understanding, current research lacks evaluation of how LLMs\nperform spatial navigation without visual cues, a fundamental requirement for\nagents operating with limited sensory information. This paper addresses this\ngap by introducing MazeEval, a benchmark designed to isolate and evaluate pure\nspatial reasoning in LLMs through coordinate-based maze navigation tasks. Our\nmethodology employs a function-calling interface where models navigate mazes of\nvarying complexity ($5\\times 5$ to $15\\times 15$ grids) using only coordinate\nfeedback and distance-to-wall information, excluding visual input to test\nfundamental spatial cognition. We evaluate eight state-of-the-art LLMs across\nidentical mazes in both English and Icelandic to assess cross-linguistic\ntransfer of spatial abilities. Our findings reveal striking disparities: while\nOpenAI's O3 achieves perfect navigation for mazes up to size $30\\times 30$,\nother models exhibit catastrophic failure beyond $9\\times 9$ mazes, with 100%\nof failures attributed to excessive looping behavior where models revisit a\ncell at least 10 times. We document a significant performance degradation in\nIcelandic, with models solving mazes 3-4 sizes smaller than in English,\nsuggesting spatial reasoning in LLMs emerges from linguistic patterns rather\nthan language-agnostic mechanisms. These results have important implications\nfor global deployment of LLM-powered autonomous systems, showing spatial\nintelligence remains fundamentally constrained by training data availability\nand highlighting the need for architectural innovations to achieve reliable\nnavigation across linguistic contexts.", "published": "2025-07-27 19:33:45", "link": "http://arxiv.org/abs/2507.20395v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping", "abstract": "Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing\nvehicles) is crucial for rebalancing the mobility demand and supply in the\nurban environments. We propose in this work a novel multi-agent reinforcement\nlearning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)\nfor dynamic mobility resource allocation. HAG-PS aims to address two important\nresearch challenges regarding multi-agent reinforcement learning for mobility\nresource allocation: (1) how to dynamically and adaptively share the mobility\nresource allocation policy (i.e., how to distribute mobility resources) across\nagents (i.e., representing the regional coordinators of mobility resources);\nand (2) how to achieve memory-efficient parameter sharing in an urban-scale\nsetting. To address the above challenges, we have provided following novel\ndesigns within HAG-PS. To enable dynamic and adaptive parameter sharing, we\nhave designed a hierarchical approach that consists of global and local\ninformation of the mobility resource states (e.g., distribution of mobility\nresources). We have developed an adaptive agent grouping approach in order to\nsplit or merge the groups of agents based on their relative closeness of\nencoded trajectories (i.e., states, actions, and rewards). We have designed a\nlearnable identity (ID) embeddings to enable agent specialization beyond simple\nparameter copy. We have performed extensive experimental studies based on\nreal-world NYC bike sharing data (a total of more than 1.2 million trips), and\ndemonstrated the superior performance (e.g., improved bike availability) of\nHAG-PS compared with other baseline approaches.", "published": "2025-07-27 18:40:04", "link": "http://arxiv.org/abs/2507.20377v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "WBHT: A Generative Attention Architecture for Detecting Black Hole Anomalies in Backbone Networks", "abstract": "We propose the Wasserstein Black Hole Transformer (WBHT) framework for\ndetecting black hole (BH) anomalies in communication networks. These anomalies\ncause packet loss without failure notifications, disrupting connectivity and\nleading to financial losses. WBHT combines generative modeling, sequential\nlearning, and attention mechanisms to improve BH anomaly detection. It\nintegrates a Wasserstein generative adversarial network with attention\nmechanisms for stable training and accurate anomaly identification. The model\nuses long-short-term memory layers to capture long-term dependencies and\nconvolutional layers for local temporal patterns. A latent space encoding\nmechanism helps distinguish abnormal network behavior. Tested on real-world\nnetwork data, WBHT outperforms existing models, achieving significant\nimprovements in F1 score (ranging from 1.65% to 58.76%). Its efficiency and\nability to detect previously undetected anomalies make it a valuable tool for\nproactive network monitoring and security, especially in mission-critical\nnetworks.", "published": "2025-07-27 18:22:28", "link": "http://arxiv.org/abs/2507.20373v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Clustering by Attention: Leveraging Prior Fitted Transformers for Data Partitioning", "abstract": "Clustering is a core task in machine learning with wide-ranging applications\nin data mining and pattern recognition. However, its unsupervised nature makes\nit inherently challenging. Many existing clustering algorithms suffer from\ncritical limitations: they often require careful parameter tuning, exhibit high\ncomputational complexity, lack interpretability, or yield suboptimal accuracy,\nespecially when applied to large-scale datasets. In this paper, we introduce a\nnovel clustering approach based on meta-learning. Our approach eliminates the\nneed for parameter optimization while achieving accuracy that outperforms\nstate-of-the-art clustering techniques. The proposed technique leverages a few\npre-clustered samples to guide the clustering process for the entire dataset in\na single forward pass. Specifically, we employ a pre-trained Prior-Data Fitted\nTransformer Network (PFN) to perform clustering. The algorithm computes\nattention between the pre-clustered samples and the unclustered samples,\nallowing it to infer cluster assignments for the entire dataset based on the\nlearned relation. We theoretically and empirically demonstrate that, given just\na few pre-clustered examples, the model can generalize to accurately cluster\nthe rest of the dataset. Experiments on challenging benchmark datasets show\nthat our approach can successfully cluster well-separated data without any\npre-clustered samples, and significantly improves performance when a few\nclustered samples are provided. We show that our approach is superior to the\nstate-of-the-art techniques. These results highlight the effectiveness and\nscalability of our approach, positioning it as a promising alternative to\nexisting clustering techniques.", "published": "2025-07-27 17:53:19", "link": "http://arxiv.org/abs/2507.20369v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "VLMPlanner: Integrating Visual Language Models with Motion Planning", "abstract": "Integrating large language models (LLMs) into autonomous driving motion\nplanning has recently emerged as a promising direction, offering enhanced\ninterpretability, better controllability, and improved generalization in rare\nand long-tail scenarios. However, existing methods often rely on abstracted\nperception or map-based inputs, missing crucial visual context, such as\nfine-grained road cues, accident aftermath, or unexpected obstacles, which are\nessential for robust decision-making in complex driving environments. To bridge\nthis gap, we propose VLMPlanner, a hybrid framework that combines a\nlearning-based real-time planner with a vision-language model (VLM) capable of\nreasoning over raw images. The VLM processes multi-view images to capture rich,\ndetailed visual information and leverages its common-sense reasoning\ncapabilities to guide the real-time planner in generating robust and safe\ntrajectories. Furthermore, we develop the Context-Adaptive Inference Gate\n(CAI-Gate) mechanism that enables the VLM to mimic human driving behavior by\ndynamically adjusting its inference frequency based on scene complexity,\nthereby achieving an optimal balance between planning performance and\ncomputational efficiency. We evaluate our approach on the large-scale,\nchallenging nuPlan benchmark, with comprehensive experimental results\ndemonstrating superior planning performance in scenarios with intricate road\nconditions and dynamic elements. Code will be available.", "published": "2025-07-27 16:15:21", "link": "http://arxiv.org/abs/2507.20342v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Cultivating Helpful, Personalized, and Creative AI Tutors: A Framework for Pedagogical Alignment using Reinforcement Learning", "abstract": "The integration of large language models (LLMs) into education presents\nunprecedented opportunities for scalable personalized learning. However,\nstandard LLMs often function as generic information providers, lacking\nalignment with fundamental pedagogical principles such as helpfulness,\nstudent-centered personalization, and creativity cultivation. To bridge this\ngap, we propose EduAlign, a novel framework designed to guide LLMs toward\nbecoming more effective and responsible educational assistants. EduAlign\nconsists of two main stages. In the first stage, we curate a dataset of 8k\neducational interactions and annotate them-both manually and\nautomatically-along three key educational dimensions: Helpfulness,\nPersonalization, and Creativity (HPC). These annotations are used to train\nHPC-RM, a multi-dimensional reward model capable of accurately scoring LLM\noutputs according to these educational principles. We further evaluate the\nconsistency and reliability of this reward model. In the second stage, we\nleverage HPC-RM as a reward signal to fine-tune a pre-trained LLM using Group\nRelative Policy Optimization (GRPO) on a set of 2k diverse prompts. We then\nassess the pre- and post-finetuning models on both educational and\ngeneral-domain benchmarks across the three HPC dimensions. Experimental results\ndemonstrate that the fine-tuned model exhibits significantly improved alignment\nwith pedagogical helpfulness, personalization, and creativity stimulation. This\nstudy presents a scalable and effective approach to aligning LLMs with nuanced\nand desirable educational traits, paving the way for the development of more\nengaging, pedagogically aligned AI tutors.", "published": "2025-07-27 15:56:29", "link": "http://arxiv.org/abs/2507.20335v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MIPS: a Multimodal Infinite Polymer Sequence Pre-training Framework for Polymer Property Prediction", "abstract": "Polymers, composed of repeating structural units called monomers, are\nfundamental materials in daily life and industry. Accurate property prediction\nfor polymers is essential for their design, development, and application.\nHowever, existing modeling approaches, which typically represent polymers by\nthe constituent monomers, struggle to capture the whole properties of polymer,\nsince the properties change during the polymerization process. In this study,\nwe propose a Multimodal Infinite Polymer Sequence (MIPS) pre-training\nframework, which represents polymers as infinite sequences of monomers and\nintegrates both topological and spatial information for comprehensive modeling.\nFrom the topological perspective, we generalize message passing mechanism (MPM)\nand graph attention mechanism (GAM) to infinite polymer sequences. For MPM, we\ndemonstrate that applying MPM to infinite polymer sequences is equivalent to\napplying MPM on the induced star-linking graph of monomers. For GAM, we propose\nto further replace global graph attention with localized graph attention (LGA).\nMoreover, we show the robustness of the \"star linking\" strategy through Repeat\nand Shift Invariance Test (RSIT). Despite its robustness, \"star linking\"\nstrategy exhibits limitations when monomer side chains contain ring structures,\na common characteristic of polymers, as it fails the Weisfeiler-Lehman~(WL)\ntest. To overcome this issue, we propose backbone embedding to enhance the\ncapability of MPM and LGA on infinite polymer sequences. From the spatial\nperspective, we extract 3D descriptors of repeating monomers to capture spatial\ninformation. Finally, we design a cross-modal fusion mechanism to unify the\ntopological and spatial information. Experimental validation across eight\ndiverse polymer property prediction tasks reveals that MIPS achieves\nstate-of-the-art performance.", "published": "2025-07-27 15:34:51", "link": "http://arxiv.org/abs/2507.20326v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting", "abstract": "This paper presents the development of an AI powered software platform that\nleverages advanced large language models (LLMs) to transform technology\nscouting and solution discovery in industrial R&D. Traditional approaches to\nsolving complex research and development challenges are often time consuming,\nmanually driven, and heavily dependent on domain specific expertise. These\nmethods typically involve navigating fragmented sources such as patent\nrepositories, commercial product catalogs, and competitor data, leading to\ninefficiencies and incomplete insights. The proposed platform utilizes cutting\nedge LLM capabilities including semantic understanding, contextual reasoning,\nand cross-domain knowledge extraction to interpret problem statements and\nretrieve high-quality, sustainable solutions. The system processes unstructured\npatent texts, such as claims and technical descriptions, and systematically\nextracts potential innovations aligned with the given problem context. These\nsolutions are then algorithmically organized under standardized technical\ncategories and subcategories to ensure clarity and relevance across\ninterdisciplinary domains. In addition to patent analysis, the platform\nintegrates commercial intelligence by identifying validated market solutions\nand active organizations addressing similar challenges. This combined insight\nsourced from both intellectual property and real world product data enables R&D\nteams to assess not only technical novelty but also feasibility, scalability,\nand sustainability. The result is a comprehensive, AI driven scouting engine\nthat reduces manual effort, accelerates innovation cycles, and enhances\ndecision making in complex R&D environments.", "published": "2025-07-27 15:22:39", "link": "http://arxiv.org/abs/2507.20322v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Comparative Study of OpenMP Scheduling Algorithm Selection Strategies", "abstract": "Scientific and data science applications are becoming increasingly complex,\nwith growing computational and memory demands. Modern high performance\ncomputing (HPC) systems provide high parallelism and heterogeneity across\nnodes, devices, and cores. To achieve good performance, effective scheduling\nand load balancing techniques are essential. Parallel programming frameworks\nsuch as OpenMP now offer a variety of advanced scheduling algorithms to support\ndiverse applications and platforms. This creates an instance of the scheduling\nalgorithm selection problem, which involves identifying the most suitable\nalgorithm for a given combination of workload and system characteristics.\n  In this work, we explore learning-based approaches for selecting scheduling\nalgorithms in OpenMP. We propose and evaluate expert-based and reinforcement\nlearning (RL)-based methods, and conduct a detailed performance analysis across\nsix applications and three systems. Our results show that RL methods are\ncapable of learning high-performing scheduling decisions, although they require\nsignificant exploration, with the choice of reward function playing a key role.\nExpert-based methods, in contrast, rely on prior knowledge and involve less\nexploration, though they may not always identify the optimal algorithm for a\nspecific application-system pair. By combining expert knowledge with RL-based\nlearning, we achieve improved performance and greater adaptability.\n  Overall, this work demonstrates that dynamic selection of scheduling\nalgorithms during execution is both viable and beneficial for OpenMP\napplications. The approach can also be extended to MPI-based programs, enabling\noptimization of scheduling decisions across multiple levels of parallelism.", "published": "2025-07-27 15:10:30", "link": "http://arxiv.org/abs/2507.20312v1", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.DC"}
{"title": "TIMEST: Temporal Information Motif Estimator Using Sampling Trees", "abstract": "The mining of pattern subgraphs, known as motifs, is a core task in the field\nof graph mining. Edges in real-world networks often have timestamps, so there\nis a need for temporal motif mining. A temporal motif is a richer structure\nthat imposes timing constraints on the edges of the motif. Temporal motifs have\nbeen used to analyze social networks, financial transactions, and biological\nnetworks.\n  Motif counting in temporal graphs is particularly challenging. A graph with\nmillions of edges can have trillions of temporal motifs, since the same edge\ncan occur with multiple timestamps. There is a combinatorial explosion of\npossibilities, and state-of-the-art algorithms cannot manage motifs with more\nthan four vertices.\n  In this work, we present TIMEST: a general, fast, and accurate estimation\nalgorithm to count temporal motifs of arbitrary sizes in temporal networks. Our\napproach introduces a temporal spanning tree sampler that leverages weighted\nsampling to generate substructures of target temporal motifs. This method\ncarefully takes a subset of temporal constraints of the motif that can be\njointly and efficiently sampled. TIMEST uses randomized estimation techniques\nto obtain accurate estimates of motif counts.\n  We give theoretical guarantees on the running time and approximation\nguarantees of TIMEST. We perform an extensive experimental evaluation and show\nthat TIMEST is both faster and more accurate than previous algorithms. Our CPU\nimplementation exhibits an average speedup of 28x over state-of-the-art GPU\nimplementation of the exact algorithm, and 6x speedup over SOTA approximate\nalgorithms while consistently showcasing less than 5% error in most cases. For\nexample, TIMEST can count the number of instances of a financial fraud temporal\nmotif in four minutes with 0.6% error, while exact methods take more than two\ndays.", "published": "2025-07-27 23:31:55", "link": "http://arxiv.org/abs/2507.20441v1", "categories": ["cs.DB", "cs.DS", "cs.IR"], "primary_category": "cs.DB"}
{"title": "TADT-CSA: Temporal Advantage Decision Transformer with Contrastive State Abstraction for Generative Recommendation", "abstract": "With the rapid advancement of Transformer-based Large Language Models (LLMs),\ngenerative recommendation has shown great potential in enhancing both the\naccuracy and semantic understanding of modern recommender systems. Compared to\nLLMs, the Decision Transformer (DT) is a lightweight generative model applied\nto sequential recommendation tasks. However, DT faces challenges in trajectory\nstitching, often producing suboptimal trajectories. Moreover, due to the high\ndimensionality of user states and the vast state space inherent in\nrecommendation scenarios, DT can incur significant computational costs and\nstruggle to learn effective state representations. To overcome these issues, we\npropose a novel Temporal Advantage Decision Transformer with Contrastive State\nAbstraction (TADT-CSA) model. Specifically, we combine the conventional\nReturn-To-Go (RTG) signal with a novel temporal advantage (TA) signal that\nencourages the model to capture both long-term returns and their sequential\ntrend. Furthermore, we integrate a contrastive state abstraction module into\nthe DT framework to learn more effective and expressive state representations.\nWithin this module, we introduce a TA-conditioned State Vector Quantization\n(TAC-SVQ) strategy, where the TA score guides the state codebooks to\nincorporate contextual token information. Additionally, a reward prediction\nnetwork and a contrastive transition prediction (CTP) network are employed to\nensure the state codebook preserves both the reward information of the current\nstate and the transition information between adjacent states. Empirical results\non both public datasets and an online recommendation system demonstrate the\neffectiveness of the TADT-CSA model and its superiority over baseline methods.", "published": "2025-07-27 15:36:13", "link": "http://arxiv.org/abs/2507.20327v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CTR-Driven Ad Text Generation via Online Feedback Preference Optimization", "abstract": "Advertising text plays a critical role in determining click-through rates\n(CTR) in online advertising. Large Language Models (LLMs) offer significant\nefficiency advantages over manual ad text creation. However, LLM-generated ad\ntexts do not guarantee higher CTR performance compared to human-crafted texts,\nrevealing a gap between generation quality and online performance of ad texts.\nIn this work, we propose a novel ad text generation method which optimizes for\nCTR through preference optimization from online feedback. Our approach adopts\nan innovative two-stage framework: (1) diverse ad text sampling via one-shot\nin-context learning, using retrieval-augmented generation (RAG) to provide\nexemplars with chain-of-thought (CoT) reasoning; (2) CTR-driven preference\noptimization from online feedback, which weighs preference pairs according to\ntheir CTR gains and confidence levels. Through our method, the resulting model\nenables end-to-end generation of high-CTR ad texts. Extensive experiments have\ndemonstrated the effectiveness of our method in both offline and online\nmetrics. Notably, we have applied our method on a large-scale online shopping\nplatform and achieved significant CTR improvements, showcasing its strong\napplicability and effectiveness in advertising systems.", "published": "2025-07-27 11:13:03", "link": "http://arxiv.org/abs/2507.20227v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Practical Multi-Task Learning for Rare Conversions in Ad Tech", "abstract": "We present a Multi-Task Learning (MTL) approach for improving predictions for\nrare (e.g., <1%) conversion events in online advertising. The conversions are\nclassified into \"rare\" or \"frequent\" types based on historical statistics. The\nmodel learns shared representations across all signals while specializing\nthrough separate task towers for each type. The approach was tested and fully\ndeployed to production, demonstrating consistent improvements in both offline\n(0.69% AUC lift) and online KPI performance metric (2% Cost per Action\nreduction).", "published": "2025-07-27 07:28:27", "link": "http://arxiv.org/abs/2507.20161v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Integrating LLM-Derived Multi-Semantic Intent into Graph Model for Session-based Recommendation", "abstract": "Session-based recommendation (SBR) is mainly based on anonymous user\ninteraction sequences to recommend the items that the next user is most likely\nto click. Currently, the most popular and high-performing SBR methods primarily\nleverage graph neural networks (GNNs), which model session sequences as\ngraph-structured data to effectively capture user intent. However, most\nGNNs-based SBR methods primarily focus on modeling the ID sequence information\nof session sequences, while neglecting the rich semantic information embedded\nwithin them. This limitation significantly hampers model's ability to\naccurately infer users' true intention. To address above challenge, this paper\nproposes a novel SBR approach called Integrating LLM-Derived Multi-Semantic\nIntent into Graph Model for Session-based Recommendation (LLM-DMsRec). The\nmethod utilizes a pre-trained GNN model to select the top-k items as candidate\nitem sets and designs prompts along with a large language model (LLM) to infer\nmulti-semantic intents from these candidate items. Specifically, we propose an\nalignment mechanism that effectively integrates the semantic intent inferred by\nthe LLM with the structural intent captured by GNNs. Extensive experiments\nconducted on the Beauty and ML-1M datasets demonstrate that the proposed method\ncan be seamlessly integrated into GNNs framework, significantly enhancing its\nrecommendation performance.", "published": "2025-07-27 06:54:00", "link": "http://arxiv.org/abs/2507.20147v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "BioNeuralNet: A Graph Neural Network based Multi-Omics Network Data Analysis Tool", "abstract": "Multi-omics data offer unprecedented insights into complex biological\nsystems, yet their high dimensionality, sparsity, and intricate interactions\npose significant analytical challenges. Network-based approaches have advanced\nmulti-omics research by effectively capturing biologically relevant\nrelationships among molecular entities. While these methods are powerful for\nrepresenting molecular interactions, there remains a need for tools\nspecifically designed to effectively utilize these network representations\nacross diverse downstream analyses. To fulfill this need, we introduce\nBioNeuralNet, a flexible and modular Python framework tailored for end-to-end\nnetwork-based multi-omics data analysis. BioNeuralNet leverages Graph Neural\nNetworks (GNNs) to learn biologically meaningful low-dimensional\nrepresentations from multi-omics networks, converting these complex molecular\nnetworks into versatile embeddings. BioNeuralNet supports all major stages of\nmulti-omics network analysis, including several network construction\ntechniques, generation of low-dimensional representations, and a broad range of\ndownstream analytical tasks. Its extensive utilities, including diverse GNN\narchitectures, and compatibility with established Python packages (e.g.,\nscikit-learn, PyTorch, NetworkX), enhance usability and facilitate quick\nadoption. BioNeuralNet is an open-source, user-friendly, and extensively\ndocumented framework designed to support flexible and reproducible multi-omics\nnetwork analysis in precision medicine.", "published": "2025-07-27 23:21:04", "link": "http://arxiv.org/abs/2507.20440v1", "categories": ["cs.LG", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "Communication-Efficient Distributed Training for Collaborative Flat Optima Recovery in Deep Learning", "abstract": "We study centralized distributed data parallel training of deep neural\nnetworks (DNNs), aiming to improve the trade-off between communication\nefficiency and model performance of the local gradient methods. To this end, we\nrevisit the flat-minima hypothesis, which suggests that models with better\ngeneralization tend to lie in flatter regions of the loss landscape. We\nintroduce a simple, yet effective, sharpness measure, Inverse Mean Valley, and\ndemonstrate its strong correlation with the generalization gap of DNNs. We\nincorporate an efficient relaxation of this measure into the distributed\ntraining objective as a lightweight regularizer that encourages workers to\ncollaboratively seek wide minima. The regularizer exerts a pushing force that\ncounteracts the consensus step pulling the workers together, giving rise to the\nDistributed Pull-Push Force (DPPF) algorithm. Empirically, we show that DPPF\noutperforms other communication-efficient approaches and achieves better\ngeneralization performance than local gradient methods and synchronous gradient\naveraging, while significantly reducing communication overhead. In addition,\nour loss landscape visualizations confirm the ability of DPPF to locate flatter\nminima. On the theoretical side, we show that DPPF guides workers to span flat\nvalleys, with the final valley width governed by the interplay between push and\npull strengths, and that its pull-push dynamics is self-stabilizing. We further\nprovide generalization guarantees linked to the valley width and prove\nconvergence in the non-convex setting.", "published": "2025-07-27 21:49:49", "link": "http://arxiv.org/abs/2507.20424v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "A General Framework for Estimating Preferences Using Response Time Data", "abstract": "We propose a general methodology for recovering preference parameters from\ndata on choices and response times. Our methods yield estimates with fast\n($1/n$ for $n$ data points) convergence rates when specialized to the popular\nDrift Diffusion Model (DDM), but are broadly applicable to generalizations of\nthe DDM as well as to alternative models of decision making that make use of\nresponse time data. The paper develops an empirical application to an\nexperiment on intertemporal choice, showing that the use of response times\ndelivers predictive accuracy and matters for the estimation of economically\nrelevant parameters.", "published": "2025-07-27 20:13:02", "link": "http://arxiv.org/abs/2507.20403v1", "categories": ["econ.TH", "cs.LG"], "primary_category": "econ.TH"}
{"title": "Bipedalism for Quadrupedal Robots: Versatile Loco-Manipulation through Risk-Adaptive Reinforcement Learning", "abstract": "Loco-manipulation of quadrupedal robots has broadened robotic applications,\nbut using legs as manipulators often compromises locomotion, while mounting\narms complicates the system. To mitigate this issue, we introduce bipedalism\nfor quadrupedal robots, thus freeing the front legs for versatile interactions\nwith the environment. We propose a risk-adaptive distributional Reinforcement\nLearning (RL) framework designed for quadrupedal robots walking on their hind\nlegs, balancing worst-case conservativeness with optimal performance in this\ninherently unstable task. During training, the adaptive risk preference is\ndynamically adjusted based on the uncertainty of the return, measured by the\ncoefficient of variation of the estimated return distribution. Extensive\nexperiments in simulation show our method's superior performance over\nbaselines. Real-world deployment on a Unitree Go2 robot further demonstrates\nthe versatility of our policy, enabling tasks like cart pushing, obstacle\nprobing, and payload transport, while showcasing robustness against challenging\ndynamics and external disturbances.", "published": "2025-07-27 18:51:34", "link": "http://arxiv.org/abs/2507.20382v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Set-based Implicit Likelihood Inference of Galaxy Cluster Mass", "abstract": "We present a set-based machine learning framework that infers posterior\ndistributions of galaxy cluster masses from projected galaxy dynamics. Our\nmodel combines Deep Sets and conditional normalizing flows to incorporate both\npositional and velocity information of member galaxies to predict residual\ncorrections to the $M$-$\\sigma$ relation for improved interpretability. Trained\non the Uchuu-UniverseMachine simulation, our approach significantly reduces\nscatter and provides well-calibrated uncertainties across the full mass range\ncompared to traditional dynamical estimates.", "published": "2025-07-27 18:44:41", "link": "http://arxiv.org/abs/2507.20378v1", "categories": ["cs.LG", "astro-ph.CO"], "primary_category": "cs.LG"}
{"title": "Sequence-Aware Inline Measurement Attribution for Good-Bad Wafer Diagnosis", "abstract": "How can we identify problematic upstream processes when a certain type of\nwafer defect starts appearing at a quality checkpoint? Given the complexity of\nmodern semiconductor manufacturing, which involves thousands of process steps,\ncross-process root cause analysis for wafer defects has been considered highly\nchallenging. This paper proposes a novel framework called Trajectory Shapley\nAttribution (TSA), an extension of Shapley values (SV), a widely used\nattribution algorithm in explainable artificial intelligence research. TSA\novercomes key limitations of standard SV, including its disregard for the\nsequential nature of manufacturing processes and its reliance on an arbitrarily\nchosen reference point. We applied TSA to a good-bad wafer diagnosis task in\nexperimental front-end-of-line processes at the NY CREATES Albany NanoTech fab,\naiming to identify measurement items (serving as proxies for process\nparameters) most relevant to abnormal defect occurrence.", "published": "2025-07-27 17:40:11", "link": "http://arxiv.org/abs/2507.20364v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS Data (Extended Version)", "abstract": "Location-tracking data from the Automatic Identification System, much of\nwhich is publicly available, plays a key role in a range of maritime safety and\nmonitoring applications. However, the data suffers from missing values that\nhamper downstream applications. Imputing the missing values is challenging\nbecause the values of different heterogeneous attributes are updated at diverse\nrates, resulting in the occurrence of multi-scale dependencies among\nattributes. Existing imputation methods that assume similar update rates across\nattributes are unable to capture and exploit such dependencies, limiting their\nimputation accuracy. We propose MH-GIN, a Multi-scale Heterogeneous Graph-based\nImputation Network that aims improve imputation accuracy by capturing\nmulti-scale dependencies. Specifically, MH-GIN first extracts multi-scale\ntemporal features for each attribute while preserving their intrinsic\nheterogeneous characteristics. Then, it constructs a multi-scale heterogeneous\ngraph to explicitly model dependencies between heterogeneous attributes to\nenable more accurate imputation of missing values through graph propagation.\nExperimental results on two real-world datasets find that MH-GIN is capable of\nan average 57% reduction in imputation errors compared to state-of-the-art\nmethods, while maintaining computational efficiency. The source code and\nimplementation details of MH-GIN are publicly available\nhttps://github.com/hyLiu1994/MH-GIN.", "published": "2025-07-27 17:31:47", "link": "http://arxiv.org/abs/2507.20362v1", "categories": ["cs.LG", "cs.DB"], "primary_category": "cs.LG"}
{"title": "Wafer Defect Root Cause Analysis with Partial Trajectory Regression", "abstract": "Identifying upstream processes responsible for wafer defects is challenging\ndue to the combinatorial nature of process flows and the inherent variability\nin processing routes, which arises from factors such as rework operations and\nrandom process waiting times. This paper presents a novel framework for wafer\ndefect root cause analysis, called Partial Trajectory Regression (PTR). The\nproposed framework is carefully designed to address the limitations of\nconventional vector-based regression models, particularly in handling\nvariable-length processing routes that span a large number of heterogeneous\nphysical processes. To compute the attribution score of each process given a\ndetected high defect density on a specific wafer, we propose a new algorithm\nthat compares two counterfactual outcomes derived from partial process\ntrajectories. This is enabled by new representation learning methods, proc2vec\nand route2vec. We demonstrate the effectiveness of the proposed framework using\nreal wafer history data from the NY CREATES fab in Albany.", "published": "2025-07-27 17:08:40", "link": "http://arxiv.org/abs/2507.20357v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "From Observations to Causations: A GNN-based Probabilistic Prediction Framework for Causal Discovery", "abstract": "Causal discovery from observational data is challenging, especially with\nlarge datasets and complex relationships. Traditional methods often struggle\nwith scalability and capturing global structural information. To overcome these\nlimitations, we introduce a novel graph neural network (GNN)-based\nprobabilistic framework that learns a probability distribution over the entire\nspace of causal graphs, unlike methods that output a single deterministic\ngraph. Our framework leverages a GNN that encodes both node and edge attributes\ninto a unified graph representation, enabling the model to learn complex causal\nstructures directly from data. The GNN model is trained on a diverse set of\nsynthetic datasets augmented with statistical and information-theoretic\nmeasures, such as mutual information and conditional entropy, capturing both\nlocal and global data properties. We frame causal discovery as a supervised\nlearning problem, directly predicting the entire graph structure. Our approach\ndemonstrates superior performance, outperforming both traditional and recent\nnon-GNN-based methods, as well as a GNN-based approach, in terms of accuracy\nand scalability on synthetic and real-world datasets without further training.\nThis probabilistic framework significantly improves causal structure learning,\nwith broad implications for decision-making and scientific discovery across\nvarious fields.", "published": "2025-07-27 16:36:45", "link": "http://arxiv.org/abs/2507.20349v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
