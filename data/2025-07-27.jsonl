{"title": "Can Foundation Models Predict Fitness for Duty?", "abstract": "Biometric capture devices have been utilised to estimate a person's alertness\nthrough near-infrared iris images, expanding their use beyond just biometric\nrecognition. However, capturing a substantial number of corresponding images\nrelated to alcohol consumption, drug use, and sleep deprivation to create a\ndataset for training an AI model presents a significant challenge. Typically, a\nlarge quantity of images is required to effectively implement a deep learning\napproach. Currently, training downstream models with a huge number of images\nbased on foundational models provides a real opportunity to enhance this area,\nthanks to the generalisation capabilities of self-supervised models. This work\nexamines the application of deep learning and foundational models in predicting\nfitness for duty, which is defined as the subject condition related to\ndetermining the alertness for work.", "published": "2025-07-27 21:26:12", "link": "http://arxiv.org/abs/2507.20418v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Indian Sign Language Detection for Real-Time Translation using Machine Learning", "abstract": "Gestural language is used by deaf & mute communities to communicate through\nhand gestures & body movements that rely on visual-spatial patterns known as\nsign languages. Sign languages, which rely on visual-spatial patterns of hand\ngestures & body movements, are the primary mode of communication for deaf &\nmute communities worldwide. Effective communication is fundamental to human\ninteraction, yet individuals in these communities often face significant\nbarriers due to a scarcity of skilled interpreters & accessible translation\ntechnologies. This research specifically addresses these challenges within the\nIndian context by focusing on Indian Sign Language (ISL). By leveraging machine\nlearning, this study aims to bridge the critical communication gap for the deaf\n& hard-of-hearing population in India, where technological solutions for ISL\nare less developed compared to other global sign languages. We propose a\nrobust, real-time ISL detection & translation system built upon a Convolutional\nNeural Network (CNN). Our model is trained on a comprehensive ISL dataset &\ndemonstrates exceptional performance, achieving a classification accuracy of\n99.95%. This high precision underscores the model's capability to discern the\nnuanced visual features of different signs. The system's effectiveness is\nrigorously evaluated using key performance metrics, including accuracy, F1\nscore, precision & recall, ensuring its reliability for real-world\napplications. For real-time implementation, the framework integrates MediaPipe\nfor precise hand tracking & motion detection, enabling seamless translation of\ndynamic gestures. This paper provides a detailed account of the model's\narchitecture, the data preprocessing pipeline & the classification methodology.\nThe research elaborates the model architecture, preprocessing & classification\nmethodologies for enhancing communication in deaf & mute communities.", "published": "2025-07-27 21:15:46", "link": "http://arxiv.org/abs/2507.20414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Second Competition on Presentation Attack Detection on ID Card", "abstract": "This work summarises and reports the results of the second Presentation\nAttack Detection competition on ID cards. This new version includes new\nelements compared to the previous one. (1) An automatic evaluation platform was\nenabled for automatic benchmarking; (2) Two tracks were proposed in order to\nevaluate algorithms and datasets, respectively; and (3) A new ID card dataset\nwas shared with Track 1 teams to serve as the baseline dataset for the training\nand optimisation. The Hochschule Darmstadt, Fraunhofer-IGD, and Facephi company\njointly organised this challenge. 20 teams were registered, and 74 submitted\nmodels were evaluated. For Track 1, the \"Dragons\" team reached first place with\nan Average Ranking and Equal Error rate (EER) of AV-Rank of 40.48% and 11.44%\nEER, respectively. For the more challenging approach in Track 2, the \"Incode\"\nteam reached the best results with an AV-Rank of 14.76% and 6.36% EER,\nimproving on the results of the first edition of 74.30% and 21.87% EER,\nrespectively. These results suggest that PAD on ID cards is improving, but it\nis still a challenging problem related to the number of images, especially of\nbona fide images.", "published": "2025-07-27 20:18:52", "link": "http://arxiv.org/abs/2507.20404v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VESPA: Towards un(Human)supervised Open-World Pointcloud Labeling for Autonomous Driving", "abstract": "Data collection for autonomous driving is rapidly accelerating, but manual\nannotation, especially for 3D labels, remains a major bottleneck due to its\nhigh cost and labor intensity. Autolabeling has emerged as a scalable\nalternative, allowing the generation of labels for point clouds with minimal\nhuman intervention. While LiDAR-based autolabeling methods leverage geometric\ninformation, they struggle with inherent limitations of lidar data, such as\nsparsity, occlusions, and incomplete object observations. Furthermore, these\nmethods typically operate in a class-agnostic manner, offering limited semantic\ngranularity. To address these challenges, we introduce VESPA, a multimodal\nautolabeling pipeline that fuses the geometric precision of LiDAR with the\nsemantic richness of camera images. Our approach leverages vision-language\nmodels (VLMs) to enable open-vocabulary object labeling and to refine detection\nquality directly in the point cloud domain. VESPA supports the discovery of\nnovel categories and produces high-quality 3D pseudolabels without requiring\nground-truth annotations or HD maps. On Nuscenes dataset, VESPA achieves an AP\nof 52.95% for object discovery and up to 46.54% for multiclass object\ndetection, demonstrating strong performance in scalable 3D scene understanding.\nCode will be available upon acceptance.", "published": "2025-07-27 19:39:29", "link": "http://arxiv.org/abs/2507.20397v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Solving Scene Understanding for Autonomous Navigation in Unstructured Environments", "abstract": "Autonomous vehicles are the next revolution in the automobile industry and\nthey are expected to revolutionize the future of transportation. Understanding\nthe scenario in which the autonomous vehicle will operate is critical for its\ncompetent functioning. Deep Learning has played a massive role in the progress\nthat has been made till date. Semantic Segmentation, the process of annotating\nevery pixel of an image with an object class, is one crucial part of this scene\ncomprehension using Deep Learning. It is especially useful in Autonomous\nDriving Research as it requires comprehension of drivable and non-drivable\nareas, roadside objects and the like. In this paper semantic segmentation has\nbeen performed on the Indian Driving Dataset which has been recently compiled\non the urban and rural roads of Bengaluru and Hyderabad. This dataset is more\nchallenging compared to other datasets like Cityscapes, since it is based on\nunstructured driving environments. It has a four level hierarchy and in this\npaper segmentation has been performed on the first level. Five different models\nhave been trained and their performance has been compared using the Mean\nIntersection over Union. These are UNET, UNET+RESNET50, DeepLabsV3, PSPNet and\nSegNet. The highest MIOU of 0.6496 has been achieved. The paper discusses the\ndataset, exploratory data analysis, preparation, implementation of the five\nmodels and studies the performance and compares the results achieved in the\nprocess.", "published": "2025-07-27 19:11:21", "link": "http://arxiv.org/abs/2507.20389v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ModalFormer: Multimodal Transformer for Low-Light Image Enhancement", "abstract": "Low-light image enhancement (LLIE) is a fundamental yet challenging task due\nto the presence of noise, loss of detail, and poor contrast in images captured\nunder insufficient lighting conditions. Recent methods often rely solely on\npixel-level transformations of RGB images, neglecting the rich contextual\ninformation available from multiple visual modalities. In this paper, we\npresent ModalFormer, the first large-scale multimodal framework for LLIE that\nfully exploits nine auxiliary modalities to achieve state-of-the-art\nperformance. Our model comprises two main components: a Cross-modal Transformer\n(CM-T) designed to restore corrupted images while seamlessly integrating\nmultimodal information, and multiple auxiliary subnetworks dedicated to\nmultimodal feature reconstruction. Central to the CM-T is our novel Cross-modal\nMulti-headed Self-Attention mechanism (CM-MSA), which effectively fuses RGB\ndata with modality-specific features--including deep feature embeddings,\nsegmentation information, geometric cues, and color information--to generate\ninformation-rich hybrid attention maps. Extensive experiments on multiple\nbenchmark datasets demonstrate ModalFormer's state-of-the-art performance in\nLLIE. Pre-trained models and results are made available at\nhttps://github.com/albrateanu/ModalFormer.", "published": "2025-07-27 19:07:22", "link": "http://arxiv.org/abs/2507.20388v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation", "abstract": "Generating high-quality cartoon animations multimodal control is challenging\ndue to the complexity of non-human characters, stylistically diverse motions\nand fine-grained emotions. There is a huge domain gap between real-world videos\nand cartoon animation, as cartoon animation is usually abstract and has\nexaggerated motion. Meanwhile, public multimodal cartoon data are extremely\nscarce due to the difficulty of large-scale automatic annotation processes\ncompared with real-life scenarios. To bridge this gap, We propose the\nMagicAnime dataset, a large-scale, hierarchically annotated, and multimodal\ndataset designed to support multiple video generation tasks, along with the\nbenchmarks it includes. Containing 400k video clips for image-to-video\ngeneration, 50k pairs of video clips and keypoints for whole-body annotation,\n12k pairs of video clips for video-to-video face animation, and 2.9k pairs of\nvideo and audio clips for audio-driven face animation. Meanwhile, we also build\na set of multi-modal cartoon animation benchmarks, called MagicAnime-Bench, to\nsupport the comparisons of different methods in the tasks above. Comprehensive\nexperiments on four tasks, including video-driven face animation, audio-driven\nface animation, image-to-video animation, and pose-driven character animation,\nvalidate its effectiveness in supporting high-fidelity, fine-grained, and\ncontrollable generation.", "published": "2025-07-27 17:53:00", "link": "http://arxiv.org/abs/2507.20368v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Generative Pre-training for Subjective Tasks: A Diffusion Transformer-Based Framework for Facial Beauty Prediction", "abstract": "Facial Beauty Prediction (FBP) is a challenging computer vision task due to\nits subjective nature and the subtle, holistic features that influence human\nperception. Prevailing methods, often based on deep convolutional networks or\nstandard Vision Transformers pre-trained on generic object classification\n(e.g., ImageNet), struggle to learn feature representations that are truly\naligned with high-level aesthetic assessment. In this paper, we propose a novel\ntwo-stage framework that leverages the power of generative models to create a\nsuperior, domain-specific feature extractor. In the first stage, we pre-train a\nDiffusion Transformer on a large-scale, unlabeled facial dataset (FFHQ) through\na self-supervised denoising task. This process forces the model to learn the\nfundamental data distribution of human faces, capturing nuanced details and\nstructural priors essential for aesthetic evaluation. In the second stage, the\npre-trained and frozen encoder of our Diffusion Transformer is used as a\nbackbone feature extractor, with only a lightweight regression head being\nfine-tuned on the target FBP dataset (FBP5500). Our method, termed Diff-FBP,\nsets a new state-of-the-art on the FBP5500 benchmark, achieving a Pearson\nCorrelation Coefficient (PCC) of 0.932, significantly outperforming prior art\nbased on general-purpose pre-training. Extensive ablation studies validate that\nour generative pre-training strategy is the key contributor to this performance\nleap, creating feature representations that are more semantically potent for\nsubjective visual tasks.", "published": "2025-07-27 17:33:51", "link": "http://arxiv.org/abs/2507.20363v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Detecting Visual Information Manipulation Attacks in Augmented Reality: A Multimodal Semantic Reasoning Approach", "abstract": "The virtual content in augmented reality (AR) can introduce misleading or\nharmful information, leading to semantic misunderstandings or user errors. In\nthis work, we focus on visual information manipulation (VIM) attacks in AR\nwhere virtual content changes the meaning of real-world scenes in subtle but\nimpactful ways. We introduce a taxonomy that categorizes these attacks into\nthree formats: character, phrase, and pattern manipulation, and three purposes:\ninformation replacement, information obfuscation, and extra wrong information.\nBased on the taxonomy, we construct a dataset, AR-VIM. It consists of 452\nraw-AR video pairs spanning 202 different scenes, each simulating a real-world\nAR scenario. To detect such attacks, we propose a multimodal semantic reasoning\nframework, VIM-Sense. It combines the language and visual understanding\ncapabilities of vision-language models (VLMs) with optical character\nrecognition (OCR)-based textual analysis. VIM-Sense achieves an attack\ndetection accuracy of 88.94% on AR-VIM, consistently outperforming vision-only\nand text-only baselines. The system reaches an average attack detection latency\nof 7.07 seconds in a simulated video processing framework and 7.17 seconds in a\nreal-world evaluation conducted on a mobile Android AR application.", "published": "2025-07-27 17:04:50", "link": "http://arxiv.org/abs/2507.20356v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PIVOTS: Aligning unseen Structures using Preoperative to Intraoperative Volume-To-Surface Registration for Liver Navigation", "abstract": "Non-rigid registration is essential for Augmented Reality guided laparoscopic\nliver surgery by fusing preoperative information, such as tumor location and\nvascular structures, into the limited intraoperative view, thereby enhancing\nsurgical navigation. A prerequisite is the accurate prediction of\nintraoperative liver deformation which remains highly challenging due to\nfactors such as large deformation caused by pneumoperitoneum, respiration and\ntool interaction as well as noisy intraoperative data, and limited field of\nview due to occlusion and constrained camera movement. To address these\nchallenges, we introduce PIVOTS, a Preoperative to Intraoperative\nVOlume-To-Surface registration neural network that directly takes point clouds\nas input for deformation prediction. The geometric feature extraction encoder\nallows multi-resolution feature extraction, and the decoder, comprising novel\ndeformation aware cross attention modules, enables pre- and intraoperative\ninformation interaction and accurate multi-level displacement prediction. We\ntrain the neural network on synthetic data simulated from a biomechanical\nsimulation pipeline and validate its performance on both synthetic and real\ndatasets. Results demonstrate superior registration performance of our method\ncompared to baseline methods, exhibiting strong robustness against high amounts\nof noise, large deformation, and various levels of intraoperative visibility.\nWe publish the training and test sets as evaluation benchmarks and call for a\nfair comparison of liver registration methods with volume-to-surface data. Code\nand datasets are available here https://github.com/pengliu-nct/PIVOTS.", "published": "2025-07-27 16:01:26", "link": "http://arxiv.org/abs/2507.20337v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Gallery to Wrist: Realistic 3D Bracelet Insertion in Videos", "abstract": "Inserting 3D objects into videos is a longstanding challenge in computer\ngraphics with applications in augmented reality, virtual try-on, and video\ncomposition. Achieving both temporal consistency, or realistic lighting remains\ndifficult, particularly in dynamic scenarios with complex object motion,\nperspective changes, and varying illumination. While 2D diffusion models have\nshown promise for producing photorealistic edits, they often struggle with\nmaintaining temporal coherence across frames. Conversely, traditional 3D\nrendering methods excel in spatial and temporal consistency but fall short in\nachieving photorealistic lighting. In this work, we propose a hybrid object\ninsertion pipeline that combines the strengths of both paradigms. Specifically,\nwe focus on inserting bracelets into dynamic wrist scenes, leveraging the high\ntemporal consistency of 3D Gaussian Splatting (3DGS) for initial rendering and\nrefining the results using a 2D diffusion-based enhancement model to ensure\nrealistic lighting interactions. Our method introduces a shading-driven\npipeline that separates intrinsic object properties (albedo, shading,\nreflectance) and refines both shading and sRGB images for photorealism. To\nmaintain temporal coherence, we optimize the 3DGS model with multi-frame\nweighted adjustments. This is the first approach to synergize 3D rendering and\n2D diffusion for video object insertion, offering a robust solution for\nrealistic and consistent video editing. Project Page:\nhttps://cjeen.github.io/BraceletPaper/", "published": "2025-07-27 15:49:07", "link": "http://arxiv.org/abs/2507.20331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SWIFT: A General Sensitive Weight Identification Framework for Fast Sensor-Transfer Pansharpening", "abstract": "Pansharpening aims to fuse high-resolution panchromatic (PAN) images with\nlow-resolution multispectral (LRMS) images to generate high-resolution\nmultispectral (HRMS) images. Although deep learning-based methods have achieved\npromising performance, they generally suffer from severe performance\ndegradation when applied to data from unseen sensors. Adapting these models\nthrough full-scale retraining or designing more complex architectures is often\nprohibitively expensive and impractical for real-world deployment. To address\nthis critical challenge, we propose a fast and general-purpose framework for\ncross-sensor adaptation, SWIFT (Sensitive Weight Identification for Fast\nTransfer). Specifically, SWIFT employs an unsupervised sampling strategy based\non data manifold structures to balance sample selection while mitigating the\nbias of traditional Farthest Point Sampling, efficiently selecting only 3\\% of\nthe most informative samples from the target domain. This subset is then used\nto probe a source-domain pre-trained model by analyzing the gradient behavior\nof its parameters, allowing for the quick identification and subsequent update\nof only the weight subset most sensitive to the domain shift. As a\nplug-and-play framework, SWIFT can be applied to various existing pansharpening\nmodels. Extensive experiments demonstrate that SWIFT reduces the adaptation\ntime from hours to approximately one minute on a single NVIDIA RTX 4090 GPU.\nThe adapted models not only substantially outperform direct-transfer baselines\nbut also achieve performance competitive with, and in some cases superior to,\nfull retraining, establishing a new state-of-the-art on cross-sensor\npansharpening tasks for the WorldView-2 and QuickBird datasets.", "published": "2025-07-27 15:06:05", "link": "http://arxiv.org/abs/2507.20311v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fine-structure Preserved Real-world Image Super-resolution via Transfer VAE Training", "abstract": "Impressive results on real-world image super-resolution (Real-ISR) have been\nachieved by employing pre-trained stable diffusion (SD) models. However, one\ncritical issue of such methods lies in their poor reconstruction of image fine\nstructures, such as small characters and textures, due to the aggressive\nresolution reduction of the VAE (eg., 8$\\times$ downsampling) in the SD model.\nOne solution is to employ a VAE with a lower downsampling rate for diffusion;\nhowever, adapting its latent features with the pre-trained UNet while\nmitigating the increased computational cost poses new challenges. To address\nthese issues, we propose a Transfer VAE Training (TVT) strategy to transfer the\n8$\\times$ downsampled VAE into a 4$\\times$ one while adapting to the\npre-trained UNet. Specifically, we first train a 4$\\times$ decoder based on the\noutput features of the original VAE encoder, then train a 4$\\times$ encoder\nwhile keeping the newly trained decoder fixed. Such a TVT strategy aligns the\nnew encoder-decoder pair with the original VAE latent space while enhancing\nimage fine details. Additionally, we introduce a compact VAE and\ncompute-efficient UNet by optimizing their network architectures, reducing the\ncomputational cost while capturing high-resolution fine-scale features.\nExperimental results demonstrate that our TVT method significantly improves\nfine-structure preservation, which is often compromised by other SD-based\nmethods, while requiring fewer FLOPs than state-of-the-art one-step diffusion\nmodels. The official code can be found at https://github.com/Joyies/TVT.", "published": "2025-07-27 14:11:29", "link": "http://arxiv.org/abs/2507.20291v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "T$^\\text{3}$SVFND: Towards an Evolving Fake News Detector for Emergencies with Test-time Training on Short Video Platforms", "abstract": "The existing methods for fake news videos detection may not be generalized,\nbecause there is a distribution shift between short video news of different\nevents, and the performance of such techniques greatly drops if news records\nare coming from emergencies. We propose a new fake news videos detection\nframework (T$^3$SVFND) using Test-Time Training (TTT) to alleviate this\nlimitation, enhancing the robustness of fake news videos detection.\nSpecifically, we design a self-supervised auxiliary task based on Mask Language\nModeling (MLM) that masks a certain percentage of words in text and predicts\nthese masked words by combining contextual information from different\nmodalities (audio and video). In the test-time training phase, the model adapts\nto the distribution of test data through auxiliary tasks. Extensive experiments\non the public benchmark demonstrate the effectiveness of the proposed model,\nespecially for the detection of emergency news.", "published": "2025-07-27 14:04:00", "link": "http://arxiv.org/abs/2507.20286v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Controllable Feature Whitening for Hyperparameter-Free Bias Mitigation", "abstract": "As the use of artificial intelligence rapidly increases, the development of\ntrustworthy artificial intelligence has become important. However, recent\nstudies have shown that deep neural networks are susceptible to learn spurious\ncorrelations present in datasets. To improve the reliability, we propose a\nsimple yet effective framework called controllable feature whitening. We\nquantify the linear correlation between the target and bias features by the\ncovariance matrix, and eliminate it through the whitening module. Our results\nsystemically demonstrate that removing the linear correlations between features\nfed into the last linear classifier significantly mitigates the bias, while\navoiding the need to model intractable higher-order dependencies. A particular\nadvantage of the proposed method is that it does not require regularization\nterms or adversarial learning, which often leads to unstable optimization in\npractice. Furthermore, we show that two fairness criteria, demographic parity\nand equalized odds, can be effectively handled by whitening with the\nre-weighted covariance matrix. Consequently, our method controls the trade-off\nbetween the utility and fairness of algorithms by adjusting the weighting\ncoefficient. Finally, we validate that our method outperforms existing\napproaches on four benchmark datasets: Corrupted CIFAR-10, Biased FFHQ,\nWaterBirds, and Celeb-A.", "published": "2025-07-27 14:01:30", "link": "http://arxiv.org/abs/2507.20284v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "L-MCAT: Unpaired Multimodal Transformer with Contrastive Attention for Label-Efficient Satellite Image Classification", "abstract": "We propose the Lightweight Multimodal Contrastive Attention Transformer\n(L-MCAT), a novel transformer-based framework for label-efficient remote\nsensing image classification using unpaired multimodal satellite data. L-MCAT\nintroduces two core innovations: (1) Modality-Spectral Adapters (MSA) that\ncompress high-dimensional sensor inputs into a unified embedding space, and (2)\nUnpaired Multimodal Attention Alignment (U-MAA), a contrastive self-supervised\nmechanism integrated into the attention layers to align heterogeneous\nmodalities without pixel-level correspondence or labels. L-MCAT achieves 95.4%\noverall accuracy on the SEN12MS dataset using only 20 labels per class,\noutperforming state-of-the-art baselines while using 47x fewer parameters and\n23x fewer FLOPs than MCTrans. It maintains over 92% accuracy even under 50%\nspatial misalignment, demonstrating robustness for real-world deployment. The\nmodel trains end-to-end in under 5 hours on a single consumer GPU.", "published": "2025-07-27 13:06:32", "link": "http://arxiv.org/abs/2507.20259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MIRepNet: A Pipeline and Foundation Model for EEG-Based Motor Imagery Classification", "abstract": "Brain-computer interfaces (BCIs) enable direct communication between the\nbrain and external devices. Recent EEG foundation models aim to learn\ngeneralized representations across diverse BCI paradigms. However, these\napproaches overlook fundamental paradigm-specific neurophysiological\ndistinctions, limiting their generalization ability. Importantly, in practical\nBCI deployments, the specific paradigm such as motor imagery (MI) for stroke\nrehabilitation or assistive robotics, is generally determined prior to data\nacquisition. This paper proposes MIRepNet, the first EEG foundation model\ntailored for the MI paradigm. MIRepNet comprises a high-quality EEG\npreprocessing pipeline incorporating a neurophysiologically-informed channel\ntemplate, adaptable to EEG headsets with arbitrary electrode configurations.\nFurthermore, we introduce a hybrid pretraining strategy that combines\nself-supervised masked token reconstruction and supervised MI classification,\nfacilitating rapid adaptation and accurate decoding on novel downstream MI\ntasks with fewer than 30 trials per class. Extensive evaluations across five\npublic MI datasets demonstrated that MIRepNet consistently achieved\nstate-of-the-art performance, significantly outperforming both specialized and\ngeneralized EEG models. Our code will be available on\nGitHub\\footnote{https://github.com/staraink/MIRepNet}.", "published": "2025-07-27 12:54:42", "link": "http://arxiv.org/abs/2507.20254v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnimalClue: Recognizing Animals by their Traces", "abstract": "Wildlife observation plays an important role in biodiversity conservation,\nnecessitating robust methodologies for monitoring wildlife populations and\ninterspecies interactions. Recent advances in computer vision have\nsignificantly contributed to automating fundamental wildlife observation tasks,\nsuch as animal detection and species identification. However, accurately\nidentifying species from indirect evidence like footprints and feces remains\nrelatively underexplored, despite its importance in contributing to wildlife\nmonitoring. To bridge this gap, we introduce AnimalClue, the first large-scale\ndataset for species identification from images of indirect evidence. Our\ndataset consists of 159,605 bounding boxes encompassing five categories of\nindirect clues: footprints, feces, eggs, bones, and feathers. It covers 968\nspecies, 200 families, and 65 orders. Each image is annotated with\nspecies-level labels, bounding boxes or segmentation masks, and fine-grained\ntrait information, including activity patterns and habitat preferences. Unlike\nexisting datasets primarily focused on direct visual features (e.g., animal\nappearances), AnimalClue presents unique challenges for classification,\ndetection, and instance segmentation tasks due to the need for recognizing more\ndetailed and subtle visual features. In our experiments, we extensively\nevaluate representative vision models and identify key challenges in animal\nidentification from their traces. Our dataset and code are available at\nhttps://dahlian00.github.io/AnimalCluePage/", "published": "2025-07-27 11:48:03", "link": "http://arxiv.org/abs/2507.20240v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decomposing Densification in Gaussian Splatting for Faster 3D Scene Reconstruction", "abstract": "3D Gaussian Splatting (GS) has emerged as a powerful representation for\nhigh-quality scene reconstruction, offering compelling rendering quality.\nHowever, the training process of GS often suffers from slow convergence due to\ninefficient densification and suboptimal spatial distribution of Gaussian\nprimitives. In this work, we present a comprehensive analysis of the split and\nclone operations during the densification phase, revealing their distinct roles\nin balancing detail preservation and computational efficiency. Building upon\nthis analysis, we propose a global-to-local densification strategy, which\nfacilitates more efficient growth of Gaussians across the scene space,\npromoting both global coverage and local refinement. To cooperate with the\nproposed densification strategy and promote sufficient diffusion of Gaussian\nprimitives in space, we introduce an energy-guided coarse-to-fine\nmulti-resolution training framework, which gradually increases resolution based\non energy density in 2D images. Additionally, we dynamically prune unnecessary\nGaussian primitives to speed up the training. Extensive experiments on\nMipNeRF-360, Deep Blending, and Tanks & Temples datasets demonstrate that our\napproach significantly accelerates training,achieving over 2x speedup with\nfewer Gaussian primitives and superior reconstruction performance.", "published": "2025-07-27 11:47:20", "link": "http://arxiv.org/abs/2507.20239v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Multi-Agent System for Information Extraction from the Chemical Literature", "abstract": "To fully expedite AI-powered chemical research, high-quality chemical\ndatabases are the cornerstone. Automatic extraction of chemical information\nfrom the literature is essential for constructing reaction databases, but it is\ncurrently limited by the multimodality and style variability of chemical\ninformation. In this work, we developed a multimodal large language model\n(MLLM)-based multi-agent system for automatic chemical information extraction.\nWe used the MLLM's strong reasoning capability to understand the structure of\ncomplex chemical graphics, decompose the extraction task into sub-tasks and\ncoordinate a set of specialized agents to solve them. Our system achieved an F1\nscore of 80.8% on a benchmark dataset of complex chemical reaction graphics\nfrom the literature, surpassing the previous state-of-the-art model (F1 score:\n35.6%) by a significant margin. Additionally, it demonstrated consistent\nimprovements in key sub-tasks, including molecular image recognition, reaction\nimage parsing, named entity recognition and text-based reaction extraction.\nThis work is a critical step toward automated chemical information extraction\ninto structured datasets, which will be a strong promoter of AI-driven chemical\nresearch.", "published": "2025-07-27 11:16:57", "link": "http://arxiv.org/abs/2507.20230v1", "categories": ["cs.AI", "cs.CV", "cs.MA"], "primary_category": "cs.AI"}
{"title": "MambaMap: Online Vectorized HD Map Construction using State Space Model", "abstract": "High-definition (HD) maps are essential for autonomous driving, as they\nprovide precise road information for downstream tasks. Recent advances\nhighlight the potential of temporal modeling in addressing challenges like\nocclusions and extended perception range. However, existing methods either fail\nto fully exploit temporal information or incur substantial computational\noverhead in handling extended sequences. To tackle these challenges, we propose\nMambaMap, a novel framework that efficiently fuses long-range temporal features\nin the state space to construct online vectorized HD maps. Specifically,\nMambaMap incorporates a memory bank to store and utilize information from\nhistorical frames, dynamically updating BEV features and instance queries to\nimprove robustness against noise and occlusions. Moreover, we introduce a\ngating mechanism in the state space, selectively integrating dependencies of\nmap elements in high computational efficiency. In addition, we design\ninnovative multi-directional and spatial-temporal scanning strategies to\nenhance feature extraction at both BEV and instance levels. These strategies\nsignificantly boost the prediction accuracy of our approach while ensuring\nrobust temporal consistency. Extensive experiments on the nuScenes and\nArgoverse2 datasets demonstrate that our proposed MambaMap approach outperforms\nstate-of-the-art methods across various splits and perception ranges. Source\ncode will be available at https://github.com/ZiziAmy/MambaMap.", "published": "2025-07-27 11:09:27", "link": "http://arxiv.org/abs/2507.20224v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Attention Stacked Ensemble for Lung Cancer Detection in CT Scans", "abstract": "In this work, we address the challenge of binary lung nodule classification\n(benign vs malignant) using CT images by proposing a multi-level attention\nstacked ensemble of deep neural networks. Three pretrained backbones -\nEfficientNet V2 S, MobileViT XXS, and DenseNet201 - are each adapted with a\ncustom classification head tailored to 96 x 96 pixel inputs. A two-stage\nattention mechanism learns both model-wise and class-wise importance scores\nfrom concatenated logits, and a lightweight meta-learner refines the final\nprediction. To mitigate class imbalance and improve generalization, we employ\ndynamic focal loss with empirically calculated class weights, MixUp\naugmentation during training, and test-time augmentation at inference.\nExperiments on the LIDC-IDRI dataset demonstrate exceptional performance,\nachieving 98.09 accuracy and 0.9961 AUC, representing a 35 percent reduction in\nerror rate compared to state-of-the-art methods. The model exhibits balanced\nperformance across sensitivity (98.73) and specificity (98.96), with\nparticularly strong results on challenging cases where radiologist disagreement\nwas high. Statistical significance testing confirms the robustness of these\nimprovements across multiple experimental runs. Our approach can serve as a\nrobust, automated aid for radiologists in lung cancer screening.", "published": "2025-07-27 11:03:07", "link": "http://arxiv.org/abs/2507.20221v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Product-Congruence Games: A Unified Impartial-Game Framework for RSA ($\u03c6$-MuM) and AES (poly-MuM)", "abstract": "RSA exponent reduction and AES S-box inversion share a hidden commonality:\nboth are governed by the same impartial combinatorial principle, which we call\na Product-Congruence Game (PCG). A Product-Congruence Game tracks play via the\nmodular or finite-field product of heap values, providing a single invariant\nthat unifies the algebraic cores of these two ubiquitous symmetric and\nasymmetric cryptosystems. We instantiate this framework with two companion\ngames. First, $\\phi$-MuM, in which a left-associated \"multi-secret\" RSA\nexponent chain compresses into the game of Multiplicative Modular Nim,\nPCG($k,\\{1\\}$), where $k = ord_N(g)$. The losing predicate then factorizes via\nthe Chinese remainder theorem, mirroring RSA's structure. Second, poly-MuM, our\nmodel for finite-field inversion such as the AES S-box. For poly-MuM we prove\nthe single-hole property inside its threshold region, implying that the\nSprague-Grundy values are multiplicative under disjunctive sums in that region.\nBeyond these instances, we establish four structural theorems for a general\nProduct-Congruence Game PCG($m,R$): (i) single-heap repair above the modulus,\n(ii) ultimate period $m$ per coordinate, (iii) exact and asymptotic losing\ndensities, and (iv) confinement of optimal play to a finite indeterminacy\nregion. An operation-alignment collapse principle explains why some variants\ndegenerate to a single aggregate while MuM, $\\phi$-MuM and poly-MuM retain rich\nlocal structure. All ingredients (multiplicative orders, the Chinese remainder\ntheorem, finite fields) are classical; the contribution is the unified\naggregation-compression viewpoint that embeds both RSA and AES inside one\nimpartial-game framework, together with the structural and collapse theorems.", "published": "2025-07-27 00:29:13", "link": "http://arxiv.org/abs/2507.20087v1", "categories": ["cs.DM", "cs.CR", "cs.IT", "math.IT", "91A46 (primary), 11A07, 94A60, 05A99", "G.2.1; E.3"], "primary_category": "cs.DM"}
{"title": "Joint Fiber and Free Space Optical Infrastructure Planning for Hybrid Integrated Access and Backhaul Networks", "abstract": "Integrated access and backhaul (IAB) is one of the promising techniques for\n5G networks and beyond (6G), in which the same node/hardware is used to provide\nboth backhaul and cellular services in a multi-hop architecture. Due to the\nsensitivity of the backhaul links with high rate/reliability demands, proper\nnetwork planning is needed to ensure the IAB network performs with the desired\nperformance levels. In this paper, we study the effect of infrastructure\nplanning and optimization on the coverage of IAB networks. We concentrate on\nthe cases where the fiber connectivity to the nodes is constrained due to cost.\nThereby, we study the performance gains and energy efficiency in the presence\nof free-space optical (FSO) communication links. Our results indicate hybrid\nfiber/FSO deployments offer substantial cost savings compared to fully fibered\nnetworks, suggesting a beneficial trade-off for strategic link deployment while\nimproving the service coverage probability. As we show, with proper network\nplanning, the service coverage, energy efficiency, and cost efficiency can be\nimproved.", "published": "2025-07-27 17:51:25", "link": "http://arxiv.org/abs/2507.20367v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Ensemble Average Analysis of Non-Adaptive Group Testing with Sparse Pooling Graphs", "abstract": "A combinatorial analysis of the false alarm (FA) and misdetection (MD)\nprobabilities of non-adaptive group testing with sparse pooling graphs is\ndeveloped. The analysis targets the combinatorial orthogonal matching pursuit\nand definite defective detection algorithms in the noiseless, non-quantitative\nsetting. The approach follows an ensemble average perspective, where average\nFA/MD probabilities are computed for pooling graph ensembles with prescribed\ndegree distributions. The accuracy of the analysis is demonstrated through\nnumerical examples, showing that the proposed technique can be used to\ncharacterize the performance of non-adaptive group testing schemes based on\nsparse pooling graphs.", "published": "2025-07-27 13:56:07", "link": "http://arxiv.org/abs/2507.20281v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Stochastic Channel Models for Satellite Mega-Constellations", "abstract": "A general satellite channel model is proposed for communications between a\nrapidly moving low Earth orbit (LEO) satellite in a mega-constellation and a\nstationary user on Earth. The channel uses a non-homogeneous binomial point\nprocess (NBPP) for modelling the satellite positions, marked with an\nascending/descending binary random variable for modelling the satellite\ndirections. Using the marked NBPP, we derive the probability distributions of\npower gain, propagation delay, and Doppler shift, resulting in a stochastic\nsignal propagation model for the mega-constellation geometry in isolation of\nother effects. This forms the basis for our proposed channel model as a\nrandomly time-varying channel. The scattering function of this channel is\nderived to characterise how the received power is spread in the delay-Doppler\ndomain. Global channel parameters such as path loss and channel spread are\nanalysed in terms of the scattering function. The channel statistics and the\nglobal channel parameters closely match realistic orbit simulations of the\nStarlink constellation.", "published": "2025-07-27 12:56:14", "link": "http://arxiv.org/abs/2507.20255v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sparse Regression Codes for Secret Key Agreement: Achieving Strong Secrecy and Near-Optimal Rates for Gaussian Sources", "abstract": "Secret key agreement from correlated physical layer observations is a\ncornerstone of information-theoretic security. This paper proposes and\nrigorously analyzes a complete, constructive protocol for secret key agreement\nfrom Gaussian sources using Sparse Regression Codes (SPARCs). Our protocol\nsystematically leverages the known optimality of SPARCs for both\nrate-distortion and Wyner-Ziv (WZ) coding, facilitated by their inherent nested\nstructure. The primary contribution of this work is a comprehensive end-to-end\nanalysis demonstrating that the proposed scheme achieves near-optimal secret\nkey rates with strong secrecy guarantees, as quantified by a vanishing\nvariational distance. We explicitly characterize the gap to the optimal rate,\nrevealing a fundamental trade-off between the key rate and the required public\ncommunication overhead, which is governed by a tunable quantization parameter.\nFurthermore, we uncover a non-trivial constrained optimization for this\nparameter, showing that practical constraints on the SPARC code parameters\ninduce a peak in the achievable secret key rate. This work establishes SPARCs\nas a viable and theoretically sound framework for secure key generation,\nproviding a compelling low-complexity alternative to existing schemes and\noffering new insights into the practical design of such protocols.", "published": "2025-07-27 07:21:19", "link": "http://arxiv.org/abs/2507.20157v1", "categories": ["cs.IT", "math.IT", "math.PR", "stat.AP"], "primary_category": "cs.IT"}
{"title": "An Optimal Transport-Based Method for Computing LM Rate and Its Convergence Analysis", "abstract": "The mismatch capacity characterizes the highest information rate of the\nchannel under a prescribed decoding metric and serves as a critical performance\nindicator in numerous practical communication scenarios. Compared to the\ncommonly used Generalized Mutual Information (GMI), the Lower bound on the\nMismatch capacity (LM rate) generally provides a tighter lower bound on the\nmismatch capacity. However, the efficient computation of the LM rate is\nsignificantly more challenging than that of the GMI, particularly as the size\nof the channel input alphabet increases. This growth in complexity renders\nstandard numerical methods (e.g., interior point methods) computationally\nintensive and, in some cases, impractical. In this work, we reformulate the\ncomputation of the LM rate as a special instance of the optimal transport (OT)\nproblem with an additional constraint. Building on this formulation, we develop\na novel numerical algorithm based on the Sinkhorn algorithm, which is well\nknown for its efficiency in solving entropy regularized optimization problems.\nWe further provide the convergence analysis of the proposed algorithm,\nrevealing that the algorithm has a sub-linear convergence rate. Numerical\nexperiments demonstrate the feasibility and efficiency of the proposed\nalgorithm for the computation of the LM rate.", "published": "2025-07-27 04:56:44", "link": "http://arxiv.org/abs/2507.20129v1", "categories": ["cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "cs.IT"}
{"title": "Rotatable RIS Assisted Physical Layer Multicasting", "abstract": "Reconfigurable Intelligent Surfaces (RIS) dynamically control signal\npropagation to enhance wireless communications. This paper presents a novel\nframework for rotatable RIS assisted physical-layer multicast systems, aiming\nto maximize the sum of minimum multicast rates via joint optimization of base\nstation beamforming, RIS phase shifts, and orientation. Unlike unicast or\nnon-rotatable setups, the rotatable RIS adapts orientation to align signals\nwith user groups, improving fairness and rates for weak users. An alternating\noptimization approach combines convex optimization for beamforming/phase shifts\nwith exhaustive search and particle swarm optimization (PSO) for orientation.\nMajorization-Minimization-based algorithms solve subproblems iteratively.\nSimulation results show the framework achieves 24.1% rate improvement via\nexhaustive search and 20.0% via PSO over the non-rotatable RIS baseline, with\nPSO performance close to the exhaustive search upper bound, highlighting the\nbenefits of physical-layer multicast and orientation optimization.", "published": "2025-07-27 03:33:03", "link": "http://arxiv.org/abs/2507.20113v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Graded Transformers: A Symbolic-Geometric Approach to Structured Learning", "abstract": "We introduce the Graded Transformer framework, a novel class of sequence\nmodels that embeds algebraic inductive biases through grading transformations\non vector spaces. Extending the theory of Graded Neural Networks (GNNs), we\npropose two architectures: the Linearly Graded Transformer (LGT) and the\nExponentially Graded Transformer (EGT). These models apply parameterized\nscaling operators-governed by fixed or learnable grading tuples and, for EGT,\nexponential factors to infuse hierarchical structure into attention and\nrepresentation layers, enhancing efficiency for structured data.\n  We derive rigorous theoretical guarantees, including universal approximation\ntheorems for continuous and Sobolev functions, reduced sample complexity via\neffective VC dimension bounds, Lipschitz continuity of graded operations, and\nrobustness to adversarial perturbations. A graded loss function ensures\ngradient stability and alignment with domain priors during optimization. By\ntreating grades as differentiable parameters, the framework enables adaptive\nfeature prioritization, overcoming limitations of fixed grades in prior work.\n  The Graded Transformer holds transformative potential for hierarchical\nlearning and neurosymbolic reasoning, with applications spanning algebraic\ngeometry (e.g., moduli spaces and zeta functions), physics (e.g., multiscale\nsimulations), natural language processing (e.g., syntactic parsing), biological\nsequence analysis (e.g., variant prediction), and emerging areas like graph\nneural networks and financial modeling. This work advances structured deep\nlearning by fusing geometric and algebraic principles with attention\nmechanisms, offering a mathematically grounded alternative to data-driven\nmodels and paving the way for interpretable, efficient systems in complex\ndomains.", "published": "2025-07-27 02:34:08", "link": "http://arxiv.org/abs/2507.20108v1", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MLC-Agent: Cognitive Model based on Memory-Learning Collaboration in LLM Empowered Agent Simulation Environment", "abstract": "Many real-world systems, such as transportation systems, ecological systems,\nand Internet systems, are complex systems. As an important tool for studying\ncomplex systems, computational experiments can map them into artificial society\nmodels that are computable and reproducible within computers, thereby providing\ndigital and computational methods for quantitative analysis. In current\nresearch, the construction of individual agent models often ignores the\nlong-term accumulative effect of memory mechanisms in the development process\nof agents, which to some extent causes the constructed models to deviate from\nthe real characteristics of real-world systems. To address this challenge, this\npaper proposes an individual agent model based on a memory-learning\ncollaboration mechanism, which implements hierarchical modeling of the memory\nmechanism and a multi-indicator evaluation mechanism. Through hierarchical\nmodeling of the individual memory repository, the group memory repository, and\nthe memory buffer pool, memory can be effectively managed, and knowledge\nsharing and dissemination between individuals and groups can be promoted. At\nthe same time, the multi-indicator evaluation mechanism enables dynamic\nevaluation of memory information, allowing dynamic updates of information in\nthe memory set and promoting collaborative decision-making between memory and\nlearning. Experimental results show that, compared with existing memory\nmodeling methods, the agents constructed by the proposed model demonstrate\nbetter decision-making quality and adaptability within the system. This\nverifies the effectiveness of the individual agent model based on the\nmemory-learning collaboration mechanism proposed in this paper in improving the\nquality of individual-level modeling in artificial society modeling and\nachieving anthropomorphic characteristics.", "published": "2025-07-27 10:42:00", "link": "http://arxiv.org/abs/2507.20215v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Local Prompt Adaptation for Style-Consistent Multi-Object Generation in Diffusion Models", "abstract": "Diffusion models have become a powerful backbone for text-to-image\ngeneration, enabling users to synthesize high-quality visuals from natural\nlanguage prompts. However, they often struggle with complex prompts involving\nmultiple objects and global or local style specifications. In such cases, the\ngenerated scenes tend to lack style uniformity and spatial coherence, limiting\ntheir utility in creative and controllable content generation. In this paper,\nwe propose a simple, training-free architectural method called Local Prompt\nAdaptation (LPA). Our method decomposes the prompt into content and style\ntokens, and injects them selectively into the U-Net's attention layers at\ndifferent stages. By conditioning object tokens early and style tokens later in\nthe generation process, LPA enhances both layout control and stylistic\nconsistency. We evaluate our method on a custom benchmark of 50 style-rich\nprompts across five categories and compare against strong baselines including\nComposer, MultiDiffusion, Attend-and-Excite, LoRA, and SDXL. Our approach\noutperforms prior work on both CLIP score and style consistency metrics,\noffering a new direction for controllable, expressive diffusion-based\ngeneration.", "published": "2025-07-27 01:32:13", "link": "http://arxiv.org/abs/2507.20094v1", "categories": ["cs.CV", "cs.AI", "cs.MA"], "primary_category": "cs.CV"}
{"title": "Subset selection for matrices in spectral norm", "abstract": "We address the subset selection problem for matrices, where the goal is to\nselect a subset of $k$ columns from a \"short-and-fat\" matrix $X \\in\n\\mathbb{R}^{m \\times n}$, such that the pseudoinverse of the sampled submatrix\nhas as small spectral or Frobenius norm as possible. For the NP-hard spectral\nnorm variant, we propose a new deterministic approximation algorithm. Our\nmethod refines the potential-based framework of spectral sparsification by\nspecializing it to a single barrier function. This key modification enables\ndirect, unweighted column selection, bypassing the intermediate weighting step\nrequired by previous approaches. It also allows for a novel adaptive update\nstrategy for the barrier. This approach yields a new, explicit bound on the\napproximation quality that improves upon existing guarantees in key parameter\nregimes, without increasing the asymptotic computational complexity.\nFurthermore, numerical experiments demonstrate that the proposed method\nconsistently outperforms its direct competitors. A complete C++ implementation\nis provided to support our findings and facilitate future research.", "published": "2025-07-27 22:36:37", "link": "http://arxiv.org/abs/2507.20435v1", "categories": ["math.NA", "cs.NA", "65F55, 90C27, 15A18, 62K05"], "primary_category": "math.NA"}
{"title": "A global Lipschitz stability perspective for understanding approximate approaches in Bayesian sequential learning", "abstract": "We establish a general, non-asymptotic error analysis framework for\nunderstanding the effects of incremental approximations made by practical\napproaches for Bayesian sequential learning (BSL) on their long-term inference\nperformance. Our setting covers inverse problems, state estimation, and\nparameter-state estimation. In these settings, we bound the difference-termed\nthe learning error-between the unknown true posterior and the approximate\nposterior computed by these approaches, using three widely used distribution\nmetrics: total variation, Hellinger, and Wasserstein distances. This framework\nbuilds on our establishment of the global Lipschitz stability of the posterior\nwith respect to the prior across these settings. To the best of our knowledge,\nthis is the first work to establish such global Lipschitz stability under the\nHellinger and Wasserstein distances and the first general error analysis\nframework for approximate BSL methods.\n  Our framework offers two sets of upper bounds on the learning error. The\nfirst set demonstrates the stability of general approximate BSL methods with\nrespect to the incremental approximation process, while the second set is\nestimable in many practical scenarios.\n  Furthermore, as an initial step toward understanding the phenomenon of\nlearning error decay, which is sometimes observed, we identify sufficient\nconditions under which data assimilation leads to learning error reduction.", "published": "2025-07-27 18:48:09", "link": "http://arxiv.org/abs/2507.20379v1", "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH"], "primary_category": "math.ST"}
{"title": "Computational Advantages of Multi-Grade Deep Learning: Convergence Analysis and Performance Insights", "abstract": "Multi-grade deep learning (MGDL) has been shown to significantly outperform\nthe standard single-grade deep learning (SGDL) across various applications.\nThis work aims to investigate the computational advantages of MGDL focusing on\nits performance in image regression, denoising, and deblurring tasks, and\ncomparing it to SGDL. We establish convergence results for the gradient descent\n(GD) method applied to these models and provide mathematical insights into\nMGDL's improved performance. In particular, we demonstrate that MGDL is more\nrobust to the choice of learning rate under GD than SGDL. Furthermore, we\nanalyze the eigenvalue distributions of the Jacobian matrices associated with\nthe iterative schemes arising from the GD iterations, offering an explanation\nfor MGDL's enhanced training stability.", "published": "2025-07-27 16:43:29", "link": "http://arxiv.org/abs/2507.20351v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Efficient numerical methods for the uncertain Boltzmann equation based on a hybrid solver", "abstract": "In this work, we propose and compare several approaches to solve the\nBoltzmann equation with uncertain parameters, including multi-level Monte Carlo\nand multi-fidelity methods that employ an asymptotic-preserving-hybrid (APH)\nscheme (Filbet and Rey, 2015) for the deterministic Boltzmann model. By\nconstructing a hierarchy of models from finer to coarser meshes in phase space\nfor the APH scheme and adopting variance reduction techniques, the MLMC method\nis able to allocate computational resources across different hierarchies\nquasi-optimally. On the other hand, in the bi-fidelity method we choose the APH\nscheme for the Boltzmann equation as the high-fidelity solver, and a finite\nvolume scheme for the compressible Euler system as the low-fidelity model.\nSince both methods are non-intrusive, they can preserve the physical properties\nof the deterministic solver. Extensive numerical experiments demonstrate that\nour APH-based MLMC and multi-fidelity methods are significantly faster than\nstandard approaches, while maintaining accuracy. We also provide practical\nguidelines for selection between APH-based MLMC and multi-fidelity approaches,\nbased on solution smoothness and computational resource availability.", "published": "2025-07-27 15:15:05", "link": "http://arxiv.org/abs/2507.20316v1", "categories": ["math.NA", "cs.NA", "35R60, 35Q20, 65C05"], "primary_category": "math.NA"}
{"title": "A Hybrid Particle-Continuum Method for Simulating Fast Ice via Subgrid Iceberg Interaction", "abstract": "A significant fraction (4%-13%) of Antarctic sea ice remains stationary as\nlandfast sea-ice (\"fast ice\"), typically anchored by grounded icebergs. Current\nglobal climate models do not represent fast-ice formation due to iceberg\ngrounding, as iceberg-sea-ice interaction mostly occurs at subgrid scales. We\npropose a novel subgrid-scale coupling mechanism between Lagrangian iceberg\nparticles and an Eulerian sea-ice continuum model. This hybrid\nparticle-continuum approach integrates feedback from icebergs into the sea-ice\nmomentum equation via a Green's function, a Stokeslet, representing the drag\nexerted by a point force on the viscous-plastic medium. The coupled system,\nincluding the Stokeslet induced drag, is discretized using a finite-element\nmethod with piecewise linear basis functions. The approach assumes that\nindividual icebergs have diameters smaller than the grid spacing. The presented\nfinite-element discretization is compatible with existing unstructured-mesh\nocean model frameworks such as FESOM and ICON, ensuring practical applicability\nin Earth system modeling. This work provides and analyzes, for the first time,\na stable numerical framework to capture the effects of individual subgrid-scale\nicebergs on sea-ice dynamics. We derive an a-priori stability estimate bounding\na functional of the sea-ice system and show that the momentum equation\nincluding the subgrid iceberg-sea-ice drag remains stable. Numerical test cases\ndemonstrate the capability of the approach to capture fast-ice formation due to\nsubgrid iceberg grounding on coarse horizontal grids.", "published": "2025-07-27 14:52:56", "link": "http://arxiv.org/abs/2507.20306v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Spectral element methods for boundary-value problems of functional differential equations", "abstract": "We prove convergence of the spectral element method for piecewise polynomial\ncollocation applied to periodic boundary value problems (BVP) for functional\n  differential equations with possibly state-dependent delays. If the exact\nsolution of the BVP has an analytic extension then the collocation solution\nconverges geometrically. This means that the accuracy of the approximation is\nof order $\\mathrm{e}^{-\\eta m}$ for some $\\eta>0$ depending on the size of the\nmesh, when using polynomials of degree $m$. If the exact solution has a finite\norder of continuous differentiability then the collocation solution converges\nwith this order.\n  For functional differential equations with state-dependent delays the\nright-hand side cannot be expected to be differentiable with respect to its\narguments in the classical sense, and analyticity of the solution does not\nnecessarily follow from analyticity of the coefficients in the right-hand side.\nThus, our geometric convergence statement assumes analyticity of the solution,\nrather than of the right-hand side.", "published": "2025-07-27 13:24:10", "link": "http://arxiv.org/abs/2507.20266v1", "categories": ["math.NA", "cs.NA", "65L03, 65L10, 65L20, 65L60"], "primary_category": "math.NA"}
{"title": "Imaging a moving point source in R^3 from the time of arrival at sparse observation points", "abstract": "In this paper, we introduce a novel numerical method for reconstructing the\ntrajectory within three-dimensional space, where both the emission moment and\nspatial location of the point source are unknown. Our approach relies solely on\nmeasuring the time of arrival at five or seven properly chosen observation\npoints. By utilizing the distinctive geometric configuration of these five or\nseven observation points, we establish the uniqueness of the trajectory and\nemission moment of the point source through rigorous mathematical proofs.\nMoreover, we analyze the stability of our proposed method. The effectiveness of\nthe method is also verified by numerical experiments.", "published": "2025-07-27 10:01:12", "link": "http://arxiv.org/abs/2507.20204v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "L\u00e9vy-Driven Option Pricing without a Riskless Asset", "abstract": "We extend the Lindquist-Rachev (LR) option-pricing framework--which values\nderivatives in markets lacking a traded risk-free bond--by introducing common\nLevy jump dynamics across two risky assets. The resulting endogenous \"shadow\"\nshort rate replaces the usual risk-free yield and governs discounting and\nrisk-neutral drifts. We focus on two widely used pure-jump specifications: the\nNormal Inverse Gaussian (NIG) process and the Carr-Geman-Madan-Yor (CGMY)\ntempered-stable process. Using Ito-Levy calculus we derive an LR partial\nintegro-differential equation (LR-PIDE) and obtain European option values\nthrough characteristic-function methods implemented with the Fast Fourier\nTransform (FFT) and Fourier-cosine (COS) algorithms. Calibrations to S and P\n500 index options show that both jump models materially reduce pricing errors\nand fit the observed volatility smile far better than the Black-Scholes\nbenchmark; CGMY delivers the largest improvement. We also extract time-varying\nshadow short rates from paired asset data and show that sharp declines coincide\nwith liquidity-stress episodes, highlighting risk signals not visible in\nTreasury yields. The framework links jump risk, relative asset pricing, and\nfunding conditions in a tractable form for practitioners.", "published": "2025-07-27 16:01:37", "link": "http://arxiv.org/abs/2507.20338v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "A Theory of $\u03b8$-Expectations", "abstract": "The canonical theory of stochastic calculus under ambiguity, founded on\nsub-additivity, is insensitive to non-convex uncertainty structures, leading to\nan identifiability impasse. This paper develops a mathematical framework for an\nidentifiable calculus sensitive to non-convex geometry. We introduce the\n$\\theta$-BSDE, a class of backward stochastic differential equations where the\ndriver is determined by a pointwise maximization over a primitive, possibly\nnon-convex, uncertainty set. The system's tractability is predicated not on\nconvexity, but on a global analytic hypothesis: the existence of a unique and\nglobally Lipschitz maximizer map for the driver function. Under this\nhypothesis, which carves out a tractable class of models, we establish\nwell-posedness via a fixed-point argument. For a distinct, geometrically\nregular class of models, we prove a result of independent interest: under\nnon-degeneracy conditions from Malliavin calculus, the maximizer is unique\nalong any solution path, ensuring the model's internal consistency. We clarify\nthe fundamental logical gap between this pathwise property and the global\nregularity required by our existence proof. The resulting valuation operator\ndefines a dynamically consistent expectation, and we establish its connection\nto fully nonlinear PDEs via a Feynman-Kac formula.", "published": "2025-07-27 16:56:01", "link": "http://arxiv.org/abs/2507.20353v1", "categories": ["math.PR", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "math.PR"}
{"title": "The Blessing and Curse of Dimensionality in Safety Alignment", "abstract": "The focus on safety alignment in large language models (LLMs) has increased\nsignificantly due to their widespread adoption across different domains. The\nscale of LLMs play a contributing role in their success, and the growth in\nparameter count follows larger hidden dimensions. In this paper, we hypothesize\nthat while the increase in dimensions has been a key advantage, it may lead to\nemergent problems as well. These problems emerge as the linear structures in\nthe activation space can be exploited, in the form of activation engineering,\nto circumvent its safety alignment. Through detailed visualizations of linear\nsubspaces associated with different concepts, such as safety, across various\nmodel scales, we show that the curse of high-dimensional representations\nuniquely impacts LLMs. Further substantiating our claim, we demonstrate that\nprojecting the representations of the model onto a lower dimensional subspace\ncan preserve sufficient information for alignment while avoiding those linear\nstructures. Empirical results confirm that such dimensional reduction\nsignificantly reduces susceptibility to jailbreaking through representation\nengineering. Building on our empirical validations, we provide theoretical\ninsights into these linear jailbreaking methods relative to a model's hidden\ndimensions. Broadly speaking, our work posits that the high dimensions of a\nmodel's internal representations can be both a blessing and a curse in safety\nalignment.", "published": "2025-07-27 15:51:23", "link": "http://arxiv.org/abs/2507.20333v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence", "abstract": "Uncertainty quantification is an important prerequisite for the deployment of\ndeep learning models in safety-critical areas. Yet, this hinges on the\nuncertainty estimates being useful to the extent the prediction intervals are\nwell-calibrated and sharp. In the absence of inherent uncertainty estimates\n(e.g. pretrained models predicting only point estimates), popular approaches\nthat operate post-hoc include Laplace's method and split conformal prediction\n(split-CP). However, Laplace's method can be miscalibrated when the model is\nmisspecified and split-CP requires sample splitting, and thus comes at the\nexpense of statistical efficiency. In this work, we construct prediction\nintervals for neural network regressors post-hoc without held-out data. This is\nachieved by approximating the full conformal prediction method (full-CP).\nWhilst full-CP nominally requires retraining the model for every test point and\ncandidate label, we propose to train just once and locally perturb model\nparameters using Gauss-Newton influence to approximate the effect of\nretraining. Coupled with linearization of the network, we express the absolute\nresidual nonconformity score as a piecewise linear function of the candidate\nlabel allowing for an efficient procedure that avoids the exhaustive search\nover the output space. On standard regression benchmarks and bounding box\nlocalization, we show the resulting prediction intervals are locally-adaptive\nand often tighter than those of split-CP.", "published": "2025-07-27 13:34:32", "link": "http://arxiv.org/abs/2507.20272v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Data-Efficient Prediction-Powered Calibration via Cross-Validation", "abstract": "Calibration data are necessary to formally quantify the uncertainty of the\ndecisions produced by an existing artificial intelligence (AI) model. To\novercome the common issue of scarce calibration data, a promising approach is\nto employ synthetic labels produced by a (generally different) predictive\nmodel. However, fine-tuning the label-generating predictor on the inference\ntask of interest, as well as estimating the residual bias of the synthetic\nlabels, demand additional data, potentially exacerbating the calibration data\nscarcity problem. This paper introduces a novel approach that efficiently\nutilizes limited calibration data to simultaneously fine-tune a predictor and\nestimate the bias of the synthetic labels. The proposed method yields\nprediction sets with rigorous coverage guarantees for AI-generated decisions.\nExperimental results on an indoor localization problem validate the\neffectiveness and performance gains of our solution.", "published": "2025-07-27 13:31:02", "link": "http://arxiv.org/abs/2507.20268v1", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Automated Deep Segmentation and Spatial-Statistics Approach for Post-Blast Rock Fragmentation Assessment", "abstract": "We introduce an end-to-end pipeline that leverages a fine-tuned YOLO12l-seg\nmodel -- trained on over 500 annotated post-blast images -- to deliver\nreal-time instance segmentation (Box mAP@0.5 ~ 0.769, Mask mAP@0.5 ~ 0.800 at ~\n15 FPS). High-fidelity masks are converted into normalized 3D coordinates, from\nwhich we extract multi-metric spatial descriptors: principal component\ndirections, kernel density hotspots, size-depth regression, and Delaunay edge\nstatistics. We present four representative examples to illustrate key\nfragmentation patterns. Experimental results confirm the framework's accuracy,\nrobustness to small-object crowding, and feasibility for rapid, automated\nblast-effect assessment in field conditions.", "published": "2025-07-27 04:25:29", "link": "http://arxiv.org/abs/2507.20126v1", "categories": ["cs.CV", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Online Learning with Probing for Sequential User-Centric Selection", "abstract": "We formalize sequential decision-making with information acquisition as the\nprobing-augmented user-centric selection (PUCS) framework, where a learner\nfirst probes a subset of arms to obtain side information on resources and\nrewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such\nas ridesharing, wireless scheduling, and content recommendation, in which both\nresources and payoffs are initially unknown and probing is costly. For the\noffline setting with known distributions, we present a greedy probing algorithm\nwith a constant-factor approximation guarantee $\\zeta = (e-1)/(2e-1)$. For the\nonline setting with unknown distributions, we introduce OLPA, a stochastic\ncombinatorial bandit algorithm that achieves a regret bound\n$\\mathcal{O}(\\sqrt{T} + \\ln^{2} T)$. We also prove a lower bound\n$\\Omega(\\sqrt{T})$, showing that the upper bound is tight up to logarithmic\nfactors. Experiments on real-world data demonstrate the effectiveness of our\nsolutions.", "published": "2025-07-27 03:32:51", "link": "http://arxiv.org/abs/2507.20112v1", "categories": ["cs.LG", "cs.AI", "cs.DS", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Meta Fusion: A Unified Framework For Multimodality Fusion with Mutual Learning", "abstract": "Developing effective multimodal data fusion strategies has become\nincreasingly essential for improving the predictive power of statistical\nmachine learning methods across a wide range of applications, from autonomous\ndriving to medical diagnosis. Traditional fusion methods, including early,\nintermediate, and late fusion, integrate data at different stages, each\noffering distinct advantages and limitations. In this paper, we introduce Meta\nFusion, a flexible and principled framework that unifies these existing\nstrategies as special cases. Motivated by deep mutual learning and ensemble\nlearning, Meta Fusion constructs a cohort of models based on various\ncombinations of latent representations across modalities, and further boosts\npredictive performance through soft information sharing within the cohort. Our\napproach is model-agnostic in learning the latent representations, allowing it\nto flexibly adapt to the unique characteristics of each modality.\nTheoretically, our soft information sharing mechanism reduces the\ngeneralization error. Empirically, Meta Fusion consistently outperforms\nconventional fusion strategies in extensive simulation studies. We further\nvalidate our approach on real-world applications, including Alzheimer's disease\ndetection and neural decoding.", "published": "2025-07-27 00:50:29", "link": "http://arxiv.org/abs/2507.20089v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Feed-anywhere ANN (I) Steady Discrete $\\to$ Diffusing on Graph Hidden States", "abstract": "We propose a novel framework for learning hidden graph structures from data\nusing geometric analysis and nonlinear dynamics. Our approach: (1) Defines\ndiscrete Sobolev spaces on graphs for scalar/vector fields, establishing key\nfunctional properties; (2) Introduces gauge-equivalent nonlinear Schr\\\"odinger\nand Landau--Lifshitz dynamics with provable stable stationary solutions\nsmoothly dependent on input data and graph weights; (3) Develops a stochastic\ngradient algorithm over graph moduli spaces with sparsity regularization.\nTheoretically, we guarantee: topological correctness (homology recovery),\nmetric convergence (Gromov--Hausdorff), and efficient search space utilization.\nOur dynamics-based model achieves stronger generalization bounds than standard\nneural networks, with complexity dependent on the data manifold's topology.", "published": "2025-07-27 00:35:15", "link": "http://arxiv.org/abs/2507.20088v1", "categories": ["cs.LG", "math-ph", "math.MP", "math.OC", "stat.ML", "G.1.6; G.1.7; G.2.2"], "primary_category": "cs.LG"}
{"title": "Two Views, One Truth: Spectral and Self-Supervised Features Fusion for Robust Speech Deepfake Detection", "abstract": "Recent advances in synthetic speech have made audio deepfakes increasingly\nrealistic, posing significant security risks. Existing detection methods that\nrely on a single modality, either raw waveform embeddings or spectral based\nfeatures, are vulnerable to non spoof disturbances and often overfit to known\nforgery algorithms, resulting in poor generalization to unseen attacks. To\naddress these shortcomings, we investigate hybrid fusion frameworks that\nintegrate self supervised learning (SSL) based representations with handcrafted\nspectral descriptors (MFCC , LFCC, CQCC). By aligning and combining\ncomplementary information across modalities, these fusion approaches capture\nsubtle artifacts that single feature approaches typically overlook. We explore\nseveral fusion strategies, including simple concatenation, cross attention,\nmutual cross attention, and a learnable gating mechanism, to optimally blend\nSSL features with fine grained spectral cues. We evaluate our approach on four\nchallenging public benchmarks and report generalization performance. All fusion\nvariants consistently outperform an SSL only baseline, with the cross attention\nstrategy achieving the best generalization with a 38% relative reduction in\nequal error rate (EER). These results confirm that joint modeling of waveform\nand spectral views produces robust, domain agnostic representations for audio\ndeepfake detection.", "published": "2025-07-27 21:22:27", "link": "http://arxiv.org/abs/2507.20417v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Self-Improvement for Audio Large Language Model using Unlabeled Speech", "abstract": "Recent audio LLMs have emerged rapidly, demonstrating strong generalization\nacross various speech tasks. However, given the inherent complexity of speech\nsignals, these models inevitably suffer from performance degradation in\nspecific target domains. To address this, we focus on enhancing audio LLMs in\ntarget domains without any labeled data. We propose a self-improvement method\ncalled SI-SDA, leveraging the information embedded in large-model decoding to\nevaluate the quality of generated pseudo labels and then perform domain\nadaptation based on reinforcement learning optimization. Experimental results\nshow that our method consistently and significantly improves audio LLM\nperformance, outperforming existing baselines in WER and BLEU across multiple\npublic datasets of automatic speech recognition (ASR), spoken\nquestion-answering (SQA), and speech-to-text translation (S2TT). Furthermore,\nour approach exhibits high data efficiency, underscoring its potential for\nreal-world deployment.", "published": "2025-07-27 08:16:23", "link": "http://arxiv.org/abs/2507.20169v1", "categories": ["cs.SD", "eess.AS", "I.2.7; H.5.5"], "primary_category": "cs.SD"}
{"title": "Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech", "abstract": "The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has\nenabled high-fidelity voice synthesis from minimal audio cues, raising\nsignificant privacy and ethical concerns. Despite the threats to voice privacy,\nresearch to selectively remove the knowledge to replicate unwanted individual\nvoices from pre-trained model parameters has not been explored. In this paper,\nwe address the new challenge of speaker identity unlearning for ZS-TTS systems.\nTo meet this goal, we propose the first machine unlearning frameworks for\nZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the\nmodel forgets designated speaker identities while retaining its ability to\ngenerate accurate speech for other speakers. Our proposed methods incorporate\nrandomness to prevent consistent replication of forget speakers' voices,\nassuring unlearned identities remain untraceable. Additionally, we propose a\nnew evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses\nthe model's ability to disregard prompts associated with forgotten speakers,\neffectively neutralizing its knowledge of these voices. The experiments\nconducted on the state-of-the-art model demonstrate that TGU prevents the model\nfrom replicating forget speakers' voices while maintaining high quality for\nother speakers. The demo is available at https://speechunlearn.github.io/", "published": "2025-07-27 06:13:58", "link": "http://arxiv.org/abs/2507.20140v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models", "abstract": "Speech language models refer to language models with speech processing and\nunderstanding capabilities. One key desirable capability for speech language\nmodels is the ability to capture the intricate interdependency between content\nand prosody. The existing mainstream paradigm of training speech language\nmodels, which converts speech into discrete tokens before feeding them into\nLLMs, is sub-optimal in learning prosody information -- we find that the\nresulting LLMs do not exhibit obvious emerging prosody processing capabilities\nvia pre-training alone. To overcome this, we propose ProsodyLM, which\nintroduces a simple tokenization scheme amenable to learning prosody. Each\nspeech utterance is first transcribed into text, followed by a sequence of\nword-level prosody tokens. Compared with conventional speech tokenization\nschemes, the proposed tokenization scheme retains more complete prosody\ninformation, and is more understandable to text-based LLMs. We find that\nProsodyLM can learn surprisingly diverse emerging prosody processing\ncapabilities through pre-training alone, ranging from harnessing the prosody\nnuances in generated speech, such as contrastive focus, understanding emotion\nand stress in an utterance, to maintaining prosody consistency in long\ncontexts.", "published": "2025-07-27 00:59:01", "link": "http://arxiv.org/abs/2507.20091v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings", "abstract": "DNA-binding proteins (DBPs) are integral to gene regulation and cellular\nprocesses, making their accurate identification essential for understanding\nbiological functions and disease mechanisms. Experimental methods for DBP\nidentification are time-consuming and costly, driving the need for efficient\ncomputational prediction techniques. In this study, we propose a novel deep\nlearning framework, ResCap-DBP, that combines a residual learning-based encoder\nwith a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly\nfrom raw protein sequences. Our architecture incorporates dilated convolutions\nwithin residual blocks to mitigate vanishing gradient issues and extract rich\nsequence features, while capsule layers with dynamic routing capture\nhierarchical and spatial relationships within the learned feature space. We\nconducted comprehensive ablation studies comparing global and local embeddings\nfrom ProteinBERT and conventional one-hot encoding. Results show that\nProteinBERT embeddings substantially outperform other representations on large\ndatasets. Although one-hot encoding showed marginal advantages on smaller\ndatasets, such as PDB186, it struggled to scale effectively. Extensive\nevaluations on four pairs of publicly available benchmark datasets demonstrate\nthat our model consistently outperforms current state-of-the-art methods. It\nachieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On\nindependent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2%\nand 83.3%, while maintaining competitive performance on larger datasets such as\nPDB20000. Notably, the model maintains a well balanced sensitivity and\nspecificity across datasets. These results demonstrate the efficacy and\ngeneralizability of integrating global protein representations with advanced\ndeep learning architectures for reliable and scalable DBP prediction in diverse\ngenomic contexts.", "published": "2025-07-27 21:54:32", "link": "http://arxiv.org/abs/2507.20426v1", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification", "abstract": "Automated analysis of lung sound auscultation is essential for monitoring\nrespiratory health, especially in regions facing a shortage of skilled\nhealthcare workers. While respiratory sound classification has been widely\nstudied in adults, its ap plication in pediatric populations, particularly in\nchildren aged <6 years, remains an underexplored area. The developmental\nchanges in pediatric lungs considerably alter the acoustic proper ties of\nrespiratory sounds, necessitating specialized classification approaches\ntailored to this age group. To address this, we propose a multistage hybrid\nCNN-Transformer framework that combines CNN-extracted features with an\nattention-based architecture to classify pediatric respiratory diseases using\nscalogram images from both full recordings and individual breath events. Our\nmodel achieved an overall score of 0.9039 in binary event classifi cation and\n0.8448 in multiclass event classification by employing class-wise focal loss to\naddress data imbalance. At the recording level, the model attained scores of\n0.720 for ternary and 0.571 for multiclass classification. These scores\noutperform the previous best models by 3.81% and 5.94%, respectively. This\napproach offers a promising solution for scalable pediatric respiratory disease\ndiagnosis, especially in resource-limited settings.", "published": "2025-07-27 20:36:46", "link": "http://arxiv.org/abs/2507.20408v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories", "abstract": "Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting\ngoods in 5G network-enabled smart factories, with the compute-intensive\nlocalization module presenting a significant opportunity for optimization. We\npropose ACCESS-AV, an energy-efficient Vehicle-to-Infrastructure (V2I)\nlocalization framework that leverages existing 5G infrastructure in smart\nfactory environments. By opportunistically accessing the periodically broadcast\n5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates\nthe need for dedicated Roadside Units (RSUs) or additional onboard sensors to\nachieve energy efficiency as well as cost reduction. We implement an\nAngle-of-Arrival (AoA)-based estimation method using the Multiple Signal\nClassification (MUSIC) algorithm, optimized for resource-constrained ADV\nplatforms through an adaptive communication-computation strategy that\ndynamically balances energy consumption with localization accuracy based on\nenvironmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle\nvelocity. Experimental results demonstrate that ACCESS-AV achieves an average\nenergy reduction of 43.09% compared to non-adaptive systems employing AoA\nalgorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30\ncm localization accuracy while also delivering substantial reductions in\ninfrastructure and operational costs, establishing its viability for\nsustainable smart factory environments.", "published": "2025-07-27 19:44:07", "link": "http://arxiv.org/abs/2507.20399v1", "categories": ["eess.SY", "cs.AR", "cs.NI", "cs.RO", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Reliability of Wi-Fi, LTE, and 5G-Based UAV RC Links in ISM Bands: Uplink Interference Asymmetry Analysis and HARQ Design", "abstract": "Command and control of uncrewed aerial vehicles (UAVs) is often realized\nthrough air-to-ground (A2G) remote control (RC) links that operate in ISM\nbands. While wireless fidelity (Wi-Fi) technology is commonly used for UAV RC\nlinks, ISM-based long-term evolution (LTE) and fifth-generation (5G)\ntechnologies have also been recently considered for the same purpose. A major\nproblem for UAV RC links in the ISM bands is that other types of interference\nsources, such as legacy Wi-Fi and Bluetooth transmissions, may degrade the link\nquality. Such interference problems are a higher concern for the UAV in the air\nthan the RC unit on the ground due to the UAV being in line-of-sight (LoS) with\na larger number of interference sources. To obtain empirical evidence of the\nasymmetric interference conditions in downlink (DL) and uplink (UL), we first\nconducted a measurement campaign using a helikite platform in urban and rural\nareas at NC State University. The results from this measurement campaign show\nthat the aggregate interference can be up to 16.66 dB at higher altitudes up to\n170 m, compared with the interference observed at a ground receiver. As a\nresult of this asymmetric UL interference, lost hybrid automatic repeat request\n(HARQ) indicators (ACK/NACK) in the UL may degrade the DL throughput. To\ninvestigate this, we study various HARQ mechanisms, including HARQ Type-I with\nno combining, HARQ Type-I with chase combining, HARQ Type-III with incremental\nredundancy, and burst transmission with chase combining. To evaluate the impact\nof asymmetric UL interference on throughput performance, we consider three\nsteps of evaluation process: 1) standalone physical DL shared channel (PDSCH)\nthroughput evaluation with perfect ACK/NACK assumption; 2) standalone physical\nUL control channel (PUCCH) decoding reliability evaluation; and 3) PDSCH DL\nthroughput evaluation with asymmetric UL ACK/NACK transmission.", "published": "2025-07-27 19:21:20", "link": "http://arxiv.org/abs/2507.20392v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Information-Preserving CSI Feedback: Invertible Networks with Endogenous Quantization and Channel Error Mitigation", "abstract": "Deep learning has emerged as a promising so- lution for efficient channel\nstate information (CSI) feedback in frequency division duplex (FDD) massive\nMIMO systems. Conventional deep learning-based methods typically rely on a deep\nautoencoder to compress the CSI, which leads to irre- versible information loss\nand degrades reconstruction accuracy. This paper introduces InvCSINet, an\ninformation-preserving CSI feedback framework based on invertible neural\nnetworks (INNs). By leveraging the bijective nature of INNs, the model ensures\ninformation-preserving compression and reconstruction with shared model\nparameters. To address practical challenges such as quantization and\nchannel-induced errors, we endoge- nously integrate an adaptive quantization\nmodule, a differentiable bit-channel distortion module and an information\ncompensation module into the INN architecture. This design enables the network\nto learn and compensate the information loss during CSI compression,\nquantization, and noisy transmission, thereby preserving the CSI integrity\nthroughout the feedback process. Simulation results validate the effectiveness\nof the proposed scheme, demonstrating superior CSI recovery performance and\nrobustness to practical impairments with a lightweight architec- ture.", "published": "2025-07-27 13:58:23", "link": "http://arxiv.org/abs/2507.20283v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis", "abstract": "Methamphetamine dependence poses a significant global health challenge, yet\nits assessment and the evaluation of treatments like repetitive transcranial\nmagnetic stimulation (rTMS) frequently depend on subjective self-reports, which\nmay introduce uncertainties. While objective neuroimaging modalities such as\nelectroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS)\noffer alternatives, their individual limitations and the reliance on\nconventional, often hand-crafted, feature extraction can compromise the\nreliability of derived biomarkers. To overcome these limitations, we propose\nNeuroCLIP, a novel deep learning framework integrating simultaneously recorded\nEEG and fNIRS data through a progressive learning strategy. This approach\noffers a robust and trustworthy biomarker for methamphetamine addiction.\nValidation experiments show that NeuroCLIP significantly improves\ndiscriminative capabilities among the methamphetamine-dependent individuals and\nhealthy controls compared to models using either EEG or only fNIRS alone.\nFurthermore, the proposed framework facilitates objective, brain-based\nevaluation of rTMS treatment efficacy, demonstrating measurable shifts in\nneural patterns towards healthy control profiles after treatment. Critically,\nwe establish the trustworthiness of the multimodal data-driven biomarker by\nshowing its strong correlation with psychometrically validated craving scores.\nThese findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP\noffers enhanced robustness and reliability over single-modality approaches,\nproviding a valuable tool for addiction neuroscience research and potentially\nimproving clinical assessments.", "published": "2025-07-27 09:16:39", "link": "http://arxiv.org/abs/2507.20189v1", "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "eess.SP"}
