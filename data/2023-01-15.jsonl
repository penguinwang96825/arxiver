{"title": "Summative Student Course Review Tool Based on Machine Learning Sentiment\n  Analysis to Enhance Life Science Feedback Efficacy", "abstract": "Machine learning enables the development of new, supplemental, and empowering\ntools that can either expand existing technologies or invent new ones. In\neducation, space exists for a tool that supports generic student course review\nformats to organize and recapitulate students' views on the pedagogical\npractices to which they are exposed. Often, student opinions are gathered with\na general comment section that solicits their feelings towards their courses\nwithout polling specifics about course contents. Herein, we show a novel\napproach to summarizing and organizing students' opinions via analyzing their\nsentiment towards a course as a function of the language/vocabulary used to\nconvey their opinions about a class and its contents. This analysis is derived\nfrom their responses to a general comment section encountered at the end of\npost-course review surveys. This analysis, accomplished with Python, LaTeX, and\nGoogle's Natural Language API, allows for the conversion of unstructured text\ndata into both general and topic-specific sub-reports that convey students'\nviews in a unique, novel way.", "published": "2023-01-15 19:56:56", "link": "http://arxiv.org/abs/2301.06173v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Rationalizing Predictions by Adversarial Information Calibration", "abstract": "Explaining the predictions of AI models is paramount in safety-critical\napplications, such as in legal or medical domains. One form of explanation for\na prediction is an extractive rationale, i.e., a subset of features of an\ninstance that lead the model to give its prediction on that instance. For\nexample, the subphrase ``he stole the mobile phone'' can be an extractive\nrationale for the prediction of ``Theft''. Previous works on generating\nextractive rationales usually employ a two-phase model: a selector that selects\nthe most important features (i.e., the rationale) followed by a predictor that\nmakes the prediction based exclusively on the selected features. One\ndisadvantage of these works is that the main signal for learning to select\nfeatures comes from the comparison of the answers given by the predictor to the\nground-truth answers. In this work, we propose to squeeze more information from\nthe predictor via an information calibration method. More precisely, we train\ntwo models jointly: one is a typical neural model that solves the task at hand\nin an accurate but black-box manner, and the other is a selector-predictor\nmodel that additionally produces a rationale for its prediction. The first\nmodel is used as a guide for the second model. We use an adversarial technique\nto calibrate the information extracted by the two models such that the\ndifference between them is an indicator of the missed or over-selected\nfeatures. In addition, for natural language tasks, we propose a\nlanguage-model-based regularizer to encourage the extraction of fluent\nrationales. Experimental results on a sentiment analysis task, a hate speech\nrecognition task as well as on three tasks from the legal domain show the\neffectiveness of our approach to rationale extraction.", "published": "2023-01-15 03:13:09", "link": "http://arxiv.org/abs/2301.06009v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A data science and machine learning approach to continuous analysis of\n  Shakespeare's plays", "abstract": "The availability of quantitative text analysis methods has provided new ways\nof analyzing literature in a manner that was not available in the\npre-information era. Here we apply comprehensive machine learning analysis to\nthe work of William Shakespeare. The analysis shows clear changes in the style\nof writing over time, with the most significant changes in the sentence length,\nfrequency of adjectives and adverbs, and the sentiments expressed in the text.\nApplying machine learning to make a stylometric prediction of the year of the\nplay shows a Pearson correlation of 0.71 between the actual and predicted year,\nindicating that Shakespeare's writing style as reflected by the quantitative\nmeasurements changed over time. Additionally, it shows that the stylometrics of\nsome of the plays is more similar to plays written either before or after the\nyear they were written. For instance, Romeo and Juliet is dated 1596, but is\nmore similar in stylometrics to plays written by Shakespeare after 1600. The\nsource code for the analysis is available for free download.", "published": "2023-01-15 06:25:50", "link": "http://arxiv.org/abs/2301.06024v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hawk: An Industrial-strength Multi-label Document Classifier", "abstract": "There are a plethora of methods and algorithms that solve the classical\nmulti-label document classification. However, when it comes to deployment and\nusage in an industry setting, most, if not all the contemporary approaches fail\nto address some of the vital aspects or requirements of an ideal solution: i.\nability to operate on variable-length texts and rambling documents. ii.\ncatastrophic forgetting problem. iii. modularity when it comes to online\nlearning and updating the model. iv. ability to spotlight relevant text while\nproducing the prediction, i.e. visualizing the predictions. v. ability to\noperate on imbalanced or skewed datasets. vi. scalability. The paper describes\nthe significance of these problems in detail and proposes a unique neural\nnetwork architecture that addresses the above problems. The proposed\narchitecture views documents as a sequence of sentences and leverages\nsentence-level embeddings for input representation. A hydranet-like\narchitecture is designed to have granular control over and improve the\nmodularity, coupled with a weighted loss driving task-specific heads. In\nparticular, two specific mechanisms are compared: Bi-LSTM and\nTransformer-based. The architecture is benchmarked on some of the popular\nbenchmarking datasets such as Web of Science - 5763, Web of Science - 11967,\nBBC Sports, and BBC News datasets. The experimental results reveal that the\nproposed model outperforms the existing methods by a substantial margin. The\nablation study includes comparisons of the impact of the attention mechanism\nand the application of weighted loss functions to train the task-specific heads\nin the hydranet.", "published": "2023-01-15 09:52:18", "link": "http://arxiv.org/abs/2301.06057v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bike Frames: Understanding the Implicit Portrayal of Cyclists in the\n  News", "abstract": "Increasing cycling for transportation or recreation can boost health and\nreduce the environmental impacts of vehicles. However, news agencies'\nideologies and reporting styles often influence public perception of cycling.\nFor example, if news agencies overly report cycling accidents, it may make\npeople perceive cyclists as \"dangerous,\" reducing the number of cyclists who\nopt to cycle. Additionally, a decline in cycling can result in less government\nfunding for safe infrastructure. In this paper, we develop a method for\ndetecting the perceived perception of cyclists within news headlines. We\nintroduce a new dataset called ``Bike Frames'' to accomplish this. The dataset\nconsists of 31,480 news headlines and 1,500 annotations. Our focus is on\nanalyzing 11,385 headlines from the United States. We also introduce the\nBikeFrame Chain-of-Code framework to predict cyclist perception, identify\naccident-related headlines, and determine fault. This framework uses pseudocode\nfor precise logic and integrates news agency bias analysis for improved\npredictions over traditional chain-of-thought reasoning in large language\nmodels. Our method substantially outperforms other methods, and most\nimportantly, we find that incorporating news bias information substantially\nimpacts performance, improving the average F1 from .739 to .815. Finally, we\nperform a comprehensive case study on US-based news headlines, finding\nreporting differences between news agencies and cycling-specific websites as\nwell as differences in reporting depending on the gender of cyclists. WARNING:\nThis paper contains descriptions of accidents and death.", "published": "2023-01-15 20:22:03", "link": "http://arxiv.org/abs/2301.06178v2", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Shades of Iteration: from Elgot to Kleene", "abstract": "Notions of iteration range from the arguably most general Elgot iteration to\na very specific Kleene iteration. The fundamental nature of Elgot iteration has\nbeen extensively explored by Bloom and Esik in the form of iteration theories,\nwhile Kleene iteration became extremely popular as an integral part of\n(untyped) formalisms, such as automata theory, regular expressions and Kleene\nalgebra. Here, we establish a formal connection between Elgot iteration and\nKleene iteration in the form of Elgot monads and Kleene monads, respectively.\nWe also introduce a novel class of while-monads, which like Kleene monads admit\na relatively simple description in algebraic terms. Like Elgot monads,\nwhile-monads cover a large variety of models that meaningfully support\nwhile-loops, but may fail the Kleene algebra laws, or even fail to support a\nKleen iteration operator altogether.", "published": "2023-01-15 22:14:43", "link": "http://arxiv.org/abs/2301.06202v2", "categories": ["cs.LO", "cs.CL"], "primary_category": "cs.LO"}
{"title": "What artificial intelligence might teach us about the origin of human\n  language", "abstract": "This study explores an interesting pattern emerging from research that\ncombines artificial intelligence with sound symbolism. In these studies,\nsupervised machine learning algorithms are trained to classify samples based on\nthe sounds of referent names. Machine learning algorithms are efficient\nlearners of sound symbolism, but they tend to bias one category over the other.\nThe pattern is this: when a category arguably represents greater threat, the\nalgorithms tend to overpredict to that category. A hypothesis, framed by error\nmanagement theory, is presented that proposes that this may be evidence of an\nadaptation to preference cautious behaviour. This hypothesis is tested by\nconstructing extreme gradient boosted (XGBoost) models using the sounds that\nmake up the names of Chinese, Japanese and Korean Pokemon and observing\nclassification error distribution.", "published": "2023-01-15 23:25:29", "link": "http://arxiv.org/abs/2301.06211v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "What's happening in your neighborhood? A Weakly Supervised Approach to\n  Detect Local News", "abstract": "Local news articles are a subset of news that impact users in a geographical\narea, such as a city, county, or state. Detecting local news (Step 1) and\nsubsequently deciding its geographical location as well as radius of impact\n(Step 2) are two important steps towards accurate local news recommendation.\nNaive rule-based methods, such as detecting city names from the news title,\ntend to give erroneous results due to lack of understanding of the news\ncontent. Empowered by the latest development in natural language processing, we\ndevelop an integrated pipeline that enables automatic local news detection and\ncontent-based local news recommendations. In this paper, we focus on Step 1 of\nthe pipeline, which highlights: (1) a weakly supervised framework incorporated\nwith domain knowledge and auto data processing, and (2) scalability to\nmulti-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline\nhas higher precision and recall evaluated on a real-world and human-labeled\ndataset. This pipeline has potential to more precise local news to users, helps\nlocal businesses get more exposure, and gives people more information about\ntheir neighborhood safety.", "published": "2023-01-15 03:20:18", "link": "http://arxiv.org/abs/2301.08146v3", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Training one model to detect heart and lung sound events from single\n  point auscultations", "abstract": "Objective: This work proposes a semi-supervised training approach for\ndetecting lung and heart sounds simultaneously with only one trained model and\nin invariance to the auscultation point. Methods: We use open-access data from\nthe 2016 Physionet/CinC Challenge, the 2022 George Moody Challenge, and from\nthe lung sound database HF_V1. We first train specialist single-task models\nusing foreground ground truth (GT) labels from different auscultation databases\nto identify background sound events in the respective lung and heart\nauscultation databases. The pseudo-labels generated in this way were combined\nwith the ground truth labels in a new training iteration, such that a new model\nwas subsequently trained to detect foreground and background signals. Benchmark\ntests ensured that the newly trained model could detect both, lung, and heart\nsound events in different auscultation sites without regressing on the original\ntask. We also established hand-validated labels for the respective background\nsignal in heart and lung sound auscultations to evaluate the models. Results:\nIn this work, we report for the first time results for i) a multi-class\nprediction for lung sound events and ii) for simultaneous detection of heart\nand lung sound events and achieve competitive results using only one model. The\ncombined multi-task model regressed slightly in heart sound detection and\ngained significantly in lung sound detection accuracy with an overall macro F1\nscore of 39.2% over six classes, representing a 6.7% improvement over the\nsingle-task baseline models. Conclusion/Significance: To the best of our\nknowledge, this is the first approach developed to date for measuring heart and\nlung sound events invariant to both, the auscultation site and capturing\ndevice. Hence, our model is capable of performing lung and heart sound\ndetection from any auscultation location.", "published": "2023-01-15 12:13:03", "link": "http://arxiv.org/abs/2301.06078v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
