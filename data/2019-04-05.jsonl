{"title": "Cross-Corpora Evaluation and Analysis of Grammatical Error Correction\n  Models --- Is Single-Corpus Evaluation Enough?", "abstract": "This study explores the necessity of performing cross-corpora evaluation for\ngrammatical error correction (GEC) models. GEC models have been previously\nevaluated based on a single commonly applied corpus: the CoNLL-2014 benchmark.\nHowever, the evaluation remains incomplete because the task difficulty varies\ndepending on the test corpus and conditions such as the proficiency levels of\nthe writers and essay topics. To overcome this limitation, we evaluate the\nperformance of several GEC models, including NMT-based (LSTM, CNN, and\ntransformer) and an SMT-based model, against various learner corpora\n(CoNLL-2013, CoNLL-2014, FCE, JFLEG, ICNALE, and KJ). Evaluation results reveal\nthat the models' rankings considerably vary depending on the corpus, indicating\nthat single-corpus evaluation is insufficient for GEC models.", "published": "2019-04-05 08:14:08", "link": "http://arxiv.org/abs/1904.02927v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Alternative Weighting Schemes for ELMo Embeddings", "abstract": "ELMo embeddings (Peters et. al, 2018) had a huge impact on the NLP community\nand may recent publications use these embeddings to boost the performance for\ndownstream NLP tasks. However, integration of ELMo embeddings in existent NLP\narchitectures is not straightforward. In contrast to traditional word\nembeddings, like GloVe or word2vec embeddings, the bi-directional language\nmodel of ELMo produces three 1024 dimensional vectors per token in a sentence.\nPeters et al. proposed to learn a task-specific weighting of these three\nvectors for downstream tasks. However, this proposed weighting scheme is not\nfeasible for certain tasks, and, as we will show, it does not necessarily yield\noptimal performance. We evaluate different methods that combine the three\nvectors from the language model in order to achieve the best possible\nperformance in downstream NLP tasks. We notice that the third layer of the\npublished language model often decreases the performance. By learning a\nweighted average of only the first two layers, we are able to improve the\nperformance for many datasets. Due to the reduced complexity of the language\nmodel, we have a training speed-up of 19-44% for the downstream task.", "published": "2019-04-05 09:24:36", "link": "http://arxiv.org/abs/1904.02954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NL-FIIT at SemEval-2019 Task 9: Neural Model Ensemble for Suggestion\n  Mining", "abstract": "In this paper, we present neural model architecture submitted to the\nSemEval-2019 Task 9 competition: \"Suggestion Mining from Online Reviews and\nForums\". We participated in both subtasks for domain specific and also\ncross-domain suggestion mining. We proposed a recurrent neural network\narchitecture that employs Bi-LSTM layers and also self-attention mechanism. Our\narchitecture tries to encode words via word representations using ELMo and\nensembles multiple models to achieve better results. We performed experiments\nwith different setups of our proposed model involving weighting of prediction\nclasses for loss function. Our best model achieved in official test evaluation\nscore of 0.6816 for subtask A and 0.6850 for subtask B. In official results, we\nachieved 12th and 10th place in subtasks A and B, respectively.", "published": "2019-04-05 10:19:56", "link": "http://arxiv.org/abs/1904.02981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Knowledge Graph Paths from Textual Definitions using\n  Sequence-to-Sequence Models", "abstract": "We present a novel method for mapping unrestricted text to knowledge graph\nentities by framing the task as a sequence-to-sequence problem. Specifically,\ngiven the encoded state of an input text, our decoder directly predicts paths\nin the knowledge graph, starting from the root and ending at the target node\nfollowing hypernym-hyponym relationships. In this way, and in contrast to other\ntext-to-entity mapping systems, our model outputs hierarchically structured\npredictions that are fully interpretable in the context of the underlying\nontology, in an end-to-end manner. We present a proof-of-concept experiment\nwith encouraging results, comparable to those of state-of-the-art systems.", "published": "2019-04-05 11:29:57", "link": "http://arxiv.org/abs/1904.02996v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identifying and Reducing Gender Bias in Word-Level Language Models", "abstract": "Many text corpora exhibit socially problematic biases, which can be\npropagated or amplified in the models trained on such data. For example, doctor\ncooccurs more frequently with male pronouns than female pronouns. In this study\nwe (i) propose a metric to measure gender bias; (ii) measure bias in a text\ncorpus and the text generated from a recurrent neural network language model\ntrained on the text corpus; (iii) propose a regularization loss term for the\nlanguage model that minimizes the projection of encoder-trained embeddings onto\nan embedding subspace that encodes gender; (iv) finally, evaluate efficacy of\nour proposed method on reducing gender bias. We find this regularization method\nto be effective in reducing gender bias up to an optimal weight assigned to the\nloss term, beyond which the model becomes unstable as the perplexity increases.\nWe replicate this study on three training corpora---Penn Treebank, WikiText-2,\nand CNN/Daily Mail---resulting in similar conclusions.", "published": "2019-04-05 12:40:28", "link": "http://arxiv.org/abs/1904.03035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PoMo: Generating Entity-Specific Post-Modifiers in Context", "abstract": "We introduce entity post-modifier generation as an instance of a\ncollaborative writing task. Given a sentence about a target entity, the task is\nto automatically generate a post-modifier phrase that provides contextually\nrelevant information about the entity. For example, for the sentence, \"Barack\nObama, _______, supported the #MeToo movement.\", the phrase \"a father of two\ngirls\" is a contextually relevant post-modifier. To this end, we build PoMo, a\npost-modifier dataset created automatically from news articles reflecting a\njournalistic need for incorporating entity information that is relevant to a\nparticular news event. PoMo consists of more than 231K sentences with\npost-modifiers and associated facts extracted from Wikidata for around 57K\nunique entities. We use crowdsourcing to show that modeling contextual\nrelevance is necessary for accurate post-modifier generation. We adapt a number\nof existing generation approaches as baselines for this dataset. Our results\nshow there is large room for improvement in terms of both identifying relevant\nfacts to include (knowing which claims are relevant gives a >20% improvement in\nBLEU score), and generating appropriate post-modifier text for the context\n(providing relevant claims is not sufficient for accurate generation). We\nconduct an error analysis that suggests promising directions for future\nresearch.", "published": "2019-04-05 15:10:09", "link": "http://arxiv.org/abs/1904.03111v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Outlier Detection for Improved Data Quality and Diversity in Dialog\n  Systems", "abstract": "In a corpus of data, outliers are either errors: mistakes in the data that\nare counterproductive, or are unique: informative samples that improve model\nrobustness. Identifying outliers can lead to better datasets by (1) removing\nnoise in datasets and (2) guiding collection of additional data to fill gaps.\nHowever, the problem of detecting both outlier types has received relatively\nlittle attention in NLP, particularly for dialog systems. We introduce a simple\nand effective technique for detecting both erroneous and unique samples in a\ncorpus of short texts using neural sentence embeddings combined with\ndistance-based outlier detection. We also present a novel data collection\npipeline built atop our detection technique to automatically and iteratively\nmine unique data samples while discarding erroneous samples. Experiments show\nthat our outlier detection technique is effective at finding errors while our\ndata collection pipeline yields highly diverse corpora that in turn produce\nmore robust intent classification and slot-filling models.", "published": "2019-04-05 15:31:28", "link": "http://arxiv.org/abs/1904.03122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Fine-Tuned Embeddings that Model Intensifiers for Emotion\n  Analysis", "abstract": "Adjective phrases like \"a little bit surprised\", \"completely shocked\", or\n\"not stunned at all\" are not handled properly by currently published\nstate-of-the-art emotion classification and intensity prediction systems which\nuse pre-dominantly non-contextualized word embeddings as input. Based on this\nfinding, we analyze differences between embeddings used by these systems in\nregard to their capability of handling such cases. Furthermore, we argue that\nintensifiers in context of emotion words need special treatment, as is\nestablished for sentiment polarity classification, but not for more\nfine-grained emotion prediction. To resolve this issue, we analyze different\naspects of a post-processing pipeline which enriches the word representations\nof such phrases. This includes expansion of semantic spaces at the phrase level\nand sub-word level followed by retrofitting to emotion lexica. We evaluate the\nimpact of these steps with A La Carte and Bag-of-Substrings extensions based on\npretrained GloVe, Word2vec, and fastText embeddings against a crowd-sourced\ncorpus of intensity annotations for tweets containing our focus phrases. We\nshow that the fastText-based models do not gain from handling these specific\nphrases under inspection. For Word2vec embeddings, we show that our\npost-processing pipeline improves the results by up to 8% on a novel dataset\ndensely populated with intensifiers.", "published": "2019-04-05 17:13:01", "link": "http://arxiv.org/abs/1904.03164v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distinguishing Clinical Sentiment: The Importance of Domain Adaptation\n  in Psychiatric Patient Health Records", "abstract": "Recently natural language processing (NLP) tools have been developed to\nidentify and extract salient risk indicators in electronic health records\n(EHRs). Sentiment analysis, although widely used in non-medical areas for\nimproving decision making, has been studied minimally in the clinical setting.\nIn this study, we undertook, to our knowledge, the first domain adaptation of\nsentiment analysis to psychiatric EHRs by defining psychiatric clinical\nsentiment, performing an annotation project, and evaluating multiple\nsentence-level sentiment machine learning (ML) models. Results indicate that\noff-the-shelf sentiment analysis tools fail in identifying clinically positive\nor negative polarity, and that the definition of clinical sentiment that we\nprovide is learnable with relatively small amounts of training data. This\nproject is an initial step towards further refining sentiment analysis methods\nfor clinical use. Our long-term objective is to incorporate the results of this\nproject as part of a machine learning model that predicts inpatient readmission\nrisk. We hope that this work will initiate a discussion concerning domain\nadaptation of sentiment analysis to the clinical setting.", "published": "2019-04-05 18:33:22", "link": "http://arxiv.org/abs/1904.03225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Lingual Transfer of Semantic Roles: From Raw Text to Semantic\n  Roles", "abstract": "We describe a transfer method based on annotation projection to develop a\ndependency-based semantic role labeling system for languages for which no\nsupervised linguistic information other than parallel data is available. Unlike\nprevious work that presumes the availability of supervised features such as\nlemmas, part-of-speech tags, and dependency parse trees, we only make use of\nword and character features. Our deep model considers using character-based\nrepresentations as well as unsupervised stem embeddings to alleviate the need\nfor supervised features. Our experiments outperform a state-of-the-art method\nthat uses supervised lexico-syntactic features on 6 out of 7 languages in the\nUniversal Proposition Bank.", "published": "2019-04-05 20:04:04", "link": "http://arxiv.org/abs/1904.03256v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Factual Min/Max Age Information from Clinical Trial Studies", "abstract": "Population age information is an essential characteristic of clinical trials.\nIn this paper, we focus on extracting minimum and maximum (min/max) age values\nfor the study samples from clinical research articles. Specifically, we\ninvestigate the use of a neural network model for question answering to address\nthis information extraction task. The min/max age QA model is trained on the\nmassive structured clinical study records from ClinicalTrials.gov. For each\narticle, based on multiple min and max age values extracted from the QA model,\nwe predict both actual min/max age values for the study samples and filter out\nnon-factual age expressions. Our system improves the results over (i) a passage\nretrieval based IE system and (ii) a CRF-based system by a large margin when\nevaluated on an annotated dataset consisting of 50 research papers on smoking\ncessation.", "published": "2019-04-05 20:18:51", "link": "http://arxiv.org/abs/1904.03262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generate, Filter, and Rank: Grammaticality Classification for\n  Production-Ready NLG Systems", "abstract": "Neural approaches to Natural Language Generation (NLG) have been promising\nfor goal-oriented dialogue. One of the challenges of productionizing these\napproaches, however, is the ability to control response quality, and ensure\nthat generated responses are acceptable. We propose the use of a generate,\nfilter, and rank framework, in which candidate responses are first filtered to\neliminate unacceptable responses, and then ranked to select the best response.\nWhile acceptability includes grammatical correctness and semantic correctness,\nwe focus only on grammaticality classification in this paper, and show that\nexisting datasets for grammatical error correction don't correctly capture the\ndistribution of errors that data-driven generators are likely to make. We\nrelease a grammatical classification and semantic correctness classification\ndataset for the weather domain that consists of responses generated by 3\ndata-driven NLG systems. We then explore two supervised learning approaches\n(CNNs and GBDTs) for classifying grammaticality. Our experiments show that\ngrammaticality classification is very sensitive to the distribution of errors\nin the data, and that these distributions vary significantly with both the\nsource of the response as well as the domain. We show that it's possible to\nachieve high precision with reasonable recall on our dataset.", "published": "2019-04-05 21:02:12", "link": "http://arxiv.org/abs/1904.03279v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A General Framework for Information Extraction using Dynamic Span Graphs", "abstract": "We introduce a general framework for several information extraction tasks\nthat share span representations using dynamically constructed span graphs. The\ngraphs are constructed by selecting the most confident entity spans and linking\nthese nodes with confidence-weighted relation types and coreferences. The\ndynamic span graph allows coreference and relation type confidences to\npropagate through the graph to iteratively refine the span representations.\nThis is unlike previous multi-task frameworks for information extraction in\nwhich the only interaction between tasks is in the shared first-layer LSTM. Our\nframework significantly outperforms the state-of-the-art on multiple\ninformation extraction tasks across multiple datasets reflecting different\ndomains. We further observe that the span enumeration approach is good at\ndetecting nested span entities, with significant F1 score improvement on the\nACE dataset.", "published": "2019-04-05 21:52:18", "link": "http://arxiv.org/abs/1904.03296v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-task Learning Approach for Named Entity Recognition using Local\n  Detection", "abstract": "Named entity recognition (NER) systems that perform well require task-related\nand manually annotated datasets. However, they are expensive to develop, and\nare thus limited in size. As there already exists a large number of NER\ndatasets that share a certain degree of relationship but differ in content, it\nis important to explore the question of whether such datasets can be combined\nas a simple method for improving NER performance. To investigate this, we\ndeveloped a novel locally detecting multitask model using FFNNs. The model\nrelies on encoding variable-length sequences of words into theoretically\nlossless and unique fixed-size representations. We applied this method to\nseveral well-known NER tasks and compared the results of our model to baseline\nmodels as well as other published results. As a result, we observed competitive\nperformance in nearly all of the tasks.", "published": "2019-04-05 21:58:27", "link": "http://arxiv.org/abs/1904.03300v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Context and Fragment Feature Usage for Named Entity\n  Recognition", "abstract": "In this paper, we explore a new approach to named entity recognition (NER)\nwith the goal of learning from context and fragment features more effectively,\ncontributing to the improvement of overall recognition performance. We use the\nrecent fixed-size ordinally forgetting encoding (FOFE) method to fully encode\neach sentence fragment and its left-right contexts into a fixed-size\nrepresentation. Next, we organize the context and fragment features into\ngroups, and feed each feature group to dedicated fully-connected layers.\nFinally, we merge each group's final dedicated layers and add a shared layer\nleading to a single output. The outcome of our experiments show that, given\nonly tokenized text and trained word embeddings, our system outperforms our\nbaseline models, and is competitive to the state-of-the-arts of various\nwell-known NER tasks.", "published": "2019-04-05 22:10:15", "link": "http://arxiv.org/abs/1904.03305v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Contextualized Word Embeddings", "abstract": "In this paper, we quantify, analyze and mitigate gender bias exhibited in\nELMo's contextualized word vectors. First, we conduct several intrinsic\nanalyses and find that (1) training data for ELMo contains significantly more\nmale than female entities, (2) the trained ELMo embeddings systematically\nencode gender information and (3) ELMo unequally encodes gender information\nabout male and female entities. Then, we show that a state-of-the-art\ncoreference system that depends on ELMo inherits its bias and demonstrates\nsignificant bias on the WinoBias probing corpus. Finally, we explore two\nmethods to mitigate such gender bias and show that the bias demonstrated on\nWinoBias can be eliminated.", "published": "2019-04-05 22:36:12", "link": "http://arxiv.org/abs/1904.03310v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abusive Language Detection with Graph Convolutional Networks", "abstract": "Abuse on the Internet represents a significant societal problem of our time.\nPrevious research on automated abusive language detection in Twitter has shown\nthat community-based profiling of users is a promising technique for this task.\nHowever, existing approaches only capture shallow properties of online\ncommunities by modeling follower-following relationships. In contrast, working\nwith graph convolutional networks (GCNs), we present the first approach that\ncaptures not only the structure of online communities but also the linguistic\nbehavior of the users within them. We show that such a heterogeneous\ngraph-structured modeling of communities significantly advances the current\nstate of the art in abusive language detection.", "published": "2019-04-05 03:49:22", "link": "http://arxiv.org/abs/1904.04073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining Sentiment Lexica with a Multi-View Variational Autoencoder", "abstract": "When assigning quantitative labels to a dataset, different methodologies may\nrely on different scales. In particular, when assigning polarities to words in\na sentiment lexicon, annotators may use binary, categorical, or continuous\nlabels. Naturally, it is of interest to unify these labels from disparate\nscales to both achieve maximal coverage over words and to create a single, more\nrobust sentiment lexicon while retaining scale coherence. We introduce a\ngenerative model of sentiment lexica to combine disparate scales into a common\nlatent representation. We realize this model with a novel multi-view\nvariational autoencoder (VAE), called SentiVAE. We evaluate our approach via a\ndownstream text classification task involving nine English-Language sentiment\nanalysis datasets; our representation outperforms six individual sentiment\nlexica, as well as a straightforward combination thereof.", "published": "2019-04-05 01:03:31", "link": "http://arxiv.org/abs/1904.02839v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Graph Pattern Entity Ranking Model for Knowledge Graph Completion", "abstract": "Knowledge graphs have evolved rapidly in recent years and their usefulness\nhas been demonstrated in many artificial intelligence tasks. However, knowledge\ngraphs often have lots of missing facts. To solve this problem, many knowledge\ngraph embedding models have been developed to populate knowledge graphs and\nthese have shown outstanding performance. However, knowledge graph embedding\nmodels are so-called black boxes, and the user does not know how the\ninformation in a knowledge graph is processed and the models can be difficult\nto interpret. In this paper, we utilize graph patterns in a knowledge graph to\novercome such problems. Our proposed model, the {\\it graph pattern entity\nranking model} (GRank), constructs an entity ranking system for each graph\npattern and evaluates them using a ranking measure. By doing so, we can find\ngraph patterns which are useful for predicting facts. Then, we perform link\nprediction tasks on standard datasets to evaluate our GRank method. We show\nthat our approach outperforms other state-of-the-art approaches such as ComplEx\nand TorusE for standard metrics such as HITS@{\\it n} and MRR. Moreover, our\nmodel is easily interpretable because the output facts are described by graph\npatterns.", "published": "2019-04-05 03:17:00", "link": "http://arxiv.org/abs/1904.02856v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Modeling Recurrence for Transformer", "abstract": "Recently, the Transformer model that is based solely on attention mechanisms,\nhas advanced the state-of-the-art on various machine translation tasks.\nHowever, recent studies reveal that the lack of recurrence hinders its further\nimprovement of translation capacity. In response to this problem, we propose to\ndirectly model recurrence for Transformer with an additional recurrence\nencoder. In addition to the standard recurrent neural network, we introduce a\nnovel attentive recurrent network to leverage the strengths of both attention\nand recurrent networks. Experimental results on the widely-used WMT14\nEnglish-German and WMT17 Chinese-English translation tasks demonstrate the\neffectiveness of the proposed approach. Our studies also reveal that the\nproposed model benefits from a short-cut that bridges the source and target\nsequences with a single recurrent layer, which outperforms its deep\ncounterpart.", "published": "2019-04-05 14:40:22", "link": "http://arxiv.org/abs/1904.03092v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Information Aggregation for Multi-Head Attention with\n  Routing-by-Agreement", "abstract": "Multi-head attention is appealing for its ability to jointly extract\ndifferent types of information from multiple representation subspaces.\nConcerning the information aggregation, a common practice is to use a\nconcatenation followed by a linear transformation, which may not fully exploit\nthe expressiveness of multi-head attention. In this work, we propose to improve\nthe information aggregation for multi-head attention with a more powerful\nrouting-by-agreement algorithm. Specifically, the routing algorithm iteratively\nupdates the proportion of how much a part (i.e. the distinct information\nlearned from a specific subspace) should be assigned to a whole (i.e. the final\noutput representation), based on the agreement between parts and wholes.\nExperimental results on linguistic probing tasks and machine translation tasks\nprove the superiority of the advanced information aggregation over the standard\nlinear transformation.", "published": "2019-04-05 14:52:28", "link": "http://arxiv.org/abs/1904.03100v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Convolutional Self-Attention Networks", "abstract": "Self-attention networks (SANs) have drawn increasing interest due to their\nhigh parallelization in computation and flexibility in modeling dependencies.\nSANs can be further enhanced with multi-head attention by allowing the model to\nattend to information from different representation subspaces. In this work, we\npropose novel convolutional self-attention networks, which offer SANs the\nabilities to 1) strengthen dependencies among neighboring elements, and 2)\nmodel the interaction between features extracted by multiple attention heads.\nExperimental results of machine translation on different language pairs and\nmodel settings show that our approach outperforms both the strong Transformer\nbaseline and other existing models on enhancing the locality of SANs. Comparing\nwith prior studies, the proposed model is parameter free in terms of\nintroducing no more parameters.", "published": "2019-04-05 15:02:26", "link": "http://arxiv.org/abs/1904.03107v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NELEC at SemEval-2019 Task 3: Think Twice Before Going Deep", "abstract": "Existing Machine Learning techniques yield close to human performance on\ntext-based classification tasks. However, the presence of multi-modal noise in\nchat data such as emoticons, slang, spelling mistakes, code-mixed data, etc.\nmakes existing deep-learning solutions perform poorly. The inability of\ndeep-learning systems to robustly capture these covariates puts a cap on their\nperformance. We propose NELEC: Neural and Lexical Combiner, a system which\nelegantly combines textual and deep-learning based methods for sentiment\nclassification. We evaluate our system as part of the third task of 'Contextual\nEmotion Detection in Text' as part of SemEval-2019. Our system performs\nsignificantly better than the baseline, as well as our deep-learning model\nbenchmarks. It achieved a micro-averaged F1 score of 0.7765, ranking 3rd on the\ntest-set leader-board. Our code is available at\nhttps://github.com/iamgroot42/nelec", "published": "2019-04-05 18:31:06", "link": "http://arxiv.org/abs/1904.03223v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "An Analysis of Attention over Clinical Notes for Predictive Tasks", "abstract": "The shift to electronic medical records (EMRs) has engendered research into\nmachine learning and natural language technologies to analyze patient records,\nand to predict from these clinical outcomes of interest. Two observations\nmotivate our aims here. First, unstructured notes contained within EMR often\ncontain key information, and hence should be exploited by models. Second, while\nstrong predictive performance is important, interpretability of models is\nperhaps equally so for applications in this domain. Together, these points\nsuggest that neural models for EMR may benefit from incorporation of attention\nover notes, which one may hope will both yield performance gains and afford\ntransparency in predictions. In this work we perform experiments to explore\nthis question using two EMR corpora and four different predictive tasks, that:\n(i) inclusion of attention mechanisms is critical for neural encoder modules\nthat operate over notes fields in order to yield competitive performance, but,\n(ii) unfortunately, while these boost predictive performance, it is decidedly\nless clear whether they provide meaningful support for predictions.", "published": "2019-04-05 19:22:47", "link": "http://arxiv.org/abs/1904.03244v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analyzing and Interpreting Neural Networks for NLP: A Report on the\n  First BlackboxNLP Workshop", "abstract": "The EMNLP 2018 workshop BlackboxNLP was dedicated to resources and techniques\nspecifically developed for analyzing and understanding the inner-workings and\nrepresentations acquired by neural models of language. Approaches included:\nsystematic manipulation of input to neural networks and investigating the\nimpact on their performance, testing whether interpretable knowledge can be\ndecoded from intermediate representations acquired by neural networks,\nproposing modifications to neural network architectures to make their knowledge\nstate or generated output more explainable, and examining the performance of\nnetworks on simplified or formal languages. Here we review a number of\nrepresentative studies in each category.", "published": "2019-04-05 15:15:45", "link": "http://arxiv.org/abs/1904.04063v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "CLEARumor at SemEval-2019 Task 7: ConvoLving ELMo Against Rumors", "abstract": "This paper describes our submission to SemEval-2019 Task 7: RumourEval:\nDetermining Rumor Veracity and Support for Rumors. We participated in both\nsubtasks. The goal of subtask A is to classify the type of interaction between\na rumorous social media post and a reply post as support, query, deny, or\ncomment. The goal of subtask B is to predict the veracity of a given rumor. For\nsubtask A, we implement a CNN-based neural architecture using ELMo embeddings\nof post text combined with auxiliary features and achieve a F1-score of 44.6%.\nFor subtask B, we employ a MLP neural network leveraging our estimates for\nsubtask A and achieve a F1-score of 30.1% (second place in the competition). We\nprovide results and analysis of our system performance and present ablation\nexperiments.", "published": "2019-04-05 14:25:25", "link": "http://arxiv.org/abs/1904.03084v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data-driven Modelling of Dynamical Systems Using Tree Adjoining Grammar\n  and Genetic Programming", "abstract": "State-of-the-art methods for data-driven modelling of non-linear dynamical\nsystems typically involve interactions with an expert user. In order to\npartially automate the process of modelling physical systems from data, many\nEA-based approaches have been proposed for model-structure selection, with\nspecial focus on non-linear systems. Recently, an approach for data-driven\nmodelling of non-linear dynamical systems using Genetic Programming (GP) was\nproposed. The novelty of the method was the modelling of noise and the use of\nTree Adjoining Grammar to shape the search-space explored by GP. In this paper,\nwe report results achieved by the proposed method on three case studies. Each\nof the case studies considered here is based on real physical systems. The case\nstudies pose a variety of challenges. In particular, these challenges range\nover varying amounts of prior knowledge of the true system, amount of data\navailable, the complexity of the dynamics of the system, and the nature of\nnon-linearities in the system. Based on the results achieved for the case\nstudies, we critically analyse the performance of the proposed method.", "published": "2019-04-05 16:42:44", "link": "http://arxiv.org/abs/1904.03152v1", "categories": ["cs.SY", "cs.CL", "cs.NE"], "primary_category": "cs.SY"}
{"title": "Improving Scientific Article Visibility by Neural Title Simplification", "abstract": "The rapidly growing amount of data that scientific content providers should\ndeliver to a user makes them create effective recommendation tools. A title of\nan article is often the only shown element to attract people's attention. We\noffer an approach to automatic generating titles with various levels of\ninformativeness to benefit from different categories of users. Statistics from\nResearchGate used to bias train datasets and specially designed post-processing\nstep applied to neural sequence-to-sequence models allow reaching the desired\nvariety of simplified titles to gain a trade-off between the attractiveness and\ntransparency of recommendation.", "published": "2019-04-05 17:44:12", "link": "http://arxiv.org/abs/1904.03172v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "An Unsupervised Autoregressive Model for Speech Representation Learning", "abstract": "This paper proposes a novel unsupervised autoregressive neural model for\nlearning generic speech representations. In contrast to other speech\nrepresentation learning methods that aim to remove noise or speaker\nvariabilities, ours is designed to preserve information for a wide range of\ndownstream tasks. In addition, the proposed model does not require any phonetic\nor word boundary labels, allowing the model to benefit from large quantities of\nunlabeled data. Speech representations learned by our model significantly\nimprove performance on both phone classification and speaker verification over\nthe surface features and other supervised and unsupervised approaches. Further\nanalysis shows that different levels of speech information are captured by our\nmodel at different layers. In particular, the lower layers tend to be more\ndiscriminative for speakers, while the upper layers provide more phonetic\ncontent.", "published": "2019-04-05 19:04:19", "link": "http://arxiv.org/abs/1904.03240v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Domain Authoring Assistant for Intelligent Virtual Agents", "abstract": "Developing intelligent virtual characters has attracted a lot of attention in\nthe recent years. The process of creating such characters often involves a team\nof creative authors who describe different aspects of the characters in natural\nlanguage, and planning experts that translate this description into a planning\ndomain. This can be quite challenging as the team of creative authors should\ndiligently define every aspect of the character especially if it contains\ncomplex human-like behavior. Also a team of engineers has to manually translate\nthe natural language description of a character's personality into the planning\ndomain knowledge. This can be extremely time and resource demanding and can be\nan obstacle to author's creativity. The goal of this paper is to introduce an\nauthoring assistant tool to automate the process of domain generation from\nnatural language description of virtual characters, thus bridging between the\ncreative authoring team and the planning domain experts. Moreover, the proposed\ntool also identifies possible missing information in the domain description and\niteratively makes suggestions to the author.", "published": "2019-04-05 20:27:26", "link": "http://arxiv.org/abs/1904.03266v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Jasper: An End-to-End Convolutional Neural Acoustic Model", "abstract": "In this paper, we report state-of-the-art results on LibriSpeech among\nend-to-end speech recognition models without any external training data. Our\nmodel, Jasper, uses only 1D convolutions, batch normalization, ReLU, dropout,\nand residual connections. To improve training, we further introduce a new\nlayer-wise optimizer called NovoGrad. Through experiments, we demonstrate that\nthe proposed deep architecture performs as well or better than more complex\nchoices. Our deepest Jasper variant uses 54 convolutional layers. With this\narchitecture, we achieve 2.95% WER using a beam-search decoder with an external\nneural language model and 3.86% WER with a greedy decoder on LibriSpeech\ntest-clean. We also report competitive results on the Wall Street Journal and\nthe Hub5'00 conversational evaluation datasets.", "published": "2019-04-05 21:35:44", "link": "http://arxiv.org/abs/1904.03288v3", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Modelling of Sound Events with Hidden Imbalances Based on Clustering and\n  Separate Sub-Dictionary Learning", "abstract": "This paper proposes an effective modelling of sound event spectra with a\nhidden data-size-imbalance, for improved Acoustic Event Detection (AED). The\nproposed method models each event as an aggregated representation of a few\nlatent factors, while conventional approaches try to find acoustic elements\ndirectly from the event spectra. In the method, all the latent factors across\nall events are assigned comparable importance and complexity to overcome the\nhidden imbalance of data-sizes in event spectra. To extract latent factors in\neach event, the proposed method employs clustering and performs non-negative\nmatrix factorization to each latent factor, and learns its acoustic elements as\na sub-dictionary. Separate sub-dictionary learning effectively models the\nacoustic elements with limited data-sizes and avoids over-fitting due to hidden\nimbalances in training data. For the task of polyphonic sound event detection\nfrom DCASE 2013 challenge, an AED based on the proposed modelling achieves a\ndetection F-measure of 46.5%, a significant improvement of more than 19% as\ncompared to the existing state-of-the-art methods.", "published": "2019-04-05 02:44:59", "link": "http://arxiv.org/abs/1904.02852v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech", "abstract": "This paper introduces a new speech corpus called \"LibriTTS\" designed for\ntext-to-speech use. It is derived from the original audio and text materials of\nthe LibriSpeech corpus, which has been used for training and evaluating\nautomatic speech recognition systems. The new corpus inherits desired\nproperties of the LibriSpeech corpus while addressing a number of issues which\nmake LibriSpeech less than ideal for text-to-speech work. The released corpus\nconsists of 585 hours of speech data at 24kHz sampling rate from 2,456 speakers\nand the corresponding texts. Experimental results show that neural end-to-end\nTTS models trained from the LibriTTS corpus achieved above 4.0 in mean opinion\nscores in naturalness in five out of six evaluation speakers. The corpus is\nfreely available for download from http://www.openslr.org/60/.", "published": "2019-04-05 06:05:00", "link": "http://arxiv.org/abs/1904.02882v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Learning Features for Robust Detection of Acoustic Events in\n  Sleep-Disordered Breathing", "abstract": "Sleep-disordered breathing (SDB) is a serious and prevalent condition, and\nacoustic analysis via consumer devices (e.g. smartphones) offers a low-cost\nsolution to screening for it. We present a novel approach for the acoustic\nidentification of SDB sounds, such as snoring, using bottleneck features\nlearned from a corpus of whole-night sound recordings. Two types of bottleneck\nfeatures are described, obtained by applying a deep autoencoder to the output\nof an auditory model or a short-term autocorrelation analysis. We investigate\ntwo architectures for snore sound detection: a tandem system and a hybrid\nsystem. In both cases, a `language model' (LM) was incorporated to exploit\ninformation about the sequence of different SDB events. Our results show that\nthe proposed bottleneck features give better performance than conventional\nmel-frequency cepstral coefficients, and that the tandem system outperforms the\nhybrid system given the limited amount of labelled training data available. The\nLM made a small improvement to the performance of both classifiers.", "published": "2019-04-05 11:07:45", "link": "http://arxiv.org/abs/1904.02992v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Exploiting Deep Neural Networks and Head Movements for Robust Binaural\n  Localisation of Multiple Sources in Reverberant Environments", "abstract": "This paper presents a novel machine-hearing system that exploits deep neural\nnetworks (DNNs) and head movements for robust binaural localisation of multiple\nsources in reverberant environments. DNNs are used to learn the relationship\nbetween the source azimuth and binaural cues, consisting of the complete\ncross-correlation function (CCF) and interaural level differences (ILDs). In\ncontrast to many previous binaural hearing systems, the proposed approach is\nnot restricted to localisation of sound sources in the frontal hemifield. Due\nto the similarity of binaural cues in the frontal and rear hemifields,\nfront-back confusions often occur. To address this, a head movement strategy is\nincorporated in the localisation model to help reduce the front-back errors.\nThe proposed DNN system is compared to a Gaussian mixture model (GMM) based\nsystem that employs interaural time differences (ITDs) and ILDs as localisation\nfeatures. Our experiments show that the DNN is able to exploit information in\nthe CCF that is not available in the ITD cue, which together with head\nmovements substantially improves localisation accuracies under challenging\nacoustic scenarios in which multiple talkers and room reverberation are\npresent.", "published": "2019-04-05 11:38:12", "link": "http://arxiv.org/abs/1904.03001v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Robust Binaural Localization of a Target Sound Source by Combining\n  Spectral Source Models and Deep Neural Networks", "abstract": "Despite there being clear evidence for top-down (e.g., attentional) effects\nin biological spatial hearing, relatively few machine hearing systems exploit\ntop-down model-based knowledge in sound localisation. This paper addresses this\nissue by proposing a novel framework for binaural sound localisation that\ncombines model-based information about the spectral characteristics of sound\nsources and deep neural networks (DNNs). A target source model and a background\nsource model are first estimated during a training phase using spectral\nfeatures extracted from sound signals in isolation. When the identity of the\nbackground source is not available, a universal background model can be used.\nDuring testing, the source models are used jointly to explain the mixed\nobservations and improve the localisation process by selectively weighting\nsource azimuth posteriors output by a DNN-based localisation system. To address\nthe possible mismatch between training and testing, a model adaptation process\nis further employed on-the-fly during testing, which adapts the background\nmodel parameters directly from the noisy observations in an iterative manner.\nThe proposed system therefore combines model-based and data-driven information\nflow within a single computational framework. The evaluation task involved\nlocalisation of a target speech source in the presence of an interfering source\nand room reverberation. Our experiments show that by exploiting model-based\ninformation in this way, sound localisation performance can be improved\nsubstantially under various noisy and reverberant conditions.", "published": "2019-04-05 11:50:25", "link": "http://arxiv.org/abs/1904.03006v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Recursive speech separation for unknown number of speakers", "abstract": "In this paper we propose a method of single-channel speaker-independent\nmulti-speaker speech separation for an unknown number of speakers. As opposed\nto previous works, in which the number of speakers is assumed to be known in\nadvance and speech separation models are specific for the number of speakers,\nour proposed method can be applied to cases with different numbers of speakers\nusing a single model by recursively separating a speaker. To make the\nseparation model recursively applicable, we propose one-and-rest permutation\ninvariant training (OR-PIT). Evaluation on WSJ0-2mix and WSJ0-3mix datasets\nshow that our proposed method achieves state-of-the-art results for two- and\nthree-speaker mixtures with a single model. Moreover, the same model can\nseparate four-speaker mixture, which was never seen during the training. We\nfurther propose the detection of the number of speakers in a mixture during\nrecursive separation and show that this approach can more accurately estimate\nthe number of speakers than detection in advance by using a deep neural network\nbased classifier.", "published": "2019-04-05 13:49:50", "link": "http://arxiv.org/abs/1904.03065v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unsupervised Low Latency Speech Enhancement with RT-GCC-NMF", "abstract": "In this paper, we present RT-GCC-NMF: a real-time (RT), two-channel blind\nspeech enhancement algorithm that combines the non-negative matrix\nfactorization (NMF) dictionary learning algorithm with the generalized\ncross-correlation (GCC) spatial localization method. Using a pre-learned\nuniversal NMF dictionary, RT-GCC-NMF operates in a frame-by-frame fashion by\nassociating individual dictionary atoms to target speech or background\ninterference based on their estimated time-delay of arrivals (TDOA). We\nevaluate RT-GCC-NMF on two-channel mixtures of speech and real-world noise from\nthe Signal Separation and Evaluation Campaign (SiSEC). We demonstrate that this\napproach generalizes to new speakers, acoustic environments, and recording\nsetups from very little training data, and outperforms all but one of the\nalgorithms from the SiSEC challenge in terms of overall Perceptual Evaluation\nmethods for Audio Source Separation (PEASS) scores and compares favourably to\nthe ideal binary mask baseline. Over a wide range of input SNRs, we show that\nthis approach simultaneously improves the PEASS and signal to noise ratio\n(SNR)-based Blind Source Separation (BSS) Eval objective quality metrics as\nwell as the short-time objective intelligibility (STOI) and extended STOI\n(ESTOI) objective speech intelligibility metrics. A flexible, soft masking\nfunction in the space of NMF activation coefficients offers real-time control\nof the trade-off between interference suppression and target speaker fidelity.\nFinally, we use an asymmetric short-time Fourier transform (STFT) to reduce the\ninherent algorithmic latency of RT-GCC-NMF from 64 ms to 2 ms with no loss in\nperformance. We demonstrate that latencies within the tolerable range for\nhearing aids are possible on current hardware platforms.", "published": "2019-04-05 15:54:38", "link": "http://arxiv.org/abs/1904.03130v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Factorization of Discriminatively Trained i-vector Extractor for Speaker\n  Recognition", "abstract": "In this work, we continue in our research on i-vector extractor for speaker\nverification (SV) and we optimize its architecture for fast and effective\ndiscriminative training. We were motivated by computational and memory\nrequirements caused by the large number of parameters of the original\ngenerative i-vector model. Our aim is to preserve the power of the original\ngenerative model, and at the same time focus the model towards extraction of\nspeaker-related information. We show that it is possible to represent a\nstandard generative i-vector extractor by a model with significantly less\nparameters and obtain similar performance on SV tasks. We can further refine\nthis compact model by discriminative training and obtain i-vectors that lead to\nbetter performance on various SV benchmarks representing different acoustic\ndomains.", "published": "2019-04-05 22:04:08", "link": "http://arxiv.org/abs/1904.04235v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "WaveCycleGAN2: Time-domain Neural Post-filter for Speech Waveform\n  Generation", "abstract": "WaveCycleGAN has recently been proposed to bridge the gap between natural and\nsynthesized speech waveforms in statistical parametric speech synthesis and\nprovides fast inference with a moving average model rather than an\nautoregressive model and high-quality speech synthesis with the adversarial\ntraining. However, the human ear can still distinguish the processed speech\nwaveforms from natural ones. One possible cause of this distinguishability is\nthe aliasing observed in the processed speech waveform via down/up-sampling\nmodules. To solve the aliasing and provide higher quality speech synthesis, we\npropose WaveCycleGAN2, which 1) uses generators without down/up-sampling\nmodules and 2) combines discriminators of the waveform domain and acoustic\nparameter domain. The results show that the proposed method 1) alleviates the\naliasing well, 2) is useful for both speech waveforms generated by\nanalysis-and-synthesis and statistical parametric speech synthesis, and 3)\nachieves a mean opinion score comparable to those of natural speech and speech\nsynthesized by WaveNet (open WaveNet) and WaveGlow while processing speech\nsamples at a rate of more than 150 kHz on an NVIDIA Tesla P100.", "published": "2019-04-05 06:53:37", "link": "http://arxiv.org/abs/1904.02892v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
