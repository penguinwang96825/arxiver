{"title": "On-The-Fly Information Retrieval Augmentation for Language Models", "abstract": "Here we experiment with the use of information retrieval as an augmentation\nfor pre-trained language models. The text corpus used in information retrieval\ncan be viewed as form of episodic memory which grows over time. By augmenting\nGPT 2.0 with information retrieval we achieve a zero shot 15% relative\nreduction in perplexity on Gigaword corpus without any re-training. We also\nvalidate our IR augmentation on an event co-reference task.", "published": "2020-07-03 07:31:14", "link": "http://arxiv.org/abs/2007.01528v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Informative Dialogue Responses with Keywords-Guided Networks", "abstract": "Recently, open-domain dialogue systems have attracted growing attention. Most\nof them use the sequence-to-sequence (Seq2Seq) architecture to generate\nresponses. However, traditional Seq2Seq-based open-domain dialogue models tend\nto generate generic and safe responses, which are less informative, unlike\nhuman responses. In this paper, we propose a simple but effective\nkeywords-guided Sequence-to-Sequence model (KW-Seq2Seq) which uses keywords\ninformation as guidance to generate open-domain dialogue responses.\nSpecifically, KW-Seq2Seq first uses a keywords decoder to predict some topic\nkeywords, and then generates the final response under the guidance of them.\nExtensive experiments demonstrate that the KW-Seq2Seq model produces more\ninformative, coherent and fluent responses, yielding substantive gain in both\nautomatic and human evaluation metrics.", "published": "2020-07-03 12:47:13", "link": "http://arxiv.org/abs/2007.01652v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Playing with Words at the National Library of Sweden -- Making a Swedish\n  BERT", "abstract": "This paper introduces the Swedish BERT (\"KB-BERT\") developed by the KBLab for\ndata-driven research at the National Library of Sweden (KB). Building on recent\nefforts to create transformer-based BERT models for languages other than\nEnglish, we explain how we used KB's collections to create and train a new\nlanguage-specific BERT model for Swedish. We also present the results of our\nmodel in comparison with existing models - chiefly that produced by the Swedish\nPublic Employment Service, Arbetsf\\\"ormedlingen, and Google's multilingual\nM-BERT - where we demonstrate that KB-BERT outperforms these in a range of NLP\ntasks from named entity recognition (NER) to part-of-speech tagging (POS). Our\ndiscussion highlights the difficulties that continue to exist given the lack of\ntraining data and testbeds for smaller languages like Swedish. We release our\nmodel for further exploration and research here:\nhttps://github.com/Kungbib/swedish-bert-models .", "published": "2020-07-03 12:53:39", "link": "http://arxiv.org/abs/2007.01658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reading Comprehension in Czech via Machine Translation and Cross-lingual\n  Transfer", "abstract": "Reading comprehension is a well studied task, with huge training datasets in\nEnglish. This work focuses on building reading comprehension systems for Czech,\nwithout requiring any manually annotated Czech training data. First of all, we\nautomatically translated SQuAD 1.1 and SQuAD 2.0 datasets to Czech to create\ntraining and development data, which we release at\nhttp://hdl.handle.net/11234/1-3249. We then trained and evaluated several BERT\nand XLM-RoBERTa baseline models. However, our main focus lies in cross-lingual\ntransfer models. We report that a XLM-RoBERTa model trained on English data and\nevaluated on Czech achieves very competitive performance, only approximately 2\npercent points worse than a~model trained on the translated Czech data. This\nresult is extremely good, considering the fact that the model has not seen any\nCzech data during training. The cross-lingual transfer approach is very\nflexible and provides a reading comprehension in any language, for which we\nhave enough monolingual raw texts.", "published": "2020-07-03 13:09:37", "link": "http://arxiv.org/abs/2007.01667v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language-agnostic BERT Sentence Embedding", "abstract": "While BERT is an effective method for learning monolingual sentence\nembeddings for semantic similarity and embedding based transfer learning\n(Reimers and Gurevych, 2019), BERT based cross-lingual sentence embeddings have\nyet to be explored. We systematically investigate methods for learning\nmultilingual sentence embeddings by combining the best methods for learning\nmonolingual and cross-lingual representations including: masked language\nmodeling (MLM), translation language modeling (TLM) (Conneau and Lample, 2019),\ndual encoder translation ranking (Guo et al., 2018), and additive margin\nsoftmax (Yang et al., 2019a). We show that introducing a pre-trained\nmultilingual language model dramatically reduces the amount of parallel\ntraining data required to achieve good performance by 80%. Composing the best\nof these methods produces a model that achieves 83.7% bi-text retrieval\naccuracy over 112 languages on Tatoeba, well above the 65.5% achieved by\nArtetxe and Schwenk (2019b), while still performing competitively on\nmonolingual transfer learning benchmarks (Conneau and Kiela, 2018). Parallel\ndata mined from CommonCrawl using our best model is shown to train competitive\nNMT models for en-zh and en-de. We publicly release our best multilingual\nsentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.", "published": "2020-07-03 17:58:42", "link": "http://arxiv.org/abs/2007.01852v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "El Departamento de Nosotros: How Machine Translated Corpora Affects\n  Language Models in MRC Tasks", "abstract": "Pre-training large-scale language models (LMs) requires huge amounts of text\ncorpora. LMs for English enjoy ever growing corpora of diverse language\nresources. However, less resourced languages and their mono- and multilingual\nLMs often struggle to obtain bigger datasets. A typical approach in this case\nimplies using machine translation of English corpora to a target language. In\nthis work, we study the caveats of applying directly translated corpora for\nfine-tuning LMs for downstream natural language processing tasks and\ndemonstrate that careful curation along with post-processing lead to improved\nperformance and overall LMs robustness. In the empirical evaluation, we perform\na comparison of directly translated against curated Spanish SQuAD datasets on\nboth user and system levels. Further experimental results on XQuAD and MLQA\ntransfer-learning evaluation question answering tasks show that presumably\nmultilingual LMs exhibit more resilience to machine translation artifacts in\nterms of the exact match score.", "published": "2020-07-03 22:22:44", "link": "http://arxiv.org/abs/2007.01955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abstractive and mixed summarization for long-single documents", "abstract": "The lack of diversity in the datasets available for automatic summarization\nof documents has meant that the vast majority of neural models for automatic\nsummarization have been trained with news articles. These datasets are\nrelatively small, with an average size of about 600 words, and the models\ntrained with such data sets see their performance limited to short documents.\nIn order to surmount this problem, this paper uses scientific papers as the\ndataset on which different models are trained. These models have been chosen\nbased on their performance on the CNN/Daily Mail data set, so that the highest\nranked model of each architectural variant is selected. In this work, six\ndifferent models are compared, two with an RNN architecture, one with a CNN\narchitecture, two with a Transformer architecture and one with a Transformer\narchitecture combined with reinforcement learning. The results from this work\nshow that those models that use a hierarchical encoder to model the structure\nof the document has a better performance than the rest.", "published": "2020-07-03 19:30:28", "link": "http://arxiv.org/abs/2007.01918v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On the Relation between Quality-Diversity Evaluation and\n  Distribution-Fitting Goal in Text Generation", "abstract": "The goal of text generation models is to fit the underlying real probability\ndistribution of text. For performance evaluation, quality and diversity metrics\nare usually applied. However, it is still not clear to what extend can the\nquality-diversity evaluation reflect the distribution-fitting goal. In this\npaper, we try to reveal such relation in a theoretical approach. We prove that\nunder certain conditions, a linear combination of quality and diversity\nconstitutes a divergence metric between the generated distribution and the real\ndistribution. We also show that the commonly used BLEU/Self-BLEU metric pair\nfails to match any divergence metric, thus propose CR/NRR as a substitute for\nquality/diversity metric pair.", "published": "2020-07-03 04:06:59", "link": "http://arxiv.org/abs/2007.01488v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MIRA: Leveraging Multi-Intention Co-click Information in Web-scale\n  Document Retrieval using Deep Neural Networks", "abstract": "We study the problem of deep recall model in industrial web search, which is,\ngiven a user query, retrieve hundreds of most relevance documents from billions\nof candidates. The common framework is to train two encoding models based on\nneural embedding which learn the distributed representations of queries and\ndocuments separately and match them in the latent semantic space. However, all\nthe exiting encoding models only leverage the information of the document\nitself, which is often not sufficient in practice when matching with query\nterms, especially for the hard tail queries. In this work we aim to leverage\nthe additional information for each document from its co-click neighbour to\nhelp document retrieval. The challenges include how to effectively extract\ninformation and eliminate noise when involving co-click information in deep\nmodel while meet the demands of billion-scale data size for real time online\ninference.\n  To handle the noise in co-click relations, we firstly propose a web-scale\nMulti-Intention Co-click document Graph(MICG) which builds the co-click\nconnections between documents on click intention level but not on document\nlevel. Then we present an encoding framework MIRA based on Bert and graph\nattention networks which leverages a two-factor attention mechanism to\naggregate neighbours. To meet the online latency requirements, we only involve\nneighbour information in document side, which can save the time-consuming query\nneighbor search in real time serving. We conduct extensive offline experiments\non both public dataset and private web-scale dataset from two major commercial\nsearch engines demonstrating the effectiveness and scalability of the proposed\nmethod compared with several baselines. And a further case study reveals that\nco-click relations mainly help improve web search quality from two aspects: key\nconcept enhancing and query term complementary.", "published": "2020-07-03 06:32:48", "link": "http://arxiv.org/abs/2007.01510v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "ProtoryNet - Interpretable Text Classification Via Prototype\n  Trajectories", "abstract": "We propose a novel interpretable deep neural network for text classification,\ncalled ProtoryNet, based on a new concept of prototype trajectories. Motivated\nby the prototype theory in modern linguistics, ProtoryNet makes a prediction by\nfinding the most similar prototype for each sentence in a text sequence and\nfeeding an RNN backbone with the proximity of each sentence to the\ncorresponding active prototype. The RNN backbone then captures the temporal\npattern of the prototypes, which we refer to as prototype trajectories.\nPrototype trajectories enable intuitive and fine-grained interpretation of the\nreasoning process of the RNN model, in resemblance to how humans analyze texts.\nWe also design a prototype pruning procedure to reduce the total number of\nprototypes used by the model for better interpretability. Experiments on\nmultiple public data sets show that ProtoryNet is more accurate than the\nbaseline prototype-based deep neural net and reduces the performance gap\ncompared to state-of-the-art black-box models. In addition, after prototype\npruning, the resulting ProtoryNet models only need less than or around 20\nprototypes for all datasets, which significantly benefits interpretability.\nFurthermore, we report a survey result indicating that human users find\nProtoryNet more intuitive and easier to understand than other prototype-based\nmethods.", "published": "2020-07-03 16:00:26", "link": "http://arxiv.org/abs/2007.01777v5", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Visual Question Answering as a Multi-Task Problem", "abstract": "Visual Question Answering(VQA) is a highly complex problem set, relying on\nmany sub-problems to produce reasonable answers. In this paper, we present the\nhypothesis that Visual Question Answering should be viewed as a multi-task\nproblem, and provide evidence to support this hypothesis. We demonstrate this\nby reformatting two commonly used Visual Question Answering datasets, COCO-QA\nand DAQUAR, into a multi-task format and train these reformatted datasets on\ntwo baseline networks, with one designed specifically to eliminate other\npossible causes for performance changes as a result of the reformatting. Though\nthe networks demonstrated in this paper do not achieve strongly competitive\nresults, we find that the multi-task approach to Visual Question Answering\nresults in increases in performance of 5-9% against the single-task formatting,\nand that the networks reach convergence much faster than in the single-task\ncase. Finally we discuss possible reasons for the observed difference in\nperformance, and perform additional experiments which rule out causes not\nassociated with the learning of the dataset as a multi-task problem.", "published": "2020-07-03 16:07:13", "link": "http://arxiv.org/abs/2007.01780v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "TICO-19: the Translation Initiative for Covid-19", "abstract": "The COVID-19 pandemic is the worst pandemic to strike the world in over a\ncentury. Crucial to stemming the tide of the SARS-CoV-2 virus is communicating\nto vulnerable populations the means by which they can protect themselves. To\nthis end, the collaborators forming the Translation Initiative for COvid-19\n(TICO-19) have made test and development data available to AI and MT\nresearchers in 35 different languages in order to foster the development of\ntools and resources for improving access to information about COVID-19 in these\nlanguages. In addition to 9 high-resourced, \"pivot\" languages, the team is\ntargeting 26 lesser resourced languages, in particular languages of Africa,\nSouth Asia and South-East Asia, whose populations may be the most vulnerable to\nthe spread of the virus. The same data is translated into all of the languages\nrepresented, meaning that testing or development can be done for any pairing of\nlanguages in the set. Further, the team is converting the test and development\ndata into translation memories (TMXs) that can be used by localizers from and\nto any of the languages.", "published": "2020-07-03 16:26:17", "link": "http://arxiv.org/abs/2007.01788v2", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Exploration and Discovery of the COVID-19 Literature through Semantic\n  Visualization", "abstract": "We are developing semantic visualization techniques in order to enhance\nexploration and enable discovery over large datasets of complex networks of\nrelations. Semantic visualization is a method of enabling exploration and\ndiscovery over large datasets of complex networks by exploiting the semantics\nof the relations in them. This involves (i) NLP to extract named entities,\nrelations and knowledge graphs from the original data; (ii) indexing the output\nand creating representations for all relevant entities and relations that can\nbe visualized in many different ways, e.g., as tag clouds, heat maps, graphs,\netc.; (iii) applying parameter reduction operations to the extracted relations,\ncreating \"relation containers\", or functional entities that can also be\nvisualized using the same methods, allowing the visualization of multiple\nrelations, partial pathways, and exploration across multiple dimensions. Our\nhope is that this will enable the discovery of novel inferences over relations\nin complex data that otherwise would go unnoticed. We have applied this to\nanalysis of the recently released CORD-19 dataset.", "published": "2020-07-03 16:40:37", "link": "http://arxiv.org/abs/2007.01800v1", "categories": ["cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Pretrained Semantic Speech Embeddings for End-to-End Spoken Language\n  Understanding via Cross-Modal Teacher-Student Learning", "abstract": "Spoken language understanding is typically based on pipeline architectures\nincluding speech recognition and natural language understanding steps. These\ncomponents are optimized independently to allow usage of available data, but\nthe overall system suffers from error propagation. In this paper, we propose a\nnovel training method that enables pretrained contextual embeddings to process\nacoustic features. In particular, we extend it with an encoder of pretrained\nspeech recognition systems in order to construct end-to-end spoken language\nunderstanding systems. Our proposed method is based on the teacher-student\nframework across speech and text modalities that aligns the acoustic and the\nsemantic latent spaces. Experimental results in three benchmarks show that our\nsystem reaches the performance comparable to the pipeline architecture without\nusing any training data and outperforms it after fine-tuning with ten examples\nper class on two out of three benchmarks.", "published": "2020-07-03 17:43:12", "link": "http://arxiv.org/abs/2007.01836v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Distortionless Multi-Channel Target Speech Enhancement for Overlapped\n  Speech Recognition", "abstract": "Speech enhancement techniques based on deep learning have brought significant\nimprovement on speech quality and intelligibility. Nevertheless, a large gain\nin speech quality measured by objective metrics, such as perceptual evaluation\nof speech quality (PESQ), does not necessarily lead to improved speech\nrecognition performance due to speech distortion in the enhancement stage. In\nthis paper, a multi-channel dilated convolutional network based frequency\ndomain modeling is presented to enhance target speaker in the far-field, noisy\nand multi-talker conditions. We study three approaches towards distortionless\nwaveforms for overlapped speech recognition: estimating complex ideal ratio\nmask with an infinite range, incorporating the fbank loss in a multi-objective\nlearning and finetuning the enhancement model by an acoustic model.\nExperimental results proved the effectiveness of all three approaches on\nreducing speech distortions and improving recognition accuracy. Particularly,\nthe jointly tuned enhancement model works very well with other standalone\nacoustic model on real test data.", "published": "2020-07-03 09:23:46", "link": "http://arxiv.org/abs/2007.01566v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Online Supervised Acoustic System Identification exploiting Prelearned\n  Local Affine Subspace Models", "abstract": "In this paper we present a novel algorithm for improved block-online\nsupervised acoustic system identification in adverse noise scenarios by\nexploiting prior knowledge about the space of Room Impulse Responses (RIRs).\nThe method is based on the assumption that the variability of the unknown RIRs\nis controlled by only few physical parameters, describing, e.g., source\nposition movements, and thus is confined to a low-dimensional manifold which is\nmodelled by a union of affine subspaces. The offsets and bases of the affine\nsubspaces are learned in advance from training data by unsupervised clustering\nfollowed by Principal Component Analysis. We suggest to denoise the parameter\nupdate of any supervised adaptive filter by projecting it onto an optimal\naffine subspace which is selected based on a novel computationally efficient\napproximation of the associated evidence. The proposed method significantly\nimproves the system identification performance of state-of-the-art algorithms\nin adverse noise scenarios.", "published": "2020-07-03 08:05:03", "link": "http://arxiv.org/abs/2007.01543v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Noise-Robust Adaptation Control for Supervised Acoustic System\n  Identification Exploiting A Noise Dictionary", "abstract": "We present a noise-robust adaptation control strategy for block-online\nsupervised acoustic system identification by exploiting a noise dictionary. The\nproposed algorithm takes advantage of the pronounced spectral structure which\ncharacterizes many types of interfering noise signals. We model the noisy\nobservations by a linear Gaussian Discrete Fourier Transform-domain state space\nmodel whose parameters are estimated by an online generalized\nExpectation-Maximization algorithm. Unlike all other state-of-the-art\napproaches we suggest to model the covariance matrix of the observation\nprobability density function by a dictionary model. We propose to learn the\nnoise dictionary from training data, which can be gathered either offline or\nonline whenever the system is not excited, while we infer the activations\ncontinuously. The proposed algorithm represents a novel machine-learning based\napproach to noise-robust adaptation control which allows for faster convergence\nin applications characterized by high-level and non-stationary interfering\nnoise signals and abrupt system changes.", "published": "2020-07-03 09:47:35", "link": "http://arxiv.org/abs/2007.01579v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
