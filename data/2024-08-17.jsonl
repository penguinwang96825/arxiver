{"title": "Method of Moments Estimation for Affine Stochastic Volatility Models", "abstract": "We develop moment estimators for the parameters of affine stochastic\nvolatility models. We first address the challenge of calculating moments for\nthe models by introducing a recursive equation for deriving closed-form\nexpressions for moments of any order. Consequently, we propose our moment\nestimators. We then establish a central limit theorem for our estimators and\nderive the explicit formulas for the asymptotic covariance matrix. Finally, we\nprovide numerical results to validate our method.", "published": "2024-08-17 12:29:55", "link": "http://arxiv.org/abs/2408.09185v1", "categories": ["q-fin.ST", "econ.EM"], "primary_category": "q-fin.ST"}
{"title": "Automatic Metrics in Natural Language Generation: A Survey of Current\n  Evaluation Practices", "abstract": "Automatic metrics are extensively used to evaluate natural language\nprocessing systems. However, there has been increasing focus on how they are\nused and reported by practitioners within the field. In this paper, we have\nconducted a survey on the use of automatic metrics, focusing particularly on\nnatural language generation (NLG) tasks. We inspect which metrics are used as\nwell as why they are chosen and how their use is reported. Our findings from\nthis survey reveal significant shortcomings, including inappropriate metric\nusage, lack of implementation details and missing correlations with human\njudgements. We conclude with recommendations that we believe authors should\nfollow to enable more rigour within the field.", "published": "2024-08-17 11:13:10", "link": "http://arxiv.org/abs/2408.09169v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TableBench: A Comprehensive and Complex Benchmark for Table Question\n  Answering", "abstract": "Recent advancements in Large Language Models (LLMs) have markedly enhanced\nthe interpretation and processing of tabular data, introducing previously\nunimaginable capabilities. Despite these achievements, LLMs still encounter\nsignificant challenges when applied in industrial scenarios, particularly due\nto the increased complexity of reasoning required with real-world tabular data,\nunderscoring a notable disparity between academic benchmarks and practical\napplications. To address this discrepancy, we conduct a detailed investigation\ninto the application of tabular data in industrial scenarios and propose a\ncomprehensive and complex benchmark TableBench, including 18 fields within four\nmajor categories of table question answering (TableQA) capabilities.\nFurthermore, we introduce TableLLM, trained on our meticulously constructed\ntraining set TableInstruct, achieving comparable performance with GPT-3.5.\nMassive experiments conducted on TableBench indicate that both open-source and\nproprietary LLMs still have significant room for improvement to meet real-world\ndemands, where the most advanced model, GPT-4, achieves only a modest score\ncompared to humans.", "published": "2024-08-17 11:40:10", "link": "http://arxiv.org/abs/2408.09174v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConVerSum: A Contrastive Learning-based Approach for Data-Scarce\n  Solution of Cross-Lingual Summarization Beyond Direct Equivalents", "abstract": "Cross-lingual summarization (CLS) is a sophisticated branch in Natural\nLanguage Processing that demands models to accurately translate and summarize\narticles from different source languages. Despite the improvement of the\nsubsequent studies, This area still needs data-efficient solutions along with\neffective training methodologies. To the best of our knowledge, there is no\nfeasible solution for CLS when there is no available high-quality CLS data. In\nthis paper, we propose a novel data-efficient approach, ConVerSum, for CLS\nleveraging the power of contrastive learning, generating versatile candidate\nsummaries in different languages based on the given source document and\ncontrasting these summaries with reference summaries concerning the given\ndocuments. After that, we train the model with a contrastive ranking loss.\nThen, we rigorously evaluate the proposed approach against current\nmethodologies and compare it to powerful Large Language Models (LLMs)- Gemini,\nGPT 3.5, and GPT 4o proving our model performs better for low-resource\nlanguages' CLS. These findings represent a substantial improvement in the area,\nopening the door to more efficient and accurate cross-lingual summarizing\ntechniques.", "published": "2024-08-17 19:03:53", "link": "http://arxiv.org/abs/2408.09273v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CyberPal.AI: Empowering LLMs with Expert-Driven Cybersecurity\n  Instructions", "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing (NLP), providing versatile capabilities across various applications.\nHowever, their application to complex, domain-specific tasks, such as\ncyber-security, often faces substantial challenges. In this study, we introduce\nSecKnowledge and CyberPal.AI to address these challenges and train\nsecurity-expert LLMs. SecKnowledge is a domain-knowledge-driven cyber-security\ninstruction dataset, meticulously designed using years of accumulated expert\nknowledge in the domain through a multi-phase generation process. CyberPal.AI\nrefers to a family of LLMs fine-tuned using SecKnowledge, aimed at building\nsecurity-specialized LLMs capable of answering and following complex\nsecurity-related instructions. Additionally, we introduce SecKnowledge-Eval, a\ncomprehensive and diverse cyber-security evaluation benchmark, composed of an\nextensive set of cyber-security tasks we specifically developed to assess LLMs\nin the field of cyber-security, along with other publicly available security\nbenchmarks. Our results show a significant average improvement of up to 24%\nover the baseline models, underscoring the benefits of our expert-driven\ninstruction dataset generation process. These findings contribute to the\nadvancement of AI-based cyber-security applications, paving the way for\nsecurity-expert LLMs that can enhance threat-hunting and investigation\nprocesses.", "published": "2024-08-17 22:37:39", "link": "http://arxiv.org/abs/2408.09304v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Open-Source American Sign Language Fingerspell Recognition and\n  Semantic Pose Retrieval Interface", "abstract": "This paper introduces an open-source interface for American Sign Language\nfingerspell recognition and semantic pose retrieval, aimed to serve as a\nstepping stone towards more advanced sign language translation systems.\nUtilizing a combination of convolutional neural networks and pose estimation\nmodels, the interface provides two modular components: a recognition module for\ntranslating ASL fingerspelling into spoken English and a production module for\nconverting spoken English into ASL pose sequences. The system is designed to be\nhighly accessible, user-friendly, and capable of functioning in real-time under\nvarying environmental conditions like backgrounds, lighting, skin tones, and\nhand sizes. We discuss the technical details of the model architecture,\napplication in the wild, as well as potential future enhancements for\nreal-world consumer applications.", "published": "2024-08-17 23:59:17", "link": "http://arxiv.org/abs/2408.09311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CodeTaxo: Enhancing Taxonomy Expansion with Limited Examples via Code\n  Language Prompts", "abstract": "Taxonomies play a crucial role in various applications by providing a\nstructural representation of knowledge. The task of taxonomy expansion involves\nintegrating emerging concepts into existing taxonomies by identifying\nappropriate parent concepts for these new query concepts. Previous approaches\ntypically relied on self-supervised methods that generate annotation data from\nexisting taxonomies. However, these methods are less effective when the\nexisting taxonomy is small (fewer than 100 entities). In this work, we\nintroduce \\textsc{CodeTaxo}, a novel approach that leverages large language\nmodels through code language prompts to capture the taxonomic structure.\nExtensive experiments on five real-world benchmarks from different domains\ndemonstrate that \\textsc{CodeTaxo} consistently achieves superior performance\nacross all evaluation metrics, significantly outperforming previous\nstate-of-the-art methods. The code and data are available at\n\\url{https://github.com/QingkaiZeng/CodeTaxo-Pub}.", "published": "2024-08-17 02:15:07", "link": "http://arxiv.org/abs/2408.09070v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Improving Rare Word Translation With Dictionaries and Attention Masking", "abstract": "In machine translation, rare words continue to be a problem for the dominant\nencoder-decoder architecture, especially in low-resource and out-of-domain\ntranslation settings. Human translators solve this problem with monolingual or\nbilingual dictionaries. In this paper, we propose appending definitions from a\nbilingual dictionary to source sentences and using attention masking to link\ntogether rare words with their definitions. We find that including definitions\nfor rare words improves performance by up to 1.0 BLEU and 1.6 MacroF1.", "published": "2024-08-17 02:26:29", "link": "http://arxiv.org/abs/2408.09075v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CogLM: Tracking Cognitive Development of Large Language Models", "abstract": "Piaget's Theory of Cognitive Development (PTC) posits that the development of\ncognitive levels forms the foundation for human learning across various\nabilities. As Large Language Models (LLMs) have recently shown remarkable\nabilities across a wide variety of tasks, we are curious about the cognitive\nlevels of current LLMs: to what extent they have developed and how this\ndevelopment has been achieved. To this end, we construct a benchmark CogLM\n(Cognitive Ability Evaluation for Language Model) based on PTC to assess the\ncognitive levels of LLMs. CogLM comprises 1,220 questions spanning 10 cognitive\nabilities crafted by more than 20 human experts, providing a comprehensive\ntestbed for the cognitive levels of LLMs. Through extensive experiments across\nmultiple mainstream LLMs with CogLM, we find that: (1) In our testing\nframework, advanced LLMs (such as GPT-4) have demonstrated human-like cognitive\nabilities, comparable to those of a 20-year-old human. (2) The parameter size\nand optimization objective are two key factors affecting the cognitive levels\nof LLMs. (3) The performance on downstream tasks is positively correlated with\nthe level of cognitive abilities. These findings fill the gap in research on\nthe cognitive abilities of LLMs, tracing the development of LLMs from a\ncognitive perspective and guiding the future direction of their evolution.", "published": "2024-08-17 09:49:40", "link": "http://arxiv.org/abs/2408.09150v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unlocking the Power of LLM Uncertainty for Active In-Context Example\n  Selection", "abstract": "Large Language Models (LLMs) have shown remarkable performance across a wide\nrange of downstream tasks. However, it is challenging for users to discern\nwhether the responses of LLM are generated with certainty or are fabricated to\nmeet user expectations. In this paper, we introduce Uncertainty Tripartite\nTesting Paradigm (Unc-TTP), a novel method for classifying LLM uncertainty by\nleveraging output inconsistency. Specifically, Unc-TTP performs three rounds of\nsampling under varying label injection interference, enumerating all possible\noutcomes, and uses the degree of output inconsistency as the indicator of the\nLLM's intrinsic uncertainty. To validate the effectiveness of this\ninconsistency-defined uncertainty, we draw inspiration from Active Learning,\ncomparing the informativeness of actively selected in-context examples. Our\nexperiments show that uncertainty examples selected via Unc-TTP are more\ninformative than certainty examples. Furthermore, the Unc-TTP-guided\nuncertainty-based active example selection strategy outperforms existing\nmethods, highlighting its effectiveness in classifying LLM uncertainty and\nenhancing in-context learning. This work not only underscores the potential of\ninconsistency-based uncertainty classification for both open- and closed-source\nLLMs but also presents a practical approach for leveraging uncertainty to\nimprove LLM performance in real-world tasks.", "published": "2024-08-17 11:33:23", "link": "http://arxiv.org/abs/2408.09172v4", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Chinese Metaphor Recognition Using a Multi-stage Prompting Large\n  Language Model", "abstract": "Metaphors are common in everyday language, and the identification and\nunderstanding of metaphors are facilitated by models to achieve a better\nunderstanding of the text. Metaphors are mainly identified and generated by\npre-trained models in existing research, but situations, where tenors or\nvehicles are not included in the metaphor, cannot be handled. The problem can\nbe effectively solved by using Large Language Models (LLMs), but significant\nroom for exploration remains in this early-stage research area. A multi-stage\ngenerative heuristic-enhanced prompt framework is proposed in this study to\nenhance the ability of LLMs to recognize tenors, vehicles, and grounds in\nChinese metaphors. In the first stage, a small model is trained to obtain the\nrequired confidence score for answer candidate generation. In the second stage,\nquestions are clustered and sampled according to specific rules. Finally, the\nheuristic-enhanced prompt needed is formed by combining the generated answer\ncandidates and demonstrations. The proposed model achieved 3rd place in Track 1\nof Subtask 1, 1st place in Track 2 of Subtask 1, and 1st place in both tracks\nof Subtask 2 at the NLPCC-2024 Shared Task 9.", "published": "2024-08-17 11:56:38", "link": "http://arxiv.org/abs/2408.09177v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AI Managed Emergency Documentation with a Pretrained Model", "abstract": "This study investigates the use of a large language model system to improve\nefficiency and quality in emergency department (ED) discharge letter writing.\nTime constraints and infrastructural deficits make compliance with current\ndischarge letter targets difficult. We explored potential efficiencies from an\nartificial intelligence software in the generation of ED discharge letters and\nthe attitudes of doctors toward this technology. The evaluated system leverages\nadvanced techniques to fine-tune a model to generate discharge summaries from\nshort-hand inputs, including voice, text, and electronic health record data.\nNineteen physicians with emergency medicine experience evaluated the system\ntext and voice-to-text interfaces against manual typing. The results showed\nsignificant time savings with MedWrite LLM interfaces compared to manual\nmethods.", "published": "2024-08-17 13:11:46", "link": "http://arxiv.org/abs/2408.09193v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Architectural Foundations for the Large Language Model Infrastructures", "abstract": "The development of a large language model (LLM) infrastructure is a pivotal\nundertaking in artificial intelligence. This paper explores the intricate\nlandscape of LLM infrastructure, software, and data management. By analyzing\nthese core components, we emphasize the pivotal considerations and safeguards\ncrucial for successful LLM development. This work presents a concise synthesis\nof the challenges and strategies inherent in constructing a robust and\neffective LLM infrastructure, offering valuable insights for researchers and\npractitioners alike.", "published": "2024-08-17 13:54:34", "link": "http://arxiv.org/abs/2408.09205v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of\n  Free-Form Text", "abstract": "The emergence of Large Language Models (LLMs) as chat assistants capable of\ngenerating human-like conversations has amplified the need for robust\nevaluation methods, particularly for open-ended tasks. Conventional metrics\nlike BLEU and ROUGE, while useful, are increasingly inadequate for capturing\nthe subtle semantics and contextual richness of such generative outputs. We\npropose a reference-guided verdict method that automates the evaluation process\nby leveraging multiple LLMs-as-judges. Through experiments on three open-ended\nquestion-answering tasks, we demonstrate that combining multiple LLMs-as-judges\nsignificantly improves the reliability and accuracy of evaluations,\nparticularly in complex tasks where a single model might struggle. Our findings\nreveal a strong correlation with human evaluations, establishing our method as\na viable and effective alternative to traditional metrics and human judgments,\nparticularly in the context of LLM-based chat assistants where the complexity\nand diversity of responses challenge existing benchmarks.", "published": "2024-08-17 16:01:45", "link": "http://arxiv.org/abs/2408.09235v2", "categories": ["cs.CL", "cs.AI", "68T50, 68T07, 68T20", "I.2.0; I.2.7; I.2.2"], "primary_category": "cs.CL"}
{"title": "Sentiment analysis of preservice teachers' reflections using a large\n  language model", "abstract": "In this study, the emotion and tone of preservice teachers' reflections were\nanalyzed using sentiment analysis with LLMs: GPT-4, Gemini, and BERT. We\ncompared the results to understand how each tool categorizes and describes\nindividual reflections and multiple reflections as a whole. This study aims to\nexplore ways to bridge the gaps between qualitative, quantitative, and\ncomputational analyses of reflective practices in teacher education. This study\nfinds that to effectively integrate LLM analysis into teacher education,\ndeveloping an analysis method and result format that are both comprehensive and\nrelevant for preservice teachers and teacher educators is crucial.", "published": "2024-08-17 01:56:15", "link": "http://arxiv.org/abs/2408.11862v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Measuring Agreeableness Bias in Multimodal Models", "abstract": "This paper examines a phenomenon in multimodal language models where\npre-marked options in question images can significantly influence model\nresponses. Our study employs a systematic methodology to investigate this\neffect: we present models with images of multiple-choice questions, which they\ninitially answer correctly, then expose the same model to versions with\npre-marked options. Our findings reveal a significant shift in the models'\nresponses towards the pre-marked option, even when it contradicts their answers\nin the neutral settings. Comprehensive evaluations demonstrate that this\nagreeableness bias is a consistent and quantifiable behavior across various\nmodel architectures. These results show potential limitations in the\nreliability of these models when processing images with pre-marked options,\nraising important questions about their application in critical decision-making\ncontexts where such visual cues might be present.", "published": "2024-08-17 06:25:36", "link": "http://arxiv.org/abs/2408.09111v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Selective Prompt Anchoring for Code Generation", "abstract": "Recent advances in large language models (LLMs) have transformed software\ndevelopment by automatically generating code from natural language. Yet\nchallenges remain in generating fully correct code that aligns with user\nintent. Our study reveals that LLMs tend to pay less attention to user prompts\nas more code tokens are generated. We hypothesize that this attention dilution\nissue is an important reason for code generation errors. To mitigate this\nissue, we propose Selective Prompt Anchoring (SPA) to guide code LLMs to pay\nmore attention to user intent when generating code. We evaluate SPA using six\nbase LLMs across six benchmarks. Our results demonstrate that SPA enhances\nPass@1 by up to 12.9%, consistently outperforming SOTA code generation methods\nin all settings. Our code is available at\nhttps://github.com/magic-YuanTian/Selective-Prompt-Anchoring.", "published": "2024-08-17 07:11:02", "link": "http://arxiv.org/abs/2408.09121v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Cognitive LLMs: Towards Integrating Cognitive Architectures and Large\n  Language Models for Manufacturing Decision-making", "abstract": "Resolving the dichotomy between the human-like yet constrained reasoning\nprocesses of Cognitive Architectures and the broad but often noisy inference\nbehavior of Large Language Models (LLMs) remains a challenging but exciting\npursuit, for enabling reliable machine reasoning capabilities in production\nsystems. Because Cognitive Architectures are famously developed for the purpose\nof modeling the internal mechanisms of human cognitive decision-making at a\ncomputational level, new investigations consider the goal of informing LLMs\nwith the knowledge necessary for replicating such processes, e.g., guided\nperception, memory, goal-setting, and action. Previous approaches that use LLMs\nfor grounded decision-making struggle with complex reasoning tasks that require\nslower, deliberate cognition over fast and intuitive inference -- reporting\nissues related to the lack of sufficient grounding, as in hallucination. To\nresolve these challenges, we introduce LLM-ACTR, a novel neuro-symbolic\narchitecture that provides human-aligned and versatile decision-making by\nintegrating the ACT-R Cognitive Architecture with LLMs. Our framework extracts\nand embeds knowledge of ACT-R's internal decision-making process as latent\nneural representations, injects this information into trainable LLM adapter\nlayers, and fine-tunes the LLMs for downstream prediction. Our experiments on\nnovel Design for Manufacturing tasks show both improved task performance as\nwell as improved grounded decision-making capability of our approach, compared\nto LLM-only baselines that leverage chain-of-thought reasoning strategies.", "published": "2024-08-17 11:49:53", "link": "http://arxiv.org/abs/2408.09176v1", "categories": ["cs.AI", "cs.CL", "cs.SC"], "primary_category": "cs.AI"}
{"title": "Generating Data with Text-to-Speech and Large-Language Models for\n  Conversational Speech Recognition", "abstract": "Currently, a common approach in many speech processing tasks is to leverage\nlarge scale pre-trained models by fine-tuning them on in-domain data for a\nparticular application. Yet obtaining even a small amount of such data can be\nproblematic, especially for sensitive domains and conversational speech\nscenarios, due to both privacy issues and annotation costs. To address this,\nsynthetic data generation using single speaker datasets has been employed. Yet,\nfor multi-speaker cases, such an approach often requires extensive manual\neffort and is prone to domain mismatches. In this work, we propose a synthetic\ndata generation pipeline for multi-speaker conversational ASR, leveraging a\nlarge language model (LLM) for content creation and a conversational\nmulti-speaker text-to-speech (TTS) model for speech synthesis. We conduct\nevaluation by fine-tuning the Whisper ASR model for telephone and distant\nconversational speech settings, using both in-domain data and generated\nsynthetic data. Our results show that the proposed method is able to\nsignificantly outperform classical multi-speaker generation approaches that use\nexternal, non-conversational speech datasets.", "published": "2024-08-17 14:47:05", "link": "http://arxiv.org/abs/2408.09215v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Unraveling Text Generation in LLMs: A Stochastic Differential Equation\n  Approach", "abstract": "This paper explores the application of Stochastic Differential Equations\n(SDE) to interpret the text generation process of Large Language Models (LLMs)\nsuch as GPT-4. Text generation in LLMs is modeled as a stochastic process where\neach step depends on previously generated content and model parameters,\nsampling the next word from a vocabulary distribution. We represent this\ngeneration process using SDE to capture both deterministic trends and\nstochastic perturbations. The drift term describes the deterministic trends in\nthe generation process, while the diffusion term captures the stochastic\nvariations. We fit these functions using neural networks and validate the model\non real-world text corpora. Through numerical simulations and comprehensive\nanalyses, including drift and diffusion analysis, stochastic process property\nevaluation, and phase space exploration, we provide deep insights into the\ndynamics of text generation. This approach not only enhances the understanding\nof the inner workings of LLMs but also offers a novel mathematical perspective\non language generation, which is crucial for diagnosing, optimizing, and\ncontrolling the quality of generated text.", "published": "2024-08-17 15:30:27", "link": "http://arxiv.org/abs/2408.11863v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "How Susceptible are LLMs to Influence in Prompts?", "abstract": "Large Language Models (LLMs) are highly sensitive to prompts, including\nadditional context provided therein. As LLMs grow in capability, understanding\ntheir prompt-sensitivity becomes increasingly crucial for ensuring reliable and\nrobust performance, particularly since evaluating these models becomes more\nchallenging. In this work, we investigate how current models (Llama, Mixtral,\nFalcon) respond when presented with additional input from another model,\nmimicking a scenario where a more capable model -- or a system with access to\nmore external information -- provides supplementary information to the target\nmodel. Across a diverse spectrum of question-answering tasks, we study how an\nLLM's response to multiple-choice questions changes when the prompt includes a\nprediction and explanation from another model. Specifically, we explore the\ninfluence of the presence of an explanation, the stated authoritativeness of\nthe source, and the stated confidence of the supplementary input. Our findings\nreveal that models are strongly influenced, and when explanations are provided\nthey are swayed irrespective of the quality of the explanation. The models are\nmore likely to be swayed if the input is presented as being authoritative or\nconfident, but the effect is small in size. This study underscores the\nsignificant prompt-sensitivity of LLMs and highlights the potential risks of\nincorporating outputs from external sources without thorough scrutiny and\nfurther validation. As LLMs continue to advance, understanding and mitigating\nsuch sensitivities will be crucial for their reliable and trustworthy\ndeployment.", "published": "2024-08-17 17:40:52", "link": "http://arxiv.org/abs/2408.11865v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Audio-Language Models through Self-Supervised Post-Training\n  with Text-Audio Pairs", "abstract": "Research on multi-modal contrastive learning strategies for audio and text\nhas rapidly gained interest. Contrastively trained Audio-Language Models\n(ALMs), such as CLAP, which establish a unified representation across audio and\nlanguage modalities, have enhanced the efficacy in various subsequent tasks by\nproviding good text aligned audio encoders and vice versa. These improvements\nare evident in areas like zero-shot audio classification and audio retrieval,\namong others. However, the ability of these models to understand natural\nlanguage and temporal relations is still a largely unexplored and open field\nfor research. In this paper, we propose to equip the multi-modal ALMs with\ntemporal understanding without loosing their inherent prior capabilities of\naudio-language tasks with a temporal instillation method TeminAL. We implement\na two-stage training scheme TeminAL A $\\&$ B, where the model first learns to\ndifferentiate between multiple sounds in TeminAL A, followed by a phase that\ninstills a sense of time, thereby enhancing its temporal understanding in\nTeminAL B. This approach results in an average performance gain of $5.28\\%$ in\ntemporal understanding on the ESC-50 dataset, while the model remains\ncompetitive in zero-shot retrieval and classification tasks on the\nAudioCap/Clotho datasets. We also note the lack of proper evaluation techniques\nfor contrastive ALMs and propose a strategy for evaluating ALMs in zero-shot\nsettings. The general-purpose zero-shot model evaluation strategy ZSTE, is used\nto evaluate various prior models. ZSTE demonstrates a general strategy to\nevaluate all ZS contrastive models. The model trained with TeminAL successfully\noutperforms current models on most downstream tasks.", "published": "2024-08-17 18:53:17", "link": "http://arxiv.org/abs/2408.09269v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Malacopula: adversarial automatic speaker verification attacks using a\n  neural-based generalised Hammerstein model", "abstract": "We present Malacopula, a neural-based generalised Hammerstein model designed\nto introduce adversarial perturbations to spoofed speech utterances so that\nthey better deceive automatic speaker verification (ASV) systems. Using\nnon-linear processes to modify speech utterances, Malacopula enhances the\neffectiveness of spoofing attacks. The model comprises parallel branches of\npolynomial functions followed by linear time-invariant filters. The adversarial\noptimisation procedure acts to minimise the cosine distance between speaker\nembeddings extracted from spoofed and bona fide utterances. Experiments,\nperformed using three recent ASV systems and the ASVspoof 2019 dataset, show\nthat Malacopula increases vulnerabilities by a substantial margin. However,\nspeech quality is reduced and attacks can be detected effectively under\ncontrolled conditions. The findings emphasise the need to identify new\nvulnerabilities and design defences to protect ASV systems from adversarial\nattacks in the wild.", "published": "2024-08-17 21:58:11", "link": "http://arxiv.org/abs/2408.09300v1", "categories": ["eess.AS", "cs.CR", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
