{"title": "Quantifying Gender Bias in Consumer Culture", "abstract": "Cultural items like songs have an important impact in creating and\nreinforcing stereotypes, biases, and discrimination. But the actual nature of\nsuch items is often less transparent. Take songs, for example. Are lyrics\nbiased against women? And how have any such biases changed over time? Natural\nlanguage processing of a quarter of a million songs over 50 years quantifies\nmisogyny. Women are less likely to be associated with desirable traits (i.e.,\ncompetence), and while this bias has decreased, it persists. Ancillary analyses\nfurther suggest that song lyrics may help drive shifts in societal stereotypes\ntowards women, and that lyrical shifts are driven by male artists (as female\nartists were less biased to begin with). Overall, these results shed light on\ncultural evolution, subtle measures of bias and discrimination, and how natural\nlanguage processing and machine learning can provide deeper insight into\nstereotypes and cultural change.", "published": "2022-01-10 05:44:54", "link": "http://arxiv.org/abs/2201.03173v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style, Content, and the Success of Ideas", "abstract": "Why do some things succeed in the marketplace of ideas? While some argue that\ncontent drives success, others suggest that style, or the way ideas are\npresented, also plays an important role. To provide a stringent test of style's\nimportance, we examine it in a context where content should be paramount:\nacademic research. While scientists often see writing as a disinterested way to\ncommunicate unobstructed truth, a multi-method investigation indicates that\nwriting style shapes impact. Separating style from content can be difficult as\npapers that tend to use certain language may also write about certain topics.\nConsequently, we focus on a unique class of words linked to style (i.e.,\nfunction words such as \"and,\" \"the,\" and \"on\") that are completely devoid of\ncontent. Natural language processing of almost 30,000 articles from a range of\ndisciplines finds that function words explain 13-27% of language's impact on\ncitations. Ancillary analyses explore specific categories of function words to\nsuggest how style matters, highlighting the role of writing simplicity,\npersonal voice, and temporal perspective. Experiments further underscore the\ncausal impact of style. The results suggest how to boost communication's impact\nand highlight the value of natural language processing for understanding the\nsuccess of ideas.", "published": "2022-01-10 05:53:26", "link": "http://arxiv.org/abs/2201.03174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Writing Style Aware Document-level Event Extraction", "abstract": "Event extraction, the technology that aims to automatically get the\nstructural information from documents, has attracted more and more attention in\nmany fields. Most existing works discuss this issue with the token-level\nmulti-label classification framework by distinguishing the tokens as different\nroles while ignoring the writing styles of documents. The writing style is a\nspecial way of content organizing for documents and it is relative fixed in\ndocuments with a special field (e.g. financial, medical documents, etc.). We\nargue that the writing style contains important clues for judging the roles for\ntokens and the ignorance of such patterns might lead to the performance\ndegradation for the existing works. To this end, we model the writing style in\ndocuments as a distribution of argument roles, i.e., Role-Rank Distribution,\nand propose an event extraction model with the Role-Rank Distribution based\nSupervision Mechanism to capture this pattern through the supervised training\nprocess of an event extraction task. We compare our model with state-of-the-art\nmethods on several real-world datasets. The empirical results show that our\napproach outperforms other alternatives with the captured patterns. This\nverifies the writing style contains valuable information that could improve the\nperformance of the event extraction task.", "published": "2022-01-10 06:54:06", "link": "http://arxiv.org/abs/2201.03188v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "There is no rose without a thorn: Finding weaknesses on BlenderBot 2.0\n  in terms of Model, Data and User-Centric Approach", "abstract": "BlenderBot 2.0 is a dialogue model that represents open-domain chatbots by\nreflecting real-time information and remembering user information for an\nextended period using an internet search module and multi-session. Nonetheless,\nthe model still has room for improvement. To this end, we examine BlenderBot\n2.0 limitations and errors from three perspectives: model, data, and user. From\nthe data point of view, we highlight the unclear guidelines provided to workers\nduring the crowdsourcing process, as well as a lack of a process for refining\nhate speech in the collected data and verifying the accuracy of internet-based\ninformation. From a user perspective, we identify nine types of limitations of\nBlenderBot 2.0, and their causes are thoroughly investigated. Furthermore, for\neach point of view, we propose practical improvement methods and discuss\nseveral potential future research directions.", "published": "2022-01-10 09:52:00", "link": "http://arxiv.org/abs/2201.03239v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latency Adjustable Transformer Encoder for Language Understanding", "abstract": "Adjusting the latency, power, and accuracy of natural language understanding\nmodels is a desirable objective of an efficient architecture. This paper\nproposes an efficient Transformer architecture that adjusts the inference\ncomputational cost adaptively with a desired inference latency speedup. In\nfine-tuning phase, the proposed method detects less important hidden sequence\nelements (word-vectors) and eliminates them in each encoder layer using a\nproposed Attention Context Contribution (ACC) metric. After the fine-tuning\nphase, with the novel offline-tuning property, the inference latency of the\nmodel can be adjusted in a wide range of inference speedup selections without\nany further training. Extensive experiments reveal that most word-vectors in\nhigher Transformer layers contribute less to subsequent layers, allowing their\nremoval to improve inference latency. Experimental results on various language\nunderstanding, text generation, and instruction tuning tasks and benchmarks\ndemonstrate the approach's effectiveness across diverse datasets, with minimal\nimpact on the input's global context. The technique improves\nTime-to-First-Token (TTFT) of Llama3 by up to 2.9x, with minor performance\ndrop. The suggested approach posits that in Large Language Models (LLMs),\nalthough the complete network is necessary for training, it can be truncated\nduring the fine-tuning phase.", "published": "2022-01-10 13:04:39", "link": "http://arxiv.org/abs/2201.03327v9", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives", "abstract": "BERT has revolutionized the NLP field by enabling transfer learning with\nlarge language models that can capture complex textual patterns, reaching the\nstate-of-the-art for an expressive number of NLP applications. For text\nclassification tasks, BERT has already been extensively explored. However,\naspects like how to better cope with the different embeddings provided by the\nBERT output layer and the usage of language-specific instead of multilingual\nmodels are not well studied in the literature, especially for the Brazilian\nPortuguese language. The purpose of this article is to conduct an extensive\nexperimental study regarding different strategies for aggregating the features\nproduced in the BERT output layer, with a focus on the sentiment analysis task.\nThe experiments include BERT models trained with Brazilian Portuguese corpora\nand the multilingual version, contemplating multiple aggregation strategies and\nopen-source datasets with predefined training, validation, and test partitions\nto facilitate the reproducibility of the results. BERT achieved the highest\nROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless,\nTF-IDF represents a good trade-off between the predictive performance and\ncomputational cost.", "published": "2022-01-10 15:05:05", "link": "http://arxiv.org/abs/2201.03382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Plagiarism Detection Systems: Case of Use with English,\n  French and Arabic Languages", "abstract": "In academia, plagiarism is certainly not an emerging concern, but it became\nof a greater magnitude with the popularisation of the Internet and the ease of\naccess to a worldwide source of content, rendering human-only intervention\ninsufficient. Despite that, plagiarism is far from being an unaddressed\nproblem, as computer-assisted plagiarism detection is currently an active area\nof research that falls within the field of Information Retrieval (IR) and\nNatural Language Processing (NLP). Many software solutions emerged to help\nfulfil this task, and this paper presents an overview of plagiarism detection\nsystems for use in Arabic, French, and English academic and educational\nsettings. The comparison was held between eight systems and was performed with\nrespect to their features, usability, technical aspects, as well as their\nperformance in detecting three levels of obfuscation from different sources:\nverbatim, paraphrase, and cross-language plagiarism. An indepth examination of\ntechnical forms of plagiarism was also performed in the context of this study.\nIn addition, a survey of plagiarism typologies and classifications proposed by\ndifferent authors is provided.", "published": "2022-01-10 16:11:54", "link": "http://arxiv.org/abs/2201.03423v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Informal Persian Universal Dependency Treebank", "abstract": "This paper presents the phonological, morphological, and syntactic\ndistinctions between formal and informal Persian, showing that these two\nvariants have fundamental differences that cannot be attributed solely to\npronunciation discrepancies. Given that informal Persian exhibits particular\ncharacteristics, any computational model trained on formal Persian is unlikely\nto transfer well to informal Persian, necessitating the creation of dedicated\ntreebanks for this variety. We thus detail the development of the open-source\nInformal Persian Universal Dependency Treebank, a new treebank annotated within\nthe Universal Dependencies scheme. We then investigate the parsing of informal\nPersian by training two dependency parsers on existing formal treebanks and\nevaluating them on out-of-domain data, i.e. the development set of our informal\ntreebank. Our results show that parsers experience a substantial performance\ndrop when we move across the two domains, as they face more unknown tokens and\nstructures and fail to generalize well. Furthermore, the dependency relations\nwhose performance deteriorates the most represent the unique properties of the\ninformal variant. The ultimate goal of this study that demonstrates a broader\nimpact is to provide a stepping-stone to reveal the significance of informal\nvariants of languages, which have been widely overlooked in natural language\nprocessing tools across languages.", "published": "2022-01-10 22:33:07", "link": "http://arxiv.org/abs/2201.03679v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GUDN: A novel guide network with label reinforcement strategy for\n  extreme multi-label text classification", "abstract": "In natural language processing, extreme multi-label text classification is an\nemerging but essential task. The problem of extreme multi-label text\nclassification (XMTC) is to recall some of the most relevant labels for a text\nfrom an extremely large label set. Large-scale pre-trained models have brought\na new trend to this problem. Though the large-scale pre-trained models have\nmade significant achievements on this problem, the valuable fine-tuned methods\nhave yet to be studied. Though label semantics have been introduced in XMTC,\nthe vast semantic gap between texts and labels has yet to gain enough\nattention. This paper builds a new guide network (GUDN) to help fine-tune the\npre-trained model to instruct classification later. Furthermore, GUDN uses raw\nlabel semantics combined with a helpful label reinforcement strategy to\neffectively explore the latent space between texts and labels, narrowing the\nsemantic gap, which can further improve predicted accuracy. Experimental\nresults demonstrate that GUDN outperforms state-of-the-art methods on Eurlex-4k\nand has competitive results on other popular datasets. In an additional\nexperiment, we investigated the input lengths' influence on the\nTransformer-based model's accuracy. Our source code is released at\nhttps://t.hk.uy/aFSH.", "published": "2022-01-10 07:33:36", "link": "http://arxiv.org/abs/2201.11582v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Morphological Analysis of Japanese Hiragana Sentences using the BI-LSTM\n  CRF Model", "abstract": "This study proposes a method to develop neural models of the morphological\nanalyzer for Japanese Hiragana sentences using the Bi-LSTM CRF model.\nMorphological analysis is a technique that divides text data into words and\nassigns information such as parts of speech. This technique plays an essential\nrole in downstream applications in Japanese natural language processing systems\nbecause the Japanese language does not have word delimiters between words.\nHiragana is a type of Japanese phonogramic characters, which is used for texts\nfor children or people who cannot read Chinese characters. Morphological\nanalysis of Hiragana sentences is more difficult than that of ordinary Japanese\nsentences because there is less information for dividing. For morphological\nanalysis of Hiragana sentences, we demonstrated the effectiveness of\nfine-tuning using a model based on ordinary Japanese text and examined the\ninfluence of training data on texts of various genres.", "published": "2022-01-10 14:36:06", "link": "http://arxiv.org/abs/2201.03366v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Black-Box Tuning for Language-Model-as-a-Service", "abstract": "Extremely large pre-trained language models (PTMs) such as GPT-3 are usually\nreleased as a service. It allows users to design task-specific prompts to query\nthe PTMs through some black-box APIs. In such a scenario, which we call\nLanguage-Model-as-a-Service (LMaaS), the gradients of PTMs are usually\nunavailable. Can we optimize the task prompts by only accessing the model\ninference APIs? This paper proposes the black-box tuning framework to optimize\nthe continuous prompt prepended to the input text via derivative-free\noptimization. Instead of optimizing in the original high-dimensional prompt\nspace, which is intractable for traditional derivative-free optimization, we\nperform optimization in a randomly generated subspace due to the low intrinsic\ndimensionality of large PTMs. The experimental results show that the black-box\ntuning with RoBERTa on a few labeled samples not only significantly outperforms\nmanual prompt and GPT-3's in-context learning, but also surpasses the\ngradient-based counterparts, i.e., prompt tuning and full model tuning.", "published": "2022-01-10 18:17:05", "link": "http://arxiv.org/abs/2201.03514v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Polish Natural Language Inference and Factivity -- an Expert-based\n  Dataset and Benchmarks", "abstract": "Despite recent breakthroughs in Machine Learning for Natural Language\nProcessing, the Natural Language Inference (NLI) problems still constitute a\nchallenge. To this purpose we contribute a new dataset that focuses exclusively\non the factivity phenomenon; however, our task remains the same as other NLI\ntasks, i.e. prediction of entailment, contradiction or neutral (ECN). The\ndataset contains entirely natural language utterances in Polish and gathers\n2,432 verb-complement pairs and 309 unique verbs. The dataset is based on the\nNational Corpus of Polish (NKJP) and is a representative sample in regards to\nfrequency of main verbs and other linguistic features (e.g. occurrence of\ninternal negation). We found that transformer BERT-based models working on\nsentences obtained relatively good results ($\\approx89\\%$ F1 score). Even\nthough better results were achieved using linguistic features ($\\approx91\\%$ F1\nscore), this model requires more human labour (humans in the loop) because\nfeatures were prepared manually by expert linguists. BERT-based models\nconsuming only the input sentences show that they capture most of the\ncomplexity of NLI/factivity. Complex cases in the phenomenon - e.g. cases with\nentitlement (E) and non-factive verbs - remain an open issue for further\nresearch.", "published": "2022-01-10 18:32:55", "link": "http://arxiv.org/abs/2201.03521v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Likelihood Ratio based Domain Adaptation Method for E2E Models", "abstract": "End-to-end (E2E) automatic speech recognition models like Recurrent Neural\nNetworks Transducer (RNN-T) are becoming a popular choice for streaming ASR\napplications like voice assistants. While E2E models are very effective at\nlearning representation of the training data they are trained on, their\naccuracy on unseen domains remains a challenging problem. Additionally, these\nmodels require paired audio and text training data, are computationally\nexpensive and are difficult to adapt towards the fast evolving nature of\nconversational speech. In this work, we explore a contextual biasing approach\nusing likelihood-ratio that leverages text data sources to adapt RNN-T model to\nnew domains and entities. We show that this method is effective in improving\nrare words recognition, and results in a relative improvement of 10% in 1-best\nword error rate (WER) and 10% in n-best Oracle WER (n=8) on multiple\nout-of-domain datasets without any degradation on a general dataset. We also\nshow that complementing the contextual biasing adaptation with adaptation of a\nsecond-pass rescoring model gives additive WER improvements.", "published": "2022-01-10 21:22:39", "link": "http://arxiv.org/abs/2201.03655v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Homepage2Vec: Language-Agnostic Website Embedding and Classification", "abstract": "Currently, publicly available models for website classification do not offer\nan embedding method and have limited support for languages beyond English. We\nrelease a dataset of more than two million category-labeled websites in 92\nlanguages collected from Curlie, the largest multilingual human-edited Web\ndirectory. The dataset contains 14 website categories aligned across languages.\nAlongside it, we introduce Homepage2Vec, a machine-learned pre-trained model\nfor classifying and embedding websites based on their homepage in a\nlanguage-agnostic way. Homepage2Vec, thanks to its feature set (textual\ncontent, metadata tags, and visual attributes) and recent progress in natural\nlanguage representation, is language-independent by design and generates\nembedding-based representations. We show that Homepage2Vec correctly classifies\nwebsites with a macro-averaged F1-score of 0.90, with stable performance across\nlow- as well as high-resource languages. Feature analysis shows that a small\nsubset of efficiently computable features suffices to achieve high performance\neven with limited computational resources. We make publicly available the\ncurated Curlie dataset aligned across languages, the pre-trained Homepage2Vec\nmodel, and libraries", "published": "2022-01-10 22:31:48", "link": "http://arxiv.org/abs/2201.03677v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Handwriting recognition and automatic scoring for descriptive answers in\n  Japanese language tests", "abstract": "This paper presents an experiment of automatically scoring handwritten\ndescriptive answers in the trial tests for the new Japanese university entrance\nexamination, which were made for about 120,000 examinees in 2017 and 2018.\nThere are about 400,000 answers with more than 20 million characters. Although\nall answers have been scored by human examiners, handwritten characters are not\nlabeled. We present our attempt to adapt deep neural network-based handwriting\nrecognizers trained on a labeled handwriting dataset into this unlabeled answer\nset. Our proposed method combines different training strategies, ensembles\nmultiple recognizers, and uses a language model built from a large general\ncorpus to avoid overfitting into specific data. In our experiment, the proposed\nmethod records character accuracy of over 97% using about 2,000 verified\nlabeled answers that account for less than 0.5% of the dataset. Then, the\nrecognized answers are fed into a pre-trained automatic scoring system based on\nthe BERT model without correcting misrecognized characters and providing rubric\nannotations. The automatic scoring system achieves from 0.84 to 0.98 of\nQuadratic Weighted Kappa (QWK). As QWK is over 0.8, it represents an acceptable\nsimilarity of scoring between the automatic scoring system and the human\nexaminers. These results are promising for further research on end-to-end\nautomatic scoring of descriptive answers.", "published": "2022-01-10 08:47:52", "link": "http://arxiv.org/abs/2201.03215v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A Planck Radiation and Quantization Scheme for Human Cognition and\n  Language", "abstract": "As a result of the identification of 'identity' and 'indistinguishability'\nand strong experimental evidence for the presence of the associated\nBose-Einstein statistics in human cognition and language, we argued in previous\nwork for an extension of the research domain of quantum cognition. In addition\nto quantum complex vector spaces and quantum probability models, we showed that\nquantization itself, with words as quanta, is relevant and potentially\nimportant to human cognition. In the present work, we build on this result, and\nintroduce a powerful radiation quantization scheme for human cognition. We show\nthat the lack of independence of the Bose-Einstein statistics compared to the\nMaxwell-Boltzmann statistics can be explained by the presence of a 'meaning\ndynamics', which causes words to be attracted to the same words. And so words\nclump together in the same states, a phenomenon well known for photons in the\nearly years of quantum mechanics, leading to fierce disagreements between\nPlanck and Einstein. Using a simple example, we introduce all the elements to\nget a better and detailed view of this 'meaning dynamics', such as micro and\nmacro states, and Maxwell-Boltzmann, Bose-Einstein and Fermi-Dirac numbers and\nweights, and compare this example and its graphs, with the radiation\nquantization scheme of a Winnie the Pooh story, also with its graphs. By\nconnecting a concept directly to human experience, we show that entanglement is\na necessity for preserving the 'meaning dynamics' we identified, and it becomes\nclear in what way Fermi-Dirac addresses human memory. Within the human mind, as\na crucial aspect of memory, in spaces with internal parameters, identical words\ncan nevertheless be assigned different states and hence realize locally and\ncontextually the necessary distinctiveness, structured by a Pauli exclusion\nprinciple, for human thought to thrive.", "published": "2022-01-10 12:13:23", "link": "http://arxiv.org/abs/2201.03306v2", "categories": ["q-bio.NC", "cs.CL", "quant-ph"], "primary_category": "q-bio.NC"}
{"title": "DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge\n  Base Population", "abstract": "We present an open-source and extensible knowledge extraction toolkit DeepKE,\nsupporting complicated low-resource, document-level and multimodal scenarios in\nthe knowledge base population. DeepKE implements various information extraction\ntasks, including named entity recognition, relation extraction and attribute\nextraction. With a unified framework, DeepKE allows developers and researchers\nto customize datasets and models to extract information from unstructured data\naccording to their requirements. Specifically, DeepKE not only provides various\nfunctional modules and model implementation for different tasks and scenarios\nbut also organizes all components by consistent frameworks to maintain\nsufficient modularity and extensibility. We release the source code at GitHub\nin https://github.com/zjunlp/DeepKE with Google Colab tutorials and\ncomprehensive documents for beginners. Besides, we present an online system in\nhttp://deepke.openkg.cn/EN/re_doc_show.html for real-time extraction of various\ntasks, and a demo video.", "published": "2022-01-10 13:29:05", "link": "http://arxiv.org/abs/2201.03335v6", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A study on cross-corpus speech emotion recognition and data augmentation", "abstract": "Models that can handle a wide range of speakers and acoustic conditions are\nessential in speech emotion recognition (SER). Often, these models tend to show\nmixed results when presented with speakers or acoustic conditions that were not\nvisible during training. This paper investigates the impact of cross-corpus\ndata complementation and data augmentation on the performance of SER models in\nmatched (test-set from same corpus) and mismatched (test-set from different\ncorpus) conditions. Investigations using six emotional speech corpora that\ninclude single and multiple speakers as well as variations in emotion style\n(acted, elicited, natural) and recording conditions are presented. Observations\nshow that, as expected, models trained on single corpora perform best in\nmatched conditions while performance decreases between 10-40% in mismatched\nconditions, depending on corpus specific features. Models trained on mixed\ncorpora can be more stable in mismatched contexts, and the performance\nreductions range from 1 to 8% when compared with single corpus models in\nmatched conditions. Data augmentation yields additional gains up to 4% and seem\nto benefit mismatched conditions more than matched ones.", "published": "2022-01-10 18:08:24", "link": "http://arxiv.org/abs/2201.03511v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SCROLLS: Standardized CompaRison Over Long Language Sequences", "abstract": "NLP benchmarks have largely focused on short texts, such as sentences and\nparagraphs, even though long texts comprise a considerable amount of natural\nlanguage in the wild. We introduce SCROLLS, a suite of tasks that require\nreasoning over long texts. We examine existing long-text datasets, and handpick\nones where the text is naturally long, while prioritizing tasks that involve\nsynthesizing information across the input. SCROLLS contains summarization,\nquestion answering, and natural language inference tasks, covering multiple\ndomains, including literature, science, business, and entertainment. Initial\nbaselines, including Longformer Encoder-Decoder, indicate that there is ample\nroom for improvement on SCROLLS. We make all datasets available in a unified\ntext-to-text format and host a live leaderboard to facilitate research on model\narchitecture and pretraining methods.", "published": "2022-01-10 18:47:15", "link": "http://arxiv.org/abs/2201.03533v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Language-driven Semantic Segmentation", "abstract": "We present LSeg, a novel model for language-driven semantic image\nsegmentation. LSeg uses a text encoder to compute embeddings of descriptive\ninput labels (e.g., \"grass\" or \"building\") together with a transformer-based\nimage encoder that computes dense per-pixel embeddings of the input image. The\nimage encoder is trained with a contrastive objective to align pixel embeddings\nto the text embedding of the corresponding semantic class. The text embeddings\nprovide a flexible label representation in which semantically similar labels\nmap to similar regions in the embedding space (e.g., \"cat\" and \"furry\"). This\nallows LSeg to generalize to previously unseen categories at test time, without\nretraining or even requiring a single additional training sample. We\ndemonstrate that our approach achieves highly competitive zero-shot performance\ncompared to existing zero- and few-shot semantic segmentation methods, and even\nmatches the accuracy of traditional segmentation algorithms when a fixed label\nset is provided. Code and demo are available at\nhttps://github.com/isl-org/lang-seg.", "published": "2022-01-10 18:59:10", "link": "http://arxiv.org/abs/2201.03546v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Graph-Based Recommendation System Enhanced with Community Detection", "abstract": "Many researchers have used tag information to improve the performance of\nrecommendation techniques in recommender systems. Examining the tags of users\nwill help to get their interests and leads to more accuracy in the\nrecommendations. Since user-defined tags are chosen freely and without any\nrestrictions, problems arise in determining their exact meaning and the\nsimilarity of tags. However, using thesaurus and ontologies to find the meaning\nof tags is not very efficient due to their free definition by users and the use\nof different languages in many data sets. Therefore, this article uses\nmathematical and statistical methods to determine lexical similarity and\nco-occurrence tags solution to assign semantic similarity. On the other hand,\ndue to the change of users' interests over time this article has considered the\ntime of tag assignments in co-occurrence tags for determining similarity of\ntags. Then the graph is created based on similarity of tags. For modeling the\ninterests of the users, the communities of tags are determined by using\ncommunity detection methods. So, recommendations based on the communities of\ntags and similarity between resources are done. The performance of the proposed\nmethod has been evaluated using two criteria of precision and recall through\nevaluations on two public datasets. The evaluation results show that the\nprecision and recall of the proposed method have significantly improved,\ncompared to the other methods. According to the experimental results, the\ncriteria of recall and precision have been improved, on average by 5% and 7%\nrespectively.", "published": "2022-01-10 20:08:40", "link": "http://arxiv.org/abs/2201.03622v3", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Emotion Intensity and its Control for Emotional Voice Conversion", "abstract": "Emotional voice conversion (EVC) seeks to convert the emotional state of an\nutterance while preserving the linguistic content and speaker identity. In EVC,\nemotions are usually treated as discrete categories overlooking the fact that\nspeech also conveys emotions with various intensity levels that the listener\ncan perceive. In this paper, we aim to explicitly characterize and control the\nintensity of emotion. We propose to disentangle the speaker style from\nlinguistic content and encode the speaker style into a style embedding in a\ncontinuous space that forms the prototype of emotion embedding. We further\nlearn the actual emotion encoder from an emotion-labelled database and study\nthe use of relative attributes to represent fine-grained emotion intensity. To\nensure emotional intelligibility, we incorporate emotion classification loss\nand emotion embedding similarity loss into the training of the EVC network. As\ndesired, the proposed network controls the fine-grained emotion intensity in\nthe output speech. Through both objective and subjective evaluations, we\nvalidate the effectiveness of the proposed network for emotional expressiveness\nand emotion intensity control.", "published": "2022-01-10 02:11:25", "link": "http://arxiv.org/abs/2201.03967v3", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multimodal Representations Learning Based on Mutual Information\n  Maximization and Minimization and Identity Embedding for Multimodal Sentiment\n  Analysis", "abstract": "Multimodal sentiment analysis (MSA) is a fundamental complex research problem\ndue to the heterogeneity gap between different modalities and the ambiguity of\nhuman emotional expression. Although there have been many successful attempts\nto construct multimodal representations for MSA, there are still two challenges\nto be addressed: 1) A more robust multimodal representation needs to be\nconstructed to bridge the heterogeneity gap and cope with the complex\nmultimodal interactions, and 2) the contextual dynamics must be modeled\neffectively throughout the information flow. In this work, we propose a\nmultimodal representation model based on Mutual information Maximization and\nMinimization and Identity Embedding (MMMIE). We combine mutual information\nmaximization between modal pairs, and mutual information minimization between\ninput data and corresponding features to mine the modal-invariant and\ntask-related information. Furthermore, Identity Embedding is proposed to prompt\nthe downstream network to perceive the contextual information. Experimental\nresults on two public datasets demonstrate the effectiveness of the proposed\nmodel.", "published": "2022-01-10 01:41:39", "link": "http://arxiv.org/abs/2201.03969v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Noisy Neonatal Chest Sound Separation for High-Quality Heart and Lung\n  Sounds", "abstract": "Stethoscope-recorded chest sounds provide the opportunity for remote\ncardio-respiratory health monitoring of neonates. However, reliable monitoring\nrequires high-quality heart and lung sounds. This paper presents novel\nNon-negative Matrix Factorisation (NMF) and Non-negative Matrix\nCo-Factorisation (NMCF) methods for neonatal chest sound separation. To assess\nthese methods and compare with existing single-source separation methods, an\nartificial mixture dataset was generated comprising of heart, lung and noise\nsounds. Signal-to-noise ratios were then calculated for these artificial\nmixtures. These methods were also tested on real-world noisy neonatal chest\nsounds and assessed based on vital sign estimation error and a signal quality\nscore of 1-5 developed in our previous works. Additionally, the computational\ncost of all methods was assessed to determine the applicability for real-time\nprocessing. Overall, both the proposed NMF and NMCF methods outperform the next\nbest existing method by 2.7dB to 11.6dB for the artificial dataset and 0.40 to\n1.12 signal quality improvement for the real-world dataset. The median\nprocessing time for the sound separation of a 10s recording was found to be\n28.3s for NMCF and 342ms for NMF. Because of stable and robust performance, we\nbelieve that our proposed methods are useful to denoise neonatal heart and lung\nsound in a real-world environment. Codes for proposed and existing methods can\nbe found at: https://github.com/egrooby-monash/Heart-and-Lung-Sound-Separation.", "published": "2022-01-10 08:38:10", "link": "http://arxiv.org/abs/2201.03211v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Local Information Assisted Attention-free Decoder for Audio Captioning", "abstract": "Automated audio captioning aims to describe audio data with captions using\nnatural language. Existing methods often employ an encoder-decoder structure,\nwhere the attention-based decoder (e.g., Transformer decoder) is widely used\nand achieves state-of-the-art performance. Although this method effectively\ncaptures global information within audio data via the self-attention mechanism,\nit may ignore the event with short time duration, due to its limitation in\ncapturing local information in an audio signal, leading to inaccurate\nprediction of captions. To address this issue, we propose a method using the\npretrained audio neural networks (PANNs) as the encoder and local information\nassisted attention-free Transformer (LocalAFT) as the decoder. The novelty of\nour method is in the proposal of the LocalAFT decoder, which allows local\ninformation within an audio signal to be captured while retaining the global\ninformation. This enables the events of different duration, including short\nduration, to be captured for more precise caption generation. Experiments show\nthat our method outperforms the state-of-the-art methods in Task 6 of the DCASE\n2021 Challenge with the standard attention-based decoder for caption\ngeneration.", "published": "2022-01-10 08:55:52", "link": "http://arxiv.org/abs/2201.03217v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cross-Modal ASR Post-Processing System for Error Correction and\n  Utterance Rejection", "abstract": "Although modern automatic speech recognition (ASR) systems can achieve high\nperformance, they may produce errors that weaken readers' experience and do\nharm to downstream tasks. To improve the accuracy and reliability of ASR\nhypotheses, we propose a cross-modal post-processing system for speech\nrecognizers, which 1) fuses acoustic features and textual features from\ndifferent modalities, 2) joints a confidence estimator and an error corrector\nin multi-task learning fashion and 3) unifies error correction and utterance\nrejection modules. Compared with single-modal or single-task models, our\nproposed system is proved to be more effective and efficient. Experiment result\nshows that our post-processing system leads to more than 10% relative reduction\nof character error rate (CER) for both single-speaker and multi-speaker speech\non our industrial ASR system, with about 1.7ms latency for each token, which\nensures that extra latency introduced by post-processing is acceptable in\nstreaming speech recognition.", "published": "2022-01-10 12:29:55", "link": "http://arxiv.org/abs/2201.03313v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Practical Guide to Logical Access Voice Presentation Attack Detection", "abstract": "Voice-based human-machine interfaces with an automatic speaker verification\n(ASV) component are commonly used in the market. However, the threat from\npresentation attacks is also growing since attackers can use recent speech\nsynthesis technology to produce a natural-sounding voice of a victim.\nPresentation attack detection (PAD) for ASV, or speech anti-spoofing, is\ntherefore indispensable. Research on voice PAD has seen significant progress\nsince the early 2010s, including the advancement in PAD models, benchmark\ndatasets, and evaluation campaigns. This chapter presents a practical guide to\nthe field of voice PAD, with a focus on logical access attacks using\ntext-to-speech and voice conversion algorithms and spoofing countermeasures\nbased on artifact detection. It introduces the basic concept of voice PAD,\nexplains the common techniques, and provides an experimental study using recent\nmethods on a benchmark dataset. Code for the experiments is open-sourced.", "published": "2022-01-10 12:42:41", "link": "http://arxiv.org/abs/2201.03321v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sub-mW Keyword Spotting on an MCU: Analog Binary Feature Extraction and\n  Binary Neural Networks", "abstract": "Keyword spotting (KWS) is a crucial function enabling the interaction with\nthe many ubiquitous smart devices in our surroundings, either activating them\nthrough wake-word or directly as a human-computer interface. For many\napplications, KWS is the entry point for our interactions with the device and,\nthus, an always-on workload. Many smart devices are mobile and their battery\nlifetime is heavily impacted by continuously running services. KWS and similar\nalways-on services are thus the focus when optimizing the overall power\nconsumption. This work addresses KWS energy-efficiency on low-cost\nmicrocontroller units (MCUs). We combine analog binary feature extraction with\nbinary neural networks. By replacing the digital preprocessing with the\nproposed analog front-end, we show that the energy required for data\nacquisition and preprocessing can be reduced by 29x, cutting its share from a\ndominating 85% to a mere 16% of the overall energy consumption for our\nreference KWS application. Experimental evaluations on the Speech Commands\nDataset show that the proposed system outperforms state-of-the-art accuracy and\nenergy efficiency, respectively, by 1% and 4.3x on a 10-class dataset while\nproviding a compelling accuracy-energy trade-off including a 2% accuracy drop\nfor a 71x energy reduction.", "published": "2022-01-10 15:10:58", "link": "http://arxiv.org/abs/2201.03386v1", "categories": ["cs.SD", "cs.AI", "cs.AR", "eess.AS"], "primary_category": "cs.SD"}
