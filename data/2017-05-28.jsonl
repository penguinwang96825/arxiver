{"title": "Understanding Abuse: A Typology of Abusive Language Detection Subtasks", "abstract": "As the body of research on abusive language detection and analysis grows,\nthere is a need for critical consideration of the relationships between\ndifferent subtasks that have been grouped under this label. Based on work on\nhate speech, cyberbullying, and online abuse we propose a typology that\ncaptures central similarities and differences between subtasks and we discuss\nits implications for data annotation and feature construction. We emphasize the\npractical actions that can be taken by researchers to best approach their\nabusive language detection subtask of interest.", "published": "2017-05-28 06:59:07", "link": "http://arxiv.org/abs/1705.09899v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Listen, Interact and Talk: Learning to Speak via Interaction", "abstract": "One of the long-term goals of artificial intelligence is to build an agent\nthat can communicate intelligently with human in natural language. Most\nexisting work on natural language learning relies heavily on training over a\npre-collected dataset with annotated labels, leading to an agent that\nessentially captures the statistics of the fixed external training data. As the\ntraining data is essentially a static snapshot representation of the knowledge\nfrom the annotator, the agent trained this way is limited in adaptiveness and\ngeneralization of its behavior. Moreover, this is very different from the\nlanguage learning process of humans, where language is acquired during\ncommunication by taking speaking action and learning from the consequences of\nspeaking action in an interactive manner. This paper presents an interactive\nsetting for grounded natural language learning, where an agent learns natural\nlanguage by interacting with a teacher and learning from feedback, thus\nlearning and improving language skills while taking part in the conversation.\nTo achieve this goal, we propose a model which incorporates both imitation and\nreinforcement by leveraging jointly sentence and reward feedbacks from the\nteacher. Experiments are conducted to validate the effectiveness of the\nproposed approach.", "published": "2017-05-28 07:48:14", "link": "http://arxiv.org/abs/1705.09906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Semantic Parsing by Character-based Translation: Experiments with\n  Abstract Meaning Representations", "abstract": "We evaluate the character-level translation method for neural semantic\nparsing on a large corpus of sentences annotated with Abstract Meaning\nRepresentations (AMRs). Using a sequence-to-sequence model, and some trivial\npreprocessing and postprocessing of AMRs, we obtain a baseline accuracy of 53.1\n(F-score on AMR-triples). We examine five different approaches to improve this\nbaseline result: (i) reordering AMR branches to match the word order of the\ninput sentence increases performance to 58.3; (ii) adding part-of-speech tags\n(automatically produced) to the input shows improvement as well (57.2); (iii)\nSo does the introduction of super characters (conflating frequent sequences of\ncharacters to a single character), reaching 57.4; (iv) optimizing the training\nprocess by using pre-training and averaging a set of models increases\nperformance to 58.7; (v) adding silver-standard training data obtained by an\noff-the-shelf parser yields the biggest improvement, resulting in an F-score of\n64.0. Combining all five techniques leads to an F-score of 71.0 on holdout\ndata, which is state-of-the-art in AMR parsing. This is remarkable because of\nthe relative simplicity of the approach.", "published": "2017-05-28 19:41:09", "link": "http://arxiv.org/abs/1705.09980v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subject Specific Stream Classification Preprocessing Algorithm for\n  Twitter Data Stream", "abstract": "Micro-blogging service Twitter is a lucrative source for data mining\napplications on global sentiment. But due to the omnifariousness of the\nsubjects mentioned in each data item; it is inefficient to run a data mining\nalgorithm on the raw data. This paper discusses an algorithm to accurately\nclassify the entire stream in to a given number of mutually exclusive\ncollectively exhaustive streams upon each of which the data mining algorithm\ncan be run separately yielding more relevant results with a high efficiency.", "published": "2017-05-28 22:16:35", "link": "http://arxiv.org/abs/1705.09995v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Deep Multi-View Learning Framework for City Event Extraction from\n  Twitter Data Streams", "abstract": "Cities have been a thriving place for citizens over the centuries due to\ntheir complex infrastructure. The emergence of the Cyber-Physical-Social\nSystems (CPSS) and context-aware technologies boost a growing interest in\nanalysing, extracting and eventually understanding city events which\nsubsequently can be utilised to leverage the citizen observations of their\ncities. In this paper, we investigate the feasibility of using Twitter textual\nstreams for extracting city events. We propose a hierarchical multi-view deep\nlearning approach to contextualise citizen observations of various city systems\nand services. Our goal has been to build a flexible architecture that can learn\nrepresentations useful for tasks, thus avoiding excessive task-specific feature\nengineering. We apply our approach on a real-world dataset consisting of event\nreports and tweets of over four months from San Francisco Bay Area dataset and\nadditional datasets collected from London. The results of our evaluations show\nthat our proposed solution outperforms the existing models and can be used for\nextracting city related events with an averaged accuracy of 81% over all\nclasses. To further evaluate the impact of our Twitter event extraction model,\nwe have used two sources of authorised reports through collecting road traffic\ndisruptions data from Transport for London API, and parsing the Time Out London\nwebsite for sociocultural events. The analysis showed that 49.5% of the Twitter\ntraffic comments are reported approximately five hours prior to the authorities\nofficial records. Moreover, we discovered that amongst the scheduled\nsociocultural event topics; tweets reporting transportation, cultural and\nsocial events are 31.75% more likely to influence the distribution of the\nTwitter comments than sport, weather and crime topics.", "published": "2017-05-28 18:22:15", "link": "http://arxiv.org/abs/1705.09975v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Deep Learning for User Comment Moderation", "abstract": "Experimenting with a new dataset of 1.6M user comments from a Greek news\nportal and existing datasets of English Wikipedia comments, we show that an RNN\noutperforms the previous state of the art in moderation. A deep,\nclassification-specific attention mechanism improves further the overall\nperformance of the RNN. We also compare against a CNN and a word-list baseline,\nconsidering both fully automatic and semi-automatic moderation.", "published": "2017-05-28 21:12:56", "link": "http://arxiv.org/abs/1705.09993v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The placement of the head that maximizes predictability. An information\n  theoretic approach", "abstract": "The minimization of the length of syntactic dependencies is a\nwell-established principle of word order and the basis of a mathematical theory\nof word order. Here we complete that theory from the perspective of information\ntheory, adding a competing word order principle: the maximization of\npredictability of a target element. These two principles are in conflict: to\nmaximize the predictability of the head, the head should appear last, which\nmaximizes the costs with respect to dependency length minimization. The\nimplications of such a broad theoretical framework to understand the\noptimality, diversity and evolution of the six possible orderings of subject,\nobject and verb are reviewed.", "published": "2017-05-28 12:19:03", "link": "http://arxiv.org/abs/1705.09932v3", "categories": ["cs.CL", "nlin.AO", "physics.soc-ph", "q-bio.NC"], "primary_category": "cs.CL"}
