{"title": "Stacked DeBERT: All Attention in Incomplete Data for Text Classification", "abstract": "In this paper, we propose Stacked DeBERT, short for Stacked Denoising\nBidirectional Encoder Representations from Transformers. This novel model\nimproves robustness in incomplete data, when compared to existing systems, by\ndesigning a novel encoding scheme in BERT, a powerful language representation\nmodel solely based on attention mechanisms. Incomplete data in natural language\nprocessing refer to text with missing or incorrect words, and its presence can\nhinder the performance of current models that were not implemented to withstand\nsuch noises, but must still perform well even under duress. This is due to the\nfact that current approaches are built for and trained with clean and complete\ndata, and thus are not able to extract features that can adequately represent\nincomplete data. Our proposed approach consists of obtaining intermediate input\nrepresentations by applying an embedding layer to the input tokens followed by\nvanilla transformers. These intermediate features are given as input to novel\ndenoising transformers which are responsible for obtaining richer input\nrepresentations. The proposed approach takes advantage of stacks of multilayer\nperceptrons for the reconstruction of missing words' embeddings by extracting\nmore abstract and meaningful hidden feature vectors, and bidirectional\ntransformers for improved embedding representation. We consider two datasets\nfor training and evaluation: the Chatbot Natural Language Understanding\nEvaluation Corpus and Kaggle's Twitter Sentiment Corpus. Our model shows\nimproved F1-scores and better robustness in informal/incorrect texts present in\ntweets and in texts with Speech-to-Text error in the sentiment and intent\nclassification tasks.", "published": "2020-01-01 04:49:23", "link": "http://arxiv.org/abs/2001.00137v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Smart Summarizer for Blind People", "abstract": "In today's world, time is a very important resource. In our busy lives, most\nof us hardly have time to read the complete news so what we have to do is just\ngo through the headlines and satisfy ourselves with that. As a result, we might\nmiss a part of the news or misinterpret the complete thing. The situation is\neven worse for the people who are visually impaired or have lost their ability\nto see. The inability of these people to read text has a huge impact on their\nlives. There are a number of methods for blind people to read the text. Braille\nscript, in particular, is one of the examples, but it is a highly inefficient\nmethod as it is really time taking and requires a lot of practice. So, we\npresent a method for visually impaired people based on the sense of sound which\nis obviously better and more accurate than the sense of touch. This paper deals\nwith an efficient method to summarize news into important keywords so as to\nsave the efforts to go through the complete text every single time. This paper\ndeals with many API's and modules like the tesseract, GTTS, and many algorithms\nthat have been discussed and implemented in detail such as Luhn's Algorithm,\nLatent Semantic Analysis Algorithm, Text Ranking Algorithm. And the other\nfunctionality that this paper deals with is converting the summarized text to\nspeech so that the system can aid even the blind people.", "published": "2020-01-01 20:39:22", "link": "http://arxiv.org/abs/2001.00575v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Attentive batch normalization for lstm-based acoustic modeling of speech\n  recognition", "abstract": "Batch normalization (BN) is an effective method to accelerate model training\nand improve the generalization performance of neural networks. In this paper,\nwe propose an improved batch normalization technique called attentive batch\nnormalization (ABN) in Long Short Term Memory (LSTM) based acoustic modeling\nfor automatic speech recognition (ASR). In the proposed method, an auxiliary\nnetwork is used to dynamically generate the scaling and shifting parameters in\nbatch normalization, and attention mechanisms are introduced to improve their\nregularized performance. Furthermore, two schemes, frame-level and\nutterance-level ABN, are investigated. We evaluate our proposed methods on\nMandarin and Uyghur ASR tasks, respectively. The experimental results show that\nthe proposed ABN greatly improves the performance of batch normalization in\nterms of transcription accuracy for both languages.", "published": "2020-01-01 02:39:42", "link": "http://arxiv.org/abs/2001.00129v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Hand bone conduction sound study by using the DSP Logger MX 300", "abstract": "Bone conduction is the transmission of acoustic energy to the inner ear by\ndifferent paths involving the bones of the skull. In this work, we use the path\nthe hand provides in order to transmit the sound coming from the cell phone\nusing Bluetooth system. The aim of this work was to study the vibrations\nproduced by a sound transmitted through bone conduction between a mobile phone\nand the hand analyzed with the DSP Logger MX equipment.", "published": "2020-01-01 23:17:13", "link": "http://arxiv.org/abs/2001.01585v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
