{"title": "Distributional Term Set Expansion", "abstract": "This paper is a short empirical study of the performance of centrality and\nclassification based iterative term set expansion methods for distributional\nsemantic models. Iterative term set expansion is an interactive process using\ndistributional semantics models where a user labels terms as belonging to some\nsought after term set, and a system uses this labeling to supply the user with\nnew, candidate, terms to label, trying to maximize the number of positive\nexamples found. While centrality based methods have a long history in term set\nexpansion, we compare them to classification methods based on the the Simple\nMargin method, an Active Learning approach to classification using Support\nVector Machines. Examining the performance of various centrality and\nclassification based methods for a variety of distributional models over five\ndifferent term sets, we can show that active learning based methods\nconsistently outperform centrality based methods.", "published": "2018-02-14 10:04:48", "link": "http://arxiv.org/abs/1802.05014v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic unit discovery from multi-modal inputs in unwritten\n  languages: Summary of the \"Speaking Rosetta\" JSALT 2017 Workshop", "abstract": "We summarize the accomplishments of a multi-disciplinary workshop exploring\nthe computational and scientific issues surrounding the discovery of linguistic\nunits (subwords and words) in a language without orthography. We study the\nreplacement of orthographic transcriptions by images and/or translated text in\na well-resourced language to help unsupervised discovery from raw speech.", "published": "2018-02-14 13:46:03", "link": "http://arxiv.org/abs/1802.05092v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Classifying movie genres by analyzing text reviews", "abstract": "This paper proposes a method for classifying movie genres by only looking at\ntext reviews. The data used are from Large Movie Review Dataset v1.0 and IMDb.\nThis paper compared a K-nearest neighbors (KNN) model and a multilayer\nperceptron (MLP) that uses tf-idf as input features. The paper also discusses\ndifferent evaluation metrics used when doing multi-label classification. For\nthe data used in this research, the KNN model performed the best with an\naccuracy of 55.4\\% and a Hamming loss of 0.047.", "published": "2018-02-14 21:04:15", "link": "http://arxiv.org/abs/1802.05322v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Co-training for Extraction of Adverse Drug Reaction Mentions from Tweets", "abstract": "Adverse drug reactions (ADRs) are one of the leading causes of mortality in\nhealth care. Current ADR surveillance systems are often associated with a\nsubstantial time lag before such events are officially published. On the other\nhand, online social media such as Twitter contain information about ADR events\nin real-time, much before any official reporting. Current state-of-the-art\nmethods in ADR mention extraction use Recurrent Neural Networks (RNN), which\ntypically need large labeled corpora. Towards this end, we propose a\nsemi-supervised method based on co-training which can exploit a large pool of\nunlabeled tweets to augment the limited supervised training data, and as a\nresult enhance the performance. Experiments with 0.1M tweets show that the\nproposed approach outperforms the state-of-the-art methods for the ADR mention\nextraction task by 5% in terms of F1 score.", "published": "2018-02-14 14:47:56", "link": "http://arxiv.org/abs/1802.05121v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Multi-Task Learning for Extraction of Adverse Drug Reaction Mentions\n  from Tweets", "abstract": "Adverse drug reactions (ADRs) are one of the leading causes of mortality in\nhealth care. Current ADR surveillance systems are often associated with a\nsubstantial time lag before such events are officially published. On the other\nhand, online social media such as Twitter contain information about ADR events\nin real-time, much before any official reporting. Current state-of-the-art in\nADR mention extraction uses Recurrent Neural Networks (RNN), which typically\nneed large labeled corpora. Towards this end, we propose a multi-task learning\nbased method which can utilize a similar auxiliary task (adverse drug event\ndetection) to enhance the performance of the main task, i.e., ADR extraction.\nFurthermore, in the absence of auxiliary task dataset, we propose a novel joint\nmulti-task learning method to automatically generate weak supervision dataset\nfor the auxiliary task when a large pool of unlabeled tweets is available.\nExperiments with 0.48M tweets show that the proposed approach outperforms the\nstate-of-the-art methods for the ADR mention extraction task by 7.2% in terms\nof F1 score.", "published": "2018-02-14 14:53:06", "link": "http://arxiv.org/abs/1802.05130v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe\n  Noise", "abstract": "The growing importance of massive datasets used for deep learning makes\nrobustness to label noise a critical property for classifiers to have. Sources\nof label noise include automatic labeling, non-expert labeling, and label\ncorruption by data poisoning adversaries. Numerous previous works assume that\nno source of labels can be trusted. We relax this assumption and assume that a\nsmall subset of the training data is trusted. This enables substantial label\ncorruption robustness performance gains. In addition, particularly severe label\nnoise can be combated by using a set of trusted data with clean labels. We\nutilize trusted data by proposing a loss correction technique that utilizes\ntrusted examples in a data-efficient manner to mitigate the effects of label\nnoise on deep neural network classifiers. Across vision and natural language\nprocessing tasks, we experiment with various label noises at several strengths,\nand show that our method significantly outperforms existing methods.", "published": "2018-02-14 19:48:50", "link": "http://arxiv.org/abs/1802.05300v4", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Neural Voice Cloning with a Few Samples", "abstract": "Voice cloning is a highly desired feature for personalized speech interfaces.\nNeural network based speech synthesis has been shown to generate high quality\nspeech for a large number of speakers. In this paper, we introduce a neural\nvoice cloning system that takes a few audio samples as input. We study two\napproaches: speaker adaptation and speaker encoding. Speaker adaptation is\nbased on fine-tuning a multi-speaker generative model with a few cloning\nsamples. Speaker encoding is based on training a separate model to directly\ninfer a new speaker embedding from cloning audios and to be used with a\nmulti-speaker generative model. In terms of naturalness of the speech and its\nsimilarity to original speaker, both approaches can achieve good performance,\neven with very few cloning audios. While speaker adaptation can achieve better\nnaturalness and similarity, the cloning time or required memory for the speaker\nencoding approach is significantly less, making it favorable for low-resource\ndeployment.", "published": "2018-02-14 18:24:41", "link": "http://arxiv.org/abs/1802.06006v3", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Authorship Attribution Using the Chaos Game Representation", "abstract": "The Chaos Game Representation, a method for creating images from nucleotide\nsequences, is modified to make images from chunks of text documents. Machine\nlearning methods are then applied to train classifiers based on authorship.\nExperiments are conducted on several benchmark data sets in English, including\nthe widely used Federalist Papers, and one in Portuguese. Validation results\nfor the trained classifiers are competitive with the best methods in prior\nliterature. The methodology is also successfully applied for text\ncategorization with encouraging results. One classifier method is moreover seen\nto hold promise for the task of digital fingerprinting.", "published": "2018-02-14 19:44:24", "link": "http://arxiv.org/abs/1802.06007v1", "categories": ["cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BachProp: Learning to Compose Music in Multiple Styles", "abstract": "Hand in hand with deep learning advancements, algorithms of music composition\nincrease in performance. However, most of the successful models are designed\nfor specific musical structures. Here, we present BachProp, an algorithmic\ncomposer that can generate music scores in any style given sufficient training\ndata. To adapt BachProp to a broad range of musical styles, we propose a novel\nnormalized representation of music and train a deep network to predict the note\ntransition probabilities of a given music corpus. In this paper, new music\nscores sampled by BachProp are compared with the original corpora via\ncrowdsourcing. This evaluation indicates that the music scores generated by\nBachProp are not less preferred than the original music corpus the algorithm\nwas provided with.", "published": "2018-02-14 15:42:17", "link": "http://arxiv.org/abs/1802.05162v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Similarity measures for vocal-based drum sample retrieval using deep\n  convolutional auto-encoders", "abstract": "The expressive nature of the voice provides a powerful medium for\ncommunicating sonic ideas, motivating recent research on methods for query by\nvocalisation. Meanwhile, deep learning methods have demonstrated\nstate-of-the-art results for matching vocal imitations to imitated sounds, yet\nlittle is known about how well learned features represent the perceptual\nsimilarity between vocalisations and queried sounds. In this paper, we address\nthis question using similarity ratings between vocal imitations and imitated\ndrum sounds. We use a linear mixed effect regression model to show how features\nlearned by convolutional auto-encoders (CAEs) perform as predictors for\nperceptual similarity between sounds. Our experiments show that CAEs outperform\nthree baseline feature sets (spectrogram-based representations, MFCCs, and\ntemporal features) at predicting the subjective similarity ratings. We also\ninvestigate how the size and shape of the encoded layer effects the predictive\npower of the learned features. The results show that preservation of temporal\ninformation is more important than spectral resolution for this application.", "published": "2018-02-14 16:08:09", "link": "http://arxiv.org/abs/1802.05178v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
