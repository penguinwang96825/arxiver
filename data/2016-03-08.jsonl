{"title": "Extracting Arabic Relations from the Web", "abstract": "The goal of this research is to extract a large list or table from named\nentities and relations in a specific domain. A small set of a handful of\ninstance relations is required as input from the user. The system exploits\nsummaries from Google search engine as a source text. These instances are used\nto extract patterns. The output is a set of new entities and their relations.\nThe results from four experiments show that precision and recall varies\naccording to relation type. Precision ranges from 0.61 to 0.75 while recall\nranges from 0.71 to 0.83. The best result is obtained for (player, club)\nrelationship, 0.72 and 0.83 for precision and recall respectively.", "published": "2016-03-08 11:47:35", "link": "http://arxiv.org/abs/1603.02488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Observing Trends in Automated Multilingual Media Analysis", "abstract": "Any large organisation, be it public or private, monitors the media for\ninformation to keep abreast of developments in their field of interest, and\nusually also to become aware of positive or negative opinions expressed towards\nthem. At least for the written media, computer programs have become very\nefficient at helping the human analysts significantly in their monitoring task\nby gathering media reports, analysing them, detecting trends and - in some\ncases - even to issue early warnings or to make predictions of likely future\ndevelopments. We present here trend recognition-related functionality of the\nEurope Media Monitor (EMM) system, which was developed by the European\nCommission's Joint Research Centre (JRC) for public administrations in the\nEuropean Union (EU) and beyond. EMM performs large-scale media analysis in up\nto seventy languages and recognises various types of trends, some of them\ncombining information from news articles written in different languages and\nfrom social media posts. EMM also lets users explore the huge amount of\nmultilingual media data through interactive maps and graphs, allowing them to\nexamine the data from various view points and according to multiple criteria. A\nlot of EMM's functionality is accessibly freely over the internet or via apps\nfor hand-held devices.", "published": "2016-03-08 17:43:48", "link": "http://arxiv.org/abs/1603.02604v1", "categories": ["cs.CL", "H.3.1; H.3.3; H.3.6; I.2.7; I.5.4; J.4"], "primary_category": "cs.CL"}
{"title": "Variational Autoencoders for Semi-supervised Text Classification", "abstract": "Although semi-supervised variational autoencoder (SemiVAE) works in image\nclassification task, it fails in text classification task if using vanilla LSTM\nas its decoder. From a perspective of reinforcement learning, it is verified\nthat the decoder's capability to distinguish between different categorical\nlabels is essential. Therefore, Semi-supervised Sequential Variational\nAutoencoder (SSVAE) is proposed, which increases the capability by feeding\nlabel into its decoder RNN at each time-step. Two specific decoder structures\nare investigated and both of them are verified to be effective. Besides, in\norder to reduce the computational complexity in training, a novel optimization\nmethod is proposed, which estimates the gradient of the unlabeled objective\nfunction by sampling, along with two variance reduction techniques.\nExperimental results on Large Movie Review Dataset (IMDB) and AG's News corpus\nshow that the proposed approach significantly improves the classification\naccuracy compared with pure-supervised classifiers, and achieves competitive\nperformance against previous advanced methods. State-of-the-art results can be\nobtained by integrating other pretraining-based methods.", "published": "2016-03-08 13:24:45", "link": "http://arxiv.org/abs/1603.02514v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The red one!: On learning to refer to things based on their\n  discriminative properties", "abstract": "As a first step towards agents learning to communicate about their visual\nenvironment, we propose a system that, given visual representations of a\nreferent (cat) and a context (sofa), identifies their discriminative\nattributes, i.e., properties that distinguish them (has_tail). Moreover,\ndespite the lack of direct supervision at the attribute level, the model learns\nto assign plausible attributes to objects (sofa-has_cushion). Finally, we\npresent a preliminary experiment confirming the referential success of the\npredicted discriminative attributes.", "published": "2016-03-08 18:39:46", "link": "http://arxiv.org/abs/1603.02618v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
