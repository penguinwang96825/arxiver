{"title": "WikiUMLS: Aligning UMLS to Wikipedia via Cross-lingual Neural Ranking", "abstract": "We present our work on aligning the Unified Medical Language System (UMLS) to\nWikipedia, to facilitate manual alignment of the two resources. We propose a\ncross-lingual neural reranking model to match a UMLS concept with a Wikipedia\npage, which achieves a recall@1 of 72%, a substantial improvement of 20% over\nword- and char-level BM25, enabling manual alignment with minimal effort. We\nrelease our resources, including ranked Wikipedia pages for 700k UMLS concepts,\nand WikiUMLS, a dataset for training and evaluation of alignment models between\nUMLS and Wikipedia. This will provide easier access to Wikipedia for health\nprofessionals, patients, and NLP systems, including in multilingual settings.", "published": "2020-05-04 05:52:10", "link": "http://arxiv.org/abs/2005.01281v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distributional Discrepancy: A Metric for Unconditional Text Generation", "abstract": "The purpose of unconditional text generation is to train a model with real\nsentences, then generate novel sentences of the same quality and diversity as\nthe training data. However, when different metrics are used for comparing the\nmethods of unconditional text generation, contradictory conclusions are drawn.\nThe difficulty is that both the diversity and quality of the sample should be\nconsidered simultaneously when the models are evaluated. To solve this problem,\na novel metric of distributional discrepancy (DD) is designed to evaluate\ngenerators based on the discrepancy between the generated and real training\nsentences. However, it cannot compute the DD directly because the distribution\nof real sentences is unavailable. Thus, we propose a method for estimating the\nDD by training a neural-network-based text classifier. For comparison, three\nexisting metrics, bi-lingual evaluation understudy (BLEU) versus self-BLEU,\nlanguage model score versus reverse language model score, and Fr\\'{e}chet\nembedding distance, along with the proposed DD, are used to evaluate two\npopular generative models of long short-term memory and generative pretrained\ntransformer 2 on both syntactic and real data. Experimental results show that\nDD is significantly better than the three existing metrics for ranking these\ngenerative models.", "published": "2020-05-04 05:53:34", "link": "http://arxiv.org/abs/2005.01282v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "pyBART: Evidence-based Syntactic Transformations for IE", "abstract": "Syntactic dependencies can be predicted with high accuracy, and are useful\nfor both machine-learned and pattern-based information extraction tasks.\nHowever, their utility can be improved. These syntactic dependencies are\ndesigned to accurately reflect syntactic relations, and they do not make\nsemantic relations explicit. Therefore, these representations lack many\nexplicit connections between content words, that would be useful for downstream\napplications. Proposals like English Enhanced UD improve the situation by\nextending universal dependency trees with additional explicit arcs. However,\nthey are not available to Python users, and are also limited in coverage. We\nintroduce a broad-coverage, data-driven and linguistically sound set of\ntransformations, that makes event-structure and many lexical relations\nexplicit. We present pyBART, an easy-to-use open-source Python library for\nconverting English UD trees either to Enhanced UD graphs or to our\nrepresentation. The library can work as a standalone package or be integrated\nwithin a spaCy NLP pipeline. When evaluated in a pattern-based relation\nextraction scenario, our representation results in higher extraction scores\nthan Enhanced UD, while requiring fewer patterns.", "published": "2020-05-04 07:38:34", "link": "http://arxiv.org/abs/2005.01306v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLP in FinTech Applications: Past, Present and Future", "abstract": "Financial Technology (FinTech) is one of the worldwide rapidly-rising topics\nin the past five years according to the statistics of FinTech from Google\nTrends. In this position paper, we focus on the researches applying natural\nlanguage processing (NLP) technologies in the finance domain. Our goal is to\nindicate the position we are now and provide the blueprint for future\nresearches. We go through the application scenarios from three aspects\nincluding Know Your Customer (KYC), Know Your Product (KYP), and Satisfy Your\nCustomer (SYC). Both formal documents and informal textual data are analyzed to\nunderstand corporate customers and personal customers. Furthermore, we talk\nover how to dynamically update the features of products from the prospect and\nthe risk points of view. Finally, we discuss satisfying the customers in both\nB2C and C2C business models. After summarizing the past and the recent\nchallenges, we highlight several promising future research directions in the\ntrend of FinTech and the open finance tendency.", "published": "2020-05-04 08:37:27", "link": "http://arxiv.org/abs/2005.01320v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DoQA -- Accessing Domain-Specific FAQs via Conversational QA", "abstract": "The goal of this work is to build conversational Question Answering (QA)\ninterfaces for the large body of domain-specific information available in FAQ\nsites. We present DoQA, a dataset with 2,437 dialogues and 10,917 QA pairs. The\ndialogues are collected from three Stack Exchange sites using the Wizard of Oz\nmethod with crowdsourcing. Compared to previous work, DoQA comprises\nwell-defined information needs, leading to more coherent and natural\nconversations with less factoid questions and is multi-domain. In addition, we\nintroduce a more realistic information retrieval(IR) scenario where the system\nneeds to find the answer in any of the FAQ documents. The results of an\nexisting, strong, system show that, thanks to transfer learning from a\nWikipedia QA dataset and fine tuning on a single FAQ domain, it is possible to\nbuild high quality conversational QA systems for FAQs without in-domain\ntraining data. The good results carry over into the more challenging IR\nscenario. In both cases, there is still ample room for improvement, as\nindicated by the higher human upperbound.", "published": "2020-05-04 08:58:54", "link": "http://arxiv.org/abs/2005.01328v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of\n  Parsing Morphologically-Rich Languages (MRLs)?", "abstract": "It has been exactly a decade since the first establishment of SPMRL, a\nresearch initiative unifying multiple research efforts to address the peculiar\nchallenges of Statistical Parsing for Morphologically-Rich Languages\n(MRLs).Here we reflect on parsing MRLs in that decade, highlight the solutions\nand lessons learned for the architectural, modeling and lexical challenges in\nthe pre-neural era, and argue that similar challenges re-emerge in neural\narchitectures for MRLs. We then aim to offer a climax, suggesting that\nincorporating symbolic ideas proposed in SPMRL terms into nowadays neural\narchitectures has the potential to push NLP for MRLs to a new level. We sketch\nstrategies for designing Neural Models for MRLs (NMRL), and showcase\npreliminary support for these strategies via investigating the task of\nmulti-tagging in Hebrew, a morphologically-rich, high-fusion, language", "published": "2020-05-04 09:05:55", "link": "http://arxiv.org/abs/2005.01330v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Introducing the VoicePrivacy Initiative", "abstract": "The VoicePrivacy initiative aims to promote the development of privacy\npreservation tools for speech technology by gathering a new community to define\nthe tasks of interest and the evaluation methodology, and benchmarking\nsolutions through a series of challenges. In this paper, we formulate the voice\nanonymization task selected for the VoicePrivacy 2020 Challenge and describe\nthe datasets used for system development and evaluation. We also present the\nattack models and the associated objective and subjective evaluation metrics.\nWe introduce two anonymization baselines and report objective evaluation\nresults.", "published": "2020-05-04 11:07:52", "link": "http://arxiv.org/abs/2005.01387v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Context in Neural Machine Translation Training Objectives", "abstract": "We present Neural Machine Translation (NMT) training using document-level\nmetrics with batch-level documents. Previous sequence-objective approaches to\nNMT training focus exclusively on sentence-level metrics like sentence BLEU\nwhich do not correspond to the desired evaluation metric, typically document\nBLEU. Meanwhile research into document-level NMT training focuses on data or\nmodel architecture rather than training procedure. We find that each of these\nlines of research has a clear space in it for the other, and propose merging\nthem with a scheme that allows a document-level evaluation metric to be used in\nthe NMT training objective.\n  We first sample pseudo-documents from sentence samples. We then approximate\nthe expected document BLEU gradient with Monte Carlo sampling for use as a cost\nfunction in Minimum Risk Training (MRT). This two-level sampling procedure\ngives NMT performance gains over sequence MRT and maximum-likelihood training.\nWe demonstrate that training is more robust for document-level metrics than\nwith sequence metrics. We further demonstrate improvements on NMT with TER and\nGrammatical Error Correction (GEC) using GLEU, both metrics used at the\ndocument level for evaluations.", "published": "2020-05-04 13:42:30", "link": "http://arxiv.org/abs/2005.01483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards A Sign Language Gloss Representation Of Modern Standard Arabic", "abstract": "Over 5% of the world's population (466 million people) has disabling hearing\nloss. 4 million are children. They can be hard of hearing or deaf. Deaf people\nmostly have profound hearing loss. Which implies very little or no hearing.\nOver the world, deaf people often communicate using a sign language with\ngestures of both hands and facial expressions. The sign language is a\nfull-fledged natural language with its own grammar and lexicon. Therefore,\nthere is a need for translation models from and to sign languages. In this\nwork, we are interested in the translation of Modern Standard Arabic(MSAr) into\nsign language. We generated a gloss representation from MSAr that extracts the\nfeatures mandatory for the generation of animation signs. Our approach locates\nthe most pertinent features that maintain the meaning of the input Arabic\nsentence.", "published": "2020-05-04 13:56:43", "link": "http://arxiv.org/abs/2005.01497v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What-if I ask you to explain: Explaining the effects of perturbations in\n  procedural text", "abstract": "We address the task of explaining the effects of perturbations in procedural\ntext, an important test of process comprehension. Consider a passage describing\na rabbit's life-cycle: humans can easily explain the effect on the rabbit\npopulation if a female rabbit becomes ill -- i.e., the female rabbit would not\nbecome pregnant, and as a result not have babies leading to a decrease in\nrabbit population. We present QUARTET, a system that constructs such\nexplanations from paragraphs, by modeling the explanation task as a multitask\nlearning problem. QUARTET provides better explanations (based on the sentences\nin the procedural text) compared to several strong baselines on a recent\nprocess comprehension benchmark. We also present a surprising secondary effect:\nour model also achieves a new SOTA with a 7% absolute F1 improvement on a\ndownstream QA task. This illustrates that good explanations do not have to come\nat the expense of end task performance.", "published": "2020-05-04 14:36:23", "link": "http://arxiv.org/abs/2005.01526v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Arguments to Key Points: Towards Automatic Argument Summarization", "abstract": "Generating a concise summary from a large collection of arguments on a given\ntopic is an intriguing yet understudied problem. We propose to represent such\nsummaries as a small set of talking points, termed \"key points\", each scored\naccording to its salience. We show, by analyzing a large dataset of\ncrowd-contributed arguments, that a small number of key points per topic is\ntypically sufficient for covering the vast majority of the arguments.\nFurthermore, we found that a domain expert can often predict these key points\nin advance. We study the task of argument-to-key point mapping, and introduce a\nnovel large-scale dataset for this task. We report empirical results for an\nextensive set of experiments with this dataset, showing promising performance.", "published": "2020-05-04 16:24:21", "link": "http://arxiv.org/abs/2005.01619v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Paradigm Discovery Problem", "abstract": "This work treats the paradigm discovery problem (PDP), the task of learning\nan inflectional morphological system from unannotated sentences. We formalize\nthe PDP and develop evaluation metrics for judging systems. Using currently\navailable resources, we construct datasets for the task. We also devise a\nheuristic benchmark for the PDP and report empirical results on five diverse\nlanguages. Our benchmark system first makes use of word embeddings and string\nsimilarity to cluster forms by cell and by paradigm. Then, we bootstrap a\nneural transducer on top of the clustered data to predict words to realize the\nempty paradigm slots. An error analysis of our system suggests clustering by\ncell across different inflection classes is the most pressing challenge for\nfuture work. Our code and data are available for public use.", "published": "2020-05-04 16:38:54", "link": "http://arxiv.org/abs/2005.01630v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code and Named Entity Recognition in StackOverflow", "abstract": "There is an increasing interest in studying natural language and computer\ncode together, as large corpora of programming texts become readily available\non the Internet. For example, StackOverflow currently has over 15 million\nprogramming related questions written by 8.5 million users. Meanwhile, there is\nstill a lack of fundamental NLP techniques for identifying code tokens or\nsoftware-related named entities that appear within natural language sentences.\nIn this paper, we introduce a new named entity recognition (NER) corpus for the\ncomputer programming domain, consisting of 15,372 sentences annotated with 20\nfine-grained entity types. We trained in-domain BERT representations\n(BERTOverflow) on 152 million sentences from StackOverflow, which lead to an\nabsolute increase of +10 F-1 score over off-the-shelf BERT. We also present the\nSoftNER model which achieves an overall 79.10 F$_1$ score for code and named\nentity recognition on StackOverflow data. Our SoftNER model incorporates a\ncontext-independent code token classifier with corpus-level features to improve\nthe BERT-based tagging model. Our code and data are available at:\nhttps://github.com/jeniyat/StackOverflowNER/", "published": "2020-05-04 16:48:29", "link": "http://arxiv.org/abs/2005.01634v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Tale of a Probe and a Parser", "abstract": "Measuring what linguistic information is encoded in neural models of language\nhas become popular in NLP. Researchers approach this enterprise by training\n\"probes\" - supervised models designed to extract linguistic structure from\nanother model's output. One such probe is the structural probe (Hewitt and\nManning, 2019), designed to quantify the extent to which syntactic information\nis encoded in contextualised word representations. The structural probe has a\nnovel design, unattested in the parsing literature, the precise benefit of\nwhich is not immediately obvious. To explore whether syntactic probes would do\nbetter to make use of existing techniques, we compare the structural probe to a\nmore traditional parser with an identical lightweight parameterisation. The\nparser outperforms structural probe on UUAS in seven of nine analysed\nlanguages, often by a substantial amount (e.g. by 11.1 points in English).\nUnder a second less common metric, however, there is the opposite trend - the\nstructural probe outperforms the parser. This begs the question: which metric\nshould we prefer?", "published": "2020-05-04 16:57:31", "link": "http://arxiv.org/abs/2005.01641v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Explanation Methods for Neural Machine Translation", "abstract": "Recently many efforts have been devoted to interpreting the black-box NMT\nmodels, but little progress has been made on metrics to evaluate explanation\nmethods. Word Alignment Error Rate can be used as such a metric that matches\nhuman understanding, however, it can not measure explanation methods on those\ntarget words that are not aligned to any source word. This paper thereby makes\nan initial attempt to evaluate explanation methods from an alternative\nviewpoint. To this end, it proposes a principled metric based on fidelity in\nregard to the predictive behavior of the NMT model. As the exact computation\nfor this metric is intractable, we employ an efficient approach as its\napproximation. On six standard translation tasks, we quantitatively evaluate\nseveral explanation methods in terms of the proposed metric and we reveal some\nvaluable findings for these explanation methods in our experiments.", "published": "2020-05-04 17:26:25", "link": "http://arxiv.org/abs/2005.01672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast and Robust Unsupervised Contextual Biasing for Speech Recognition", "abstract": "Automatic speech recognition (ASR) system is becoming a ubiquitous\ntechnology. Although its accuracy is closing the gap with that of human level\nunder certain settings, one area that can further improve is to incorporate\nuser-specific information or context to bias its prediction. A common framework\nis to dynamically construct a small language model from the provided contextual\nmini corpus and interpolate its score with the main language model during the\ndecoding process.\n  Here we propose an alternative approach that does not entail explicit\ncontextual language model. Instead, we derive the bias score for every word in\nthe system vocabulary from the training corpus. The method is unique in that 1)\nit does not require meta-data or class-label annotation for the context or the\ntraining corpus. 2) The bias score is proportional to the word's\nlog-probability, thus not only would it bias the provided context, but also\nrobust against irrelevant context (e.g. user mis-specified or in case where it\nis hard to quantify a tight scope). 3) The bias score for the entire vocabulary\nis pre-determined during the training stage, thereby eliminating\ncomputationally expensive language model construction during inference.\n  We show significant improvement in recognition accuracy when the relevant\ncontext is available. Additionally, we also demonstrate that the proposed\nmethod exhibits high tolerance to false-triggering errors in the presence of\nirrelevant context.", "published": "2020-05-04 17:29:59", "link": "http://arxiv.org/abs/2005.01677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What is Learned in Visually Grounded Neural Syntax Acquisition", "abstract": "Visual features are a promising signal for learning bootstrap textual models.\nHowever, blackbox learning models make it difficult to isolate the specific\ncontribution of visual components. In this analysis, we consider the case study\nof the Visually Grounded Neural Syntax Learner (Shi et al., 2019), a recent\napproach for learning syntax from a visual training signal. By constructing\nsimplified versions of the model, we isolate the core factors that yield the\nmodel's strong performance. Contrary to what the model might be capable of\nlearning, we find significantly less expressive versions produce similar\npredictions and perform just as well, or even better. We also find that a\nsimple lexical signal of noun concreteness plays the main role in the model's\npredictions as opposed to more complex syntactic reasoning.", "published": "2020-05-04 17:32:20", "link": "http://arxiv.org/abs/2005.01678v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discrete Optimization for Unsupervised Sentence Summarization with\n  Word-Level Extraction", "abstract": "Automatic sentence summarization produces a shorter version of a sentence,\nwhile preserving its most important information. A good summary is\ncharacterized by language fluency and high information overlap with the source\nsentence. We model these two aspects in an unsupervised objective function,\nconsisting of language modeling and semantic similarity metrics. We search for\na high-scoring summary by discrete optimization. Our proposed method achieves a\nnew state-of-the art for unsupervised sentence summarization according to ROUGE\nscores. Additionally, we demonstrate that the commonly reported ROUGE F1 metric\nis sensitive to summary length. Since this is unwillingly exploited in recent\nwork, we emphasize that future evaluation should explicitly group summarization\nsystems by output length brackets.", "published": "2020-05-04 19:01:55", "link": "http://arxiv.org/abs/2005.01791v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Controllable Text Generation Techniques", "abstract": "Neural controllable text generation is an important area gaining attention\ndue to its plethora of applications. Although there is a large body of prior\nwork in controllable text generation, there is no unifying theme. In this work,\nwe provide a new schema of the pipeline of the generation process by\nclassifying it into five modules. The control of attributes in the generation\nprocess requires modification of these modules. We present an overview of\ndifferent techniques used to perform the modulation of these modules. We also\nprovide an analysis on the advantages and disadvantages of these techniques. We\nfurther pave ways to develop new architectures based on the combination of the\nmodules described in this paper.", "published": "2020-05-04 20:04:47", "link": "http://arxiv.org/abs/2005.01822v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Scanned Receipts", "abstract": "Tasking machines with understanding receipts can have important applications\nsuch as enabling detailed analytics on purchases, enforcing expense policies,\nand inferring patterns of purchase behavior on large collections of receipts.\nIn this paper, we focus on the task of Named Entity Linking (NEL) of scanned\nreceipt line items; specifically, the task entails associating shorthand text\nfrom OCR'd receipts with a knowledge base (KB) of grocery products. For\nexample, the scanned item \"STO BABY SPINACH\" should be linked to the catalog\nitem labeled \"Simple Truth Organic Baby Spinach\". Experiments that employ a\nvariety of Information Retrieval techniques in combination with statistical\nphrase detection shows promise for effective understanding of scanned receipt\ndata.", "published": "2020-05-04 20:20:33", "link": "http://arxiv.org/abs/2005.01828v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Exploring Content Selection in Summarization of Novel Chapters", "abstract": "We present a new summarization task, generating summaries of novel chapters\nusing summary/chapter pairs from online study guides. This is a harder task\nthan the news summarization task, given the chapter length as well as the\nextreme paraphrasing and generalization found in the summaries. We focus on\nextractive summarization, which requires the creation of a gold-standard set of\nextractive summaries. We present a new metric for aligning reference summary\nsentences with chapter sentences to create gold extracts and also experiment\nwith different alignment methods. Our experiments demonstrate significant\nimprovement over prior alignment approaches for our task as shown through\nautomatic metrics and a crowd-sourced pyramid analysis. We make our data\ncollection scripts available at\nhttps://github.com/manestay/novel-chapter-dataset .", "published": "2020-05-04 20:45:39", "link": "http://arxiv.org/abs/2005.01840v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Soft Gazetteers for Low-Resource Named Entity Recognition", "abstract": "Traditional named entity recognition models use gazetteers (lists of\nentities) as features to improve performance. Although modern neural network\nmodels do not require such hand-crafted features for strong performance, recent\nwork has demonstrated their utility for named entity recognition on English\ndata. However, designing such features for low-resource languages is\nchallenging, because exhaustive entity gazetteers do not exist in these\nlanguages. To address this problem, we propose a method of \"soft gazetteers\"\nthat incorporates ubiquitously available information from English knowledge\nbases, such as Wikipedia, into neural named entity recognition models through\ncross-lingual entity linking. Our experiments on four low-resource languages\nshow an average improvement of 4 points in F1 score. Code and data are\navailable at https://github.com/neulab/soft-gazetteers.", "published": "2020-05-04 21:58:02", "link": "http://arxiv.org/abs/2005.01866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FarsBase-KBP: A Knowledge Base Population System for the Persian\n  Knowledge Graph", "abstract": "While most of the knowledge bases already support the English language, there\nis only one knowledge base for the Persian language, known as FarsBase, which\nis automatically created via semi-structured web information. Unlike English\nknowledge bases such as Wikidata, which have tremendous community support, the\npopulation of a knowledge base like FarsBase must rely on automatically\nextracted knowledge. Knowledge base population can let FarsBase keep growing in\nsize, as the system continues working. In this paper, we present a knowledge\nbase population system for the Persian language, which extracts knowledge from\nunlabeled raw text, crawled from the Web. The proposed system consists of a set\nof state-of-the-art modules such as an entity linking module as well as\ninformation and relation extraction modules designed for FarsBase. Moreover, a\ncanonicalization system is introduced to link extracted relations to FarsBase\nproperties. Then, the system uses knowledge fusion techniques with minimal\nintervention of human experts to integrate and filter the proper knowledge\ninstances, extracted by each module. To evaluate the performance of the\npresented knowledge base population system, we present the first gold dataset\nfor benchmarking knowledge base population in the Persian language, which\nconsisting of 22015 FarsBase triples and verified by human experts. The\nevaluation results demonstrate the efficiency of the proposed system.", "published": "2020-05-04 22:51:54", "link": "http://arxiv.org/abs/2005.01879v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop\n  Question Answering", "abstract": "Evidence retrieval is a critical stage of question answering (QA), necessary\nnot only to improve performance, but also to explain the decisions of the\ncorresponding QA method. We introduce a simple, fast, and unsupervised\niterative evidence retrieval method, which relies on three ideas: (a) an\nunsupervised alignment approach to soft-align questions and answers with\njustification sentences using only GloVe embeddings, (b) an iterative process\nthat reformulates queries focusing on terms that are not covered by existing\njustifications, which (c) a stopping criterion that terminates retrieval when\nthe terms in the given question and candidate answers are covered by the\nretrieved justifications. Despite its simplicity, our approach outperforms all\nthe previous methods (including supervised methods) on the evidence selection\ntask on two datasets: MultiRC and QASC. When these evidence sentences are fed\ninto a RoBERTa answer classification component, we achieve state-of-the-art QA\nperformance on these two datasets.", "published": "2020-05-04 00:19:48", "link": "http://arxiv.org/abs/2005.01218v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Noise Pollution in Hospital Readmission Prediction: Long Document\n  Classification with Reinforcement Learning", "abstract": "This paper presents a reinforcement learning approach to extract noise in\nlong clinical documents for the task of readmission prediction after kidney\ntransplant. We face the challenges of developing robust models on a small\ndataset where each document may consist of over 10K tokens with full of noise\nincluding tabular text and task-irrelevant sentences. We first experiment four\ntypes of encoders to empirically decide the best document representation, and\nthen apply reinforcement learning to remove noisy text from the long documents,\nwhich models the noise extraction process as a sequential decision problem. Our\nresults show that the old bag-of-words encoder outperforms deep learning-based\nencoders on this task, and reinforcement learning is able to improve upon\nbaseline while pruning out 25% text segments. Our analysis depicts that\nreinforcement learning is able to identify both typical noisy tokens and\ntask-specific noisy text.", "published": "2020-05-04 04:06:53", "link": "http://arxiv.org/abs/2005.01259v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Adversarial Text Generation by Modeling the Distant Future", "abstract": "Auto-regressive text generation models usually focus on local fluency, and\nmay cause inconsistent semantic meaning in long text generation. Further,\nautomatically generating words with similar semantics is challenging, and\nhand-crafted linguistic rules are difficult to apply. We consider a text\nplanning scheme and present a model-based imitation-learning approach to\nalleviate the aforementioned issues. Specifically, we propose a novel guider\nnetwork to focus on the generative process over a longer horizon, which can\nassist next-word prediction and provide intermediate rewards for generator\noptimization. Extensive experiments demonstrate that the proposed method leads\nto improved performance.", "published": "2020-05-04 05:45:13", "link": "http://arxiv.org/abs/2005.01279v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Sensitivity of Language Models and Humans to Winograd Schema\n  Perturbations", "abstract": "Large-scale pretrained language models are the major driving force behind\nrecent improvements in performance on the Winograd Schema Challenge, a widely\nemployed test of common sense reasoning ability. We show, however, with a new\ndiagnostic dataset, that these models are sensitive to linguistic perturbations\nof the Winograd examples that minimally affect human understanding. Our results\nhighlight interesting differences between humans and language models: language\nmodels are more sensitive to number or gender alternations and synonym\nreplacements than humans, and humans are more stable and consistent in their\npredictions, maintain a much higher absolute performance, and perform better on\nnon-associative instances than associative ones. Overall, humans are correct\nmore often than out-of-the-box models, and the models are sometimes right for\nthe wrong reasons. Finally, we show that fine-tuning on a large, task-specific\ndataset can offer a solution to these issues.", "published": "2020-05-04 09:44:54", "link": "http://arxiv.org/abs/2005.01348v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Systematically Building a Controlled Natural Language for Functional\n  Requirements", "abstract": "[Context] Natural language (NL) is pervasive in software requirements\nspecifications (SRSs). However, despite its popularity and widespread use, NL\nis highly prone to quality issues such as vagueness, ambiguity, and\nincompleteness. Controlled natural languages (CNLs) have been proposed as a way\nto prevent quality problems in requirements documents, while maintaining the\nflexibility to write and communicate requirements in an intuitive and\nuniversally understood manner. [Objective] In collaboration with an industrial\npartner from the financial domain, we systematically develop and evaluate a\nCNL, named Rimay, intended at helping analysts write functional requirements.\n[Method] We rely on Grounded Theory for building Rimay and follow well-known\nguidelines for conducting and reporting industrial case study research.\n[Results] Our main contributions are: (1) a qualitative methodology to\nsystematically define a CNL for functional requirements; this methodology is\ngeneral and applicable to information systems beyond the financial domain, (2)\na CNL grammar to represent functional requirements; this grammar is derived\nfrom our experience in the financial domain, but should be applicable, possibly\nwith adaptations, to other information-system domains, and (3) an empirical\nevaluation of our CNL (Rimay) through an industrial case study. Our\ncontributions draw on 15 representative SRSs, collectively containing 3215 NL\nrequirements statements from the financial domain. [Conclusion] Our evaluation\nshows that Rimay is expressive enough to capture, on average, 88% (405 out of\n460) of the NL requirements statements in four previously unseen SRSs from the\nfinancial domain.", "published": "2020-05-04 09:55:38", "link": "http://arxiv.org/abs/2005.01355v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "To Test Machine Comprehension, Start by Defining Comprehension", "abstract": "Many tasks aim to measure machine reading comprehension (MRC), often focusing\non question types presumed to be difficult. Rarely, however, do task designers\nstart by considering what systems should in fact comprehend. In this paper we\nmake two key contributions. First, we argue that existing approaches do not\nadequately define comprehension; they are too unsystematic about what content\nis tested. Second, we present a detailed definition of comprehension -- a\n\"Template of Understanding\" -- for a widely useful class of texts, namely short\nnarratives. We then conduct an experiment that strongly suggests existing\nsystems are not up to the task of narrative understanding as we define it.", "published": "2020-05-04 14:36:07", "link": "http://arxiv.org/abs/2005.01525v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Compose Like Humans: Jointly Improving the Coherence and Novelty for\n  Modern Chinese Poetry Generation", "abstract": "Chinese poetry is an important part of worldwide culture, and classical and\nmodern sub-branches are quite different. The former is a unique genre and has\nstrict constraints, while the latter is very flexible in length, optional to\nhave rhymes, and similar to modern poetry in other languages. Thus, it requires\nmore to control the coherence and improve the novelty. In this paper, we\npropose a generate-retrieve-then-refine paradigm to jointly improve the\ncoherence and novelty. In the first stage, a draft is generated given keywords\n(i.e., topics) only. The second stage produces a \"refining vector\" from\nretrieval lines. At last, we take into consideration both the draft and the\n\"refining vector\" to generate a new poem. The draft provides future\nsentence-level information for a line to be generated. Meanwhile, the \"refining\nvector\" points out the direction of refinement based on impressive words\ndetection mechanism which can learn good patterns from references and then\ncreate new ones via insertion operation. Experimental results on a collected\nlarge-scale modern Chinese poetry dataset show that our proposed approach can\nnot only generate more coherent poems, but also improve the diversity and\nnovelty.", "published": "2020-05-04 15:16:10", "link": "http://arxiv.org/abs/2005.01556v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Probabilistic Generative Model for Typographical Analysis of Early\n  Modern Printing", "abstract": "We propose a deep and interpretable probabilistic generative model to analyze\nglyph shapes in printed Early Modern documents. We focus on clustering\nextracted glyph images into underlying templates in the presence of multiple\nconfounding sources of variance. Our approach introduces a neural editor model\nthat first generates well-understood printing phenomena like spatial\nperturbations from template parameters via interpertable latent variables, and\nthen modifies the result by generating a non-interpretable latent vector\nresponsible for inking variations, jitter, noise from the archiving process,\nand other unforeseen phenomena associated with Early Modern printing.\nCritically, by introducing an inference network whose input is restricted to\nthe visual residual between the observation and the interpretably-modified\ntemplate, we are able to control and isolate what the vector-valued latent\nvariable captures. We show that our approach outperforms rigid interpretable\nclustering baselines (Ocular) and overly-flexible deep generative models (VAE)\nalike on the task of completely unsupervised discovery of typefaces in\nmixed-font documents.", "published": "2020-05-04 17:01:11", "link": "http://arxiv.org/abs/2005.01646v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Words aren't enough, their order matters: On the Robustness of Grounding\n  Visual Referring Expressions", "abstract": "Visual referring expression recognition is a challenging task that requires\nnatural language understanding in the context of an image. We critically\nexamine RefCOCOg, a standard benchmark for this task, using a human study and\nshow that 83.7% of test instances do not require reasoning on linguistic\nstructure, i.e., words are enough to identify the target object, the word order\ndoesn't matter. To measure the true progress of existing models, we split the\ntest set into two sets, one which requires reasoning on linguistic structure\nand the other which doesn't. Additionally, we create an out-of-distribution\ndataset Ref-Adv by asking crowdworkers to perturb in-domain examples such that\nthe target object changes. Using these datasets, we empirically show that\nexisting methods fail to exploit linguistic structure and are 12% to 23% lower\nin performance than the established progress for this task. We also propose two\nmethods, one based on contrastive learning and the other based on multi-task\nlearning, to increase the robustness of ViLBERT, the current state-of-the-art\nmodel for this task. Our datasets are publicly available at\nhttps://github.com/aws/aws-refcocog-adv", "published": "2020-05-04 17:09:15", "link": "http://arxiv.org/abs/2005.01655v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and\n  Socially-engaged Conversational Agents", "abstract": "We present ADVISER - an open-source, multi-domain dialog system toolkit that\nenables the development of multi-modal (incorporating speech, text and vision),\nsocially-engaged (e.g. emotion recognition, engagement level prediction and\nbackchanneling) conversational agents. The final Python-based implementation of\nour toolkit is flexible, easy to use, and easy to extend not only for\ntechnically experienced users, such as machine learning researchers, but also\nfor less technically experienced users, such as linguists or cognitive\nscientists, thereby providing a flexible platform for collaborative research.\nLink to open-source code: https://github.com/DigitalPhonetics/adviser", "published": "2020-05-04 18:27:58", "link": "http://arxiv.org/abs/2005.01777v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Systematic Media Frame Analysis of 1.5 Million New York Times Articles\n  from 2000 to 2017", "abstract": "Framing is an indispensable narrative device for news media because even the\nsame facts may lead to conflicting understandings if deliberate framing is\nemployed. Therefore, identifying media framing is a crucial step to\nunderstanding how news media influence the public. Framing is, however,\ndifficult to operationalize and detect, and thus traditional media framing\nstudies had to rely on manual annotation, which is challenging to scale up to\nmassive news datasets. Here, by developing a media frame classifier that\nachieves state-of-the-art performance, we systematically analyze the media\nframes of 1.5 million New York Times articles published from 2000 to 2017. By\nexamining the ebb and flow of media frames over almost two decades, we show\nthat short-term frame abundance fluctuation closely corresponds to major\nevents, while there also exist several long-term trends, such as the gradually\nincreasing prevalence of the ``Cultural identity'' frame. By examining specific\ntopics and sentiments, we identify characteristics and dynamics of each frame.\nFinally, as a case study, we delve into the framing of mass shootings,\nrevealing three major framing patterns. Our scalable, computational approach to\nmassive news datasets opens up new pathways for systematic media framing\nstudies.", "published": "2020-05-04 19:25:39", "link": "http://arxiv.org/abs/2005.01803v1", "categories": ["cs.CY", "cs.CL", "J.4"], "primary_category": "cs.CY"}
{"title": "Spying on your neighbors: Fine-grained probing of contextual embeddings\n  for information about surrounding words", "abstract": "Although models using contextual word embeddings have achieved\nstate-of-the-art results on a host of NLP tasks, little is known about exactly\nwhat information these embeddings encode about the context words that they are\nunderstood to reflect. To address this question, we introduce a suite of\nprobing tasks that enable fine-grained testing of contextual embeddings for\nencoding of information about surrounding words. We apply these tasks to\nexamine the popular BERT, ELMo and GPT contextual encoders, and find that each\nof our tested information types is indeed encoded as contextual information\nacross tokens, often with near-perfect recoverability-but the encoders vary in\nwhich features they distribute to which tokens, how nuanced their distributions\nare, and how robust the encoding of each feature is to distance. We discuss\nimplications of these results for how different types of models breakdown and\nprioritize word-level context information when constructing token embeddings.", "published": "2020-05-04 19:34:46", "link": "http://arxiv.org/abs/2005.01810v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Data Augmentation for Hypernymy Detection", "abstract": "The automatic detection of hypernymy relationships represents a challenging\nproblem in NLP. The successful application of state-of-the-art supervised\napproaches using distributed representations has generally been impeded by the\nlimited availability of high quality training data. We have developed two novel\ndata augmentation techniques which generate new training examples from existing\nones. First, we combine the linguistic principles of hypernym transitivity and\nintersective modifier-noun composition to generate additional pairs of vectors,\nsuch as \"small dog - dog\" or \"small dog - animal\", for which a hypernymy\nrelationship can be assumed. Second, we use generative adversarial networks\n(GANs) to generate pairs of vectors for which the hypernymy relation can also\nbe assumed. We furthermore present two complementary strategies for extending\nan existing dataset by leveraging linguistic resources such as WordNet. Using\nan evaluation across 3 different datasets for hypernymy detection and 2\ndifferent vector spaces, we demonstrate that both of the proposed automatic\ndata augmentation and dataset extension strategies substantially improve\nclassifier performance.", "published": "2020-05-04 21:32:12", "link": "http://arxiv.org/abs/2005.01854v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Successfully Applying the Stabilized Lottery Ticket Hypothesis to the\n  Transformer Architecture", "abstract": "Sparse models require less memory for storage and enable a faster inference\nby reducing the necessary number of FLOPs. This is relevant both for\ntime-critical and on-device computations using neural networks. The stabilized\nlottery ticket hypothesis states that networks can be pruned after none or few\ntraining iterations, using a mask computed based on the unpruned converged\nmodel. On the transformer architecture and the WMT 2014 English-to-German and\nEnglish-to-French tasks, we show that stabilized lottery ticket pruning\nperforms similar to magnitude pruning for sparsity levels of up to 85%, and\npropose a new combination of pruning techniques that outperforms all other\ntechniques for even higher levels of sparsity. Furthermore, we confirm that the\nparameter's initial sign and not its specific value is the primary factor for\nsuccessful training, and show that magnitude pruning could be used to find\nwinning lottery tickets.", "published": "2020-05-04 15:17:28", "link": "http://arxiv.org/abs/2005.03454v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Robust Encodings: A Framework for Combating Adversarial Typos", "abstract": "Despite excellent performance on many tasks, NLP systems are easily fooled by\nsmall adversarial perturbations of inputs. Existing procedures to defend\nagainst such perturbations are either (i) heuristic in nature and susceptible\nto stronger attacks or (ii) provide guaranteed robustness to worst-case\nattacks, but are incompatible with state-of-the-art models like BERT. In this\nwork, we introduce robust encodings (RobEn): a simple framework that confers\nguaranteed robustness, without making compromises on model architecture. The\ncore component of RobEn is an encoding function, which maps sentences to a\nsmaller, discrete space of encodings. Systems using these encodings as a\nbottleneck confer guaranteed robustness with standard training, and the same\nencodings can be used across multiple tasks. We identify two desiderata to\nconstruct robust encoding functions: perturbations of a sentence should map to\na small set of encodings (stability), and models using encodings should still\nperform well (fidelity). We instantiate RobEn to defend against a large family\nof adversarial typos. Across six tasks from GLUE, our instantiation of RobEn\npaired with BERT achieves an average robust accuracy of 71.3% against all\nadversarial typos in the family considered, while previous work using a\ntypo-corrector achieves only 35.3% accuracy against a simple greedy attack.", "published": "2020-05-04 01:28:18", "link": "http://arxiv.org/abs/2005.01229v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A New Data Normalization Method to Improve Dialogue Generation by\n  Minimizing Long Tail Effect", "abstract": "Recent neural models have shown significant progress in dialogue generation.\nMost generation models are based on language models. However, due to the Long\nTail Phenomenon in linguistics, the trained models tend to generate words that\nappear frequently in training datasets, leading to a monotonous issue. To\naddress this issue, we analyze a large corpus from Wikipedia and propose three\nfrequency-based data normalization methods. We conduct extensive experiments\nbased on transformers and three datasets respectively collected from social\nmedia, subtitles, and the industrial application. Experimental results\ndemonstrate significant improvements in diversity and informativeness (defined\nas the numbers of nouns and verbs) of generated responses. More specifically,\nthe unigram and bigram diversity are increased by 2.6%-12.6% and 2.2%-18.9% on\nthe three datasets, respectively. Moreover, the informativeness, i.e. the\nnumbers of nouns and verbs, are increased by 4.0%-7.0% and 1.4%-12.1%,\nrespectively. Additionally, the simplicity and effectiveness enable our methods\nto be adapted to different generation models without much extra computational\ncost.", "published": "2020-05-04 05:20:19", "link": "http://arxiv.org/abs/2005.01278v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Does Visual Self-Supervision Improve Learning of Speech Representations\n  for Emotion Recognition?", "abstract": "Self-supervised learning has attracted plenty of recent research interest.\nHowever, most works for self-supervision in speech are typically unimodal and\nthere has been limited work that studies the interaction between audio and\nvisual modalities for cross-modal self-supervision. This work (1) investigates\nvisual self-supervision via face reconstruction to guide the learning of audio\nrepresentations; (2) proposes an audio-only self-supervision approach for\nspeech representation learning; (3) shows that a multi-task combination of the\nproposed visual and audio self-supervision is beneficial for learning richer\nfeatures that are more robust in noisy conditions; (4) shows that\nself-supervised pretraining can outperform fully supervised training and is\nespecially useful to prevent overfitting on smaller sized datasets. We evaluate\nour learned audio representations for discrete emotion recognition, continuous\naffect recognition and automatic speech recognition. We outperform existing\nself-supervised methods for all tested downstream tasks. Our results\ndemonstrate the potential of visual self-supervision for audio feature learning\nand suggest that joint visual and audio self-supervision leads to more\ninformative audio representations for speech and emotion recognition.", "published": "2020-05-04 11:33:40", "link": "http://arxiv.org/abs/2005.01400v3", "categories": ["eess.AS", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Reward Constrained Interactive Recommendation with Natural Language\n  Feedback", "abstract": "Text-based interactive recommendation provides richer user feedback and has\ndemonstrated advantages over traditional interactive recommender systems.\nHowever, recommendations can easily violate preferences of users from their\npast natural-language feedback, since the recommender needs to explore new\nitems for further improvement. To alleviate this issue, we propose a novel\nconstraint-augmented reinforcement learning (RL) framework to efficiently\nincorporate user preferences over time. Specifically, we leverage a\ndiscriminator to detect recommendations violating user historical preference,\nwhich is incorporated into the standard RL objective of maximizing expected\ncumulative future rewards. Our proposed framework is general and is further\nextended to the task of constrained text generation. Empirical results show\nthat the proposed method yields consistent improvement relative to standard RL\nmethods.", "published": "2020-05-04 16:23:34", "link": "http://arxiv.org/abs/2005.01618v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular\n  Summarization Techniques", "abstract": "Following each patient visit, physicians draft long semi-structured clinical\nsummaries called SOAP notes. While invaluable to clinicians and researchers,\ncreating digital SOAP notes is burdensome, contributing to physician burnout.\nIn this paper, we introduce the first complete pipelines to leverage deep\nsummarization models to generate these notes based on transcripts of\nconversations between physicians and patients. After exploring a spectrum of\nmethods across the extractive-abstractive spectrum, we propose Cluster2Sent, an\nalgorithm that (i) extracts important utterances relevant to each summary\nsection; (ii) clusters together related utterances; and then (iii) generates\none summary sentence per cluster. Cluster2Sent outperforms its purely\nabstractive counterpart by 8 ROUGE-1 points, and produces significantly more\nfactual and coherent sentences as assessed by expert human evaluators. For\nreproducibility, we demonstrate similar benefits on the publicly available AMI\ndataset. Our results speak to the benefits of structuring summaries into\nsections and annotating supporting evidence when constructing summarization\ncorpora.", "published": "2020-05-04 19:10:26", "link": "http://arxiv.org/abs/2005.01795v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users\n  Predict Model Behavior?", "abstract": "Algorithmic approaches to interpreting machine learning models have\nproliferated in recent years. We carry out human subject tests that are the\nfirst of their kind to isolate the effect of algorithmic explanations on a key\naspect of model interpretability, simulatability, while avoiding important\nconfounding experimental factors. A model is simulatable when a person can\npredict its behavior on new inputs. Through two kinds of simulation tests\ninvolving text and tabular data, we evaluate five explanations methods: (1)\nLIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a\nComposite approach that combines explanations from each method. Clear evidence\nof method effectiveness is found in very few cases: LIME improves\nsimulatability in tabular classification, and our Prototype method is effective\nin counterfactual simulation tests. We also collect subjective ratings of\nexplanations, but we do not find that ratings are predictive of how helpful\nexplanations are. Our results provide the first reliable and comprehensive\nestimates of how explanations influence simulatability across a variety of\nexplanation methods and data domains. We show that (1) we need to be careful\nabout the metrics we use to evaluate explanation methods, and (2) there is\nsignificant room for improvement in current methods. All our supporting code,\ndata, and models are publicly available at:\nhttps://github.com/peterbhase/InterpretableNLP-ACL2020", "published": "2020-05-04 20:35:17", "link": "http://arxiv.org/abs/2005.01831v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CAiRE-COVID: A Question Answering and Query-focused Multi-Document\n  Summarization System for COVID-19 Scholarly Information Management", "abstract": "We present CAiRE-COVID, a real-time question answering (QA) and\nmulti-document summarization system, which won one of the 10 tasks in the\nKaggle COVID-19 Open Research Dataset Challenge, judged by medical experts. Our\nsystem aims to tackle the recent challenge of mining the numerous scientific\narticles being published on COVID-19 by answering high priority questions from\nthe community and summarizing salient question-related information. It combines\ninformation extraction with state-of-the-art QA and query-focused\nmulti-document summarization techniques, selecting and highlighting evidence\nsnippets from existing literature given a query. We also propose query-focused\nabstractive and extractive multi-document summarization methods, to provide\nmore relevant information related to the question. We further conduct\nquantitative experiments that show consistent improvements on various metrics\nfor each module. We have launched our website CAiRE-COVID for broader use by\nthe medical community, and have open-sourced the code for our system, to\nbootstrap further study by other researches.", "published": "2020-05-04 15:07:27", "link": "http://arxiv.org/abs/2005.03975v3", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding and Detecting Dangerous Speech in Social Media", "abstract": "Social media communication has become a significant part of daily activity in\nmodern societies. For this reason, ensuring safety in social media platforms is\na necessity. Use of dangerous language such as physical threats in online\nenvironments is a somewhat rare, yet remains highly important. Although several\nworks have been performed on the related issue of detecting offensive and\nhateful language, dangerous speech has not previously been treated in any\nsignificant way. Motivated by these observations, we report our efforts to\nbuild a labeled dataset for dangerous speech. We also exploit our dataset to\ndevelop highly effective models to detect dangerous content. Our best model\nperforms at 59.60% macro F1, significantly outperforming a competitive\nbaseline.", "published": "2020-05-04 09:42:09", "link": "http://arxiv.org/abs/2005.06608v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Modelling Grocery Retail Topic Distributions: Evaluation,\n  Interpretability and Stability", "abstract": "Understanding the shopping motivations behind market baskets has high\ncommercial value in the grocery retail industry. Analyzing shopping\ntransactions demands techniques that can cope with the volume and\ndimensionality of grocery transactional data while keeping interpretable\noutcomes. Latent Dirichlet Allocation (LDA) provides a suitable framework to\nprocess grocery transactions and to discover a broad representation of\ncustomers' shopping motivations. However, summarizing the posterior\ndistribution of an LDA model is challenging, while individual LDA draws may not\nbe coherent and cannot capture topic uncertainty. Moreover, the evaluation of\nLDA models is dominated by model-fit measures which may not adequately capture\nthe qualitative aspects such as interpretability and stability of topics.\n  In this paper, we introduce clustering methodology that post-processes\nposterior LDA draws to summarise the entire posterior distribution and identify\nsemantic modes represented as recurrent topics. Our approach is an alternative\nto standard label-switching techniques and provides a single posterior summary\nset of topics, as well as associated measures of uncertainty. Furthermore, we\nestablish a more holistic definition for model evaluation, which assesses topic\nmodels based not only on their likelihood but also on their coherence,\ndistinctiveness and stability. By means of a survey, we set thresholds for the\ninterpretation of topic coherence and topic similarity in the domain of grocery\nretail data. We demonstrate that the selection of recurrent topics through our\nclustering methodology not only improves model likelihood but also outperforms\nthe qualitative aspects of LDA such as interpretability and stability. We\nillustrate our methods on an example from a large UK supermarket chain.", "published": "2020-05-04 21:23:36", "link": "http://arxiv.org/abs/2005.10125v2", "categories": ["stat.AP", "cs.CL", "stat.ME"], "primary_category": "stat.AP"}
{"title": "Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS?", "abstract": "Previous work on speaker adaptation for end-to-end speech synthesis still\nfalls short in speaker similarity. We investigate an orthogonal approach to the\ncurrent speaker adaptation paradigms, speaker augmentation, by creating\nartificial speakers and by taking advantage of low-quality data. The base\nTacotron2 model is modified to account for the channel and dialect factors\ninherent in these corpora. In addition, we describe a warm-start training\nstrategy that we adopted for Tacotron2 training. A large-scale listening test\nis conducted, and a distance metric is adopted to evaluate synthesis of\ndialects. This is followed by an analysis on synthesis quality, speaker and\ndialect similarity, and a remark on the effectiveness of our speaker\naugmentation approach. Audio samples are available online.", "published": "2020-05-04 03:20:35", "link": "http://arxiv.org/abs/2005.01245v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Approximal operator with application to audio inpainting", "abstract": "In their recent evaluation of time-frequency representations and structured\nsparsity approaches to audio inpainting, Lieb and Stark (2018) have used a\nparticular mapping as a proximal operator. This operator serves as the\nfundamental part of an iterative numerical solver. However, their mapping is\nimproperly justified. The present article proves that their mapping is indeed a\nproximal operator, and also derives its proper counterpart. Furthermore, it is\nrationalized that Lieb and Stark's operator can be understood as an\napproximation of the proper mapping. Surprisingly, in most cases, such an\napproximation (referred to as the approximal operator) is shown to provide even\nbetter numerical results in audio inpainting compared to its proper\ncounterpart, while being computationally much more effective.", "published": "2020-05-04 12:46:03", "link": "http://arxiv.org/abs/2005.01437v3", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Noise2Weight: On Detecting Payload Weight from Drones Acoustic Emissions", "abstract": "The increasing popularity of autonomous and remotely-piloted drones have\npaved the way for several use-cases, e.g., merchandise delivery and\nsurveillance. In many scenarios, estimating with zero-touch the weight of the\npayload carried by a drone before its physical approach could be attractive,\ne.g., to provide an early tampering detection.\n  In this paper, we investigate the possibility to remotely detect the weight\nof the payload carried by a commercial drone by analyzing its acoustic\nfingerprint. We characterize the difference in the thrust needed by the drone\nto carry different payloads, resulting in significant variations of the related\nacoustic fingerprint. We applied the above findings to different use-cases,\ncharacterized by different computational capabilities of the detection system.\nResults are striking: using the Mel-Frequency Cepstral Coefficients (MFCC)\ncomponents of the audio signal and different Support Vector Machine (SVM)\nclassifiers, we achieved a minimum classification accuracy of 98% in the\ndetection of the specific payload class carried by the drone, using an\nacquisition time of 0.25 s---performances improve when using longer time\nacquisitions.\n  All the data used for our analysis have been released as open-source, to\nenable the community to validate our findings and use such data as a\nready-to-use basis for further investigations.", "published": "2020-05-04 09:44:18", "link": "http://arxiv.org/abs/2005.01347v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "VisualEchoes: Spatial Image Representation Learning through Echolocation", "abstract": "Several animal species (e.g., bats, dolphins, and whales) and even visually\nimpaired humans have the remarkable ability to perform echolocation: a\nbiological sonar used to perceive spatial layout and locate objects in the\nworld. We explore the spatial cues contained in echoes and how they can benefit\nvision tasks that require spatial reasoning. First we capture echo responses in\nphoto-realistic 3D indoor scene environments. Then we propose a novel\ninteraction-based representation learning framework that learns useful visual\nfeatures via echolocation. We show that the learned image features are useful\nfor multiple downstream vision tasks requiring spatial reasoning---monocular\ndepth estimation, surface normal estimation, and visual navigation---with\nresults comparable or even better than heavily supervised pre-training. Our\nwork opens a new path for representation learning for embodied agents, where\nsupervision comes from interacting with the physical world.", "published": "2020-05-04 16:16:58", "link": "http://arxiv.org/abs/2005.01616v2", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
