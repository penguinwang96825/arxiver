{"title": "On the Conjecture of the Representation Number of Bipartite Graphs", "abstract": "While the problem of determining the representation number of an arbitrary\nword-representable graph is NP-hard, this problem is open even for bipartite\ngraphs. The representation numbers are known for certain bipartite graphs\nincluding all the graphs with at most nine vertices. For bipartite graphs with\npartite sets of sizes $m$ and $n$, Glen et al. conjectured that the\nrepresentation number is at most $\\lceil \\frac{m+n}{4}\\rceil$, where $m+n \\ge\n9$.\n  In this paper, we show that every bipartite graph is $\\left( 1+ \\lceil\n\\frac{m}{2} \\rceil \\right)$-representable, where $m$ is the size of its\nsmallest partite set. Furthermore, if $m$ is odd then we prove that the\nbipartite graphs are $\\lceil \\frac{m}{2} \\rceil $-representable. Accordingly,\nwe establish that the conjecture by Glen et al. holds good for all bipartite\ngraphs leaving the bipartite graphs whose partite sets are of equal and even\nsize. In case of the bipartite graphs with partite sets of equal and even size,\nwe prove the conjecture for certain subclasses using the neighborhood inclusion\ngraph approach.", "published": "2025-06-01 15:52:23", "link": "http://arxiv.org/abs/2506.01057v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "On surjectivity and dynamical properties of dill maps", "abstract": "In this paper, we study certain dynamical properties of dill maps, a class of\nfunctions introduced in~\\cite{salo2015block} that generalizes both cellular\nautomata and substitutions. In particular, we prove that surjective uniform\ndill maps are precisely the surjective cellular automata. We also establish a\nsufficient condition for a dill map to be equicontinuous.", "published": "2025-06-01 11:11:33", "link": "http://arxiv.org/abs/2506.00960v1", "categories": ["math.DS", "cs.DM"], "primary_category": "math.DS"}
{"title": "AI4Contracts: LLM & RAG-Powered Encoding of Financial Derivative Contracts", "abstract": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) are\nreshaping how AI systems extract and organize information from unstructured\ntext. A key challenge is designing AI methods that can incrementally extract,\nstructure, and validate information while preserving hierarchical and\ncontextual relationships. We introduce CDMizer, a template-driven, LLM, and\nRAG-based framework for structured text transformation. By leveraging\ndepth-based retrieval and hierarchical generation, CDMizer ensures a\ncontrolled, modular process that aligns generated outputs with predefined\nschema. Its template-driven approach guarantees syntactic correctness, schema\nadherence, and improved scalability, addressing key limitations of direct\ngeneration methods. Additionally, we propose an LLM-powered evaluation\nframework to assess the completeness and accuracy of structured\nrepresentations. Demonstrated in the transformation of Over-the-Counter (OTC)\nfinancial derivative contracts into the Common Domain Model (CDM), CDMizer\nestablishes a scalable foundation for AI-driven document understanding,\nstructured synthesis, and automated validation in broader contexts.", "published": "2025-06-01 16:05:00", "link": "http://arxiv.org/abs/2506.01063v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Evaluating the Unseen Capabilities: How Many Theorems Do LLMs Know?", "abstract": "Accurate evaluation of large language models (LLMs) is crucial for\nunderstanding their capabilities and guiding their development. However,\ncurrent evaluations often inconsistently reflect the actual capacities of these\nmodels. In this paper, we demonstrate that one of many contributing factors to\nthis \\textit{evaluation crisis} is the oversight of unseen knowledge --\ninformation encoded by LLMs but not directly observed or not yet observed\nduring evaluations. We introduce KnowSum, a statistical framework designed to\nprovide a more comprehensive assessment by quantifying the unseen knowledge for\na class of evaluation tasks. KnowSum estimates the unobserved portion by\nextrapolating from the appearance frequencies of observed knowledge instances.\nWe demonstrate the effectiveness and utility of KnowSum across three critical\napplications: estimating total knowledge, evaluating information retrieval\neffectiveness, and measuring output diversity. Our experiments reveal that a\nsubstantial volume of knowledge is omitted when relying solely on observed LLM\nperformance. Importantly, KnowSum yields significantly different comparative\nrankings for several common LLMs based on their internal knowledge.", "published": "2025-06-01 15:32:44", "link": "http://arxiv.org/abs/2506.02058v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.AP", "stat.ME"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap: From Ad-hoc to Proactive Search in Conversations", "abstract": "Proactive search in conversations (PSC) aims to reduce user effort in\nformulating explicit queries by proactively retrieving useful relevant\ninformation given conversational context. Previous work in PSC either directly\nuses this context as input to off-the-shelf ad-hoc retrievers or further\nfine-tunes them on PSC data. However, ad-hoc retrievers are pre-trained on\nshort and concise queries, while the PSC input is longer and noisier. This\ninput mismatch between ad-hoc search and PSC limits retrieval quality. While\nfine-tuning on PSC data helps, its benefits remain constrained by this input\ngap. In this work, we propose Conv2Query, a novel conversation-to-query\nframework that adapts ad-hoc retrievers to PSC by bridging the input gap\nbetween ad-hoc search and PSC. Conv2Query maps conversational context into\nad-hoc queries, which can either be used as input for off-the-shelf ad-hoc\nretrievers or for further fine-tuning on PSC data. Extensive experiments on two\nPSC datasets show that Conv2Query significantly improves ad-hoc retrievers'\nperformance, both when used directly and after fine-tuning on PSC.", "published": "2025-06-01 12:30:58", "link": "http://arxiv.org/abs/2506.00983v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "H.3.3"], "primary_category": "cs.IR"}
{"title": "AliBoost: Ecological Boosting Framework in Alibaba Platform", "abstract": "Maintaining a healthy ecosystem in billion-scale online platforms is\nchallenging, as users naturally gravitate toward popular items, leaving cold\nand less-explored items behind. This ''rich-get-richer'' phenomenon hinders the\ngrowth of potentially valuable cold items and harms the platform's ecosystem.\nExisting cold-start models primarily focus on improving initial recommendation\nperformance for cold items but fail to address users' natural preference for\npopular content. In this paper, we introduce AliBoost, Alibaba's ecological\nboosting framework, designed to complement user-oriented natural\nrecommendations and foster a healthier ecosystem. AliBoost incorporates a\ntiered boosting structure and boosting principles to ensure high-potential\nitems quickly gain exposure while minimizing disruption to low-potential items.\nTo achieve this, we propose the Stacking Fine-Tuning Cold Predictor to enhance\nthe foundation CTR model's performance on cold items for accurate CTR and\npotential prediction. AliBoost then employs an Item-oriented Bidding Boosting\nmechanism to deliver cold items to the most suitable users while balancing\nboosting speed with user-personalized preferences. Over the past six months,\nAliBoost has been deployed across Alibaba's mainstream platforms, successfully\ncold-starting over a billion new items and increasing both clicks and GMV of\ncold items by over 60% within 180 days. Extensive online analysis and A/B\ntesting demonstrate the effectiveness of AliBoost in addressing ecological\nchallenges, offering new insights into the design of billion-scale recommender\nsystems.", "published": "2025-06-01 10:56:18", "link": "http://arxiv.org/abs/2506.00954v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Breaker: Removing Shortcut Cues with User Clustering for Single-slot Recommendation System", "abstract": "In a single-slot recommendation system, users are only exposed to one item at\na time, and the system cannot collect user feedback on multiple items\nsimultaneously. Therefore, only pointwise modeling solutions can be adopted,\nfocusing solely on modeling the likelihood of clicks or conversions for items\nby users to learn user-item preferences, without the ability to capture the\nranking information among different items directly. However, since user-side\ninformation is often much more abundant than item-side information, the model\ncan quickly learn the differences in user intrinsic tendencies, which are\nindependent of the items they are exposed to. This can cause these intrinsic\ntendencies to become a shortcut bias for the model, leading to insufficient\nmining of the most concerned user-item preferences. To solve this challenge, we\nintroduce the Breaker model. Breaker integrates an auxiliary task of user\nrepresentation clustering with a multi-tower structure for cluster-specific\npreference modeling. By clustering user representations, we ensure that users\nwithin each cluster exhibit similar characteristics, which increases the\ncomplexity of the pointwise recommendation task on the user side. This forces\nthe multi-tower structure with cluster-driven parameter learning to better\nmodel user-item preferences, ultimately eliminating shortcut biases related to\nuser intrinsic tendencies. In terms of training, we propose a delayed parameter\nupdate mechanism to enhance training stability and convergence, enabling\nend-to-end joint training of the auxiliary clustering and classification tasks.\nBoth offline and online experiments demonstrate that our method surpasses the\nbaselines. It has already been deployed and is actively serving tens of\nmillions of users daily on Meituan, one of the most popular e-commerce\nplatforms for services.", "published": "2025-06-01 04:23:06", "link": "http://arxiv.org/abs/2506.00828v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "DFRC Systems Co-existing in Licensed Spectrum: Cognitive Beamforming Designs", "abstract": "This paper introduces a dual-function radar-communication (DFRC) system with\ncognitive radio capability to tackle the spectral scarcity problem in wireless\ncommunications. Particularly, a cognitive DFRC system operates on a spectrum\nowned by a primary system to simultaneously perform data communication and\ntarget tracking with the condition that its interference to the primary users\n(PUs) is below a certain threshold. To achieve this, an optimization problem is\nformulated to jointly design the beamforming vectors for both the radar and\ncommunication functions in such a way that the mean square error (MSE) of the\nbeam pattern between the designed and desired waveforms is minimized. The\noptimization problem has the following three constraints: i) the\nsignal-to-interference-plus-noise ratio (SINR) at each data communication user\nis above a predetermined level; ii) the per-antenna transmit power is\nmaintained at a given level; iii) the interference imposed on each PU is below\na certain threshold. Both the semidefinite relaxation and nature-inspired\nfirefly algorithms are proposed in order to search for the optimal solutions to\nthe optimization problem. The simulation results indicate that our proposed\nalgorithms can enable the DFRC system to protect the PUs while simultaneously\nperforming its communication and radar functions.", "published": "2025-06-01 22:36:48", "link": "http://arxiv.org/abs/2506.01202v2", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Linear regression with overparameterized linear neural networks: Tight upper and lower bounds for implicit $\\ell^1$-regularization", "abstract": "Modern machine learning models are often trained in a setting where the\nnumber of parameters exceeds the number of training samples. To understand the\nimplicit bias of gradient descent in such overparameterized models, prior work\nhas studied diagonal linear neural networks in the regression setting. These\nstudies have shown that, when initialized with small weights, gradient descent\ntends to favor solutions with minimal $\\ell^1$-norm - an effect known as\nimplicit regularization. In this paper, we investigate implicit regularization\nin diagonal linear neural networks of depth $D\\ge 2$ for overparameterized\nlinear regression problems. We focus on analyzing the approximation error\nbetween the limit point of gradient flow trajectories and the solution to the\n$\\ell^1$-minimization problem. By deriving tight upper and lower bounds on the\napproximation error, we precisely characterize how the approximation error\ndepends on the scale of initialization $\\alpha$. Our results reveal a\nqualitative difference between depths: for $D \\ge 3$, the error decreases\nlinearly with $\\alpha$, whereas for $D=2$, it decreases at rate\n$\\alpha^{1-\\varrho}$, where the parameter $\\varrho \\in [0,1)$ can be explicitly\ncharacterized. Interestingly, this parameter is closely linked to so-called\nnull space property constants studied in the sparse recovery literature. We\ndemonstrate the asymptotic tightness of our bounds through explicit examples.\nNumerical experiments corroborate our theoretical findings and suggest that\ndeeper networks, i.e., $D \\ge 3$, may lead to better generalization,\nparticularly for realistic initialization scales.", "published": "2025-06-01 19:55:31", "link": "http://arxiv.org/abs/2506.01143v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.OC"], "primary_category": "stat.ML"}
{"title": "Learning DNF through Generalized Fourier Representations", "abstract": "The Fourier representation for the uniform distribution over the Boolean cube\nhas found numerous applications in algorithms and complexity analysis. Notably,\nin learning theory, learnability of Disjunctive Normal Form (DNF) under uniform\nas well as product distributions has been established through such\nrepresentations. This paper makes five main contributions. First, it introduces\na generalized Fourier expansion that can be used with any distribution $D$\nthrough the representation of the distribution as a Bayesian network (BN).\nSecond, it shows that the main algorithmic tools for learning with the Fourier\nrepresentation, that use membership queries to approximate functions by\nrecovering their heavy Fourier coefficients, can be used with slight\nmodifications with the generalized expansion. These results hold for any\ndistribution. Third, it analyzes the $L_1$ spectral norm of conjunctions under\nthe new expansion, showing that it is bounded for a class of distributions\nwhich can be represented by difference bounded tree BN, where a parent node in\nthe BN representation can change the conditional expectation of a child node by\nat most $\\alpha<0.5$. Lower bounds are presented to show that such constraints\nare necessary. The fourth contribution uses these results to show the\nlearnability of DNF with membership queries under difference bounded tree BN.\nThe final contribution is to develop an algorithm for learning\ndifference-bounded tree BN distributions, thus extending the DNF learnability\nresult to cases where the distribution is not known in advance.", "published": "2025-06-01 16:24:44", "link": "http://arxiv.org/abs/2506.01075v1", "categories": ["cs.DS", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.DS"}
{"title": "A Generic Construction on Self-orthogonal Algebraic Geometric Codes and Its Applications", "abstract": "In the realm of algebraic geometric (AG) codes, characterizing dual codes has\nlong been a challenging task. In this paper we introduces a generalized\ncriterion to characterize self-orthogonality of AG codes based on residues,\ndrawing upon the rich algebraic structures of finite fields and the geometric\nproperties of algebraic curves. We also present a generic construction of\nself-orthogonal AG codes from self-dual MDS codes. Using these approaches, we\nconstruct several families of self-dual and almost self-dual AG codes. These\ncodes combine two merits: good performance as AG code whose parameters are\nclose to the Singleton bound together with Euclidean (or Hermtian)\nself-dual/self-orthogonal property. Furthermore, some AG codes with Hermitian\nself-orthogonality can be applied to construct quantum codes with notably good\nparameters.", "published": "2025-06-01 12:50:29", "link": "http://arxiv.org/abs/2506.00994v1", "categories": ["cs.IT", "math.IT", "94B27"], "primary_category": "cs.IT"}
{"title": "Blind Passive Beamforming for MIMO System", "abstract": "Passive beamforming for the intelligent surface (IS)-aided multiple-input\nmultiple-output (MIMO) communication is a difficult nonconvex problem. It\nbecomes even more challenging under the practical discrete constraints on phase\nshifts. Unlike most of the existing approaches that rely on the channel state\ninformation (CSI), this work advocates a blind beamforming strategy without any\nCSI. Simply put, we propose a statistical method that learns the main feature\nof the wireless environment from the random samples of received signal power.\nField tests in the 5G commercial network demonstrate the superiority of the\nproposed blind passive beamforming method.", "published": "2025-06-01 12:43:36", "link": "http://arxiv.org/abs/2506.00987v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Constructions of Optimal Frequency-Hopping Sequences with Controlled Minimum Gaps", "abstract": "Frequency-hopping sequences (FHSs) with low Hamming correlation and wide gaps\nsignificantly contribute to the anti-interference performance in FH\ncommunication systems. This paper investigates FHSs with optimal Hamming\ncorrelation and controlled minimum gaps. We start with the discussion of the\nupper bounds on the minimum gaps of uniform FHSs and then propose a general\nconstruction of optimal uniform wide-gap FHSs with length 2l and 3l, which\nincludes the work by Li et al. in IEEE Trans. Inf. Theory, vol. 68, no. 1, 2022\nas a special case. Furthermore, we present a recursive construction of FHSs\nwith length 2l, which concatenate shorter sequences of known minimum gaps. It\nis shown that the resulting FHSs have the same Hamming correlation as the\nconcatenation-ordering sequences. As applications, several known optimal FHSs\nare used to produce optimal FHSs with controlled minimum gaps.", "published": "2025-06-01 10:29:47", "link": "http://arxiv.org/abs/2506.00945v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Three-Dimensional Channel Modeling for Molecular Communications in Tubular Environments with Heterogeneous Boundary Conditions", "abstract": "Molecular communication (MC), one of the emerging techniques in the field of\ncommunication, is entering a new phase following several decades of\nfoundational research. Recently, attention has shifted toward MC in liquid\nmedia, particularly within tubular environments, due to novel application\nscenarios. The spatial constraints of such environments make accurate modeling\nof molecular movement in tubes more challenging than in traditional free-space\nchannels. In this paper, we propose a three-dimensional channel model for\nmolecular communications with an absorbing ring-shaped receiver in a tubular\nenvironment. To the best of our knowledge, this is the first theoretical study\nto model the impact of an absorbing ring-shaped receiver on the channel\nresponse in tube-based MC systems. The problem is formulated as a partial\ndifferential equation with heterogeneous boundary conditions, and an\napproximate solution is derived under flow-dominated conditions. The accuracy\nof the proposed model is validated through particle-based simulations. We\nanticipate that the results of this study will contribute to the design of\npractical MC systems in real-world tubular environments.", "published": "2025-06-01 03:07:12", "link": "http://arxiv.org/abs/2506.00803v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Robust and Safe Multi-Agent Reinforcement Learning Framework with Communication for Autonomous Vehicles", "abstract": "Deep multi-agent reinforcement learning (MARL) has been demonstrated\neffectively in simulations for many multi-robot problems. For autonomous\nvehicles, the development of vehicle-to-vehicle (V2V) communication\ntechnologies provide opportunities to further enhance safety of the system.\nHowever, zero-shot transfer of simulator-trained MARL policies to hardware\ndynamic systems remains challenging, and how to leverage communication and\nshared information for MARL has limited demonstrations on hardware. This\nproblem is challenged by discrepancies between simulated and physical states,\nsystem state and model uncertainties, practical shared information design, and\nthe need for safety guarantees in both simulation and hardware. This paper\nintroduces RSR-RSMARL, a novel Robust and Safe MARL framework that supports\nReal-Sim-Real (RSR) policy adaptation for multi-agent systems with\ncommunication among agents, with both simulation and hardware demonstrations.\nRSR-RSMARL leverages state (includes shared state information among agents) and\naction representations considering real system complexities for MARL\nformulation. The MARL policy is trained with robust MARL algorithm to enable\nzero-shot transfer to hardware considering the sim-to-real gap. A safety shield\nmodule using Control Barrier Functions (CBFs) provides safety guarantee for\neach individual agent. Experiment results on F1/10th-scale autonomous vehicles\nwith V2V communication demonstrate the ability of RSR-RSMARL framework to\nenhance driving safety and coordination across multiple configurations. These\nfindings emphasize the importance of jointly designing robust policy\nrepresentations and modular safety architectures to enable scalable,\ngeneralizable RSR transfer in multi-agent autonomy.", "published": "2025-06-01 12:29:53", "link": "http://arxiv.org/abs/2506.00982v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Will Agents Replace Us? Perceptions of Autonomous Multi-Agent AI", "abstract": "Autonomous multi-agent AI systems are poised to transform various industries,\nparticularly software development and knowledge work. Understanding current\nperceptions among professionals is crucial for anticipating adoption\nchallenges, ethical considerations, and future workforce development. This\nstudy analyzes responses from 130 participants to a survey on the capabilities,\nimpact, and governance of AI agents. We explore expected timelines for AI\nreplacing programmers, identify perceived barriers to deployment, and examine\nbeliefs about responsibility when agents make critical decisions. Key findings\nreveal three distinct clusters of respondents. While the study explored factors\nassociated with current AI agent deployment, the initial logistic regression\nmodel did not yield statistically significant predictors, suggesting that\ndeployment decisions are complex and may be influenced by factors not fully\ncaptured or that a larger sample is needed. These insights highlight the need\nfor organizations to address compliance concerns (a commonly cited barrier) and\nestablish clear governance frameworks as they integrate autonomous agents into\ntheir workflows.", "published": "2025-06-01 11:02:52", "link": "http://arxiv.org/abs/2506.02055v1", "categories": ["cs.CY", "cs.AI", "cs.MA", "I.2.m"], "primary_category": "cs.CY"}
{"title": "EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration", "abstract": "We introduce EvoGit, a decentralized multi-agent framework for collaborative\nsoftware development driven by autonomous code evolution. EvoGit deploys a\npopulation of independent coding agents, each proposing edits to a shared\ncodebase without centralized coordination, explicit message passing, or shared\nmemory. Instead, all coordination emerges through a Git-based phylogenetic\ngraph that tracks the full version lineage and enables agents to asynchronously\nread from and write to the evolving code repository. This graph-based structure\nsupports fine-grained branching, implicit concurrency, and scalable agent\ninteraction while preserving a consistent historical record. Human involvement\nis minimal but strategic: users define high-level goals, periodically review\nthe graph, and provide lightweight feedback to promote promising directions or\nprune unproductive ones. Experiments demonstrate EvoGit's ability to\nautonomously produce functional and modular software artifacts across two\nreal-world tasks: (1) building a web application from scratch using modern\nframeworks, and (2) constructing a meta-level system that evolves its own\nlanguage-model-guided solver for the bin-packing optimization problem. Our\nresults underscore EvoGit's potential to establish a new paradigm for\ndecentralized, automated, and continual software development. EvoGit is\nopen-sourced at https://github.com/BillHuang2001/evogit.", "published": "2025-06-01 05:20:42", "link": "http://arxiv.org/abs/2506.02049v1", "categories": ["cs.DC", "cs.AI", "cs.MA", "cs.NE"], "primary_category": "cs.DC"}
{"title": "Improving Multi-Vehicle Perception Fusion with Millimeter-Wave Radar Assistance", "abstract": "Cooperative perception enables vehicles to share sensor readings and has\nbecome a new paradigm to improve driving safety, where the key enabling\ntechnology for realizing this vision is to real-time and accurately align and\nfuse the perceptions. Recent advances to align the views rely on high-density\nLiDAR data or fine-grained image feature representations, which however fail to\nmeet the requirements of accuracy, real-time, and adaptability for autonomous\ndriving. To this end, we present MMatch, a lightweight system that enables\naccurate and real-time perception fusion with mmWave radar point clouds. The\nkey insight is that fine-grained spatial information provided by the radar\npresent unique associations with all the vehicles even in two separate views.\nAs a result, by capturing and understanding the unique local and global\nposition of the targets in this association, we can quickly find out all the\nco-visible vehicles for view alignment. We implement MMatch on both the\ndatasets collected from the CARLA platform and the real-world traffic with over\n15,000 radar point cloud pairs. Experimental results show that MMatch achieves\ndecimeter-level accuracy within 59ms, which significantly improves the\nreliability for autonomous driving.", "published": "2025-06-01 04:58:33", "link": "http://arxiv.org/abs/2506.00837v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Sharp error bounds for approximate eigenvalues and singular values from subspace methods", "abstract": "Subspace methods are commonly used for finding approximate eigenvalues and\nsingular values of large-scale matrices. Once a subspace is found, the\nRayleigh-Ritz method (for symmetric eigenvalue problems) and Petrov-Galerkin\nprojection (for singular values) are the de facto method for extraction of\neigenvalues and singular values. In this work we derive quadratic error bounds\nfor approximate eigenvalues obtained via the Rayleigh-Ritz process. Our bounds\ntake advantage of the fact that extremal eigenpairs tend to converge faster\nthan the rest, hence having smaller residuals $\\|A\\widehat x_i-\\theta_i\\widehat\nx_i\\|_2$, where $(\\theta_i,\\widehat x_i)$ is a Ritz pair (approximate\neigenpair). The proof uses the structure of the perturbation matrix underlying\nthe Rayleigh-Ritz method to bound the components of its eigenvectors. In this\nway, we obtain a bound of the form $c\\frac{\\|A\\widehat x_i-\\theta_i\\widehat\nx_i\\|_2^2}{\\eta_i}$, where $\\eta_i$ is roughly the gap between the $i$th Ritz\nvalue and the eigenvalues that are not approximated by the Ritz process, and\n$c> 1$ is a modest scalar. Our bound is adapted to each Ritz value and is\nrobust to clustered Ritz values, which is a key improvement over existing\nresults. We further show that the bound is asymptotically sharp, and generalize\nit to singular values of arbitrary real matrices. Finally, we apply these\nbounds to several methods for computing eigenvalues and singular values, and\nillustrate the sharpness of our bounds in a number of computational settings,\nincluding Krylov methods and randomized algorithms.", "published": "2025-06-01 22:55:14", "link": "http://arxiv.org/abs/2506.01207v1", "categories": ["math.NA", "cs.NA", "65F15, 15A18, 15A42, 68W20"], "primary_category": "math.NA"}
{"title": "Computing matrix $\\varphi$-functions arising in exponential integrators", "abstract": "A new scaling and recovering algorithm is proposed for simultaneously\ncomputing the matrix $\\varphi$-functions that arise in exponential integrator\nmethods for the numerical solution of certain first-order systems of ordinary\ndifferential equations (ODEs). The algorithm initially scales the input matrix\ndown by a nonnegative integer power of two, then computes the $[m/m]$ diagonal\nPad\\'e approximant to $\\varphi_p$, where $p$ is the largest index of interest.\nThe remaining $[m+p{-}j/m]$ Pad\\'e approximants to $\\varphi_j$, $0 \\le j < p$,\nare obtained implicitly via a recurrence relation. The effect of scaling is\nsubsequently recovered using the double-argument formula. A rigorous backward\nerror analysis, based on the $[m+p/m]$ Pad\\'e approximant to the exponential,\nenables sharp bounds on the relative backward errors. These bounds are\nexpressed in terms of the sequence $\\|A^k\\|^{1/k}$, which can be much smaller\nthan $\\|A\\|$ for nonnormal matrices. The scaling parameter and the degrees of\nthe Pad\\'e approximants are selected to minimize the overall computational\ncost, which benefits from the a priori sharpness of the bounds and the optimal\nevaluation schemes for diagonal Pad\\'e approximants. Furthermore, if the input\nmatrix is (quasi-)triangular, the algorithm exploits its structure in the\nrecovering phase. Numerical experiments demonstrate the superiority of the\nproposed algorithm over existing alternatives in both accuracy and efficiency.", "published": "2025-06-01 22:05:10", "link": "http://arxiv.org/abs/2506.01193v1", "categories": ["math.NA", "cs.NA", "65F60, 65F30, 65L05, 15A60"], "primary_category": "math.NA"}
{"title": "A Positivity-Preserving Finite Element Framework for Accurate Dose Computation in Proton Therapy", "abstract": "We present a stabilised finite element method for modelling proton transport\nin tissue, incorporating both inelastic energy loss and elastic angular\nscattering. A key innovation is a positivity-preserving formulation that\nguarantees non-negative fluence and dose, even on coarse meshes. This enables\nreliable computation of clinically relevant quantities for treatment planning.\nWe derive a priori error estimates demonstrating optimal convergence rates and\nvalidate the method through numerical benchmarks. The proposed framework\nprovides a robust, accurate and efficient tool for advancing proton beam\ntherapy.", "published": "2025-06-01 18:07:47", "link": "http://arxiv.org/abs/2506.01105v1", "categories": ["math.NA", "cs.NA", "physics.med-ph"], "primary_category": "math.NA"}
{"title": "Convergence Analysis of An Alternating Nonlinear GMRES on Linear Systems", "abstract": "In this work, we develop an alternating nonlinear Generalized Minimum\nResidual (NGMRES) algorithm with depth $m$ and periodicity $p$, denoted by\naNGMRES($m,p$), applied to linear systems. We provide a theoretical analysis to\nquantify by how much aNGMRES($m$) can improve the convergence speed of the\nunderlying fixed-point iteration for diagonalizable and symmetric positive\ndefinite cases. Our theoretical analysis gives us a better understanding of\nwhich factors affect the convergence speed. Moreover, under certain conditions,\nwe prove the periodic equivalence between aNGMRES applied to Richardson\niteration and GMRES. Specifically, aNGMRES($\\infty,p$) and full GMRES are\nidentical at the iteration index $jp$. aNGMRES($\\infty,p$) can be regarded as\nan alternative to GMRES for solving linear systems. For finite $m$, the\niterates of aNGMRES($m,m+1$) and restarted GMRES (GMRES($m+1$)) are the same at\nthe end of each periodic interval of length $p$, i.e, at the iteration index\n$jp$. The advantages of aNGMRES($m,p$) method are that there is no need to\nsolve a least-squares problem at each iteration which can reduce the\ncomputational cost, and it can enhance the robustness against stagnations,\nwhich could occur for NGMRES($m$).", "published": "2025-06-01 16:52:46", "link": "http://arxiv.org/abs/2506.01081v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Physics-Informed Neural Networks for the Relativistic Burgers Equation in the Exterior of a Schwarzschild Black Hole", "abstract": "We introduce a Physics-Informed Neural Networks(PINN) to solve a relativistic\nBurgers equation in the exterior domain of a Schwarzschild black hole. Our main\ncontribution is a PINN architecture that is able to simulate shock wave\nformations in such curved spacetime, by training a shock-aware network block\nand introducing a Godunov-inspired residuals in the loss function. We validate\nour method with numerical experiments with different kinds of initial\nconditions. We show its ability to reproduce both smooth and discontinuous\nsolutions in the context of general relativity.", "published": "2025-06-01 10:51:34", "link": "http://arxiv.org/abs/2506.00951v2", "categories": ["math.NA", "cs.NA", "gr-qc"], "primary_category": "math.NA"}
{"title": "Deformable registration and generative modelling of aortic anatomies by auto-decoders and neural ODEs", "abstract": "This work introduces AD-SVFD, a deep learning model for the deformable\nregistration of vascular shapes to a pre-defined reference and for the\ngeneration of synthetic anatomies. AD-SVFD operates by representing each\ngeometry as a weighted point cloud and models ambient space deformations as\nsolutions at unit time of ODEs, whose time-independent right-hand sides are\nexpressed through artificial neural networks. The model parameters are\noptimized by minimizing the Chamfer Distance between the deformed and reference\npoint clouds, while backward integration of the ODE defines the inverse\ntransformation. A distinctive feature of AD-SVFD is its auto-decoder structure,\nthat enables generalization across shape cohorts and favors efficient weight\nsharing. In particular, each anatomy is associated with a low-dimensional code\nthat acts as a self-conditioning field and that is jointly optimized with the\nnetwork parameters during training. At inference, only the latent codes are\nfine-tuned, substantially reducing computational overheads. Furthermore, the\nuse of implicit shape representations enables generative applications: new\nanatomies can be synthesized by suitably sampling from the latent space and\napplying the corresponding inverse transformations to the reference geometry.\nNumerical experiments, conducted on healthy aortic anatomies, showcase the\nhigh-quality results of AD-SVFD, which yields extremely accurate approximations\nat competitive computational costs.", "published": "2025-06-01 10:30:58", "link": "http://arxiv.org/abs/2506.00947v1", "categories": ["cs.CV", "cs.NA", "math.NA", "68T07, 68U05,", "J.3; I.2.m; I.4.m"], "primary_category": "cs.CV"}
{"title": "Learning to optimize convex risk measures: The cases of utility-based shortfall risk and optimized certainty equivalent risk", "abstract": "We consider the problems of estimation and optimization of two popular convex\nrisk measures: utility-based shortfall risk (UBSR) and Optimized Certainty\nEquivalent (OCE) risk. We extend these risk measures to cover possibly\nunbounded random variables. We cover prominent risk measures like the entropic\nrisk, expectile risk, monotone mean-variance risk, Value-at-Risk, and\nConditional Value-at-Risk as few special cases of either the UBSR or the OCE\nrisk. In the context of estimation, we derive non-asymptotic bounds on the mean\nabsolute error (MAE) and mean-squared error (MSE) of the classical sample\naverage approximation (SAA) estimators of both, the UBSR and the OCE. Next, in\nthe context of optimization, we derive expressions for the UBSR gradient and\nthe OCE gradient under a smooth parameterization. Utilizing these expressions,\nwe propose gradient estimators for both, the UBSR and the OCE. We use the SAA\nestimator of UBSR in both these gradient estimators, and derive non-asymptotic\nbounds on MAE and MSE for the proposed gradient estimation schemes. We\nincorporate the aforementioned gradient estimators into a stochastic gradient\n(SG) algorithm for optimization. Finally, we derive non-asymptotic bounds that\nquantify the rate of convergence of our SG algorithm for the optimization of\nthe UBSR and the OCE risk measure.", "published": "2025-06-01 17:53:15", "link": "http://arxiv.org/abs/2506.01101v1", "categories": ["cs.CE", "q-fin.MF", "stat.CO"], "primary_category": "cs.CE"}
{"title": "Markovian projections for functionals of It\u00f4 semimartingales with jumps", "abstract": "Given an It\\^o semimartingale $X$, its Markovian projection is an It\\^o\nsemimartingale $\\widehat{X}$, with Markovian differential characteristics, that\nmatches the one-dimensional marginal laws of $X$. One may even require certain\nfunctionals of the two processes to have the same fixed-time marginals, at the\ncost of enhancing the differential characteristics of $\\widehat{X}$ but still\nin a Markovian sense. In the continuous case, the definitive result on\nexistence of Markovian projections was obtained by Brunick and\nShreve~\\cite{MR3098443}. In this paper, we extend their result to the fully\ngeneral setting of It\\^o semimartingales with jumps.", "published": "2025-06-01 00:36:23", "link": "http://arxiv.org/abs/2506.00762v1", "categories": ["math.PR", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "On the Stability of Graph Convolutional Neural Networks: A Probabilistic Perspective", "abstract": "Graph convolutional neural networks (GCNNs) have emerged as powerful tools\nfor analyzing graph-structured data, achieving remarkable success across\ndiverse applications. However, the theoretical understanding of the stability\nof these models, i.e., their sensitivity to small changes in the graph\nstructure, remains in rather limited settings, hampering the development and\ndeployment of robust and trustworthy models in practice. To fill this gap, we\nstudy how perturbations in the graph topology affect GCNN outputs and propose a\nnovel formulation for analyzing model stability. Unlike prior studies that\nfocus only on worst-case perturbations, our distribution-aware formulation\ncharacterizes output perturbations across a broad range of input data. This\nway, our framework enables, for the first time, a probabilistic perspective on\nthe interplay between the statistical properties of the node data and\nperturbations in the graph topology. We conduct extensive experiments to\nvalidate our theoretical findings and demonstrate their benefits over existing\nbaselines, in terms of both representation stability and adversarial attacks on\ndownstream tasks. Our results demonstrate the practical significance of the\nproposed formulation and highlight the importance of incorporating data\ndistribution into stability analysis.", "published": "2025-06-01 23:17:19", "link": "http://arxiv.org/abs/2506.01213v2", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Dynamic Modes as Time Representation for Spatiotemporal Forecasting", "abstract": "This paper introduces a data-driven time embedding method for modeling\nlong-range seasonal dependencies in spatiotemporal forecasting tasks. The\nproposed approach employs Dynamic Mode Decomposition (DMD) to extract temporal\nmodes directly from observed data, eliminating the need for explicit timestamps\nor hand-crafted time features. These temporal modes serve as time\nrepresentations that can be seamlessly integrated into deep spatiotemporal\nforecasting models. Unlike conventional embeddings such as time-of-day\nindicators or sinusoidal functions, our method captures complex multi-scale\nperiodicity through spectral analysis of spatiotemporal data. Extensive\nexperiments on urban mobility, highway traffic, and climate datasets\ndemonstrate that the DMD-based embedding consistently improves long-horizon\nforecasting accuracy, reduces residual correlation, and enhances temporal\ngeneralization. The method is lightweight, model-agnostic, and compatible with\nany architecture that incorporates time covariates.", "published": "2025-06-01 23:16:39", "link": "http://arxiv.org/abs/2506.01212v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Uncovering Bias Mechanisms in Observational Studies", "abstract": "Observational studies are a key resource for causal inference but are often\naffected by systematic biases. Prior work has focused mainly on detecting these\nbiases, via sensitivity analyses and comparisons with randomized controlled\ntrials, or mitigating them through debiasing techniques. However, there remains\na lack of methodology for uncovering the underlying mechanisms driving these\nbiases, e.g., whether due to hidden confounding or selection of participants.\nIn this work, we show that the relationship between bias magnitude and the\npredictive performance of nuisance function estimators (in the observational\nstudy) can help distinguish among common sources of causal bias. We validate\nour methodology through extensive synthetic experiments and a real-world case\nstudy, demonstrating its effectiveness in revealing the mechanisms behind\nobserved biases. Our framework offers a new lens for understanding and\ncharacterizing bias in observational studies, with practical implications for\nimproving causal inference.", "published": "2025-06-01 21:58:09", "link": "http://arxiv.org/abs/2506.01191v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Doubly Robust Alignment for Large Language Models", "abstract": "This paper studies reinforcement learning from human feedback (RLHF) for\naligning large language models with human preferences. While RLHF has\ndemonstrated promising results, many algorithms are highly sensitive to\nmisspecifications in the underlying preference model (e.g., the Bradley-Terry\nmodel), the reference policy, or the reward function, resulting in undesirable\nfine-tuning. To address model misspecification, we propose a doubly robust\npreference optimization algorithm that remains consistent when either the\npreference model or the reference policy is correctly specified (without\nrequiring both). Our proposal demonstrates superior and more robust performance\nthan state-of-the-art algorithms, both in theory and in practice. The code is\navailable at https://github.com/DRPO4LLM/DRPO4LLM", "published": "2025-06-01 21:34:37", "link": "http://arxiv.org/abs/2506.01183v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Nearly-Linear Time Private Hypothesis Selection with the Optimal Approximation Factor", "abstract": "Estimating the density of a distribution from its samples is a fundamental\nproblem in statistics. Hypothesis selection addresses the setting where, in\naddition to a sample set, we are given $n$ candidate distributions -- referred\nto as hypotheses -- and the goal is to determine which one best describes the\nunderlying data distribution. This problem is known to be solvable very\nefficiently, requiring roughly $O(\\log n)$ samples and running in\n$\\tilde{O}(n)$ time. The quality of the output is measured via the total\nvariation distance to the unknown distribution, and the approximation factor of\nthe algorithm determines how large this distance is compared to the optimal\ndistance achieved by the best candidate hypothesis. It is known that $\\alpha =\n3$ is the optimal approximation factor for this problem. We study hypothesis\nselection under the constraint of differential privacy. We propose a\ndifferentially private algorithm in the central model that runs in\nnearly-linear time with respect to the number of hypotheses, achieves the\noptimal approximation factor, and incurs only a modest increase in sample\ncomplexity, which remains polylogarithmic in $n$. This resolves an open\nquestion posed by [Bun, Kamath, Steinke, Wu, NeurIPS 2019]. Prior to our work,\nexisting upper bounds required quadratic time.", "published": "2025-06-01 20:46:46", "link": "http://arxiv.org/abs/2506.01162v1", "categories": ["cs.DS", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.DS"}
{"title": "FORT: Forward-Only Regression Training of Normalizing Flows", "abstract": "Simulation-free training frameworks have been at the forefront of the\ngenerative modelling revolution in continuous spaces, leading to neural\ndynamical systems that encompass modern large-scale diffusion and flow matching\nmodels. Despite the scalability of training, the generation of high-quality\nsamples and their corresponding likelihood under the model requires expensive\nnumerical simulation -- inhibiting adoption in numerous scientific applications\nsuch as equilibrium sampling of molecular systems. In this paper, we revisit\nclassical normalizing flows as one-step generative models with exact\nlikelihoods and propose a novel, scalable training objective that does not\nrequire computing the expensive change of variable formula used in conventional\nmaximum likelihood training. We propose Forward-Only Regression Training\n(FORT), a simple $\\ell_2$-regression objective that maps prior samples under\nour flow to specifically chosen targets. We demonstrate that FORT supports a\nwide class of targets, such as optimal transport targets and targets from\npre-trained continuous-time normalizing flows (CNF). We further demonstrate\nthat by using CNF targets, our one-step flows allow for larger-scale training\nthat exceeds the performance and stability of maximum likelihood training,\nwhile unlocking a broader class of architectures that were previously\nchallenging to train. Empirically, we elucidate that our trained flows can\nperform equilibrium conformation sampling in Cartesian coordinates of alanine\ndipeptide, alanine tripeptide, and alanine tetrapeptide.", "published": "2025-06-01 20:32:27", "link": "http://arxiv.org/abs/2506.01158v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Flexible Selective Inference with Flow-based Transport Maps", "abstract": "Data-carving methods perform selective inference by conditioning the\ndistribution of data on the observed selection event. However, existing\ndata-carving approaches typically require an analytically tractable\ncharacterization of the selection event. This paper introduces a new method\nthat leverages tools from flow-based generative modeling to approximate a\npotentially complex conditional distribution, even when the underlying\nselection event lacks an analytical description -- take, for example, the\ndata-adaptive tuning of model parameters. The key idea is to learn a transport\nmap that pushes forward a simple reference distribution to the conditional\ndistribution given selection. This map is efficiently learned via a normalizing\nflow, without imposing any further restrictions on the nature of the selection\nevent. Through extensive numerical experiments on both simulated and real data,\nwe demonstrate that this method enables flexible selective inference by\nproviding: (i) valid p-values and confidence sets for adaptively selected\nhypotheses and parameters, (ii) a closed-form expression for the conditional\ndensity function, enabling likelihood-based and quantile-based inference, and\n(iii) adjustments for intractable selection steps that can be easily integrated\nwith existing methods designed to account for the tractable steps in a\nselection procedure involving multiple steps.", "published": "2025-06-01 20:05:20", "link": "http://arxiv.org/abs/2506.01150v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Generative diffusion posterior sampling for informative likelihoods", "abstract": "Sequential Monte Carlo (SMC) methods have recently shown successful results\nfor conditional sampling of generative diffusion models. In this paper we\npropose a new diffusion posterior SMC sampler achieving improved statistical\nefficiencies, particularly under outlier conditions or highly informative\nlikelihoods. The key idea is to construct an observation path that correlates\nwith the diffusion model and to design the sampler to leverage this correlation\nfor more efficient sampling. Empirical results conclude the efficiency.", "published": "2025-06-01 17:01:14", "link": "http://arxiv.org/abs/2506.01083v1", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "stat.ML"}
{"title": "A Finite-Time Analysis of TD Learning with Linear Function Approximation without Projections nor Strong Convexity", "abstract": "We investigate the finite-time convergence properties of Temporal Difference\n(TD) learning with linear function approximation, a cornerstone algorithm in\nreinforcement learning. While prior work has established convergence\nguarantees, these results typically rely on the assumption that each iterate is\nprojected onto a bounded set or that the learning rate is set according to the\nunknown strong convexity constant -- conditions that are both artificial and do\nnot match the current practice.\n  In this paper, we challenge the necessity of such assumptions and present a\nrefined analysis of TD learning. We show that the simple projection-free\nvariant converges with a rate of\n$\\tilde{\\mathcal{O}}(\\frac{||\\theta^*||^2_2}{\\sqrt{T}})$, even in the presence\nof Markovian noise. Our analysis reveals a novel self-bounding property of the\nTD updates and exploits it to guarantee bounded iterates.", "published": "2025-06-01 15:39:00", "link": "http://arxiv.org/abs/2506.01052v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Optimistic critics can empower small actors", "abstract": "Actor-critic methods have been central to many of the recent advances in deep\nreinforcement learning. The most common approach is to use symmetric\narchitectures, whereby both actor and critic have the same network topology and\nnumber of parameters. However, recent works have argued for the advantages of\nasymmetric setups, specifically with the use of smaller actors. We perform\nbroad empirical investigations and analyses to better understand the\nimplications of this and find that, in general, smaller actors result in\nperformance degradation and overfit critics. Our analyses suggest poor data\ncollection, due to value underestimation, as one of the main causes for this\nbehavior, and further highlight the crucial role the critic can play in\nalleviating this pathology. We explore techniques to mitigate the observed\nvalue underestimation, which enables further research in asymmetric\nactor-critic methods.", "published": "2025-06-01 14:00:03", "link": "http://arxiv.org/abs/2506.01016v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Quantization-based Bounds on the Wasserstein Metric", "abstract": "The Wasserstein metric has become increasingly important in many machine\nlearning applications such as generative modeling, image retrieval and domain\nadaptation. Despite its appeal, it is often too costly to compute. This has\nmotivated approximation methods like entropy-regularized optimal transport,\ndownsampling, and subsampling, which trade accuracy for computational\nefficiency. In this paper, we consider the challenge of computing efficient\napproximations to the Wasserstein metric that also serve as strict upper or\nlower bounds. Focusing on discrete measures on regular grids, our approach\ninvolves formulating and exactly solving a Kantorovich problem on a coarse grid\nusing a quantized measure and specially designed cost matrix, followed by an\nupscaling and correction stage. This is done either in the primal or dual space\nto obtain valid upper and lower bounds on the Wasserstein metric of the\nfull-resolution inputs. We evaluate our methods on the DOTmark optimal\ntransport images benchmark, demonstrating a 10x-100x speedup compared to\nentropy-regularized OT while keeping the approximation error below 2%.", "published": "2025-06-01 12:06:31", "link": "http://arxiv.org/abs/2506.00976v1", "categories": ["cs.LG", "stat.CO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reinforcement Learning with Random Time Horizons", "abstract": "We extend the standard reinforcement learning framework to random time\nhorizons. While the classical setting typically assumes finite and\ndeterministic or infinite runtimes of trajectories, we argue that multiple\nreal-world applications naturally exhibit random (potentially\ntrajectory-dependent) stopping times. Since those stopping times typically\ndepend on the policy, their randomness has an effect on policy gradient\nformulas, which we (mostly for the first time) derive rigorously in this work\nboth for stochastic and deterministic policies. We present two complementary\nperspectives, trajectory or state-space based, and establish connections to\noptimal control theory. Our numerical experiments demonstrate that using the\nproposed formulas can significantly improve optimization convergence compared\nto traditional approaches.", "published": "2025-06-01 11:22:45", "link": "http://arxiv.org/abs/2506.00962v1", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enhancing Parallelism in Decentralized Stochastic Convex Optimization", "abstract": "Decentralized learning has emerged as a powerful approach for handling large\ndatasets across multiple machines in a communication-efficient manner. However,\nsuch methods often face scalability limitations, as increasing the number of\nmachines beyond a certain point negatively impacts convergence rates. In this\nwork, we propose Decentralized Anytime SGD, a novel decentralized learning\nalgorithm that significantly extends the critical parallelism threshold,\nenabling the effective use of more machines without compromising performance.\nWithin the stochastic convex optimization (SCO) framework, we establish a\ntheoretical upper bound on parallelism that surpasses the current\nstate-of-the-art, allowing larger networks to achieve favorable statistical\nguarantees and closing the gap with centralized learning in highly connected\ntopologies.", "published": "2025-06-01 11:17:32", "link": "http://arxiv.org/abs/2506.00961v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reconstruction and Prediction of Volterra Integral Equations Driven by Gaussian Noise", "abstract": "Integral equations are widely used in fields such as applied modeling,\nmedical imaging, and system identification, providing a powerful framework for\nsolving deterministic problems. While parameter identification for differential\nequations has been extensively studied, the focus on integral equations,\nparticularly stochastic Volterra integral equations, remains limited. This\nresearch addresses the parameter identification problem, also known as the\nequation reconstruction problem, in Volterra integral equations driven by\nGaussian noise. We propose an improved deep neural networks framework for\nestimating unknown parameters in the drift term of these equations. The network\nrepresents the primary variables and their integrals, enhancing parameter\nestimation accuracy by incorporating inter-output relationships into the loss\nfunction. Additionally, the framework extends beyond parameter identification\nto predict the system's behavior outside the integration interval. Prediction\naccuracy is validated by comparing predicted and true trajectories using a 95%\nconfidence interval. Numerical experiments demonstrate the effectiveness of the\nproposed deep neural networks framework in both parameter identification and\nprediction tasks, showing robust performance under varying noise levels and\nproviding accurate solutions for modeling stochastic systems.", "published": "2025-06-01 09:54:50", "link": "http://arxiv.org/abs/2506.00933v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Projection Pursuit Density Ratio Estimation", "abstract": "Density ratio estimation (DRE) is a paramount task in machine learning, for\nits broad applications across multiple domains, such as covariate shift\nadaptation, causal inference, independence tests and beyond. Parametric methods\nfor estimating the density ratio possibly lead to biased results if models are\nmisspecified, while conventional non-parametric methods suffer from the curse\nof dimensionality when the dimension of data is large. To address these\nchallenges, in this paper, we propose a novel approach for DRE based on the\nprojection pursuit (PP) approximation. The proposed method leverages PP to\nmitigate the impact of high dimensionality while retaining the model\nflexibility needed for the accuracy of DRE. We establish the consistency and\nthe convergence rate for the proposed estimator. Experimental results\ndemonstrate that our proposed method outperforms existing alternatives in\nvarious applications.", "published": "2025-06-01 07:15:07", "link": "http://arxiv.org/abs/2506.00866v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Infinite-Width Limit of a Single Attention Layer: Analysis via Tensor Programs", "abstract": "In modern theoretical analyses of neural networks, the infinite-width limit\nis often invoked to justify Gaussian approximations of neuron preactivations\n(e.g., via neural network Gaussian processes or Tensor Programs). However,\nthese Gaussian-based asymptotic theories have so far been unable to capture the\nbehavior of attention layers, except under special regimes such as infinitely\nmany heads or tailored scaling schemes. In this paper, leveraging the Tensor\nPrograms framework, we rigorously identify the infinite-width limit\ndistribution of variables within a single attention layer under realistic\narchitectural dimensionality and standard $1/\\sqrt{n}$-scaling with $n$\ndimensionality. We derive the exact form of this limit law without resorting to\ninfinite-head approximations or tailored scalings, demonstrating that it\ndeparts fundamentally from Gaussianity. This limiting distribution exhibits\nnon-Gaussianity from a hierarchical structure, being Gaussian conditional on\nthe random similarity scores. Numerical experiments validate our theoretical\npredictions, confirming the effectiveness of our theory at finite width and\naccurate description of finite-head attentions. Beyond characterizing a\nstandalone attention layer, our findings lay the groundwork for developing a\nunified theory of deep Transformer architectures in the infinite-width regime.", "published": "2025-06-01 05:53:47", "link": "http://arxiv.org/abs/2506.00846v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Generalized Linear Markov Decision Process", "abstract": "The linear Markov Decision Process (MDP) framework offers a principled\nfoundation for reinforcement learning (RL) with strong theoretical guarantees\nand sample efficiency. However, its restrictive assumption-that both transition\ndynamics and reward functions are linear in the same feature space-limits its\napplicability in real-world domains, where rewards often exhibit nonlinear or\ndiscrete structures. Motivated by applications such as healthcare and\ne-commerce, where data is scarce and reward signals can be binary or\ncount-valued, we propose the Generalized Linear MDP (GLMDP) framework-an\nextension of the linear MDP framework-that models rewards using generalized\nlinear models (GLMs) while maintaining linear transition dynamics. We establish\nthe Bellman completeness of GLMDPs with respect to a new function class that\naccommodates nonlinear rewards and develop two offline RL algorithms:\nGeneralized Pessimistic Value Iteration (GPEVI) and a semi-supervised variant\n(SS-GPEVI) that utilizes both labeled and unlabeled trajectories. Our\nalgorithms achieve theoretical guarantees on policy suboptimality and\ndemonstrate improved sample efficiency in settings where reward labels are\nexpensive or limited.", "published": "2025-06-01 03:50:41", "link": "http://arxiv.org/abs/2506.00818v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Iola Walker: A Mobile Footfall Detection System for Music Composition", "abstract": "This project is the first of several experiments composing music that changes\nin response to biosignals. The system is dubbed \"iola walker\" in reference to a\ncommon polyrhythm, the hemiola. A listener goes for a walk, and the Iola Walker\napp detects their walking pace. Iola Walker picks up footfalls using a\nfoot-mounted accelerometer, processing the signals in real time using a\nrecurrent neural network in an Android app. The Android app outputs a MIDI\nevent for each footfall. The iola walker player, which might be a VST running\nin a DAW, plays the version of the next music passage with underlying\npolyrhythms closest to the listener's walking pace.\n  This paper documents the process of training the model to detect the\nfootfalls in real time. The model is trained on accelerometer data from an\nMbient Labs foot-mounted IMU at 200~Hz, with the ground truth for footfalls\nannotated by pressing the volume-up button on the Android device when the foot\nhits the ground. To collect training data, I walked around my neighborhood\nclicking the volume-up button each time my foot hit the ground. Several methods\nwere tried for detecting footfalls in real time from sensor data, including\nones based on digital signal processing techniques and traditional machine\nlearning techniques.", "published": "2025-06-01 23:13:46", "link": "http://arxiv.org/abs/2506.01211v1", "categories": ["cs.MM", "eess.AS"], "primary_category": "cs.MM"}
{"title": "GigaAM: Efficient Self-Supervised Learner for Speech Recognition", "abstract": "Self-Supervised Learning (SSL) has demonstrated strong performance in speech\nprocessing, particularly in automatic speech recognition. In this paper, we\nexplore an SSL pretraining framework that leverages masked language modeling\nwith targets derived from a speech recognition model. We also present chunkwise\nattention with dynamic chunk size sampling during pretraining to enable both\nfull-context and streaming fine-tuning. Our experiments examine scaling with\nrespect to model size and the amount of data. Using our method, we train the\nGigaAM family of models, including a state-of-the-art model for Russian speech\nrecognition that outperforms Whisper-large-v3 by 50%. We have released our\nfoundation and ASR models, along with the inference code, under the MIT license\nas open-source resources to the research community. Available at\nhttps://github.com/salute-developers/gigaam.", "published": "2025-06-01 22:03:40", "link": "http://arxiv.org/abs/2506.01192v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Source Tracing of Synthetic Speech Systems Through Paralinguistic Pre-Trained Representations", "abstract": "In this work, we focus on source tracing of synthetic speech generation\nsystems (STSGS). Each source embeds distinctive paralinguistic features--such\nas pitch, tone, rhythm, and intonation--into their synthesized speech,\nreflecting the underlying design of the generation model. While previous\nresearch has explored representations from speech pre-trained models (SPTMs),\nthe use of representations from SPTM pre-trained for paralinguistic speech\nprocessing, which excel in paralinguistic tasks like synthetic speech\ndetection, speech emotion recognition has not been investigated for STSGS. We\nhypothesize that representations from paralinguistic SPTM will be more\neffective due to its ability to capture source-specific paralinguistic cues\nattributing to its paralinguistic pre-training. Our comparative study of\nrepresentations from various SOTA SPTMs, including paralinguistic, monolingual,\nmultilingual, and speaker recognition, validates this hypothesis. Furthermore,\nwe explore fusion of representations and propose TRIO, a novel framework that\nfuses SPTMs using a gated mechanism for adaptive weighting, followed by\ncanonical correlation loss for inter-representation alignment and\nself-attention for feature refinement. By fusing TRILLsson (Paralinguistic\nSPTM) and x-vector (Speaker recognition SPTM), TRIO outperforms individual\nSPTMs, baseline fusion methods, and sets new SOTA for STSGS in comparison to\nprevious works.", "published": "2025-06-01 20:32:10", "link": "http://arxiv.org/abs/2506.01157v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Mispronunciation Detection Without L2 Pronunciation Dataset in Low-Resource Setting: A Case Study in Finland Swedish", "abstract": "Mispronunciation detection (MD) models are the cornerstones of many language\nlearning applications. Unfortunately, most systems are built for English and\nother major languages, while low-resourced language varieties, such as Finland\nSwedish (FS), lack such tools. In this paper, we introduce our MD model for FS,\ntrained on 89 hours of first language (L1) speakers' spontaneous speech and\ntested on 33 minutes of L2 transcribed read-aloud speech.\n  We trained a multilingual wav2vec 2.0 model with entropy regularization,\nfollowed by temperature scaling and top-k normalization after the inference to\nbetter adapt it for MD. The main novelty of our method lies in its simplicity,\nrequiring minimal L2 data. The process is also language-independent, making it\nsuitable for other low-resource languages. Our proposed algorithm allows us to\nbalance Recall (43.2%) and Precision (29.8%), compared with the baseline\nmodel's Recall (77.5%) and Precision (17.6%).", "published": "2025-06-01 20:28:35", "link": "http://arxiv.org/abs/2506.01156v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Fusion of Neural Audio Codec-based Representations with Spectral for Heart Murmur Classification via Bandit-based Cross-Attention Mechanism", "abstract": "In this study, we focus on heart murmur classification (HMC) and hypothesize\nthat combining neural audio codec representations (NACRs) such as EnCodec with\nspectral features (SFs), such as MFCC, will yield superior performance. We\nbelieve such fusion will trigger their complementary behavior as NACRs excel at\ncapturing fine-grained acoustic patterns such as rhythm changes, spectral\nfeatures focus on frequency-domain properties such as harmonic structure,\nspectral energy distribution crucial for analyzing the complex of heart sounds.\nTo this end, we propose, BAOMI, a novel framework banking on novel bandit-based\ncross-attention mechanism for effective fusion. Here, a agent provides more\nweightage to most important heads in multi-head cross-attention mechanism and\nhelps in mitigating the noise. With BAOMI, we report the topmost performance in\ncomparison to individual NACRs, SFs, and baseline fusion techniques and setting\nnew state-of-the-art.", "published": "2025-06-01 20:01:15", "link": "http://arxiv.org/abs/2506.01148v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "PARROT: Synergizing Mamba and Attention-based SSL Pre-Trained Models via Parallel Branch Hadamard Optimal Transport for Speech Emotion Recognition", "abstract": "The emergence of Mamba as an alternative to attention-based architectures has\nled to the development of Mamba-based self-supervised learning (SSL)\npre-trained models (PTMs) for speech and audio processing. Recent studies\nsuggest that these models achieve comparable or superior performance to\nstate-of-the-art (SOTA) attention-based PTMs for speech emotion recognition\n(SER). Motivated by prior work demonstrating the benefits of PTM fusion across\ndifferent speech processing tasks, we hypothesize that leveraging the\ncomplementary strengths of Mamba-based and attention-based PTMs will enhance\nSER performance beyond the fusion of homogenous attention-based PTMs. To this\nend, we introduce a novel framework, PARROT that integrates parallel branch\nfusion with Optimal Transport and Hadamard Product. Our approach achieves SOTA\nresults against individual PTMs, homogeneous PTMs fusion, and baseline fusion\ntechniques, thus, highlighting the potential of heterogeneous PTM fusion for\nSER.", "published": "2025-06-01 19:46:41", "link": "http://arxiv.org/abs/2506.01138v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "From Words to Waves: Analyzing Concept Formation in Speech and Text-Based Foundation Models", "abstract": "The emergence of large language models (LLMs) has demonstrated that systems\ntrained solely on text can acquire extensive world knowledge, develop reasoning\ncapabilities, and internalize abstract semantic concepts--showcasing properties\nthat can be associated with general intelligence. This raises an intriguing\nquestion: Do such concepts emerge in models trained on other modalities, such\nas speech? Furthermore, when models are trained jointly on multiple modalities:\nDo they develop a richer, more structured semantic understanding? To explore\nthis, we analyze the conceptual structures learned by speech and textual models\nboth individually and jointly. We employ Latent Concept Analysis, an\nunsupervised method for uncovering and interpreting latent representations in\nneural networks, to examine how semantic abstractions form across modalities.\nFor reproducibility we made scripts and other resources available to the\ncommunity.", "published": "2025-06-01 19:33:21", "link": "http://arxiv.org/abs/2506.01133v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Comparative Evaluation of Acoustic Feature Extraction Tools for Clinical Speech Analysis", "abstract": "This study compares three acoustic feature extraction toolkits (OpenSMILE,\nPraat, and Librosa) applied to clinical speech data from individuals with\nschizophrenia spectrum disorders (SSD) and healthy controls (HC). By\nstandardizing extraction parameters across the toolkits, we analyzed speech\nsamples from 77 SSD and 87 HC participants and found significant\ntoolkit-dependent variations. While F0 percentiles showed high cross-toolkit\ncorrelation (r=0.962 to 0.999), measures like F0 standard deviation and formant\nvalues often had poor, even negative, agreement. Additionally, correlation\npatterns differed between SSD and HC groups. Classification analysis identified\nF0 mean, HNR, and MFCC1 (AUC greater than 0.70) as promising discriminators.\nThese findings underscore reproducibility concerns and advocate for\nstandardized protocols, multi-toolkit cross-validation, and transparent\nreporting.", "published": "2025-06-01 19:26:25", "link": "http://arxiv.org/abs/2506.01129v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FusionAudio-1.2M: Towards Fine-grained Audio Captioning with Multimodal Contextual Fusion", "abstract": "High-quality, large-scale audio captioning is crucial for advancing audio\nunderstanding, yet current automated methods often generate captions that lack\nfine-grained detail and contextual accuracy, primarily due to their reliance on\nlimited unimodal or superficial multimodal information. Drawing inspiration\nfrom human auditory perception, which adeptly integrates cross-modal cues and\nperforms sophisticated auditory scene analysis, we introduce a novel two-stage\nautomated pipeline. This pipeline first employs specialized pretrained models\nto extract diverse contextual cues (e.g., speech, music, general sounds, and\nvisual information from associated video). A large language model (LLM) then\nsynthesizes these rich, multimodal inputs to generate detailed and\ncontext-aware audio captions. Key contributions of this work include: (1) the\nproposed scalable method for fine-grained audio caption generation; (2)\nFusionAudio, a new large-scale dataset comprising 1.2 million such detailed\ncaptions, combined with 6 million QA pairs; and (3) enhanced audio models\ndeveloped using FusionAudio, specifically a CLAP-based audio encoder with\nsuperior audio-text alignment and instruction following. This paper paves the\nway for more nuanced and accurate automated understanding of complex audio\nenvironments. Code and data can be found in\nhttps://github.com/satsuki2486441738/FusionAudio.", "published": "2025-06-01 18:29:17", "link": "http://arxiv.org/abs/2506.01111v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PseudoVC: Improving One-shot Voice Conversion with Pseudo Paired Data", "abstract": "As parallel training data is scarce for one-shot voice conversion (VC) tasks,\nwaveform reconstruction is typically performed by various VC systems. A typical\none-shot VC system comprises a content encoder and a speaker encoder. However,\ntwo types of mismatches arise: one for the inputs to the content encoder during\ntraining and inference, and another for the inputs to the speaker encoder. To\naddress these mismatches, we propose a novel VC training method called\n\\textit{PseudoVC} in this paper. First, we introduce an innovative information\nperturbation approach named \\textit{Pseudo Conversion} to tackle the first\nmismatch problem. This approach leverages pretrained VC models to convert the\nsource utterance into a perturbed utterance, which is fed into the content\nencoder during training. Second, we propose an approach termed \\textit{Speaker\nSampling} to resolve the second mismatch problem, which will substitute the\ninput to the speaker encoder by another utterance from the same speaker during\ntraining. Experimental results demonstrate that our proposed \\textit{Pseudo\nConversion} outperforms previous information perturbation methods, and the\noverall \\textit{PseudoVC} method surpasses publicly available VC models. Audio\nexamples are available.", "published": "2025-06-01 14:46:26", "link": "http://arxiv.org/abs/2506.01039v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ReFlow-VC: Zero-shot Voice Conversion Based on Rectified Flow and Speaker Feature Optimization", "abstract": "In recent years, diffusion-based generative models have demonstrated\nremarkable performance in speech conversion, including Denoising Diffusion\nProbabilistic Models (DDPM) and others. However, the advantages of these models\ncome at the cost of requiring a large number of sampling steps. This limitation\nhinders their practical application in real-world scenarios. In this paper, we\nintroduce ReFlow-VC, a novel high-fidelity speech conversion method based on\nrectified flow. Specifically, ReFlow-VC is an Ordinary Differential Equation\n(ODE) model that transforms a Gaussian distribution to the true Mel-spectrogram\ndistribution along the most direct path. Furthermore, we propose a modeling\napproach that optimizes speaker features by utilizing both content and pitch\ninformation, allowing speaker features to reflect the properties of the current\nspeech more accurately. Experimental results show that ReFlow-VC performs\nexceptionally well in small datasets and zero-shot scenarios.", "published": "2025-06-01 14:21:07", "link": "http://arxiv.org/abs/2506.01032v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Two-Stage Hierarchical Deep Filtering Framework for Real-Time Speech Enhancement", "abstract": "This paper proposes a model that integrates sub-band processing and deep\nfiltering to fully exploit information from the target time-frequency (TF) bin\nand its surrounding TF bins for single-channel speech enhancement. The sub-band\nmodule captures surrounding frequency bin information at the input, while the\ndeep filtering module applies filtering at the output to both the target TF bin\nand its surrounding TF bins. To further improve the model performance, we\ndecouple deep filtering into temporal and frequency components and introduce a\ntwo-stage framework, reducing the complexity of filter coefficient prediction\nat each stage. Additionally, we propose the TAConv module to strengthen\nconvolutional feature extraction. Experimental results demonstrate that the\nproposed hierarchical deep filtering network (HDF-Net) effectively utilizes\nsurrounding TF bin information and outperforms other advanced systems while\nusing fewer resources.", "published": "2025-06-01 14:09:27", "link": "http://arxiv.org/abs/2506.01023v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DS-TTS: Zero-Shot Speaker Style Adaptation from Voice Clips via Dynamic Dual-Style Feature Modulation", "abstract": "Recent advancements in text-to-speech (TTS) technology have increased demand\nfor personalized audio synthesis. Zero-shot voice cloning, a specialized TTS\ntask, aims to synthesize a target speaker's voice using only a single audio\nsample and arbitrary text, without prior exposure to the speaker during\ntraining. This process employs pattern recognition techniques to analyze and\nreplicate the speaker's unique vocal features. Despite progress, challenges\nremain in adapting to the vocal style of unseen speakers, highlighting\ndifficulties in generalizing TTS systems to handle diverse voices while\nmaintaining naturalness, expressiveness, and speaker fidelity. To address the\nchallenges of unseen speaker style adaptation, we propose DS-TTS, a novel\napproach aimed at enhancing the synthesis of diverse, previously unheard\nvoices. Central to our method is a Dual-Style Encoding Network (DuSEN), where\ntwo distinct style encoders capture complementary aspects of a speaker's vocal\nidentity. These speaker-specific style vectors are seamlessly integrated into\nthe Dynamic Generator Network (DyGN) via a Style Gating-Film (SGF) mechanism,\nenabling more accurate and expressive reproduction of unseen speakers' unique\nvocal characteristics. In addition, we introduce a Dynamic Generator Network to\ntackle synthesis issues that arise with varying sentence lengths. By\ndynamically adapting to the length of the input, this component ensures robust\nperformance across diverse text inputs and speaker styles, significantly\nimproving the model's ability to generalize to unseen speakers in a more\nnatural and expressive manner. Experimental evaluations on the VCTK dataset\nsuggest that DS-TTS demonstrates superior overall performance in voice cloning\ntasks compared to existing state-of-the-art models, showing notable\nimprovements in both word error rate and speaker similarity.", "published": "2025-06-01 14:04:08", "link": "http://arxiv.org/abs/2506.01020v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching", "abstract": "Zero-Shot Voice Conversion (VC) aims to transform the source speaker's timbre\ninto an arbitrary unseen one while retaining speech content. Most prior work\nfocuses on preserving the source's prosody, while fine-grained timbre\ninformation may leak through prosody, and transferring target prosody to\nsynthesized speech is rarely studied. In light of this, we propose R-VC, a\nrhythm-controllable and efficient zero-shot voice conversion model. R-VC\nemploys data perturbation techniques and discretize source speech into Hubert\ncontent tokens, eliminating much content-irrelevant information. By leveraging\na Mask Generative Transformer for in-context duration modeling, our model\nadapts the linguistic content duration to the desired target speaking style,\nfacilitating the transfer of the target speaker's rhythm. Furthermore, R-VC\nintroduces a powerful Diffusion Transformer (DiT) with shortcut flow matching\nduring training, conditioning the network not only on the current noise level\nbut also on the desired step size, enabling high timbre similarity and quality\nspeech generation in fewer sampling steps, even in just two, thus minimizing\nlatency. Experimental results show that R-VC achieves comparable speaker\nsimilarity to state-of-the-art VC methods with a smaller dataset, and surpasses\nthem in terms of speech naturalness, intelligibility and style transfer\nperformance.", "published": "2025-06-01 13:53:28", "link": "http://arxiv.org/abs/2506.01014v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training", "abstract": "How language-specific are speech representations learned by self-supervised\nmodels? Existing work has shown that a range of linguistic features can be\nsuccessfully decoded from end-to-end models trained only on speech recordings.\nHowever, it's less clear to what extent pre-training on specific languages\nimproves language-specific linguistic information. Here we test the encoding of\nDutch phonetic and lexical information in internal representations of\nself-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the\nrepresentation of Dutch linguistic features as compared to pre-training on\nsimilar amounts of English or larger amounts of multilingual data. This\nlanguage-specific advantage is well-detected by trained clustering or\nclassification probes, and partially observable using zero-shot metrics.\nFurthermore, the language-specific benefit on linguistic feature encoding\naligns with downstream performance on Automatic Speech Recognition.", "published": "2025-06-01 12:25:13", "link": "http://arxiv.org/abs/2506.00981v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "NTPP: Generative Speech Language Modeling for Dual-Channel Spoken Dialogue via Next-Token-Pair Prediction", "abstract": "Inspired by the impressive capabilities of GPT-4o, there is growing interest\nin enabling speech language models (SLMs) to engage in natural, fluid spoken\ninteractions with humans. Recent advancements have led to the development of\nseveral SLMs that demonstrate promising results in this area. However, current\napproaches have yet to fully exploit dual-channel speech data, which inherently\ncaptures the structure and dynamics of human conversation. In this work, we\nsystematically explore the use of dual-channel speech data in the context of\nmodern large language models, and introduce a novel generative modeling\nparadigm, Next-Token-Pair Prediction (NTPP), to enable speaker-independent\ndual-channel spoken dialogue learning using decoder-only architectures for the\nfirst time. We evaluate our approach on standard benchmarks, and empirical\nresults show that our proposed method, NTPP, significantly improves the\nconversational abilities of SLMs in terms of turn-taking prediction, response\ncoherence, and naturalness. Moreover, compared to existing methods, NTPP\nachieves substantially lower inference latency, highlighting its practical\nefficiency for real-time applications.", "published": "2025-06-01 12:01:40", "link": "http://arxiv.org/abs/2506.00975v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Sarcastic Speech Annotation in Sarcasm Detection", "abstract": "Sarcasm fundamentally alters meaning through tone and context, yet detecting\nit in speech remains a challenge due to data scarcity. In addition, existing\ndetection systems often rely on multimodal data, limiting their applicability\nin contexts where only speech is available. To address this, we propose an\nannotation pipeline that leverages large language models (LLMs) to generate a\nsarcasm dataset. Using a publicly available sarcasm-focused podcast, we employ\nGPT-4o and LLaMA 3 for initial sarcasm annotations, followed by human\nverification to resolve disagreements. We validate this approach by comparing\nannotation quality and detection performance on a publicly available sarcasm\ndataset using a collaborative gating architecture. Finally, we introduce\nPodSarc, a large-scale sarcastic speech dataset created through this pipeline.\nThe detection model achieves a 73.63% F1 score, demonstrating the dataset's\npotential as a benchmark for sarcasm detection research.", "published": "2025-06-01 11:00:18", "link": "http://arxiv.org/abs/2506.00955v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Crowdsourcing MUSHRA Tests in the Age of Generative Speech Technologies: A Comparative Analysis of Subjective and Objective Testing Methods", "abstract": "The MUSHRA framework is widely used for detecting subtle audio quality\ndifferences but traditionally relies on expert listeners in controlled\nenvironments, making it costly and impractical for model development. As a\nresult, objective metrics are often used during development, with expert\nevaluations conducted later. While effective for traditional DSP codecs, these\nmetrics often fail to reliably evaluate generative models. This paper proposes\nadaptations for conducting MUSHRA tests with non-expert, crowdsourced\nlisteners, focusing on generative speech codecs. We validate our approach by\ncomparing results from MTurk and Prolific crowdsourcing platforms with expert\nlistener data, assessing test-retest reliability and alignment. Additionally,\nwe evaluate six objective metrics, showing that traditional metrics undervalue\ngenerative models. Our findings reveal platform-specific biases and emphasize\ncodec-aware metrics, offering guidance for scalable perceptual testing of\nspeech codecs.", "published": "2025-06-01 10:51:33", "link": "http://arxiv.org/abs/2506.00950v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "General-purpose audio representation learning for real-world sound scenes", "abstract": "While audio foundation models perform well on myriad of tasks from sound\nclassification to speech analysis, these models are trained and tested on dry,\nnon-spatial, single-source audio clips. This limits their success in real-world\nsituations and results in spatially unaware audio embeddings. To address these\nlimitations, we propose a novel self-supervised training approach for\nGeneral-Purpose, Real-world Audio Models (GRAMs). The GRAM training approach\nenables robust spatial audio representation learning for naturalistic, noisy\nsound scenes and can be applied to any masking-based deep learning model. We\ndemonstrate the success of our approach by training two state-of-the-art\nmodels, one with a transformer and one with a mamba backbone. We assess the\nquality of the extracted audio representations from GRAMs using the original\nversion of the HEAR benchmark, a newly synthesized, naturalistic version of the\nHEAR benchmark, and novel sound localization tasks based on HEAR benchmark\ndatasets. The results show that our approach minimizes the performance gap\nbetween dry, non-spatial, single-source sound scenes and naturalistic sound\nscenes for crucial tasks such as auditory scene analysis, outperforming\nexisting state-of-the-art audio foundation models at a fraction of the training\nsteps. Moreover, GRAMs show state-of-the-art performance on sound localization\ntasks, exceeding even supervised sound localization models. In sum, the\nproposed approach represents a significant advancement towards robust audio\nfoundation models for real-world applications with state-of-the-art performance\non naturalistic sound scenes as well as spatial audio representation learning.", "published": "2025-06-01 09:56:33", "link": "http://arxiv.org/abs/2506.00934v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "In-the-wild Audio Spatialization with Flexible Text-guided Localization", "abstract": "To enhance immersive experiences, binaural audio offers spatial awareness of\nsounding objects in AR, VR, and embodied AI applications. While existing audio\nspatialization methods can generally map any available monaural audio to\nbinaural audio signals, they often lack the flexible and interactive control\nneeded in complex multi-object user-interactive environments. To address this,\nwe propose a Text-guided Audio Spatialization (TAS) framework that utilizes\nflexible text prompts and evaluates our model from unified generation and\ncomprehension perspectives. Due to the limited availability of premium and\nlarge-scale stereo data, we construct the SpatialTAS dataset, which encompasses\n376,000 simulated binaural audio samples to facilitate the training of our\nmodel. Our model learns binaural differences guided by 3D spatial location and\nrelative position prompts, augmented by flipped-channel audio. It outperforms\nexisting methods on both simulated and real-recorded datasets, demonstrating\nsuperior generalization and accuracy. Besides, we develop an assessment model\nbased on Llama-3.1-8B, which evaluates the spatial semantic coherence between\nour generated binaural audio and text prompts through a spatial reasoning task.\nResults demonstrate that text prompts provide flexible and interactive control\nto generate binaural audio with excellent quality and semantic consistency in\nspatial locations. Dataset is available at\n\\href{https://github.com/Alice01010101/TASU}", "published": "2025-06-01 09:41:56", "link": "http://arxiv.org/abs/2506.00927v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoVoMix2: Advancing Zero-Shot Dialogue Generation with Fully Non-Autoregressive Flow Matching", "abstract": "Generating natural-sounding, multi-speaker dialogue is crucial for\napplications such as podcast creation, virtual agents, and multimedia content\ngeneration. However, existing systems struggle to maintain speaker consistency,\nmodel overlapping speech, and synthesize coherent conversations efficiently. In\nthis paper, we introduce CoVoMix2, a fully non-autoregressive framework for\nzero-shot multi-talker dialogue generation. CoVoMix2 directly predicts\nmel-spectrograms from multi-stream transcriptions using a flow-matching-based\ngenerative model, eliminating the reliance on intermediate token\nrepresentations. To better capture realistic conversational dynamics, we\npropose transcription-level speaker disentanglement, sentence-level alignment,\nand prompt-level random masking strategies. Our approach achieves\nstate-of-the-art performance, outperforming strong baselines like MoonCast and\nSesame in speech quality, speaker consistency, and inference speed. Notably,\nCoVoMix2 operates without requiring transcriptions for the prompt and supports\ncontrollable dialogue generation, including overlapping speech and precise\ntiming control, demonstrating strong generalizability to real-world speech\ngeneration scenarios.", "published": "2025-06-01 07:51:45", "link": "http://arxiv.org/abs/2506.00885v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging AM and FM Rhythm Spectrograms for Dementia Classification and Assessment", "abstract": "This study explores the potential of Rhythm Formant Analysis (RFA) to capture\nlong-term temporal modulations in dementia speech. Specifically, we introduce\nRFA-derived rhythm spectrograms as novel features for dementia classification\nand regression tasks. We propose two methodologies: (1) handcrafted features\nderived from rhythm spectrograms, and (2) a data-driven fusion approach,\nintegrating proposed RFA-derived rhythm spectrograms with vision transformer\n(ViT) for acoustic representations along with BERT-based linguistic embeddings.\nWe compare these with existing features. Notably, our handcrafted features\noutperform eGeMAPs with a relative improvement of $14.2\\%$ in classification\naccuracy and comparable performance in the regression task. The fusion approach\nalso shows improvement, with RFA spectrograms surpassing Mel spectrograms in\nclassification by around a relative improvement of $13.1\\%$ and a comparable\nregression score with the baselines.", "published": "2025-06-01 06:56:52", "link": "http://arxiv.org/abs/2506.00861v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fine-Tuning ASR for Stuttered Speech: Personalized vs. Generalized Approaches", "abstract": "Stuttering -- characterized by involuntary disfluencies such as blocks,\nprolongations, and repetitions -- is often misinterpreted by automatic speech\nrecognition (ASR) systems, resulting in elevated word error rates and making\nvoice-driven technologies inaccessible to people who stutter. The variability\nof disfluencies across speakers and contexts further complicates ASR training,\ncompounded by limited annotated stuttered speech data. In this paper, we\ninvestigate fine-tuning ASRs for stuttered speech, comparing generalized models\n(trained across multiple speakers) to personalized models tailored to\nindividual speech characteristics. Using a diverse range of voice-AI scenarios,\nincluding virtual assistants and video interviews, we evaluate how\npersonalization affects transcription accuracy. Our findings show that\npersonalized ASRs significantly reduce word error rates, especially in\nspontaneous speech, highlighting the potential of tailored models for more\ninclusive voice technologies.", "published": "2025-06-01 06:25:20", "link": "http://arxiv.org/abs/2506.00853v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Unlearning", "abstract": "We introduce machine unlearning for speech tasks, a novel and underexplored\nresearch problem that aims to efficiently and effectively remove the influence\nof specific data from trained speech models without full retraining. This has\nimportant applications in privacy preservation, removal of outdated or noisy\ndata, and bias mitigation. While machine unlearning has been studied in\ncomputer vision and natural language processing, its application to speech is\nlargely unexplored due to the high-dimensional, sequential, and\nspeaker-dependent nature of speech data. We define two fundamental speech\nunlearning tasks: sample unlearning, which removes individual data points\n(e.g., a voice recording), and class unlearning, which removes an entire\ncategory (e.g., all data from a speaker), while preserving performance on the\nremaining data. Experiments on keyword spotting and speaker identification\ndemonstrate that unlearning speech data is significantly more challenging than\nunlearning image or text data. We conclude with key future directions in this\narea, including structured training, robust evaluation, feature-level\nunlearning, broader applications, scalable methods, and adversarial robustness.", "published": "2025-06-01 06:04:16", "link": "http://arxiv.org/abs/2506.00848v1", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "HASRD: Hierarchical Acoustic and Semantic Representation Disentanglement", "abstract": "Effective speech representations for spoken language models must balance\nsemantic relevance with acoustic fidelity for high-quality reconstruction.\nHowever, existing approaches struggle to achieve both simultaneously. To\naddress this, we introduce Hierarchical Acoustic and Semantic Representation\nDisentanglement (HASRD, pronounced `hazard'), a framework that factorizes\nself-supervised learning representations into discrete semantic and acoustic\ntokens. HASRD assigns the semantic representation to the first codebook, while\nencoding acoustic residuals in subsequent codebooks. This preserves ASR\nperformance while achieving high-quality reconstruction. Additionally, we\nenhance HASRD's encoder efficiency, improving ASR performance without\ncompromising reconstruction quality. Compared to SpeechTokenizer, HASRD\nachieves a 44% relative WER improvement, superior reconstruction quality, and\n2x lower bitrate, demonstrating its effectiveness in disentangling acoustic and\nsemantic information.", "published": "2025-06-01 05:38:39", "link": "http://arxiv.org/abs/2506.00843v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Counterfactual Activation Editing for Post-hoc Prosody and Mispronunciation Correction in TTS Models", "abstract": "Recent advances in Text-to-Speech (TTS) have significantly improved speech\nnaturalness, increasing the demand for precise prosody control and\nmispronunciation correction. Existing approaches for prosody manipulation often\ndepend on specialized modules or additional training, limiting their capacity\nfor post-hoc adjustments. Similarly, traditional mispronunciation correction\nrelies on grapheme-to-phoneme dictionaries, making it less practical in\nlow-resource settings. We introduce Counterfactual Activation Editing, a\nmodel-agnostic method that manipulates internal representations in a\npre-trained TTS model to achieve post-hoc control of prosody and pronunciation.\nExperimental results show that our method effectively adjusts prosodic features\nand corrects mispronunciations while preserving synthesis quality. This opens\nthe door to inference-time refinement of TTS outputs without retraining,\nbridging the gap between pre-trained TTS models and editable speech synthesis.", "published": "2025-06-01 04:33:37", "link": "http://arxiv.org/abs/2506.00832v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FUSE: Universal Speech Enhancement using Multi-Stage Fusion of Sparse Compression and Token Generation Models for the URGENT 2025 Challenge", "abstract": "We propose a multi-stage framework for universal speech enhancement, designed\nfor the Interspeech 2025 URGENT Challenge. Our system first employs a Sparse\nCompression Network to robustly separate sources and extract an initial clean\nspeech estimate from noisy inputs. This is followed by an efficient generative\nmodel that refines speech quality by leveraging self-supervised features and\noptimizing a masked language modeling objective on acoustic tokens derived from\na neural audio codec. In the final stage, a fusion network integrates the\noutputs of the first two stages with the original noisy signal, achieving a\nbalanced improvement in both signal fidelity and perceptual quality.\nAdditionally, a shift trick that aggregates multiple time-shifted predictions,\nalong with output blending, further boosts performance. Experimental results on\nchallenging multilingual datasets with variable sampling rates and diverse\ndistortion types validate the effectiveness of our approach.", "published": "2025-06-01 03:23:27", "link": "http://arxiv.org/abs/2506.00809v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CLAP-ART: Automated Audio Captioning with Semantic-rich Audio Representation Tokenizer", "abstract": "Automated Audio Captioning (AAC) aims to describe the semantic contexts of\ngeneral sounds, including acoustic events and scenes, by leveraging effective\nacoustic features. To enhance performance, an AAC method, EnCLAP, employed\ndiscrete tokens from EnCodec as an effective input for fine-tuning a language\nmodel BART. However, EnCodec is designed to reconstruct waveforms rather than\ncapture the semantic contexts of general sounds, which AAC should describe. To\naddress this issue, we propose CLAP-ART, an AAC method that utilizes\n``semantic-rich and discrete'' tokens as input. CLAP-ART computes semantic-rich\ndiscrete tokens from pre-trained audio representations through vector\nquantization. We experimentally confirmed that CLAP-ART outperforms baseline\nEnCLAP on two AAC benchmarks, indicating that semantic-rich discrete tokens\nderived from semantically rich AR are beneficial for AAC.", "published": "2025-06-01 03:01:16", "link": "http://arxiv.org/abs/2506.00800v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Development of Hardware-in-Loop Framework for Satellite Communication Self-Healing Networks", "abstract": "The use of Low Earth Orbit (LEO) satellites in the next generation (Next-G)\ncommunication systems has been gaining traction over the last few years due to\ntheir potential for providing global connectivity with low latency. Since they\nare the closest to the earth they come with their own set of disadvantages\nincluding high vulnerability to jamming and interference. To address these\nissues, this paper introduces a resilient, self-healing network designed to\noptimize signal quality under dynamic interference and adversarial conditions.\nThe network leverages inter-satellite communication and an intelligent\nalgorithm selection process, incorporating combining techniques like\ndistributed-Maximal Ratio Combining (d-MRC), distributed-Linear Minimum Mean\nSquared Error Estimation (d-LMMSE), and Selection Combining (SC). These\nalgorithms are selected to improve performance by adapting to changing network\nconditions. To evaluate the effectiveness of the proposed solution, we develop\na software-defined radio (SDR)-based hardware testbed and perform detailed\nperformance evaluations. Additionally, we present results from field tests\nconducted on the AERPAW testbed, which validate the proposed combining\nsolutions in real-world scenarios. The results show that our approach makes LEO\nsatellite networks more reliable and better able to handle interference, making\nthem suitable for critical communications.", "published": "2025-06-01 23:03:04", "link": "http://arxiv.org/abs/2506.01210v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wasserstein Distributionally Robust Adaptive Beamforming", "abstract": "Distributionally robust optimization (DRO)-based robust adaptive beamforming\n(RAB) enables enhanced robustness against model uncertainties, such as steering\nvector mismatches and interference-plus-noise covariance matrix estimation\nerrors. Existing DRO-based RAB methods primarily rely on uncertainty sets\ncharacterized by the first- and second-order moments. In this work, we propose\na novel Wasserstein DRO-based beamformer, using the worst-case\nsignal-to-interference-plus-noise ratio maximization formulation. The proposed\nmethod leverages the Wasserstein metric to define uncertainty sets, offering a\ndata-driven characterization of uncertainty. We show that the choice of the\nWasserstein cost function plays a crucial role in shaping the resulting\nformulation, with norm-based and Mahalanobis-like quadratic costs recovering\nclassical norm-constrained and ellipsoidal robust beamforming models,\nrespectively. This insight highlights the Wasserstein DRO framework as a\nunifying approach, bridging deterministic and distributionally robust\nbeamforming methodologies.", "published": "2025-06-01 20:13:40", "link": "http://arxiv.org/abs/2506.01154v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Scalable Association of Users in CF-mMIMO: A Synergy of Communication, Sensing, and JCAS", "abstract": "Cell-free massive multiple-input multiple-output (CF-mMIMO) is a key enabler\nfor the sixth generation (6G) networks, offering unprecedented spectral\nefficiency and ubiquitous coverage. In CF-mMIMO systems, the association of\nuser equipments (UEs) to access points (APs) is a critical challenge, as it\ndirectly impacts network scalability, interference management, and overall\nsystem performance. Conventional association methods primarily focus on\noptimizing communication performance. However, with the emergence of sensing\nand joint communication and sensing (JCAS) requirements, conventional\napproaches become insufficient. To address this challenge, we propose a\nscalable user association (SUA) scheme for CF-mMIMO networks, considering\nheterogeneous UE requirements. Designed to enhance the performance of both\nsensing and communication, the proposed SUA scheme aims to ensure network\nscalability. This is achieved by dynamically assigning APs to UEs based on\ntheir specific service requirements (communication, sensing, or JCAS), while\nconsidering link quality, interference mitigation, and network-related\nconstraints. Specifically, the proposed SUA scheme employs AP masking, link\nprioritization, and an optimization-based association mechanism to select the\nmost suitable APs for each UE. Simulations show that, compared to conventional\nCF-mMIMO methods, the proposed SUA scheme significantly reduces interference\nand computational runtime, while improving the symbol error rate for\ncommunication and the probability of detection for sensing.", "published": "2025-06-01 15:58:46", "link": "http://arxiv.org/abs/2506.01060v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Group-Wise Narrow Beam Design for Uplink Channel Estimation in Hybrid Beamforming Systems", "abstract": "In this paper, we consider uplink channel estimation for massive multi-input\nmulti-output (MIMO) systems with partially connected hybrid beamforming\n(PC-HBF) structures. Existing beam design and channel estimation schemes are\nusually based on ideal assumptions and require transmitting pilots across\nmultiple timeslots, making them unsuitable for practical PC-HBF systems. To\novercome these drawbacks, we propose a novel beam design and a corresponding\nchannel estimation algorithm to achieve accurate and real-time uplink channel\nestimation. Firstly, we introduce a group-wise narrow beam design in the\nvertical dimension to suppress interference from undesired angular components\nand improve vertical angle estimation accuracy,which divides the columns of the\nuniform planar array (UPA)into groups and the vertical angle interval into\nsub-intervals.In this way, each group is assigned with a narrow beam to cover\none vertical angle sub-interval, and the set of narrow beams is designed based\non the filter design theory. Secondly, we optimize the antenna grouping pattern\nusing the Estimation of Distribution Algorithm (EDA), balancing interference\nsuppression and resolution capability in the horizontal dimension, leading to a\nbetter horizontal angle estimation performance. Finally, we design a\nlow-complexity group-wise subspace constrained variational Bayesian inference\n(GW-SC-VBI) algorithm to fully take advantage of the proposed beam design to\nachieve both low-complexity and high-accurate channel estimation. Simulation\nresults demonstrate that the proposed scheme achieves notable performance gains\nover baseline methods.", "published": "2025-06-01 14:59:39", "link": "http://arxiv.org/abs/2506.01043v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Self-Supervised-ISAR-Net Enables Fast Sparse ISAR Imaging", "abstract": "Numerous sparse inverse synthetic aperture radar (ISAR) imaging methods based\non unfolded neural networks have been developed for high-quality image\nreconstruction with sparse measurements. However, their training typically\nrequires paired ISAR images and echoes, which are often difficult to obtain.\nMeanwhile, one property can be observed that for a certain sparse measurement\nconfiguration of ISAR, when a target is rotated around its center of mass, only\nthe image of the target undergoes the corresponding rotation after ISAR\nimaging, while the grating lobes do not follow this rotation and are solely\ndetermined by the sparse-sampling pattern. This property is mathematically\ntermed as the equivariant property. Taking advantage of this property, an\nunfolded neural network for sparse ISAR imaging with self-supervised learning,\nnamed SS-ISAR-Net is proposed. It effectively mitigates grating lobes caused by\nsparse radar echo, allowing high-quality training to be achieved using only\nsparse radar echo data. The superiority of the proposed SS-ISAR-Net, compared\nto existing methods, is verified through experiments with both synthetic and\nreal-world measurement data.", "published": "2025-06-01 14:38:59", "link": "http://arxiv.org/abs/2506.01038v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field Directional Modulation for RIS-Aided Movable Antenna MIMO Systems with Hardware Impairments", "abstract": "Movable antennas (MAs) are a promising technology to achieve a significant\nenhancement in rate for future wireless networks. The pioneering investigation\non near-field directional modulation design for a reconfigurable intelligent\nsurface (RIS)-assisted MA system is presented, with the base station equipped\nwith a MA array. To maximize the secrecy sum rate (Max-SSR) with hardware\nimpairments (HWIs) and imperfect channel state information (CSI), which\ninvolves a joint optimization of beamforming vectors for confidential messages\nand artificial noise (AN), power allocation factors, phase shift matrices, MA\npositions, and receive beamforming vectors. Firstly, the transmit beamforming\nvectors and phase shift matrices are iteratively optimized, leveraging leakage\ntheory and phase alignment techniques. Then, two novel algorithms for discrete\nMA positioning are proposed, respectively, employing uniform and compressed\nsensing (CS)-based non-uniform grouping strategies. Subsequently, the AN is\nconsidered and designed as the additional energy required for zero-space\nprojection, and the receive beamforming vector is derived using the minimum\nmean square error (MMSE) method. The proposed algorithms have low computational\ncomplexity. Simulation results demonstrate the effectiveness of the proposed\nalgorithms. Under HWIs and imperfect CSI, the proposed algorithm can achieve a\n28\\% enhancement in SSR performance while reducing the number of antennas by\n37.5\\% compared to traditional fixed-position antenna (FPA) systems.", "published": "2025-06-01 11:47:03", "link": "http://arxiv.org/abs/2506.00972v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "anyECG-chat: A Generalist ECG-MLLM for Flexible ECG Input and Multi-Task Understanding", "abstract": "The advent of multimodal large language models (MLLMs) has sparked interest\nin their application to electrocardiogram (ECG) analysis. However, existing\nECG-focused MLLMs primarily focus on report generation tasks, often limited to\nsingle 12-lead, short-duration (10s) ECG inputs, thereby underutilizing the\npotential of MLLMs. To this end, we aim to develop a MLLM for ECG analysis that\nsupports a broader range of tasks and more flexible ECG inputs. However,\nexisting ECG-QA datasets are often monotonous. To address this gap, we first\nconstructed the anyECG dataset, which encompasses a wide variety of tasks,\nincluding report generation, abnormal waveform localization, and open-ended\nquestion answering. In addition to standard hospital ECGs, we introduced\nlong-duration reduced-lead ECGs for home environments and multiple ECG\ncomparison scenarios commonly encountered in clinical practice. Furthermore, we\npropose the anyECG-chat model, which supports dynamic-length ECG inputs and\nmultiple ECG inputs. We trained the model using a three-stage curriculum\ntraining recipe with the anyECG dataset. A comprehensive evaluation was\nconducted, demonstrating that anyECG-chat is capable of supporting various\npractical application scenarios, including not only common report generation\ntasks but also abnormal waveform localization for long-duration reduced-lead\nECGs in home environments and comprehensive comparative analysis of multiple\nECGs.", "published": "2025-06-01 10:17:13", "link": "http://arxiv.org/abs/2506.00942v1", "categories": ["cs.CL", "cs.AI", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Training Beam Design for Channel Estimation in Hybrid mmWave MIMO Systems", "abstract": "Training beam design for channel estimation with infinite-resolution and\nlow-resolution phase shifters (PSs) in hybrid analog-digital milimeter wave\n(mmWave) massive multiple-input multiple-output (MIMO) systems is considered in\nthis paper. By exploiting the sparsity of mmWave channels, the optimization of\nthe sensing matrices (corresponding to training beams) is formulated according\nto the compressive sensing (CS) theory. Under the condition of\ninfinite-resolution PSs, we propose relevant algorithms to construct the\nsensing matrix, where the theory of convex optimization and the gradient\ndescent in Riemannian manifold is used to design the digital and analog part,\nrespectively. Furthermore, a block-wise alternating hybrid analog-digital\nalgorithm is proposed to tackle the design of training beams with\nlow-resolution PSs, where the performance degeneration caused by non-convex\nconstant modulus and discrete phase constraints is effectively compensated to\nsome extent thanks to the iterations among blocks. Finally, the orthogonal\nmatching pursuit (OMP) based estimator is adopted for achieving an effective\nrecovery of the sparse mmWave channel. Simulation results demonstrate the\nperformance advantages of proposed algorithms compared with some existing\nschemes.", "published": "2025-06-01 09:00:36", "link": "http://arxiv.org/abs/2506.00913v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-Field Multiuser Localization Based on Extremely Large Antenna Array with Limited RF Chains", "abstract": "Extremely large antenna array (ELAA) not only effectively enhances system\ncommunication performance but also improves the sensing capabilities of\ncommunication systems, making it one of the key enabling technologies in 6G\nwireless networks. This paper investigates the multiuser localization problem\nin an uplink Multiple Input Multiple Output (MIMO) system, where the base\nstation (BS) is equipped with an ELAA to receive signals from multiple\nsingle-antenna users. We exploit analog beamforming to reduce the number of\nradio frequency (RF) chains. We first develop a comprehensive near-field ELAA\nchannel model that accounts for the antenna radiation pattern and free space\npath loss. Due to the large aperture of the ELAA, the angular resolution of the\narray is high, which improves user localization accuracy. However, it also\nmakes the user localization problem highly non-convex, posing significant\nchallenges when the number of RF chains is limited. To address this issue, we\nuse an array partitioning strategy to divide the ELAA channel into multiple\nsubarray channels and utilize the geometric constraints between user locations\nand subarrays for probabilistic modeling. To fully exploit these geometric\nconstraints, we propose the array partitioning-based location estimation with\nlimited measurements (APLE-LM) algorithm based on the message passing principle\nto achieve multiuser localization. We derive the Bayesian Cramer-Rao Bound\n(BCRB) as the theoretical performance lower bound for our formulated near-field\nmultiuser localization problem. Extensive simulations under various parameter\nconfigurations validate the proposed APLE-LM algorithm. The results demonstrate\nthat APLE-LM achieves superior localization accuracy compared to baseline\nalgorithms and approaches the BCRB at high signal-to-noise ratio (SNR).", "published": "2025-06-01 07:51:16", "link": "http://arxiv.org/abs/2506.00884v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Conceal Truth while Show Fake: T/F Frequency Multiplexing based Anti-Intercepting Transmission", "abstract": "In wireless communication adversarial scenarios, signals are easily\nintercepted by non-cooperative parties, exposing the transmission of\nconfidential information. This paper proposes a true-and-false (T/F) frequency\nmultiplexing based anti-intercepting transmission scheme capable of concealing\ntruth while showing fake (CTSF), integrating both offensive and defensive\nstrategies. Specifically, through multi-source cooperation, true and false\nsignals are transmitted over multiple frequency bands using non-orthogonal\nfrequency division multiplexing. The decoy signals are used to deceive\nnon-cooperative eavesdropper, while the true signals are hidden to counter\ninterception threats. Definitions for the interception and deception\nprobabilities are provided, and the mechanism of CTSF is discussed. To improve\nthe secrecy performance of true signals while ensuring decoy signals achieve\ntheir deceptive purpose, we model the problem as maximizing the sum secrecy\nrate of true signals, with constraint on the decoy effect. Furthermore, we\npropose a bi-stage alternating dual-domain optimization approach for joint\noptimization of both power allocation and correlation coefficients among\nmultiple sources, and a Newton's method is proposed for fitting the T/F\nfrequency multiplexing factor. In addition, simulation results verify the\nefficiency of anti-intercepting performance of our proposed CTSF scheme.", "published": "2025-06-01 03:27:26", "link": "http://arxiv.org/abs/2506.00811v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
