{"title": "Contextualized moral inference", "abstract": "Developing moral awareness in intelligent systems has shifted from a topic of\nphilosophical inquiry to a critical and practical issue in artificial\nintelligence over the past decades. However, automated inference of everyday\nmoral situations remains an under-explored problem. We present a text-based\napproach that predicts people's intuitive judgment of moral vignettes. Our\nmethodology builds on recent work in contextualized language models and textual\ninference of moral sentiment. We show that a contextualized representation\noffers a substantial advantage over alternative representations based on word\nembeddings and emotion sentiment in inferring human moral judgment, evaluated\nand reflected in three independent datasets from moral psychology. We discuss\nthe promise and limitations of our approach toward automated textual moral\nreasoning.", "published": "2020-08-25 00:34:28", "link": "http://arxiv.org/abs/2008.10762v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple Unsupervised Similarity-Based Aspect Extraction", "abstract": "In the context of sentiment analysis, there has been growing interest in\nperforming a finer granularity analysis focusing on the specific aspects of the\nentities being evaluated. This is the goal of Aspect-Based Sentiment Analysis\n(ABSA) which basically involves two tasks: aspect extraction and polarity\ndetection. The first task is responsible for discovering the aspects mentioned\nin the review text and the second task assigns a sentiment orientation\n(positive, negative, or neutral) to that aspect. Currently, the\nstate-of-the-art in ABSA consists of the application of deep learning methods\nsuch as recurrent, convolutional and attention neural networks. The limitation\nof these techniques is that they require a lot of training data and are\ncomputationally expensive. In this paper, we propose a simple approach called\nSUAEx for aspect extraction. SUAEx is unsupervised and relies solely on the\nsimilarity of word embeddings. Experimental results on datasets from three\ndifferent domains have shown that SUAEx achieves results that can outperform\nthe state-of-the-art attention-based approach at a fraction of the time.", "published": "2020-08-25 04:58:07", "link": "http://arxiv.org/abs/2008.10820v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TabSim: A Siamese Neural Network for Accurate Estimation of Table\n  Similarity", "abstract": "Tables are a popular and efficient means of presenting structured\ninformation. They are used extensively in various kinds of documents including\nweb pages. Tables display information as a two-dimensional matrix, the\nsemantics of which is conveyed by a mixture of structure (rows, columns),\nheaders, caption, and content. Recent research has started to consider tables\nas first class objects, not just as an addendum to texts, yielding interesting\nresults for problems like table matching, table completion, or value\nimputation. All of these problems inherently rely on an accurate measure for\nthe semantic similarity of two tables. We present TabSim, a novel method to\ncompute table similarity scores using deep neural networks. Conceptually,\nTabSim represents a table as a learned concatenation of embeddings of its\ncaption, its content, and its structure. Given two tables in this\nrepresentation, a Siamese neural network is trained to compute a score\ncorrelating with the tables' semantic similarity. To train and evaluate our\nmethod, we created a gold standard corpus consisting of 1500 table pairs\nextracted from biomedical articles and manually scored regarding their degree\nof similarity, and adopted two other corpora originally developed for a\ndifferent yet similar task. Our evaluation shows that TabSim outperforms other\ntable similarity measures on average by app. 7% pp F1-score in a binary\nsimilarity classification setting and by app. 1.5% pp in a ranking scenario.", "published": "2020-08-25 07:32:09", "link": "http://arxiv.org/abs/2008.10856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ETC-NLG: End-to-end Topic-Conditioned Natural Language Generation", "abstract": "Plug-and-play language models (PPLMs) enable topic-conditioned natural\nlanguage generation by pairing large pre-trained generators with attribute\nmodels used to steer the predicted token distribution towards the selected\ntopic. Despite their computational efficiency, PPLMs require large amounts of\nlabeled texts to effectively balance generation fluency and proper\nconditioning, making them unsuitable for low-resource settings. We present\nETC-NLG, an approach leveraging topic modeling annotations to enable\nfully-unsupervised End-to-end Topic-Conditioned Natural Language Generation\nover emergent topics in unlabeled document collections. We first test the\neffectiveness of our approach in a low-resource setting for Italian, evaluating\nthe conditioning for both topic models and gold annotations. We then perform a\ncomparative evaluation of ETC-NLG for Italian and English using a parallel\ncorpus. Finally, we propose an automatic approach to estimate the effectiveness\nof conditioning on the generated utterances.", "published": "2020-08-25 08:22:38", "link": "http://arxiv.org/abs/2008.10875v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Query Understanding via Intent Description Generation", "abstract": "Query understanding is a fundamental problem in information retrieval (IR),\nwhich has attracted continuous attention through the past decades. Many\ndifferent tasks have been proposed for understanding users' search queries,\ne.g., query classification or query clustering. However, it is not that precise\nto understand a search query at the intent class/cluster level due to the loss\nof many detailed information. As we may find in many benchmark datasets, e.g.,\nTREC and SemEval, queries are often associated with a detailed description\nprovided by human annotators which clearly describes its intent to help\nevaluate the relevance of the documents. If a system could automatically\ngenerate a detailed and precise intent description for a search query, like\nhuman annotators, that would indicate much better query understanding has been\nachieved. In this paper, therefore, we propose a novel\nQuery-to-Intent-Description (Q2ID) task for query understanding. Unlike those\nexisting ranking tasks which leverage the query and its description to compute\nthe relevance of documents, Q2ID is a reverse task which aims to generate a\nnatural language intent description based on both relevant and irrelevant\ndocuments of a given query. To address this new task, we propose a novel\nContrastive Generation model, namely CtrsGen for short, to generate the intent\ndescription by contrasting the relevant documents with the irrelevant documents\ngiven a query. We demonstrate the effectiveness of our model by comparing with\nseveral state-of-the-art generation models on the Q2ID task. We discuss the\npotential usage of such Q2ID technique through an example application.", "published": "2020-08-25 08:56:40", "link": "http://arxiv.org/abs/2008.10889v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Computational Analysis of Global Structure in Canonical,\n  Non-Canonical and Non-Literary Texts", "abstract": "This study investigates global properties of literary and non-literary texts.\nWithin the literary texts, a distinction is made between canonical and\nnon-canonical works. The central hypothesis of the study is that the three text\ntypes (non-literary, literary/canonical and literary/non-canonical) exhibit\nsystematic differences with respect to structural design features as correlates\nof aesthetic responses in readers. To investigate these differences, we\ncompiled a corpus containing texts of the three categories of interest, the\nJena Textual Aesthetics Corpus. Two aspects of global structure are\ninvestigated, variability and self-similar (fractal) patterns, which reflect\nlong-range correlations along texts. We use four types of basic observations,\n(i) the frequency of POS-tags per sentence, (ii) sentence length, (iii) lexical\ndiversity in chunks of text, and (iv) the distribution of topic probabilities\nin chunks of texts. These basic observations are grouped into two more general\ncategories, (a) the low-level properties (i) and (ii), which are observed at\nthe level of the sentence (reflecting linguistic decoding), and (b) the\nhigh-level properties (iii) and (iv), which are observed at the textual level\n(reflecting comprehension). The basic observations are transformed into time\nseries, and these time series are subject to multifractal detrended fluctuation\nanalysis (MFDFA). Our results show that low-level properties of texts are\nbetter discriminators than high-level properties, for the three text types\nunder analysis. Canonical literary texts differ from non-canonical ones\nprimarily in terms of variability. Fractality seems to be a universal feature\nof text, more pronounced in non-literary than in literary texts. Beyond the\nspecific results of the study, we intend to open up new perspectives on the\nexperimental study of textual aesthetics.", "published": "2020-08-25 09:37:06", "link": "http://arxiv.org/abs/2008.10906v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "JokeMeter at SemEval-2020 Task 7: Convolutional humor", "abstract": "This paper describes our system that was designed for Humor evaluation within\nthe SemEval-2020 Task 7. The system is based on convolutional neural network\narchitecture. We investigate the system on the official dataset, and we provide\nmore insight to model itself to see how the learned inner features look.", "published": "2020-08-25 14:27:58", "link": "http://arxiv.org/abs/2008.11053v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Impact of Indirect Machine Translation on Sentiment Classification", "abstract": "Sentiment classification has been crucial for many natural language\nprocessing (NLP) applications, such as the analysis of movie reviews, tweets,\nor customer feedback. A sufficiently large amount of data is required to build\na robust sentiment classification system. However, such resources are not\nalways available for all domains or for all languages.\n  In this work, we propose employing a machine translation (MT) system to\ntranslate customer feedback into another language to investigate in which cases\ntranslated sentences can have a positive or negative impact on an automatic\nsentiment classifier. Furthermore, as performing a direct translation is not\nalways possible, we explore the performance of automatic classifiers on\nsentences that have been translated using a pivot MT system.\n  We conduct several experiments using the above approaches to analyse the\nperformance of our proposed sentiment classification system and discuss the\nadvantages and drawbacks of classifying translated sentences.", "published": "2020-08-25 20:30:21", "link": "http://arxiv.org/abs/2008.11257v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating (Factual?) Narrative Summaries of RCTs: Experiments with\n  Neural Multi-Document Summarization", "abstract": "We consider the problem of automatically generating a narrative biomedical\nevidence summary from multiple trial reports. We evaluate modern neural models\nfor abstractive summarization of relevant article abstracts from systematic\nreviews previously conducted by members of the Cochrane collaboration, using\nthe authors conclusions section of the review abstract as our target. We enlist\nmedical professionals to evaluate generated summaries, and we find that modern\nsummarization systems yield consistently fluent and relevant synopses, but that\nthey are not always factual. We propose new approaches that capitalize on\ndomain-specific models to inform summarization, e.g., by explicitly demarcating\nsnippets of inputs that convey key findings, and emphasizing the reports of\nlarge and high-quality trials. We find that these strategies modestly improve\nthe factual accuracy of generated summaries. Finally, we propose a new method\nfor automatically evaluating the factuality of generated narrative evidence\nsyntheses using models that infer the directionality of reported findings.", "published": "2020-08-25 22:22:50", "link": "http://arxiv.org/abs/2008.11293v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concept Extraction Using Pointer-Generator Networks", "abstract": "Concept extraction is crucial for a number of downstream applications.\nHowever, surprisingly enough, straightforward single token/nominal\nchunk-concept alignment or dictionary lookup techniques such as DBpedia\nSpotlight still prevail. We propose a generic open-domain OOV-oriented\nextractive model that is based on distant supervision of a pointer-generator\nnetwork leveraging bidirectional LSTMs and a copy mechanism. The model has been\ntrained on a large annotated corpus compiled specifically for this task from\n250K Wikipedia pages, and tested on regular pages, where the pointers to other\npages are considered as ground truth concepts. The outcome of the experiments\nshows that our model significantly outperforms standard techniques and, when\nused on top of DBpedia Spotlight, further improves its performance. The\nexperiments furthermore show that the model can be readily ported to other\ndatasets on which it equally achieves a state-of-the-art performance.", "published": "2020-08-25 22:28:14", "link": "http://arxiv.org/abs/2008.11295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Complicating the Social Networks for Better Storytelling: An Empirical\n  Study of Chinese Historical Text and Novel", "abstract": "Digital humanities is an important subject because it enables developments in\nhistory, literature, and films. In this paper, we perform an empirical study of\na Chinese historical text, Records of the Three Kingdoms (\\textit{Records}),\nand a historical novel of the same story, Romance of the Three Kingdoms\n(\\textit{Romance}). We employ natural language processing techniques to extract\ncharacters and their relationships. Then, we characterize the social networks\nand sentiments of the main characters in the historical text and the historical\nnovel. We find that the social network in \\textit{Romance} is more complex and\ndynamic than that of \\textit{Records}, and the influence of the main characters\ndiffers. These findings shed light on the different styles of storytelling in\nthe two literary genres and how the historical novel complicates the social\nnetworks of characters to enrich the literariness of the story.", "published": "2020-08-25 06:03:14", "link": "http://arxiv.org/abs/2008.10835v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Is this sentence valid? An Arabic Dataset for Commonsense Validation", "abstract": "The commonsense understanding and validation remains a challenging task in\nthe field of natural language understanding. Therefore, several research papers\nhave been published that studied the capability of proposed systems to evaluate\nthe models ability to validate commonsense in text. In this paper, we present a\nbenchmark Arabic dataset for commonsense understanding and validation as well\nas a baseline research and models trained using the same dataset. To the best\nof our knowledge, this dataset is considered as the first in the field of\nArabic text commonsense validation. The dataset is distributed under the\nCreative Commons BY-SA 4.0 license and can be found on GitHub.", "published": "2020-08-25 08:15:55", "link": "http://arxiv.org/abs/2008.10873v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A simple method for domain adaptation of sentence embeddings", "abstract": "Pre-trained sentence embeddings have been shown to be very useful for a\nvariety of NLP tasks. Due to the fact that training such embeddings requires a\nlarge amount of data, they are commonly trained on a variety of text data. An\nadaptation to specific domains could improve results in many cases, but such a\nfinetuning is usually problem-dependent and poses the risk of over-adapting to\nthe data used for adaptation. In this paper, we present a simple universal\nmethod for finetuning Google's Universal Sentence Encoder (USE) using a Siamese\narchitecture. We demonstrate how to use this approach for a variety of data\nsets and present results on different data sets representing similar problems.\nThe approach is also compared to traditional finetuning on these data sets. As\na further advantage, the approach can be used for combining data sets with\ndifferent annotations. We also present an embedding finetuned on all data sets\nin parallel.", "published": "2020-08-25 18:31:08", "link": "http://arxiv.org/abs/2008.11228v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conceptualized Representation Learning for Chinese Biomedical Text\n  Mining", "abstract": "Biomedical text mining is becoming increasingly important as the number of\nbiomedical documents and web data rapidly grows. Recently, word representation\nmodels such as BERT has gained popularity among researchers. However, it is\ndifficult to estimate their performance on datasets containing biomedical texts\nas the word distributions of general and biomedical corpora are quite\ndifferent. Moreover, the medical domain has long-tail concepts and\nterminologies that are difficult to be learned via language models. For the\nChinese biomedical text, it is more difficult due to its complex structure and\nthe variety of phrase combinations. In this paper, we investigate how the\nrecently introduced pre-trained language model BERT can be adapted for Chinese\nbiomedical corpora and propose a novel conceptualized representation learning\napproach. We also release a new Chinese Biomedical Language Understanding\nEvaluation benchmark (\\textbf{ChineseBLUE}). We examine the effectiveness of\nChinese pre-trained models: BERT, BERT-wwm, RoBERTa, and our approach.\nExperimental results on the benchmark show that our approach could bring\nsignificant gain. We release the pre-trained model on GitHub:\nhttps://github.com/alibaba-research/ChineseBLUE.", "published": "2020-08-25 04:41:35", "link": "http://arxiv.org/abs/2008.10813v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ICE-Talk: an Interface for a Controllable Expressive Talking Machine", "abstract": "ICE-Talk is an open source web-based GUI that allows the use of a TTS system\nwith controllable parameters via a text field and a clickable 2D plot. It\nenables the study of latent spaces for controllable TTS. Moreover it is\nimplemented as a module that can be used as part of a Human-Agent interaction.", "published": "2020-08-25 14:17:10", "link": "http://arxiv.org/abs/2008.11045v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learning from students' perception on professors through opinion mining", "abstract": "Students' perception of classes measured through their opinions on teaching\nsurveys allows to identify deficiencies and problems, both in the environment\nand in the learning methodologies. The purpose of this paper is to study,\nthrough sentiment analysis using natural language processing (NLP) and machine\nlearning (ML) techniques, those opinions in order to identify topics that are\nrelevant for students, as well as predicting the associated sentiment via\npolarity analysis. As a result, it is implemented, trained and tested two\nalgorithms to predict the associated sentiment as well as the relevant topics\nof such opinions. The combination of both approaches then becomes useful to\nidentify specific properties of the students' opinions associated with each\nsentiment label (positive, negative or neutral opinions) and topic.\nFurthermore, we explore the possibility that students' perception surveys are\ncarried out without closed questions, relying on the information that students\ncan provide through open questions where they express their opinions about\ntheir classes.", "published": "2020-08-25 17:36:45", "link": "http://arxiv.org/abs/2008.11183v1", "categories": ["cs.CL", "cs.CY", "cs.NA", "math.NA"], "primary_category": "cs.CL"}
{"title": "Extractive Summarizer for Scholarly Articles", "abstract": "We introduce an extractive method that will summarize long scientific papers.\nOur model uses presentation slides provided by the authors of the papers as the\ngold summary standard to label the sentences. The sentences are ranked based on\ntheir novelty and their importance as estimated by deep neural networks. Our\nwindow-based extractive labeling of sentences results in the improvement of at\nleast 4 ROUGE1-Recall points.", "published": "2020-08-25 22:08:34", "link": "http://arxiv.org/abs/2008.11290v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Aphasic Speech Recognition using a Mixture of Speech Intelligibility\n  Experts", "abstract": "Robust speech recognition is a key prerequisite for semantic feature\nextraction in automatic aphasic speech analysis. However, standard\none-size-fits-all automatic speech recognition models perform poorly when\napplied to aphasic speech. One reason for this is the wide range of speech\nintelligibility due to different levels of severity (i.e., higher severity\nlends itself to less intelligible speech). To address this, we propose a novel\nacoustic model based on a mixture of experts (MoE), which handles the varying\nintelligibility stages present in aphasic speech by explicitly defining\nseverity-based experts. At test time, the contribution of each expert is\ndecided by estimating speech intelligibility with a speech intelligibility\ndetector (SID). We show that our proposed approach significantly reduces phone\nerror rates across all severity stages in aphasic speech compared to a baseline\napproach that does not incorporate severity information into the modeling\nprocess.", "published": "2020-08-25 02:35:22", "link": "http://arxiv.org/abs/2008.10788v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learned Transferable Architectures Can Surpass Hand-Designed\n  Architectures for Large Scale Speech Recognition", "abstract": "In this paper, we explore the neural architecture search (NAS) for automatic\nspeech recognition (ASR) systems. With reference to the previous works in the\ncomputer vision field, the transferability of the searched architecture is the\nmain focus of our work. The architecture search is conducted on the small proxy\ndataset, and then the evaluation network, constructed with the searched\narchitecture, is evaluated on the large dataset. Especially, we propose a\nrevised search space for speech recognition tasks which theoretically\nfacilitates the search algorithm to explore the architectures with low\ncomplexity. Extensive experiments show that: (i) the architecture searched on\nthe small proxy dataset can be transferred to the large dataset for the speech\nrecognition tasks. (ii) the architecture learned in the revised search space\ncan greatly reduce the computational overhead and GPU memory usage with mild\nperformance degradation. (iii) the searched architecture can achieve more than\n20% and 15% (average on the four test sets) relative improvements respectively\non the AISHELL-2 dataset and the large (10k hours) dataset, compared with our\nbest hand-designed DFSMN-SAN architecture. To the best of our knowledge, this\nis the first report of NAS results with large scale dataset (up to 10K hours),\nindicating the promising application of NAS to industrial ASR systems.", "published": "2020-08-25 08:41:36", "link": "http://arxiv.org/abs/2008.11589v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Few Shot Text-Independent speaker verification using 3D-CNN", "abstract": "Facial recognition system is one of the major successes of Artificial\nintelligence and has been used a lot over the last years. But, images are not\nthe only biometric present: audio is another possible biometric that can be\nused as an alternative to the existing recognition systems. However, the\ntext-independent audio data is not always available for tasks like speaker\nverification and also no work has been done in the past for text-independent\nspeaker verification assuming very little training data. Therefore, In this\npaper, we have proposed a novel method to verify the identity of the claimed\nspeaker using very few training data. To achieve this we are using a Siamese\nneural network with center loss and speaker bias loss. Experiments conducted on\nthe VoxCeleb1 dataset show that the proposed model accuracy even on training\nwith very few data is near to the state of the art model on text-independent\nspeaker verification", "published": "2020-08-25 15:03:29", "link": "http://arxiv.org/abs/2008.11088v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Medley2K: A Dataset of Medley Transitions", "abstract": "The automatic generation of medleys, i.e., musical pieces formed by different\nsongs concatenated via smooth transitions, is not well studied in the current\nliterature. To facilitate research on this topic, we make available a dataset\ncalled Medley2K that consists of 2,000 medleys and 7,712 labeled transitions.\nOur dataset features a rich variety of song transitions across different music\ngenres. We provide a detailed description of this dataset and validate it by\ntraining a state-of-the-art generative model in the task of generating\ntransitions between songs.", "published": "2020-08-25 16:46:56", "link": "http://arxiv.org/abs/2008.11159v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
