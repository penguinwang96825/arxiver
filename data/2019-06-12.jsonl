{"title": "Towards Geocoding Spatial Expressions", "abstract": "Imprecise composite location references formed using ad hoc spatial\nexpressions in English text makes the geocoding task challenging for both\ninference and evaluation. Typically such spatial expressions fill in\nunestablished areas with new toponyms for finer spatial referents. For example,\nthe spatial extent of the ad hoc spatial expression \"north of\" or \"50 minutes\naway from\" in relation to the toponym \"Dayton, OH\" refers to an ambiguous,\nimprecise area, requiring translation from this qualitative representation to a\nquantitative one with precise semantics using systems such as WGS84. Here we\nhighlight the challenges of geocoding such referents and propose a formal\nrepresentation that employs background knowledge, semantic approximations and\nrules, and fuzzy linguistic variables. We also discuss an appropriate\nevaluation technique for the task that is based on human contextualized and\nsubjective judgment.", "published": "2019-06-12 06:30:01", "link": "http://arxiv.org/abs/1906.04960v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incremental Learning from Scratch for Task-Oriented Dialogue Systems", "abstract": "Clarifying user needs is essential for existing task-oriented dialogue\nsystems. However, in real-world applications, developers can never guarantee\nthat all possible user demands are taken into account in the design phase.\nConsequently, existing systems will break down when encountering unconsidered\nuser needs. To address this problem, we propose a novel incremental learning\nframework to design task-oriented dialogue systems, or for short Incremental\nDialogue System (IDS), without pre-defining the exhaustive list of user needs.\nSpecifically, we introduce an uncertainty estimation module to evaluate the\nconfidence of giving correct responses. If there is high confidence, IDS will\nprovide responses to users. Otherwise, humans will be involved in the dialogue\nprocess, and IDS can learn from human intervention through an online learning\nmodule. To evaluate our method, we propose a new dataset which simulates\nunanticipated user needs in the deployment stage. Experiments show that IDS is\nrobust to unconsidered user actions, and can update itself online by smartly\nselecting only the most effective training data, and hence attains better\nperformance with less annotation cost.", "published": "2019-06-12 08:08:38", "link": "http://arxiv.org/abs/1906.04991v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Learning of Privacy-Preserving Text Representations for\n  De-Identification of Medical Records", "abstract": "De-identification is the task of detecting protected health information (PHI)\nin medical text. It is a critical step in sanitizing electronic health records\n(EHRs) to be shared for research. Automatic de-identification classifierscan\nsignificantly speed up the sanitization process. However, obtaining a large and\ndiverse dataset to train such a classifier that works wellacross many types of\nmedical text poses a challenge as privacy laws prohibit the sharing of raw\nmedical records. We introduce a method to create privacy-preserving shareable\nrepresentations of medical text (i.e. they contain no PHI) that does not\nrequire expensive manual pseudonymization. These representations can be shared\nbetween organizations to create unified datasets for training de-identification\nmodels. Our representation allows training a simple LSTM-CRF de-identification\nmodel to an F1 score of 97.4%, which is comparable to a strong baseline that\nexposes private information in its representation. A robust, widely available\nde-identification classifier based on our representation could potentially\nenable studies for which de-identification would otherwise be too costly.", "published": "2019-06-12 08:29:24", "link": "http://arxiv.org/abs/1906.05000v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Concept Discovery through Information Extraction in Restaurant Domain", "abstract": "Concept identification is a crucial step in understanding and building a\nknowledge base for any particular domain. However, it is not a simple task in\nvery large domains such as restaurants and hotel. In this paper, a novel\napproach of identifying a concept hierarchy and classifying unseen words into\nidentified concepts related to restaurant domain is presented. Sorting,\nidentifying, classifying of domain-related words manually is tedious and\ntherefore, the proposed process is automated to a great extent. Word embedding,\nhierarchical clustering, classification algorithms are effectively used to\nobtain concepts related to the restaurant domain. Further, this approach can\nalso be extended to create a semi-automatic ontology on restaurant domain.", "published": "2019-06-12 09:55:20", "link": "http://arxiv.org/abs/1906.05039v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Multilingual Sentence Representations With X-Probe", "abstract": "This paper extends the task of probing sentence representations for\nlinguistic insight in a multilingual domain. In doing so, we make two\ncontributions: first, we provide datasets for multilingual probing, derived\nfrom Wikipedia, in five languages, viz. English, French, German, Spanish and\nRussian. Second, we evaluate six sentence encoders for each language, each\ntrained by mapping sentence representations to English sentence\nrepresentations, using sentences in a parallel corpus. We discover that\ncross-lingually mapped representations are often better at retaining certain\nlinguistic information than representations derived from English encoders\ntrained on natural language inference (NLI) as a downstream task.", "published": "2019-06-12 11:21:05", "link": "http://arxiv.org/abs/1906.05061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Putting words in context: LSTM language models and lexical ambiguity", "abstract": "In neural network models of language, words are commonly represented using\ncontext-invariant representations (word embeddings) which are then put in\ncontext in the hidden layers. Since words are often ambiguous, representing the\ncontextually relevant information is not trivial. We investigate how an LSTM\nlanguage model deals with lexical ambiguity in English, designing a method to\nprobe its hidden representations for lexical and contextual information about\nwords. We find that both types of information are represented to a large\nextent, but also that there is room for improvement for contextual information.", "published": "2019-06-12 14:07:40", "link": "http://arxiv.org/abs/1906.05149v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monotonic Infinite Lookback Attention for Simultaneous Machine\n  Translation", "abstract": "Simultaneous machine translation begins to translate each source sentence\nbefore the source speaker is finished speaking, with applications to live and\nstreaming scenarios. Simultaneous systems must carefully schedule their reading\nof the source sentence to balance quality against latency. We present the first\nsimultaneous translation system to learn an adaptive schedule jointly with a\nneural machine translation (NMT) model that attends over all source tokens read\nthus far. We do so by introducing Monotonic Infinite Lookback (MILk) attention,\nwhich maintains both a hard, monotonic attention head to schedule the reading\nof the source sentence, and a soft attention head that extends from the\nmonotonic head back to the beginning of the source. We show that MILk's\nadaptive schedule allows it to arrive at latency-quality trade-offs that are\nfavorable to those of a recently proposed wait-k strategy for many latency\nvalues.", "published": "2019-06-12 15:49:31", "link": "http://arxiv.org/abs/1906.05218v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthetic QA Corpora Generation with Roundtrip Consistency", "abstract": "We introduce a novel method of generating synthetic question answering\ncorpora by combining models of question generation and answer extraction, and\nby filtering the results to ensure roundtrip consistency. By pretraining on the\nresulting corpora we obtain significant improvements on SQuAD2 and NQ,\nestablishing a new state-of-the-art on the latter. Our synthetic data\ngeneration models, for both question generation and answer extraction, can be\nfully reproduced by finetuning a publicly available BERT model on the\nextractive subsets of SQuAD2 and NQ. We also describe a more powerful variant\nthat does full sequence-to-sequence pretraining for question generation,\nobtaining exact match and F1 at less than 0.1% and 0.4% from human performance\non SQuAD2.", "published": "2019-06-12 22:50:31", "link": "http://arxiv.org/abs/1906.05416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does BLEU Score Work for Code Migration?", "abstract": "Statistical machine translation (SMT) is a fast-growing sub-field of\ncomputational linguistics. Until now, the most popular automatic metric to\nmeasure the quality of SMT is BiLingual Evaluation Understudy (BLEU) score.\nLately, SMT along with the BLEU metric has been applied to a Software\nEngineering task named code migration. (In)Validating the use of BLEU score\ncould advance the research and development of SMT-based code migration tools.\nUnfortunately, there is no study to approve or disapprove the use of BLEU score\nfor source code. In this paper, we conducted an empirical study on BLEU score\nto (in)validate its suitability for the code migration task due to its\ninability to reflect the semantics of source code. In our work, we use human\njudgment as the ground truth to measure the semantic correctness of the\nmigrated code. Our empirical study demonstrates that BLEU does not reflect\ntranslation quality due to its weak correlation with the semantic correctness\nof translated code. We provided counter-examples to show that BLEU is\nineffective in comparing the translation quality between SMT-based models. Due\nto BLEU's ineffectiveness for code migration task, we propose an alternative\nmetric RUBY, which considers lexical, syntactical, and semantic representations\nof source code. We verified that RUBY achieves a higher correlation coefficient\nwith the semantic correctness of migrated code, 0.775 in comparison with 0.583\nof BLEU score. We also confirmed the effectiveness of RUBY in reflecting the\nchanges in translation quality of SMT-based translation models. With its\nadvantages, RUBY can be used to evaluate SMT-based code migration models.", "published": "2019-06-12 02:48:57", "link": "http://arxiv.org/abs/1906.04903v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "CogCompTime: A Tool for Understanding Time in Natural Language Text", "abstract": "Automatic extraction of temporal information in text is an important\ncomponent of natural language understanding. It involves two basic tasks: (1)\nUnderstanding time expressions that are mentioned explicitly in text (e.g.,\nFebruary 27, 1998 or tomorrow), and (2) Understanding temporal information that\nis conveyed implicitly via relations. In this paper, we introduce CogCompTime,\na system that has these two important functionalities. It incorporates the most\nrecent progress, achieves state-of-the-art performance, and is publicly\navailable.1 We believe that this demo will be useful for multiple time-aware\napplications and provide valuable insight for future research in temporal\nunderstanding.", "published": "2019-06-12 04:48:27", "link": "http://arxiv.org/abs/1906.04940v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "A Structured Learning Approach to Temporal Relation Extraction", "abstract": "Identifying temporal relations between events is an essential step towards\nnatural language understanding. However, the temporal relation between two\nevents in a story depends on, and is often dictated by, relations among other\nevents. Consequently, effectively identifying temporal relations between events\nis a challenging problem even for human annotators. This paper suggests that it\nis important to take these dependencies into account while learning to identify\nthese relations and proposes a structured learning approach to address this\nchallenge. As a byproduct, this provides a new perspective on handling missing\nrelations, a known issue that hurts existing methods. As we show, the proposed\napproach results in significant improvements on the two commonly used data sets\nfor this problem.", "published": "2019-06-12 05:07:42", "link": "http://arxiv.org/abs/1906.04943v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BiSET: Bi-directional Selective Encoding with Template for Abstractive\n  Summarization", "abstract": "The success of neural summarization models stems from the meticulous\nencodings of source articles. To overcome the impediments of limited and\nsometimes noisy training data, one promising direction is to make better use of\nthe available training data by applying filters during summarization. In this\npaper, we propose a novel Bi-directional Selective Encoding with Template\n(BiSET) model, which leverages template discovered from training data to softly\nselect key information from each source article to guide its summarization\nprocess. Extensive experiments on a standard summarization dataset were\nconducted and the results show that the template-equipped BiSET model manages\nto improve the summarization performance significantly with a new state of the\nart.", "published": "2019-06-12 09:03:26", "link": "http://arxiv.org/abs/1906.05012v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unified Semantic Parsing with Weak Supervision", "abstract": "Semantic parsing over multiple knowledge bases enables a parser to exploit\nstructural similarities of programs across the multiple domains. However, the\nfundamental challenge lies in obtaining high-quality annotations of (utterance,\nprogram) pairs across various domains needed for training such models. To\novercome this, we propose a novel framework to build a unified multi-domain\nenabled semantic parser trained only with weak supervision (denotations).\nWeakly supervised training is particularly arduous as the program search space\ngrows exponentially in a multi-domain setting. To solve this, we incorporate a\nmulti-policy distillation mechanism in which we first train domain-specific\nsemantic parsers (teachers) using weak supervision in the absence of the ground\ntruth programs, followed by training a single unified parser (student) from the\ndomain specific policies obtained from these teachers. The resultant semantic\nparser is not only compact but also generalizes better, and generates more\naccurate programs. It further does not require the user to provide a domain\nlabel while querying. On the standard Overnight dataset (containing multiple\ndomains), we demonstrate that the proposed model improves performance by 20% in\nterms of denotation accuracy in comparison to baseline techniques.", "published": "2019-06-12 11:27:38", "link": "http://arxiv.org/abs/1906.05062v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vispi: Automatic Visual Perception and Interpretation of Chest X-rays", "abstract": "Medical imaging contains the essential information for rendering diagnostic\nand treatment decisions. Inspecting (visual perception) and interpreting image\nto generate a report are tedious clinical routines for a radiologist where\nautomation is expected to greatly reduce the workload. Despite rapid\ndevelopment of natural image captioning, computer-aided medical image visual\nperception and interpretation remain a challenging task, largely due to the\nlack of high-quality annotated image-report pairs and tailor-made generative\nmodels for sufficient extraction and exploitation of localized semantic\nfeatures, particularly those associated with abnormalities. To tackle these\nchallenges, we present Vispi, an automatic medical image interpretation system,\nwhich first annotates an image via classifying and localizing common thoracic\ndiseases with visual support and then followed by report generation from an\nattentive LSTM model. Analyzing an open IU X-ray dataset, we demonstrate a\nsuperior performance of Vispi in disease classification, localization and\nreport generation using automatic performance evaluation metrics ROUGE and\nCIDEr.", "published": "2019-06-12 15:01:31", "link": "http://arxiv.org/abs/1906.05190v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop\n  Reading Comprehension", "abstract": "Multi-hop reading comprehension requires the model to explore and connect\nrelevant information from multiple sentences/documents in order to answer the\nquestion about the context. To achieve this, we propose an interpretable\n3-module system called Explore-Propose-Assemble reader (EPAr). First, the\nDocument Explorer iteratively selects relevant documents and represents\ndivergent reasoning chains in a tree structure so as to allow assimilating\ninformation from all chains. The Answer Proposer then proposes an answer from\nevery root-to-leaf path in the reasoning tree. Finally, the Evidence Assembler\nextracts a key sentence containing the proposed answer from every path and\ncombines them to predict the final answer. Intuitively, EPAr approximates the\ncoarse-to-fine-grained comprehension behavior of human readers when facing\nmultiple long documents. We jointly optimize our 3 modules by minimizing the\nsum of losses from each stage conditioned on the previous stage's output. On\ntwo multi-hop reading comprehension datasets WikiHop and MedHop, our EPAr model\nachieves significant improvements over the baseline and competitive results\ncompared to the state-of-the-art model. We also present multiple\nreasoning-chain-recovery tests and ablation studies to demonstrate our system's\nability to perform interpretable and accurate reasoning.", "published": "2019-06-12 15:26:59", "link": "http://arxiv.org/abs/1906.05210v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Keeping Notes: Conditional Natural Language Generation with a Scratchpad\n  Mechanism", "abstract": "We introduce the Scratchpad Mechanism, a novel addition to the\nsequence-to-sequence (seq2seq) neural network architecture and demonstrate its\neffectiveness in improving the overall fluency of seq2seq models for natural\nlanguage generation tasks. By enabling the decoder at each time step to write\nto all of the encoder output layers, Scratchpad can employ the encoder as a\n\"scratchpad\" memory to keep track of what has been generated so far and thereby\nguide future generation. We evaluate Scratchpad in the context of three\nwell-studied natural language generation tasks --- Machine Translation,\nQuestion Generation, and Text Summarization --- and obtain state-of-the-art or\ncomparable performance on standard datasets for each task. Qualitative\nassessments in the form of human judgements (question generation), attention\nvisualization (MT), and sample output (summarization) provide further evidence\nof the ability of Scratchpad to generate fluent and expressive output.", "published": "2019-06-12 17:58:27", "link": "http://arxiv.org/abs/1906.05275v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COMET: Commonsense Transformers for Automatic Knowledge Graph\n  Construction", "abstract": "We present the first comprehensive study on automatic knowledge base\nconstruction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et\nal., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional\nKBs that store knowledge with canonical templates, commonsense KBs only store\nloosely structured open-text descriptions of knowledge. We posit that an\nimportant step toward automatic commonsense completion is the development of\ngenerative models of commonsense knowledge, and propose COMmonsEnse\nTransformers (COMET) that learn to generate rich and diverse commonsense\ndescriptions in natural language. Despite the challenges of commonsense\nmodeling, our investigation reveals promising results when implicit knowledge\nfrom deep pre-trained language models is transferred to generate explicit\nknowledge in commonsense knowledge graphs. Empirical results demonstrate that\nCOMET is able to generate novel knowledge that humans rate as high quality,\nwith up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which\napproaches human performance for these resources. Our findings suggest that\nusing generative commonsense models for automatic commonsense KB completion\ncould soon be a plausible alternative to extractive methods.", "published": "2019-06-12 18:11:20", "link": "http://arxiv.org/abs/1906.05317v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Arabic Question Answering", "abstract": "This paper tackles the problem of open domain factual Arabic question\nanswering (QA) using Wikipedia as our knowledge source. This constrains the\nanswer of any question to be a span of text in Wikipedia. Open domain QA for\nArabic entails three challenges: annotated QA datasets in Arabic, large scale\nefficient information retrieval and machine reading comprehension. To deal with\nthe lack of Arabic QA datasets we present the Arabic Reading Comprehension\nDataset (ARCD) composed of 1,395 questions posed by crowdworkers on Wikipedia\narticles, and a machine translation of the Stanford Question Answering Dataset\n(Arabic-SQuAD). Our system for open domain question answering in Arabic (SOQAL)\nis based on two components: (1) a document retriever using a hierarchical\nTF-IDF approach and (2) a neural reading comprehension model using the\npre-trained bi-directional transformer BERT. Our experiments on ARCD indicate\nthe effectiveness of our approach with our BERT-based reader achieving a 61.3\nF1 score, and our open domain system SOQAL achieving a 27.6 F1 score.", "published": "2019-06-12 21:49:06", "link": "http://arxiv.org/abs/1906.05394v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analyzing the Limitations of Cross-lingual Word Embedding Mappings", "abstract": "Recent research in cross-lingual word embeddings has almost exclusively\nfocused on offline methods, which independently train word embeddings in\ndifferent languages and map them to a shared space through linear\ntransformations. While several authors have questioned the underlying\nisomorphism assumption, which states that word embeddings in different\nlanguages have approximately the same structure, it is not clear whether this\nis an inherent limitation of mapping approaches or a more general issue when\nlearning cross-lingual embeddings. So as to answer this question, we experiment\nwith parallel corpora, which allows us to compare offline mapping to an\nextension of skip-gram that jointly learns both embedding spaces. We observe\nthat, under these ideal conditions, joint learning yields to more isomorphic\nembeddings, is less sensitive to hubness, and obtains stronger results in\nbilingual lexicon induction. We thus conclude that current mapping methods do\nhave strong limitations, calling for further research to jointly learn\ncross-lingual embeddings with a weaker cross-lingual signal.", "published": "2019-06-12 22:19:26", "link": "http://arxiv.org/abs/1906.05407v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Action-Sensitive Phonological Dependencies", "abstract": "This paper defines a subregular class of functions called the tier-based\nsynchronized strictly local (TSSL) functions. These functions are similar to\nthe the tier-based input-output strictly local (TIOSL) functions, except that\nthe locality condition is enforced not on the input and output streams, but on\nthe computation history of the minimal subsequential finite-state transducer.\nWe show that TSSL functions naturally describe rhythmic syncope while TIOSL\nfunctions cannot, and we argue that TSSL functions provide a more restricted\ncharacterization of rhythmic syncope than existing treatments within Optimality\nTheory.", "published": "2019-06-12 00:03:33", "link": "http://arxiv.org/abs/1906.06464v1", "categories": ["cs.CL", "cs.FL"], "primary_category": "cs.CL"}
{"title": "SPoC: Search-based Pseudocode to Code", "abstract": "We consider the task of mapping pseudocode to long programs that are\nfunctionally correct. Given test cases as a mechanism to validate programs, we\nsearch over the space of possible translations of the pseudocode to find a\nprogram that passes the validation. However, without proper credit assignment\nto localize the sources of program failures, it is difficult to guide search\ntoward more promising programs. We propose to perform credit assignment based\non signals from compilation errors, which constitute 88.7% of program failures.\nConcretely, we treat the translation of each pseudocode line as a discrete\nportion of the program, and whenever a synthesized program fails to compile, an\nerror localization method tries to identify the portion of the program\nresponsible for the failure. We then focus search over alternative translations\nof the pseudocode for those portions. For evaluation, we collected the SPoC\ndataset (Search-based Pseudocode to Code) containing 18,356 programs with\nhuman-authored pseudocode and test cases. Under a budget of 100 program\ncompilations, performing search improves the synthesis success rate over using\nthe top-one translation of the pseudocode from 25.6% to 44.7%.", "published": "2019-06-12 03:13:18", "link": "http://arxiv.org/abs/1906.04908v1", "categories": ["cs.LG", "cs.CL", "cs.PL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Partial Or Complete, That's The Question", "abstract": "For many structured learning tasks, the data annotation process is complex\nand costly. Existing annotation schemes usually aim at acquiring completely\nannotated structures, under the common perception that partial structures are\nof low quality and could hurt the learning process. This paper questions this\ncommon perception, motivated by the fact that structures consist of\ninterdependent sets of variables. Thus, given a fixed budget, partly annotating\neach structure may provide the same level of supervision, while allowing for\nmore structures to be annotated. We provide an information theoretic\nformulation for this perspective and use it, in the context of three diverse\nstructured learning tasks, to show that learning from partial structures can\nsometimes outperform learning from complete ones. Our findings may provide\nimportant insights into structured data annotation schemes and could support\nprogress in learning protocols for structured tasks.", "published": "2019-06-12 04:35:11", "link": "http://arxiv.org/abs/1906.04937v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Joint Reasoning for Temporal and Causal Relations", "abstract": "Understanding temporal and causal relations between events is a fundamental\nnatural language understanding task. Because a cause must be before its effect\nin time, temporal and causal relations are closely related and one relation\neven dictates the other one in many cases. However, limited attention has been\npaid to studying these two relations jointly. This paper presents a joint\ninference framework for them using constrained conditional models (CCMs).\nSpecifically, we formulate the joint problem as an integer linear programming\n(ILP) problem, enforcing constraints inherently in the nature of time and\ncausality. We show that the joint inference framework results in statistically\nsignificant improvement in the extraction of both temporal and causal relations\nfrom text.", "published": "2019-06-12 04:58:51", "link": "http://arxiv.org/abs/1906.04941v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unsupervised Question Answering by Cloze Translation", "abstract": "Obtaining training data for Question Answering (QA) is time-consuming and\nresource-intensive, and existing QA datasets are only available for limited\ndomains and languages. In this work, we explore to what extent high quality\ntraining data is actually required for Extractive QA, and investigate the\npossibility of unsupervised Extractive QA. We approach this problem by first\nlearning to generate context, question and answer triples in an unsupervised\nmanner, which we then use to synthesize Extractive QA training data\nautomatically. To generate such triples, we first sample random context\nparagraphs from a large corpus of documents and then random noun phrases or\nnamed entity mentions from these paragraphs as answers. Next we convert answers\nin context to \"fill-in-the-blank\" cloze questions and finally translate them\ninto natural questions. We propose and compare various unsupervised ways to\nperform cloze-to-natural question translation, including training an\nunsupervised NMT model using non-aligned corpora of natural questions and cloze\nquestions as well as a rule-based approach. We find that modern QA models can\nlearn to answer human questions surprisingly well using only synthetic training\ndata. We demonstrate that, without using the SQuAD training data at all, our\napproach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named\nentity mention), outperforming early supervised models.", "published": "2019-06-12 07:30:32", "link": "http://arxiv.org/abs/1906.04980v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Continual and Multi-Task Architecture Search", "abstract": "Architecture search is the process of automatically learning the neural model\nor cell structure that best suits the given task. Recently, this approach has\nshown promising performance improvements (on language modeling and image\nclassification) with reasonable training speed, using a weight sharing strategy\ncalled Efficient Neural Architecture Search (ENAS). In our work, we first\nintroduce a novel continual architecture search (CAS) approach, so as to\ncontinually evolve the model parameters during the sequential training of\nseveral tasks, without losing performance on previously learned tasks (via\nblock-sparsity and orthogonality constraints), thus enabling life-long\nlearning. Next, we explore a multi-task architecture search (MAS) approach over\nENAS for finding a unified, single cell structure that performs well across\nmultiple tasks (via joint controller rewards), and hence allows more\ngeneralizable transfer of the cell structure knowledge to an unseen new task.\nWe empirically show the effectiveness of our sequential continual learning and\nparallel multi-task learning based architecture search approaches on diverse\nsentence-pair classification tasks (GLUE) and multimodal-generation based video\ncaptioning tasks. Further, we present several ablations and analyses on the\nlearned cell structures.", "published": "2019-06-12 16:01:35", "link": "http://arxiv.org/abs/1906.05226v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "E3: Entailment-driven Extracting and Editing for Conversational Machine\n  Reading", "abstract": "Conversational machine reading systems help users answer high-level questions\n(e.g. determine if they qualify for particular government benefits) when they\ndo not know the exact rules by which the determination is made(e.g. whether\nthey need certain income levels or veteran status). The key challenge is that\nthese rules are only provided in the form of a procedural text (e.g. guidelines\nfrom government website) which the system must read to figure out what to ask\nthe user. We present a new conversational machine reading model that jointly\nextracts a set of decision rules from the procedural text while reasoning about\nwhich are entailed by the conversational history and which still need to be\nedited to create questions for the user. On the recently introduced ShARC\nconversational machine reading dataset, our Entailment-driven Extract and Edit\nnetwork (E3) achieves a new state-of-the-art, outperforming existing systems as\nwell as a new BERT-based baseline. In addition, by explicitly highlighting\nwhich information still needs to be gathered, E3 provides a more explainable\nalternative to prior work. We release source code for our models and\nexperiments at https://github.com/vzhong/e3.", "published": "2019-06-12 20:49:48", "link": "http://arxiv.org/abs/1906.05373v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Compositional generalization through meta sequence-to-sequence learning", "abstract": "People can learn a new concept and use it compositionally, understanding how\nto \"blicket twice\" after learning how to \"blicket.\" In contrast, powerful\nsequence-to-sequence (seq2seq) neural networks fail such tests of\ncompositionality, especially when composing new concepts together with existing\nconcepts. In this paper, I show how memory-augmented neural networks can be\ntrained to generalize compositionally through meta seq2seq learning. In this\napproach, models train on a series of seq2seq problems to acquire the\ncompositional skills needed to solve new seq2seq problems. Meta se2seq learning\nsolves several of the SCAN tests for compositional learning and can learn to\napply implicit rules to variables.", "published": "2019-06-12 21:25:09", "link": "http://arxiv.org/abs/1906.05381v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Representation Learning for Words and Entities", "abstract": "This thesis presents new methods for unsupervised learning of distributed\nrepresentations of words and entities from text and knowledge bases. The first\nalgorithm presented in the thesis is a multi-view algorithm for learning\nrepresentations of words called Multiview Latent Semantic Analysis (MVLSA). By\nincorporating up to 46 different types of co-occurrence statistics for the same\nvocabulary of english words, I show that MVLSA outperforms other\nstate-of-the-art word embedding models. Next, I focus on learning entity\nrepresentations for search and recommendation and present the second method of\nthis thesis, Neural Variational Set Expansion (NVSE). NVSE is also an\nunsupervised learning method, but it is based on the Variational Autoencoder\nframework. Evaluations with human annotators show that NVSE can facilitate\nbetter search and recommendation of information gathered from noisy, automatic\nannotation of unstructured natural language corpora. Finally, I move from\nunstructured data and focus on structured knowledge graphs. I present novel\napproaches for learning embeddings of vertices and edges in a knowledge graph\nthat obey logical constraints.", "published": "2019-06-12 17:29:22", "link": "http://arxiv.org/abs/1906.05651v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Multiscale Visualization of Attention in the Transformer Model", "abstract": "The Transformer is a sequence model that forgoes traditional recurrent\narchitectures in favor of a fully attention-based approach. Besides improving\nperformance, an advantage of using attention is that it can also help to\ninterpret a model by showing how the model assigns weight to different input\nelements. However, the multi-layer, multi-head attention mechanism in the\nTransformer model can be difficult to decipher. To make the model more\naccessible, we introduce an open-source tool that visualizes attention at\nmultiple scales, each of which provides a unique perspective on the attention\nmechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three\nexample use cases: detecting model bias, locating relevant attention heads, and\nlinking neurons to model behavior.", "published": "2019-06-12 15:45:26", "link": "http://arxiv.org/abs/1906.05714v1", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Toward Interpretable Music Tagging with Self-Attention", "abstract": "Self-attention is an attention mechanism that learns a representation by\nrelating different positions in the sequence. The transformer, which is a\nsequence model solely based on self-attention, and its variants achieved\nstate-of-the-art results in many natural language processing tasks. Since music\ncomposes its semantics based on the relations between components in sparse\npositions, adopting the self-attention mechanism to solve music information\nretrieval (MIR) problems can be beneficial. Hence, we propose a self-attention\nbased deep sequence model for music tagging. The proposed architecture consists\nof shallow convolutional layers followed by stacked Transformer encoders.\nCompared to conventional approaches using fully convolutional or recurrent\nneural networks, our model is more interpretable while reporting competitive\nresults. We validate the performance of our model with the MagnaTagATune and\nthe Million Song Dataset. In addition, we demonstrate the interpretability of\nthe proposed architecture with a heat map visualization.", "published": "2019-06-12 07:08:01", "link": "http://arxiv.org/abs/1906.04972v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "(A) Data in the Life: Authorship Attribution of Lennon-McCartney Songs", "abstract": "The songwriting duo of John Lennon and Paul McCartney, the two founding\nmembers of the Beatles, composed some of the most popular and memorable songs\nof the last century. Despite having authored songs under the joint credit\nagreement of Lennon-McCartney, it is well-documented that most of their songs\nor portions of songs were primarily written by exactly one of the two.\nFurthermore, the authorship of some Lennon-McCartney songs is in dispute, with\nthe recollections of authorship based on previous interviews with Lennon and\nMcCartney in conflict. For Lennon-McCartney songs of known and unknown\nauthorship written and recorded over the period 1962-66, we extracted musical\nfeatures from each song or song portion. These features consist of the\noccurrence of melodic notes, chords, melodic note pairs, chord change pairs,\nand four-note melody contours. We developed a prediction model based on\nvariable screening followed by logistic regression with elastic net\nregularization. Out-of-sample classification accuracy for songs with known\nauthorship was 76\\%, with a $c$-statistic from an ROC analysis of 83.7\\%. We\napplied our model to the prediction of songs and song portions with unknown or\ndisputed authorship.", "published": "2019-06-12 23:52:05", "link": "http://arxiv.org/abs/1906.05427v1", "categories": ["cs.SD", "eess.AS", "62P99, 62F15"], "primary_category": "cs.SD"}
