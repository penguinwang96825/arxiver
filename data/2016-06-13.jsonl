{"title": "Learning to Generate Compositional Color Descriptions", "abstract": "The production of color language is essential for grounded language\ngeneration. Color descriptions have many challenging properties: they can be\nvague, compositionally complex, and denotationally rich. We present an\neffective approach to generating color descriptions using recurrent neural\nnetworks and a Fourier-transformed color representation. Our model outperforms\nprevious work on a conditional language modeling task over a large corpus of\nnaturalistic color descriptions. In addition, probing the model's output\nreveals that it can accurately produce not only basic color terms but also\ndescriptors with non-convex denotations (\"greenish\"), bare modifiers (\"bright\",\n\"dull\"), and compositional phrases (\"faded teal\") not seen in training.", "published": "2016-06-13 06:17:32", "link": "http://arxiv.org/abs/1606.03821v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Resource Translation with Multi-Lingual Neural Machine Translation", "abstract": "In this paper, we propose a novel finetuning algorithm for the recently\nintroduced multi-way, mulitlingual neural machine translate that enables\nzero-resource machine translation. When used together with novel many-to-one\ntranslation strategies, we empirically show that this finetuning algorithm\nallows the multi-way, multilingual model to translate a zero-resource language\npair (1) as well as a single-pair neural translation model trained with up to\n1M direct parallel sentences of the same language pair and (2) better than\npivot-based translation strategy, while keeping only one additional copy of\nattention-related parameters.", "published": "2016-06-13 22:40:33", "link": "http://arxiv.org/abs/1606.04164v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection", "abstract": "We describe MITRE's submission to the SemEval-2016 Task 6, Detecting Stance\nin Tweets. This effort achieved the top score in Task A on supervised stance\ndetection, producing an average F1 score of 67.8 when assessing whether a tweet\nauthor was in favor or against a topic. We employed a recurrent neural network\ninitialized with features learned via distant supervision on two large\nunlabeled datasets. We trained embeddings of words and phrases with the\nword2vec skip-gram method, then used those features to learn sentence\nrepresentations via a hashtag prediction auxiliary task. These sentence vectors\nwere then fine-tuned for stance detection on several hundred labeled examples.\nThe result was a high performing system that used transfer learning to maximize\nthe value of the available training data.", "published": "2016-06-13 00:12:49", "link": "http://arxiv.org/abs/1606.03784v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Rationalizing Neural Predictions", "abstract": "Prediction without justification has limited applicability. As a remedy, we\nlearn to extract pieces of input text as justifications -- rationales -- that\nare tailored to be short and coherent, yet sufficient for making the same\nprediction. Our approach combines two modular components, generator and\nencoder, which are trained to operate well together. The generator specifies a\ndistribution over text fragments as candidate rationales and these are passed\nthrough the encoder for prediction. Rationales are never given during training.\nInstead, the model is regularized by desiderata for rationales. We evaluate the\napproach on multi-aspect sentiment analysis against manually annotated test\ncases. Our approach outperforms attention-based baseline by a significant\nmargin. We also successfully illustrate the method on the question retrieval\ntask.", "published": "2016-06-13 22:10:23", "link": "http://arxiv.org/abs/1606.04155v2", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Neural Associative Memory for Dual-Sequence Modeling", "abstract": "Many important NLP problems can be posed as dual-sequence or\nsequence-to-sequence modeling tasks. Recent advances in building end-to-end\nneural architectures have been highly successful in solving such tasks. In this\nwork we propose a new architecture for dual-sequence modeling that is based on\nassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)\nwhich augments generic recurrent neural networks (RNN). This architecture is\nextended to the Dual AM-RNN which operates on two AMs at once. Our models\nachieve very competitive results on textual entailment. A qualitative analysis\ndemonstrates that long range dependencies between source and target-sequence\ncan be bridged effectively using Dual AM-RNNs. However, an initial experiment\non auto-encoding reveals that these benefits are not exploited by the system\nwhen learning to solve sequence-to-sequence tasks which indicates that\nadditional supervision or regularization is needed.", "published": "2016-06-13 09:08:04", "link": "http://arxiv.org/abs/1606.03864v2", "categories": ["cs.NE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Dialog state tracking, a machine reading approach using Memory Network", "abstract": "In an end-to-end dialog system, the aim of dialog state tracking is to\naccurately estimate a compact representation of the current dialog status from\na sequence of noisy observations produced by the speech recognition and the\nnatural language understanding modules. This paper introduces a novel method of\ndialog state tracking based on the general paradigm of machine reading and\nproposes to solve it using an End-to-End Memory Network, MemN2N, a\nmemory-enhanced neural network architecture. We evaluate the proposed approach\non the second Dialog State Tracking Challenge (DSTC-2) dataset. The corpus has\nbeen converted for the occasion in order to frame the hidden state variable\ninference as a question-answering task based on a sequence of utterances\nextracted from a dialog. We show that the proposed tracker gives encouraging\nresults. Then, we propose to extend the DSTC-2 dataset with specific reasoning\ncapabilities requirement like counting, list maintenance, yes-no question\nanswering and indefinite knowledge management. Finally, we present encouraging\nresults using our proposed MemN2N based tracking model.", "published": "2016-06-13 18:09:40", "link": "http://arxiv.org/abs/1606.04052v5", "categories": ["cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Graph-Community Detection for Cross-Document Topic Segment Relationship\n  Identification", "abstract": "In this paper we propose a graph-community detection approach to identify\ncross-document relationships at the topic segment level. Given a set of related\ndocuments, we automatically find these relationships by clustering segments\nwith similar content (topics). In this context, we study how different\nweighting mechanisms influence the discovery of word communities that relate to\nthe different topics found in the documents. Finally, we test different mapping\nfunctions to assign topic segments to word communities, determining which topic\nsegments are considered equivalent.\n  By performing this task it is possible to enable efficient multi-document\nbrowsing, since when a user finds relevant content in one document we can\nprovide access to similar topics in other documents. We deploy our approach in\ntwo different scenarios. One is an educational scenario where equivalence\nrelationships between learning materials need to be found. The other consists\nof a series of dialogs in a social context where students discuss commonplace\ntopics. Results show that our proposed approach better discovered equivalence\nrelationships in learning material documents and obtained close results in the\nsocial speech domain, where the best performing approach was a clustering\ntechnique.", "published": "2016-06-13 19:41:56", "link": "http://arxiv.org/abs/1606.04081v1", "categories": ["cs.CL", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
