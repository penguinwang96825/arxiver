{"title": "Unsupervised Ensemble Ranking of Terms in Electronic Health Record Notes\n  Based on Their Importance to Patients", "abstract": "Background: Electronic health record (EHR) notes contain abundant medical\njargon that can be difficult for patients to comprehend. One way to help\npatients is to reduce information overload and help them focus on medical terms\nthat matter most to them.\n  Objective: The aim of this work was to develop FIT (Finding Important Terms\nfor patients), an unsupervised natural language processing (NLP) system that\nranks medical terms in EHR notes based on their importance to patients.\n  Methods: We built FIT on a new unsupervised ensemble ranking model derived\nfrom the biased random walk algorithm to combine heterogeneous information\nresources for ranking candidate terms from each EHR note. Specifically, FIT\nintegrates four single views for term importance: patient use of medical\nconcepts, document-level term salience, word-occurrence based term relatedness,\nand topic coherence. It also incorporates partial information of term\nimportance as conveyed by terms' unfamiliarity levels and semantic types. We\nevaluated FIT on 90 expert-annotated EHR notes and compared it with three\nbenchmark unsupervised ensemble ranking methods.\n  Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR\nnotes to identify important terms. When including term identification, the\nperformance of FIT for identifying important terms from EHR notes was 0.813\nAUC-ROC. It outperformed the three ensemble rankers for most metrics. Its\nperformance is relatively insensitive to its parameter.\n  Conclusions: FIT can automatically identify EHR terms important to patients\nand may help develop personalized interventions to improve quality of care. By\nusing unsupervised learning as well as a robust and flexible framework for\ninformation fusion, FIT can be readily applied to other domains and\napplications.", "published": "2017-03-01 22:37:02", "link": "http://arxiv.org/abs/1703.00538v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Frequency patterns of semantic change: Corpus-based evidence of a\n  near-critical dynamics in language change", "abstract": "It is generally believed that, when a linguistic item acquires a new meaning,\nits overall frequency of use in the language rises with time with an S-shaped\ngrowth curve. Yet, this claim has only been supported by a limited number of\ncase studies. In this paper, we provide the first corpus-based quantitative\nconfirmation of the genericity of the S-curve in language change. Moreover, we\nuncover another generic pattern, a latency phase of variable duration preceding\nthe S-growth, during which the frequency of use of the semantically expanding\nword remains low and more or less constant. We also propose a usage-based model\nof language change supported by cognitive considerations, which predicts that\nboth phases, the latency and the fast S-growth, take place. The driving\nmechanism is a stochastic dynamics, a random walk in the space of frequency of\nuse. The underlying deterministic dynamics highlights the role of a control\nparameter, the strength of the cognitive impetus governing the onset of change,\nwhich tunes the system at the vicinity of a saddle-node bifurcation. In the\nneighborhood of the critical point, the latency phase corresponds to the\ndiffusion time over the critical region, and the S-growth to the fast\nconvergence that follows. The duration of the two phases is computed as\nspecific first passage times of the random walk process, leading to\ndistributions that fit well the ones extracted from our dataset. We argue that\nour results are not specific to the studied corpus, but apply to semantic\nchange in general.", "published": "2017-03-01 10:02:04", "link": "http://arxiv.org/abs/1703.00203v3", "categories": ["physics.soc-ph", "cs.CL"], "primary_category": "physics.soc-ph"}
{"title": "Tracing Linguistic Relations in Winning and Losing Sides of Explicit\n  Opposing Groups", "abstract": "Linguistic relations in oral conversations present how opinions are\nconstructed and developed in a restricted time. The relations bond ideas,\narguments, thoughts, and feelings, re-shape them during a speech, and finally\nbuild knowledge out of all information provided in the conversation. Speakers\nshare a common interest to discuss. It is expected that each speaker's reply\nincludes duplicated forms of words from previous speakers. However, linguistic\nadaptation is observed and evolves in a more complex path than just\ntransferring slightly modified versions of common concepts. A conversation\naiming a benefit at the end shows an emergent cooperation inducing the\nadaptation. Not only cooperation, but also competition drives the adaptation or\nan opposite scenario and one can capture the dynamic process by tracking how\nthe concepts are linguistically linked. To uncover salient complex dynamic\nevents in verbal communications, we attempt to discover self-organized\nlinguistic relations hidden in a conversation with explicitly stated winners\nand losers. We examine open access data of the United States Supreme Court. Our\nunderstanding is crucial in big data research to guide how transition states in\nopinion mining and decision-making should be modeled and how this required\nknowledge to guide the model should be pinpointed, by filtering large amount of\ndata.", "published": "2017-03-01 14:40:22", "link": "http://arxiv.org/abs/1703.00317v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence\n  Labelling", "abstract": "Most existing sequence labelling models rely on a fixed decomposition of a\ntarget sequence into a sequence of basic units. These methods suffer from two\nmajor drawbacks: 1) the set of basic units is fixed, such as the set of words,\ncharacters or phonemes in speech recognition, and 2) the decomposition of\ntarget sequences is fixed. These drawbacks usually result in sub-optimal\nperformance of modeling sequences. In this pa- per, we extend the popular CTC\nloss criterion to alleviate these limitations, and propose a new loss function\ncalled Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically\nlearns the best set of basic units (grams), as well as the most suitable\ndecomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to\noutput variable number of characters at each time step, which enables the model\nto capture longer term dependency and improves the computational efficiency. We\ndemonstrate that the proposed Gram-CTC improves CTC in terms of both\nperformance and efficiency on the large vocabulary speech recognition task at\nmultiple scales of data, and that with Gram-CTC we can outperform the\nstate-of-the-art on a standard speech benchmark.", "published": "2017-03-01 00:59:17", "link": "http://arxiv.org/abs/1703.00096v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Learning Conversational Systems that Interleave Task and Non-Task\n  Content", "abstract": "Task-oriented dialog systems have been applied in various tasks, such as\nautomated personal assistants, customer service providers and tutors. These\nsystems work well when users have clear and explicit intentions that are\nwell-aligned to the systems' capabilities. However, they fail if users\nintentions are not explicit. To address this shortcoming, we propose a\nframework to interleave non-task content (i.e. everyday social conversation)\ninto task conversations. When the task content fails, the system can still keep\nthe user engaged with the non-task content. We trained a policy using\nreinforcement learning algorithms to promote long-turn conversation coherence\nand consistency, so that the system can have smooth transitions between task\nand non-task content. To test the effectiveness of the proposed framework, we\ndeveloped a movie promotion dialog system. Experiments with human users\nindicate that a system that interleaves social and task content achieves a\nbetter task success rate and is also rated as more engaging compared to a pure\ntask-oriented system.", "published": "2017-03-01 01:27:32", "link": "http://arxiv.org/abs/1703.00099v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
