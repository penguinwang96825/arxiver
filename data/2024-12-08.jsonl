{"title": "Multi-Factor Function-on-Function Regression of Bond Yields on WTI Commodity Futures Term Structure Dynamics", "abstract": "In the analysis of commodity futures, it is commonly assumed that futures\nprices are driven by two latent factors: short-term fluctuations and long-term\nequilibrium price levels. In this study, we extend this framework by\nintroducing a novel state-space functional regression model that incorporates\nyield curve dynamics. Our model offers a distinct advantage in capturing the\ninterdependencies between commodity futures and the yield curve. Through a\ncomprehensive empirical analysis of WTI crude oil futures, using US Treasury\nyields as a functional predictor, we demonstrate the superior accuracy of the\nfunctional regression model compared to the Schwartz-Smith two-factor model,\nparticularly in estimating the short-end of the futures curve. Additionally, we\nconduct a stress testing analysis to examine the impact of both temporary and\npermanent shocks to US Treasury yields on futures price estimation.", "published": "2024-12-08 10:53:03", "link": "http://arxiv.org/abs/2412.05889v1", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "Are Clinical T5 Models Better for Clinical Text?", "abstract": "Large language models with a transformer-based encoder/decoder architecture,\nsuch as T5, have become standard platforms for supervised tasks. To bring these\ntechnologies to the clinical domain, recent work has trained new or adapted\nexisting models to clinical data. However, the evaluation of these clinical T5\nmodels and comparison to other models has been limited. Are the clinical T5\nmodels better choices than FLAN-tuned generic T5 models? Do they generalize\nbetter to new clinical domains that differ from the training sets? We\ncomprehensively evaluate these models across several clinical tasks and\ndomains. We find that clinical T5 models provide marginal improvements over\nexisting models, and perform worse when evaluated on different domains. Our\nresults inform future choices in developing clinical LLMs.", "published": "2024-12-08 07:52:17", "link": "http://arxiv.org/abs/2412.05845v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cooperative SQL Generation for Segmented Databases By Using\n  Multi-functional LLM Agents", "abstract": "Text-to-SQL task aims to automatically yield SQL queries according to user\ntext questions. To address this problem, we propose a Cooperative SQL\nGeneration framework based on Multi-functional Agents (CSMA) through\ninformation interaction among large language model (LLM) based agents who own\npart of the database schema seperately. Inspired by the collaboration in human\nteamwork, CSMA consists of three stages: 1) Question-related schema collection,\n2) Question-corresponding SQL query generation, and 3) SQL query correctness\ncheck. In the first stage, agents analyze their respective schema and\ncommunicate with each other to collect the schema information relevant to the\nquestion. In the second stage, agents try to generate the corresponding SQL\nquery for the question using the collected information. In the third stage,\nagents check if the SQL query is created correctly according to their known\ninformation. This interaction-based method makes the question-relevant part of\ndatabase schema from each agent to be used for SQL generation and check.\nExperiments on the Spider and Bird benckmark demonstrate that CSMA achieves a\nhigh performance level comparable to the state-of-the-arts, meanwhile holding\nthe private data in these individual agents.", "published": "2024-12-08 08:16:19", "link": "http://arxiv.org/abs/2412.05850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain-Specific Translation with Open-Source Large Language Models:\n  Resource-Oriented Analysis", "abstract": "In this work, we compare the domain-specific translation performance of\nopen-source autoregressive decoder-only large language models (LLMs) with\ntask-oriented machine translation (MT) models. Our experiments focus on the\nmedical domain and cover four language pairs with varied resource availability:\nEnglish-to-French, English-to-Portuguese, English-to-Swahili, and\nSwahili-to-English. Despite recent advancements, LLMs exhibit a clear gap in\nspecialized translation quality compared to multilingual encoder-decoder MT\nmodels such as NLLB-200. In three out of four language directions in our study,\nNLLB-200 3.3B outperforms all LLMs in the size range of 8B parameters in\nmedical translation. While fine-tuning LLMs such as Mistral and Llama improves\ntheir performance at medical translation, these models still fall short\ncompared to fine-tuned NLLB-200 3.3B models. Our findings highlight the ongoing\nneed for specialized MT models to achieve higher-quality domain-specific\ntranslation, especially in medium-resource and low-resource settings. As larger\nLLMs outperform their 8B variants, this also encourages pre-training\ndomain-specific medium-sized LMs to improve quality and efficiency in\nspecialized translation tasks.", "published": "2024-12-08 08:54:13", "link": "http://arxiv.org/abs/2412.05862v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Paraphrase-Aligned Machine Translation", "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities in\nmachine translation. However, their translation quality is sometimes\nquestioned, as the generated outputs may deviate from expressions typically\nused by native speakers. These deviations often arise from differences in\nsentence structure between language systems. To address this issue, we propose\nParaAlign Translator, a method that fine-tunes LLMs to paraphrase sentences,\naligning their structures with those of the target language systems. This\napproach improves the performance of subsequent translations. Experimental\nresults demonstrate that the proposed method enhances the LLaMA-3-8B model's\nperformance in both resource-rich and low-resource scenarios and achieves\nparity with or surpassing the much larger LLaMA-3-70B model.", "published": "2024-12-08 12:17:26", "link": "http://arxiv.org/abs/2412.05916v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Cross-Validation Study of Turkish Sentiment Analysis Datasets and\n  Tools", "abstract": "In recent years, sentiment analysis has gained increasing significance,\nprompting researchers to explore datasets in various languages, including\nTurkish. However, the limited availability of Turkish datasets has led to their\nmultifaceted usage in different studies, yielding diverse outcomes. To overcome\nthis challenge, a rigorous review was conducted of research articles published\nbetween 2012 and 2022. 31 studies were listed, and 23 Turkish datasets obtained\nfrom publicly available sources and email requests used in these studies were\ncollected. We labeled these 31 studies using a taxonomy. We provide a map of\nsentiment analysis datasets according to this taxonomy in Turkish over 10\nyears. Moreover, we run state-of-the-art sentiment analysis tools on these\ndatasets and analyzed performance across popular Turkish sentiment datasets. We\nobserved that the performance of the sentiment analysis tools significantly\ndepends on the characteristics of the target text. Our study fosters a more\nnuanced understanding of sentiment analysis in the Turkish language.", "published": "2024-12-08 14:59:21", "link": "http://arxiv.org/abs/2412.05964v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Infusing Prompts with Syntax and Semantics", "abstract": "Despite impressive success, language models often generate outputs with\nflawed linguistic structure. We analyze the effect of directly infusing various\nkinds of syntactic and semantic information into large language models. To\ndemonstrate the value of our proposals, we focus on the translation of natural\nlanguage queries to SQL, in particular dealing with languages with less\nresources than English, to better investigate how much help we can get from low\ncost syntactic and semantic information. We show that linguistic analysis can\nsignificantly boost language models, to the point that we have surpassed\nprevious best systems.", "published": "2024-12-08 23:49:38", "link": "http://arxiv.org/abs/2412.06107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncovering Uncertainty in Transformer Inference", "abstract": "We explore the Iterative Inference Hypothesis (IIH) within the context of\ntransformer-based language models, aiming to understand how a model's latent\nrepresentations are progressively refined and whether observable differences\nare present between correct and incorrect generations. Our findings provide\nempirical support for the IIH, showing that the nth token embedding in the\nresidual stream follows a trajectory of decreasing loss. Additionally, we\nobserve that the rate at which residual embeddings converge to a stable output\nrepresentation reflects uncertainty in the token generation process. Finally,\nwe introduce a method utilizing cross-entropy to detect this uncertainty and\ndemonstrate its potential to distinguish between correct and incorrect token\ngenerations on a dataset of idioms.", "published": "2024-12-08 00:46:10", "link": "http://arxiv.org/abs/2412.05768v1", "categories": ["cs.CL", "cs.AI", "68T50 (Primary), 68T07 (Secondary)", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Speech Is Not Enough: Interpreting Nonverbal Indicators of Common\n  Knowledge and Engagement", "abstract": "Our goal is to develop an AI Partner that can provide support for group\nproblem solving and social dynamics. In multi-party working group environments,\nmultimodal analytics is crucial for identifying non-verbal interactions of\ngroup members. In conjunction with their verbal participation, this creates an\nholistic understanding of collaboration and engagement that provides necessary\ncontext for the AI Partner. In this demo, we illustrate our present\ncapabilities at detecting and tracking nonverbal behavior in student\ntask-oriented interactions in the classroom, and the implications for tracking\ncommon ground and engagement.", "published": "2024-12-08 03:26:44", "link": "http://arxiv.org/abs/2412.05797v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Entailment Tree Generation Approach for Multimodal Multi-Hop Question\n  Answering with Mixture-of-Experts and Iterative Feedback Mechanism", "abstract": "With the rise of large-scale language models (LLMs), it is currently popular\nand effective to convert multimodal information into text descriptions for\nmultimodal multi-hop question answering. However, we argue that the current\nmethods of multi-modal multi-hop question answering still mainly face two\nchallenges: 1) The retrieved evidence containing a large amount of redundant\ninformation, inevitably leads to a significant drop in performance due to\nirrelevant information misleading the prediction. 2) The reasoning process\nwithout interpretable reasoning steps makes the model difficult to discover the\nlogical errors for handling complex questions. To solve these problems, we\npropose a unified LLMs-based approach but without heavily relying on them due\nto the LLM's potential errors, and innovatively treat multimodal multi-hop\nquestion answering as a joint entailment tree generation and question answering\nproblem. Specifically, we design a multi-task learning framework with a focus\non facilitating common knowledge sharing across interpretability and prediction\ntasks while preventing task-specific errors from interfering with each other\nvia mixture of experts. Afterward, we design an iterative feedback mechanism to\nfurther enhance both tasks by feeding back the results of the joint training to\nthe LLM for regenerating entailment trees, aiming to iteratively refine the\npotential answer. Notably, our method has won the first place in the official\nleaderboard of WebQA (since April 10, 2024), and achieves competitive results\non MultimodalQA.", "published": "2024-12-08 05:47:55", "link": "http://arxiv.org/abs/2412.05821v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Self-Learning Multimodal Approach for Fake News Detection", "abstract": "The rapid growth of social media has resulted in an explosion of online news\ncontent, leading to a significant increase in the spread of misleading or false\ninformation. While machine learning techniques have been widely applied to\ndetect fake news, the scarcity of labeled datasets remains a critical\nchallenge. Misinformation frequently appears as paired text and images, where a\nnews article or headline is accompanied by a related visuals. In this paper, we\nintroduce a self-learning multimodal model for fake news classification. The\nmodel leverages contrastive learning, a robust method for feature extraction\nthat operates without requiring labeled data, and integrates the strengths of\nLarge Language Models (LLMs) to jointly analyze both text and image features.\nLLMs are excel at this task due to their ability to process diverse linguistic\ndata drawn from extensive training corpora. Our experimental results on a\npublic dataset demonstrate that the proposed model outperforms several\nstate-of-the-art classification approaches, achieving over 85% accuracy,\nprecision, recall, and F1-score. These findings highlight the model's\neffectiveness in tackling the challenges of multimodal fake news detection.", "published": "2024-12-08 07:41:44", "link": "http://arxiv.org/abs/2412.05843v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "XKV: Personalized KV Cache Memory Reduction for Long-Context LLM\n  Inference", "abstract": "Recently the generative Large Language Model (LLM) has achieved remarkable\nsuccess in numerous applications. Notably its inference generates output tokens\none-by-one, leading to many redundant computations. The widely-used KV-Cache\nframework makes a compromise between time and space complexities. However,\ncaching data generates the increasingly growing memory demand, that can quickly\nexhaust the limited memory capacity of the modern accelerator like GPUs,\nparticularly in long-context inference tasks. Existing studies reduce memory\nconsumption by evicting some of cached data that have less important impact on\ninference accuracy. But the benefit in practice is far from ideal due to the\nstatic cache allocation across different LLM network layers. This paper\nobserves that the layer-specific cached data have very different impacts on\naccuracy. We quantify this difference, and give experimental and theoretical\nvalidation. We accordingly make a formal analysis and shows that customizing\nthe cache size for each layer in a personalized manner can yield a significant\nmemory reduction, while still providing comparable accuracy. We simulate the\ncache allocation as a combinatorial optimization problem and give a global\noptimal solution. In particular, we devise a mini- and sampling-based inference\nover a lightweight variant of the LLM model, so as to quickly capture the\ndifference and then feed it into the personalized algorithms. Extensive\nexperiments on real-world datasets demonstrate that our proposals can reduce KV\ncache memory consumption by 61.6% on average, improve computational efficiency\nby 2.1x and then increase the throughput by up to 5.5x.", "published": "2024-12-08 11:32:08", "link": "http://arxiv.org/abs/2412.05896v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Does RLHF Scale? Exploring the Impacts From Data, Model, and Method", "abstract": "This study explores the scaling properties of Reinforcement Learning from\nHuman Feedback (RLHF) in Large Language Models (LLMs). Although RLHF is\nconsidered an important step in post-training of LLMs, its scaling potential is\nstill largely unknown. We systematically analyze key components in the RLHF\nframework--model size, data composition, and inference budget--and their\nimpacts on performance. Our findings show that increasing data diversity and\nvolume improves reward model performance, helping process-supervision models\nscale better. For policy training, more response samples per prompt boost\nperformance initially but quickly plateau. And larger reward models offer\nmodest gains in policy training. In addition, larger policy models benefit less\nfrom RLHF with a fixed reward model. Overall, RLHF scales less efficiently than\npretraining, with diminishing returns from additional computational resources.\nBased on these observations, we propose strategies to optimize RLHF performance\nwithin computational limits.", "published": "2024-12-08 17:19:48", "link": "http://arxiv.org/abs/2412.06000v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Steering Large Language Models to Evaluate and Amplify Creativity", "abstract": "Although capable of generating creative text, Large Language Models (LLMs)\nare poor judges of what constitutes \"creativity\". In this work, we show that we\ncan leverage this knowledge of how to write creatively in order to better judge\nwhat is creative. We take a mechanistic approach that extracts differences in\nthe internal states of an LLM when prompted to respond \"boringly\" or\n\"creatively\" to provide a robust measure of creativity that corresponds\nstrongly with human judgment. We also show these internal state differences can\nbe applied to enhance the creativity of generated text at inference time.", "published": "2024-12-08 20:28:48", "link": "http://arxiv.org/abs/2412.06060v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhanced Computationally Efficient Long LoRA Inspired Perceiver\n  Architectures for Auto-Regressive Language Modeling", "abstract": "The Transformer architecture has revolutionized the Natural Language\nProcessing field and is the backbone of Large Language Models (LLMs). The\nTransformer uses the attention mechanism that computes the pair-wise similarity\nbetween its input tokens to produce latent vectors that are able to understand\nthe semantic meaning of the input text. One of the challenges in the\nTransformer architecture is the quadratic complexity of the attention mechanism\nthat prohibits the efficient processing of long sequence lengths. While many\nrecent research works have attempted to provide a reduction from $O(n^2)$ time\ncomplexity of attention to semi-linear complexity, it remains an unsolved\nproblem in the sense of maintaining a high performance when such complexity is\nreduced. One of the important works in this respect is the Perceiver class of\narchitectures that have demonstrated excellent performance while reducing the\ncomputation complexity. In this paper, we use the PerceiverAR that was proposed\nfor Auto-Regressive modeling as a baseline, and provide three different\narchitectural enhancements to it with varying computation overhead tradeoffs.\nInspired by the recently proposed efficient attention computation approach of\nLong-LoRA, we then present an equally efficient Perceiver-based architecture\n(termed as Long LoRA Pereceiver - LLP) that can be used as the base\narchitecture in LLMs instead of just a fine-tuning add-on. Our results on\ndifferent benchmarks indicate impressive improvements compared to recent\nTransformer based models.", "published": "2024-12-08 23:41:38", "link": "http://arxiv.org/abs/2412.06106v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Depression detection from Social Media Bangla Text Using Recurrent\n  Neural Networks", "abstract": "Emotion artificial intelligence is a field of study that focuses on figuring\nout how to recognize emotions, especially in the area of text mining. Today is\nthe age of social media which has opened a door for us to share our individual\nexpressions, emotions, and perspectives on any event. We can analyze sentiment\non social media posts to detect positive, negative, or emotional behavior\ntoward society. One of the key challenges in sentiment analysis is to identify\ndepressed text from social media text that is a root cause of mental\nill-health. Furthermore, depression leads to severe impairment in day-to-day\nliving and is a major source of suicide incidents. In this paper, we apply\nnatural language processing techniques on Facebook texts for conducting emotion\nanalysis focusing on depression using multiple machine learning algorithms.\nPreprocessing steps like stemming, stop word removal, etc. are used to clean\nthe collected data, and feature extraction techniques like stylometric feature,\nTF-IDF, word embedding, etc. are applied to the collected dataset which\nconsists of 983 texts collected from social media posts. In the process of\nclass prediction, LSTM, GRU, support vector machine, and Naive-Bayes\nclassifiers have been used. We have presented the results using the primary\nclassification metrics including F1-score, and accuracy. This work focuses on\ndepression detection from social media posts to help psychologists to analyze\nsentiment from shared posts which may reduce the undesirable behaviors of\ndepressed individuals through diagnosis and treatment.", "published": "2024-12-08 08:53:51", "link": "http://arxiv.org/abs/2412.05861v1", "categories": ["cs.HC", "cs.CL", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Automated Extraction and Creation of FBS Design Reasoning Knowledge\n  Graphs from Structured Data in Product Catalogues Lacking Contextual\n  Information", "abstract": "Ontology-based knowledge graphs (KG) are desirable for effective knowledge\nmanagement and reuse in various decision making scenarios, including design.\nCreating and populating extensive KG based on specific ontological models can\nbe highly labour and time-intensive unless automated processes are developed\nfor knowledge extraction and graph creation. Most research and development on\nautomated extraction and creation of KG is based on extensive unstructured data\nsets that provide contextual information. However, some of the most useful\ninformation about the products and services of a company has traditionally been\nrecorded as structured data. Such structured data sets rarely follow a standard\nontology, do not capture explicit mapping of relationships between the\nentities, and provide no contextual information. Therefore, this research\nreports a method and digital workflow developed to address this gap. The\ndeveloped method and workflow employ rule-based techniques to extract and\ncreate a Function Behaviour-Structure (FBS) ontology-based KG from legacy\nstructured data, especially specification sheets and product catalogues. The\nsolution approach consists of two main components: a process for deriving\ncontext and context-based classification rules for FBS ontology concepts and a\nworkflow for populating and retrieving the FBS ontology-based KG. KG and\nNatural Language Processing (NLP) are used to automate knowledge extraction,\nrepresentation, and retrieval. The workflow's effectiveness is demonstrated via\npilot implementation in an industrial context. Insights gained from the pilot\nstudy are reported regarding the challenges and opportunities, including\ndiscussing the FBS ontology and concepts.", "published": "2024-12-08 09:20:25", "link": "http://arxiv.org/abs/2412.05868v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Exploring Multi-Grained Concept Annotations for Multimodal Large\n  Language Models", "abstract": "Multimodal Large Language Models (MLLMs) excel in vision--language tasks by\npre-training solely on coarse-grained concept annotations (e.g., image\ncaptions). We hypothesize that integrating fine-grained concept annotations\n(e.g., object labels and object regions) will further improve performance, as\nboth data granularities complement each other in terms of breadth and depth in\nconcept representation. We introduce a new dataset featuring Multimodal\nMulti-Grained Concept annotations (MMGiC) for MLLMs. In constructing MMGiC, we\nexplore the impact of different data recipes on multimodal comprehension and\ngeneration. Our analyses reveal that multi-grained concept annotations\nintegrate and complement each other, under our structured template and a\ngeneral MLLM framework. We clearly explore and demonstrate the potential of\nMMGiC to help MLLMs better locate and learn concepts, aligning vision and\nlanguage at multiple granularities. We further validate our hypothesis by\ninvestigating the fair comparison and effective collaboration between MMGiC and\nimage--caption data on 12 multimodal comprehension and generation benchmarks,\ne.g., their appropriate combination achieve 3.95% and 2.34% absolute\nimprovements over image--caption data alone on POPE and SEED-Bench. Code, data\nand models will be available at https://github.com/LooperXX/MMGiC.", "published": "2024-12-08 13:45:44", "link": "http://arxiv.org/abs/2412.05939v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Language hooks: a modular framework for augmenting LLM reasoning that\n  decouples tool usage from the model and its prompt", "abstract": "Prompting and fine-tuning have emerged as two competing paradigms for\naugmenting language models with new capabilities, such as the use of tools.\nPrompting approaches are quick to set up but rely on providing explicit\ndemonstrations of each tool's usage in the model's prompt, thus coupling tool\nuse to the task at hand and limiting generalisation. Fine-tuning removes the\nneed for task-specific demonstrations of tool usage at runtime; however, this\nties new capabilities to a single model, thus making already-heavier setup\ncosts a recurring expense. In this paper, we introduce language hooks, a novel\nframework for augmenting language models with new capabilities that is\ndecoupled both from the model's task-specific prompt and from the model itself.\nThe language hook algorithm interleaves text generation by the base model with\nthe execution of modular programs that trigger conditionally based on the\nexisting text and the available capabilities. Upon triggering, programs may\ncall external tools, auxiliary language models (e.g. using tool specific\nprompts), and modify the existing context. We benchmark our method against\nstate-of-the-art baselines, find that it outperforms task-aware approaches, and\ndemonstrate its ability to generalise to novel tasks.", "published": "2024-12-08 15:16:17", "link": "http://arxiv.org/abs/2412.05967v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "1-800-SHARED-TASKS at RegNLP: Lexical Reranking of Semantic Retrieval\n  (LeSeR) for Regulatory Question Answering", "abstract": "This paper presents the system description of our entry for the COLING 2025\nRegNLP RIRAG (Regulatory Information Retrieval and Answer Generation)\nchallenge, focusing on leveraging advanced information retrieval and answer\ngeneration techniques in regulatory domains. We experimented with a combination\nof embedding models, including Stella, BGE, CDE, and Mpnet, and leveraged\nfine-tuning and reranking for retrieving relevant documents in top ranks. We\nutilized a novel approach, LeSeR, which achieved competitive results with a\nrecall@10 of 0.8201 and map@10 of 0.6655 for retrievals. This work highlights\nthe transformative potential of natural language processing techniques in\nregulatory applications, offering insights into their capabilities for\nimplementing a retrieval augmented generation system while identifying areas\nfor future improvement in robustness and domain adaptation.", "published": "2024-12-08 17:53:43", "link": "http://arxiv.org/abs/2412.06009v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can Generative AI Solve Your In-Context Learning Problem? A Martingale\n  Perspective", "abstract": "This work is about estimating when a conditional generative model (CGM) can\nsolve an in-context learning (ICL) problem. An in-context learning (ICL)\nproblem comprises a CGM, a dataset, and a prediction task. The CGM could be a\nmulti-modal foundation model; the dataset, a collection of patient histories,\ntest results, and recorded diagnoses; and the prediction task to communicate a\ndiagnosis to a new patient. A Bayesian interpretation of ICL assumes that the\nCGM computes a posterior predictive distribution over an unknown Bayesian model\ndefining a joint distribution over latent explanations and observable data.\nFrom this perspective, Bayesian model criticism is a reasonable approach to\nassess the suitability of a given CGM for an ICL problem. However, such\napproaches -- like posterior predictive checks (PPCs) -- often assume that we\ncan sample from the likelihood and posterior defined by the Bayesian model,\nwhich are not explicitly given for contemporary CGMs. To address this, we show\nwhen ancestral sampling from the predictive distribution of a CGM is equivalent\nto sampling datasets from the posterior predictive of the assumed Bayesian\nmodel. Then we develop the generative predictive $p$-value, which enables PPCs\nand their cousins for contemporary CGMs. The generative predictive $p$-value\ncan then be used in a statistical decision procedure to determine when the\nmodel is appropriate for an ICL problem. Our method only requires generating\nqueries and responses from a CGM and evaluating its response log probability.\nWe empirically evaluate our method on synthetic tabular, imaging, and natural\nlanguage ICL tasks using large language models.", "published": "2024-12-08 19:03:21", "link": "http://arxiv.org/abs/2412.06033v1", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models", "abstract": "The increasing sizes of large language models (LLMs) result in significant\ncomputational overhead and memory usage when adapting these models to specific\ntasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have\nbeen devised to mitigate these challenges by training a small set of parameters\nfor the task-specific updates of the model weights. Among PEFT methods, LoRA\nstands out for its simplicity and efficiency, inspiring the development of a\nseries of variants. However, LoRA and its successors disregard the knowledge\nthat is noisy or irrelevant to the targeted task, detrimentally impacting model\nperformance and leading to suboptimality. To address this limitation, we\nintroduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that\nleverages singular value decomposition (SVD) with knowledge-aware singular\nvalues to dynamically activate knowledge based on its relevance to the task at\nhand. We conduct extensive experiments across a range of LLMs on tasks spanning\nnatural language understanding (NLU), generation (NLG), instruction following,\nand commonsense reasoning. The experimental results demonstrate that KaSA\nconsistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks\nand 4 synthetic datasets, underscoring our method's efficacy and adaptability.\nThe source code of our method is available at\nhttps://github.com/juyongjiang/KaSA.", "published": "2024-12-08 21:26:22", "link": "http://arxiv.org/abs/2412.06071v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Measuring Grammatical Diversity from Small Corpora: Derivational Entropy\n  Rates, Mean Length of Utterances, and Annotation Invariance", "abstract": "In many fields, such as language acquisition, neuropsychology of language,\nthe study of aging, and historical linguistics, corpora are used for estimating\nthe diversity of grammatical structures that are produced during a period by an\nindividual, community, or type of speakers. In these cases, treebanks are taken\nas representative samples of the syntactic structures that might be\nencountered. Generalizing the potential syntactic diversity from the structures\ndocumented in a small corpus requires careful extrapolation whose accuracy is\nconstrained by the limited size of representative sub-corpora. In this article,\nI demonstrate -- theoretically, and empirically -- that a grammar's\nderivational entropy and the mean length of the utterances (MLU) it generates\nare fundamentally linked, giving rise to a new measure, the derivational\nentropy rate. The mean length of utterances becomes the most practical index of\nsyntactic complexity; I demonstrate that MLU is not a mere proxy, but a\nfundamental measure of syntactic diversity. In combination with the new\nderivational entropy rate measure, it provides a theory-free assessment of\ngrammatical complexity. The derivational entropy rate indexes the rate at which\ndifferent grammatical annotation frameworks determine the grammatical\ncomplexity of treebanks. I introduce the Smoothed Induced Treebank Entropy\n(SITE) as a tool for estimating these measures accurately, even from very small\ntreebanks. I conclude by discussing important implications of these results for\nboth NLP and human language processing.", "published": "2024-12-08 22:54:57", "link": "http://arxiv.org/abs/2412.06095v1", "categories": ["cs.CL", "cs.FL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Fully Open Source Moxin-7B Technical Report", "abstract": "Recently, Large Language Models (LLMs) have undergone a significant\ntransformation, marked by a rapid rise in both their popularity and\ncapabilities. Leading this evolution are proprietary LLMs like GPT-4 and\nGPT-o1, which have captured widespread attention in the AI community due to\ntheir remarkable performance and versatility. Simultaneously, open-source LLMs,\nsuch as LLaMA and Mistral, have made great contributions to the ever-increasing\npopularity of LLMs due to the ease to customize and deploy the models across\ndiverse applications. Although open-source LLMs present unprecedented\nopportunities for innovation and research, the commercialization of LLMs has\nraised concerns about transparency, reproducibility, and safety. Many\nopen-source LLMs fail to meet fundamental transparency requirements by\nwithholding essential components like training code and data, and some use\nrestrictive licenses whilst claiming to be \"open-source,\" which may hinder\nfurther innovations on LLMs. To mitigate this issue, we introduce Moxin 7B, a\nfully open-source LLM developed in accordance with the Model Openness Framework\n(MOF), a ranked classification system that evaluates AI models based on model\ncompleteness and openness, adhering to principles of open science, open source,\nopen data, and open access. Our model achieves the highest MOF classification\nlevel of \"open science\" through the comprehensive release of pre-training code\nand configurations, training and fine-tuning datasets, and intermediate and\nfinal checkpoints. Experiments show that our model achieves superior\nperformance in zero-shot evaluation compared with popular 7B models and\nperforms competitively in few-shot evaluation.", "published": "2024-12-08 02:01:46", "link": "http://arxiv.org/abs/2412.06845v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GL-Fusion: Rethinking the Combination of Graph Neural Network and Large\n  Language model", "abstract": "Recent research on integrating Large Language Models (LLMs) with Graph Neural\nNetworks (GNNs) typically follows two approaches: LLM-centered models, which\nconvert graph data into tokens for LLM processing, and GNN-centered models,\nwhich use LLMs to encode text features into node and edge representations for\nGNN input. LLM-centered models often struggle to capture graph structures\neffectively, while GNN-centered models compress variable-length textual data\ninto fixed-size vectors, limiting their ability to understand complex\nsemantics. Additionally, GNN-centered approaches require converting tasks into\na uniform, manually-designed format, restricting them to classification tasks\nand preventing language output. To address these limitations, we introduce a\nnew architecture that deeply integrates GNN with LLM, featuring three key\ninnovations: (1) Structure-Aware Transformers, which incorporate GNN's\nmessage-passing capabilities directly into LLM's transformer layers, allowing\nsimultaneous processing of textual and structural information and generating\noutputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes\nfull, uncompressed text from graph nodes and edges, ensuring complete semantic\nintegration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible\nautoregressive generation alongside GNN's scalable one-pass prediction.\nGL-Fusion achieves outstand performance on various tasks. Notably, it achieves\nstate-of-the-art performance on OGBN-Arxiv and OGBG-Code2.", "published": "2024-12-08 05:49:58", "link": "http://arxiv.org/abs/2412.06849v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Taming Sensitive Weights : Noise Perturbation Fine-tuning for Robust LLM\n  Quantization", "abstract": "Quantization is a critical step to enable efficient LLM serving under limited\nresource. However, previous research observes that certain weights in the LLM,\nknown as outliers, are significantly sensitive to quantization noises. Existing\nquantization methods leave these outliers as floating points or higher\nprecisions to retain performance, posting challenges on the efficient hardware\ndeployment of the mixed-precision model. This work investigates an alternative\nway to tame the sensitive weights' impact on the quantization error, by\nreducing the loss Hessian trace with respect to outliers through an efficient\nfine-tuning process. We propose Noise Perturbation Fine-tuning (NPFT), which\nidentifies outlier weights and add random weight perturbations on the outliers\nas the model going through a PEFT optimization. NPFT tames the sensitivity of\noutlier weights so that the quantized model performance can be improved without\nspecial treatment to the outliers. When applied to OPT and LLaMA models, our\nNPFT method achieves stable performance improvements for both uniform and\nnon-uniform quantizers, while also offering better inference efficiency.\nNotably, the simplest RTN can achieve performance on par with GPTQ using our\nNPFT on LLaMA2-7B-4bits benchmark.", "published": "2024-12-08 21:46:22", "link": "http://arxiv.org/abs/2412.06858v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Learning to Correction: Explainable Feedback Generation for Visual\n  Commonsense Reasoning Distractor", "abstract": "Large multimodal models (LMMs) have shown remarkable performance in the\nvisual commonsense reasoning (VCR) task, which aims to answer a multiple-choice\nquestion based on visual commonsense within an image. However, the ability of\nLMMs to correct potential visual commonsense errors in the distractor upon\ntheir occurrence is yet under-explored. Drawing inspiration from how a human\nteacher crafts challenging distractors to test students' comprehension of the\nconcepts or skills and assists them in identifying and correcting errors toward\nthe answer, we are the pioneering research for LMMs to simulate this error\ncorrection process. To this end, we employ GPT-4 as a ``teacher'' to collect\nthe explainable feedback dataset VCR-DF for error correction, which serves as a\nbenchmark to evaluate the ability of LMMs to identify misconceptions and\nclarify reasons behind the error in VCR distractors toward final answers. In\naddition, we propose an LMM-based Pedagogical Expert Instructed Feedback\nGeneration (PEIFG) model to incorporate the learnable expert prompts and\nmultimodal instruction as guidance for feedback generation. Experimental\nresults show that our PEIFG significantly outperforms existing LMMs. We believe\nthat our benchmark provides a new direction for evaluating the capabilities of\nLMMs.", "published": "2024-12-08 03:59:59", "link": "http://arxiv.org/abs/2412.07801v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Evaluating Robustness of LLMs on Crisis-Related Microblogs across\n  Events, Information Types, and Linguistic Features", "abstract": "The widespread use of microblogging platforms like X (formerly Twitter)\nduring disasters provides real-time information to governments and response\nauthorities. However, the data from these platforms is often noisy, requiring\nautomated methods to filter relevant information. Traditionally, supervised\nmachine learning models have been used, but they lack generalizability. In\ncontrast, Large Language Models (LLMs) show better capabilities in\nunderstanding and processing natural language out of the box. This paper\nprovides a detailed analysis of the performance of six well-known LLMs in\nprocessing disaster-related social media data from a large-set of real-world\nevents. Our findings indicate that while LLMs, particularly GPT-4o and GPT-4,\noffer better generalizability across different disasters and information types,\nmost LLMs face challenges in processing flood-related data, show minimal\nimprovement despite the provision of examples (i.e., shots), and struggle to\nidentify critical information categories like urgent requests and needs.\nAdditionally, we examine how various linguistic features affect model\nperformance and highlight LLMs' vulnerabilities against certain features like\ntypos. Lastly, we provide benchmarking results for all events across both zero-\nand few-shot settings and observe that proprietary models outperform\nopen-source ones in all tasks.", "published": "2024-12-08 10:30:29", "link": "http://arxiv.org/abs/2412.10413v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI", "abstract": "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful\nbehaviors is a critical challenge, especially for systems with high autonomy or\nin safety-critical domains. Despite various safety assurance proposals and\nextreme risk warnings, comprehensive guidelines balancing AI safety and\ncapability remain lacking. In this position paper, we propose the\n\\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced\nroadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of\nTrustworthy AGI} as a practical framework. This framework provides a systematic\ntaxonomy and hierarchical structure for current AI capability and safety\nresearch, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder\ncomprises three core layers: the Approximate Alignment Layer, the Intervenable\nLayer, and the Reflectable Layer. These layers address the key challenges of\nsafety and trustworthiness in AGI and contemporary AI systems. Building upon\nthis framework, we define five levels of trustworthy AGI: perception,\nreasoning, decision-making, autonomy, and collaboration trustworthiness. These\nlevels represent distinct yet progressive aspects of trustworthy AGI. Finally,\nwe present a series of potential governance measures to support the development\nof trustworthy AGI.", "published": "2024-12-08 14:14:16", "link": "http://arxiv.org/abs/2412.14186v2", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Experimenting with Multi-modal Information to Predict Success of Indian\n  IPOs", "abstract": "With consistent growth in Indian Economy, Initial Public Offerings (IPOs)\nhave become a popular avenue for investment. With the modern technology\nsimplifying investments, more investors are interested in making data driven\ndecisions while subscribing for IPOs. In this paper, we describe a machine\nlearning and natural language processing based approach for estimating if an\nIPO will be successful. We have extensively studied the impact of various facts\nmentioned in IPO filing prospectus, macroeconomic factors, market conditions,\nGrey Market Price, etc. on the success of an IPO. We created two new datasets\nrelating to the IPOs of Indian companies. Finally, we investigated how\ninformation from multiple modalities (texts, images, numbers, and categorical\nfeatures) can be used for estimating the direction and underpricing with\nrespect to opening, high and closing prices of stocks on the IPO listing day.", "published": "2024-12-08 06:11:55", "link": "http://arxiv.org/abs/2412.16174v1", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "From Critique to Clarity: A Pathway to Faithful and Personalized Code\n  Explanations with Large Language Models", "abstract": "In the realm of software development, providing accurate and personalized\ncode explanations is crucial for both technical professionals and business\nstakeholders. Technical professionals benefit from enhanced understanding and\nimproved problem-solving skills, while business stakeholders gain insights into\nproject alignments and transparency. Despite the potential, generating such\nexplanations is often time-consuming and challenging. This paper presents an\ninnovative approach that leverages the advanced capabilities of large language\nmodels (LLMs) to generate faithful and personalized code explanations. Our\nmethodology integrates prompt enhancement, self-correction mechanisms,\npersonalized content customization, and interaction with external tools,\nfacilitated by collaboration among multiple LLM agents. We evaluate our\napproach using both automatic and human assessments, demonstrating that our\nmethod not only produces accurate explanations but also tailors them to\nindividual user preferences. Our findings suggest that this approach\nsignificantly improves the quality and relevance of code explanations, offering\na valuable tool for developers and stakeholders alike.", "published": "2024-12-08 09:02:04", "link": "http://arxiv.org/abs/2501.14731v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "SILMM: Self-Improving Large Multimodal Models for Compositional\n  Text-to-Image Generation", "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities in\nmultimodal understanding and generation, pushing forward advancements in\ntext-to-image generation. However, achieving accurate text-image alignment for\nLMMs, particularly in compositional scenarios, remains challenging. Existing\napproaches, such as layout planning for multi-step generation and learning from\nhuman feedback or AI feedback, depend heavily on prompt engineering, costly\nhuman annotations, and continual upgrading, limiting flexibility and\nscalability. In this work, we introduce a model-agnostic iterative\nself-improvement framework (SILMM) that can enable LMMs to provide helpful and\nscalable self-feedback and optimize text-image alignment via Direct Preference\nOptimization (DPO). DPO can readily applied to LMMs that use discrete visual\ntokens as intermediate image representations; while it is less suitable for\nLMMs with continuous visual features, as obtaining generation probabilities is\nchallenging. To adapt SILMM to LMMs with continuous features, we propose a\ndiversity mechanism to obtain diverse representations and a kernel-based\ncontinuous DPO for alignment. Extensive experiments on three compositional\ntext-to-image generation benchmarks validate the effectiveness and superiority\nof SILMM, showing improvements exceeding 30% on T2I-CompBench++ and around 20%\non DPG-Bench.", "published": "2024-12-08 05:28:08", "link": "http://arxiv.org/abs/2412.05818v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Semi-Supervised Contrastive Learning for Controllable Video-to-Music\n  Retrieval", "abstract": "Content creators often use music to enhance their videos, from soundtracks in\nmovies to background music in video blogs and social media content. However,\nidentifying the best music for a video can be a difficult and time-consuming\ntask. To address this challenge, we propose a novel framework for automatically\nretrieving a matching music clip for a given video, and vice versa. Our\napproach leverages annotated music labels, as well as the inherent artistic\ncorrespondence between visual and music elements. Distinct from previous\ncross-modal music retrieval works, our method combines both self-supervised and\nsupervised training objectives. We use self-supervised and label-supervised\ncontrastive learning to train a joint embedding space between music and video.\nWe show the effectiveness of our approach by using music genre labels for the\nsupervised training component, and our framework can be generalized to other\nmusic annotations (e.g., emotion, instrument, etc.). Furthermore, our method\nenables fine-grained control over how much the retrieval process focuses on\nself-supervised vs. label information at inference time. We evaluate the\nlearned embeddings through a variety of video-to-music and music-to-video\nretrieval tasks. Our experiments show that the proposed approach successfully\ncombines self-supervised and supervised objectives and is effective for\ncontrollable music-video retrieval.", "published": "2024-12-08 06:37:27", "link": "http://arxiv.org/abs/2412.05831v2", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "When Vision Models Meet Parameter Efficient Look-Aside Adapters Without\n  Large-Scale Audio Pretraining", "abstract": "Recent studies show that pretrained vision models can boost performance in\naudio downstream tasks. To enhance the performance further, an additional\npretraining stage with large scale audio data is typically required to infuse\naudio specific knowledge into the vision model. However, such approaches\nrequire extensive audio data and a carefully designed objective function. In\nthis work, we propose bypassing the pretraining stage by directly fine-tuning\nthe vision model with our Look Aside Adapter (LoAA) designed for efficient\naudio understanding. Audio spectrum data is represented across two\nheterogeneous dimensions time and frequency and we refine adapters to\nfacilitate interactions between tokens across these dimensions. Our experiments\ndemonstrate that our adapters allow vision models to reach or surpass the\nperformance of pretrained audio models in various audio and speech tasks,\noffering a resource efficient and effective solution for leveraging vision\nmodels in audio applications.", "published": "2024-12-08 14:14:30", "link": "http://arxiv.org/abs/2412.05951v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "M6: Multi-generator, Multi-domain, Multi-lingual and cultural,\n  Multi-genres, Multi-instrument Machine-Generated Music Detection Databases", "abstract": "Machine-generated music (MGM) has emerged as a powerful tool with\napplications in music therapy, personalised editing, and creative inspiration\nfor the music community. However, its unregulated use threatens the\nentertainment, education, and arts sectors by diminishing the value of\nhigh-quality human compositions. Detecting machine-generated music (MGMD) is,\ntherefore, critical to safeguarding these domains, yet the field lacks\ncomprehensive datasets to support meaningful progress. To address this gap, we\nintroduce \\textbf{M6}, a large-scale benchmark dataset tailored for MGMD\nresearch. M6 is distinguished by its diversity, encompassing multiple\ngenerators, domains, languages, cultural contexts, genres, and instruments. We\noutline our methodology for data selection and collection, accompanied by\ndetailed data analysis, providing all WAV form of music. Additionally, we\nprovide baseline performance scores using foundational binary classification\nmodels, illustrating the complexity of MGMD and the significant room for\nimprovement. By offering a robust and multifaceted resource, we aim to empower\nfuture research to develop more effective detection methods for MGM. We believe\nM6 will serve as a critical step toward addressing this societal challenge. The\ndataset and code will be freely available to support open collaboration and\ninnovation in this field.", "published": "2024-12-08 17:23:03", "link": "http://arxiv.org/abs/2412.06001v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
