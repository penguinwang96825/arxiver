{"title": "Multi-Source Neural Machine Translation with Missing Data", "abstract": "Multi-source translation is an approach to exploit multiple inputs (e.g. in\ntwo different languages) to increase translation accuracy. In this paper, we\nexamine approaches for multi-source neural machine translation (NMT) using an\nincomplete multilingual corpus in which some translations are missing. In\npractice, many multilingual corpora are not complete due to the difficulty to\nprovide translations in all of the relevant languages (for example, in TED\ntalks, most English talks only have subtitles for a small portion of the\nlanguages that TED supports). Existing studies on multi-source translation did\nnot explicitly handle such situations. This study focuses on the use of\nincomplete multilingual corpora in multi-encoder NMT and mixture of NMT experts\nand examines a very simple implementation where missing source translations are\nreplaced by a special symbol <NULL>. These methods allow us to use incomplete\ncorpora both at training time and test time. In experiments with real\nincomplete multilingual corpora of TED Talks, the multi-source NMT with the\n<NULL> tokens achieved higher translation accuracies measured by BLEU than\nthose by any one-to-one NMT systems.", "published": "2018-06-07 06:11:34", "link": "http://arxiv.org/abs/1806.02525v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Challenge Set for French --> English Machine Translation", "abstract": "We present a challenge set for French --> English machine translation based\non the approach introduced in Isabelle, Cherry and Foster (EMNLP 2017). Such\nchallenge sets are made up of sentences that are expected to be relatively\ndifficult for machines to translate correctly because their most\nstraightforward translations tend to be linguistically divergent. We present\nhere a set of 506 manually constructed French sentences, 307 of which are\ntargeted to the same kinds of structural divergences as in the paper mentioned\nabove. The remaining 199 sentences are designed to test the ability of the\nsystems to correctly translate difficult grammatical words such as\nprepositions. We report on the results of using this challenge set for testing\ntwo different systems, namely Google Translate and DEEPL, each on two different\ndates (October 2017 and January 2018). All the resulting data are made publicly\navailable.", "published": "2018-06-07 15:16:02", "link": "http://arxiv.org/abs/1806.02725v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Adversarial Training for Accented Speech Recognition", "abstract": "In this paper, we propose a domain adversarial training (DAT) algorithm to\nalleviate the accented speech recognition problem. In order to reduce the\nmismatch between labeled source domain data (\"standard\" accent) and unlabeled\ntarget domain data (with heavy accents), we augment the learning objective for\na Kaldi TDNN network with a domain adversarial training (DAT) objective to\nencourage the model to learn accent-invariant features. In experiments with\nthree Mandarin accents, we show that DAT yields up to 7.45% relative character\nerror rate reduction when we do not have transcriptions of the accented speech,\ncompared with the baseline trained on standard accent data only. We also find a\nbenefit from DAT when used in combination with training from automatic\ntranscriptions on the accented data. Furthermore, we find that DAT is superior\nto multi-task learning for accented speech recognition.", "published": "2018-06-07 17:02:54", "link": "http://arxiv.org/abs/1806.02786v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Exploration of Unreliable News Classification in Brazil and The U.S", "abstract": "The propagation of unreliable information is on the rise in many places\naround the world. This expansion is facilitated by the rapid spread of\ninformation and anonymity granted by the Internet. The spread of unreliable\ninformation is a wellstudied issue and it is associated with negative social\nimpacts. In a previous work, we have identified significant differences in the\nstructure of news articles from reliable and unreliable sources in the US\nmedia. Our goal in this work was to explore such differences in the Brazilian\nmedia. We found significant features in two data sets: one with Brazilian news\nin Portuguese and another one with US news in English. Our results show that\nfeatures related to the writing style were prominent in both data sets and,\ndespite the language difference, some features have a universal behavior, being\nsignificant to both US and Brazilian news articles. Finally, we combined both\ndata sets and used the universal features to build a machine learning\nclassifier to predict the source type of a news article as reliable or\nunreliable.", "published": "2018-06-07 19:28:35", "link": "http://arxiv.org/abs/1806.02875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multimodal Relational Tensor Network for Sentiment and Emotion\n  Classification", "abstract": "Understanding Affect from video segments has brought researchers from the\nlanguage, audio and video domains together. Most of the current multimodal\nresearch in this area deals with various techniques to fuse the modalities, and\nmostly treat the segments of a video independently. Motivated by the work of\n(Zadeh et al., 2017) and (Poria et al., 2017), we present our architecture,\nRelational Tensor Network, where we use the inter-modal interactions within a\nsegment (intra-segment) and also consider the sequence of segments in a video\nto model the inter-segment inter-modal interactions. We also generate rich\nrepresentations of text and audio modalities by leveraging richer audio and\nlinguistic context alongwith fusing fine-grained knowledge based polarity\nscores from text. We present the results of our model on CMU-MOSEI dataset and\nshow that our model outperforms many baselines and state of the art methods for\nsentiment classification and emotion recognition.", "published": "2018-06-07 23:21:51", "link": "http://arxiv.org/abs/1806.02923v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Characterizing Departures from Linearity in Word Translation", "abstract": "We investigate the behavior of maps learned by machine translation methods.\nThe maps translate words by projecting between word embedding spaces of\ndifferent languages. We locally approximate these maps using linear maps, and\nfind that they vary across the word embedding space. This demonstrates that the\nunderlying maps are non-linear. Importantly, we show that the locally linear\nmaps vary by an amount that is tightly correlated with the distance between the\nneighborhoods on which they are trained. Our results can be used to test\nnon-linear methods, and to drive the design of more accurate maps for word\ntranslation.", "published": "2018-06-07 23:04:19", "link": "http://arxiv.org/abs/1806.04508v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker-Follower Models for Vision-and-Language Navigation", "abstract": "Navigation guided by natural language instructions presents a challenging\nreasoning problem for instruction followers. Natural language instructions\ntypically identify only a few high-level decisions and landmarks rather than\ncomplete low-level motor behaviors; much of the missing information must be\ninferred based on perceptual context. In machine learning settings, this is\ndoubly challenging: it is difficult to collect enough annotated data to enable\nlearning of this reasoning process from scratch, and also difficult to\nimplement the reasoning process using generic sequence models. Here we describe\nan approach to vision-and-language navigation that addresses both these issues\nwith an embedded speaker model. We use this speaker model to (1) synthesize new\ninstructions for data augmentation and to (2) implement pragmatic reasoning,\nwhich evaluates how well candidate action sequences explain an instruction.\nBoth steps are supported by a panoramic action space that reflects the\ngranularity of human-generated instructions. Experiments show that all three\ncomponents of this approach---speaker-driven data augmentation, pragmatic\nreasoning and panoramic action space---dramatically improve the performance of\na baseline instruction follower, more than doubling the success rate over the\nbest existing approach on a standard benchmark.", "published": "2018-06-07 15:15:35", "link": "http://arxiv.org/abs/1806.02724v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Embedding Transfer for Low-Resource Medical Named Entity Recognition: A\n  Case Study on Patient Mobility", "abstract": "Functioning is gaining recognition as an important indicator of global\nhealth, but remains under-studied in medical natural language processing\nresearch. We present the first analysis of automatically extracting\ndescriptions of patient mobility, using a recently-developed dataset of free\ntext electronic health records. We frame the task as a named entity recognition\n(NER) problem, and investigate the applicability of NER techniques to mobility\nextraction. As text corpora focused on patient functioning are scarce, we\nexplore domain adaptation of word embeddings for use in a recurrent neural\nnetwork NER system. We find that embeddings trained on a small in-domain corpus\nperform nearly as well as those learned from large out-of-domain corpora, and\nthat domain adaptation techniques yield additional improvements in both\nprecision and recall. Our analysis identifies several significant challenges in\nextracting descriptions of patient mobility, including the length and\ncomplexity of annotated entities and high linguistic variability in mobility\ndescriptions.", "published": "2018-06-07 17:49:54", "link": "http://arxiv.org/abs/1806.02814v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is preprocessing of text really worth your time for online comment\n  classification?", "abstract": "A large proportion of online comments present on public domains are\nconstructive, however a significant proportion are toxic in nature. The\ncomments contain lot of typos which increases the number of features manifold,\nmaking the ML model difficult to train. Considering the fact that the data\nscientists spend approximately 80% of their time in collecting, cleaning and\norganizing their data [1], we explored how much effort should we invest in the\npreprocessing (transformation) of raw comments before feeding it to the\nstate-of-the-art classification models. With the help of four models on Jigsaw\ntoxic comment classification data, we demonstrated that the training of model\nwithout any transformation produce relatively decent model. Applying even basic\ntransformations, in some cases, lead to worse performance and should be applied\nwith caution.", "published": "2018-06-07 21:29:39", "link": "http://arxiv.org/abs/1806.02908v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Training Augmentation with Adversarial Examples for Robust Speech\n  Recognition", "abstract": "This paper explores the use of adversarial examples in training speech\nrecognition systems to increase robustness of deep neural network acoustic\nmodels. During training, the fast gradient sign method is used to generate\nadversarial examples augmenting the original training data. Different from\nconventional data augmentation based on data transformations, the examples are\ndynamically generated based on current acoustic model parameters. We assess the\nimpact of adversarial data augmentation in experiments on the Aurora-4 and\nCHiME-4 single-channel tasks, showing improved robustness against noise and\nchannel variation. Further improvement is obtained when combining adversarial\nexamples with teacher/student training, leading to a 23% relative word error\nrate reduction on Aurora-4.", "published": "2018-06-07 16:53:12", "link": "http://arxiv.org/abs/1806.02782v2", "categories": ["cs.CL", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Simple Method for Commonsense Reasoning", "abstract": "Commonsense reasoning is a long-standing challenge for deep learning. For\nexample, it is difficult to use neural networks to tackle the Winograd Schema\ndataset (Levesque et al., 2011). In this paper, we present a simple method for\ncommonsense reasoning with neural networks, using unsupervised learning. Key to\nour method is the use of language models, trained on a massive amount of\nunlabled data, to score multiple choice questions posed by commonsense\nreasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges,\nour models outperform previous state-of-the-art methods by a large margin,\nwithout using expensive annotated knowledge bases or hand-engineered features.\nWe train an array of large RNN language models that operate at word or\ncharacter level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a\ncustomized corpus for this task and show that diversity of training data plays\nan important role in test performance. Further analysis also shows that our\nsystem successfully discovers important features of the context that decide the\ncorrect answer, indicating a good grasp of commonsense knowledge.", "published": "2018-06-07 18:13:08", "link": "http://arxiv.org/abs/1806.02847v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Semi-supervised and Transfer learning approaches for low resource\n  sentiment classification", "abstract": "Sentiment classification involves quantifying the affective reaction of a\nhuman to a document, media item or an event. Although researchers have\ninvestigated several methods to reliably infer sentiment from lexical, speech\nand body language cues, training a model with a small set of labeled datasets\nis still a challenge. For instance, in expanding sentiment analysis to new\nlanguages and cultures, it may not always be possible to obtain comprehensive\nlabeled datasets. In this paper, we investigate the application of\nsemi-supervised and transfer learning methods to improve performances on low\nresource sentiment classification tasks. We experiment with extracting dense\nfeature representations, pre-training and manifold regularization in enhancing\nthe performance of sentiment classification systems. Our goal is a coherent\nimplementation of these methods and we evaluate the gains achieved by these\nmethods in matched setting involving training and testing on a single corpus\nsetting as well as two cross corpora settings. In both the cases, our\nexperiments demonstrate that the proposed methods can significantly enhance the\nmodel performance against a purely supervised approach, particularly in cases\ninvolving a handful of training data.", "published": "2018-06-07 18:59:26", "link": "http://arxiv.org/abs/1806.02863v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.IR"}
{"title": "Probabilistic FastText for Multi-Sense Word Embeddings", "abstract": "We introduce Probabilistic FastText, a new model for word embeddings that can\ncapture multiple word senses, sub-word structure, and uncertainty information.\nIn particular, we represent each word with a Gaussian mixture density, where\nthe mean of a mixture component is given by the sum of n-grams. This\nrepresentation allows the model to share statistical strength across sub-word\nstructures (e.g. Latin roots), producing accurate representations of rare,\nmisspelt, or even unseen words. Moreover, each component of the mixture can\ncapture a different word sense. Probabilistic FastText outperforms both\nFastText, which has no probabilistic model, and dictionary-level probabilistic\nembeddings, which do not incorporate subword structures, on several\nword-similarity benchmarks, including English RareWord and foreign language\ndatasets. We also achieve state-of-art performance on benchmarks that measure\nability to discern different meanings. Thus, the proposed model is the first to\nachieve multi-sense representations while having enriched semantics on rare\nwords.", "published": "2018-06-07 20:57:22", "link": "http://arxiv.org/abs/1806.02901v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
