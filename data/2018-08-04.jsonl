{"title": "Abstractive Summarization Improved by WordNet-based Extractive Sentences", "abstract": "Recently, the seq2seq abstractive summarization models have achieved good\nresults on the CNN/Daily Mail dataset. Still, how to improve abstractive\nmethods with extractive methods is a good research direction, since extractive\nmethods have their potentials of exploiting various efficient features for\nextracting important sentences in one text. In this paper, in order to improve\nthe semantic relevance of abstractive summaries, we adopt the WordNet based\nsentence ranking algorithm to extract the sentences which are most semantically\nto one text. Then, we design a dual attentional seq2seq framework to generate\nsummaries with consideration of the extracted information. At the same time, we\ncombine pointer-generator and coverage mechanisms to solve the problems of\nout-of-vocabulary (OOV) words and duplicate words which exist in the\nabstractive models. Experiments on the CNN/Daily Mail dataset show that our\nmodels achieve competitive performance with the state-of-the-art ROUGE scores.\nHuman evaluations also show that the summaries generated by our models have\nhigh semantic relevance to the original text.", "published": "2018-08-04 05:03:43", "link": "http://arxiv.org/abs/1808.01426v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Triplet Network with Attention for Speaker Diarization", "abstract": "In automatic speech processing systems, speaker diarization is a crucial\nfront-end component to separate segments from different speakers. Inspired by\nthe recent success of deep neural networks (DNNs) in semantic inferencing,\ntriplet loss-based architectures have been successfully used for this problem.\nHowever, existing work utilizes conventional i-vectors as the input\nrepresentation and builds simple fully connected networks for metric learning,\nthus not fully leveraging the modeling power of DNN architectures. This paper\ninvestigates the importance of learning effective representations from the\nsequences directly in metric learning pipelines for speaker diarization. More\nspecifically, we propose to employ attention models to learn embeddings and the\nmetric jointly in an end-to-end fashion. Experiments are conducted on the\nCALLHOME conversational speech corpus. The diarization results demonstrate\nthat, besides providing a unified model, the proposed approach achieves\nimproved performance when compared against existing approaches.", "published": "2018-08-04 21:10:03", "link": "http://arxiv.org/abs/1808.01535v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Predicting Expressive Speaking Style From Text In End-To-End Speech\n  Synthesis", "abstract": "Global Style Tokens (GSTs) are a recently-proposed method to learn latent\ndisentangled representations of high-dimensional data. GSTs can be used within\nTacotron, a state-of-the-art end-to-end text-to-speech synthesis system, to\nuncover expressive factors of variation in speaking style. In this work, we\nintroduce the Text-Predicted Global Style Token (TP-GST) architecture, which\ntreats GST combination weights or style embeddings as \"virtual\" speaking style\nlabels within Tacotron. TP-GST learns to predict stylistic renderings from text\nalone, requiring neither explicit labels during training nor auxiliary inputs\nfor inference. We show that, when trained on a dataset of expressive speech,\nour system generates audio with more pitch and energy variation than two\nstate-of-the-art baseline models. We further demonstrate that TP-GSTs can\nsynthesize speech with background noise removed, and corroborate these analyses\nwith positive results on human-rated listener preference audiobook tasks.\nFinally, we demonstrate that multi-speaker TP-GST models successfully factorize\nspeaker identity and speaking style. We provide a website with audio samples\nfor each of our findings.", "published": "2018-08-04 02:21:07", "link": "http://arxiv.org/abs/1808.01410v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS", "stat.ML", "eess.AS"], "primary_category": "cs.CL"}
