{"title": "Towards Accurate Word Segmentation for Chinese Patents", "abstract": "A patent is a property right for an invention granted by the government to\nthe inventor. An invention is a solution to a specific technological problem.\nSo patents often have a high concentration of scientific and technical terms\nthat are rare in everyday language. The Chinese word segmentation model trained\non currently available everyday language data sets performs poorly because it\ncannot effectively recognize these scientific and technical terms. In this\npaper we describe a pragmatic approach to Chinese word segmentation on patents\nwhere we train a character-based semi-supervised sequence labeling model by\nextracting features from a manually segmented corpus of 142 patents, enhanced\nwith information extracted from the Chinese TreeBank. Experiments show that the\naccuracy of our model reached 95.08% (F1 score) on a held-out test set and\n96.59% on development set, compared with an F1 score of 91.48% on development\nset if the model is trained on the Chinese TreeBank. We also experimented with\nsome existing domain adaptation techniques, the results show that the amount of\ntarget domain data and the selected features impact the performance of the\ndomain adaptation techniques.", "published": "2016-11-30 07:53:34", "link": "http://arxiv.org/abs/1611.10038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep encoding of etymological information in TEI", "abstract": "This paper aims to provide a comprehensive modeling and representation of\netymological data in digital dictionaries. The purpose is to integrate in one\ncoherent framework both digital representations of legacy dictionaries, and\nalso born-digital lexical databases that are constructed manually or\nsemi-automatically. We want to propose a systematic and coherent set of\nmodeling principles for a variety of etymological phenomena that may contribute\nto the creation of a continuum between existing and future lexical constructs,\nwhere anyone interested in tracing the history of words and their meanings will\nbe able to seamlessly query lexical resources.Instead of designing an ad hoc\nmodel and representation language for digital etymological data, we will focus\non identifying all the possibilities offered by the TEI guidelines for the\nrepresentation of lexical information.", "published": "2016-11-30 12:30:11", "link": "http://arxiv.org/abs/1611.10122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anchored Correlation Explanation: Topic Modeling with Minimal Domain\n  Knowledge", "abstract": "While generative models such as Latent Dirichlet Allocation (LDA) have proven\nfruitful in topic modeling, they often require detailed assumptions and careful\nspecification of hyperparameters. Such model complexity issues only compound\nwhen trying to generalize generative models to incorporate human input. We\nintroduce Correlation Explanation (CorEx), an alternative approach to topic\nmodeling that does not assume an underlying generative model, and instead\nlearns maximally informative topics through an information-theoretic framework.\nThis framework naturally generalizes to hierarchical and semi-supervised\nextensions with no additional modeling assumptions. In particular, word-level\ndomain knowledge can be flexibly incorporated within CorEx through anchor\nwords, allowing topic separability and representation to be promoted with\nminimal human intervention. Across a variety of datasets, metrics, and\nexperiments, we demonstrate that CorEx produces topics that are comparable in\nquality to those produced by unsupervised and semi-supervised variants of LDA.", "published": "2016-11-30 17:32:17", "link": "http://arxiv.org/abs/1611.10277v4", "categories": ["cs.CL", "cs.IR", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.CL"}
