{"title": "Text Mining for Processing Interview Data in Computational Social\n  Science", "abstract": "We use commercially available text analysis technology to process interview\ntext data from a computational social science study. We find that topical\nclustering and terminological enrichment provide for convenient exploration and\nquantification of the responses. This makes it possible to generate and test\nhypotheses and to compare textual and non-textual variables, and saves analyst\neffort. We encourage studies in social science to use text analysis, especially\nfor exploratory open-ended studies. We discuss how replicability requirements\nare met by text analysis technology. We note that the most recent learning\nmodels are not designed with transparency in mind, and that research requires a\nmodel to be editable and its decisions to be explainable. The tools available\ntoday, such as the one used in the present study, are not built for processing\ninterview texts. While many of the variables under consideration are\nquantifiable using lexical statistics, we find that some interesting and\npotentially valuable features are difficult or impossible to automatise\nreliably at present. We note that there are some potentially interesting\napplications for traditional natural language processing mechanisms such as\nnamed entity recognition and anaphora resolution in this application area. We\nconclude with a suggestion for language technologists to investigate the\nchallenge of processing interview data comprehensively, especially the\ninterplay between question and response, and we encourage social science\nresearchers not to hesitate to use text analysis tools, especially for the\nexploratory phase of processing interview data.?", "published": "2020-11-28 00:44:35", "link": "http://arxiv.org/abs/2011.14037v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Investigation of Language Model Interpretability via Sentence Editing", "abstract": "Pre-trained language models (PLMs) like BERT are being used for almost all\nlanguage-related tasks, but interpreting their behavior still remains a\nsignificant challenge and many important questions remain largely unanswered.\nIn this work, we re-purpose a sentence editing dataset, where faithful\nhigh-quality human rationales can be automatically extracted and compared with\nextracted model rationales, as a new testbed for interpretability. This enables\nus to conduct a systematic investigation on an array of questions regarding\nPLMs' interpretability, including the role of pre-training procedure,\ncomparison of rationale extraction methods, and different layers in the PLM.\nThe investigation generates new insights, for example, contrary to the common\nunderstanding, we find that attention weights correlate well with human\nrationales and work better than gradient-based saliency in extracting model\nrationales. Both the dataset and code are available at\nhttps://github.com/samuelstevens/sentence-editing-interpretability to\nfacilitate future interpretability research.", "published": "2020-11-28 00:46:43", "link": "http://arxiv.org/abs/2011.14039v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Multiple Subwords to Improve English-Esperanto Automated Literary\n  Translation Quality", "abstract": "Building Machine Translation (MT) systems for low-resource languages remains\nchallenging. For many language pairs, parallel data are not widely available,\nand in such cases MT models do not achieve results comparable to those seen\nwith high-resource languages.\n  When data are scarce, it is of paramount importance to make optimal use of\nthe limited material available. To that end, in this paper we propose employing\nthe same parallel sentences multiple times, only changing the way the words are\nsplit each time. For this purpose we use several Byte Pair Encoding models,\nwith various merge operations used in their configuration.\n  In our experiments, we use this technique to expand the available data and\nimprove an MT system involving a low-resource language pair, namely\nEnglish-Esperanto.\n  As an additional contribution, we made available a set of English-Esperanto\nparallel data in the literary domain.", "published": "2020-11-28 18:44:52", "link": "http://arxiv.org/abs/2011.14190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disentangling Homophemes in Lip Reading using Perplexity Analysis", "abstract": "The performance of automated lip reading using visemes as a classification\nschema has achieved less success compared with the use of ASCII characters and\nwords largely due to the problem of different words sharing identical visemes.\nThe Generative Pre-Training transformer is an effective autoregressive language\nmodel used for many tasks in Natural Language Processing, including sentence\nprediction and text classification.\n  This paper proposes a new application for this model and applies it in the\ncontext of lip reading, where it serves as a language model to convert visual\nspeech in the form of visemes, to language in the form of words and sentences.\nThe network uses the search for optimal perplexity to perform the\nviseme-to-word mapping and is thus a solution to the one-to-many mapping\nproblem that exists whereby various words that sound different when spoken look\nidentical. This paper proposes a method to tackle the one-to-many mapping\nproblem when performing automated lip reading using solely visual cues in two\nseparate scenarios: the first scenario is where the word boundary, that is, the\nbeginning and the ending of a word, is unknown; and the second scenario is\nwhere the boundary is known.\n  Sentences from the benchmark BBC dataset \"Lip Reading Sentences in the\nWild\"(LRS2), are classified with a character error rate of 10.7% and a word\nerror rate of 18.0%. The main contribution of this paper is to propose a method\nof predicting words through the use of perplexity analysis when only visual\ncues are present, using an autoregressive language model.", "published": "2020-11-28 12:12:17", "link": "http://arxiv.org/abs/2012.07528v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Data-Driven Study of Commonsense Knowledge using the ConceptNet\n  Knowledge Base", "abstract": "Acquiring commonsense knowledge and reasoning is recognized as an important\nfrontier in achieving general Artificial Intelligence (AI). Recent research in\nthe Natural Language Processing (NLP) community has demonstrated significant\nprogress in this problem setting. Despite this progress, which is mainly on\nmultiple-choice question answering tasks in limited settings, there is still a\nlack of understanding (especially at scale) of the nature of commonsense\nknowledge itself. In this paper, we propose and conduct a systematic study to\nenable a deeper understanding of commonsense knowledge by doing an empirical\nand structural analysis of the ConceptNet knowledge base. ConceptNet is a\nfreely available knowledge base containing millions of commonsense assertions\npresented in natural language. Detailed experimental results on three carefully\ndesigned research questions, using state-of-the-art unsupervised graph\nrepresentation learning ('embedding') and clustering techniques, reveal deep\nsubstructures in ConceptNet relations, allowing us to make data-driven and\ncomputational claims about the meaning of phenomena such as 'context' that are\ntraditionally discussed only in qualitative terms. Furthermore, our methodology\nprovides a case study in how to use data-science and computational\nmethodologies for understanding the nature of an everyday (yet complex)\npsychological phenomenon that is an essential feature of human intelligence.", "published": "2020-11-28 08:08:25", "link": "http://arxiv.org/abs/2011.14084v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware\n  Multi-Task NLP Inference", "abstract": "Transformer-based language models such as BERT provide significant accuracy\nimprovement for a multitude of natural language processing (NLP) tasks.\nHowever, their hefty computational and memory demands make them challenging to\ndeploy to resource-constrained edge platforms with strict latency requirements.\nWe present EdgeBERT, an in-depth algorithm-hardware co-design for latency-aware\nenergy optimization for multi-task NLP. EdgeBERT employs entropy-based early\nexit predication in order to perform dynamic voltage-frequency scaling (DVFS),\nat a sentence granularity, for minimal energy consumption while adhering to a\nprescribed target latency. Computation and memory footprint overheads are\nfurther alleviated by employing a calibrated combination of adaptive attention\nspan, selective network pruning, and floating-point quantization. Furthermore,\nin order to maximize the synergistic benefits of these algorithms in always-on\nand intermediate edge computing settings, we specialize a 12nm scalable\nhardware accelerator system, integrating a fast-switching low-dropout voltage\nregulator (LDO), an all-digital phase-locked loop (ADPLL), as well as,\nhigh-density embedded non-volatile memories (eNVMs) wherein the sparse\nfloating-point bit encodings of the shared multi-task parameters are carefully\nstored. Altogether, latency-aware multi-task NLP inference acceleration on the\nEdgeBERT hardware system generates up to 7x, 2.5x, and 53x lower energy\ncompared to the conventional inference without early stopping, the\nlatency-unbounded early exit approach, and CUDA adaptations on an Nvidia Jetson\nTegra X2 mobile GPU, respectively.", "published": "2020-11-28 19:21:47", "link": "http://arxiv.org/abs/2011.14203v5", "categories": ["cs.AR", "cs.CL"], "primary_category": "cs.AR"}
{"title": "Unsupervised Spoken Term Discovery Based on Re-clustering of\n  Hypothesized Speech Segments with Siamese and Triplet Networks", "abstract": "Spoken term discovery from untranscribed speech audio could be achieved via a\ntwo-stage process. In the first stage, the unlabelled speech is decoded into a\nsequence of subword units that are learned and modelled in an unsupervised\nmanner. In the second stage, partial sequence matching and clustering are\nperformed on the decoded subword sequences, resulting in a set of discovered\nwords or phrases. A limitation of this approach is that the results of subword\ndecoding could be erroneous, and the errors would impact the subsequent steps.\nWhile Siamese/Triplet network is one approach to learn segment representations\nthat can improve the discovery process, the challenge in spoken term discovery\nunder a complete unsupervised scenario is that training examples are\nunavailable. In this paper, we propose to generate training examples from\ninitial hypothesized sequence clusters. The Siamese/Triplet network is trained\non the hypothesized examples to measure the similarity between two speech\nsegments and hereby perform re-clustering of all hypothesized subword sequences\nto achieve spoken term discovery. Experimental results show that the proposed\napproach is effective in obtaining training examples for Siamese and Triplet\nnetworks, improving the efficacy of spoken term discovery as compared with the\noriginal two-stage method.", "published": "2020-11-28 03:52:38", "link": "http://arxiv.org/abs/2011.14062v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Transformer Query-Target Knowledge Discovery (TEND): Drug Discovery from\n  CORD-19", "abstract": "Previous work established skip-gram word2vec models could be used to mine\nknowledge in the materials science literature for the discovery of\nthermoelectrics. Recent transformer architectures have shown great progress in\nlanguage modeling and associated fine-tuned tasks, but they have yet to be\nadapted for drug discovery. We present a RoBERTa transformer-based method that\nextends the masked language token prediction using query-target conditioning to\ntreat the specificity challenge. The transformer discovery method entails\nseveral benefits over the word2vec method including domain-specific (antiviral)\nanalogy performance, negation handling, and flexible query analysis (specific)\nand is demonstrated on influenza drug discovery. To stimulate COVID-19\nresearch, we release an influenza clinical trials and antiviral analogies\ndataset used in conjunction with the COVID-19 Open Research Dataset Challenge\n(CORD-19) literature dataset in the study. We examine k-shot fine-tuning to\nimprove the downstream analogies performance as well as to mine analogies for\nmodel explainability. Further, the query-target analysis is verified in a\nforward chaining analysis against the influenza drug clinical trials dataset,\nbefore adapted for COVID-19 drugs (combinations and side-effects) and on-going\nclinical trials. In consideration of the present topic, we release the model,\ndataset, and code.", "published": "2020-11-28 04:30:31", "link": "http://arxiv.org/abs/2012.04682v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unsupervised Spoken Term Discovery on Untranscribed Speech", "abstract": "(Part of the abstract) In this thesis, we investigate the use of unsupervised\nspoken term discovery in tackling this problem. Unsupervised spoken term\ndiscovery aims to discover topic-related terminologies in a speech without\nknowing the phonetic properties of the language and content. It can be further\ndivided into two parts: Acoustic segment modelling (ASM) and unsupervised\npattern discovery. ASM learns the phonetic structures of zero-resource language\naudio with no phonetic knowledge available, generating self-derived \"phonemes\".\nThe audio are labelled with these \"phonemes\" to obtain \"phoneme\" sequences.\nUnsupervised pattern discovery searches for repetitive patterns in the\n\"phoneme\" sequences. The discovered patterns can be grouped to determine the\nkeywords of the audio. Multilingual neural network with bottleneck layer is\nused for feature extraction. Experiments show that bottleneck features\nfacilitate the training of ASM compared to conventional features such as MFCC.\nThe unsupervised spoken term discovery system is experimented with online\nlectures covering different topics by different speakers. It is shown that the\nsystem learns the phonetic information of the language and can discover\nfrequent spoken terms that align with text transcription. By using information\nretrieval technology such as word embedding and TFIDF, it is shown that the\ndiscovered keywords can be further used for topic comparison.", "published": "2020-11-28 03:46:04", "link": "http://arxiv.org/abs/2011.14060v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
