{"title": "Context Gates for Neural Machine Translation", "abstract": "In neural machine translation (NMT), generation of a target word depends on\nboth source and target contexts. We find that source contexts have a direct\nimpact on the adequacy of a translation while target contexts affect the\nfluency. Intuitively, generation of a content word should rely more on the\nsource context and generation of a functional word should rely more on the\ntarget context. Due to the lack of effective control over the influence from\nsource and target contexts, conventional NMT tends to yield fluent but\ninadequate translations. To address this problem, we propose context gates\nwhich dynamically control the ratios at which source and target contexts\ncontribute to the generation of target words. In this way, we can enhance both\nthe adequacy and fluency of NMT with more careful control of the information\nflow from contexts. Experiments show that our approach significantly improves\nupon a standard attention-based NMT system by +2.3 BLEU points.", "published": "2016-08-22 03:19:27", "link": "http://arxiv.org/abs/1608.06043v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Incremental Parser for Abstract Meaning Representation", "abstract": "Meaning Representation (AMR) is a semantic representation for natural\nlanguage that embeds annotations related to traditional tasks such as named\nentity recognition, semantic role labeling, word sense disambiguation and\nco-reference resolution. We describe a transition-based parser for AMR that\nparses sentences left-to-right, in linear time. We further propose a test-suite\nthat assesses specific subtasks that are helpful in comparing AMR parsers, and\nshow that our parser is competitive with the state of the art on the LDC2015E86\ndataset and that it outperforms state-of-the-art parsers for recovering named\nentities and handling polarity.", "published": "2016-08-22 10:30:18", "link": "http://arxiv.org/abs/1608.06111v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Median-Based Generation of Synthetic Speech Durations using a\n  Non-Parametric Approach", "abstract": "This paper proposes a new approach to duration modelling for statistical\nparametric speech synthesis in which a recurrent statistical model is trained\nto output a phone transition probability at each timestep (acoustic frame).\nUnlike conventional approaches to duration modelling -- which assume that\nduration distributions have a particular form (e.g., a Gaussian) and use the\nmean of that distribution for synthesis -- our approach can in principle model\nany distribution supported on the non-negative integers. Generation from this\nmodel can be performed in many ways; here we consider output generation based\non the median predicted duration. The median is more typical (more probable)\nthan the conventional mean duration, is robust to training-data irregularities,\nand enables incremental generation. Furthermore, a frame-level approach to\nduration prediction is consistent with a longer-term goal of modelling\ndurations and acoustic features together. Results indicate that the proposed\nmethod is competitive with baseline approaches in approximating the median\nduration of held-out natural speech.", "published": "2016-08-22 11:52:55", "link": "http://arxiv.org/abs/1608.06134v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
