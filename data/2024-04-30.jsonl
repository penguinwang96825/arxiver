{"title": "Game-MUG: Multimodal Oriented Game Situation Understanding and\n  Commentary Generation Dataset", "abstract": "The dynamic nature of esports makes the situation relatively complicated for\naverage viewers. Esports broadcasting involves game expert casters, but the\ncaster-dependent game commentary is not enough to fully understand the game\nsituation. It will be richer by including diverse multimodal esports\ninformation, including audiences' talks/emotions, game audio, and game match\nevent information. This paper introduces GAME-MUG, a new multimodal game\nsituation understanding and audience-engaged commentary generation dataset and\nits strong baseline. Our dataset is collected from 2020-2022 LOL game live\nstreams from YouTube and Twitch, and includes multimodal esports game\ninformation, including text, audio, and time-series event logs, for detecting\nthe game situation. In addition, we also propose a new audience conversation\naugmented commentary dataset by covering the game situation and audience\nconversation understanding, and introducing a robust joint multimodal dual\nlearning model as a baseline. We examine the model's game situation/event\nunderstanding ability and commentary generation capability to show the\neffectiveness of the multimodal aspects coverage and the joint integration\nlearning approach.", "published": "2024-04-30 00:39:26", "link": "http://arxiv.org/abs/2404.19175v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revenge of the Fallen? Recurrent Models Match Transformers at Predicting\n  Human Language Comprehension Metrics", "abstract": "Transformers have generally supplanted recurrent neural networks as the\ndominant architecture for both natural language processing tasks and for\nmodelling the effect of predictability on online human language comprehension.\nHowever, two recently developed recurrent model architectures, RWKV and Mamba,\nappear to perform natural language tasks comparably to or better than\ntransformers of equivalent scale. In this paper, we show that contemporary\nrecurrent models are now also able to match - and in some cases, exceed - the\nperformance of comparably sized transformers at modeling online human language\ncomprehension. This suggests that transformer language models are not uniquely\nsuited to this task, and opens up new directions for debates about the extent\nto which architectural features of language models make them better or worse\nmodels of human language comprehension.", "published": "2024-04-30 01:02:15", "link": "http://arxiv.org/abs/2404.19178v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViTHSD: Exploiting Hatred by Targets for Hate Speech Detection on\n  Vietnamese Social Media Texts", "abstract": "The growth of social networks makes toxic content spread rapidly. Hate speech\ndetection is a task to help decrease the number of harmful comments. With the\ndiversity in the hate speech created by users, it is necessary to interpret the\nhate speech besides detecting it. Hence, we propose a methodology to construct\na system for targeted hate speech detection from online streaming texts from\nsocial media. We first introduce the ViTHSD - a targeted hate speech detection\ndataset for Vietnamese Social Media Texts. The dataset contains 10K comments,\neach comment is labeled to specific targets with three levels: clean,\noffensive, and hate. There are 5 targets in the dataset, and each target is\nlabeled with the corresponding level manually by humans with strict annotation\nguidelines. The inter-annotator agreement obtained from the dataset is 0.45 by\nCohen's Kappa index, which is indicated as a moderate level. Then, we construct\na baseline for this task by combining the Bi-GRU-LSTM-CNN with the pre-trained\nlanguage model to leverage the power of text representation of BERTology.\nFinally, we suggest a methodology to integrate the baseline model for targeted\nhate speech detection into the online streaming system for practical\napplication in preventing hateful and offensive content on social media.", "published": "2024-04-30 04:16:55", "link": "http://arxiv.org/abs/2404.19252v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aspect and Opinion Term Extraction Using Graph Attention Network", "abstract": "In this work we investigate the capability of Graph Attention Network for\nextracting aspect and opinion terms. Aspect and opinion term extraction is\nposed as a token-level classification task akin to named entity recognition. We\nuse the dependency tree of the input query as additional feature in a Graph\nAttention Network along with the token and part-of-speech features. We show\nthat the dependency structure is a powerful feature that in the presence of a\nCRF layer substantially improves the performance and generates the best result\non the commonly used datasets from SemEval 2014, 2015 and 2016. We experiment\nwith additional layers like BiLSTM and Transformer in addition to the CRF\nlayer. We also show that our approach works well in the presence of multiple\naspects or sentiments in the same query and it is not necessary to modify the\ndependency tree based on a single aspect as was the original application for\nsentiment classification.", "published": "2024-04-30 04:53:59", "link": "http://arxiv.org/abs/2404.19260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Octopus v4: Graph of language models", "abstract": "Language models have been effective in a wide range of applications, yet the\nmost sophisticated models are often proprietary. For example, GPT-4 by OpenAI\nand various models by Anthropic are expensive and consume substantial energy.\nIn contrast, the open-source community has produced competitive models, like\nLlama3. Furthermore, niche-specific smaller language models, such as those\ntailored for legal, medical or financial tasks, have outperformed their\nproprietary counterparts. This paper introduces a novel approach that employs\n\\textit{functional tokens} to integrate \\textbf{multiple open-source models},\neach optimized for particular tasks. Our newly developed Octopus v4 model\nleverages \\textit{functional tokens} to intelligently direct user queries to\nthe most appropriate vertical model and reformat the query to achieve the best\nperformance. Octopus v4, an evolution of the Octopus v1, v2, and v3 models,\nexcels in selection and parameter understanding and reformatting. Additionally,\nwe explore the use of graph as a versatile data structure that effectively\ncoordinates multiple open-source models by harnessing the capabilities of the\nOctopus model and \\textit{functional tokens}. Use our open-sourced GitHub\n(\\url{https://www.nexa4ai.com/}) to try Octopus v4 models\n(\\url{https://huggingface.co/NexaAIDev/Octopus-v4}), and contrite to a larger\ngraph of language models. By activating models less than 10B parameters, we\nachieved SOTA MMLU score of 74.8 among the same level models.", "published": "2024-04-30 06:55:45", "link": "http://arxiv.org/abs/2404.19296v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Whisper understand Swiss German? An automatic, qualitative, and\n  human evaluation", "abstract": "Whisper is a state-of-the-art automatic speech recognition (ASR) model\n(Radford et al., 2022). Although Swiss German dialects are allegedly not part\nof Whisper's training data, preliminary experiments showed that Whisper can\ntranscribe Swiss German quite well, with the output being a speech translation\ninto Standard German. To gain a better understanding of Whisper's performance\non Swiss German, we systematically evaluate it using automatic, qualitative,\nand human evaluation. We test its performance on three existing test sets:\nSwissDial (Dogan-Sch\\\"onberger et al., 2021), STT4SG-350 (Pl\\\"uss et al.,\n2023), and Swiss Parliaments Corpus (Pl\\\"uss et al., 2021). In addition, we\ncreate a new test set for this work, based on short mock clinical interviews.\n  For automatic evaluation, we used word error rate (WER) and BLEU. In the\nqualitative analysis, we discuss Whisper's strengths and weaknesses and anylyze\nsome output examples. For the human evaluation, we conducted a survey with 28\nparticipants who were asked to evaluate Whisper's performance.\n  All of our evaluations suggest that Whisper is a viable ASR system for Swiss\nGerman, so long as the Standard German output is desired.", "published": "2024-04-30 07:29:40", "link": "http://arxiv.org/abs/2404.19310v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Orthographic Variation in Occitan's Dialects", "abstract": "Effectively normalizing textual data poses a considerable challenge,\nespecially for low-resource languages lacking standardized writing systems. In\nthis study, we fine-tuned a multilingual model with data from several Occitan\ndialects and conducted a series of experiments to assess the model's\nrepresentations of these dialects. For evaluation purposes, we compiled a\nparallel lexicon encompassing four Occitan dialects. Intrinsic evaluations of\nthe model's embeddings revealed that surface similarity between the dialects\nstrengthened representations. When the model was further fine-tuned for\npart-of-speech tagging and Universal Dependency parsing, its performance was\nrobust to dialectical variation, even when trained solely on part-of-speech\ndata from a single dialect. Our findings suggest that large multilingual models\nminimize the need for spelling normalization during pre-processing.", "published": "2024-04-30 07:33:51", "link": "http://arxiv.org/abs/2404.19315v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QLSC: A Query Latent Semantic Calibrator for Robust Extractive Question\n  Answering", "abstract": "Extractive Question Answering (EQA) in Machine Reading Comprehension (MRC)\noften faces the challenge of dealing with semantically identical but\nformat-variant inputs. Our work introduces a novel approach, called the ``Query\nLatent Semantic Calibrator (QLSC)'', designed as an auxiliary module for\nexisting MRC models. We propose a unique scaling strategy to capture latent\nsemantic center features of queries. These features are then seamlessly\nintegrated into traditional query and passage embeddings using an attention\nmechanism. By deepening the comprehension of the semantic queries-passage\nrelationship, our approach diminishes sensitivity to variations in text format\nand boosts the model's capability in pinpointing accurate answers. Experimental\nresults on robust Question-Answer datasets confirm that our approach\neffectively handles format-variant but semantically identical queries,\nhighlighting the effectiveness and adaptability of our proposed method.", "published": "2024-04-30 07:34:42", "link": "http://arxiv.org/abs/2404.19316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Distillation vs. Pretraining from Scratch under a Fixed\n  (Computation) Budget", "abstract": "Compared to standard language model (LM) pretraining (i.e., from scratch),\nKnowledge Distillation (KD) entails an additional forward pass through a\nteacher model that is typically substantially larger than the target student\nmodel. As such, KD in LM pretraining materially slows down throughput of\npretraining instances vis-a-vis pretraining from scratch. Scaling laws of LM\npretraining suggest that smaller models can close the gap to larger\ncounterparts if trained on more data (i.e., processing more tokens)-and under a\nfixed computation budget, smaller models are able be process more data than\nlarger models. We thus hypothesize that KD might, in fact, be suboptimal to\npretraining from scratch for obtaining smaller LMs, when appropriately\naccounting for the compute budget. To test this, we compare pretraining from\nscratch against several KD strategies for masked language modeling (MLM) in a\nfair experimental setup, with respect to amount of computation as well as\npretraining data. Downstream results on GLUE, however, do not confirm our\nhypothesis: while pretraining from scratch performs comparably to ordinary KD\nunder a fixed computation budget, more sophisticated KD strategies, namely\nTinyBERT (Jiao et al., 2020) and MiniLM (Wang et al., 2023), outperform it by a\nnotable margin. We further find that KD yields larger gains over pretraining\nfrom scratch when the data must be repeated under the fixed computation budget.", "published": "2024-04-30 07:40:35", "link": "http://arxiv.org/abs/2404.19319v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StablePT: Towards Stable Prompting for Few-shot Learning via Input\n  Separation", "abstract": "Large language models have shown their ability to become effective few-shot\nlearners with prompting, revolutionizing the paradigm of learning with data\nscarcity. However, this approach largely depends on the quality of prompt\ninitialization, and always exhibits large variability among different runs.\nSuch property makes prompt tuning highly unreliable and vulnerable to poorly\nconstructed prompts, which limits its extension to more real-world\napplications. To tackle this issue, we propose to treat the hard prompt and\nsoft prompt as separate inputs to mitigate noise brought by the prompt\ninitialization. Furthermore, we optimize soft prompts with contrastive learning\nfor utilizing class-aware information in the training process to maintain model\nperformance. Experimental results demonstrate that \\sysname outperforms\nstate-of-the-art methods by 6.97% in accuracy and reduces the standard\ndeviation by 1.92 on average. Furthermore, extensive experiments underscore its\nrobustness and stability across 8 datasets covering various tasks. Codes are\navailable at https://github.com/lccc0528/Stable/tree/main.", "published": "2024-04-30 08:01:49", "link": "http://arxiv.org/abs/2404.19335v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Expressivity and Speech Synthesis", "abstract": "Imbuing machines with the ability to talk has been a longtime pursuit of\nartificial intelligence (AI) research. From the very beginning, the community\nhas not only aimed to synthesise high-fidelity speech that accurately conveys\nthe semantic meaning of an utterance, but also to colour it with inflections\nthat cover the same range of affective expressions that humans are capable of.\nAfter many years of research, it appears that we are on the cusp of achieving\nthis when it comes to single, isolated utterances. This unveils an abundance of\npotential avenues to explore when it comes to combining these single utterances\nwith the aim of synthesising more complex, longer-term behaviours. In the\npresent chapter, we outline the methodological advances that brought us so far\nand sketch out the ongoing efforts to reach that coveted next level of\nartificial expressivity. We also discuss the societal implications coupled with\nrapidly advancing expressive speech synthesis (ESS) technology and highlight\nways to mitigate those risks and ensure the alignment of ESS capabilities with\nethical norms.", "published": "2024-04-30 08:47:24", "link": "http://arxiv.org/abs/2404.19363v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Navigating Brain Language Representations: A Comparative Analysis of\n  Neural Language Models and Psychologically Plausible Models", "abstract": "Neural language models, particularly large-scale ones, have been consistently\nproven to be most effective in predicting brain neural activity across a range\nof studies. However, previous research overlooked the comparison of these\nmodels with psychologically plausible ones. Moreover, evaluations were reliant\non limited, single-modality, and English cognitive datasets. To address these\nquestions, we conducted an analysis comparing encoding performance of various\nneural language models and psychologically plausible models. Our study utilized\nextensive multi-modal cognitive datasets, examining bilingual word and\ndiscourse levels. Surprisingly, our findings revealed that psychologically\nplausible models outperformed neural language models across diverse contexts,\nencompassing different modalities such as fMRI and eye-tracking, and spanning\nlanguages from English to Chinese. Among psychologically plausible models, the\none incorporating embodied information emerged as particularly exceptional.\nThis model demonstrated superior performance at both word and discourse levels,\nexhibiting robust prediction of brain activation across numerous regions in\nboth English and Chinese.", "published": "2024-04-30 08:48:07", "link": "http://arxiv.org/abs/2404.19364v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Countering Reward Over-optimization in LLM with Demonstration-Guided\n  Reinforcement Learning", "abstract": "While Reinforcement Learning (RL) has been proven essential for tuning large\nlanguage models (LLMs), it can lead to reward over-optimization (ROO). Existing\napproaches address ROO by adding KL regularization, requiring computationally\nexpensive hyperparameter tuning. Additionally, KL regularization focuses solely\non regularizing the language policy, neglecting a potential source of\nregularization: the reward function itself. Inspired by demonstration-guided\nRL, we here introduce the Reward Calibration from Demonstration (RCfD), which\nleverages human demonstrations and a reward model to recalibrate the reward\nobjective. Formally, given a prompt, the RCfD objective minimizes the distance\nbetween the demonstrations' and LLM's rewards rather than directly maximizing\nthe reward function. This objective shift avoids incentivizing the LLM to\nexploit the reward model and promotes more natural and diverse language\ngeneration. We show the effectiveness of RCfD on three language tasks, which\nachieves comparable performance to carefully tuned baselines while mitigating\nROO.", "published": "2024-04-30 09:57:21", "link": "http://arxiv.org/abs/2404.19409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S\u00f5najaht: Definition Embeddings and Semantic Search for Reverse\n  Dictionary Creation", "abstract": "We present an information retrieval based reverse dictionary system using\nmodern pre-trained language models and approximate nearest neighbors search\nalgorithms. The proposed approach is applied to an existing Estonian language\nlexicon resource, S\\~onaveeb (word web), with the purpose of enhancing and\nenriching it by introducing cross-lingual reverse dictionary functionality\npowered by semantic search.\n  The performance of the system is evaluated using both an existing labeled\nEnglish dataset of words and definitions that is extended to contain also\nEstonian and Russian translations, and a novel unlabeled evaluation approach\nthat extracts the evaluation data from the lexicon resource itself using\nsynonymy relations.\n  Evaluation results indicate that the information retrieval based semantic\nsearch approach without any model training is feasible, producing median rank\nof 1 in the monolingual setting and median rank of 2 in the cross-lingual\nsetting using the unlabeled evaluation approach, with models trained for\ncross-lingual retrieval and including Estonian in their training data showing\nsuperior performance in our particular task.", "published": "2024-04-30 10:21:14", "link": "http://arxiv.org/abs/2404.19430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Generative AI speak Nigerian-Pidgin?: Issues about\n  Representativeness and Bias for Multilingualism in LLMs", "abstract": "Nigeria is a multilingual country with 500+ languages. Naija is a Nigerian\nPidgin spoken by approximately 120M speakers and it is a mixed language (e.g.,\nEnglish, Portuguese, Yoruba, Hausa and Igbo). Although it has mainly been a\nspoken language until recently, there are some online platforms (e.g.,\nWikipedia), publishing in written Naija as well. West African Pidgin English\n(WAPE) is also spoken in Nigeria and it is used by BBC to broadcast news on the\ninternet to a wider audience not only in Nigeria but also in other West African\ncountries (e.g., Cameroon and Ghana). Through statistical analyses and Machine\nTranslation experiments, our paper shows that these two pidgin varieties do not\nrepresent each other (i.e., there are linguistic differences in word order and\nvocabulary) and Generative AI operates only based on WAPE. In other words,\nNaija is underrepresented in Generative AI, and it is hard to teach LLMs with\nfew examples. In addition to the statistical analyses, we also provide\nhistorical information on both pidgins as well as insights from the interviews\nconducted with volunteer Wikipedia contributors in Naija.", "published": "2024-04-30 10:45:40", "link": "http://arxiv.org/abs/2404.19442v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FactCheck Editor: Multilingual Text Editor with End-to-End fact-checking", "abstract": "We introduce 'FactCheck Editor', an advanced text editor designed to automate\nfact-checking and correct factual inaccuracies. Given the widespread issue of\nmisinformation, often a result of unintentional mistakes by content creators,\nour tool aims to address this challenge. It supports over 90 languages and\nutilizes transformer models to assist humans in the labor-intensive process of\nfact verification. This demonstration showcases a complete workflow that\ndetects text claims in need of verification, generates relevant search engine\nqueries, and retrieves appropriate documents from the web. It employs Natural\nLanguage Inference (NLI) to predict the veracity of claims and uses LLMs to\nsummarize the evidence and suggest textual revisions to correct any errors in\nthe text. Additionally, the effectiveness of models used in claim detection and\nveracity assessment is evaluated across multiple languages.", "published": "2024-04-30 11:55:20", "link": "http://arxiv.org/abs/2404.19482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Aware Machine Translation with Source Coreference Explanation", "abstract": "Despite significant improvements in enhancing the quality of translation,\ncontext-aware machine translation (MT) models underperform in many cases. One\nof the main reasons is that they fail to utilize the correct features from\ncontext when the context is too long or their models are overly complex. This\ncan lead to the explain-away effect, wherein the models only consider features\neasier to explain predictions, resulting in inaccurate translations. To address\nthis issue, we propose a model that explains the decisions made for translation\nby predicting coreference features in the input. We construct a model for input\ncoreference by exploiting contextual features from both the input and\ntranslation output representations on top of an existing MT model. We evaluate\nand analyze our method in the WMT document-level translation task of\nEnglish-German dataset, the English-Russian dataset, and the multilingual TED\ntalk dataset, demonstrating an improvement of over 1.0 BLEU score when compared\nwith other context-aware models.", "published": "2024-04-30 12:41:00", "link": "http://arxiv.org/abs/2404.19505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do Large Language Models Understand Conversational Implicature -- A case\n  study with a chinese sitcom", "abstract": "Understanding the non-literal meaning of an utterance is critical for large\nlanguage models (LLMs) to become human-like social communicators. In this work,\nwe introduce SwordsmanImp, the first Chinese multi-turn-dialogue-based dataset\naimed at conversational implicature, sourced from dialogues in the Chinese\nsitcom $\\textit{My Own Swordsman}$. It includes 200 carefully handcrafted\nquestions, all annotated on which Gricean maxims have been violated. We test\neight close-source and open-source LLMs under two tasks: a multiple-choice\nquestion task and an implicature explanation task. Our results show that GPT-4\nattains human-level accuracy (94%) on multiple-choice questions. CausalLM\ndemonstrates a 78.5% accuracy following GPT-4. Other models, including GPT-3.5\nand several open-source models, demonstrate a lower accuracy ranging from 20%\nto 60% on multiple-choice questions. Human raters were asked to rate the\nexplanation of the implicatures generated by LLMs on their reasonability, logic\nand fluency. While all models generate largely fluent and self-consistent text,\ntheir explanations score low on reasonability except for GPT-4, suggesting that\nmost LLMs cannot produce satisfactory explanations of the implicatures in the\nconversation. Moreover, we find LLMs' performance does not vary significantly\nby Gricean maxims, suggesting that LLMs do not seem to process implicatures\nderived from different maxims differently. Our data and code are available at\nhttps://github.com/sjtu-compling/llm-pragmatics.", "published": "2024-04-30 12:43:53", "link": "http://arxiv.org/abs/2404.19509v2", "categories": ["cs.CL", "J.5"], "primary_category": "cs.CL"}
{"title": "Extending Llama-3's Context Ten-Fold Overnight", "abstract": "We extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA\nfine-tuning. The entire training cycle is super efficient, which takes 8 hours\non one 8xA800 (80G) GPU machine. The resulted model exhibits superior\nperformances across a broad range of evaluation tasks, such as NIHS, topic\nretrieval, and long-context language understanding; meanwhile, it also well\npreserves the original capability over short contexts. The dramatic context\nextension is mainly attributed to merely 3.5K synthetic training samples\ngenerated by GPT-4 , which indicates the LLMs' inherent (yet largely\nunderestimated) potential to extend its original context length. In fact, the\ncontext length could be extended far beyond 80K with more computation\nresources. Therefore, the team will publicly release the entire resources\n(including data, model, data generation pipeline, training code) so as to\nfacilitate the future research from the community:\n\\url{https://github.com/FlagOpen/FlagEmbedding}.", "published": "2024-04-30 13:25:20", "link": "http://arxiv.org/abs/2404.19553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RepEval: Effective Text Evaluation with LLM Representation", "abstract": "The era of Large Language Models (LLMs) raises new demands for automatic\nevaluation metrics, which should be adaptable to various application scenarios\nwhile maintaining low cost and effectiveness. Traditional metrics for automatic\ntext evaluation are often tailored to specific scenarios, while LLM-based\nevaluation metrics are costly, requiring fine-tuning or rely heavily on the\ngeneration capabilities of LLMs. Besides, previous LLM-based metrics ignore the\nfact that, within the space of LLM representations, there exist direction\nvectors that indicate the estimation of text quality. To this end, we introduce\nRepEval, a metric that leverages the projection of LLM representations for\nevaluation. Through simple prompt modifications, RepEval can easily transition\nto various tasks, requiring only minimal sample pairs for direction vector\nconstruction. Results on fourteen datasets across two evaluation tasks\ndemonstrate the high effectiveness of our method, which exhibits a higher\ncorrelation with human judgments than previous methods, even in complex\nevaluation scenarios involving pair-wise selection under nuanced aspects. Our\nwork underscores the richness of information regarding text quality embedded\nwithin LLM representations, offering insights for the development of new\nmetrics.", "published": "2024-04-30 13:50:55", "link": "http://arxiv.org/abs/2404.19563v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Generation of High-Quality Medical Simulation Scenarios\n  Through Integration of Semi-Structured Data and Large Language Models", "abstract": "This study introduces a transformative framework for medical education by\nintegrating semi-structured data with Large Language Models (LLMs), primarily\nOpenAIs ChatGPT3.5, to automate the creation of medical simulation scenarios.\nTraditionally, developing these scenarios was a time-intensive process with\nlimited flexibility to meet diverse educational needs. The proposed approach\nutilizes AI to efficiently generate detailed, clinically relevant scenarios\nthat are tailored to specific educational objectives. This innovation has\nsignificantly reduced the time and resources required for scenario development,\nallowing for a broader variety of simulations. Preliminary feedback from\neducators and learners has shown enhanced engagement and improved knowledge\nacquisition, confirming the effectiveness of this AI-enhanced methodology in\nsimulation-based learning. The integration of structured data with LLMs not\nonly streamlines the creation process but also offers a scalable, dynamic\nsolution that could revolutionize medical training, highlighting the critical\nrole of AI in advancing educational outcomes and patient care standards.", "published": "2024-04-30 17:06:11", "link": "http://arxiv.org/abs/2404.19713v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ThangDLU at #SMM4H 2024: Encoder-decoder models for classifying text\n  data on social disorders in children and adolescents", "abstract": "This paper describes our participation in Task 3 and Task 5 of the #SMM4H\n(Social Media Mining for Health) 2024 Workshop, explicitly targeting the\nclassification challenges within tweet data. Task 3 is a multi-class\nclassification task centered on tweets discussing the impact of outdoor\nenvironments on symptoms of social anxiety. Task 5 involves a binary\nclassification task focusing on tweets reporting medical disorders in children.\nWe applied transfer learning from pre-trained encoder-decoder models such as\nBART-base and T5-small to identify the labels of a set of given tweets. We also\npresented some data augmentation methods to see their impact on the model\nperformance. Finally, the systems obtained the best F1 score of 0.627 in Task 3\nand the best F1 score of 0.841 in Task 5.", "published": "2024-04-30 17:06:20", "link": "http://arxiv.org/abs/2404.19714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better & Faster Large Language Models via Multi-token Prediction", "abstract": "Large language models such as GPT and Llama are trained with a next-token\nprediction loss. In this work, we suggest that training language models to\npredict multiple future tokens at once results in higher sample efficiency.\nMore specifically, at each position in the training corpus, we ask the model to\npredict the following n tokens using n independent output heads, operating on\ntop of a shared model trunk. Considering multi-token prediction as an auxiliary\ntraining task, we measure improved downstream capabilities with no overhead in\ntraining time for both code and natural language models. The method is\nincreasingly useful for larger model sizes, and keeps its appeal when training\nfor multiple epochs. Gains are especially pronounced on generative benchmarks\nlike coding, where our models consistently outperform strong baselines by\nseveral percentage points. Our 13B parameter models solves 12 % more problems\non HumanEval and 17 % more on MBPP than comparable next-token models.\nExperiments on small algorithmic tasks demonstrate that multi-token prediction\nis favorable for the development of induction heads and algorithmic reasoning\ncapabilities. As an additional benefit, models trained with 4-token prediction\nare up to 3 times faster at inference, even with large batch sizes.", "published": "2024-04-30 17:33:57", "link": "http://arxiv.org/abs/2404.19737v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HistNERo: Historical Named Entity Recognition for the Romanian Language", "abstract": "This work introduces HistNERo, the first Romanian corpus for Named Entity\nRecognition (NER) in historical newspapers. The dataset contains 323k tokens of\ntext, covering more than half of the 19th century (i.e., 1817) until the late\npart of the 20th century (i.e., 1990). Eight native Romanian speakers annotated\nthe dataset with five named entities. The samples belong to one of the\nfollowing four historical regions of Romania, namely Bessarabia, Moldavia,\nTransylvania, and Wallachia. We employed this proposed dataset to perform\nseveral experiments for NER using Romanian pre-trained language models. Our\nresults show that the best model achieved a strict F1-score of 55.69%. Also, by\nreducing the discrepancies between regions through a novel domain adaption\ntechnique, we improved the performance on this corpus to a strict F1-score of\n66.80%, representing an absolute gain of more than 10%.", "published": "2024-04-30 19:05:22", "link": "http://arxiv.org/abs/2405.00155v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In-Context Learning with Long-Context Models: An In-Depth Exploration", "abstract": "As model context lengths continue to increase, the number of demonstrations\nthat can be provided in-context approaches the size of entire training\ndatasets. We study the behavior of in-context learning (ICL) at this extreme\nscale on multiple datasets and models. We show that, for many datasets with\nlarge label spaces, performance continues to increase with thousands of\ndemonstrations. We contrast this with example retrieval and finetuning: example\nretrieval shows excellent performance at low context lengths but has diminished\ngains with more demonstrations; finetuning is more data hungry than ICL but can\nexceed long-context ICL performance with additional data. We use the ICL\nsetting to study several properties of both in-context learning and\nlong-context models. We show that long-context ICL is less sensitive to random\ninput shuffling than short-context ICL, that grouping of same-label examples\nnegatively impacts performance, and that the performance boosts do not arise\nfrom cumulative gain from encoding many examples together. We conclude that\nlong-context ICL can be an effective tool, and may not require long-context for\nencoding the demonstration set at all.", "published": "2024-04-30 21:06:52", "link": "http://arxiv.org/abs/2405.00200v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Primer on the Inner Workings of Transformer-based Language Models", "abstract": "The rapid progress of research aimed at interpreting the inner workings of\nadvanced language models has highlighted a need for contextualizing the\ninsights gained from years of work in this area. This primer provides a concise\ntechnical introduction to the current techniques used to interpret the inner\nworkings of Transformer-based language models, focusing on the generative\ndecoder-only architecture. We conclude by presenting a comprehensive overview\nof the known internal mechanisms implemented by these models, uncovering\nconnections across popular approaches and active research directions in this\narea.", "published": "2024-04-30 21:20:17", "link": "http://arxiv.org/abs/2405.00208v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Disease Detection from Social Media Text via Self-Augmentation\n  and Contrastive Learning", "abstract": "Detecting diseases from social media has diverse applications, such as public\nhealth monitoring and disease spread detection. While language models (LMs)\nhave shown promising performance in this domain, there remains ongoing research\naimed at refining their discriminating representations. In this paper, we\npropose a novel method that integrates Contrastive Learning (CL) with language\nmodeling to address this challenge. Our approach introduces a self-augmentation\nmethod, wherein hidden representations of the model are augmented with their\nown representations. This method comprises two branches: the first branch, a\ntraditional LM, learns features specific to the given data, while the second\nbranch incorporates augmented representations from the first branch to\nencourage generalization. CL further refines these representations by pulling\npairs of original and augmented versions closer while pushing other samples\naway. We evaluate our method on three NLP datasets encompassing binary,\nmulti-label, and multi-class classification tasks involving social media posts\nrelated to various diseases. Our approach demonstrates notable improvements\nover traditional fine-tuning methods, achieving up to a 2.48% increase in\nF1-score compared to baseline approaches and a 2.1% enhancement over\nstate-of-the-art methods.", "published": "2024-04-30 15:24:54", "link": "http://arxiv.org/abs/2405.01597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mix of Experts Language Model for Named Entity Recognition", "abstract": "Named Entity Recognition (NER) is an essential steppingstone in the field of\nnatural language processing. Although promising performance has been achieved\nby various distantly supervised models, we argue that distant supervision\ninevitably introduces incomplete and noisy annotations, which may mislead the\nmodel training process. To address this issue, we propose a robust NER model\nnamed BOND-MoE based on Mixture of Experts (MoE). Instead of relying on a\nsingle model for NER prediction, multiple models are trained and ensembled\nunder the Expectation-Maximization (EM) framework, so that noisy supervision\ncan be dramatically alleviated. In addition, we introduce a fair assignment\nmodule to balance the document-model assignment process. Extensive experiments\non real-world datasets show that the proposed method achieves state-of-the-art\nperformance compared with other distantly supervised NER.", "published": "2024-04-30 01:41:03", "link": "http://arxiv.org/abs/2404.19192v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Transcrib3D: 3D Referring Expression Resolution through Large Language\n  Models", "abstract": "If robots are to work effectively alongside people, they must be able to\ninterpret natural language references to objects in their 3D environment.\nUnderstanding 3D referring expressions is challenging -- it requires the\nability to both parse the 3D structure of the scene and correctly ground\nfree-form language in the presence of distraction and clutter. We introduce\nTranscrib3D, an approach that brings together 3D detection methods and the\nemergent reasoning capabilities of large language models (LLMs). Transcrib3D\nuses text as the unifying medium, which allows us to sidestep the need to learn\nshared representations connecting multi-modal inputs, which would require\nmassive amounts of annotated 3D data. As a demonstration of its effectiveness,\nTranscrib3D achieves state-of-the-art results on 3D reference resolution\nbenchmarks, with a great leap in performance from previous multi-modality\nbaselines. To improve upon zero-shot performance and facilitate local\ndeployment on edge computers and robots, we propose self-correction for\nfine-tuning that trains smaller models, resulting in performance close to that\nof large models. We show that our method enables a real robot to perform\npick-and-place tasks given queries that contain challenging referring\nexpressions. Project site is at https://ripl.github.io/Transcrib3D.", "published": "2024-04-30 02:48:20", "link": "http://arxiv.org/abs/2404.19221v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "GRAMMAR: Grounded and Modular Methodology for Assessment of\n  Closed-Domain Retrieval-Augmented Language Model", "abstract": "Retrieval-Augmented Generation (RAG) systems are widely used across various\nindustries for querying closed-domain and in-house knowledge bases. However,\nevaluating these systems presents significant challenges due to the private\nnature of closed-domain data and a scarcity of queries with verifiable ground\ntruths. Moreover, there is a lack of analytical methods to diagnose problematic\nmodules and identify types of failure, such as those caused by knowledge\ndeficits or issues with robustness. To address these challenges, we introduce\nGRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation\nframework comprising a grounded data generation process and an evaluation\nprotocol that effectively pinpoints defective modules. Our validation\nexperiments reveal that GRAMMAR provides a reliable approach for identifying\nvulnerable modules and supports hypothesis testing for textual form\nvulnerabilities. An open-source tool accompanying this framework is available\nin our GitHub repository (see https://github.com/xinzhel/grammar), allowing for\neasy reproduction of our results and enabling reliable and modular evaluation\nin closed-domain settings.", "published": "2024-04-30 03:29:30", "link": "http://arxiv.org/abs/2404.19232v7", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning", "abstract": "Adapting Large Language Models (LLMs) to new tasks through fine-tuning has\nbeen made more efficient by the introduction of Parameter-Efficient Fine-Tuning\n(PEFT) techniques, such as LoRA. However, these methods often underperform\ncompared to full fine-tuning, particularly in scenarios involving complex\ndatasets. This issue becomes even more pronounced in complex domains,\nhighlighting the need for improved PEFT approaches that can achieve better\nperformance. Through a series of experiments, we have uncovered two critical\ninsights that shed light on the training and parameter inefficiency of LoRA.\nBuilding on these insights, we have developed HydraLoRA, a LoRA framework with\nan asymmetric structure that eliminates the need for domain expertise. Our\nexperiments demonstrate that HydraLoRA outperforms other PEFT approaches, even\nthose that rely on domain knowledge during the training and inference phases.", "published": "2024-04-30 04:01:09", "link": "http://arxiv.org/abs/2404.19245v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Suvach -- Generated Hindi QA benchmark", "abstract": "Current evaluation benchmarks for question answering (QA) in Indic languages\noften rely on machine translation of existing English datasets. This approach\nsuffers from bias and inaccuracies inherent in machine translation, leading to\ndatasets that may not reflect the true capabilities of EQA models for Indic\nlanguages. This paper proposes a new benchmark specifically designed for\nevaluating Hindi EQA models and discusses the methodology to do the same for\nany task. This method leverages large language models (LLMs) to generate a\nhigh-quality dataset in an extractive setting, ensuring its relevance for the\ntarget language. We believe this new resource will foster advancements in Hindi\nNLP research by providing a more accurate and reliable evaluation tool.", "published": "2024-04-30 04:19:17", "link": "http://arxiv.org/abs/2404.19254v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Revisiting N-Gram Models: Their Impact in Modern Neural Networks for\n  Handwritten Text Recognition", "abstract": "In recent advances in automatic text recognition (ATR), deep neural networks\nhave demonstrated the ability to implicitly capture language statistics,\npotentially reducing the need for traditional language models. This study\ndirectly addresses whether explicit language models, specifically n-gram\nmodels, still contribute to the performance of state-of-the-art deep learning\narchitectures in the field of handwriting recognition. We evaluate two\nprominent neural network architectures, PyLaia and DAN, with and without the\nintegration of explicit n-gram language models. Our experiments on three\ndatasets - IAM, RIMES, and NorHand v2 - at both line and page level,\ninvestigate optimal parameters for n-gram models, including their order,\nweight, smoothing methods and tokenization level. The results show that\nincorporating character or subword n-gram models significantly improves the\nperformance of ATR models on all datasets, challenging the notion that deep\nlearning models alone are sufficient for optimal performance. In particular,\nthe combination of DAN with a character language model outperforms current\nbenchmarks, confirming the value of hybrid approaches in modern document\nanalysis systems.", "published": "2024-04-30 07:37:48", "link": "http://arxiv.org/abs/2404.19317v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Enhancing Trust in LLM-Generated Code Summaries with Calibrated\n  Confidence Scores", "abstract": "A good summary can often be very useful during program comprehension. While a\nbrief, fluent, and relevant summary can be helpful, it does require significant\nhuman effort to produce. Often, good summaries are unavailable in software\nprojects, thus making maintenance more difficult. There has been a considerable\nbody of research into automated AI-based methods, using Large Language models\n(LLMs), to generate summaries of code; there also has been quite a bit work on\nways to measure the performance of such summarization methods, with special\nattention paid to how closely these AI-generated summaries resemble a summary a\nhuman might have produced. Measures such as BERTScore and BLEU have been\nsuggested and evaluated with human-subject studies.\n  However, LLM-produced summaries can be too long, irrelevant, etc: generally,\ntoo dissimilar to what a human might say. Given an LLM-produced code summary,\nhow can we judge if a summary is good enough? Given some input source code, and\nan LLM-generated summary, existing approaches can help judge brevity, fluency\nand relevance; however, it's difficult to gauge whether an LLM-produced summary\nsufficiently resembles what a human might produce, without a \"golden\"\nhuman-produced summary to compare against. We study this resemblance question\nas a calibration problem: given just the summary from an LLM, can we compute a\nconfidence measure, that provides a reliable indication of whether the summary\nsufficiently resembles what a human would have produced in this situation? We\nexamine this question using several LLMs, for several languages, and in several\ndifferent settings. Our investigation suggests approaches to provide reliable\npredictions of the likelihood that an LLM-generated summary would sufficiently\nresemble a summary a human might write for the same code.", "published": "2024-04-30 07:38:08", "link": "http://arxiv.org/abs/2404.19318v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Computational Approaches for Integrating out Subjectivity in Cognate\n  Synonym Selection", "abstract": "Working with cognate data involves handling synonyms, that is, multiple words\nthat describe the same concept in a language. In the early days of language\nphylogenetics it was recommended to select one synonym only. However, as we\nshow here, binary character matrices, which are used as input for computational\nmethods, do allow for representing the entire dataset including all synonyms.\nHere we address the question how one can and if one should include all synonyms\nor whether it is preferable to select synonyms a priori. To this end, we\nperform maximum likelihood tree inferences with the widely used RAxML-NG tool\nand show that it yields plausible trees when all synonyms are used as input.\nFurthermore, we show that a priori synonym selection can yield topologically\nsubstantially different trees and we therefore advise against doing so. To\nrepresent cognate data including all synonyms, we introduce two types of\ncharacter matrices beyond the standard binary ones: probabilistic binary and\nprobabilistic multi-valued character matrices. We further show that it is\ndataset-dependent for which character matrix type the inferred RAxML-NG tree is\ntopologically closest to the gold standard. We also make available a Python\ninterface for generating all of the above character matrix types for cognate\ndata provided in CLDF format.", "published": "2024-04-30 07:52:26", "link": "http://arxiv.org/abs/2404.19328v2", "categories": ["cs.CL", "q-bio.PE"], "primary_category": "cs.CL"}
{"title": "Evaluating Lexicon Incorporation for Depression Symptom Estimation", "abstract": "This paper explores the impact of incorporating sentiment, emotion, and\ndomain-specific lexicons into a transformer-based model for depression symptom\nestimation. Lexicon information is added by marking the words in the input\ntranscripts of patient-therapist conversations as well as in social media\nposts. Overall results show that the introduction of external knowledge within\npre-trained language models can be beneficial for prediction performance, while\ndifferent lexicons show distinct behaviours depending on the targeted task.\nAdditionally, new state-of-the-art results are obtained for the estimation of\ndepression level over patient-therapist interviews.", "published": "2024-04-30 08:41:06", "link": "http://arxiv.org/abs/2404.19359v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Telugu Proficiency in Large Language Models_ A Comparative\n  Analysis of ChatGPT and Gemini", "abstract": "The growing prominence of large language models (LLMs) necessitates the\nexploration of their capabilities beyond English. This research investigates\nthe Telugu language proficiency of ChatGPT and Gemini, two leading LLMs.\nThrough a designed set of 20 questions encompassing greetings, grammar,\nvocabulary, common phrases, task completion, and situational reasoning, the\nstudy delves into their strengths and weaknesses in handling Telugu. The\nanalysis aims to identify the LLM that demonstrates a deeper understanding of\nTelugu grammatical structures, possesses a broader vocabulary, and exhibits\nsuperior performance in tasks like writing and reasoning. By comparing their\nability to comprehend and use everyday Telugu expressions, the research sheds\nlight on their suitability for real-world language interaction. Furthermore,\nthe evaluation of adaptability and reasoning capabilities provides insights\ninto how each LLM leverages Telugu to respond to dynamic situations. This\ncomparative analysis contributes to the ongoing discussion on multilingual\ncapabilities in AI and paves the way for future research in developing LLMs\nthat can seamlessly integrate with Telugu-speaking communities.", "published": "2024-04-30 08:55:01", "link": "http://arxiv.org/abs/2404.19369v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Can Large Language Models put 2 and 2 together? Probing for Entailed\n  Arithmetical Relationships", "abstract": "Two major areas of interest in the era of Large Language Models regard\nquestions of what do LLMs know, and if and how they may be able to reason (or\nrather, approximately reason). Since to date these lines of work progressed\nlargely in parallel (with notable exceptions), we are interested in\ninvestigating the intersection: probing for reasoning about the implicitly-held\nknowledge. Suspecting the performance to be lacking in this area, we use a very\nsimple set-up of comparisons between cardinalities associated with elements of\nvarious subjects (e.g. the number of legs a bird has versus the number of\nwheels on a tricycle). We empirically demonstrate that although LLMs make\nsteady progress in knowledge acquisition and (pseudo)reasoning with each new\nGPT release, their capabilities are limited to statistical inference only. It\nis difficult to argue that pure statistical learning can cope with the\ncombinatorial explosion inherent in many commonsense reasoning tasks,\nespecially once arithmetical notions are involved. Further, we argue that\nbigger is not always better and chasing purely statistical improvements is\nflawed at the core, since it only exacerbates the dangerous conflation of the\nproduction of correct answers with genuine reasoning ability.", "published": "2024-04-30 10:28:04", "link": "http://arxiv.org/abs/2404.19432v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Safe Training with Sensitive In-domain Data: Leveraging Data\n  Fragmentation To Mitigate Linkage Attacks", "abstract": "Current text generation models are trained using real data which can\npotentially contain sensitive information, such as confidential patient\ninformation and the like. Under certain conditions output of the training data\nwhich they have memorised can be triggered, exposing sensitive data. To\nmitigate against this risk we propose a safer alternative which sees fragmented\ndata in the form of domain-specific short phrases randomly grouped together\nshared instead of full texts. Thus, text fragments that could re-identify an\nindividual cannot be reproduced by the model in one sequence, giving\nsignificant protection against linkage attacks. We fine-tune several\nstate-of-the-art LLMs using meaningful syntactic chunks to explore their\nutility. In particular, we fine-tune BERT-based models to predict two\ncardiovascular diagnoses. Our results demonstrate the capacity of LLMs to\nbenefit from the pre-trained knowledge and deliver classification results when\nfine-tuned with fragmented data comparable to fine-tuning with full training\ndata.", "published": "2024-04-30 12:09:55", "link": "http://arxiv.org/abs/2404.19486v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural\n  Language Processing", "abstract": "Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey.", "published": "2024-04-30 13:14:51", "link": "http://arxiv.org/abs/2404.19543v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TuBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with\n  Instruction Tuning", "abstract": "The implications of backdoor attacks on English-centric large language models\n(LLMs) have been widely examined - such attacks can be achieved by embedding\nmalicious behaviors during training and activated under specific conditions\nthat trigger malicious outputs. Despite the increasing support for multilingual\ncapabilities in open-source and proprietary LLMs, the impact of backdoor\nattacks on these systems remains largely under-explored. Our research focuses\non cross-lingual backdoor attacks against multilingual LLMs, particularly\ninvestigating how poisoning the instruction-tuning data for one or two\nlanguages can affect the outputs for languages whose instruction-tuning data\nwere not poisoned. Despite its simplicity, our empirical analysis reveals that\nour method exhibits remarkable efficacy in models like mT5 and GPT-4o, with\nhigh attack success rates, surpassing 90% in more than 7 out of 12 languages\nacross various scenarios. Our findings also indicate that more powerful models\nshow increased susceptibility to transferable cross-lingual backdoor attacks,\nwhich also applies to LLMs predominantly pre-trained on English data, such as\nLlama2, Llama3, and Gemma. Moreover, our experiments demonstrate 1) High\nTransferability: the backdoor mechanism operates successfully in cross-lingual\nresponse scenarios across 26 languages, achieving an average attack success\nrate of 99%, and 2) Robustness: the proposed attack remains effective even\nafter defenses are applied. These findings expose critical security\nvulnerabilities in multilingual LLMs and highlight the urgent need for more\nrobust, targeted defense strategies to address the unique challenges posed by\ncross-lingual backdoor transfer.", "published": "2024-04-30 14:43:57", "link": "http://arxiv.org/abs/2404.19597v3", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "When to Retrieve: Teaching LLMs to Utilize Information Retrieval\n  Effectively", "abstract": "In this paper, we demonstrate how Large Language Models (LLMs) can\neffectively learn to use an off-the-shelf information retrieval (IR) system\nspecifically when additional context is required to answer a given question.\nGiven the performance of IR systems, the optimal strategy for question\nanswering does not always entail external information retrieval; rather, it\noften involves leveraging the parametric memory of the LLM itself. Prior\nresearch has identified this phenomenon in the PopQA dataset, wherein the most\npopular questions are effectively addressed using the LLM's parametric memory,\nwhile less popular ones require IR system usage. Following this, we propose a\ntailored training approach for LLMs, leveraging existing open-domain question\nanswering datasets. Here, LLMs are trained to generate a special token, <RET>,\nwhen they do not know the answer to a question. Our evaluation of the Adaptive\nRetrieval LLM (Adapt-LLM) on the PopQA dataset showcases improvements over the\nsame LLM under three configurations: (i) retrieving information for all the\nquestions, (ii) using always the parametric memory of the LLM, and (iii) using\na popularity threshold to decide when to use a retriever. Through our analysis,\nwe demonstrate that Adapt-LLM is able to generate the <RET> token when it\ndetermines that it does not know how to answer a question, indicating the need\nfor IR, while it achieves notably high accuracy levels when it chooses to rely\nonly on its parametric memory.", "published": "2024-04-30 16:52:55", "link": "http://arxiv.org/abs/2404.19705v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "PANGeA: Procedural Artificial Narrative using Generative AI for\n  Turn-Based Video Games", "abstract": "This research introduces Procedural Artificial Narrative using Generative AI\n(PANGeA), a structured approach for leveraging large language models (LLMs),\nguided by a game designer's high-level criteria, to generate narrative content\nfor turn-based role-playing video games (RPGs). Distinct from prior\napplications of LLMs used for video game design, PANGeA innovates by not only\ngenerating game level data (which includes, but is not limited to, setting, key\nitems, and non-playable characters (NPCs)), but by also fostering dynamic,\nfree-form interactions between the player and the environment that align with\nthe procedural game narrative. The NPCs generated by PANGeA are\npersonality-biased and express traits from the Big 5 Personality Model in their\ngenerated responses. PANGeA addresses challenges behind ingesting free-form\ntext input, which can prompt LLM responses beyond the scope of the game\nnarrative. A novel validation system that uses the LLM's intelligence evaluates\ntext input and aligns generated responses with the unfolding narrative. Making\nthese interactions possible, PANGeA is supported by a server that hosts a\ncustom memory system that supplies context for augmenting generated responses\nthus aligning them with the procedural narrative. For its broad application,\nthe server has a REST interface enabling any game engine to integrate directly\nwith PANGeA, as well as an LLM interface adaptable with local or private LLMs.\nPANGeA's ability to foster dynamic narrative generation by aligning responses\nwith the procedural narrative is demonstrated through an empirical study and\nablation test of two versions of a demo game. These are, a custom,\nbrowser-based GPT and a Unity demo. As the results show, PANGeA holds potential\nto assist game designers in using LLMs to generate narrative-consistent content\neven when provided varied and unpredictable, free-form text input.", "published": "2024-04-30 17:11:54", "link": "http://arxiv.org/abs/2404.19721v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Iterative Reasoning Preference Optimization", "abstract": "Iterative preference optimization methods have recently been shown to perform\nwell for general instruction tuning tasks, but typically make little\nimprovement on reasoning tasks (Yuan et al., 2024, Chen et al., 2024). In this\nwork we develop an iterative approach that optimizes the preference between\ncompeting generated Chain-of-Thought (CoT) candidates by optimizing for winning\nvs. losing reasoning steps that lead to the correct answer. We train using a\nmodified DPO loss (Rafailov et al., 2023) with an additional negative\nlog-likelihood term, which we find to be crucial. We show reasoning improves\nacross repeated iterations of this scheme. While only relying on examples in\nthe training set, our approach results in increasing accuracy on GSM8K, MATH,\nand ARC-Challenge for Llama-2-70B-Chat, outperforming other Llama-2-based\nmodels not relying on additionally sourced datasets. For example, we see a\nlarge improvement from 55.6% to 81.6% on GSM8K and an accuracy of 88.7% with\nmajority voting out of 32 samples.", "published": "2024-04-30 17:28:05", "link": "http://arxiv.org/abs/2404.19733v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph Neural Network Approach to Semantic Type Detection in Tables", "abstract": "This study addresses the challenge of detecting semantic column types in\nrelational tables, a key task in many real-world applications. While language\nmodels like BERT have improved prediction accuracy, their token input\nconstraints limit the simultaneous processing of intra-table and inter-table\ninformation. We propose a novel approach using Graph Neural Networks (GNNs) to\nmodel intra-table dependencies, allowing language models to focus on\ninter-table information. Our proposed method not only outperforms existing\nstate-of-the-art algorithms but also offers novel insights into the utility and\nfunctionality of various GNN types for semantic type detection. The code is\navailable at https://github.com/hoseinzadeehsan/GAIT", "published": "2024-04-30 18:17:44", "link": "http://arxiv.org/abs/2405.00123v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Transforming Dutch: Debiasing Dutch Coreference Resolution Systems for\n  Non-binary Pronouns", "abstract": "Gender-neutral pronouns are increasingly being introduced across Western\nlanguages. Recent evaluations have however demonstrated that English NLP\nsystems are unable to correctly process gender-neutral pronouns, with the risk\nof erasing and misgendering non-binary individuals. This paper examines a Dutch\ncoreference resolution system's performance on gender-neutral pronouns,\nspecifically hen and die. In Dutch, these pronouns were only introduced in\n2016, compared to the longstanding existence of singular they in English. We\nadditionally compare two debiasing techniques for coreference resolution\nsystems in non-binary contexts: Counterfactual Data Augmentation (CDA) and\ndelexicalisation. Moreover, because pronoun performance can be hard to\ninterpret from a general evaluation metric like LEA, we introduce an innovative\nevaluation metric, the pronoun score, which directly represents the portion of\ncorrectly processed pronouns. Our results reveal diminished performance on\ngender-neutral pronouns compared to gendered counterparts. Nevertheless,\nalthough delexicalisation fails to yield improvements, CDA substantially\nreduces the performance gap between gendered and gender-neutral pronouns. We\nfurther show that CDA remains effective in low-resource settings, in which a\nlimited set of debiasing documents is used. This efficacy extends to previously\nunseen neopronouns, which are currently infrequently used but may gain\npopularity in the future, underscoring the viability of effective debiasing\nwith minimal resources and low computational costs.", "published": "2024-04-30 18:31:19", "link": "http://arxiv.org/abs/2405.00134v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards a Search Engine for Machines: Unified Ranking for Multiple\n  Retrieval-Augmented Large Language Models", "abstract": "This paper introduces uRAG--a framework with a unified retrieval engine that\nserves multiple downstream retrieval-augmented generation (RAG) systems. Each\nRAG system consumes the retrieval results for a unique purpose, such as\nopen-domain question answering, fact verification, entity linking, and relation\nextraction. We introduce a generic training guideline that standardizes the\ncommunication between the search engine and the downstream RAG systems that\nengage in optimizing the retrieval model. This lays the groundwork for us to\nbuild a large-scale experimentation ecosystem consisting of 18 RAG systems that\nengage in training and 18 unknown RAG systems that use the uRAG as the new\nusers of the search engine. Using this experimentation ecosystem, we answer a\nnumber of fundamental research questions that improve our understanding of\npromises and challenges in developing search engines for machines.", "published": "2024-04-30 19:51:37", "link": "http://arxiv.org/abs/2405.00175v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained\n  Large Language Models", "abstract": "Full fine-tuning is a popular approach to adapt Transformer-based pre-trained\nlarge language models to a specific downstream task. However, the substantial\nrequirements for computational power and storage have discouraged its\nwidespread use. Moreover, increasing evidence of catastrophic forgetting and\noverparameterization in the Transformer architecture has motivated researchers\nto seek more efficient fine-tuning (PEFT) methods. Commonly known\nparameter-efficient fine-tuning methods like LoRA and BitFit are typically\napplied across all layers of the model. We propose a PEFT method, called\nStratified Progressive Adaptation Fine-tuning (SPAFIT), based on the\nlocalization of different types of linguistic knowledge to specific layers of\nthe model. Our experiments, conducted on nine tasks from the GLUE benchmark,\nshow that our proposed SPAFIT method outperforms other PEFT methods while\nfine-tuning only a fraction of the parameters adjusted by other methods.", "published": "2024-04-30 21:07:32", "link": "http://arxiv.org/abs/2405.00201v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "General Purpose Verification for Chain of Thought Prompting", "abstract": "Many of the recent capabilities demonstrated by Large Language Models (LLMs)\narise primarily from their ability to exploit contextual information. In this\npaper, we explore ways to improve reasoning capabilities of LLMs through (1)\nexploration of different chains of thought and (2) validation of the individual\nsteps of the reasoning process. We propose three general principles that a\nmodel should adhere to while reasoning: (i) Relevance, (ii) Mathematical\nAccuracy, and (iii) Logical Consistency. We apply these constraints to the\nreasoning steps generated by the LLM to improve the accuracy of the final\ngeneration. The constraints are applied in the form of verifiers: the model\nitself is asked to verify if the generated steps satisfy each constraint. To\nfurther steer the generations towards high-quality solutions, we use the\nperplexity of the reasoning steps as an additional verifier. We evaluate our\nmethod on 4 distinct types of reasoning tasks, spanning a total of 9 different\ndatasets. Experiments show that our method is always better than vanilla\ngeneration, and, in 6 out of the 9 datasets, it is better than best-of N\nsampling which samples N reasoning chains and picks the lowest perplexity\ngeneration.", "published": "2024-04-30 21:15:17", "link": "http://arxiv.org/abs/2405.00204v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CodeHalu: Investigating Code Hallucinations in LLMs via Execution-based\n  Verification", "abstract": "Large Language Models (LLMs) have made significant progress in code\ngeneration, offering developers groundbreaking automated programming support.\nHowever, LLMs often generate code that is syntactically correct and even\nsemantically plausible, but may not execute as expected or fulfill specified\nrequirements. This phenomenon of hallucinations in the code domain has not been\nsystematically explored. To advance the community's understanding and research\non this issue, we introduce the concept of code hallucinations and propose a\nclassification method for code hallucination based on execution verification.\nWe categorize code hallucinations into four main types: mapping, naming,\nresource, and logic hallucinations, with each category further divided into\ndifferent subcategories to understand and address the unique challenges faced\nby LLMs in code generation with finer granularity. Additionally, we present a\ndynamic detection algorithm called CodeHalu designed to detect and quantify\ncode hallucinations. We also introduce the CodeHaluEval benchmark, which\nincludes 8,883 samples from 699 tasks, to systematically and quantitatively\nevaluate code hallucinations. By evaluating 17 popular LLMs using this\nbenchmark, we reveal significant differences in their accuracy and reliability\nin code generation, offering detailed insights for further improving the code\ngeneration capabilities of LLMs. The CodeHalu benchmark and code are publicly\navailable at https://github.com/yuchen814/CodeHalu.", "published": "2024-04-30 23:56:38", "link": "http://arxiv.org/abs/2405.00253v4", "categories": ["cs.CL", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Multi-hop Question Answering over Knowledge Graphs using Large Language\n  Models", "abstract": "Knowledge graphs (KGs) are large datasets with specific structures\nrepresenting large knowledge bases (KB) where each node represents a key entity\nand relations amongst them are typed edges. Natural language queries formed to\nextract information from a KB entail starting from specific nodes and reasoning\nover multiple edges of the corresponding KG to arrive at the correct set of\nanswer nodes. Traditional approaches of question answering on KG are based on\n(a) semantic parsing (SP), where a logical form (e.g., S-expression, SPARQL\nquery, etc.) is generated using node and edge embeddings and then reasoning\nover these representations or tuning language models to generate the final\nanswer directly, or (b) information-retrieval based that works by extracting\nentities and relations sequentially. In this work, we evaluate the capability\nof (LLMs) to answer questions over KG that involve multiple hops. We show that\ndepending upon the size and nature of the KG we need different approaches to\nextract and feed the relevant information to an LLM since every LLM comes with\na fixed context window. We evaluate our approach on six KGs with and without\nthe availability of example-specific sub-graphs and show that both the IR and\nSP-based methods can be adopted by LLMs resulting in an extremely competitive\nperformance.", "published": "2024-04-30 03:31:03", "link": "http://arxiv.org/abs/2404.19234v1", "categories": ["cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.AI"}
{"title": "Large Language Model Informed Patent Image Retrieval", "abstract": "In patent prosecution, image-based retrieval systems for identifying\nsimilarities between current patent images and prior art are pivotal to ensure\nthe novelty and non-obviousness of patent applications. Despite their growing\npopularity in recent years, existing attempts, while effective at recognizing\nimages within the same patent, fail to deliver practical value due to their\nlimited generalizability in retrieving relevant prior art. Moreover, this task\ninherently involves the challenges posed by the abstract visual features of\npatent images, the skewed distribution of image classifications, and the\nsemantic information of image descriptions. Therefore, we propose a\nlanguage-informed, distribution-aware multimodal approach to patent image\nfeature learning, which enriches the semantic understanding of patent image by\nintegrating Large Language Models and improves the performance of\nunderrepresented classes with our proposed distribution-aware contrastive\nlosses. Extensive experiments on DeepPatent2 dataset show that our proposed\nmethod achieves state-of-the-art or comparable performance in image-based\npatent retrieval with mAP +53.3%, Recall@10 +41.8%, and MRR@10 +51.9%.\nFurthermore, through an in-depth user analysis, we explore our model in aiding\npatent professionals in their image retrieval efforts, highlighting the model's\nreal-world applicability and effectiveness.", "published": "2024-04-30 08:45:16", "link": "http://arxiv.org/abs/2404.19360v1", "categories": ["cs.CV", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
{"title": "More Compute Is What You Need", "abstract": "Large language model pre-training has become increasingly expensive, with\nmost practitioners relying on scaling laws to allocate compute budgets for\nmodel size and training tokens, commonly referred to as Compute-Optimal or\nChinchilla Optimal. In this paper, we hypothesize a new scaling law that\nsuggests model performance depends mostly on the amount of compute spent for\ntransformer-based models, independent of the specific allocation to model size\nand dataset size. Using this unified scaling law, we predict that (a) for\ninference efficiency, training should prioritize smaller model sizes and larger\ntraining datasets, and (b) assuming the exhaustion of available web datasets,\nscaling the model size might be the only way to further improve model\nperformance.", "published": "2024-04-30 12:05:48", "link": "http://arxiv.org/abs/2404.19484v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Naturally Supervised 3D Visual Grounding with Language-Regularized\n  Concept Learners", "abstract": "3D visual grounding is a challenging task that often requires direct and\ndense supervision, notably the semantic label for each object in the scene. In\nthis paper, we instead study the naturally supervised setting that learns from\nonly 3D scene and QA pairs, where prior works underperform. We propose the\nLanguage-Regularized Concept Learner (LARC), which uses constraints from\nlanguage as regularization to significantly improve the accuracy of\nneuro-symbolic concept learners in the naturally supervised setting. Our\napproach is based on two core insights: the first is that language constraints\n(e.g., a word's relation to another) can serve as effective regularization for\nstructured representations in neuro-symbolic models; the second is that we can\nquery large language models to distill such constraints from language\nproperties. We show that LARC improves performance of prior works in naturally\nsupervised 3D visual grounding, and demonstrates a wide range of 3D visual\nreasoning capabilities-from zero-shot composition, to data efficiency and\ntransferability. Our method represents a promising step towards regularizing\nstructured visual reasoning frameworks with language-based priors, for learning\nin settings without dense supervision.", "published": "2024-04-30 16:44:18", "link": "http://arxiv.org/abs/2404.19696v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Harmonic LLMs are Trustworthy", "abstract": "We introduce an intuitive method to test the robustness (stability and\nexplainability) of any black-box LLM in real-time via its local deviation from\nharmoniticity, denoted as $\\gamma$. To the best of our knowledge this is the\nfirst completely model-agnostic and unsupervised method of measuring the\nrobustness of any given response from an LLM, based upon the model itself\nconforming to a purely mathematical standard. To show general application and\nimmediacy of results, we measure $\\gamma$ in 10 popular LLMs (ChatGPT,\nClaude-2.1, Claude3.0, GPT-4, GPT-4o, Smaug-72B, Mixtral-8x7B, Llama2-7B,\nMistral-7B and MPT-7B) across thousands of queries in three objective domains:\nWebQA, ProgrammingQA, and TruthfulQA. Across all models and domains tested,\nhuman annotation confirms that $\\gamma \\to 0$ indicates trustworthiness, and\nconversely searching higher values of $\\gamma$ easily exposes examples of\nhallucination, a fact that enables efficient adversarial prompt generation\nthrough stochastic gradient ascent in $\\gamma$. The low-$\\gamma$ leaders among\nthe models in the respective domains are GPT-4o, GPT-4, and Smaug-72B,\nproviding evidence that mid-size open-source models can win out against large\ncommercial models.", "published": "2024-04-30 17:00:32", "link": "http://arxiv.org/abs/2404.19708v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "DOCCI: Descriptions of Connected and Contrasting Images", "abstract": "Vision-language datasets are vital for both text-to-image (T2I) and\nimage-to-text (I2T) research. However, current datasets lack descriptions with\nfine-grained detail that would allow for richer associations to be learned by\nmodels. To fill the gap, we introduce Descriptions of Connected and Contrasting\nImages (DOCCI), a dataset with long, human-annotated English descriptions for\n15k images that were taken, curated and donated by a single researcher intent\non capturing key challenges such as spatial relations, counting, text\nrendering, world knowledge, and more. We instruct human annotators to create\ncomprehensive descriptions for each image; these average 136 words in length\nand are crafted to clearly distinguish each image from those that are related\nor similar. Each description is highly compositional and typically encompasses\nmultiple challenges. Through both quantitative and qualitative analyses, we\ndemonstrate that DOCCI serves as an effective training resource for\nimage-to-text generation -- a PaLI 5B model finetuned on DOCCI shows equal or\nsuperior results compared to highly-performant larger models like LLaVA-1.5 7B\nand InstructBLIP 7B. Furthermore, we show that DOCCI is a useful testbed for\ntext-to-image generation, highlighting the limitations of current text-to-image\nmodels in capturing long descriptions and fine details.", "published": "2024-04-30 17:56:24", "link": "http://arxiv.org/abs/2404.19753v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Creative Beam Search: LLM-as-a-Judge For Improving Response Generation", "abstract": "Large language models are revolutionizing several areas, including artificial\ncreativity. However, the process of generation in machines profoundly diverges\nfrom that observed in humans. In particular, machine generation is\ncharacterized by a lack of intentionality and an underlying creative process.\nWe propose a method called Creative Beam Search that uses Diverse Beam Search\nand LLM-as-a-Judge to perform response generation and response validation. The\nresults of a qualitative experiment show how our approach can provide better\noutput than standard sampling techniques. We also show that the response\nvalidation step is a necessary complement to the response generation step.", "published": "2024-04-30 18:00:02", "link": "http://arxiv.org/abs/2405.00099v4", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Graphical Reasoning: LLM-based Semi-Open Relation Extraction", "abstract": "This paper presents a comprehensive exploration of relation extraction\nutilizing advanced language models, specifically Chain of Thought (CoT) and\nGraphical Reasoning (GRE) techniques. We demonstrate how leveraging in-context\nlearning with GPT-3.5 can significantly enhance the extraction process,\nparticularly through detailed example-based reasoning. Additionally, we\nintroduce a novel graphical reasoning approach that dissects relation\nextraction into sequential sub-tasks, improving precision and adaptability in\nprocessing complex relational data. Our experiments, conducted on multiple\ndatasets, including manually annotated data, show considerable improvements in\nperformance metrics, underscoring the effectiveness of our methodologies.", "published": "2024-04-30 21:41:53", "link": "http://arxiv.org/abs/2405.00216v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modeling Caption Diversity in Contrastive Vision-Language Pretraining", "abstract": "There are a thousand ways to caption an image. Contrastive Language\nPretraining (CLIP) on the other hand, works by mapping an image and its caption\nto a single vector -- limiting how well CLIP-like models can represent the\ndiverse ways to describe an image. In this work, we introduce Llip, Latent\nLanguage Image Pretraining, which models the diversity of captions that could\nmatch an image. Llip's vision encoder outputs a set of visual features that are\nmixed into a final representation by conditioning on information derived from\nthe text. We show that Llip outperforms non-contextualized baselines like CLIP\nand SigLIP on a variety of tasks even with large-scale encoders. Llip improves\nzero-shot classification by an average of 2.9% zero-shot classification\nbenchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot\ntop-1 accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by\n1.4%. We also demonstrate improvement on zero-shot retrieval on MS-COCO by\n6.0%. We provide a comprehensive analysis of the components introduced by the\nmethod and demonstrate that Llip leads to richer visual representations.", "published": "2024-04-30 01:19:18", "link": "http://arxiv.org/abs/2405.00740v4", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Large Language Model Agent for Fake News Detection", "abstract": "In the current digital era, the rapid spread of misinformation on online\nplatforms presents significant challenges to societal well-being, public trust,\nand democratic processes, influencing critical decision making and public\nopinion. To address these challenges, there is a growing need for automated\nfake news detection mechanisms. Pre-trained large language models (LLMs) have\ndemonstrated exceptional capabilities across various natural language\nprocessing (NLP) tasks, prompting exploration into their potential for\nverifying news claims. Instead of employing LLMs in a non-agentic way, where\nLLMs generate responses based on direct prompts in a single shot, our work\nintroduces FactAgent, an agentic approach of utilizing LLMs for fake news\ndetection. FactAgent enables LLMs to emulate human expert behavior in verifying\nnews claims without any model training, following a structured workflow. This\nworkflow breaks down the complex task of news veracity checking into multiple\nsub-steps, where LLMs complete simple tasks using their internal knowledge or\nexternal tools. At the final step of the workflow, LLMs integrate all findings\nthroughout the workflow to determine the news claim's veracity. Compared to\nmanual human verification, FactAgent offers enhanced efficiency. Experimental\nstudies demonstrate the effectiveness of FactAgent in verifying claims without\nthe need for any training process. Moreover, FactAgent provides transparent\nexplanations at each step of the workflow and during final decision-making,\noffering insights into the reasoning process of fake news detection for end\nusers. FactAgent is highly adaptable, allowing for straightforward updates to\nits tools that LLMs can leverage within the workflow, as well as updates to the\nworkflow itself using domain knowledge. This adaptability enables FactAgent's\napplication to news verification across various domains.", "published": "2024-04-30 06:55:27", "link": "http://arxiv.org/abs/2405.01593v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CONTUNER: Singing Voice Beautifying with Pitch and Expressiveness\n  Condition", "abstract": "Singing voice beautifying is a novel task that has application value in\npeople's daily life, aiming to correct the pitch of the singing voice and\nimprove the expressiveness without changing the original timbre and content.\nExisting methods rely on paired data or only concentrate on the correction of\npitch. However, professional songs and amateur songs from the same person are\nhard to obtain, and singing voice beautifying doesn't only contain pitch\ncorrection but other aspects like emotion and rhythm. Since we propose a fast\nand high-fidelity singing voice beautifying system called ConTuner, a diffusion\nmodel combined with the modified condition to generate the beautified\nMel-spectrogram, where the modified condition is composed of optimized pitch\nand expressiveness. For pitch correction, we establish a mapping relationship\nfrom MIDI, spectrum envelope to pitch. To make amateur singing more expressive,\nwe propose the expressiveness enhancer in the latent space to convert amateur\nvocal tone to professional. ConTuner achieves a satisfactory beautification\neffect on both Mandarin and English songs. Ablation study demonstrates that the\nexpressiveness enhancer and generator-based accelerate method in ConTuner are\neffective.", "published": "2024-04-30 01:27:12", "link": "http://arxiv.org/abs/2404.19187v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EAD-VC: Enhancing Speech Auto-Disentanglement for Voice Conversion with\n  IFUB Estimator and Joint Text-Guided Consistent Learning", "abstract": "Using unsupervised learning to disentangle speech into content, rhythm,\npitch, and timbre for voice conversion has become a hot research topic.\nExisting works generally take into account disentangling speech components\nthrough human-crafted bottleneck features which can not achieve sufficient\ninformation disentangling, while pitch and rhythm may still be mixed together.\nThere is a risk of information overlap in the disentangling process which\nresults in less speech naturalness. To overcome such limits, we propose a\ntwo-stage model to disentangle speech representations in a self-supervised\nmanner without a human-crafted bottleneck design, which uses the Mutual\nInformation (MI) with the designed upper bound estimator (IFUB) to separate\noverlapping information between speech components. Moreover, we design a Joint\nText-Guided Consistent (TGC) module to guide the extraction of speech content\nand eliminate timbre leakage issues. Experiments show that our model can\nachieve a better performance than the baseline, regarding disentanglement\neffectiveness, speech naturalness, and similarity. Audio samples can be found\nat https://largeaudiomodel.com/eadvc.", "published": "2024-04-30 02:23:37", "link": "http://arxiv.org/abs/2404.19212v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "EfficientASR: Speech Recognition Network Compression via Attention\n  Redundancy and Chunk-Level FFN Optimization", "abstract": "In recent years, Transformer networks have shown remarkable performance in\nspeech recognition tasks. However, their deployment poses challenges due to\nhigh computational and storage resource requirements. To address this issue, a\nlightweight model called EfficientASR is proposed in this paper, aiming to\nenhance the versatility of Transformer models. EfficientASR employs two primary\nmodules: Shared Residual Multi-Head Attention (SRMHA) and Chunk-Level\nFeedforward Networks (CFFN). The SRMHA module effectively reduces redundant\ncomputations in the network, while the CFFN module captures spatial knowledge\nand reduces the number of parameters. The effectiveness of the EfficientASR\nmodel is validated on two public datasets, namely Aishell-1 and HKUST.\nExperimental results demonstrate a 36% reduction in parameters compared to the\nbaseline Transformer network, along with improvements of 0.3% and 0.2% in\nCharacter Error Rate (CER) on the Aishell-1 and HKUST datasets, respectively.", "published": "2024-04-30 02:30:05", "link": "http://arxiv.org/abs/2404.19214v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep low-latency joint speech transmission and enhancement over a\n  gaussian channel", "abstract": "Ensuring intelligible speech communication for hearing assistive devices in\nlow-latency scenarios presents significant challenges in terms of speech\nenhancement, coding and transmission. In this paper, we propose novel solutions\nfor low-latency joint speech transmission and enhancement, leveraging deep\nneural networks (DNNs). Our approach integrates two state-of-the-art DNN\narchitectures for low-latency speech enhancement and low-latency analog joint\nsource-channel-based transmission, creating a combined low-latency system and\njointly training both systems in an end-to-end approach. Due to the\ncomputational demands of the enhancement system, this order is suitable when\nhigh computational power is unavailable in the decoder, like hearing assistive\ndevices. The proposed system enables the configuration of total latency,\nachieving high performance even at latencies as low as 3 ms, which is typically\nchallenging to attain. The simulation results provide compelling evidence that\na joint enhancement and transmission system is superior to a simple\nconcatenation system in diverse settings, encompassing various wireless channel\nconditions, latencies, and background noise scenarios.", "published": "2024-04-30 09:06:32", "link": "http://arxiv.org/abs/2404.19375v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized\n  Transformers", "abstract": "Neural speech codecs aim to compress input signals into minimal bits while\nmaintaining content quality in a low-latency manner. However, existing neural\ncodecs often trade model complexity for reconstruction performance. These\ncodecs primarily use convolutional blocks for feature transformation, which are\nnot inherently suited for capturing the local redundancies in speech signals.\nTo compensate, they require either adversarial discriminators or a large number\nof model parameters to enhance audio quality. In response to these challenges,\nwe introduce the Efficient Speech Codec (ESC), a lightweight,\nparameter-efficient speech codec based on a cross-scale residual vector\nquantization scheme and transformers. Our model employs mirrored hierarchical\nwindow transformer blocks and performs step-wise decoding from coarse-to-fine\nfeature representations. To enhance bitrate efficiency, we propose a novel\ncombination of vector quantization techniques along with a pre-training\nparadigm. Extensive experiments demonstrate that ESC can achieve high-fidelity\nspeech reconstruction with significantly lower model complexity, making it a\npromising alternative to existing convolutional audio codecs.", "published": "2024-04-30 10:44:33", "link": "http://arxiv.org/abs/2404.19441v3", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Attention-Constrained Inference for Robust Decoder-Only Text-to-Speech", "abstract": "Recent popular decoder-only text-to-speech models are known for their ability\nof generating natural-sounding speech. However, such models sometimes suffer\nfrom word skipping and repeating due to the lack of explicit monotonic\nalignment constraints. In this paper, we notice from the attention maps that\nsome particular attention heads of the decoder-only model indicate the\nalignments between speech and text. We call the attention maps of those heads\nAlignment-Emerged Attention Maps (AEAMs). Based on this discovery, we propose a\nnovel inference method without altering the training process, named\nAttention-Constrained Inference (ACI), to facilitate monotonic synthesis. It\nfirst identifies AEAMs using the Attention Sweeping algorithm and then applies\nconstraining masks on AEAMs. Our experimental results on decoder-only TTS model\nVALL-E show that the WER of synthesized speech is reduced by up to 20.5%\nrelatively with ACI while the naturalness and speaker similarity are\ncomparable.", "published": "2024-04-30 17:17:07", "link": "http://arxiv.org/abs/2404.19723v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SemiPL: A Semi-supervised Method for Event Sound Source Localization", "abstract": "In recent years, Event Sound Source Localization has been widely applied in\nvarious fields. Recent works typically relying on the contrastive learning\nframework show impressive performance. However, all work is based on large\nrelatively simple datasets. It's also crucial to understand and analyze human\nbehaviors (actions and interactions of people), voices, and sounds in chaotic\nevents in many applications, e.g., crowd management, and emergency response\nservices. In this paper, we apply the existing model to a more complex dataset,\nexplore the influence of parameters on the model, and propose a semi-supervised\nimprovement method SemiPL. With the increase in data quantity and the influence\nof label quality, self-supervised learning will be an unstoppable trend. The\nexperiment shows that the parameter adjustment will positively affect the\nexisting model. In particular, SSPL achieved an improvement of 12.2% cIoU and\n0.56% AUC in Chaotic World compared to the results provided. The code is\navailable at: https://github.com/ly245422/SSPL", "published": "2024-04-30 15:13:57", "link": "http://arxiv.org/abs/2404.19615v1", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Who is Authentic Speaker", "abstract": "Voice conversion (VC) using deep learning technologies can now generate high\nquality one-to-many voices and thus has been used in some practical application\nfields, such as entertainment and healthcare. However, voice conversion can\npose potential social issues when manipulated voices are employed for deceptive\npurposes. Moreover, it is a big challenge to find who are real speakers from\nthe converted voices as the acoustic characteristics of source speakers are\nchanged greatly. In this paper we attempt to explore the feasibility of\nidentifying authentic speakers from converted voices. This study is conducted\nwith the assumption that certain information from the source speakers persists,\neven when their voices undergo conversion into different target voices.\nTherefore our experiments are geared towards recognising the source speakers\ngiven the converted voices, which are generated by using FragmentVC on the\nrandomly paired utterances from source and target speakers. To improve the\nrobustness against converted voices, our recognition model is constructed by\nusing hierarchical vector of locally aggregated descriptors (VLAD) in deep\nneural networks. The authentic speaker recognition system is mainly tested in\ntwo aspects, including the impact of quality of converted voices and the\nvariations of VLAD. The dataset used in this work is VCTK corpus, where source\nand target speakers are randomly paired. The results obtained on the converted\nutterances show promising performances in recognising authentic speakers from\nconverted voices.", "published": "2024-04-30 23:41:00", "link": "http://arxiv.org/abs/2405.00248v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fake it to make it: Using synthetic data to remedy the data shortage in\n  joint multimodal speech-and-gesture synthesis", "abstract": "Although humans engaged in face-to-face conversation simultaneously\ncommunicate both verbally and non-verbally, methods for joint and unified\nsynthesis of speech audio and co-speech 3D gesture motion from text are a new\nand emerging field. These technologies hold great promise for more human-like,\nefficient, expressive, and robust synthetic communication, but are currently\nheld back by the lack of suitably large datasets, as existing methods are\ntrained on parallel data from all constituent modalities. Inspired by\nstudent-teacher methods, we propose a straightforward solution to the data\nshortage, by simply synthesising additional training material. Specifically, we\nuse unimodal synthesis models trained on large datasets to create multimodal\n(but synthetic) parallel training data, and then pre-train a joint synthesis\nmodel on that material. In addition, we propose a new synthesis architecture\nthat adds better and more controllable prosody modelling to the\nstate-of-the-art method in the field. Our results confirm that pre-training on\nlarge amounts of synthetic data improves the quality of both the speech and the\nmotion synthesised by the multimodal model, with the proposed architecture\nyielding further benefits when pre-trained on the synthetic data. See\nhttps://shivammehta25.github.io/MAGI/ for example output.", "published": "2024-04-30 15:22:19", "link": "http://arxiv.org/abs/2404.19622v1", "categories": ["cs.HC", "cs.CV", "cs.GR", "cs.SD", "eess.AS", "68T07 (Primary), 68T42 (Secondary)", "I.2.7; I.2.6; H.5"], "primary_category": "cs.HC"}
{"title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General\n  Sound", "abstract": "Large language models (LLMs) have significantly advanced audio processing\nthrough audio codecs that convert audio into discrete tokens, enabling the\napplication of language modelling techniques to audio data. However,\ntraditional codecs often operate at high bitrates or within narrow domains such\nas speech and lack the semantic clues required for efficient language\nmodelling. Addressing these challenges, we introduce SemantiCodec, a novel\ncodec designed to compress audio into fewer than a hundred tokens per second\nacross diverse audio types, including speech, general sound, and music, without\ncompromising quality. SemantiCodec features a dual-encoder architecture: a\nsemantic encoder using a self-supervised pre-trained Audio Masked Autoencoder\n(AudioMAE), discretized using k-means clustering on extensive audio data, and\nan acoustic encoder to capture the remaining details. The semantic and acoustic\nencoder outputs are used to reconstruct audio via a diffusion-model-based\ndecoder. SemantiCodec is presented in three variants with token rates of 25,\n50, and 100 per second, supporting a range of ultra-low bit rates between 0.31\nkbps and 1.40 kbps. Experimental results demonstrate that SemantiCodec\nsignificantly outperforms the state-of-the-art Descript codec on reconstruction\nquality. Our results also suggest that SemantiCodec contains significantly\nricher semantic information than all evaluated state-of-the-art audio codecs,\neven at significantly lower bitrates. Our code and demos are available at\nhttps://haoheliu.github.io/SemantiCodec/.", "published": "2024-04-30 22:51:36", "link": "http://arxiv.org/abs/2405.00233v2", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
