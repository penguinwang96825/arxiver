{"title": "Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility\n  of Vector Differences for Lexical Relation Learning", "abstract": "Recent work on word embeddings has shown that simple vector subtraction over\npre-trained embeddings is surprisingly effective at capturing different lexical\nrelations, despite lacking explicit supervision. Prior work has evaluated this\nintriguing result using a word analogy prediction formulation and hand-selected\nrelations, but the generality of the finding over a broader range of lexical\nrelation types and different learning settings has not been evaluated. In this\npaper, we carry out such an evaluation in two learning settings: (1) spectral\nclustering to induce word relations, and (2) supervised learning to classify\nvector differences into relation types. We find that word embeddings capture a\nsurprising amount of information, and that, under suitable supervised training,\nvector subtraction generalises well to a broad range of relations, including\nover unseen lexical items.", "published": "2015-09-05 11:23:44", "link": "http://arxiv.org/abs/1509.01692v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A commentary on \"The now-or-never bottleneck: a fundamental constraint\n  on language\", by Christiansen and Chater (2016)", "abstract": "In a recent article, Christiansen and Chater (2016) present a fundamental\nconstraint on language, i.e. a now-or-never bottleneck that arises from our\nfleeting memory, and explore its implications, e.g., chunk-and-pass processing,\noutlining a framework that promises to unify different areas of research. Here\nwe explore additional support for this constraint and suggest further\nconnections from quantitative linguistics and information theory.", "published": "2015-09-05 17:52:16", "link": "http://arxiv.org/abs/1509.01722v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
