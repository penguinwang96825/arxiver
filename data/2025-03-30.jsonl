{"title": "Distill-C: Enhanced NL2SQL via Distilled Customization with LLMs", "abstract": "The growing adoption of large language models (LLMs) in business applications\nhas amplified interest in Natural Language to SQL (NL2SQL) solutions, in which\nthere is competing demand for high performance and efficiency. Domain- and\ncustomer-specific requirements further complicate the problem. To address this\nconundrum, we introduce Distill-C, a distilled customization framework tailored\nfor NL2SQL tasks. Distill-C utilizes large teacher LLMs to produce high-quality\nsynthetic data through a robust and scalable pipeline. Finetuning smaller and\nopen-source LLMs on this synthesized data enables them to rival or outperform\nteacher models an order of magnitude larger. Evaluated on multiple challenging\nbenchmarks, Distill-C achieves an average improvement of 36% in execution\naccuracy compared to the base models from three distinct LLM families.\nAdditionally, on three internal customer benchmarks, Distill-C demonstrates a\n22.6% performance improvement over the base models. Our results demonstrate\nthat Distill-C is an effective, high-performing and generalizable approach for\ndeploying lightweight yet powerful NL2SQL models, delivering exceptional\naccuracies while maintaining low computational cost.", "published": "2025-03-30 23:23:21", "link": "http://arxiv.org/abs/2504.00048v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models", "abstract": "In recent years, social media has emerged as a primary channel for users to\npromptly share feedback and issues during disasters and emergencies, playing a\nkey role in crisis management. While significant progress has been made in\ncollecting and analyzing social media content, there remains a pressing need to\nenhance the automation, aggregation, and customization of this data to deliver\nactionable insights tailored to diverse stakeholders, including the press,\npolice, EMS, and firefighters. This effort is essential for improving the\ncoordination of activities such as relief efforts, resource distribution, and\nmedia communication. This paper presents a methodology that leverages the\ncapabilities of LLMs to enhance disaster response and management. Our approach\ncombines classification techniques with generative AI to bridge the gap between\nraw user feedback and stakeholder-specific reports. Social media posts shared\nduring catastrophic events are analyzed with a focus on user-reported issues,\nservice interruptions, and encountered challenges. We employ full-spectrum\nLLMs, using analytical models like BERT for precise, multi-dimensional\nclassification of content type, sentiment, emotion, geolocation, and topic.\nGenerative models such as ChatGPT are then used to produce human-readable,\ninformative reports tailored to distinct audiences, synthesizing insights\nderived from detailed classifications. We compare standard approaches, which\nanalyze posts directly using prompts in ChatGPT, to our advanced method, which\nincorporates multi-dimensional classification, sub-event selection, and\ntailored report generation. Our methodology demonstrates superior performance\nin both quantitative metrics, such as text coherence scores and latent\nrepresentations, and qualitative assessments by automated tools and field\nexperts, delivering precise insights for diverse disaster response\nstakeholders.", "published": "2025-03-30 22:53:52", "link": "http://arxiv.org/abs/2504.00046v1", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Measuring Online Hate on 4chan using Pre-trained Deep Learning Models", "abstract": "Online hate speech can harmfully impact individuals and groups, specifically\non non-moderated platforms such as 4chan where users can post anonymous\ncontent. This work focuses on analysing and measuring the prevalence of online\nhate on 4chan's politically incorrect board (/pol/) using state-of-the-art\nNatural Language Processing (NLP) models, specifically transformer-based models\nsuch as RoBERTa and Detoxify. By leveraging these advanced models, we provide\nan in-depth analysis of hate speech dynamics and quantify the extent of online\nhate non-moderated platforms. The study advances understanding through\nmulti-class classification of hate speech (racism, sexism, religion, etc.),\nwhile also incorporating the classification of toxic content (e.g., identity\nattacks and threats) and a further topic modelling analysis. The results show\nthat 11.20% of this dataset is identified as containing hate in different\ncategories. These evaluations show that online hate is manifested in various\nforms, confirming the complicated and volatile nature of detection in the wild.", "published": "2025-03-30 22:47:11", "link": "http://arxiv.org/abs/2504.00045v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Dynamic hashtag recommendation in social media with trend shift detection and adaptation", "abstract": "The widespread use of social media platforms results in the generation of\nvast amounts of user-generated content, which requires efficient methods for\ncategorization and search. Hashtag recommendation systems have emerged as a\ncrucial tool for automatically suggesting relevant hashtags and improving\ncontent discoverability. However, existing static models struggle to adapt to\nthe highly dynamic and real-time nature of social media conversations, where\nnew hashtags emerge and existing ones undergo semantic shifts. To address these\nchallenges, this paper presents H-ADAPTS (Hashtag recommendAtion by Detecting\nand adAPting to Trend Shifts), a BERT-based hashtag recommendation methodology\nthat can detect and adapt to shifts in the main trends and topics underlying\nsocial media conversation. Our approach introduces a trend-aware detection\nmechanism to identify changes in hashtag usage, triggering efficient model\nadaptation on a (small) set of recent posts. The framework leverages Apache\nStorm for real-time stream processing, enabling scalable and fault-tolerant\nanalysis of high-velocity social data. Experimental results on two real-world\ncase studies, including the COVID-19 pandemic and the 2020 US presidential\nelection, demonstrate the ability to maintain high recommendation accuracy by\nadapting to emerging trends. Our methodology significantly outperforms existing\nsolutions, ensuring timely and relevant hashtag recommendations in dynamic\nenvironments.", "published": "2025-03-30 22:04:14", "link": "http://arxiv.org/abs/2504.00044v1", "categories": ["cs.SI", "cs.CL", "cs.DC", "cs.NE"], "primary_category": "cs.SI"}
{"title": "CrossWordBench: Evaluating the Reasoning Capabilities of LLMs and LVLMs with Controllable Puzzle Generation", "abstract": "Existing reasoning evaluation frameworks for Large Language Models (LLMs) and\nLarge Vision-Language Models (LVLMs) predominantly either assess text-based\nreasoning or vision-language understanding capabilities, with limited dynamic\ninterplay between textual and visual constraints. To address this limitation,\nwe introduce CrossWordBench, a benchmark designed to evaluate the reasoning\ncapabilities of both LLMs and LVLMs through the medium of crossword puzzles-a\ntask requiring multimodal adherence to semantic constraints from text-based\nclues and intersectional constraints from visual grid structures.\nCrossWordBench leverages a controllable puzzle generation framework that\nproduces puzzles in multiple formats (text and image) and offers different\nevaluation strategies ranging from direct puzzle solving to interactive modes.\nOur extensive evaluation of over 20 models reveals that reasoning LLMs\noutperform non-reasoning models substantially by effectively leveraging\ncrossing-letter constraints. We further demonstrate that LVLMs struggle with\nthe task, showing a strong correlation between their puzzle-solving performance\nand grid-parsing accuracy. Our findings offer insights into the limitations of\nthe reasoning capabilities of current LLMs and LVLMs, and provide an effective\napproach for creating multimodal constrained tasks for future evaluations.", "published": "2025-03-30 20:03:36", "link": "http://arxiv.org/abs/2504.00043v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "The Impact of Code-switched Synthetic Data Quality is Task Dependent: Insights from MT and ASR", "abstract": "Code-switching, the act of alternating between languages, emerged as a\nprevalent global phenomenon that needs to be addressed for building\nuser-friendly language technologies. A main bottleneck in this pursuit is data\nscarcity, motivating research in the direction of code-switched data\naugmentation. However, current literature lacks comprehensive studies that\nenable us to understand the relation between the quality of synthetic data and\nimprovements on NLP tasks. We extend previous research conducted in this\ndirection on machine translation (MT) with results on automatic speech\nrecognition (ASR) and cascaded speech translation (ST) to test generalizability\nof findings. Our experiments involve a wide range of augmentation techniques,\ncovering lexical replacements, linguistic theories, and back-translation. Based\non the results of MT, ASR, and ST, we draw conclusions and insights regarding\nthe efficacy of various augmentation techniques and the impact of quality on\nperformance.", "published": "2025-03-30 19:55:28", "link": "http://arxiv.org/abs/2503.23576v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond the Reported Cutoff: Where Large Language Models Fall Short on Financial Knowledge", "abstract": "Large Language Models (LLMs) are frequently utilized as sources of knowledge\nfor question-answering. While it is known that LLMs may lack access to\nreal-time data or newer data produced after the model's cutoff date, it is less\nclear how their knowledge spans across historical information. In this study,\nwe assess the breadth of LLMs' knowledge using financial data of U.S. publicly\ntraded companies by evaluating more than 197k questions and comparing model\nresponses to factual data. We further explore the impact of company\ncharacteristics, such as size, retail investment, institutional attention, and\nreadability of financial filings, on the accuracy of knowledge represented in\nLLMs. Our results reveal that LLMs are less informed about past financial\nperformance, but they display a stronger awareness of larger companies and more\nrecent information. Interestingly, at the same time, our analysis also reveals\nthat LLMs are more likely to hallucinate for larger companies, especially for\ndata from more recent years. We will make the code, prompts, and model outputs\npublic upon the publication of the work.", "published": "2025-03-30 19:43:20", "link": "http://arxiv.org/abs/2504.00042v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When LLM Therapists Become Salespeople: Evaluating Large Language Models for Ethical Motivational Interviewing", "abstract": "Large language models (LLMs) have been actively applied in the mental health\nfield. Recent research shows the promise of LLMs in applying psychotherapy,\nespecially motivational interviewing (MI). However, there is a lack of studies\ninvestigating how language models understand MI ethics. Given the risks that\nmalicious actors can use language models to apply MI for unethical purposes, it\nis important to evaluate their capability of differentiating ethical and\nunethical MI practices. Thus, this study investigates the ethical awareness of\nLLMs in MI with multiple experiments. Our findings show that LLMs have a\nmoderate to strong level of knowledge in MI. However, their ethical standards\nare not aligned with the MI spirit, as they generated unethical responses and\nperformed poorly in detecting unethical responses. We proposed a Chain-of-Ethic\nprompt to mitigate those risks and improve safety. Finally, our proposed\nstrategy effectively improved ethical MI response generation and detection\nperformance. These findings highlight the need for safety evaluations and\nguidelines for building ethical LLM-powered psychotherapy.", "published": "2025-03-30 19:20:32", "link": "http://arxiv.org/abs/2503.23566v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantum Methods for Managing Ambiguity in Natural Language Processing", "abstract": "The Categorical Compositional Distributional (DisCoCat) framework models\nmeaning in natural language using the mathematical framework of quantum theory,\nexpressed as formal diagrams. DisCoCat diagrams can be associated with tensor\nnetworks and quantum circuits. DisCoCat diagrams have been connected to density\nmatrices in various contexts in Quantum Natural Language Processing (QNLP).\nPrevious use of density matrices in QNLP entails modelling ambiguous words as\nprobability distributions over more basic words (the word \\texttt{queen}, e.g.,\nmight mean the reigning queen or the chess piece). In this article, we\ninvestigate using probability distributions over processes to account for\nsyntactic ambiguity in sentences. The meanings of these sentences are\nrepresented by density matrices. We show how to create probability\ndistributions on quantum circuits that represent the meanings of sentences and\nexplain how this approach generalises tasks from the literature. We conduct an\nexperiment to validate the proposed theory.", "published": "2025-03-30 19:10:37", "link": "http://arxiv.org/abs/2504.00040v1", "categories": ["cs.CL", "cs.AI", "quant-ph", "I.2"], "primary_category": "cs.CL"}
{"title": "NRC VAD Lexicon v2: Norms for Valence, Arousal, and Dominance for over 55k English Terms", "abstract": "Factor analysis studies have shown that the primary dimensions of word\nmeaning are Valence (V), Arousal (A), and Dominance (D) (also referred to in\nsocial cognition research as Competence (C)). These dimensions impact various\naspects of our lives from social competence and emotion regulation to success\nin the work place and how we view the world. We present here the NRC VAD\nLexicon v2, which has human ratings of valence, arousal, and dominance for more\nthan 55,000 English words and phrases. Notably, it adds entries for $\\sim$25k\nadditional words to v1.0. It also now includes for the first time entries for\ncommon multi-word phrases (~10k). We show that the associations are highly\nreliable. The lexicon enables a wide variety of research in psychology, NLP,\npublic health, digital humanities, and social sciences. The NRC VAD Lexicon v2\nis made freely available for research through our project webpage.", "published": "2025-03-30 18:07:09", "link": "http://arxiv.org/abs/2503.23547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Whisper-LM: Improving ASR Models with Language Models for Low-Resource Languages", "abstract": "Automatic speech recognition systems have undoubtedly advanced with the\nintegration of multilingual and multitask models such as Whisper, which have\nshown a promising ability to understand and process speech across a wide range\nof languages. Despite their robustness, these models often fall short in\nhandling the linguistic distinctions of minority languages. This study\naddresses this gap by integrating traditional and novel language models with\nfine-tuned Whisper models to raise their performance in less commonly studied\nlanguages. Through rigorous fine-tuning and evaluation across multiple\ndatasets, we demonstrate substantial improvements in word error rate,\nparticularly in low-resource scenarios. Our approach not only does take\nadvantage of the extensive data Whisper was pre-trained on, but also\ncomplements its linguistic adaptability by incorporating language models. We\nobtained improvements up to 51\\% for in-distribution datasets and up to 34\\%\nfor out-of-distribution sentences using statistical language models, while\nlarge language models provided moderate but consistently robust improvement\nacross diverse linguistic contexts. The findings reveal that, while the\nintegration reliably benefits all model sizes, the extent of improvement\nvaries, highlighting the importance of optimized language model parameters.\nFinally, we emphasize the importance of selecting appropriate evaluation\nparameters when reporting the results using transformer-based ASR models. In\nsummary, this research clears the way for more inclusive ASR technologies that\nperform better across languages by enriching their linguistic knowledge. For\nfurther implementation details of this study, the technical documentation and\nsource code are available at http://www.github.com/hitz-zentroa/whisper-lm.", "published": "2025-03-30 18:03:52", "link": "http://arxiv.org/abs/2503.23542v1", "categories": ["cs.CL", "68T50 (Primary), 62H30", "I.2.7; I.2.6; J.5.2"], "primary_category": "cs.CL"}
{"title": "Question-Aware Knowledge Graph Prompting for Enhancing Large Language Models", "abstract": "Large Language Models (LLMs) often struggle with tasks requiring external\nknowledge, such as knowledge-intensive Multiple Choice Question Answering\n(MCQA). Integrating Knowledge Graphs (KGs) can enhance reasoning; however,\nexisting methods typically demand costly fine-tuning or retrieve noisy KG\ninformation. Recent approaches leverage Graph Neural Networks (GNNs) to\ngenerate KG-based input embedding prefixes as soft prompts for LLMs but fail to\naccount for question relevance, resulting in noisy prompts. Moreover, in MCQA\ntasks, the absence of relevant KG knowledge for certain answer options remains\na significant challenge. To address these issues, we propose Question-Aware\nKnowledge Graph Prompting (QAP), which incorporates question embeddings into\nGNN aggregation to dynamically assess KG relevance. QAP employs global\nattention to capture inter-option relationships, enriching soft prompts with\ninferred knowledge. Experimental results demonstrate that QAP outperforms\nstate-of-the-art methods across multiple datasets, highlighting its\neffectiveness.", "published": "2025-03-30 17:09:11", "link": "http://arxiv.org/abs/2503.23523v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "If an LLM Were a Character, Would It Know Its Own Story? Evaluating Lifelong Learning in LLMs", "abstract": "Large language models (LLMs) can carry out human-like dialogue, but unlike\nhumans, they are stateless due to the superposition property. However, during\nmulti-turn, multi-agent interactions, LLMs begin to exhibit consistent,\ncharacter-like behaviors, hinting at a form of emergent lifelong learning.\nDespite this, existing benchmarks often fail to capture these dynamics,\nprimarily focusing on static, open-ended evaluations. To address this gap, we\nintroduce LIFESTATE-BENCH, a benchmark designed to assess lifelong learning in\nLLMs. It features two episodic datasets: Hamlet and a synthetic script\ncollection, rich in narrative structure and character interactions. Our fact\nchecking evaluation probes models' self-awareness, episodic memory retrieval,\nand relationship tracking, across both parametric and non-parametric\napproaches. Experiments on models like Llama3.1-8B, GPT-4-turbo, and DeepSeek\nR1, we demonstrate that nonparametric methods significantly outperform\nparametric ones in managing stateful learning. However, all models exhibit\nchallenges with catastrophic forgetting as interactions extend, highlighting\nthe need for further advancements in lifelong learning.", "published": "2025-03-30 16:50:57", "link": "http://arxiv.org/abs/2503.23514v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RARE: Retrieval-Augmented Reasoning Modeling", "abstract": "Domain-specific intelligence demands specialized knowledge and sophisticated\nreasoning for problem-solving, posing significant challenges for large language\nmodels (LLMs) that struggle with knowledge hallucination and inadequate\nreasoning capabilities under constrained parameter budgets. Inspired by Bloom's\nTaxonomy in educational theory, we propose Retrieval-Augmented Reasoning\nModeling (RARE), a novel paradigm that decouples knowledge storage from\nreasoning optimization. RARE externalizes domain knowledge to retrievable\nsources and internalizes domain-specific reasoning patterns during training.\nSpecifically, by injecting retrieved knowledge into training prompts, RARE\ntransforms learning objectives from rote memorization to contextualized\nreasoning application. It enables models to bypass parameter-intensive\nmemorization and prioritize the development of higher-order cognitive\nprocesses. Our experiments demonstrate that lightweight RARE-trained models\n(e.g., Llama-3.1-8B) could achieve state-of-the-art performance, surpassing\nretrieval-augmented GPT-4 and Deepseek-R1 distilled counterparts. RARE\nestablishes a paradigm shift where maintainable external knowledge bases\nsynergize with compact, reasoning-optimized models, collectively driving more\nscalable domain-specific intelligence. Repo:\nhttps://github.com/Open-DataFlow/RARE", "published": "2025-03-30 16:49:44", "link": "http://arxiv.org/abs/2503.23513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SCORE: Story Coherence and Retrieval Enhancement for AI Narratives", "abstract": "Large Language Models (LLMs) excel at generating creative narratives but\nstruggle with long-term coherence and emotional consistency in complex stories.\nTo address this, we propose SCORE (Story Coherence and Retrieval Enhancement),\na framework integrating three components: 1) Dynamic State Tracking (monitoring\nobjects/characters via symbolic logic), 2) Context-Aware Summarization\n(hierarchical episode summaries for temporal progression), and 3) Hybrid\nRetrieval (combining TF-IDF keyword relevance with cosine similarity-based\nsemantic embeddings). The system employs a temporally-aligned\nRetrieval-Augmented Generation (RAG) pipeline to validate contextual\nconsistency. Evaluations show SCORE achieves 23.6% higher coherence (NCI-2.0\nbenchmark), 89.7% emotional consistency (EASM metric), and 41.8% fewer\nhallucinations versus baseline GPT models. Its modular design supports\nincremental knowledge graph construction for persistent story memory and\nmulti-LLM backend compatibility, offering an explainable solution for\nindustrial-scale narrative systems requiring long-term consistency.", "published": "2025-03-30 16:48:27", "link": "http://arxiv.org/abs/2503.23512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evolutionary Prompt Optimization Discovers Emergent Multimodal Reasoning Strategies in Vision-Language Models", "abstract": "We present a framework for optimizing prompts in vision-language models to\nelicit multimodal reasoning without model retraining. Using an evolutionary\nalgorithm to guide prompt updates downstream of visual tasks, our approach\nimproves upon baseline prompt-updating algorithms, which lack evolution-style\n\"survival of the fittest\" iteration. Crucially, we find this approach enables\nthe language model to independently discover progressive problem-solving\ntechniques across several evolution generations. For example, the model reasons\nthat to \"break down\" visually complex spatial tasks, making a tool call to a\nPython interpreter to perform tasks (such as cropping, image segmentation, or\nsaturation changes) would improve performance significantly. Our\nexperimentation shows that explicitly evoking this \"tool calling\" call, via\nsystem-level XML $...\\texttt{<tool>} ... \\texttt{</tool>}...$ tags, can\neffectively flag Python interpreter access for the same language model to\ngenerate relevant programs, generating advanced multimodal functionality. This\nfunctionality can be crystallized into a system-level prompt that induces\nimproved performance at inference time, and our experimentation suggests up to\n$\\approx 50\\%$ relative improvement across select visual tasks. Downstream\nperformance is trained and evaluated across subtasks from MathVista, M3CoT, and\nGeoBench-VLM datasets. Importantly, our approach shows that evolutionary prompt\noptimization guides language models towards self-reasoning discoveries, which\nresult in improved zero-shot generalization across tasks.", "published": "2025-03-30 16:25:45", "link": "http://arxiv.org/abs/2503.23503v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Benchmarking Systematic Relational Reasoning with Large Language and Reasoning Models", "abstract": "Large Language Models (LLMs) have been found to struggle with systematic\nreasoning. Even on tasks where they appear to perform well, their performance\noften depends on shortcuts, rather than on genuine reasoning abilities, leading\nthem to collapse on out-of-distribution examples. Post-training strategies\nbased on reinforcement learning and chain-of-thought prompting have recently\nbeen hailed as a step change. However, little is still known about the\npotential of the resulting ``Large Reasoning Models'' (LRMs) beyond problem\nsolving in mathematics and programming, where finding genuine\nout-of-distribution problems can be difficult. In this paper, we focus on tasks\nthat require systematic reasoning about relational compositions, especially for\nqualitative spatial and temporal reasoning. These tasks allow us to control the\ndifficulty of problem instances, and measure in a precise way to what extent\nmodels can generalise. We find that that the considered LLMs and LRMs overall\nperform poorly overall, albeit better than random chance.", "published": "2025-03-30 15:41:55", "link": "http://arxiv.org/abs/2503.23487v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Order Independence With Finetuning", "abstract": "Large language models (LLMs) demonstrate remarkable performance on many NLP\ntasks, yet often exhibit order dependence: simply reordering semantically\nidentical tokens (e.g., answer choices in multiple-choice questions) can lead\nto inconsistent predictions. Recent work proposes Set-Based Prompting (SBP) as\na way to remove order information from designated token subsets, thereby\nmitigating positional biases. However, applying SBP on base models induces an\nout-of-distribution input format, which can degrade in-distribution\nperformance. We introduce a fine-tuning strategy that integrates SBP into the\ntraining process, \"pulling\" these set-formatted prompts closer to the model's\ntraining manifold. We show that SBP can be incorporated into a model via\nfine-tuning. Our experiments on in-distribution (MMLU) and out-of-distribution\n(CSQA, ARC Challenge) multiple-choice tasks show that SBP fine-tuning\nsignificantly improves accuracy and robustness to answer-order permutations,\nall while preserving broader language modeling capabilities. We discuss the\nbroader implications of order-invariant modeling and outline future directions\nfor building fairer, more consistent LLMs.", "published": "2025-03-30 15:38:43", "link": "http://arxiv.org/abs/2503.23483v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Codehacks: A Dataset of Adversarial Tests for Competitive Programming Problems Obtained from Codeforces", "abstract": "Software is used in critical applications in our day-to-day life and it is\nimportant to ensure its correctness. One popular approach to assess correctness\nis to evaluate software on tests. If a test fails, it indicates a fault in the\nsoftware under test; if all tests pass correctly, one may assume that the\nsoftware is correct. However, the reliability of these results depends on the\ntest suite considered, and there is a risk of false negatives (i.e. software\nthat passes all available tests but contains bugs because some cases are not\ntested). Therefore, it is important to consider error-inducing test cases when\nevaluating software.\n  To support data-driven creation of such a test-suite, which is especially of\ninterest for testing software synthesized from large language models, we curate\na dataset (Codehacks) of programming problems together with corresponding\nerror-inducing test cases (i.e., \"hacks\"). This dataset is collected from the\nwild, in particular, from the Codeforces online judge platform. The dataset\ncomprises 288,617 hacks for 5,578 programming problems, each with a natural\nlanguage description, as well as the source code for 2,196 submitted solutions\nto these problems that can be broken with their corresponding hacks.\n  Keywords: competitive programming, language model, dataset", "published": "2025-03-30 14:50:03", "link": "http://arxiv.org/abs/2503.23466v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Semantic-Preserving Transformations as Mutation Operators: A Study on Their Effectiveness in Defect Detection", "abstract": "Recent advances in defect detection use language models. Existing works\nenhanced the training data to improve the models' robustness when applied to\nsemantically identical code (i.e., predictions should be the same). However,\nthe use of semantically identical code has not been considered for improving\nthe tools during their application - a concept closely related to metamorphic\ntesting.\n  The goal of our study is to determine whether we can use semantic-preserving\ntransformations, analogue to mutation operators, to improve the performance of\ndefect detection tools in the testing stage. We first collect existing\npublications which implemented semantic-preserving transformations and share\ntheir implementation, such that we can reuse them. We empirically study the\neffectiveness of three different ensemble strategies for enhancing defect\ndetection tools. We apply the collected transformations on the Devign dataset,\nconsidering vulnerabilities as a type of defect, and two fine-tuned large\nlanguage models for defect detection (VulBERTa, PLBART). We found 28\npublications with 94 different transformations.\n  We choose to implement 39 transformations from four of the publications, but\na manual check revealed that 23 out 39 transformations change code semantics.\nUsing the 16 remaining, correct transformations and three ensemble strategies,\nwe were not able to increase the accuracy of the defect detection models. Our\nresults show that reusing shared semantic-preserving transformation is\ndifficult, sometimes even causing wrongful changes to the semantics.\n  Keywords: defect detection, language model, semantic-preserving\ntransformation, ensemble", "published": "2025-03-30 14:00:22", "link": "http://arxiv.org/abs/2503.23448v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Speculative End-Turn Detector for Efficient Speech Chatbot Assistant", "abstract": "Spoken dialogue systems powered by large language models have demonstrated\nremarkable abilities in understanding human speech and generating appropriate\nspoken responses. However, these systems struggle with end-turn detection (ETD)\n-- the ability to distinguish between user turn completion and hesitation. This\nlimitation often leads to premature or delayed responses, disrupting the flow\nof spoken conversations. In this paper, we introduce the ETD Dataset, the first\npublic dataset for end-turn detection. The ETD dataset consists of both\nsynthetic speech data generated with text-to-speech models and real-world\nspeech data collected from web sources. We also propose SpeculativeETD, a novel\ncollaborative inference framework that balances efficiency and accuracy to\nimprove real-time ETD in resource-constrained environments. Our approach\njointly employs a lightweight GRU-based model, which rapidly detects the\nnon-speaking units in real-time on local devices, and a high-performance\nWav2vec-based model running on the server to make a more challenging\nclassification of distinguishing turn ends from mere pauses. Experiments\ndemonstrate that the proposed SpeculativeETD significantly improves ETD\naccuracy while keeping the required computations low. Datasets and code will be\navailable after the review.", "published": "2025-03-30 13:34:23", "link": "http://arxiv.org/abs/2503.23439v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CoRanking: Collaborative Ranking with Small and Large Ranking Agents", "abstract": "Large Language Models (LLMs) have demonstrated superior listwise ranking\nperformance. However, their superior performance often relies on large-scale\nparameters (\\eg, GPT-4) and a repetitive sliding window process, which\nintroduces significant efficiency challenges. In this paper, we propose\n\\textbf{CoRanking}, a novel collaborative ranking framework that combines small\nand large ranking models for efficient and effective ranking. CoRanking first\nemploys a small-size reranker to pre-rank all the candidate passages, bringing\nrelevant ones to the top part of the list (\\eg, top-20). Then, the LLM listwise\nreranker is applied to only rerank these top-ranked passages instead of the\nwhole list, substantially enhancing overall ranking efficiency. Although more\nefficient, previous studies have revealed that the LLM listwise reranker have\nsignificant positional biases on the order of input passages. Directly feed the\ntop-ranked passages from small reranker may result in the sub-optimal\nperformance of LLM listwise reranker. To alleviate this problem, we introduce a\npassage order adjuster trained via reinforcement learning, which reorders the\ntop passages from the small reranker to align with the LLM's preferences of\npassage order. Extensive experiments on three IR benchmarks demonstrate that\nCoRanking significantly improves efficiency (reducing ranking latency by about\n70\\%) while achieving even better effectiveness compared to using only the LLM\nlistwise reranker.", "published": "2025-03-30 13:00:52", "link": "http://arxiv.org/abs/2503.23427v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "What Makes an Evaluation Useful? Common Pitfalls and Best Practices", "abstract": "Following the rapid increase in Artificial Intelligence (AI) capabilities in\nrecent years, the AI community has voiced concerns regarding possible safety\nrisks. To support decision-making on the safe use and development of AI\nsystems, there is a growing need for high-quality evaluations of dangerous\nmodel capabilities. While several attempts to provide such evaluations have\nbeen made, a clear definition of what constitutes a \"good evaluation\" has yet\nto be agreed upon. In this practitioners' perspective paper, we present a set\nof best practices for safety evaluations, drawing on prior work in model\nevaluation and illustrated through cybersecurity examples. We first discuss the\nsteps of the initial thought process, which connects threat modeling to\nevaluation design. Then, we provide the characteristics and parameters that\nmake an evaluation useful. Finally, we address additional considerations as we\nmove from building specific evaluations to building a full and comprehensive\nevaluation suite.", "published": "2025-03-30 12:51:47", "link": "http://arxiv.org/abs/2503.23424v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "cs.CY"], "primary_category": "cs.LG"}
{"title": "An Analysis of Decoding Methods for LLM-based Agents for Faithful Multi-Hop Question Answering", "abstract": "Large Language Models (LLMs) frequently produce factually inaccurate outputs\n- a phenomenon known as hallucination - which limits their accuracy in\nknowledge-intensive NLP tasks. Retrieval-augmented generation and agentic\nframeworks such as Reasoning and Acting (ReAct) can address this issue by\ngiving the model access to external knowledge. However, LLMs often fail to\nremain faithful to retrieved information. Mitigating this is critical,\nespecially if LLMs are required to reason about the retrieved information.\nRecent research has explored training-free decoding strategies to improve the\nfaithfulness of model generations. We present a systematic analysis of how the\ncombination of the ReAct framework and decoding strategies (i.e., DeCoRe, DoLa,\nand CAD) can influence the faithfulness of LLM-generated answers. Our results\nshow that combining an agentic framework for knowledge retrieval with decoding\nmethods that enhance faithfulness can increase accuracy on the downstream\nMulti-Hop Question Answering tasks. For example, we observe an F1 increase from\n19.5 to 32.6 on HotpotQA when using ReAct and DoLa.", "published": "2025-03-30 12:18:21", "link": "http://arxiv.org/abs/2503.23415v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ToRL: Scaling Tool-Integrated RL", "abstract": "We introduce ToRL (Tool-Integrated Reinforcement Learning), a framework for\ntraining large language models (LLMs) to autonomously use computational tools\nvia reinforcement learning. Unlike supervised fine-tuning, ToRL allows models\nto explore and discover optimal strategies for tool use. Experiments with\nQwen2.5-Math models show significant improvements: ToRL-7B reaches 43.3\\%\naccuracy on AIME~24, surpassing reinforcement learning without tool integration\nby 14\\% and the best existing Tool-Integrated Reasoning (TIR) model by 17\\%.\nFurther analysis reveals emergent behaviors such as strategic tool invocation,\nself-regulation of ineffective code, and dynamic adaptation between\ncomputational and analytical reasoning, all arising purely through\nreward-driven learning.", "published": "2025-03-30 10:16:25", "link": "http://arxiv.org/abs/2503.23383v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FeRG-LLM : Feature Engineering by Reason Generation Large Language Models", "abstract": "One of the key tasks in machine learning for tabular data is feature\nengineering. Although it is vital for improving the performance of models, it\ndemands considerable human expertise and deep domain knowledge, making it\nlabor-intensive endeavor. To address this issue, we propose a novel framework,\n\\textbf{FeRG-LLM} (\\textbf{Fe}ature engineering by \\textbf{R}eason\n\\textbf{G}eneration \\textbf{L}arge \\textbf{L}anguage \\textbf{M}odels), a large\nlanguage model designed to automatically perform feature engineering at an\n8-billion-parameter scale. We have constructed two-stage conversational\ndialogues that enable language models to analyze machine learning tasks and\ndiscovering new features, exhibiting their Chain-of-Thought (CoT) capabilities.\nWe use these dialogues to fine-tune Llama 3.1 8B model and integrate Direct\nPreference Optimization (DPO) to receive feedback improving quality of new\nfeatures and the model's performance. Our experiments show that FeRG-LLM\nperforms comparably to or better than Llama 3.1 70B on most datasets, while\nusing fewer resources and achieving reduced inference time. It outperforms\nother studies in classification tasks and performs well in regression tasks.\nMoreover, since it does not rely on cloud-hosted LLMs like GPT-4 with extra API\ncosts when generating features, it can be deployed locally, addressing security\nconcerns.", "published": "2025-03-30 09:07:21", "link": "http://arxiv.org/abs/2503.23371v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Better Logical Fallacy Reasoners with Counterargument, Explanation, and Goal-Aware Prompt Formulation", "abstract": "The advancement of Large Language Models (LLMs) has greatly improved our\nability to process complex language. However, accurately detecting logical\nfallacies remains a significant challenge. This study presents a novel and\neffective prompt formulation approach for logical fallacy detection, applicable\nin both supervised (fine-tuned) and unsupervised (zero-shot) settings. Our\nmethod enriches input text incorporating implicit contextual information --\ncounterarguments, explanations, and goals -- which we query for validity within\nthe context of the argument. We then rank these queries based on confidence\nscores to inform classification. We evaluate our approach across multiple\ndatasets from 5 domains, covering 29 distinct fallacy types, using models from\nthe GPT and LLaMA series. The results show substantial improvements over\nstate-of-the-art models, with F1 score increases of up to 0.60 in zero-shot\nsettings and up to 0.45 in fine-tuned models. Extensive analyses further\nillustrate why and how our method excels.", "published": "2025-03-30 08:41:09", "link": "http://arxiv.org/abs/2503.23363v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Mixture of Routers", "abstract": "Supervised fine-tuning (SFT) is a milestone in aligning large language models\nwith human instructions and adapting them to downstream tasks. In particular,\nLow-Rank Adaptation (LoRA) has gained widespread attention due to its parameter\nefficiency. However, its impact on improving the performance of large models\nremains limited. Recent studies suggest that combining LoRA with\nMixture-of-Experts (MoE) can significantly enhance fine-tuning performance. MoE\nadapts to the diversity and complexity of datasets by dynamically selecting the\nmost suitable experts, thereby improving task accuracy and efficiency. Despite\nimpressive results, recent studies reveal issues in the MoE routing mechanism,\nsuch as incorrect assignments and imbalanced expert allocation. Inspired by the\nprinciples of Redundancy and Fault Tolerance Theory. We innovatively integrate\nthe concept of Mixture of Experts into the routing mechanism and propose an\nefficient fine-tuning method called Mixture of Routers (MoR). It employs\nmultiple sub-routers for joint selection and uses a learnable main router to\ndetermine the weights of the sub-routers. The results show that MoR outperforms\nbaseline models on most tasks, achieving an average performance improvement of\n1%. MoR can serve as a plug-and-play, parameter-efficient fine-tuning method\nsuitable for a wide range of applications. Our code is available here:\nhttps://anonymous.4open.science/r/MoR-DFC6.", "published": "2025-03-30 08:39:09", "link": "http://arxiv.org/abs/2503.23362v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Discovering Knowledge Deficiencies of Language Models on Massive Knowledge Base", "abstract": "Large language models (LLMs) possess impressive linguistic capabilities but\noften fail to faithfully retain factual knowledge, leading to hallucinations\nand unreliable outputs. Understanding LLMs' knowledge deficiencies by\nexhaustively evaluating against full-scale knowledge bases is computationally\nprohibitive, especially for closed-weight models. We propose stochastic error\nascent (SEA), a scalable and efficient framework for discovering knowledge\ndeficiencies (errors) in closed-weight LLMs under a strict query budget. Rather\nthan naively probing all knowledge candidates, SEA formulates error discovery\nas a stochastic optimization process: it iteratively retrieves new high-error\ncandidates by leveraging the semantic similarity to previously observed\nfailures. To further enhance search efficiency and coverage, SEA employs\nhierarchical retrieval across document and paragraph levels, and constructs a\nrelation directed acyclic graph to model error propagation and identify\nsystematic failure modes. Empirically, SEA uncovers 40.7x more knowledge errors\nthan Automated Capability Discovery and 26.7% more than AutoBencher, while\nreducing the cost-per-error by 599x and 9x, respectively. Human evaluation\nconfirms the high quality of generated questions, while ablation and\nconvergence analyses validate the contribution of each component in SEA.\nFurther analysis on the discovered errors reveals correlated failure patterns\nacross LLM families and recurring deficits, highlighting the need for better\ndata coverage and targeted fine-tuning in future LLM development.", "published": "2025-03-30 08:33:56", "link": "http://arxiv.org/abs/2503.23361v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not All LoRA Parameters Are Essential: Insights on Inference Necessity", "abstract": "Current research on LoRA primarily focuses on minimizing the number of\nfine-tuned parameters or optimizing its architecture. However, the necessity of\nall fine-tuned LoRA layers during inference remains underexplored. In this\npaper, we investigate the contribution of each LoRA layer to the model's\nability to predict the ground truth and hypothesize that lower-layer LoRA\nmodules play a more critical role in model reasoning and understanding. To\naddress this, we propose a simple yet effective method to enhance the\nperformance of large language models (LLMs) fine-tuned with LoRA. Specifically,\nwe identify a ``boundary layer'' that distinguishes essential LoRA layers by\nanalyzing a small set of validation samples. During inference, we drop all LoRA\nlayers beyond this boundary. We evaluate our approach on three strong baselines\nacross four widely-used text generation datasets. Our results demonstrate\nconsistent and significant improvements, underscoring the effectiveness of\nselectively retaining critical LoRA layers during inference.", "published": "2025-03-30 08:33:04", "link": "http://arxiv.org/abs/2503.23360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Scalable Framework for Evaluating Health Language Models", "abstract": "Large language models (LLMs) have emerged as powerful tools for analyzing\ncomplex datasets. Recent studies demonstrate their potential to generate\nuseful, personalized responses when provided with patient-specific health\ninformation that encompasses lifestyle, biomarkers, and context. As LLM-driven\nhealth applications are increasingly adopted, rigorous and efficient one-sided\nevaluation methodologies are crucial to ensure response quality across multiple\ndimensions, including accuracy, personalization and safety. Current evaluation\npractices for open-ended text responses heavily rely on human experts. This\napproach introduces human factors and is often cost-prohibitive,\nlabor-intensive, and hinders scalability, especially in complex domains like\nhealthcare where response assessment necessitates domain expertise and\nconsiders multifaceted patient data. In this work, we introduce Adaptive\nPrecise Boolean rubrics: an evaluation framework that streamlines human and\nautomated evaluation of open-ended questions by identifying gaps in model\nresponses using a minimal set of targeted rubrics questions. Our approach is\nbased on recent work in more general evaluation settings that contrasts a\nsmaller set of complex evaluation targets with a larger set of more precise,\ngranular targets answerable with simple boolean responses. We validate this\napproach in metabolic health, a domain encompassing diabetes, cardiovascular\ndisease, and obesity. Our results demonstrate that Adaptive Precise Boolean\nrubrics yield higher inter-rater agreement among expert and non-expert human\nevaluators, and in automated assessments, compared to traditional Likert\nscales, while requiring approximately half the evaluation time of Likert-based\nmethods. This enhanced efficiency, particularly in automated evaluation and\nnon-expert contributions, paves the way for more extensive and cost-effective\nevaluation of LLMs in health.", "published": "2025-03-30 06:47:57", "link": "http://arxiv.org/abs/2503.23339v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Beyond Unimodal Boundaries: Generative Recommendation with Multimodal Semantics", "abstract": "Generative recommendation (GR) has become a powerful paradigm in\nrecommendation systems that implicitly links modality and semantics to item\nrepresentation, in contrast to previous methods that relied on non-semantic\nitem identifiers in autoregressive models. However, previous research has\npredominantly treated modalities in isolation, typically assuming item content\nis unimodal (usually text). We argue that this is a significant limitation\ngiven the rich, multimodal nature of real-world data and the potential\nsensitivity of GR models to modality choices and usage. Our work aims to\nexplore the critical problem of Multimodal Generative Recommendation (MGR),\nhighlighting the importance of modality choices in GR nframeworks. We reveal\nthat GR models are particularly sensitive to different modalities and examine\nthe challenges in achieving effective GR when multiple modalities are\navailable. By evaluating design strategies for effectively leveraging multiple\nmodalities, we identify key challenges and introduce MGR-LF++, an enhanced late\nfusion framework that employs contrastive modality alignment and special tokens\nto denote different modalities, achieving a performance improvement of over 20%\ncompared to single-modality alternatives.", "published": "2025-03-30 06:24:43", "link": "http://arxiv.org/abs/2503.23333v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science", "abstract": "Large Language Models (LLMs) have revolutionized automated data analytics and\nmachine learning by enabling dynamic reasoning and adaptability. While recent\napproaches have advanced multi-stage pipelines through multi-agent systems,\nthey typically rely on rigid, single-path workflows that limit the exploration\nand integration of diverse strategies, often resulting in suboptimal\npredictions. To address these challenges, we propose SPIO (Sequential Plan\nIntegration and Optimization), a novel framework that leverages LLM-driven\ndecision-making to orchestrate multi-agent planning across four key modules:\ndata preprocessing, feature engineering, modeling, and hyperparameter tuning.\nIn each module, dedicated planning agents independently generate candidate\nstrategies that cascade into subsequent stages, fostering comprehensive\nexploration. A plan optimization agent refines these strategies by suggesting\nseveral optimized plans. We further introduce two variants: SPIO-S, which\nselects a single best solution path as determined by the LLM, and SPIO-E, which\nselects the top k candidate plans and ensembles them to maximize predictive\nperformance. Extensive experiments on Kaggle and OpenML datasets demonstrate\nthat SPIO significantly outperforms state-of-the-art methods, providing a\nrobust and scalable solution for automated data science task.", "published": "2025-03-30 04:45:32", "link": "http://arxiv.org/abs/2503.23314v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Linguistic Loops and Geometric Invariants as a Way to Pre-Verbal Thought?", "abstract": "In this work we introduce the concepts of linguistic transformation,\nlinguistic loop and semantic deficit. By exploiting Lie group theoretical and\ngeometric techniques, we define invariants that capture the structural\nproperties of a whole linguistic loop. This result introduces new line of\nresearch, employing tools from Lie theory and higher-dimensional geometry\nwithin language studies. But, even more intriguingly, our study hints to a\nmathematical characterization of the meta-linguistic or pre-verbal thought,\nnamely of those cognitive structures that precede the language.", "published": "2025-03-30 04:38:36", "link": "http://arxiv.org/abs/2503.23311v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Focus Directions Make Your Language Models Pay More Attention to Relevant Contexts", "abstract": "Long-context large language models (LLMs) are prone to be distracted by\nirrelevant contexts. The reason for distraction remains poorly understood. In\nthis paper, we first identify the contextual heads, a special group of\nattention heads that control the overall attention of the LLM. Then, we\ndemonstrate that distraction arises when contextual heads fail to allocate\nsufficient attention to relevant contexts and can be mitigated by increasing\nattention to these contexts. We further identify focus directions, located at\nthe key and query activations of these heads, which enable them to allocate\nmore attention to relevant contexts without explicitly specifying which context\nis relevant. We comprehensively evaluate the effect of focus direction on\nvarious long-context tasks and find out focus directions could help to mitigate\nthe poor task alignment of the long-context LLMs. We believe our findings could\npromote further research on long-context LLM alignment.", "published": "2025-03-30 04:18:28", "link": "http://arxiv.org/abs/2503.23306v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Source-Side Confidence Estimation for Reliable Translation into Unfamiliar Languages", "abstract": "We present an interactive machine translation (MT) system designed for users\nwho are not proficient in the target language. It aims to improve\ntrustworthiness and explainability by identifying potentially mistranslated\nwords and allowing the user to intervene to correct mistranslations. However,\nconfidence estimation in machine translation has traditionally focused on the\ntarget side. Whereas the conventional approach to source-side confidence\nestimation would have been to project target word probabilities to the source\nside via word alignments, we propose a direct, alignment-free approach that\nmeasures how sensitive the target word probabilities are to changes in the\nsource embeddings. Experimental results show that our method outperforms\ntraditional alignment-based methods at detection of mistranslations.", "published": "2025-03-30 04:03:42", "link": "http://arxiv.org/abs/2503.23305v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Advancing Sentiment Analysis in Tamil-English Code-Mixed Texts: Challenges and Transformer-Based Solutions", "abstract": "The sentiment analysis task in Tamil-English code-mixed texts has been\nexplored using advanced transformer-based models. Challenges from grammatical\ninconsistencies, orthographic variations, and phonetic ambiguities have been\naddressed. The limitations of existing datasets and annotation gaps have been\nexamined, emphasizing the need for larger and more diverse corpora. Transformer\narchitectures, including XLM-RoBERTa, mT5, IndicBERT, and RemBERT, have been\nevaluated in low-resource, code-mixed environments. Performance metrics have\nbeen analyzed, highlighting the effectiveness of specific models in handling\nmultilingual sentiment classification. The findings suggest that further\nadvancements in data augmentation, phonetic normalization, and hybrid modeling\napproaches are required to enhance accuracy. Future research directions for\nimproving sentiment analysis in code-mixed texts have been proposed.", "published": "2025-03-30 03:27:41", "link": "http://arxiv.org/abs/2503.23295v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cocktail: Chunk-Adaptive Mixed-Precision Quantization for Long-Context LLM Inference", "abstract": "Recently, large language models (LLMs) have been able to handle longer and\nlonger contexts. However, a context that is too long may cause intolerant\ninference latency and GPU memory usage. Existing methods propose\nmixed-precision quantization to the key-value (KV) cache in LLMs based on token\ngranularity, which is time-consuming in the search process and hardware\ninefficient during computation. This paper introduces a novel approach called\nCocktail, which employs chunk-adaptive mixed-precision quantization to optimize\nthe KV cache. Cocktail consists of two modules: chunk-level quantization search\nand chunk-level KV cache computation. Chunk-level quantization search\ndetermines the optimal bitwidth configuration of the KV cache chunks quickly\nbased on the similarity scores between the corresponding context chunks and the\nquery, maintaining the model accuracy. Furthermore, chunk-level KV cache\ncomputation reorders the KV cache chunks before quantization, avoiding the\nhardware inefficiency caused by mixed-precision quantization in inference\ncomputation. Extensive experiments demonstrate that Cocktail outperforms\nstate-of-the-art KV cache quantization methods on various models and datasets.", "published": "2025-03-30 03:20:34", "link": "http://arxiv.org/abs/2503.23294v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Patient History from Clinical Text: A Comparative Study of Clinical Large Language Models", "abstract": "Extracting medical history entities (MHEs) related to a patient's chief\ncomplaint (CC), history of present illness (HPI), and past, family, and social\nhistory (PFSH) helps structure free-text clinical notes into standardized EHRs,\nstreamlining downstream tasks like continuity of care, medical coding, and\nquality metrics. Fine-tuned clinical large language models (cLLMs) can assist\nin this process while ensuring the protection of sensitive data via on-premises\ndeployment. This study evaluates the performance of cLLMs in recognizing\nCC/HPI/PFSH-related MHEs and examines how note characteristics impact model\naccuracy. We annotated 1,449 MHEs across 61 outpatient-related clinical notes\nfrom the MTSamples repository. To recognize these entities, we fine-tuned seven\nstate-of-the-art cLLMs. Additionally, we assessed the models' performance when\nenhanced by integrating, problems, tests, treatments, and other basic medical\nentities (BMEs). We compared the performance of these models against GPT-4o in\na zero-shot setting. To further understand the textual characteristics\naffecting model accuracy, we conducted an error analysis focused on note\nlength, entity length, and segmentation. The cLLMs showed potential in reducing\nthe time required for extracting MHEs by over 20%. However, detecting many\ntypes of MHEs remained challenging due to their polysemous nature and the\nfrequent involvement of non-medical vocabulary. Fine-tuned GatorTron and\nGatorTronS, two of the most extensively trained cLLMs, demonstrated the highest\nperformance. Integrating pre-identified BME information improved model\nperformance for certain entities. Regarding the impact of textual\ncharacteristics on model performance, we found that longer entities were harder\nto identify, note length did not correlate with a higher error rate, and\nwell-organized segments with headings are beneficial for the extraction.", "published": "2025-03-30 02:00:56", "link": "http://arxiv.org/abs/2503.23281v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PromptDistill: Query-based Selective Token Retention in Intermediate Layers for Efficient Large Language Model Inference", "abstract": "As large language models (LLMs) tackle increasingly complex tasks and longer\ndocuments, their computational and memory costs during inference become a major\nbottleneck. To address this, we propose PromptDistill, a novel, training-free\nmethod that improves inference efficiency while preserving generation quality.\nPromptDistill identifies and retains the most informative tokens by leveraging\nattention interactions in early layers, preserving their hidden states while\nreducing the computational burden in later layers. This allows the model to\nfocus on essential contextual information without fully processing all tokens.\nUnlike previous methods such as H2O and SnapKV, which perform compression only\nafter processing the entire input, or GemFilter, which selects a fixed portion\nof the initial prompt without considering contextual dependencies,\nPromptDistill dynamically allocates computational resources to the most\nrelevant tokens while maintaining a global awareness of the input. Experiments\nusing our method and baseline approaches with base models such as LLaMA 3.1 8B\nInstruct, Phi 3.5 Mini Instruct, and Qwen2 7B Instruct on benchmarks including\nLongBench, InfBench, and Needle in a Haystack demonstrate that PromptDistill\nsignificantly improves efficiency while having minimal impact on output quality\ncompared to the original models. With a single-stage selection strategy,\nPromptDistill effectively balances performance and efficiency, outperforming\nprior methods like GemFilter, H2O, and SnapKV due to its superior ability to\nretain essential information. Specifically, compared to GemFilter,\nPromptDistill achieves an overall $1\\%$ to $5\\%$ performance improvement while\nalso offering better time efficiency. Additionally, we explore multi-stage\nselection, which further improves efficiency while maintaining strong\ngeneration performance.", "published": "2025-03-30 01:47:23", "link": "http://arxiv.org/abs/2503.23274v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EAP4EMSIG -- Enhancing Event-Driven Microscopy for Microfluidic Single-Cell Analysis", "abstract": "Microfluidic Live-Cell Imaging yields data on microbial cell factories.\nHowever, continuous acquisition is challenging as high-throughput experiments\noften lack realtime insights, delaying responses to stochastic events. We\nintroduce three components in the Experiment Automation Pipeline for\nEvent-Driven Microscopy to Smart Microfluidic Single-Cell Analysis: a fast,\naccurate Deep Learning autofocusing method predicting the focus offset, an\nevaluation of real-time segmentation methods and a realtime data analysis\ndashboard. Our autofocusing achieves a Mean Absolute Error of 0.0226\\textmu m\nwith inference times below 50~ms. Among eleven Deep Learning segmentation\nmethods, Cellpose~3 reached a Panoptic Quality of 93.58\\%, while a\ndistance-based method is fastest (121~ms, Panoptic Quality 93.02\\%). All six\nDeep Learning Foundation Models were unsuitable for real-time segmentation.", "published": "2025-03-30 23:16:23", "link": "http://arxiv.org/abs/2504.00047v1", "categories": ["q-bio.QM", "cs.AI", "cs.CV"], "primary_category": "q-bio.QM"}
{"title": "Beyond Detection: Designing AI-Resilient Assessments with Automated Feedback Tool to Foster Critical Thinking", "abstract": "The growing use of generative AI tools like ChatGPT has raised urgent\nconcerns about their impact on student learning, particularly the potential\nerosion of critical thinking and creativity. As students increasingly turn to\nthese tools to complete assessments, foundational cognitive skills are at risk\nof being bypassed, challenging the integrity of higher education and the\nauthenticity of student work. Existing AI-generated text detection tools are\ninadequate; they produce unreliable outputs and are prone to both false\npositives and false negatives, especially when students apply paraphrasing,\ntranslation, or rewording. These systems rely on shallow statistical patterns\nrather than true contextual or semantic understanding, making them unsuitable\nas definitive indicators of AI misuse. In response, this research proposes a\nproactive, AI-resilient solution based on assessment design rather than\ndetection. It introduces a web-based Python tool that integrates Bloom's\nTaxonomy with advanced natural language processing techniques including GPT-3.5\nTurbo, BERT-based semantic similarity, and TF-IDF metrics to evaluate the\nAI-solvability of assessment tasks. By analyzing surface-level and semantic\nfeatures, the tool helps educators determine whether a task targets lower-order\nthinking such as recall and summarization or higher-order skills such as\nanalysis, evaluation, and creation, which are more resistant to AI automation.\nThis framework empowers educators to design cognitively demanding, AI-resistant\nassessments that promote originality, critical thinking, and fairness. It\noffers a sustainable, pedagogically sound strategy to foster authentic learning\nand uphold academic standards in the age of AI.", "published": "2025-03-30 23:13:00", "link": "http://arxiv.org/abs/2503.23622v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Graph-Eq: Discovering Mathematical Equations using Graph Generative Models", "abstract": "The ability to discover meaningful, accurate, and concise mathematical\nequations that describe datasets is valuable across various domains. Equations\noffer explicit relationships between variables, enabling deeper insights into\nunderlying data patterns. Most existing equation discovery methods rely on\ngenetic programming, which iteratively searches the equation space but is often\nslow and prone to overfitting. By representing equations as directed acyclic\ngraphs, we leverage the use of graph neural networks to learn the underlying\nsemantics of equations, and generate new, previously unseen equations. Although\ngraph generative models have been shown to be successful in discovering new\ntypes of graphs in many fields, there application in discovering equations\nremains largely unexplored. In this work, we propose Graph-EQ, a deep graph\ngenerative model designed for efficient equation discovery. Graph-EQ uses a\nconditional variational autoencoder (CVAE) to learn a rich latent\nrepresentation of the equation space by training it on a large corpus of\nequations in an unsupervised manner. Instead of directly searching the equation\nspace, we employ Bayesian optimization to efficiently explore this learned\nlatent space. We show that the encoder-decoder architecture of Graph-Eq is able\nto accurately reconstruct input equations. Moreover, we show that the learned\nlatent representation can be sampled and decoded into valid equations,\nincluding new and previously unseen equations in the training data. Finally, we\nassess Graph-Eq's ability to discover equations that best fit a dataset by\nexploring the latent space using Bayesian optimization. Latent space\nexploration is done on 20 dataset with known ground-truth equations, and\nGraph-Eq is shown to successfully discover the grountruth equation in the\nmajority of datasets.", "published": "2025-03-30 22:47:57", "link": "http://arxiv.org/abs/2503.23617v1", "categories": ["cs.LG", "cs.AI", "I.2"], "primary_category": "cs.LG"}
{"title": "Interpretable Machine Learning in Physics: A Review", "abstract": "Machine learning is increasingly transforming various scientific fields,\nenabled by advancements in computational power and access to large data sets\nfrom experiments and simulations. As artificial intelligence (AI) continues to\ngrow in capability, these algorithms will enable many scientific discoveries\nbeyond human capabilities. Since the primary goal of science is to understand\nthe world around us, fully leveraging machine learning in scientific discovery\nrequires models that are interpretable -- allowing experts to comprehend the\nconcepts underlying machine-learned predictions. Successful interpretations\nincrease trust in black-box methods, help reduce errors, allow for the\nimprovement of the underlying models, enhance human-AI collaboration, and\nultimately enable fully automated scientific discoveries that remain\nunderstandable to human scientists. This review examines the role of\ninterpretability in machine learning applied to physics. We categorize\ndifferent aspects of interpretability, discuss machine learning models in terms\nof both interpretability and performance, and explore the philosophical\nimplications of interpretability in scientific inquiry. Additionally, we\nhighlight recent advances in interpretable machine learning across many\nsubfields of physics. By bridging boundaries between disciplines -- each with\nits own unique insights and challenges -- we aim to establish interpretable\nmachine learning as a core research focus in science.", "published": "2025-03-30 22:44:40", "link": "http://arxiv.org/abs/2503.23616v1", "categories": ["physics.comp-ph", "cs.AI", "cs.LG"], "primary_category": "physics.comp-ph"}
{"title": "An Organizationally-Oriented Approach to Enhancing Explainability and Control in Multi-Agent Reinforcement Learning", "abstract": "Multi-Agent Reinforcement Learning can lead to the development of\ncollaborative agent behaviors that show similarities with organizational\nconcepts. Pushing forward this perspective, we introduce a novel framework that\nexplicitly incorporates organizational roles and goals from the\n$\\mathcal{M}OISE^+$ model into the MARL process, guiding agents to satisfy\ncorresponding organizational constraints. By structuring training with roles\nand goals, we aim to enhance both the explainability and control of agent\nbehaviors at the organizational level, whereas much of the literature primarily\nfocuses on individual agents. Additionally, our framework includes a\npost-training analysis method to infer implicit roles and goals, offering\ninsights into emergent agent behaviors. This framework has been applied across\nvarious MARL environments and algorithms, demonstrating coherence between\npredefined organizational specifications and those inferred from trained\nagents.", "published": "2025-03-30 22:43:01", "link": "http://arxiv.org/abs/2503.23615v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Partial Transportability for Domain Generalization", "abstract": "A fundamental task in AI is providing performance guarantees for predictions\nmade in unseen domains. In practice, there can be substantial uncertainty about\nthe distribution of new data, and corresponding variability in the performance\nof existing predictors. Building on the theory of partial identification and\ntransportability, this paper introduces new results for bounding the value of a\nfunctional of the target distribution, such as the generalization error of a\nclassifier, given data from source domains and assumptions about the data\ngenerating mechanisms, encoded in causal diagrams. Our contribution is to\nprovide the first general estimation technique for transportability problems,\nadapting existing parameterization schemes such Neural Causal Models to encode\nthe structural constraints necessary for cross-population inference. We\ndemonstrate the expressiveness and consistency of this procedure and further\npropose a gradient-based optimization scheme for making scalable inferences in\npractice. Our results are corroborated with experiments.", "published": "2025-03-30 22:06:37", "link": "http://arxiv.org/abs/2503.23605v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs", "abstract": "Raven's Progressive Matrices (RPMs) is an established benchmark to examine\nthe ability to perform high-level abstract visual reasoning (AVR). Despite the\ncurrent success of algorithms that solve this task, humans can generalize\nbeyond a given puzzle and create new puzzles given a set of rules, whereas\nmachines remain locked in solving a fixed puzzle from a curated choice list. We\npropose Generative Visual Puzzles (GenVP), a framework to model the entire RPM\ngeneration process, a substantially more challenging task. Our model's\ncapability spans from generating multiple solutions for one specific problem\nprompt to creating complete new puzzles out of the desired set of rules.\nExperiments on five different datasets indicate that GenVP achieves\nstate-of-the-art (SOTA) performance both in puzzle-solving accuracy and\nout-of-distribution (OOD) generalization in 22 OOD scenarios. Compared to SOTA\ngenerative approaches, which struggle to solve RPMs when the feasible solution\nspace increases, GenVP efficiently generalizes to these challenging setups.\nMoreover, our model demonstrates the ability to produce a wide range of\ncomplete RPMs given a set of abstract rules by effectively capturing the\nrelationships between abstract rules and visual object properties.", "published": "2025-03-30 21:35:26", "link": "http://arxiv.org/abs/2503.23598v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "DASH: Detection and Assessment of Systematic Hallucinations of VLMs", "abstract": "Vision-language models (VLMs) are prone to object hallucinations, where they\nerroneously indicate the presenceof certain objects in an image. Existing\nbenchmarks quantify hallucinations using relatively small, labeled datasets.\nHowever, this approach is i) insufficient to assess hallucinations that arise\nin open-world settings, where VLMs are widely used, and ii) inadequate for\ndetecting systematic errors in VLMs. We propose DASH (Detection and Assessment\nof Systematic Hallucinations), an automatic, large-scale pipeline designed to\nidentify systematic hallucinations of VLMs on real-world images in an\nopen-world setting. A key component is DASH-OPT for image-based retrieval,\nwhere we optimize over the ''natural image manifold'' to generate images that\nmislead the VLM. The output of DASH consists of clusters of real and\nsemantically similar images for which the VLM hallucinates an object. We apply\nDASH to PaliGemma and two LLaVA-NeXT models across 380 object classes and, in\ntotal, find more than 19k clusters with 950k images. We study the transfer of\nthe identified systematic hallucinations to other VLMs and show that\nfine-tuning PaliGemma with the model-specific images obtained with DASH\nmitigates object hallucinations. Code and data are available at\nhttps://YanNeu.github.io/DASH.", "published": "2025-03-30 19:45:09", "link": "http://arxiv.org/abs/2503.23573v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Addressing Model Overcomplexity in Drug-Drug Interaction Prediction With Molecular Fingerprints", "abstract": "Accurately predicting drug-drug interactions (DDIs) is crucial for\npharmaceutical research and clinical safety. Recent deep learning models often\nsuffer from high computational costs and limited generalization across\ndatasets. In this study, we investigate a simpler yet effective approach using\nmolecular representations such as Morgan fingerprints (MFPS), graph-based\nembeddings from graph convolutional networks (GCNs), and transformer-derived\nembeddings from MoLFormer integrated into a straightforward neural network. We\nbenchmark our implementation on DrugBank DDI splits and a drug-drug affinity\n(DDA) dataset from the Food and Drug Administration. MFPS along with MoLFormer\nand GCN representations achieve competitive performance across tasks, even in\nthe more challenging leak-proof split, highlighting the sufficiency of simple\nmolecular representations. Moreover, we are able to identify key molecular\nmotifs and structural patterns relevant to drug interactions via gradient-based\nanalyses using the representations under study. Despite these results, dataset\nlimitations such as insufficient chemical diversity, limited dataset size, and\ninconsistent labeling impact robust evaluation and challenge the need for more\ncomplex approaches. Our work provides a meaningful baseline and emphasizes the\nneed for better dataset curation and progressive complexity scaling.", "published": "2025-03-30 18:27:01", "link": "http://arxiv.org/abs/2503.23550v1", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "A Survey on Unlearnable Data", "abstract": "Unlearnable data (ULD) has emerged as an innovative defense technique to\nprevent machine learning models from learning meaningful patterns from specific\ndata, thus protecting data privacy and security. By introducing perturbations\nto the training data, ULD degrades model performance, making it difficult for\nunauthorized models to extract useful representations. Despite the growing\nsignificance of ULD, existing surveys predominantly focus on related fields,\nsuch as adversarial attacks and machine unlearning, with little attention given\nto ULD as an independent area of study. This survey fills that gap by offering\na comprehensive review of ULD, examining unlearnable data generation methods,\npublic benchmarks, evaluation metrics, theoretical foundations and practical\napplications. We compare and contrast different ULD approaches, analyzing their\nstrengths, limitations, and trade-offs related to unlearnability,\nimperceptibility, efficiency and robustness. Moreover, we discuss key\nchallenges, such as balancing perturbation imperceptibility with model\ndegradation and the computational complexity of ULD generation. Finally, we\nhighlight promising future research directions to advance the effectiveness and\napplicability of ULD, underscoring its potential to become a crucial tool in\nthe evolving landscape of data protection in machine learning.", "published": "2025-03-30 17:41:30", "link": "http://arxiv.org/abs/2503.23536v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "BiPVL-Seg: Bidirectional Progressive Vision-Language Fusion with Global-Local Alignment for Medical Image Segmentation", "abstract": "Medical image segmentation typically relies solely on visual data,\noverlooking the rich textual information clinicians use for diagnosis.\nVision-language models attempt to bridge this gap, but existing approaches\noften process visual and textual features independently, resulting in weak\ncross-modal alignment. Simple fusion techniques fail due to the inherent\ndifferences between spatial visual features and sequential text embeddings.\nAdditionally, medical terminology deviates from general language, limiting the\neffectiveness of off-the-shelf text encoders and further hindering\nvision-language alignment. We propose BiPVL-Seg, an end-to-end framework that\nintegrates vision-language fusion and embedding alignment through architectural\nand training innovations, where both components reinforce each other to enhance\nmedical image segmentation. BiPVL-Seg introduces bidirectional progressive\nfusion in the architecture, which facilitates stage-wise information exchange\nbetween vision and text encoders. Additionally, it incorporates global-local\ncontrastive alignment, a training objective that enhances the text encoder's\ncomprehension by aligning text and vision embeddings at both class and concept\nlevels. Extensive experiments on diverse medical imaging benchmarks across CT\nand MR modalities demonstrate BiPVL-Seg's superior performance when compared\nwith state-of-the-art methods in complex multi-class segmentation. Source code\nis available in this GitHub repository.", "published": "2025-03-30 17:34:39", "link": "http://arxiv.org/abs/2503.23534v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Buffer is All You Need: Defending Federated Learning against Backdoor Attacks under Non-iids via Buffering", "abstract": "Federated Learning (FL) is a popular paradigm enabling clients to jointly\ntrain a global model without sharing raw data. However, FL is known to be\nvulnerable towards backdoor attacks due to its distributed nature. As\nparticipants, attackers can upload model updates that effectively compromise\nFL. What's worse, existing defenses are mostly designed under\nindependent-and-identically-distributed (iid) settings, hence neglecting the\nfundamental non-iid characteristic of FL. Here we propose FLBuff for tackling\nbackdoor attacks even under non-iids. The main challenge for such defenses is\nthat non-iids bring benign and malicious updates closer, hence harder to\nseparate. FLBuff is inspired by our insight that non-iids can be modeled as\nomni-directional expansion in representation space while backdoor attacks as\nuni-directional. This leads to the key design of FLBuff, i.e., a\nsupervised-contrastive-learning model extracting penultimate-layer\nrepresentations to create a large in-between buffer layer. Comprehensive\nevaluations demonstrate that FLBuff consistently outperforms state-of-the-art\ndefenses.", "published": "2025-03-30 16:46:14", "link": "http://arxiv.org/abs/2503.23511v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model", "abstract": "Omnidirectional depth perception is essential for mobile robotics\napplications that require scene understanding across a full 360{\\deg} field of\nview. Camera-based setups offer a cost-effective option by using stereo depth\nestimation to generate dense, high-resolution depth maps without relying on\nexpensive active sensing. However, existing omnidirectional stereo matching\napproaches achieve only limited depth accuracy across diverse environments,\ndepth ranges, and lighting conditions, due to the scarcity of real-world data.\nWe present DFI-OmniStereo, a novel omnidirectional stereo matching method that\nleverages a large-scale pre-trained foundation model for relative monocular\ndepth estimation within an iterative optimization-based stereo matching\narchitecture. We introduce a dedicated two-stage training strategy to utilize\nthe relative monocular depth features for our omnidirectional stereo matching\nbefore scale-invariant fine-tuning. DFI-OmniStereo achieves state-of-the-art\nresults on the real-world Helvipad dataset, reducing disparity MAE by\napproximately 16% compared to the previous best omnidirectional stereo method.", "published": "2025-03-30 16:24:22", "link": "http://arxiv.org/abs/2503.23502v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Revisiting the Relationship between Adversarial and Clean Training: Why Clean Training Can Make Adversarial Training Better", "abstract": "Adversarial training (AT) is an effective technique for enhancing adversarial\nrobustness, but it usually comes at the cost of a decline in generalization\nability. Recent studies have attempted to use clean training to assist\nadversarial training, yet there are contradictions among the conclusions. We\ncomprehensively summarize the representative strategies and, with a focus on\nthe multi - view hypothesis, provide a unified explanation for the\ncontradictory phenomena among different studies. In addition, we conduct an in\n- depth analysis of the knowledge combinations transferred from clean - trained\nmodels to adversarially - trained models in previous studies, and find that\nthey can be divided into two categories: reducing the learning difficulty and\nproviding correct guidance. Based on this finding, we propose a new idea of\nleveraging clean training to further improve the performance of advanced AT\nmethods.We reveal that the problem of generalization degradation faced by AT\npartly stems from the difficulty of adversarial training in learning certain\nsample features, and this problem can be alleviated by making full use of clean\ntraining.", "published": "2025-03-30 15:58:41", "link": "http://arxiv.org/abs/2504.00038v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "POINT$^{2}$: A Polymer Informatics Training and Testing Database", "abstract": "The advancement of polymer informatics has been significantly propelled by\nthe integration of machine learning (ML) techniques, enabling the rapid\nprediction of polymer properties and expediting the discovery of\nhigh-performance polymeric materials. However, the field lacks a standardized\nworkflow that encompasses prediction accuracy, uncertainty quantification, ML\ninterpretability, and polymer synthesizability. In this study, we introduce\nPOINT$^{2}$ (POlymer INformatics Training and Testing), a comprehensive\nbenchmark database and protocol designed to address these critical challenges.\nLeveraging the existing labeled datasets and the unlabeled PI1M dataset, a\ncollection of approximately one million virtual polymers generated via a\nrecurrent neural network trained on the realistic polymers, we develop an\nensemble of ML models, including Quantile Random Forests, Multilayer\nPerceptrons with dropout, Graph Neural Networks, and pretrained large language\nmodels. These models are coupled with diverse polymer representations such as\nMorgan, MACCS, RDKit, Topological, Atom Pair fingerprints, and graph-based\ndescriptors to achieve property predictions, uncertainty estimations, model\ninterpretability, and template-based polymerization synthesizability across a\nspectrum of properties, including gas permeability, thermal conductivity, glass\ntransition temperature, melting temperature, fractional free volume, and\ndensity. The POINT$^{2}$ database can serve as a valuable resource for the\npolymer informatics community for polymer discovery and optimization.", "published": "2025-03-30 15:46:01", "link": "http://arxiv.org/abs/2503.23491v1", "categories": ["cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "A Systematic Decade Review of Trip Route Planning with Travel Time Estimation based on User Preferences and Behavior", "abstract": "This paper systematically explores the advancements in adaptive trip route\nplanning and travel time estimation (TTE) through Artificial Intelligence (AI).\nWith the increasing complexity of urban transportation systems, traditional\nnavigation methods often struggle to accommodate dynamic user preferences,\nreal-time traffic conditions, and scalability requirements. This study explores\nthe contributions of established AI techniques, including Machine Learning\n(ML), Reinforcement Learning (RL), and Graph Neural Networks (GNNs), alongside\nemerging methodologies like Meta-Learning, Explainable AI (XAI), Generative AI,\nand Federated Learning. In addition to highlighting these innovations, the\npaper identifies critical challenges such as ethical concerns, computational\nscalability, and effective data integration, which must be addressed to advance\nthe field. The paper concludes with recommendations for leveraging AI to build\nefficient, transparent, and sustainable navigation systems.", "published": "2025-03-30 15:41:44", "link": "http://arxiv.org/abs/2503.23486v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "ViT-Linearizer: Distilling Quadratic Knowledge into Linear-Time Vision Models", "abstract": "Vision Transformers (ViTs) have delivered remarkable progress through global\nself-attention, yet their quadratic complexity can become prohibitive for\nhigh-resolution inputs. In this work, we present ViT-Linearizer, a\ncross-architecture distillation framework that transfers rich ViT\nrepresentations into a linear-time, recurrent-style model. Our approach\nleverages 1) activation matching, an intermediate constraint that encourages\nstudent to align its token-wise dependencies with those produced by the\nteacher, and 2) masked prediction, a contextual reconstruction objective that\nrequires the student to predict the teacher's representations for unseen\n(masked) tokens, to effectively distill the quadratic self-attention knowledge\ninto the student while maintaining efficient complexity. Empirically, our\nmethod provides notable speedups particularly for high-resolution tasks,\nsignificantly addressing the hardware challenges in inference. Additionally, it\nalso elevates Mamba-based architectures' performance on standard vision\nbenchmarks, achieving a competitive 84.3% top-1 accuracy on ImageNet with a\nbase-sized model. Our results underscore the good potential of RNN-based\nsolutions for large-scale visual tasks, bridging the gap between theoretical\nefficiency and real-world practice.", "published": "2025-03-30 15:35:24", "link": "http://arxiv.org/abs/2504.00037v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Handling Delay in Real-Time Reinforcement Learning", "abstract": "Real-time reinforcement learning (RL) introduces several challenges. First,\npolicies are constrained to a fixed number of actions per second due to\nhardware limitations. Second, the environment may change while the network is\nstill computing an action, leading to observational delay. The first issue can\npartly be addressed with pipelining, leading to higher throughput and\npotentially better policies. However, the second issue remains: if each neuron\noperates in parallel with an execution time of $\\tau$, an $N$-layer\nfeed-forward network experiences observation delay of $\\tau N$. Reducing the\nnumber of layers can decrease this delay, but at the cost of the network's\nexpressivity. In this work, we explore the trade-off between minimizing delay\nand network's expressivity. We present a theoretically motivated solution that\nleverages temporal skip connections combined with history-augmented\nobservations. We evaluate several architectures and show that those\nincorporating temporal skip connections achieve strong performance across\nvarious neuron execution times, reinforcement learning algorithms, and\nenvironments, including four Mujoco tasks and all MinAtar games. Moreover, we\ndemonstrate parallel neuron computation can accelerate inference by 6-350% on\nstandard hardware. Our investigation into temporal skip connections and\nparallel computations paves the way for more efficient RL agents in real-time\nsetting.", "published": "2025-03-30 15:30:27", "link": "http://arxiv.org/abs/2503.23478v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Multi-Dimensional AGV Path Planning in 3D Warehouses Using Ant Colony Optimization and Advanced Neural Networks", "abstract": "Within modern warehouse scenarios, the rapid expansion of e-commerce and\nincreasingly complex, multi-level storage environments have exposed the\nlimitations of traditional AGV (Automated Guided Vehicle) path planning\nmethods--often reliant on static 2D models and expert-tuned heuristics that\nstruggle to handle dynamic traffic and congestion. Addressing these\nlimitations, this paper introduces a novel AGV path planning approach for 3D\nwarehouse environments that leverages a hybrid framework combining ACO (Ant\nColony Optimization) with deep learning models, called NAHACO (Neural Adaptive\nHeuristic Ant Colony Optimization). NAHACO integrates three key innovations:\nfirst, an innovative heuristic algorithm for 3D warehouse cargo modeling using\nmultidimensional tensors, which addresses the challenge of achieving superior\nheuristic accuracy; second, integration of a congestion-aware loss function\nwithin the ACO framework to adjust path costs based on traffic and capacity\nconstraints, called CARL (Congestion-Aware Reinforce Loss), enabling dynamic\nheuristic calibration for optimizing ACO-based path planning; and third, an\nadaptive attention mechanism that captures multi-scale spatial features,\nthereby addressing dynamic heuristic calibration for further optimization of\nACO-based path planning and AGV navigation. NAHACO significantly boosts path\nplanning efficiency, yielding faster computation times and superior performance\nover both vanilla and state-of-the-art methods, while automatically adapting to\nwarehouse constraints for real-time optimization. NAHACO outperforms\nstate-of-the-art methods, lowering the total cost by up to 24.7% on TSP\nbenchmarks. In warehouse tests, NAHACO cuts cost by up to 41.5% and congestion\nby up to 56.1% compared to previous methods.", "published": "2025-03-30 14:09:21", "link": "http://arxiv.org/abs/2504.01985v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Improving Diseases Predictions Utilizing External Bio-Banks", "abstract": "Machine learning has been successfully used in critical domains, such as\nmedicine. However, extracting meaningful insights from biomedical data is often\nconstrained by the lack of their available disease labels. In this research, we\ndemonstrate how machine learning can be leveraged to enhance explainability and\nuncover biologically meaningful associations, even when predictive improvements\nin disease modeling are limited. We train LightGBM models from scratch on our\ndataset (10K) to impute metabolomics features and apply them to the UK Biobank\n(UKBB) for downstream analysis. The imputed metabolomics features are then used\nin survival analysis to assess their impact on disease-related risk factors. As\na result, our approach successfully identified biologically relevant\nconnections that were not previously known to the predictive models.\nAdditionally, we applied a genome-wide association study (GWAS) on key\nmetabolomics features, revealing a link between vascular dementia and smoking.\nAlthough being a well-established epidemiological relationship, this link was\nnot embedded in the model's training data, which validated the method's ability\nto extract meaningful signals. Furthermore, by integrating survival models as\ninputs in the 10K data, we uncovered associations between metabolic substances\nand obesity, demonstrating the ability to infer disease risk for future\npatients without requiring direct outcome labels. These findings highlight the\npotential of leveraging external bio-banks to extract valuable biomedical\ninsights, even in data-limited scenarios. Our results demonstrate that machine\nlearning models trained on smaller datasets can still be used to uncover real\nbiological associations when carefully integrated with survival analysis and\ngenetic studies.", "published": "2025-03-30 13:05:20", "link": "http://arxiv.org/abs/2504.00036v1", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "From Content Creation to Citation Inflation: A GenAI Case Study", "abstract": "This paper investigates the presence and impact of questionable, AI-generated\nacademic papers on widely used preprint repositories, with a focus on their\nrole in citation manipulation. Motivated by suspicious patterns observed in\npublications related to our ongoing research on GenAI-enhanced cybersecurity,\nwe identify clusters of questionable papers and profiles. These papers\nfrequently exhibit minimal technical content, repetitive structure,\nunverifiable authorship, and mutually reinforcing citation patterns among a\nrecurring set of authors. To assess the feasibility and implications of such\npractices, we conduct a controlled experiment: generating a fake paper using\nGenAI, embedding citations to suspected questionable publications, and\nuploading it to one such repository (ResearchGate). Our findings demonstrate\nthat such papers can bypass platform checks, remain publicly accessible, and\ncontribute to inflating citation metrics like the H-index and i10-index. We\npresent a detailed analysis of the mechanisms involved, highlight systemic\nweaknesses in content moderation, and offer recommendations for improving\nplatform accountability and preserving academic integrity in the age of GenAI.", "published": "2025-03-30 12:17:26", "link": "http://arxiv.org/abs/2503.23414v1", "categories": ["cs.DL", "cs.AI", "cs.CR"], "primary_category": "cs.DL"}
{"title": "GMapLatent: Geometric Mapping in Latent Space", "abstract": "Cross-domain generative models based on encoder-decoder AI architectures have\nattracted much attention in generating realistic images, where domain alignment\nis crucial for generation accuracy. Domain alignment methods usually deal\ndirectly with the initial distribution; however, mismatched or mixed clusters\ncan lead to mode collapse and mixture problems in the decoder, compromising\nmodel generalization capabilities. In this work, we innovate a cross-domain\nalignment and generation model that introduces a canonical latent space\nrepresentation based on geometric mapping to align the cross-domain latent\nspaces in a rigorous and precise manner, thus avoiding mode collapse and\nmixture in the encoder-decoder generation architectures. We name this model\nGMapLatent. The core of the method is to seamlessly align latent spaces with\nstrict cluster correspondence constraints using the canonical parameterizations\nof cluster-decorated latent spaces. We first (1) transform the latent space to\na canonical parameter domain by composing barycenter translation, optimal\ntransport merging and constrained harmonic mapping, and then (2) compute\ngeometric registration with cluster constraints over the canonical parameter\ndomains. This process realizes a bijective (one-to-one and onto) mapping\nbetween newly transformed latent spaces and generates a precise alignment of\ncluster pairs. Cross-domain generation is then achieved through the aligned\nlatent spaces embedded in the encoder-decoder pipeline. Experiments on\ngray-scale and color images validate the efficiency, efficacy and applicability\nof GMapLatent, and demonstrate that the proposed model has superior performance\nover existing models.", "published": "2025-03-30 12:02:36", "link": "http://arxiv.org/abs/2503.23407v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Diffusion Meets Few-shot Class Incremental Learning", "abstract": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, miniImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.", "published": "2025-03-30 11:20:08", "link": "http://arxiv.org/abs/2503.23402v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Scaling Auditory Cognition via Test-Time Compute in Audio Language Models", "abstract": "Large language models (LLMs) have shown exceptional versatility in natural\nlanguage processing, prompting recent efforts to extend their multimodal\ncapabilities to speech processing through the development of audio large\nlanguage models (Audio LLMs). While Audio LLMs excel in tasks such as speech\nrecognition and synthesis, it remains unclear how they perform when faced with\nthe auditory cognitive challenges posed by real-world environments, such as\naudio comprehension and listening recall, particularly in the presence of\nbackground noise or overlapping speech. Unlike text-based LLMs, which have\naccess to vast amounts of text data for pre-training, retraining Audio LLMs\nwith diverse auditory cognitive scenes is difficult due to the limited datasets\nthat simulate real-world auditory cognitive scenarios and the challenge of\nacquiring auditory cognitive labels for training. While test-time compute (TTC)\nmethods have been shown to enhance the capabilities of text-based LLMs during\ninference, a key challenge lies in designing these TTC methods to improve the\nauditory capabilities of Audio LLMs. This study aims to address these two\nresearch gaps by: i) exploring the auditory cognitive capabilities of Audio\nLLMs, and ii) enhancing their capabilities using TTC approaches. We have\ninvestigated five different Audio LLMs for auditory cognition using a\n\\textit{self-collected} database and have proposed five TTC approaches to\nenhance auditory cognitive capabilities during inference. Our findings reveal\nthat Audio LLMs performance decreases in more challenging auditory cognitive\ntasks. The proposed TTC approaches significantly enhance cognitive auditory\ncapabilities, advancing the development of more adaptable and resilient Audio\nLLMs for practical applications such as assistive listening devices,\nvoice-based AI assistants, and communication technologies.", "published": "2025-03-30 11:04:18", "link": "http://arxiv.org/abs/2503.23395v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Spatiotemporal Learning of Brain Dynamics from fMRI Using Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric Applications", "abstract": "Understanding how the brain's complex nonlinear dynamics give rise to\nadaptive cognition and behavior is a central challenge in neuroscience. These\ndynamics exhibit scale-free and multifractal properties, influencing the\nreconfiguration of neural networks. However, conventional neuroimaging models\nare constrained by linear and stationary assumptions, limiting their ability to\ncapture these processes. Transformer-based architectures, known for capturing\nlong-range dependencies, align well with the brain's hierarchical and temporal\norganization. We introduce Multi-Band Brain Net (MBBN), a transformer-based\nframework that models frequency-specific spatiotemporal brain dynamics from\nfMRI by integrating scale-free network principles with frequency-resolved\nmulti-band self-attention. Trained on three large-scale neuroimaging cohorts\n(UK Biobank, ABCD, ABIDE) totaling 45,951 individuals, MBBN reveals previously\nundetectable frequency-dependent network interactions, shedding light on\nconnectivity disruptions in psychiatric conditions (ADHD, ASD, depression).\nThis validation shows robust generalizability and highlights core neural\nprinciples conserved across populations. MBBN achieves up to 30.59% higher\npredictive accuracy than state-of-the-art methods, demonstrating the advantage\nof frequency-informed spatiotemporal modeling in capturing latent neural\ncomputations. MBBN's interpretability uncovers novel frequency-specific\nbiomarkers for neurodevelopmental disorders, providing insights into the\nhierarchical organization of brain function. By offering an interpretable\nframework for spatiotemporal learning, MBBN provides insights into how neural\ncomputations underpin cognitive function and psychiatric vulnerability, with\nimplications for brain decoding, cognitive neuroscience, and precision\npsychiatry.", "published": "2025-03-30 10:56:50", "link": "http://arxiv.org/abs/2503.23394v1", "categories": ["q-bio.NC", "cs.AI"], "primary_category": "q-bio.NC"}
{"title": "Pareto Continual Learning: Preference-Conditioned Learning and Adaption for Dynamic Stability-Plasticity Trade-off", "abstract": "Continual learning aims to learn multiple tasks sequentially. A key challenge\nin continual learning is balancing between two objectives: retaining knowledge\nfrom old tasks (stability) and adapting to new tasks (plasticity). Experience\nreplay methods, which store and replay past data alongside new data, have\nbecome a widely adopted approach to mitigate catastrophic forgetting. However,\nthese methods neglect the dynamic nature of the stability-plasticity trade-off\nand aim to find a fixed and unchanging balance, resulting in suboptimal\nadaptation during training and inference. In this paper, we propose Pareto\nContinual Learning (ParetoCL), a novel framework that reformulates the\nstability-plasticity trade-off in continual learning as a multi-objective\noptimization (MOO) problem. ParetoCL introduces a preference-conditioned model\nto efficiently learn a set of Pareto optimal solutions representing different\ntrade-offs and enables dynamic adaptation during inference. From a\ngeneralization perspective, ParetoCL can be seen as an objective augmentation\napproach that learns from different objective combinations of stability and\nplasticity. Extensive experiments across multiple datasets and settings\ndemonstrate that ParetoCL outperforms state-of-the-art methods and adapts to\ndiverse continual learning scenarios.", "published": "2025-03-30 10:38:36", "link": "http://arxiv.org/abs/2503.23390v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation", "abstract": "Recent vision-language models (VLMs) face significant challenges in test-time\nadaptation to novel domains. While cache-based methods show promise by\nleveraging historical information, they struggle with both caching unreliable\nfeature-label pairs and indiscriminately using single-class information during\nquerying, significantly compromising adaptation accuracy. To address these\nlimitations, we propose COSMIC (Clique-Oriented Semantic Multi-space\nIntegration for CLIP), a robust test-time adaptation framework that enhances\nadaptability through multi-granular, cross-modal semantic caching and\ngraph-based querying mechanisms. Our framework introduces two key innovations:\nDual Semantics Graph (DSG) and Clique Guided Hyper-class (CGH). The Dual\nSemantics Graph constructs complementary semantic spaces by incorporating\ntextual features, coarse-grained CLIP features, and fine-grained DINOv2\nfeatures to capture rich semantic relationships. Building upon these dual\ngraphs, the Clique Guided Hyper-class component leverages structured class\nrelationships to enhance prediction robustness through correlated class\nselection. Extensive experiments demonstrate COSMIC's superior performance\nacross multiple benchmarks, achieving significant improvements over\nstate-of-the-art methods: 15.81% gain on out-of-distribution tasks and 5.33% on\ncross-domain generation with CLIP RN-50. Code is available at\ngithub.com/hf618/COSMIC.", "published": "2025-03-30 10:34:45", "link": "http://arxiv.org/abs/2503.23388v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "KernelDNA: Dynamic Kernel Sharing via Decoupled Naive Adapters", "abstract": "Dynamic convolution enhances model capacity by adaptively combining multiple\nkernels, yet faces critical trade-offs: prior works either (1) incur\nsignificant parameter overhead by scaling kernel numbers linearly, (2)\ncompromise inference speed through complex kernel interactions, or (3) struggle\nto jointly optimize dynamic attention and static kernels. We also observe that\npre-trained Convolutional Neural Networks (CNNs) exhibit inter-layer redundancy\nakin to that in Large Language Models (LLMs). Specifically, dense convolutional\nlayers can be efficiently replaced by derived ``child\" layers generated from a\nshared ``parent\" convolutional kernel through an adapter.\n  To address these limitations and implement the weight-sharing mechanism, we\npropose a lightweight convolution kernel plug-in, named KernelDNA. It decouples\nkernel adaptation into input-dependent dynamic routing and pre-trained static\nmodulation, ensuring both parameter efficiency and hardware-friendly inference.\nUnlike existing dynamic convolutions that expand parameters via multi-kernel\nensembles, our method leverages cross-layer weight sharing and adapter-based\nmodulation, enabling dynamic kernel specialization without altering the\nstandard convolution structure. This design preserves the native computational\nefficiency of standard convolutions while enhancing representation power\nthrough input-adaptive kernel adjustments. Experiments on image classification\nand dense prediction tasks demonstrate that KernelDNA achieves state-of-the-art\naccuracy-efficiency balance among dynamic convolution variants. Our codes are\navailable at https://github.com/haiduo/KernelDNA.", "published": "2025-03-30 09:54:07", "link": "http://arxiv.org/abs/2503.23379v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchronization", "abstract": "This paper introduces JavisDiT, a novel Joint Audio-Video Diffusion\nTransformer designed for synchronized audio-video generation (JAVG). Built upon\nthe powerful Diffusion Transformer (DiT) architecture, JavisDiT is able to\ngenerate high-quality audio and video content simultaneously from open-ended\nuser prompts. To ensure optimal synchronization, we introduce a fine-grained\nspatio-temporal alignment mechanism through a Hierarchical Spatial-Temporal\nSynchronized Prior (HiST-Sypo) Estimator. This module extracts both global and\nfine-grained spatio-temporal priors, guiding the synchronization between the\nvisual and auditory components. Furthermore, we propose a new benchmark,\nJavisBench, consisting of 10,140 high-quality text-captioned sounding videos\nspanning diverse scenes and complex real-world scenarios. Further, we\nspecifically devise a robust metric for evaluating the synchronization between\ngenerated audio-video pairs in real-world complex content. Experimental results\ndemonstrate that JavisDiT significantly outperforms existing methods by\nensuring both high-quality generation and precise synchronization, setting a\nnew standard for JAVG tasks. Our code, model, and dataset will be made publicly\navailable at https://javisdit.github.io/.", "published": "2025-03-30 09:40:42", "link": "http://arxiv.org/abs/2503.23377v1", "categories": ["cs.CV", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A Hybrid Reinforcement Learning Framework for Hard Latency Constrained Resource Scheduling", "abstract": "In the forthcoming 6G era, extend reality (XR) has been regarded as an\nemerging application for ultra-reliable and low latency communications (URLLC)\nwith new traffic characteristics and more stringent requirements. In addition\nto the quasi-periodical traffic in XR, burst traffic with both large frame size\nand random arrivals in some real world low latency communication scenarios has\nbecome the leading cause of network congestion or even collapse, and there\nstill lacks an efficient algorithm for the resource scheduling problem under\nburst traffic with hard latency constraints. We propose a novel hybrid\nreinforcement learning framework for resource scheduling with hard latency\nconstraints (HRL-RSHLC), which reuses polices from both old policies learned\nunder other similar environments and domain-knowledge-based (DK) policies\nconstructed using expert knowledge to improve the performance. The joint\noptimization of the policy reuse probabilities and new policy is formulated as\nan Markov Decision Problem (MDP), which maximizes the hard-latency constrained\neffective throughput (HLC-ET) of users. We prove that the proposed HRL-RSHLC\ncan converge to KKT points with an arbitrary initial point. Simulations show\nthat HRL-RSHLC can achieve superior performance with faster convergence speed\ncompared to baseline algorithms.", "published": "2025-03-30 09:39:13", "link": "http://arxiv.org/abs/2504.03721v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior", "abstract": "Video diffusion models (VDMs) have advanced significantly in recent years,\nenabling the generation of highly realistic videos and drawing the attention of\nthe community in their potential as world simulators. However, despite their\ncapabilities, VDMs often fail to produce physically plausible videos due to an\ninherent lack of understanding of physics, resulting in incorrect dynamics and\nevent sequences. To address this limitation, we propose a novel two-stage\nimage-to-video generation framework that explicitly incorporates physics with\nvision and language informed physical prior. In the first stage, we employ a\nVision Language Model (VLM) as a coarse-grained motion planner, integrating\nchain-of-thought and physics-aware reasoning to predict a rough motion\ntrajectories/changes that approximate real-world physical dynamics while\nensuring the inter-frame consistency. In the second stage, we use the predicted\nmotion trajectories/changes to guide the video generation of a VDM. As the\npredicted motion trajectories/changes are rough, noise is added during\ninference to provide freedom to the VDM in generating motion with more fine\ndetails. Extensive experimental results demonstrate that our framework can\nproduce physically plausible motion, and comparative evaluations highlight the\nnotable superiority of our approach over existing methods. More video results\nare available on our Project Page:\nhttps://madaoer.github.io/projects/physically_plausible_video_generation.", "published": "2025-03-30 09:03:09", "link": "http://arxiv.org/abs/2503.23368v3", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MiZero: The Shadowy Defender Against Text Style Infringements", "abstract": "In-Context Learning (ICL) and efficient fine-tuning methods significantly\nenhanced the efficiency of applying Large Language Models (LLMs) to downstream\ntasks. However, they also raise concerns about the imitation and infringement\nof personal creative data. Current methods for data copyright protection\nprimarily focuses on content security but lacks effectiveness in protecting the\ncopyrights of text styles. In this paper, we introduce a novel implicit\nzero-watermarking scheme, namely MiZero. This scheme establishes a precise\nwatermark domain to protect the copyrighted style, surpassing traditional\nwatermarking methods that distort the style characteristics. Specifically, we\nemploy LLMs to extract condensed-lists utilizing the designed instance\ndelimitation mechanism. These lists guide MiZero in generating the watermark.\nExtensive experiments demonstrate that MiZero effectively verifies text style\ncopyright ownership against AI imitation.", "published": "2025-03-30 08:19:12", "link": "http://arxiv.org/abs/2504.00035v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Object Isolated Attention for Consistent Story Visualization", "abstract": "Open-ended story visualization is a challenging task that involves generating\ncoherent image sequences from a given storyline. One of the main difficulties\nis maintaining character consistency while creating natural and contextually\nfitting scenes--an area where many existing methods struggle. In this paper, we\npropose an enhanced Transformer module that uses separate self attention and\ncross attention mechanisms, leveraging prior knowledge from pre-trained\ndiffusion models to ensure logical scene creation. The isolated self attention\nmechanism improves character consistency by refining attention maps to reduce\nfocus on irrelevant areas and highlight key features of the same character.\nMeanwhile, the isolated cross attention mechanism independently processes each\ncharacter's features, avoiding feature fusion and further strengthening\nconsistency. Notably, our method is training-free, allowing the continuous\ngeneration of new characters and storylines without re-tuning. Both qualitative\nand quantitative evaluations show that our approach outperforms current\nmethods, demonstrating its effectiveness.", "published": "2025-03-30 08:16:52", "link": "http://arxiv.org/abs/2503.23353v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Survey of WebAgents: Towards Next-Generation AI Agents for Web Automation with Large Foundation Models", "abstract": "With the advancement of web techniques, they have significantly\nrevolutionized various aspects of people's lives. Despite the importance of the\nweb, many tasks performed on it are repetitive and time-consuming, negatively\nimpacting overall quality of life. To efficiently handle these tedious daily\ntasks, one of the most promising approaches is to advance autonomous agents\nbased on Artificial Intelligence (AI) techniques, referred to as AI Agents, as\nthey can operate continuously without fatigue or performance degradation. In\nthe context of the web, leveraging AI Agents -- termed WebAgents -- to\nautomatically assist people in handling tedious daily tasks can dramatically\nenhance productivity and efficiency. Recently, Large Foundation Models (LFMs)\ncontaining billions of parameters have exhibited human-like language\nunderstanding and reasoning capabilities, showing proficiency in performing\nvarious complex tasks. This naturally raises the question: `Can LFMs be\nutilized to develop powerful AI Agents that automatically handle web tasks,\nproviding significant convenience to users?' To fully explore the potential of\nLFMs, extensive research has emerged on WebAgents designed to complete daily\nweb tasks according to user instructions, significantly enhancing the\nconvenience of daily human life. In this survey, we comprehensively review\nexisting research studies on WebAgents across three key aspects: architectures,\ntraining, and trustworthiness. Additionally, several promising directions for\nfuture research are explored to provide deeper insights.", "published": "2025-03-30 08:15:44", "link": "http://arxiv.org/abs/2503.23350v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Artificial intelligence and democracy: Towards digital authoritarianism or a democratic upgrade?", "abstract": "Do robots vote? Do machines make decisions instead of us? No, (at least not\nyet), but this is something that could happen. The impact of Artificial\nIntelligence (AI) on democracy is a complex issue that requires thorough\nresearch and careful regulation. At the most important level, that of the\nelectoral process, it is noted that it is not determined by the AI, but it is\ngreatly impacted by its multiple applications. New types of online campaigns,\ndriven by AI applications, are replacing traditional ones. The potential for\nmanipulating voters and indirectly influencing the electoral outcome should not\nbe underestimated. Certainly, instances of voter manipulation are not absent\nfrom traditional political campaigns, with the only difference being that\ndigital manipulation is often carried out without our knowledge, e.g. by\nmonitoring our behavior on social media. Nevertheless, we should not overlook\nthe positive impact that AI has in the upgrading of democratic institutions by\nproviding a forum for participation in decision-making. In this context, as a\nfirst step, we look into the potential jeopardization of democratic processes\nposed by the use of AI tools. Secondly, we consider the possibility of\nstrengthening democratic processes by using AI, as well as the democratization\nof AI itself through the possibilities it offers. And thirdly, the impact of AI\non the representative system is also discussed. The paper is concluded with\nrecommendations and conclusions.", "published": "2025-03-30 06:43:54", "link": "http://arxiv.org/abs/2504.01034v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "A Multi-Agent Framework with Automated Decision Rule Optimization for Cross-Domain Misinformation Detection", "abstract": "Misinformation spans various domains, but detection methods trained on\nspecific domains often perform poorly when applied to others. With the rapid\ndevelopment of Large Language Models (LLMs), researchers have begun to utilize\nLLMs for cross-domain misinformation detection. However, existing LLM-based\nmethods often fail to adequately analyze news in the target domain, limiting\ntheir detection capabilities. More importantly, these methods typically rely on\nmanually designed decision rules, which are limited by domain knowledge and\nexpert experience, thus limiting the generalizability of decision rules to\ndifferent domains. To address these issues, we propose a MultiAgent Framework\nfor cross-domain misinformation detection with Automated Decision Rule\nOptimization (MARO). Under this framework, we first employs multiple expert\nagents to analyze target-domain news. Subsequently, we introduce a\nquestion-reflection mechanism that guides expert agents to facilitate\nhigherquality analysis. Furthermore, we propose a decision rule optimization\napproach based on carefully-designed cross-domain validation tasks to\niteratively enhance the effectiveness of decision rules in different domains.\nExperimental results and in-depth analysis on commonlyused datasets demonstrate\nthat MARO achieves significant improvements over existing methods.", "published": "2025-03-30 06:08:33", "link": "http://arxiv.org/abs/2503.23329v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring Explainable Multi-player MCTS-minimax Hybrids in Board Game Using Process Mining", "abstract": "Monte-Carlo Tree Search (MCTS) is a family of sampling-based search\nalgorithms widely used for online planning in sequential decision-making\ndomains and at the heart of many recent advances in artificial intelligence.\nUnderstanding the behavior of MCTS agents is difficult for developers and users\ndue to the frequently large and complex search trees that result from the\nsimulation of many possible futures, their evaluations, and their\nrelationships. This paper presents our ongoing investigation into potential\nexplanations for the decision-making and behavior of MCTS. A weakness of MCTS\nis that it constructs a highly selective tree and, as a result, can miss\ncrucial moves and fall into tactical traps. Full-width minimax search\nconstitutes the solution. We integrate shallow minimax search into the rollout\nphase of multi-player MCTS and use process mining technique to explain agents'\nstrategies in 3v3 checkers.", "published": "2025-03-30 05:48:53", "link": "http://arxiv.org/abs/2503.23326v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AI Agents in Engineering Design: A Multi-Agent Framework for Aesthetic and Aerodynamic Car Design", "abstract": "We introduce the concept of \"Design Agents\" for engineering applications,\nparticularly focusing on the automotive design process, while emphasizing that\nour approach can be readily extended to other engineering and design domains.\nOur framework integrates AI-driven design agents into the traditional\nengineering workflow, demonstrating how these specialized computational agents\ninteract seamlessly with engineers and designers to augment creativity, enhance\nefficiency, and significantly accelerate the overall design cycle. By\nautomating and streamlining tasks traditionally performed manually, such as\nconceptual sketching, styling enhancements, 3D shape retrieval and generative\nmodeling, computational fluid dynamics (CFD) meshing, and aerodynamic\nsimulations, our approach reduces certain aspects of the conventional workflow\nfrom weeks and days down to minutes. These agents leverage state-of-the-art\nvision-language models (VLMs), large language models (LLMs), and geometric deep\nlearning techniques, providing rapid iteration and comprehensive design\nexploration capabilities. We ground our methodology in industry-standard\nbenchmarks, encompassing a wide variety of conventional automotive designs, and\nutilize high-fidelity aerodynamic simulations to ensure practical and\napplicable outcomes. Furthermore, we present design agents that can swiftly and\naccurately predict simulation outcomes, empowering engineers and designers to\nengage in more informed design optimization and exploration. This research\nunderscores the transformative potential of integrating advanced generative AI\ntechniques into complex engineering tasks, paving the way for broader adoption\nand innovation across multiple engineering disciplines.", "published": "2025-03-30 04:57:17", "link": "http://arxiv.org/abs/2503.23315v1", "categories": ["cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.AI"}
{"title": "LaViC: Adapting Large Vision-Language Models to Visually-Aware Conversational Recommendation", "abstract": "Conversational recommender systems engage users in dialogues to refine their\nneeds and provide more personalized suggestions. Although textual information\nsuffices for many domains, visually driven categories such as fashion or home\ndecor potentially require detailed visual information related to color, style,\nor design. To address this challenge, we propose LaViC (Large Vision-Language\nConversational Recommendation Framework), a novel approach that integrates\ncompact image representations into dialogue-based recommendation systems. LaViC\nleverages a large vision-language model in a two-stage process: (1) visual\nknowledge self-distillation, which condenses product images from hundreds of\ntokens into a small set of visual tokens in a self-distillation manner,\nsignificantly reducing computational overhead, and (2) recommendation prompt\ntuning, which enables the model to incorporate both dialogue context and\ndistilled visual tokens, providing a unified mechanism for capturing textual\nand visual features. To support rigorous evaluation of visually-aware\nconversational recommendation, we construct a new dataset by aligning Reddit\nconversations with Amazon product listings across multiple visually oriented\ncategories (e.g., fashion, beauty, and home). This dataset covers realistic\nuser queries and product appearances in domains where visual details are\ncrucial. Extensive experiments demonstrate that LaViC significantly outperforms\ntext-only conversational recommendation methods and open-source vision-language\nbaselines. Moreover, LaViC achieves competitive or superior accuracy compared\nto prominent proprietary baselines (e.g., GPT-3.5-turbo, GPT-4o-mini, and\nGPT-4o), demonstrating the necessity of explicitly using visual data for\ncapturing product attributes and showing the effectiveness of our\nvision-language integration. Our code and dataset are available at\nhttps://github.com/jeon185/LaViC.", "published": "2025-03-30 04:44:13", "link": "http://arxiv.org/abs/2503.23312v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "SalesRLAgent: A Reinforcement Learning Approach for Real-Time Sales Conversion Prediction and Optimization", "abstract": "Current approaches to sales conversation analysis and conversion prediction\ntypically rely on Large Language Models (LLMs) combined with basic retrieval\naugmented generation (RAG). These systems, while capable of answering\nquestions, fail to accurately predict conversion probability or provide\nstrategic guidance in real time. In this paper, we present SalesRLAgent, a\nnovel framework leveraging specialized reinforcement learning to predict\nconversion probability throughout sales conversations. Unlike systems from\nKapa.ai, Mendable, Inkeep, and others that primarily use off-the-shelf LLMs for\ncontent generation, our approach treats conversion prediction as a sequential\ndecision problem, training on synthetic data generated using GPT-4O to develop\na specialized probability estimation model. Our system incorporates Azure\nOpenAI embeddings (3072 dimensions), turn-by-turn state tracking, and\nmeta-learning capabilities to understand its own knowledge boundaries.\nEvaluations demonstrate that SalesRLAgent achieves 96.7% accuracy in conversion\nprediction, outperforming LLM-only approaches by 34.7% while offering\nsignificantly faster inference (85ms vs 3450ms for GPT-4). Furthermore,\nintegration with existing sales platforms shows a 43.2% increase in conversion\nrates when representatives utilize our system's real-time guidance.\nSalesRLAgent represents a fundamental shift from content generation to\nstrategic sales intelligence, providing moment-by-moment conversion probability\nestimation with actionable insights for sales professionals.", "published": "2025-03-30 03:56:26", "link": "http://arxiv.org/abs/2503.23303v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GRASP: Municipal Budget AI Chatbots for Enhancing Civic Engagement", "abstract": "There are a growing number of AI applications, but none tailored specifically\nto help residents answer their questions about municipal budget, a topic most\nare interested in but few have a solid comprehension of. In this research\npaper, we propose GRASP, a custom AI chatbot framework which stands for\nGeneration with Retrieval and Action System for Prompts. GRASP provides more\ntruthful and grounded responses to user budget queries than traditional\ninformation retrieval systems like general Large Language Models (LLMs) or web\nsearches. These improvements come from the novel combination of a\nRetrieval-Augmented Generation (RAG) framework (\"Generation with Retrieval\")\nand an agentic workflow (\"Action System\"), as well as prompt engineering\ntechniques, the incorporation of municipal budget domain knowledge, and\ncollaboration with local town officials to ensure response truthfulness. During\ntesting, we found that our GRASP chatbot provided precise and accurate\nresponses for local municipal budget queries 78% of the time, while GPT-4o and\nGemini were only accurate 60% and 35% of the time, respectively. GRASP chatbots\ngreatly reduce the time and effort needed for the general public to get an\nintuitive and correct understanding of their town's budget, thus fostering\ngreater communal discourse, improving government transparency, and allowing\ncitizens to make more informed decisions.", "published": "2025-03-30 03:46:06", "link": "http://arxiv.org/abs/2503.23299v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Two Heads Are Better than One: Model-Weight and Latent-Space Analysis for Federated Learning on Non-iid Data against Poisoning Attacks", "abstract": "Federated Learning is a popular paradigm that enables remote clients to\njointly train a global model without sharing their raw data. However, FL has\nbeen shown to be vulnerable towards model poisoning attacks due to its\ndistributed nature. Particularly, attackers acting as participants can upload\narbitrary model updates that effectively compromise the global model of FL.\nWhile extensive research has been focusing on fighting against these attacks,\nwe find that most of them assume data at remote clients are under iid while in\npractice they are inevitably non-iid. Our benchmark evaluations reveal that\nexisting defenses generally fail to live up to their reputation when applied to\nvarious non-iid scenarios. In this paper, we propose a novel approach,\nGeminiGuard, that aims to address such a significant gap. We design GeminiGuard\nto be lightweight, versatile, and unsupervised so that it aligns well with the\npractical requirements of deploying such defenses. The key challenge from\nnon-iids is that they make benign model updates look more similar to malicious\nones. GeminiGuard is mainly built on two fundamental observations: (1) existing\ndefenses based on either model-weight analysis or latent-space analysis face\nlimitations in covering different MPAs and non-iid scenarios, and (2)\nmodel-weight and latent-space analysis are sufficiently different yet\npotentially complementary methods as MPA defenses. We hence incorporate a novel\nmodel-weight analysis component as well as a custom latent-space analysis\ncomponent in GeminiGuard, aiming to further enhance its defense performance. We\nconduct extensive experiments to evaluate our defense across various settings,\ndemonstrating its effectiveness in countering multiple types of untargeted and\ntargeted MPAs, including adaptive ones. Our comprehensive evaluations show that\nGeminiGuard consistently outperforms SOTA defenses under various settings.", "published": "2025-03-30 02:56:05", "link": "http://arxiv.org/abs/2503.23288v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions", "abstract": "The Model Context Protocol (MCP) is a standardized interface designed to\nenable seamless interaction between AI models and external tools and resources,\nbreaking down data silos and facilitating interoperability across diverse\nsystems. This paper provides a comprehensive overview of MCP, focusing on its\ncore components, workflow, and the lifecycle of MCP servers, which consists of\nthree key phases: creation, operation, and update. We analyze the security and\nprivacy risks associated with each phase and propose strategies to mitigate\npotential threats. The paper also examines the current MCP landscape, including\nits adoption by industry leaders and various use cases, as well as the tools\nand platforms supporting its integration. We explore future directions for MCP,\nhighlighting the challenges and opportunities that will influence its adoption\nand evolution within the broader AI ecosystem. Finally, we offer\nrecommendations for MCP stakeholders to ensure its secure and sustainable\ndevelopment as the AI landscape continues to evolve.", "published": "2025-03-30 01:58:22", "link": "http://arxiv.org/abs/2503.23278v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Improved Ear Verification with Vision Transformers and Overlapping Patches", "abstract": "Ear recognition has emerged as a promising biometric modality due to the\nrelative stability in appearance during adulthood. Although Vision Transformers\n(ViTs) have been widely used in image recognition tasks, their efficiency in\near recognition has been hampered by a lack of attention to overlapping\npatches, which is crucial for capturing intricate ear features. In this study,\nwe evaluate ViT-Tiny (ViT-T), ViT-Small (ViT-S), ViT-Base (ViT-B) and ViT-Large\n(ViT-L) configurations on a diverse set of datasets (OPIB, AWE, WPUT, and\nEarVN1.0), using an overlapping patch selection strategy. Results demonstrate\nthe critical importance of overlapping patches, yielding superior performance\nin 44 of 48 experiments in a structured study. Moreover, upon comparing the\nresults of the overlapping patches with the non-overlapping configurations, the\nincrease is significant, reaching up to 10% for the EarVN1.0 dataset. In terms\nof model performance, the ViT-T model consistently outperformed the ViT-S,\nViT-B, and ViT-L models on the AWE, WPUT, and EarVN1.0 datasets. The highest\nscores were achieved in a configuration with a patch size of 28x28 and a stride\nof 14 pixels. This patch-stride configuration represents 25% of the normalized\nimage area (112x112 pixels) for the patch size and 12.5% of the row or column\nsize for the stride. This study confirms that transformer architectures with\noverlapping patch selection can serve as an efficient and high-performing\noption for ear-based biometric recognition tasks in verification scenarios.", "published": "2025-03-30 01:50:21", "link": "http://arxiv.org/abs/2503.23275v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Coordinated Bimanual Manipulation Policies using State Diffusion and Inverse Dynamics Models", "abstract": "When performing tasks like laundry, humans naturally coordinate both hands to\nmanipulate objects and anticipate how their actions will change the state of\nthe clothes. However, achieving such coordination in robotics remains\nchallenging due to the need to model object movement, predict future states,\nand generate precise bimanual actions. In this work, we address these\nchallenges by infusing the predictive nature of human manipulation strategies\ninto robot imitation learning. Specifically, we disentangle task-related state\ntransitions from agent-specific inverse dynamics modeling to enable effective\nbimanual coordination. Using a demonstration dataset, we train a diffusion\nmodel to predict future states given historical observations, envisioning how\nthe scene evolves. Then, we use an inverse dynamics model to compute robot\nactions that achieve the predicted states. Our key insight is that modeling\nobject movement can help learning policies for bimanual coordination\nmanipulation tasks. Evaluating our framework across diverse simulation and\nreal-world manipulation setups, including multimodal goal configurations,\nbimanual manipulation, deformable objects, and multi-object setups, we find\nthat it consistently outperforms state-of-the-art state-to-action mapping\npolicies. Our method demonstrates a remarkable capacity to navigate multimodal\ngoal configurations and action distributions, maintain stability across\ndifferent control modes, and synthesize a broader range of behaviors than those\npresent in the demonstration dataset.", "published": "2025-03-30 01:25:35", "link": "http://arxiv.org/abs/2503.23271v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Localized Graph-Based Neural Dynamics Models for Terrain Manipulation", "abstract": "Predictive models can be particularly helpful for robots to effectively\nmanipulate terrains in construction sites and extraterrestrial surfaces.\nHowever, terrain state representations become extremely high-dimensional\nespecially to capture fine-resolution details and when depth is unknown or\nunbounded. This paper introduces a learning-based approach for terrain dynamics\nmodeling and manipulation, leveraging the Graph-based Neural Dynamics (GBND)\nframework to represent terrain deformation as motion of a graph of particles.\nBased on the principle that the moving portion of a terrain is usually\nlocalized, our approach builds a large terrain graph (potentially millions of\nparticles) but only identifies a very small active subgraph (hundreds of\nparticles) for predicting the outcomes of robot-terrain interaction. To\nminimize the size of the active subgraph we introduce a learning-based approach\nthat identifies a small region of interest (RoI) based on the robot's control\ninputs and the current scene. We also introduce a novel domain boundary feature\nencoding that allows GBNDs to perform accurate dynamics prediction in the RoI\ninterior while avoiding particle penetration through RoI boundaries. Our\nproposed method is both orders of magnitude faster than naive GBND and it\nachieves better overall prediction accuracy. We further evaluated our framework\non excavation and shaping tasks on terrain with different granularity.", "published": "2025-03-30 01:24:10", "link": "http://arxiv.org/abs/2503.23270v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "On Gottschalk's surjunctivity conjecture for non-uniform cellular automata", "abstract": "Gottschalk's surjunctivity conjecture for a group $G$ states that it is\nimpossible for cellular automata (CA) over the universe $G$ with finite\nalphabet to produce strict embeddings of the full shift into itself. A group\nuniverse $G$ satisfying Gottschalk's surjunctivity conjecture is called a\nsurjunctive group. The surjunctivity theorem of Gromov and Weiss shows that\nevery sofic group is surjunctive. In this paper, we study the surjunctivity of\nlocal perturbations of CA and more generally of non-uniform cellular automata\n(NUCA) with finite memory and uniformly bounded singularity over surjunctive\ngroup universes. In particular, we show that such a NUCA must be invertible\nwhenever it is reversible. We also obtain similar results which extend to the\nclass of NUCA a certain dual-surjunctivity theorem of Capobianco, Kari, and\nTaati for CA.", "published": "2025-03-30 13:26:52", "link": "http://arxiv.org/abs/2503.23435v1", "categories": ["math.DS", "cs.DM", "math.GR", "nlin.CG"], "primary_category": "math.DS"}
{"title": "Multi-Pass Streaming Lower Bounds for Approximating Max-Cut", "abstract": "In the Max-Cut problem in the streaming model, an algorithm is given the\nedges of an unknown graph $G = (V,E)$ in some fixed order, and its goal is to\napproximate the size of the largest cut in $G$. Improving upon an earlier\nresult of Kapralov, Khanna and Sudan, it was shown by Kapralov and Krachun that\nfor all $\\varepsilon>0$, no $o(n)$ memory streaming algorithm can achieve a\n$(1/2+\\varepsilon)$-approximation for Max-Cut. Their result holds for\nsingle-pass streams, i.e.~the setting in which the algorithm only views the\nstream once, and it was open whether multi-pass access may help. The\nstate-of-the-art result along these lines, due to Assadi and N, rules out\narbitrarily good approximation algorithms with constantly many passes and\n$n^{1-\\delta}$ space for any $\\delta>0$.\n  We improve upon this state-of-the-art result, showing that any non-trivial\napproximation algorithm for Max-Cut requires either polynomially many passes or\npolynomially large space. More specifically, we show that for all\n$\\varepsilon>0$, a $k$-pass streaming $(1/2+\\varepsilon)$-approximation\nalgorithm for Max-Cut requires $\\Omega_{\\varepsilon}\\left(n^{1/3}/k\\right)$\nspace. This result leads to a similar lower bound for the Maximum Directed Cut\nproblem, showing the near optimality of the algorithm of [Saxena, Singer,\nSudan, Velusamy, SODA 2025].\n  Our lower bounds proceed by showing a communication complexity lower bound\nfor the Distributional Implicit Hidden Partition (DIHP) Problem, introduced by\nKapralov and Krachun. While a naive application of the discrepancy method\nfails, we identify a property of protocols called ``globalness'', and show that\n(1) any protocol for DIHP can be turned into a global protocol, (2) the\ndiscrepancy of a global protocol must be small. The second step is the more\ntechnically involved step in the argument, and therein we use global\nhypercontractive inequalities.", "published": "2025-03-30 11:22:59", "link": "http://arxiv.org/abs/2503.23404v1", "categories": ["cs.DS", "cs.CC", "cs.DM"], "primary_category": "cs.DS"}
{"title": "Understanding Visual Saliency of Outlier Items in Product Search", "abstract": "In two-sided marketplaces, items compete for user attention, which translates\nto revenue for suppliers. Item exposure, indicated by the amount of attention\nitems receive in a ranking, can be influenced by factors like position bias.\nRecent work suggests that inter-item dependencies, such as outlier items in a\nranking, also affect item exposure. Outlier items are items that observably\ndeviate from the other items in a ranked list. Understanding outlier items is\ncrucial for determining an item's exposure distribution. In our previous work,\nwe investigated the impact of different presentational features on users'\nperception of outlier in search results. In this work, we focus on two key\nquestions left unanswered by our previous work: (i) What is the effect of\nisolated bottom-up visual factors on item outlierness in product lists? (ii)\nHow do top-down factors influence users' perception of item outlierness in a\nrealistic online shopping scenario? We start with bottom-up factors and employ\nvisual saliency models to evaluate their ability to detect outlier items in\nproduct lists purely based on visual attributes. Then, to examine top-down\nfactors, we conduct eye-tracking experiments on an online shopping task.\nMoreover, we employ eye-tracking to not only be closer to the real-world case\nbut also to address the accuracy problem of reaction time in the visual search\ntask. Our experiments show the ability of visual saliency models to detect\nbottom-up factors, consistently highlighting areas with strong visual\ncontrasts. The results of our eye-tracking experiment for lists without\noutliers show that despite being less visually attractive, product descriptions\ncaptured attention the fastest, indicating the importance of top-down factors.\nIn our eye-tracking experiments, we observed that outlier items engaged users\nfor longer durations compared to non-outlier items.", "published": "2025-03-30 21:22:23", "link": "http://arxiv.org/abs/2503.23596v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Design and Experimental Validation of an Autonomous USV for Sensor Fusion-Based Navigation in GNSS-Denied Environments", "abstract": "This paper presents the design, development, and experimental validation of\nMARVEL, an autonomous unmanned surface vehicle built for real-world testing of\nsensor fusion-based navigation algorithms in GNSS-denied environments. MARVEL\nwas developed under strict constraints of cost-efficiency, portability, and\nseaworthiness, with the goal of creating a modular, accessible platform for\nhigh-frequency data acquisition and experimental learning. It integrates\nelectromagnetic logs, Doppler velocity logs, inertial sensors, and real-time\nkinematic GNSS positioning. MARVEL enables real-time, in-situ validation of\nadvanced navigation and AI-driven algorithms using redundant, synchronized\nsensors. Field experiments demonstrate the system's stability, maneuverability,\nand adaptability in challenging sea conditions. The platform offers a novel,\nscalable approach for researchers seeking affordable, open-ended tools to\nevaluate sensor fusion techniques under real-world maritime constraints.", "published": "2025-03-30 13:50:46", "link": "http://arxiv.org/abs/2503.23445v1", "categories": ["cs.RO", "cs.IR"], "primary_category": "cs.RO"}
{"title": "Filtering with Time-frequency Analysis: An Adaptive and Lightweight Model for Sequential Recommender Systems Based on Discrete Wavelet Transform", "abstract": "Sequential Recommender Systems (SRS) aim to model sequential behaviors of\nusers to capture their interests which usually evolve over time.\nTransformer-based SRS have achieved distinguished successes recently. However,\nstudies reveal self-attention mechanism in Transformer-based models is\nessentially a low-pass filter and ignores high frequency information\npotentially including meaningful user interest patterns. This motivates us to\nseek better filtering technologies for SRS, and finally we find Discrete\nWavelet Transform (DWT), a famous time-frequency analysis technique from\ndigital signal processing field, can effectively process both low-frequency and\nhigh-frequency information. We design an adaptive time-frequency filter with\nDWT technique, which decomposes user interests into multiple signals with\ndifferent frequency and time, and can automatically learn weights of these\nsignals. Furthermore, we develop DWTRec, a model for sequential recommendation\nall based on the adaptive time-frequency filter. Thanks to fast DWT technique,\nDWTRec has a lower time complexity and space complexity theoretically, and is\nProficient in modeling long sequences. Experiments show that our model\noutperforms state-of-the-art baseline models in datasets with different\ndomains, sparsity levels and average sequence lengths. Especially, our model\nshows great performance increase in contrast with previous models when the\nsequence grows longer, which demonstrates another advantage of our model.", "published": "2025-03-30 13:28:42", "link": "http://arxiv.org/abs/2503.23436v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "LIRA: A Learning-based Query-aware Partition Framework for Large-scale ANN Search", "abstract": "Approximate nearest neighbor search is fundamental in information retrieval.\nPrevious partition-based methods enhance search efficiency by probing partial\npartitions, yet they face two common issues. In the query phase, a common\nstrategy is to probe partitions based on the distance ranks of a query to\npartition centroids, which inevitably probes irrelevant partitions as it\nignores data distribution. In the partition construction phase, all\npartition-based methods face the boundary problem that separates a query's\nnearest neighbors to multiple partitions, resulting in a long-tailed kNN\ndistribution and degrading the optimal nprobe (i.e., the number of probing\npartitions). To address this gap, we propose LIRA, a LearnIng-based queRy-aware\npArtition framework. Specifically, we propose a probing model to directly probe\nthe partitions containing the kNN of a query, which can reduce probing waste\nand allow for query-aware probing with nprobe individually. Moreover, we\nincorporate the probing model into a learning-based redundancy strategy to\nmitigate the adverse impact of the long-tailed kNN distribution on search\nefficiency. Extensive experiments on real-world vector datasets demonstrate the\nsuperiority of LIRA in the trade-off among accuracy, latency, and query\nfan-out. The codes are available at\nhttps://github.com/SimoneZeng/LIRA-ANN-search.", "published": "2025-03-30 12:03:57", "link": "http://arxiv.org/abs/2503.23409v1", "categories": ["cs.IR", "cs.DB"], "primary_category": "cs.IR"}
{"title": "RuleAgent: Discovering Rules for Recommendation Denoising with Autonomous Language Agents", "abstract": "The implicit feedback (e.g., clicks) in real-world recommender systems is\noften prone to severe noise caused by unintentional interactions, such as\nmisclicks or curiosity-driven behavior. A common approach to denoising this\nfeedback is manually crafting rules based on observations of training loss\npatterns. However, this approach is labor-intensive and the resulting rules\noften lack generalization across diverse scenarios. To overcome these\nlimitations, we introduce RuleAgent, a language agent based framework which\nmimics real-world data experts to autonomously discover rules for\nrecommendation denoising. Unlike the high-cost process of manual rule mining,\nRuleAgent offers rapid and dynamic rule discovery, ensuring adaptability to\nevolving data and varying scenarios. To achieve this, RuleAgent is equipped\nwith tailored profile, memory, planning, and action modules and leverages\nreflection mechanisms to enhance its reasoning capabilities for rule discovery.\nFurthermore, to avoid the frequent retraining in rule discovery, we propose\nLossEraser-an unlearning strategy that streamlines training without\ncompromising denoising performance. Experiments on benchmark datasets\ndemonstrate that, compared with existing denoising methods, RuleAgent not only\nderives the optimal recommendation performance but also produces generalizable\ndenoising rules, assisting researchers in efficient data cleaning.", "published": "2025-03-30 09:19:03", "link": "http://arxiv.org/abs/2503.23374v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Graph-Structured Driven Dual Adaptation for Mitigating Popularity Bias", "abstract": "Popularity bias challenges recommender systems by causing uneven\nrecommendation performance and amplifying the Matthew effect. Limited user-item\ninteractions confine unpopular items within embedding neighborhoods of few\nusers, leading to representation collapse and reduced model generalization.\nExisting supervised alignment and reweighting methods mitigate this bias but\nhave key limitations: (1) ignoring inherent variability across Graph\nConvolutional Networks (GCNs) layers, causing negative effects in deeper\nlayers; (2) reliance on fixed hyperparameters to balance item popularity,\nrestricting adaptability and increasing complexity.\n  To address these issues, we propose the Graph-Structured Dual Adaptation\nFramework (GSDA). Our theoretical analysis identifies a crucial limitation of\nsupervised alignment methods caused by over-smoothing in GCNs. As GCN layers\ndeepen, popular and unpopular items increasingly lose distinctiveness,\nquantified by reduced conditional entropy. This diminished distinctiveness\nweakens supervised alignment effectiveness in mitigating popularity bias.\nMotivated by this, GSDA captures structural and distribution characteristics\nfrom the adjacency matrix through a dual adaptive strategy. First, a\nhierarchical adaptive alignment mechanism uses the adjacency matrix's Frobenius\nnorm for layer-specific weight decay, countering conditional entropy reduction\neffects at deeper layers. Second, a distribution-aware dynamic contrast\nweighting strategy, guided by a real-time Gini coefficient, removes dependence\non fixed hyperparameters, enabling adaptability to diverse data. Experiments on\nthree benchmark datasets demonstrate GSDA significantly alleviates popularity\nbias and consistently outperforms state-of-the-art recommendation methods.", "published": "2025-03-30 08:26:29", "link": "http://arxiv.org/abs/2503.23358v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Torsion of $\u03b1$-connections on the density manifold", "abstract": "We study the torsion of the $\\alpha$-connections defined on the density\nmanifold in terms of a regular Riemannian metric. In the case of the Fisher-Rao\nmetric our results confirm the fact that all $\\alpha$-connections are torsion\nfree. For the $\\alpha$-connections obtained by the Otto metric, we show that,\nexcept for $\\alpha = -1$, they are not torsion free.", "published": "2025-03-30 20:54:27", "link": "http://arxiv.org/abs/2503.23588v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Semantic Communication for the Internet of Space: New Architecture, Challenges, and Future Vision", "abstract": "The expansion of sixth-generation (6G) wireless networks into space\nintroduces technical challenges that conventional bit-oriented communication\napproaches cannot efficiently address, including intermittent connectivity,\nsevere latency, limited bandwidth, and constrained onboard resources. To\novercome these limitations, semantic communication has emerged as a\ntransformative paradigm, shifting the communication focus from transmitting raw\ndata to delivering context-aware, missionrelevant information. In this article,\nwe propose a semantic communication architecture explicitly tailored for the 6G\nInternet of Space (IoS), integrating multi-modal semantic processing, AIdriven\nsemantic encoding and decoding, and adaptive transmission mechanisms optimized\nfor space environments. The effectiveness of our proposed framework is\ndemonstrated through a representative deep-space scenario involving\nsemantic-based monitoring of Mars dust storms. Finally, we outline open\nresearch challenges and discuss future directions toward realizing practical\nsemantic-enabled IoS systems.", "published": "2025-03-30 13:57:45", "link": "http://arxiv.org/abs/2503.23446v1", "categories": ["cs.NI", "cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.NI"}
{"title": "Quasi-cyclic Linear Error-Block Code-based Post-quantum Signature", "abstract": "Shor algorithm led to the discovery of multiple vulnerabilities in a number\nof cryptosystems. As a result, post-quantum cryptography attempts to provide\ncryptographic solutions that can face these attacks, ensuring the security of\nsensitive data in a future where quantum computers are assumed to exist. Error\ncorrecting codes are a source for efficiency when it comes to signatures,\nespecially random ones described in this paper, being quantum-resistant and\nreaching the Gilbert-Varshamov bound, thus offering a good trade-off between\nrate and distance. In the light of this discussion, we introduce a signature\nbased on a family of linear error-block codes (LEB), with strong algebraic\nproperties: it is the family of quasi-cyclic LEB codes that we do define\nalgebraically during this work.", "published": "2025-03-30 11:36:05", "link": "http://arxiv.org/abs/2503.23405v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Information-theoretic subset selection of multivariate Markov chains via submodular optimization", "abstract": "We study the problem of optimally projecting the transition matrix of a\nfinite ergodic multivariate Markov chain onto a lower-dimensional state space.\nSpecifically, we seek to construct a projected Markov chain that optimizes\nvarious information-theoretic criteria under cardinality constraints. These\ncriteria include entropy rate, information-theoretic distance to\nfactorizability, independence, and stationarity. We formulate these tasks as\nbest subset selection problems over multivariate Markov chains and leverage the\nsubmodular (or supermodular) structure of the objective functions to develop\nefficient greedy-based algorithms with theoretical guarantees. We extend our\nanalysis to $k$-submodular settings and introduce a generalized version of the\ndistorted greedy algorithm, which may be of independent interest. Finally, we\nillustrate the theory and algorithms through extensive numerical experiments\nwith publicly available code on multivariate Markov chains associated with the\nBernoulli-Laplace and Curie-Weiss model.", "published": "2025-03-30 06:51:56", "link": "http://arxiv.org/abs/2503.23340v1", "categories": ["math.PR", "cs.IT", "math.CO", "math.IT", "60J10, 60J22, 90C27, 94A15, 94A17"], "primary_category": "math.PR"}
{"title": "A Constrained Multi-Agent Reinforcement Learning Approach to Autonomous Traffic Signal Control", "abstract": "Traffic congestion in modern cities is exacerbated by the limitations of\ntraditional fixed-time traffic signal systems, which fail to adapt to dynamic\ntraffic patterns. Adaptive Traffic Signal Control (ATSC) algorithms have\nemerged as a solution by dynamically adjusting signal timing based on real-time\ntraffic conditions. However, the main limitation of such methods is that they\nare not transferable to environments under real-world constraints, such as\nbalancing efficiency, minimizing collisions, and ensuring fairness across\nintersections. In this paper, we view the ATSC problem as a constrained\nmulti-agent reinforcement learning (MARL) problem and propose a novel algorithm\nnamed Multi-Agent Proximal Policy Optimization with Lagrange Cost Estimator\n(MAPPO-LCE) to produce effective traffic signal control policies. Our approach\nintegrates the Lagrange multipliers method to balance rewards and constraints,\nwith a cost estimator for stable adjustment. We also introduce three\nconstraints on the traffic network: GreenTime, GreenSkip, and PhaseSkip, which\npenalize traffic policies that do not conform to real-world scenarios. Our\nexperimental results on three real-world datasets demonstrate that MAPPO-LCE\noutperforms three baseline MARL algorithms by across all environments and\ntraffic constraints (improving on MAPPO by 12.60%, IPPO by 10.29%, and QTRAN by\n13.10%). Our results show that constrained MARL is a valuable tool for traffic\nplanners to deploy scalable and efficient ATSC methods in real-world traffic\nnetworks. We provide code at https://github.com/Asatheesh6561/MAPPO-LCE.", "published": "2025-03-30 23:29:48", "link": "http://arxiv.org/abs/2503.23626v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "VFlow: Discovering Optimal Agentic Workflows for Verilog Generation", "abstract": "Hardware design automation faces challenges in generating high-quality\nVerilog code efficiently. This paper introduces VFlow, an automated framework\nthat optimizes agentic workflows for Verilog code generation. Unlike existing\napproaches that rely on pre-defined prompting strategies, VFlow leverages Monte\nCarlo Tree Search (MCTS) to discover effective sequences of Large Language\nModels invocations that maximize code quality while minimizing computational\ncosts. VFlow extends the AFLOW methodology with domain-specific operators\naddressing hardware design requirements, including syntax validation,\nsimulation-based verification, and synthesis optimization. Experimental\nevaluation on the VerilogEval benchmark demonstrates VFlow's superiority,\nachieving an 83.6% average pass@1 rate-a 6.1\\% improvement over\nstate-of-the-art PromptV and a 36.9\\% gain compared to direct LLM invocation.\nMost significantly, VFlow enhances the capabilities of smaller models, enabling\nDeepSeek-V3 to achieve 141.2\\% of GPT-4o's performance while reducing API costs\nto just 13\\%. These findings indicate that intelligently optimized workflows\nenable cost-efficient LLMs to outperform larger models on hardware design\ntasks, potentially democratizing access to advanced digital circuit development\ntools and accelerating innovation in the semiconductor industry", "published": "2025-03-30 15:44:22", "link": "http://arxiv.org/abs/2504.03723v1", "categories": ["cs.AR", "cs.MA"], "primary_category": "cs.AR"}
{"title": "Least squares spectral element formulation of eigenvalue problems with/without interface : the one dimensional example", "abstract": "Here, we present a least-squares based spectral element formulation for\none-dimensional eigenvalue problems with interface conditions. First we develop\nthe method for without interface case, then we extend it to interface case.\nConvergence analysis for eigenvalues and eigenfunctions have been discussed.\nNumerical experiments with different jump conditions have been displayed.", "published": "2025-03-30 19:20:46", "link": "http://arxiv.org/abs/2503.23567v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Unconditionally Energy Stable Second Order Numerical Scheme for a Microemulsion model", "abstract": "We present a numerical scheme for solving a sixth-order Cahn-Hilliard type\nequation that captures the dynamics of phase transitions in a ternary mixture\nconsisting of two immiscible fluids and a surface active molecule that is\namphiphilic. We show that by considering a suitable midpoint approximation for\nthe nonlinear terms in the differential equation, we obtain an unconditionally\nenergy-stable numerical scheme that is second-order in time. We demonstrate\nthat our proposed numerical scheme satisfies these key properties for a wide\nrange of physical parameters in two and three dimensions. Moreover, we present\nthe results of a numerical study to report on the impact of each physical\nparameter on the behavior of the dynamics of the phase transitions, which are\nin agreement with the experimental observations.", "published": "2025-03-30 16:52:34", "link": "http://arxiv.org/abs/2503.23516v1", "categories": ["math.NA", "cs.NA", "35K51, 35M13, 35Q35, 65M12, 65M60"], "primary_category": "math.NA"}
{"title": "$p$-Adic Polynomial Regression as Alternative to Neural Network for Approximating $p$-Adic Functions of Many Variables", "abstract": "A method for approximating continuous functions\n$\\mathbb{Z}_{p}^{n}\\rightarrow\\mathbb{Z}_{p}$ by a linear superposition of\ncontinuous functions $\\mathbb{Z}_{p}\\rightarrow\\mathbb{Z}_{p}$ is presented and\na polynomial regression model is constructed that allows approximating such\nfunctions with any degree of accuracy. A physical interpretation of such a\nmodel is given and possible methods for its training are discussed. The\nproposed model can be considered as a simple alternative to possible $p$-adic\nmodels based on neural network architecture.", "published": "2025-03-30 15:42:08", "link": "http://arxiv.org/abs/2503.23488v2", "categories": ["math-ph", "cs.LG", "cs.NA", "math.MP", "math.NA", "math.NT", "math.OC"], "primary_category": "math-ph"}
{"title": "Asymptotically accurate and locking-free finite element implementation of the refined shell theory", "abstract": "A formulation of the 2D refined shell theory incorporating transverse shear\nin the rescaled coordinates and angles of rotation is considered. This novel\napproach provides the first asymptotically accurate and inherently locking-free\nfinite element implementation. Numerical simulations of semi-cylindrical shells\ndemonstrate excellent agreement between the analytical solution, the 2D refined\nshell theory, and three-dimensional elasticity theory, validating the\neffectiveness and accuracy of the method.", "published": "2025-03-30 09:05:30", "link": "http://arxiv.org/abs/2503.23369v1", "categories": ["math.NA", "cs.NA", "physics.class-ph"], "primary_category": "math.NA"}
{"title": "Robust superconvergence analysis of physics-preserving RMAC scheme for the Stokes and Navier--Stokes equations on non-uniform grids at high Reynolds numbers", "abstract": "The velocity errors of the classical marker and cell (MAC) scheme are\ndependent on the pressure approximation errors, which is non-pressure-robust\nand will cause the accuracy of the velocity approximation to deteriorate when\nthe pressure approximation is poor. In this paper, we first propose the\nreconstructed MAC scheme (RMAC) based on the finite volume method to obtain the\npressure-robustness for the time-dependent Stokes equations and then construct\nthe $\\mu$-robust and physics-preserving RMAC scheme on non-uniform grids for\nthe Navier--Stokes equations, where $\\mu$-robustness means that the velocity\nerrors do not blow up for small viscosity $\\mu$ when the true velocity is\nsufficiently smooth. Compared with the original MAC scheme, which was analyzed\nin [SIAM J. Numer. Anal. 55 (2017): 1135-1158], the RMAC scheme is different\nonly on the right-hand side for Stokes equations. It can also be proved that\nthe constructed scheme satisfies the local mass conservation law, the discrete\nunconditional energy dissipation law, the momentum conservation, and the\nangular momentum conservation for the Stokes and Navier--Stokes equations.\nFurthermore, by constructing the new auxiliary function depending on the\nvelocity and using the high-order consistency analysis, we can obtain the\npressure-robust and $\\mu$-robust error estimates for the velocity and derive\nthe second-order superconvergence for the velocity and pressure in the discrete\n$l^{\\infty}(l^2)$ norm on non-uniform grids and the discrete\n$l^{\\infty}(l^{\\infty})$ norm on uniform grids. Finally, numerical experiments\nusing the constructed schemes are demonstrated to show the robustness for our\nconstructed schemes.", "published": "2025-03-30 03:36:58", "link": "http://arxiv.org/abs/2503.23296v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Optimal Invariant Bases for Atomistic Machine Learning", "abstract": "The representation of atomic configurations for machine learning models has\nled to the development of numerous descriptors, often to describe the local\nenvironment of atoms. However, many of these representations are incomplete\nand/or functionally dependent. Incomplete descriptor sets are unable to\nrepresent all meaningful changes in the atomic environment. Complete\nconstructions of atomic environment descriptors, on the other hand, often\nsuffer from a high degree of functional dependence, where some descriptors can\nbe written as functions of the others. These redundant descriptors do not\nprovide additional power to discriminate between different atomic environments\nand increase the computational burden. By employing techniques from the pattern\nrecognition literature to existing atomistic representations, we remove\ndescriptors that are functions of other descriptors to produce the smallest\npossible set that satisfies completeness. We apply this in two ways: first we\nrefine an existing description, the Atomistic Cluster Expansion. We show that\nthis yields a more efficient subset of descriptors. Second, we augment an\nincomplete construction based on a scalar neural network, yielding a new\nmessage-passing network architecture that can recognize up to 5-body patterns\nin each neuron by taking advantage of an optimal set of Cartesian tensor\ninvariants. This architecture shows strong accuracy on state-of-the-art\nbenchmarks while retaining low computational cost. Our results not only yield\nimproved models, but point the way to classes of invariant bases that minimize\ncost while maximizing expressivity for a host of applications.", "published": "2025-03-30 16:52:29", "link": "http://arxiv.org/abs/2503.23515v2", "categories": ["physics.chem-ph", "cs.CV", "stat.ML"], "primary_category": "physics.chem-ph"}
{"title": "Accelerated Stein Variational Gradient Flow", "abstract": "Stein variational gradient descent (SVGD) is a kernel-based particle method\nfor sampling from a target distribution, e.g., in generative modeling and\nBayesian inference. SVGD does not require estimating the gradient of the\nlog-density, which is called score estimation. In practice, SVGD can be slow\ncompared to score-estimation based sampling algorithms. To design fast and\nefficient high-dimensional sampling algorithms, we introduce ASVGD, an\naccelerated SVGD, based on an accelerated gradient flow in a metric space of\nprobability densities following Nesterov's method. We then derive a\nmomentum-based discrete-time sampling algorithm, which evolves a set of\nparticles deterministically. To stabilize the particles' momentum update, we\nalso study a Wasserstein metric regularization. For the generalized bilinear\nkernel and the Gaussian kernel, toy numerical examples with varied target\ndistributions demonstrate the effectiveness of ASVGD compared to SVGD and other\npopular sampling methods.", "published": "2025-03-30 14:37:21", "link": "http://arxiv.org/abs/2503.23462v1", "categories": ["stat.ML", "cs.LG", "math.OC", "46N10 (Primary) 46E22 94A15 (Secondary)"], "primary_category": "stat.ML"}
{"title": "DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization", "abstract": "Domain generalization (DG) aims to learn models that can generalize well to\nunseen domains by training only on a set of source domains. Sharpness-Aware\nMinimization (SAM) has been a popular approach for this, aiming to find flat\nminima in the total loss landscape. However, we show that minimizing the total\nloss sharpness does not guarantee sharpness across individual domains. In\nparticular, SAM can converge to fake flat minima, where the total loss may\nexhibit flat minima, but sharp minima are present in individual domains.\nMoreover, the current perturbation update in gradient ascent steps is\nineffective in directly updating the sharpness of individual domains. Motivated\nby these findings, we introduce a novel DG algorithm, Decreased-overhead\nGradual Sharpness-Aware Minimization (DGSAM), that applies gradual domain-wise\nperturbation to reduce sharpness consistently across domains while maintaining\ncomputational efficiency. Our experiments demonstrate that DGSAM outperforms\nstate-of-the-art DG methods, achieving improved robustness to domain shifts and\nbetter performance across various benchmarks, while reducing computational\noverhead compared to SAM.", "published": "2025-03-30 13:20:06", "link": "http://arxiv.org/abs/2503.23430v1", "categories": ["stat.ML", "cs.LG", "math.OC", "stat.AP"], "primary_category": "stat.ML"}
{"title": "A first-order DirAC-based parametric Ambisonic coder for immersive communications", "abstract": "Directional Audio Coding (DirAC) is a proven method for parametrically\nrepresenting a 3D audio scene in B-format and is capable of reproducing it on\narbitrary loudspeaker layouts. Although such a method seems well suited for low\nbitrate Ambisonic transmission, little work has been done on the feasibility of\nbuilding a real system upon it. In this paper, we present a DirAC-based coding\nfor Higher-Order Ambisonics (HOA), developed as part of a standardisation\neffort to extend the 3GPP EVS codec to immersive communications. Starting from\nthe first-order DirAC model, we show how to reduce algorithmic delay, the\nbitrate required for the parameters and complexity by bringing the full\nsynthesis in the spherical harmonic domain. The evaluation of the proposed\ntechnique for coding 3\\textsuperscript{rd} order Ambisonics at bitrates from 32\nto 128 kbps shows the relevance of the parametric approach compared with\nexisting solutions.", "published": "2025-03-30 20:47:10", "link": "http://arxiv.org/abs/2503.23586v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Evaluation of the Pronunciation of Tajweed Rules Based on DNN as a Step Towards Interactive Recitation Learning", "abstract": "Proper recitation of the Quran, adhering to the rules of Tajweed, is crucial\nfor preventing mistakes during recitation and requires significant effort to\nmaster. Traditional methods of teaching these rules are limited by the\navailability of qualified instructors and time constraints. Automatic\nevaluation of recitation can address these challenges by providing prompt\nfeedback and supporting independent practice. This study focuses on developing\na deep learning model to classify three Tajweed rules - separate stretching (Al\nMad), tight noon (Ghunnah), and hide (Ikhfaa) - using the publicly available\nQDAT dataset, which contains over 1,500 audio recordings. The input data\nconsisted of audio recordings from this dataset, transformed into normalized\nmel-spectrograms. For classification, the EfficientNet-B0 architecture was\nused, enhanced with a Squeeze-and-Excitation attention mechanism. The developed\nmodel achieved accuracy rates of 95.35%, 99.34%, and 97.01% for the respective\nrules. An analysis of the learning curves confirmed the model's robustness and\nabsence of overfitting. The proposed approach demonstrates high efficiency and\npaves the way for developing interactive educational systems for Tajweed study.", "published": "2025-03-30 15:03:02", "link": "http://arxiv.org/abs/2503.23470v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "D3-Guard: Acoustic-based Drowsy Driving Detection Using Smartphones", "abstract": "Since the number of cars has grown rapidly in recent years, driving safety\ndraws more and more public attention. Drowsy driving is one of the biggest\nthreatens to driving safety. Therefore, a simple but robust system that can\ndetect drowsy driving with commercial off-the-shelf devices (such as\nsmartphones) is very necessary. With this motivation, we explore the\nfeasibility of purely using acoustic sensors embedded in smartphones to detect\ndrowsy driving. We first study characteristics of drowsy driving, and find some\nunique patterns of Doppler shift caused by three typical drowsy behaviors, i.e.\nnodding, yawning and operating steering wheel. We then validate our important\nfindings through empirical analysis of the driving data collected from real\ndriving environments. We further propose a real-time Drowsy Driving Detection\nsystem (D3-Guard) based on audio devices embedded in smartphones. In order to\nimprove the performance of our system, we adopt an effective feature extraction\nmethod based on undersampling technique and FFT, and carefully design a\nhigh-accuracy detector based on LSTM networks for the early detection of drowsy\ndriving. Through extensive experiments with 5 volunteer drivers in real driving\nenvironments, our system can distinguish drowsy driving actions with an average\ntotal accuracy of 93.31% in real-time. Over 80% drowsy driving actions can be\ndetected within first 70% of action duration.", "published": "2025-03-30 10:52:01", "link": "http://arxiv.org/abs/2503.23393v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "HearSmoking: Smoking Detection in Driving Environment via Acoustic Sensing on Smartphones", "abstract": "Driving safety has drawn much public attention in recent years due to the\nfast-growing number of cars. Smoking is one of the threats to driving safety\nbut is often ignored by drivers. Existing works on smoking detection either\nwork in contact manner or need additional devices. This motivates us to explore\nthe practicability of using smartphones to detect smoking events in driving\nenvironment. In this paper, we propose a cigarette smoking detection system,\nnamed HearSmoking, which only uses acoustic sensors on smartphones to improve\ndriving safety. After investigating typical smoking habits of drivers,\nincluding hand movement and chest fluctuation, we design an acoustic signal to\nbe emitted by the speaker and received by the microphone. We calculate Relative\nCorrelation Coefficient of received signals to obtain movement patterns of\nhands and chest. The processed data is sent into a trained Convolutional Neural\nNetwork for classification of hand movement. We also design a method to detect\nrespiration at the same time. To improve system performance, we further analyse\nthe periodicity of the composite smoking motion. Through extensive experiments\nin real driving environments, HearSmoking detects smoking events with an\naverage total accuracy of 93.44 percent in real-time.", "published": "2025-03-30 10:40:44", "link": "http://arxiv.org/abs/2503.23391v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "HearFit+: Personalized Fitness Monitoring via Audio Signals on Smart Speakers", "abstract": "Fitness can help to strengthen muscles, increase resistance to diseases, and\nimprove body shape. Nowadays, a great number of people choose to exercise at\nhome/office rather than at the gym due to lack of time. However, it is\ndifficult for them to get good fitness effects without professional guidance.\nMotivated by this, we propose the first personalized fitness monitoring system,\nHearFit+, using smart speakers at home/office. We explore the feasibility of\nusing acoustic sensing to monitor fitness. We design a fitness detection method\nbased on Doppler shift and adopt the short time energy to segment fitness\nactions. Based on deep learning, HearFit+ can perform fitness classification\nand user identification at the same time. Combined with incremental learning,\nusers can easily add new actions. We design 4 evaluation metrics (i.e.,\nduration, intensity, continuity, and smoothness) to help users to improve\nfitness effects. Through extensive experiments including over 9,000 actions of\n10 types of fitness from 12 volunteers, HearFit+ can achieve an average\naccuracy of 96.13% on fitness classification and 91% accuracy for user\nidentification. All volunteers confirm that HearFit+ can help improve the\nfitness effect in various environments.", "published": "2025-03-30 10:31:55", "link": "http://arxiv.org/abs/2503.23387v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint Source-Environment Adaptation for Deep Learning-Based Underwater Acoustic Source Ranging", "abstract": "In this paper, we propose a method to adapt a pre-trained deep-learning-based\nmodel for underwater acoustic localization to a new environment. We use\nunsupervised domain adaptation to improve the generalization performance of the\nmodel, i.e., using an unsupervised loss, fine-tune the pre-trained network\nparameters without access to any labels of the target environment or any data\nused to pre-train the model. This method improves the pre-trained model\nprediction by coupling that with an almost independent estimation based on the\nreceived signal energy (that depends on the source). We show the effectiveness\nof this approach on Bellhop generated data in an environment similar to that of\nthe SWellEx-96 experiment contaminated with real ocean noise from the KAM11\nexperiment.", "published": "2025-03-30 00:32:51", "link": "http://arxiv.org/abs/2503.23262v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Mismatch-Robust Underwater Acoustic Localization Using A Differentiable Modular Forward Model", "abstract": "In this paper, we study the underwater acoustic localization in the presence\nof environmental mismatch. Especially, we exploit a pre-trained neural network\nfor the acoustic wave propagation in a gradient-based optimization framework to\nestimate the source location. To alleviate the effect of mismatch between the\ntraining data and the test data, we simultaneously optimize over the network\nweights at the inference time, and provide conditions under which this method\nis effective. Moreover, we introduce a physics-inspired modularity in the\nforward model that enables us to learn the path lengths of the multipath\nstructure in an end-to-end training manner without access to the specific path\nlabels. We investigate the validity of the assumptions in a simple yet\nillustrative environment model.", "published": "2025-03-30 00:12:20", "link": "http://arxiv.org/abs/2503.23260v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Joint Source-Environment Adaptation of Data-Driven Underwater Acoustic Source Ranging Based on Model Uncertainty", "abstract": "Adapting pre-trained deep learning models to new and unknown environments is\na difficult challenge in underwater acoustic localization. We show that\nalthough pre-trained models have performance that suffers from mismatch between\nthe training and test data, they generally exhibit a higher ``implied\nuncertainty'' in environments where there is more mismatch. Leveraging this\nnotion of implied uncertainty, we partition the test samples into more certain\nand less certain sets, and implement an estimation method using the certain\nsamples to improve the labeling for uncertain samples, which helps to adapt the\nmodel. We use an efficient method to quantify model prediction uncertainty, and\nan innovative approach to adapt a pre-trained model to unseen underwater\nenvironments at test time. This eliminates the need for labeled data from the\ntarget environment or the original training data. This adaptation is enhanced\nby integrating an independent estimate based on the received signal energy. We\nvalidate the approach extensively using real experimental data, as well as\nsynthetic data consisting of model-generated signals with real ocean noise. The\nresults demonstrate significant improvements in model prediction accuracy,\nunderscoring the potential of the method to enhance underwater acoustic\nlocalization in diverse, noisy, and unknown environments.", "published": "2025-03-30 00:00:17", "link": "http://arxiv.org/abs/2503.23258v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Zak-OTFS for Mutually Unbiased Sensing and Communication", "abstract": "Waveforms with ideal ambiguity functions are fundamental to integrated\nsensing and communication, to active sensing (radar), and to uplink multiple\naccess. We describe a general method of constructing waveforms using the\ndiscrete Zak transform (DZT) to convert sequences of length $MN$ in the time\ndomain to waveforms in the delay-Doppler (DD) domain, each of which is defined\nby an $M\\times N$ quasi-periodic array. The DZT preserves inner products, and\nwe show that phase coded waveforms used in radar (CAZAC sequences) determine\nnoise-like waveforms in the DD domain, each with low Peak to Average Power\nRatio. In a Zak-OTFS communication system, we show that these waveforms are\nmutually unbiased with respect to every carrier and use them to integrate\nsensing and communication as spread pilots. We view each waveform as a linear\ncombination of Zak-OTFS carriers and show that the self-ambiguity function is\nsupported on a discrete line in the integers modulo $MN$. The sidelobes are\nsignificantly lower than the original CAZAC sequence, and the advantage of\ndiscrete support is better localization/resolution in delay and Doppler\ncompared with standard methods based on chirps or tones. We show that the\nabsolute value of the cross-ambiguity function for pairs of waveforms in the\nsame family is small and constant. This property makes the waveforms ideal\npreambles in the 2-step RACH protocol introduced in Release 15, 3GPP to enable\ngrant-free multiple access. The characteristics of the cross-ambiguity function\nmake it possible to simultaneously detect multiple preambles in the presence of\nmobility and delay spread.", "published": "2025-03-30 17:58:48", "link": "http://arxiv.org/abs/2503.23540v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "STAR-RIS-aided NOMA for Secured xURLLC", "abstract": "Short packet-based advanced Internet of things (A-IoT) calls for not only the\nnext generation of ultra-reliable low-latency communications (xURLLC) but also\nhighly secured communications. In this paper, we aim to address this objective\nby developing a non-orthogonal multiple access (NOMA) system with untrusted\nuser. There exist two key problems: The confidential/private message for the\nfar user will be exposed to the untrusted near user with successful SIC; The\nrestrictive trade-off among reliability, security and latency poses a great\nchallenge in achieving secured xURLLC. In order to solve these issues, we\nintroduce simultaneous transmitting and reflecting reconfigurable intelligent\nsurface (STAR-RIS), which provides additional degree of freedom to enable a\nsecure and fair decoding order and achieve a desired trade-off among\nreliability, security and latency. To fully reveal the trade-off among\nreliability, security and latency, we characterize the reliability and security\nvia decoding error probabilities. A leakage probability minimization problem is\nmodeled to optimize the passive beamforming, power allocation and blocklength\nsubject to secure successive interference cancellation (SIC) order, reliability\nand latency constraints. To solve this complex problem, we explore its\nintrinsic properties and propose an algorithm based on majorization\nminimization (MM) and alternative optimization (AO). Simulation results\ndemonstrate the validness of our study in this paper.", "published": "2025-03-30 08:16:51", "link": "http://arxiv.org/abs/2503.23352v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Improving Neonatal Care: An Active Dry-Contact Electrode-based Continuous EEG Monitoring System with Seizure Detection", "abstract": "Objective: Neonates are highly susceptible to seizures, which can have severe\nlong-term consequences if undetected and left untreated. Early detection is\ncrucial and typically requires continuous electroencephalography (EEG)\nmonitoring in a hospital setting, which is costly, inconvenient, and requires\nspecialized experts for diagnosis. In this work, we propose a new low-cost\nactive dry-contact electrode-based adjustable EEG headset, a new explainable\ndeep learning model to detect neonatal seizures, and an advanced signal\nprocessing algorithm to remove artifacts to address the key aspects that lead\nto the underdiagnosis of neonatal seizures. Methods: EEG signals are acquired\nthrough active electrodes and processed using a custom-designed analog front\nend (AFE) that filters and digitizes the captured EEG signals. The adjustable\nheadset is designed using three-dimensional (3D) printing and laser cutting to\nfit a wide range of head sizes. A deep learning model is developed to classify\nseizure and non-seizure epochs in real-time. Furthermore, a separate multimodal\ndeep learning model is designed to remove noise artifacts. The device is tested\non a pediatric patient with absence seizures in a hospital setting.\nSimultaneous recordings are captured using both the custom device and the\ncommercial wet electrode device available in the hospital for comparison.\nResults: The signals obtained using our custom design and a commercial device\nshow a high correlation (>0.8). Further analysis using signal-to-noise ratio\nvalues shows that our device can mitigate noise similar to the commercial\ndevice. The proposed deep learning model has improvements in accuracy and\nrecall by 2.76% and 16.33%, respectively, compared to the state-of-the-art.\nFurthermore, the developed artifact removal algorithm can identify and remove\nartifacts while keeping seizure patterns intact.", "published": "2025-03-30 06:44:15", "link": "http://arxiv.org/abs/2503.23338v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Method for Localization of Cellular Users from Call Detail Records", "abstract": "A common problem in justice applications is localization of a user of a\ncellular network using a call detail record (CDR), which typically reveals only\nthe base station and sector to which the user was connected. This precludes\nprecise estimation of location. Instead, one is limited to estimating a region\nof plausible locations (RPL) using static information such as sector antenna\norientation, beamwidth, and locations of nearby base stations. In this paper,\nwe propose a method for RPL estimation in which the shape bounding the RPL is\nderived from a model of the antenna pattern via the Friis Transmission\nEquation, and the size of the RPL is determined by mean distance to nearby base\nstations. The performance of the proposed method is evaluated by \"best server\"\nanalysis of measurements acquired from drive testing in the vicinity of Winter\nGarden, Florida, observing three 700 MHz-band LTE cellular networks serving\nthis area. Of the 16 sectors evaluated, the aggregate error rate (i.e.,\nfraction of users located outside the RPL estimated for the associated sector)\nis found to be 1.3%, with worst per-sector error rate of about 13.3% and error\nrates below 1.8% for 13 of the 16 sectors. The principal difficulty is shown to\nbe estimation of RPL size, which entails a tradeoff between minimizing RPL area\n(yielding the \"tightest\" localization) and minimizing error rate.", "published": "2025-03-30 00:36:52", "link": "http://arxiv.org/abs/2503.23263v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
