{"title": "BiToD: A Bilingual Multi-Domain Dataset For Task-Oriented Dialogue\n  Modeling", "abstract": "Task-oriented dialogue (ToD) benchmarks provide an important avenue to\nmeasure progress and develop better conversational agents. However, existing\ndatasets for end-to-end ToD modeling are limited to a single language,\nhindering the development of robust end-to-end ToD systems for multilingual\ncountries and regions. Here we introduce BiToD, the first bilingual\nmulti-domain dataset for end-to-end task-oriented dialogue modeling. BiToD\ncontains over 7k multi-domain dialogues (144k utterances) with a large and\nrealistic bilingual knowledge base. It serves as an effective benchmark for\nevaluating bilingual ToD systems and cross-lingual transfer learning\napproaches. We provide state-of-the-art baselines under three evaluation\nsettings (monolingual, bilingual, and cross-lingual). The analysis of our\nbaselines in different settings highlights 1) the effectiveness of training a\nbilingual ToD system compared to two independent monolingual ToD systems, and\n2) the potential of leveraging a bilingual knowledge base and cross-lingual\ntransfer learning to improve the system performance under low resource\ncondition.", "published": "2021-06-05 03:38:42", "link": "http://arxiv.org/abs/2106.02787v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related\n  Domains", "abstract": "Social media has become a valuable resource for the study of suicidal\nideation and the assessment of suicide risk. Among social media platforms,\nReddit has emerged as the most promising one due to its anonymity and its focus\non topic-based communities (subreddits) that can be indicative of someone's\nstate of mind or interest regarding mental health disorders such as\nr/SuicideWatch, r/Anxiety, r/depression. A challenge for previous work on\nsuicide risk assessment has been the small amount of labeled data. We propose\nan empirical investigation into several classes of weakly-supervised\napproaches, and show that using pseudo-labeling based on related issues around\nmental health (e.g., anxiety, depression) helps improve model performance for\nsuicide risk assessment.", "published": "2021-06-05 04:31:06", "link": "http://arxiv.org/abs/2106.02792v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Automated Evaluation of Open Domain Dialog via Diverse\n  Reference Augmentation", "abstract": "Multiple different responses are often plausible for a given open domain\ndialog context. Prior work has shown the importance of having multiple valid\nreference responses for meaningful and robust automated evaluations. In such\ncases, common practice has been to collect more human written references.\nHowever, such collection can be expensive, time consuming, and not easily\nscalable. Instead, we propose a novel technique for automatically expanding a\nhuman generated reference to a set of candidate references. We fetch plausible\nreferences from knowledge sources, and adapt them so that they are more fluent\nin context of the dialog instance in question. More specifically, we use (1) a\ncommonsense knowledge base to elicit a large number of plausible reactions\ngiven the dialog history (2) relevant instances retrieved from dialog corpus,\nusing similar past as well as future contexts. We demonstrate that our\nautomatically expanded reference sets lead to large improvements in\ncorrelations of automated metrics with human ratings of system outputs for\nDailyDialog dataset.", "published": "2021-06-05 08:18:41", "link": "http://arxiv.org/abs/2106.02833v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MergeDistill: Merging Pre-trained Language Models using Distillation", "abstract": "Pre-trained multilingual language models (LMs) have achieved state-of-the-art\nresults in cross-lingual transfer, but they often lead to an inequitable\nrepresentation of languages due to limited capacity, skewed pre-training data,\nand sub-optimal vocabularies. This has prompted the creation of an ever-growing\npre-trained model universe, where each model is trained on large amounts of\nlanguage or domain specific data with a carefully curated, linguistically\ninformed vocabulary. However, doing so brings us back full circle and prevents\none from leveraging the benefits of multilinguality. To address the gaps at\nboth ends of the spectrum, we propose MergeDistill, a framework to merge\npre-trained LMs in a way that can best leverage their assets with minimal\ndependencies, using task-agnostic knowledge distillation. We demonstrate the\napplicability of our framework in a practical setting by leveraging\npre-existing teacher LMs and training student LMs that perform competitively\nwith or even outperform teacher LMs trained on several orders of magnitude more\ndata and with a fixed model capacity. We also highlight the importance of\nteacher selection and its impact on student model performance.", "published": "2021-06-05 08:22:05", "link": "http://arxiv.org/abs/2106.02834v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERTnesia: Investigating the capture and forgetting of knowledge in BERT", "abstract": "Probing complex language models has recently revealed several insights into\nlinguistic and semantic patterns found in the learned representations. In this\narticle, we probe BERT specifically to understand and measure the relational\nknowledge it captures in its parametric memory. While probing for linguistic\nunderstanding is commonly applied to all layers of BERT as well as fine-tuned\nmodels, this has not been done for factual knowledge. We utilize existing\nknowledge base completion tasks (LAMA) to probe every layer of pre-trained as\nwell as fine-tuned BERT models(ranking, question answering, NER). Our findings\nshow that knowledge is not just contained in BERT's final layers. Intermediate\nlayers contribute a significant amount (17-60%) to the total knowledge found.\nProbing intermediate layers also reveals how different types of knowledge\nemerge at varying rates. When BERT is fine-tuned, relational knowledge is\nforgotten. The extent of forgetting is impacted by the fine-tuning objective\nand the training data. We found that ranking models forget the least and retain\nmore knowledge in their final layer compared to masked language modeling and\nquestion-answering. However, masked language modeling performed the best at\nacquiring new knowledge from the training data. When it comes to learning\nfacts, we found that capacity and fact density are key factors. We hope this\ninitial work will spur further research into understanding the parametric\nmemory of language models and the effect of training objectives on factual\nknowledge. The code to repeat the experiments is publicly available on GitHub.", "published": "2021-06-05 14:23:49", "link": "http://arxiv.org/abs/2106.02902v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Meta-Learning with Variational Semantic Memory for Word Sense\n  Disambiguation", "abstract": "A critical challenge faced by supervised word sense disambiguation (WSD) is\nthe lack of large annotated datasets with sufficient coverage of words in their\ndiversity of senses. This inspired recent research on few-shot WSD using\nmeta-learning. While such work has successfully applied meta-learning to learn\nnew word senses from very few examples, its performance still lags behind its\nfully supervised counterpart. Aiming to further close this gap, we propose a\nmodel of semantic memory for WSD in a meta-learning setting. Semantic memory\nencapsulates prior experiences seen throughout the lifetime of the model, which\naids better generalization in limited data settings. Our model is based on\nhierarchical variational inference and incorporates an adaptive memory update\nrule via a hypernetwork. We show our model advances the state of the art in\nfew-shot WSD, supports effective learning in extremely data scarce (e.g.\none-shot) scenarios and produces meaning prototypes that capture similar senses\nof distinct words.", "published": "2021-06-05 20:40:01", "link": "http://arxiv.org/abs/2106.02960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Taxonomy Completion with Concept Generation via Fusing\n  Relational Representations", "abstract": "Automatic construction of a taxonomy supports many applications in\ne-commerce, web search, and question answering. Existing taxonomy expansion or\ncompletion methods assume that new concepts have been accurately extracted and\ntheir embedding vectors learned from the text corpus. However, one critical and\nfundamental challenge in fixing the incompleteness of taxonomies is the\nincompleteness of the extracted concepts, especially for those whose names have\nmultiple words and consequently low frequency in the corpus. To resolve the\nlimitations of extraction-based methods, we propose GenTaxo to enhance taxonomy\ncompletion by identifying positions in existing taxonomies that need new\nconcepts and then generating appropriate concept names. Instead of relying on\nthe corpus for concept embeddings, GenTaxo learns the contextual embeddings\nfrom their surrounding graph-based and language-based relational information,\nand leverages the corpus for pre-training a concept name generator.\nExperimental results demonstrate that GenTaxo improves the completeness of\ntaxonomies over existing methods.", "published": "2021-06-05 21:50:13", "link": "http://arxiv.org/abs/2106.02974v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lifelong Learning of Hate Speech Classification on Social Media", "abstract": "Existing work on automated hate speech classification assumes that the\ndataset is fixed and the classes are pre-defined. However, the amount of data\nin social media increases every day, and the hot topics changes rapidly,\nrequiring the classifiers to be able to continuously adapt to new data without\nforgetting the previously learned knowledge. This ability, referred to as\nlifelong learning, is crucial for the real-word application of hate speech\nclassifiers in social media. In this work, we propose lifelong learning of hate\nspeech classification on social media. To alleviate catastrophic forgetting, we\npropose to use Variational Representation Learning (VRL) along with a memory\nmodule based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural\nNetwork). Experimentally, we show that combining variational representation\nlearning and the LB-SOINN memory module achieves better performance than the\ncommonly-used lifelong learning techniques.", "published": "2021-06-05 07:14:34", "link": "http://arxiv.org/abs/2106.02821v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Denoising Word Embeddings by Averaging in a Shared Space", "abstract": "We introduce a new approach for smoothing and improving the quality of word\nembeddings. We consider a method of fusing word embeddings that were trained on\nthe same corpus but with different initializations. We project all the models\nto a shared vector space using an efficient implementation of the Generalized\nProcrustes Analysis (GPA) procedure, previously used in multilingual word\ntranslation. Our word representation demonstrates consistent improvements over\nthe raw models as well as their simplistic average, on a range of tasks. As the\nnew representations are more stable and reliable, there is a noticeable\nimprovement in rare word evaluations.", "published": "2021-06-05 19:49:02", "link": "http://arxiv.org/abs/2106.02954v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-shot Task Adaptation using Natural Language", "abstract": "Imitation learning and instruction-following are two common approaches to\ncommunicate a user's intent to a learning agent. However, as the complexity of\ntasks grows, it could be beneficial to use both demonstrations and language to\ncommunicate with an agent. In this work, we propose a novel setting where an\nagent is given both a demonstration and a description, and must combine\ninformation from both the modalities. Specifically, given a demonstration for a\ntask (the source task), and a natural language description of the differences\nbetween the demonstrated task and a related but different task (the target\ntask), our goal is to train an agent to complete the target task in a zero-shot\nsetting, that is, without any demonstrations for the target task. To this end,\nwe introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a\nsource demonstration and a linguistic description of how the target task\ndiffers, learns to output a reward / value function that accurately describes\nthe target task. Our experiments show that on a diverse set of adaptations, our\napproach is able to complete more than 95% of target tasks when using\ntemplate-based descriptions, and more than 70% when using free-form natural\nlanguage.", "published": "2021-06-05 21:39:04", "link": "http://arxiv.org/abs/2106.02972v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End\n  Text-to-Speech", "abstract": "Text-to-speech (TTS) synthesis is the process of producing synthesized speech\nfrom text or phoneme input. Traditional TTS models contain multiple processing\nsteps and require external aligners, which provide attention alignments of\nphoneme-to-frame sequences. As the complexity increases and efficiency\ndecreases with every additional step, there is expanding demand in modern\nsynthesis pipelines for end-to-end TTS with efficient internal aligners. In\nthis work, we propose an end-to-end text-to-waveform network with a novel\nreinforcement learning based duration search method. Our proposed generator is\nfeed-forward and the aligner trains the agent to make optimal duration\npredictions by receiving active feedback from actions taken to maximize\ncumulative reward. We demonstrate accurate alignments of phoneme-to-frame\nsequence generated from trained agents enhance fidelity and naturalness of\nsynthesized audio. Experimental results also show the superiority of our\nproposed model compared to other state-of-the-art TTS models with internal and\nexternal aligners.", "published": "2021-06-05 08:08:37", "link": "http://arxiv.org/abs/2106.02830v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Human Listening and Live Captioning: Multi-Task Training for Speech\n  Enhancement", "abstract": "With the surge of online meetings, it has become more critical than ever to\nprovide high-quality speech audio and live captioning under various noise\nconditions. However, most monaural speech enhancement (SE) models introduce\nprocessing artifacts and thus degrade the performance of downstream tasks,\nincluding automatic speech recognition (ASR). This paper proposes a multi-task\ntraining framework to make the SE models unharmful to ASR. Because most ASR\ntraining samples do not have corresponding clean signal references, we\nalternately perform two model update steps called SE-step and ASR-step. The\nSE-step uses clean and noisy signal pairs and a signal-based loss function. The\nASR-step applies a pre-trained ASR model to training signals enhanced with the\nSE model. A cross-entropy loss between the ASR output and reference\ntranscriptions is calculated to update the SE model parameters. Experimental\nresults with realistic large-scale settings using ASR models trained on\n75,000-hour data show that the proposed framework improves the word error rate\nfor the SE output by 11.82% with little compromise in the SE quality.\nPerformance analysis is also carried out by changing the ASR model, the data\nused for the ASR-step, and the schedule of the two update steps.", "published": "2021-06-05 13:40:53", "link": "http://arxiv.org/abs/2106.02896v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "An Attribute-Aligned Strategy for Learning Speech Representation", "abstract": "Advancement in speech technology has brought convenience to our life.\nHowever, the concern is on the rise as speech signal contains multiple personal\nattributes, which would lead to either sensitive information leakage or bias\ntoward decision. In this work, we propose an attribute-aligned learning\nstrategy to derive speech representation that can flexibly address these issues\nby attribute-selection mechanism. Specifically, we propose a\nlayered-representation variational autoencoder (LR-VAE), which factorizes\nspeech representation into attribute-sensitive nodes, to derive an\nidentity-free representation for speech emotion recognition (SER), and an\nemotionless representation for speaker verification (SV). Our proposed method\nachieves competitive performances on identity-free SER and a better performance\non emotionless SV, comparing to the current state-of-the-art method of using\nadversarial learning applied on a large emotion corpora, the MSP-Podcast. Also,\nour proposed learning strategy reduces the model and training process needed to\nachieve multiple privacy-preserving tasks.", "published": "2021-06-05 06:19:14", "link": "http://arxiv.org/abs/2106.02810v2", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Lightweight Dual-channel Target Speaker Separation for Mobile Voice\n  Communication", "abstract": "Nowadays, there is a strong need to deploy the target speaker separation\n(TSS) model on mobile devices with a limitation of the model size and\ncomputational complexity. To better perform TSS for mobile voice communication,\nwe first make a dual-channel dataset based on a specific scenario, LibriPhone.\nSpecifically, to better mimic the real-case scenario, instead of simulating\nfrom the single-channel dataset, LibriPhone is made by simultaneously replaying\npairs of utterances from LibriSpeech by two professional artificial heads and\nrecording by two built-in microphones of the mobile. Then, we propose a\nlightweight time-frequency domain separation model, LSTM-Former, which is based\non the LSTM framework with source-to-noise ratio (SI-SNR) loss. For the\nexperiments on Libri-Phone, we explore the dual-channel LSTMFormer model and a\nsingle-channel version by a random single channel of Libri-Phone. Experimental\nresult shows that the dual-channel LSTM-Former outperforms the single-channel\nLSTMFormer with relative 25% improvement. This work provides a feasible\nsolution for the TSS task on mobile devices, playing back and recording\nmultiple data sources in real application scenarios for getting dual-channel\nreal data can assist the lightweight model to achieve higher performance.", "published": "2021-06-05 17:19:34", "link": "http://arxiv.org/abs/2106.02934v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Impact of data-splits on generalization: Identifying COVID-19 from cough\n  and context", "abstract": "Rapidly scaling screening, testing and quarantine has shown to be an\neffective strategy to combat the COVID-19 pandemic. We consider the application\nof deep learning techniques to distinguish individuals with COVID from\nnon-COVID by using data acquirable from a phone. Using cough and context\n(symptoms and meta-data) represent such a promising approach. Several\nindependent works in this direction have shown promising results. However, none\nof them report performance across clinically relevant data splits.\nSpecifically, the performance where the development and test sets are split in\ntime (retrospective validation) and across sites (broad validation). Although\nthere is meaningful generalization across these splits the performance\nsignificantly varies (up to 0.1 AUC score). In addition, we study the\nperformance of symptomatic and asymptomatic individuals across these three\nsplits. Finally, we show that our model focuses on meaningful features of the\ninput, cough bouts for cough and relevant symptoms for context. The code and\ncheckpoints are available at https://github.com/WadhwaniAI/cough-against-covid", "published": "2021-06-05 07:48:05", "link": "http://arxiv.org/abs/2106.03851v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
